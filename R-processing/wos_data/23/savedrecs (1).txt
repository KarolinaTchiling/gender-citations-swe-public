FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Reddy, N
   Rattani, A
   Derakhshani, R
AF Reddy, Narsi
   Rattani, Ajita
   Derakhshani, Reza
TI Generalizable deep features for ocular biometrics
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ocular recognition; Invariant feature representation; Data augmentation
ID PERIOCULAR RECOGNITION
AB There has been a continued interest in learning features that are generalizable across sensors and spectra for ocular biometrics. This is usually facilitated through a model that can learn features that are robust across pose, lighting conditions, spectra, and device sensor variations. In this paper, we propose an efficient deep learningbased feature extraction pipeline for learning the aforementioned generalizable features for ocular recognition. The proposed pipeline uses a relatively small Convolutional Neural Network (CNN) based feature extraction model along with a region of interest (ROI) detector and data augmenter. Our proposed CNN model has 36 times fewer parameters compared to the popular ResNet- 50. Cross dataset experiments on five benchmark datasets suggest that the proposed feature extractionmodel, trained only on 200 subjects fromthe VISOB dataset, reduces the error rate up to 7x when compared to the existing models. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Reddy, Narsi; Derakhshani, Reza] Univ Missouri, Dept CSEE, Kansas City, MO 64110 USA.
   [Rattani, Ajita] Wichita State Univ, Dept Elect Engn & Comp Sci, Kansas City, MO USA.
C3 University of Missouri System; University of Missouri Kansas City;
   Wichita State University
RP Reddy, N (corresponding author), Univ Missouri, Dept CSEE, Kansas City, MO 64110 USA.
EM sdhy7@mail.umkc.edu; ajita.rattani@wichita.edu; derakhshanir@umkc.edu
FU EyeVerify (dba ZOLOZ)
FX VISOB dataset was originally supported in part by a grant from EyeVerify
   (dba ZOLOZ). Reza Derakhshani is also a consultant for the company.
CR Ahuja K, 2017, PATTERN RECOGN LETT, V91, P17, DOI 10.1016/j.patrec.2017.04.002
   Alahmadi A, 2020, J INTELL FUZZY SYST, V38, P3041, DOI 10.3233/JIFS-190834
   Alonso-Fernandez F, 2016, PATTERN RECOGN LETT, V82, P92, DOI 10.1016/j.patrec.2015.08.026
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bakshi S, 2015, BIOCYBERN BIOMED ENG, V35, P30, DOI 10.1016/j.bbe.2014.05.003
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Cao ZCX, 2014, IEEE IMAGE PROC, P4967, DOI 10.1109/ICIP.2014.7026006
   Center for Biometrics and Security Research, 2010, CASIA IR IM DAT
   Chen D, 2012, LECT NOTES COMPUT SC, V7574, P566, DOI 10.1007/978-3-642-33712-3_41
   De Marsico M, 2015, PATTERN RECOGN LETT, V57, P17, DOI 10.1016/j.patrec.2015.02.009
   FOCS National Institute of Standards and Technology, 2010, FAC OC CHALL SER FOC
   FRGC National Institute of Standards and Technology, 2005, FAC REC GRAND CHALL
   Gangwar A, 2014, 2014 7TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP 2014), P714, DOI 10.1109/CISP.2014.7003871
   Garg R., 2018, HETEROGENEITY AWARE, P1, DOI [10.1109/BTAS.2018.8698551, DOI 10.1109/BTAS.2018.8698551]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   ICS, 2016, 1979512006 ICS ISOIE
   Jaderberg M, 2015, ADV NEUR IN, V28
   King DB, 2015, ACS SYM SER, V1214, P1
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kumari P, 2022, J KING SAUD UNIV-COM, V34, P1086, DOI 10.1016/j.jksuci.2019.06.003
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Lucio DR, 2019, SIBGRAPI, P178, DOI 10.1109/SIBGRAPI.2019.00032
   Marval-pérez LR, 2019, IEICE T FUND ELECTR, VE102A, P1351, DOI 10.1587/transfun.E102.A.1351
   Nie L, 2014, INT C PATT RECOG, P399, DOI 10.1109/ICPR.2014.77
   Padole C. N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P439, DOI 10.1109/ICB.2012.6199790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Raghavendra R, 2016, IEEE IMAGE PROC, P325, DOI 10.1109/ICIP.2016.7532372
   Raja KB, 2016, IEEE IMAGE PROC, P330, DOI 10.1109/ICIP.2016.7532373
   Raja KB, 2014, 2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS, P15, DOI 10.1109/BIOMS.2014.6951530
   Rattani A., 2019, SELFIE BIOMETRICS AD, DOI [10.1007/978-3-030-26972-2, DOI 10.1007/978-3-030-26972-2]
   Rattani A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P762, DOI 10.1109/BTAS.2017.8272767
   Rattani A, 2017, IMAGE VISION COMPUT, V59, P1, DOI 10.1016/j.imavis.2016.11.019
   Rattani A, 2016, IEEE IMAGE PROC, P320, DOI 10.1109/ICIP.2016.7532371
   Reddy N., 2018 IEEE INT S TECH, DOI DOI 10.1109/THS.2018.8574156
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Santos G, 2015, PATTERN RECOGN LETT, V57, P52, DOI 10.1016/j.patrec.2014.09.012
   Sequeira AF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P725, DOI 10.1109/BTAS.2017.8272762
   Sharma A, 2014, IEEE IMAGE PROC, P5007, DOI 10.1109/ICIP.2014.7026014
   Sharma V, 2019, J COMPL MED RES, V10, P1, DOI 10.5455/jcmr.20181028100040
   Tiong LCO, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132709
   Wang HT, 2004, IEEE IMAGE PROC, P1397
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Woodard D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P162, DOI DOI 10.1109/CVPRW.2010.5544621
   Zhao ZJ, 2018, IEEE T INF FOREN SEC, V13, P2937, DOI 10.1109/TIFS.2018.2833018
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
NR 48
TC 15
Z9 15
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 103996
DI 10.1016/j.imavis.2020.103996
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000006
DA 2024-07-18
ER

PT J
AU Zalluhoglu, C
   Ikizler-Cinbis, N
AF Zalluhoglu, Cemil
   Ikizler-Cinbis, Nazli
TI Collective Sports: A multi-task dataset for collective activity
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Collective activity recognition; Action recognition; Convolutional
   neural networks; Multi-task learning; LSTM
AB Collective activity recognition is an important subtask of human action recognition, where the existing datasets are mostly limited. In this paper, we look into this issue and introduce the Collective Sports (C-Sports) dataset, which is a novel benchmark dataset for multi-task recognition of both collective activity and sports categories. Various state-of-the-art techniques are evaluated on this dataset, together with multi-task variants which demonstrate increased performance. From the experimental results, we can say that while sports categories of the videos are inferred accurately, there is still room for improvement for collective activity recognition, especially regarding the generalization ability beyond previously unseen sports categories. In order to evaluate this ability, we introduce a novel evaluation protocol called unseen sports, where the training and test are carried out on disjoint sets of sports categories. The relatively lower recognition performances in this evaluation protocol indicate that the recognition models tend to be influenced by the surrounding context, rather than focusing on the essence of the collective activities. We believe that C-Sports dataset will stir further interest in this research direction. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zalluhoglu, Cemil; Ikizler-Cinbis, Nazli] Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
C3 Hacettepe University
RP Zalluhoglu, C (corresponding author), Hacettepe Univ, Dept Comp Engn, Ankara, Turkey.
EM cemil@cs.hacettepe.edu.tr; nazli@cs.hacettepe.edu.tr
RI ZALLUHOĞLU, CEMİL/G-6035-2013; Ikizler-Cinbis, Nazli/E-8961-2013
OI ZALLUHOĞLU, CEMİL/0000-0001-8716-6297; 
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   Research Program (1001) [116E102]
FX We would like to sincerely thank Emre Boran, Leyla Helin Cetin, Canberk
   Esmeliler and Hasan Serefal for their help in data collection and
   annotation. This work was supported in part by the Scientific and
   Technological Research Council of Turkey (TUBITAK) Research Program
   (1001), Project No 116E102.
CR Amer MR, 2013, IEEE I CONF COMP VIS, P1353, DOI 10.1109/ICCV.2013.171
   Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14
   Amer MR, 2014, LECT NOTES COMPUT SC, V8694, P572, DOI 10.1007/978-3-319-10599-4_37
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2019, IEEE T PATTERN ANAL
   [Anonymous], 2010, Advances in neural information processing systems
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], 2015, P 2015 IEEE INT C CO
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2016, CVPR
   [Anonymous], 2014, CVPR
   Antic B, 2014, LECT NOTES COMPUT SC, V8689, P33, DOI 10.1007/978-3-319-10590-1_3
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Caruana R., 1993, ICML, P41, DOI 10.1016/b978-1-55860-307-3.50012-5
   Choi W, 2014, IEEE T PATTERN ANAL, V36, P1242, DOI 10.1109/TPAMI.2013.220
   Choi W, 2009, IEEE ANTENNAS PROP, P1280
   Deng J., 2009, IEEE C COMP VIS PATT
   Deng ZW, 2016, PROC CVPR IEEE, P4772, DOI 10.1109/CVPR.2016.516
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Hajimirsadeghi H, 2015, PROC CVPR IEEE, P2596, DOI 10.1109/CVPR.2015.7298875
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kay W., 2017, CORR ABS170506950
   Khamis S, 2012, LECT NOTES COMPUT SC, V7572, P116, DOI 10.1007/978-3-642-33718-5_9
   Lin WY, 2016, IEEE T IMAGE PROCESS, V25, P1674, DOI 10.1109/TIP.2016.2531281
   Lin WY, 2013, IEEE T CIRC SYST VID, V23, P1980, DOI 10.1109/TCSVT.2013.2269780
   Lu L., 2019, IEEE T MULTIMEDIA
   Lu LH, 2018, NEUROCOMPUTING, V322, P195, DOI 10.1016/j.neucom.2018.09.060
   Majumdar S, 2012, CHANDOS ASIAN STUD, P215
   Shu  T., 2017, P IEEE COMP SOC C CO
   Solera F, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P7, DOI 10.1109/AVSS.2013.6636608
   Tang Y., 2019, IEEE T IMAGE PROCESS
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Tran KN, 2014, PATTERN RECOGN LETT, V44, P49, DOI 10.1016/j.patrec.2013.09.015
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Zalluhoglu C, 2019, J VIS COMMUN IMAGE R, V60, P170, DOI 10.1016/j.jvcir.2019.02.016
   Zhang P., 2019, IEEE T IMAGE PROCESS
NR 43
TC 19
Z9 20
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103870
DI 10.1016/j.imavis.2020.103870
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900015
DA 2024-07-18
ER

PT J
AU Zeng, XX
   Zhang, Y
   Wang, XD
   Chen, KR
   Li, D
   Yang, WJ
AF Zeng, Xianxian
   Zhang, Yun
   Wang, Xiaodong
   Chen, Kairui
   Li, Dong
   Yang, Weijun
TI Fine-Grained Image Retrieval via Piecewise Cross Entropy loss
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fine-Grained Image Retrieval; CNN; Piecewise cross entropy loss
ID SIMILARITY
AB Fine-Grained Image Retrieval is an important problem in computer vision. It is more challenging than the task of content-based image retrieval because it has small diversity within the different classes but large diversity in the same class. Recently, the cross entropy loss can be utilized to make Convolutional Neural Network (CNN) generate distinguish feature for Fine-Grained Image Retrieval, and it can obtain further improvement with some extra operations, such as Normalize-Scale layer. In this paper, we propose a variant of the cross entropy loss, named Piecewise Cross Entropy loss function, for enhancing model generalization and promoting the retrieval performance. Besides, the Piecewise Cross Entropy loss is easy to implement. We evaluate the performance of the proposed scheme on two standard fine-grained retrieval benchmarks, and obtain significant improvements over the state-of-the-art, with 11.8% and 3.3% over the previous work on CARS196 and CUB-200-2011, respectively. (C) 2019 Published by Elsevier B.V. reserved.
C1 [Zeng, Xianxian; Zhang, Yun; Wang, Xiaodong; Li, Dong] Guangdong Univ Technol, Automat, Guangzhou 510006, Peoples R China.
   [Chen, Kairui] Guangzhou Univ, Sch Mech & Elect Engn, Guangzhou 510006, Peoples R China.
   [Yang, Weijun] Guangzhou City Polytech, Dept Electromech Engn, Guangzhou 510405, Peoples R China.
C3 Guangdong University of Technology; Guangzhou University
RP Zhang, Y (corresponding author), Guangdong Univ Technol, Automat, Guangzhou 510006, Peoples R China.
EM yun@gdut.edu.cn
RI yang, weijun/HHS-5908-2022; Yang, Wei/GWV-4107-2022; Yang,
   Wei/HIA-0360-2022; Ling, Jie/JJF-9995-2023; Yang, Wei/JBJ-1928-2023;
   chen, kairui/AAS-4887-2020
OI yang, weijun/0000-0002-2585-8033; Chen, Kairui/0000-0002-6252-5502
FU National Natural Science Foundation of China [61503084, U1501251];
   Natural Science Foundation of Guangdong Province, China
   [2016A030310348]; Science and Technology Program of Guangzhou, China
   [201804010098]
FX This work was supported by National Natural Science Foundation of China:
   61503084, U1501251, Natural Science Foundation of Guangdong Province,
   China: 2016A030310348 and the Science and Technology Program of
   Guangzhou, China: 201804010098.
CR [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2014, P 3 INT C LEARN REPR
   [Anonymous], RENDICONTI CIRCOLO M
   [Anonymous], CALTECH UCSD BIRDS 2
   [Anonymous], 2019, ARXIV190306150
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dubey A, 2018, LECT NOTES COMPUT SC, V11216, P71, DOI 10.1007/978-3-030-01258-8_5
   Dubey A, 2018, ADV NEUR IN, V31
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Garcia N, 2019, IMAGE VISION COMPUT, V82, P18, DOI 10.1016/j.imavis.2019.01.001
   Golik P, 2013, INTERSPEECH, P1755
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu Tao, 2019, See better before looking closer: Weakly supervised data augmentation network for fine-grained visual classification
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang M, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P1262, DOI 10.1109/ICISCE.2016.270
   Jaderberg M, 2015, ADV NEUR IN, V28
   Krause J, 2016, LECT NOTES COMPUT SC, V9907, P301, DOI 10.1007/978-3-319-46487-9_19
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Li PH, 2018, PROC CVPR IEEE, P947, DOI 10.1109/CVPR.2018.00105
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sohn K, 2016, ADV NEUR IN, V29
   Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tamayol A, 2011, PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON NANOCHANNELS, MICROCHANNELS AND MINICHANNELS, 2010, PTS A AND B, P21
   Ustinova E, 2016, ADV NEUR IN, V29
   van der Maaten L, 2014, J MACH LEARN RES, V15, P3221
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang YM, 2018, PROC CVPR IEEE, P4148, DOI 10.1109/CVPR.2018.00436
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Xie LX, 2015, IEEE T MULTIMEDIA, V17, P636, DOI 10.1109/TMM.2015.2408566
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126
   Zheng HL, 2017, IEEE I CONF COMP VIS, P5219, DOI 10.1109/ICCV.2017.557
   Zheng XW, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1226
   Zheng XW, 2019, AAAI CONF ARTIF INTE, P9291
NR 41
TC 26
Z9 27
U1 13
U2 42
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103820
DI 10.1016/j.imavis.2019.10.006
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000007
DA 2024-07-18
ER

PT J
AU Zhang, W
   He, XJ
   Li, WY
   Zhang, Z
   Luo, YK
   Su, L
   Wang, P
AF Zhang, Wen
   He, Xujie
   Li, Wanyi
   Zhang, Zhi
   Luo, Yongkang
   Su, Li
   Wang, Peng
TI An integrated ship segmentation method based on discriminator and
   extractor
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ship segmentation; Sea fog; Classification; Interference Factor
   Discriminator; Ship extractor
ID RECONSTRUCTION; ALGORITHM
AB Ship segmentation is an important task in maritime surveillance systems. A great deal of research on image segmentation has been done in the past few years, but there appears to be some problems when directly utilizing them for ship segmentation under complex maritime background. The interference factors decreasing segmentation performance usually are from the peculiarity of complex maritime background, such as the existence of sea fog, large wakes and large waves. To deal with these interference factors, this paper presents an integrated ship segmentation method based on discriminator and extractor (ISDE). Different from traditional segmentation methods, our method consists of two components in light of the structure: Interference Factor Discriminator (IFD) and Ship Extractor (SE). SqueezeNet is employed for the implementation of IFD as the first step to make a judgment on what interference factors are contained in the input image. While DeepLabv3 + and improved DeepLabv3 + are employed for the implementation of SE as the second step to finally extract ships. We collect a ship segmentation dataset and conduct intensive experiments on it. The experimental results demonstrate that our method for ship segmentation outperforms state-of-the-art methods in terms of segmentation accuracy, especially for the images contain sea fog. Besides our method can run in real time as well. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Zhang, Wen; He, Xujie; Zhang, Zhi; Su, Li] Harbin Engn Univ China, Coll Automat, Harbin 150001, Peoples R China.
   [Li, Wanyi; Luo, Yongkang; Wang, Peng] Chinese Acad Sci, Inst Automat, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP He, XJ (corresponding author), Harbin Engn Univ, Coll Automat, Room 4138,Bldg 61,145 Nantong Ave, Harbin, Heilongjiang, Peoples R China.
EM hexujie@hrbeu.edu.cn
RI He, Xujie/JZD-4630-2024
OI Wang, Peng/0000-0002-8265-9866
FU National Key R&D Program Projects [2018YEB1601502]
FX This work was supported by National Key R&D Program Projects [grant
   number 2018YEB1601502].
CR Angelina S., 2012, 2012 International Conference on Computing, Electronics and Electrical Technologies (ICCEET 2012), P970, DOI 10.1109/ICCEET.2012.6203833
   [Anonymous], J OPTOELECTRONICS LA
   [Anonymous], IMAGE SEGMENTATION N
   [Anonymous], 2015, COMPUTER SCI
   [Anonymous], 2017, C COMP VIS PATT REC
   Bai XZ, 2016, IEEE T CYBERNETICS, V46, P3259, DOI 10.1109/TCYB.2015.2501848
   Bai XZ, 2016, APPL SOFT COMPUT, V46, P128, DOI 10.1016/j.asoc.2016.05.004
   Bloisi D.D., 2015, P 2015 12 IEEE INT C, DOI [10.1109/AVSS.2015.7301727, DOI 10.1109/AVSS.2015.7301727]
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dong Jiankang, 2013, Journal of Computer Aided Design & Computer Graphics, V25, P397
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Iandola Forrest, 2017, 2017 International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), DOI 10.1145/3125502.3125606
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Ji KF, 2013, PROC SPIE, V8918, DOI 10.1117/12.2031494
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Khokher MR, 2013, IET IMAGE PROCESS, V7, P201, DOI 10.1049/iet-ipr.2012.0082
   King DB, 2015, ACS SYM SER, V1214, P1
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu ZY, 2016, IMAGE VISION COMPUT, V48-49, P14, DOI 10.1016/j.imavis.2015.12.005
   Liu ZY, 2014, PATTERN RECOGN, V47, P2839, DOI 10.1016/j.patcog.2014.03.005
   Liu Z, 2013, PROCEEDINGS OF THE 2013 IEEE INTERNATIONAL CONFERENCE ON EVOLVABLE SYSTEMS (ICES), P9, DOI 10.1109/ICES.2013.6613276
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Oliva D, 2013, J APPL MATH, DOI 10.1155/2013/575414
   Prasad DK, 2017, IEEE T INTELL TRANSP, V18, P1993, DOI 10.1109/TITS.2016.2634580
   Ramire WA, 2018, OCEAN ENG, V166, P26, DOI 10.1016/j.oceaneng.2018.07.056
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Senthilkumaran N, 2009, 2009 INTERNATIONAL CONFERENCE ON ADVANCES IN RECENT TECHNOLOGIES IN COMMUNICATION AND COMPUTING (ARTCOM 2009), P844, DOI 10.1109/ARTCom.2009.219
   Shen JH, 2005, J INFRARED MILLIM W, V24, P224
   Tao WB, 2007, OPT ENG, V46, DOI 10.1117/1.2823159
   Van den Bergh M, 2015, INT J COMPUT VISION, V111, P298, DOI 10.1007/s11263-014-0744-2
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   Wang XY, 2007, PROC SPIE, V6786, DOI 10.1117/12.748937
   Wang ZH, 2019, OCEAN ENG, V183, P270, DOI 10.1016/j.oceaneng.2019.04.085
   Wei Y, 2019, OCEAN ENG, V178, P463, DOI 10.1016/j.oceaneng.2019.03.015
   Wijaya AP, 2015, OCEAN ENG, V106, P261, DOI 10.1016/j.oceaneng.2015.07.009
   Zhang Q, 2018, J MACH LEARN RES, V18, P1
   Zhang TX, 2006, J INFRARED MILLIM W, V25, P295
   Zhang Y, 2017, OCEAN ENG, V141, P53, DOI 10.1016/j.oceaneng.2017.06.022
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao ZX, 2014, IET IMAGE PROCESS, V8, P150, DOI 10.1049/iet-ipr.2011.0128
NR 45
TC 21
Z9 21
U1 0
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103824
DI 10.1016/j.imavis.2019.11.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000011
DA 2024-07-18
ER

PT J
AU Xing, CD
   Wang, ZS
   Ouyang, Q
   Dong, C
   Duan, CW
AF Xing, Changda
   Wang, Zhisheng
   Ouyang, Quan
   Dong, Chong
   Duan, Chaowei
TI Image fusion method based on spatially masked convolutional sparse
   representation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sparse representation (SR); Image fusion; Spatially masked convolutional
   sparse representation (SMCSR); Two-scale gradient optimization
ID MULTI-FOCUS; TRANSFORM; REGULARIZATION; APPROXIMATION; ALGORITHMS;
   EQUATIONS; FREQUENCY; FRAMEWORK
AB The technique of sparse representation (SR) has achieved enormous successes in multi-source image fusion. However, using SR-based fusion methods, there exists the performance degradation in limited detail preservation caused by the independent processing of image patches. To remedy this deficiency, in this paper, a novel method based on spatially masked convolutional sparse representation (SMCSR-based) is proposed for image fusion, which is composed of three steps as follows. Firstly, low-frequency and high-frequency bands are separated from each source image by the designed two-scale gradient optimization approach. Secondly, the SMCSR model is employed to fuse the high-frequency bands, and the "average" rule is applied to the combination of the low-frequency bands. At last, the fused image is reconstructed. Compared with traditional SR-based algorithms, the proposed SMCSR-based method is focused on entire images instead of those divided patches to reduce detail-loss. In addition, this method can overcome the difficulty in the selection of decomposition levels originated by multi-scale transform (MST) based fusion strategies, as well as also suppress the boundary artifacts produced by the traditional convolutional sparse representation (CSR) model. Extensive experiments and related analysis are given to verify the effectiveness of the proposed SMCSR-based fusion method. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Xing, Changda; Wang, Zhisheng; Ouyang, Quan; Dong, Chong; Duan, Chaowei] Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 211106, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Ouyang, Q (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Automat Engn, Nanjing 211106, Jiangsu, Peoples R China.
EM ouyangquan@nuaa.edu.cn
RI Ouyang, Quan/AGS-0163-2022; Xing, Changda/AAE-8282-2019
OI Ouyang, Quan/0000-0002-4381-4763; Xing, Changda/0000-0002-0387-4497;
   Wang, Zhisheng/0000-0002-2973-680X
FU National Natural Science Foundation of China [61473144]; Aeronautical
   Science Foundation of China [20162852031]
FX This work was supported by the National Natural Science Foundation of
   China (61473144) and the Aeronautical Science Foundation of China
   (20162852031).
CR Aghdasi F, 1996, IEEE T IMAGE PROCESS, V5, P611, DOI 10.1109/83.491337
   Barigye SJ, 2018, ACS COMB SCI, V20, P75, DOI 10.1021/acscombsci.7b00155
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Burt P. J., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P173, DOI 10.1109/ICCV.1993.378222
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Cao AX, 2016, DESTECH TRANS MAT, P78
   Cao L, 2015, IEEE SIGNAL PROC LET, V22, P220, DOI 10.1109/LSP.2014.2354534
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Dong ZK, 2018, NEUROCOMPUTING, V308, P172, DOI 10.1016/j.neucom.2018.04.066
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Duan LY, 2018, IEEE T IMAGE PROCESS, V27, DOI 10.1109/TIP.2018.2818008
   Golub GH, 1999, SIAM J MATRIX ANAL A, V21, P185, DOI 10.1137/S0895479897326432
   Gu SH, 2015, IEEE I CONF COMP VIS, P1823, DOI 10.1109/ICCV.2015.212
   Hara K, 2014, IEEE SIGNAL PROC LET, V21, P742, DOI 10.1109/LSP.2014.2314647
   Heide F, 2015, PROC CVPR IEEE, P5135, DOI 10.1109/CVPR.2015.7299149
   Hill P., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P487
   Hou YT, 2007, IEEE INFOCOM SER, P1, DOI 10.1109/INFCOM.2007.9
   Kalantari N. K., 2017, ACM Trans. Graph., V36, DOI DOI 10.1145/3072959.3073609
   Kihl O, 2015, PATTERN RECOGN, V48, P1174, DOI 10.1016/j.patcog.2014.11.013
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li ST, 2011, INFORM FUSION, V12, P74, DOI 10.1016/j.inffus.2010.03.002
   Li YN, 2018, NEUROCOMPUTING, V283, P73, DOI 10.1016/j.neucom.2017.12.046
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   López J, 2018, INFORM SCIENCES, V429, P377, DOI 10.1016/j.ins.2017.11.035
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Piella G., 2003, IEEE INT C IM PROC I
   Rusu C, 2017, IEEE T SIGNAL PROCES, V65, P4367, DOI 10.1109/TSP.2017.2712120
   Ryder M M, 2010, IEEE T SIGNAL PROCES, V58, P2194
   SHEN CY, 1989, IEEE T ANTENN PROPAG, V37, P1032, DOI 10.1109/8.34141
   Tian YZ, 2017, APPL OPTICS, V56, P6300, DOI 10.1364/AO.56.006300
   Tropp JA, 2006, SIGNAL PROCESS, V86, P572, DOI 10.1016/j.sigpro.2005.05.030
   Wohlberg B., 2016, IEEE INT C IM PROC I, P5135
   Wohlberg B, 2016, IEEE T IMAGE PROCESS, V25, P301, DOI 10.1109/TIP.2015.2495260
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xing CD, 2018, IET IMAGE PROCESS, V12, P2300, DOI 10.1049/iet-ipr.2018.5554
   Xing CD, 2018, INFRARED PHYS TECHN, V94, P232, DOI 10.1016/j.infrared.2018.09.016
   Xydeas C. S, 2000, MIL TECH COUR, V56, P181, DOI 10.5937/vojtehg0802181B
   Yang B, 2012, INFORM FUSION, V13, P10, DOI 10.1016/j.inffus.2010.04.001
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yin HP, 2016, NEUROCOMPUTING, V216, P216, DOI 10.1016/j.neucom.2016.07.039
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zeiler MD, 2010, PROC CVPR IEEE, P2528, DOI 10.1109/CVPR.2010.5539957
   Zhang BH, 2016, NEUROCOMPUTING, V174, P733, DOI 10.1016/j.neucom.2015.09.092
   Zhang L., 2013, IEEE INT C IM PROC, P1473, DOI DOI 10.1109/ICIP.2012.6467149
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhang Q, 2016, IEEE T IMAGE PROCESS, V25, P2045, DOI 10.1109/TIP.2016.2524212
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao CC, 2018, INFORM SCIENCES, V459, P135, DOI 10.1016/j.ins.2018.05.032
NR 56
TC 13
Z9 13
U1 2
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2019
VL 90
AR 103806
DI 10.1016/j.imavis.2019.08.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU0WT
UT WOS:000501400600003
DA 2024-07-18
ER

PT J
AU Mou, WX
   Tzelepis, C
   Mezaris, V
   Gunes, H
   Patras, I
AF Mou, Wenxuan
   Tzelepis, Christos
   Mezaris, Vasileios
   Gunes, Hatice
   Patras, Ioannis
TI A deep generic to specific recognition model for group membership
   analysis using non-verbal cues
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Non-verbal behavior analysis; Group membership; Automatic group
   analysis; Deep learning
AB Automatic understanding and analysis of groups has attracted increasing attention in the vision and multimedia communities in recent years. However, little attention has been paid to the automatic analysis of the non-verbal behaviors and how this can be utilized for analysis of group membership, i.e., recognizing which group each individual is part of. This paper presents a novel Support Vector Machine (SVM) based Deep Specific Recognition Model (DeepSRM) that is learned based on a generic recognition model. The generic recognition model refers to the model trained with data across different conditions, i.e., when people are watching movies of different types. Although the generic recognition model can provide a baseline for the recognition model trained for each specific condition, the different behaviors people exhibit in different conditions limit the recognition performance of the generic model. Therefore, the specific recognition model is proposed for each condition separately and built on top of the generic recognition model. A number of experiments are conducted using a database aiming to study group analysis while each group (i.e., four participants together) were watching a number of long movie segments. Our experimental results show that the proposed deep specific recognition model (44%) outperforms the generic recognition model (26%). The recognition of group membership also indicates that the non-verbal behaviors of individuals within a group share commonalities. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Mou, Wenxuan; Tzelepis, Christos; Patras, Ioannis] Queen Mary Univ London, London, England.
   [Gunes, Hatice] Univ Cambridge, Cambridge, England.
   [Tzelepis, Christos; Mezaris, Vasileios] Ctr Res & Technol Hellas CERTH, Informat Technol Inst, Thessaloniki, Greece.
C3 University of London; Queen Mary University London; University of
   Cambridge; Centre for Research & Technology Hellas
RP Mou, WX (corresponding author), Queen Mary Univ London, London, England.
EM w.mou@qmul.ac.uk
RI Tzelepis, Christos/O-6413-2015
OI Tzelepis, Christos/0000-0002-2036-9089; Patras,
   Ioannis/0000-0003-3913-4738
FU CSC/Queen Mary joint PhD scholarship; EPSRC [EP/L00416X/1]; EU's Horizon
   2020 programme [H2020-693092 MOVING]; EPSRC [EP/L00416X/1] Funding
   Source: UKRI
FX The work of Wenxuan Mou is supported by CSC/Queen Mary joint PhD
   scholarship. The work of Hatice Gunes and Wenxuan Mou is partially
   funded by the EPSRC under its IDEAS Factory Sandpits call on Digital
   Personhood (grant ref: EP/L00416X/1). The work of Christos Tzelepis and
   Vasileios Mezaris is supported by EU's Horizon 2020 programme under
   grant agreement H2020-693092 MOVING.
CR Allen J. A., 2017, SMALL GROUP RES
   [Anonymous], 2017, P IEEE INT C AUT FAC
   [Anonymous], ARXIV151106040
   [Anonymous], ARXIV E PRINTS
   [Anonymous], 2015, IEEE T PATTERN ANAL
   Avci U., 2014, P ACM WORKSH UND MOD
   Barsade S.G., 1998, COMPOSITION
   Barsade S. G., 2002, ADM SCI Q
   Bhullar N., 2012, N AM J PSYCHOL
   Celiktutan Oya., 2017, IEEE Transactions on Affective Computing
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dhall A., 2015, IEEE T AFFECT COMPUT
   Dhall A., 2012, P AS C COMP VIS ACCV
   Dhall A., 2015, P AFF COMP INT INT A
   Dhall A, 2015, IEEE INT CONF AUTOMA
   Eberl M., 2010, Handbook of Partial Least Squares, P487, DOI DOI 10.1007/978-3-540-32827-8_22
   Gallagher Andrew, 2009, P IEEE INT C COMP VI
   Goette L., 2006, IMPACT GROUP MEMBERS
   Hagad J. L., 2011, P IEEE INT C SOC COM
   Huang Xiaohua, 2015, P BRIT MACH VIS C BM
   Hung H., 2010, IEEE T MULTIMEDIA
   Jain V., 2014, P INT WORKSH AUD VIS
   Lan T., 2012, P IEEE INT C COMP VI
   Lan Tian., 2012, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Lehmann-Willenbrock N., 2017, SMALL GROUP RES
   Leite I., 2015, P ACM IEEE INT C HUM
   Mou W., 2016, P ACM C MULT ACMMM
   Mou W., 2017, P IEEE INT C AUT FAC
   Mou WX, 2015, IEEE INT CONF AUTOMA
   Mou Wenxuan, 2016, P IEEE INT C COMP VI
   Platt JC, 2000, ADV NEUR IN, P61
   Reiter-Palmon R., 2017, SMALL GROUP RES
   Salas E., 2015, HUM FACTORS J HUM FA
   Sanchez J., 2013, INT J COMPUT VIS IJC
   Sanchez-Cortes D., 2012, IEEE T MULTIMEDIA
   Saxena Shobhit, 2008, ADV CONCEPTS INTELLI
   Smith E. R., 2007, J PERS SOC PSYCHOL
   Theano Development Team, 2016, ARXIV160502688
   Vascon S., 2016, COMPUT VIS IMAGE UND
   Wang H., 2013, INT J COMPUT VIS IJC
   Zhang L, 2016, P IEEE INT C COMP VI
NR 41
TC 2
Z9 2
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2019
VL 81
BP 42
EP 50
DI 10.1016/j.imavis.2018.09.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA HO1ZJ
UT WOS:000460710900005
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Oñoro-Rubio, D
   López-Sastre, RJ
   Redondo-Cabrera, C
   Gil-Jiménez, P
AF Onoro-Rubio, Daniel
   Lopez-Sastre, Roberto J.
   Redondo-Cabrera, Carolina
   Gil-Jimenez, Pedro
TI The challenge of simultaneous object detection and pose estimation: A
   comparative study
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pose estimation; Viewpoint estimation; Object detection; Deep learning;
   Convolutional neural network
AB Detecting objects and estimating their pose remains as one of the major challenges of the computer vision research community. There exists a compromise between localizing the objects and estimating their viewpoints. The detector ideally needs to be view-invariant, while the pose estimation process should be able to generalize towards the category-level. This work is an exploration of using deep learning models for solving both problems simultaneously. For doing so, we propose three novel deep learning architectures, which are able to perform a joint detection and pose estimation, where we gradually decouple the two tasks. We also investigate whether the pose estimation problem should be solved as a classification or regression problem, being this still an open question in the computer vision community. We detail a comparative analysis of all our solutions and the methods that currently define the state of the art for this problem. We use PASCAL3D+ and ObjectNet3D datasets to present the thorough experimental evaluation and main results. With the proposed models we achieve the state-of-the-art performance in both datasets. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Onoro-Rubio, Daniel; Lopez-Sastre, Roberto J.; Redondo-Cabrera, Carolina; Gil-Jimenez, Pedro] Univ Alcala, GRAM, Alcala De Henares 28805, Spain.
C3 Universidad de Alcala
RP López-Sastre, RJ (corresponding author), Univ Alcala, GRAM, Alcala De Henares 28805, Spain.
EM daniel.onoro@edu.uah.es; robertoj.lopez@uah.es;
   carolina.redondoc@edu.uah.es; pedro.gil@uah.es
RI Jiménez, Pedro Gil/F-4066-2017; Sastre, Roberto Lopez/AAA-2180-2019
OI Jiménez, Pedro Gil/0000-0002-6991-0702; Sastre, Roberto
   Lopez/0000-0002-2477-0152
FU Spanish Ministry of Economy, Industry and Competitiveness
   [TEC2016-80326-R]; NVIDIA Corporation
FX This work is supported by project PREPEATE, with reference
   TEC2016-80326-R, of the Spanish Ministry of Economy, Industry and
   Competitiveness. We gratefully acknowledge the support of NVIDIA
   Corporation with the donation of a GPU used for this research. Cloud
   computing resources were kindly provided through a Microsoft Azure for
   Research Award.
CR [Anonymous], 2016, 3DV
   [Anonymous], BMVC
   [Anonymous], 2013, P INT C MACH LEAR
   [Anonymous], 2016, ECCV
   [Anonymous], 2014ABS14091556 CORR
   [Anonymous], ICML
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2009, PROC IEEE C COMPUT V
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2012, CVPR
   [Anonymous], 2015, P IEEE INT C COMPUTE
   [Anonymous], 2015, INT C COMP VIS
   [Anonymous], 2013, IEEE INT C COMP VIS
   [Anonymous], CVPR
   [Anonymous], 2012, CVPR
   [Anonymous], ICCV
   Bao SY, 2011, IMAGE VISION COMPUT, V29, P569, DOI 10.1016/j.imavis.2011.08.001
   Beyer L, 2015, LECT NOTES COMPUT SC, V9358, P157, DOI 10.1007/978-3-319-24947-6_13
   Girshick R., 2013, IEEE Comput. Soc., P580
   Glasner D, 2012, IMAGE VISION COMPUT, V30, P923, DOI 10.1016/j.imavis.2012.09.006
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1990, NeurIPS, P396
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Lopez-Sastre R. J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1052, DOI 10.1109/ICCVW.2011.6130367
   Lopez-Sastre R.J., 2010, ICARO: Image Collection of Annotated Real-world Objects
   Massa F., 2016, BMVC
   Ozuysal M., 2009, CVPR
   Redondo-Cabrera C, 2016, LECT NOTES COMPUT SC, V9911, P118, DOI 10.1007/978-3-319-46478-7_8
   Redondo-cabrera Carolina., 2014, BMVC
   Ren S., 2015, NEURAL INFORM PROCES, V28, P91, DOI DOI 10.1109/TPAMI.2016.2577031
   Savarese S., 2008, ECCV
   Singhal Amit., 2001, B IEEE COMPUTER SOC, V24
   Thomas A., 2006, CVPR
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Xiang Y, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATIONS AND COMPUTING (ICSPCC)
NR 37
TC 6
Z9 6
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 109
EP 122
DI 10.1016/j.imavis.2018.09.013
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Roopalakshmi, R
AF Roopalakshmi, R.
TI A brand new application of visual-audio fingerprints: Estimating the
   position of the pirate in a theater - A case study
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camcorder piracy; Content-Based video Copy Detection (CBCD); Visual
   fingerprints; Audio signatures; SURF; Projective geometry; Geometric
   distortions
ID WATERMARKING
AB Combating against camcorder piracy requires identification of the theater and show time information, followed by the estimation of camcorder location in a theater from which an illegal recording was made, in order to find out the pirate and limit the number of pirate suspects. State-of-the-art pirate position estimation frameworks employ watermarking techniques to approximate the position of the pirate in a movie theater. However, watermarks are fragile in nature and involve complex procedures, which may damage the video content. To solve this, a novel forensic tracking framework, which exploits visual-audio fingerprints for estimating the location of the pirate in a theater without embedding digital watermarks is presented. Precisely, the proposed framework first spatio-temporally aligns the source movie and captured video contents, then estimates the geometric distortions and consequently derives the illegal capture location in a theater by exploiting multimodal features. The case study results in the form of sophisticated In-theater experiments prove that, it is certainly possible to estimate the illegal capture location in a theater with a mean absolute error of (38.25, 22.45, 11.11) cm, by employing multimodal fingerprints. In this way, the proposed article demonstrates a brand-new application of video fingerprinting for investigating the location of illegal camcorder capture in a theater, which is applicable for digital cinema applications. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Roopalakshmi, R.] Alvas Inst Engn & Technol, Mangaluru, Karnataka, India.
RP Roopalakshmi, R (corresponding author), Alvas Inst Engn & Technol, Mangaluru, Karnataka, India.
EM drroopalakshmir@aiet.org.in
CR [Anonymous], 2008, DIG CIN SYST SPEC VE
   [Anonymous], 2006, P IEEE INT C AC SPEE
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2009, J ELECTRON IMAGING
   Baudry S, 2010, INT CONF ACOUST SPEE, P1786, DOI 10.1109/ICASSP.2010.5495422
   Baudry S, 2009, IEEE IMAGE PROC, P2889, DOI 10.1109/ICIP.2009.5413438
   Chen L, 2008, PATTERN RECOGN LETT, V29, P1824, DOI 10.1016/j.patrec.2008.05.015
   Cheng H, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P489
   Cheng H., 2003, SPATIAL TEMPORAL HIS, P735
   Chupeau B., 2008, P SPIE SECURITY FORE, VX, P6819
   Chupeau B., 2007, P SPIE VISUAL COMMN, P6508
   CMPDA, 2011, REP EC CONS MOV PIR
   Delannay D, 2003, PROC SPIE, V5020, P481, DOI 10.1117/12.477292
   Delannay D, 2001, PROC SPIE, V4314, P149, DOI 10.1117/12.435395
   Haitsma J, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P487, DOI 10.1109/ICIP.2001.958534
   Lee MJ, 2010, IEEE T MULTIMEDIA, V12, P605, DOI 10.1109/TMM.2010.2061221
   Lefebvre F., 2009, P SPIE IS T J ELECT, V7254
   Nakashima Y, 2009, IEEE T MULTIMEDIA, V11, P443, DOI 10.1109/TMM.2009.2012938
   Roopalakshmi R., 2012, ELSEVIER SIGNAL PROC, DOI [10.1016/ignorespacesj.sigpro.2012.06.004, DOI 10.1016/IGNORESPACESJ.SIGPRO.2012.06.004]
   Saracoglu A, 2009, INT WORK CONTENT MUL, P213, DOI 10.1109/CBMI.2009.12
   Thakur PS, 2015, 2015 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING AND COMMUNICATION ENGINEERING ICACCE 2015, P515, DOI 10.1109/ICACCE.2015.122
NR 21
TC 0
Z9 0
U1 2
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2018
VL 76
BP 48
EP 63
DI 10.1016/j.imavis.2018.06.001
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GR1TB
UT WOS:000442333500005
DA 2024-07-18
ER

PT J
AU Citraro, L
   Mahmoodi, S
   Darekar, A
   Vollmer, B
AF Citraro, Leonardo
   Mahmoodi, Sasan
   Darekar, Angela
   Vollmer, Brigitte
TI Extended three-dimensional rotation invariant local binary patterns
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Local binary patterns (LBPs); Three-dimensions; Rotation invariance;
   Texture classification
ID TEXTURE CLASSIFICATION; RECOGNITION
AB This paper presents a new set of three-dimensional rotation invariant texture descriptors based on the well-known local binary patterns (LBPs). In the approach proposed here, we extend an existing three-dimensional LBP based on the region growing algorithm using existing features developed exquisitely for two-dimensional LBPs (pixel intensities and differences). We have conducted experiments on a synthetic dataset of three-dimensional randomly rotated texture images in order to evaluate the discriminatory power and the rotation invariant properties of our descriptors as well as those of other two-dimensional and three-dimensional texture descriptors. Our results demonstrate the effectiveness of the extended LBPs and improvements against other state-of-the-art hand-crafted three-dimensional texture descriptors on this dataset. Furthermore, we prove that the extended LBPs can be used in medical datasets to discriminate between MR images of oxygenated and non-oxygenated brain tissues of newborn babies. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Citraro, Leonardo; Mahmoodi, Sasan] Univ Southampton, Sch Elect & Comp Sci, Bldg 1, Southampton SO17 1BJ, Hants, England.
   [Darekar, Angela] Univ Hosp Southampton NHS Fdn Trust, Dept Med Phys, Southampton SO16 6YD, Hants, England.
   [Vollmer, Brigitte] Univ Southampton, Fac Med, Clin Neurosci Clin & Expt Sci, Southampton, Hants, England.
   [Vollmer, Brigitte] Univ Hosp Southampton NHS Fdn Trust, Southampton SO16 6YD, Hants, England.
C3 University of Southampton; University of Southampton; University
   Hospital Southampton NHS Foundation Trust; University of Southampton;
   University of Southampton; University Hospital Southampton NHS
   Foundation Trust
RP Citraro, L (corresponding author), Univ Southampton, Sch Elect & Comp Sci, Bldg 1, Southampton SO17 1BJ, Hants, England.
EM ldo.citraro@gmail.com; sm3y07@soton.ac.uk; angela.darekar@uhs.nhs.uk;
   b.vollmer@soton.ac.uk
RI vollmer, brigitte/AAB-3132-2020
OI vollmer, brigitte/0000-0003-4088-5336
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], INT C IM VIS COMP NZ
   [Anonymous], 2003, GEODESIC MATH USE IT
   [Anonymous], 2006, BMVC
   Banerjee Jyotirmoy, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P26, DOI 10.1007/978-3-642-37410-4_3
   Biasotti S, 2016, VISUAL COMPUT, V32, P217, DOI 10.1007/s00371-015-1146-3
   Depeursinge A, 2014, MED IMAGE ANAL, V18, P176, DOI 10.1016/j.media.2013.10.005
   Fehr J, 2008, INT C PATT RECOG, P616
   HARWOOD D, 1995, PATTERN RECOGN LETT, V16, P1, DOI 10.1016/0167-8655(94)00061-7
   Huynh T., 2012, ACCV 2012 WORKSH COM
   Kovalev VA, 2001, IEEE T MED IMAGING, V20, P424, DOI 10.1109/42.925295
   Li SZ, 2005, LECT NOTES COMPUT SC, V3723, P44
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Majtner T, 2014, LECT NOTES COMPUT SC, V8466, P186, DOI 10.1007/978-3-319-07148-0_17
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Paulhac L, 2008, LECT NOTES COMPUT SC, V5112, P670, DOI 10.1007/978-3-540-69812-8_66
   Paulhac L, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P135
   Pietikainen M., 2013, 2013 INT C BIOMETRIC, P1
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Werghi N, 2015, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR.2015.7298867
   Werghi N, 2015, IEEE T IMAGE PROCESS, V24, P220, DOI 10.1109/TIP.2014.2370253
   Werghi N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P562, DOI 10.1109/ICCVW.2013.78
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao G, 2007, LECT NOTES COMPUT SC, V4358, P165
   Zhao G, 2006, INT C PATT RECOG, P211
NR 26
TC 16
Z9 16
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2017
VL 62
BP 8
EP 18
DI 10.1016/j.imavis.2017.03.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EX3GV
UT WOS:000403121500002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kim, HK
   Kim, D
AF Kim, Hak-Kyoung
   Kim, Daijin
TI Robust pedestrian detection under deformation using simple boosted
   features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Regionlet; Pedestrian detection; Selective max pooling; Selective
   difference pooling; Boosted tree-structured classifier
AB Many existing methods for pedestrian detection have the limited detection performance in case of deformation such as large appearance variations. To overcome this limitation, we propose a novel pedestrian detection method that uses two low-level boosted features to detect pedestrians despite the presence of deformations. One is a boosted max feature (BMF) that uses a max operation to aggregate a selected pair of features to make them invariant to deformation. Another is a boosted difference feature (BDF) that uses a difference operation between a selected pair of features to improve localization accuracy of pedestrian detection. We incorporate a spatial pyramid pool method that uses multiple sized blocks to increase the richness of boosted features in a local region and use a RealBoost method to train a tree-structured classifier for the proposed pedestrian detection method. We also apply a region-of-interest method to the detected results to remove false positives effectively. Our proposed detector achieved log-average miss rates of 19.95%, 10.39%, 36.12%, and 39.57% on the Caltech-USA, INRIA, ETH, and TUD-Brussels dataset, respectively, which are the lowest among those of all state-of-the-art pedestrian detectors. (C) 2017 Elsevier B.V. All rights reserved.
EM khk88@postech.ac.kr; dkim@postech.ac.kr
FU MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   'IT Consilience Creative Program' [NIPA-2014-H0201-14-1001]; NIPA
   (National IT Industry Promotion Agency); ICT R&D program of MSIP/IITP
   [14-824-09-005]
FX This research was partially supported by the MSIP (Ministry of Science,
   ICT and Future Planning), Korea, under the 'IT Consilience Creative
   Program' (NIPA-2014-H0201-14-1001) supervised by the NIPA (National IT
   Industry Promotion Agency). This research was partially supported by the
   ICT R&D program of MSIP/IITP (14-824-09-005, Development of Predictive
   Visual Intelligence Technology).
CR [Anonymous], 2016, SCALE AWARE FAST R C, P2
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Boureau YL, 2011, IEEE I CONF COMP VIS, P2651, DOI 10.1109/ICCV.2011.6126555
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   CAI Z, 2016, EUR C COMP VIS, P354, DOI DOI 10.1007/978-3-319-46493-0_22
   Chen XG, 2015, LECT NOTES COMPUT SC, V9008, P354, DOI 10.1007/978-3-319-16628-5_26
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollar P., 2010, BMVC 2010, DOI DOI 10.5244/C.24.68
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dollar Piotr, 2009, BMVC, DOI 10.5244/ C.23.91
   Ess A, 2008, PROC CVPR IEEE, P1857
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb P. F., PATTERN ANAL MACH IN, V32
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Geiger A., 2012, CVPR
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hosang J, 2015, PROC CVPR IEEE, P4073, DOI 10.1109/CVPR.2015.7299034
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Nam W., 2014, P 27 INT C NEURAL IN, V27
   Paisitkriangkrai S, 2014, LECT NOTES COMPUT SC, V8692, P546, DOI 10.1007/978-3-319-10593-2_36
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Tian YL, 2015, IEEE I CONF COMP VIS, P1904, DOI 10.1109/ICCV.2015.221
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   van de Sande KEA, 2011, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2011.6126456
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Walk S., 2010, CVPR 2010, DOI DOI 10.1109/CVPR.2010.5540102
   Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638
   Yan JJ, 2013, PROC CVPR IEEE, P3033, DOI 10.1109/CVPR.2013.390
   Yan JJ, 2012, PROC CVPR IEEE, P3124, DOI 10.1109/CVPR.2012.6248045
   Yu T., 2009, P 26 ANN INT C MACH, P1169, DOI DOI 10.1145/1553374.1553523
   Zhang S., 2015, FILTERED CHANNEL FEA
   Zhang S, 2014, CVPR
NR 39
TC 9
Z9 9
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2017
VL 61
BP 1
EP 11
DI 10.1016/j.imavis.2017.02.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EU7HK
UT WOS:000401205700001
DA 2024-07-18
ER

PT J
AU Hu, JL
AF Hu, Junlin
TI Discriminative transfer learning with sparsity regularization for
   single-sample face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Transfer learning; Discriminant analysis; Sparsity regularization;
   Single-sample face recognition
ID TRAINING SAMPLE; IMAGE; EIGENFACES; DATABASE; FLDA; AGE
AB Discriminant analysis is an important technique for face recognition because it can extract discriminative features to classify different persons. However, most existing discriminant analysis methods fail to work for single-sample face recognition (SSFR) because there is only a single training sample per person such that the within-class variation of this person cannot be estimated in such scenario. In this paper, we present a new discriminative transfer learning (DTL) approach for SSFR, where discriminant analysis is performed on a multiple-sample generic training set and then transferred into the single-sample gallery set. Specifically, our DTL learns a feature projection to minimize the intra-class variation and maximize the inter-class variation of samples in the training set, and minimize the difference between the generic training set and the gallery set, simultaneously. To make the DTL be robust to outliers and noise, we employ a sparsity regularizer to regularize the DTL and further propose a novel discriminative transfer learning with sparsity regularization (DTLSR) method. Experimental results on three face datasets including the FERET, CAS-PEAL-R1, and real world LFW datasets are presented to show the efficacy of the proposed methods. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Hu, Junlin] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Hu, JL (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM jhu007@e.ntu.edu.sg
OI Hu, Junlin/0000-0002-0117-3494
FU National Research Foundation, Singapore, under its Interactive Digital
   Media (IDM) Strategic Research Programme
FX Partial of this research was carried out at the Rapid-Rich Object Search
   (ROSE) Lab at the Nanyang Technological University, Singapore. The ROSE
   Lab is supported by the National Research Foundation, Singapore, under
   its Interactive Digital Media (IDM) Strategic Research Programme.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2007, 0749 U MASS
   [Anonymous], 2006, Advances in Neural Information Processing Systems, DOI DOI 10.1007/S10994-007-5040-8
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Deng WH, 2014, PATTERN RECOGN, V47, P3738, DOI 10.1016/j.patcog.2014.06.020
   Gao QX, 2008, APPL MATH COMPUT, V205, P726, DOI 10.1016/j.amc.2008.05.019
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Hu JL, 2015, INT CONF BIOMETR, P272, DOI 10.1109/ICB.2015.7139095
   Kan MN, 2013, PATTERN RECOGN, V46, P2497, DOI 10.1016/j.patcog.2013.01.037
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Lu JW, 2007, PATTERN RECOGN LETT, V28, P2401, DOI 10.1016/j.patrec.2007.08.004
   Lu JW, 2016, IEEE T CIRC SYST VID, V26, P529, DOI 10.1109/TCSVT.2015.2412831
   Lu JW, 2015, IEEE I CONF COMP VIS, P3721, DOI 10.1109/ICCV.2015.424
   Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu JW, 2015, IEEE T INF FOREN SEC, V10, P79, DOI 10.1109/TIFS.2014.2363792
   Lu JW, 2015, IEEE T INF FOREN SEC, V10, P1371, DOI 10.1109/TIFS.2015.2408431
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Lu JW, 2013, IEEE T CIRC SYST VID, V23, P1070, DOI 10.1109/TCSVT.2013.2241353
   Lu JW, 2013, IEEE T INF FOREN SEC, V8, P510, DOI 10.1109/TIFS.2013.2243146
   Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Lu JW, 2012, IEEE T INF FOREN SEC, V7, P944, DOI 10.1109/TIFS.2012.2188389
   Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926
   Martinez A. M., 1998, THE AR FACE DATABASE
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Su Y, 2010, PROC CVPR IEEE, P2699, DOI 10.1109/CVPR.2010.5539990
   Sui YL, 2013, INT SYM CODE GENER, P1
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu JX, 2002, PATTERN RECOGN LETT, V23, P1711, DOI 10.1016/S0167-8655(02)00134-4
   Yan HB, 2014, NEUROCOMPUTING, V143, P134, DOI 10.1016/j.neucom.2014.06.012
   Yang M, 2013, IEEE I CONF COMP VIS, P689, DOI 10.1109/ICCV.2013.91
   Zhang DQ, 2005, APPL MATH COMPUT, V163, P895, DOI 10.1016/j.amc.2004.04.016
   Zhuang LS, 2013, PROC CVPR IEEE, P3546, DOI 10.1109/CVPR.2013.455
NR 41
TC 19
Z9 20
U1 0
U2 19
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 48
EP 57
DI 10.1016/j.imavis.2016.08.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800006
DA 2024-07-18
ER

PT J
AU Hui, Z
   Liu, WB
   Lam, KM
AF Hui, Zhuo
   Liu, Wenbo
   Lam, Kin-Man
TI A novel correspondence-based face-hallucination method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face hallucination; Face super-resolution; Corresponding-based method;
   Local kernel
ID IMAGE; SUPERRESOLUTION; RECOGNITION; ILLUMINATION; TEXTURE
AB This paper addresses the problem of estimating high-resolution (HR) facial images from a single low resolution (LR) input. We assume that the input LR and estimated HR images are under the same view-point and illumination condition, i.e. the setting of image super-resolution. At the core of our techniques is that the facial images can be decomposed as a texture vector, characterized in terms of the appearance, and a shape vector, characterized in terms of the geometry variations. This enables a two-stage successive estimation framework that is geometry aware and obviates the needs in sophisticated optimizations. In particular, the proposed technique first solves for appearance of the HR faces form the correspondence derived between an interpolated LR face and its corresponding HR face. Given the texture of the HR faces, we incorporate optical flow to solve the local structure at sub-pixel level for the HR faces: here, we use additional geometry inspired priors to further regularize the solution. Experimental results show that our method outperforms other state-of-the-art methods in terms of retaining the facial-feature shape and the estimation of novel features. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Hui, Zhuo; Liu, Wenbo] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
   [Lam, Kin-Man] Hong Kong Polytech Univ, Dept Elect & Informat Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Carnegie Mellon University; Hong Kong Polytechnic University
RP Hui, Z (corresponding author), Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
EM huizhuo1987@gmail.com
RI Hui, Zhuo/AAA-6568-2020
OI hui, zhuo/0000-0001-9564-0155
CR [Anonymous], 2012, MATRIX COMPUTATIONS
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905
   Bishop TE, 2012, IEEE T PATTERN ANAL, V34, P972, DOI 10.1109/TPAMI.2011.168
   Biswas S, 2012, IEEE T PATTERN ANAL, V34, P2019, DOI 10.1109/TPAMI.2011.278
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Burt P., 1984, Proc. SPIE, V0575, P173, DOI [10.1117/12.966501, DOI 10.1117/12.966501]
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P4381, DOI 10.1109/TIP.2015.2463223
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   De Benet J. S., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P361, DOI 10.1145/258734.258882
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Fan W., 2007, Proc. of the CVPR, P1, DOI DOI 10.1109/CVPR.2007.383001
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Hu Y, 2011, IEEE T IMAGE PROCESS, V20, P433, DOI 10.1109/TIP.2010.2063437
   Hui Z, 2012, INT CONF ACOUST SPEE, P1265, DOI 10.1109/ICASSP.2012.6288119
   Hui Z, 2012, PATTERN RECOGN LETT, V33, P718, DOI 10.1016/j.patrec.2011.12.001
   Jaiswal Ajay, 2012, International Journal of Computer Vision and Image Processing, V2, P48, DOI 10.4018/ijcvip.2012040104
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Liu C, 2001, PROC CVPR IEEE, P192
   Liu C, 2011, IEEE T PATTERN ANAL, V33, P978, DOI 10.1109/TPAMI.2010.147
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Peng X., 2016, IEEE T CYBEM
   Peng X., 2015, IEEE T NEURAL NETW L
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Vetter T, 1997, J OPT SOC AM A, V14, P2152, DOI 10.1364/JOSAA.14.002152
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2009, IEEE SIGNAL PROC MAG, V26, P98, DOI 10.1109/MSP.2008.930649
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 36
TC 6
Z9 6
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 171
EP 184
DI 10.1016/j.imavis.2017.01.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800018
DA 2024-07-18
ER

PT J
AU Ko, H
   Shim, HS
   Choi, O
   Kuo, CCJ
AF Ko, Hyunsuk
   Shim, Han Suk
   Choi, Ouk
   Kuo, C. -C. Jay
TI Robust uncalibrated stereo rectification with constrained geometric
   distortions (USR-CGD)
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Projective rectification; Regularization; Homography; Epipolar geometry;
   Fundamental matrix; Geometric distortion; Constrained optimization
ID PROJECTIVE RECTIFICATION; VISION
AB A novel algorithm for uncalibrated stereo image-pair rectification under the constraint of geometric distortion, called USR-CGD, is presented in this work. Although it is straightforward to define a rectifying transformation (or homography) given the epipolar geometry, many existing algorithms have unwanted geometric distortions as a side effect. To obtain rectified images with reduced geometric distortions while maintaining a small rectification error, we parameterize the homography by considering the influence of various kinds of geometric distortions. Next, we define several geometric measures and incorporate them into a new cost function as regularization terms for parameter optimization. Finally, we propose a constrained adaptive optimization scheme to allow a balanced performance between the rectification error and the geometric error. Extensive experimental results are provided to demonstrate the superb performance of the proposed USR-CGD method, which outperforms existing algorithms by a significant margin. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Ko, Hyunsuk] Elect & Telecommun Res Inst, Daejeon 34129, South Korea.
   [Shim, Han Suk] LG Elect Inc, IVI AVN Dev Team, Seoul 135860, South Korea.
   [Choi, Ouk] Incheon Natl Univ, Dept Elect Engn, Incheon 22012, South Korea.
   [Kuo, C. -C. Jay] Univ Southern Calif, Ming Hsieh Dept Elect Engn, Los Angeles, CA 90089 USA.
   [Kuo, C. -C. Jay] Univ Southern Calif, Signal & Image Proc Inst, Los Angeles, CA 90089 USA.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI); LG
   Electronics; Incheon National University; University of Southern
   California; University of Southern California
RP Ko, H (corresponding author), Elect & Telecommun Res Inst, Daejeon 34129, South Korea.
RI Ko, Hyunsuk/ABC-9258-2020; Kuo, C.-C. Jay/A-7110-2011
OI Kuo, C.-C. Jay/0000-0001-9474-5035
FU Institute for Information & Communications Technology Promotion (IITP)
   grant - Korea government (MSIP) [B0117-16-1006]
FX This work was supported by Institute for Information & Communications
   Technology Promotion (IITP) grant funded by the Korea government (MSIP)
   (B0117-16-1006, Development and Standardization of 5th Generation
   Video/Audio Coding Technology for Ultra High Quality Media Services).
CR AYACHE N, 1991, IEEE T PATTERN ANAL, V13, P73, DOI 10.1109/34.67633
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   Fusiello A, 2011, MACH VISION APPL, V22, P663, DOI 10.1007/s00138-010-0270-3
   Georgiev M, 2013, IEEE IMAGE PROC, P24, DOI 10.1109/ICIP.2013.6738006
   Gluckman J, 2001, PROC CVPR IEEE, P111
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Isgro F., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P297, DOI 10.1109/ICIAP.1999.797611
   Loop C., 1999, Comput. Vision Pattern Recognit, V1, P1125, DOI [10.1109/CVPR.1999.786928, DOI 10.1109/CVPR.1999.786928]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818
   Mallon J, 2005, IMAGE VISION COMPUT, V23, P643, DOI 10.1016/j.imavis.2005.03.002
   Pollefeys M., 2001, P IEEE C COMP VIS PA, V1, P111
   Wu HHP, 2005, J INTELL ROBOT SYST, V42, P71, DOI 10.1007/s10846-004-3023-6
   Yuan YX, 2000, ICIAM, V99, P271
   Zilly F., 2010, P 3DPVT
NR 18
TC 10
Z9 12
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 98
EP 114
DI 10.1016/j.imavis.2017.01.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gunes, H
   Hung, HL
AF Gunes, Hatice
   Hung, Hayley
TI Is automatic facial expression recognition of emotions coming to a dead
   end? The rise of the new kids on the block
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Biometrics Conference
CY OCT, 2015
CL London, ENGLAND
DE Opinion paper; Facial expression recognition; New emotional and social
   signals
C1 [Gunes, Hatice] Univ Cambridge, Comp Lab, Cambridge CB2 1TN, England.
   [Hung, Hayley] Delft Univ Technol, Delft, Netherlands.
C3 University of Cambridge; Delft University of Technology
RP Gunes, H (corresponding author), Univ Cambridge, Comp Lab, Cambridge CB2 1TN, England.
EM Hatice.Gunes@cl.cam.ac.uk; H.Hung@tudelft.nl
FU EPSRC [EP/L00416X/1] Funding Source: UKRI
CR Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 3
TC 28
Z9 30
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
BP 6
EP 8
DI 10.1016/j.imavis.2016.03.013
PN 1
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA ED8BO
UT WOS:000389097100003
OA Green Accepted, hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Zhu, F
   Shao, L
   Xie, J
   Fang, Y
AF Zhu, Fan
   Shao, Ling
   Xie, Jin
   Fang, Yi
TI From handcrafted to learned representations for human action
   recognition: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human action recognition; Handcrafted features; Deep learning;
   Convolutional neural network; Dictionary learning
ID IMAGE CLASSIFICATION; ALGORITHM; MODEL
AB Human action recognition is an important branch among the studies of both human perception and computer vision systems. Along with the development of artificial intelligence, deep learning techniques have gained remarkable reputation when dealing with image categorization tasks (e.g., object detection and classification). However, since human actions normally present in the form of sequential image frames, analyzing human action data requires significantly increased computational power than still images when deep learning techniques are employed. Such a challenge has been the bottleneck for the migration of learning based image representation techniques to action sequences, so that the old fashioned handcrafted human action representations are still widely used for human action recognition tasks. On the other hand, since handcrafted representations are usually ad-hoc and overfit to specific data, they are incapable of being generalized to deal with various realistic scenarios. Consequently, resorting to deep learning action representations for human action recognition tasks is eventually a natural option. In this work, we provide a detailed overview of recent advancements in human action representations. As the first survey that covers both handcrafted and learning-based action representations, we explicitly discuss the superiorities and limitations of exiting techniques from both kinds. The ultimate goal of this survey is to provide comprehensive analysis and comparisons between learning-based and handcrafted action representations respectively, so as to inspire action recognition researchers towards the study of both kinds of representation techniques. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zhu, Fan; Xie, Jin; Fang, Yi] NYU, Multimedia & Visual Comp Ldb, New York, NY 10003 USA.
   [Zhu, Fan; Xie, Jin; Fang, Yi] New York Univ Abu Dhabi, Elect & Comp Engn, Abu Dhabi, U Arab Emirates.
   [Shao, Ling] Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
C3 New York University; New York University Abu Dhabi; Northumbria
   University
RP Fang, Y (corresponding author), NYU, Multimedia & Visual Comp Ldb, New York, NY 10003 USA.; Fang, Y (corresponding author), New York Univ Abu Dhabi, Elect & Comp Engn, Abu Dhabi, U Arab Emirates.
EM yfang@nyu.edu
RI Shao, Ling/D-3535-2011; zhu, fan/HMK-5557-2023
OI Shao, Ling/0000-0002-8264-6117
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], 2005, INT WORKSH VIS SURV
   [Anonymous], 1998, GENETIC PROGRAMMING
   [Anonymous], 2006, P 9 EUR C COMP VIS 1
   [Anonymous], 2003, P IEEE INT C COMP VI
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], ACM INT C MACH LEARN
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], 2014, CVPR
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIV14054506
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2006, P EUR C COMP VIS GRA
   [Anonymous], 2008, BRIT MACH VIS C
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2009, BMVC
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], ARXIV14085093
   [Anonymous], 2013, IEEE INT C COMP VIS
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], ACM INT C UB COMP
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIV150105964
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 1966, ANN MATH STAT
   [Anonymous], 2014, ARXIV14062199CS
   [Anonymous], 2004, EUR C COMP VIS
   [Anonymous], 2010, IEEE C COMP VIS PATT
   [Anonymous], 2014, ABS14053531 CORR
   [Anonymous], EUR C COMP VIS
   [Anonymous], INT JOINT C ART INT
   [Anonymous], ACM INT C MULT
   [Anonymous], LARGE SCALE KERNEL M
   [Anonymous], 2010, EUR C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C FAST PROC PHOT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2010, EUR C COMP VIS
   [Anonymous], PC MAG COM
   [Anonymous], 2014, 2 INT C LEARN REPR I
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C PATT REC
   [Anonymous], 2008, EUR C COMP VIS
   [Anonymous], 2012, CoRR
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], 2009, Construction and Analysis of a Large Scale Image Ontology
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 1997, INTRO WAVELETS WAVEL
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Buccino G, 2004, BRAIN LANG, V89, P370, DOI 10.1016/S0093-934X(03)00356-0
   CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K
   Diwadkar VA, 1997, PSYCHOL SCI, V8, P302, DOI 10.1111/j.1467-9280.1997.tb00442.x
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Gers FA, 2003, J MACH LEARN RES, V3, P115, DOI 10.1162/153244303768966139
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Harris C., 1988, P ALV VIS C, P5210
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hyvärinen A, 2009, COMPUT IMAGING VIS, V39, P1
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Jones S, 2014, PROC CVPR IEEE, P604, DOI 10.1109/CVPR.2014.84
   Keysers C, 2003, EXP BRAIN RES, V153, P628, DOI 10.1007/s00221-003-1603-5
   Kim HJ, 2006, LECT NOTES COMPUT SC, V4233, P177
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Le QV, 2011, PROC CVPR IEEE
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Ning F, 2005, IEEE T IMAGE PROCESS, V14, P1360, DOI 10.1109/TIP.2005.852470
   Parameswaran V, 2006, INT J COMPUT VISION, V66, P83, DOI 10.1007/s11263-005-3671-4
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Pulvermüller F, 2005, J COGNITIVE NEUROSCI, V17, P884, DOI 10.1162/0898929054021111
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Schacter Daniel, 2011, PSYCHOL EUROPEAN EDI
   Shao L, 2014, IEEE T NEUR NET LEAR, V25, P1359, DOI 10.1109/TNNLS.2013.2293418
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Siddiqui M., 2010, COMPUTER VISION PATT, P1, DOI [10.1109/cvprw.2010.5543618, DOI 10.1109/CVPRW.2010.5543618]
   SOTAK GE, 1989, COMPUT VISION GRAPH, V48, P147, DOI 10.1016/S0734-189X(89)80036-2
   Spencer TE, 2002, FRONT BIOSCI-LANDMRK, V7, pD1879, DOI 10.2741/spencer
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Zeiler M.D., European conference on computer vision, P818
   Zhen XT, 2014, INFORM SCIENCES, V281, P295, DOI 10.1016/j.ins.2014.05.021
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
   Zhu Youding., 2007, LECT NOTES COMPUT SC, P408
NR 114
TC 84
Z9 91
U1 0
U2 42
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 42
EP 52
DI 10.1016/j.imavis.2016.06.007
PN 2
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300002
DA 2024-07-18
ER

PT J
AU Martinez, B
   Valstar, MF
AF Martinez, Brais
   Valstar, Michel F.
TI <i>L</i><sub>2,1</sub>-based regression and prediction accumulation
   across views for robust facial landmark detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial landmark detection; regression; 300 W challenge
ID FACE ALIGNMENT
AB We propose a new methodology for facial landmark detection. Similar to other state-of-the-art methods, we rely on the use of cascaded regression to perform inference, and we use a feature representation that results from concatenating 66 HOG descriptors, one per landmark. However, we propose a novel regression method that substitutes the commonly used Least Squares regressor. This new method makes use of the L-2,L-1 norm, and it is designed to increase the robustness of the regressor to poor initialisations (e.g., due to large out of plane head poses) or partial occlusions. Furthermore, we propose to use multiple initialisations, consisting of both spatial translation and 4 head poses corresponding to different pan rotations. These estimates are aggregated into a single prediction in a robust manner. Both strategies are designed to improve the convergence behaviour of the algorithm, so that it can cope with the challenges of in-the-wild data. We further detail some important experimental details, and show extensive performance comparisons highlighting the performance improvement attained by the method proposed here. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Martinez, Brais; Valstar, Michel F.] Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.
C3 University of Nottingham
RP Martinez, B (corresponding author), Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.
EM brais.martinez@nottingham.ac.uk; michel.valstar@nottingham.ac.uk
FU European Union [645378 ARIA-VALUSPA]
FX The work of Dr. Valstar and Dr. Martinez is funded by the European Union
   Horizon 2020 Research and Innovation Programme under grant agreement no.
   645378 ARIA-VALUSPA.
CR [Anonymous], BRIT MACH VIS C
   [Anonymous], ICCVW
   [Anonymous], 2013, INT C COMP VIS WORKS
   Asthana A., 2014, COMPUTER VISION PATT
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Chang C.-C., ACM T INTELLIGENT SY, V2
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Liu J., 2009, P 25 C UNCERTAINTY A, P339, DOI DOI 10.5555/1795114.1795154
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Orozco J., IMAGE VISION COMPUTI
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C., 2013, COMP VIS PATT REC WO
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tzimiropoulos G., 2013, INT C COMP VIS
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Xing JL, 2014, PROC CVPR IEEE, P1829, DOI 10.1109/CVPR.2014.236
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 31
TC 19
Z9 21
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2016
VL 47
BP 36
EP 44
DI 10.1016/j.imavis.2015.09.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO5LL
UT WOS:000377824500005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Do, HN
   Jadaliha, M
   Choi, J
   Lim, CY
AF Do, Huan N.
   Jadaliha, Mahdi
   Choi, Jongeun
   Lim, Chae Young
TI Feature selection for position estimation using an omnidirectional
   camera
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vision-based localization; Appearance-based localization; Feature
   selection; Gaussian process regression; Hyperparameter estimation;
   Empirical Bayes methods
ID ROBOT NAVIGATION; VISION; LOCALIZATION; INFORMATION
AB This paper considers visual feature selection to implement position estimation using an omnidirectional camera. The localization is based on a maximum likelihood estimation (MLE) with a map from optimally selected visual features using Gaussian process (GP) regression. In particular, the collection of selected features over a surveillance region is modeled by a multivariate GP with unknown hyperparameters. The hyperparameters are identified through the learning process by an MLE, which are used for prediction in an empirical Bayes fashion. To select features, we apply a backward sequential elimination technique in order to improve the quality of the position estimation with compressed features for efficient localization. The excellent results of the proposed algorithm are illustrated by the experimental studies with different visual features under both indoor and outdoor real-world scenarios. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Do, Huan N.; Jadaliha, Mahdi; Choi, Jongeun] Michigan State Univ, Dept Mech Engn, E Lansing, MI 48824 USA.
   [Choi, Jongeun] Michigan State Univ, Dept Elect & Comp Engn, E Lansing, MI 48824 USA.
   [Lim, Chae Young] Michigan State Univ, Dept Stat & Probabil, E Lansing, MI 48824 USA.
C3 Michigan State University; Michigan State University; Michigan State
   University
RP Choi, J (corresponding author), 428 S Shaw Lane,Room 2459, E Lansing, MI 48824 USA.
EM dohuan@msu.edu; jadaliha@msu.edu; jchoi@egr.msu.edu; lim@stt.msu.edu
OI Choi, Jongeun/0000-0002-7532-5315
FU National Science Foundation through CAREER award [CMMI-0846547]; Vietnam
   Education Foundation [G-3-10180]; Directorate For Engineering; Div Of
   Civil, Mechanical, & Manufact Inn [0846547] Funding Source: National
   Science Foundation
FX This work has been supported by the National Science Foundation through
   CAREER award CMMI-0846547. Mr. Do has been supported by the Vietnam
   Education Foundation (G-3-10180) fellowship. The authors would like to
   thank Mr. Alexander Robinson from Thornapple Kellogg High School and Ms.
   Tam Le from the Department of Computer Science and Engineering, Michigan
   State University for their contributions in the preparation of the
   experiments.
CR [Anonymous], 2020, Feature Extraction and Image Processing
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Blaer P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1031, DOI 10.1109/ROBOT.2002.1013491
   Bonin-Font F, 2008, J INTELL ROBOT SYST, V53, P263, DOI 10.1007/s10846-008-9235-4
   Botterill T., 2008, Proceedings of the 23rd International Conference Image and Vision Computing, P1
   Brooks A, 2008, IEEE T ROBOT, V24, P1341, DOI 10.1109/TRO.2008.2004887
   Choi S, 2015, J DYN SYST-T ASME, V137, DOI 10.1115/1.4028148
   Demonceaux C, 2011, IMAGE VISION COMPUT, V29, P840, DOI 10.1016/j.imavis.2011.09.007
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903
   Dovgalecs V, 2013, ADV MULTIMED, V2013, DOI 10.1155/2013/175064
   Dupuis Y, 2013, IMAGE VISION COMPUT, V31, P580, DOI 10.1016/j.imavis.2013.04.001
   Fernandes J. C. A., 2006, P INT C NEXT GEN WEB, P157
   Ferris B, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2480
   Guo BF, 2009, IEEE T SYST MAN CY A, V39, P36, DOI 10.1109/TSMCA.2008.2007977
   Hadjidemetriou E, 2004, IEEE T PATTERN ANAL, V26, P831, DOI 10.1109/TPAMI.2004.32
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Higdon D, 2008, J AM STAT ASSOC, V103, P570, DOI 10.1198/016214507000000888
   Jadaliha M, 2013, IEEE T SIGNAL PROCES, V61, P223, DOI 10.1109/TSP.2012.2223695
   Jang GJ, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P1037, DOI 10.1109/ROBOT.2002.1013492
   Jeong WY, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P2570, DOI 10.1109/IROS.2006.281708
   Kanan C, 2012, PLOS ONE, V7, P133, DOI 10.1371/journal.pone.0029740
   KELLER JM, 1985, IEEE T SYST MAN CYB, V15, P580, DOI 10.1109/TSMC.1985.6313426
   Kim JH, 2009, COMPUT STAT DATA AN, V53, P3735, DOI 10.1016/j.csda.2009.04.009
   Konishi S, 2008, SPRINGER SER STAT, P211
   Kosecká J, 2003, PROC CVPR IEEE, P3
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Menegatti E, 2004, ROBOT AUTON SYST, V48, P17, DOI 10.1016/j.robot.2004.05.003
   Menegatti E, 2004, ROBOT AUTON SYST, V47, P251, DOI 10.1016/j.robot.2004.03.014
   Ohnishi N, 2013, IMAGE VISION COMPUT, V31, P511, DOI 10.1016/j.imavis.2012.11.004
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y
   Salomon D., 2004, Data Compression: the Complete Reference, V4th ed.
   Schairer T, 2011, IEEE INT C INT ROBOT, P4229, DOI 10.1109/IROS.2011.6048206
   Scharstein D, 2001, IMAGE VISION COMPUT, V19, P763, DOI 10.1016/S0262-8856(00)00105-0
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Thrun S, 1998, MACH LEARN, V33, P41, DOI 10.1023/A:1007554531242
   Torralba A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P273
   Vlassis N, 2001, IEEE INT CONF ROBOT, P499, DOI 10.1109/ROBOT.2001.932599
   Wells G, 1996, IMAGE VISION COMPUT, V14, P715, DOI 10.1016/0262-8856(96)89022-6
   Wells G, 2001, J INTELL ROBOT SYST, V30, P95, DOI 10.1023/A:1008198321503
   Xu YF, 2011, SENSORS-BASEL, V11, P3051, DOI 10.3390/s110303051
NR 42
TC 16
Z9 16
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2015
VL 39
BP 1
EP 9
DI 10.1016/j.imavis.2015.04.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CM2WQ
UT WOS:000357543400001
DA 2024-07-18
ER

PT J
AU Guo, GD
   Mu, GW
AF Guo, Guodong
   Mu, Guowang
TI A framework for joint estimation of age, gender and ethnicity on a large
   database
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Joint estimation of age, gender and ethnicity; A general framework;
   Partial least squares (PLS); Canonical correlation analysis (CCA);
   Regularized CCA; Kernel PLS (KPLS); Kernel CCA (KCCA); Regularized KCCA;
   Least squares CCA
ID CANONICAL CORRELATION-ANALYSIS; CLASSIFICATION; RECOGNITION; POSE
AB Human age, gender and ethnicity are valuable demographic characteristics. They are also important soft biometric traits useful for human identification or verification. We present a framework that can estimate the three traits jointly. The joint estimation framework could deal with the mutual influence of age, gender, and ethnicity implicitly. Under this joint estimation framework, we explore different methods for simultaneous estimation of age, gender, and ethnicity. The canonical correlation analysis (CCA) based methods, and partial least squares (PLS) models are explored under our joint estimation framework. Both the linear and nonlinear methods are investigated to measure the performance. We also validate some extensions of these methods, such as the least squares formulations of the CCA methods. We found some consistent ranking of these methods under our joint estimation framework. More importantly, we found that the CCA based methods can derive an extremely low dimensionality in estimating age, gender and ethnicity. An analysis of this property is given based on the rank theory. The experiments are conducted on a very large database containing more than 55,000 face images. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Guo, Guodong] W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
   [Mu, Guowang] Hebei Univ Technol, Sch Sci, Tianjin 300401, Peoples R China.
C3 West Virginia University; Hebei University of Technology
RP Guo, GD (corresponding author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
EM guodong.guo@mail.wvu.edu
RI Guo, Guodong/M-5066-2015
OI Guo, Guodong/0000-0001-9583-0055
CR [Anonymous], P 2006 IEEE COMP SOC
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2006, P 14 ANN ACM INT C M
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Brunelli R., 1992, P DARPA IMAGE UNDERS, P311
   Chang KY, 2011, PROC CVPR IEEE, P585, DOI 10.1109/CVPR.2011.5995437
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2013, IEEE T PATTERN ANAL, V35, P2401, DOI 10.1109/TPAMI.2013.51
   Golomb BA., 1991, Advances in Neural Information Processing Systems, V3, P572, DOI DOI 10.1007/978-1-4757-2379-3_3
   Guo G. -D., 2010, IEEE INT WORKSH AN M
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2013, IEEE INT CONF AUTOMA
   Guo GD, 2012, STUD COMPUT INTELL, V409, P101
   Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404
   Guo GD, 2009, IEEE I CONF COMP VIS, P1986, DOI 10.1109/ICCV.2009.5459438
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Han H, 2013, INT C BIOM, P1
   Hardoon DR, 2006, LECT NOTES ARTIF INT, V4093, P681
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   Hastie T., 2009, The Elements of Statistical Learning
   Hosoi S., 2004, INT C AUT FAC GEST R
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Kim T.-K., 2007, CVPR, P1
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Li AN, 2009, PROC CVPR IEEE, P605, DOI 10.1109/CVPRW.2009.5206659
   Lu X., 2004, P SPIE DEF SEC S
   Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Ni B., 2009, ACM MULTIMEDIA
   Ramanathan N., 2006, AGE PROGR HUMAN FACE, P307
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Rosipal R, 2002, J MACH LEARN RES, V2, P97, DOI 10.1162/15324430260185556
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Rosipal R, 2011, CHEMOINFORMATICS AND ADVANCED MACHINE LEARNING PERSPECTIVES: COMPLEX COMPUTATIONAL METHODS AND COLLABORATIVE TECHNIQUES, P169, DOI 10.4018/978-1-61520-911-8.ch009
   SHAKHNAROVICH G, 2002, INT C AUT FAC GEST R
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Sun LA, 2011, IEEE T PATTERN ANAL, V33, P194, DOI 10.1109/TPAMI.2010.160
   Wold H, 1985, ENCY STAT SCI, P581, DOI DOI 10.1002/0471667196.ESS1914.PUB2
   Wold H., 1975, Quantitative sociology, P307
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
NR 46
TC 65
Z9 73
U1 0
U2 20
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 761
EP 770
DI 10.1016/j.imavis.2014.04.011
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700013
DA 2024-07-18
ER

PT J
AU Scherer, S
   Stratou, G
   Lucas, G
   Mahmoud, M
   Boberg, J
   Gratch, J
   Rizzo, A
   Morency, LP
AF Scherer, Stefan
   Stratou, Giota
   Lucas, Gale
   Mahmoud, Marwa
   Boberg, Jill
   Gratch, Jonathan
   Rizzo, Albert (Skip)
   Morency, Louis-Philippe
TI Automatic audiovisual behavior descriptors for psychological disorder
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Psychological distress; Depression; Post-traumatic stress disorder;
   Anxiety; Nonverbal behavior; Automatic assessment; Audiovisual
ID DEPRESSION SEVERITY; PTSD CHECKLIST; SPEECH; INVENTORY; SYMPTOMS;
   VALIDITY; ANXIETY; PHQ-9; WAVE
AB We investigate the capabilities of automatic audiovisual nonverbal behavior descriptors to identify indicators of psychological disorders such as depression, anxiety, and post-traumatic stress disorder. Due to strong correlations between these disordersas measured with standard self-assessment questionnaires in this study, we focus our investigations in particular on a generic distress measure as identified using factor analysis. Within this work, we seek to confirm and enrich present state of the art, predominantly based on qualitative manual annotations, with automatic quantitative behavior descriptors. We propose a number of nonverbal behavior descriptors that can be automatically estimated from audiovisual signals. Such automatic behavior descriptors could be used to support healthcare providers with quantified and objective observations that could ultimately improve clinical assessment. We evaluate our work on the dataset called the Distress Assessment Interview Corpus (DAIC) which comprises dyadic interactions between a confederate interviewer and a paid participant. Our evaluation on this dataset shows correlation of our automatic behavior descriptors with the derived general distress measure. Our analysis also includes a deeper study of self-adaptor and fidgeting behaviors based on detailed annotations of where these behaviors occur. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Scherer, Stefan; Stratou, Giota; Lucas, Gale; Mahmoud, Marwa; Boberg, Jill; Gratch, Jonathan; Rizzo, Albert (Skip); Morency, Louis-Philippe] Univ So Calif, Inst Creat Technol, Playa Vista, CA 90094 USA.
   [Mahmoud, Marwa] Univ Cambridge, Cambridge CB2 1TN, England.
C3 University of Southern California; University of Cambridge
RP Scherer, S (corresponding author), Univ So Calif, Inst Creat Technol, 12015 Waterfront Dr, Playa Vista, CA 90094 USA.
EM scherer@ict.usc.edu; Stratou@ict.usc.edu; Lucas@ict.usc.edu;
   emmam3@cam.ac.uk; Boberg@ict.usc.edu; gratch@ict.usc.edu;
   rizzo@ict.usc.edu; morency@ict.usc.edu
RI Morency, Louis-Philippe/B-2006-2008
OI Mahmoud, Marwa/0000-0002-5932-9113
FU DARPA [W911NF-04-D-0005]; U.S. Army
FX The effort described here is supported by DARPA under contract
   W911NF-04-D-0005 and the U.S. Army. Any opinion, content or information
   presented does not necessarily reflect the position or the policy of the
   United States Government, and no official endorsement should be
   inferred.
CR Alku P, 2002, J ACOUST SOC AM, V112, P701, DOI 10.1121/1.1490365
   ALKU P, 1992, SPEECH COMMUN, V11, P109, DOI 10.1016/0167-6393(92)90005-R
   [Anonymous], P INT C AFF COMP INT
   [Anonymous], P LANG RES EV C LREC
   [Anonymous], THESIS WAYNE STATE U
   [Anonymous], 2013, Proceedings of the SIGDIAL 2013 Conference. pages
   Arbisi PA, 2012, PSYCHOL ASSESSMENT, V24, P1034, DOI 10.1037/a0028014
   Baltrusaitis T., 2012, IEEE COMPUTER VISION
   BECK AT, 1988, J CONSULT CLIN PSYCH, V56, P893, DOI 10.1037/0022-006X.56.6.893
   Bieling PJ, 1998, BEHAV RES THER, V36, P777, DOI 10.1016/S0005-7967(98)00023-0
   Blanchard EB, 1996, BEHAV RES THER, V34, P669, DOI 10.1016/0005-7967(96)00033-2
   Bolton EE, 2006, J ANXIETY DISORD, V20, P877, DOI 10.1016/j.janxdis.2006.01.009
   BOUHUYS AL, 1991, J AFFECT DISORDERS, V23, P63, DOI 10.1016/0165-0327(91)90093-8
   Bylsma LM, 2008, CLIN PSYCHOL REV, V28, P676, DOI 10.1016/j.cpr.2007.10.001
   Campbell DG, 2007, J GEN INTERN MED, V22, P711, DOI 10.1007/s11606-006-0101-4
   Campbell N., 2003, P 15 INT C PHON SCI, P2417
   Cohn Jeffrey F., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPR.2009.5204260
   Cummins N., 2011, P INT 2011
   Cummins N, 2013, INTERSPEECH, P857
   Cummins N, 2013, INT CONF ACOUST SPEE, P7542, DOI 10.1109/ICASSP.2013.6639129
   DARBY JK, 1984, J COMMUN DISORD, V17, P75, DOI 10.1016/0021-9924(84)90013-3
   Degottex G., 2014, P IEEE INT IN PRESS
   DeVault D, 2014, AAMAS'14: PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS & MULTIAGENT SYSTEMS, P1061
   Ekman P., 1969, Semiotica, V1, P49, DOI [10.1515/semi.1969.1.1.49, DOI 10.1515/SEMI.1969.1.1.49]
   Ekman P., 1978, Facial action coding system
   Elhai JD, 2011, J ANXIETY DISORD, V25, P404, DOI 10.1016/j.janxdis.2010.11.003
   FAIRBANKS LA, 1982, J ABNORM PSYCHOL, V91, P109, DOI 10.1037/0021-843X.91.2.109
   FLINT AJ, 1993, J PSYCHIAT RES, V27, P309, DOI 10.1016/0022-3956(93)90041-Y
   Geerts E.N., 1999, J AFFECT DISORDERS, V40, P15
   Girard J.M., 2013, P IEEE C AUT FAC GES
   GOBL C., 2003, ISCA TUTORIAL RES WO, P151
   Gratch J., STUDIES HLTH TECHNOL, V1842012, P151
   HACKI T, 1989, FOLIA PHONIATR, V41, P43, DOI 10.1159/000265931
   HALL JA, 1995, APPL PREV PSYCHOL, V4, P21, DOI 10.1016/S0962-1849(05)80049-6
   Hanson HM, 2001, J PHONETICS, V29, P451, DOI 10.1006/jpho.2001.0146
   HARRIS FC, 1982, CLIN PSYCHOL REV, V2, P539, DOI 10.1016/0272-7358(82)90029-0
   Henrich N., 2001, P EUROSPEECH
   Hoge CW, 2004, NEW ENGL J MED, V351, P13, DOI 10.1056/NEJMoa040603
   ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641
   Joshi J., J MULTIMODAL USER IN, V72013, P217
   Joshi J, 2013, IEEE INT CONF AUTOMA
   Joshi J, 2013, INT CONF AFFECT, P492, DOI 10.1109/ACII.2013.87
   Kane J, 2013, INT CONF ACOUST SPEE, P7982, DOI 10.1109/ICASSP.2013.6639219
   Kirsch A, 2007, PSYCHOPATHOLOGY, V40, P296, DOI 10.1159/000104779
   Krippendorff K, 2011, COMMUN METHODS MEAS, V5, P93, DOI 10.1080/19312458.2011.568376
   Kroenke K, 2002, PSYCHIAT ANN, V32, P509, DOI 10.3928/0048-5713-20020901-06
   Kroenke K, 2001, J GEN INTERN MED, V16, P606, DOI 10.1046/j.1525-1497.2001.016009606.x
   Lausberg H, 2009, BEHAV RES METHODS, V41, P841, DOI 10.3758/BRM.41.3.841
   Marshall GN, 2010, J ABNORM PSYCHOL, V119, P126, DOI 10.1037/a0018477
   Moore E, 2008, IEEE T BIO-MED ENG, V55, P96, DOI 10.1109/TBME.2007.900562
   Morency L., 2008, IEEE International Conference on Automatic Face Gesture Recognition, P1
   NILSONNE A, 1988, ACTA PSYCHIAT SCAND, V77, P253, DOI 10.1111/j.1600-0447.1988.tb05118.x
   Perez J.E., 2003, Nonverbal Behavior in Clinical Settings, P17, DOI [10.1093/med:psych/9780195141092.003.0002, DOI 10.1093/MED:PSYCH/9780195141092.003.0002]
   Reed LI, 2007, J ABNORM PSYCHOL, V116, P804, DOI 10.1037/0021-843X.116.4.804
   Russell JA, 1999, J PERS SOC PSYCHOL, V76, P805, DOI 10.1037/0022-3514.76.5.805
   Schelde JTM, 1998, J NERV MENT DIS, V186, P133, DOI 10.1097/00005053-199803000-00001
   Scherer S, 2013, IEEE INT CONF AUTOMA
   Scherer S, 2013, INTERSPEECH, P847
   Scherer S, 2013, INT CONF ACOUST SPEE, P709, DOI 10.1109/ICASSP.2013.6637740
   Scherer S, 2013, COMPUT SPEECH LANG, V27, P263, DOI 10.1016/j.csl.2012.06.001
   Sesti A., 2000, Quality of Life Newsletter, P15
   Spielberger CD, 1970, MANUAL STATE TRAIT A
   Sturim D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P2992
   Talkin D., 1995, Speech coding and synthesis, V495, P518
   TIMCKE R, 1958, ARCHIV OTOLARYNGOL, V68, P1
   Trevino AC, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-42
   Wagner J., SOCIAL SIGNAL INTERP, P251
   WAXER P, 1974, J ABNORM PSYCHOL, V83, P319, DOI 10.1037/h0036706
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   WILDMAN BG, 1975, CHILD DEV, V46, P520, DOI 10.2307/1128151
   Williamson J.R., 2013, AVEC 2013 P 3 ACM IN, P41, DOI [DOI 10.1145/2512530.2512531, 10.1145/2512530.2512531]
   Yang Y, 2013, IEEE T AFFECT COMPUT, V4, P142, DOI 10.1109/T-AFFC.2012.38
   Zhou Y., 2013, P WORKSHOP SERIES SE
NR 73
TC 69
Z9 73
U1 3
U2 41
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 648
EP 658
DI 10.1016/j.imavis.2014.06.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700004
DA 2024-07-18
ER

PT J
AU Phillips, PJ
   O'Toole, AJ
AF Phillips, P. Jonathon
   O'Toole, Alice J.
TI Comparison of human and computer performance across face recognition
   experiments
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Face recognition; Algorithm performance; Human performance; Challenge
   problem
ID ALGORITHMS; EIGENFACES; VIDEO; OWN
AB Since 2005, human and computer performance has been systematically compared as part of face recognition competitions, with results being reported for both still and video imagery. The key results from these competitions are reviewed. To analyze performance across studies, the cross-modal performance analysis (CMPA) framework is introduced. The CMPA framework is applied to experiments that were part of face a recognition competition. The analysis shows that for matching frontal faces in still images, algorithms are consistently superior to humans. For video and difficult still face pairs, humans are superior. Finally, based on the CMPA framework and a face performance index, we outline a challenge problem for developing algorithms that are superior to humans for the general face recognition problem. Published by Elsevier B.V.
C1 [Phillips, P. Jonathon] NIST, Gaithersburg, MD 20899 USA.
   [O'Toole, Alice J.] Univ Texas Dallas, Sch Behav & Brain Sci, Richardson, TX 75083 USA.
C3 National Institute of Standards & Technology (NIST) - USA; University of
   Texas System; University of Texas Dallas
RP Phillips, PJ (corresponding author), NIST, 100 Bur Dr MS 8490, Gaithersburg, MD 20899 USA.
EM jonathon@nist.gov; otoole@utdallas.edu
OI O'Toole, Alice/0000-0001-7981-1508
FU Federal Bureau of Investigation; Department of Defense
FX PJP was supported by the Federal Bureau of Investigation and AJO was
   supported by the Department of Defense. The identification of any
   commercial product or trade name does not imply endorsement or
   recommendation by NIST or U of Texas at Dallas.
CR [Anonymous], FACE RECOGNITION
   [Anonymous], P 9 IEEE INT C AUT F
   [Anonymous], P 9 INT C AUT FAC GE
   [Anonymous], 1975, SIGNAL DETECTION THE
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 1991, Detection theory: A user's guide
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Beveridge JR, 2009, COMPUT VIS IMAGE UND, V113, P750, DOI 10.1016/j.cviu.2008.12.007
   Beveridge JR, 2005, MACH VISION APPL, V16, P128, DOI 10.1007/s00138-004-0144-7
   BOTHWELL RK, 1989, PERS SOC PSYCHOL B, V15, P19, DOI 10.1177/0146167289151002
   Burton AM, 1999, PSYCHOL SCI, V10, P243, DOI 10.1111/1467-9280.00144
   DiCarlo J.J., 2011, NEURAL COMPUTATION P
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Furl N, 2002, COGNITIVE SCI, V26, P797, DOI 10.1016/S0364-0213(02)00084-8
   Givens GH, 2013, COMPUT STAT DATA AN, V67, P236, DOI 10.1016/j.csda.2013.05.025
   Grother P., 2010, Report on the evaluation of 2d still-image face recognition algorithms
   HELLAND IS, 1990, SCAND J STAT, V17, P97
   HUSKEN M, 2005, IEEE WORKSH FAC REC
   Jenkins R, 2011, COGNITION, V121, P313, DOI 10.1016/j.cognition.2011.08.001
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Kriegeskorte N, 2008, FRONT SYST NEUROSCI, V2, DOI 10.3389/neuro.06.004.2008
   Lee Won-Joon., 2009, AXIS, V1, P19
   Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90
   MALPASS RS, 1969, J PERS SOC PSYCHOL, V13, P330, DOI 10.1037/h0028434
   Meissner CA, 2001, PSYCHOL PUBLIC POL L, V7, P3, DOI 10.1037//1076-8971.7.1.3
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   O'Toole A. J., 2008, 8 INT C AUT FAC GEST
   O'Toole AJ, 2005, IEEE T PATTERN ANAL, V27, P812, DOI 10.1109/TPAMI.2005.90
   O'Toole AJ, 2007, IEEE T SYST MAN CY B, V37, P1149, DOI 10.1109/TSMCB.2007.907034
   O'Toole AJ, 2007, IEEE T PATTERN ANAL, V29, P1642, DOI 10.1109/TPAMI.2007.1107
   O'Toole AJ, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2355598.2355599
   O'Toole AJ, 2012, IMAGE VISION COMPUT, V30, P169, DOI 10.1016/j.imavis.2011.12.007
   O'Toole AJ, 2011, VISION RES, V51, P74, DOI 10.1016/j.visres.2010.09.035
   Phillips P. J., 2009, P 3 IAPR INT C BIOM
   Phillips P. J., 2011, IEEE COMPUT, P96
   Phillips PJ, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870082
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Rice A, 2013, PSYCHOL SCI, V24, P2235, DOI 10.1177/0956797613492986
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Russell R, 2009, PSYCHON B REV, V16, P252, DOI 10.3758/PBR.16.2.252
   SHAPIRO PN, 1986, PSYCHOL BULL, V100, P139, DOI 10.1037/0033-2909.100.2.139
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wilkinson C, 2009, SCI JUSTICE, V49, P191, DOI 10.1016/j.scijus.2008.10.011
   Xie CY, 2005, LECT NOTES COMPUT SC, V3723, P32
NR 45
TC 77
Z9 84
U1 0
U2 34
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2014
VL 32
IS 1
BP 74
EP 85
DI 10.1016/j.imavis.2013.12.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA AB0RV
UT WOS:000331500700007
DA 2024-07-18
ER

PT J
AU Papoutsakis, KE
   Argyros, AA
AF Papoutsakis, Konstantinos E.
   Argyros, Antonis A.
TI Integrating tracking with fine object segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Kernel-based object tracking; Video-based object segmentation; Tracking
   by segmentation; Bayesian Inference; Data fusion; Expectation
   Maximization; Random Walker
ID IMAGE SEGMENTATION; GRAPH CUTS; COLOR; PROPAGATION; VOLUMES; MOTION;
   MODEL
AB We present a novel method for on-line, joint object tracking and segmentation in a monocular video captured by a possibly moving camera. Our goal is to integrate tracking and fine segmentation of a single, previously unseen, potentially non-rigid object of unconstrained appearance, given its segmentation in the first frame of an image sequence as the only prior information. To this end, we tightly couple an existing kernel-based object tracking method with Random Walker-based image segmentation. Bayesian inference mediates between tracking and segmentation, enabling effective data fusion of pixel-wise spatial and color visual cues. The fine segmentation of an object at a certain frame provides tracking with reliable initialization for the next frame, closing the loop between the two building blocks of the proposed framework. The effectiveness of the proposed methodology is evaluated experimentally by comparing it to a large collection of state of the art tracking and video-based object segmentation methods on the basis of a data set consisting of several challenging image sequences for which ground truth data is available. (C) 2013 Elsevier B.V. All rights reserved.
EM argyros@ics.forth.gr
RI Argyros, Antonis/AAD-9251-2019; Argyros, Antonis/GPK-4775-2022
OI Argyros, Antonis/0000-0001-8230-3192
FU  [IST-FP7-IP-288533]
FX This work was partially supported by the IST-FP7-IP-288533 project
   Robohow.Cog.
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P584, DOI 10.1145/1015706.1015764
   [Anonymous], IEEE WORKSH MOT VID
   [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   Armstrong CJ, 2007, COMPUT GRAPH-UK, V31, P212, DOI 10.1016/j.cag.2006.11.015
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B., 2011, ROBUST OBJECT TRACKI
   Bai X, 2010, LECT NOTES COMPUT SC, V6315, P617
   Bai X, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531376
   Bai X, 2009, INT J COMPUT VISION, V82, P113, DOI 10.1007/s11263-008-0191-z
   Baltzakis H, 2009, LECT NOTES COMPUT SC, V5876, P140, DOI 10.1007/978-3-642-10520-3_13
   Bibby C, 2008, LECT NOTES COMPUT SC, V5303, P831, DOI 10.1007/978-3-540-88688-4_61
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Grady L, 2005, PROC CVPR IEEE, P763
   Grady L, 2004, LECT NOTES COMPUT SC, V3117, P230
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Khan S, 2001, PROC CVPR IEEE, P746
   Knutsson H., 1983, IEEE COMP SOC WORKSH
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Li Y, 2005, ACM T GRAPHIC, V24, P595, DOI 10.1145/1073204.1073234
   Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346
   Malik J., 2007, Computer Vision and Pattern Recognition, P1
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Papoutsakis KE, 2010, LECT NOTES COMPUT SC, V6453, P405
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Price BL, 2009, IEEE I CONF COMP VIS, P779, DOI 10.1109/ICCV.2009.5459293
   Ranchin F, 2007, LECT NOTES COMPUT SC, V4485, P743
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Santner J, 2010, PROC CVPR IEEE, P723, DOI 10.1109/CVPR.2010.5540145
   Shi YG, 2005, PROC CVPR IEEE, P34
   Simoncelli EP, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC444
   Sinop A, 2007, SEEDED IMAGE SEGMENT, P1, DOI DOI 10.1109/ICCV.2007.4408927
   Team A.C., 2010, ADOBE EFFECTS CS5 CL
   Unger M, 2009, LECT NOTES COMPUT SC, V5681, P193, DOI 10.1007/978-3-642-03641-5_15
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang J, 2005, ACM T GRAPHIC, V24, P585, DOI 10.1145/1073204.1073233
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Werlberger M, 2009, LECT NOTES COMPUT SC, V5567, P200, DOI 10.1007/978-3-642-02256-2_17
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin ZZ, 2009, PROC CVPR IEEE, P731, DOI 10.1109/CVPRW.2009.5206674
   Zivkovic Z, 2004, PROC CVPR IEEE, P798
NR 60
TC 17
Z9 18
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 771
EP 785
DI 10.1016/j.imavis.2013.07.008
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900008
DA 2024-07-18
ER

PT J
AU Vezzetti, E
   Marcolin, F
AF Vezzetti, Enrico
   Marcolin, Federica
TI 3D human face description: landmarks measures and geometrical features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D models; 3D scanners; Face morphology; Soft tissue landmarks
ID FACIAL EXPRESSION RECOGNITION; ANATOMICAL POINT LANDMARKS; OBJECT
   RECOGNITION; LOCAL FEATURES; 3-D FACE; LOCALIZATION; MORPHOLOGY; IMAGES;
   ACCURACY; MODEL
AB Distance measures and geometrical features are widely used to describe faces. Generally, they are extracted punctually from landmarks, namely anthropometric reference points. The aims are various, such as face recognition, facial expression recognition, face detection, study of changes in facial morphology due to growth, or dysmorphologies. Most of the time, landmarks were extracted with the help of an algorithm or manually located on the faces. Then, measures are computed or geometrical features are extracted to perform the scope of the study. This paper is intended as a survey collecting and explaining all these features, in order to provide a structured user database of the potential parameters and their characteristics. Firstly, facial soft-tissue landmarks are defined and contextualized; then the various measures are introduced and some results are given; lastly, the most important measures are compared to identify the best one for face recognition applications. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Vezzetti, Enrico; Marcolin, Federica] Politecn Torino, Dipartimento Ingn Gest & Prod, Turin, Italy.
C3 Polytechnic University of Turin
RP Vezzetti, E (corresponding author), Politecn Torino, Dipartimento Ingn Gest & Prod, Turin, Italy.
EM enrico.vezzetti@polito.it
OI Marcolin, Federica/0000-0002-4360-6905; VEZZETTI,
   Enrico/0000-0001-8910-7020
CR Abboud B, 2004, SIGNAL PROCESS-IMAGE, V19, P723, DOI 10.1016/j.image.2004.05.009
   Salah AA, 2007, ANN TELECOMMUN, V62, P83
   Alyüz N, 2008, LECT NOTES COMPUT SC, V5372, P57, DOI 10.1007/978-3-540-89991-4_7
   [Anonymous], EUR WORKSH 3D OBJ RE
   [Anonymous], COORDINATE FREE METH
   [Anonymous], P 2009 5 INT C SOFT
   [Anonymous], FACE RECOGNITION USI
   [Anonymous], P 2005 IEEE COMP SOC
   [Anonymous], AUTOMATIC 3D FACE RE
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], AUTOMATIC FACIAL LAN
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2005, MULTIMODAL FACIAL FE
   [Anonymous], 2008 23 INT S COMP I
   [Anonymous], COMP LANDMARKING MET
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 7 INT C AUT FAC GEST
   [Anonymous], 3D FACE RECOGNITION
   [Anonymous], AUTOMATIC SYSTEM UNF
   [Anonymous], PROFILE BASED 3D AID
   [Anonymous], P IEEE 3 INT C BIOM
   [Anonymous], 3 IEEE INT C AUT FAC
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], P 5 INT C MULT INT
   [Anonymous], THESIS DEP PRODUCTIO
   [Anonymous], IEEE 3 INT C BIOM TH
   [Anonymous], 2006, INDIGENOUS LANGUAGE
   [Anonymous], 9 INT C CONTR AUT RO
   [Anonymous], 16 INT C IM PROC ICI
   [Anonymous], LECT NOTES COMPUTER
   AUNG SC, 1995, BRIT J PLAST SURG, V48, P551, DOI 10.1016/0007-1226(95)90043-8
   Benabdelkader C, 2005, IMAGE VISION COMPUT, V23, P339, DOI 10.1016/j.imavis.2004.09.004
   Bronstein A.M., 2005, ICIP, P756
   Bronstein AM, 2006, LECT NOTES COMPUT SC, V3953, P396, DOI 10.1007/11744078_31
   Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y
   Bronstein AM, 2004, LECT NOTES COMPUT SC, V3022, P225
   Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62
   Carnicky J., 2006, Measurement Science Review, V6, P1
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cohen Ira., 2003, P 5 ACM SIGMM INT WO
   Colbry D., 2005, P 2005 IEEE COMPUTER, V03, P118
   Colombo A, 2006, PATTERN RECOGN, V39, P444, DOI 10.1016/j.patcog.2005.09.009
   D'Hose J., 2007, IEEE Conference on Biometrics: Theory, Applications and Systems, BTAS'07, P1
   Daniyal F, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P302, DOI 10.1109/AVSS.2009.71
   Dibeklioglu H., 2008, BTAS 2008 - IEEE 2nd International Conference on Biometrics: Theory, Applications and Systems, P1
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Dorai C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P697, DOI 10.1109/ICPR.1996.546114
   DORAI C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1024, DOI 10.1109/ICCV.1995.466822
   EKMAN P, 1992, PSYCHOL REV, V99, P550, DOI 10.1037/0033-295X.99.3.550
   Ekman P., 1999, HDB COGNITION EMOTIO
   Enciso R, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 and 2, P1119
   Farkas L G, 1972, Cleft Palate J, V9, P132
   Farkas LG, 2000, AESTHET PLAST SURG, V24, P179, DOI 10.1007/s002660010029
   Farkas LG, 2005, J CRANIOFAC SURG, V16, P615, DOI 10.1097/01.scs.0000171847.58031.9e
   FARKAS LG, 1992, CLEFT PALATE-CRAN J, V29, P303, DOI 10.1597/1545-1569(1992)029<0303:AGSOTH>2.3.CO;2
   Farkas LG, 1996, CLEFT PALATE-CRAN J, V33, P10, DOI 10.1597/1545-1569(1996)033<0010:AOAMPP>2.3.CO;2
   FARKAS LG, 1985, CLEFT PALATE J, V22, P253
   FARKAS LG, 1995, J ORAL MAXIL SURG, V53, P1014, DOI 10.1016/0278-2391(95)90116-7
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   Frantz S, 2005, IMAGE VISION COMPUT, V23, P956, DOI 10.1016/j.imavis.2005.05.019
   Frantz S., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P687, DOI 10.1007/BFb0055698
   Frantz S, 2000, LECT NOTES COMPUT SC, V1935, P492
   Frantz S, 1999, LECT NOTES COMPUT SC, V1679, P253
   Gizatdinova Y, 2006, IEEE T PATTERN ANAL, V28, P135, DOI 10.1109/TPAMI.2006.10
   Gordon G. G., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P808, DOI 10.1109/CVPR.1992.223253
   Gupta Shakti Dumar., 2007, Modern Trentrends in Planning and Designing of Hospital Principles and Practice, P1
   Gupta S, 2010, INT J COMPUT VISION, V90, P331, DOI 10.1007/s11263-010-0360-8
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Jain AnilK., 2005, Handbook of Face Recognition
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Ji RR, 2011, PATTERN RECOGN, V44, P624, DOI 10.1016/j.patcog.2010.08.022
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kin Choong Yow, 1997, Computer Vision - ACCV '98. Third Asian Conference on Computer Vision. Proceedings, P515
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Kohout MP, 1998, PLAST RECONSTR SURG, V102, P1339, DOI 10.1097/00006534-199810000-00004
   KOLAR JC, 1985, CLEFT PALATE J, V22, P266
   Le TT, 2002, AESTHET PLAST SURG, V26, P64, DOI 10.1007/s00266-001-0033-7
   Lee Y, 2005, LECT NOTES COMPUT SC, V3546, P909
   Liao MZW, 2006, PROCEEDINGS OF 2006 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P4133
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   Lu XG, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P585
   Mpiperis I., 2008, FG'08, P1
   Mpiperis I, 2008, IEEE T INF FOREN SEC, V3, P498, DOI 10.1109/TIFS.2008.924598
   Mpiperis I, 2008, INT CONF ACOUST SPEE, P2133, DOI 10.1109/ICASSP.2008.4518064
   Mpiperis I, 2007, IEEE T INF FOREN SEC, V2, P537, DOI 10.1109/TIFS.2007.902326
   Mpiperis I, 2008, 2008 IEEE SECOND INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), P1
   Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629
   Ras F, 1996, J DENT, V24, P369, DOI 10.1016/0300-5712(95)00081-X
   Rodrigues J, 2005, LECT NOTES COMPUT SC, V3704, P205, DOI 10.1007/11565123_21
   Romero M, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P73, DOI 10.1109/AVSS.2009.90
   Ruiz M. C., 2008, 5th International Conference on Visual Information Engineering, VIE 2008, P41, DOI 10.1049/cp:20080280
   Salah AA, 2006, LECT NOTES COMPUT SC, V4105, P338
   Sang-Jun Park, 2008, 2008 International Conference on Control, Automation and Systems (ICCAS), P1881, DOI 10.1109/ICCAS.2008.4694404
   Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021
   Shi J, 2006, COMPUT VIS IMAGE UND, V102, P117, DOI 10.1016/j.cviu.2005.10.002
   Song H, 2006, LECT NOTES COMPUT SC, V3832, P99
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Takacs B, 1997, PATTERN RECOGN, V30, P1623, DOI 10.1016/S0031-3203(96)00159-8
   Takacs B, 1998, COMPUT VIS IMAGE UND, V70, P63, DOI 10.1006/cviu.1998.0619
   Tang H., 2008, 8 IEEE INT C AUTOMAT, P1
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Wang DW, 1997, AESTHET PLAST SURG, V21, P265
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wang J, 2007, COMPUT VIS IMAGE UND, V108, P19, DOI 10.1016/j.cviu.2006.10.011
   Wang YB, 2004, INT C PATT RECOG, P926, DOI 10.1109/ICPR.2004.1334680
   Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1
   Worthington PL, 2000, INT C PATT RECOG, P738, DOI 10.1109/ICPR.2000.905492
   Wörz S, 2006, MED IMAGE ANAL, V10, P41, DOI 10.1016/j.media.2005.02.003
   Xu CH, 2006, PATTERN RECOGN LETT, V27, P1487, DOI 10.1016/j.patrec.2006.02.015
   Zhang GP, 2009, LECT NOTES COMPUT SC, V5558, P394, DOI 10.1007/978-3-642-01793-3_41
   Zhao X., 2010, HICSS, P1
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
NR 114
TC 37
Z9 39
U1 1
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2012
VL 30
IS 10
BP 698
EP 712
DI 10.1016/j.imavis.2012.02.007
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 027YD
UT WOS:000310389100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Carvalho, P
   Cardoso, JS
   Corte-Real, L
AF Carvalho, Pedro
   Cardoso, Jaime S.
   Corte-Real, Luis
TI Filling the gap in quality assessment of video object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Tracking; Algorithm assessment; Evaluation metrics;
   Information fusion
ID MOTION DETECTION; SEGMENTATION
AB Current evaluation methods either rely heavily on reference information manually annotated or, by completely avoiding human input, provide only a rough evaluation of the performance of video object tracking algorithms. The main objective of this paper is to present a novel approach to the problem of evaluating video object tracking algorithms. It is proposed the use different types of reference information and the combination of heterogeneous metrics for the purpose of approximating the ideal error. This will enable a significant decrease of the required reference information, thus bridging the gap between metrics with different requirements concerning this type of data. As a result, evaluation frameworks can aggregate the benefits from individual approaches while overcoming their weaknesses, providing a flexible and powerful tool to assess and characterize the behavior of the tracking algorithms. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Carvalho, Pedro; Cardoso, Jaime S.; Corte-Real, Luis] INESC Porto, P-4200465 Oporto, Portugal.
C3 Universidade do Porto; INESC TEC
RP Carvalho, P (corresponding author), INESC Porto, Campus FEUP,Rua Dr Roberto Frias 378, P-4200465 Oporto, Portugal.
EM pedro.carvalho@inescporto.pt
RI Carvalho, Pedro/V-6468-2019; Corte-Real, Luís/I-4852-2012; Cardoso,
   Jaime S/I-3286-2013
OI Carvalho, Pedro/0000-0003-4983-4316; Cardoso, Jaime
   S/0000-0002-3760-2473; Corte-Real, Luis/0000-0003-2116-7056
FU Fundacao para a Ciencia e a Tecnologia (FCT), Portugal; European
   Commission [SFRH/BD/31259/2006]; Fundação para a Ciência e a Tecnologia
   [SFRH/BD/31259/2006] Funding Source: FCT
FX The authors would like to thank the Fundacao para a Ciencia e a
   Tecnologia (FCT), Portugal and the European Commission, for financing
   this work through the grant SFRH/BD/31259/2006 and Fundo Social Europeu
   (FSE).
CR [Anonymous], P IEEE INT WORKSH PE
   [Anonymous], EC FUND CAVIAR PROJ
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P IEEE WORKSH MOT VI
   [Anonymous], 2002, 3 IEEE INT WORKSH PE
   [Anonymous], IEEE INT WORKSH PERF
   Black J., 2003, In Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance VS-PETS, P125
   Cardoso JS, 2009, COMPUT VIS IMAGE UND, V113, P811, DOI 10.1016/j.cviu.2009.02.001
   Cardoso JS, 2005, IEEE T IMAGE PROCESS, V14, P1773, DOI 10.1109/TIP.2005.854491
   Carvalho P, 2010, ELECTRON LETT, V46, P411, DOI 10.1049/el.2010.3165
   Correia PL, 2003, IEEE T IMAGE PROCESS, V12, P186, DOI 10.1109/TIP.2002.807355
   Denman S, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P541, DOI 10.1109/AVSS.2009.32
   Doermann D, 2000, INT C PATT RECOG, P167, DOI 10.1109/ICPR.2000.902888
   Erdem ÇE, 2004, IEEE T IMAGE PROCESS, V13, P937, DOI 10.1109/TIP.2004.828427
   Gelasca ED, 2009, IEEE J-STSP, V3, P319, DOI 10.1109/JSTSP.2009.2015067
   Jaynes C., 2002, PROC IEEE WORKSHOP P, P32
   Jiang XY, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/35909
   Krinidis M, 2005, INT CONF ACOUST SPEE, P237
   Lazarevic-McManus N, 2008, COMPUT VIS IMAGE UND, V111, P74, DOI 10.1016/j.cviu.2007.07.007
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Nascimento JC, 2006, IEEE T MULTIMEDIA, V8, P761, DOI 10.1109/TMM.2006.876287
   Nghiem AT, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P476, DOI 10.1109/AVSS.2007.4425357
   Pingali S., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P33, DOI 10.1109/ACV.1996.571994
   Schlögl T, 2004, INT C PATT RECOG, P519, DOI 10.1109/ICPR.2004.1333825
   Vezzani R, 2010, MULTIMED TOOLS APPL, V50, P359, DOI 10.1007/s11042-009-0402-9
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
NR 28
TC 8
Z9 9
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2012
VL 30
IS 9
BP 630
EP 640
DI 10.1016/j.imavis.2012.06.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 024EV
UT WOS:000310092600004
DA 2024-07-18
ER

PT J
AU Jiménez, P
   Bergasa, LM
   Nuevo, J
   Alcantarilla, PF
AF Jimenez, Pedro
   Bergasa, Luis M.
   Nuevo, Jesus
   Alcantarilla, Pablo F.
TI Face pose estimation with automatic 3D model creation in challenging
   scenarios
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face pose estimation; Face model; Yaw rotation; Feature
   re-registering; Stereo vision
ID FEATURES; TRACKING
AB This paper proposes a new method to perform real-time face pose estimation for +/- 90 degrees yaw rotations and under low light conditions. The algorithm works on the basis of a completely automatic and run-time incremental 3D face modelling. The model is initially made up upon a set of 3D points derived from stereo grey-scale images. As new areas of the subject face appear to the cameras, new 3D points are automatically added to complete the model. In this way, we can estimate the pose for a wide range of rotation angles, where typically 3D frontal points are occluded.
   We propose a new feature re-registering technique which combines views of both cameras of the stereo rig in a smart way in order to perform a fast and robust tracking for the full range of yaw rotations. The Levenberg-Marquardt algorithm is used to recover the pose and a RANSAC framework rejects incorrectly tracked points.
   The model is continuously optimised in a bundle adjustment process that reduces the accumulated error on the 3D reconstruction.
   The intended application of this work is estimating the focus of attention of drivers in a simulator, which imposes challenging requirements. We validate our method on sequences recorded in a naturalistic truck simulator. on driving exercises designed by a team of psychologists. (C) 2012 Elsevier BM. All rights reserved.
C1 [Alcantarilla, Pablo F.] Univ Auvergne, ISIT CNRS UMR6284, Clermont Ferrand, France.
   [Jimenez, Pedro; Bergasa, Luis M.] Univ Alcala de Henares, Dept Elect, Madrid, Spain.
   [Nuevo, Jesus] CSIRO, Informat Commun Technol ICT Ctr, Brisbane, Qld, Australia.
C3 Universite Clermont Auvergne (UCA); Universidad de Alcala; Commonwealth
   Scientific & Industrial Research Organisation (CSIRO)
RP Alcantarilla, PF (corresponding author), Univ Auvergne, ISIT CNRS UMR6284, Clermont Ferrand, France.
EM pjimenez@depeca.uah.es; bergasa@depeca.uah.es; jesus.nuevo@csiro.au;
   pablofdezalc@gmail.com
RI Bergasa, Luis M./H-9810-2013
OI Bergasa, Luis M./0000-0002-0087-3077; Fernandez Alcantarilla,
   Pablo/0000-0001-7185-2911
FU Ministerio de Ciencia e Innovacion [TRA2008-03600, PSE-370000-2009-12];
   Ministerio de Economia y Competitividad [TRA2011-29001-C04-01]
FX This work has been financed with funds from the Ministerio de Ciencia e
   Innovacion through the project DRIVER-ALERT (TRA2008-03600) and project
   CABINTEC (PSE-370000-2009-12) as well as from the Ministerio de Economia
   y Competitividad through the project ADD-Gaze (TRA2011-29001-C04-01).
CR Agarwal S, 2010, LECT NOTES COMPUT SC, V6312, P29, DOI 10.1007/978-3-642-15552-9_3
   An KH, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P307, DOI 10.1109/IROS.2008.4650742
   [Anonymous], IEICE T INFO SYST
   [Anonymous], ANN STAT REP
   [Anonymous], HIGHLIGHTS PANORAMA
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], SEQUENTIAL NONRIGID
   [Anonymous], 2006, TENCON 2006
   [Anonymous], FITTING 3D DATA CYLI
   [Anonymous], N TIER SIMULTANEOUS
   Balasubramanian V., 2007, IEEE C COMPUTER VISI, P1
   Balasubramanian V, 2008, COMM COM INF SC, V21, P177
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598
   Bradski G., 2008, LEARNING OPENCV
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   Di Stefano L, 2005, PATTERN RECOGN LETT, V26, P2129, DOI 10.1016/j.patrec.2005.03.022
   Dornaika F, 2009, IEEE T SYST MAN CY B, V39, P935, DOI 10.1109/TSMCB.2008.2009566
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Harris C., 1988, ALVEY VISION C, P147151
   Huang KS, 2004, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2004.1334689
   Jiménez P, 2009, IET COMPUT VIS, V3, P93, DOI 10.1049/iet-cvi.2008.0057
   Krinidis M, 2009, IEEE T CIRC SYST VID, V19, P261, DOI 10.1109/TCSVT.2008.2009261
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   Lin YP, 2010, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2010.5539793
   Lourakis M.I.A., 2004, levmar: Levenberg-marquardt nonlinear least squares algorithms in C/C++
   Lourakis MIA, 2009, ACM T MATH SOFTWARE, V36, DOI 10.1145/1486525.1486527
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Mouragnon E, 2009, IMAGE VISION COMPUT, V27, P1178, DOI 10.1016/j.imavis.2008.11.006
   Murphy-Chutorian E, 2008, IEEE INT VEH SYM, P1174
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Nuevo J, 2011, IMAGE VISION COMPUT, V29, P209, DOI 10.1016/j.imavis.2010.11.004
   Nuevo J, 2010, PATTERN RECOGN LETT, V31, P2455, DOI 10.1016/j.patrec.2010.07.016
   Ranney T.A., 2008, Driver distraction: A review of the current state-of-knowledge
   Sheerman-Chase Tim, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1386, DOI 10.1109/ICCVW.2009.5457450
   Stutts J.C., 2001, The Role of Driver Distraction in Traffic Crashes, DOI 10.1037/e363942004-001
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   Tu JL, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P573
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu J, 2008, PATTERN RECOGN, V41, P1138, DOI 10.1016/j.patcog.2007.07.017
   Xiao J, 2004, PROC CVPR IEEE, P535
   Yi-Tzu Lin, 2009, 2009 IEEE International Conference on Robotics and Automation (ICRA), P453, DOI 10.1109/ROBOT.2009.5152816
   Zhao G., 2007, P 15 INT C MULTIMEDI, P807
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 49
TC 7
Z9 7
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2012
VL 30
IS 9
BP 589
EP 602
DI 10.1016/j.imavis.2012.06.013
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 024EV
UT WOS:000310092600001
OA Green Published
DA 2024-07-18
ER

PT J
AU Barnes, N
AF Barnes, Nick
TI The role of computer vision in prosthetic vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Prosthetic vision; Bionic eye; Retinal implants;
   Orientation and mobility; Face recognition
AB The cost of vision loss worldwide has been estimated at nearly $3 trillion (http://www.amdalliance.org/cost-of-blindness.html). Non-preventable diseases cause a significant proportion of blindness in developed nations and will become more prevalent as people live longer. Prosthetic vision technologies including retinal implants will play an important therapeutic role. Retinal implants convert an input image stream to visual percepts via stimulation of the retina. This paper highlights some barriers to restoring functional human vision for current generation visual prosthetic devices that computer vision can help overcome. Such computer vision is interactive, aiming to restore function including visuo-motor tasks and recognition. (c) 2012 Elsevier B.V. All rights reserved.
C1 Australian Natl Univ, NICTA, Bion Vis Australia, Canberra, ACT 0200, Australia.
C3 Australian National University
RP Barnes, N (corresponding author), Australian Natl Univ, NICTA, Bion Vis Australia, Canberra, ACT 0200, Australia.
EM nick.barnes@nicta.com.au
RI Barnes, Nick/Y-2744-2018
FU Australian Government; Digital Economy; Australian Research Council
   (ARC) through the ICT Centre of Excellence Program; ARC through its
   Special Research Initiative (SRI) in Bionic Vision Science and
   Technology grant to Bionic Vision Australia (BVA)
FX NICTA is funded by the Australian Government as represented by the
   Department of Broadband, Communications, and the Digital Economy, and
   the Australian Research Council (ARC) through the ICT Centre of
   Excellence Program. This research was also supported in part by ARC
   through its Special Research Initiative (SRI) in Bionic Vision Science
   and Technology grant to Bionic Vision Australia (BVA).
CR BRINDLEY GS, 1968, J PHYSIOL-LONDON, V196, P479, DOI 10.1113/jphysiol.1968.sp008519
   Degenaar P.A., 2011, ARVO
   Humayun M. S., OPHTHALMOLO IN PRESS, V119, P779
   Zrenner E, 2011, P ROY SOC B-BIOL SCI, V278, P1489, DOI 10.1098/rspb.2010.1747
NR 4
TC 7
Z9 8
U1 11
U2 142
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 478
EP 479
DI 10.1016/j.imavis.2012.05.007
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100008
OA hybrid
DA 2024-07-18
ER

PT J
AU Su, J
   Dryden, IL
   Klassen, E
   Le, H
   Srivastava, A
AF Su, J.
   Dryden, I. L.
   Klassen, E.
   Le, H.
   Srivastava, A.
TI Fitting smoothing splines to time-indexed, noisy points on nonlinear
   manifolds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Splines on manifolds; Pose tracking; Activity recognition;
   Interpolation; Curve fitting; Diffusion tensor analysis
ID INTERPOLATION; RECOGNITION; GENERATION; CURVES; PATHS
AB We address the problem of estimating full curves/paths on certain nonlinear manifolds using only a set of time-indexed points, for use in interpolation, smoothing, and prediction of dynamic systems. These curves are analogous to smoothing splines in Euclidean spaces as they are optimal under a similar objective function, which is a weighted sum of a fitting-related (data term) and a regularity-related (smoothing term) cost functions. The search for smoothing splines on manifolds is based on a Palais metric-based steepest-decent algorithm developed in Samir et al. [38]. Using three representative manifolds: the rotation group for pose tracking, the space of symmetric positive-definite matrices for DTI image analysis, and Kendall's shape space for video-based activity recognition, we demonstrate the effectiveness of the proposed algorithm for optimal curve fitting. This paper derives certain geometrical elements, namely the exponential map and its inverse, parallel transport of tangents, and the curvature tensor, on these manifolds, that are needed in the gradient-based search for smoothing splines. These ideas are illustrated using experimental results involving both simulated and real data, and comparing the results to some current algorithms such as piecewise geodesic curves and splines on tangent spaces, including the method by Kume et al. [24]. (c) 2011 Elsevier B.V. All rights reserved.
C1 [Su, J.; Srivastava, A.] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA.
   [Klassen, E.] Florida State Univ, Dept Math, Tallahassee, FL 32306 USA.
   [Le, H.] Univ Nottingham, Sch Math Sci, Nottingham NG7 2RD, England.
   [Dryden, I. L.] Univ S Carolina, Dept Stat, Columbia, SC 29208 USA.
C3 State University System of Florida; Florida State University; State
   University System of Florida; Florida State University; University of
   Nottingham; University of South Carolina System; University of South
   Carolina Columbia
RP Su, J (corresponding author), Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA.
EM jingyong@stat.fsu.edu
RI Srivastava, Anuj/L-4705-2019; Dryden, Ian/C-8742-2017
OI Srivastava, Anuj/0000-0001-7406-0338; Dryden, Ian/0000-0003-4900-3571
FU Division Of Mathematical Sciences; Direct For Mathematical & Physical
   Scien [0915003] Funding Source: National Science Foundation
CR Altafini C, 2000, LECT NOTES CONTR INF, V258, P23
   [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], 1999, Shape and Shape Theory
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boothby W. M., 2002, An introduction to differentiable manifolds and Riemannian geometry
   Buss SR, 2001, ACM T GRAPHIC, V20, P95, DOI 10.1145/502122.502124
   Camarinha M., 1995, IMA Journal of Mathematical Control and Information, V12, P399, DOI 10.1093/imamci/12.4.399
   Crouch P., 1991, Proceedings of the 1991 American Control Conference (IEEE Cat. No. 91CH2939-7), P1131
   Crouch P., 1995, Journal of Dynamical and Control Systems, V1, P177, DOI 10.1007/BF02254638
   Crouch P., 1999, Journal of Dynamical and Control Systems, V5, P397, DOI 10.1023/A:1021770717822
   Das S, 2010, IEEE T PATTERN ANAL, V32, P579, DOI 10.1109/TPAMI.2009.94
   Dryden IL, 2009, ANN APPL STAT, V3, P1102, DOI 10.1214/09-AOAS249
   Fletcher PT, 2007, SIGNAL PROCESS, V87, P250, DOI 10.1016/j.sigpro.2005.12.018
   Grenander U, 1998, IEEE T PATTERN ANAL, V20, P790, DOI 10.1109/34.709572
   Gu X., 2005, SPM 05, P27
   Hofer M, 2004, ACM T GRAPHIC, V23, P284, DOI 10.1145/1015706.1015716
   Hüper K, 2007, J DYN CONTROL SYST, V13, P467, DOI 10.1007/s10883-007-9027-3
   Jakubiak J, 2006, J COMPUT APPL MATH, V194, P177, DOI 10.1016/j.cam.2005.07.003
   JOST J, 1998, RIEMANNIAN GEOMETRY
   JUPP PE, 1987, J R STAT SOC C-APPL, V36, P34
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   Kenobi K, 2010, BIOMETRIKA, V97, P567, DOI 10.1093/biomet/asq027
   Kent J.T., 2001, Proceedings in Functional and Spatial Data Analysis, P109
   Kume A, 2007, BIOMETRIKA, V94, P513, DOI 10.1093/biomet/asm047
   Liu XW, 2004, IEEE T PATTERN ANAL, V26, P662, DOI 10.1109/TPAMI.2004.1273986
   Machado L., 2006, LMS Journal of Computation and Mathematics, V9, P86, DOI DOI 10.1112/S1461157000001200
   Machado L, 2006, INT J APPL MATH STAT, V4, P25
   Mardia K.V., 2000, Directional Statistics, V2
   Moakher M, 2005, SIAM J MATRIX ANAL A, V26, P735, DOI 10.1137/S0895479803436937
   Moakher M, 2002, SIAM J MATRIX ANAL A, V24, P1, DOI 10.1137/S0895479801383877
   Morris RJ, 1999, INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY, PROCEEDINGS, P404
   NOAKES L, 1989, IMA J MATH CONTROL I, V6, P465, DOI 10.1093/imamci/6.4.465
   Palais RS., 1963, Topology, V2, P299, DOI [10.1016/0040-9383(63)90013-2, DOI 10.1016/0040-9383(63)90013-2]
   Park FC, 1997, ACM T GRAPHIC, V16, P277, DOI 10.1145/256157.256160
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Popiel T, 2007, J APPROX THEORY, V148, P111, DOI 10.1016/j.jat.2007.03.002
   Rathi Y, 2007, IEEE T PATTERN ANAL, V29, P1470, DOI 10.1109/TPAMI.2007.1081
   Samir C, 2012, FOUND COMPUT MATH, V12, P49, DOI 10.1007/s10208-011-9091-7
   Schwartzman A., 2006, THESIS STANFORD
   Solo V, 2009, IEEE DECIS CONTR P, P8500, DOI 10.1109/CDC.2009.5400200
   Srivastava A, 2004, ADV APPL PROBAB, V36, P43, DOI 10.1239/aap/1077134463
   Srivastava A., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Tompkins Frank, 2007, 2007 2nd IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing, P261, DOI 10.1109/CAMSAP.2007.4498015
   Vaswani N, 2005, IEEE T IMAGE PROCESS, V14, P1603, DOI 10.1109/TIP.2005.852197
   Vaswani N, 2010, IEEE T IMAGE PROCESS, V19, P841, DOI 10.1109/TIP.2009.2037465
   Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143
   Zefran M, 1998, IEEE T ROBOTIC AUTOM, V14, P576, DOI 10.1109/70.704225
NR 48
TC 42
Z9 51
U1 0
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2012
VL 30
IS 6-7
SI SI
BP 428
EP 442
DI 10.1016/j.imavis.2011.09.006
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 977BA
UT WOS:000306630100006
DA 2024-07-18
ER

PT J
AU Nicolaou, MA
   Gunes, H
   Pantic, M
AF Nicolaou, Mihalis A.
   Gunes, Hatice
   Pantic, Maja
TI Output-associative RVM regression for dimensional and continuous emotion
   prediction
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Dimensional and continuous emotion prediction; Facial expressions;
   Shoulder movements; Audio cues; Output-associative RVM regression
ID RECOGNITION; EXPRESSION; VALENCE; AROUSAL
AB Many problems in machine learning and computer vision consist of predicting multi-dimensional output vectors given a specific set of input features. In many of these problems, there exist inherent temporal and spatial dependencies between the output vectors, as well as repeating output patterns and input-output associations, that can provide more robust and accurate predictors when modeled properly. With this intrinsic motivation, we propose a novel Output-Associative Relevance Vector Machine (OA-RVM) regression framework that augments the traditional RVM regression by being able to learn non-linear input and output dependencies. Instead of depending solely on the input patterns, OA-RVM models output covariances within a predefined temporal window, thus capturing past, current and future context. As a result, output patterns manifested in the training data are captured within a formal probabilistic framework, and subsequently used during inference. As a proof of concept, we target the highly challenging problem of dimensional and continuous prediction of emotions, and evaluate the proposed framework by focusing on the case of multiple nonverbal cues, namely facial expressions, shoulder movements and audio cues. We demonstrate the advantages of the proposed OA-RVM regression by performing subject-independent evaluation using the SAL database that constitutes naturalistic conversational interactions. The experimental results show that OA-RVM regression outperforms the traditional RVM and SVM regression approaches in terms of accuracy of the prediction (evaluated using the Root Mean Squared Error) and structure of the prediction (evaluated using the correlation coefficient), generating more accurate and robust prediction models. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Nicolaou, Mihalis A.; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
   [Gunes, Hatice] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London, England.
   [Pantic, Maja] Univ Twente, EEMCS, Enschede, Netherlands.
C3 Imperial College London; University of London; Queen Mary University
   London; University of Twente
RP Nicolaou, MA (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
EM mihalis@imperial.ac.uk
CR Alvarado N, 1997, MOTIV EMOTION, V21, P323, DOI 10.1023/A:1024484306654
   [Anonymous], 1953, KATHIMERINI
   [Anonymous], 2006, Proceedings of Fechner Day
   [Anonymous], 2006, P 8 INT C MULT INT, DOI [10.1145/1180995.1181029, DOI 10.1145/1180995.1181029]
   [Anonymous], P EUR SIGN PROC C
   [Anonymous], 2010, PROC LREC INT WORKSH
   Bo LF, 2010, INT J COMPUT VISION, V87, P28, DOI 10.1007/s11263-008-0204-y
   Boersma P., 1993, P I PHONETIC SCI, V17, P97, DOI DOI 10.1371/JOURNAL.PONE.0069107
   Breiman L, 1996, MACH LEARN, V24, P49
   Cortes C., 2005, INT C MACHINE LEARNI, P153, DOI DOI 10.1145/1102351.1102371
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Eyben F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P322, DOI 10.1109/FG.2011.5771417
   Gilroy S.W., 2009, P 3 INT C AFFECTIVE, P1
   Glowinski Donald, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563173
   Grimm M, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P381
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Gunes Hatice, 2010, International Journal of Strategic Synthetic Emotions, V1, P68, DOI 10.4018/jse.2010101605
   Gunes H, 2011, COMPUTER ANALYSIS OF HUMAN BEHAVIOR, P255, DOI 10.1007/978-0-85729-994-9_10
   Gunes H, 2010, LECT NOTES ARTIF INT, V6356, P371, DOI 10.1007/978-3-642-15892-6_39
   Ioannou SV, 2005, NEURAL NETWORKS, V18, P423, DOI 10.1016/j.neunet.2005.03.004
   Jurafsky D., 2021, SPEECH LANGUAGE PROC
   Kring AM, 1998, J PERS SOC PSYCHOL, V74, P686, DOI 10.1037/0022-3514.74.3.686
   Lane R.D., 2000, COGNITIVE NEUROSCIEN
   Lewis PA, 2007, CEREB CORTEX, V17, P742, DOI 10.1093/cercor/bhk024
   Liefeng Bo, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2403, DOI 10.1109/CVPRW.2009.5206699
   McDuff D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), P17, DOI [DOI 10.1109/CVPRW.2010.5543833, 10.1109/CVPRW.2010.5543833]
   Mehrabian A., 1974, APPROACH ENV PSYCHOL
   Metallinou A, 2011, INT CONF ACOUST SPEE, P2288
   Mitra K, 2010, PROC CVPR IEEE, P1887, DOI 10.1109/CVPR.2010.5539861
   Nicolaou Mihalis A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P16, DOI 10.1109/FG.2011.5771396
   Nicolaou Mihalis A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3695, DOI 10.1109/ICPR.2010.900
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Patras I, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P97, DOI 10.1109/AFGR.2004.1301515
   Espinosa HP, 2010, INT CONF ACOUST SPEE, P5138, DOI 10.1109/ICASSP.2010.5495031
   Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schuller B, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P552, DOI 10.1109/ASRU.2009.5372886
   Thayananthan A., 2006, EUROPEAN C COMPUTER, P124
   Tipping M. E., 2003, PMLR, P276
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Truong KP, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1995
   Weston J., 2002, ADV NEURAL INFORM PR
   Wöllmer M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2362
   Wöllmer M, 2010, IEEE J-STSP, V4, P867, DOI 10.1109/JSTSP.2010.2057200
   Wöllmer M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P597
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 48
TC 68
Z9 76
U1 0
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 186
EP 196
DI 10.1016/j.imavis.2011.12.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000007
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU O'Hara, S
   Lui, YM
   Draper, BA
AF O'Hara, Stephen
   Lui, Yui Man
   Draper, Bruce A.
TI Using a Product Manifold distance for unsupervised action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Unsupervised learning; Product Manifold; Action recognition
AB This paper presents a method for unsupervised learning and recognition of human actions in video. Lacking any supervision, there is nothing except the inherent biases of a given representation to guide grouping of video clips along semantically meaningful partitions. Thus, in the first part of this paper, we compare two contemporary methods. Bag of Features (BOF) and Product Manifolds (PM), for clustering video clips of human facial expressions, hand gestures, and full-body actions, with the goal of better understanding how well these very different approaches to behavior recognition produce semantically relevant clustering of data.
   We show that PM yields superior results when measuring the alignment between the generated clusters and the nominal class labeling of the data set. We found that while gross motions were easily clustered by both methods, the lack of preservation of structural information inherent to the BOF representation leads to limitations that are not easily overcome without supervised training. This was evidenced by the poor separation of shape labels in the hand gestures data by BOF, and the overall poor performance on full-body actions.
   In the second part of this paper, we present an unsupervised mechanism for learning micro-actions in continuous video streams using the PM representation. Unlike other works, our method requires no prior knowledge of an expected number of labels/classes, requires no silhouette extraction, is tolerant to minor tracking errors and jitter, and can operate at near real-time speed. We show how to construct a set of training "tracklets," how to cluster them using the Product Manifold distance measure, and how to perform detection using exemplars learned from the clusters. Further, we show that the system is amenable to incremental learning as anomalous activities are detected in the video stream. We demonstrate performance using the publicly-available ETHZ Livingroom data set. (C) 2011 Elsevier B.V. All rights reserved.
C1 [O'Hara, Stephen; Lui, Yui Man; Draper, Bruce A.] Colorado State Univ, Dept Comp Sci, Ft Collins, CO 80523 USA.
C3 Colorado State University
RP O'Hara, S (corresponding author), Colorado State Univ, Dept Comp Sci, Ft Collins, CO 80523 USA.
EM svohara@cs.colostate.edu; lui@cs.colostate.edu; draper@cs.colostate.edu
CR [Anonymous], 2007, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], P INT C PATT REC ICP
   [Anonymous], P JOINT IEEE INT WOR
   [Anonymous], 2009, P BRIT MACH VIS C BM
   [Anonymous], P INT C COMP VIS ICC
   Elgammal A, 2009, IEEE T PATTERN ANAL, V31, P520, DOI 10.1109/TPAMI.2008.101
   Gilbert A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.66
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Guo K, 2010, LECT NOTES COMPUT SC, V6388, P294, DOI 10.1007/978-3-642-17711-8_30
   KE Y, 2005, P INT C COMP VIS ICC
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lui Y.M., 2010, P IEEE C COMP VIS PA
   Lui YM, 2012, IMAGE VISION COMPUT, V30, P380, DOI 10.1016/j.imavis.2011.08.002
   Nater F., 2010, P IEEE C COMP VIS PA
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   O'Hara S., 2011, P IEEE INT C ADV VID, P6
   O'Hara S., 2011, P IEEE C AUT FAC GES
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ryoo M.S., 2010, P INT C PATT REC ICP
   Scovanner P, 2007, P 15 INT C MULT ACM
   Wolpert DH, 2002, SOFT COMPUTING AND INDUSTRY, P25
NR 23
TC 10
Z9 10
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 206
EP 216
DI 10.1016/j.imavis.2011.11.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000009
DA 2024-07-18
ER

PT J
AU Nuevo, J
   Bergasa, LM
   Llorca, DF
   Ocaña, M
AF Nuevo, Jesus
   Bergasa, Luis M.
   Llorca, David F.
   Ocana, Manuel
TI Face tracking with automatic model construction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face tracking; Appearance modeling; Incremental clustering; Robust
   fitting; Driver monitoring
ID IMAGES; SYSTEM
AB This paper describes an active model with a robust texture model built on-line. The model uses one camera and it is able to operate without active illumination. The texture model is defined by a series of clusters, which are built in a video sequence using previously encountered samples. This model is used to search for the corresponding element in the following frames. An on-line clustering method, named leaderP is described and evaluated on an application of face tracking. A 20-point shape model is used. This model is built offline, and a robust fitting function is used to restrict the position of the points. Our proposal is to serve as one of the stages in a driver monitoring system. To test it, a new set of sequences of drivers recorded outdoors and in a realistic simulator has been compiled. Experimental results for typical outdoor driving scenarios, with frequent head movement, turns and occlusions are presented. Our approach is tested and compared with the Simultaneous Modeling and Tracking (SMAT) [1], and the recently presented Stacked Trimmed Active Shape Model (STASM) [2], and shows better results than SMAT and similar fitting error levels to STASM, with much faster execution times and improved robustness. (C) 2010 Elsevier By. All rights reserved.
C1 [Nuevo, Jesus; Bergasa, Luis M.; Llorca, David F.; Ocana, Manuel] Univ Alcala, Dept Elect, Esc Politecn, Madrid 28871, Spain.
C3 Universidad de Alcala
RP Bergasa, LM (corresponding author), Univ Alcala, Dept Elect, Esc Politecn, Crta Madrid Barcelona,Km 33,600, Madrid 28871, Spain.
EM jnuevo@depeca.uah.es; bergasa@depeca.uah.es; llorca@depeca.uah.es;
   mocana@depeca.uah.es
RI Ocaña, Manuel/AAU-2650-2021; Nuevo-Chiquero, Jesus/C-5156-2011; Bergasa,
   Luis M./H-9810-2013; Fernandez-Llorca, David/K-2613-2012
OI Ocaña, Manuel/0000-0002-8875-1866; Bergasa, Luis M./0000-0002-0087-3077;
   Fernandez-Llorca, David/0000-0003-2433-7110
FU Spanish Ministry of Science and Innovation [TRA2008-03600]; Comunidad de
   Madrid [s-0505/CPI/000176]; Education Department of the Comunidad de
   Madrid; European Social Fund
FX The authors would like to thank Pedro Jimenez, Ivan Garcia and Noelia
   Hernandez of RobeSafe for their work in recording the sequences,
   Sebastian Bronte for his help in marking the images, as well as the
   drivers that participated. The outdoor recordings were made under
   project MOVI<SUP>2</SUP>CON (TRA2005-08529-C02-02) and the simulator
   recordings under CABINTEC project (PSE-370100-2007-2). This work was
   supported in part by the Spanish Ministry of Science and Innovation
   under DRIVER-ALERT Project (TRA2008-03600), and Comunidad de Madrid
   under project RoboCity2030 (s-0505/CPI/000176). J. Nuevo was working
   under a researcher training grant from the Education Department of the
   Comunidad de Madrid and the European Social Fund.
CR [Anonymous], P IEEE WORKSH FAC PR
   [Anonymous], VTI922A SWED NAT ROA
   [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], THESIS VIT TECHNICAL
   [Anonymous], DRIV AL CONTR
   [Anonymous], ANTISLEEP
   [Anonymous], 1980, Cluster analysis algorithms: for data reduction and classification of objects
   [Anonymous], DRIV STAT SENS
   [Anonymous], ATTENTION ASSIST
   [Anonymous], LOCATING FACIAL FEAT
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2006, 100 CAR NATURALISTIC
   [Anonymous], 2006, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2006.215
   [Anonymous], 17 BRIT MACH VIS C
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], [No title captured]
   [Anonymous], 2007, Proc. IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'07)
   [Anonymous], P 17 BRIT MACH VIS C
   [Anonymous], P INT C SER VIS VEH
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Baker S, 2001, PROC CVPR IEEE, P1090
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598
   Bergasa LM, 2008, PROCEEDINGS OF THE 11TH INTERNATIONAL IEEE CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS, P1149, DOI 10.1109/ITSC.2008.4732544
   Buenaposada JM, 2008, PATTERN ANAL APPL, V11, P101, DOI 10.1007/s10044-007-0084-8
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   D'Orazio T, 2007, PATTERN RECOGN, V40, P2341, DOI 10.1016/j.patcog.2007.01.018
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Hartigan J. A., 1975, CLUSTERING ALGORITHM, V458, P468
   Huber Peter J, 2011, ROBUST STAT, P1248
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Ji Q, 2004, IEEE T VEH TECHNOL, V53, P1052, DOI 10.1109/TVT.2004.830974
   Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Matsumoto Y., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P499, DOI 10.1109/AFGR.2000.840680
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Pilet J, 2005, PROC CVPR IEEE, P822, DOI 10.1109/CVPR.2005.293
   Rogers M, 2002, LECT NOTES COMPUT SC, V2353, P517
   Segvic S, 2006, LECT NOTES COMPUT SC, V3952, P112
   Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342
   UENO H, 1994, 1994 VEHICLE NAVIGATION & INFORMATION SYSTEMS CONFERENCE PROCEEDINGS, pA15
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wu JD, 2008, EXPERT SYST APPL, V34, P1556, DOI 10.1016/j.eswa.2007.01.019
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yin Z., 2007, IEEE Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383237
   Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2
NR 52
TC 8
Z9 8
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2011
VL 29
IS 4
BP 209
EP 218
DI 10.1016/j.imavis.2010.11.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 727UR
UT WOS:000287828800001
DA 2024-07-18
ER

PT J
AU Singh, C
   Walia, E
AF Singh, Chandan
   Walia, Ekta
TI Algorithms for fast computation of Zernike moments and their numerical
   stability
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Zernike moments; Geometric moments; Quasi-symmetry; Fast computation;
   Numerical stability
ID SUBPIXEL EDGE-DETECTION; CHARACTER-RECOGNITION; DESCRIPTORS
AB Accuracy, speed and numerical stability are among the major factors restricting the use of Zernike moments (ZMs) in numerous commercial applications where they are a tool of significant utility. Often these factors are conflicting in nature. The direct formulation of ZMs is prone to numerical integration error while in the recent past many fast algorithms are developed for its computation. On the other hand, the relationship between geometric moments (GMs) and ZMs reduces numerical integration error but it is observed to be computation intensive. We propose fast algorithms for both the formulations. In the proposed method, the order of time complexity for GMs-to-ZMs formulation is reduced and further enhancement in speed is achieved by using quasi-symmetry property of GMs. The existing q-recursive method for direct formulation is further modified by incorporating the recursive steps for the computation of trigonometric functions. We also observe that q-recursive method provides numerical stability caused by finite precision arithmetic at high orders of moment which is hitherto not reported in the literature. Experimental results on images of different sizes support our claim. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Singh, Chandan] Punjabi Univ, Dept Comp Sci, Patiala 147002, Punjab, India.
   [Walia, Ekta] MM Univ, Dept Informat Technol, Mullana 133203, Ambala, India.
C3 Punjabi University; Maharishi Markandeshwar University
RP Singh, C (corresponding author), Punjabi Univ, Dept Comp Sci, Patiala 147002, Punjab, India.
EM chandan.csp@gmail.com; wekta@yahoo.com
RI Singh, Amrik/AAR-5466-2020
FU All India Council for Technical Education (AICTE), Govt. of India, New
   Delhi [8023/RID/BOR/RPS-77/2005-06]
FX The authors are thankful to the anonymous reviewers for their useful
   suggestions and comments. The authors are also thankful to All India
   Council for Technical Education (AICTE), Govt. of India, New Delhi, for
   supporting the research work with their file number
   8023/RID/BOR/RPS-77/2005-06.
CR Alghoniemy M, 2004, IEEE T IMAGE PROCESS, V13, P145, DOI 10.1109/TIP.2004.823831
   AMAYEH GR, 2005, LNCS, V3804
   Broumandnia A, 2007, IMAGE VISION COMPUT, V25, P717, DOI 10.1016/j.imavis.2006.05.014
   Chong CW, 2003, PATTERN RECOGN, V36, P731, DOI 10.1016/S0031-3203(02)00091-2
   GHOSAL S, 1993, PATTERN RECOGN, V26, P295, DOI 10.1016/0031-3203(93)90038-X
   Hwang SK, 2006, IEEE T IMAGE PROCESS, V15, P112, DOI 10.1109/TIP.2005.860337
   Hwang SK, 2006, PATTERN RECOGN, V39, P2065, DOI 10.1016/j.patcog.2006.03.004
   JEANNIN S, 2000, ISOIECJIC1SC29WG11N3
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Kotoulas L, 2005, IEEE T CIRC SYST VID, V15, P801, DOI 10.1109/TCSVT.2005.848302
   Kotoulas L, 2007, IEEE T IMAGE PROCESS, V16, P2028, DOI 10.1109/TIP.2007.899621
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   PANG YH, 2003, J WSCG, V12, P1
   Papakostas GA, 2008, APPL MATH COMPUT, V195, P326, DOI 10.1016/j.amc.2007.04.110
   Papakostas GA, 2007, INFORM SCIENCES, V177, P2802, DOI 10.1016/j.ins.2007.01.010
   Papakostas GA, 2006, IMAGE VISION COMPUT, V24, P960, DOI 10.1016/j.imavis.2006.02.015
   Patil PM, 2007, PATTERN RECOGN, V40, P2110, DOI 10.1016/j.patcog.2006.12.018
   PAWLAK M, 1992, IEEE T INFORM THEORY, V38, P1698, DOI 10.1109/18.165444
   Qu YD, 2005, IMAGE VISION COMPUT, V23, P11, DOI 10.1016/j.imavis.2004.07.003
   Singh C, 2006, PATTERN RECOGN, V39, P2047, DOI 10.1016/j.patcog.2006.05.025
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   Wee CY, 2007, IMAGE VISION COMPUT, V25, P967, DOI 10.1016/j.imavis.2006.07.010
   Wee CY, 2006, PATTERN RECOGN, V39, P2036, DOI 10.1016/j.patcog.2006.05.027
   Xin YQ, 2007, IEEE T IMAGE PROCESS, V16, P581, DOI 10.1109/TIP.2006.888346
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zibreira C, 2000, LECT NOTES COMPUT SC, V1923, P332
NR 28
TC 37
Z9 39
U1 0
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2011
VL 29
IS 4
BP 251
EP 259
DI 10.1016/j.imavis.2010.10.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 727UR
UT WOS:000287828800005
DA 2024-07-18
ER

PT J
AU Vichik, A
   Keshet, R
   Malah, D
AF Vichik, Alla
   Keshet, Renato
   Malah, David
TI A general framework for tree-based morphology and its applications to
   self-dual filtering
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 8th International Symposium on Mathematical Morphology
CY OCT 10-13, 2007
CL Rio de Janeiro, BRAZIL
DE Complete inf-semilattices; Self-dual operators; Tree representation of
   images
AB This paper presents a tree-based framework for producing self-dual morphological operators, based on a tree-representation complete inf-semilattice (CISL). The idea is to use a self-dual tree transform to map a given image into the above CISL, perform one or more morphological operations there, and map the result back to the image domain using the inverse tree transform. We also present a particular case of this general framework, involving a new tree transform, the Extrema-Watershed Tree (EWT). The operators obtained by using the EWT in the above framework behave like classical morphological operators, but in addition are self-dual. Some application examples are provided: pre-processing for OCR and dust and scratch removal algorithms, and image denoising. We also explore first steps towards obtaining tree transforms that induce a CISL on the image domain as well. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Keshet, Renato] Hewlett Packard Labs Israel, IL-32000 Technion, Haifa, Israel.
   [Vichik, Alla; Keshet, Renato; Malah, David] Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
C3 Hewlett-Packard; Technion Israel Institute of Technology
RP Keshet, R (corresponding author), Hewlett Packard Labs Israel, IL-32000 Technion, Haifa, Israel.
EM alla.vichik@gmail.com; renato.keshet@hp.com; malah@ee.technion.ac.il
RI Malah, David/KCY-5739-2024
OI Malah, David/0009-0001-8310-7844
CR [Anonymous], 2016, Graph Theory
   Ballester C, 2003, ESAIM CONTR OPTIM CA, V9, P1, DOI 10.1051/cocv:2002069
   Caselles V, 2002, J MATH IMAGING VIS, V17, P249, DOI 10.1023/A:1020715626538
   Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X
   Goutsias J., 2000, Fundamenta Informaticae, V41, P1
   Heijmans HJAM, 2002, J MATH IMAGING VIS, V17, P55, DOI 10.1023/A:1020726725590
   Keshet R, 2005, J MATH IMAGING VIS, V22, P309, DOI 10.1007/s10851-005-4896-0
   Keshet R., 2000, Fundamenta Informaticae, V41, P33
   KESHET R, 1998, P ISMM 98 JUN, P35
   Keshet R, 2007, IMAGE VISION COMPUT, V25, P436, DOI 10.1016/j.imavis.2006.04.016
   Monasse P, 2000, J VIS COMMUN IMAGE R, V11, P224, DOI 10.1006/jvci.1999.0441
   Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532
   MONASSE P, 2000, THESIS U PARIS 9 DAU
   Ronse C, 2008, APPL ALGEBR ENG COMM, V19, P51, DOI 10.1007/s00200-008-0064-2
   Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500
   Salembier P, 2002, PATTERN RECOGN, V35, P563, DOI 10.1016/S0031-3203(01)00060-7
   Salembier P, 2000, INT C PATT RECOG, P367, DOI 10.1109/ICPR.2000.903561
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   VICHIK A, 2007, MATH MORPHOLOGY ITS, P49
   VICHIK A, 2006, THESIS EE DEP ISRAEL
   VICHIK S, 1999, MOVING CAR LICENSE P
NR 21
TC 1
Z9 1
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2010
VL 28
IS 10
SI SI
BP 1443
EP 1451
DI 10.1016/j.imavis.2009.08.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 638YK
UT WOS:000280936300003
DA 2024-07-18
ER

PT J
AU Choi, K
   Lee, S
   Seo, Y
AF Choi, Kyuhyoung
   Lee, Subin
   Seo, Yongduek
TI A branch-and-bound algorithm for globally optimal camera pose and focal
   length
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Global optimization; Branch-and-bound algorithm; Camera pose and focal
   length
ID OPTIMIZATION
AB This paper considers the problem of finding the global optimum of the camera rotation, translation and the focal length given a set of 2D-3D point pairs. The global solution is obtained under the L-infinity optimality by a branch-and-bound algorithm. To obtain the goal, we firstly extend the previous branch-and-bound formulation and show that the image space error (pixel distance) may be used instead of the angular error. Then, we present that the problem of camera pose plus focal length given the rotation is a quasi-convex problem. This provides a derivation of a novel inequality for the branch-and-bound algorithm for our problem. Finally, experimental results with synthetic and real data are provided. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Choi, Kyuhyoung; Lee, Subin; Seo, Yongduek] Sogang Univ, Dept Media Technol, Seoul, South Korea.
C3 Sogang University
RP Seo, Y (corresponding author), Sogang Univ, Dept Media Technol, Seoul, South Korea.
EM kyu@sogang.ac.kr; subin@sogang.ac.kr; yndk@sogang.ac.kr
OI SEO, Yongduek/0000-0002-0570-2197
FU MCST/MKE/KEIT [2008-F-030-01]
FX This work was supported by the strategic technology development program
   of MCST/MKE/KEIT [2008-F-030-01, Development of Full 3D Reconstruction
   Technology for Broadcasting Communication Fusion].
CR AGARWAL S, 2006, P EUR C COMP VIS
   [Anonymous], 2006, P IEEE C COMP VIS PA
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Boyd S., 2004, CONVEX OPTIMIZATION
   Fiore PD, 2001, IEEE T PATTERN ANAL, V23, P140, DOI 10.1109/34.908965
   *FSF GNU, 2006, FSF GNU LIN PROGR KI
   HARTLEY R, 2008, IEEE INT C COMP VIS
   HARTLEY R, 2004, P IEEE C COMP VIS PA
   Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9
   JAIN S, 2006, P INT C PATT REC
   Kahl F, 2008, IEEE T PATTERN ANAL, V30, P1603, DOI 10.1109/TPAMI.2007.70824
   Kato H., 1999, P 2 INT WORKSH AUGM
   Ke Q, 2007, IEEE T PATTERN ANAL, V29, P1834, DOI 10.1109/TPAMI.2007.1083
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   MATSUNAGA C, 2000, P EUR C COMP VIS
   Moreno-Noguer F., 2007, P INT C COMP VIS
   Olsson C, 2006, INT C PATT RECOG, P5
   Olsson C, 2009, IEEE I CONF COMP VIS, P405, DOI 10.1109/ICCV.2009.5459206
   Park SW, 2000, REAL-TIME IMAGING, V6, P433, DOI 10.1006/rtim.1999.0199
   Pirker K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.115
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   Seo Y, 2007, IEEE I CONF COMP VIS, P668
   Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766
NR 23
TC 6
Z9 9
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2010
VL 28
IS 9
BP 1369
EP 1376
DI 10.1016/j.imavis.2010.02.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 620NN
UT WOS:000279506700004
DA 2024-07-18
ER

PT J
AU Condat, L
AF Condat, Laurent
TI Color filter array design using random patterns with blue noise
   chromatic spectra
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Color filter array; Random pattern; Blue noise; Demosaicking
ID DEMOSAICKING; INTERPOLATION
AB We propose two new types of random patterns with R, G, B colors, which allow to design color filter arrays (CFAs) with good spectral properties. Indeed, the chrominance channels have blue noise characteristics, a property which maximizes the robustness of the acquisition system to aliasing. With these new CFAs, the demosaicking artifacts appear as incoherent noise, which is less visually disturbing than the moire structures characteristic of CFAs with periodic patterns. (C) 2009 Elsevier B.V. All rights reserved.
C1 GREYC, F-14050 Caen, France.
C3 Universite de Caen Normandie
RP Condat, L (corresponding author), GREYC, 6 Bd Marechal Juin, F-14050 Caen, France.
EM laurent.condat@greyc.ensicaen.fr
RI Condat, Laurent/E-4978-2018
OI Condat, Laurent/0000-0001-7087-1002
FU European Commission [MEXT-CT-2004-013477]
FX This material is based upon work performed during the stay of the author
   as postdoc in the Helmholtz Zentrum Munchen, Neuherberg, Germany. This
   stay was supported by the Marie Curie Excellence Team Grant
   MEXT-CT-2004-013477, Acronym MAME-BIA, funded by the European
   Commission.
CR Alleysson D, 2005, IEEE T IMAGE PROCESS, V14, P439, DOI 10.1109/TIP.2004.841200
   [Anonymous], HPL2003164R1
   Bayer B. E., 1976, U.S. patent, Patent No. 3,971,065
   Cohen MF, 2003, ACM T GRAPHIC, V22, P287, DOI 10.1145/882262.882265
   CONDAT L, 2009, P IEEE ICIP
   DIPPE MAZ, 1985, P SIGGRAPH 85, P69
   Dubois E, 2005, IEEE SIGNAL PROC LET, V12, P847, DOI 10.1109/LSP.2005.859503
   Glassner A. S., 1995, Principles of Digital Image Synthesis
   Gunturk BK, 2005, IEEE SIGNAL PROC MAG, V22, P44, DOI 10.1109/MSP.2005.1407714
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   Hirakawa K, 2008, IEEE T IMAGE PROCESS, V17, P1876, DOI 10.1109/TIP.2008.2002164
   Lian NX, 2007, IEEE T IMAGE PROCESS, V16, P2515, DOI 10.1109/TIP.2007.904459
   Lukac R, 2005, IEEE T CONSUM ELECTR, V51, P1260, DOI 10.1109/TCE.2005.1561853
   Lukac R, 2005, PATTERN RECOGN, V38, P2208, DOI 10.1016/j.patcog.2005.04.008
   McCool M., 1992, Proceedings. Graphics Interface '92, P94
   MENON D, 2009, THESIS U PADOVA ITAL
   MITCHELL D, 1987, P SIGGRAPH 87, P65
   MITSA T, 1992, J OPT SOC AM A, V9, P1920, DOI 10.1364/JOSAA.9.001920
   Pei SC, 2003, IEEE T CIRC SYST VID, V13, P503, DOI 10.1109/TCSVT.2003.813422
   PORTILLA J, 2005, P IEEE ICIP
   Rodríguez JB, 2008, IEEE T IMAGE PROCESS, V17, P1368, DOI 10.1109/TIP.2008.926145
   ULICHNEY RA, 1988, P IEEE, V76, P56, DOI 10.1109/5.3288
   Wandell B. A, 1995, Foundations of vision
   YELLOTT JI, 1983, SCIENCE, V221, P382, DOI 10.1126/science.6867716
   Zhu W, 1999, J VIS COMMUN IMAGE R, V10, P245, DOI 10.1006/jvci.1999.0412
NR 25
TC 19
Z9 24
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1196
EP 1202
DI 10.1016/j.imavis.2009.12.004
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400003
DA 2024-07-18
ER

PT J
AU Wu, J
   Smith, WAP
   Hancock, ER
AF Wu, Jing
   Smith, William A. P.
   Hancock, Edwin R.
TI Facial gender classification using shape-from-shading
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gender classification; Principal geodesic analysis; Shape-from-shading
ID PRINCIPAL GEODESIC ANALYSIS; CONSTRAINTS; DIFFERENCE
AB The aim in this paper is to show how to use the 2.5D facial surface normals (needle-maps) recovered using shape-from-shading (SFS) to perform gender classification. We use principal geodesic analysis (PGA) to model the distribution of facial surface normals which reside on a Remannian manifold. We incorporate PGA into shape-from-shading, and develop a principal geodesic shape-from-shading (PGSFS) method. This method guarantees that the recovered needle-maps exhibit realistic facial shape by satisfying a statistical model. Moreover, because the recovered facial needle-maps satisfy the data-closeness constraint as a hard constraint, they not only encode facial shape but also implicitly encode image intensity. Experiments explore the gender classification performance using the recovered facial needle-maps on two databases (Notre Dame and FERET), and compare the results with those obtained using intensity images. The results demonstrate the feasibility of gender classification using the recovered facial shape information. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Wu, Jing; Smith, William A. P.; Hancock, Edwin R.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
C3 University of York - UK
RP Wu, J (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
EM jwu@cs.york.ac.uk; wsmith@cs.york.ac.uk; erh@cs.york.ac.uk
RI Hancock, Edwin/N-7548-2019; Smith, William/AAK-9101-2020
OI Hancock, Edwin/0000-0003-4496-2028; Smith, William/0000-0002-6047-0413;
   Wu, Jing/0000-0001-5123-9861
CR Atick JJ, 1996, NEURAL COMPUT, V8, P1321, DOI 10.1162/neco.1996.8.6.1321
   BALUJA S, 2007, INT J COMPUTER VISIO, V7
   BELHUMEUR P, 1997, IEEE T PAMI, V19
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   BRUCE V, 1993, PERCEPTION, V22, P131, DOI 10.1068/p220131
   Brunelli R., 1992, P DARPA IMAGE UNDERS, P311
   Buchala S., 2005, P IEEE ICMI
   BURTON AM, 1993, PERCEPTION, V22, P153, DOI 10.1068/p220153
   Castelán M, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P183
   Chang K., 2003, MULTIMODAL USER AUTH, P25
   Cootes T., 1998, Proc. ECCV, V2, P484
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Fleming M. K., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P65, DOI 10.1109/IJCNN.1990.137696
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Flynn PJ, 2003, LECT NOTES COMPUT SC, V2688, P44
   Golomb B.A., 1991, ADV NEURAL INFORM PR, P572
   Gosselin F, 2001, VISION RES, V41, P2261, DOI 10.1016/S0042-6989(01)00097-9
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Hadid A, 2009, PATTERN RECOGN, V42, P2818, DOI 10.1016/j.patcog.2009.02.011
   Jain A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P159, DOI 10.1109/AFGR.2004.1301524
   Kim HC, 2006, PATTERN RECOGN LETT, V27, P618, DOI 10.1016/j.patrec.2005.09.027
   LENG X, 2008, P ICIP, P1656
   Lu HC, 2008, J REAL-TIME IMAGE PR, V3, P109, DOI 10.1007/s11554-008-0072-2
   Lu XG, 2006, LECT NOTES COMPUT SC, V3832, P554
   Maekinen E, 2008, PATTERN RECOGN LETT, V29, P1544, DOI 10.1016/j.patrec.2008.03.016
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   OTOOLE AJ, 1997, PERCEPTION, P130
   PENNEC X, 2004, RR5093 INRIA
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   PHUNG SL, 2006, INT C NEUR INF PROC, P207
   PRADOS E, 2004, RR5133 INRIA
   ROBLESKELLY A, 2005, GRAPH MODELS, V67, P18
   SAATCI Y, 2006, P INT C AUT FAC GEST
   Samaras D, 2003, IEEE T PATTERN ANAL, V25, P247, DOI 10.1109/TPAMI.2003.1177155
   Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124
   SIROVICH L, 1987, Q APPL MATH, V45, P561, DOI 10.1090/qam/910462
   Smith WAP, 2008, INT J COMPUT VISION, V76, P71, DOI 10.1007/s11263-007-0074-8
   Sun ZH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P165, DOI 10.1109/ACV.2002.1182176
   Wilhelm T, 2005, LECT NOTES COMPUT SC, V3696, P569, DOI 10.1007/11550822_89
   Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406
   Wu B, 2003, LECT NOTES COMPUT SC, V2688, P104
   WU J, 2008, P ICPR
   Wu J, 2007, LECT NOTES COMPUT SC, V4756, P331
   Wu J, 2006, LECT NOTES COMPUT SC, V4225, P58
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhao W.Y., 2000, P CVPR
NR 47
TC 22
Z9 26
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 1039
EP 1048
DI 10.1016/j.imavis.2009.09.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200017
DA 2024-07-18
ER

PT J
AU Cai, XD
   Ali, FH
   Stipidis, E
AF Cai, Xiaodong
   Ali, F. H.
   Stipidis, E.
TI Object-based video coding with dynamic quality control
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE MPEG-4; Video object; Video coding; Dynamic bit allocation; Visual
   attention; Priority
ID BIT ALLOCATION; ROBUST; MODEL
AB This paper presents a novel MPEG-4 priority-based multiple video objects coding system integrating User Visual Attention Model (UVAM) and Dynamic Bit Allocation (DBA) rate control mechanism. In the proposed system, the importance of individual objects is defined automatically and the coding parameters are adaptively adjusted so that the perceptual quality of important objects is maximized. The first contribution of the paper is an object-based UVAM utilizing a two-level structure and a blob extraction algorithm. Following that, two DBA algorithms are designed for object-based coding quality control in which weighted bits are allocated to prioritized single or group of video objects. Experimental results confirm that the defined automatic object-based priority is consistent with the observation of human visual system and the coding quality is maximized for the most important object and group of objects. In addition, the proposed system provides object-based coding flexibility and improved efficiency of utilizing coding resources. It offers key techniques to ensure the quality of services for real-time content-based video coding and streaming systems. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Cai, Xiaodong; Ali, F. H.; Stipidis, E.] Design Univ Sussex, Sch Engn, Commun Res Grp, Brighton BN1 9QT, E Sussex, England.
C3 University of Sussex
RP Ali, FH (corresponding author), Design Univ Sussex, Sch Engn, Commun Res Grp, Brighton BN1 9QT, E Sussex, England.
EM f.h.ali@sussex.ac.uk
CR Altunbasak Y, 1998, GRAPH MODEL IM PROC, V60, P13, DOI 10.1006/gmip.1997.0453
   [Anonymous], 2004, 144962 ISOIEC
   Chen LQ, 2003, MULTIMEDIA SYST, V9, P353, DOI 10.1007/s00530-003-0105-4
   Chen ZZ, 2006, IEEE T MULTIMEDIA, V8, P1117, DOI 10.1109/TMM.2006.884633
   Chen ZZ, 2004, IEEE IMAGE PROC, P761
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DOREA C, 2004, P INT WORKSH IM AN M, P71
   Elgammal A, 2000, EUR C COMP VIS, P751, DOI DOI 10.1007/3-540-45053-X_48
   *ISO IEC, 2001, 144965 ISOIEC
   *ISO IEC, 2001, JTC1SC29WG11N3908 IS
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   KUHNE G, 2001, P 9 ACM INT C MULT, V9, P41
   Lee HJ, 2000, IEEE T CIRC SYST VID, V10, P878, DOI 10.1109/76.867926
   Meier T, 1997, TENCON IEEE REGION, P283, DOI 10.1109/TENCON.1997.647312
   Nishi T, 2004, INT C PATT RECOG, P306, DOI 10.1109/ICPR.2004.1334528
   Ronda JI, 1999, IEEE T CIRC SYST VID, V9, P1243, DOI 10.1109/76.809159
   SALEMBIER P, 1995, P IEEE, V83, P843, DOI 10.1109/5.387088
   Schuster G., 1997, RATE DISTORTION BASE
   SCHUSTER GM, 1996, P 1996 IEEE INT C AC, V4, P1966
   SCHUSTER GM, 1996, P SPIE C VIS COMM IM, P784
   SHOHAM Y, 1988, IEEE T ACOUST SPEECH, V36, P1445, DOI 10.1109/29.90373
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun Y, 2004, IEEE T CIRC SYST VID, V14, P1167, DOI 10.1109/TCSVT.2004.833164
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vetro A, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P417
   Vetro A, 2001, INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: CODING AND COMPUTING, PROCEEDINGS, P366, DOI 10.1109/ITCC.2001.918823
   Vetro A, 1999, IEEE T CIRC SYST VID, V9, P186, DOI 10.1109/76.744285
   Wang DM, 1998, IEEE T CIRC SYST VID, V8, P539, DOI 10.1109/76.718501
   Wang HH, 2005, IEEE T CIRC SYST VID, V15, P1113, DOI 10.1109/TCSVT.2005.852629
   Yang XG, 1999, IEEE T IMAGE PROCESS, V8, P332, DOI 10.1109/83.748889
   Zhang YS, 2005, ADV CEM RES, V17, P23, DOI 10.1680/adcr.17.1.23.58388
NR 33
TC 1
Z9 1
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 285
EP 297
DI 10.1016/j.imavis.2009.08.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300001
DA 2024-07-18
ER

PT J
AU Urdiales, C
   Dominguez, M
   de Trazegnies, C
   Sandoval, F
AF Urdiales, C.
   Dominguez, M.
   de Trazegnies, C.
   Sandoval, F.
TI A new pyramid-based color image representation for visual localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Localization; Color histogram; Principal components; Hierarchical
   segmentation; Spatial graph
ID ROBOT LOCALIZATION; SEGMENTATION; PERFORMANCE; RETRIEVAL; VISION;
   IMPLEMENTATION; ENVIRONMENTS; RECOGNITION; INFORMATION; ALGORITHMS
AB This paper presents a new algorithm to extract a color graph from a real image so that it can be efficiently represented in a compact way. The proposal presents two main novelties. First, a new PCA-based color feature vector has been defined. This vector is resistant against illumination changes, noise and microtextures. Second, the image is segmented by means of a fast, hierarchical split and merge algorithm based on a pyramid structure that implicitly provides a color graph. In order to test the suitability of the proposed representation technique, simple localization experiments have been conducted in different real environments. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Urdiales, C.; Dominguez, M.; de Trazegnies, C.; Sandoval, F.] Univ Malaga, Dept Tecnol Elect, ETSI Telecomunicac, E-29071 Malaga, Spain.
C3 Universidad de Malaga
RP Urdiales, C (corresponding author), Univ Malaga, Dept Tecnol Elect, ETSI Telecomunicac, Campus Teatinos, E-29071 Malaga, Spain.
EM cristina@dte.uma.es
RI Urdiales, Cristina/H-4664-2019; Sandoval, Francisco/B-4487-2016
OI Urdiales, Cristina/0000-0002-9251-6447; Sandoval,
   Francisco/0000-0001-9235-7856; Trazegnies, Carmen de/0000-0002-6756-5087
FU Spanish Junta de Andalucia [TIC249]
FX This work has been partially supported by the Spanish Junta de
   Andalucia, Project No. TIC249 (SIAMA).
CR AGGARWAL G, 2000, P IEEE C MULT EXP IC
   Aliaga DG, 2004, IEEE ROBOT AUTOM MAG, V11, P53, DOI 10.1109/MRA.2004.1371609
   [Anonymous], HDB PATTERN RECOGNIT
   ATIYA S, 1993, IEEE T ROBOTIC AUTOM, V9, P785, DOI 10.1109/70.265922
   BARONTI S, 1990, COMPUT VISION GRAPH, V49, P346, DOI 10.1016/0734-189X(90)90108-8
   Berman AP, 1999, COMPUT VIS IMAGE UND, V75, P175, DOI 10.1006/cviu.1999.0772
   Borenstein J., 1996, NAVIGATING MOBILE RO
   BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619
   CANNON RL, 1986, IEEE T PATTERN ANAL, V8, P248, DOI 10.1109/TPAMI.1986.4767778
   CARSON C, 1999, P INT C VIS INF SYST
   Cho KJ, 1997, COMPUT VIS IMAGE UND, V68, P72, DOI 10.1006/cviu.1997.0546
   Christensen H. I., 1994, Robotics and Autonomous Systems, V12, P199, DOI 10.1016/0921-8890(94)90026-4
   Cobzas D., 2003, P IEEE INT C ROB AUT
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903
   Diplaros A, 2006, IEEE T IMAGE PROCESS, V15, P1, DOI 10.1109/TIP.2005.860320
   GLANTZ R, 2000, JOINT IAPR INT WORKS, P367
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   JERMYN IH, 2002, P ADV CONC INT VIS S
   Jolion J.M., 1994, PYRAMID FRAMEWORK EA
   KROSE B, 1999, P INT C ROB AUT ICRA
   Kröse BJA, 2001, IMAGE VISION COMPUT, V19, P381, DOI 10.1016/S0262-8856(00)00086-X
   Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255
   Li ZN, 1999, J VIS COMMUN IMAGE R, V10, P219, DOI 10.1006/jvci.1998.0403
   Lin XF, 2003, PATTERN RECOGN LETT, V24, P1959, DOI 10.1016/S0167-8655(03)00035-7
   MALLON J, 2002, OPTO IR SPIES REG M
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K., 2002, P INT C COMPUTER VIS, P128
   MU X, 2005, P INT C COMP VIS PAT
   Mukherjea S., 1999, World Wide Web, V2, P115, DOI 10.1023/A:1019248722478
   NACKEN PFM, 1995, PATTERN RECOGN, V28, P907, DOI 10.1016/0031-3203(94)00172-I
   Ortega M, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P403, DOI 10.1145/266180.266394
   Porta JM, 2005, AUTON ROBOT, V18, P59, DOI 10.1023/B:AURO.0000047287.00119.b6
   RUI Y, 1999, J VISUAL COMMUNICATI, V10, P123
   SCLAROFF S, 1997, P IEEE WORKSH CONT B
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467
   Se S, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P414, DOI 10.1109/IROS.2001.973392
   SHAFFER CA, 1987, COMPUT VISION GRAPH, V37, P402, DOI 10.1016/0734-189X(87)90045-4
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sim R., 2003, P INT JOINT C ART IN
   SIROVICH L, 1992, INT J SUPERCOMPUT AP, V6, P50, DOI 10.1177/109434209200600104
   SPANN M, 1989, PATTERN RECOGN, V22, P719, DOI 10.1016/0031-3203(89)90008-3
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   SWAIN MJ, 1996, TR9614 U CHIC DEP CO
   ULRICH I, 2000, IEEE INT C ROB AUT S, P1023
   VENDRIG J, 1999, LECT NOTES COMPUTER, V1614, P229
   VOLMER S, 1997, P 2 INT C VIS INF SY, P163
   WOLF J, 2002, P INT C IM VID RETR
   Zingaretti P, 2006, IEEE ROBOT AUTOM MAG, V13, P59, DOI 10.1109/MRA.2006.1598054
NR 49
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 78
EP 91
DI 10.1016/j.imavis.2009.04.014
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mouragnon, E
   Lhuillier, M
   Dhome, M
   Dekeyser, F
   Sayd, P
AF Mouragnon, E.
   Lhuillier, M.
   Dhome, M.
   Dekeyser, F.
   Sayd, P.
TI Generic and real-time structure from motion using local bundle
   adjustment
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 18th British Machine Vision Conference
CY 2007
CL Warwick, ENGLAND
DE Structure from motion; Bundle adjustment; Generic camera
ID POSE ESTIMATION; RECONSTRUCTION
AB This paper describes a method for estimating the motion of a calibrated camera and the three-dimensional geometry of the filmed environment. The only data used is video input. Interest points are tracked and matched between frames at video rate. Robust estimates of the camera motion are computed in real-time, key frames are selected to enable 3D reconstruction of the features. We introduce a local bundle adjustment allowing 3D points and camera poses to be refined simultaneously through the sequence. This significantly reduces computational complexity when compared with global bundle adjustment. This method is applied initially to a perspective camera model, then extended to a generic camera model to describe most existing kinds of cameras. Experiments performed using real-world data provide evaluations of the speed and robustness of the method. Results are compared to the ground truth measured with a differential GPS. The generalized method is also evaluated experimentally, using three types of calibrated cameras: stereo rig, perspective and catadioptric. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Mouragnon, E.; Lhuillier, M.; Dhome, M.] Univ Blaise Pascal, CNRS, LASMEA UMR 6602, F-63177 Clermont Ferrand, France.
   [Mouragnon, E.; Dekeyser, F.; Sayd, P.] CEA, Image & Embedded Comp Lab, LIST, DTSI SARC, F-91191 Gif Sur Yvette, France.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Engineering & Systems Sciences (INSIS); Universite Clermont Auvergne
   (UCA); CEA; Universite Paris Saclay
RP Lhuillier, M (corresponding author), Univ Blaise Pascal, CNRS, LASMEA UMR 6602, 24 Ave Landais, F-63177 Clermont Ferrand, France.
EM Maxime.Lhuillier@univ-bpclermont.fr
CR [Anonymous], 2006, PHOTOGRAMMETRIC COMP
   [Anonymous], P WORKSH OMN VIS
   Chang P, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P127, DOI 10.1109/OMNVIS.2000.853819
   DAVISON AJ, 2003, P INT C COMP VIS
   FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Kannala J, 2006, IEEE T PATTERN ANAL, V28, P1335, DOI 10.1109/TPAMI.2006.153
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   LHUILLIER M, 2006, INT C PATT REC
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   MICUSIK B, 2004, P C COMP VIS PATT RE
   MOURAGNON E, 2006, P C COMP VIS PATT RE
   MOURAGNON E, 2007, P BRIT MACH VIS C
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nistér D, 2004, PROC CVPR IEEE, P652
   Pless R, 2003, PROC CVPR IEEE, P587, DOI 10.1109/cvpr.2003.1211520
   Pollefeys M, 2000, ISPRS J PHOTOGRAMM, V55, P251, DOI 10.1016/S0924-2716(00)00023-X
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Ramalingam S, 2006, COMPUT VIS IMAGE UND, V103, P218, DOI 10.1016/j.cviu.2006.06.006
   ROYER E, 2005, P C COMP VIS PATT RE
   SHUM HY, 1999, P C COMP VIS PATT RE
   Steedly D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P223, DOI 10.1109/ICCV.2001.937628
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Zhang ZY, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P343
NR 27
TC 145
Z9 172
U1 1
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1178
EP 1193
DI 10.1016/j.imavis.2008.11.006
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Aguilar, W
   Frauel, Y
   Escolano, F
   Martinez-Perez, ME
   Espinosa-Romero, A
   Lozano, MA
AF Aguilar, Wendy
   Frauel, Yann
   Escolano, Francisco
   Elena Martinez-Perez, M.
   Espinosa-Romero, Arturo
   Angel Lozano, Miguel
TI A robust Graph Transformation Matching for non-rigid registration
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Matching; Graph-based based algorithms; Registration; Mosaicing; Retinal
   images; Feature matching
ID ALGORITHM
AB In this paper, we propose a simple and highly robust point-matching method named Graph Transformation Matching (GTM) relying on finding a consensus nearest-neighbour graph emerging from candidate matches. The method iteratively eliminates dubious matches in order to obtain the consensus graph. The proposed technique is compared against both the Softassign algorithm and a combination of RANSAC and epipolar constraint. Among these three techniques, GTM demonstrates to yield the best results in terms of elimination of outliers. The algorithm is shown to be able to deal with difficult cases such as duplication of patterns and non-rigid deformations of objects. An execution time comparison is also presented, where GTM shows to be also superior to RANSAC for high outlier rates. In order to improve the performance of GTM for lower outlier rates, we present an optimised version of the algorithm. Lastly, GTM is successfully applied in the context of constructing mosaics of retinal images, where feature points are extracted from properly segmented binary images. Similarly, the proposed method could be applied to a number of other important applications. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Aguilar, Wendy; Frauel, Yann; Elena Martinez-Perez, M.] Univ Nacl Autonoma Mexico, Dept Ciencias Computac, Inst Invest Matemat Aplicadas & Sistemas, Mexico City 04510, DF, Mexico.
   [Escolano, Francisco; Angel Lozano, Miguel] Univ Alicante, Depto Ciencia Computac & Inteligencia Artificial, E-03080 Alicante, Spain.
   [Espinosa-Romero, Arturo] Univ Autonoma Yucatan, Fac Matemat, Merida, Yucatan, Mexico.
C3 Universidad Nacional Autonoma de Mexico; Universitat d'Alacant;
   Universidad Autonoma de Yucatan
RP Aguilar, W (corresponding author), Univ Nacl Autonoma Mexico, Dept Ciencias Computac, Inst Invest Matemat Aplicadas & Sistemas, Apartado Postal 20-726,Ciudad Univ, Mexico City 04510, DF, Mexico.
EM weam@turing.iimas.unam.mx; yann@leibniz.iimas.unam.mx; sco@dccia.ua.es;
   elena@leibniz.iimas.unam.mx; eromero@tunku.uady.mx; malozano@dccia.ua.es
RI Aguilar, Wendy/IAR-2558-2023; Lozano, Miguel Angel/F-1258-2017;
   Martinez-Perez, Maria Elena/R-4844-2016
OI Aguilar, Wendy/0000-0003-1867-8859; Lozano, Miguel
   Angel/0000-0002-4757-5587; Espinosa Romero, Arturo/0000-0002-5153-2950;
   Martinez-Perez, Maria Elena/0000-0002-4469-3895
CR AGUILAR W, 2006, THESIS UNAM MEXICO C
   Aguilar W, 2007, LECT NOTES COMPUT SC, V4538, P25
   [Anonymous], MATLAB and Octave functions for computer vision and image processing
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gelman R, 2005, INVEST OPHTH VIS SCI, V46, P4734, DOI 10.1167/iovs.05-0646
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hughes AD, 2006, J HYPERTENS, V24, P889, DOI 10.1097/01.hjh.0000222759.61735.98
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez-Perez ME, 2007, MED IMAGE ANAL, V11, P47, DOI 10.1016/j.media.2006.11.004
   Martinez-Perez ME, 2002, IEEE T BIO-MED ENG, V49, P912, DOI 10.1109/TBME.2002.800789
   Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179
   Qiu HJ, 2007, PATTERN RECOGN, V40, P2874, DOI 10.1016/j.patcog.2006.11.013
   Rangarajan A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P671
   Robles-Kelly A, 2005, IEEE T PATTERN ANAL, V27, P365, DOI 10.1109/TPAMI.2005.56
   Torr PHS, 2004, IEEE T PATTERN ANAL, V26, P648, DOI 10.1109/TPAMI.2004.1273967
   Torr PHS, 2003, IEEE T PATTERN ANAL, V25, P354, DOI 10.1109/TPAMI.2003.1182098
   Vincent E., 2001, Machine Graphics & Vision, V10, P237
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 21
TC 129
Z9 161
U1 2
U2 50
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 897
EP 910
DI 10.1016/j.imavis.2008.05.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300008
DA 2024-07-18
ER

PT J
AU Peltier, S
   Ion, A
   Kropatsch, WG
   Damiand, G
   Haxhimusa, Y
AF Peltier, Samuel
   Ion, Adrian
   Kropatsch, Walter G.
   Damiand, Guillaume
   Haxhimusa, Yll
TI Directly computing the generators of image homology using graph pyramids
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Homology generators; Irregular graph pyramids
AB We introduce a method for computing homology groups and their generators of a 2D image, using a hierarchical structure, i.e. irregular graph pyramid. Starting from an image, a hierarchy of the image is built by two operations that preserve homology of each region. Instead of computing homology generators in the base where the number of entities (cells) is large, we first reduce the number of cells by a graph pyramid. Then homology generators are computed efficiently on the top level of the pyramid, since the number of cells is small. A top down process is then used to deduce homology generators in any level of the pyramid, including the base level, i.e. the initial image. The produced generators fit on the object boundaries. A unique set of generators called the minimal set, is defined and its computation is discussed. We show that the new method produces valid homology generators and present some experimental results. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Peltier, Samuel; Ion, Adrian; Kropatsch, Walter G.; Haxhimusa, Yll] Vienna Univ Technol, Pattern Recognit & Image Proc Grp, Fac Informat, A-1040 Vienna, Austria.
   [Peltier, Samuel; Damiand, Guillaume] Univ Lyon, CNRS, LIRIS, UMR5205, F-69622 Villeurbanne, France.
   [Haxhimusa, Yll] Purdue Univ, Dept Psychol Sci, W Lafayette, IN 47907 USA.
C3 Technische Universitat Wien; Institut National des Sciences Appliquees
   de Lyon - INSA Lyon; Centre National de la Recherche Scientifique
   (CNRS); Purdue University System; Purdue University
RP Peltier, S (corresponding author), Vienna Univ Technol, Pattern Recognit & Image Proc Grp, Fac Informat, A-1040 Vienna, Austria.
EM peltier@sic.univ-poitiers.fr; ion@prip.tuwien.ac.at;
   krw@prip.tuwien.ac.at; guillaume.damiand@liris.cnrs.fr;
   yll@psych.purdue.edu
RI Damiand, Guillaume/IAM-8662-2023; Damiand, Guillaume/AAJ-2151-2020
OI Damiand, Guillaume/0000-0003-1580-5517
CR Agoston M. K., 1976, PURE APPL MATH
   Allili M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P173, DOI 10.1109/ICIP.2001.958452
   Brun L, 2006, PATTERN RECOGN, V39, P515, DOI 10.1016/j.patcog.2005.10.015
   DAMIAND G, 2006, LNCS, V4292, P1151
   Damiand G, 2006, LECT NOTES COMPUT SC, V4040, P1
   Dumas JG, 2003, ALGEBRA, GEOMETRY, AND SOFTWARE SYSTEMS, P177
   Gonzalez-Diaz R, 2007, LECT NOTES COMPUT SC, V4538, P330
   Haxhimusa Y, 2003, LECT NOTES COMPUT SC, V2781, P338
   Jolion J.M., 1994, PYRAMID FRAMEWORK EA
   KACZYNKSI T, 2004, COMPUTATIONAL HOMOLO
   Kaczynski T, 1998, COMPUT MATH APPL, V35, P59, DOI 10.1016/S0898-1221(97)00289-7
   Kaczynski Tomasz, 2004, COMPUTATIONAL HOMOLO, V3
   KANNAN R, 1979, SIAM J COMPUT, V8, P499, DOI 10.1137/0208040
   KOVALEVSKY VA, 1989, COMPUT VISION GRAPH, V46, P141, DOI 10.1016/0734-189X(89)90165-5
   KOVALEVSKY VA, 1993, GEOMETRIE DISCRETE I, P259
   Kropatsch WG, 1995, IEE P-VIS IMAGE SIGN, V142, P366, DOI 10.1049/ip-vis:19952115
   MEER P, 1989, COMPUT VISION GRAPH, V45, P269, DOI 10.1016/0734-189X(89)90084-4
   MUNKRES J. R., 1984, Elements of Algebraic Topology
   Niethammer M, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P969
   Peltier S, 2007, LECT NOTES COMPUT SC, V4538, P283
   Peltier S, 2006, COMPUT GRAPH-UK, V30, P62, DOI 10.1016/j.cag.2005.10.011
   Sonka M., 2014, Image processing, analysis, and machine vision
   Storjohann A., 1996, P INT S SYMBOLIC ALG, P267
   Thulasiraman K., 1992, Graphs: theory and algorithms
NR 24
TC 13
Z9 13
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 846
EP 853
DI 10.1016/j.imavis.2008.06.009
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rodriguez-Benitez, L
   Moreno-Garcia, J
   Castro-Schez, JJ
   Albusac, J
   Jimenez-Linares, L
AF Rodriguez-Benitez, L.
   Moreno-Garcia, J.
   Castro-Schez, J. J.
   Albusac, J.
   Jimenez-Linares, L.
TI Automatic objects behaviour recognition from compressed video domain
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fuzzy logic; Linguistic labels; MPEG compressed video; Behaviour models;
   Vehicles tracking
AB In this paper we present a system that, directly from compressed video domain, establishes a correspondence between objects in motion in a video scene and a concrete behaviour. This behaviour is expressed by using linguistic variables. Besides, with this fuzzy logic-based approach, the imprecision and vagueness of our primary source of information, MPEG motion vectors, is reduced. Proposed algorithms for segmentation and tracking are based on fuzzification of MPEG motion data. Once the tracking phase has finished, a linguistic model for each objective in the scene is generated and compared with each one of the behaviour models previously described in a linguistic manner. Finally, a practical application of this system for detection, tracking and behaviour analysis of vehicles in complex traffic scenes is presented. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Rodriguez-Benitez, L.; Castro-Schez, J. J.; Albusac, J.; Jimenez-Linares, L.] Univ Castilla La Mancha Technol & Sistemas Inform, Oreto Res Grp, E-13071 Ciudad Real, Spain.
   [Moreno-Garcia, J.] Escuela Ingn Tecn Ind, Toledo, OH USA.
C3 Universidad de Castilla-La Mancha
RP Rodriguez-Benitez, L (corresponding author), Univ Castilla La Mancha Technol & Sistemas Inform, Oreto Res Grp, Paseo Univ S-N, E-13071 Ciudad Real, Spain.
EM luis.rodriguez@uclm.es
RI Castro-Schez, Jose Jesus/AAH-7344-2021; Jiménez, Javier Alonso
   Albusac/AAB-6432-2019; Castro-Schez, Jose Jesus/E-8934-2012; Jimenez
   Linares, Luis/J-6832-2012
OI Castro-Schez, Jose Jesus/0000-0002-0201-7653; Jiménez, Javier Alonso
   Albusac/0000-0003-1889-3065; Rodriguez Benitez,
   Luis/0000-0002-7665-943X; Moreno Garcia, Juan/0000-0003-2430-145X;
   Jimenez Linares, Luis/0000-0002-2737-5887
FU Regional Government of Castilla-la Mancha [PAC06-0141, PBC06-0064];
   Spanish Ministry of Education and Science [TIN2007-62568]
FX This work has been funded by the Regional Government of Castilla-la
   Mancha (PAC06-0141 and PBC06-0064) and the Spanish Ministry of Education
   and Science (TIN2007-62568).
CR Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Ardizzone E., 1999, P IEEE INT C MULT CO
   Busch F., 1987, CONCISE ENCY TRAFFIC, P219
   Buxton H, 2003, IMAGE VISION COMPUT, V21, P125, DOI 10.1016/S0262-8856(02)00127-0
   Cheu RL, 1995, TRANSPORT RES C-EMER, V3, P371, DOI 10.1016/0968-090X(95)00016-C
   COIMBRA M, 2004, P IEEE ICASSP 04 MON
   Coimbra MT, 2005, IEEE T CIRC SYST VID, V15, P103, DOI 10.1109/TCSVT.2004.837016
   Dubois D, 1980, Fuzzy sets and systems
   GILVARRY J, 1999, CALCULATION MOTION U
   Kastrinaki V, 2003, IMAGE VISION COMPUT, V21, P359, DOI 10.1016/S0262-8856(03)00004-0
   KIM NW, 2002, INT TECHN C CIRC SYS
   Mezaris V, 2004, IEEE T CIRC SYST VID, V14, P606, DOI 10.1109/TCSVT.2004.826768
   MORENOGARCIA J, 2004, FUZZY SETS SYSTEMS I
   Naphade MR, 2001, IEEE T MULTIMEDIA, V3, P141, DOI 10.1109/6046.909601
   PILU M, 1997, USING RAW MPEG MOTIO
   RAPANTZIDOS K, 2005, P ICASSP 05 IEEE INT
   Remagnino P, 2004, PATTERN RECOGN, V37, P675, DOI 10.1016/j.patcog.2003.09.017
   RODRIGUEZBENITE.L, 2005, 11 INT FUZZ SYST ASS
   RODRIGUEZBENITE.L, 2007, 2 INT C COMP VIS THE
   VENKATESH R, 2001, IEEE WORKSH 2001, P44
   VENKATESH R, 2002, IND C COMP VIS
   VU V, 2004, THESIS
   Wang R, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL V, P21, DOI 10.1109/ISCAS.2000.857353
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   YOON K, 2000, 15 C PATT REC IEEE
   YOSHIDA T, 1997, ICIP, V2, P152
   ZADEH LA, 1975, INFORM SCIENCES, V9, P43, DOI 10.1016/0020-0255(75)90017-1
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
   Zadeh LA., 1975, INFORMATION SCI, V8, P310
   ZADEH LA, 1960, FUZZY SET INFORM CON
NR 30
TC 8
Z9 8
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 648
EP 657
DI 10.1016/j.imavis.2008.07.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000005
DA 2024-07-18
ER

PT J
AU Buenaposada, JM
   Muñoz, E
   Baumela, L
AF Buenaposada, Jose M.
   Munoz, Enrique
   Baumela, Luis
TI Efficient illumination independent appearance-based face tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 17th Annual British Machine Vision Conference
CY SEP, 2006
CL British Machine Vis Assoc, Edinburgh, SCOTLAND
HO British Machine Vis Assoc
DE Linear models of appearance; Illumination invariance; Efficient linear
   subspace model fitting; Facial expression analysis
ID VISUAL TRACKING; MODELS; IMAGE; CONSTRUCTION; RECOGNITION
AB One of the major challenges that visual tracking algorithms face nowadays is being able to cope with changes in the appearance of the target during tracking. Linear subspace models have been extensively studied and are possibly the most popular way of modelling target appearance. We introduce a linear subspace representation in which the appearance of a face is represented by the addition of two approximately independent linear subspaces modelling facial expressions and illumination, respectively. This model is more compact than previous bilinear or multilinear approaches. The independence assumption notably simplifies system training. We only require two image sequences. One facial expression is subject to all possible illuminations in one sequence and the face adopts all facial expressions under one particular illumination in the other. This simple model enables us to train the system with no manual intervention. We also revisit the problem of efficiently fitting a linear subspace-based model to a target image and introduce an additive procedure for solving this problem. We prove that Matthews and Baker's inverse compositional approach makes a smoothness assumption on the subspace basis that is equivalent to Hager and Belhumeur's, which worsens convergence. Our approach differs from Hager and Belhumeur's additive and Matthews and Baker's compositional approaches in that we make no smoothness assumptions on the subspace basis. In the experiments conducted we show that the model introduced accurately represents the appearance variations caused by illumination changes and facial expressions. We also verify experimentally that our fitting Procedure is more accurate and has better convergence rate than the other related approaches, albeit at the expense of a slight increase in computational cost. Our approach can be used for tracking a human face at standard video frame rates on an average personal computer. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Munoz, Enrique; Baumela, Luis] Univ Politecn Madrid, Fac Informat, Dept Inteligencia Artificial, E-28040 Madrid, Spain.
C3 Universidad Politecnica de Madrid
RP Baumela, L (corresponding author), Univ Politecn Madrid, Fac Informat, Dept Inteligencia Artificial, E-28040 Madrid, Spain.
EM lbaumela@fi.upm.es
RI Baumela, Luis/F-8867-2013; Buenaposada, Jose M./L-6458-2014
OI Buenaposada, Jose M./0000-0002-4308-9653
CR [Anonymous], P ICCV
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 1981, P 7 INT JOINT C ART
   [Anonymous], LNCS, DOI DOI 10.1007/3-540-47969-4_30
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker S, 2004, IEEE T PATTERN ANAL, V26, P1380, DOI 10.1109/TPAMI.2004.77
   Baker S, 2001, PROC CVPR IEEE, P1090
   Bartoli A, 2008, IEEE T PATTERN ANAL, V30, P2098, DOI 10.1109/TPAMI.2008.22
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Basu S., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P611, DOI 10.1109/ICPR.1996.547019
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   BUENAPOSADA JM, 2004, P CVPR WORKSH NONR A
   Buenaposada M, 2002, INT C PATT RECOG, P697, DOI 10.1109/ICPR.2002.1048397
   COOTES T, 1998, LNCS, V1047, P484
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   De la Torre F, 2002, LECT NOTES COMPUT SC, V2353, P653
   DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811
   Dornaika F, 2004, IEEE T SYST MAN CY B, V34, P1838, DOI 10.1109/TSMCB.2004.829135
   Elgammal A, 2004, PROC CVPR IEEE, P478
   Elgammal A, 2003, PROC CVPR IEEE, P781
   Fei H, 2004, LECT NOTES COMPUT SC, V3023, P497
   Gee A, 1996, IMAGE VISION COMPUT, V14, P105, DOI 10.1016/0262-8856(95)01044-0
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Grimes DB, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1478
   Gross R., 2004, P BRIT MACH VIS C, P457
   Gross R, 2006, IMAGE VISION COMPUT, V24, P593, DOI 10.1016/j.imavis.2005.08.001
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625
   Khan Z, 2004, PROC CVPR IEEE, P980
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Lee KC, 2005, PROC CVPR IEEE, P852
   Lim Jongwoo., 2005, Advances in Neural Information Processing Systems, P793
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Murphy K, 2001, STAT ENG IN, P499
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Rahimi A, 2005, PROC CVPR IEEE, P868
   Romdhani S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P59
   Ross D, 2004, LECT NOTES COMPUT SC, V3022, P470
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726
   Toyama K, 2002, INT J COMPUT VISION, V48, P9, DOI 10.1023/A:1014899027014
   VALILESCU MAO, 2005, P CVPR, V1, P547
   Williams O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P353
NR 48
TC 10
Z9 11
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 2
PY 2009
VL 27
IS 5
SI SI
BP 560
EP 578
DI 10.1016/j.imavis.2008.04.015
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 437WD
UT WOS:000265516700007
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Yu, L
   Wang, Q
   Wu, LA
   Me, J
AF Yu, Lu
   Wang, Qiao
   Wu, Lenan
   Me, Jun
TI A Mumford-Shah model on lattice
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Mumford-Shah; Discrete model
AB Mumford-Shah piecewise smooth functional is a variational PDE model widely used in image segmentation and smoothing. An analogous discrete model which models image as an MRF has also been built. In this paper, we propose another discrete Mumford-Shah piecewise smooth model on lattice from a different perspective. We present a discrete objective functional, as well as the method to find the solution. Only two simple and deterministic optimization techniques, that is, derivation and greedy algorithm are used in the model to seek the solution. Compared with traditional continuous model, the model in this paper is much simpler and the approach is much easier and faster. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Yu, Lu; Wang, Qiao; Wu, Lenan] Southeast Univ, Dept Radio Engn, Nanjing 210096, Peoples R China.
   [Yu, Lu] PLA Univ Sci & Technol, Inst Commun Engn, Nanjing 210007, Peoples R China.
   [Me, Jun] PLA Univ Sci & Technol, Inst Command Automat, Nanjing 210007, Peoples R China.
C3 Southeast University - China; Army Engineering University of PLA; Army
   Engineering University of PLA
RP Wang, Q (corresponding author), Southeast Univ, Dept Radio Engn, Nanjing 210096, Peoples R China.
EM qiaowang@seu.edu.cn
RI Wang, Qiao/AAU-2338-2020
OI Wang, Qiao/0000-0002-5271-0472; Yu, Lu/0000-0001-9692-7190
FU key lab of image processing and image communication; Nanjing University
   of Post and Telecommunications
FX This work was supported by open fund from key lab of image processing
   and image communication, Nanjing University of Post and
   Telecommunications.
CR CHAN T, 0377 UCLA CAM
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P161, DOI 10.1109/VLSM.2001.938895
   DIBOS F, 2005, INT C IM PROC
   DROSKE M, 0563 UCLA CAM
   Esedoglu S, 2002, EUR J APPL MATH, V13, P353, DOI 10.1017/S0956792501004904
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GIBOU F, 2002, STANDFORD TECHNICAL
   JUN X, 2007, CHINESE J ELECTRON, V16, P547
   KULKARNI SR, 1994, IEEE T PATTERN ANAL, V16, P711, DOI 10.1109/34.297951
   LIE J, 2004, EUR C COMP METH APPL
   LIE J, 0431 UCLA CAM
   MUMFORD D, 1994, PROG MATH, V119, P187
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   NIELSEN LK, 0551 UCLA CAM
   NIELSEN LK, 0550 UCLA CAM
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   SHEN J, 0554 UCLA CAM
   Shi Y, 2005, INT CONF ACOUST SPEE, P97
   Shi YG, 2005, PROC CVPR IEEE, P34
   SONG B, 0268 UCLA CAM
   TAI XC, 0524 UCLA CAM
   TAI XC, 0552 UCLA CAM
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   WITTMAN T, 2005, LOT HILL VIS C
NR 25
TC 2
Z9 2
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1663
EP 1669
DI 10.1016/j.imavis.2008.04.024
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500009
DA 2024-07-18
ER

PT J
AU Madrid-Cuevas, FJ
   Carmona-Poyato, A
   Medina-Carnicer, R
   Muñoz-Salinas, R
AF Madrid-Cuevas, F. J.
   Carmona-Poyato, A.
   Medina-Carnicer, R.
   Munoz-Salinas, R.
TI Contour simplification using a multi-scale local phase analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE contour simplification; local phase; multi-scale contour analysis
ID DOMINANT-POINT DETECTION; POLYGONAL-APPROXIMATION; SHAPE REPRESENTATION;
   DIGITAL CURVES; WAVELET TRANSFORM; PLANAR CURVES; OBJECT RECOGNITION;
   DIGITIZED-CURVES; CORNER DETECTION; ALGORITHM
AB This paper proposes a new method for simplifying contours based on the multi-scale analysis of the local phase. The main advantages of the proposed method are: (i) it does not use any curvature measure approximation to stand out the characteristic points. (ii) The symmetry/asymmetry points can be considered as dominant points of the contour and (iii) it provides a robust approach to suppress the contour noise. The method has been compared with a representative number of other methods using an objective measure of the quality of the generated approximation. The experimental results have shown that the proposed method is superior to those reviewed in our study. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Madrid-Cuevas, F. J.; Carmona-Poyato, A.; Medina-Carnicer, R.; Munoz-Salinas, R.] Univ Cordoba, Dpto Informat & Anal Numer, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba
RP Madrid-Cuevas, FJ (corresponding author), Univ Cordoba, Dpto Informat & Anal Numer, Campus Rabanales S-N, E-14071 Cordoba, Spain.
EM Ma1macuf@uco.es
RI Muñoz-Salinas, Rafael/K-5999-2014; Carmona-Poyato, Angel/G-1593-2015;
   Medina-Carnicer, Rafael/G-3401-2015; Madrid-Cuevas, Francisco
   Jose/H-1396-2015
OI Muñoz-Salinas, Rafael/0000-0002-8773-8571; Carmona-Poyato,
   Angel/0000-0002-8820-8396; Medina-Carnicer, Rafael/0000-0003-4481-0614;
   Madrid-Cuevas, Francisco Jose/0000-0001-6557-7431
FU Science and Technology Ministry of Spain; FEDER;  [DPI2006-02608]
FX This work has been developed with the support of the Research Project
   called "DP2006-02608" and financed by Science and Technology Ministry of
   Spain and FEDER.
CR [Anonymous], THESIS U W AUSTR
   Antoine JP, 1997, SIGNAL PROCESS, V62, P265, DOI 10.1016/S0165-1684(97)00129-1
   BALLARD DH, 1981, COMMUN ACM, V24, P310, DOI 10.1145/358645.358661
   Bandera A, 1999, PATTERN RECOGN LETT, V20, P49, DOI 10.1016/S0167-8655(98)00123-8
   Carmona-Poyato A, 2005, IMAGE VISION COMPUT, V23, P1226, DOI 10.1016/j.imavis.2005.07.025
   CHUNG PC, 1994, PATTERN RECOGN, V27, P1505, DOI 10.1016/0031-3203(94)90128-7
   COHEN FS, 1995, IEEE T IMAGE PROCESS, V4, P1, DOI 10.1109/83.350818
   Cornic P, 1997, PATTERN RECOGN LETT, V18, P13, DOI 10.1016/S0167-8655(96)00116-X
   Costa L. da F., 2001, SHAPE ANAL CLASSIFIC
   Davis L., 1986, Handbook of Pattern Recognition and Image Processing, P233
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Fu AMN, 1997, PATTERN RECOGN LETT, V18, P55, DOI 10.1016/S0167-8655(96)00131-6
   Fu AMN, 1997, PATTERN RECOGN, V30, P1661, DOI 10.1016/S0031-3203(96)00183-5
   Gao XT, 2007, IMAGE VISION COMPUT, V25, P890, DOI 10.1016/j.imavis.2006.07.002
   Garrido A, 1998, PATTERN RECOGN, V31, P791, DOI 10.1016/S0031-3203(97)00104-0
   Gonzalez R., 1996, TRATAMIENTO DIGITAL
   Gu YH, 2000, PATTERN RECOGN, V33, P1411, DOI 10.1016/S0031-3203(99)00131-4
   HENDERSON T, 1983, FUNDAMENTALS COMPUTE, P273
   Huang PW, 1999, PATTERN RECOGN LETT, V20, P163, DOI 10.1016/S0167-8655(98)00132-9
   IKEBE Y, 1982, SHAPE DESIGN REPRESE
   LEE JS, 1995, IEEE T IMAGE PROCESS, V4, P100, DOI 10.1109/83.350810
   LIN YJ, 1992, PATTERN RECOGN, V25, P17, DOI 10.1016/0031-3203(92)90003-2
   LONCARIC S, PATTERN RECOGNITION, V31
   LOWE D, 1987, ARTIF INTELL, V31, P335
   Marji M, 2004, PATTERN RECOGN, V37, P2113, DOI 10.1016/j.patcog.2004.03.004
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387
   MORRONE MC, 1987, PATTERN RECOGN LETT, V6, P303, DOI 10.1016/0167-8655(87)90013-4
   NAVA FP, 1999, P 4 S IB REC PATR HA, V1, P109
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P443, DOI 10.1016/0167-8655(92)90051-Z
   ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188
   ROSIN PL, 1997, IEEE T PATTERN ANAL, V19, P1659
   SAGHRI JA, 1981, IEEE T PATTERN ANAL, V3, P533, DOI 10.1109/TPAMI.1981.4767146
   Sonka M., 1993, IMAGE PROCESSING ANA
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Urdiales C, 2002, PATTERN RECOGN, V35, P43, DOI 10.1016/S0031-3203(01)00041-3
   WU JS, 1993, PATTERN RECOGN, V26, P471, DOI 10.1016/0031-3203(93)90103-4
   WU WY, 1993, CVGIP-GRAPH MODEL IM, V55, P79, DOI 10.1006/cgip.1993.1006
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Wu WY, 2003, IMAGE VISION COMPUT, V21, P517, DOI 10.1016/S0262-8856(03)00031-3
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   ZHU PF, 1995, IEEE T PATTERN ANAL, V17, P737, DOI 10.1109/34.400564
NR 45
TC 2
Z9 2
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1499
EP 1506
DI 10.1016/j.imavis.2008.04.009
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000005
DA 2024-07-18
ER

PT J
AU Palacios, R
   Gupta, A
AF Palacios, Rafael
   Gupta, Amar
TI A system for processing handwritten bank checks automatically
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE handwritten checks; reading unconstrained handwritten material; neural
   network based reading; automation of banking systems
ID AMOUNT RECOGNITION; SEGMENTATION; ALGORITHM
AB In the US and many other countries, bank checks are preprinted with the account number and the check number in special ink and format; as such, these two numeric fields can be easily read and processed using automated techniques. However, the amount fields on a filled-in check is usually read by human eyes, and involves significant time and cost, especially when one considers that over 50 billion checks are processed per annum in the US alone. The system described in this paper uses the scanned image of a bank check to 'read' the check. It includes three main modules that allow for fully automated bank check processing. These three modules are described in the paper; they focus sequentially on: the detection of strings within the image; the segmentation and recognition of string in a feedback loop; and the post-processing issues that help to ensure higher accuracy of recognition. The major benefit of the integrated system is the ability to address the complex problem of reading handwritten bank checks by implementing efficient algorithms for each processing step. All modules have been implemented and subsequently tested for reading the value of the check using different image databases. Due to the particular requirements of this application, the system can be tuned to yield low levels of incorrect readings; this, in turn, leads to higher levels of rejection than the levels encountered in other handwritten recognition applications. A 'rejected' check can be read subsequently by human eyes or other more advanced automated approaches. However, a check 'read' incorrectly is more difficult to deal with, in terms of costs and time involved to rectify the mistake. As such, our architecture can be geared towards producing the most suitable balance between inaccurate readings and rejection level, in accordance with user preferences. The experimental results presented in the paper do not focus on the best possible results for a particular database of checks; instead, they show the benefits attained independently by each of the modules proposed. (c) 2006 Elsevier B.V. All rights reserved.
C1 [Palacios, Rafael] Univ Pontificia Comillas, Inst Invest Tecnol, Madrid 28015, Spain.
   [Gupta, Amar] Harvard Univ, MIT, Cambridge, MA 02139 USA.
   [Gupta, Amar] Univ Arizona, Tucson, AZ USA.
C3 Comillas Pontifical University; Harvard University; Massachusetts
   Institute of Technology (MIT); University of Arizona
RP Palacios, R (corresponding author), Univ Pontificia Comillas, Inst Invest Tecnol, Alberto Aguilera 23, Madrid 28015, Spain.
EM rafael.palacios@iit.upcomillas.es
RI Palacios, Rafael/A-6724-2010
OI Palacios, Rafael/0000-0002-8963-5074; Gupta, Amar/0000-0001-9306-1256
CR AGARWAL A, 1997, HDB CHARACTER RECOGN
   BAIRD H, 1994, DOCUMENT ANAL RECOGN
   BOZINOVIC RM, 1989, IEEE T PATTERN ANAL, V11, P68, DOI 10.1109/34.23114
   CARRASCO RC, 1995, PATTERN RECOGN LETT, V16, P539, DOI 10.1016/0167-8655(95)00121-V
   Casey RG, 1996, IEEE T PATTERN ANAL, V18, P690, DOI 10.1109/34.506792
   COHEN E, 1991, CHARACTER HANDWRITIN, P221
   CONGEDO G, 1995, P 3 INT C DOC AN REC, V2, P1038
   de Almendra Freitas C. O., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), P97, DOI 10.1109/SIBGRA.2000.883901
   DEY S, 1999, THESIS MIT
   Dimauro G, 1997, INT J PATTERN RECOGN, V11, P467, DOI 10.1142/S0218001497000214
   Fan R., 1997, PROGR HANDWRITING RE, P473
   FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112
   Friedl J.E. F., 1997, MASTERING REGULAR EX
   Fu K.S., 1982, SYNTACTIC PATTERN RE, Vsecond
   Garris M. D., 1997, NIST FORM BASED HAND
   Gorski N., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P523, DOI 10.1109/ICDAR.1999.791840
   GUILLEVIC D, 1998, P INT C PATT REC, V2
   GUPTA A, 1997, Patent No. 5633954
   GUYON I, 1993, ADV PATTERN RECOGNIT
   HAN K, 1997, OFF LINE CURSIVE HAN, P295
   Heutte L, 1997, INT J PATTERN RECOGN, V11, P595, DOI 10.1142/S0218001497000251
   HU F, 1999, SYNTAX VERIFICATION
   Hussein KM, 1999, PATTERN RECOGN, V32, P305, DOI 10.1016/S0031-3203(98)00073-9
   Jee T.-C., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P95, DOI 10.1109/ICDAR.1999.791733
   KAUFMANN G, 1998, P 3 INT ASS PATT REC, P302
   KEELER J, 1992, P SOC PHOTO-OPT INS, V1710, P744, DOI 10.1117/12.140155
   KHAN S, 1998, THESIS MIT
   Kim JH, 2000, INT C PATT RECOG, P319, DOI 10.1109/ICPR.2000.906077
   Kim KK, 2001, PROC INT CONF DOC, P964, DOI 10.1109/ICDAR.2001.953928
   Knerr S, 1997, INT J PATTERN RECOGN, V11, P505, DOI 10.1142/S0218001497000226
   LAM L, 1995, IEEE T PATTERN ANAL, V17, P914, DOI 10.1109/34.406659
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   LETHAGEN S, 1995, HAEMOPHILIA, V1, P97, DOI 10.1111/j.1365-2516.1995.tb00047.x
   Martin G. L., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P831, DOI 10.1142/S021800149300042X
   MARTIN GL, 1993, NEURAL COMPUT, V5, P419, DOI 10.1162/neco.1993.5.3.419
   MATAN O, 1992, COMPUTER, V25, P59, DOI 10.1109/2.144441
   Mitchell B. T., 1989, Machine Vision and Applications, V2, P231, DOI 10.1007/BF01215877
   Nagendraprasad M. V., 1993, Digital Signal Processing, V3, P97, DOI 10.1006/dspr.1993.1014
   Palacios R, 2003, J ELECTRON IMAGING, V12, P194, DOI 10.1117/1.1526105
   PALACIOS R, 2004, INT J IMAGE GRAPH, V4, P203, DOI DOI 10.1142/S0219467804001373
   Prundaru M, 1998, P SOC PHOTO-OPT INS, V3365, P302, DOI 10.1117/12.317524
   PUNNOOSE J, 1999, THESIS MIT
   ROMAN E, 1990, 12490 IFSRC
   SINHA A, 1999, THESIS MIT
   SPARKS PL, 1992, 2 INT C AUT ROB COMP
   SRIHARI S, 1987, FEATURE EXTRACTION L, P261
   SRIHARI SN, 1987, AI MAG, V8, P25
   Suen CY, 1999, PATTERN RECOGN LETT, V20, P1287, DOI 10.1016/S0167-8655(99)00098-7
   UEDA K, 1998, P INT C PATT REC, V1
   WANG PSP, 1989, IEEE T COMPUTERS, V38
   2002, OFFICIAL PAGE QUESTI
NR 51
TC 20
Z9 22
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1297
EP 1313
DI 10.1016/j.imavis.2006.04.012
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700001
DA 2024-07-18
ER

PT J
AU Xu, D
   Li, YF
   Tan, M
AF Xu, De
   Li, You Fu
   Tan, Min
TI A general recursive linear method and unique solution pattern design for
   the perspective-n-point problem
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE perspective-n-point problem; pattern design; three-dimensional sensing;
   pose estimation; visual positioning; recursive least square; solution
   distribution; solution stability
ID POSE
AB In this paper, a new method for solving the perspective-n-point (PnP) problem is developed. With an auxiliary point, the linear method for the special case of four coplanar points is extended to find the coarse solutions for the general P3P problem. A recursive least square algorithm with a forgetting factor is introduced to find all the accurate solutions for the P3P problem. Then the algorithm is extended to the general PnP problem. The solution stability issues are investigated for the P3P, P4P and P5P problem, respectively. Furthermore, a pattern is designed to ensure unique solution for the PnP problem. Experiments are performed to verify the effectiveness of the proposed method. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Xu, De; Li, You Fu] City Univ Hong Kong, Dept Mfg Engn & Engn Management, Kowloon, Hong Kong, Peoples R China.
   [Xu, De; Tan, Min] Chinese Acad Sci, Inst Automat, Key Lab Complex Syst & Intelligence Sci, Beijing 100080, Peoples R China.
C3 City University of Hong Kong; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Li, YF (corresponding author), City Univ Hong Kong, Dept Mfg Engn & Engn Management, 83 Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
EM sdxude@yahoo.com; meyfli@cityu.edu.hk; tan@compsys.ia.ac.cn
RI Tan, Min/GQQ-2702-2022; Liu, Liu/JXM-8208-2024
OI LI, You Fu/0000-0002-5227-1326
CR ABIDI MA, 1995, IEEE T PATTERN ANAL, V17, P534, DOI 10.1109/34.391388
   ALTER TD, 1994, IEEE T PATTERN ANAL, V16, P802, DOI 10.1109/34.308475
   DEMENTHON D, 1992, IEEE T PATTERN ANAL, V14, P1100, DOI 10.1109/34.166625
   Faugeras O. D., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P15
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Gao XS, 2001, J COMPUT SCI TECHNOL, V16, P194, DOI 10.1007/BF02943199
   Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759
   HOLT RJ, 1995, IEEE T PATTERN ANAL, V17, P303, DOI 10.1109/34.368195
   HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2
   Hu ZY, 2002, IEEE T PATTERN ANAL, V24, P550, DOI 10.1109/34.993561
   JUANG JG, 1997, P IEEE INT S IND EL, V3, P1065
   Moriya T, 2000, PROC CVPR IEEE, P766, DOI 10.1109/CVPR.2000.855898
   Nistér D, 2004, PROC CVPR IEEE, P560
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Su C., 1997, P 5 INT C CAD CG, V1, P211
   WOLFE WJ, 1991, IEEE T PATTERN ANAL, V13, P66, DOI 10.1109/34.67632
   YUAN JSC, 1989, IEEE T ROBOTIC AUTOM, V5, P129, DOI 10.1109/70.88034
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 19
TC 38
Z9 48
U1 4
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 740
EP 750
DI 10.1016/j.imavis.2007.08.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900002
DA 2024-07-18
ER

PT J
AU Guironnet, M
   Pellerin, D
   Rombaut, M
AF Guironnet, M.
   Pellerin, D.
   Rombaut, M.
TI A fusion architecture based on TBM for camera motion classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE camera motion classification; transferable belief model; motion
   estimation; motion description; video indexing
ID VIDEO
AB We propose in this paper an original method of camera motion classification based on Transferable Belief Model (TBM). It consists in locating in a video the motions of translation and zoom, and the absence of camera motion (i.e static camera). The classification process is based on a rule-based system that is divided into three stages. From a parametric motion model, the first stage consists in combining data to obtain frame-level belief masses on camera motions. To ensure the temporal coherence of motions, a filtering of belief masses according to TBM is achieved. The second stage carries out a separation between static and dynamic frames. In the third stage, a temporal integration allows the motion to be studied on a set of frames and to preserve only those with significant magnitude and duration. Then, a more detailed description of each motion is given. Experimental results obtained show the effectiveness of the method. (c) 2007 Elsevier B.V. All rights reserved.
C1 GIPSA Lab Ex LIS, F-38031 Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS)
RP Pellerin, D (corresponding author), GIPSA Lab Ex LIS, 46 Ave Felix Viallet, F-38031 Grenoble, France.
EM mickael.guironnet@yahoo.fr; denis.pellerin@lis.inpg.fr;
   michele.rombaut@lis.inpg.fr
OI pellerin, denis/0000-0002-3792-1706
CR Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057
   CHEN C, 2004, P IEEE RSJ INT C INT, V3, P2343
   Cheng WH, 2005, IEICE T INF SYST, VE88D, P1578, DOI 10.1093/ietisy/e88-d.7.1578
   DUAN LY, 2004, P INT C IM PROC ICIP, V3, P1597
   FAUVET B, 2004, C IM VID RETR CIVR, P419
   GILLESPIE WJ, 2004, P C AN DIG TECHN EL, V1, P395
   Kim JG, 2004, ETRI J, V26, P269, DOI 10.4218/etrij.04.0203.0009
   Lazarescu M, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P181
   Lazarescu M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P809, DOI 10.1109/ICME.2002.1035905
   Lee S, 2002, INT CONF ACOUST SPEE, P3664
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   Porter SV, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P460, DOI 10.1109/ICIAP.2003.1234093
   Qi Y, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL II, PROCEEDINGS, P689
   SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4
   Takagi S, 2003, P SOC PHOTO-OPT INS, V5150, P2082, DOI 10.1117/12.502866
   Tan YP, 2000, IEEE T CIRC SYST VID, V10, P133, DOI 10.1109/76.825867
   Zhu XQ, 2005, IEEE T MULTIMEDIA, V7, P648, DOI 10.1109/TMM.2005.850977
NR 17
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1737
EP 1747
DI 10.1016/j.imavis.2007.01.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lin, HD
AF Lin, Hong-Dar
TI Automated visual inspection of ripple defects using wavelet
   characteristic based multivariate statistical approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE detection of ripple defects; machine vision; hotelling T-2 multivariate
   statistics; wavelet characteristics
ID SELECTION; TEXTURES; FEATURES; SYSTEM
AB This paper presents a wavelet characteristic based approach for the automated visual inspection of ripple defects in the surface barrier layer (SBL) chips of ceramic capacitors. Difficulties exist in automatically inspecting ripple defects because of their semi-opaque and unstructured appearances, the gradual changes of their intensity levels, and the low intensity contrast between their surfaces and the rough exterior of a SBL chip. To overcome these difficulties, we first utilize wavelet transform to decompose an image and use wavelet characteristics as texture features to describe surface texture properties. Then, we apply multivariate statistics of Hotelling T-2, Mahalanobis distance D 2, and Chi-square X-2, respectively, to integrate the multiple texture features and judge the existence of defects. Finally, we compare the defect detection performance of the three wavelet-based multivariate statistical models. Experimental results show that the proposed approach (Hotelling T2) achieves a 93.75% probability of accurately detecting the existence of ripple defects and an approximate 90'/o probability of correctly segmenting their regions. (c) 2007 Elsevier B.V. All rights reserved.
C1 Chaoyang Univ Technol, Dept Ind Engn & Management, Taichung 41349, Taiwan.
C3 Chaoyang University of Technology
RP Lin, HD (corresponding author), Chaoyang Univ Technol, Dept Ind Engn & Management, 168 Jifong E Rd,Wufong Township, Taichung 41349, Taiwan.
EM hdlin@cyut.edu.tw
OI Lin, Hong-Dar/0000-0003-1875-8779
CR Abouelela A, 2005, PATTERN RECOGN LETT, V26, P1435, DOI 10.1016/j.patrec.2004.11.016
   Alt F. B., 1985, ENCY STAT SCI, V6, P110
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P3197, DOI 10.1016/j.patrec.2003.08.005
   Bharati MH, 2004, CHEMOMETR INTELL LAB, V72, P57, DOI 10.1016/j.chemolab.2004.02.005
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chetverikov D, 2002, PATTERN RECOGN, V35, P2165, DOI 10.1016/S0031-3203(01)00188-1
   Cui PL, 2006, PATTERN RECOGN LETT, V27, P408, DOI 10.1016/j.patrec.2005.09.001
   DOUGLAS C, 1999, APPL STAT PROBABILIT, P170
   Fadzil MHA, 1998, PATTERN ANAL APPL, V1, P62, DOI 10.1007/BF01238027
   Fang T, 2003, MACH VISION APPL, V15, P63, DOI [10.1007/s00138-002-0074-1, 10.1007/s00138-003-0074-1]
   Garcia C, 2000, IMAGE VISION COMPUT, V18, P289, DOI 10.1016/S0262-8856(99)00056-6
   HAIR JF, 1998, MULTIVAR DATA ANAL, P223
   Hotelling H., 1947, TECHNIQUES STAT ANAL, P111
   Huang K, 2006, SIGNAL PROCESS, V86, P1410, DOI 10.1016/j.sigpro.2005.07.032
   JOLAYEMI JK, 1995, COMPUT STAT DATA AN, V20, P633, DOI 10.1016/0167-9473(94)00063-0
   Kubota T, 2005, MACH VISION APPL, V16, P170, DOI 10.1007/s00138-004-0169-y
   Kumar A, 2003, PATTERN RECOGN, V36, P1645, DOI 10.1016/S0031-3203(03)00005-0
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   Latif-Amet A., 2002, COMPUT GEOSCI, V28, P763
   LOWRY CA, 1995, IIE TRANS, V27, P800, DOI 10.1080/07408179508936797
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Martin E. B., 1999, Annual Reviews in Control, V23, P35, DOI 10.1016/S1367-5788(99)90055-X
   Mason RL, 1999, J QUAL TECHNOL, V31, P155
   Mason RL, 2001, J QUAL TECHNOL, V33, P466
   Montgomery D.C., 2005, INTRO STAT QUALITY C, P486
   Ngan HYT, 2005, PATTERN RECOGN, V38, P559, DOI 10.1016/j.patcog.2004.07.009
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pikaz A, 1997, GRAPH MODEL IM PROC, V59, P1, DOI 10.1006/gmip.1996.0410
   Ramana KV, 1996, PATTERN RECOGN, V29, P1447, DOI 10.1016/0031-3203(96)00008-8
   RAMESH J, 2005, MACHINE VISION INT, P76
   RYAN TP, 2000, MULTIVARIATE CONTROL, P253
   Shirazi MN, 2000, IMAGE VISION COMPUT, V18, P967, DOI 10.1016/S0262-8856(00)00039-1
   SIEW LH, 1988, IEEE T PATTERN ANAL, V10, P92, DOI 10.1109/34.3870
   Song KY, 1996, IMAGE VISION COMPUT, V14, P667, DOI 10.1016/0262-8856(96)84491-X
   Suen PH, 1999, PATTERN RECOGN, V32, P1009, DOI 10.1016/S0031-3203(98)00130-7
   Tico M, 2001, ELECTRON LETT, V37, P21, DOI 10.1049/el:20010031
   Tsai DM, 2000, INT J ADV MANUF TECH, V16, P474, DOI 10.1007/s001700070055
   Tsai DM, 2003, IMAGE VISION COMPUT, V21, P413, DOI 10.1016/S0262-8856(03)00003-9
   Tsai DM, 2001, PATTERN RECOGN, V34, P1285, DOI 10.1016/S0031-3203(00)00071-6
   Tsai DM, 2001, IMAGE VISION COMPUT, V19, P299, DOI 10.1016/S0262-8856(00)00078-0
   Van de Wouwer G, 1999, PATTERN RECOGN, V32, P443, DOI 10.1016/S0031-3203(98)00035-1
   WALPOLE RE, 1998, PROBABILITY STAT ENG, P108
   Wikstrom C, 1998, CHEMOMETR INTELL LAB, V42, P233, DOI 10.1016/S0169-7439(98)00015-X
   Wikstrom C, 1998, CHEMOMETR INTELL LAB, V42, P221, DOI 10.1016/S0169-7439(98)00014-8
   Ye N, 2002, IEEE T COMPUT, V51, P810, DOI 10.1109/TC.2002.1017701
NR 45
TC 44
Z9 53
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1785
EP 1801
DI 10.1016/j.imavis.2007.02.002
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900008
DA 2024-07-18
ER

PT J
AU Li, F
   Klette, R
AF Li, Fqjie
   Klette, Reinhard
TI Analysis of the rubberband algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE digital geometry; shortest Euclidean path; cube-curves; minimum-length
   polygonal curve
ID LENGTH ESTIMATION
AB We consider simple cube-curves in the orthogonal 3D grid of cells. The union of all cells contained in such a curve (also called the tube of this curve) is a polyhedrally bounded set. The curve's length is defined to be that of the minimum-length polygonal curve (MLP) contained and complete in the tube of the curve. Only one general algorithm, called rubberband algorithm, was known for the approximative calculation of such an MLP so far.
   An open problem in [R. Klette and A. Rosenfeld. Digital Geometry: Geometric Methods for Digital Picture Analysis. Morgan Kaufmann, San Francisco, 2004.] is related to the design of algorithms for the calculation of the MLP of a simple cube-curve: Is there a simple cube-curve such that none of the nodes of its MLP is a grid vertex? This paper constructs an example of such a simple cube-curve, and we also characterize the class of all of such cube-curves. This study leads to a correction in Option 3 of the rubberband algorithm (by adding one missing test).
   We also prove that the rubberband algorithm has linear time complexity (9(m) where m is the number of critical edges of a given simple cube-curve, which solves another open problem in the context of this algorithm. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Auckland, Dept Comp Sci, Auckland 1, New Zealand.
   Univ Auckland, CITR, Auckland 1, New Zealand.
C3 University of Auckland; University of Auckland
RP Klette, R (corresponding author), Univ Auckland, Dept Comp Sci, Auckland 1, New Zealand.
EM r.klette@auckland.ac.nz
RI Klette, Reinhard/B-7018-2012
OI Klette, Reinhard/0000-0001-8818-7145
CR Bülow T, 2002, IEEE T PATTERN ANAL, V24, P962, DOI 10.1109/TPAMI.2002.1017622
   Canny J., 1987, P 28 ANN IEEE S FDN, P49
   Choi Joonsoo., 1994, Proceedings of the 10th annual symposium on Computational geometry (SoCG), P41
   Ficarra E, 2005, IEEE T INF TECHNOL B, V9, P508, DOI 10.1109/TITB.2005.855546
   Jonas A, 1998, J MATH IMAGING VIS, V8, P215, DOI 10.1023/A:1008218517090
   Klette R, 2000, LECT NOTES COMPUT SC, V1953, P467
   Klette R., 2004, DIGITAL GEOMETRY GEO
   Li FJ, 2004, LECT NOTES COMPUT SC, V3322, P502
   MELKMAN AA, 1987, INFORM PROCESS LETT, V25, P11, DOI 10.1016/0020-0190(87)90086-X
   Sloboda F, 1998, P SOC PHOTO-OPT INS, V3454, P52, DOI 10.1117/12.323274
   Sloboda F., 1998, Advances in Digital and Computational Geometry, P113
   SUNDAY D, ALGORITHM 15 CONVEX
   Wolber Rainer, 2004, J Dtsch Dermatol Ges, V2, P580, DOI 10.1046/j.1439-0353.2004.04052.x
NR 13
TC 10
Z9 10
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1588
EP 1598
DI 10.1016/j.imavis.2006.06.021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200007
DA 2024-07-18
ER

PT J
AU Coleman, SA
   Scotney, BW
   Herron, MG
AF Coleman, S. A.
   Scotney, B. W.
   Herron, M. G.
TI A validated edge model technique for the empirical performance
   evaluation of discrete zero-crossing methods
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE performance evaluation; edge sensitivity analysis; zero-crossings
AB A new evaluation technique is presented to enable edge sensitivity analysis with respect to angular orientation and displacement errors for edges located by discrete zero-crossing operators. The technique is validated by using a Gaussian edge model and is shown to provide an effective mechanism for characterising the quality of second derivative feature detection operators in terms of quantitative measures of' correctness of edge location and orientation. The technique applies a finite element interpolation to the output values of the discrete operator in order to extract sub-pixel level information about zero-crossings; in general, the displacement and orientation of a local line segment along which the line integral of the output interpolant is zero may then be readily found as the solution of a pair of simultaneous algebraic equations. A significant advantage over earlier edge sensitivity techniques is that the method does not require the use of a supplementary first derivative operator for gradient approximation. The method can therefore be used to make direct comparisons between zero-crossing operators in terms of basic performance standards without reference to particular test images; such standards are also important as they form the necessary basis for investigating the potential for the use of proxies for operator performance in relation to subsequent higher-level image processing tasks. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Ulster, Sch Comp & Intelligent Syst, Magee Coll, Londonderry BT48 7JL, North Ireland.
   Univ Ulster, Sch Comp & Informat Engn, Coleraine BT52 1SA, Londonderry, North Ireland.
   Univ Ulster, Sch Comp & Math, Jordanstown, North Ireland.
C3 Ulster University; Ulster University; Ulster University
RP Coleman, SA (corresponding author), Univ Ulster, Sch Comp & Intelligent Syst, Magee Coll, Londonderry BT48 7JL, North Ireland.
EM sa.coleman@ulster.ac.uk
OI Coleman, Sonya/0000-0002-4676-7640
CR ABDOU IE, 1979, P IEEE, V67, P753, DOI 10.1109/PROC.1979.11325
   BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   Cheng H, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P930
   COLEMAN SA, 2000, P 4 IR MACH VIS IM P, P211
   COLEMAN SA, 2001, P 5 IMVIP C, P211
   Forbes LA, 2000, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2000.854859
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   Karantzalos K. G., 2002, 2002 14th International Conference on Digital Signal Processing Proceedings. DSP 2002 (Cat. No.02TH8628), P897, DOI 10.1109/ICDSP.2002.1028235
   Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417
   KITCHEN L, 1981, IEEE T SYST MAN CYB, V11, P597, DOI 10.1109/TSMC.1981.4308758
   KITCHEN LJ, 1989, COMPUT VISION GRAPH, V47, P243, DOI 10.1016/S0734-189X(89)80009-X
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Mikolajczyk Krystian., 2003, BRIT MACHINE VISION, V2, P779
   Morii F., 2004, Proceedings. Third International Conference on Image and Graphics, P80
   Pratt W. K., DIGITAL IMAGE PROCES
   Rockett PI, 2003, IEEE T IMAGE PROCESS, V12, P1668, DOI 10.1109/TIP.2003.818041
   Scotney BW, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P844, DOI 10.1109/ICIP.2001.958252
   SCOTNEY BW, LNCS
   Shin MC, 2001, COMPUT VIS IMAGE UND, V84, P160, DOI 10.1006/cviu.2001.0932
   SPREEUWERS LJ, 1992, P INT C PATT REC, V3, P771
   VENKATESH S, 1995, GRAPH MODEL IM PROC, V57, P146, DOI 10.1006/gmip.1995.1015
NR 23
TC 1
Z9 2
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1315
EP 1328
DI 10.1016/j.imavis.2006.08.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000012
DA 2024-07-18
ER

PT J
AU Beucher, S
AF Beucher, Serge
TI Numerical residues
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE image analysis; mathematical morphology; residues; ultimate opening;
   quasi-distance; image segmentation; hierarchy
AB Binary morphological transformations based on the residues (ultimate erosion, skeleton by openings, etc.) and their associated functions which are based on the analysis of the residue evolution in every point of the image are extended to functions. In this approach, the associated function indicates the value of the residue index for which the evolution is the most important. The approach also has the advantage of supplying effective tools for shape analysis and of allowing the definition of new residual transforms together with their associated functions. Two of these numerical residues will be introduced, called, respectively, ultimate opening and quasi-distance and, through some applications, the interest and efficiency of these operators will be illustrated. Finally, this residual approach will be extended to more complex operators. (c) 2006 Elsevier B.V. All rights reserved.
C1 Ecole Mines Paris, Ctr Morphol Mathemat, F-77305 Fontainebleau, France.
C3 Universite PSL; MINES ParisTech
RP Beucher, S (corresponding author), Ecole Mines Paris, Ctr Morphol Mathemat, 35 Rue St Honore, F-77305 Fontainebleau, France.
EM Serge.Beucher@ensmp.fr
CR BEUCHER S, 1990, JOURN ANRT DEC 1988
   BEUCHER S, 1990, THESIS PARIS SCH MIN
   BEUCHER S, 1979, P 5 INT C STER SALZB, P138
   BEUCHER S, 1960, J VIS COMMUN IMAGE R, V1
   BEUCHER S, 1994, P MATH MORPH ITS APP, P69
   KRESCH R, 1994, SIGNAL PROCESS, V38, P143, DOI 10.1016/0165-1684(94)90062-0
   LANTUEJOUL C, 1981, J MICROSC-OXFORD, V121, P39, DOI 10.1111/j.1365-2818.1981.tb01197.x
   MARAGOS PA, 1986, IEEE T ACOUST SPEECH, V34, P1228, DOI 10.1109/TASSP.1986.1164959
   Meyer F., 1992, MATH MORPHOLOGY IMAG
   Sapiro G., 1994, Journal of Visual Communication and Image Representation, V5, P29, DOI 10.1006/jvci.1994.1003
NR 10
TC 39
Z9 40
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 405
EP 415
DI 10.1016/j.imavis.2006.07.020
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600003
DA 2024-07-18
ER

PT J
AU Talbot, H
   Appleton, B
AF Talbot, Hugues
   Appleton, Ben
TI Efficient complete and incomplete path openings and closings
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE algebraic morphological operators; attributes; complexity
AB Path openings and closings are algebraic morphological operators using families of thin and oriented structuring elements that are not necessarily perfectly straight. These operators can typically be used in filtering applications in lieu of operators based on the more standard families of straight line structuring elements. They yield results which are less constrained than filters based on straight line segments, yet more constrained than connected area or other attribute-based operators. Furthermore, path operators can be parametrised to behave more like either extreme.
   Natural implementations of this idea using actual suprema or infima of morphological operators with paths as structuring elements would imply exponential complexity. Fortunately, a linear complexity algorithm exists in the literature. This algorithm has similar running times as the best known implementation of morphological operators using straight lines as structuring elements.
   However, even this implementation is sometimes not fast enough, leading practitioners to favour some attribute-based operators instead, which in some applications is not the best solution.
   In this paper, we propose an implementation of path-based morphological operators that is shown experimentally to exhibit a logarithmic complexity and comparable computing times with those of attribute-based operators. This implementation has the added benefit of allowing the computation of the related opening transform at no extra computational cost.
   In order to give additional flexibility and noise-robustness to these operators, we also investigate the case when some pixels are left ignored from the path (i.e. "jumps" are allowed) and form incomplete paths. (c) 2006 Elsevier B.V. All rights reserved.
C1 ESIEE, IGM, A2SI, F-93162 Noisy Le Grand, France.
   Google Inc, Mountain View, CA USA.
C3 Universite Gustave-Eiffel; ESIEE Paris; Google Incorporated
RP Talbot, H (corresponding author), ESIEE, IGM, A2SI, 2 Bd Blaise Pascal, F-93162 Noisy Le Grand, France.
EM h.talbot@esiee.fr; ben.appleton@gmail.com
OI Talbot, Hugues/0000-0002-2179-3498
CR [Anonymous], 1973, The art of computer programming
   Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066
   Breen EJ, 1994, COMP IMAG VIS, V2, P249
   Buckley M, 2000, COMP IMAG VIS, V18, P109
   Heijmans H, 2005, J MATH IMAGING VIS, V22, P107, DOI 10.1007/s10851-005-4885-3
   HEIJMANS H, 2004, P ICIP 04 OCT 2004 S
   HEIJMANS HJA, 1996, P ISMM 96, P127
   JAUMIER F, 1988, THESIS ENPC
   KURDY MB, 1989, ACTA STEREOL, V8, P473
   LAY B, 1987, ACTA STEREOL, V6, P691
   Lee T, 1997, COMPUT BIOL MED, V27, P533, DOI 10.1016/S0010-4825(97)00020-6
   LUENGOHENDRIKS CL, 2001, 4 INT WORKSH VIS FOR, P378
   Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556
   Ronse C., 1988, WD47 PHIL RES LAB
   SKLADNEV VN, 2001, 02094098 WO
   Soille P, 2001, IEEE T PATTERN ANAL, V23, P1313, DOI 10.1109/34.969120
   Soille P, 1996, IEEE T PATTERN ANAL, V18, P562, DOI 10.1109/34.494646
   Talbot H, 2000, J MICROSC-OXFORD, V200, P251, DOI 10.1046/j.1365-2818.2000.00752.x
   VANANTWERPEN G, 1986, SIGNAL PROCESS, V3, P891
   Vincent L, 1996, COMP IMAG VIS, P273
   Vincent L., 1993, PROC EURASIP WORKSHO, P22
   Vogt RC, 1994, COMP IMAG VIS, V2, P45
   [No title captured]
NR 23
TC 58
Z9 65
U1 0
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 416
EP 425
DI 10.1016/j.imavis.2006.07.021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600004
DA 2024-07-18
ER

PT J
AU Pece, AEC
   Worrall, AD
AF Pece, Arthur E. C.
   Worrall, Anthony D.
TI A comparison between feature-based and EM-based contour tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Performance Evaluation of Tracking and Surveillance (PETS)
CY DEC09, 2001
CL Kauai, HI
SP IEEE
DE generative model; active contour; EM algorithm; Kalman filter; empirical
   information matrix
ID ALGORITHM; MODELS
AB Most active-contour methods are based either on maximizing the image contrast under the contour or on minimizing the sum of squared distances between contour and image 'features'. The Marginalized Likelihood Ratio (MLR) contour model uses a contrast-based measure of goodness-of-fit for the contour and thus falls into the first class. The point of departure from previous models consists in marginalizing this contrast measure over unmodelled shape variations.
   The MLR model naturally leads to the EM Contour algorithm, in which pose optimization is carried out by iterated least-squares, as in feature-based contour methods. The difference with respect to other feature-based algorithms is that the EM Contour algorithm minimizes squared distances from Bayes least-squares (marginalized) estimates of contour locations, rather than from 'strongest features' in the neighborhood of the contour. Within the framework of the MLR model, alternatives to the EM algorithm can also be derived: one of these alternatives is the empirical-information method.
   Tracking experiments demonstrate the robustness of pose estimates given by the MLR model, and support the theoretical expectation that the EM Contour algorithm is more robust than either feature-based methods or the empirical-information method. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen, Denmark.
   Heimdall Vision, DK-2500 Valby, Denmark.
   Univ Reading, Sch Syst Engn, Reading RG6 6AY, Berks, England.
C3 University of Copenhagen; University of Reading
RP Pece, AEC (corresponding author), Univ Copenhagen, Dept Comp Sci, Univ Pk 1, DK-2100 Copenhagen, Denmark.
EM aecp@heimdall-vision.com
CR [Anonymous], 1992, ACTIVE VISION
   [Anonymous], COMPUTER GRAPHICS
   [Anonymous], 1996, Numerical Methods for Unconstrained Optimization and Nonlinear Equations
   Bar-Shalom Y., 1988, TRACKING DATA ASS
   BAUMBERG A, 1994, LNCS, P299, DOI DOI 10.1007/3-540-57956-7_34
   Blake A., 1998, ACTIVE CONTOURS
   Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842
   Dahlkamp H, 2004, LECT NOTES COMPUT SC, V3175, P71
   DAHLKAMP H, 2004, P WORKSH SPAT COH VI
   Ferryman J., 2001, P 2 IEEE INT WORKSH
   Ferryman JM, 1997, ROBOT AUTON SYST, V19, P315, DOI 10.1016/S0921-8890(97)83348-9
   FERRYMAN JM, 2000, P 1 IEEE INT WORKSH
   Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006
   Hanek R, 2004, INT J COMPUT VISION, V59, P233, DOI 10.1023/B:VISI.0000025799.44214.29
   Hansen DW, 2005, COMPUT VIS IMAGE UND, V98, P155, DOI 10.1016/j.cviu.2004.07.013
   HANSEN DW, 2004, P INT C COMP VIS PAT, V2, P159
   HANSEN DW, 2003, P WORKSH AN MOD FAC
   HUANG J, 1999, P IEEE C COMP VIS PA, V1, P541
   JORGENSEN B, 1984, INT STAT REV, V52, P283, DOI 10.2307/1403047
   KAAS M, 1987, P 1 ICCV, P259
   Kollnig H, 1997, INT J COMPUT VISION, V23, P283, DOI 10.1023/A:1007927317325
   LEUCK H, 1999, P IEEE COMP SOC C CO, V2, P360
   MacCormick J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P390, DOI 10.1109/ICCV.1998.710748
   McLachlan G. J., 1997, The EM Algorithm and Extensions, V473, P486
   MEILIJSON I, 1989, J ROY STAT SOC B MET, V51, P127
   Oksendal B, 1995, Stochastic Differential Equations. An Introduction with Applications, VFourth
   Pece A, 1998, IMAGE VISION COMPUT, V16, P541, DOI 10.1016/S0262-8856(98)00098-5
   Pece AEC, 2002, ROBOT AUTON SYST, V39, P181, DOI 10.1016/S0921-8890(02)00203-8
   PECE AEC, IN PRESS IMAGE VISIO
   PECE AEC, 2003, P 3 WORKSH STAT COMP
   Pece AV, 2002, LECT NOTES COMPUT SC, V2350, P3
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Sidenbladh H, 2003, INT J COMPUT VISION, V54, P181, DOI 10.1023/A:1023765619733
   STEPHENS RS, 1989, P ALV VIS C, P85
   SULLIVAN GD, 1992, PHILOS T ROY SOC B, V337, P361, DOI 10.1098/rstb.1992.0114
   Worrall AD, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P137
   Yuille AL, 2000, IEEE T PATTERN ANAL, V22, P160, DOI 10.1109/34.825754
NR 38
TC 4
Z9 4
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2006
VL 24
IS 11
BP 1218
EP 1232
DI 10.1016/j.imavis.2005.06.013
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 101CJ
UT WOS:000241716200007
DA 2024-07-18
ER

PT J
AU Papakostas, GA
   Boutalis, YS
   Papaodysseus, CN
   Fragoulis, DK
AF Papakostas, G. A.
   Boutalis, Y. S.
   Papaodysseus, C. N.
   Fragoulis, D. K.
TI Numerical error analysis in Zernike moments computation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Zernike moments; recursive computation; finite precision error;
   numerical stability; image vision; feature extraction
ID FINITE PRECISION ERROR; GENERAL METHODOLOGY; RECOGNITION; ALGORITHM;
   ROBUST
AB An exact analysis of the numerical errors being generated during the computation of the Zemike moments, by using the well-known 'q-recursive' method, is attempted in this paper. Overflow is one kind of error, which may occur when one needs to calculate the Zemike moments up to a high order. Moreover, by applying a novel methodology it is shown that there are specific formulas, which generate and propagate 'finite precision error'. This finite precision error is accumulated during execution of the algorithm, and it finally 'destroys' the algorithm, in the sense that eventually makes its results totally unreliable.
   The knowledge of the exact computation errors and the way that they are generated and propagated is a fundamental step for developing more robust error-free recursive algorithms, for the computation of Zemike moments. (c) 2006 Elsevier B.V. All rights reserved.
C1 Democritus Univ Thrace, Dept Elect & Comp Engn, GR-67100 Xanthi, Greece.
   Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-15773 Athens, Greece.
C3 Democritus University of Thrace; National Technical University of Athens
RP Papakostas, GA (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Vas Sofias 12, GR-67100 Xanthi, Greece.
EM gpapakos@ee.duth.gr; ybout@ee.duth.gr; cpapaod@cs.ntua.g;
   dfrag@mail.ntua.gr
RI Papakostas, George A./F-1038-2017; Papaodysseus,
   Constantin/JCD-9028-2023; Papaodysseus, Constantin/AAI-6900-2020
OI Papakostas, George A./0000-0001-5545-1499; Papaodysseus,
   Constantin/0000-0002-5238-5833; 
CR [Anonymous], 2005, ICGST International Journal on Graphics, Vision and Image Processing
   Belkasim SO, 1996, J FRANKLIN I, V333B, P577, DOI 10.1016/0016-0032(96)00017-8
   Boutalis Y, 2000, J ALGORITHMS, V37, P283, DOI 10.1006/jagm.2000.1113
   Chong CW, 2003, PATTERN RECOGN, V36, P731, DOI 10.1016/S0031-3203(02)00091-2
   CHONG CW, 2004, INFORM SCI, V159, P203
   Gu J, 2002, PATTERN RECOGN, V35, P2905, DOI 10.1016/S0031-3203(01)00194-7
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   LIN TW, 2003, P 16 IPPR C COMP VIS, P621
   MUKUNDAN R, 1995, PATTERN RECOGN, V28, P1433, DOI 10.1016/0031-3203(95)00011-N
   Mukundan R, 2004, IEEE T IMAGE PROCESS, V13, P1055, DOI 10.1109/TIP.2004.828430
   Mukundan R, 2001, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS I AND II, P23
   MUKUNDAN R, 1997, P NAT C RES DEV COMP, P188
   Papakostas G.A., 2003, 10 INT WORKSH SYST S
   Papakostas GA, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P517, DOI 10.1109/ICDSP.2002.1028141
   Papaodysseus C, 1997, MATH COMPUT SIMULAT, V44, P29, DOI 10.1016/S0378-4754(97)00004-9
   PAPAODYSSEUS C, 1994, IEEE T SIGNAL PROCES, V42, P1097, DOI 10.1109/78.295208
   Papaodysseus C, 2003, STOCH ENV RES RISK A, V17, P1, DOI 10.1007/S00477-002-0116-2
   PAPAODYSSEUS CN, 1993, IEEE T SIGNAL PROCES, V41
   Sim DG, 2004, IMAGE VISION COMPUT, V22, P331, DOI 10.1016/j.imavis.2003.11.003
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Zernike F, 1934, PHYSICA, V1, P689
   Zhenjiang M., 2000, Pattern Recognition Letters, V21, P169
NR 26
TC 31
Z9 36
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 960
EP 969
DI 10.1016/j.imavis.2006.02.015
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200005
DA 2024-07-18
ER

PT J
AU Rodriguez, Y
   Cardinaux, F
   Bengio, S
   Mariéthoz, J
AF Rodriguez, Yann
   Cardinaux, Fabien
   Bengio, Sarny
   Mariethoz, Johnny
TI Measuring the performance of face localization systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face detection and localization; face verification; BANCA and XM2VTS
   databases
ID AUTHENTICATION
AB The purpose of face localization is to determine the coordinates of a face in a given image. It is a fundamental research area in computer vision because it serves, as a necessary first step in any face processing system, such as automatic face recognition, face tracking or expression analysis. Most of these techniques assume, in general, that the face region has been perfectly localized. Therefore, their performances depend widely on the accuracy of the face localization process. The purpose of this paper is to mainly show that the error made during the localization process may have different impacts on the final application. We first show the influence of localization errors on the face verification task and then empirically demonstrate the problems of current localization performance measures when applied to this task. In order to properly evaluate the performance of a face localization algorithm, we then propose to embed the final application (here face verification) into the performance measuring process. Using two benchmark databases, BANCA and XM2VTS, we proceed by showing empirically that our proposed method to evaluate localization algorithms better matches the final verification performance. (c) 2006 Elsevier B.V. All rights reserved.
C1 IDIAP Res Inst, CH-1920 Martigny, Switzerland.
RP Rodriguez, Y (corresponding author), IDIAP Res Inst, Rue Simplon 4,Case Postale 592, CH-1920 Martigny, Switzerland.
EM rodrig@idiap.ch
CR Bailly-Bailliére E, 2003, LECT NOTES COMPUT SC, V2688, P625
   BEHNKE S, 2003, P 7 INT C KNOWL BAS, P139
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Cardinaux F, 2006, IEEE T SIGNAL PROCES, V54, P361, DOI 10.1109/TSP.2005.861075
   Cardinaux F, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P825, DOI 10.1109/AFGR.2004.1301636
   Cardinaux F, 2003, LECT NOTES COMPUT SC, V2688, P911
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   COLLOBERT R, 2002, 0246 IDIAP RES I
   Comaniciu D, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P11, DOI 10.1109/VS.2000.856853
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Fröba B, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P342, DOI 10.1109/AFGR.2002.1004177
   Fröba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514
   Hamouz M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P67, DOI 10.1109/AFGR.2004.1301510
   Huang KS, 2004, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2004.1334689
   HUANG RJ, 1998, THESIS G MASON U FAI
   JESORSKY O, 2001, P 3 INT C AUD VID BA, P90
   Li S. Z., 2004, HDB FACE RECOGNITION
   Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297
   LUTTIN J, 1998, 9805 IDIAP RES I
   Medioni G., 2004, EMERGING TOPICS COMP
   Popovici V, 2004, INT C PATT RECOG, P313, DOI 10.1109/ICPR.2004.1334115
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Rodriguez Y, 2004, IEEE IMAGE PROC, P581
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   SADEGHI M, 2003, P AUD VID BAS BIOM P, P35
   Sanderson C, 2004, PROCEEDINGS OF THE 2004 INTELLIGENT SENSORS, SENSOR NETWORKS & INFORMATION PROCESSING CONFERENCE, P581
   Sanderson C, 2004, DIGIT SIGNAL PROCESS, V14, P449, DOI 10.1016/j.dsp.2004.05.001
   Sanderson C, 2003, PATTERN RECOGN LETT, V24, P2409, DOI 10.1016/S0167-8655(03)00070-9
   SPORS S, 2001, P IEEE INT C AC SPEE
   TEK F, 2002, THESIS MIDDLE E TU A
   Tsalakanidou F, 2005, IEEE T IMAGE PROCESS, V14, P152, DOI 10.1109/TIP.2004.840714
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vapnik Vladimir., 1998, Lecture Notes in Economics and Mathematical Systems, V454
   VEZHNEVETS V, 2002, P ICDIPCES, P51
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   YOW KC, 1998, THESIS U CAMBRIDGE
NR 37
TC 28
Z9 32
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 882
EP 893
DI 10.1016/j.imavis.2006.02.012
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shih, FY
   Klotz, T
   Brockmann, W
AF Shih, Frank Y.
   Klotz, Tobias
   Brockmann, Werner
TI A system for rotational velocity computation from image sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE optical flow; velocity computation; comer detection; mathematical
   morphology
ID MOTION; MORPHOLOGY
AB This paper presents a system for the computation of rotational velocity from image sequences. Most existing algorithms for rotation computation are shown to work only on synthetic data. The problems arisen from real image data are discussed and solved in our proposed system. Currently, we are capable of computing two rotational parameters of a moving observer given the translational velocity in real-time from a live image sequence. (c) 2006 Elsevier B.V. All rights reserved.
C1 New Jersey Inst Technol, Comp Vis Lab, Dept Comp Sci, Coll Comp Sci, Newark, NJ 07102 USA.
   Med Univ Lubeck, Dept Comp Engn, D-23538 Lubeck, Germany.
C3 New Jersey Institute of Technology; University of Lubeck
RP Shih, FY (corresponding author), New Jersey Inst Technol, Comp Vis Lab, Dept Comp Sci, Coll Comp Sci, Univ Hts, Newark, NJ 07102 USA.
EM shih@njit.edu
RI Wang, Xiaojing/HNI-4384-2023
OI Wang, Xiaojing/0000-0001-6921-3619
CR BARRON J, 1994, INT J COMPUTER VISIO, V12
   FERMULLER C, 1995, SCIENCE, V270, P1973, DOI 10.1126/science.270.5244.1973
   Heeger D. J., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P96, DOI 10.1109/ICCV.1990.139502
   HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130
   HORN BKP, 1980, 572 AI MIT
   HUMMEL R, 1993, IEEE T PATTERN ANAL, V15, P459, DOI 10.1109/34.211466
   Irani M, 1997, IEEE T PATTERN ANAL, V19, P268, DOI 10.1109/34.584105
   Jepson A., 1992, RBCVTR9240 U TOR DEP
   Jepson A. D., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P124, DOI 10.1109/WVM.1991.212779
   Laganiere R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P280, DOI 10.1109/ICCV.1998.710731
   Lappe M, 1999, TRENDS COGN SCI, V3, P329, DOI 10.1016/S1364-6613(99)01364-9
   Shih FYC, 1992, IEEE T IMAGE PROCESS, V1, P197, DOI 10.1109/83.136596
   SHIH FYC, 1989, IEEE T PATTERN ANAL, V11, P31, DOI 10.1109/34.23111
   Silva C, 1997, IEEE T PATTERN ANAL, V19, P1026, DOI 10.1109/34.615451
   SILVA C, 1996, P 13 INT C PATT REC, V1, P702
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
NR 16
TC 0
Z9 0
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2006
VL 24
IS 4
BP 357
EP 362
DI 10.1016/j.imavis.2005.12.002
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 049US
UT WOS:000238043500004
DA 2024-07-18
ER

PT J
AU Mahmoodi, S
   Sharif, BS
AF Mahmoodi, S
   Sharif, BS
TI Nonlinear optimisation method for image segmentation and noise reduction
   using geometrical intrinsic properties
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE optimisation; edge detection; noise reduction; partial differential
   equations; differential geometry
ID ACTIVE CONTOURS; MUMFORD; EDGES
AB This paper considers the optimisation of a nonlinear functional for image segmentation and noise reduction. Equations optimising this functional are derived and employed to detect edges using geometrical intrinsic properties such as metric and Riemann curvature tensor of a smooth differentiable surface approximating the original image. Images are then smoothed using a Helmholtz type partial differential equation. The proposed approach is shown to be very efficient and robust ill the presence of noise, and the reported results demonstrate better performance than the conventional derivative based edge detectors. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Newcastle, Sch Biol, Dept Psychol, Newcastle Upon Tyne NE2 4HH, Tyne & Wear, England.
   Univ Newcastle, Sch Elect Elect & Comp Engn, Newcastle Upon Tyne NE1 7RU, Tyne & Wear, England.
C3 Newcastle University - UK; Newcastle University - UK
RP Univ Newcastle, Sch Biol, Dept Psychol, Henry Wellcome Bldg, Newcastle Upon Tyne NE2 4HH, Tyne & Wear, England.
EM sasan.mahmoodi@ncl.ac.uk
OI Sharif, Bayan/0000-0002-8679-4272
CR [Anonymous], 1996, Level Set Methods: Evolving Interfaces in Computational Geometry, Fluid Mechanics, Computer Vision, and Materials Science
   [Anonymous], 1995, Variational Methods in Image Segmentation
   Aubert G., 2002, MATH PROBLEMS IMAGE
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carmo Do., 1976, DIFFERENTIAL GEOMETR
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P161, DOI 10.1109/VLSM.2001.938895
   Gelfand IM., 1963, Calculus of Variations
   Hinterberger W, 2003, J MATH IMAGING VIS, V19, P219, DOI 10.1023/A:1026276804745
   Hintermüller M, 2004, J MATH IMAGING VIS, V20, P19, DOI 10.1023/B:JMIV.0000011317.13643.3a
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KAY DC, 1988, SCHAUMS OUTLINE SERI
   Kreyszig E., 2006, ADV ENG MATH
   Lipschutz M., 1969, THEORY PROBLEMS DIFF
   Mahmoodi S, 2005, SIGNAL PROCESS, V85, P1845, DOI 10.1016/j.sigpro.2005.03.016
   MAHMOODI S, IN PRESS IEE P VIS I
   MANDERSCHEID UB, 1991, INTRO CALCULUS VARIA
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vese L, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P175, DOI 10.1007/0-387-21810-6_10
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
NR 26
TC 6
Z9 6
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 202
EP 209
DI 10.1016/j.imavis.2005.11.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900010
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Lindblad, J
AF Lindblad, J
TI Surface area estimation of digitized 3D objects using weighted local
   configurations
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE surface area estimation; marching cubes; digital planes
ID PERIMETER; REPRESENTATION
AB We present a method for estimating surface area of three-dimensional objects in discrete binary images. A surface area weight is assigned to each 2 x 2 x 2 configuration of voxels. The total surface area of a digital object is given by a summation of the local area contributions. Optimal area weights are derived in order to provide an unbiased estimate with minimum variance for randomly oriented digitized planar surfaces. Due to co-appearance of certain voxel combinations, the optimal solution is not uniquely defined for planar surfaces. A Monte Carlo-based optimization of the estimator performance on the distribution of digitized balls of increasing radii is performed in order to uniquely determine the optimal surface area weights. The method is further evaluated on various objects in a range of sizes. A significant reduction of the error for small objects is observed. The algorithm is appealingly simple; the use of only a small local neighborhood enables efficient implementations in hardware and/or in parallel architectures. (C) 2004 Elsevier B.V. All rights reserved.
C1 Uppsala Univ, Ctr Image Anal, SE-75237 Uppsala, Sweden.
C3 Uppsala University
RP Uppsala Univ, Ctr Image Anal, Lagerhyddsv 3, SE-75237 Uppsala, Sweden.
EM joakim@cb.uu.se
RI Lindblad, Joakim/F-1960-2016
OI Lindblad, Joakim/0000-0001-7312-8222
CR Coeurjolly D, 2003, LECT NOTES COMPUT SC, V2616, P101
   Coeurjolly D, 2002, INT C PATT RECOG, P330, DOI 10.1109/ICPR.2002.1047463
   DORST L, 1987, COMPUT VISION GRAPH, V40, P311, DOI 10.1016/S0734-189X(87)80145-7
   Freeman H., 1970, PICTURE P PSYCHOPICT, P241
   GORDON D, 1989, COMPUT VISION GRAPH, V45, P196, DOI 10.1016/0734-189X(89)90132-1
   Kenmochi Y, 2000, PROC SPIE, V4117, P100, DOI 10.1117/12.404839
   KLETTE R, 2001, LECT NOTES COMPUT SC, V2059, P356
   KLETTE R, 2001, LNCS, V2243, P314
   KOPLOWITZ J, 1989, IEEE T PATTERN ANAL, V11, P611, DOI 10.1109/34.24795
   Kulpa Z., 1977, COMP GRAPH IMAGE PRO, V6, P434, DOI DOI 10.1016/S0146-664X(77)80021-X
   Lee AB, 1999, P IEEE WORKSH STAT C
   Lindblad J, 2003, LECT NOTES COMPUT SC, V2886, P348
   Lorensen W. E., 1987, P SIGGRAPH 87, P163, DOI DOI 10.1145/37401.37422
   MARSAGLIA G, 1972, ANN MATH STAT, V43, P645, DOI 10.1214/aoms/1177692644
   Mullikin J. C., 1993, Bioimaging, V1, P6, DOI 10.1002/1361-6374(199303)1:1<6::AID-BIO3>3.3.CO;2-V
   PROFFITT D, 1979, COMPUT VISION GRAPH, V10, P318, DOI 10.1016/S0146-664X(79)80041-6
   Quadros WR, 2001, ENG COMPUT-GERMANY, V17, P186, DOI 10.1007/PL00007200
   SINTORN IM, 2002, LNCS, V2301, P244
   Sladoje N, 2003, LECT NOTES COMPUT SC, V2886, P368
   Windreich G, 2003, PATTERN RECOGN, V36, P2531, DOI 10.1016/S0031-3203(03)00173-0
NR 20
TC 69
Z9 76
U1 0
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 111
EP 122
DI 10.1016/j.imavis.2004.06.012
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800003
DA 2024-07-18
ER

PT J
AU Soille, P
AF Soille, P
TI Beyond self-duality in morphological image analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE mathematical morphology; self-duality; switch operator;
   self-complementarity; partition; region growing; flat regions;
   simplification; satellite images
ID OPERATORS; SEGMENTATION; OPENINGS
AB Most morphological operators occur by pair of dual operators as highlighted by the erosion/dilation and opening/closing pairs. In practice, one decides to apply an operator or its dual depending on whether the targeted image structures are darker or brighter than their neighbourhood. Nevertheless, the same type of image structures may appear brighter than their neighbourhood in a region of the image definition domain but brighter in another. In this situation, self-dual rather than dual operators should be used. However, self-dual operators still assume that image structures roughly correspond to image extrema. Therefore, this model does not apply to complex images representing a partition of the space into image objects of arbitrary intensity values such as satellite images displaying landscapes with fields of various crop types. In this paper, we revisit the notion of self-duality, propose two new self-dual morphological filters, and show that it is possible to go beyond self-duality either by considering self-complementary operators or by substituting the image extrema paradigm with the more general concept of flat zones. (C) 2004 Elsevier B.V. All rights reserved.
C1 Joint Res Ctr European Commiss, Land Management Unit, Inst Environm & Sustainabil, I-21020 Ispra, Italy.
C3 European Commission Joint Research Centre; EC JRC ISPRA Site
RP Joint Res Ctr European Commiss, Land Management Unit, Inst Environm & Sustainabil, Via Fermi 1,TP 262, I-21020 Ispra, Italy.
EM pierre.soille@jrc.it
OI Soille, Pierre/0000-0002-8479-9205
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], IMAGE ANAL MATH MORP
   [Anonymous], 1994, Morphological Image Operators
   Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066
   Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X
   Heijmans HJAM, 2002, J MATH IMAGING VIS, V17, P55, DOI 10.1023/A:1020726725590
   Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703
   HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O
   Heijmans HJAM, 1999, IEEE T IMAGE PROCESS, V8, P1330, DOI 10.1109/83.791959
   Heijmans HJAM, 1996, J MATH IMAGING VIS, V6, P15, DOI 10.1007/BF00127373
   Keshet R., 2000, Fundamenta Informaticae, V41, P33
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556
   MEYER F, 1989, SIGNAL PROCESS, V16, P303, DOI 10.1016/0165-1684(89)90028-5
   Meyer F, 1998, COMP IMAG VIS, V12, P199
   Meyer F, 2000, J VIS COMMUN IMAGE R, V11, P245, DOI 10.1006/jvci.1999.0447
   Pesaresi M, 2001, IEEE T GEOSCI REMOTE, V39, P309, DOI 10.1109/36.905239
   Salembier P, 1998, COMP IMAG VIS, V12, P183
   SERRA J, 1988, IMAGE ANAL MATH MORP, V2, P159
   Soille P, 2003, LECT NOTES COMPUT SC, V2886, P52
   SOILLE P, 2002, LECT NOTES COMPUTER, V2301, P175
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   STERNBERG SR, 1986, COMPUT VISION GRAPH, V35, P333, DOI 10.1016/0734-189X(86)90004-6
NR 23
TC 40
Z9 45
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 249
EP 257
DI 10.1016/j.imavis.2004.06.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800015
DA 2024-07-18
ER

PT J
AU Chang, HT
AF Chang, HT
TI Arbitrary affine transformation and their composition effects for
   two-dimensional fractal sets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE iterated function system; affine transformation; fractal image; image
   synthesize
ID SYNTHESIZER; ALGORITHM; IMAGES; CODES
AB Fractal sets can be generated by the iterated function system (IFS) codes using the contractive affine transformation. This paper presents various geometric affine transformations and their composition effects for two-dimensional (2-D) fractal sets. Here, the geometric transformations include translation, rotation, shearing, dilation/contraction, and reflection. First, a hierarchical fixed point-searching algorithm is proposed to determine the original coordinates of a 2-D fractal set directly from its IFS code. Then, the IFS code is modified according to the desired transformation. Instead of post processing the generated result, arbitrary affine transformation on the original fractal set can be directly obtained. On the other hand, the composite geometric transformations for 2-D fractal sets are also available. Finally, a complicated image frame can be synthesized by multiple 2-D fractal sets. (C) 2004 Elsevier B.V. All rights reserved.
C1 Natl Yunlin Univ Sci & Technol, Dept Elect Engn, Photon & Informat Lab, Touliu 64045, Taiwan.
C3 National Yunlin University Science & Technology
RP Chang, HT (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Elect Engn, Photon & Informat Lab, Touliu 64045, Taiwan.
EM htchang@pine.yuntech.edu.tw
CR Barnsley M.F., 1993, Fractal Image Compression
   Barnsley M.F., 1993, FRACTAL EVERYWHERE, V2, P84
   BARNSLEY MF, 1988, BYTE             JAN, P215
   BISOI AK, 1999, P 1999 3 INT C COMP, P454
   Chang HT, 1998, APPL OPTICS, V37, P1310, DOI 10.1364/AO.37.001310
   Chang HT, 2001, OPT ENG, V40, P941, DOI 10.1117/1.1367345
   CHANG HT, 1997, 1997 IEEE P INT C CI, V2, P1277
   CHANG KL, 1994, APPL IMMUNOHISTOCHEM, V2, P146
   COHEN HA, 1992, P IEEE INT C AC SPEE, V3, P509
   KAMEJIMA K, 1999, P 1999 IEEE INT C SY, V6, P890
   KAMEJIMA K, 1999, P 1999 38 SICE ANN C, P1077
   KAMEJIMA K, 1997, P 1999 36 SICE ANN C, P1273
   KAWAMATA M, 1992, P IEEE WORKSH INT SI, P219
   Pei SC, 1996, IEEE T IMAGE PROCESS, V5, P411, DOI 10.1109/83.491315
   PEI SC, 1995, IEEE T IMAGE PROCESS, V4, P682, DOI 10.1109/83.382503
   RAYNAL F, 1999, P C EV COMP WASH DC, V2, P1171
   RINALDO R, 1994, IEEE T IMAGE PROCESS, V3, P802, DOI 10.1109/83.336249
   Sasaki T, 2000, APPL OPTICS, V39, P2959, DOI 10.1364/AO.39.002959
   TANIDA J, 1993, APPL OPTICS, V32, P653, DOI 10.1364/AO.32.000653
   WILLIAMS G, 1996, LINEAR ALGEBRA APPL, P342
NR 20
TC 9
Z9 10
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2004
VL 22
IS 13
BP 1117
EP 1127
DI 10.1016/j.imavis.2004.05.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 862LY
UT WOS:000224493600003
DA 2024-07-18
ER

PT J
AU Tsai, DM
   Chiang, CH
AF Tsai, DM
   Chiang, CH
TI Automatic band selection for wavelet reconstruction in the application
   of defect detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE surface inspection; defect detection; textured image; wavelet transform;
   band selection
ID TEXTURE SEGMENTATION; GABOR FILTERS; IMAGE SEGMENTATION; CLASSIFICATION;
   DISCRIMINATION; REPRESENTATION; FEATURES
AB In this paper, we present a multiresolution approach for the inspection of local defects embedded in homogeneously textured surfaces. It is based on an efficient image restoration scheme using the wavelet transforms. By properly selecting the smooth subimage or the combination of detail subimages at different resolution levels for image reconstruction, the global repetitive texture pattern can be effectively removed and only local anomalies are preserved in the restored image. A wavelet band selection procedure is developed to automatically determine the best reconstruction parameters based on the energy distribution of wavelet coefficients. Experimental results show that the decomposed subimages and the number of resolution levels determined by the automatic band selection scheme are similar to the manual selection results, and the defects in a variety of real textures including machined surfaces, natural wood, sandpaper and textile fabrics are well detected. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Yuan Ze Univ, Dept Ind Engn & Management, Tao Yuan 320, Taiwan.
C3 Yuan Ze University
RP Tsai, DM (corresponding author), Yuan Ze Univ, Dept Ind Engn & Management, 135 Yuan Tung Rd,Chung Li, Tao Yuan 320, Taiwan.
CR AMET AL, 1998, IMAGE ANAL INTERPRET, V1, P205
   Arof H, 1998, IEE P-VIS IMAGE SIGN, V145, P167, DOI 10.1049/ip-vis:19981688
   Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796
   Chitre Y, 1999, PATTERN RECOGN, V32, P773, DOI 10.1016/S0031-3203(98)00111-3
   CLARK M, 1987, PATTERN RECOGN LETT, V6, P261, DOI 10.1016/0167-8655(87)90086-9
   COHEN FS, 1992, CVGIP-GRAPH MODEL IM, V54, P239, DOI 10.1016/1049-9652(92)90054-2
   CONNERS RW, 1983, IEEE T PATTERN ANAL, V5, P573, DOI 10.1109/TPAMI.1983.4767446
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DUNN D, 1995, IEEE T IMAGE PROCESS, V4, P947, DOI 10.1109/83.392336
   DUNN D, 1994, IEEE T PATTERN ANAL, V16, P130, DOI 10.1109/34.273736
   Escofet J, 1996, P SOC PHOTO-OPT INS, V2785, P163, DOI 10.1117/12.248537
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   LAMBERT G, 1997, IEEE INT C IM PROC, V3, P201, DOI DOI 10.1109/ICIP.1997.632054
   Lemarie-Rieusset P. G., 1986, Rev Mat Iberoamericana, V2, P1
   LIU SS, 1990, COMPUT VISION GRAPH, V49, P52, DOI 10.1016/0734-189X(90)90162-O
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   NG I, 1993, SIGNAL PROCESS, V31, P133, DOI 10.1016/0165-1684(93)90062-F
   Raghu PP, 1996, IEEE T IMAGE PROCESS, V5, P1625, DOI 10.1109/83.544570
   Ramana KV, 1996, PATTERN RECOGN, V29, P1447, DOI 10.1016/0031-3203(96)00008-8
   SIEW LH, 1988, IEEE T PATTERN ANAL, V10, P92, DOI 10.1109/34.3870
   SONG KY, 1992, P SOC PHOTO-OPT INS, V1708, P99, DOI 10.1117/12.58564
   SONG KY, 1994, P SOC PHOTO-OPT INS, V2183, P193, DOI 10.1117/12.171208
   Song KY, 1996, IMAGE VISION COMPUT, V14, P667, DOI 10.1016/0262-8856(96)84491-X
   Ten Daubechies I., 1992, lecture on wavelets
   TEUNER A, 1995, IEEE T IMAGE PROCESS, V4, P863, DOI 10.1109/83.388091
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   VANHULLE MM, 1993, NEURAL NETWORKS, V6, P7, DOI 10.1016/S0893-6080(05)80070-X
   Weldon TP, 1996, PATTERN RECOGN, V29, P2005, DOI 10.1016/S0031-3203(96)00047-7
   Zou MY, 2001, PROC SPIE, V4550, P34, DOI 10.1117/12.441495
NR 30
TC 87
Z9 101
U1 5
U2 21
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2003
VL 21
IS 5
BP 413
EP 431
DI 10.1016/S0262-8856(03)00003-9
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 676DA
UT WOS:000182735600002
DA 2024-07-18
ER

PT J
AU Yu, WC
   Sommer, G
   Daniilidis, K
AF Yu, WC
   Sommer, G
   Daniilidis, K
TI Three dimensional orientation signatures with conic kernel filtering for
   multiple motion analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE conic kernel; 3D orientation signature; multiple motion estimation;
   hough transform; expectation; maximization algorithm; steerable filter
ID OPTICAL-FLOW; SEGMENTATION; MODEL; CELLS
AB We propose a new 3D kernel for the recovery of 3D orientation signatures. In the Cartesian coordinates, the kernel has a shape of a truncated cone with its axis in the radial direction and very small angular support. In the local spherical coordinates, the angular part of the kernel is a 2D Gaussian function. A set of such kernels is obtained by uniformly sampling the 2D space of azimuth and elevation angles. The projection of a local neighborhood on such a kernel set produces a local 3D orientation signature. In case of spatio-temporal analysis, such a kernel set can be applied either on the derivative space of a local neighborhood or on the local Fourier transform. The well known planes arising from one or multiple motions produce maxima in the orientation signature. The kernel's local support enables the resulting spatio-temporal signatures to possess higher orientation resolution than 3D steerable filters. Consequently, motion maxima can be detected and localized more accurately. We describe and show in experiments the superiority of the proposed kernels compared to Hough transformation or expectation-maximization based multiple motion detection. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Yale Univ, Dept Diagnost Radiol, New Haven, CT 06520 USA.
   Univ Kiel, Inst Comp Sci, D-24105 Kiel, Germany.
   Univ Penn, GRASP Lab, Philadelphia, PA 19104 USA.
C3 Yale University; University of Kiel; University of Pennsylvania
RP Yu, WC (corresponding author), Yale Univ, Dept Diagnost Radiol, BML 332,POB 208042, New Haven, CT 06520 USA.
EM weichuan@noodle.med.yale.edu; gs@ks.informatik.uni-kiel.de;
   kostas@grasp.cis.upenn.edu
OI Daniilidis, Kostas/0000-0003-0498-0758; Yu, Weichuan/0000-0002-5510-6916
CR ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   ANDERSSON MT, 1992, THESIS LINKOEPING U
   AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Beauchemin SS, 2000, IEEE T PATTERN ANAL, V22, P200, DOI 10.1109/34.825758
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   FLEET DJ, 1994, VISION RES, V34, P3057, DOI 10.1016/0042-6989(94)90278-X
   Folsom TC, 1998, IEEE T PATTERN ANAL, V20, P1161, DOI 10.1109/34.730552
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   GRZYWACZ NM, 1990, PROC R SOC SER B-BIO, V239, P129, DOI 10.1098/rspb.1990.0012
   Gu HS, 1996, IEEE T PATTERN ANAL, V18, P58, DOI 10.1109/34.476012
   HauSSecker H., 1999, HDB COMPUTER VISION, P309
   HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568
   HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L
   Horn B.K.P, 1986, Robot Vision
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   HUANG CL, 1995, IMAGE VISION COMPUT, V13, P21, DOI 10.1016/0262-8856(95)91465-P
   JAHNE B, 1998, P ECCV, V2, P322
   Jahne B., 1993, Spatio-temporal image processing: theory and scientific applications
   MICHAELIS M, 1994, LECT NOTES COMPUT SC, V800, P101
   PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394
   POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   SHIZAWA M, 1993, IEEE C COMP VIS PATT, P508
   SHIZAWA M, 1991, IEEE C COMP VIS PATT, P289
   Simoncelli EP, 1998, VISION RES, V38, P743, DOI 10.1016/S0042-6989(97)00183-1
   Simoncelli EP, 1996, IEEE T IMAGE PROCESS, V5, P1377, DOI 10.1109/83.535851
   WEISS Y, 1997, IEEE C COMP VIS PATT, P520
   Xiong YL, 1997, INT J COMPUT VISION, V22, P25, DOI 10.1023/A:1007927810205
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Yu WC, 2001, IEEE T IMAGE PROCESS, V10, P193, DOI 10.1109/83.902274
NR 31
TC 7
Z9 7
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2003
VL 21
IS 5
BP 447
EP 458
DI 10.1016/S0262-8856(03)00012-X
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 676DA
UT WOS:000182735600004
DA 2024-07-18
ER

PT J
AU Vilariño, DL
   Cabello, D
   Pardo, XM
   Brea, VM
AF Vilariño, DL
   Cabello, D
   Pardo, XM
   Brea, VM
TI Cellular neural networks and active contours:: a tool for image
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE cellular neural networks; active contours; image segmentation
ID DISCRETE-TIME CNN; TEMPLATE; TRACKING; DESIGN; MODELS
AB In this paper Cellular Neural Networks (CNN) are applied to image segmentation based on active contour techniques. The approach is based on deformable contours which evolve pixel by pixel from their initial shapes and locations until delimiting the objects of interest. The contour shift is guided by external information from the image under consideration which attracts them towards the target characteristics (intensity extremes, edges, etc.) and by internal forces which try to maintain the smoothness of the contour curve. This CNN-based proposal combines the characteristics from implicit and parametric models. As a consequence a high flexibility and control for the evolution dynamics of the snakes are provided, allowing the solution of complex tasks as is the case of the topologic transformations. In addition the proposal is suitable for its implementation as an integrated circuit allowing to take advantages of the massively parallel processing in CNN to reduce processing time. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Santiago de Compostela, Dept Elect & Comp Sci, Santiago De Compostela, Spain.
C3 Universidade de Santiago de Compostela
RP Univ Santiago de Compostela, Dept Elect & Comp Sci, Santiago De Compostela, Spain.
EM eldiego@usc.es
RI Brea, Victor/N-5165-2014; Pardo, Xose M./L-8567-2014; Cabello,
   Diego/O-1756-2014
OI Brea, Victor/0000-0003-0078-0425; Pardo, Xose M./0000-0002-3997-5150;
   Cabello, Diego/0000-0002-4859-2899
CR AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681
   Blake A., 1998, ACTIVE CONTOURS
   Brea VM, 2000, PROCEEDINGS OF THE 2000 6TH IEEE INTERNATIONAL WORKSHOP ON CELLULAR NEURAL NETWORKS AND THEIR APPLICATIONS (CNNA 2000), P425, DOI 10.1109/CNNA.2000.877366
   BREA VM, 1998, P IEEE INT C EL CIRC, V3, P285
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, P66
   CHUA LO, 1988, IEEE T CIRCUITS SYST, V35, P1257, DOI 10.1109/31.7600
   CHUA LO, 1991, IEEE T CIRCUITS SYST, V38, P1332, DOI 10.1109/31.99162
   Cohen L. D., 1991, Artificial Intelligence and Computer Vision. Proceedings of the Seventh Israeli Conference, P237
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Hänggi M, 1999, IEEE T CIRCUITS-I, V46, P304, DOI 10.1109/81.747207
   HARRER H, 1992, INT J CIRC THEOR APP, V20, P453, DOI 10.1002/cta.4490200503
   HARRER H, 1993, IEEE T CIRCUITS-II, V40, P191, DOI 10.1109/82.222818
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kozek T, 1999, J VLSI SIG PROC SYST, V23, P403, DOI 10.1023/A:1008105404510
   Lopez P, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P133, DOI 10.1109/ISCAS.2000.858706
   MAGNUSSEN H, 1994, 3 IEEE INT WORKSH CE, P165
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   MATSUMOTO T, 1990, IEEE T CIRCUITS SYST, V37, P633, DOI 10.1109/31.55003
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9
   MOTZKIN TS, 1954, CAN J MATH, V6, P393, DOI 10.4153/CJM-1954-038-x
   Niessen WJ, 1998, IEEE T MED IMAGING, V17, P634, DOI 10.1109/42.730407
   Nossek JA, 1996, INT J CIRC THEOR APP, V24, P15, DOI 10.1002/(SICI)1097-007X(199601/02)24:1<15::AID-CTA900>3.0.CO;2-5
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Paragios N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P926, DOI 10.1109/ICCV.1999.790347
   PARDO JM, 1998, THESIS U SANTIAGO CO
   RADEVA P, 1993, VIS C SWISS 93, P187
   ROSKA T, 1993, IEEE T CIRCUITS-II, V40, P163, DOI 10.1109/82.222815
   Roska T., 1999, Cnn software library (templates and algorithms) version 7.3. Technical Report DNS-CADET-15
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   STORVIK G, 1994, IEEE T PATTERN ANAL, V16, P976, DOI 10.1109/34.329011
   VENETIANER PL, 1995, IEEE T CIRCUITS SYST, V42
   Vilarino D. L., 1999, Proceedings of the European Conference on Circuit Theory and Design. ECCTD'99, P1351
   Vilarino DL, 1998, PATTERN RECOGN LETT, V19, P721, DOI 10.1016/S0167-8655(98)00050-6
   Vilarino DL, 1997, LECT NOTES COMPUT SC, V1240, P1193, DOI 10.1007/BFb0032579
   VILARINO DL, 1998, 5 IEEE INT WORKSH CE, P331
   Zarándy A, 1999, INT J CIRC THEOR APP, V27, P5, DOI 10.1002/(SICI)1097-007X(199901/02)27:1<5::AID-CTA38>3.0.CO;2-C
   Zhu Y, 1997, IEEE T MED IMAGING, V16, P55, DOI 10.1109/42.552055
   Zou F., 1990, 1990 IEEE International Workshop on Cellular Neural Networks and their Applications, CNNA-90 (Cat. No.90TH0312-9), P73, DOI 10.1109/CNNA.1990.207509
NR 41
TC 35
Z9 37
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 10
PY 2003
VL 21
IS 2
BP 189
EP 204
AR PII S0262-8856(02)00153-1
DI 10.1016/S0262-8856(02)00153-1
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 655CP
UT WOS:000181534000005
DA 2024-07-18
ER

PT J
AU Coughlan, J
   Yuille, A
AF Coughlan, J
   Yuille, A
TI Algorithms from statistical physics for generative models of images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN   02, 2002
CL COPENHAGEN, DENMARK
DE Markov random field; generalized iterative scaling; minimax entropy
   learning; histogram statistics
AB A general framework for defining generative models of images is Markov random fields (MRFs), with shift-invariant (homogeneous) MRFs being an important special case for modeling textures and generic images. Given a dataset of natural images and a set of filters from which filter histogram statistics are obtained, a shift-invariant MRF can be defined (as in [Neural Comput. 9 (1997) 1627]) as a distribution of images whose mean filter histogram values match the empirical values obtained from the data set. Certain parameters in the MRF model, called potentials, must be determined in order for the model to match the empirical statistics. Standard methods for calculating the potentials are computationally very demanding, such as Generalized Iterative Scaling (GIs), an iterative procedure that converges to the correct potential values. We define a fast approximation, called BKGIS, which uses the Bethe-Kikuchi approximation from statistical physics to speed up the GIs procedure. Results are demonstrated on a model using two filters, and we show synthetic images that have been sampled from the model. Finally, we show a connection between GIs and our previous work on the g-factor. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Smith Kettlewell Eye Res Inst, San Francisco, CA 94115 USA.
C3 The Smith-Kettlewell Eye Research Institute
RP Coughlan, J (corresponding author), Smith Kettlewell Eye Res Inst, 2318 Fillmore St, San Francisco, CA 94115 USA.
OI Yuille, Alan L./0000-0001-5207-9249
CR COUGHLAN JM, 2002, ADV NEURAL INFORMATI, V14
   COUGHLAN JM, 1998, P NIPS 98, P761
   DARROCH JN, 1972, ANN MATH STAT, V43, P1470, DOI 10.1214/aoms/1177692379
   Domb C., 1972, Phase Transitions and Critical Phenomena, V2
   Konishi S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P573, DOI 10.1109/CVPR.1999.786996
   Lee AB, 2001, INT J COMPUT VISION, V41, P35, DOI 10.1023/A:1011109015675
   PORTILLA EP, 2000, INT J COMPUT VISION, P49
   TEH YW, 2002, IN PRESS P NIPS 01
   YEDIDIA JS, 2000, P NIPS 00, P698
   YUILLE AL, 2002, ADV NEURAL INFORMATI, V14
   Zhu SC, 1997, IEEE T PATTERN ANAL, V19, P1236, DOI 10.1109/34.632983
   Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627
NR 12
TC 2
Z9 2
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 29
EP 36
AR PII S0262-8856(02)00134-8
DI 10.1016/S0262-8856(02)00134-8
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800004
DA 2024-07-18
ER

PT J
AU Wu, HJ
   Qi, HR
   Zhang, HR
   Jin, Z
   Salihu, D
   Hu, JF
AF Wu, Hongjun
   Qi, Haoran
   Zhang, Huanrong
   Jin, Zhi
   Salihu, Driton
   Hu, Jian-Fang
TI Reconstruction with robustness: A semantic prior guided face
   super-resolution framework for multiple degradations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face super-resolution; Robustness; Multiple degradations; Semantic prior
AB Despite the rapid advancements made with the support of deep learning, Face Super-Resolution (FSR) methods still suffer from challenges under multiple degradations. These challenges significantly impede the practical applications of FSR methods in real-world scenarios. Incorporating facial priors could potentially relieve this issue. However, ground truth priors are not feasible in real-world applications, meanwhile the accuracy of predicted priors is difficult to guarantee, especially for low-resolution faces under multiple degradations. Hence, it is worth exploring how to effectively leverage facial priors for improving the robustness of FSR under multiple degradations. To tackle these problems, we propose RSemFace, a robust semantic prior guided FSR framework to reconstruct multiple degraded faces. In RSemFace, we design the Degradation Stage to synthesize multiple degraded low-resolution faces with a variety of interpolations, noise levels, blurring kernels, and even the realworld interference. The Generation Stage generates Coarse-SR faces, and extracts semantic features from the Coarse-SR as priors, which are used to the reconstruction of Fine-SR faces with the support of Semantic Feature Attention Blocks (SFABs) and Semantic Loss. Both quantitative and qualitative results show the better robustness of our RSemFace for content recovery and perceptual quality in simultaneously handling multiple degraded faces compared with other state-of-the-art methods. Lastly, faces reconstructed by RSemFace are proven to improve the high-level vision task due to better recovered identities.
C1 [Wu, Hongjun; Qi, Haoran; Zhang, Huanrong; Jin, Zhi] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen Campus, Shenzhen 518107, Guangdong, Peoples R China.
   [Jin, Zhi] Guangdong Prov Key Lab Fire Sci & Technol, Guangzhou 510006, Peoples R China.
   [Jin, Zhi] Guangdong Prov Key Lab Robot & Digital Intelligent, Guangzhou 510535, Peoples R China.
   [Salihu, Driton] Tech Univ Munich, Chair Media Technol, Munich Inst Robot & Machine Intelligence MIRMI, Sch Computat Informat & Technol,Dept Comp Engn, D-80333 Munich, Germany.
   [Hu, Jian-Fang] Sun Yat Sen Univ, Sch Comp Sci & Engn, Guangzhou 511400, Guangdong, Peoples R China.
C3 Sun Yat Sen University; Technical University of Munich; Sun Yat Sen
   University
RP Jin, Z (corresponding author), Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen Campus, Shenzhen 518107, Guangdong, Peoples R China.; Jin, Z (corresponding author), Guangdong Prov Key Lab Fire Sci & Technol, Guangzhou 510006, Peoples R China.; Jin, Z (corresponding author), Guangdong Prov Key Lab Robot & Digital Intelligent, Guangzhou 510535, Peoples R China.
EM jinzh26@mail.sysu.edu.cn
RI Jin, Zhi/AAB-2440-2022
OI Jin, Zhi/0000-0001-9670-7366; Zhang, Huanrong/0000-0003-3830-3480
FU National Natural Science Foundation of China; Sino-Germen Mobility
   Programme;  [62071500];  [M-0421]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 62071500; Supported by Sino-Germen Mobility
   Programme M-0421.
CR Adjabi I, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9081188
   Amos B., 2023, Open face: a general-purpose face recognition library with mobile applications
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Ben Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P191, DOI 10.1007/978-3-030-58610-2_12
   Bulat A, 2018, LECT NOTES COMPUT SC, V11210, P187, DOI 10.1007/978-3-030-01231-1_12
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chan Kelvin CK, 2021, CVPR
   Chen CF, 2021, PROC CVPR IEEE, P11891, DOI 10.1109/CVPR46437.2021.01172
   Chen XZ, 2020, NEUROCOMPUTING, V376, P119, DOI 10.1016/j.neucom.2019.09.079
   Chen Y, 2018, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR.2018.00264
   Cheng X., 2022, APSIPA ASC
   Cheng ZY, 2020, IEEE WINT CONF APPL, P2424, DOI [10.1109/WACV45572.2020.9093480, 10.1109/wacv45572.2020.9093480]
   Dastmalchi H., 2023, Image Commun., V107
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fu JH, 2022, Arxiv, DOI arXiv:2209.10305
   Guo Y, 2020, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR42600.2020.00545
   He ZY, 2022, IEEE T MULTIMEDIA, V24, P2877, DOI 10.1109/TMM.2021.3090166
   Hensel M, 2017, ADV NEUR IN, V30
   Hou H, 2023, IEEE T IMAGE PROCESS, V32, P1184, DOI 10.1109/TIP.2023.3240845
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Huang W., 2022, ICANN
   Ke X, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104484
   Kingma D. P., 2014, arXiv
   Kowalski M, 2017, IEEE COMPUT SOC CONF, P2034, DOI 10.1109/CVPRW.2017.254
   Kumar B, 2023, COMPUT ELECTR ENG, V106, DOI 10.1016/j.compeleceng.2023.108612
   Laghari AA, 2022, COMPUT SCI INF SYST, V19, P1305, DOI 10.2298/CSIS220322038L
   Laghari AA, 2018, MULTIAGENT GRID SYST, V14, P125, DOI 10.3233/MGS-180284
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Liu Z., 2023, Large-scale celebfaces attributes (celeba) dataset
   Lu T., 2021, ACM MM
   Lu YY, 2018, LECT NOTES COMPUT SC, V11216, P293, DOI 10.1007/978-3-030-01258-8_18
   Maeda S, 2020, PROC CVPR IEEE, P288, DOI 10.1109/CVPR42600.2020.00037
   Nie H, 2016, PROC INT C TOOLS ART, P485, DOI [10.1109/ICTAI.2016.77, 10.1109/ICTAI.2016.0080]
   Park H, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103883
   Paszke A, 2019, ADV NEUR IN, V32
   Rai D, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3280537
   Rajput SS, 2019, MULTIMED TOOLS APPL, V78, P25407, DOI 10.1007/s11042-019-07791-y
   Umer M, 2023, IMAGE VISION COMPUT, V133, DOI 10.1016/j.imavis.2023.104657
   Wang XT, 2021, IEEE INT CONF COMP V, P1905, DOI 10.1109/ICCVW54120.2021.00217
   Wang XT, 2021, PROC CVPR IEEE, P9164, DOI 10.1109/CVPR46437.2021.00905
   Xin JW, 2019, AAAI CONF ARTIF INTE, P9054
   Yang LB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1551, DOI 10.1145/3394171.3413965
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Yin Z, 2021, COGN NEURODYNAMICS, V15, P169, DOI 10.1007/s11571-020-09615-4
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu X., 2023, IEEE Trans. Pattern Anal. Mach. Intell., P908
   Yu X, 2018, PROC CVPR IEEE, P908, DOI 10.1109/CVPR.2018.00101
   Zhang HR, 2021, IEEE J-STSP, V15, P253, DOI 10.1109/JSTSP.2020.3045282
   Zhang HR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2113, DOI 10.1145/3394171.3413664
   Zhang K, 2018, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2018.00344
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang YL, 2018, LECT NOTES COMPUT SC, V11211, P294, DOI 10.1007/978-3-030-01234-2_18
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhao TY, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102926
NR 54
TC 2
Z9 2
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104857
DI 10.1016/j.imavis.2023.104857
EA NOV 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Y9XG0
UT WOS:001108710600001
DA 2024-07-18
ER

PT J
AU Bisogni, C
   Cimmino, L
   De Marsico, M
   Hao, F
   Narducci, F
AF Bisogni, Carmen
   Cimmino, Lucia
   De Marsico, Maria
   Hao, Fei
   Narducci, Fabio
TI Emotion recognition at a distance: The robustness of machine learning
   based on hand-crafted facial features vs deep learning models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Emotion recognition; Facial expression; Expression recognition at a
   distance; Deep learning; Machine learning; Mediapipe
ID EXPRESSION
AB Emotion estimation from face expression analysis is nowadays a widely-explored computer vision task. In turn, the classification of expressions relies on relevant facial features and their dynamics. Despite the promising accuracy results achieved in controlled and favorable conditions, the processing of faces acquired at a distance, entailing low-quality images, still suffers from a significant performance decrease. In particular, most approaches and related computational models become extremely unstable in the case of the very small amount of useful pixels that is typical in these conditions. Therefore, their behavior should be investigated more carefully. On the other hand, real-time emotion recognition at a distance may play a critical role in smart video surveillance, especially when controlling particular kinds of events, e.g., political meetings, to try to prevent adverse actions. This work compares facial expression recognition at a distance by: 1) a deep learning architecture based on stateof-the-art (SOTA) proposals, which exploits the whole images to autonomously learn the relevant embeddings; 2) a machine learning approach that relies on hand-crafted features, namely the facial landmarks preliminarily extracted using the popular Mediapipe framework. Instead of using either the complete sequence of frames or only the final still image of the expression, like current SOTA approaches, the two proposed methods are designed to use rich temporal information to identify three different stages of emotion. Expressions are time-split accordingly into four phases to better exploit their temporal-dependent dynamics. Experiments were conducted on the popular Extended Cohn-Kanade dataset (CK+). It was chosen for its wide use in related literature, and because it includes videos of facial expressions and not only still images. The results show that the approach relying on machine learning via hand-crafted features is more suitable for classifying the initial phases of the expression and does not decay in terms of accuracy when images are at a distance (only 0.08% of decay). On the contrary, deep learning not only has difficulties classifying the initial phases of the expressions but also suffers from relevant performance decay when considering images at a distance (52.68% accuracy decay). & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Bisogni, Carmen; Cimmino, Lucia; Narducci, Fabio] Univ Salerno, Dept Comp Sci, I-84084 Salerno, Italy.
   [De Marsico, Maria] Univ Roma La Sapienza, Dept Comp Sci, I-00185 Rome, Italy.
   [Hao, Fei] Shaanxi Normal Univ, Sch Comp Sci, Xian 710119, Peoples R China.
C3 University of Salerno; Sapienza University Rome; Shaanxi Normal
   University
RP Cimmino, L (corresponding author), Univ Salerno, Dept Comp Sci, I-84084 Salerno, Italy.
EM cbisogni@unisa.it; lcimmino@unisa.it; demarsico@uniroma1.it;
   fhao@snnu.edu.cn; fnarducci@unisa.it
RI Cimmino, Lucia/ADL-8213-2022; Narducci, Fabio/R-5833-2017
OI Narducci, Fabio/0000-0003-4879-7138
CR [Anonymous], 2005, PROX 2 ANN C INF SEC
   Arunnehru J, 2017, STUD COMPUT INTELL, V660, P321, DOI 10.1007/978-3-319-44790-2_15
   Bai MJ, 2020, COMPANION PUBLICATON OF THE 2020 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION (ICMI '20 COMPANION), P7, DOI 10.1145/3395035.3425248
   Bashir Faisal, 2008, 2008 IEEE Fifth International Conference on Advanced Video and Signal Based Surveillance, P175, DOI 10.1109/AVSS.2008.28
   Bashir F, 2008, 2008 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, VOLS 1 AND 2, P426, DOI 10.1109/THS.2008.4534490
   Bouchrika Imed, 2018, SURVEILLANCE ACTION, P1, DOI DOI 10.1007/978-3-319-68533-5_1
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cheng BW, 2017, INT CONF AFFECT, P65
   De Marsico M, 2014, MULTIMED TOOLS APPL, V73, P109, DOI 10.1007/s11042-012-1279-6
   EKMAN P, 1993, AM PSYCHOL, V48, P384, DOI 10.1037/0003-066X.48.4.384
   Benitez-Quiroz CF, 2017, Arxiv, DOI arXiv:1703.01210
   Goh KM, 2020, VISUAL COMPUT, V36, P445, DOI 10.1007/s00371-018-1607-6
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Guo Bingchen H., 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P292, DOI 10.1109/TBIOM.2019.2943934
   Guo JN, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P2888
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Horstmann G, 2003, EMOTION, V3, P150, DOI 10.1037/1528-3542.3.2.150
   Hung BT, 2021, RES INTELLIGENT COMP, V1254, P549, DOI 10.1007/978-981-15-7527-3
   Kartynnik Y., 2019, ABS190706724 CORR
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Lee H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030785
   Lee HS, 2020, INTEL SERV ROBOT, V13, P15, DOI 10.1007/s11370-019-00301-x
   Li P, 2021, TRAIT SIGNAL, V38, P359, DOI 10.18280/ts.380213
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li SZ, 2009, ADV PATTERN RECOGNIT, P3, DOI 10.1007/978-1-84882-385-3_1
   Liu ZY, 2007, IMAGE VISION COMPUT, V25, P817, DOI 10.1016/j.imavis.2006.05.022
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Maqableh W, 2022, VIS INFORM, V7, P1, DOI 10.1016/j.visinf.2022.10.001
   Mishkin D, 2017, COMPUT VIS IMAGE UND, V161, P11, DOI 10.1016/j.cviu.2017.05.007
   Moon HM, 2017, SOFT COMPUT, V21, P4995, DOI 10.1007/s00500-016-2095-0
   Park U, 2013, IEEE T INF FOREN SEC, V8, P1665, DOI 10.1109/TIFS.2013.2261061
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Sagawa R, 2006, LECT NOTES COMPUT SC, V3852, P141
   Sajjad M, 2020, MOBILE NETW APPL, V25, P1611, DOI 10.1007/s11036-019-01366-9
   Shan CF, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P330
   Shao J, 2021, APPL INTELL, V51, P549, DOI 10.1007/s10489-020-01855-5
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Singh JP, 2018, IEEE ACCESS, V6, P70497, DOI 10.1109/ACCESS.2018.2879896
   Tan CW, 2014, IEEE T IMAGE PROCESS, V23, P3962, DOI 10.1109/TIP.2014.2337714
   Wang K, 2021, IEEE T INF FOREN SEC, V16, P866, DOI 10.1109/TIFS.2020.3023289
   Ye L, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13040628
   Yu S., 2021, P 2021 IEEE INT S CI, P1
   Yu ZB, 2018, NEUROCOMPUTING, V317, P50, DOI 10.1016/j.neucom.2018.07.028
   Zhao ZX, 2009, 2008 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS, VOLS 1-4, P2150
NR 46
TC 6
Z9 6
U1 2
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104724
DI 10.1016/j.imavis.2023.104724
EA JUN 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA L8QK0
UT WOS:001025853100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Chang, XY
   Yi, WT
   Lin, XB
   Sun, Y
AF Chang, Xiaoyun
   Yi, Wentao
   Lin, Xiangbo
   Sun, Yi
TI 3D hand reconstruction with both shape and appearance from an RGB image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D hand reconstruction; Implicit representation; Signed distance
   function; Appearance synthesis
AB Modeling 3D hands with geometry details and appearance can increase perceptual immersion and realism in many applications. However, traditional 3D representations such as meshes and voxel grids can not represent high-quality hand shapes with their property of the discrete surface and fixed topology. To address these prob-lems, we introduce implicit function for more detailed shape reconstruction, and design a Structure-aware Signed Distance Function (S-SDF) to reconstruct hand shape in arbitrary resolution. In this way, our method not only focuses on independent fingers but also keeps the relationship between fingers. Such implicit function of 3D representation associated with part semantics and structure of the hand is central to generating realistic hand shapes of diverse variations. Meanwhile, in order to avoid time-consuming and laborious 3D annotating of texture, we present a self-supervised appearance synthesis approach. Extensive experiments on widely used datasets demonstrate that the proposed method reconstructs more realistic hands compared with previous methods.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Chang, Xiaoyun; Yi, Wentao; Lin, Xiangbo; Sun, Yi] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China.
C3 Dalian University of Technology
RP Chang, XY (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian, Peoples R China.
EM cgsmalcloud83@mail.dlut.edu.cn; raywit@mail.dlut.edu.cn;
   linxbo@dlut.edu.cn; lslwf@dlut.edu.cn
FU National Natural Science Founda-tion of China [61873046, U1708263]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China [grant numbers 61873046, U1708263] .
CR Ahmad A, 2019, IMAGE VISION COMPUT, V89, P35, DOI 10.1016/j.imavis.2019.06.003
   Boukhayma A, 2019, PROC CVPR IEEE, P10835, DOI 10.1109/CVPR.2019.01110
   Chang L.J., 2022, ARXIV
   Chen X., 2021, P IEEECVF C COMPUTER, P13274
   Chen X., P IEEE CVF C COMP VI, P20544
   Chen Y., 2021, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P10451
   Chen YJ, 2019, IEEE I CONF COMP VIS, P6960, DOI 10.1109/ICCV.2019.00706
   Chen Z., P IEEE CVF C COMP VI, P5939
   Chengde Wan, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P442, DOI 10.1007/978-3-030-58577-8_27
   Choi H., 2020, COMPUTER VISION ECCV, P769
   Corona E, 2022, PROC CVPR IEEE, P20501, DOI 10.1109/CVPR52688.2022.01988
   Defferrard M, 2016, ADV NEUR IN, V29
   Deng XM, 2021, IEEE T IMAGE PROCESS, V30, P532, DOI 10.1109/TIP.2020.3037479
   Fahim G, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104377
   Ge LH, 2019, PROC CVPR IEEE, P10825, DOI 10.1109/CVPR.2019.01109
   Gomez-Donoso F, 2019, IMAGE VISION COMPUT, V81, P25, DOI 10.1016/j.imavis.2018.12.001
   Gyeongsik Moon, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P752, DOI 10.1007/978-3-030-58571-6_44
   Hampali S, 2020, PROC CVPR IEEE, P3193, DOI 10.1109/CVPR42600.2020.00326
   Hasson Y., P IEEE CVF C COMP VI, P11807
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2020, Arxiv, DOI arXiv:2006.08072
   Huang Z., P IEEE CVF C COMP VI, P3093
   Jackson AS, 2019, LECT NOTES COMPUT SC, V11132, P64, DOI 10.1007/978-3-030-11018-5_6
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kanazawa A, 2018, LECT NOTES COMPUT SC, V11219, P386, DOI 10.1007/978-3-030-01267-0_23
   Karunratanakul K, 2020, INT CONF 3D VISION, P333, DOI 10.1109/3DV50981.2020.00043
   Karunratanakul Korrawe, arXiv
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Li C.L., P IEEE CVF C COMP VI, P11967
   Li ZG, 2022, APPL INTELL, V52, P6739, DOI 10.1007/s10489-021-02783-8
   Lin Kevin, 2021, P IEEE CVF INT C COM, P12939
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Madadi M, 2018, IMAGE VISION COMPUT, V79, P63, DOI 10.1016/j.imavis.2018.09.006
   Malik J., P IEEE CVF C COMP VI, P7113
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Miller AT, 2004, IEEE ROBOT AUTOM MAG, V11, P110, DOI 10.1109/MRA.2004.1371616
   Moon Gyeongsik, 2020, P EUR C COMP VIS ECC, P440
   Neng Qian, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P54, DOI 10.1007/978-3-030-58621-8_4
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Park J, 2022, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR52688.2022.00155
   Phong B.T., 1973, THESIS U UTAH
   Ravi N, 2020, Arxiv, DOI arXiv:2007.08501
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Varol G, 2018, LECT NOTES COMPUT SC, V11211, P20, DOI 10.1007/978-3-030-01234-2_2
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Zimmermann C, 2019, IEEE I CONF COMP VIS, P813, DOI 10.1109/ICCV.2019.00090
NR 52
TC 0
Z9 0
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104690
DI 10.1016/j.imavis.2023.104690
EA MAY 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA H8NY1
UT WOS:000998475000001
DA 2024-07-18
ER

PT J
AU Liu, Y
   Zhang, YZ
   Wang, ZY
   Yang, F
   Qin, C
   Qiu, F
   Coleman, S
   Kerr, D
AF Liu, Yan
   Zhang, Yunzhou
   Wang, Zhenyu
   Yang, Fei
   Qin, Cao
   Qiu, Feng
   Coleman, Sonya
   Kerr, Dermot
TI Complementary characteristics fusion network for weakly supervised
   salient object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; Weakly supervised learning; Edge fusion
   module; Feature correlation module; Self-supervised salient detection
   loss
ID FEATURES; CNN
AB Salient object detection (SOD) is a challenging and fundamental research in computer vision and image process-ing. Since the cost of pixel-level annotations is high, scribble annotations are usually used as weak supervisions. However, scribble annotations are too sparse and always located inside the objects with lacking annotations close to the semantic boundaries, which can't make confident predictions. To alleviate these issues, we propose a novel and effective scribble-based weakly supervised approach for SOD, named complementary characteristics fusion network (CCFNet). To be more specific, we design an edge fusion module (EFM) by taking account of local and high-level semantic information to equip our model, which would be beneficial to enhance the power of aggre-gating edge information. Then to achieve the complementary role of different features, a series of feature corre-lation modules (FCMs) are employed to strengthen the localization information and details learning. This is based on low-level, high-level global and edge information, which will complement each other to obtain relatively complete salient regions. Alternatively, to encourage the network to learn structural information and further im-prove the results of saliency maps in foreground and background, we propose a self-supervised salient detection (SSD) loss. Extensive experiments using five benchmark datasets demonstrate that our proposed approach per-forms favorably against the state-of-the-art weakly supervised algorithms, and even surpasses the performance of those fully supervised.(c) 2022 Published by Elsevier B.V.
C1 [Liu, Yan; Wang, Zhenyu] Northeastern Univ, Fac Robot Sci & Engineenng, Shenyang, Peoples R China.
   [Zhang, Yunzhou; Qin, Cao; Qiu, Feng] Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Peoples R China.
   [Yang, Fei] Zhejiang Lab New Campus, Hangzhou, Peoples R China.
   [Coleman, Sonya; Kerr, Dermot] Ulster Univ, Sch Comp Engn & Intelligent Syst, Coleraine, North Ireland.
C3 Northeastern University - China; Northeastern University - China; Ulster
   University
RP Zhang, YZ (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang, Peoples R China.
EM zhangyunzhou@mail.neu.edu.cn
RI wang, zhenyu/GSN-1592-2022
FU National Natural Science Foundation of China [61973066]; Major Science
   and Technology Projects of Liao- ning Province [2021JH1/10400049];
   Foundation of Key Laboratory of Equipment Reliability [WD2C20205500306];
   Foundation of Key Laboratory of Aerospace System Simulation
   [6142002200301]
FX Acknowledgements This work was supported by National Natural Science
   Foundation of China (No. 61973066) , Major Science and Technology
   Projects of Liao- ning Province (No. 2021JH1/10400049) , Foundation of
   Key Laboratory of Equipment Reliability (No. WD2C20205500306) and
   Foundation of Key Laboratory of Aerospace System Simulation (No.
   6142002200301) .
CR Araslanov N, 2020, PROC CVPR IEEE, P4252, DOI 10.1109/CVPR42600.2020.00431
   Bilen H, 2016, PROC CVPR IEEE, P2846, DOI 10.1109/CVPR.2016.311
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Craye C, 2016, IEEE INT CONF ROBOT, P2303, DOI 10.1109/ICRA.2016.7487379
   Deselaers T, 2012, INT J COMPUT VISION, V100, P275, DOI 10.1007/s11263-012-0538-3
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Li GB, 2018, AAAI CONF ARTIF INTE, P7024
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu N., 2021, IEEE INT C COMP VIS, P4722
   Liu Y, 2022, IEEE INT CONF AUTOM, DOI [10.1145/3551349.3559512, 10.1016/j.patrec.2021.12.011]
   Liu YX, 2021, IEEE T IMAGE PROCESS, V30, P4423, DOI 10.1109/TIP.2021.3071691
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Luo Z., P IEEE C COMPUTER VI, P6609
   Nguyen D.T., 2019, ADV NEURAL INFORM PR, V32
   Noori M, 2020, ENG APPL ARTIF INTEL, V89, DOI 10.1016/j.engappai.2019.103419
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Piao Yongri, 2021, ICCV, P4136
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siva P, 2013, PROC CVPR IEEE, P3238, DOI 10.1109/CVPR.2013.416
   Tang M, 2018, PROC CVPR IEEE, P1818, DOI 10.1109/CVPR.2018.00195
   Ullah I, 2021, NEUROCOMPUTING, V455, P139, DOI 10.1016/j.neucom.2021.05.001
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184
   Wang Z, 2021, IMAGE VISION COMPUT
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Wu Zhe, 2019, CVPR, P3907
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Yu SY, 2021, AAAI CONF ARTIF INTE, V35, P3234
   Zeng Y, 2019, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2019.00623
   Zhai Y., 2006, P 14 ACM INT C MULT, P815, DOI [DOI 10.1145/1180639.1180824, 10.1145/1180639.1180824]
   Zhang DW, 2022, IEEE T PATTERN ANAL, V44, P5866, DOI 10.1109/TPAMI.2021.3074313
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649
   Zhang DW, 2017, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2017.436
   Zhang J, 2018, PROC CVPR IEEE, P9029, DOI 10.1109/CVPR.2018.00941
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang P, 2017, NEUROCOMPUTING, V257, P115, DOI 10.1016/j.neucom.2016.10.073
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhuge MC, 2023, IEEE T PATTERN ANAL, V45, P3738, DOI 10.1109/TPAMI.2022.3179526
NR 64
TC 4
Z9 4
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104536
DI 10.1016/j.imavis.2022.104536
EA AUG 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5A4KL
UT WOS:000862857600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, YZ
   Huang, JJ
   Zhu, Z
   Long, XL
   Gu, QY
AF Chen, Yunze
   Huang, Junjie
   Zhu, Zheng
   Long, Xianlei
   Gu, Qingyi
TI Boosting semi-supervised face recognition with raw faces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Artificial intelligence; Face recognition; Semi -supervised learning;
   Clustering
AB Deep facial recognition benefits significantly from large-scale training data; however, the bottleneck of high la-beling costs persists. Therefore, to reduce the labeling costs, it is desirable to train a model using limited labeled data and abundant unlabeled data (i.e., semi-supervised learning). However, existing semi-supervised learning methods present two primary challenges: (1) The possibility of identity overlaps between the unlabeled and la-beled data. These overlaps can affect the correctness of pseudo-labels of the unlabeled set. (2) Different pseudo -labels generated by the clustering algorithm may belong to the same individual (i.e., over-decomposition prob-lem). Thus, in this study, instead of experimenting with non-overlapping conditions, we apply smooth labels to exploit the potential of those samples that are similar to the identities in the labeled set. For samples that are not similar to the labeled set, we introduce a dual clustering strategy to remedy the over-decomposition prob-lem caused by single clustering. With the upgraded semi-supervised framework, we recycle the discarded samples during purification of MS-Celeb-1 M (MS1M) to further scale up the training set, which offers a consid-erable performance boost of 94.39% on the IJB-C dataset.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Chen, Yunze; Long, Xianlei; Gu, Qingyi] Chinese Acad Sci Beijing, Ctr Precis Sensing & Control, Inst Automat, Beijing, Peoples R China.
   [Chen, Yunze; Long, Xianlei] Univ Chinese Acad Sci Beijing, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Huang, Junjie] XForward AI Technol Co Ltd, Beijing, Peoples R China.
   [Zhu, Zheng] Tsinghua Univ, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Tsinghua University
RP Gu, QY (corresponding author), Chinese Acad Sci Beijing, Ctr Precis Sensing & Control, Inst Automat, Beijing, Peoples R China.
EM qingyi.gu@ia.ac.cn
RI Gu, Qingyi/J-6290-2016; Long, Xianlei/HGA-5811-2022; Huang,
   Junjie/U-1939-2018
OI Long, Xianlei/0000-0002-2623-8768; 
FU National Natural Science Foundation of China [61673376]
FX Acknowledgements This work is supported in part by the National Natural
   Science Foundation of China under Grants 61673376.
CR Cao JJ, 2018, IEEE IMAGE PROC, P2406, DOI 10.1109/ICIP.2018.8451704
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng JK, 2019, IEEE INT CONF COMP V, P2638, DOI 10.1109/ICCVW.2019.00322
   Deng Jiankang, COMPUTER VISION PATT, P5203
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G.B., 2008, WORKSH FAC REAL LIF
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Kang BN, 2019, IEEE I CONF COMP VIS, P5471, DOI 10.1109/ICCV.2019.00557
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Kingma Diederik P., 2015, P 3 INT C LEARN
   Lei Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13366, DOI 10.1109/CVPR42600.2020.01338
   Liu Q, 2020, IET COMPUT VIS, V14, P92, DOI 10.1049/iet-cvi.2019.0125
   Liu WY, 2017, PROC CVPR IEEE, P6738, DOI 10.1109/CVPR.2017.713
   Liu Y, 2018, LECT NOTES COMPUT SC, V11209, P72, DOI 10.1007/978-3-030-01228-1_5
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Qian N, 1999, NEURAL NETWORKS, V12, P145, DOI 10.1016/S0893-6080(98)00116-6
   Ranjan Rajeev, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P82, DOI 10.1109/TBIOM.2019.2908436
   RoyChowdhury Aruni, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P119, DOI 10.1007/978-3-030-58586-0_8
   Sengupta S, 2016, IEEE WINT CONF APPL
   Shi YC, 2019, IEEE I CONF COMP VIS, P6901, DOI 10.1109/ICCV.2019.00700
   Shi Yichun, COMPUTER VISION PATT, P2021
   Sohn K, 2017, IEEE I CONF COMP VIS, P5917, DOI 10.1109/ICCV.2017.630
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sutskever I., 2013, INT C MACHINE LEARNI
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wan JW, 2019, IEEE T INF FOREN SEC, V14, P1729, DOI 10.1109/TIFS.2018.2885252
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87
   Xie WD, 2018, LECT NOTES COMPUT SC, V11215, P811, DOI 10.1007/978-3-030-01252-6_48
   Yang JW, 2016, PROC CVPR IEEE, P5147, DOI 10.1109/CVPR.2016.556
   Yang L, 2019, PROC CVPR IEEE, P2293, DOI 10.1109/CVPR.2019.00240
   Yong Peng, 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8227, P148, DOI 10.1007/978-3-642-42042-9_19
   Yu HM, 2019, IEEE INT CONF COMP V, P2662, DOI 10.1109/ICCVW.2019.00325
   Zhan XH, 2018, LECT NOTES COMPUT SC, V11213, P576, DOI 10.1007/978-3-030-01240-3_35
   Zhang Q, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207042
   Zhang X, 2017, IEEE I CONF COMP VIS, P5419, DOI 10.1109/ICCV.2017.578
   Zhao J. Jidong, 2014, J INFORMAT COMPUTAT, V11, P6847
   Zhao XR, 2011, IEEE IMAGE PROC
NR 46
TC 3
Z9 3
U1 0
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2022
VL 125
AR 104512
DI 10.1016/j.imavis.2022.104512
EA JUL 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3Y7JW
UT WOS:000843898700005
DA 2024-07-18
ER

PT J
AU Shi, R
   Li, TX
   Yamaguchi, Y
AF Shi, Rui
   Li, Tianxing
   Yamaguchi, Yasushi
TI Output-targeted baseline for neuron attribution calculation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional neural networks; Network interpretability; Attribution
   methods; Shapley values
ID EXPLANATION
AB Attribution methods explaining a particular decision for a given convolutional neural network (CNN) have gained a lot of attention over the last few years. Among them, approximation methods of Shapley values are considered to be better ways of assigning attribution scores such that several desirable axioms are satisfied. Nevertheless, these attribution scores may still be misleading or inaccurate due to the inappropriate selection of a baseline which is necessary to apply Shapley values to CNNs. Previous baseline studies have focused on developing a ge-neric baseline selection method for all approximation methods; however, we find that designing a baseline under the essence of the selected approximation method itself produces better results than generic ones. With this ob-servation, we propose two primal baseline properties for Aumann-Shapley-based attributions and design a gen-eral objective function of generating a baseline iteratively by gradient descent. To increase efficiency, we further reduce the objective function into a quadratic optimization problem where the gradients only need to be calcu-lated once. We show that our method produces better attribution results than several state-of-the-art baseline selections and attribution methods on both qualitative and quantitative experiments.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Shi, Rui; Li, Tianxing] Beijing Univ Technol, Fac Informat Technol, Beijing 100124, Peoples R China.
   [Yamaguchi, Yasushi] Univ Tokyo, Dept Gen Syst Studies, Tokyo 1538902, Japan.
C3 Beijing University of Technology; University of Tokyo
RP Yamaguchi, Y (corresponding author), Univ Tokyo, Dept Gen Syst Studies, Tokyo 1538902, Japan.
EM yama@g.ecc.u-tokyo.ac.jp
RI Yamaguchi, Yasushi/S-5779-2019
OI YAMAGUCHI, Yasushi/0000-0003-0790-4144
FU Japan Society for the Promotion of Science (JSPS KAKENHI) [20H04203]
FX This research was partly supported by Japan Society for the Promotion of
   Science (JSPS KAKENHI) [grant number 20H04203] .
CR Ancona M., P INT C MACHINE LEAR, P272
   Ancona Marco, 2018, INT C LEARNING REPRE
   [Anonymous], 2014, WORKSHOP INT C LEARN
   Aumann RJ, 1974, Values of Non-Atomic Games
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Castro J, 2009, COMPUT OPER RES, V36, P1726, DOI 10.1016/j.cor.2008.04.004
   Chen H., 2021, EXPLAINABLE AI HEALT, P261
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dhamdhere Kedar, 2019, INT C LEARN REPR
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371
   Ghorbani Amirata, 2020, Adv. Neural Inf. Process. Syst.
   Guerrero-Gómez-Olmedo R, 2020, NEUROCOMPUTING, V381, P252, DOI 10.1016/j.neucom.2019.11.059
   Haug J, 2021, Arxiv, DOI arXiv:2101.00905
   Hohman F, 2020, IEEE T VIS COMPUT GR, V26, P1096, DOI 10.1109/TVCG.2019.2934659
   Hooker S, 2019, ADV NEUR IN, V32
   Izzo C, 2021, Arxiv, DOI arXiv:2006.04896
   Katzmann A, 2021, NEUROCOMPUTING, V458, P141, DOI 10.1016/j.neucom.2021.05.081
   Kingma DP., 2014, ADAM METHOD STOCHAST
   Kumar IE, 2020, PR MACH LEARN RES, V119
   Kurakin A, 2017, Arxiv, DOI arXiv:1611.01236
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lundberg S. M., 2017, ADV NEURAL INFORM PR, P4765
   Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008
   Ras G., 2018, Explainable and interpretable models in computer vision and machine learning, P19, DOI DOI 10.1007/978-3-319-98131-4_2
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Schulz K., 2020, P INT C LEARNING REP
   Shapley L.S., 1953, Contrib Theor Game, P307
   Shi R, 2020, COMPUT ELECTRON AGR, V169, DOI 10.1016/j.compag.2020.105214
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Shrikumar Avanti, 2016, arXiv, DOI DOI 10.48550/ARXIV.1605.01713
   Smilkov D, 2017, Arxiv, DOI [arXiv:1706.03825, DOI 10.48550/ARXIV.1706.03825]
   Strumbelj E, 2010, J MACH LEARN RES, V11, P1
   Sturmfels P, 2020, DISTILL, V5, pe22, DOI 10.23915/distill.00022.
   Sun Yi, 2011, P 12 ACM C ELECT COM, P177, DOI [10.1145/1993574.1993601, DOI 10.1145/1993574.1993601]
   Sundararajan M., 2020, INT C MACHINE LEARNI, P9269
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tomsett R, 2020, AAAI CONF ARTIF INTE, V34, P6021
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JM, 2018, INT J COMPUT VISION, V126, P1084, DOI 10.1007/s11263-017-1059-x
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 43
TC 3
Z9 3
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104516
DI 10.1016/j.imavis.2022.104516
EA JUL 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3F6VI
UT WOS:000830804100008
DA 2024-07-18
ER

PT J
AU Zhang, C
   Zou, YX
   Chen, G
   Gan, L
AF Zhang, Can
   Zou, Yuexian
   Chen, Guang
   Gan, Lei
TI EAR: Efficient action recognition with local-global temporal aggregation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Efficient action recognition; Local-global temporal aggregation; Motion
   representation; Persistence of appearance
ID MOTION REPRESENTATION
AB Temporal modeling in videos is crucial for action recognition. Traditionally, it involves feature aggregation for both local motion and global semantic. In this paper, we propose an Efficient Action Recognition network (EAR), which includes a Persistence of Appearance (PA) module anda Various-timescale Aggregation (VA) module for local and global temporal aggregations respectively. For local motion aggregation, instead of using the previ-ous time-consuming optical flow, our PA calculates pixel-wise differences in feature space as the motion repre-sentation, which is much more efficient (8196 fps vs. 8 fps in optical flow). Besides, to capture global semantic hints, we propose VA module which adaptively emphasizes expressive features and suppresses less informative ones across various timescales. Empowered by the local-global temporal aggregation, our EAR achieves compet-itive results on six challenging action recognition benchmarks at low FLOPs. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhang, Can; Zou, Yuexian; Chen, Guang; Gan, Lei] Peking Univ, Sch ECE, ADSPLAB, Shenzhen, Peoples R China.
   [Zou, Yuexian] Pengcheng Lab, Shenzhen, Peoples R China.
C3 Peking University
RP Zou, YX (corresponding author), Peking Univ, Sch ECE, ADSPLAB, Shenzhen, Peoples R China.
EM zhangcan@pku.edu.cn; zouyx@pku.edu.cn; guangchen@pku.edu.cn;
   ganlei@pku.edu.cn
OI Zhang, Can/0000-0001-9530-5218; CHen, Guang/0000-0002-7416-592X
FU National Natural Science Foundation of China (NSFC) [62176008]; IER
   foundation [HT-JD-CXY-201904]; Shenzhen Municipal Development and Reform
   Com-mission (Disciplinary Development Program for Data Science and
   Intel-ligent Computing)
FX This paper was partially supported by the National Natural Science
   Foundation of China (NSFC) 62176008, the IER foundation (No.
   HT-JD-CXY-201904) and Shenzhen Municipal Development and Reform
   Com-mission (Disciplinary Development Program for Data Science and
   Intel-ligent Computing) . Special acknowledgements are given to
   Aoto-PKUSZ Joint Lab for its support.
CR [Anonymous], 2017, ARXIV170400389
   [Anonymous], 2017, P GERM C PATT REC
   [Anonymous], 2018, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2018.2791180
   Bilen H, 2018, IEEE T PATTERN ANAL, V40, P2799, DOI 10.1109/TPAMI.2017.2769085
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Diba A, 2018, LECT NOTES COMPUT SC, V11208, P299, DOI 10.1007/978-3-030-01225-0_18
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heeseung Kwon, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P345, DOI 10.1007/978-3-030-58517-4_21
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huang WB, 2019, IEEE T IMAGE PROCESS, V28, P1773, DOI 10.1109/TIP.2018.2877936
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kay W., 2017, CORR ABS170506950
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kwon H., 2021, ARXIV PREPRINT ARXIV
   Lee M., 2018, P EUR C COMP VIS ECC
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu Z. Y., 2020, ARXIV PREPRINT ARXIV
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Liu ZY, 2020, AAAI CONF ARTIF INTE, V34, P11669
   Materzynska J, 2019, IEEE INT CONF COMP V, P2874, DOI 10.1109/ICCVW.2019.00349
   Ng JYH, 2018, IEEE WINT CONF APPL, P1606, DOI 10.1109/WACV.2018.00179
   Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ranjan A, 2017, PROC CVPR IEEE, P2720, DOI 10.1109/CVPR.2017.291
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song XL, 2020, IEEE T CIRC SYST VID, V30, P748, DOI 10.1109/TCSVT.2019.2896029
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang L., P IEEE CVF C COMP VI, P1895
   Wang L., 2016, P ECCV
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang C, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P500, DOI 10.1145/3343031.3350876
   Zhao Y, 2018, PROC CVPR IEEE, P6566, DOI 10.1109/CVPR.2018.00687
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 54
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104329
DI 10.1016/j.imavis.2021.104329
EA NOV 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WZ2LF
UT WOS:000719802700001
DA 2024-07-18
ER

PT J
AU Osman, I
   Eltantawy, A
   Shehata, MS
AF Osman, Islam
   Eltantawy, Agwad
   Shehata, Mohamed S.
TI Task-based parameter isolation for foreground segmentation without
   catastrophic forgetting using multi-scale region and edges fusion
   network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Foreground segmentation; Moving objects; Deep learning; Continual
   learning; Parameter isolation
ID OBJECT DETECTION; VIDEO
AB Foreground segmentation of moving objects is widely used in different computer vision applications; however, existing deep learning-based methods generally suffer from overall degraded F-measure performance. The two main sources that degrade the F-measure are under-segmentation and catastrophic forgetting. Under segmentation is the problem of misdetecting objects' fine details. The catastrophic forgetting problem occurs when training on a large number of video sequences that leads to forgetting information learned from early video sequences. This paper proposes a novel multi-scale region and edges fusion network with task-based parameter isolation (REFNet-TBPI) to overcome these two problems. The proposed method consists of a novel multi-scale region and edges fusion network (REFNet) to capture the moving objects' boundary details by extracting regions and boundary edges of each object at different feature scales and fusing them to produce high-detailed segmented objects. REFNet is trained using a novel continual learning technique called task based parameter isolation (TBPI) to overcome the catastrophic forgetting problem. The proposed method (REFNet-TBPI) is extensively evaluated on three benchmarks, namely CDnet2014, DAVIS2016, and SegTrack. By comparing REFNet-TBPI with current state-of-the-art methods, the proposed method outperforms the best reported state-of-the-art by 4.4% on average. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Osman, Islam; Eltantawy, Agwad; Shehata, Mohamed S.] Univ British Columbia, 3333 Univ Way, Kelowna, BC, Canada.
C3 University of British Columbia
RP Osman, I (corresponding author), Univ British Columbia, 3333 Univ Way, Kelowna, BC, Canada.
EM islam.osman@ubc.ca; Agwad.eltantawy@mun.ca; mohamed.sami.shehata@ubc.ca
RI Shehata, Mohamed S./AER-6269-2022
OI Shehata, Mohamed S./0000-0002-8464-8650
CR Akilan T, 2020, IEEE T INTELL TRANSP, V21, P4435, DOI 10.1109/TITS.2019.2940547
   Ali S, 2006, PROC SPIE, V6209, DOI 10.1117/12.667266
   [Anonymous], 2016, ARXIV E PRINTS
   [Anonymous], 2018, FOREGROUND SEGMENTAT
   Aslani S., 2013, INT J EL COMP ENG SY, V7, P1252
   Babaee M, 2018, PATTERN RECOGN, V76, P635, DOI 10.1016/j.patcog.2017.09.040
   Bao LC, 2018, PROC CVPR IEEE, P5977, DOI 10.1109/CVPR.2018.00626
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bianco S, 2017, IEEE T EVOLUT COMPUT, V21, P914, DOI 10.1109/TEVC.2017.2694160
   Braham M, 2017, IEEE IMAGE PROC, P4552, DOI 10.1109/ICIP.2017.8297144
   Braham M, 2016, INT CONF SYST SIGNAL, P113
   ElTantawy A, 2020, SIGNAL IMAGE VIDEO P, V14, P87, DOI 10.1007/s11760-019-01528-y
   Eltantawy A, 2019, IEEE T IMAGE PROCESS, V28, P5991, DOI 10.1109/TIP.2019.2923376
   ElTantawy A, 2019, IEEE T CIRC SYST VID, V29, P1672, DOI 10.1109/TCSVT.2018.2843761
   French R. M, 2006, Catastrophic Forgetting in Connectionist Networks
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Johnander J, 2019, PROC CVPR IEEE, P8945, DOI 10.1109/CVPR.2019.00916
   Khoreva A, 2019, INT J COMPUT VISION, V127, P1175, DOI 10.1007/s11263-019-01164-6
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee SH, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11050621
   Li FX, 2013, IEEE I CONF COMP VIS, P2192, DOI 10.1109/ICCV.2013.273
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li HF, 2019, IEEE I CONF COMP VIS, P7273, DOI 10.1109/ICCV.2019.00737
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Lopez-Paz David, 2017, CoRR
   Mallya A, 2018, PROC CVPR IEEE, P7765, DOI 10.1109/CVPR.2018.00810
   Maninis KK, 2019, IEEE T PATTERN ANAL, V41, P1515, DOI 10.1109/TPAMI.2018.2838670
   NAKAYA Y, 1994, IEEE T CIRC SYST VID, V4, P339, DOI 10.1109/76.305878
   Patil P.W., P IEEE CVF C COMP VI, P8149
   Pont-Tuset J., 2017, ARXIV170400675
   Pouzet Mathieu, 2014, Proceedings of the 11th International Conference on Informatics in Control, Automation and Robotics ICINCO 2014, P266
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Seoung Wug Oh, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P9225, DOI 10.1109/ICCV.2019.00932
   Shen H, 2013, CHINESE J AERONAUT, V26, P1211, DOI 10.1016/j.cja.2013.07.038
   St-Charles PL, 2015, IEEE WINT CONF APPL, P990, DOI 10.1109/WACV.2015.137
   St-Charles PL, 2015, IEEE T IMAGE PROCESS, V24, P359, DOI 10.1109/TIP.2014.2378053
   Tezcan MO, 2020, IEEE WINT CONF APPL, P2763, DOI [10.1109/WACV45572.2020.9093464, 10.1109/wacv45572.2020.9093464]
   Le TN, 2018, IEEE T IMAGE PROCESS, V27, P5002, DOI 10.1109/TIP.2018.2849860
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wang ZQ, 2019, IEEE I CONF COMP VIS, P3977, DOI 10.1109/ICCV.2019.00408
   Zhang L., P IEEE CVF INT C COM, P5582
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhuo T, 2020, IEEE T IMAGE PROCESS, V29, P237, DOI 10.1109/TIP.2019.2930152
NR 47
TC 7
Z9 7
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104248
DI 10.1016/j.imavis.2021.104248
EA JUL 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900005
DA 2024-07-18
ER

PT J
AU Seha, SNA
   Hatzinakos, D
   Zandi, AS
   Comeau, FJE
AF Seha, Sherif Nagib Abbas
   Hatzinakos, Dimitrios
   Zandi, Ali Shahidi
   Comeau, Felix J. E.
TI Improving eye movement biometrics in low frame rate eye-tracking devices
   using periocular and eye blinking features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Eye movements; Eye blinking; Periocular features; Multi-modal
   biometrics; Continuous driver authentication
AB In this paper, the biometric potential of eye movement patterns extracted from low frame rate eye-tracking devices is evaluated. Also, possible improvement in recognition rates is investigated using other static and dynamic features extracted from the eyes including eye blinking patterns and periocular shape features. These modalities can be applicable for specific biometric applications like continuous driver authentication for law enforcement. For this purpose, two databases are collected with two low frame rate eye-tracking systems that capture the eye movements. Data were recorded from 55 participants while watching real driving sessions. For eye gaze, features from fixations and saccades are extracted separately including duration, amplitude, and statistical features. For eye blinking, features from the blinking pattern, its speed, acceleration, and power per unit mass profiles are extracted. Periocular features include the eye-opening height, width, axial ratio, etc. Each modality is evaluated first, then, these modalities are combined in a multi-modal setup for performance improvement. While each trait achieved a moderate performance in a single-modality setup, the fusion of the static and the dynamic features from the eye provides a great performance improvement up to 98.5% recognition rate and 0% error rate in both modes of authentication. Although the single-modality setup might not be secure enough, the fusion of these traits achieves high levels of identification making these traits effective for continuous driver authentication application.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Seha, Sherif Nagib Abbas; Hatzinakos, Dimitrios] Univ Toronto, Elect & Comp Engn Dept, Toronto, ON, Canada.
   [Zandi, Ali Shahidi; Comeau, Felix J. E.] Alcohol Countermeasure Syst ACS Corp, Toronto, ON, Canada.
C3 University of Toronto
RP Seha, SNA (corresponding author), Univ Toronto, Elect & Comp Engn Dept, Toronto, ON, Canada.
EM sherif.seha@mail.utoronto.ca
FU Natural Sciences and Engineering Research Council (NSERC) of Canada;
   Royal Bank of Canada (RBC) [503492, 503493]; Alcohol Countermeasure
   Systems (ACS) Corp.
FX The authors would like to thank the Natural Sciences and Engineering
   Research Council (NSERC) of Canada, Alcohol Countermeasure Systems (ACS)
   Corp., and the Royal Bank of Canada (RBC) for their support (Grant
   numbers 503492 and 503493) . Also, the authors would like to thank the
   participants who agreed to do the experiment.
CR Abbas SN, 2017, SIGNAL PROC SEC TEC, P121, DOI 10.1007/978-3-319-47301-7_5
   Abe N., 2016, 2016 INT C BIOM SPEC, DOI [10.1109/biosig.2016.7736903, DOI 10.1109/BIOSIG.2016.7736903]
   Abo-Zahhad M, 2016, PATTERN RECOGN LETT, V82, P216, DOI 10.1016/j.patrec.2015.07.034
   Abo-Zahhad M, 2015, IEEE SIGNAL PROC LET, V22, P876, DOI 10.1109/LSP.2014.2374338
   Burton A, 2016, INT CONF NETW SER, P388, DOI 10.1109/CNSM.2016.7818453
   Cappelli R., 2007, Biom. Technol. Today, V15, P7, DOI DOI 10.1016/S0969-4765(07)70140-6
   Espinosa J, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196125
   Ezzini S, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-018-0118-7
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally-Herrero J, 2006, CAR C SECUR, P130, DOI 10.1109/CCST.2006.313441
   Galdi Chiara, 2019, BIOMETRICS BIOMEDICA, P171
   George A, 2016, PATTERN RECOGN LETT, V82, P207, DOI 10.1016/j.patrec.2015.11.020
   Haghighat M, 2016, EXPERT SYST APPL, V47, P23, DOI 10.1016/j.eswa.2015.10.047
   Kasprowski P, 2004, LECT NOTES COMPUT SC, V3087, P248
   Kasprowski P, 2016, SMART INNOV SYST TEC, V57, P83, DOI 10.1007/978-3-319-39627-9_8
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Komogortsev Oleg V, 2015, BIOM THEOR APPL SYST, P1
   Konstantopoulos P, 2010, ACCIDENT ANAL PREV, V42, P827, DOI 10.1016/j.aap.2009.09.022
   Miyajima C, 2007, P IEEE, V95, P427, DOI 10.1109/JPROC.2006.888405
   Olsen A., 2012, TOBII I VT FIXATION
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Rayner K., 2012, Eye movements and visual cognition: Scene perception and reading
   Rigas I, 2017, J EYE MOVEMENT RES, V11, DOI 10.16910/jemr.11.1.3
   Rigas I, 2017, IMAGE VISION COMPUT, V58, P129, DOI 10.1016/j.imavis.2016.03.014
   Rigas I, 2016, ACM T APPL PERCEPT, V13, DOI 10.1145/2842614
   Salvucci DD, 2000, 2000 S EYE TRACKING, P71, DOI [10.1145/355017.355028, DOI 10.1145/355017.355028]
   Seha S, 2019, INT CONF ACOUST SPEE, P2562, DOI 10.1109/ICASSP.2019.8683757
   Soukupova T., 2016, 21 COMP VIS WINT WOR, P1
   Sun QS, 2005, PATTERN RECOGN, V38, P2437, DOI 10.1016/j.patcog.2004.12.013
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P13, DOI 10.1016/B978-1-59749-272-0.50004-9
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Wahab A, 2009, IEEE T NEURAL NETWOR, V20, P563, DOI 10.1109/TNN.2008.2007906
   Wu QJ, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020335
   Xun YJ, 2020, IEEE T IND INFORM, V16, P1417, DOI 10.1109/TII.2019.2946626
NR 35
TC 8
Z9 9
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104124
DI 10.1016/j.imavis.2021.104124
EA MAR 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600009
DA 2024-07-18
ER

PT J
AU Jing, WP
   Lin, JB
   Wang, HH
AF Jing, Weipeng
   Lin, Jingbo
   Wang, Huihui
TI Building NAS: Automatic designation of efficient neural architectures
   for building extraction in high-resolution aerial images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional neural network; Deep learning; Aerial images; Semantic
   segmentation; Neural architecture search
AB Building extraction, which is a fundamental task in the community of remote sensing image analysis, has been extensively applied in various applications related to smart cities. Due to the complicated background information in urban areas, how to extract building footprints from high-resolution aerial images is challenging. The recent achievements of deep learning have shed light on building extraction and other remote sensing domain tasks. However, the heavy consumption of computational resources and the design of the neural architectures became the biggest bottleneck of utilizing deep learning techniques to improve the performance. In this work, we developed a Neural Architecture Search (NAS) algorithm, dubbed BuildingNAS, for building extraction from high-resolution aerial images. In particular, we built an efficient candidate operation set upon Separable Factorized Residual Blocks as our cell-level search space. Different from previous NAS in semantic segmentation tasks, we employed the hierarchical search space and proposed the Single-Path Sampling strategy to eliminate excessive GPU memory comsumption in searching process. In addition, we proposed an entropy regularized objective for the optimization of architecture parameters. As the result, the larger batch size can be adopted in the whole pipeline to accelerate the searching process, and make the resulted architecturemore stable and accurate. We evaluated our proposed algorithm inWHUBuilding Dataset, the derived network achieved mIoU of 86.95% with only 2.05G FLOPs and 3.10Mparameters. The comparison results demonstrate that the network discovered by our algorithm can achieve great efficiency-accuracy trade-off. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Jing, Weipeng; Lin, Jingbo] Northeast Forestry Univ, Key Lab Forestry Data Sci & Cloud Comp State Fore, Harbin 150040, Hlj, Peoples R China.
   [Wang, Huihui] Jacksonville Univ, Dept Engn, 2800 Univ Blvd N, Jacksonville, FL 32211 USA.
C3 Northeast Forestry University - China; Jacksonville University
RP Jing, WP (corresponding author), Northeast Forestry Univ, Key Lab Forestry Data Sci & Cloud Comp State Fore, Harbin 150040, Hlj, Peoples R China.
EM jwp@nefu.edu.cn; hwang1@ju.edu
RI Wang, Huihui/ABB-6935-2021
OI Wang, Huihui/0000-0002-4098-5313
FU National Natural Science Foundation of China [31770768]; Heilongjiang
   Province Applied Technology Research and Development Program Major
   Project [GA18B301]; China State Forestry Administration Forestry
   Industry Public Welfare Project [201504307]
FX This work is supported by National Natural Science Foundation of China
   (31770768), Heilongjiang Province Applied Technology Research and
   Development Program Major Project (GA18B301) and China State Forestry
   Administration Forestry Industry Public Welfare Project (201504307).
CR Alvarez J.M., 2016, ABS160605426 ARXIV
   [Anonymous], INT C LEARN REPR ICL
   [Anonymous], 2017, INT C LEARNING REPRE
   Bello I., 2017, INT C MACHINE LEARNI, V70, P459
   Brock A., 2018, INT C LEARN REPR REP
   Chen LC, 2018, ADV NEUR IN, V31
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ji SP, 2019, IEEE T GEOSCI REMOTE, V57, P574, DOI 10.1109/TGRS.2018.2858817
   Kim JH, 2019, IEEE GEOSCI REMOTE S, V16, P115, DOI 10.1109/LGRS.2018.2868880
   Li G., 2019, ARXIV191200195
   Lin JB, 2019, IEEE ACCESS, V7, P54285, DOI 10.1109/ACCESS.2019.2912822
   Liu C., 2019, IEEE C COMP VIS PATT
   Liu H., 2018, INT C LEARNING REPRE
   Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3
   Nekrasov V., 2019, IEEE C COMP VIS PATT
   Paszke A., 2017, NAT COMMUN, P1, DOI DOI 10.1038/S41467-016-0009-6
   Pham H, 2018, PR MACH LEARN RES, V80
   Real E., 2017, Large-scale evolution of image classifiers, V70, P2902
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruder S., ARXIV160904747
   Saxena Shreyas., 2016, NIPS
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Weng Y, 2019, IEEE ACCESS, V7, P44247, DOI 10.1109/ACCESS.2019.2908991
   Wu GM, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10030407
   Xie X., 2019, ABS191110511 ARXIV
   Zhang Y., 2019, IEEE C COMP VIS PATT
   Zhang ZX, 2018, IEEE GEOSCI REMOTE S, V15, P749, DOI 10.1109/LGRS.2018.2802944
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 34
TC 6
Z9 6
U1 4
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104025
DI 10.1016/j.imavis.2020.104025
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000014
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, LB
   Chen, BB
   Xu, P
   Ren, HL
   Fang, XY
   Wan, SH
AF Wang, Linbo
   Chen, Binbin
   Xu, Peng
   Ren, Honglong
   Fang, Xianyong
   Wan, Shaohua
TI Geometry consistency aware confidence evaluation for feature matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature matching; Topological structure; Matching confidence
ID GRAPH
AB Most existing approaches prunewrong matches via estimating an image transformation or solving a graph-based global matching optimization problem, which usually suffers fromvarying local transformations and outliers. Inspired by the insight that neighboring truematches usually hold consistent local topological structures across images, in this paper we propose a new approach to evaluate the confidence of each putative match based on how well its two keypoints can predict each other by exploring the geometric constraintwith its neighboringmatches. With the evaluation, a two- stage approach combining recursively false match pruning and correct match incrementing is presented to obtain the reliable matches. Experiments on various image pairs demonstrate that our approach can conduct robust feature matching in challenging conditions and outperform state-of-theart approaches. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Wang, Linbo; Chen, Binbin; Xu, Peng; Ren, Honglong; Fang, Xianyong] Anhui Univ, Sch Comp Sci & Technol, MOE Key Lab Intelligent Comp & Signal Proc, Hefei 230039, Peoples R China.
   [Wan, Shaohua] Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan, Peoples R China.
C3 Anhui University; Zhongnan University of Economics & Law
RP Wan, SH (corresponding author), Zhongnan Univ Econ & Law, Sch Informat & Safety Engn, Wuhan, Peoples R China.
EM shwanhust@zuel.edu.cn
RI LIN, WANG/JWA-3182-2024; 陈, 彬彬/I-1913-2014; wang, lili/HDL-7210-2022;
   Wan, Shaohua/L-8492-2019; wang, lin/HZK-4145-2023; wang,
   lili/HZJ-5080-2023; Wan, Shaohua/B-9243-2014
OI Xu, Peng/0009-0002-2523-0614; Wang, Linbo/0000-0001-7276-7065; Wan,
   Shaohua/0000-0001-7013-9081
FU National Natural Science Foundation of China [61502005]; Anhui Science
   Foundation [1608085QF129]; Key Programs for Science and Technology
   Development of Anhui Province [1604d0802004]
FX This work is co-supported by the National Natural Science Foundation of
   China (61502005), Anhui Science Foundation (1608085QF129), Key Programs
   for Science and Technology Development of Anhui Province (1604d0802004).
CR Adamczewski K, 2015, IEEE I CONF COMP VIS, P109, DOI 10.1109/ICCV.2015.21
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2017, COMPUTER VISION PATT
   Barath D, 2019, PROC CVPR IEEE, P10189, DOI 10.1109/CVPR.2019.01044
   Barath D, 2018, PROC CVPR IEEE, P6733, DOI 10.1109/CVPR.2018.00704
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bian JW, 2017, PROC CVPR IEEE, P2828, DOI 10.1109/CVPR.2017.302
   Chen HY, 2013, PROC CVPR IEEE, P2762, DOI 10.1109/CVPR.2013.356
   Cho MS, 2008, LECT NOTES COMPUT SC, V5305, P144
   Cho MS, 2012, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2012.6247727
   Cho M, 2012, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2012.6247701
   Cho M, 2009, IEEE I CONF COMP VIS, P1280, DOI 10.1109/ICCV.2009.5459322
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao Z, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3377876
   Gao Z, 2020, NEURAL NETWORKS, V125, P290, DOI 10.1016/j.neunet.2020.02.017
   Jiang XY, 2020, IEEE T IMAGE PROCESS, V29, P736, DOI 10.1109/TIP.2019.2934572
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Li L, 2020, NEURAL COMPUT APPL, V32, P4387, DOI 10.1007/s00521-018-3865-7
   Lin WY, 2018, IEEE T PATTERN ANAL, V40, P34, DOI 10.1109/TPAMI.2017.2652468
   Liu HR, 2013, IEEE T PATTERN ANAL, V35, P2131, DOI 10.1109/TPAMI.2013.16
   Liu YH, 2016, PATTERN RECOGN, V60, P849, DOI 10.1016/j.patcog.2016.07.011
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma JY, 2019, IEEE T IMAGE PROCESS, V28, P4045, DOI 10.1109/TIP.2019.2906490
   Ma JY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4492
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Rocco I, 2017, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2017.12
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schönberger JL, 2017, PROC CVPR IEEE, P6959, DOI 10.1109/CVPR.2017.736
   Suh YM, 2015, PROC CVPR IEEE, P5070, DOI 10.1109/CVPR.2015.7299142
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Torresani L, 2013, IEEE T PATTERN ANAL, V35, P259, DOI 10.1109/TPAMI.2012.105
   Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596
   Wan SH, 2020, IEEE T MULTIMEDIA, V22, P1756, DOI 10.1109/TMM.2020.2976573
   Wang LB, 2015, IEEE T IMAGE PROCESS, V24, P5442, DOI 10.1109/TIP.2015.2481701
   Wu Xiaomeng, 2015, P BRIT MACH VIS C, P25
   Yi KM, 2018, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2018.00282
   Yi KM, 2016, LECT NOTES COMPUT SC, V9910, P467, DOI 10.1007/978-3-319-46466-4_28
   Zagoruyko S, 2015, PROC CVPR IEEE, P4353, DOI 10.1109/CVPR.2015.7299064
   Zanfir A, 2018, PROC CVPR IEEE, P2684, DOI 10.1109/CVPR.2018.00284
   Zhang W, 2012, LECT NOTES COMPUT SC, V7572, P428, DOI 10.1007/978-3-642-33718-5_31
   Zhang Z, 2019, IEEE I CONF COMP VIS, P5086, DOI 10.1109/ICCV.2019.00519
   Zhao C, 2019, PROC CVPR IEEE, P215, DOI 10.1109/CVPR.2019.00030
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
NR 47
TC 8
Z9 8
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 103984
DI 10.1016/j.imavis.2020.103984
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000002
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Shu, QY
   Fu, KR
   Wei, PC
   Zhan, J
AF Zhao, Yu
   Shu, Qiaoyuan
   Fu, Keren
   Wei, Pengcheng
   Zhan, Jian
TI Joint patch and instance discrimination learning for unsupervised person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised person re-identification; Large-scale person re-ID;
   Instance-wise supervision; Joint training
ID ATTRIBUTE; NETWORK
AB The unsupervised person re-identification (re-ID) has become increasingly significant in the community because it is more scalable than the supervisedmethodwhen dealingwith the large-scale person re-ID. However, it is difficult to learn discriminative enough features from across-camera images without labelling information. To address this problem, we propose a joint patch and instance discrimination learning (JPIL) framework for the unsupervised person re-ID. The JPIL framework exploits a patch feature extraction model to generate patchwise features for each input image. Then the patch discrimination learning (PDL) loss is designed to guide the model to mine the patch-wise discriminative information from unlabelled person image patches. On the other hand, we introduce the instance discrimination learning (IDL) loss to provide instance-wise supervision. The IDL loss aims to pull features of the same instance under different transformations closer and push features belonging to different instances away. Finally, we combine the PDL and IDL loss to apply the joint training. Extensive experiments on Market-1501 and DukeMTMC-reID datasets demonstrate the effectiveness of the proposed method for unsupervised person re-ID. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Zhao, Yu; Shu, Qiaoyuan; Wei, Pengcheng; Zhan, Jian] Chongqing Univ Educ, Sch Math & Informat Engn, Chongqing 400065, Peoples R China.
   [Fu, Keren] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Sichuan, Peoples R China.
C3 Chongqing University of Education; Sichuan University
RP Zhao, Y (corresponding author), Chongqing Univ Educ, Sch Math & Informat Engn, Chongqing 400065, Peoples R China.
EM zhaoyunccq@foxmail.com
RI wei, peng/IVH-1711-2023; Fu, Keren/HPG-4742-2023
OI Fu, Keren/0000-0002-3195-2077
FU Scientific Research Project of Chongqing University of Education
   [KY201923C]; Project of Science and Technology Research Program of
   Chongqing Education Commission of China [KJZDK201801601]; Chongqing Big
   Data Engineering Laboratory for Children
FX This work was supported by the Scientific Research Project of Chongqing
   University of Education (Grant No. KY201923C), the Project of Science
   and Technology Research Program of Chongqing Education Commission of
   China (Grant No. KJZDK201801601), and Chongqing Big Data Engineering
   Laboratory for Children.
CR Bak S, 2018, LECT NOTES COMPUT SC, V11217, P193, DOI 10.1007/978-3-030-01261-8_12
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Dean J., 2015, NIPS DEEP LEARNING R
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Donahue J., 2016, ARXIV160509782
   Dumoulin Vincent, 2016, ARXIV160600704
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Jaderberg M, 2015, ADV NEUR IN, V28
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Li MX, 2018, LECT NOTES COMPUT SC, V11208, P772, DOI 10.1007/978-3-030-01225-0_45
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao R., 2016, Proceedings of Neural Information Processing Systems, P5076
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu J, 2016, BIOMED SIGNAL PROCES, V24, P19, DOI 10.1016/j.bspc.2015.09.004
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32
   Noroozi M, 2017, IEEE I CONF COMP VIS, P5899, DOI 10.1109/ICCV.2017.628
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Ranzato M, 2007, PROC CVPR IEEE, P1429
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Subramaniam A, 2016, ADV NEUR IN, V29
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Sutskever I., 2013, INT C MACHINE LEARNI, P1139
   Tang YC, 2012, PROC CVPR IEEE, P2264, DOI 10.1109/CVPR.2012.6247936
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Vincent E, 2008, INT CONF ACOUST SPEE, P109, DOI 10.1109/ICASSP.2008.4517558
   Wang C, 2020, NEUROCOMPUTING, V382, P64, DOI 10.1016/j.neucom.2019.11.062
   Wang F, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1041, DOI 10.1145/3123266.3123359
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu G, 2020, ROU S CONT CHIN PHIL, P1
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xiao T, 2016, PROC CVPR IEEE, P1249, DOI 10.1109/CVPR.2016.140
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   Yang WX, 2019, NEUROCOMPUTING, V340, P125, DOI 10.1016/j.neucom.2019.02.042
   Ye M, 2019, PROC CVPR IEEE, P6203, DOI 10.1109/CVPR.2019.00637
   Ye M, 2019, IEEE T IMAGE PROCESS, V28, P2976, DOI 10.1109/TIP.2019.2893066
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu HX, 2020, IEEE T PATTERN ANAL, V42, P956, DOI 10.1109/TPAMI.2018.2886878
   Yu HX, 2017, IEEE I CONF COMP VIS, P994, DOI 10.1109/ICCV.2017.113
   Zeng KW, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103913
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang X, 2017, IEEE I CONF COMP VIS, P4605, DOI 10.1109/ICCV.2017.492
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhong Z, 2019, IEEE T IMAGE PROCESS, V28, P1176, DOI 10.1109/TIP.2018.2874313
NR 70
TC 6
Z9 6
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104000
DI 10.1016/j.imavis.2020.104000
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000008
OA Bronze
DA 2024-07-18
ER

PT J
AU Zhou, XF
   Wen, HF
   Shi, R
   Yin, HB
   Yan, CG
AF Zhou, Xiaofei
   Wen, Hongfa
   Shi, Ran
   Yin, Haibing
   Yan, Chenggang
TI Depth-guided saliency detection via boundary information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RGBD; Saliency; Boundary; Depth
ID OBJECT DETECTION; FUSION; FEATURES
AB Existing efforts of saliency detection have achieved excellent performance in RGB images, thus to sufficiently exploit existing RGB saliency models and further do some extensions on them, we can transfer existing RGB saliency models to the similar research field, i.e. RGBD saliency detection, by introducing depth cues. Here, we construct a novel RGBD saliencymodel upon an existing RGB saliencymodel. To be specific, firstly, ourmodel deploys a depth-guided module to guide the deep features extraction, where the multi-level deep depth features obtained from depth branch are embedded into the backbone network and integrate with multi-level deep RGB features. Secondly, to further promote the performance of our model, we devise a boundary constraintmodule to elevate the detection accuracy, where the boundary information is compounded by the low-level deep RGB and depth features. Comprehensive experiments are performed on five public RGBD saliency detection datasets, and the experimental results clearly demonstrate the effectiveness and superiority of our modelwhen compared with the state-of-the-art RGBD saliency models. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Zhou, Xiaofei; Wen, Hongfa; Yan, Chenggang] Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
   [Shi, Ran] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Nanjing 210094, Peoples R China.
   [Yin, Haibing] Hangzhou Dianzi Univ, Sch Commun Engn, Hangzhou 310018, Peoples R China.
C3 Hangzhou Dianzi University; Nanjing University of Science & Technology;
   Hangzhou Dianzi University
RP Yan, CG (corresponding author), Hangzhou Dianzi Univ, Sch Automat, Hangzhou 310018, Peoples R China.
EM zxforchid@hdu.edu.cn; cgyan@hdu.edu.cn
FU National Natural Science Foundation of China [61901145, 61801219,
   61972123, 61931008]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61901145, Grant 61801219, Grant
   61972123, Grant 61931008.
CR Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen H, 2020, IEEE T CYBERNETICS, V50, P4808, DOI 10.1109/TCYB.2019.2934986
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen YX, 2014, INTERNATIONAL CONFERENCE ON MECHANICS AND MATERIALS ENGINEERING (ICMME 2014), P23
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P2625, DOI 10.1109/TIP.2014.2305100
   Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Guo J., 2016, P ANN REL MAINT S, P1, DOI DOI 10.1109/RAMS.2016.7448068
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Ju R, 2015, SIGNAL PROCESS-IMAGE, V38, P115, DOI 10.1016/j.image.2015.07.002
   Kingma D.P., 2011, INT C LEARN REPR
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2014, INT J COMPUT VISION, V107, P239, DOI 10.1007/s11263-013-0678-0
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Liu C, 2010, IMAGE VISION COMPUT, V28, P825, DOI 10.1016/j.imavis.2009.07.009
   Liu D, 2019, IEEE IMAGE PROC, P3925, DOI [10.1109/icip.2019.8803653, 10.1109/ICIP.2019.8803653]
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu ZY, 2019, NEUROCOMPUTING, V363, P46, DOI 10.1016/j.neucom.2019.07.012
   Liu Z, 2014, IEEE T IMAGE PROCESS, V23, P1937, DOI 10.1109/TIP.2014.2307434
   Mahendran A, 2015, PROC CVPR IEEE, P5188, DOI 10.1109/CVPR.2015.7299155
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Mukherjee P, 2017, IMAGE VISION COMPUT, V61, P82, DOI 10.1016/j.imavis.2017.02.008
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Shigematsu R, 2017, IEEE INT CONF COMP V, P2749, DOI 10.1109/ICCVW.2017.323
   Simonyan K., 2014, 14091556 ARXIV
   Song HK, 2017, IEEE T IMAGE PROCESS, V26, P4204, DOI 10.1109/TIP.2017.2711277
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wen HF, 2019, J VIS COMMUN IMAGE R, V62, P279, DOI 10.1016/j.jvcir.2019.05.018
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xu XY, 2017, PATTERN RECOGN, V72, P300, DOI 10.1016/j.patcog.2017.07.026
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhou XF, 2018, IEEE T MULTIMEDIA, V20, P2993, DOI 10.1109/TMM.2018.2829605
   Zhu CB, 2019, IEEE INT CON MULTI, P199, DOI 10.1109/ICME.2019.00042
   Zhu CB, 2017, IEEE INT CONF COMP V, P1509, DOI 10.1109/ICCVW.2017.178
NR 57
TC 6
Z9 6
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104001
DI 10.1016/j.imavis.2020.104001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000009
DA 2024-07-18
ER

PT J
AU Perrot, R
   Bourdon, P
   Helbert, D
AF Perrot, Romuald
   Bourdon, Pascal
   Helbert, David
TI Implementing cascaded regression tree-based face landmarking: An
   in-depth overview
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face landmarking; Cascaded regression; Regression trees; Temporal
   tracking
ID ALIGNMENT
AB Face landmarking, defined as the detection of fiducial points on faces, has received a lot of attention over the last two decades within the computer vision community. While research literature documents major advances using state-of-art deep convolutional neural networks, earlier cascaded regression tree-based approaches remain a relevant alternative for low-cost, low-power embedded systems. Yet, from a practical point of view, their implementation and parametrization can be a difficult and tedious process. In this paper, we provide the readers with insights and advice on how to design a successful face landmarking system using a cascade of regression trees. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Perrot, Romuald; Bourdon, Pascal; Helbert, David] Univ Poitiers, XLIM, CNRS, UMR 7252, F-86000 Poitiers, France.
   [Bourdon, Pascal; Helbert, David] Univ Poitiers, Common Lab CNRS Siemens, I3M, Poitiers, France.
   [Bourdon, Pascal; Helbert, David] Hosp Poitiers, Poitiers, France.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Engineering & Systems Sciences (INSIS); Universite de Poitiers;
   Universite de Poitiers; Universite de Poitiers
RP Helbert, D (corresponding author), Univ Poitiers, XLIM, CNRS, UMR 7252, F-86000 Poitiers, France.
EM David.Helbert@univ-poitiers.fr
OI Helbert, David/0000-0001-6518-1509
CR [Anonymous], 2006, BMVC
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Breiman L., 2001, Mach. Learn., V45, P5
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Deng JK, 2016, IMAGE VISION COMPUT, V47, P19, DOI 10.1016/j.imavis.2015.11.005
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Fan HQ, 2016, IMAGE VISION COMPUT, V47, P27, DOI 10.1016/j.imavis.2015.11.004
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Hasan MK, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P362, DOI 10.1109/ICCVW.2013.55
   Huang G.B., 2008, PROC WORKSHOP FACES
   Jaiswal S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P370, DOI 10.1109/ICCVW.2013.56
   Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142
   Jin X., ABS160804188 CORR
   Jourabloo A, 2017, IEEE I CONF COMP VIS, P3219, DOI 10.1109/ICCV.2017.347
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Milborrow S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P378, DOI 10.1109/ICCVW.2013.57
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Sánchez-Lozano E, 2018, IEEE T PATTERN ANAL, V40, P2037, DOI 10.1109/TPAMI.2017.2745568
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang N., ABS14101037 CORR
   Wang NN, 2018, NEUROCOMPUTING, V275, P50, DOI 10.1016/j.neucom.2017.05.013
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Xiong XH, 2015, PROC CVPR IEEE, P2664, DOI 10.1109/CVPR.2015.7298882
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126
   Yang H., ABS150904954 CORR
   Yang H., ABS151105049 CORR
   Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 46
TC 1
Z9 1
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103976
DI 10.1016/j.imavis.2020.103976
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700009
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Ye, XY
   Hong, DS
   Chen, HH
   Hsiao, PY
   Fu, LC
AF Ye, Xing-Yu
   Hong, Dza-Shiang
   Chen, Hung-Hao
   Hsiao, Pei-Yung
   Fu, Li-Chen
TI A two-stage real-time YOLOv2-based road marking detector with
   lightweight spatial transformation-invariant classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Road marking; Spatial transform; Real-time object
   detection; Object classification
ID BASE-LINE
AB In recent years, Autonomous Driving Systems (ADS) become more and more popular and reliable. Road markings are important for drivers and advanced driver assistance systems by better understanding the road environment. While the detection of road markings may suffer a lot from various illuminations, weather conditions and angles of view, most traditional road marking detection methods use fixed threshold to detect road markings, which is not robust enough to handle various situations in the real world. To deal with this problem, some deep learning-based real-time detection frameworks such as Single Shot Detector (SSD) and You Only Look Once (YOLO) are suitable for this task. However, these deep learning-based methods are data-driven even while there is no public road marking dataset. Besides, these detection frameworks usually struggle with distorted road markings and balancing between the precision and recall. We propose a two-stage YOLOv2-based network to tackle distorted road marking detection as well as to balance precision and recall. The proposed spatial transformer layer is able to handle the distorted road markings in the second stage, so as to achieve the improvement of precision. Our network is able to run at 58 FPS in a single GTX 1070 under diverse circumstances. Furthermore, we present a dataset for the public use of road marking detection tasks, which consists of 11,800 high-resolution images captured under different weather conditions. Specifically, the images are manually annotated into 13 classes with bounding boxes. We empirically demonstrate both mean average precision ( mAP) and detection speed of our system over several baseline models. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Ye, Xing-Yu; Hong, Dza-Shiang; Chen, Hung-Hao; Fu, Li-Chen] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Hsiao, Pei-Yung] Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
C3 National Taiwan University; National University Kaohsiung
RP Hsiao, PY (corresponding author), Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
EM pyhsiao@nuk.edu.tw
FU Ministry of Science and Technology (MOST), Taiwan ROC
   [108-2634-F-002-016, 108-2634-F-002-017, 108-2221-E-390-019-MY3]; Center
   for AI AMP; Advanced Robotics, National Taiwan University; Joint
   Research Center for AI Technology under MOST; All Vista Healthcare under
   MOST
FX This work was partially sponsored by the Ministry of Science and
   Technology (MOST), Taiwan ROC, under Project 108-2634-F-002-016,
   108-2634-F-002-017, and 108-2221-E-390-019-MY3. This research was also
   supported in part by the Center for AI & Advanced Robotics, National
   Taiwan University and the Joint Research Center for AI Technology and
   All Vista Healthcare under MOST.
CR Ahmad T, 2017, IEEE INT VEH SYM, P1428, DOI 10.1109/IVS.2017.7995910
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2016, DARKNET OPEN SOURCE
   Bailo O, 2017, IEEE WINT CONF APPL, P760, DOI 10.1109/WACV.2017.90
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen HC, 2004, IEEE T INTELL TRANSP, V5, P329, DOI 10.1109/TITS.2004.837824
   Chen TR, 2015, IEEE INT VEH SYM, P617, DOI 10.1109/IVS.2015.7225753
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Huang GB, 2011, INT J MACH LEARN CYB, V2, P107, DOI 10.1007/s13042-011-0019-y
   Jaderberg M, 2015, ADV NEUR IN, V28
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Yann, Lenet-5, convolutional neural networks
   Lee S, 2017, IEEE I CONF COMP VIS, P1965, DOI 10.1109/ICCV.2017.215
   Liu W, 2015, IEEE INT VEH SYM, P41, DOI 10.1109/IVS.2015.7225660
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Ouerhani Y, 2017, PROC SPIE, V10395, DOI 10.1117/12.2273304
   Redmon J, 2017, P IEEE C COMP VIS PA, DOI DOI 10.48550/ARXIV.1612.08242
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suhr JK, 2015, IEEE INT VEH SYM, P186, DOI 10.1109/IVS.2015.7225684
   Sun ZL, 2014, NEUROCOMPUTING, V128, P153, DOI 10.1016/j.neucom.2012.11.057
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Toh KA, 2008, IEEE T PATTERN ANAL, V30, P658, DOI 10.1109/TPAMI.2007.70730
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vacek S., 2007, PREC EUR C MOB ROB E
   Wu T, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P25, DOI 10.1109/IVS.2012.6232144
   Zhou K, 2016, DESTECH TRANS COMP
   Zuiderveld K., 1994, Graphics Gems, P474, DOI 10.1016/B978-0-12-336156-1.50061-6
NR 34
TC 22
Z9 24
U1 2
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103978
DI 10.1016/j.imavis.2020.103978
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700004
DA 2024-07-18
ER

PT J
AU Leksut, JT
   Zhao, JP
   Itti, L
AF Leksut, Jatuporn Toy
   Zhao, Jiaping
   Itti, Laurent
TI Learning visual variation for object recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object recognition; Multi-task learning; Convolutional neural network
ID POSE
AB We propose visual variation learning to improve object recognition with convolutional neural networks (CNN). While a typical CNN regards visual variations as nuisances and marginalizes them from the data, we speculate that some variations are informative. We study the impact of visual variation as an auxiliary task, during training only, on classification and similarity embedding problems. To train the network, we introduce the iLab-20M dataset, a large-scale controlled parametric dataset of toy vehicle objects under systematic annotated variations of viewpoint, lighting, focal setting, and background. After training, we strip out the network components related to visual variations, and test dassification accuracy on images with no visual variation labels. Our experiments on 1.75 million images from Rab-20M show significant improvement in object recognition accuracy, i.e., AlexNet: 84.49% to 91.15%; ResNet: 86.14% to 90.70%; and DenseNet: 85.56% to 91.55%. Our key contribution is that, at the cost of visual variation annotation during training only, CNN enhanced with visual variation learning is able to focus its attention on distinctive features and learn better object representations, reducing classification error rate of Alexnet by 42%, ResNet by 32%, and DenseNet by 41%, without significant sacrificing of training time and model complexity. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Leksut, Jatuporn Toy; Zhao, Jiaping; Itti, Laurent] Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Leksut, JT (corresponding author), Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
EM leksut@usc.edu; jiapingz@usc.edu; itti@usc.edu
FU National Science Foundation [CCF-1317433]; C-BRIC (DARPA); Intel
   Corporation; CISCO Corporation; University of Southern California's
   Center for High-Performance Computing
FX This work was supported by the National Science Foundation (grant
   numbers CCF-1317433), C-BRIC (one of six centers in JUMP, a
   Semiconductor Research Corporation (SRC) programsponsored by DARPA), and
   the Intel and CISCO Corporations. The authors affirm that the views
   expressed herein are solely their own, and do not represent the views of
   the United States government or any agency thereof. Computation for the
   work described in this paper was also supported by the University of
   Southern California's Center for High-Performance Computing (hpc.
   usc.edu).
CR [Anonymous], 2008, PROC INT C MACHINE L
   [Anonymous], 2015, CVPR
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Borji A, 2016, PROC CVPR IEEE, P2221, DOI 10.1109/CVPR.2016.244
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Caruana R, 1998, LEARNING TO LEARN, P95, DOI 10.1007/978-1-4615-5529-2_5
   Chaichulee S, 2017, IEEE INT CONF AUTOMA, P266, DOI 10.1109/FG.2017.41
   Chen X, 2016, ADV NEUR IN, V29
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gebru T, 2017, IEEE I CONF COMP VIS, P1358, DOI 10.1109/ICCV.2017.151
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hwang SJ, 2011, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2011.5995543
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Mathieu M., 2016, Neural Information Processing Symposium, pages, P5041
   Misra I, 2016, PROC CVPR IEEE, P3994, DOI 10.1109/CVPR.2016.433
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Pinto Lerrel, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P2161, DOI 10.1109/ICRA.2017.7989249
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Reed S, 2014, PR MACH LEARN RES, V32, P1431
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Simonyan K, 2015, IEEE INT C ICLR
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Xiang Y, 2014, INTERNATIONAL CONFERENCE ON EDUCATION SCIENCE AND HUMAN DEVELOPMENT (ESHD 2014), P300
   Yin X, 2018, IEEE T IMAGE PROCESS, V27, P964, DOI 10.1109/TIP.2017.2765830
   Zhao JP, 2017, IEEE WINT CONF APPL, P550, DOI 10.1109/WACV.2017.67
   Zhao JP, 2017, IEEE WINT CONF APPL, P560, DOI 10.1109/WACV.2017.68
NR 48
TC 6
Z9 6
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2020
VL 98
AR 103912
DI 10.1016/j.imavis.2020.103912
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR9US
UT WOS:000536040700001
OA Bronze
DA 2024-07-18
ER

PT J
AU Skelton, PSM
   Finn, A
   Brinkworth, RSA
AF Skelton, Phillip S. M.
   Finn, Anthony
   Brinkworth, Russell S. A.
TI Consistent estimation of rotational optical flow in real environments
   using a biologically-inspired vision algorithm on embedded hardware
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optical flow; Biologically inspired; Rotational velocity; Embedded
   hardware; Robotic sensing
ID MOTION VISION; CONTRAST; COMPUTATION; SPEED
AB Insects are able to freely navigate through ever-changing environments using predominantly visual inputs, while possessing very minimal processing power compared to humans. Not only are they able to move at high velocities and accelerations, but they are also able to achieve extraordinary levels of obstacle avoidance. We begin to emulate this biological behaviour in a robotic application by first modelling how these visual pathways react to separable degrees of freedom within the motion field, specifically rotation in this case. We have developed upon an existing biologically-inspired algorithm based on the visual pathway of the hoverfly, and statistically compare results to current state-of-the-art algorithms, all the while performing this on computationally-constrained embedded hardware. We have shown that, using a complex, highly-elaborated representation of the hoverfly visual pathway, rotation optical flow estimations can be achieved with a high level of accuracy, at a level of consistency previously unseen in dense-flow algorithms, and they can be achieved at 100 frames per second on an embedded system. This work forms a fundamental basis to understanding one of the two separable components of insect egomotion (rotation and translation), allowing for consistently accurate rotational velocity estimation, providing a building block towards understanding the translational component of insect vision and the application of biologically-inspired egomotion estimation in autonomous vehicles. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Skelton, Phillip S. M.; Finn, Anthony; Brinkworth, Russell S. A.] Univ South Australia, Def & Syst Inst, Mawson Lakes, SA 5095, Australia.
C3 University of South Australia
RP Skelton, PSM (corresponding author), Univ South Australia, Def & Syst Inst, Mawson Lakes, SA 5095, Australia.
EM Phillip.Skelton@mymail.unisa.edu.au
RI Finn, Anthony/F-4674-2013
OI Finn, Anthony/0000-0002-2690-0838; Skelton, Phillip/0000-0001-6192-8193;
   Brinkworth, Russell/0000-0003-0270-3538
FU Australian Government Research Training Program PhD Scholarship;
   Australian Government Department of Defence [CIT013]
FX Phillip S.M. Skelton was supported by an Australian Government Research
   Training Program PhD Scholarship. This work was supported by the
   Australian Government Department of Defence [CIT013]. Neither funding
   agency had any input into the direction or outcomes of this research.
CR [Anonymous], THESIS
   [Anonymous], 2008, SIGGRAPH 2008 Classes
   [Anonymous], 1981, 7 INT JOINT C ARTIFI
   Babies B, 2011, SENSORS-BASEL, V11, P3303, DOI 10.3390/s110303303
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Baraldi P, 1996, IEEE T BIO-MED ENG, V43, P259, DOI 10.1109/10.486283
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bassett DS, 2011, TRENDS COGN SCI, V15, P200, DOI 10.1016/j.tics.2011.03.006
   Bayerl P, 2007, IEEE T PATTERN ANAL, V29, P246, DOI 10.1109/TPAMI.2007.24
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Beghdadi A, 2013, SIGNAL PROCESS-IMAGE, V28, P811, DOI 10.1016/j.image.2013.06.003
   Bertrand OJN, 2015, PLOS COMPUT BIOL, V11, DOI 10.1371/journal.pcbi.1004339
   Bolzon DM, 2009, J NEUROSCI, V29, P14143, DOI 10.1523/JNEUROSCI.2857-09.2009
   Borst A, 2002, J COMP PHYSIOL A, V188, P419, DOI 10.1007/s00359-002-0316-8
   Brinkworth R, 2010, 2010 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2010.5596502
   Brinkworth RSA, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000555
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cadík M, 2008, COMPUT GRAPH-UK, V32, P330, DOI 10.1016/j.cag.2008.04.003
   Chahl JS, 2023, J MOD OPTIC, V70, P793, DOI 10.1080/09500340.2016.1221153
   COLLETT TS, 1975, J COMP PHYSIOL, V99, P1, DOI 10.1007/BF01464710
   Courtney SM, 1996, CEREB CORTEX, V6, P39, DOI 10.1093/cercor/6.1.39
   Cui JZ, 2010, IEEE INT VEH SYM, P871, DOI 10.1109/IVS.2010.5548101
   Cuntz H, 2007, P NATL ACAD SCI USA, V104, P10229, DOI 10.1073/pnas.0703697104
   Deng J.D., 2008, 2008 23 INT C IM VIS, P1
   Dodd C., 2012, COMPUTER VISION SENS
   EMERSON RC, 1992, VISION RES, V32, P203, DOI 10.1016/0042-6989(92)90130-B
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Franceschini N, 2004, J PHYSIOL-PARIS, V98, P281, DOI 10.1016/j.jphysparis.2004.06.002
   FRANCESCHINI N, 1992, PHILOS T R SOC B, V337, P283, DOI 10.1098/rstb.1992.0106
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gibson J.J., 1950, PERCEPTION VISUAL WO
   Gonzalez-Bellido PT, 2016, CURR OPIN NEUROBIOL, V41, P122, DOI 10.1016/j.conb.2016.09.001
   Griffiths David John, 2017, THESIS
   Haag J, 2004, P NATL ACAD SCI USA, V101, P16333, DOI 10.1073/pnas.0407368101
   HASSENSTEIN B, 1951, Z VERGL PHYSIOL, V33, P301
   HASSENSTEIN B, 1956, Z NATURFORSCH PT B, V11, P513
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Kroeger T, 2016, LECT NOTES COMPUT SC, V9908, P471, DOI 10.1007/978-3-319-46493-0_29
   Lecoeur J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24162-z
   Li JL, 2016, FRONT COMPUT NEUROSC, V10, DOI 10.3389/fncom.2016.00111
   Longden KD, 2017, CURR BIOL, V27, P3225, DOI 10.1016/j.cub.2017.09.044
   Mann S., 1993, PROC IS T ANN M, P50
   Matkovic K., 2005, Computational Aesthetics, P159
   Medathati NVK, 2016, COMPUT VIS IMAGE UND, V150, P1, DOI 10.1016/j.cviu.2016.04.009
   Nakamura J., 2016, IMAGE SENSORS SIGNAL
   Nordstrom K, 2008, CURR BIOL, V18, P661, DOI 10.1016/j.cub.2008.03.061
   Nordström K, 2011, J EXP BIOL, V214, P4000, DOI 10.1242/jeb.057539
   PELI E, 1990, J OPT SOC AM A, V7, P2032, DOI 10.1364/JOSAA.7.002032
   Reinhard E, 2002, ACM T GRAPHIC, V21, P267, DOI 10.1145/566570.566575
   Ruffier Franck., 2003, CIRCUITS SYSTEMS, V3, pIII
   Schwegmann A, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00083
   Serres J, 2008, AUTON ROBOT, V25, P103, DOI 10.1007/s10514-007-9069-0
   Shi J., 1993, TECH REP
   Simone G, 2012, J VIS COMMUN IMAGE R, V23, P491, DOI 10.1016/j.jvcir.2012.01.008
   Skelton PSM, 2017, 2017 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING - TECHNIQUES AND APPLICATIONS (DICTA), P149
   Srinivasan MV, 1999, ROBOT AUTON SYST, V26, P203, DOI 10.1016/S0921-8890(98)00069-4
   SRINIVASAN MV, 1991, VISUAL NEUROSCI, V6, P519, DOI 10.1017/S095252380000136X
   Srinivasan MV, 1996, J EXP BIOL, V199, P237
   Strausfeld NJ, 1981, HDB SENSORY PHYSL
   Straw AD, 2008, J VISION, V8, DOI 10.1167/8.3.32
   Tao M, 2012, COMPUT GRAPH FORUM, V31, P345, DOI 10.1111/j.1467-8659.2012.03013.x
   Timofte R, 2015, IEEE WINT CONF APPL, P1100, DOI 10.1109/WACV.2015.151
   Tomsic D, 2017, CURR BIOL, V27, pR1156, DOI 10.1016/j.cub.2017.09.038
   Ullrich TW, 2015, BIOL OPEN, V4, P13, DOI 10.1242/bio.20149449
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Yang JL, 2015, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2015.7298704
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
NR 68
TC 10
Z9 10
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2019
VL 92
AR 103814
DI 10.1016/j.imavis.2019.09.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JW2JO
UT WOS:000502884200002
DA 2024-07-18
ER

PT J
AU Faraji, M
   Basu, A
AF Faraji, Mehdi
   Basu, Anup
TI Simplified Active Calibration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active Calibration; Self Calibration; Simplified Active Calibration;
   SAC; Pan; Tilt; Zoom; Camera; PTZ
ID SELF-CALIBRATION; CAMERA CALIBRATION; TILT; PAN
AB We present a new mathematical formulation to estimate the intrinsic parameters of a camera in active or robotic platforms. We show that the focal lengths can be estimated using only one point correspondence that relates images taken before and after a degenerate rotation of the camera. The estimated focal lengths are then treated as known parameters to obtain a linear set of equations to calculate the principal point. Assuming that the principal point is close to the image center, the accuracy of the linear equations are increased by integrating the image center into the formulation. We extensively evaluate the formulations on a simulated camera, 3D scenes and real-world images. Our error analysis over simulated and real images indicates that the proposed Simplified Active Calibration method estimates the parameters of a camera with low error rates that can be used as an initial guess for further non-linear refinement procedures. Simplified Active Calibration can be employed in real-time environments for automatic calibrations given the proposed closed-form solutions. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Faraji, Mehdi; Basu, Anup] Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada.
C3 University of Alberta
RP Basu, A (corresponding author), Univ Alberta, Dept Comp Sci, Edmonton, AB, Canada.
EM faraji@ualberta.ca; basu@ualberta.ca
RI faraji, mehdi/AAA-3093-2020
FU NSERC, Canada
FX The authors acknowledge the financial support of NSERC, Canada, in
   making this work possible.
CR Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694
   Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571
   BASU A, 1995, IEEE T SYST MAN CYB, V25, P256, DOI 10.1109/21.364838
   Basu A, 1997, IEEE T SYST MAN CY B, V27, P559, DOI 10.1109/3477.584964
   BASU A, 1993, PROCEEDINGS : IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-3, pB764
   Basu A., 1993, COMP VIS PATT REC 19, P495
   Brückner M, 2014, MACH VISION APPL, V25, P389, DOI 10.1007/s00138-013-0541-x
   Dron L, 1993, CVPR, P501
   Du F., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P477, DOI 10.1109/CVPR.1993.341087
   Faraji M., 2015, IEEE T IMAGE PROCESS
   Faraji M., 2018, ARXIV180603584
   Faraji M, 2015, IEEE IMAGE PROC, P681, DOI 10.1109/ICIP.2015.7350885
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   Frahm JM, 2003, VISION, MODELING, AND VISUALIZATION 2003, P79
   Frahm JM, 2003, LECT NOTES COMPUT SC, V2781, P249
   Frahm JM, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1418
   Galego R, 2012, LECT NOTES COMPUT SC, V7431, P169, DOI 10.1007/978-3-642-33179-4_17
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley R. I., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P471
   Hartley RI, 1997, INT J COMPUT VISION, V22, P5, DOI 10.1023/A:1007957826135
   Heng L, 2015, AUTON ROBOT, V39, P259, DOI 10.1007/s10514-015-9466-8
   Ji Q, 2004, IEEE T ROBOTIC AUTOM, V20, P1, DOI 10.1109/TRA.2003.820921
   Junejo IN, 2012, MACH VISION APPL, V23, P375, DOI 10.1007/s00138-011-0326-z
   Junejo IN, 2008, IEEE IMAGE PROC, P1936, DOI 10.1109/ICIP.2008.4712160
   KANATANI KI, 1987, COMPUT VISION GRAPH, V39, P328, DOI 10.1016/S0734-189X(87)80185-8
   Knight J., 2003, IEEE COMP SOC C COMP, V1, P1
   Li Hua, 2000, Chinese Journal of Computers, V23, P1121
   MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781
   Sun Q, 2016, OPTIK, V127, P4506, DOI 10.1016/j.ijleo.2016.01.123
   Tresadern PA, 2008, IMAGE VISION COMPUT, V26, P851, DOI 10.1016/j.imavis.2007.10.001
   Wan DR, 2010, IMAGE VISION COMPUT, V28, P367, DOI 10.1016/j.imavis.2009.06.003
   Wu ZY, 2013, IEEE T PATTERN ANAL, V35, P1994, DOI 10.1109/TPAMI.2012.250
   Zhao FD, 2018, IMAGE VISION COMPUT, V70, P46, DOI 10.1016/j.imavis.2017.12.006
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
NR 36
TC 3
Z9 3
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2019
VL 91
AR 103799
DI 10.1016/j.imavis.2019.08.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU3YI
UT WOS:000501614200003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, XL
   Li, XM
   Liu, Y
   Feng, FX
AF Zhang, Xianlin
   Li, Xueming
   Liu, Yang
   Feng, Fangxiang
TI A survey on freehand sketch recognition and retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Touch-screen devices; Freehand sketches; Sketch generation; SBIR;
   FG-SBIR
ID IMAGE RETRIEVAL; RELEVANCE FEEDBACK; FEATURES; COLOR; CLASSIFICATION;
   LOCALIZATION; PERFORMANCE; DESCRIPTOR; FRAMEWORK; ALGORITHM
AB With the development of digital devices and pressure sensing equipment, research into freehand sketches from touch-screen interfaces has increased significantly in recent years. As such, we provide the first comprehensive survey of recognition tasks based on sketch generation, freehand sketch classification, sketch-based image retrieval (SBIR), fine-grained sketch-based image retrieval (FG-SBIR), and sketch-based 3D shape image retrieval. Specifically, SBIR and FG-SBIR were the main focus of the survey. Primary technologies and benchmark datasets related to all sketch-based recognition topics are also discussed, along with future trends for this promising technology. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Zhang, Xianlin; Li, Xueming; Liu, Yang] Beijing Univ Posts & Telecommun, Sch Digital Media & Art Design, 10 Xitu Cheng Rd, Beijing, Peoples R China.
   [Li, Xueming] Beijing Key Lab Network Syst & Network Culture, Beijing, Peoples R China.
   [Zhang, Xianlin; Feng, Fangxiang] Beijing Univ Posts & Telecommun, Sch Comp Sci, 10 Xitu Cheng Rd, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Zhang, XL; Liu, Y (corresponding author), Beijing Univ Posts & Telecommun, Sch Digital Media & Art Design, 10 Xitu Cheng Rd, Beijing, Peoples R China.; Zhang, XL (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp Sci, 10 Xitu Cheng Rd, Beijing, Peoples R China.
EM zxlin@bupt.edu.cn; lixm@bupt.edu.cn; Yangliu@bupt.edu.cn
RI Wang, Xiaoman/JYP-1144-2024; Li, Xueming/W-8707-2019
OI , Xianlin/0000-0003-3905-2062; liu, yang/0000-0001-9814-638X
CR Akata Z, 2016, PROC CVPR IEEE, P59, DOI 10.1109/CVPR.2016.14
   [Anonymous], 2011, IEEE T VIS COMPUT GR, DOI DOI 10.1109/TVCG.2010.266
   [Anonymous], QUERY ADAPTIVE SHAPE
   [Anonymous], 2017, BRIT MACH VIS C BMVC
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], THE IEEE CONFERENCE
   [Anonymous], CORR
   [Anonymous], 2009, SIGGRAPH 2009 TALKS, DOI DOI 10.1145/1597990.1598050
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.632
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2017, INT J COMPUT VISION, DOI DOI 10.1007/s11263-016-0932-3
   [Anonymous], 2016, CORR
   [Anonymous], 2011, P 16 INT C INT US IN
   [Anonymous], ACM T GRAPH TOG
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], INT C COMP PROBL SOL
   [Anonymous], 2012, P 20 ACM INT C MULT
   [Anonymous], 2016, INT C CIRCUIT POWER, DOI DOI 10.1109/ICCPCT.2016.7530358
   [Anonymous], 2017, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2017.622
   [Anonymous], THESIS
   [Anonymous], INT C DIG IM COMP TE
   [Anonymous], 2016, CORR
   [Anonymous], CORR
   [Anonymous], 2015, 2015 INT C INN INF E, DOI DOI 10.1109/ICIIECS.2015.7192911
   [Anonymous], 2009, ACM T GRAPHIC, DOI DOI 10.1145/1618452.1618470
   [Anonymous], IEEE 17 INT WORKSH M
   [Anonymous], 2002, Introduction to MPEG-7: Multimedia Content Description Interface
   [Anonymous], 2015, FREEHAND SKETCH RECO
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 2017, BRIT MACH VIS C BMVC
   [Anonymous], CORR
   [Anonymous], 1995, proceedings of ACM International Conference on Management of Data (SIGMOD)
   [Anonymous], 2015, PROC 28 INT C NEURAL
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arjovsky M., 2017, ARXIV170107875
   Benaim Sagie, 2017, Advances in neural information processing systems, P752
   Berger I, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461964
   Bo Jiang, 2013, 2013 Seventh International Conference on Image and Graphics (ICIG), P927, DOI 10.1109/ICIG.2013.187
   Bozas K, 2012, LECT NOTES COMPUT SC, V7431, P210, DOI 10.1007/978-3-642-33179-4_21
   Bu SH, 2015, COMPUT GRAPH-UK, V46, P117, DOI 10.1016/j.cag.2014.09.007
   Bui T, 2017, COMPUT VIS IMAGE UND, V164, P27, DOI 10.1016/j.cviu.2017.06.007
   Bui T, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P1012, DOI 10.1109/ICCVW.2015.133
   Buoncompagni S, 2018, ADV INTELL SYST COMP, V578, P159, DOI 10.1007/978-3-319-59162-9_17
   Cao XC, 2013, IEEE I CONF COMP VIS, P313, DOI 10.1109/ICCV.2013.46
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Cao Yang, 2010, P 18 ACM INT C MULT, P1605
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chatbri H, 2013, INT CONF SYST SIGNAL, P19, DOI 10.1109/IWSSIP.2013.6623439
   Chatbri H, 2012, INT C PATT RECOG, P3030
   Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169
   Chen X, 2016, 2016 AUSTRALIAN CONTROL CONFERENCE (AUCC), P180, DOI 10.1109/AUCC.2016.7868184
   Chen XY, 2015, LECT NOTES COMPUT SC, V9006, P127, DOI 10.1007/978-3-319-16817-3_9
   Cheng E, 2009, IEEE T IMAGE PROCESS, V18, P1350, DOI 10.1109/TIP.2009.2017128
   Cheng SJ, 2014, 28TH INTERNATIONAL SYMPOSIUM ON BALLISTICS, VOLS 1 AND 2, P133
   Chua TS, 1998, 1998 MULTIMEDIA MODELING, PROCEEDINGS, P24, DOI 10.1109/MULMM.1998.722971
   Creswell Antonia, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P798, DOI 10.1007/978-3-319-46604-0_55
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   Di Sciascio E., 1999, Visual Information and Information Systems. Third International Conference, VISUAL'99. Proceedings (Lecture Notes in Computer Science Vol.1614), P123
   Ding C, 2016, FRONT COMPUT SCI-CHI, V10, P985, DOI 10.1007/s11704-016-5422-9
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089
   Eitz M, 2011, IEEE COMPUT GRAPH, V31, P56, DOI 10.1109/MCG.2011.67
   Eitz M, 2010, COMPUT GRAPH-UK, V34, P482, DOI 10.1016/j.cag.2010.07.002
   Eitz Mathias., 2009, P 6 EUR S SKETCH BAS, P29
   Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Fonseca MJ, 2005, INT J COMPUT APPL T, V23, P86, DOI 10.1504/IJCAT.2005.006467
   Fonseca MJ, 2010, 16TH INTERNATIONAL CONFERENCE ON DISTRIBUTED MULTIMEDIA SYSTEMS (DMS 2010), P327
   Fonseca MJ, 2009, COMPUT AIDED DESIGN, V41, P1067, DOI 10.1016/j.cad.2009.09.004
   Franti P., 2000, International Journal on Document Analysis and Recognition, V3, P117, DOI 10.1007/s100320070001
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2016, PROC CVPR IEEE, P5337, DOI 10.1109/CVPR.2016.576
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Furuya Takahiko, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P543, DOI 10.1109/3DV.2014.72
   Furuya Takahiko, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P37, DOI 10.1007/978-3-319-04114-8_4
   Furuya T, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P274, DOI 10.1109/CW.2013.60
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004
   Ha D., 2017, CoRR
   Hammond T, 2005, COMPUT GRAPH-UK, V29, P518, DOI 10.1016/j.cag.2005.05.005
   Herot C. F., 1976, Computer Graphics, V10, P97, DOI 10.1145/965143.563294
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Hu R, 2010, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2010.5649331
   Huang Z, 2014, ACM T GRAPHIC, V33, DOI [10.1145/2661229.2661280, 10.1145/2661228.2661280]
   Hui C, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION PROBLEM-SOLVING (ICCP), P14, DOI 10.1109/ICCPS.2015.7454078
   Huiqin Wang, 2010, Proceedings 3rd International Congress on Image and Signal Processing (CISP 2010), P2665, DOI 10.1109/CISP.2010.5648112
   Ip HHS, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P55, DOI 10.1109/CGI.2001.934658
   Jain AK, 1996, PATTERN RECOGN, V29, P1233, DOI 10.1016/0031-3203(95)00160-3
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kang Y, 2014, INT C DIGITAL HOME, P277, DOI 10.1109/ICDH.2014.60
   KATO T, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P530, DOI 10.1109/ICPR.1992.201616
   Kennedy R., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2065, DOI 10.1109/CVPR.2011.5995739
   Kumagai Y, 2013, IEICE T INF SYST, VE96D, P340, DOI 10.1587/transinf.E96.D.340
   Längkvist M, 2014, PATTERN RECOGN LETT, V42, P11, DOI 10.1016/j.patrec.2014.01.008
   Laviola JJ, 2004, ACM T GRAPHIC, V23, P432, DOI 10.1145/1015706.1015741
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee J., 2008, P EUROGRAPHICS WORKS, P97, DOI DOI 10.2312/SBM/SBM08/097-104
   Lee YJ, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964922
   Leng B, 2015, SIGNAL PROCESS, V112, P119, DOI 10.1016/j.sigpro.2014.09.005
   Leung WH, 2002, IEEE IMAGE PROC, P908
   Li B, 2006, LECT NOTES COMPUT SC, V4261, P201
   Li B, 2014, IEEE INT CONF COMM, P121, DOI 10.1109/ICCW.2014.6881183
   Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li K, 2017, IEEE T IMAGE PROCESS, V26, P5908, DOI 10.1109/TIP.2017.2745106
   Li Y., 2014, BMVC
   Li Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.35
   Li Y, 2017, INT J COMPUT VISION, V122, P169, DOI 10.1007/s11263-016-0963-9
   Li Y, 2015, COMPUT VIS IMAGE UND, V137, P1, DOI 10.1016/j.cviu.2015.02.003
   Li YH, 2018, MULTIMED TOOLS APPL, V77, P2921, DOI 10.1007/s11042-017-4446-y
   Liang S, 2008, PATTERN RECOGN LETT, V29, P1733, DOI 10.1016/j.patrec.2008.05.004
   Liang SN, 2005, COMPUTER GRAPHICS, IMAGING AND VISION: NEW TRENDS, P24
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Limpaecher A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462016
   Lin YL, 2013, IEEE I CONF COMP VIS, P3495, DOI 10.1109/ICCV.2013.434
   Liu L, 2017, PROC CVPR IEEE, P2298, DOI 10.1109/CVPR.2017.247
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma C, 2016, IMAGE VISION COMPUT, V46, P64, DOI 10.1016/j.imavis.2015.11.007
   Mao DH, 2016, LECT NOTES ELECTR EN, V360, P395, DOI 10.1007/978-3-662-48365-7_40
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Marvaniya S, 2012, LECT NOTES COMPUT SC, V7583, P63, DOI 10.1007/978-3-642-33863-2_7
   Matsui Y, 2014, IEEE IMAGE PROC, P3097, DOI 10.1109/ICIP.2014.7025626
   Matusiak S., 1998, Advances in Multimedia Information Systems. 4th International Workshop, MIS'98. Proceedings, P185
   Bada AMM, 2014, INT CONF ELECTR COMM, P183, DOI 10.1109/CONIELECOMP.2014.6808588
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Niu JW, 2017, LECT NOTES COMPUT SC, V10133, P257, DOI 10.1007/978-3-319-51814-5_22
   Ouyang SX, 2016, IMAGE VISION COMPUT, V56, P28, DOI 10.1016/j.imavis.2016.09.001
   Pan D, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY (FSKD), P825, DOI 10.1109/FSKD.2014.6980944
   Pang KY, 2018, LECT NOTES COMPUT SC, V11219, P37, DOI 10.1007/978-3-030-01267-0_3
   Parui S, 2014, LECT NOTES COMPUT SC, V8694, P398, DOI 10.1007/978-3-319-10599-4_26
   Patil CVishal., 2014, International Journal of Engineering Research Technology, V3, P2475
   Paulson Brandon, 2008, 13th International Conference on Intelligent User Interfaces. IUI 2008, P1, DOI 10.1145/1378773.1378775
   Peng Xu, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P19, DOI 10.1007/978-3-319-46604-0_2
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Qi YG, 2014, LECT NOTES COMPUT SC, V8888, P74, DOI 10.1007/978-3-319-14364-4_8
   Qi Y, 2014, 2014 9TH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND NETWORKING IN CHINA (CHINACOM), P275, DOI 10.1109/CHINACOM.2014.7054300
   Qian XM, 2016, IEEE T IMAGE PROCESS, V25, P195, DOI 10.1109/TIP.2015.2497145
   Qiu G, 2002, PATTERN RECOGN, V35, P1675, DOI 10.1016/S0031-3203(01)00162-5
   Rajendran RK, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P717, DOI 10.1109/ICME.2000.871462
   Rui Hu, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3661, DOI 10.1109/ICIP.2011.6116513
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P815, DOI 10.1109/ICIP.1997.638621
   Saavedra J.M., 2011, Proceedings of the 1st ACM International Conference on Multimedia Retrieval, P1
   Saavedra JM, 2014, IEEE IMAGE PROC, P2998, DOI 10.1109/ICIP.2014.7025606
   Saavedra JM, 2014, MULTIMED TOOLS APPL, V73, P2033, DOI 10.1007/s11042-013-1689-0
   Saavedra JM, 2010, LECT NOTES COMPUT SC, V6376, P432
   SALTON G, 1990, J AM SOC INFORM SCI, V41, P288, DOI 10.1002/(SICI)1097-4571(199006)41:4<288::AID-ASI8>3.0.CO;2-H
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Sasaki K, 2016, LECT NOTES COMPUT SC, V9887, P283, DOI 10.1007/978-3-319-44781-0_34
   Savarese S, 2007, IEEE I CONF COMP VIS, P1245
   Schneider RG, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2898351
   Schneider RG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661231
   Scott AM, 2018, JOVE-J VIS EXP, DOI 10.3791/58059
   Seddati O, 2017, LECT NOTES COMPUT SC, V10317, P296, DOI 10.1007/978-3-319-59876-5_33
   Sezgin T.M., 2005, Proceedings of International Conference on Intelligent User Interfaces (IUI 2005), P281, DOI DOI 10.1145/1040830.1040899
   Sezgin T.M., 2001, PROC WORKSHOP PERCEP, P1
   Sharath Kumar Y. H., 2015, Mining Intelligence and Knowledge Exploration. Third International Conference, MIKE 2015. Proceedings: LNCS 9468, P247, DOI 10.1007/978-3-319-26832-3_24
   Shechtman E, 2007, PROC CVPR IEEE, P1744
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Shih JL, 2001, IMAGE VISION COMPUT, V19, P1011, DOI 10.1016/S0262-8856(01)00063-4
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Song JF, 2017, IEEE I CONF COMP VIS, P5552, DOI 10.1109/ICCV.2017.592
   Song YZ., 2016, 2016 IEEE WINT C APP, P1, DOI DOI 10.1109/IPDPS.2016.126
   Songtao Ji, 2016, 2016 IEEE International Workshop on Electromagnetics (iWEM): Applications and Student Innovation Competition, P1, DOI 10.1109/iWEM.2016.7505029
   Sousa P, 2010, J VISUAL LANG COMPUT, V21, P69, DOI 10.1016/j.jvlc.2009.12.001
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun Xinghai., 2013, Proceedings of the International Conference On Multimedia (MM), P233
   Sun ZB, 2012, LECT NOTES COMPUT SC, V7572, P626, DOI 10.1007/978-3-642-33718-5_45
   Sutherland I. E., 1964, P SHARE DES AUT WORK, DOI DOI 10.1145/800265.810742
   Szanto B., 2011, 2011 IEEE 9th International Symposium on Applied Machine Intelligence and Informatics (SAMI), P183, DOI 10.1109/SAMI.2011.5738872
   Tao L., 2009, Advanced Architectures and Control Concepts for More Microgrids DG3, P1, DOI DOI 10.1145/1576246.1531374
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Tu CT, 2017, MULTIMED TOOLS APPL, V76, P11669, DOI 10.1007/s11042-016-3326-1
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vedaldi A, 2014, PROC CVPR IEEE, P3622, DOI 10.1109/CVPR.2014.463
   Wang Changhu., 2010, proceedings of the International Conference on World Wide Web, P1309
   Wang Changhu., 2011, Proceedings of the ACM Conference on Multimedia, P789
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang M, 2012, IEEE T IMAGE PROCESS, V21, P4649, DOI 10.1109/TIP.2012.2207397
   Wang S, 2005, IEEE T PATTERN ANAL, V27, P546, DOI 10.1109/TPAMI.2005.84
   Wang S, 2015, IEEE T MULTIMEDIA, V17, P1045, DOI 10.1109/TMM.2015.2431492
   Wang XG, 2016, NEUROCOMPUTING, V207, P387, DOI 10.1016/j.neucom.2016.04.046
   Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131
   Wing Ho Leung, 2002, Proceedings 2002 IEEE International Conference on Multimedia and Expo (Cat. No.02TH8604), P517, DOI 10.1109/ICME.2002.1035662
   Wu ST, 2018, MULTIMED TOOLS APPL, V77, P10437, DOI 10.1007/s11042-017-4440-4
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xiao Zhang, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P515, DOI 10.1007/978-3-319-27671-7_43
   Xie SN, 2017, INT J COMPUT VISION, V125, P3, DOI 10.1007/s11263-017-1004-z
   Xie XH, 2013, COMPUT GRAPH FORUM, V32, P233, DOI 10.1111/cgf.12200
   Xu Puyang., 2018, CoRR
   Yang XP, 2016, IEEE T IMAGE PROCESS, V25, P4617, DOI 10.1109/TIP.2016.2593653
   Yang XY, 2015, IEEE T IMAGE PROCESS, V24, P1709, DOI 10.1109/TIP.2015.2411433
   Yasseen Z, 2017, VISUAL COMPUT, V33, P565, DOI 10.1007/s00371-016-1328-7
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yin Chans, 1997, Proceedings of the SPIE - The International Society for Optical Engineering, V3229, P220, DOI 10.1117/12.290343
   Yu Q, 2016, PROC CVPR IEEE, P799, DOI 10.1109/CVPR.2016.93
   [于谦 Yu Qian], 2015, [高分子通报, Polymer Bulletin], P1
   Zhang H, 2016, PROC CVPR IEEE, P1105, DOI 10.1109/CVPR.2016.125
   Zhang SL, 2013, IEEE T IMAGE PROCESS, V22, P2889, DOI 10.1109/TIP.2013.2251650
   Zhang XL, 2018, NEUROCOMPUTING, V322, P38, DOI 10.1016/j.neucom.2018.09.047
   Zhang XF, 2016, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2016.126
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhou F, 2016, PROC CVPR IEEE, P1124, DOI 10.1109/CVPR.2016.127
   Zhou RJ, 2012, PROCEEDINGS OF THE 10TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA 2012), P2097, DOI 10.1109/WCICA.2012.6358222
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
   Zhu F, 2016, AAAI CONF ARTIF INTE, P3683
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
   Zhu QH, 2007, IEEE I CONF COMP VIS, P793
NR 220
TC 12
Z9 13
U1 1
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 67
EP 87
DI 10.1016/j.imavis.2019.06.010
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900007
DA 2024-07-18
ER

PT J
AU Roy, H
   Bhattacharjee, D
AF Roy, Hiranmoy
   Bhattacharjee, Debotosh
TI A novel local wavelet energy mesh pattern (LWEMeP) for heterogeneous
   face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Wavelet transform; Local wavelet energy; Derived local mesh pattern;
   Local wavelet energy mesh pattern; Heterogeneous face recognition
ID TEXTURE CLASSIFICATION; BINARY PATTERNS; ILLUMINATION-INVARIANT;
   EDGE-DETECTION; SKETCHES
AB This paper proposes a novel and accurate methodology for matching of heterogeneous faces, such as sketch photo and near infrared (NIR)-visible (VIS) images. Inspired from mesh topology in computer networking, a new local binary pattern has been developed. We call it derived local mesh pattern (DLMeP). DLMeP is computed based on the relationship among each and every pixel present in a local window. For heterogeneous face recognition, more emphasis is given to the edge and texture features, because these features could be extracted invariant to different modalities. The wavelet transform is employed to capture the edge and texture features simultaneously. Then a local wavelet energy feature is calculated to enhance the local texture information and edges. Finally, DLMeP is used to measure the local variation or pattern of wavelet energy, and we call it local wavelet energy mesh pattern (LWEMeP). For refinement of LWEMeP, a model based weight value learning is suggested. We have tested the proposed methodology on different sketch photo and NIR-VIS benchmark databases. In the case of viewed sketches, the rank-1 recognition accuracy of 99.37% is achieved on CUFSF database. LWEMeP gives the rank-1 accuracy of 65.31% on challenging e-PRIP composite sketch database. In the case of NIR-VIS matching, the rank-1 accuracy of 89.78% is achieved and which is superior to other state-of-the-art methods. Finally, proposed LWEMeP is also compared with state-of-the-art deep learning based methods in the case of composite sketch vs photo matching and NIR vs VIS matching. Superior results of the proposed feature after combining with deep learning suggest that handcrafted features combining with deep learning give excellent classification results. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Roy, Hiranmoy] RCC Inst Informat Technol, Dept Informat Technol, Canal South Rd, Kolkata 700015, India.
   [Bhattacharjee, Debotosh] Jadavpur Univ, Dept Comp Sci & Engn, Kolkata 700032, India.
C3 RCC Institute of Information Technology (RCCIIT); Jadavpur University
RP Roy, H (corresponding author), RCC Inst Informat Technol, Dept Informat Technol, Canal South Rd, Kolkata 700015, India.
EM hiranmoy.roy@rcciit.org
RI Bhattacharjee, Debotosh/Q-4065-2019; Bhattacharjee,
   Debotosh/L-8521-2015; Roy, Hiranmoy/P-8477-2019
OI Bhattacharjee, Debotosh/0000-0002-1163-6413; Bhattacharjee,
   Debotosh/0000-0002-1163-6413; 
CR Acharyya M., 2001, P IEEE INT C IM PROC
   [Anonymous], 2013, MULTIFEATURE CANONIC
   [Anonymous], P IAPR INT C BIOM
   [Anonymous], 2012, AS C COMP VIS
   [Anonymous], END TO END PHOTO SKE
   [Anonymous], 2009, Encyclopedia of Biometrics
   Bhatt HS, 2012, IEEE T INF FOREN SEC, V7, P1522, DOI 10.1109/TIFS.2012.2204252
   Bourlai T, 2016, IMAGE VISION COMPUT, V55, P14, DOI 10.1016/j.imavis.2016.03.017
   Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832
   Chen WP, 2013, IEEE T IMAGE PROCESS, V22, P4798, DOI 10.1109/TIP.2013.2277920
   Dagher I, 2012, IMAGE VISION COMPUT, V30, P896, DOI 10.1016/j.imavis.2012.07.007
   Forouzan B. A., 2010, DATA COMMUNICATIONS
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   Goh YZ, 2011, EXPERT SYST APPL, V38, P3959, DOI 10.1016/j.eswa.2010.09.057
   Han H, 2013, IEEE T INF FOREN SEC, V8, P191, DOI 10.1109/TIFS.2012.2228856
   Hu G., 2015, ARXIV150402351 CORR
   Huang G. B., 2012, P IEEE INT C COMP VI, P2
   Huang WL, 2017, PATTERN RECOGN, V68, P126, DOI 10.1016/j.patcog.2017.03.010
   Jain AK, 2016, PATTERN RECOGN LETT, V79, P80, DOI 10.1016/j.patrec.2015.12.013
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Kim SC, 2007, PATTERN RECOGN, V40, P1207, DOI 10.1016/j.patcog.2006.09.012
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Lei Z, 2012, IEEE T INF FOREN SEC, V7, P1707, DOI 10.1109/TIFS.2012.2210041
   Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860
   Li J, 2008, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2008.4711792
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Lin DH, 2006, LECT NOTES COMPUT SC, V3954, P13
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Liu XM, 2016, AER ADV ENG RES, V116, P1, DOI 10.1145/2875194.2875248
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Mittal P, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Mittal P, 2015, INT CONF BIOMETR, P251, DOI 10.1109/ICB.2015.7139092
   Murala S, 2014, IEEE J BIOMED HEALTH, V18, P929, DOI 10.1109/JBHI.2013.2288522
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ouyang SX, 2016, IMAGE VISION COMPUT, V56, P28, DOI 10.1016/j.imavis.2016.09.001
   Peng CL, 2017, IEEE T PATTERN ANAL, V39, P301, DOI 10.1109/TPAMI.2016.2542816
   Peng CL, 2016, IEEE T NEUR NET LEAR, V27, P2201, DOI 10.1109/TNNLS.2015.2464681
   Pun C., 2002, IEEE T PATTERN ANAL, V24, P971
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Rivera AR, 2013, IEEE T IMAGE PROCESS, V22, P1740, DOI 10.1109/TIP.2012.2235848
   Roy H, 2018, PATTERN RECOGN LETT, V113, P19, DOI 10.1016/j.patrec.2017.09.029
   Roy H, 2017, INT J MACH LEARN CYB, V8, P1457, DOI 10.1007/s13042-016-0516-0
   Roy H, 2016, APPL SOFT COMPUT, V46, P967, DOI 10.1016/j.asoc.2015.12.006
   Roy H, 2016, IEEE INTELL SYST, V31, P30, DOI 10.1109/MIS.2016.44
   Roy H, 2016, IEEE T INF FOREN SEC, V11, P1412, DOI 10.1109/TIFS.2016.2530043
   Saxena S, 2016, LECT NOTES COMPUT SC, V9915, P483, DOI 10.1007/978-3-319-49409-8_40
   Sharma A, 2011, PROC CVPR IEEE, P593, DOI 10.1109/CVPR.2011.5995350
   Shih MY, 2005, IMAGE VISION COMPUT, V23, P441, DOI 10.1016/j.imavis.2004.11.005
   Shirazi MN, 2000, IMAGE VISION COMPUT, V18, P967, DOI 10.1016/S0262-8856(00)00039-1
   Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093
   Song YB, 2014, LECT NOTES COMPUT SC, V8694, P800, DOI 10.1007/978-3-319-10599-4_51
   Srivastava N., 2012, ADV NEURAL INFORM PR, P2222, DOI DOI 10.1109/CVPR.2013.49
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Tang XO, 2004, IEEE T CIRC SYST VID, V14, P50, DOI 10.1109/TCSVT.2003.818353
   Unar JA, 2014, PATTERN RECOGN, V47, P2673, DOI 10.1016/j.patcog.2014.01.016
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Nguyen VD, 2014, IEEE T CIRC SYST VID, V24, P263, DOI 10.1109/TCSVT.2013.2254898
   Wang NN, 2013, IEEE T NEUR NET LEAR, V24, P1364, DOI 10.1109/TNNLS.2013.2258174
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Wu Y, 2005, IMAGE VISION COMPUT, V23, P1159, DOI 10.1016/j.imavis.2005.07.012
   Yi D., 2015, P F IEEE INT C AUT F
   Yi D, 2007, LECT NOTES COMPUT SC, V4642, P523
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhang H, 2015, COMPUT VIS IMAGE UND, V137, P50, DOI 10.1016/j.cviu.2015.03.003
   Zhang J, 2013, IEEE T IMAGE PROCESS, V22, P31, DOI 10.1109/TIP.2012.2214045
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhou H, 2012, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2012.6247788
   Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977
NR 72
TC 6
Z9 6
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2018
VL 72
BP 1
EP 13
DI 10.1016/j.imavis.2018.01.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GE4DI
UT WOS:000431164100001
DA 2024-07-18
ER

PT J
AU Karpushin, M
   Valenzise, G
   Dufaux, F
AF Karpushin, Maxim
   Valenzise, Giuseppe
   Dufaux, Frederic
TI TRISK: A local features extraction framework for texture-plus-depth
   content matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Texture-plus-depth; RGBD; Local feature; Keypoint detector; Descriptor;
   Viewpoint changes
ID DETECTORS; SCALE; DESCRIPTORS; IMAGES
AB In this paper we present a new complete detector-descriptor framework for local features extraction from grayscale texture-plus-depth images. It is designed by putting together a locally normalized binary descriptor and the popular AGAST corner detector modified to incorporate the depth map into the key point detection process. With these new local features, we target image matching applications when significant out-of-plane rotations and viewpoint position changes are present in the input data. Our approach is designed to perform on RGBD images acquired with low-cost sensors such as Kinect without any complex depth map preprocessing such as denoising or inpainting. We show improved results with respect to several other highly competitive local image features through both a classic local feature evaluation procedure and an illustrative application scenario. Moreover, the proposed method requires low computational effort. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Karpushin, Maxim] Univ Paris Saclay, Telecom ParisTech, LTCI, 46 Rue Barrault, F-75013 Paris, France.
   [Valenzise, Giuseppe; Dufaux, Frederic] Univ Paris Sud, Cent Supelec, CNRS, L2S, 3 Rue Joliot Curie, F-91192 Gif Sur Yvette, France.
C3 Universite Paris Saclay; IMT - Institut Mines-Telecom; Institut
   Polytechnique de Paris; Telecom Paris; Universite Paris Cite; Universite
   Paris Saclay; Universite Paris Cite; Centre National de la Recherche
   Scientifique (CNRS)
RP Valenzise, G (corresponding author), Univ Paris Sud, Cent Supelec, CNRS, L2S, 3 Rue Joliot Curie, F-91192 Gif Sur Yvette, France.
EM giuseppe.valenzise@12s.centralesupelec.fr
RI Dufaux, Frederic/HJJ-1496-2023
OI Dufaux, Frederic/0000-0001-6388-4112
CR Agrawal M., 2008, P EUR C COMP VIS
   Alahi A., 2012, P IEEE INT C COMP VI
   [Anonymous], 2014, 1593813 ISOIEC JTC 1
   [Anonymous], 2012, P INT C INT ROB SYST
   [Anonymous], 2009, IEEE INT C ROB AUT
   [Anonymous], P IEEE INT C ROB AUT
   [Anonymous], 2011, P IEEE INT C ROB AUT
   [Anonymous], 2014, N14509 ISOIEC JTC 1S
   [Anonymous], 2010, P EUR C COMP VIS
   Balntas V., 2017, IEEE T PATTERN ANAL, V99, P1
   Baroffio L., 2014, P IEEE INT C IM PROC
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Brown M., 2002, P BRIT MACH VIS C CA
   Canclini A., 2013, P IEEE INT C DIG SIG
   Chen X., 2017, P IEEE C COMP VIS PA, P3901
   do Nascimento ER, 2013, NEUROCOMPUTING, V120, P141, DOI 10.1016/j.neucom.2012.08.064
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, PROC CVPR IEEE, P4857, DOI 10.1109/CVPR.2017.516
   Fraundorfer F., 2005, P IEEE INT C COMP VI
   Gil A, 2010, MACH VISION APPL, V21, P905, DOI 10.1007/s00138-009-0195-x
   Gossow D., 2012, P IEEE INT C PATT RE
   Guan H., 2017, P IEEE C COMPUTER VI, P4516
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Heinly J., 2012, P EUR C COMP VIS
   Jain H., 2017, ARXIV170802932
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Karpushin M., 2015, P IEEE INT C IM P QU
   Karpushin M., 2016, P IEEE INT C AC SPEE
   Karpushin M., 2016, P EUR SIGN P C EURAS
   Karpushin M., 2014, P IEEE INT C IM P PA
   Karpushin M, 2015, IEEE INT CON MULTI
   Karpushin M, 2016, IEEE T MULTIMEDIA, V18, P1762, DOI 10.1109/TMM.2016.2590305
   Kitt B., 2010, P IEEE INT VEH S SAN
   Koser K., 2007, P IEEE INT C COMP VI
   Leutenegger S, 2011, P IEEE INT C COMP VI
   Lin B., 2015, P IEEE INT C IM P QU
   Ling H., 2005, P IEEE INT C COMP VI
   Lo TWR, 2009, COMPUT VIS IMAGE UND, V113, P1235, DOI 10.1016/j.cviu.2009.06.005
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mair E., 2010, P EUR C COMP VIS
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Moreno-Noguer F., 2011, P IEEE INT C COMP VI
   Mukherjee D, 2015, MACH VISION APPL, V26, P443, DOI 10.1007/s00138-015-0679-9
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pang YW, 2012, NEUROCOMPUTING, V85, P6, DOI 10.1016/j.neucom.2011.12.006
   Ramisa A., 2013, P IEEE INT C INT ROB
   ROSTEN E, 2005, P IEEE INT C COMP VI
   Rublee E., 2011, ICCV, P2564
   Rusu R. B., 2009, P IEEE INT C ROB AUT
   Shen Y., 2017, ARXIV170802531
   Sinha SN, 2011, MACH VISION APPL, V22, P207, DOI 10.1007/s00138-007-0105-z
   Tombari F., 2010, P EUR C COMP VIS
   Tombari F., 2011, COMBINED TEXTURE SHA
   Trzcinski T., 2013, P IEEE INT C COMP VI
   Vedaldi A., 2010, P INT C MULT MM 10
   Wu C., 2008, P IEEE INT C COMP VI
   Zaharescu A., 2009, P IEEE INT C COMP VI
   Zeng A., 2017, P IEEE C COMP VIS PA
NR 64
TC 3
Z9 3
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2018
VL 71
BP 1
EP 16
DI 10.1016/j.imavis.2017.11.007
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GB1QS
UT WOS:000428825900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chan, FKS
   Kong, AWK
AF Chan, Frodo Kin Sun
   Kong, Adams Wai Kin
TI A further study of low resolution androgenic hair patterns as a soft
   biometric trait
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Soft biometrics; Biometrics; Emetging biometrics; Forensics
ID TEXTURE; SCALE
AB Soft biometric traits such as skin color, tattoos, shoe size, height, and weight have been regularly used for forensic investigation, especially when hard biometric traits, e.g., faces and fingerprints are not available. Recently, a new soft biometric trait, androgenic hair also called body hair, was evaluated. The previous study showed that low resolution androgenic hair patterns have potential for forensic investigation. However, it was believed that they are not a distinctive biometric trait because of the reported accuracy. To explore discriminative information in androgenic hair patterns, in this paper, a new algorithm, which makes use of leg geometry to align lower leg images, large feature sets (about 60,000 features) extracted through multi-directional grid systems to increase discriminative power and robustness, and class-specific partial least squares (PLS) models to utilize the features effectively, is employed. To further enhance the performance of the class-specific PLS models trained on very limited positive samples, one to three images per model in the experiments, and further enhance robustness against viewpoint and pose variations, a scheme is designed to generate more positive samples from a single image. Experimental results on 1493 low resolution leg images with large viewpoint and pose variations from 412 legs demonstrate that low resolution androgenic hair patterns contain rich information and the impression of low discriminative power on androgenic hair is due to the method used in the previous study. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Chan, Frodo Kin Sun; Kong, Adams Wai Kin] Nanyang Technol Univ, Sch Comp Sci & Engn, Nanyang Ave, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chan, FKS (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Nanyang Ave, Singapore 639798, Singapore.
EM kchan008@e.ntu.edu.sg; adamskong@ntu.edu.sg
FU Ministry of Education Singapore through Academic Research Fund Tier 2
   [MOE2012-T2-1-024]
FX This work is partially supported by the Ministry of Education Singapore
   through Academic Research Fund Tier 2, MOE2012-T2-1-024.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2011, Daily Mail
   [Anonymous], 2011, CBC News
   [Anonymous], 2011, The Guardian
   [Anonymous], P INT JOINT C BIOM
   [Anonymous], 2013, Business Insider
   [Anonymous], 2015, CVPR
   Blume-Peytavi U., 2008, Hair Growth and Disorders, V1st edn
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Chan FKS, 2017, IEEE T INF FOREN SEC, V12, P1900, DOI 10.1109/TIFS.2017.2692684
   Chan FKS, 2014, INT C PATT RECOG, P495, DOI 10.1109/ICPR.2014.94
   Choi JY, 2012, IEEE T IMAGE PROCESS, V21, P1366, DOI 10.1109/TIP.2011.2168413
   Crowley JL, 1997, PROC CVPR IEEE, P640, DOI 10.1109/CVPR.1997.609393
   Dantcheva A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1356, DOI 10.1109/ICCVW.2011.6130409
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   eMarketer, 2 BILL CONS WORLDW G
   GARN SM, 1951, ANN NY ACAD SCI, V53, P498, DOI 10.1111/j.1749-6632.1951.tb31952.x
   Hao Y, 2008, IEEE IMAGE PROC, P281, DOI 10.1109/ICIP.2008.4711746
   Ho CH, 2012, J MACH LEARN RES, V13, P3323
   Islam MR, 2014, INT C PATT RECOG, P427, DOI 10.1109/ICPR.2014.82
   Jain AK, 2004, PROC SPIE, V5404, P561, DOI 10.1117/12.542890
   Jain AK, 2002, PATTERN RECOGN, V35, P2653, DOI 10.1016/S0031-3203(01)00218-7
   Kembhavi A, 2011, IEEE T PATTERN ANAL, V33, P1250, DOI 10.1109/TPAMI.2010.182
   Killourhy KS, 2009, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN.2009.5270346
   Kong AWK, 2006, PATTERN RECOGN, V39, P2149, DOI 10.1016/j.patcog.2006.04.035
   Liu ZM, 2010, PATTERN RECOGN, V43, P2882, DOI 10.1016/j.patcog.2010.03.003
   Mignotte M, 2008, IEEE T IMAGE PROCESS, V17, P780, DOI 10.1109/TIP.2008.920761
   Montagna W., 1958, BIOL HAIR GROWTH
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nurhudatiana A., 2011, P INT JOINT C BIOM, P1
   Nurhudatiana A, 2013, IEEE T INF FOREN SEC, V8, P998, DOI 10.1109/TIFS.2013.2258338
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qu HN, 2010, PATTERN RECOGN, V43, P3448, DOI 10.1016/j.patcog.2010.05.002
   Reid DA, 2014, IEEE T PATTERN ANAL, V36, P1216, DOI 10.1109/TPAMI.2013.219
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Schwartz WR, 2012, IEEE T IMAGE PROCESS, V21, P2245, DOI 10.1109/TIP.2011.2176951
   Srinivas N, 2012, IEEE T INF FOREN SEC, V7, P1536, DOI 10.1109/TIFS.2012.2206027
   Stenn KS, 2001, PHYSIOL REV, V81, P449, DOI 10.1152/physrev.2001.81.1.449
   Su H, 2014, IEEE T INF FOREN SEC, V9, P666, DOI 10.1109/TIFS.2014.2306591
   Tang CY, 2011, PROC CVPR IEEE, P665, DOI 10.1109/CVPR.2011.5995531
   Vogt A., 2008, HAIR GROWTH DISORDER
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Zeng XQ, 2014, PATTERN RECOGN, V47, P3726, DOI 10.1016/j.patcog.2014.05.022
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 49
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 125
EP 142
DI 10.1016/j.imavis.2017.08.009
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100011
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Choi, S
   Kim, JH
AF Choi, Sunglok
   Kim, Jong-Hwan
TI Fast and reliable minimal relative pose estimation under planar motion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Relative pose estimation; Planar motion; Epipolar geometry; Essential
   matrix; 2-point algorithm
ID STRUCTURE-FROM-MOTION; RANSAC
AB This paper proposes fast, reliable, and minimal non-iterative relative pose solvers under planar motion constraint. Relative pose estimation is popularly utilized in many important problems such as visual odometry and SLAM, and planar motion is common for mobile robots and vehicles on floors and roads. We transform the original problem formulation of finding intersections of two ellipses into more accessible form of finding intersections of a line and unit circle. Such transformation leads to a non-iterative and closed form solver, which enables significant speed-up compared to previous methods. The proposed algorithm is almost 9 times faster than the previous minimal solver with planar motion and around 90 times faster than the previous minimal solver with general motion. In addition, our algorithms provide reliable relative pose in degeneracy of the previous minimal planar solvers. Effectiveness of the proposed algorithms is demonstrated with two types of experiments: relative pose estimation with synthetic data and monocular visual odometry with real image sequences. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Choi, Sunglok] ETRI, Intelligent Robot Res Div, Daejeon, South Korea.
   [Choi, Sunglok] Korea Adv Inst Sci & Technol, Robot Program, Daejeon, South Korea.
   [Kim, Jong-Hwan] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Korea Advanced Institute of Science & Technology (KAIST); Korea Advanced
   Institute of Science & Technology (KAIST)
RP Kim, JH (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
EM johkim@rit.kaist.ac.kr
RI Choi, Sunglok/AAL-9797-2020; Kim, Jong-Hwan/C-1969-2011; Kim,
   Jong-Hwan/AFK-9063-2022
OI Choi, Sunglok/0000-0002-1127-1346; Kim, Jong-Hwan/0000-0002-4172-4174;
   Kim, Jong-Hwan/0000-0002-4172-4174
FU R&D program of the Korea Ministry of Land, Infrastructure and Transport
   (MOLIT); Korea Agency for Infrastructure Technology Advancement (KAIA),
   Train Station Service Standardization and the Development of Safety
   Management Automation Technology [14RTRP-B091404-01]
FX This work was supported by the R&D program of the Korea Ministry of
   Land, Infrastructure and Transport (MOLIT) and the Korea Agency for
   Infrastructure Technology Advancement (KAIA), Train Station Service
   Standardization and the Development of Safety Management Automation
   Technology (14RTRP-B091404-01).
CR [Anonymous], P IEEE INT C ROB AUT
   Choi S., 2010, P INT C UB ROB AMB I
   Choi SI, 2015, ADV ROBOTICS, V29, P1005, DOI 10.1080/01691864.2015.1024285
   Choi S, 2015, INT J CONTROL AUTOM, V13, P1454, DOI 10.1007/s12555-014-0157-6
   Choi S, 2013, INT CONF UBIQ ROBOT, P604, DOI 10.1109/URAI.2013.6677403
   Choi S, 2011, 2011 11TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P1480
   Choi S, 2008, IEEE SYS MAN CYBERN, P3464
   Chou CC, 2015, IEEE INT CONF ROBOT, P3646, DOI 10.1109/ICRA.2015.7139705
   Civera J, 2010, J FIELD ROBOT, V27, P609, DOI 10.1002/rob.20345
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hong S, 2016, ELECTRON LETT, V52, P355, DOI 10.1049/el.2015.2500
   Im S, 2015, IEEE I CONF COMP VIS, P837, DOI 10.1109/ICCV.2015.102
   Lee GH, 2013, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2013.354
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Ortín D, 2001, ROBOTICA, V19, P331, DOI 10.1017/S0263574700003143
   Pajdla T., ICCV 2015 TUTORIAL
   Scaramuzza D, 2011, INT J COMPUT VISION, V95, P74, DOI 10.1007/s11263-011-0441-3
   Stewénius H, 2008, IMAGE VISION COMPUT, V26, P871, DOI 10.1016/j.imavis.2007.10.003
   Stewénius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005
   Troiani C., 2014, P IEEE INT C ROB AUT
NR 23
TC 21
Z9 21
U1 2
U2 18
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 103
EP 112
DI 10.1016/j.imavis.2017.08.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100009
DA 2024-07-18
ER

PT J
AU Tian, Q
   Chen, SC
AF Tian, Qing
   Chen, Songcan
TI Joint gender classification and age estimation by nearly orthogonalizing
   their semantic spaces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gender classification; Age estimation; Nearly orthogonal semantic
   spaces; Support vector ordinal regression; Discriminant learning for
   ordinal regression
ID FACE; RECOGNITION; IMAGE; REGRESSION; MODEL; ATTRIBUTES; PATTERNS;
   FEATURES
AB In human face-based biometrics, gender classification and age estimation are two important research topics. Although a variety of approaches have been proposed to handle them, just a few of them are solved jointly, even so, these joint methods do not specifically concern the semantic difference between human gender and age, which is intuitively helpful for joint learning, consequently leaving us a room of further improving their performance. To this end, in this work we firstly propose a general learning framework for jointly estimating human gender and age by attempting to formulate such semantic relationships as a form of near orthogonality regularization and then to incorporate it into the objective of the joint learning framework. In order to evaluate the effectiveness of the proposed framework, we exemplify it by respectively taking the widely used binary-class SVM for gender classification, and two threshold-based ordinal regression methods (i.e., the discriminant learning for ordinal regression and support vector ordinal regression) for age estimation, and crucially coupling both through the proposed semantic formulation. Moreover, we construct its nonlinear counterpart by deriving a representer theorem for the joint learning strategy. Finally, extensive experiments on four aging datasets, i.e., FG-NET, Morph Album I, Album II and Images of Groups demonstrate the effectiveness and superiority of the proposed strategy. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Tian, Qing] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Tian, Qing] Nanjing Univ Informat Sci & Technol, Jiangsu Engn Ctr Network Monitoring, Nanjing 210044, Jiangsu, Peoples R China.
   [Tian, Qing; Chen, Songcan] Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Jiangsu, Peoples R China.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Nanjing University of
   Aeronautics & Astronautics
RP Chen, SC (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Comp Sci & Technol, Nanjing 211106, Jiangsu, Peoples R China.
EM s.chen@nuaa.edu.cn
RI tian, qing/JMQ-8820-2023
FU National Natural Science Foundation of China [61702273, 61472186];
   Natural Science Foundation of Jiangsu Province [BK20170956]; Natural
   Science Foundation of the Jiangsu Higher Education Institutions of China
   [17KJB520022]; Priority Academic Program Development of Jiangsu Higher
   Education Institutions; Startup Foundation for Talents of Nanjing
   University of Information Science and Technology
FX The authors first want to thank the Pattern Recognition and Neural
   Computing (ParNec) laboratory of Nanjing University of Aeronautics and
   Astronautics because the initial work of this paper was done there.
   Besides, we would like to thank Junliang Xing, et al. (Institute of
   Automation, Chinese Academy of Sciences) who provided source codes for
   our experimental comparison. This work was partially supported by the
   National Natural Science Foundation of China under grants 61702273 and
   61472186, the Natural Science Foundation of Jiangsu Province under grant
   BK20170956, the Natural Science Foundation of the Jiangsu Higher
   Education Institutions of China under grant 17KJB520022, a Project
   Funded by the Priority Academic Program Development of Jiangsu Higher
   Education Institutions, and the Startup Foundation for Talents of
   Nanjing University of Information Science and Technology.
CR Aghajanian J, 2009, IEEE I CONF COMP VIS, P1125, DOI 10.1109/ICCV.2009.5459352
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], P 10 IEEE INT C WORK
   [Anonymous], 2016, ACCV 3
   [Anonymous], 2008, SUPPORT VECTOR MACHI
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.532
   [Anonymous], 2006, P 14 ANN ACM INT C M
   [Anonymous], NEURAL COMPUT APPL
   Antipov G, 2016, PATTERN RECOGN LETT, V70, P59, DOI 10.1016/j.patrec.2015.11.011
   Ballihi L, 2012, IEEE T INF FOREN SEC, V7, P1766, DOI 10.1109/TIFS.2012.2209876
   Castrillón-Santana M, 2017, IMAGE VISION COMPUT, V57, P15, DOI 10.1016/j.imavis.2016.10.004
   Castrillon-Santana M, 2016, PATTERN RECOGN LETT, V82, P181, DOI 10.1016/j.patrec.2015.09.014
   Chen K, 2013, PROC CVPR IEEE, P2467, DOI 10.1109/CVPR.2013.319
   Chen YY, 2013, IEEE T MULTIMEDIA, V15, P1283, DOI 10.1109/TMM.2013.2265077
   Chu W., 2005, P INT C MACH LEARN N, P145
   Dantcheva A, 2017, IEEE T INF FOREN SEC, V12, P719, DOI 10.1109/TIFS.2016.2632070
   Das M, 2003, IEEE SYS MAN CYBERN, P3726
   Del Coco M, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P271, DOI 10.1109/AVSS.2016.7738061
   Dibeklioglu H, 2015, IEEE T MULTIMEDIA, V17, P279, DOI 10.1109/TMM.2015.2394777
   Du YJ, 2016, MULTIMED TOOLS APPL, V75, P987, DOI 10.1007/s11042-014-2338-y
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2006, IEEE T CIRC SYST VID, V16, P830, DOI 10.1109/TCSVT.2006.877398
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Geng X, 2009, INT CONF ACOUST SPEE, P865, DOI 10.1109/ICASSP.2009.4959721
   Guo G., 2010, IEEE COMP SOC C COMP, P71, DOI DOI 10.1109/CVPRW.2010.5543609
   Guo GD, 2014, PROC CVPR IEEE, P4257, DOI 10.1109/CVPR.2014.542
   Guo GD, 2012, PROC CVPR IEEE, P2547, DOI 10.1109/CVPR.2012.6247972
   Guo GD, 2011, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2011.5995404
   Guo GD, 2009, IEEE I CONF COMP VIS, P1986, DOI 10.1109/ICCV.2009.5459438
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guodong Guo, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P2032, DOI 10.1109/ICCVW.2009.5457531
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Huang D, 2014, IMAGE VISION COMPUT, V32, P1181, DOI 10.1016/j.imavis.2014.06.009
   Jia S, 2016, INT CONF DAT MIN WOR, P462, DOI [10.1109/ICDMW.2016.0072, 10.1109/ICDMW.2016.45]
   Juefei-Xu F, 2016, IEEE COMPUT SOC CONF, P136, DOI 10.1109/CVPRW.2016.24
   Lanitis A, 2004, IEEE T SYST MAN CY B, V34, P621, DOI 10.1109/TSMCB.2003.817091
   Lapedriza A, 2006, INT C PATT RECOG, P834
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li CS, 2012, INT C PATT RECOG, P2327
   Li CS, 2012, PROC CVPR IEEE, P2570, DOI 10.1109/CVPR.2012.6247975
   Li K, 2017, PATTERN RECOGN, V66, P95, DOI 10.1016/j.patcog.2017.01.007
   Liang YX, 2011, IEEE IMAGE PROC, P565, DOI 10.1109/ICIP.2011.6116611
   Linoff G.S., 2011, Data Mining Techniques: For Marketing, Sales, and Customer Relationship Management, V3
   Liu H, 2017, PATTERN RECOGN, V66, P82, DOI 10.1016/j.patcog.2016.10.026
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727
   Lu JW, 2011, INT CONF ACOUST SPEE, P1477
   Mahmood SF, 2017, NEUROCOMPUTING, V219, P312, DOI 10.1016/j.neucom.2016.09.046
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Meier L, 2008, J R STAT SOC B, V70, P53, DOI 10.1111/j.1467-9868.2007.00627.x
   Patel B, 2016, NEUROCOMPUTING, V218, P203, DOI 10.1016/j.neucom.2016.08.055
   Patterson E., 2007, BTAS, P1, DOI 10.1109/BTAS.2007.4401953
   Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Rothe R., 2016, International Journal of Computer Vision, P1
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Shashidhar KK, 2014, ADV INTELL SYST, V216, P169, DOI 10.1007/978-81-322-1299-7_17
   Su Y, 2010, INT CONF ACOUST SPEE, P1270, DOI 10.1109/ICASSP.2010.5495414
   Sun BY, 2010, IEEE T KNOWL DATA EN, V22, P906, DOI 10.1109/TKDE.2009.170
   Tian Q, 2015, NEUROCOMPUTING, V165, P456, DOI 10.1016/j.neucom.2015.03.078
   Van Leeuwen Peter, 2004, BMC Pregnancy Childbirth, V4, P6, DOI 10.1186/1471-2393-4-6
   Wang C, 2012, INT C PATT RECOG, P2432
   Wang JG, 2010, I C CONT AUTOMAT ROB, P1860, DOI 10.1109/ICARCV.2010.5707370
   Wang SF, 2016, MULTIMED TOOLS APPL, V75, P8419, DOI 10.1007/s11042-015-2756-5
   Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77
   Wang Y, 2010, NAT COMMUN, V1, DOI 10.1038/ncomms1089
   Weixin Li, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P19, DOI 10.1109/ICB.2012.6199753
   Wu YD, 2013, IEEE T MULTIMEDIA, V15, P778, DOI 10.1109/TMM.2013.2238910
   Xia BG, 2015, PATTERN RECOGN, V48, P746, DOI 10.1016/j.patcog.2014.09.021
   Xing JH, 2017, PATTERN RECOGN, V66, P106, DOI 10.1016/j.patcog.2017.01.005
   Yang W., 2016, MULTIMED TOOLS APPL, P1
   Yang X, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P344, DOI 10.1109/ICCVW.2015.53
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
   Yi D, 2015, LECT NOTES COMPUT SC, V9005, P144, DOI 10.1007/978-3-319-16811-1_10
   Yun F, 2004, IEEE SYS MAN CYBERN, P2180
   Zhang C, 2013, IEEE COMPUT SOC CONF, P458, DOI 10.1109/CVPRW.2013.75
   Zhang WH, 2016, COMPUT VIS IMAGE UND, V149, P32, DOI 10.1016/j.cviu.2016.03.014
   Zhu Y, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P267, DOI 10.1109/ICCVW.2015.43
NR 78
TC 15
Z9 16
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 9
EP 21
DI 10.1016/j.imavis.2017.10.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lucas, GM
   Gratch, J
   Malandrakis, N
   Szablowski, E
   Fessler, E
   Nichols, J
AF Lucas, Gale M.
   Gratch, Jonathan
   Malandrakis, Nikolaos
   Szablowski, Evan
   Fessler, Eli
   Nichols, Jeffrey
TI GOAALLL!: Using sentiment in the world cup to explore theories of
   emotion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sentiment; Sentiment analysis; Sport; Emotion models; Twitter
ID HOT HAND
AB Sporting events evoke strong emotions among fans and thus act as natural laboratories to explore emotions and how they unfold in the wild. Computational tools, such as sentiment analysis, provide new ways to examine such dynamic emotional processes. In this article we use sentiment analysis to examine tweets posted during 2014 World Cup. Such analysis gives insight into how people respond to highly emotional events, and how these emotions are shaped by contextual factors, such as prior expectations, and how these emotions change as events unfold over time. Here we report on some preliminary analysis of a World Cup twitter corpus using sentiment analysis techniques. After performing initial tests of validation for sentiment analysis on data in this corpus, we show these tools can give new insights into existing theories of what makes a sporting match exciting. This analysis seems to suggest that, contrary to assumptions in sports economics, excitement relates to expressions of negative emotion. The results are discussed in terms of innovations in methodology and understanding the role of emotion for "tuning in" to real world events. We also discuss some challenges that such data present for existing sentiment analysis techniques and discuss future analysis. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Lucas, Gale M.; Gratch, Jonathan; Malandrakis, Nikolaos; Szablowski, Evan; Fessler, Eli; Nichols, Jeffrey] Univ Southern Calif, Inst Creat Technol, 12015 Waterfront Dr, Playa Vista, CA 90094 USA.
C3 University of Southern California
RP Gratch, J (corresponding author), Univ Southern Calif, Inst Creat Technol, 12015 Waterfront Dr, Playa Vista, CA 90094 USA.
EM gratch@ict.usc.edu
FU National Science Foundation [1,263,386]; US Army
FX This research was supported by the National Science Foundation under
   grant 1,263,386 and the US Army. The content does not necessarily
   reflect the position or the policy of any Government, and no official
   endorsement should be inferred.
CR Alavy K, 2010, INT J SPORT FINANC, V5, P75
   [Anonymous], 2014, 8 INT WORKSHOP SEMEV
   Artemenko O., 2006, Applied Computing 2006. 21st Annual ACM Symposium on Applied Computing, P859, DOI 10.1145/1141277.1141473
   Bar-Eli M, 2006, PSYCHOL SPORT EXERC, V7, P525, DOI 10.1016/j.psychsport.2006.03.001
   Bird Steven, 2009, NATURAL LANGUAGE PRO, DOI DOI 10.1007/S10579-010-9124-X
   Clore G. L., 2007, JOY VICTORY AGNONY D
   Dredge S., 2014, The Guardian
   FERNANDEZ-DOLS JM, 1995, J PERS SOC PSYCHOL, V69, P1113, DOI 10.1037/0022-3514.69.6.1113
   GILOVICH T, 1985, COGNITIVE PSYCHOL, V17, P295, DOI 10.1016/0010-0285(85)90010-6
   Gupta R., 2014, P 4 INT WORKSH AUD V, P33, DOI [DOI 10.1145/2661806.2661810, 10.1145/2661806.2661810]
   Hall M., 1999, PhD thesis, DOI 10.1.1.149.3848
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P1114, DOI 10.1109/TMM.2005.858397
   KAHNEMAN D, 1979, ECONOMETRICA, V47, P263, DOI 10.2307/1914185
   Malandrakis Nikolaos, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4838, DOI 10.1109/ICASSP.2014.6854521
   Malandrakis N, 2013, IEEE T AUDIO SPEECH, V21, P2379, DOI 10.1109/TASL.2013.2277931
   MEDVEC VH, 1995, J PERS SOC PSYCHOL, V69, P603, DOI 10.1037/0022-3514.69.4.603
   Nakov P., 2016, P 10 INT WORKSH SEM, P1, DOI [DOI 10.18653/V1/S16-1001, 10.18653/v1/S16-1001]
   Nichols J., 2012, Summarizing sporting events using Twitter, P189, DOI DOI 10.1145/2166966.2166999
   Owoputi Olutobi, 2013, Proceedings of the 2013 conference of the North American chapter of the association for computational linguistics: human language technologies, P380, DOI DOI 10.1177/001316446002000104
   Palogiannidi E., 2016, SemEval@ NAACL-HLT, P155
   Pawlowski T., 2013, J SPORTS EC
   Rosenthal S., 2014, P SEMEVAL2014
   ROTTENBERG S, 1956, J POLIT ECON, V64, P242, DOI 10.1086/257790
   Szymanski S, 2003, J ECON LIT, V41, P1137, DOI 10.1257/002205103771800004
   Zhao S., 2011, CoRR
NR 25
TC 21
Z9 23
U1 2
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2017
VL 65
SI SI
BP 58
EP 65
DI 10.1016/j.imavis.2017.01.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA FJ3GM
UT WOS:000412618500007
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, XL
   Guo, GD
   Merler, M
   Codella, NCF
   Rohith, M
   Smith, JR
   Kambhamettu, C
AF Wang, Xiaolong
   Guo, Guodong
   Merler, Michele
   Codella, Noel C. F.
   Rohith, M., V
   Smith, John R.
   Kambhamettu, Chandra
TI Leveraging multiple cues for recognizing family photos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Family photo recognition; Social media; Semantics; Group photo analysis
ID CONVEX-HULL; FACE DESCRIPTION; IMAGES
AB Social relation analysis via images is a new research area that has attracted much interest recently. As social media usage increases, a wide variety of information can be extracted from the growing number of consumer photos shared online, such as the category of events captured or the relationships between individuals in a given picture. Family is one of the most important units in our society, thus categorizing family photos constitutes an essential step toward image-based social analysis and content-based retrieval of consumer photos. We propose an approach that combines multiple unique and complimentary cues for recognizing family photos. The first cue analyzes the geometric arrangement of people in the photograph, which characterizes scene-level information with efficient yet discriminative capability. The Second cue models facial appearance similarities to capture and quantify relevant pairwise relations between individuals in a given photo. The last cue investigates the semantics of the context in which the photo was taken. Experiments on a dataset containing thousands of family and non-family pictures collected from social media indicate that each individual model produces good recognition results. Furthermore, a combined approach incorporating appearance, geometric and semantic features significantly outperforms the state of the art in this domain, achieving 96.7% classification accuracy. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Wang, Xiaolong; Rohith, M., V; Kambhamettu, Chandra] Univ Delaware, CIS, Newark, DE 19716 USA.
   [Guo, Guodong] West Virginia Univ, LCSEE, Morgantown, WV 26506 USA.
   [Merler, Michele; Codella, Noel C. F.; Smith, John R.] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
C3 University of Delaware; West Virginia University; International Business
   Machines (IBM)
RP Wang, XL (corresponding author), Univ Delaware, CIS, Newark, DE 19716 USA.
EM xiaolong@udel.edu; guodong.guo@mail.wvu.edu; mimerler@us.ibm.com;
   nccodell@us.ibm.com; jsmith@us.ibm.com; chandrak@udel.edu
RI Smith, John/GYJ-1302-2022; Smith, John/Y-2316-2019; Smith,
   John/HJB-2300-2022
OI Smith, John/0000-0001-6885-1117; 
FU Direct For Computer & Info Scie & Enginr; Division Of Computer and
   Network Systems [1066197] Funding Source: National Science Foundation
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alsabti K, 1998, FIRST MERGED INTERNATIONAL PARALLEL PROCESSING SYMPOSIUM & SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING, P556, DOI 10.1109/IPPS.1998.669980
   [Anonymous], UNDERSTANDING IMAGES
   [Anonymous], 2010, Evaluation of pooling operations in convolutional architectures for object recognition, DOI [10.1007/978-3-642- 15825-4_10., DOI 10.1007/978-3-642-15825-4_10, 10.1007/978-3-642-15825-4_10]
   [Anonymous], STUDY HUMAN AGE ESTI
   [Anonymous], 2015 IEEE WINT C APP
   [Anonymous], 1999, The Nature Statist. Learn. Theory
   [Anonymous], 2015, MATH PROB ENG, DOI DOI 10.1016/J.CMET.2015.09.010
   [Anonymous], 1991, DFT/FFT and Convolution Algorithms: Theory and Implementation
   [Anonymous], KINSHIP CLASSIFICATI
   [Anonymous], 2012, P 20 ACM INT C MULT, DOI DOI 10.1145/2393347.2393439
   [Anonymous], 2014 IEEE C COMP VIS
   [Anonymous], MEMORY EFFICIENT LAR
   [Anonymous], 2015 IEEE 12 INT S B
   [Anonymous], 2014 INT JOINT C NEU
   [Anonymous], NANDAKUMAR INTRO BIO
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2014 IEEE INT C IM P
   [Anonymous], LOCATING FACIAL FEAT
   [Anonymous], P 6 ACM MULT SYST C
   [Anonymous], 2014, BRIT MACH VIS C BMVC
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 1990, NIPS
   [Anonymous], 1992, COMPUTATIONAL FRAMEW
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 2006, SOUND EFFICIENT INFE
   Ayache S, 2007, LECT NOTES COMPUT SC, V4425, P494
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Corney J, 2002, IEEE COMPUT GRAPH, V22, P65, DOI 10.1109/MCG.2002.999789
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Fierrez-Aguilar J, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P5
   GRAHAM RL, 1983, J ALGORITHM, V4, P324, DOI 10.1016/0196-6774(83)90013-5
   Guo GD, 2012, IEEE T INSTRUM MEAS, V61, P2322, DOI 10.1109/TIM.2012.2187468
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guo R, 2016, IEEE WINT CONF APPL
   Guodong Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3392, DOI 10.1109/ICPR.2010.828
   Hershberger J, 1998, COMP GEOM-THEOR APPL, V11, P175, DOI 10.1016/S0925-7721(98)00027-3
   Horvath T., 1992, Computer Graphics Forum, V11, P163, DOI 10.1111/1467-8659.1120163
   Huang G.B., 2008, PROC WORKSHOP FACES
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2012, PROC CVPR IEEE, P2594, DOI 10.1109/CVPR.2012.6247978
   Lukaszewski A, 1999, VACUUM, V54, P67, DOI 10.1016/S0042-207X(98)00437-0
   Meeran S, 1997, MECHATRONICS, V7, P737, DOI 10.1016/S0957-4158(97)00033-0
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Ng HW, 2014, IEEE IMAGE PROC, P343, DOI 10.1109/ICIP.2014.7025068
   Peng X, 2015, IEEE I CONF COMP VIS, P3880, DOI 10.1109/ICCV.2015.442
   Peng X, 2015, COMPUT VIS IMAGE UND, V136, P92, DOI 10.1016/j.cviu.2015.03.008
   Rui Yong., 1996, PROC 1 INT WORKSHOP, P22
   Serre T, 2007, P NATL ACAD SCI USA, V104, P6424, DOI 10.1073/pnas.0700622104
   Singla Parag, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563047
   Smith JR, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2398590
   Sun Y, 2014, ADV NEUR IN, V27
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Vezzetti E, 2012, IMAGE VISION COMPUT, V30, P698, DOI 10.1016/j.imavis.2012.02.007
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang G, 2010, LECT NOTES COMPUT SC, V6315, P169, DOI 10.1007/978-3-642-15555-0_13
   Wang XL, 2013, 2013 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA 2013), VOL 2, P309, DOI 10.1109/ICMLA.2013.141
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Xu CH, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P308
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
NR 70
TC 6
Z9 7
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 61
EP 75
DI 10.1016/j.imavis.2016.07.006
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700007
DA 2024-07-18
ER

PT J
AU Gil-Jiménez, P
   Gómez-Moreno, H
   López-Sastre, RJ
   Bermejillo-Martín-Romo, A
AF Gil-Jimenez, Pedro
   Gomez-Moreno, Hilario
   Lopez-Sastre, Roberto J.
   Bermejillo-Martin-Romo, Alberto
TI Estimating the focus of expansion in a video sequence using the
   trajectories of interest points
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Focus of expansion; Optical flow; Interest point; Point trajectory;
   Cross ratio
ID INDEPENDENT MOTION
AB In this paper, we present a new algorithm for the computation of the focus of expansion in a video sequence. Although several algorithms have been proposed in the literature for its computation, almost all of them are based on the optical flow vectors between a pair of consecutive frames, so being very sensitive to noise, optical flow errors and camera vibrations. Our algorithm is based on the computation of the vanishing point of point trajectories, thus integrating information for more than two consecutive frames. It can improve performance in the presence of erroneous correspondences and occlusions in the field of view of the camera. The algorithm has been tested with virtual sequences generated with Blender, as well as some real sequences from both, the public KITTI benchmark, and a number of challenging video sequences also proposed in this paper. For comparison purposes, some algorithms from the literature have also been implemented. The results show that the algorithm has proven to be very robust, outperforming the compared algorithms, specially in outdoor scenes, where the lack of texture can make optical flow algorithms yield inaccurate results. Timing evaluation proves that the proposed algorithm can reach up to 15fps, showing its suitability for real-time applications. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Gil-Jimenez, Pedro; Gomez-Moreno, Hilario; Lopez-Sastre, Roberto J.; Bermejillo-Martin-Romo, Alberto] Univ Alcala de Henares, Dept Teoria Senal & Comunicac, Alcala De Henares 28805, Madrid, Spain.
C3 Universidad de Alcala
RP Gil-Jiménez, P (corresponding author), Univ Alcala de Henares, Dept Teoria Senal & Comunicac, Alcala De Henares 28805, Madrid, Spain.
EM pedro.gil@uah.es
RI Sastre, Roberto Lopez/AAA-2180-2019; Gomez Moreno, Hilario/J-6410-2012;
   Jiménez, Pedro Gil/F-4066-2017
OI Sastre, Roberto Lopez/0000-0002-2477-0152; Gomez Moreno,
   Hilario/0000-0002-8284-6733; Jiménez, Pedro Gil/0000-0002-6991-0702
FU  [CCG2014/EXP-055];  [TEC2013-45183-R]
FX This research was supported by projects CCG2014/EXP-055 and
   TEC2013-45183-R.
CR Badino H., 2011, The CMU Visual Localization Data Set
   Bak A, 2011, LECT NOTES COMPUT SC, V6978, P484, DOI 10.1007/978-3-642-24085-0_50
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Born C., 1994, P DTSCH ARB MUST, P711
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A., 2012, CVPR
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Herdtweck C., 2012, IEEE INT C MULT FUS
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   NEGAHDARIPOUR S, 1989, COMPUT VISION GRAPH, V46, P303, DOI 10.1016/0734-189X(89)90035-2
   Raudies F, 2012, COMPUT VIS IMAGE UND, V116, P606, DOI 10.1016/j.cviu.2011.04.004
   Sazbon D, 2004, MACH VISION APPL, V15, P229, DOI 10.1007/s00138-004-0152-7
   Scaramuzza D, 2011, IEEE ROBOT AUTOM MAG, V18, P80, DOI 10.1109/MRA.2011.943233
   Sharma R, 1996, IEEE T SYST MAN CY B, V26, P42, DOI 10.1109/3477.484437
   Suhr JK, 2008, PATTERN RECOGN LETT, V29, P828, DOI 10.1016/j.patrec.2007.11.019
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Woelk F, 2007, LECT NOTES COMPUT SC, V3417, P209
   Wu FC, 2007, PATTERN RECOGN, V40, P1971, DOI 10.1016/j.patcog.2006.07.013
NR 22
TC 5
Z9 9
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2016
VL 50
BP 14
EP 26
DI 10.1016/j.imavis.2016.03.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4KP
UT WOS:000378465100002
DA 2024-07-18
ER

PT J
AU Lee, S
   Lee, JH
   Lim, J
   Suh, IH
AF Lee, Sehyung
   Lee, Jin Han
   Lim, Jongwoo
   Suh, Il Hong
TI Robust stereo matching using adaptive random walk with restart algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Global optimization; Random walk with restart; Stereo matching;
   Superpixels
AB In this paper, we propose a robust dense stereo reconstruction algorithm using a random walk with restart. The pixel-wise matching costs are aggregated into superpixels and the modified random walk with restart algorithm updates the matching cost for all possible disparities between the superpixels. In comparison to the majority of existing stereo methods using the graph cut, belief propagation, or semi-global matching, our proposed method computes the final reconstruction through the determination of the best disparity at each pixel in the matching cost update. In addition, our method also considers occlusion and depth discontinuities through the visibility and fidelity terms. These terms assist in the cost update procedure in the calculation of the standard smoothness constraint. The method results in minimal computational costs while achieving high accuracy in the reconstruction. We test our method on standard benchmark datasets and challenging real-world sequences. We also show that the processing time increases linearly in relation to an increase in the disparity search range. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Lee, Sehyung; Lee, Jin Han; Suh, Il Hong] Hanyang Univ, Dept Elect & Comp Engn, Seoul 133791, South Korea.
   [Lim, Jongwoo] Hanyang Univ, Div Comp Sci & Engn, Seoul 133791, South Korea.
C3 Hanyang University; Hanyang University
RP Lim, J (corresponding author), Hanyang Univ, Div Comp Sci & Engn, Seoul 133791, South Korea.
EM shl@incorl.hanyang.ac.kr; jhlee@incorl.hanyang.ac.kr;
   jlim@hanyang.ac.kr; ihsuh@hanyang.ac.kr
FU MSIP/IITP [10047078]; Industrial Strategic Technology Development
   Program - Ministry of Trade, Industry and Energy (MOTIE, Korea)
   [10044009]
FX This work was supported by the ICT R&D programs of MSIP/IITP (No.
   10047078) and by the Industrial Strategic Technology Development Program
   (10044009) funded by the Ministry of Trade, Industry and Energy (MOTIE,
   Korea).
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2013, P INT C SCAL SPAC VA, DOI DOI 10.1007/978-3-642-38267-3_24
   Bleyer M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3081, DOI 10.1109/CVPR.2011.5995581
   Bleyer M., P BMVC, P14
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Cech J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3129, DOI 10.1109/CVPR.2011.5995442
   Cech J., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Çigla C, 2012, LECT NOTES COMPUT SC, V7584, P134, DOI 10.1007/978-3-642-33868-7_14
   De-Maeztu L, 2011, IEEE I CONF COMP VIS, P1708, DOI 10.1109/ICCV.2011.6126434
   Einecke N., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P227, DOI 10.1109/DICTA.2010.49
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3
   He J., P 12 ANN ACM INT C M, P9
   Hermann S., LNCS
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Khan W., 2013, MLTECHTR82 U AUCKL
   Kim TH, 2008, LECT NOTES COMPUT SC, V5304, P264
   Klaus A, 2006, INT C PATT RECOG, P15
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Kostkova J., P BMVC, V1
   Koutra D, 2011, LECT NOTES ARTIF INT, V6912, P245, DOI 10.1007/978-3-642-23783-6_16
   Li G., 2006, COMP VIS PATT REC 20, V2, P2355
   Mei X, 2011, PROC CVPR IEEE, P1257
   Ranftl R, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P401, DOI 10.1109/IVS.2012.6232171
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Spangenberg R., COMPUTER ANAL IMAGES, P34
   Sun J, 2005, PROC CVPR IEEE, P399
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   Yamaguchi K, 2013, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2013.243
   Yamaguchi K, 2012, LECT NOTES COMPUT SC, V7576, P45, DOI 10.1007/978-3-642-33715-4_4
   Yang QQ, 2014, IMAGE VISION COMPUT, V32, P202, DOI 10.1016/j.imavis.2014.01.001
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zabih R., 1994, P ECCV, P151
   Zhang K, 2012, INT C PATT RECOG, P356
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu SQ, 2012, LECT NOTES COMPUT SC, V7576, P101, DOI 10.1007/978-3-642-33715-4_8
   Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8
NR 41
TC 41
Z9 51
U1 0
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2015
VL 37
BP 1
EP 11
DI 10.1016/j.imavis.2015.01.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CI8NK
UT WOS:000355028800001
DA 2024-07-18
ER

PT J
AU Zhang, LG
   Tjondronegoro, D
   Chandran, V
AF Zhang, Ligang
   Tjondronegoro, Dian
   Chandran, Vinod
TI Representation of facial expression categories in continuous
   arousal-valence space: Feature and correlation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Dimensional space; Continuous axis;
   Correlation; Categorized emotion
ID RECOGNITION
AB Representation of facial expressions using continuous dimensions has shown to be inherently more expressive and psychologically meaningful than using categorized emotions, and thus has gained increasing attention over recent years. Many sub-problems have arisen in this new field that remain only partially understood. A comparison of the regression performance of different texture and geometric features and the investigation of the correlations between continuous dimensional axes and basic categorized emotions are two of these. This paper presents empirical studies addressing these problems, and it reports results from an evaluation of different methods for detecting spontaneous facial expressions within the arousal-valence (AV) dimensional space. The evaluation compares the performance of texture features (SIFT, Gabor, LBP) against geometric features (FAP-based distances), and the fusion of the two. It also compares the prediction of arousal and valence, obtained using the best fusion method, to the corresponding ground truths. Spatial distribution, shift, similarity, and correlation are considered for the six basic categorized emotions (i.e. anger, disgust, fear, happiness, sadness, surprise). Using the NVIE database, results show that the fusion of LBP and FAP features performs the best. The results from the NVIE and FEEDTUM databases reveal novel findings about the correlations of arousal and valence dimensions to each of six basic emotion categories. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Zhang, Ligang] Xian Univ Technol, Fac Comp Sci & Engn, Xian 710048, Peoples R China.
   [Zhang, Ligang; Tjondronegoro, Dian; Chandran, Vinod] Queensland Univ Technol, Fac Sci & Engn, Brisbane, Qld 4000, Australia.
C3 Xi'an University of Technology; Queensland University of Technology
   (QUT)
RP Zhang, LG (corresponding author), Xian Univ Technol, Fac Comp Sci & Engn, 5 South Jinhua Rd, Xian 710048, Peoples R China.
EM lg.zhang@xaut.edu.cn; dian@qut.edu.au; v.chandran@qut.edu.au
RI Tjondronegoro, Dian/AAE-4685-2022; Chandran, Vinod/N-3053-2019
OI Tjondronegoro, Dian/0000-0001-7446-2839; Chandran,
   Vinod/0000-0003-3185-0852
FU National Natural Science Foundation of China [61402362]; Xi'an
   University of Technology [116-211406]
FX This work is funded by the National Natural Science Foundation of China
   (Grant No. 61402362) and the Xi'an University of Technology (Grant No.
   116-211406).
CR [Anonymous], FACIAL ACTION CODING
   [Anonymous], 2013, P 3 ACM INT WORKSHOP
   [Anonymous], INT C INT SYST COMP
   [Anonymous], P BRIT MACH VIS C LE
   [Anonymous], 2013, 10 IEEE INT C WORKSH
   Berretti S., 2010, P INT C PATTERN RECO, P4125
   Caridakis G, 2010, J MULTIMODAL USER IN, V3, P49, DOI [10.1007/s12193-009-0030, 10.1007/s12193-009-0030-8]
   Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cummins N., 2013, P 3 ACM INT WORKSH A, P11
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Du Y., 2007, P 6 ACM INT C IM VID, P395
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Eyben F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P322, DOI 10.1109/FG.2011.5771417
   Eyben F., 2009, 3 INT C AFF COMP INT, P1, DOI DOI 10.1109/ACII.2009.5349350
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Gunes H., 2009, INT J SYNTH EMOT, V1, P68
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   Gunes H, 2011, COMPUTER ANALYSIS OF HUMAN BEHAVIOR, P255, DOI 10.1007/978-0-85729-994-9_10
   Hall M. A., 1999, Correlation-based feature subset selection for machine learning
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Harris RJ, 2012, P NATL ACAD SCI USA, V109, P21164, DOI 10.1073/pnas.1212207110
   Ligang Zhang, 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P620, DOI 10.1109/DICTA.2011.110
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   Nicolaou Mihalis A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P16, DOI 10.1109/FG.2011.5771396
   Nicolaou Mihalis A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3695, DOI 10.1109/ICPR.2010.900
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Nicolaou MihalisA., 2013, Proceedings of the 21st ACM international conference on Multimedia, P773
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Osgood C. E., 1957, The measurement of meaning
   Pandzic I.S., 2002, MPEG 4 FACIAL ANIMAT
   Pantic M., 2005, 13th Annual ACM International Conference on Multimedia, P669, DOI 10.1145/1101149.1101299
   Ramirez GA, 2011, LECT NOTES COMPUT SC, V6975, P396, DOI 10.1007/978-3-642-24571-8_51
   RUSSELL JA, 1980, J PERS SOC PSYCHOL, V39, P1161, DOI 10.1037/h0077714
   Schuller B, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P361
   Schuller B, 2011, LECT NOTES COMPUT SC, V6975, P415, DOI 10.1007/978-3-642-24571-8_53
   Shan CF, 2005, LECT NOTES COMPUT SC, V3766, P221, DOI 10.1007/11573425_22
   Shin YS, 2007, LECT NOTES COMPUT SC, V4488, P81
   Song ML, 2010, IEEE T SYST MAN CY B, V40, P779, DOI 10.1109/TSMCB.2009.2029076
   Sun K, 2009, IEEE INT CON MULTI, P566, DOI 10.1109/ICME.2009.5202559
   Valstar M., 2013, P 3 ACM INT WORKSHOP, DOI [10.1145/2512530.2512533, DOI 10.1145/2512530.2512533]
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wallhoff F., 2006, Facial Expressions and Emotion Database
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Wöllmer M, 2013, IMAGE VISION COMPUT, V31, P153, DOI 10.1016/j.imavis.2012.03.001
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang L., 2012, THESIS QUEENSLAND U
   Zhang LG, 2014, IMAGE VISION COMPUT, V32, P107, DOI 10.1016/j.imavis.2013.12.008
   Zhang LG, 2011, LECT NOTES COMPUT SC, V7064, P431, DOI 10.1007/978-3-642-24965-5_49
NR 55
TC 15
Z9 16
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1067
EP 1079
DI 10.1016/j.imavis.2014.09.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600009
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Peng, XJ
   Qiao, Y
   Peng, Q
AF Peng, Xiaojiang
   Qiao, Yu
   Peng, Qiang
TI Motion boundary based sampling and 3D co-occurrence descriptors for
   action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dense trajectory; Action recognition; 3D co-occurrence descriptors;
   Motion boundary; Bag of Features
ID CATEGORIES; HISTOGRAMS
AB Recent studies witness the success of Bag-of-Features (BoF) frameworks for video based human action recognition. The detection and description of local interest regions are two fundamental problems in BoF framework. In this paper, we propose a motion boundary based sampling strategy and spatial-temporal (3D) co-occurrence descriptors for action video representation and recognition. Our sampling strategy is partly inspired by the recent success of dense trajectory (DT) based features [Wang et al., 20131 for action recognition. Compared with DT, we densely sample spatial-temporal cuboids along a motion boundary which can greatly reduce the number of valid trajectories and preserve the discriminative power. Moreover, we develop a set of 3D co-occurrence descriptors which take account of the spatial-temporal context within local cuboids and deliver rich information for recognition. Furthermore, we decompose each 3D co-occurrence descriptor at pixel level and bin level and integrate the decomposed components with a multi-channel framework, which can improve the performance significantly. To evaluate the proposed methods, we conduct extensive experiments on three benchmarks including KTH, YouTube and HMDB51. The results show that our sampling strategy significantly reduces the computational cost of point tracking without degrading performance. Meanwhile, we achieve superior performance than the state-of-the-art methods. We report 95.6% on KTH, 87.6% on YouTube and 51.8% on HMDB51. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Peng, Xiaojiang; Peng, Qiang] Southwest Jiaotong Univ, Chengdu, Peoples R China.
   [Peng, Xiaojiang] Hengyang Normal Univ, Dept Comp Sci, Hengyang, Peoples R China.
   [Peng, Xiaojiang; Qiao, Yu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen Key Lab CVPR, Shenzhen, Peoples R China.
   [Qiao, Yu] Chinese Univ Hong Kong, Hong Kong, Hong Kong, Peoples R China.
C3 Southwest Jiaotong University; Hengyang Normal University; Chinese
   Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS;
   Chinese University of Hong Kong
RP Qiao, Y (corresponding author), 1068 Xueyuan Ave, Shenzhen, Peoples R China.
RI Yu, Qiao/IAP-6999-2023; Peng, Xiaojiang/AAN-8100-2020; Qiao,
   Yu/ABD-5787-2021
FU construct program of the key discipline in Hunan province; Natural
   Science Foundation of China [91320101, 60972111]; Shenzhen Basic
   Research Program [JC201005270350A, JCYJ20120903092050890,
   JCYJ20120617114614438]; 100 Talents Program of CAS; Guangdong Innovative
   Research Team Program [201001D0104648280]
FX This work is partly supported by the construct program of the key
   discipline in Hunan province, Natural Science Foundation of China
   (91320101, 60972111), Shenzhen Basic Research Program (JC201005270350A,
   JCYJ20120903092050890, JCYJ20120617114614438), 100 Talents Program of
   CAS, and Guangdong Innovative Research Team Program (201001D0104648280).
CR [Anonymous], VISUAL ANAL HUMANS
   [Anonymous], 2012, ACCV
   Arpit J., 2013, CVPR
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Bhattacharya S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2593, DOI 10.1109/CVPR.2011.5995746
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Feng S., 2013, CVPR
   GROSSBERG S, 1993, PERCEPT PSYCHOPHYS, V53, P243, DOI 10.3758/BF03205182
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kliper-Gross O, 2012, LECT NOTES COMPUT SC, V7577, P256, DOI 10.1007/978-3-642-33783-3_19
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Li N, 2008, SCIENCE, V321, P1502, DOI 10.1126/science.1160028
   LiMin W., 2013, CVPR
   Jingen Liu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1996, DOI [10.1109/ICINIS.2009.13, 10.1109/CVPRW.2009.5206744]
   Lv F., 2007, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P1
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Peng X., 2013, BMVC
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qi XB, 2012, LECT NOTES COMPUT SC, V7577, P158, DOI 10.1007/978-3-642-33783-3_12
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Starner T., 1997, Motion-Based Recognit, P227
   Tal H., 2013, CVPR
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Wang H., 2009, BMVC
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Watanabe T, 2009, LECT NOTES COMPUT SC, V5414, P37, DOI 10.1007/978-3-540-92957-4_4
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   Yao G.F. Angela, 2011, BMVC, P671
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 46
TC 19
Z9 27
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2014
VL 32
IS 9
BP 616
EP 628
DI 10.1016/j.imavis.2014.06.011
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AO6QY
UT WOS:000341477800006
DA 2024-07-18
ER

PT J
AU Sener, F
   Ikizler-Cinbis, N
AF Sener, Fadime
   Ikizler-Cinbis, Nazli
TI Ensemble of multiple instance classifiers for image re-ranking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image retrieval; Image re-ranking; Multiple Instance Learning
AB Text-based image retrieval may perform poorly due to the irrelevant and/or incomplete text surrounding the images in the web pages. In such situations, visual content of the images can be leveraged to improve the image ranking performance. In this paper, we look into this problem of image re-ranking and propose a system that automatically constructs multiple candidate "multi-instance bags (MI-bags)", which are likely to contain relevant images. These automatically constructed bags are then utilized by ensembles of Multiple Instance Learning (MIL) classifiers and the images are re-ranked according to the final classification responses. Our method is unsupervised in the sense that, the only input to the system is the text query itself, without any user feedback or annotation. The experimental results demonstrate that constructing multiple instance bags based on the retrieval order and utilizing ensembles of MIL classifiers greatly enhance the retrieval performance, achieving on par or better results compared to the state-of-the-art. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Sener, Fadime] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
   [Ikizler-Cinbis, Nazli] Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University; Hacettepe University
RP Ikizler-Cinbis, N (corresponding author), Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM fadime.sener@cs.bilkent.edu.tr; nazli@cs.hacettepe.edu.tr
RI Ikizler-Cinbis, Nazli/E-8961-2013
FU Google Research Award; Scientific and Technological Research Council of
   Turkey (TUBITAK) Career Development Award [112E149]
FX This work was supported in part by a Google Research Award and the
   Scientific and Technological Research Council of Turkey (TUBITAK) Career
   Development Award 112E149.
CR Andrews Stuart, 2002, PROC 25 ANN C NEURAL, P561
   [Anonymous], 2013, Handbook on neural information processing
   [Anonymous], 2009, CVPR
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], 2008, CVPR
   [Anonymous], 2012, IEEE C COMP VIS PATT
   [Anonymous], CVPR
   [Anonymous], 2009, NIPS
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Ben-Haim N., 2006, CVPR WORKSH SLAM
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Doll'ar P., 2008, ECCV
   Duan LX, 2011, IEEE T IMAGE PROCESS, V20, P3280, DOI 10.1109/TIP.2011.2159227
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Fritz M., 2008, IEEE COMPUTER SOC
   Geng B., 2010, CVPR
   Grangier D, 2008, IEEE T PATTERN ANAL, V30, P1371, DOI 10.1109/TPAMI.2007.70791
   Han Y., 2013, INT JOINT C ART INT
   He Xiaofei., 2004, ACM MULTIMEDIA, P17
   Hsu Winston., 2006, ACM MULTIMEDIA
   Hsu WH, 2007, IEEE MULTIMEDIA, V14, P14, DOI 10.1109/MMUL.2007.61
   Jain V., 2011, International Conference on World Wide Web, P277, DOI DOI 10.1145/1963405.1963447
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Krapac J, 2010, PROC CVPR IEEE, P1094, DOI 10.1109/CVPR.2010.5540092
   Li W., 2011, ICCV
   Liu W., 2011, IEEE COMPUTER SOC
   Liu Y, 2010, IEEE T CIRC SYST VID, V20, P749, DOI 10.1109/TCSVT.2010.2045801
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JY, 2012, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2012.6248033
   Maron O., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P341
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Schroff F, 2007, IEEE I CONF COMP VIS, P2120
   Tian XM, 2011, IEEE MULTIMEDIA, V18, P12, DOI 10.1109/MMUL.2011.36
   Viola P., 2006, NIPS 18, P1419
   Wu F., 2010, Proceedings of the International Conference on Multimedia (MM'10), P15, DOI DOI 10.1145/1873951.1873957
   Yakhnenko O, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.59
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zeisl B., 2010, COMPUTER VISION PATT
   Zha Z.-J., 2008, 2008 IEEE C COMPUTER, DOI DOI 10.1109/CVPR.2008.4587384
   Zhang DS, 2012, PATTERN RECOGN, V45, P346, DOI 10.1016/j.patcog.2011.05.013
NR 41
TC 0
Z9 2
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2014
VL 32
IS 5
BP 348
EP 362
DI 10.1016/j.imavis.2014.02.014
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AH3HI
UT WOS:000336013900004
DA 2024-07-18
ER

PT J
AU Shi, KF
   Dong, QL
   Wu, FC
AF Shi, Kunfeng
   Dong, Qiulei
   Wu, Fuchao
TI Euclidean upgrading from segment lengths: DLT-like algorithm and its
   variants
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE DLT-like algorithm; Euclidean upgrading; Multi-camera calibration;
   Segment lengths; Weighted DLT-like algorithm
ID CAMERA CALIBRATION; SELF-CALIBRATION
AB In this paper, how to calibrate a fixed multi-camera system and simultaneously achieve a Euclidean reconstruction from a set of segments is addressed. It is well known that only a projective reconstruction could be achieved without any prior information. Here, the known segment lengths are exploited to upgrade the projective reconstruction to a Euclidean reconstruction and simultaneously calibrate the intrinsic and extrinsic camera parameters. At first, a DLT(Direct Linear Transformation)-like algorithm for the Euclidean upgrading from segment lengths is derived in a very simple way. Although the intermediate results in the DLT-like algorithm are essentially equivalent to the quadric of segments (QoS), the DLT-like algorithm is of higher accuracy than the existing linear algorithms derived from the QoS because of a more accurate way to extract the plane at infinity from the intermediate results. Then, to further improve the accuracy of Euclidean upgrading, two weighted DLT-like algorithms are presented by weighting the linear constraint equations in the original DLT-like algorithm. Finally, using the results of these linear algorithms as the initial values, a new weighted nonlinear algorithm for Euclidean upgrading is explored to recover the Euclidean structure more accurately. Extensive experimental results on both the synthetic data and the real image data demonstrate the effectiveness of our proposed algorithms in Euclidean upgrading and multi-camera calibration. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Shi, Kunfeng; Dong, Qiulei; Wu, Fuchao] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Shi, KF (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, POB 2728, Beijing 100190, Peoples R China.
EM kfshi@nlpr.ia.ac.cn; qldong@nlpr.ia.ac.cn; fcwu@nlpr.ia.ac.cn
OI Shi, KunFeng/0000-0001-8437-3127
FU National Natural Science Foundation of China [61333015, 91120012,
   61375042]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grants No. 61333015, No. 91120012, and No.
   61375042.
CR [Anonymous], 1999, proceedings of Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.1999.786974
   [Anonymous], 1996, ECONOMETRICA J ECONO
   Birchfield S., 1998, An introduction to projective geometry (for computer vision)
   CLARKE J, 1998, 216198 U OXF DEP ENG
   Davis L., 1999, P INT WORKSH COOP DI, P1
   de França JA, 2012, PATTERN RECOGN, V45, P3636, DOI 10.1016/j.patcog.2012.04.006
   Fitzgibbon A., 1998, LECT NOTES COMPUTER, V1506, P155
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley R. I., 1994, Computer Vision - ECCV'94. Third European Conference on Computer Vision. Proceedings. Vol.I, P471
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Heikkilä J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788
   KANATANI K, 2007, P 10 M IM REC UND, P219
   Kanatani K, 2008, INT J COMPUT VISION, V80, P167, DOI 10.1007/s11263-007-0098-0
   Liebowitz D, 2003, INT J COMPUT VISION, V51, P171, DOI 10.1023/A:1021897717694
   MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171
   Pollefeys M, 1999, IEEE T PATTERN ANAL, V21, P707, DOI 10.1109/34.784285
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705
   Ronda JI, 2008, J MATH IMAGING VIS, V32, P193, DOI 10.1007/s10851-008-0095-0
   Ronda JI, 2010, INT J COMPUT VISION, V90, P350, DOI 10.1007/s11263-010-0369-z
   SAMPSON PD, 1982, COMPUT VISION GRAPH, V18, P97, DOI 10.1016/0146-664X(82)90101-0
   Shi KF, 2012, IEEE T IMAGE PROCESS, V21, P3806, DOI 10.1109/TIP.2012.2195013
   Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388
   Tsai R. Y., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P364
   Wang L., 2007, 2007 IEEE 11 INT C C
   Zhang ZY, 2004, IEEE T PATTERN ANAL, V26, P892, DOI 10.1109/TPAMI.2004.21
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 28
TC 0
Z9 1
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2014
VL 32
IS 2
BP 155
EP 168
DI 10.1016/j.imavis.2013.12.012
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AD0DS
UT WOS:000332905300005
DA 2024-07-18
ER

PT J
AU Ptucha, R
   Savakis, A
AF Ptucha, Raymond
   Savakis, Andreas
TI Manifold based sparse representation for facial understanding in natural
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Classification of facial expression; Race; Gender; Glasses and facial
   hair
AB Sparse representations, motivated by strong evidence of sparsity in the primate visual cortex, are gaining popularity in the computer vision and pattern recognition fields, yet sparse methods have not gained widespread acceptance in the facial understanding communities. A main criticism brought forward by recent publications is that sparse reconstruction models work well with controlled datasets, but exhibit coefficient contamination in natural datasets. To better handle facial understanding problems, specifically the broad category of facial classification problems, an improved sparse paradigm is introduced in this paper. Our paradigm combines manifold learning for dimensionality reduction, based on a newly introduced variant of semi-supervised Locality Preserving Projections, with a l(1) reconstruction error, and a regional based statistical inference model. We demonstrate state-of-the-art classification accuracy for the facial understanding problems of expression, gender, race, glasses, and facial hair classification. Our method minimizes coefficient contamination and offers a unique advantage over other facial classification methods when dealing with occlusions. Experimental results are presented on multi-class as well as binary facial classification problems using the Labeled Faces in the Wild, Cohn-Kanade, Extended Cohn-Kanade, and GEMEP-FERA datasets demonstrating how and under what conditions sparse representations can further the field of facial understanding. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Ptucha, Raymond; Savakis, Andreas] Rochester Inst Technol, Rochester, NY 14623 USA.
C3 Rochester Institute of Technology
RP Ptucha, R (corresponding author), Rochester Inst Technol, Rochester, NY 14623 USA.
EM rwpeec@rit.edu
FU National Science Foundation through a Graduate Research Fellowship,
   Cisco; Center for Emerging and Innovative Sciences (CEIS);
   NYSTAR-designated Center for Advanced Technology in New York State
FX This research was supported in part by the National Science Foundation
   through a Graduate Research Fellowship, Cisco, and the Center for
   Emerging and Innovative Sciences (CEIS), a NYSTAR-designated Center for
   Advanced Technology in New York State.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], LEARN DEEP ARCHIT AI
   [Anonymous], 2011, IEEE INT C COMP VIS
   [Anonymous], 2006, ADV NEURAL INFORM PR
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], 2011, PROC CVPR IEEE
   [Anonymous], 10 EUR C COMP VIS
   [Anonymous], CS20080923 U CAL
   [Anonymous], 2001, ADV NEURAL INF PROCE
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], 8 INT C MACH LEARN C
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], 2007, 0749 U MASS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2010, IEEE COMPUTER SOC C
   [Anonymous], P INT C IM PROC
   [Anonymous], INT C AUT FAC GEST R
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C MACH LEARN CYB
   [Anonymous], IEEE C COMP VIS PATT
   Banziger T., 2010, Blueprint for affective computing: A sourcebook, P271, DOI DOI 10.1037/A0025827
   Cai D, 2005, IEEE T KNOWL DATA EN, V17, P1624, DOI 10.1109/TKDE.2005.198
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   Chew S., 2011, Automatic Face and Gesture Recognition
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P6, DOI 10.1109/TIT.2005.860430
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Feng X., 2007, Pattern Recognition and Image Analysis, V17, P592, DOI 10.1134/S1054661807040190
   Ghodsi A., 2006, DIMENSIONALITY REDUC
   He XF, 2004, ADV NEUR IN, V16, P153
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Jiang B., 2011, Face and Gesture Recognition
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   PATI Y. C., 1993, P 27 AS C SIGN SYST
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sherrah J, 2001, IMAGE VISION COMPUT, V19, P807, DOI 10.1016/S0262-8856(00)00096-2
   SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Valstar M., 2011, Face and Gesture Recognition
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang A., 2007, Feature Selection in Face Recognition: A Sparse Representation Perspective
NR 49
TC 28
Z9 33
U1 0
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2013
VL 31
IS 5
BP 365
EP 378
DI 10.1016/j.imavis.2013.03.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 154YR
UT WOS:000319713100001
DA 2024-07-18
ER

PT J
AU Shabou, A
   Darbon, J
   Tupin, F
AF Shabou, A.
   Darbon, J.
   Tupin, F.
TI Multilabel partition moves for MRF optimization
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Markov random fields; Graph-cut; Approximate optimization; Image
   restoration; Multichannel InSAR phase unwrapping
ID CONSTRAINED TOTAL VARIATION; A-POSTERIORI ESTIMATION; MARKOV
   RANDOM-FIELDS; ENERGY MINIMIZATION; IMAGE-RESTORATION
AB This paper presents new graph-cut based optimization algorithms for image processing problems. Popular graph-cut based algorithms give approximate solutions and are based on the concept of partition move. The main contribution of this work consists in proposing novel partition moves called multilabel moves to minimize Markov random field (MRF) energies with convex prior and any likelihood energy functions. These moves improve the optimum quality of the state-of-the-art approximate minimization algorithms while controlling the memory need of the algorithm at the same time. Thus, the two challenging problems, improving local optimum quality and reducing required memory for graph construction are handled with our approach. These new performances are illustrated on some image processing experiments, such as image restoration and InSAR phase unwrapping. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Shabou, A.; Tupin, F.] TELECOM ParisTech, CNRS LTCI, Inst TELECOM, Paris, France.
   [Darbon, J.] PRES UniverSud, ENS Cachan, CMLA, Paris, France.
C3 IMT - Institut Mines-Telecom; IMT Atlantique; Institut Polytechnique de
   Paris; Telecom Paris; Centre National de la Recherche Scientifique
   (CNRS); Universite Paris Saclay
RP Shabou, A (corresponding author), TELECOM ParisTech, CNRS LTCI, Inst TELECOM, Paris, France.
EM aymen.shabou@telecom-paristech.fr; darbon@cmla.ens-cachan.fr;
   florence.tupin@telecom-paristech.fr
RI Darbon, Jerome/S-8142-2019
OI Darbon, Jerome/0000-0003-0483-7919
FU Office of Naval Research [N000140710810]
FX Part of this work has been done while J. Darbon was with the UCLA
   Mathematics Department, and was supported by the Office of Naval
   Research through grant N000140710810.
CR Ahuja R. K., 1993, Network flows: theory, algorithms, and applications
   [Anonymous], THESIS ECOLE NATL SU
   [Anonymous], 1999, THESIS CORNELL U
   Bamler R, 1998, INVERSE PROBL, V14, pR1, DOI 10.1088/0266-5611/14/4/001
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Bioucas-Dias JM, 2007, IEEE T IMAGE PROCESS, V16, P698, DOI 10.1109/TIP.2006.888351
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Carr P, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P532, DOI 10.1109/DICTA.2009.90
   Darbon J, 2006, J MATH IMAGING VIS, V26, P277, DOI 10.1007/s10851-006-0644-3
   Darbon J, 2006, J MATH IMAGING VIS, V26, P261, DOI 10.1007/s10851-006-8803-0
   Darbon J, 2009, DISCRETE APPL MATH, V157, P3412, DOI 10.1016/j.dam.2009.02.026
   Denis L, 2009, IEEE T IMAGE PROCESS, V18, P1588, DOI 10.1109/TIP.2009.2019302
   Ferraioli G, 2009, IEEE GEOSCI REMOTE S, V6, P562, DOI 10.1109/LGRS.2009.2021165
   Ferraiuolo G, 2004, IEEE GEOSCI REMOTE S, V1, P66, DOI 10.1109/LGRS.2003.822882
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908
   Itho K., 1982, APPL OPT, V2
   IVANESCU PL, 1965, OPER RES, V13, P388, DOI 10.1287/opre.13.3.388
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Komodakis N, 2008, COMPUT VIS IMAGE UND, V112, P14, DOI 10.1016/j.cviu.2008.06.007
   Komodakis N, 2007, IEEE T PATTERN ANAL, V29, P1436, DOI 10.1109/TPAMI.2007.1061
   Lempitsky V, 2010, IEEE T PATTERN ANAL, V32, P1392, DOI 10.1109/TPAMI.2009.143
   Ramanathan S., 2008, PHOTOVOLTAIC SPECIAL, P1, DOI DOI 10.1201/9781420068764
   Shabou A, 2009, IEEE IMAGE PROC, P2413, DOI 10.1109/ICIP.2009.5414189
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   VEKSLER O, 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383249
   Veksler O, 2009, LECT NOTES COMPUT SC, V5681, P1, DOI 10.1007/978-3-642-03641-5_1
NR 29
TC 1
Z9 3
U1 2
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2013
VL 31
IS 1
BP 14
EP 30
DI 10.1016/j.imavis.2012.10.004
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 084RP
UT WOS:000314557100002
DA 2024-07-18
ER

PT J
AU Weber, J
   Lefèvre, S
AF Weber, J.
   Lefevre, S.
TI Spatial and spectral morphological template matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hit-or-miss transform; Remote sensing; Multivariate morphology; Template
   matching
ID OR-MISS TRANSFORM; EXTRACTION
AB Template matching is a very topical issue in a wide range of imaging applications. Mathematical morphology offers the hit-or-miss transform, an operator which has been successfully applied for template matching in binary images. More recently, it has been extended to grayscale images and even to multivariate images. Nevertheless, these extensions, despite being relevant from a theoretical point-of-view, might lack practical interest due to the inherent difficulty to set up correctly the transform and its parameters (e.g. the structuring functions). In this paper, we propose a new and more intuitive operator which allows for morphological template matching in multivariate images from both a spatial and spectral point of view. We illustrate the potential of this operator in the context of remote sensing. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Weber, J.] Univ Lorraine, LORIA UMR 7503, F-54506 Vandoeuvre Les Nancy, France.
C3 Universite de Lorraine
RP Weber, J (corresponding author), LORIA Nancy, Campus Sci,BP 239, F-54506 Vandoeuvre Les Nancy, France.
EM jonathan.weber@loria.fr; sebastien.lefevre@univ-ubs.fr
RI Weber, Jonathan/S-4449-2019; Lefevre, Sebastien/S-9444-2017
OI Weber, Jonathan/0000-0002-3694-4703; Lefevre,
   Sebastien/0000-0002-2384-8202
FU ANR-JC ECOSGIL project
FX The authors thank Anne Puissant from University of Strasbourg for the
   set-up and the evaluation of the coastline extraction experiment, Erchan
   Aptoula from Okan University for the English improvements and the ANR-JC
   ECOSGIL project for remote sensing data and financial support.
CR [Anonymous], 1982, IMAGE ANAL MATH MORP
   Aptoula E, 2007, PATTERN RECOGN, V40, P2914, DOI 10.1016/j.patcog.2007.02.004
   Aptoula E, 2009, PATTERN RECOGN LETT, V30, P760, DOI 10.1016/j.patrec.2009.02.007
   Bagli S., 2003, 5 INT S GIS COMP CAR
   Barat C, 2010, PATTERN RECOGN, V43, P3433, DOI 10.1016/j.patcog.2010.04.020
   Boak EH, 2005, J COASTAL RES, V21, P688, DOI 10.2112/03-0071.1
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Briechle K., 2001, SPIE OPTICAL PATTERN, V4387
   Gonzalez R.C., 2002, DIGITAL IMAGE PROCES, P703
   Heene G, 2000, INT GEOSCI REMOTE SE, P2632, DOI 10.1109/IGARSS.2000.859664
   Jishuang Q., 2002, ISPRS COMM 1 S INT R
   Matheron G., 1975, Random sets and integral geometry
   Naegel B, 2007, PATTERN RECOGN, V40, P635, DOI 10.1016/j.patcog.2006.06.004
   Perret B, 2009, PATTERN RECOGN, V42, P2470, DOI 10.1016/j.patcog.2009.02.013
   Puissant A., 2008, 21 ISPRS C BENJ
   Ronse C, 1996, J VIS COMMUN IMAGE R, V7, P273, DOI 10.1006/jvci.1996.0024
   Serra J., 1988, IMAGE ANAL MATH MORP
   Soille P., 2002, Discrete Geometry for Computer Imagery. 10th International Conference, DGCI 2002. Proceedings (Lecture Notes in Computer Science Vol.2301), P175
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Velasco-Forero S, 2010, LECT NOTES COMPUT SC, V6474, P452, DOI 10.1007/978-3-642-17688-3_42
   Weber J, 2008, LECT NOTES COMPUT SC, V5099, P226, DOI 10.1007/978-3-540-69905-7_26
   Weber J, 2011, INT SYMP IMAGE SIG, P265
NR 22
TC 16
Z9 16
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 934
EP 945
DI 10.1016/j.imavis.2012.07.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800002
DA 2024-07-18
ER

PT J
AU O'Toole, AJ
   Phillips, PJ
   An, XB
   Dunlop, J
AF O'Toole, Alice J.
   Phillips, P. Jonathon
   An, Xiaobo
   Dunlop, Joseph
TI Demographic effects on estimates of automatic face recognition
   performance
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Face recognition; Algorithm evaluation; Demographics
ID OWN
AB The intended applications of automatic face recognition systems include venues that vary widely in demographic diversity. Formal evaluations of algorithms do not commonly consider the effects of population diversity on performance. We document the effects of racial and gender demographics on estimates of the accuracy of algorithms that match identity in pairs of face images. In particular, we focus on the effects of the "background" population distribution of non-matched identities against which identity matches are compared. The algorithm we tested was created by fusing three of the top performers from a recent US Government competition. First, we demonstrate the variability of algorithm performance estimates when the population of non-matched identities was demographically "yoked" by race and/or gender (i.e., "yoking" constrains non-matched pairs to be of the same race or gender). We also report differences in the match threshold required to obtain a false alarm rate of .001 when demographic controls on the non-matched identity pairs varied. In a second experiment, we explored the effect on algorithm performance of progressively increasing population diversity. We found systematic, but non-general, effects when the balance between majority and minority populations of non-matched identities shifted. Third, we show that identity match accuracy differs substantially when the non-match identity population varied by race. Finally, we demonstrate the impact on performance when the non-match distribution consists of faces chosen to resemble a target face. The results from all experiments indicate the importance of the demographic composition and modeling of the background population in predicting the accuracy of face recognition algorithms. (C) 2012 Elsevier B.V. All rights reserved.
C1 [O'Toole, Alice J.; An, Xiaobo; Dunlop, Joseph] Univ Texas Dallas, Richardson, TX 75080 USA.
   [Phillips, P. Jonathon] Natl Inst Stand & Technol, Gaithersburg, MD 20899 USA.
C3 University of Texas System; University of Texas Dallas; National
   Institute of Standards & Technology (NIST) - USA
RP O'Toole, AJ (corresponding author), Univ Texas Dallas, Richardson, TX 75080 USA.
EM otoole@utdallas.edu
OI O'Toole, Alice/0000-0001-7981-1508
CR BOTHWELL RK, 1989, PERS SOC PSYCHOL B, V15, P19, DOI 10.1177/0146167289151002
   Furl N, 2002, COGNITIVE SCI, V26, P797, DOI 10.1016/S0364-0213(02)00084-8
   Gross R, 2005, HANDBOOK OF FACE RECOGNITION, P193, DOI 10.1007/0-387-27257-7_10
   MALPASS RS, 1969, J PERS SOC PSYCHOL, V13, P330, DOI 10.1037/h0028434
   Meissner CA, 2001, PSYCHOL PUBLIC POL L, V7, P3, DOI 10.1037//1076-8971.7.1.3
   Phillips P.J., 2011, P 9 INT C AUT FAC GE
   Phillips PJ, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870082
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   PHILLIPS PJ, 2003, 6965 NISTIR
   SHAPIRO PN, 1986, PSYCHOL BULL, V100, P139, DOI 10.1037/0033-2909.100.2.139
NR 12
TC 28
Z9 33
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 169
EP 176
DI 10.1016/j.imavis.2011.12.007
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000005
DA 2024-07-18
ER

PT J
AU Shen, XH
   Hua, G
   Williams, L
   Wu, Y
AF Shen, Xiaohui
   Hua, Gang
   Williams, Lance
   Wu, Ying
TI Dynamic hand gesture recognition: An exemplar-based approach from motion
   divergence fields
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Hand gesture recognition; Divergence fields; Optical flow; Maximum
   Stable Extremal Regions; Term frequency-inverse document frequency
   (TF-IDF)
AB Exemplar-based approaches for dynamic hand gesture recognition usually require a large collection of gestures to achieve high-quality performance. Efficient visual representation of the motion patterns hence is very important to offer a scalable solution for gesture recognition when the databases are large. In this paper, we propose a new visual representation for hand motions based on the motion divergence fields, which can be normalized to gray-scale images. Salient regions such as Maximum Stable Extremal Regions (MSER) are then detected on the motion divergence maps. From each detected region, a local descriptor is extracted to capture local motion patterns. We further leverage indexing techniques from image search into gesture recognition. The extracted descriptors are indexed using a pre-trained vocabulary. A new gesture sample accordingly can be efficiently matched with database gestures through a term frequency-inverse document frequency (TF-IDF) weighting scheme. We have collected a hand gesture database with 10 categories and 1050 video samples for performance evaluation and further applications. The proposed method achieves higher recognition accuracy than other state-of-the-art motion and spatio-temporal features on this database. Besides, the average recognition time of our method for each gesture sequence is only 34.53 ms. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Shen, Xiaohui; Wu, Ying] Northwestern Univ, Evanston, IL 60208 USA.
   [Hua, Gang] Stevens Inst Technol, Hoboken, NJ 07030 USA.
   [Williams, Lance] Nokia Res Ctr Hollywood, Santa Monica, CA 90404 USA.
C3 Northwestern University; Stevens Institute of Technology; Nokia
   Corporation; Nokia Bell Labs
RP Shen, XH (corresponding author), Northwestern Univ, Evanston, IL 60208 USA.
EM xsh835@eecs.northwestern.edu
RI wu, yiping/JEF-4104-2023; Wu, Ying/B-7283-2009
OI Koochak, Atousa/0000-0001-6547-2728
CR [Anonymous], 2009, BMVC
   [Anonymous], 2007, CVPR
   [Anonymous], 2005, ICCV VS PETS
   [Anonymous], 2008, ECCV
   [Anonymous], 2007, ICCV
   [Anonymous], CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], CVPR
   [Anonymous], 2008, CVPR
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chen FS, 2003, IMAGE VISION COMPUT, V21, P745, DOI 10.1016/S0262-8856(03)00070-2
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davis J., 1994, ECCV REC HAND GEST
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Elgammal A., 2003, CVPR
   Fei-Fei L., 2005, BAYESIAN HIERARCHICA
   Florez F., 2002, FG
   Freeman WilliamT., 1995, FG
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Kirishima T, 2005, IEEE T PATTERN ANAL, V27, P351, DOI 10.1109/TPAMI.2005.61
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Lockton R., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P817
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Marcel S., 2000, FG
   Matas J., 2002, BMVC
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Nistér D, 2008, LECT NOTES COMPUT SC, V5303, P183, DOI 10.1007/978-3-540-88688-4_14
   Nister David, 2006, CVPR
   Patron-Perez A., 2007, BMVC
   Pengyu Hong, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P410, DOI 10.1109/AFGR.2000.840667
   Rajko S., 2007, CVPR
   Shen X., 2011, FG
   Suk H., 2008, FG
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Yu T.H., 2010, BMVC
NR 35
TC 53
Z9 59
U1 0
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 227
EP 235
DI 10.1016/j.imavis.2011.11.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000011
DA 2024-07-18
ER

PT J
AU Lao, YW
   Zheng, YF
AF Lao, Yuanwei
   Zheng, Yuan F.
TI Tracking highly correlated targets through statistical multiplexing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-target tracking; Markov chain Monte Carlo; Particle filter;
   Correlation
ID MONTE-CARLO METHODS; MULTITARGET TRACKING; DATA ASSOCIATION; OBJECT
   TRACKING; MCMC
AB We consider a special problem of multi-target tracking, where a group of targets are highly correlated, usually demonstrating a common motion pattern with individual variations. We focus on the task of searching and provide a statistical framework of embedding the correlation among targets and the most recent observations into sampling, where the correlation is learned dynamically from the previous tracking results. Proposal distribution is updated during the sampling process fused with the motion prior and observation information. In this way, the observation of a single target is multiplexed statistically through mutual correlation among the multiple targets, and the correlation serves as both a prior information to improve the efficiency and a constraint to prevent trackers from drifting. Extensive experiments on tracking both naturally correlated and environment-constrained targets demonstrate superior and promising robust results with low complexity. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Lao, Yuanwei; Zheng, Yuan F.] Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Zheng, YF (corresponding author), Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
EM laoy@ece.osu.edu; zheng@ece.osu.edu
RI zheng, yuan/JCN-7781-2023
CR Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116
   [Anonymous], 1990, Multitarget-Multisensor Tracking: Advanced Applications
   [Anonymous], EURASIP J APPL SIGNA
   [Anonymous], P 8 INT C INF FUS JU
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Cai YZ, 2006, LECT NOTES COMPUT SC, V3954, P107
   Cappé O, 2007, P IEEE, V95, P899, DOI 10.1109/JPROC.2007.893250
   Chang C, 2005, PROC CVPR IEEE, P566
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   COX IJ, 1994, ARTIF INTELL, V66, P311, DOI 10.1016/0004-3702(94)90029-9
   Fan ZM, 2007, IEEE T PATTERN ANAL, V29, P1268, DOI 10.1109/TPAMI.2007.1034
   Grabner H, 2010, PROC CVPR IEEE, P1285, DOI 10.1109/CVPR.2010.5539819
   Hue C, 2001, 2001 IEEE WORKSHOP ON MULTI-OBJECT TRACKING, PROCEEDINGS, P61, DOI 10.1109/MOT.2001.937982
   Hue C, 2002, IEEE T SIGNAL PROCES, V50, P309, DOI 10.1109/78.978386
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549
   Khan S. M., 2005, 13th Annual ACM International Conference on Multimedia, P403, DOI 10.1145/1101149.1101237
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Khan Z, 2006, IEEE T PATTERN ANAL, V28, P1960, DOI 10.1109/TPAMI.2006.247
   Lao YW, 2009, IEEE T CIRC SYST VID, V19, P1365, DOI 10.1109/TCSVT.2009.2022797
   Li S.Z., 2009, MARKOV RANDOM FIELD
   Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pan P, 2008, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2008.4712335
   Park M., 2008, PROC IEEE C COMPUTER, P1
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Qu W, 2007, IEEE T IMAGE PROCESS, V16, P2129, DOI 10.1109/TIP.2007.899619
   Qu W, 2007, IEEE T MULTIMEDIA, V9, P511, DOI 10.1109/TMM.2006.886266
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Reid ID, 1996, INT J COMPUT VISION, V18, P41, DOI 10.1007/BF00126139
   Ristic B., 2003, Beyond the Kalman Filter: Particle Filters for Tracking Applications
   Smith K, 2005, PROC CVPR IEEE, P962
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Vermaak J, 2005, IEEE T AERO ELEC SYS, V41, P309, DOI 10.1109/TAES.2005.1413764
   Wu Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1094, DOI 10.1109/ICCV.2003.1238471
   Yu Q:, 2007, PROC IEEE C COMPUTER, P1
   Yu T, 2005, PROC CVPR IEEE, P939
   Yu T, 2004, PROC CVPR IEEE, P834
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
NR 43
TC 2
Z9 2
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2011
VL 29
IS 12
BP 803
EP 817
DI 10.1016/j.imavis.2011.09.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 873TJ
UT WOS:000298905600001
DA 2024-07-18
ER

PT J
AU Zhao, Y
   Taubin, G
AF Zhao, Yong
   Taubin, Gabriel
TI Real-time stereo on GPGPU using progressive multi-resolution adaptive
   windows
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Real-time stereo; GPGPU
AB We introduce a new GPGPU-based real-time dense stereo matching algorithm. The algorithm is based on a progressive multi-resolution pipeline which includes background modeling and dense matching with adaptive windows. For applications in which only moving objects are of interest, this approach effectively reduces the overall computation cost quite significantly, and preserves the high definition details. Running on an off-the-shelf commodity graphics card, our implementation achieves a 36 fps stereo matching on 1024 x 768 stereo video with a fine 256 pixel disparity range. This is effectively same as 7200 M disparity evaluations per second. For scenes where the static background assumption holds, our approach outperforms all published alternative algorithms in terms of the speed performance, by a large margin. We envision a number of potential applications such as real-time motion capture, as well as tracking, recognition and identification of moving objects in multi-camera networks. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Zhao, Yong; Taubin, Gabriel] Brown Univ, Div Engn, Providence, RI 02912 USA.
C3 Brown University
RP Zhao, Y (corresponding author), Brown Univ, Div Engn, 182 Hope St, Providence, RI 02912 USA.
EM yongzhao@brown.edu; taubin@brown.edu
OI Taubin, Gabriel/0000-0002-1983-7607
CR [Anonymous], P C COMP VIS PATT RE
   [Anonymous], CVPRW 04 P 2004 C CO
   [Anonymous], P INT C 3 D DIG IM M
   [Anonymous], ICPR 06 P 18 INT C P
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], BRIT MACH VIS C
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P 18 INT C PATT REC
   [Anonymous], 2004, IEEE C COMPUTER VISI
   [Anonymous], COMPUTER VISION IMAG
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P 3DIM
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P INT C COMP VIS SYS
   [Anonymous], ISVC 09
   [Anonymous], CUDA PROGR GUID 2 0
   COCHRAN SD, 1992, IEEE T PATTERN ANAL, V14, P981, DOI 10.1109/34.159902
   Cornelis N, 2005, PROC CVPR IEEE, P1099
   Deng Y, 2006, LECT NOTES COMPUT SC, V3953, P201, DOI 10.1007/11744078_16
   Gong M, 2005, PROC CVPR IEEE, P924
   Hirschmuller H., 2006, P 2006 IEEE COMPUTER, P2386, DOI DOI 10.1109/CVPR.2006.294
   Klaus A, 2006, INT C PATT RECOG, P15
   Larsen ES, 2007, IEEE I CONF COMP VIS, P1440
   Salmen J, 2009, LECT NOTES COMPUT SC, V5702, P1096, DOI 10.1007/978-3-642-03767-2_133
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sun J, 2005, PROC CVPR IEEE, P399
   Wang L, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P798
   Wang ZF, 2008, PROC CVPR IEEE, P887
   Yang Q., 2006, IEEE COMPUTER SOC C, P2347
   Yang Q., 2008, BMVC '08
   Yang RG, 2003, PROC CVPR IEEE, P211, DOI 10.1109/ISCS.2003.1239980
   Yu W., 2010, IEEE Transactions on Circuits and Systems for Video Technology
NR 34
TC 17
Z9 22
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2011
VL 29
IS 6
BP 420
EP 432
DI 10.1016/j.imavis.2011.01.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 761TD
UT WOS:000290423000005
DA 2024-07-18
ER

PT J
AU Zhao, M
   Li, ST
   Kwok, J
AF Zhao, Ming
   Li, Shutao
   Kwok, James
TI Text detection in images using sparse representation with discriminative
   dictionaries
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Text detection; Sparse representation; Discriminative dictionary
ID SEGMENTATION; EXTRACTION; RECOGNITION; PERFORMANCE
AB Text detection is important in the retrieval of texts from digital pictures, video databases and webpages. However, it can be very challenging since the text is often embedded in a complex background. In this paper, we propose a classification-based algorithm for text detection using a sparse representation with discriminative dictionaries. First, the edges are detected by the wavelet transform and scanned into patches by a sliding window. Then, candidate text areas are obtained by applying a simple classification procedure using two learned discriminative dictionaries. Finally, the adaptive run-length smoothing algorithm and projection profile analysis are used to further refine the candidate text areas. The proposed method is evaluated on the Microsoft common test set, the ICDAR 2003 text locating set, and an image set collected from the web. Extensive experiments show that the proposed method can effectively detect texts of various sizes, fonts and colors from images and videos. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Zhao, Ming; Li, Shutao] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
   [Kwok, James] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Hunan University; Hong Kong University of Science & Technology
RP Li, ST (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
EM mingzhao_frank@yahoo.cn; shutao_li@yahoo.com.cn; jamesk@cse.ust.hk
RI Li, Shutao/Y-3102-2019
OI Li, Shutao/0000-0002-0585-9848
FU National Natural Science Foundation of China [60871096, 60835004];
   Foundation of the Ministry of Education of China [200805320006]; Chinese
   Ministry of Education [2009-120]; National Laboratory of Pattern
   Recognition, China
FX The authors would like to thank the editor and anonymous reviewers for
   their detailed review, valuable comments, and constructive suggestions.
   This paper is supported by the National Natural Science Foundation of
   China (No. 60871096 and 60835004), the Ph.D. Programs Foundation of the
   Ministry of Education of China (No. 200805320006), the Key Project of
   the Chinese Ministry of Education (2009-120), and the Open Projects
   Program of the National Laboratory of Pattern Recognition, China.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], IMAGE VISION COMPUT
   [Anonymous], P ICPR
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587652
   ANTHIMOPOULOS M, 2010, IMAGE VISIO IN PRESS
   Avanindra, 1997, IEEE T IMAGE PROCESS, V6, P344
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gllavata J, 2004, INT C PATT RECOG, P425, DOI 10.1109/ICPR.2004.1334146
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538
   *ICDAR, ICDAR 2003 COMP
   Jung C, 2009, IMAGE VISION COMPUT, V27, P1295, DOI 10.1016/j.imavis.2008.11.012
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Kumar S, 2007, IEEE T IMAGE PROCESS, V16, P2117, DOI 10.1109/TIP.2007.900098
   Lee TW, 2002, IEEE T IMAGE PROCESS, V11, P270, DOI 10.1109/83.988960
   Li ST, 2007, PATTERN RECOGN LETT, V28, P555, DOI 10.1016/j.patrec.2006.10.002
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   Lim J, 2007, IMAGE VISION COMPUT, V25, P671, DOI 10.1016/j.imavis.2006.05.011
   Liu X, 2008, PATTERN RECOGN, V41, P484, DOI 10.1016/j.patcog.2007.06.004
   Lyu MR, 2005, IEEE T CIRC SYST VID, V15, P243, DOI 10.1109/TCSVT.2004.841653
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   Mancas-Thillou C, 2007, COMPUT VIS IMAGE UND, V107, P97, DOI 10.1016/j.cviu.2006.11.010
   Nikolaou N, 2010, IMAGE VISION COMPUT, V28, P590, DOI 10.1016/j.imavis.2009.09.013
   PAN W, 2008, P 19 INT C PATT REC, P1, DOI DOI 10.1109/ICPR.2008.4760967
   Roth S, 2005, PROC CVPR IEEE, P860
   Shang L, 2008, IMAGE VISION COMPUT, V26, P1137, DOI 10.1016/j.imavis.2007.12.006
   Shen HY, 2009, IMAGE VISION COMPUT, V27, P854, DOI 10.1016/j.imavis.2009.02.006
   Strouthopoulos C, 1998, IMAGE VISION COMPUT, V16, P879, DOI 10.1016/S0262-8856(98)00055-9
   WONG KY, 1982, IBM J RES DEV, V26, P647, DOI 10.1147/rd.266.0647
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Ye QX, 2005, IMAGE VISION COMPUT, V23, P565, DOI 10.1016/j.imavis.2005.01.004
   Zhang T, 2008, APPL ECON LETT, V15, P641, DOI 10.1080/13504850600721874
NR 33
TC 70
Z9 79
U1 0
U2 32
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1590
EP 1599
DI 10.1016/j.imavis.2010.04.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300002
DA 2024-07-18
ER

PT J
AU Graña, M
   Savio, AM
   García-Sebastián, M
   Fernandez, E
AF Grana, Manuel
   Savio, Alexandre M.
   Garcia-Sebastian, Maite
   Fernandez, Elsa
TI A lattice computing approach for on-line fMRI analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fMRI; Lattice computing; Lattice Associative Memories; Linear mixing
   model
AB We introduce an approach to fMRI analysis based on the Endmember Induction Heuristic Algorithm (EIHA). This algorithm uses the Lattice Associative Memory (LAM) to detect Lattice Independent vectors, which can be assumed to be Affine Independent, and therefore candidates to be the endmembers of the data. Induced endmembers are used to compute the activation levels of voxels as result of an unmixing process. The endmembers correspond to diverse activation patterns, one of these activation patterns corresponds to the resting state of the neuronal tissue. The on-line working of the algorithm does not need neither a previous training process nor a priori models of the data. Results on a case study compare with the results given by the state of art SPM software. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Grana, Manuel; Savio, Alexandre M.; Garcia-Sebastian, Maite; Fernandez, Elsa] Univ Basque Country, Dept CCIA, Computat Intelligence Grp, San Sebastian 20080, Spain.
C3 University of Basque Country
RP Graña, M (corresponding author), Univ Basque Country, Dept CCIA, Computat Intelligence Grp, Apdo 649, San Sebastian 20080, Spain.
EM ccpgrrom@gmail.com
RI Hernandez, María/GYU-3543-2022; HERNÁNDEZ, MARÍA/JQW-0995-2023; Romay,
   Manuel M. Graña/L-1341-2014; Garcia-Sebastian, Maite/AGG-6584-2022;
   Fernandez, Elsa/B-7178-2013; Savio, Alexandre/L-8369-2014
OI Garcia-Sebastian, Maite/0000-0003-3480-6056; Fernandez,
   Elsa/0000-0001-9142-7752; Savio, Alexandre/0000-0002-6608-6885
FU Basque Government
FX We are grateful to the detailed comments of the reviewers that helped us
   to improve the paper. The work has been supported by Saoitek grants of
   the Basque Government.
CR Buffington ALH, 2005, PAIN, V113, P172, DOI 10.1016/j.pain.2004.10.006
   Calhoun VD, 2006, IEEE ENG MED BIOL, V25, P79, DOI 10.1109/MEMB.2006.1607672
   Calhoun VD, 2004, NEUROPSYCHOPHARMACOL, V29, P2097, DOI 10.1038/sj.npp.1300543
   Calhoun VD, 2004, BIOL PSYCHIAT, V55, P842, DOI 10.1016/j.biopsych.2004.01.011
   Deneux T, 2006, NEUROIMAGE, V32, P1669, DOI 10.1016/j.neuroimage.2006.03.006
   Friston KJ., 1994, HUMAN BRAIN MAPPING, V2, P189, DOI [10.1002/hbm.460020402, DOI 10.1002/HBM.460020402]
   Gibbons RD, 2004, NEUROIMAGE, V22, P804, DOI 10.1016/j.neuroimage.2004.02.003
   Graña M, 2009, NEUROCOMPUTING, V72, P2111, DOI 10.1016/j.neucom.2008.06.026
   Graña M, 2008, IEEE INT CONF FUZZY, P1779
   Greicius MD, 2004, P NATL ACAD SCI USA, V101, P4637, DOI 10.1073/pnas.0308627101
   Hanson RJ., 1974, SOLVING LEAST SQUARE
   Keshava N., 2003, Lincoln Laboratory Journal, V14, P55
   Keshava N, 2002, IEEE SIGNAL PROC MAG, V19, P44, DOI 10.1109/79.974727
   LAZAR NA, 2008, STAT BIOL HLTH SERIE
   Lindquist MA, 2008, STAT SCI, V23, P439, DOI 10.1214/09-STS282
   Müller HP, 2002, IEEE ENG MED BIOL, V21, P134, DOI 10.1109/MEMB.2002.1044183
   Pekar JJ, 2006, IEEE ENG MED BIOL, V25, P24, DOI 10.1109/MEMB.2006.1607665
   Raducanu B, 2003, J MATH IMAGING VIS, V19, P113, DOI 10.1023/A:1024725414204
   Ritter G, 2006, ADV IMAG ELECT PHYS, V144, P165, DOI 10.1016/S1076-5670(06)44002-7
   Ritter GX, 2009, NEUROCOMPUTING, V72, P2101, DOI 10.1016/j.neucom.2008.06.025
   Ritter GX, 2003, J MATH IMAGING VIS, V19, P95, DOI 10.1023/A:1024773330134
   Ritter GX, 1998, IEEE T NEURAL NETWOR, V9, P281, DOI 10.1109/72.661123
   Ritter GX, 1999, NEURAL NETWORKS, V12, P851, DOI 10.1016/S0893-6080(99)00033-7
   Sarty G.E., 2007, Computing Brain Activity Maps from fMRI Time-Series Images
   Smith SM, 2004, BRIT J RADIOL, V77, pS167, DOI 10.1259/bjr/33553595
   Strother SC, 2006, IEEE ENG MED BIOL, V25, P27, DOI 10.1109/MEMB.2006.1607667
NR 26
TC 18
Z9 18
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2010
VL 28
IS 7
SI SI
BP 1155
EP 1161
DI 10.1016/j.imavis.2009.10.004
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 603UP
UT WOS:000278233900009
DA 2024-07-18
ER

PT J
AU Chen, HN
   Chung, KL
   Hung, JE
AF Chen, Hsiu-Niang
   Chung, Kuo-Liang
   Hung, Jian-Er
TI Novel fractal image encoding algorithm using normalized one-norm and
   kick-out condition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Conventional full search; Fractal encoding; Image quality; Kick-out
   rule; Normalized one-norm; DCT inner product
ID SPATIAL CORRELATION; COMPRESSION; SEARCH
AB For fractal image encoding, based on a special measure called the one-norm of normalized block, this paper presents a novel kick-out method to discard impossible domain blocks in early stage for the current range block. It leads to speed up the encoding time. Since our proposed kick-out method is based on Jacquin's full search method, both methods need to search the whole image and the decoded image quality are the same. Based on five typical testing images, our proposed method has 22% execution time improvement ratio in average when compared with Jacquin's full search method. Combining our proposed method with Truong et al.'s DCT inner product method, Lai et al.'s kick-out method, or both methods, the encoding-time performance can be improved further. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Chen, Hsiu-Niang; Chung, Kuo-Liang; Hung, Jian-Er] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei 10672, Taiwan.
   [Chen, Hsiu-Niang] Vannung Univ Sci & Technol, Dept Informat Management, Chungli 320, Taiwan.
C3 National Taiwan University of Science & Technology
RP Chung, KL (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, 43,Sect 4,Keelung Rd, Taipei 10672, Taiwan.
EM k.l.chung@ntust.edu.tw
RI Chung, Kuo-Liang/H-6207-2011
CR [Anonymous], 1988, FRACTAL EVERYWHERE
   BARTHEL KU, 1994, P INT WORKSH IM PROC, P33
   Cardinal J, 2001, IEEE T IMAGE PROCESS, V10, P159, DOI 10.1109/83.892452
   Chung KL, 2006, CHAOS SOLITON FRACT, V29, P215, DOI 10.1016/j.chaos.2005.08.023
   Distasi R, 2006, IEEE T IMAGE PROCESS, V15, P89, DOI 10.1109/TIP.2005.860334
   Duh DJ, 2005, IMAGE VISION COMPUT, V23, P1115, DOI 10.1016/j.imavis.2005.05.013
   Fisher Y., 1995, Fractal Image Compression: Theory and Application
   FURAO S, 2004, SIGNAL PROCESS-IMAGE, V5, P393
   He CJ, 2006, CHAOS SOLITON FRACT, V27, P1178, DOI 10.1016/j.chaos.2005.04.006
   Jackson DJ, 1997, IMAGE VISION COMPUT, V15, P759, DOI 10.1016/S0262-8856(97)00020-6
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Kovács T, 2008, IMAGE VISION COMPUT, V26, P1129, DOI 10.1016/j.imavis.2007.12.008
   Chung KL, 2006, J VIS COMMUN IMAGE R, V17, P1209, DOI 10.1016/j.jvcir.2006.01.002
   Lai CM, 2003, IEEE T IMAGE PROCESS, V12, P1398, DOI 10.1109/TIP.2003.817246
   Sze CJ, 1996, IMAGE VISION COMPUT, V14, P401, DOI 10.1016/0262-8856(95)01074-2
   Truong TK, 2004, CHAOS SOLITON FRACT, V22, P1071, DOI 10.1016/j.chaos.2004.03.015
   Truong TK, 2000, IEEE T IMAGE PROCESS, V9, P529, DOI 10.1109/83.841930
   Tseng CC, 2008, IMAGE VISION COMPUT, V26, P1154, DOI 10.1016/j.imavis.2008.01.003
   Wang XY, 2008, COMPUT GRAPH-UK, V32, P445, DOI 10.1016/j.cag.2008.02.004
   Wang Z, 2000, SIGNAL PROCESS-IMAGE, V15, P767, DOI 10.1016/S0923-5965(99)00018-1
   Wu MS, 2006, CHAOS SOLITON FRACT, V28, P497, DOI 10.1016/j.chaos.2005.07.004
   Wu XW, 2005, COMPUT ELECTR ENG, V31, P402, DOI 10.1016/j.compeleceng.2005.02.003
NR 22
TC 21
Z9 22
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 518
EP 525
DI 10.1016/j.imavis.2009.08.007
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300021
DA 2024-07-18
ER

PT J
AU Boughorbel, F
   Mercimek, M
   Koschan, A
   Abidi, M
AF Boughorbel, Faysal
   Mercimek, Muharrem
   Koschan, Andreas
   Abidi, Mongi
TI A new method for the registration of three-dimensional point-sets: The
   Gaussian Fields framework
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Rigid registration; Gaussian Fields; Moment invariants; Fast Gauss
   Transform; Optimization
ID AUTOMATIC REGISTRATION; RECOGNITION; REPRESENTATION; IMAGES
AB In this paper, we present a 3D automatic registration method based on Gaussian Fields and energy minimization. A continuously differentiable energy function is defined, which is convex in a large neighborhood of the alignment parameters. We show that the size of the region of convergence can be significantly extended reducing the need for close initialization and overcoming local convergence problems of the standard Iterative Closest Point (ICP) algorithms. Moreover, the Gaussian criterion can be applied with linear computational complexity using Fast Gauss Transform methods. Experimental evaluation of the technique using synthetic and real datasets demonstrates the usefulness as well as the limits of the approach. Published by Elsevier B.V.
C1 [Boughorbel, Faysal; Mercimek, Muharrem; Koschan, Andreas; Abidi, Mongi] Univ Tennessee, Imaging Robot & Intelligent Syst Lab, Knoxville, TN 37996 USA.
C3 University of Tennessee System; University of Tennessee Knoxville
RP Koschan, A (corresponding author), Univ Tennessee, Imaging Robot & Intelligent Syst Lab, 334 Ferris Hall, Knoxville, TN 37996 USA.
EM akoschan@utk.edu
RI Mercimek, Muharrem/AAH-7901-2019; Mercimek, Muharrem/X-6735-2019
OI Mercimek, Muharrem/0000-0001-8737-298X; 
FU DOE University Research Program in Robotics [DOE-DE-FG02-86NE37968];
   DOD/TACOM/NAC/ARC [R01-1344-18]
FX This work was supported in part by the DOE University Research Program
   in Robotics under Grant DOE-DE-FG02-86NE37968 and by the
   DOD/TACOM/NAC/ARC Program, R01-1344-18.
CR Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   BES PJ, 1992, IEEE T PATTERN ANAL, V14, P239
   Boughorbel F, 2004, INT C PATT RECOG, P24, DOI 10.1109/ICPR.2004.1334460
   Boughorbel F, 2004, PATTERN RECOGN, V37, P1567, DOI 10.1016/j.patcog.2004.02.005
   BOUGHORBEL F, 2005, P INT C IM PROC IEEE, V3, P804
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   CHARPIAT G, 2003, P INT C IM PROC BARC, V2, P627
   Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Dalley G, 2002, COMPUT VIS IMAGE UND, V87, P104, DOI 10.1006/cviu.2002.0986
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1131, DOI 10.1109/34.625115
   Elgammal A, 2003, IEEE T PATTERN ANAL, V25, P1499, DOI 10.1109/TPAMI.2003.1240123
   FAUGERAS OD, 1986, INT J ROBOT RES, V5, P27, DOI 10.1177/027836498600500302
   Fitzgibbon AW, 2003, IMAGE VISION COMPUT, V21, P1145, DOI 10.1016/j.imavis.2003.09.004
   GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004
   Greengard L., 1988, RAPID EVALUATION POT
   HEBERT M, 1995, IEEE T PATTERN ANAL, V17, P681, DOI 10.1109/34.391410
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   MASUDA T, 1995, COMPUT VIS IMAGE UND, V61, P295, DOI 10.1006/cviu.1995.1024
   Medioni G., 2000, COMPUTATIONAL FRAMEW
   Murio D.A., 2011, The Mollification Method and the Numerical Solution of Ill-Posed Problems
   Park SY, 2004, IMAGE VISION COMPUT, V22, P623, DOI 10.1016/j.imavis.2004.01.002
   Pottmann H, 2004, COMPUT VIS IMAGE UND, V95, P54, DOI 10.1016/j.cviu.2004.04.002
   Press W. H., 1996, NUMERICAL RECIPES FO
   Rodrigues M, 2002, COMPUT VIS IMAGE UND, V87, P1, DOI 10.1006/cviu.2002.0978
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785
   Stoddart A. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P40, DOI 10.1109/ICPR.1996.546720
   Taati B, 2007, 3DIM 2007: SIXTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P265
   Thirion JP, 1996, INT J COMPUT VISION, V18, P121, DOI 10.1007/BF00054999
   Trucco E, 1999, PATTERN RECOGN LETT, V20, P889, DOI 10.1016/S0167-8655(99)00055-0
   Turk G., 1994, P ACM SIGGRAPH
   Yang CJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P464
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zinsser T, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P695
NR 39
TC 29
Z9 36
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 124
EP 137
DI 10.1016/j.imavis.2009.05.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000013
DA 2024-07-18
ER

PT J
AU Yu, L
   He, ZS
   Cao, Q
AF Yu, Lei
   He, Zhongshi
   Cao, Qi
TI Gabor texture representation method for face recognition using the Gamma
   and generalized Gaussian models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Gabor magnitude; Gabor phase; Texture information;
   Null space linear discriminant analysis (NLDA); Feature level fusion
ID FEATURES; RETRIEVAL; 2D
AB A novel face recognition algorithm based on Gabor texture information is proposed in this paper. Two kinds of strategies to capture it are introduced: Gabor magnitude-based texture representation (GMTR) and Gabor phase-based texture representation (GPTR). Specifically, GMTR is characterized by using the Gamma density (F D) to model the Gabor magnitude distribution, while GPTR is characterized by using the generalized Gaussian density (GGD) to model the Gabor phase distribution. The estimated model parameters serve as texture representation. Experiments are performed on Yale, ORL and FERET databases to validate the feasibility of the proposed method. The results show that the proposed GMTR-based and GPTR-based NLDA both significantly outperform the widely used Gabor features-based NLDA and other existing subspace methods. In addition, the feature level fusion of these two kinds of texture representations performs better than them individually. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Yu, Lei; He, Zhongshi; Cao, Qi] Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
C3 Chongqing University
RP He, ZS (corresponding author), Chongqing Univ, Coll Comp Sci, Chongqing 400030, Peoples R China.
EM zshe@cqu.edu.cn
FU Natural Science Foundation of Chongqing CSTC [2007BB2134]; National High
   Technology Research and Development Program of China (863 Program)
   [2007AA01Z423]
FX This research is partly supported by a Grant from the Natural Science
   Foundation of Chongqing CSTC (No. 2007BB2134) and a Grant from the
   National High Technology Research and Development Program of China (863
   Program, No. 2007AA01Z423). The authors also thank the anonymous
   reviewers for their critical and constructive comments and suggestions.
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Dang H, 2000, J MATH ANAL APPL, V245, P1, DOI 10.1006/jmaa.2000.6709
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Do MN, 2002, IEEE T IMAGE PROCESS, V11, P146, DOI 10.1109/83.982822
   GONZALEZJIMENEZ D, 2007, P IEEE C IM PROC, V4, P485
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Heisele B, 2007, INT J COMPUT VISION, V74, P167, DOI 10.1007/s11263-006-0006-z
   Huang R, 2002, INT C PATT RECOG, P29, DOI 10.1109/ICPR.2002.1047787
   Hyvarinen A., 1999, Neural Computing Surveys, V2
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kalocsai P, 2000, IMAGE VISION COMPUT, V18, P273, DOI 10.1016/S0262-8856(99)00051-7
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu DH, 2004, PATTERN RECOGN LETT, V25, P267, DOI 10.1016/j.patrec.2003.10.007
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Niu B, 2008, PATTERN RECOGN, V41, P3237, DOI 10.1016/j.patcog.2007.12.001
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   PHILLIPS PJ, 2007, FRVT 2006 REPORT FRV
   SHAN S, 2005, LNCS, P278
   SHARIFI K, 1995, IEEE T CIRC SYST VID, V5, P52, DOI 10.1109/76.350779
   Shen L., 2004, Proc. of Image and Vision Computing NewZealand, P77
   Shen L, 2007, IMAGE VISION COMPUT, V25, P553, DOI 10.1016/j.imavis.2006.05.002
   Shen LL, 2006, PATTERN RECOGN LETT, V27, P1758, DOI 10.1016/j.patrec.2006.02.005
   Shen LL, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P170
   Shin JW, 2005, IEEE SIGNAL PROC LET, V12, P258, DOI 10.1109/LSP.2004.840869
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhao W, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P336, DOI 10.1109/AFGR.1998.670971
NR 37
TC 39
Z9 42
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 177
EP 187
DI 10.1016/j.imavis.2009.05.012
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000017
DA 2024-07-18
ER

PT J
AU Berretti, S
   Del Bimbo, A
   Pala, P
AF Berretti, Stefano
   Del Bimbo, Alberto
   Pala, Pietro
TI 3D Mesh decomposition using Reeb graphs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D Mesh decomposition; Reeb graph; Geodesic distance
ID SURFACE DECOMPOSITION; SEGMENTATION; SHAPE
AB Decomposition of complex 3D objects into simpler sub-parts is a challenging research subject with relevant outcomes for several application contexts. In this paper, an approach is proposed for decomposition of 3D objects based on Reeb graphs. The approach is motivated by perceptual principles and supports identification of salient object protrusions. Experimental results are presented to demonstrate the effectiveness of the proposed approach with respect to different solutions appeared in the literature, and with reference to ground-truth data obtained by manual decomposition of 3D objects. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Berretti, Stefano; Del Bimbo, Alberto; Pala, Pietro] Univ Florence, Dipartimento Sistemi & Informat, I-50139 Florence, Italy.
C3 University of Florence
RP Berretti, S (corresponding author), Univ Florence, Dipartimento Sistemi & Informat, Via S Marto 3, I-50139 Florence, Italy.
EM berretti@dsi.unifi.it; delbimbo@dsi.unifi.it; pala@dsi.unifi.it
RI Berretti, Stefano/U-9004-2019
OI Berretti, Stefano/0000-0003-1219-4386; PALA, PIETRO/0000-0001-5670-3774;
   DEL BIMBO, ALBERTO/0000-0002-1052-8322
FU Information Society Technologies (IST) Program; European Commission;
   DELOS Network of Excellence on Digital Libraries [G038-507618]
FX This work is partially supported by the Information Society Technologies
   (IST) Program of the European Commission as part of the DELOS Network of
   Excellence on Digital Libraries (Contract G038-507618).; Very
   preliminary versions of this work appeared in [39,40].
CR Acharya T, 2005, IMAGE PROCESSING: PRINCIPLES AND APPLICATIONS, P1, DOI 10.1002/0471745790
   [Anonymous], 1963, MORSE THEORY AM 51, DOI [10.1515/9781400881802, DOI 10.1515/9781400881802]
   [Anonymous], P IEEE INT C MULT EX
   Attene M, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P14
   Attene M, 2003, VISUAL COMPUT, V19, P127, DOI 10.1007/s00371-002-0182-y
   ATTENE M, 2003, VISUAL COMPUT, V22, P181
   Axen Ulrike., 1998, Mathematical Visualization, P223
   Berretti S, 2006, INT C PATT RECOG, P19
   Carr H, 2004, IEEE VISUALIZATION 2004, PROCEEEDINGS, P497, DOI 10.1109/VISUAL.2004.96
   CECCARELLI E, 2005, P INT C MULT EXP AMS, P153
   Chung F. R., 1997, REGIONAL C SERIES MA, V92
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Cohen-Steiner D., 2003, P 19 ANN S COMP GEOM, P312, DOI DOI 10.1145/777792.777839
   Funkhouser T, 2004, ACM T GRAPHIC, V23, P652, DOI 10.1145/1015706.1015775
   Garland M., 2001, I3D 01, P49, DOI [DOI 10.1145/364338.364345, 10.1145/364338.364345]
   Gregory A, 1999, VISUAL COMPUT, V15, P453, DOI 10.1007/s003710050192
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   Katz S, 2005, VISUAL COMPUT, V21, P649, DOI 10.1007/s00371-005-0344-9
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Lavoué G, 2005, COMPUT AIDED DESIGN, V37, P975, DOI 10.1016/j.cad.2004.09.001
   Lee Y, 2005, COMPUT AIDED GEOM D, V22, P444, DOI 10.1016/j.cagd.2005.04.002
   Lévy B, 2002, ACM T GRAPHIC, V21, P362, DOI 10.1145/566570.566590
   Li X., 2001, P 2001 S INT 3D GRAP, P35, DOI DOI 10.1145/364338.364343
   Lien J, 2006, P 2006 ACM S SOL PHY, P219
   Liu R, 2007, COMPUT GRAPH FORUM, V26, P385, DOI 10.1111/j.1467-8659.2007.01061.x
   Mangan AP, 1999, IEEE T VIS COMPUT GR, V5, P308, DOI 10.1109/2945.817348
   Mortara M, 2004, ALGORITHMICA, V38, P227, DOI 10.1007/s00453-003-1051-4
   Page DL, 2003, PROC CVPR IEEE, P27
   Podolak J, 2006, ACM T GRAPHIC, V25, P549, DOI 10.1145/1141911.1141923
   REEB G, 1946, CR HEBD ACAD SCI, V222, P847
   Shamir A, 2008, COMPUT GRAPH FORUM, V27, P1539, DOI 10.1111/j.1467-8659.2007.01103.x
   Shapira L, 2008, VISUAL COMPUT, V24, P249, DOI 10.1007/s00371-007-0197-5
   Shatz I, 2006, VISUAL COMPUT, V22, P825, DOI 10.1007/s00371-006-0067-6
   Shlafman S, 2002, COMPUT GRAPH FORUM, V21, P219, DOI 10.1111/1467-8659.00581
   TAUBIN G, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P902, DOI 10.1109/ICCV.1995.466840
   Tierny J., 2006, PACIFIC GRAPHICS, V2006, P85
   Tierny J, 2007, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2007, PROCEEDINGS, P215, DOI 10.1109/SMI.2007.38
   Tierny J, 2009, COMPUT GRAPH FORUM, V28, P41, DOI 10.1111/j.1467-8659.2008.01190.x
   Wu KN, 1997, IEEE T PATTERN ANAL, V19, P1223, DOI 10.1109/34.632982
   Zhang E, 2005, ACM T GRAPHIC, V24, P1, DOI 10.1145/1037957.1037958
   Zhou K., 2004, P EUR ICS ACM SIGGRA, P45
   Zöckler M, 2000, VISUAL COMPUT, V16, P241, DOI 10.1007/PL00013396
   Zuckerberger E, 2002, COMPUT GRAPH-UK, V26, P733, DOI 10.1016/S0097-8493(02)00128-0
NR 46
TC 37
Z9 42
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1540
EP 1554
DI 10.1016/j.imavis.2009.02.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800012
DA 2024-07-18
ER

PT J
AU Mahdian, B
   Saic, S
AF Mahdian, Babak
   Saic, Stanislav
TI Using noise inconsistencies for blind image forensics
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image forensics; Digital forgery; Image tampering; Image segmentation;
   Noise inconsistency
AB A commonly used tool to conceal the traces of tampering is the addition of locally random noise to the altered image regions. The noise degradation is the main cause of failure of many active or passive image forgery detection methods. Typically, the amount of noise is uniform across the entire authentic image. Adding locally random noise may cause inconsistencies in the image's noise. Therefore, the detection of various noise levels in an image may signify tampering. In this paper, we propose a novel method capable of dividing an investigated image into various partitions with homogenous noise levels. In other words, we introduce a segmentation method detecting changes in noise level. We assume the additive white Gaussian noise. Several examples are shown to demonstrate the proposed method's output. An extensive quantitative measure of the efficiency of the noise estimation part as a function of different noise standard deviations, region sizes and various JPEG compression qualities is proposed as well. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Mahdian, Babak; Saic, Stanislav] Acad Sci Czech Republ, Inst Informat Theory & Automat, CR-18208 Prague 8, Czech Republic.
C3 Czech Academy of Sciences; Institute of Information Theory & Automation
   of the Czech Academy of Sciences
RP Mahdian, B (corresponding author), Acad Sci Czech Republ, Inst Informat Theory & Automat, Pod Vodarenskou Vezi 4, CR-18208 Prague 8, Czech Republic.
EM mahdian@utia.cas.cz; ssaic@utia.cas.cz
RI Mahdian, Babak/H-4313-2014; Saic, Stanislav/B-8308-2018
OI Saic, Stanislav/0000-0002-8043-1841
FU Czech Science Foundation [GACR 102/08/0470]
FX This work has been supported by the Czech Science Foundation under the
   Project No. GACR 102/08/0470.
CR [Anonymous], THESIS DARTMOUTH COL
   [Anonymous], P DIG FOR RES WORKSH
   [Anonymous], SPIE ELECT IMAGING S
   BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1
   Brox T., 2001, P 22 S INF THEOR BEN
   Chui C. K., 1992, WAVELETS TUTORIAL TH
   Coifman RR., 1995, WAVELETS STAT, P125, DOI DOI 10.1007/978-1-4612-2544-7_9
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Fridrich J., 1999, PROC ACM WORKSHOM MU, P19
   Johnson SL, 2005, ENVIRON MICROBIOL, V7, P1, DOI 10.1111/j.1462-2920.2004.00649.x
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Yeung MM, 1998, COMMUN ACM, V41, P30
   Yu ZY, 2002, INT C PATT RECOG, P941, DOI 10.1109/ICPR.2002.1048460
NR 18
TC 231
Z9 266
U1 1
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1497
EP 1503
DI 10.1016/j.imavis.2009.02.001
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800008
DA 2024-07-18
ER

PT J
AU Adán, A
   Vázquez, AS
   Cerrada, C
   Salamanca, S
AF Adan, Antonio
   Vazquez, Andres S.
   Cerrada, Carlos
   Salamanca, Santiago
TI Moving surface extraction based on unordered hexagonal perfect submaps
   projection: Applications to 3D feature tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Machine vision; Moving scene recovering; Active vision; 3D tracking;
   Feature extraction; Robot-vision systems
ID STRUCTURED LIGHT; ACQUISITION; PATTERNS
AB in this paper, we present a structured light technique based on the projection of a color coded hexagonal array that is able to obtain range images from moving scenes. Repetition and disorder is allowed in the codeword which implies several advantages: the mean Hamming distance between contiguous codewords of the pattern increases, the code loss due to occlusions and discontinuities can be efficiently handled and the computational cost in the pattern-image correspondence phase is highly reduced.
   The structured light projection system has been tested under real moving scenes on medium resolution range images and for slow controlled movements. In order to validate the performance of our range vision system we have used it to identify and track several 3D feature points as the scene moves. To measure the accuracy of the tracking a 6 DOE manipulator robot has been included in the experimental setup. All this experimental work, the results and the main contributions of our method compared to other perfect map and submap based techniques are detailed in the paper. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Adan, Antonio; Vazquez, Andres S.] Univ Castilla La Mancha, Escuela Super Informat, E-13071 Ciudad Real, Spain.
   [Cerrada, Carlos] Univ Nacl Educ Distancia, ETSI Informat, Madrid, Spain.
   [Salamanca, Santiago] Univ Extremadura, Escuela Ingn Ind, Badajoz, Spain.
C3 Universidad de Castilla-La Mancha; Universidad Nacional de Educacion a
   Distancia (UNED); Universidad de Extremadura
RP Adán, A (corresponding author), Univ Castilla La Mancha, Escuela Super Informat, Paseo Univ 4, E-13071 Ciudad Real, Spain.
EM Antonio.Adan@uclm.es; Andress.Vazquez@uclm.es; ccerrada@issi.uned.es;
   ssalaman@unex.es
RI Salamanca, Santiago/C-7052-2012; Salamanca, Santiago/AGN-4408-2022;
   Cerrada, Carlos/O-2221-2019; Adán, Antonio/A-1153-2012; Vázquez, Andres
   S./ABA-8641-2020
OI Salamanca, Santiago/0000-0001-5878-5988; Cerrada,
   Carlos/0000-0002-8591-6581; Adán, Antonio/0000-0002-0370-9651; Vázquez,
   Andres S./0000-0002-8144-9429
FU  [DPI2006-14794-C02];  [PCI08-0052-1401]
FX This research has been supported by DPI2006-14794-C02 and
   PCI08-0052-1401 Spanish projects.
CR ADAN A, 2004, 2 INT S 3D DAT PROC
   [Anonymous], PROC SPIE
   BOYER KL, 1987, IEEE T PATTERN ANAL, V9, P14, DOI 10.1109/TPAMI.1987.4767869
   Brimkov V.E., 2001, ELECT NOTES THEORETI, V46
   Chen CS, 1997, IMAGE VISION COMPUT, V15, P445, DOI 10.1016/S0262-8856(96)01148-1
   Davies CJ, 1998, IEEE T SYST MAN CY B, V28, P90, DOI 10.1109/3477.658582
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Durdle NG, 1998, UNIVERSITY AND INDUSTRY - PARTNERS IN SUCCESS, CONFERENCE PROCEEDINGS VOLS 1-2, P874, DOI 10.1109/CCECE.1998.685637
   ETZION T, 1988, IEEE T INFORM THEORY, V34, P1308, DOI 10.1109/18.21260
   GRIFFIN PM, 1992, PATTERN RECOGN, V25, P609, DOI 10.1016/0031-3203(92)90078-W
   Hall-Holt O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P359, DOI 10.1109/ICCV.2001.937648
   Hsieh YC, 2001, PATTERN RECOGN, V34, P343, DOI 10.1016/S0031-3203(99)00224-1
   ITO M, 1995, PATTERN RECOGN, V28, P27, DOI 10.1016/0031-3203(94)E0047-O
   KIYASU S, 1995, IEEE T INSTRUM MEAS, V44, P775, DOI 10.1109/19.387330
   Koninckx TP, 2006, IEEE T PATTERN ANAL, V28, P432, DOI 10.1109/TPAMI.2006.62
   Lavoie P., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P370, DOI 10.1109/ICIAP.1999.797623
   MACWILLIAMS FJ, 1976, P IEEE, V64, P1715, DOI 10.1109/PROC.1976.10411
   MARUYAMA M, 1987, T PATTERN ANAL MACHI, V15, P647
   MONKS TP, 1994, THESIS U SOUTHAMPTON
   Morano RA, 1998, IEEE T PATTERN ANAL, V20, P322, DOI 10.1109/34.667888
   Pagès J, 2005, IMAGE VISION COMPUT, V23, P707, DOI 10.1016/j.imavis.2005.05.007
   Pagès J, 2006, IEEE INT CONF ROBOT, P4118, DOI 10.1109/ROBOT.2006.1642335
   Petriu EM, 2000, IEEE IMTC P, P1237, DOI 10.1109/IMTC.2000.848675
   Salvi J, 1998, PATTERN RECOGN LETT, V19, P1055, DOI 10.1016/S0167-8655(98)00085-3
   Spoelder HJW, 2000, IEEE T INSTRUM MEAS, V49, P1331, DOI 10.1109/19.893279
   Umeda K, 2004, IEEE INT CONF ROBOT, P3167, DOI 10.1109/ROBOT.2004.1307550
   VUYLSTEKE P, 1990, IEEE T PATTERN ANAL, V12, P148, DOI 10.1109/34.44402
   ZHANG L, 2002, P 3D DPVT IEEE, P532
   ZHANG S, 2004, P 2004 C COMP VIS PA, V3, P28
   Zhou LX, 2001, PROC SPIE, V4302, P99, DOI 10.1117/12.424920
NR 30
TC 7
Z9 9
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1083
EP 1096
DI 10.1016/j.imavis.2008.10.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000010
DA 2024-07-18
ER

PT J
AU Eade, E
   Drummond, T
AF Eade, Ethan
   Drummond, Tom
TI Edge landmarks in monocular SLAM
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 17th Annual British Machine Vision Conference
CY SEP, 2006
CL British Machine Vis Assoc, Edinburgh, SCOTLAND
HO British Machine Vis Assoc
DE SLAM; Monocular SLAM; Structure and motion; Edges; Landmarks; Particle
   filter; Edgelet; Partial initialization; Inverse depth; Data
   association; Simultaneous localization and mapping; Edge detection;
   Monocular vision
AB While many visual simultaneous localization and mapping (SLAM) systems use point features as landmarks, few take advantage of the edge information in images. Those SLAM systems that do observe edge features do not consider edges with all degrees of freedom. Edges are difficult to use in vision SLAM because of selection, observation, initialization and data association challenges. A map that includes edge features, however, contains higher-order geometric information useful both during and after SLAM. We define a well-localized edge landmark and present an efficient algorithm for selecting such landmarks. Further, we describe how to initialize new landmarks, observe mapped landmarks in subsequent images, and address the data association challenges of edges. Our methods, implemented in a particle-filter SLAM system, operate at frame rate on live video sequences. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Eade, Ethan; Drummond, Tom] Univ Cambridge, Cambridge CB2 1PZ, England.
C3 University of Cambridge
RP Eade, E (corresponding author), Univ Cambridge, Cambridge CB2 1PZ, England.
EM ee231@cam.ac.uk; twd20@cam.ac.uk
RI Drummond, Tom/A-4696-2011
OI Drummond, Tom/0000-0001-8204-5904
CR [Anonymous], 1986, IEEE T PATTERN ANAL
   [Anonymous], IJCAI WORKSH REAS UN
   DAVISON AJ, 2003, ICCV
   Drummond T, 2000, INT J COMPUT VISION, V37, P21, DOI 10.1023/A:1008125412549
   EADE E, 2006, P 17 BRIT MACH VIS C, V1
   Eade E., 2006, P 2006 IEEE COMPUTER, VVolume 1, P469, DOI DOI 10.1109/CVPR.2006.263
   FOLKESSON J, 2005, ICRA 05
   GEE AP, 2006, 2 INT S VIS COMP
   HEATH M, 1996, CVPR 96
   Jin HL, 2003, VISUAL COMPUT, V19, P377, DOI 10.1007/s00371-003-0202-6
   JULIER JKU, 1997, P AEROSENSE
   KLEIN G, 2005, P BRIT MACH VIS C BM, V2
   KWOK N, 2003, ACRA 03
   LEMAIRE T, 2005, IROS 2005
   Lemaire T, 2007, IEEE INT CONF ROBOT, P2791, DOI 10.1109/ROBOT.2007.363894
   MONTEMERLO M, 2003, IJCAI
   ROSTEN E, 2005, ICCV 2005, V2
   SHIN MC, 1998, CVPR 98
   SMITH P, 2006, P 17 BRIT MACH VIS C, V1
   TAYLOR CJ, 1995, IEEE T PATTERN ANAL, V17, P1021, DOI 10.1109/34.473228
NR 20
TC 68
Z9 86
U1 0
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 2
PY 2009
VL 27
IS 5
SI SI
BP 588
EP 596
DI 10.1016/j.imavis.2008.04.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 437WD
UT WOS:000265516700009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Khan, JF
   Adhami, RR
   Bhuiyan, SMA
AF Khan, Jesmin F.
   Adhami, Reza R.
   Bhuiyan, Sharif M. A.
TI A customized Gabor filter for unsupervised color image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised clustering; Expectation maximization; Image segmentation;
   Schwarz criterion; Gabor filter
ID INFORMATION; SPACE; MODEL
AB This paper presents work on accurate image segmentation utilizing local image characteristics. Image features are measured by employing an appropriate Gabor filter with adaptively chosen size, orientation. frequency and phase for each pixel. An image property called phase divergence is used for the selection of the appropriate filter size. Characteristic features related to the change in brightness, color, texture and position are extracted for each pixel at the selected size of the filter. In order to cluster the pixels into different regions, the joint distribution of these pixel features is modeled by a mixture of Gaussians utilizing three variants of the expectation maximization (EM) algorithm. The three different versions of EM used in this work for unsupervised clustering are: (1) penalized EM, (2) penalized stochastic EM, and (3) penalized inverse EM. Given the desired number of Gaussian mixture components, all three EM algorithms estimate the parameters of the mixture of Gaussians model that represents the joint distribution of pixel features. We determine the value of the number of models that best suits the natural number of clusters present in the image based on the Schwarz criterion, which maximizes the posterior probability of the number of groups given the samples of observation. This segmentation algorithm has been tested on the images of the Berkeley segmentation benchmark and the performance has demonstrated the effectiveness, accuracy and superiority of the proposed method. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Khan, Jesmin F.; Adhami, Reza R.; Bhuiyan, Sharif M. A.] Univ Alabama, Dept Elect & Comp Engn, Huntsville, AL 35899 USA.
C3 University of Alabama System; University of Alabama Huntsville
RP Khan, JF (corresponding author), Univ Alabama, Dept Elect & Comp Engn, 272 Engn Bldg, Huntsville, AL 35899 USA.
EM khanj@ece.uah.edu; adhami@ece.uah.edu; bhuiyas@ece.uah.edu
RI cai, bo/G-1491-2010
CR BRUCE A, 1994, BAYESIAN THEORY
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Celeux G., 1985, Computational Statistics Quarterly, V2, P73
   Chen HC, 2004, IEEE SIGNAL PROC LET, V11, P641, DOI 10.1109/LSP.2004.830116
   Cheng HD, 2000, IEEE T IMAGE PROCESS, V9, P2071, DOI 10.1109/83.887975
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Cheung YM, 2005, IEEE T KNOWL DATA EN, V17, P1583, DOI 10.1109/TKDE.2005.184
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FERRI F, 1992, PATTERN RECOGN LETT, V13, P561, DOI 10.1016/0167-8655(92)90091-D
   FORSTNER W, 1994, P EUR C COMP VIS, P383
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   Garding J, 1996, INT J COMPUT VISION, V17, P163, DOI 10.1007/BF00058750
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   GRUNLAND G, 1995, SIGNAL PROCESSING CO
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   HECKERMAN D, MSRTR9554
   LEUNG T, 1996, P EUR C COMP VIS, P546
   LEUNG T, 1996, P C VIS MOD VIS NOV, P507
   Littmann E, 1997, IEEE T NEURAL NETWOR, V8, P175, DOI 10.1109/72.554203
   LIU JQ, 1994, IEEE T PATTERN ANAL, V16, P689, DOI 10.1109/34.297949
   LUO Q, 2006, IEEE T IMAGE PROCESS, V15, P100
   Makrogiannis S, 2005, IEEE T SYST MAN CY B, V35, P44, DOI 10.1109/TSMCB.2004.837756
   Makrogiannis S, 2005, IEEE T SYST MAN CY A, V35, P224, DOI 10.1109/TSMCA.2004.832820
   MARTIN CFD, 2004, IEEE T PATTERN ANAL, V26, P1
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073
   OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6
   OHTA Y, 1980, COMPUT VISION GRAPH, V13, P222, DOI 10.1016/0146-664X(80)90047-7
   Ormoneit D, 1998, IEEE T NEURAL NETWOR, V9, P639, DOI 10.1109/72.701177
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Rao A., 1990, TAXONOMY TEXTURE DES
   Rubner Y, 2001, COMPUT VIS IMAGE UND, V84, P25, DOI 10.1006/cviu.2001.0934
   SARABI A, 1981, PATTERN RECOGN, V13, P417, DOI 10.1016/0031-3203(81)90004-2
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Snoussi H, 2007, IEEE T SIGNAL PROCES, V55, P3185, DOI 10.1109/TSP.2007.893923
   TOMINAGA S, COLOR RES APPL, V17
   Underwood S., 1977, Computer Graphics and Image Processing, V6, P1
NR 38
TC 30
Z9 36
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 489
EP 501
DI 10.1016/j.imavis.2008.07.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600019
DA 2024-07-18
ER

PT J
AU Amato, A
   Di Lecce, V
AF Amato, Alberto
   Di Lecce, Vincenzo
TI A knowledge based approach for a fast image retrieval system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE knowledge; multi-query relevance feedback; image retrieval; fuzzy
   clustering
ID CLASSIFICATION
AB Due to the huge increase in the amount of digital images available in the "Internet era", making efficient Content Based Image Retrieval (CBIR) systems has become one of the major endeavors. In this paper, the authors study the integration of an automatic generated knowledge base in a CBIR system based on relevance feedback method. An extensive analysis of the database structure has been carried Out using fuzzy clustering algorithms to build the knowledge base. This knowledge base is used to make users aware of the overall organization of the image database during the query process. The relevance feedback method has been used to model the cluster structure as well as the correspondence between high-level user concepts and their low-level machine representation by performing retrievals according to multiple queries supplied by the user during the course of a retrieval session. The results presented in this paper demonstrate that this approach provides accurate retrieval results showing acceptable interaction speed that can be compared with existing methods. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Amato, Alberto; Di Lecce, Vincenzo] Politecn Bari, DIASS, I-74100 Taranto, Italy.
C3 Politecnico di Bari
RP Di Lecce, V (corresponding author), Politecn Bari, DIASS, Vle Turismo 8, I-74100 Taranto, Italy.
EM a.amato@poliba.it; dilecce@poliba.it
CR Amato A, 2003, PROCEEDINGS EC-VIP-MC 2003, VOLS 1 AND 2, P143
   AMATO A, 2004, VECIMS 2004, P67
   AMATO A, 2002, CRETA 6 WSEAS INT MU, P169
   [Anonymous], 1999, P 7 IEEE INTL C COMP
   [Anonymous], 2003, 6 INT C VIS INF SYST
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   Bezdek James C., 1981, PATTERN RECOGN
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Di Lecce V, 2001, J VISUAL LANG COMPUT, V12, P105, DOI 10.1006/jvlc.1999.0154
   Eakins J., 1999, Content based image retrieval: A report to the JISC technology applications programme
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Fu K.S., 1982, SYNTACTIC PATTERN RE, Vsecond
   Jacobs DW, 2000, IEEE T PATTERN ANAL, V22, P583, DOI 10.1109/34.862197
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Krishnapuram R., 1999, FUZZY SYSTEMS C P, V3, p1281 
   KRUSKAL JB, 1964, PSYCHOMETRIKA, V29, P1, DOI 10.1007/BF02289565
   Le Saux B, 2002, INT C PATT RECOG, P259, DOI 10.1109/ICPR.2002.1044678
   Mehrotra S, 1997, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS '97, PROCEEDINGS, P632, DOI 10.1109/MMCS.1997.609791
   Müller H, 2002, LECT NOTES COMPUT SC, V2383, P38
   Murase Hiroshi, 1996, COLUMBIA OBJECT IMAG
   NASTAR C, 1998, 6 ACM INT MULT C MM, P339
   OOMMEN BJ, 1997, IEEE INT C COMP CYB, V1, P12
   PAPATHOMAS TV, 1998, P IS T SPIE C HUM VI, V3, P591
   PAUWELS EJ, 1997, P 2 INT C VIS INF SY, P13
   PEDRYCZ W, 1985, PATTERN RECOGN LETT, V3, P13, DOI 10.1016/0167-8655(85)90037-6
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Santini S, 2000, IEEE MULTIMEDIA, V7, P26, DOI 10.1109/93.879766
   Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   Santini S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P524, DOI 10.1109/MMCS.1999.779256
   Sheikholeslami G, 2002, IEEE T KNOWL DATA EN, V14, P988, DOI 10.1109/TKDE.2002.1033769
   Shen XP, 2004, PROC SPIE, V5307, P188
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Wang ZY, 2004, I C CONT AUTOMAT ROB, P676
NR 38
TC 6
Z9 6
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1466
EP 1480
DI 10.1016/j.imavis.2008.01.005
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000002
DA 2024-07-18
ER

PT J
AU Sevilmis, T
   Bastan, M
   Güdükbay, U
   Ulusoy, Ö
AF Sevilmis, Tarkan
   Bastan, Muhammet
   Gudukbay, Ugur
   Ulusoy, Oezguer
TI Automatic detection of salient objects and spatial relations in videos
   for a video database system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multimedia databases; salient object detection and tracking; camera
   focus estimation; object labeling; knowledge-base construction;
   spatio-temporal queries
ID BOUNDARY DETECTION; MOVING-OBJECTS; SEGMENTATION; IMAGE; TRACKING; COLOR
AB Multimedia databases have gained popularity due to rapidly growing quantities of multimedia data and the need to perform efficient indexing, retrieval and analysis of this data. One downside of multimedia databases is the necessity to process the data for feature extraction and labeling prior to storage and querying. Huge amount of data makes it impossible to complete this task manually. We propose a toot for the automatic detection and tracking of salient objects, and derivation of spatio-temporal relations between them in video. Our system aims to reduce the work for manual selection and labeling of objects significantly by detecting and tracking the salient objects, and hence, requiring to enter the label for each object only once within each shot instead of specifying the labels for each object in every frame they appear. This is also required as a first step in a fully-automatic video database management system in which the labeling should also be done automatically. The proposed framework covers a scalable architecture for video processing and stages of shot boundary detection, salient object detection and tracking, and knowledge-base construction for effective spatio-temporal object querying. (c) 2008 Elsevier B.V. All rights reserved.
C1 [Sevilmis, Tarkan; Bastan, Muhammet; Gudukbay, Ugur; Ulusoy, Oezguer] Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Ulusoy, Ö (corresponding author), Bilkent Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM sevilmis@cs.bilkent.edu.tr; bastan@cs.bilkent.edu.tr;
   gudukbay@cs.bilkent.edu.tr; oulusoy@cs.bilkent.edu.tr
RI Ulusoy, Ozgur/KVY-4530-2024; Gudukbay, Ugur/F-1012-2011
OI Ulusoy, Ozgur/0000-0002-6887-3778; Gudukbay, Ugur/0000-0003-2462-6959
FU European Union 6th Framework Program [FP6-507752]; TUBITAK
   [EEEAG-105E065]
FX This work is supported by European Union 6th Framework Program under
   Grant No. FP6-507752 (MUSCLE Network of Excellence Project) and TUBITAK
   under Grant No. EEEAG-105E065 (New Information Society Technologies for
   Turkey). We are grateful to Kirsten Ward for proofreading the paper.
CR [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], 2003, P 11 ACM INT C MULTI, DOI DOI 10.1145/957013.957094
   [Anonymous], 2001, International Journal of Image and Graphics (IJIG), Vol, DOI DOI 10.1142/S021946780100027X
   ASHLEY J, 1995, P SPIE STORAGE RETRI, V3, P24
   Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   CAVALLARO A, 2002, P 10 ACM INT C MULT, P523
   Chalmond B, 2006, IEEE T IMAGE PROCESS, V15, P2644, DOI 10.1109/TIP.2006.877380
   Chang SF, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P313, DOI 10.1145/266180.266382
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Desa SM, 2004, I C COMP GRAPH IM VI, P41, DOI 10.1109/CGIV.2004.1323958
   Dönderler ME, 2005, MULTIMED TOOLS APPL, V27, P79, DOI 10.1007/s11042-005-2715-7
   Dönderler ME, 2002, INFORM SCIENCES, V143, P13, DOI 10.1016/S0020-0255(02)00172-X
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Ge F., 2006, IEEE COMP SOC C COMP, V1, P1146, DOI DOI 10.1109/CVRR.2006.147
   Gu C, 1998, IEEE T CIRC SYST VID, V8, P572, DOI 10.1109/76.718504
   Hsieh JW, 2006, IEEE IMAGE PROC, P1821, DOI 10.1109/ICIP.2006.312600
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kim C, 2002, IEEE T CIRC SYST VID, V12, P122, DOI 10.1109/76.988659
   Kwak SY, 2004, LECT NOTES COMPUT SC, V3332, P138
   Li L, 2003, ICCAD-2003: IEEE/ACM DIGEST OF TECHNICAL PAPERS, P2
   Liu T., 2007, Proc. International Conference on Advanced Intelligent Mechatronics, P1
   Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433
   Marcus S, 1996, J ACM, V43, P474, DOI 10.1145/233551.233554
   Marques O, 2003, LECT NOTES COMPUT SC, V2870, P550
   Moscheni F, 1998, IEEE T PATTERN ANAL, V20, P897, DOI 10.1109/34.713358
   PORIKLI F, 2004, J APPL SIGNAL PROCES
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Ryan K, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P273, DOI 10.1109/ICME.2006.262451
   Saykol E, 2005, IMAGE VISION COMPUT, V23, P1170, DOI 10.1016/j.imavis.2005.07.015
   Shao J, 2006, IEEE IMAGE PROC, P2813, DOI 10.1109/ICIP.2006.312993
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Xu LQ, 2004, BT TECHNOL J, V22, P140, DOI 10.1023/B:BTTJ.0000047128.53316.f2
   Zhang DS, 2001, CIRC SYST SIGNAL PR, V20, P143, DOI 10.1007/BF01201137
   Zhang GY, 2006, INT C COMMUN CIRCUIT, P437, DOI 10.1109/ICCCAS.2006.284671
NR 40
TC 22
Z9 25
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1384
EP 1396
DI 10.1016/j.imavis.2008.01.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700008
DA 2024-07-18
ER

PT J
AU Bermudez-Contreras, E
   Buxton, H
   Spier, E
AF Bermudez-Contreras, E.
   Buxton, H.
   Spier, E.
TI Attention can improve a simple model for object recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object recognition; HMAX; foveation; attention; active vision; visual
   cortex; translation invariance; scale invariance
AB Object recognition is one of the most important tasks of the visual cortex. Even though it has been closely studied in the field of computer vision and neuroscience, the underlying processes in the visual cortex are not completely understood. A model that lately has gained attention is the HMAX model, which describes a feedforward hierarchical structure. This model shows a degree of scale and translation invariance. Our work explores and compares the HMAX model with a simpler model for object recognition emulating simple cells in the primary visual cortex, VI. This model shows a better performance than the HMAX model for translation and scale invariance experiments when an attentional mechanism is employed in realistic conditions. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Bermudez-Contreras, E.; Buxton, H.; Spier, E.] Univ Sussex, Dept Informat, Brighton BN1 9HQ, E Sussex, England.
C3 University of Sussex
RP Bermudez-Contreras, E (corresponding author), Univ Sussex, Dept Informat, Brighton BN1 9HQ, E Sussex, England.
EM ejb2l@sussex.ac.uk; hilaryb@sussex.ac.uk; emmet@sussex.ac.uk
RI Contreras, Edgar Bermudez/AAB-2566-2019
OI Contreras, Edgar Bermudez/0000-0002-4937-1780
CR Aloimonos Y., 1993, Active perception
   BERMUDEZ E, 2007, IN PRESS GEN EV COMP
   BERNARDINO A, 2002, 2 WORKSH BIOL MOT CO, P127
   Booth MCA, 1998, CEREB CORTEX, V8, P510, DOI 10.1093/cercor/8.6.510
   DANNA H, 1991, ARTIFICIAL INTELLIGE
   Deco G, 2004, EUR J NEUROSCI, V20, P1089, DOI 10.1111/j.1460-9568.2004.03528.x
   DUVDEVANIBAR S, 1998, 3 FACE GESTURE, P118
   Edelman S, 1997, PHILOS T R SOC B, V352, P1191, DOI 10.1098/rstb.1997.0102
   Floreano D, 2004, BIOL CYBERN, V90, P218, DOI 10.1007/s00422-004-0467-5
   HOWELL J, 1995, P INT WORKSH AUT FAC, P221
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Hung CP, 2005, SCIENCE, V310, P863, DOI 10.1126/science.1117593
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Land M.F., 2002, Animal eyes, Vi-xii, P1
   Laughlin SB, 2003, SCIENCE, V301, P1870, DOI 10.1126/science.1089662
   LEE TS, 2003, LECT NOTES MATH ITS, P87
   Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9
   LINDENBERG T, 1996, CERN SCH COMPUTING, P8
   LOGOTHETIS NK, 1994, CURR BIOL, V4, P401, DOI 10.1016/S0960-9822(00)00089-0
   Orr M J L, 1996, Introduction to radial basis function networksJ
   Paletta Lucas, 2005, P642, DOI 10.1016/B978-012375731-9/50109-9
   POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0
   Riesenhuber M, 1999, NEURON, V24, P87, DOI 10.1016/S0896-6273(00)80824-7
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Riesenhuber M., 2003, VISUAL NEUROSCIENCES
   Riesenhuber M, 2000, NAT NEUROSCI, V3, P1199, DOI 10.1038/81479
   SCHNEIDER R, 2004, 2004004 MIT
   Serre T., 2005, P 2005 IEEE COMP SOC
   SERRE T, 2005, 259AI MIT
   Spier E, 2004, Artificial Life IX, P133
   WALTHER D, 2002, 2 IEEE INT WORKSH BI, P387
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
NR 32
TC 5
Z9 5
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 776
EP 787
DI 10.1016/j.imavis.2007.08.014
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900005
DA 2024-07-18
ER

PT J
AU Jeng, SW
   Tsai, WH
AF Jeng, Sheng-Wen
   Tsai, Wen-Hsiang
TI Analytic image unwarping by a systematic calibration method for
   omni-directional cameras with hyperbolic-shaped mirrors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE omni-directional camera; single-viewpoint (SVP) constraint; image
   unwarping; hyperbolic mirror; hypercatadioptric camera; camera
   calibration; analytic solution
AB Unwarping an orimi-directional image into a perspective-view one is easy for a single-viewpoint (SVP) designed catadioptric omnidirectional camera. But misalignment between the components (such as the mirror and the lens) of this kind of camera creates multiple viewpoints and distorts the unwarped image if the SVP constraint is assumed. The SVP constraint is relaxed in this study and a systematic method is proposed to derive a set of new and general analytic equations for unwarping images taken from an omni-directional camera with a hyperbolic-shaped mirror (called a hypercatadioptric camera). The derivation is made possible by careful investigation on the system configuration and precise calibration of involved system parameters. As a verification of the correctness of the derived equations, some of the system parameters are adjusted to fit the SVP constraint, and unwarped images using the resulting simplified camera model are shown to be of no difference from those obtained by a method based on the SVP model. The generality of the proposed method so has extended the image-unwarping capability of the existing methods for the hypercatadioptric camera to tolerate lens/mirror assembly imprecision, which is difficult to overcome in most real applications. Some experimental results of image unwarping are also included to show the effectiveness of the proposed method. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Jeng, Sheng-Wen; Tsai, Wen-Hsiang] Natl Chiao Tung Univ, Dept Comp Sci, Hsinchu 300, Taiwan.
   [Tsai, Wen-Hsiang] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
C3 National Yang Ming Chiao Tung University; Asia University Taiwan
RP Jeng, SW (corresponding author), Natl Chiao Tung Univ, Dept Comp Sci, 1001 Ta Hsueh Rd, Hsinchu 300, Taiwan.
EM sunny@itri.org.tw; whtsai@cis.nctu
CR Aliaga DG, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P127, DOI 10.1109/ICCV.2001.937508
   Baker S, 1999, INT J COMPUT VISION, V35, P175, DOI 10.1023/A:1008128724364
   Fabrizio J, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P45, DOI 10.1109/OMNVIS.2002.1044490
   Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241
   GEYER C, 1999, P 7 IEEE INT C COMP, V1, P398
   JENG SW, 2004, P 2004 IEEE INT C NE, P204
   Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820
   Nayar SK, 1997, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1997.609369
   Onoe Y, 1998, INT C PATT RECOG, P588, DOI 10.1109/ICPR.1998.711211
   Salvi J, 2002, PATTERN RECOGN, V35, P1617, DOI 10.1016/S0031-3203(01)00126-1
   Swaminathan R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P2, DOI 10.1109/ICCV.2001.937581
   Tsai R.Y., 1986, P IEEE C COMPUTER VI, P364
   YAMAZAWA K, 1993, IROS 93 : PROCEEDINGS OF THE 1993 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOL 1-3, P1029, DOI 10.1109/IROS.1993.583287
NR 13
TC 7
Z9 10
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 690
EP 701
DI 10.1016/j.imavis.2007.08.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900009
DA 2024-07-18
ER

PT J
AU Lu, TC
   Chang, CC
AF Lu, Tzu-Chuen
   Chang, Chin-Chen
TI Lossless nibbled data embedding scheme based on difference expansion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE lossless data embedding; difference expansion; nibble; arithmetic
   coding; prediction by partial matching
AB This paper proposes a lossless data embedding scheme of great payload capacity and good image quality, which is based on difference expansion. In this scheme, every pixel in a host image is divided into two nibbles and each nibble pair between two adjacent pixels can be used to hide a secret message. In order to completely recover the host image, the arithmetic coding is adopted based on prediction by partial matching (PPM) model to compress the restored information. This proposed scheme has been successfully applied to different images. According to the experimental results, embedded information can be extracted correctly and quickly from the embedded image. In addition, the proposed scheme can not only hide a large amount of information in a host image without making noticeable distortion, but can also completely restore the host image from the embedded image. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Lu, Tzu-Chuen] Chaoyang Univ Technol, Dept Informat Management, Taichung 41349, Taiwan.
   [Chang, Chin-Chen] Feng Chia Univ, Dept Comp Sci & Informat Engn, Taichung 40724, Taiwan.
C3 Chaoyang University of Technology; Feng Chia University
RP Lu, TC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung 41349, Taiwan.
EM tclu@cyut.edu.tw; ccc@cs.ccu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR Bell T. C., 1990, TEXT COMPRESSION
   Celik MU, 2005, IEEE T IMAGE PROCESS, V14, P253, DOI 10.1109/TIP.2004.840686
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   Celik MU, 2003, PROC SPIE, V5020, P689, DOI 10.1117/12.477312
   Chang CC, 2005, 19TH INTERNATIONAL CONFERENCE ON ADVANCED INFORMATION NETWORKING AND APPLICATIONS, VOL 1, PROCEEDINGS, P947
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   CLEARY JG, 1984, IEEE T COMMUN, V32, P396, DOI 10.1109/TCOM.1984.1096090
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   Huang JW, 2002, IEEE T CIRC SYST VID, V12, P916, DOI 10.1109/TCSVT.2002.804897
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Sayood K, 2017, Introduction to data compression
   Stinson D. R., 2018, Cryptography Theory and Practice
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Tseng YC, 2002, IEEE T COMPUT, V51, P873, DOI 10.1109/TC.2002.1017706
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   WITTEN IH, 1987, COMMUN ACM, V30, P520, DOI 10.1145/214762.214771
   Wu M, 2003, IEEE T CIRC SYST VID, V13, P831, DOI 10.1109/TCSVT.2003.815951
   Yeung MM, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P680, DOI 10.1109/ICIP.1997.638587
NR 21
TC 16
Z9 17
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 632
EP 638
DI 10.1016/j.imavis.2007.07.011
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900003
DA 2024-07-18
ER

PT J
AU Masood, A
AF Masood, Asif
TI Dominant point detection by reverse polygonization of digital curves
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE reverse polygonization; dominant points; break points; polygonal
   approximation
ID PIECEWISE LINEAR-APPROXIMATION; POLYGONAL-APPROXIMATION; ALGORITHM
AB A polygonal approximation technique using reverse polygonization is presented in this paper. The reverse polygonization starts from an initial set of dominant points i.e. break points. In that, dominant points are deleted (one in each iteration) such that the maximal perpendicular distance of approximating straight line from original curve is minimal. A comparative study with some commonly referred algorithms is also presented, which shows that this technique can produce better approximation results. The algorithm has additional advantages like simplicity, polygonal approximation with any number of dominant points and up to any error value, and computational efficiency. (C) 2007 Elsevier B.V. All rights reserved.
C1 Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
C3 University of Engineering & Technology Lahore
RP Masood, A (corresponding author), Univ Engn & Technol, Dept Comp Sci & Engn, Lahore, Pakistan.
EM asif@uet.edu.pk
CR ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472
   ANSARI N, 1991, PATTERN RECOGN, V24, P849, DOI 10.1016/0031-3203(91)90004-O
   ARCELLI C, 1993, PATTERN RECOGN, V26, P1563, DOI 10.1016/0031-3203(93)90161-O
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   BANERJEE S, 1996, 10007 RJ IBM RES DIV
   Cronin TM, 1999, PATTERN RECOGN LETT, V20, P617, DOI 10.1016/S0167-8655(99)00025-2
   DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Guru DS, 2004, 1ST CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P417, DOI 10.1109/CCCRV.2004.1301477
   HELD A, 1994, IEEE T SYST MAN CYB, V24, P942, DOI 10.1109/21.293514
   HU XP, 1994, IEEE T PATTERN ANAL, V16, P1041, DOI 10.1109/34.329004
   Huang SC, 1999, PATTERN RECOGN, V32, P1409, DOI 10.1016/S0031-3203(98)00173-3
   KUROZUMI Y, 1982, COMPUT VISION GRAPH, V19, P248, DOI 10.1016/0146-664X(82)90011-9
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Latecki LJ, 2000, J ELECTRON IMAGING, V9, P317, DOI 10.1117/1.482748
   Latecki LJ, 1999, LECT NOTES COMPUT SC, V1682, P398
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   Melkman A, 1988, P COMPUTATIONAL MORP, P87
   Neumann R, 2002, PATTERN RECOGN, V35, P1447, DOI 10.1016/S0031-3203(01)00145-5
   Pal NR, 1998, INT J SYST SCI, V29, P207, DOI 10.1080/00207729808929513
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P849, DOI 10.1016/0167-8655(92)90084-D
   RAY BK, 1993, PATTERN RECOGN, V26, P505, DOI 10.1016/0031-3203(93)90106-7
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P443, DOI 10.1016/0167-8655(92)90051-Z
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Sarfraz M, 2004, IEEE INFOR VIS, P991, DOI 10.1109/IV.2004.1320262
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
   SATO Y, 1992, PATTERN RECOGN, V25, P1535, DOI 10.1016/0031-3203(92)90126-4
   SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872
   SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   TSAI WH, 1985, IEEE T PATTERN ANAL, V7, P453, DOI 10.1109/TPAMI.1985.4767684
   VIDAL PE, 1994, PATTERN RECOGN, V15, P743
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Yin PY, 1999, INT J PATTERN RECOGN, V13, P1061, DOI 10.1142/S0218001499000598
   YUEN PC, 1993, ELECTRON LETT, V29, P2023, DOI 10.1049/el:19931350
   ZHU PF, 1995, IEEE T PATTERN ANAL, V17, P737, DOI 10.1109/34.400564
NR 40
TC 49
Z9 50
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 702
EP 715
DI 10.1016/j.imavis.2007.08.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900010
DA 2024-07-18
ER

PT J
AU Lei, Q
   Zheng, QF
   Jiang, SQ
   Huang, QG
   Gao, W
AF Qin, Lei
   Zheng, Qingfang
   Jiang, Shuqiang
   Huang, Qingining
   Gao, Wen
TI Unsupervised texture classification: Automatically discover and classify
   texture patterns
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE unsupervised texture classification; NMF; PLSI; invariant descriptor
AB In this paper, we present a novel approach to classify texture collections. This approach does not require experts to provide annotated training set. Given the image collection, we extract a set of invariant descriptors from each image. The descriptors of all images are veetor-quantized to form 'keypoints'. Then we represent the texture images by 'bag-of-keypoints' vectors. By analogy text classification, we use Probabilistic Latent Semantic Indexing (PLSI) and Non-negative Matrix Factorization (NMF) to perform unsupervised classification. The proposed approach is evaluated using the UIUC database which contains significant viewpoint and scale changes. We also report the results for simultaneously classifying I I I texture categories using the Brodatz database. The performances of classifying new images using the parameters learnt from the unannotated image collection are also presented. The experiment results clearly demonstrate that the approach is robust to scale and viewpoint changes, and achieves good classification accuracy even without annotated training set. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Qin, Lei; Zheng, Qingfang; Jiang, Shuqiang; Huang, Qingining; Gao, Wen] Chinese Acad Sci, Inst Computing Technol, Beijing, Peoples R China.
   [Qin, Lei; Huang, Qingining] Chinese Acad Sci, Grad Sch, Beijing, Peoples R China.
   [Gao, Wen] Peking Univ, Sch Elect Engn & Comp Sci, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Peking University
RP Lei, Q (corresponding author), Chinese Acad Sci, Inst Computing Technol, Beijing, Peoples R China.
EM lqin@jdl.ac.cn; qfzheng@jdl.ac.cn; sqjiang@jdl.ac.cn; qmhuang@jdl.ac.cn;
   wgao@jdl.ac.cn
CR [Anonymous], ICCV
   [Anonymous], 2003, P ICCV
   [Anonymous], 1999, SIGIR
   [Anonymous], P ECCV
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Cula OG, 2001, PROC CVPR IEEE, P1041
   DING C, 2006, P AAAI NATL C ART IN
   Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K., 2005, INT J COMPUT VIS
   OPELT A, 2004, P ECCV
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   SIVIC J, 2005, P ICCV 2005 OCT
   Sivic Josef, 2004, P ECCV
   Teh Y., 2004, P NIPS
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   Xu K, 2000, INT C PATT RECOG, P275, DOI 10.1109/ICPR.2000.902912
NR 28
TC 13
Z9 14
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 647
EP 656
DI 10.1016/j.imavis.2007.08.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900005
DA 2024-07-18
ER

PT J
AU Marsland, S
   Twining, CJ
   Taylor, CJ
AF Marsland, Stephen
   Twining, Carole J.
   Taylor, Chris J.
TI A minimum description length objective function for groupwise non-rigid
   image registration
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE image registration; non-rigid registration; groupwise registration;
   minimum description length (MDL)
ID REPRESENTATIONS; MAXIMIZATION; SHAPE
AB Non-rigid registration finds a dense correspondence between a pair of images, so that analogous structures in the two images are aligned. While this is sufficient for atlas comparisons, in order for registration to be an aid to diagnosis, registrations need to be performed on a set of images. In this paper, we describe an objective function that can be used for this group wise registration. We view the problem of image registration as one of learning correspondences from a set of exemplar images (the registration set), and derive a minimum description length (MDL) objective function.
   We give a brief description of the MDL approach as applied to transmitting both single images and sets of images, and show that the concept of a reference image (which is central to defining a consistent correspondence across a set of images) appears naturally as a valid model choice in the MDL approach.
   In this paper, we demonstrate both rigid and non-rigid groupwise registration using our MDL objective function on two-dimensional T1 MR images of the human brain, and show that we obtain a sensible alignment. The extension to the multi-modal case is also discussed. We conclude with a discussion as to how the MDL principle can be extended to include other encoding models than those we present here. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Marsland, Stephen] Massey Univ, Inst Informat Sci, Palmerston North, New Zealand.
   [Twining, Carole J.; Taylor, Chris J.] Univ Manchester, ISBE, Manchester M13 9PL, Lancs, England.
C3 Massey University; University of Manchester
RP Marsland, S (corresponding author), Massey Univ, Inst Informat Sci, Private Bag 11222, Palmerston North, New Zealand.
EM s.r.marsland@massey.ac.nz; carole.twining@maiichester.ac.uk;
   chris.taylor@manchester.ac.uk
RI Twining, Carole J/F-7423-2012; Marsland, Stephen/D-9734-2012; Taylor,
   Chris/A-3909-2009
OI Taylor, Chris/0000-0001-7867-9533
CR [Anonymous], 1989, Stochastic Complexity in Statistical Inquiry
   Bhatia KK, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P908
   BroNielsen M, 1996, LECT NOTES COMPUT SC, V1131, P267
   Christensen GE, 2001, IEEE T MED IMAGING, V20, P568, DOI 10.1109/42.932742
   Cootes T.F., 1998, COMPUTER VISION ECCV, V1407, P484, DOI [DOI 10.1007/BFB0054760, DOI 10.1109/34.927467]
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Davies RH, 2002, LECT NOTES COMPUT SC, V2352, P3
   Ferrant M, 1999, LECT NOTES COMPUT SC, V1679, P202
   GEE JC, 1993, J COMPUT ASSIST TOMO, V17, P225, DOI 10.1097/00004728-199303000-00011
   Hagemann A, 1999, IEEE T MED IMAGING, V18, P875, DOI 10.1109/42.811267
   Hermosillo G, 2002, INT J COMPUT VISION, V50, P329, DOI 10.1023/A:1020830525823
   HRABER P, 0304023 SANT I
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Marsland S, 2004, IEEE T MED IMAGING, V23, P1006, DOI 10.1109/TMI.2004.831228
   Marsland S, 2003, LECT NOTES COMPUT SC, V2879, P771
   Marsland S, 2003, LECT NOTES COMPUT SC, V2717, P50
   Pizer SM, 1998, COMPUT VIS IMAGE UND, V69, P55, DOI 10.1006/cviu.1997.0563
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Schnabel J. A., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P344
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Twining CJ, 2004, INT C PATT RECOG, P704, DOI 10.1109/ICPR.2004.1334626
   TWINING CJ, 2002, P BRIT MACH VIS C BM, V2, P847
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 26
TC 36
Z9 43
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 333
EP 346
DI 10.1016/j.imavis.2006.12.009
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500003
DA 2024-07-18
ER

PT J
AU Siegl, H
   Hanheide, M
   Wrede, S
   Pinz, A
AF Siegl, H.
   Hanheide, M.
   Wrede, S.
   Pinz, A.
TI An augmented reality human-computer interface for object localization in
   a cognitive vision system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D cursor; human-computer interaction; mobile augmented reality;
   cognitive vision system
AB The European Cognitive Vision project VAMPIRE uses mobile AR-kits to interact with a visual active memory for teaching and retrieval purposes. This paper describes concept and technical realization of the used mobile AR-kits and discusses interactive learning and retrieval in office environments, and the active memory infrastructure. The focus is on 3D interaction for pointing in a scene coordinate system. This is achieved by 3D augmented pointing, which combines inside-out tracking for head pose recovery and 3D stereo human-computer interaction. Experimental evaluation shows that the accuracy of this 3D cursor is within a few centimeters, which is sufficient to point at an object in an office. Finally, an application of the cursor in VAMPIRE is presented, where in addition to the mobile system, at least one stationary active camera is used to obtain different views of an object. There are many potential applications, for example an improved view-based object recognition. (C) 2006 Elsevier B.V. All rights reserved.
C1 Graz Univ Technol, Inst Elelct Measurement & Measurement Signal Proc, A-8010 Graz, Austria.
   Univ Bielefeld, Fac Technol, D-4800 Bielefeld, Germany.
C3 Graz University of Technology; University of Bielefeld
RP Pinz, A (corresponding author), Graz Univ Technol, Inst Elelct Measurement & Measurement Signal Proc, A-8010 Graz, Austria.
EM axel.pinz@tugraz.at
RI Hanheide, Marc/AAO-9299-2021
OI Hanheide, Marc/0000-0001-7728-1849; Wrede, Sebastian/0000-0003-0029-8188
CR BARHAM PT, 1991, STEREOSCOPIC DISPLAY, V2, P18
   Bauckhage C, 2005, EURASIP J APPL SIG P, V2005, P2375, DOI 10.1155/ASP.2005.2375
   BAUCKHAGE C, 2004, COGNITIVE VISION SYS, P827
   Bouget Jean-Yves., CAMERA CALIBRATION T
   CHANDRAKER MK, 2003, INT C COMP VIS SYST, P98
   CHEN J, 2004, CAPTECH 04, P26
   CHRISTENSEN H, 2003, ERCIM NEWS, V53, P17
   CROWLEY JL, 1995, VISION PROCESS
   Drascic D, 1996, P SOC PHOTO-OPT INS, V2653, P123, DOI 10.1117/12.237425
   DRASCIC D, 1991, SPIE P, V1457, P302
   GHEORGHE LA, 2004, ECCV 2004 WORKSH HCI, P117
   GORGES N, 2004, DAGM 04 HEIDELBERG, P342
   HANHEIDE M, 2004, ICPR 04, V2, P459
   HEIDEMANN G, 2003, ICVS 03, P22
   Höllerer T, 1999, COMPUT GRAPH-UK, V23, P779, DOI 10.1016/S0097-8493(99)00103-X
   HOU M, 2001, CASCON 01
   Muehlmann U, 2004, IEEE INT CONF ROBOT, P5195, DOI 10.1109/ROBOT.2004.1302542
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Piekarski W, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P269, DOI 10.1109/ISMAR.2002.1115107
   Piekarski W, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P31, DOI 10.1109/ISWC.2001.962093
   PIEKARSKI W, 2004, ISMAR 04, V5
   Sands J, 2004, IEEE INFOR VIS, P633, DOI 10.1109/IV.2004.1320208
   Schmalstieg D., 1999, ACM S INT 3D GRAPH A, P147
   SIEGL H, 2003, AAPR 03, P245
   SIEGL H, 2004, ECCV 2004 WORKSH HCI, P176
   Thomas B. H., 2002, Virtual Reality, V6, P167, DOI 10.1007/s100550200017
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wither J, 2004, EIGHTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P124, DOI 10.1109/ISWC.2004.18
   Wrede S., 2004, Seventh International Conference on Information Fusion, P198
   WREDE S, 2004, ICPR, V1, P757
NR 30
TC 7
Z9 9
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 3
PY 2007
VL 25
IS 12
BP 1895
EP 1903
DI 10.1016/j.imavis.2006.04.027
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220BD
UT WOS:000250131000008
DA 2024-07-18
ER

PT J
AU Liu, H
   Yan, JQ
   Li, ZS
   Zhang, H
AF Liu, Heng
   Yan, Jinqi
   Li, Zushu
   Zhang, Hua
TI Portrait beautification: A fast and robust approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE portrait segmentation; Portrait fusion; visual background photography;
   color temperature estimation; face color correction
ID SEGMENTATION
AB Portrait beautification technology has important significance regarding virtual background photography and augment reality said. In this work, a set of integrated portrait beautification approaches are raised. Aiming at fast portrait division, quantum evolution algorithm is introduced into the course of threshold searching. In order to merge images and virtual background, based on Human Vision System principles, a multi-layer portrait weighted method is proposed. To overcome the effects of illumination on face skin color, one kind of fast face color correction technology based on color temperature estimation is presented. Detail experimental results and comparisons are provided to show our approaches are effective. (C) 2006 Elsevier B.V. All rights reserved.
C1 Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   SW Univ Sci & Technol, Mianyang 621000, Peoples R China.
   Chongqing Univ, Inst Intelligent Automat, Chongqing 400044, Peoples R China.
C3 Shanghai Jiao Tong University; Southwest University of Science &
   Technology - China; Chongqing University
RP Liu, H (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM hengliu@sjtu.edu.cn; jqyan@sjtu.edu.cn; zushuli@vip.sina.com;
   zzhh839@163.com
CR AALAND M, 2003, SHOOTING DIGITAL
   AGARWALA A, P SIGGRAPH 2004, P294
   [Anonymous], ACM T GRAPHICS
   CHARD R, 2004, PATTERN CLASSIFICATI
   CHEN S, 2004, J IEEE T SYSTEMS M B, V34
   CHOW G, 1993, PATTERN RECOGN, V26, P1739, DOI 10.1016/0031-3203(93)90173-T
   de Dios JJ, 2004, IEEE IMAGE PROC, P191
   Duchowski A., 2003, Eye Tracking Methodology: Theory and Practice
   FORSYTH DA, 2003, COMPUTE VISION MODER
   Gasparini F, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P646, DOI 10.1109/ICIAP.2003.1234123
   Grady L, 2004, LECT NOTES COMPUT SC, V3117, P230
   Han KH, 2002, IEEE T EVOLUT COMPUT, V6, P580, DOI 10.1109/TEVC.2002.804320
   He J, 2002, IEEE T EVOLUT COMPUT, V6, P495, DOI 10.1109/TEVC.2002.800886
   HILL PR, 2005, P INT C IM PROC, V2, P1338
   Huber DF, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P153, DOI 10.1109/IM.2001.924424
   Hunt R.W. G., 2004, REPROD COLOUR, V6th
   Lenz R, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P885
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   Liu H, 2005, LECT NOTES COMPUT SC, V3645, P920
   Narayanan A, 1996, IEEE C EVOL COMPUTAT, P61, DOI 10.1109/ICEC.1996.542334
   Okuda M, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P632, DOI 10.1109/ICIP.2000.899533
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Palmer S.E., 2002, VISION SCI PHOTONS P, V3rd
   Petrovic VS, 2004, IEEE T IMAGE PROCESS, V13, P228, DOI 10.1109/tip.2004.823821
   Rother C., 2004, ACM Transactions on Graphics (SIGGRAPH), V23, P309
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   TANG S, 1990, CHROMA THEORY
   Tu PH, 2004, LECT NOTES COMPUT SC, V3247, P187
   WANG Z, 2004, LECT NOTES COMPUTER, V3024, P304
   Wang ZJ, 2005, IEEE T GEOSCI REMOTE, V43, P1391, DOI 10.1109/TGRS.2005.846874
   Yang FG, 2003, IEEE T IMAGE PROCESS, V12, P1552, DOI 10.1109/TIP.2003.817242
NR 33
TC 7
Z9 7
U1 2
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1404
EP 1413
DI 10.1016/j.imavis.2006.12.010
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000003
DA 2024-07-18
ER

PT J
AU Wu, YH
   Wang, GH
   Wu, FC
   Hu, ZY
AF Wu, Yihong
   Wang, Guanghui
   Wu, Fuchao
   Hu, Zhanyi
TI Euclidean reconstruction of a circular truncated cone only from its
   uncalibrated contours
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE circular truncated cone or cylinder; absolute conic; circular point;
   camera intrinsic parameter; camera extrinsic parameter; Euclidean
   reconstruction
ID CALIBRATION
AB We present a method to recover a circular truncated cone only from its contour up to a similarity transformation. First, we find the images of circular points, and then use them to calibrate the camera with constant intrinsic parameters from two or three contours of a circular truncated cone, or from a single contour of a circular truncated cylinder. Second, we give an analytical solution of the relative pose between each camera and the circular truncated cone. After the camera's intrinsic parameters and pose are recovered, the circular truncated cone or cylinder is reconstructed from one image. Experiments on both simulated data and real images are performed and validate our approach. (c) 2006 Elsevier B.V. All rights reserved.
C1 Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Wu, YH (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, 95 Easrd ZhongGuanCun,POB 2728, Beijing 100080, Peoples R China.
EM yhwu@nlpr.ia.ac.cn
RI Wang, Guanghui/B-1080-2008
CR ASTROM K, 1996, P 4 EUR C COMP VIS C, P97
   Boyer E, 1997, INT J COMPUT VISION, V22, P219, DOI 10.1023/A:1007978616082
   CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775
   Cross G, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P25, DOI 10.1109/ICCV.1998.710697
   FREMONT V, 2002, P INT C ART REAL TEL, P93
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Kim JS, 2002, P 5 AS C COMP VIS, P515
   Ma S. D., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P344, DOI 10.1109/ICPR.1996.546046
   MA SD, 1993, INT J COMPUT VISION, V10, P7
   Mendonca P. R. S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P9, DOI 10.1109/CVPR.1999.786910
   Meng XQ, 2003, PATTERN RECOGN, V36, P1155, DOI 10.1016/S0031-3203(02)00225-X
   Quan L, 1996, IEEE T PATTERN ANAL, V18, P151, DOI 10.1109/34.481540
   Sato J, 1999, IEEE T PATTERN ANAL, V21, P1188, DOI 10.1109/34.809111
   SEMPLE JG, 1952, ALGEBRAIC PROJECTIVE
   Song De Ma, 1994, Proceedings of the 12th IAPR International Conference on Pattern Recognition (Cat. No.94CH3440-5), P27, DOI 10.1109/ICPR.1994.576219
   WRONG K, 1999, P BRIT MACH VIS C, P83
   Wu YH, 2005, PATTERN RECOGN LETT, V26, P1192, DOI 10.1016/j.patrec.2004.11.020
   Wu YH, 2004, LECT NOTES COMPUT SC, V3021, P190
   Wu YH, 2006, IMAGE VISION COMPUT, V24, P319, DOI 10.1016/j.imavis.2005.11.008
   Zhang ZY, 1996, IEEE T ROBOTIC AUTOM, V12, P103, DOI 10.1109/70.481754
NR 20
TC 5
Z9 10
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 810
EP 818
DI 10.1016/j.imavis.2006.02.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100002
DA 2024-07-18
ER

PT J
AU Lu, L
   Dai, XT
   Hager, G
AF Lu, Le
   Dai, Xiangtian
   Hager, Gregory
TI Efficient particle filtering using RANSAC with application to 3D face
   tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE random projection; RANSAC; particle filtering; robust 3D face tracking
ID ROBUST; IMAGES
AB Particle filtering is a very popular technique for sequential state estimation. However. in high-dimensional cases where the state dynamics are complex or poorly modeled, thousands of particles are Usually required for real applications. This paper presents a hybrid sampling solution that combines RANSAC and particle filtering. In this approach. RANSAC provides proposal particles that, with high probability. represent the observation likelihood. Both conditionally independent RANSAC sampling and boosting-like conditionally dependent RANSAC sampling are explored. We show that the use of RANSAC-guided sampling reduces the necessary number of particles to dozens for a full 3D tracking problem. This method is particularly advantageous when state dynamics are poorly modeled. We show empirically that the sampling efficiency (in terms of likelihood) is much higher with the use of RANSAC. The algorithm has been applied to the problem of 3D face pose tracking with changing expression. We demonstrate the validity Of Our approach with several video sequences acquired in an unstructured environment. (c) 2005 Elsevier B.V. All rights reserved.
C1 Johns Hopkins Univ, Dept Comp Sci, Computat Interact & Robot Lab, Baltimore, MD 21218 USA.
C3 Johns Hopkins University
RP Lu, L (corresponding author), 3400 N Charles St, Baltimore, MD 21218 USA.
EM lelu@cs.jhu.edu
RI Hager, Gregory D/A-3222-2010; Lu, Le/AAD-7619-2020
OI Lu, Le/0000-0002-6799-9416
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], CVPR
   Crisan D, 2002, IEEE T SIGNAL PROCES, V50, P736, DOI 10.1109/78.984773
   Crisan D., 2000, CUEDFINFENGTR381
   DEUTSCHER J, 2000, ARTICULATED BODY MOT
   Duda R. O., 2001, PATTERN CLASSIFICATI
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fox D., 2001, Kld-sampling: Adaptive particle filters and mobile robot localization
   HAGER G, 1998, IEEE T PAMI, V20
   Harris C., 1988, Proc. of the 4th Alvey Vision Conference, P189
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1998, PROC 5 EUROPEAN C CO, V1, P893
   KING O, 2000, ECCV, P695
   LACASCIA M, 2000, IEEE T PAMI, V22
   Liu J., 2000, Sequential Monte Carlo Methods in Practice
   Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847
   MOON H, 2001, ICCV
   North B, 2000, IEEE T PATTERN ANAL, V22, P1016, DOI 10.1109/34.877523
   Okuma Kenji, 2004, EUR C COMP VIS
   PAVLOVIC V, 2000, NEURAL INFORMATION P
   PAVLOVIC V, 2004, CVPR
   Sullivan J, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P323, DOI 10.1109/ICCV.2001.937536
   TORR PH, 2003, IEEE T PAMI, V25
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Toyama K, 1999, INT J COMPUT VISION, V35, P45, DOI 10.1023/A:1008159011682
   TOYAMA K, 2001, ICCV
   TU ZW, 2002, IEEE T PAMI, V24
   VACCHETTI L, 2003, CVPR
   Viola P, 2001, P 2001 IEEE COMP SOC, pII
   Xiao J., 2002, Robust full-motion recovery of head by dynamic templates andre-registration techniques
   Zhang ZY, 2004, INT J COMPUT VISION, V58, P93, DOI 10.1023/B:VISI.0000015915.50080.85
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 33
TC 16
Z9 18
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2006
VL 24
IS 6
BP 581
EP 592
DI 10.1016/j.imavis.2005.08.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 061NB
UT WOS:000238878200005
DA 2024-07-18
ER

PT J
AU Davis, JW
   Tyagi, A
AF Davis, James W.
   Tyagi, Ambrish
TI Minimal-latency human action recognition using reliable-inference
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE action recognition; reliable-inference; MAP; video analysis
ID HIDDEN MARKOV-MODELS; HUMAN MOVEMENT; LIKELIHOOD
AB We present a probabilistic reliable-inference framework to address the issue of rapid detection of human actions with low error rates. The approach determines the shortest video exposures needed for low-latency recognition by sequentially evaluating a series of posterior ratios for different action classes. If a subsequence is deemed unreliable or confusing, additional video frames are incorporated until a reliable classification to a particular action can be made. Results are presented for multiple action classes and subsequence durations, and are compared to alternative probabilistic approaches. The framework provides a means to accurately classify human actions using the least amount of temporal information. (C) 2006 Elsevier B.V. All rights reserved.
C1 Ohio State Univ, Dept Comp Sci & Engn, Dreese Lab 491, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University
RP Davis, JW (corresponding author), Ohio State Univ, Dept Comp Sci & Engn, Dreese Lab 491, 2015 Neil Ave, Columbus, OH 43210 USA.
EM jwdavis@cse.ohio-state.edu; tyagia@cse.ohio-state.edu
RI Davis, James/D-4314-2012
CR Aggarwal JK, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P90, DOI 10.1109/NAMW.1997.609859
   [Anonymous], 1989, Decision Estimation and Classification
   Arslan LM, 1998, IEEE T SPEECH AUDI P, V6, P410, DOI 10.1109/89.701374
   BAUM CW, 1994, IEEE T INFORM THEORY, V40, P1994, DOI 10.1109/18.340472
   Bicego M, 2004, IEEE T PATTERN ANAL, V26, P281, DOI 10.1109/TPAMI.2004.1262200
   Biem A, 2003, PROC INT CONF DOC, P104
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Brand M, 2000, IEEE T PATTERN ANAL, V22, P844, DOI 10.1109/34.868685
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Chang IC, 2000, IMAGE VISION COMPUT, V18, P1067, DOI 10.1016/S0262-8856(00)00046-9
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   DAVIS J, 2004, P WORKSH DET REC EV
   Davis JW, 2001, LECT NOTES COMPUT SC, V2091, P295
   Davis JW, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P169, DOI 10.1109/AVSS.2003.1217918
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fine S, 1998, MACH LEARN, V32, P41, DOI 10.1023/A:1007469218079
   Gavrila D., 2000, Pedestrian Detection from a Moving Vehicle, V1843, P37
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Jepson A., 1991, SPATIAL VISION HUMAN, P89
   JOHANSSON G, 1976, PSYCHOL RES-PSYCH FO, V38, P379, DOI 10.1007/BF00309043
   Lee Jehee., 2002, Proceedings of the 29th annual conference on Computer graphics and interactive techniques, P491, DOI DOI 10.1145/566570.566607
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   Little J., 1998, VIDERE, V1, P1
   Liu F, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P376, DOI 10.1109/ICCV.1998.710746
   Liu YX, 2002, LECT NOTES COMPUT SC, V2351, P657
   Moënne-Loccoz N, 2003, LECT NOTES COMPUT SC, V2626, P68
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319
   POLANA R, 1994, WORKSH MOT NONR ART, P77
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rosales R, 2000, PROC CVPR IEEE, P721, DOI 10.1109/CVPR.2000.854946
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Wald Abraham, 1947, SEQUENTIAL ANAL
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   WANG P, 2005, P WORKSH APPL COMP V, P401
NR 38
TC 34
Z9 44
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 455
EP 472
DI 10.1016/j.imavis.2006.01.012
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chang, CC
   Chou, YC
   Yu, YH
   Shih, KJ
AF Chang, CC
   Chou, YC
   Yu, YH
   Shih, KJ
TI An image zooming technique based on vector quantization approximation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image zooming; image magnification; vector quantization
ID INTERPOLATION METHODS; DIGITAL IMAGES; ALGORITHM
AB An image zooming method based on vector quantization approximation for magnifying gray-scale and color image by a factor of 2 is proposed. In our proposed method, the unknown pixel values on the image are interpolated by using a vector quantization codebook based on their local information. In comparison of our method with the locally adaptive zooming algorithm published in [S. Battiato, G. Gallo, F. Stanco, A locally adaptive zooming algorithm for digital images, Image and Vision Computing, 20(11) (2002) 805-812.], our experimental results have demonstrated that the image quality of the enlarged image is superior to the method in [S. Battiato, G. Gallo, F. Stanco, A locally adaptive zooming algorithm for digital images, Image and Vision Computing, 20(11) (2002) 805-812.]. Not only is our method simpler to implement by utilizing a table look-up technique on codebook, but also is much easier in translating to color images than that of [S. Battiato, G. Gallo, F. Stanco, A locally adaptive zooming algorithm for digital images, Image and Vision Computing, 20(11) (2002) 805-812.] by replacing an adequate codebook. (C) 2005 Elsevier Ltd All rights reserved.
C1 Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
   So Taiwan Univ Technol, Dept Multimedia & Game Sci, Tainan 710, Taiwan.
   Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 Feng Chia University; Southern Taiwan University of Science &
   Technology; National Chung Cheng University
RP Feng Chia Univ, Dept Informat Engn & Comp Sci, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM ccc@cs.ccu.edu.tw; yhyu@mail.stut.edu.tw
RI cai, bo/G-1491-2010; Chang, Ching-Chun/JAN-6210-2023
CR [Anonymous], 1992, R. woods digital image processing
   Battiato S, 2002, IMAGE VISION COMPUT, V20, P805, DOI 10.1016/S0262-8856(02)00089-6
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Keys R., 1978, IEEE Trans. Acoust. Speech Signal Process, V26, P508, DOI [10.1109/TASSP.1978.1163154, DOI 10.1109/TASSP.1978.1163154]
   Kim DH, 2002, IEEE T NANOTECHNOL, V1, P170, DOI 10.1109/TNANO.2002.807382
   Kim KW, 2003, IEEE MICROW WIREL CO, V13, P335, DOI 10.1109/LMWC.2003.815689
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Lin SD, 2000, IEICE T INF SYST, VE83D, P1671
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   MAELAND E, 1988, IEEE T MED IMAGING, V7, P213, DOI 10.1109/42.7784
   Parker J, 1983, IEEE Trans Med Imaging, V2, P31, DOI 10.1109/TMI.1983.4307610
   POLIDORI E, 1997, FRACTALS, V5, P111
   Pumar MA, 1996, COMPUT GRAPH, V20, P171, DOI 10.1016/0097-8493(95)00102-6
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P247, DOI 10.1109/83.366474
NR 14
TC 28
Z9 31
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1214
EP 1225
DI 10.1016/j.imavis.2005.07.020
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500010
DA 2024-07-18
ER

PT J
AU Zhao, CH
   Zhang, WC
AF Zhao, CH
   Zhang, WC
TI Using genetic algorithm optimizing stack filters based on MMSE criterion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE minimum mean square error criterion (MMSE); nonlinear filter; simple
   genetic algorithm; adaptive genetic algorithm; stack filters; image
   processing
ID ABSOLUTE ERROR CRITERION
AB In this paper, the problem of optimizing stack filters is changed into a one-zero knapsack problem based on the minimum mean square error (MMSE) criterion. The optimization of stack filters is realized by solving this knapsack problem with genetic algorithm (GA). Optimal stack filters are designed to process the images corrupted by impulsive noise in this paper. The computer simulated experiments show that the suppressing noise capability of the optimal stack filters based on the MMSE criterion is better than that of the optimal stack filters based on the minimum mean absolute error (MMAE) criterion. Moreover, the optimizing performances of simple genetic algorithm and adaptive genetic algorithm are discussed in this paper. (c) 2005 Elsevier B.V. All rights reserved.
C1 Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Peoples R China.
C3 Harbin Engineering University
RP Harbin Engn Univ, Coll Informat & Commun Engn, Harbin 150001, Peoples R China.
EM zhangwencheng@hrbeu.edu.cn
CR COYLE EJ, 1988, IEEE T ACOUST SPEECH, V36, P1244, DOI 10.1109/29.1653
   Delibasis KK, 1996, IEE P-VIS IMAGE SIGN, V143, P177, DOI 10.1049/ip-vis:19960513
   LIN JH, 1990, IEEE T ACOUST SPEECH, V38, P938, DOI [10.1109/29.56055, 10.1117/12.19608]
   SAVIN CE, 1997, MINIMUM MEAN SQUARE, P644
   WANG XP, 2002, GENETIC ALGORITHM TH, P11
   WENDT PD, 1986, IEEE T ACOUST SPEECH, V34, P898, DOI 10.1109/TASSP.1986.1164871
   Yoo J, 1999, IEEE T IMAGE PROCESS, V8, P1014, DOI 10.1109/83.777083
   ZHOU M, 1999, THEORY GENETIC ALGOR, P64
NR 8
TC 2
Z9 2
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2005
VL 23
IS 10
BP 853
EP 860
DI 10.1016/j.imavis.2005.05.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 962PQ
UT WOS:000231745100001
DA 2024-07-18
ER

PT J
AU Pagès, J
   Salvi, J
   Collewet, C
   Forest, J
AF Pagès, J
   Salvi, J
   Collewet, C
   Forest, J
TI Optimised De Bruijn patterns for one-shot shape acquisition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE shape acquisition; active stereo; coded structured light
ID RANGE DATA-ACQUISITION; STRUCTURED LIGHT; ALGORITHM; SYSTEMS; ARRAYS
AB Coded structured light is an optical technique based on active stereovision which allows shape acquisition. By projecting a suitable set of light patterns onto the surface of an object and capturing images with a camera, a large number of correspondences can be found and 3D points can be reconstructed by means of triangulation. One-shot techniques are based on projecting an unique pattern so that moving objects can be measured. A major group of techniques in this field define coloured multi-slit or stripe patterns in order to obtain dense reconstructions. The former type of patterns is suitable for locating intensity peaks in the image while the latter is aimed to locate edges. In this paper, we present a new way to design coloured stripe patterns so that both intensity peaks and edges can be located without loss of accuracy and reducing the number of hue levels included in the pattern. The results obtained by the new pattern are quantitatively and qualitatively compared to similar techniques. These results also contribute to a comparison between the peak-based and edge-based reconstruction strategies. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Girona, Inst Informat & Applicat, Comp Vis & Robot Grp, E-17071 Girona, Spain.
   Irstea, F-35042 Rennes, France.
C3 Universitat de Girona; INRAE
RP Univ Girona, Inst Informat & Applicat, Comp Vis & Robot Grp, Avda Lluis Santalo S-N, E-17071 Girona, Spain.
EM jpages@eia.udg.es; qsalvi@eia.udg.es; christophe.collewet@cemagref.fr;
   forest@eia.udg.es
RI ; Salvi, Joaquim/L-2648-2014
OI Collewet, Christophe/0000-0001-8285-2212; Forest,
   Josep/0000-0002-4868-5884; Salvi, Joaquim/0000-0002-9482-7126
CR [Anonymous], PROC SPIE
   [Anonymous], 5 INT C COMP AN IM P
   Armangué X, 2003, IMAGE VISION COMPUT, V21, P205, DOI 10.1016/S0262-8856(02)00154-3
   Besl P.J., 1988, ADV MACHINE VISION, P1
   BLAIS F, 1986, SIGNAL PROCESS, V11, P145, DOI 10.1016/0165-1684(86)90033-2
   Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177
   Chen CS, 1997, IMAGE VISION COMPUT, V15, P445, DOI 10.1016/S0262-8856(96)01148-1
   Chen F, 2000, OPT ENG, V39, P10, DOI 10.1117/1.602438
   Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040
   Davies CJ, 1998, IEEE T SYST MAN CY B, V28, P90, DOI 10.1109/3477.658582
   ETZION T, 1988, IEEE T INFORM THEORY, V34, P1308, DOI 10.1109/18.21260
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   GRIFFIN PM, 1992, PATTERN RECOGN, V25, P609, DOI 10.1016/0031-3203(92)90078-W
   Guan C, 2003, OPT EXPRESS, V11, P406, DOI 10.1364/OE.11.000406
   JARVIS R, 1993, ADV IMAGE COMMUNICAT, P17
   Koninckx TP, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P413, DOI 10.1109/TDPVT.2004.1335268
   Koninckx TP, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P293, DOI 10.1109/IM.2003.1240262
   Lavoie P., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P370, DOI 10.1109/ICIAP.1999.797623
   MACWILLIAMS FJ, 1976, P IEEE, V64, P1715, DOI 10.1109/PROC.1976.10411
   MARUYAMA M, 1993, IEEE T PATTERN ANAL, V15, P647, DOI 10.1109/34.216735
   MONKS TP, 1992, IEE CONF PUBL, V354, P327
   NAYAR SK, 2003, PROJECTOR AUTOMATIC
   Petriu EM, 2000, IEEE IMTC P, P1237, DOI 10.1109/IMTC.2000.848675
   POSDAMER JL, 1982, COMPUT VISION GRAPH, V18, P1, DOI 10.1016/0146-664X(82)90096-X
   Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002
   Salvi J, 2002, PATTERN RECOGN, V35, P1617, DOI 10.1016/S0031-3203(01)00126-1
   Salvi J, 1998, PATTERN RECOGN LETT, V19, P1055, DOI 10.1016/S0167-8655(98)00085-3
   Spoelder HJW, 2000, IEEE T INSTRUM MEAS, V49, P1331, DOI 10.1109/19.893279
   Trobina M., 1995, Error model of a coded-light range sensor
   Trucco E, 1998, INT J COMPUT INTEG M, V11, P293, DOI 10.1080/095119298130642
   Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035
NR 32
TC 119
Z9 150
U1 1
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2005
VL 23
IS 8
BP 707
EP 720
DI 10.1016/j.imavis.2005.05.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VD
UT WOS:000231400500003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Johnston, DJ
   Fleury, M
   Downton, AC
   Clark, AF
AF Johnston, DJ
   Fleury, M
   Downton, AC
   Clark, AF
TI Real-time positioning for augmented reality on a custom parallel machine
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE augmented reality; parallel computing; position finding
ID PERFORMANCE
AB Augmented Reality (AR) is frequently implemented using vision processing for target recognition, but performance that is simultaneously robust and real-time is still elusive for larger frame sizes. The processing requirements of a particular AR system developed at the University of Essex (the Video Positioning System) were analysed. It has been found that the critical region-based processing steps could be parallelised, despite the resulting complex accumulation of intermediate results. The paper presents the parallel algorithms involved and the performance achieved. Comparison is made with more traditional edge-based systems, which may execute somewhat faster but are not as robust. The success of the parallelisation overcomes this performance limitation, and suggests a future production route. (C) 2003 Elsevier B.V.. All rights reserved.
C1 Univ Essex, Dept Elect Syst Engn, Colchester CO4 3SQ, Essex, England.
C3 University of Essex
RP Univ Essex, Dept Elect Syst Engn, Wivenhoe Pk, Colchester CO4 3SQ, Essex, England.
EM fleum@essex.ac.uk
CR [Anonymous], P INT S MIX AUGM REA
   Appel M, 2002, MACH VISION APPL, V13, P111, DOI 10.1007/s001380100066
   BODEN NJ, 1995, IEEE MICRO, V15, P29, DOI 10.1109/40.342015
   Brown L.G., 1992, ACM COMPUT SURV, V24, P325, DOI DOI 10.1145/146370.146374
   Fleury M., 2001, IEE Proceedings-Software, V148, P31, DOI 10.1049/ip-sen:20010213
   Fleury M, 2000, IEEE T PARALL DISTR, V11, P1164, DOI 10.1109/71.888637
   FUCHS H, 1981, VLSI DESIGN, V2, P20
   Gropp W, 1996, PARALLEL COMPUT, V22, P789, DOI 10.1016/0167-8191(96)00024-5
   Mellor J. P., 1995, Computer Vision, Virtual Reality and Robotics in Medicine. First International Conference, CVRMed '95. Proceedings, P471, DOI 10.1007/BFb0034988
   PARADISO J, 1999, CHI 99, P212
   Skillicorn DB, 1998, ACM COMPUT SURV, V30, P123, DOI 10.1145/280277.280278
   Thomas GA, 1997, IEE CONF PUBL, P284, DOI 10.1049/cp:19971284
   VONEICKEN T, 1992, ACM COMP AR, V20, P256, DOI 10.1145/146628.140382
   WANT R, 1992, ACM T INFORM SYST, V10, P91, DOI 10.1145/128756.128759
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 22
TC 6
Z9 6
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2005
VL 23
IS 3
BP 271
EP 286
DI 10.1016/j.imavis.2003.08.002
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NO
UT WOS:000227221800001
DA 2024-07-18
ER

PT J
AU Tsai, DM
   Chao, SM
AF Tsai, DM
   Chao, SM
TI An anisotropic diffusion-based defect detection for sputtered surfaces
   with inhomogeneous textures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE anisotropic diffusion; defect detection; inhomogeneous texture;
   sputtered surfaces
ID EDGE-DETECTION; IMAGE SEGMENTATION; GABOR FILTERS; CLASSIFICATION;
   INSPECTION; RESOLUTION; FEATURES; SPACE
AB Texture analysis techniques are being increasingly used for surface inspection, in which small defects that appear as local anomalies in textured surfaces must be detected. Traditional surface inspection methods mainly focus on homogeneous textures that contain periodical, repetitive patterns. In this paper, we study defect detection in sputtered glass substrates that involve inhomogeneous textures. Such sputtered surfaces can be found in touch panels and LCDs. An anisotropic diffusion scheme is proposed to detect subtle defects embedded in inhomogeneous textures. The proposed anisotropic diffusion model takes a non-negative decreasing function with an annealing gradient threshold as the diffusion coefficient to adaptively adjust the significance of edge gradients. It triggers the smoothing process in faultless areas for background texture removal by assigning a large diffusion coefficient value, and stops the diffusion process in defective areas to preserve sharp edges of anomalies by assigning a small diffusion coefficient value. Experimental results from a number of sputtered glass samples have shown the effectiveness of the proposed anisotropic diffusion scheme. (C) 2004 Elsevier B.V. All rights reserved.
C1 Yuan Ze Univ, Dept Ind Engn & Management, Tao Yuan, Taiwan.
C3 Yuan Ze University
RP Yuan Ze Univ, Dept Ind Engn & Management, 135 Yuan Tung Rd,Nei Li, Tao Yuan, Taiwan.
EM iedmtsai@saturn.yzu.edu.tw
CR ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796
   Bakalexis SA, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1203, DOI 10.1109/ICDSP.2002.1028309
   Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390
   Bodnarova A, 2000, INT CONF ACOUST SPEE, P3606, DOI 10.1109/ICASSP.2000.860182
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chen S., 1993, Pure and Applied Optics, V2, P429, DOI 10.1088/0963-9659/2/5/004
   Chen Y, 2001, COMPUT VIS IMAGE UND, V82, P85, DOI 10.1006/cviu.2001.0903
   CLARK M, 1987, PATTERN RECOGN LETT, V6, P261, DOI 10.1016/0167-8655(87)90086-9
   Clausi DA, 2000, PATTERN RECOGN, V33, P1835, DOI 10.1016/S0031-3203(99)00181-8
   COHEN FS, 1992, CVGIP-GRAPH MODEL IM, V54, P239, DOI 10.1016/1049-9652(92)90054-2
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   CONNERS RW, 1983, IEEE T PATTERN ANAL, V5, P573, DOI 10.1109/TPAMI.1983.4767446
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Deng H., 2000, INT S MULT INF PROC, P62
   Escofet J, 1998, P SOC PHOTO-OPT INS, V3490, P207, DOI 10.1117/12.308923
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Haris K, 1998, IEEE T IMAGE PROCESS, V7, P1684, DOI 10.1109/83.730380
   HIMAYAT N, 1991, IEEE INTERNATIONAL CONFERENCE ON SYSTEMS ENGINEERING //, P261, DOI 10.1109/ICSYSE.1991.161128
   KHALAJ BH, 1994, MACH VISION APPL, V7, P178, DOI 10.1007/BF01211662
   Lambert G, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P201, DOI 10.1109/ICIP.1997.632054
   LINNETT LM, 1995, IEE P-VIS IMAGE SIGN, V142, P1, DOI 10.1049/ip-vis:19951678
   LIU SS, 1990, COMPUT VISION GRAPH, V49, P52, DOI 10.1016/0734-189X(90)90162-O
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Maruo K, 1999, IEICE T ELECTRON, VE82C, P1003
   Niessen WJ, 1997, COMPUT VIS IMAGE UND, V66, P233, DOI 10.1006/cviu.1997.0614
   OHSHIGE T, 1991, ELEVENTH IEEE/CHMT INTERNATIONAL ELECTRONICS MANUFACTURING TECHNOLOGY SYMPOSIUM : THE KEY TO MANUFACTURING IN THE 1990S, P192, DOI 10.1109/IEMT.1991.279775
   Paschos G, 2000, PATTERN RECOGN LETT, V21, P837, DOI 10.1016/S0167-8655(00)00043-X
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pölzleitner W, 1999, P SOC PHOTO-OPT INS, V3837, P220, DOI 10.1117/12.360301
   Ramana KV, 1996, PATTERN RECOGN, V29, P1447, DOI 10.1016/0031-3203(96)00008-8
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Sari-Sarraf H, 1998, PROC CVPR IEEE, P938, DOI 10.1109/CVPR.1998.698717
   SIEW LH, 1988, IEEE T PATTERN ANAL, V10, P92, DOI 10.1109/34.3870
   Solé AF, 2001, COMPUT VIS IMAGE UND, V84, P241, DOI 10.1006/cviu.2001.0945
   THOMAS F, 1999, SPIE C WAV APPL SIGN, V3813, P85
   TorkamaniAzar F, 1996, IEEE T IMAGE PROCESS, V5, P1573, DOI 10.1109/83.541427
   Tsai DM, 2000, INT J ADV MANUF TECH, V16, P474, DOI 10.1007/s001700070055
   Tsai DM, 2003, IMAGE VISION COMPUT, V21, P307, DOI 10.1016/S0262-8856(03)00007-6
   Tsai DM, 1999, PATTERN RECOGN, V32, P389, DOI 10.1016/S0031-3203(98)00077-6
   Tsai DM, 1999, IMAGE VISION COMPUT, V18, P49, DOI 10.1016/S0262-8856(99)00009-8
   Tsuji H, 2002, IEEE IMAGE PROC, P85
   VANHULLE MM, 1993, NEURAL NETWORKS, V6, P7, DOI 10.1016/S0893-6080(05)80070-X
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Wiltschi K, 2000, MACH VISION APPL, V12, P113, DOI 10.1007/s001380050130
   Yang FG, 2003, IEEE T IMAGE PROCESS, V12, P1552, DOI 10.1109/TIP.2003.817242
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424
   ZHANG Y, 2000, 5 INT C SIGN PROC P, V2, P905
NR 48
TC 19
Z9 25
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2005
VL 23
IS 3
BP 325
EP 338
DI 10.1016/j.imavis.2004.09.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NO
UT WOS:000227221800005
DA 2024-07-18
ER

PT J
AU Chandran, S
   Srivastava, MP
AF Chandran, S
   Srivastava, MP
TI Irregular, unknown light sources in dynamic global illumination
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Indian Conference on Vision, Graphics and Image Processing (ICVGIP)
CY DEC 16-18, 2002
CL Ahmedabad, INDIA
DE dynamic global illumination; hierarchical radiosity
AB The goal in global illumination solutions for dynamic environments is to update a scene based on past scenes. For this difficult problem, current state of the art solutions are either not applicable, or unduly complex, when there are large changes in the illumination of unbounded number of objects. Such changes may be caused by the appearance of unexpected (at modeling time), irregular light sources.
   We define a subset of dynamic environments in which new light sources may be user introduced, and implement solutions that complement existing schemes. (C) 2004 Elsevier B.V. All rights reserved.
C1 Indian Inst Technol, Dept Comp Sci & Engn, Bombay 400076, Maharashtra, India.
   Banaras Hindu Univ, Inst Technol, Dept Comp Sci & Engn, Varanasi 221005, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bombay; Banaras Hindu University (BHU); Indian
   Institute of Technology System (IIT System); Indian Institute of
   Technology BHU Varanasi (IIT BHU Varanasi)
RP Indian Inst Technol, Dept Comp Sci & Engn, Bombay 400076, Maharashtra, India.
EM sharat@iitb.ac.in; mayur_prakash@rediffmail.com
CR Chen S. E., 1990, Computer Graphics, V24, P135, DOI 10.1145/97880.97894
   Damez C, 1999, SPRING EUROGRAP, P235
   DORSEY JO, 1991, COMP GRAPH, V25, P41
   DRETTAKIS G, 1997, ANN C SERIES, P57
   Foley J. D., 1994, Introduction to Computer Graphics", V55
   FORSYTH D, 1994, 5 EUR WORKSH REND
   GEORGE DW, 1990, IEEE COMPUT GRAPH, V10, P26, DOI 10.1109/38.56296
   HANRAHAN P, 1991, COMP GRAPH, V25, P197
   LINDHOLM E, 2001, ANN C SERIES, P149
   MYSZKOWSKI K, 2001, ANN C SERIES ACM, P221
   SCHOEFFEL F, 1999, EUR REND WORKSH 1999, P225
   TOLE P, 2002, ANN C SERIES ACM SIG
NR 12
TC 0
Z9 0
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2004
VL 22
IS 14
BP 1203
EP 1210
DI 10.1016/j.imavis.2004.03.014
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 882LG
UT WOS:000225939800007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Matas, J
   Chum, O
   Urban, M
   Pajdla, T
AF Matas, J
   Chum, O
   Urban, M
   Pajdla, T
TI Robust wide-baseline stereo from maximally stable extremal regions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE wide-baseline stereo; distinguished regions; maximally stable extremal
   regions; MSER; robust metric
AB The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied.
   A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER).
   A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal re ions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences.
   The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5 X), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained. (C) 2004 Elsevier B.V. All rights reserved.
C1 Czech Tech Univ, Ctr Machine Percept, Dept Cybernet, CZ-12135 Prague, Czech Republic.
   Univ Surrey, CVSSP, Guildford GU2 7XH, Surrey, England.
C3 Czech Technical University Prague; University of Surrey
RP Czech Tech Univ, Ctr Machine Percept, Dept Cybernet, Karlovo Nam 13, CZ-12135 Prague, Czech Republic.
EM matas@cmp.felk.cvut.cz; chum@cmp.felk.cvut.cz
RI Chum, Ondrej/F-5262-2015; , Matas/AAW-3282-2020; Urban,
   M./JPA-1357-2023; Pajdla, Tomas/K-7954-2013
OI Pajdla, Tomas/0000-0001-6325-0072; Matas, Jiri/0000-0003-0863-4844;
   Chum, Ondrej/0000-0001-7042-1810
CR [Anonymous], 1988, Algorithms
   [Anonymous], LNCS
   Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899
   CHUM O, 2003, P BMVC 03 LOND UK SE, V1, P73
   Dufournaud Y, 2000, PROC CVPR IEEE, P612, DOI 10.1109/CVPR.2000.855876
   GRIMSON WEL, 1990, OBJECT RECOGNITION
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Matas J, 2002, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2002.1047471
   MATAS J, 2002, P CVWW 02 FEB, P296
   MIKOLAJCZYK K, 2001, 8 INT C COMP VIS VAN
   MIKOLAJCZYK K, 2002, P ECCV, V1, P128
   MINDRU F, 1999, CVPR99, P368
   Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   SCHAFFALITZKY F, 2001, 8 INT C COMP VIS VAN
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   TELL D, 2000, ECCV 00
   TORR P, 1996, BMVC 96
   Tuytelaars T., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P412
   TUYTELAARS T, 1999, P 3 INT C VIS INF SY, P493
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
NR 22
TC 1922
Z9 2338
U1 7
U2 211
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 761
EP 767
DI 10.1016/j.imavis.2004.02.006
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300003
DA 2024-07-18
ER

PT J
AU Weber, M
   Blake, A
   Cipolla, R
AF Weber, M
   Blake, A
   Cipolla, R
TI Towards a complete dense geometric and photometric reconstruction under
   varying pose and illumination
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE dense reconstruction; shape; reflectance; stereo with changing
   illumination
ID SHAPE; STEREO
AB This paper proposes a novel framework to construct a geometric and photometric model of a viewed object that can be used for visualisation in arbitrary pose and illumination. The method is solely based on images and does not require any specialised equipment. We assume that the object has a piece-wise smooth surface and that its reflectance can be modelled using a parametric bidirectional reflectance distribution function. Without assuming any prior knowledge on the object, geometry and reflectance have to be estimated simultaneously and occlusion and shadows have to be treated consistently. We exploit the geometric and photometric consistency using the fact that surface orientation and reflectance are local invariants. In a first implementation, we demonstrate the method using a Lambertian object placed on a turn-table and illuminated by a number of unknown point light-sources. A discrete voxel model is initialised to the visual hull and voxels identified as inconsistent with the invariants are removed iteratively. The resulting model is used to render images in novel pose and illumination. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Cambridge, Dept Engn, Cambridge CB2 2PZ, England.
   Microsoft Res, Cambridge, England.
C3 University of Cambridge; Microsoft
RP Univ Cambridge, Dept Engn, Trumpington St, Cambridge CB2 2PZ, England.
EM mw232@cam.ac.uk
RI Arandjelović, Ognjen/V-5255-2019
OI Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla,
   Roberto/0000-0002-8999-2151
CR BLAKE A, 1985, IMAGE VISION COMPUT, V3, P183, DOI 10.1016/0262-8856(85)90006-X
   Carceroni RL, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P60
   Cipolla R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P616, DOI 10.1109/ICCV.1990.139606
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   FAUGERAS OD, 1998, LNCS, V1406, P379
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3
   IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0
   Kutulakos K. N., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P307, DOI 10.1109/ICCV.1999.791235
   Magda S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P391, DOI 10.1109/ICCV.2001.937652
   Maki A, 2002, INT J COMPUT VISION, V48, P75, DOI 10.1023/A:1016057422703
   Nishino K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P599, DOI 10.1109/ICCV.2001.937573
   Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271
   Sato I., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P306, DOI 10.1109/CVPR.1999.786956
   Seitz SM, 2002, INT J COMPUT VISION, V48, P115, DOI 10.1023/A:1016046923611
   Weber M, 2001, P BRIT MACH VIS C, P471
   WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050
   Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406
   YEZZI A, 2001, P IEEE INT C COMP VI, V1, P56
NR 19
TC 7
Z9 7
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 787
EP 793
DI 10.1016/j.imavis.2004.02.010
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chojnacki, W
   Brooks, MJ
   van den Hengel, A
   Gawley, D
AF Chojnacki, W
   Brooks, MJ
   van den Hengel, A
   Gawley, D
TI A new constrained parameter estimator for computer vision applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Statistical Methods in Video Processing
CY JUN 01-02, 2002
CL COPENHAGEN, DENMARK
DE Gaussian errors; maximum likelihood; constrained minimisation;
   fundamental matrix; epipolar equation; ancillary constraint; singularity
   constraint
AB A method of constrained parameter estimation is proposed for a class of computer vision problems. In a typical application, the parameters will describe a relationship between image feature locations, expressed as an equation linking the parameters and the image data, and will satisfy an ancillary constraint not involving the image data. A salient feature of the method is that it handles the ancillary constraint in an integrated fashion. not by means of a correction process operating upon results of unconstrained minimisation. The method is evaluated through experiments in fundamental matrix computation. Results are given for both synthetic and real images. It is demonstrated that the method produces results commensurate with, or superior to, previous approaches, with the advantage of being faster than comparable techniques. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
   CRC Sensor Signal & Informat Proc, Mawson Lakes, SA 5095, Australia.
C3 University of Adelaide
RP Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
EM wojtek@cs.adelaide.edu.au; mjb@cs.adelaide.edu.au;
   hengel@cs.adelaide.edu.au; dg@cs.adelaide.edu.au
RI Chojnacki, Wojciech/AAE-9875-2020; Brooks, Michael/G-5614-2012
OI Chojnacki, Wojciech/0000-0001-7782-1956; Brooks,
   Michael/0000-0001-9612-5884; van den Hengel, Anton/0000-0003-3027-8364
CR Brooks MJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P302, DOI 10.1109/ICCV.2001.937533
   Brooks MJ, 1997, J OPT SOC AM A, V14, P2670, DOI 10.1364/JOSAA.14.002670
   Chojnacki W, 2001, J MATH IMAGING VIS, V14, P21, DOI 10.1023/A:1008355213497
   Chojnacki W, 2000, IEEE T PATTERN ANAL, V22, P1294, DOI 10.1109/34.888714
   CHOJNACKI W, IN PRESS IEEE T PATT
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Kanatani K., 1996, Statistical optimization for geometric computation: theory and practice
   Leedan Y, 2000, INT J COMPUT VISION, V37, P127, DOI 10.1023/A:1008185619375
   Matei B, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.854727
NR 12
TC 24
Z9 26
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2004
VL 22
IS 2
BP 85
EP 91
DI 10.1016/S0262-8856(03)00140-9
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 769DW
UT WOS:000188612000002
DA 2024-07-18
ER

PT J
AU Devin, VE
   Hogg, DC
AF Devin, VE
   Hogg, DC
TI Reactive memories: an interactive talking-head
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE interactive head; face tracking; speech generation; behaviour modelling;
   human-computer interaction
AB We demonstrate a novel method for producing a synthetic talking-head. The method is based on earlier work in which the behaviour of a synthetic individual is generated by reference to a probabilistic model of interactive behaviour within the visual domain-such models are learnt automatically from typical interactions. We extend this work into a combined visual and auditory domain and employ a state-of-the-art facial appearance model. The result is a real-time synthetic talking-head that responds appropriately and with realistic timing to simple forms of greeting. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
C3 University of Leeds
RP Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
EM vincent@comp.leeds.ac.uk
OI Hogg, David/0000-0002-6125-9564
CR [Anonymous], 1998, ECCV
   BOWDEN R, 2002, INT S SMART GRAPH, P124
   BROOKE N, 1994, INT S SPEECH IM PROC
   CASSEL J, 1994, SIGGRAPH
   Cosatto E, 1998, COMP ANIM CONF PROC, P103, DOI 10.1109/CA.1998.681914
   DECAROLIS B, 2001, IJCAI
   DEVIN VE, 2002, THESIS U LEEDS
   GRAF H, 2000, P 4 IEEE INT C AUT F
   HASEGAWA O, 1992, PATTERN RECOGNITION
   HASEGAWA O, 1994, PATTERN RECOGNITION
   Isard M., 1996, ECCV
   JEBARA T, 1999, ICVS, P273
   Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8
   JOHNSON N, 1998, THESIS U LEEDS
   JOHNSON N, 1998, COMP SOC C COMP VIS
   MORISHIMA S, 1989, ACOUSTIC SPEECH SOUN
   NOH JY, 2000, IEEE INT C MULT EXP
   NOH JY, 2001, SIGGRAPH
   OLIVES J, 1999, MULTIMEDIA SIGNAL PR
   Pasquariello S., 2001, 6 ONL WORLD C SOFT C
   PELACHAUD C, 1998, WORKSH EMB CONV CHAR
   PIGHIN F, 1998, ANN C SERIES, V32, P75
   Poggi I, 1998, SPEECH COMMUN, V26, P5, DOI 10.1016/S0167-6393(98)00047-8
   REISS M, 1991, NEURAL NETWORKS, V4, P773, DOI 10.1016/0893-6080(91)90057-C
   Shatkay H., 1995, The Fourier Transform - a Primer
   TAKEUCHI A, 1993, INTERCHI 93, P187
   THORISSON KR, 1998, ICAA
   THORISSON KR, 1997, 1 ACM INT C AUT AG C
   WANG DL, 1990, P IEEE, V78, P1536, DOI 10.1109/5.58329
NR 29
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1125
EP 1133
DI 10.1016/j.imavis.2003.08.009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100007
DA 2024-07-18
ER

PT J
AU Torreao, JRA
AF Torreao, JRA
TI Geometric-photometric approach to monocular shape estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Green's function; photometric stereo; physics-based vision; shape from
   shading; structure from motion
ID GREENS-FUNCTION APPROACH; STEREO; CONSTRAINTS; GRADIENT; IMAGES; MOTION
AB Monocular, reflectance map-based shape estimation has traditionally relied exclusively on photometric data, but the recently introduced disparity-based photometric stereo (DBPS) and Green's function shape from shading (GSFS) have brought more geometry into it by incorporating a matching equation, and can appropriately be termed a geometric-photometric approach. In DBPS, the matching equation is used for obtaining disparities from the input image pair, while in GSFS it is used for generating the matching image, a uniform disparity field being considered. In both cases, depth can be recovered if one assumes the disparities to result from the displacement of the irradiance pattern over the imaged surface. Starting from the analysis of such displacement under perspective projection, we show that the original DBPS/GSFS formulation must be amended: reconstructions with no free parameters are no longer feasible, but we are able to propose an approximate procedure which yields higher quality estimates, up to a multiplicative factor. (C) 2003 Elsevier B.V. All rights reserved.
C1 Pontificia Univ Catolica Parana, Programa Posgrad Informat Aplicada, BR-80215901 Curitiba, Parana, Brazil.
C3 Pontificia Universidade Catolica do Parana
RP Torreao, JRA (corresponding author), Pontificia Univ Catolica Parana, Programa Posgrad Informat Aplicada, BR-80215901 Curitiba, Parana, Brazil.
CR DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   HORN BKP, 1990, INT J COMPUT VISION, V5, P37, DOI 10.1007/BF00056771
   KIM B, 1991, COMPUTER VISION GRAP, V53, P416
   KIMMEL R, 2000, P 4 AS C COMP VIS JA
   LANGER MS, 1994, J OPT SOC AM A, V11, P467, DOI 10.1364/JOSAA.11.000467
   Lee K. M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P479, DOI 10.1109/CVPR.1992.223147
   Marr D., 1982, Visual perception
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P879, DOI 10.1109/34.93807
   PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815
   PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394
   POGGIO GF, 1995, EARLY VISION
   POGGIO T, 1985, AIM833 MIT ART INT L
   Samaras D, 2003, IEEE T PATTERN ANAL, V25, P247, DOI 10.1109/TPAMI.2003.1177155
   SPACEK LA, 1986, IMAGE VISION COMPUT, V4, P43, DOI 10.1016/0262-8856(86)90007-7
   SZELISKI R, 1991, CVGIP-IMAG UNDERSTAN, V53, P129, DOI 10.1016/1049-9660(91)90023-I
   Torreao JRA, 2002, PATTERN RECOGN LETT, V23, P1755, DOI 10.1016/S0167-8655(02)00149-6
   Torreao JRA, 1998, J OPT SOC AM A, V15, P2966, DOI 10.1364/JOSAA.15.002966
   Torreao JRA, 1999, PATTERN RECOGN LETT, V20, P535, DOI 10.1016/S0167-8655(99)00026-4
   Torreao JRA, 2001, PATTERN RECOGN, V34, P2367, DOI 10.1016/S0031-3203(00)00168-0
   TORREAO JRA, 1995, MACH VISION APPL, V8, P163, DOI 10.1007/BF01215811
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406
   Yuille AL, 1998, COMPUT VIS IMAGE UND, V72, P351, DOI 10.1006/cviu.1998.0676
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang R, 1999, IEEE T SYST MAN CY A, V29, P318, DOI 10.1109/3468.759291
   Zhang R, 1996, COMPUT VIS IMAGE UND, V63, P221, DOI 10.1006/cviu.1996.0016
NR 26
TC 10
Z9 10
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2003
VL 21
IS 12
BP 1045
EP 1061
DI 10.1016/j.imavis.2003.08.007
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 737UW
UT WOS:000186251000004
DA 2024-07-18
ER

PT J
AU Bhanu, B
   Lin, YQ
AF Bhanu, B
   Lin, YQ
TI Genetic algorithm based feature selection for target detection in SAR
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT IEEE Workshop in Computer Vision Beyond the Visible Spectrum
CY DEC 14, 2001
CL KAUAI, HI
SP IEEE
DE ATR system; feature selection; genetic algorithm; minimum description
   length; target detection
AB A genetic algorithm (GA) approach is presented to select a set of features to discriminate the targets from the natural clutter false alarms in SAR images. Four stages of an automatic target detection system are developed: the rough target detection, feature extraction from the potential target regions. GA based feature selection and the final Bayesian classification. A new fitness function based on minimum description length principle (MDLP) is proposed to drive GA and it is compared with three other fitness functions. Experimental results show that the new fitness function Outperforms the other three fitness functions and the GA driven by it selected a good subset of features to discriminate the targets from clutters effectively. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Calif Riverside, Coll Engn, Ctr Res Intelligent Syst, Riverside, CA 92521 USA.
C3 University of California System; University of California Riverside
RP Univ Calif Riverside, Coll Engn, Ctr Res Intelligent Syst, B232 Bourns Hall, Riverside, CA 92521 USA.
EM bhanu@cris.ucr.edu; yqlin@cris.ucr.edu
OI Bhanu, Bir/0000-0001-8971-6416
CR [Anonymous], GENETIC LEARNING ADA
   Bhanu B, 1997, IEEE T IMAGE PROCESS, V6, P1, DOI 10.1109/TIP.1997.552076
   BHANU B, 1994, IEEE T PATTERN ANAL, V16, P865
   Cagnoni S, 1999, IMAGE VISION COMPUT, V17, P881, DOI 10.1016/S0262-8856(98)00166-8
   EMMANOUILIDIS C, 1999, P INT JOINT C NEUR N, V6, P4387
   ESTEVEZ P, 1998, P 8 INT C ART NEUR N, V1, P311
   Gao Q, 2000, ARTIF INTELL, V121, P1, DOI 10.1016/S0004-3702(00)00034-5
   HALVERSEN SD, 1992, PROC NAECON IEEE NAT, P260, DOI 10.1109/NAECON.1992.220611
   KATZ A, 1994, IEEE T PATTERN ANAL, V16
   Kreithen D. E., 1993, Lincoln Laboratory Journal, V6, P25
   Matsui K., 1999, Systems and Computers in Japan, V30, P69, DOI 10.1002/(SICI)1520-684X(19990630)30:7<69::AID-SCJ8>3.0.CO;2-U
   Novak L. M., 1993, Lincoln Laboratory Journal, V6, P11
   NOVAK LM, 1993, IEEE T AERO ELEC SYS, V29, P234, DOI 10.1109/7.249129
   Ozcan E, 1997, PATTERN RECOGN LETT, V18, P987, DOI 10.1016/S0167-8655(97)00123-2
   PUNCH WF, 1993, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P557
   QUINLAN JR, 1989, INFORM COMPUT, V80, P227, DOI 10.1016/0890-5401(89)90010-2
   RHEE F, 1999, P IEEE INT FUZZ SYST, V3, P1266
   RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150
   RIZKI M, 1993, P IEEE NAT AER EL C, P24
   SIEDLECKI W, 1989, PATTERN RECOGN LETT, V10, P335, DOI 10.1016/0167-8655(89)90037-8
   SRIKANTH R, 1995, PATTERN RECOGN LETT, V16, P789, DOI 10.1016/0167-8655(95)00043-G
NR 21
TC 80
Z9 100
U1 0
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2003
VL 21
IS 7
BP 591
EP 608
DI 10.1016/S0262-8856(03)00057-X
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 706FR
UT WOS:000184443400004
DA 2024-07-18
ER

PT J
AU Pizer, SM
   Fletcher, PT
   Thall, A
   Styner, M
   Gerig, G
   Joshi, S
AF Pizer, SM
   Fletcher, PT
   Thall, A
   Styner, M
   Gerig, G
   Joshi, S
TI Object models in multiscale intrinsic coordinates via m-reps
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE m-rep; intrinsic coordinates; figural coordinate system
ID SHAPE-DESCRIPTION; ANATOMY
AB Object descriptions used for 3D segmentation by deformable models and for statistical characterization of 3D object classes benefit from having intrinsic correspondences over deformation of the objects or multiple instances in the same object class. These correspondences apply over a variety of spatial scale levels and consequently lead to efficient segmentation and probability distributions of geometry that are trainable with an achievable number of training instances. This paper describes a figural coordinate system provided by m-reps models and shows how such coordinates not only provide the required positional correspondences, but also are intuitive and provide orientational and metric correspondences. Examples are given for the segmentation of kidneys from CT and for the statistical characterization of schizophrenia and control classes of cerebral ventricles and of hippocampus pairs. (C) 2002 Published by Elsevier Science B.V.
C1 Univ N Carolina, Med Image Display & Anal Grp, Chapel Hill, NC 27514 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Pizer, SM (corresponding author), Univ N Carolina, Med Image Display & Anal Grp, Chapel Hill, NC 27514 USA.
EM pizer@es.unc.edu
OI Gerig, Guido/0000-0002-9547-6233
CR [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], P WORKSH MATH METH B
   BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0
   BRECHBUHLER C, 1995, COMPUT VIS IMAGE UND, V61, P154, DOI 10.1006/cviu.1995.1013
   Christensen GE, 1997, IEEE T MED IMAGING, V16, P864, DOI 10.1109/42.650882
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 1999, LECT NOTES COMPUT SC, V1613, P322
   CROUCH JR, 2001, 2 INT C INN SOL PROS
   Csernansky JG, 1998, P NATL ACAD SCI USA, V95, P11406, DOI 10.1073/pnas.95.19.11406
   DAMON J, 2002, SMOOTHNESS GEOMETRY
   Delingette H, 1999, INT J COMPUT VISION, V32, P111, DOI 10.1023/A:1008157432188
   FLETCHER PT, 2002, P IEEE INT S BIOM IM
   Gerig G, 2001, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P171, DOI 10.1109/MMBIA.2001.991731
   Gerig G., 2001, Lecture Notes in Computer Science, V2208, P24
   Grenander U, 1998, Q APPL MATH, V56, P617, DOI 10.1090/qam/1668732
   JOSHI S, 2001, P IPMI, V2082, P64
   Joshi SC, 2000, IEEE T IMAGE PROCESS, V9, P1357, DOI 10.1109/83.855431
   Kelemen A, 1999, IEEE T MED IMAGING, V18, P828, DOI 10.1109/42.811260
   LUO B, 1999, P 10 BRIT MACH VIS C, P43
   Martin J, 1998, IEEE T PATTERN ANAL, V20, P97, DOI 10.1109/34.659928
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660
   PIZER SM, 2002, DEFORMABLE M REPS 3D
   Shenton ME, 2002, PSYCHIAT RES-NEUROIM, V115, P15, DOI 10.1016/S0925-4927(02)00025-2
   Styner M, 2001, PROC CVPR IEEE, P651
   STYNER M, 2002, IN PRESS IJCV
   Styner M., 2001, PROC MED IMAG LECT N, V2082, P502
   Szekely G, 1996, Med Image Anal, V1, P19, DOI 10.1016/S1361-8415(01)80003-7
   Thall A., 2002, TR02001 U N CAR COMP
   Wang YM, 1998, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1998.698628
   WILLIS LA, 2001, THESIS UNC
   YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59
   YUSHKEVICH P, 2001, P IPMI, V2082, P402
NR 32
TC 7
Z9 7
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 5
EP 15
AR PII S0262-8856(02)00130-0
DI 10.1016/S0262-8856(02)00130-0
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800002
DA 2024-07-18
ER

PT J
AU Li, XH
   Li, GQ
   Li, M
   Liu, KL
   Mitrouchev, P
AF Li, Xihang
   Li, Guiqin
   Li, Ming
   Liu, Kuiliang
   Mitrouchev, Peter
TI 3D human body modeling with orthogonal human mask image based on
   multi-channel Swin transformer architecture
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Body shape space; Human shape estimation; Orthogonal human mask; Swin
   transformer; Body shape classification
ID RECONSTRUCTION
AB The reconstruction based on RGB images of dressed human body lacks the shape information of the human body under clothing, while the naked 3D human body scanning will violate the user's privacy. To overcome these limitations, a new method, based on Swin transformer (Swin-T), for reconstructing 3D human body shape from human orthogonal mask image is proposed. Its core is to express the reconstruction problem as solving regression mapping function. A fast body shape type classification method based on the human front mask is proposed. The regression function is innovatively represented as a piecewise function, with the body shape of the human body as the segmentation criterion. A multi-channel Swin-T architecture is designed, which can not only extract features from front and side mask images, but also their mixed features to construct the regression mapping function. Different body types for different genders are predicted with separate regression function to help estimate an accurate human model. Extensive experimental results show that the proposed method effectively achieves visually realistic and accurate body reconstruction, and significantly outperforms the current state-ofthe-art methods. In addition, the classification of body types can compensate for the errors caused by partial clothing laxity in practical applications, which is beneficial for users to obtain a more accurate 3D human model.
C1 [Li, Xihang; Li, Guiqin; Li, Ming; Liu, Kuiliang] Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, Shanghai, Peoples R China.
   [Mitrouchev, Peter] Univ Grenoble Alpes, G SCOP, St Martin Dheres, France.
   [Li, Guiqin] Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, 333 Nanchen Rd, Shanghai 200444, Peoples R China.
C3 Shanghai University; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA);
   Centre National de la Recherche Scientifique (CNRS); Shanghai University
RP Li, GQ (corresponding author), Shanghai Univ, Shanghai Key Lab Intelligent Mfg & Robot, 333 Nanchen Rd, Shanghai 200444, Peoples R China.
EM leeching@shu.edu.cn
CR Alldieck T, 2018, PROC CVPR IEEE, P8387, DOI 10.1109/CVPR.2018.00875
   Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Carion Nicolas, 2020, EUR C COMP VIS ECCV, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen D., 2022, VISUAL COMPUT, P1
   Chen HT, 2021, PROC CVPR IEEE, P12294, DOI 10.1109/CVPR46437.2021.01212
   Choutas Vasileios, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P20, DOI 10.1007/978-3-030-58607-2_2
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dibra E, 2016, INT CONF 3D VISION, P108, DOI 10.1109/3DV.2016.19
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Grishchenko I, 2022, Arxiv, DOI arXiv:2206.11678
   Hasson Y, 2019, PROC CVPR IEEE, P11799, DOI 10.1109/CVPR.2019.01208
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heo B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11916, DOI 10.1109/ICCV48922.2021.01172
   Hu PP, 2021, IEEE T IND INFORM, V17, P3793, DOI 10.1109/TII.2020.3016591
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang JH, 2022, NEUROCOMPUTING, V493, P281, DOI 10.1016/j.neucom.2022.04.051
   Ji ZP, 2019, COMPUT AIDED GEOM D, V71, P231, DOI 10.1016/j.cagd.2019.04.019
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kolotouros N, 2019, PROC CVPR IEEE, P4496, DOI 10.1109/CVPR.2019.00463
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B., 2022, Vis. Comput, P1
   Li XL, 2023, VISUAL COMPUT, V39, P663, DOI 10.1007/s00371-021-02365-2
   Li XH, 2022, TEXT RES J, V92, P3750, DOI 10.1177/00405175221093663
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu B, 2022, J COMPUT INF SCI ENG, V22, DOI 10.1115/1.4054001
   Liu Z., 2016, IEEE T CYBERNETICS
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Osman Ahmed A. A., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P598, DOI 10.1007/978-3-030-58539-6_36
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Pishchulin L, 2017, PATTERN RECOGN, V67, P276, DOI 10.1016/j.patcog.2017.02.018
   Radford A., 2018, Improving language understanding by generative pre-training
   Robinette K.M., 2002, Civilian American and European surface anthropometry resource (CAESAR), V1, DOI DOI 10.21236/ADA406704
   Rogge L, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2634212
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song, 2018, SEMANTIC PARAMETRIC
   Song D, 2018, IEEE ACCESS, V6, P27939, DOI 10.1109/ACCESS.2018.2837147
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YZ, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480488
   Wei FY, 2020, INT CONF 3D VISION, P434, DOI 10.1109/3DV50981.2020.00053
   Xie HY, 2020, IEEE ACCESS, V8, P3539, DOI 10.1109/ACCESS.2019.2962833
   Xie HY, 2020, TEXT RES J, V90, P937, DOI 10.1177/0040517519883957
   Xu HY, 2020, PROC CVPR IEEE, P6183, DOI 10.1109/CVPR42600.2020.00622
   Yang YP, 2014, 2014 2ND INTERNATIONAL CONFERENCE ON 3D VISION, VOL. 2, P41, DOI 10.1109/3DV.2014.47
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zanfir Andrei, 2020, ECCV
   Zeng, 2018, 3D HUMAN BODY RESHAP
   Zhang C, 2017, PROC CVPR IEEE, P5484, DOI 10.1109/CVPR.2017.582
NR 57
TC 0
Z9 0
U1 9
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104795
DI 10.1016/j.imavis.2023.104795
EA AUG 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA R2LE4
UT WOS:001062704700001
DA 2024-07-18
ER

PT J
AU Wang, JH
   Lu, Y
   Lu, GM
AF Wang, Jiahuan
   Lu, Yao
   Lu, Guangming
TI Lightweight image denoising network with four-channel interaction
   transform
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Image denoising; Lightweight network; Four -channel interaction
   transform
ID SPARSE; ALGORITHM
AB Image denoising has always been a fundamental task in computer vision. In recent years, deep learning methods have emerged as the dominant approach for image denoising and have significantly improved denoising per-formance. However, these deep denoising methods typically require large model sizes, making network training prohibitively expensive and limiting their applicability in realistic scenarios. To address this issue, we propose a Lightweight Image Denoising Network (LWNet) with a four-channel interaction transform that effectively re-duces the model size. The proposed four-channel interaction transform first constructs the LWNet using four channels within the input and output dimensions. Specifically, an additional empty channel with all zeros is attached to the input image, and the output dimension has four channels. This additional channel significantly enhances the robustness of network training, as the expansion of features in the channel dimension provides richer information. Compared to three-channel networks, LWNet exhibits greater fault tolerance. Furthermore, the proposed LWNet uses a dual-branch structure to achieve the four-channel interaction transform in the feature space. One branch focuses on the feature learning of the additional channel within the input dimension, while the other branch handles the original three channels. This mechanism enables the network to retrieve abundant denoising features and adaptively inject them into the denoised images, significantly enhancing the denoising performance. Thanks to the powerful feature retrieval ability of the four-channel transform, the proposed LWNet can significantly decrease the required number of parameters. Extensive experimental results show that LWNet achieves the best denoising results on synthetic datasets using much fewer parameters. Even when extrapolating to real datasets for validation, it maintains better denoising performance with effective model size. Overall, the proposed LWNet offers an effective solution to reduce model size without compromising denoising performance and has potential practical applications in various image denoising scenarios.
C1 [Wang, Jiahuan] Harbin Inst Technol Shenzhen, Dept Comp Sci, Shenzhen 518057, Peoples R China.
   [Lu, Yao; Lu, Guangming] Harbin Inst Technol Shenzhen, Dept Comp Sci & Technol, Shenzhen, Peoples R China.
   [Lu, Yao; Lu, Guangming] Guangdong Prov Key Lab Novel Secur Intelligence Te, Shenzhen 518057, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Lu, Y; Lu, GM (corresponding author), Harbin Inst Technol Shenzhen, Dept Comp Sci & Technol, Shenzhen, Peoples R China.
EM wangjiahuanszhit@163.com; luyao2021@hit.edu.cn; luguangm@hit.edu.cn
FU NSFC [62176077, 62206073]; Shenzhen Key Technical Project [2022N001,
   2020N046, 2022N063]; Shenzhen Fundamental Research Fund
   [JCYJ20210324132210025]; Guangdong Provincial Key Laboratory of Novel
   Security Intelligence Technologies [2022B1212010005]; Guangdong Shenzhen
   joint Youth Fund [2021A151511074]; Natural Science Foundation of
   Guangdong Province [2023A1515010893]; Shenzhen Doctoral Initiation
   Technology Plan [RCBS20221008093222010]
FX This work was supported in part by the NSFC fund 62176077 and 62206073,
   in part by the Shenzhen Key Technical Project under Grant 2022N001,
   2020N046, and 2022N063, in part by the Shenzhen Fundamental Research
   Fund under Grant JCYJ20210324132210025, in part by the Guangdong
   Provincial Key Laboratory of Novel Security Intelligence Technologies
   (2022B1212010005) , in part by the Guangdong Shenzhen joint Youth Fund
   under Grant 2021A151511074, in part by the Natural Science Foundation of
   Guangdong Province under Grant 2023A1515010893, and in part by the
   Shenzhen Doctoral Initiation Technology Plan under Grant
   RCBS20221008093222010.
CR Abdelhamed A, 2018, PROC CVPR IEEE, P1692, DOI 10.1109/CVPR.2018.00182
   Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Anwar S, 2019, IEEE I CONF COMP VIS, P3155, DOI 10.1109/ICCV.2019.00325
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Aspandi D, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104189
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Burger HC, 2012, PROC CVPR IEEE, P2392, DOI 10.1109/CVPR.2012.6247952
   Chen YJ, 2017, IEEE T PATTERN ANAL, V39, P1256, DOI 10.1109/TPAMI.2016.2596743
   Cheng S, 2021, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR46437.2021.00486
   Dabov K, 2007, IEEE IMAGE PROC, P313, DOI 10.1109/icip.2007.4378954
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   Dabov K, 2006, PROC SPIE, V6064, DOI 10.1117/12.643267
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gu SH, 2014, PROC CVPR IEEE, P2862, DOI 10.1109/CVPR.2014.366
   Guo S, 2019, PROC CVPR IEEE, P1712, DOI 10.1109/CVPR.2019.00181
   Kim J, 2016, PROC CVPR IEEE, P1637, DOI [10.1109/CVPR.2016.182, 10.1109/CVPR.2016.181]
   Lefkimmiatis S, 2018, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2018.00338
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Mairal J, 2009, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2009.5459452
   Mao XJ, 2016, ADV NEUR IN, V29
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nakkiran P, 2021, J STAT MECH-THEORY E, V2021, DOI 10.1088/1742-5468/ac3a74
   Plötz T, 2017, PROC CVPR IEEE, P2750, DOI 10.1109/CVPR.2017.294
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Ren HY, 2019, LECT NOTES COMPUT SC, V11365, P215, DOI 10.1007/978-3-030-20873-8_14
   Saeedi J, 2010, IMAGE VISION COMPUT, V28, P1611, DOI 10.1016/j.imavis.2010.04.004
   Santhanam V, 2017, PROC CVPR IEEE, P5395, DOI 10.1109/CVPR.2017.573
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wang ZD, 2022, PROC CVPR IEEE, P17662, DOI 10.1109/CVPR52688.2022.01716
   Yue Z., 2019, ADV NEURAL INF PROCE, V32, P101
   Zamir Syed Waqas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P492, DOI 10.1007/978-3-030-58595-2_30
   Zamir SW, 2021, PROC CVPR IEEE, P14816, DOI 10.1109/CVPR46437.2021.01458
   Zhang K, 2018, IEEE T IMAGE PROCESS, V27, P4608, DOI 10.1109/TIP.2018.2839891
   Zhang K, 2017, PROC CVPR IEEE, P2808, DOI 10.1109/CVPR.2017.300
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zongsheng Yue, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P41, DOI 10.1007/978-3-030-58607-2_3
NR 38
TC 3
Z9 3
U1 11
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104766
DI 10.1016/j.imavis.2023.104766
EA JUL 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P5WM4
UT WOS:001051377900001
DA 2024-07-18
ER

PT J
AU Liu, ZG
   Wu, Y
   Yin, ZY
   Gao, CL
AF Liu, Zhigang
   Wu, Yin
   Yin, Ziyang
   Gao, Chunlei
TI Unsupervised video segmentation for multi-view daily action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video segmentation; Multi-layer representation; Multi-view action
   recognition; Motion atom; Motion phrase
ID VECTOR; REPRESENTATION; FRAMEWORK; NETWORK
AB Multi-layer representations have achieved outstanding performances in the complex daily action recognition. However, the fixed length of the sliding window (SW) leads to the segmented motion atoms incomplete or non-unique. To deal with this problem, we propose unsupervised video segmentation (UVS) for multi-view daily action recognition. Firstly, the average cosine similarity is designed to ensure the integrity of motion atoms. Secondly, we utilize the ordered combination of motion atoms to construct the table of multi-scale motion phrases in a top-down manner, instead of the fixed-scale traditional motion phrases. Finally, the experimental results based on the WVU dataset, the NTU RGB-D 120 dataset, and the N-UCLA dataset show that the proposed UVS method has state-of-the-art performance, compared with the classic methods such as IDT, MoFAP, JLMF, FGCN, and MVMLR.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Liu, Zhigang; Wu, Yin; Yin, Ziyang; Gao, Chunlei] Northeastern Univ, Sch Comp & Commun Engn, Qinhuangdao 066004, Peoples R China.
C3 Northeastern University - China
RP Liu, ZG (corresponding author), Northeastern Univ, Sch Comp & Commun Engn, Qinhuangdao 066004, Peoples R China.
EM zliu@neuq.edu.cn
FU National Natural Science Founda-tion of China [61973069, 61901099]
FX Acknowledgements This work was supported by the National Natural Science
   Founda-tion of China under Grant 61973069 and Grant 61901099.
CR Bulbul MF, 2021, COMPUT J, V64, P1633, DOI 10.1093/comjnl/bxz123
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Cheng ZW, 2012, LECT NOTES COMPUT SC, V7584, P52, DOI 10.1007/978-3-642-33868-7_6
   Dhiman C, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P225, DOI [10.1109/BigMM.2019.00-21, 10.1109/BigMM.2019.00041]
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Dhiman C, 2019, IEEE SENS J, V19, P5195, DOI 10.1109/JSEN.2019.2903645
   Ding L, 2017, Arxiv, DOI arXiv:1705.07818
   Gammulle H, 2020, PATTERN RECOGN LETT, V131, P442, DOI 10.1016/j.patrec.2020.01.023
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   Gutoski M, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104313
   Hashemi SM, 2016, MULTIMED TOOLS APPL, V75, P6755, DOI 10.1007/s11042-015-2606-5
   Holte M. B., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P342, DOI 10.1109/3DIMPVT.2011.50
   Khan MA, 2019, PATTERN ANAL APPL, V22, P1377, DOI 10.1007/s10044-018-0688-1
   Khan S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237941
   Lillo I, 2017, IMAGE VISION COMPUT, V59, P63, DOI 10.1016/j.imavis.2016.11.004
   Ling MG, 2019, FRONT COMPUT SCI-CHI, V13, P302, DOI 10.1007/s11704-018-8015-y
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu ZG, 2022, DIGIT SIGNAL PROCESS, V126, DOI 10.1016/j.dsp.2022.103487
   Liu ZG, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104333
   Naeem HB, 2021, PATTERN RECOGN LETT, V148, P22, DOI 10.1016/j.patrec.2021.04.023
   Naeem HB, 2020, ARAB J SCI ENG, V45, P6109, DOI 10.1007/s13369-020-04481-y
   Tu NA, 2019, IEEE T CIRC SYST VID, V29, P800, DOI 10.1109/TCSVT.2018.2816960
   Panagiotakis C, 2018, IEEE IMAGE PROC, P923, DOI 10.1109/ICIP.2018.8451336
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Santos L, 2015, PATTERN RECOGN, V48, P568, DOI 10.1016/j.patcog.2014.08.015
   Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Si ZZ, 2013, IEEE T PATTERN ANAL, V35, P2189, DOI 10.1109/TPAMI.2013.35
   Song H, 2019, IEEE T MULTIMEDIA, V21, P717, DOI 10.1109/TMM.2018.2866370
   Sun B, 2021, ACM T KNOWL DISCOV D, V15, DOI 10.1145/3434746
   Sun D., 2021, COGN COMPUT, P1
   Ulhaq A, 2018, IEEE T IMAGE PROCESS, V27, P1230, DOI 10.1109/TIP.2017.2765821
   Ullah A, 2021, NEUROCOMPUTING, V435, P321, DOI 10.1016/j.neucom.2019.12.151
   Vishwakarma DK, 2019, VISUAL COMPUT, V35, P1595, DOI 10.1007/s00371-018-1560-4
   Vyas Shruti, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P427, DOI 10.1007/978-3-030-58583-9_26
   Wang CX, 2019, J PHYS CONF SER, V1176, DOI 10.1088/1742-6596/1176/6/062015
   Wang DG, 2018, LECT NOTES COMPUT SC, V11213, P457, DOI 10.1007/978-3-030-01240-3_28
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang HS, 2018, IEEE T IMAGE PROCESS, V27, P4382, DOI 10.1109/TIP.2018.2837386
   Wang J, 2016, IEEE T CIRC SYST VID, V26, P1461, DOI 10.1109/TCSVT.2014.2382984
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
   Wang RS, 2020, CHIN CONT DECIS CONF, P4858, DOI 10.1109/CCDC49329.2020.9164815
   Wang TW, 2019, J VIS COMMUN IMAGE R, V61, P315, DOI 10.1016/j.jvcir.2019.04.001
   Wei CC, 2021, IEEE T CIRC SYST VID, V31, P1138, DOI 10.1109/TCSVT.2020.2999384
   Wei P, 2019, IEEE T MULTIMEDIA, V21, P2195, DOI 10.1109/TMM.2019.2897902
   Wen J, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108445
   Xie YL, 2022, IET COMPUT VIS, V16, P266, DOI 10.1049/cvi2.12086
   Xu C, 2021, NEUROCOMPUTING, V456, P384, DOI 10.1016/j.neucom.2021.05.077
   Yang H, 2022, IEEE T IMAGE PROCESS, V31, P164, DOI 10.1109/TIP.2021.3129117
   Zhu LC, 2022, IEEE T MULTIMEDIA, V24, P668, DOI 10.1109/TMM.2021.3057503
NR 49
TC 2
Z9 2
U1 6
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2023
VL 134
AR 104687
DI 10.1016/j.imavis.2023.104687
EA MAY 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA M7HX9
UT WOS:001031901200001
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, SK
   Peer, P
AF Kumar, Sumit
   Singh, Satish Kumar
   Peer, Peter
TI Occluded thermal face recognition using BoCNN and radial derivative
   Gaussian feature descriptor
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE BoCNN (bag of CNN); Handcrafted features; Convolutional neural network;
   K-nearest neighbor; Facial occlusion; Thermal faces; Face recognition
ID FACIAL IMAGE RECOGNITION; HANDCRAFTED FEATURES; PATTERN
AB In this work, we propose a Radial derivative Gaussian feature (RDGF) descriptor, a novel handcrafted feature descriptor for disguised thermal face recognition. The feature encoding has been done so that the performance is least affected by noise and works well over challenging datasets. We propose a cascaded framework that combines two modules, namely BoCNN and the RDGF descriptor. The cascading architecture estimates the performance of BoCNN before classification. It also uses a dynamic classifier selector in run time to choose between handcrafted features and the CNN framework to enhance the overall performance. We also propose a thermal face dataset with partial occlusion. We have compared the performance of the RDGF descriptor with state-of-the-art descriptors on the IIIT-Delhi disguised thermal face dataset and our proposed dataset. RDGF exhibits better performance compared to other state-of-the-art descriptors. Our proposed descriptor shows relative increment of 56.84%, 64.92%, 67.25%, 64.03%, 48.06%, and 7.28% on IIIT-D Occluded Thermal Dataset when compared with LBP, LDP, LBDP, LVP, LGHP, and HOG, respectively. A similar enhancement of accuracy has been observed on our proposed dataset as well. An exhaustive comparison based on the performance of the cascaded framework with state-of-the-art CNN models has also been done in a similar fashion. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Kumar, Sumit; Singh, Satish Kumar] Indian Inst Informat Technol, Prayagraj 211012, India.
   [Peer, Peter] Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, SI-1000 Ljubljana, Slovenia.
C3 Indian Institute of Information Technology Allahabad; University of
   Ljubljana
RP Kumar, S (corresponding author), Indian Inst Informat Technol, Prayagraj 211012, India.
EM sumit.093040@gmail.com
RI Kumar, Sumit/HJZ-0984-2023; singh, satish/U-7158-2018
OI singh, satish/0000-0002-8536-4991
FU Ministry of Human Resource Development as per the norms of the
   Government of India; Slovenian Research Agency ARRS; DST Ministry of
   Science and Technology, Government of India [P2-0214 (A)]; 
   [DST/ICD/Indo-Slovenia/2022/09 (G)]
FX This research has been conducted in Computer Vision and Biometric Lab at
   the Indian Institute of Information Technology, Allahabad and the
   financial assistance was provided by the Ministry of Human Resource
   Development as per the norms of the Government of India. We are thankful
   to the Slovenian Research Agency ARRS for its contribution to this work
   under the Slovenian-Indian bilateral project. Peter Peer is partially
   supported by the Slovenian Research Agency ARRS through the Research
   Programmes P2-0214 (A) ?Computer Vision?. We are also thankful to the
   DST Ministry of Science and Technology, Government of India for
   partially supporting the research vide DST/ICD/Indo-Slovenia/2022/09 (G)
   .
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Akhloufi M, 2008, PROCEEDINGS OF THE FIFTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, P269, DOI 10.1109/CRV.2008.43
   [Anonymous], 2010, ROBOT SOCCER WORLD C
   [Anonymous], 2015, CVPR
   Balaban S, 2015, PROC SPIE, V9457, DOI 10.1117/12.2181526
   Batagelj B, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052070
   Belhumeur PN, 2013, IEEE T PATTERN ANAL, V35, P2930, DOI 10.1109/TPAMI.2013.23
   Buddharaju P, 2007, IEEE T PATTERN ANAL, V29, P613, DOI 10.1109/TPAMI.2007.1007
   Chakraborty S, 2020, IEEE SENS J, V20, P8117, DOI 10.1109/JSEN.2020.2979907
   Chakraborty S, 2019, MULTIMED TOOLS APPL, V78, P14799, DOI 10.1007/s11042-018-6846-z
   Chakraborty S, 2018, PATTERN RECOGN LETT, V115, P50, DOI 10.1016/j.patrec.2017.10.015
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Chakraborty S, 2015, 2015 IEEE UP SECTION CONFERENCE ON ELECTRICAL COMPUTER AND ELECTRONICS (UPCON), DOI 10.1109/UPCON.2015.7456681
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng JK, 2019, Arxiv, DOI [arXiv:1905.00641, DOI 10.48550/ARXIV.1905.00641, 10.48550/ARXIV.1905.00641]
   Deng JK, 2019, IEEE INT CONF COMP V, P2638, DOI 10.1109/ICCVW.2019.00322
   Dhamecha TI, 2013, INT CONF BIOMETR
   Dhamecha TI, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099212
   Du H, 2021, IEEE SIGNAL PROC LET, V28, P768, DOI 10.1109/LSP.2021.3071663
   Dubey SR, 2016, IEEE J BIOMED HEALTH, V20, P1139, DOI 10.1109/JBHI.2015.2437396
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   Ge S., 2017, IEEE C COMPUT VIS PA, P2682, DOI DOI 10.1109/CVPR.2017.53
   Hansley EE, 2018, IET BIOMETRICS, V7, P215, DOI 10.1049/iet-bmt.2017.0210
   Hariri W, 2022, SIGNAL IMAGE VIDEO P, V16, P605, DOI 10.1007/s11760-021-02050-w
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herpers R, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P212, DOI 10.1109/AFGR.1996.557266
   Ibrahim A, 2018, SIGNAL IMAGE VIDEO P, V12, P711, DOI 10.1007/s11760-017-1212-6
   Iqbal M, 2019, PATTERN RECOGN LETT, V128, P414, DOI 10.1016/j.patrec.2019.10.002
   Khan MJ, 2022, VISUAL COMPUT, V38, P509, DOI 10.1007/s00371-020-02031-z
   Kowalski M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22135012
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar S., 2018, 2018 5 IEEE UTT PRAD, P1
   Kumar S, 2020, IEEE SIGNAL PROC LET, V27, P975, DOI 10.1109/LSP.2020.2996429
   Makhoul J., 1999, P DARPA BROADCAST NE, V249, P252
   Meden B, 2021, IEEE T INF FOREN SEC, V16, P4147, DOI 10.1109/TIFS.2021.3096024
   Min R, 2014, SCI WORLD J, DOI 10.1155/2014/519158
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   Neto PCP, 2022, IEEE ACCESS, V10, P86222, DOI 10.1109/ACCESS.2022.3199014
   Peng M, 2016, INFORMATION, V7, DOI 10.3390/info7040061
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Socolinsky DA, 2004, PROC CVPR IEEE, P1012
   Socolinsky DA, 2003, COMPUT VIS IMAGE UND, V91, P72, DOI 10.1016/S1077-3142(03)00075-4
   Socolinsky DA, 2002, INT C PATT RECOG, P217, DOI 10.1109/ICPR.2002.1047436
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vu HN, 2022, APPL INTELL, V52, P5497, DOI 10.1007/s10489-021-02728-1
   Wang C., 2021, 2021 IEEE INT JOINT, P1
   Wei X, 2018, INT J MACH LEARN CYB, V9, P383, DOI 10.1007/s13042-015-0427-5
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Wu Z, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON OPTOELECTRONICS AND IMAGE PROCESSING (ICOIP 2016), P6, DOI 10.1109/OPTIP.2016.7528489
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhang YX, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108522
NR 56
TC 3
Z9 3
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2023
VL 132
AR 104646
DI 10.1016/j.imavis.2023.104646
EA FEB 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA D0LN3
UT WOS:000965729000001
DA 2024-07-18
ER

PT J
AU Shang, JH
   Wei, P
   Li, H
   Zheng, NN
AF Shang, Jiahui
   Wei, Ping
   Li, Huan
   Zheng, Nanning
TI Multi-scale interaction transformer for temporal action proposal
   generation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Temporal action proposal generation; Transformer; Multi-scale
   interaction; Feature pyramids
ID RECOGNITION; VIDEO
AB Temporal action proposal generation is to localize the time intervals with actions in untrimmed videos. Action instances in untrimmed videos have dramatically varied temporal scales which brings about great challenges for temporal action proposal generation. While temporal action proposal generation has achieved tremendous progress over the past years, multi-scale issue in action proposal generation is still an open problem. In this paper, we propose a Multi-scale Interaction Transformer (MSIT) architecture, which adopts a directly set prediction method to work out the temporal action proposal generation task. MSIT constructs multi-scale feature pyramids and incorporates a novel multi-scale mechanism into Transformer framework. A customized top-down interaction structure is designed to perform self-scale attention and cross-scale attention at different levels of the feature pyramids. Through the top-down interaction, the semantic and location information in each feature level is strengthened and therefore the proposal generation performance can be improved. Furthermore, to model the accurate action locations for each frame, we incorporate an actionness prediction structure to constrain the features output from the encoder. The proposed method was tested on two challenging datasets: THUMOS14 and ActivityNet-1.3. Experiments show that our method achieves comparable performance with state-of-the-art methods. Extensive studies and visualizations also demonstrate the strength of our method. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Shang, Jiahui; Wei, Ping; Li, Huan; Zheng, Nanning] Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Peoples R China.
C3 Xi'an Jiaotong University
RP Wei, P (corresponding author), Xi An Jiao Tong Univ, Inst Artificial Intelligence & Robot, Xian, Peoples R China.
EM pingwei@xjtu.edu.cn
FU National Key Research and Development Program [2020YFB1406900]; National
   Natural Science Foundation of China [61876149, 62088102]; Fundamental
   Research Funds for the Central Universities
FX This research was supported by the grants National Key Research and
   Development Program (No. 2020YFB1406900) , National Natural Science
   Foundation of China (No. 61876149, No. 62088102) , and the Fundamental
   Research Funds for the Central Universities.
CR Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Gao JL, 2020, AAAI CONF ARTIF INTE, V34, P10810
   Gao JY, 2018, LECT NOTES COMPUT SC, V11206, P70, DOI 10.1007/978-3-030-01216-8_5
   Gao JY, 2017, IEEE I CONF COMP VIS, P3648, DOI 10.1109/ICCV.2017.392
   Gu Jiatao, 2018, ICLR
   He JY, 2021, NEUROCOMPUTING, V444, P319, DOI 10.1016/j.neucom.2020.05.118
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Kingma D. P, 2015, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1412.6980
   Li YH, 2021, NEUROCOMPUTING, V454, P373, DOI 10.1016/j.neucom.2021.04.121
   Lin CM, 2021, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR46437.2021.00333
   Lin CRN, 2020, AAAI CONF ARTIF INTE, V34, P11499
   Lin T., 2017, P IEEE INT C COMP VI
   Lin TW, 2019, IEEE I CONF COMP VIS, P3888, DOI 10.1109/ICCV.2019.00399
   Lin TW, 2018, LECT NOTES COMPUT SC, V11208, P3, DOI 10.1007/978-3-030-01225-0_1
   Lin TW, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P988, DOI 10.1145/3123266.3123343
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu QY, 2020, AAAI CONF ARTIF INTE, V34, P11612
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y., P IEEE CVF C COMP VI, P3604
   Long FC, 2019, PROC CVPR IEEE, P344, DOI 10.1109/CVPR.2019.00043
   Lu CK, 2021, INT C PATT RECOG, P4781, DOI 10.1109/ICPR48806.2021.9412081
   Ming Y, 2021, NEUROCOMPUTING, V450, P362, DOI 10.1016/j.neucom.2021.03.120
   Parmar N, 2018, PR MACH LEARN RES, V80
   Qing ZW, 2021, PROC CVPR IEEE, P485, DOI 10.1109/CVPR46437.2021.00055
   Ramachandran P., 2019, INT C NEURAL INFORM
   Su H., 2020, P AAAI C ARTIFICIAL
   Tan J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13506, DOI 10.1109/ICCV48922.2021.01327
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JM, 2021, NEUROCOMPUTING, V451, P265, DOI 10.1016/j.neucom.2021.04.071
   Wang L, 2021, NEUROCOMPUTING, V434, P211, DOI 10.1016/j.neucom.2020.12.126
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wei P, 2017, IEEE T PATTERN ANAL, V39, P1165, DOI 10.1109/TPAMI.2016.2574712
   Wei P, 2013, IEEE I CONF COMP VIS, P3136, DOI 10.1109/ICCV.2013.389
   Yang L, 2020, IEEE T IMAGE PROCESS, V29, P8535, DOI 10.1109/TIP.2020.3016486
   Yueran Bai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P121, DOI 10.1007/978-3-030-58604-1_8
   Zeng R., 2021, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Zhang W, 2021, NEUROCOMPUTING, V444, P16, DOI 10.1016/j.neucom.2021.02.085
   Zhang YY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13557, DOI [10.1109/iccv48922.2021.01332, 10.1109/ICCV48922.2021.01332]
   Zhang Z., 2018, P EUR C COMP VIS ECC, P269
   Zhao Y., IEEE I C COMP VIS 20, P2914
   Zhenzhi Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P34, DOI 10.1007/978-3-030-58595-2_3
   Zhu LC, 2017, INT J COMPUT VISION, V124, P409, DOI 10.1007/s11263-017-1033-7
   Zhu X., 2021, INT C LEARNING REPRE
NR 48
TC 4
Z9 4
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104589
DI 10.1016/j.imavis.2022.104589
EA DEC 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA C7ZT0
UT WOS:000964061500001
DA 2024-07-18
ER

PT J
AU Su, W
   Zhang, HF
   Su, Y
   Yu, J
   Wang, ZF
AF Su, Wen
   Zhang, Haifeng
   Su, Yuan
   Yu, Jun
   Wang, Zengfu
TI Monocular depth estimation with spatially coherent sliced network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth estimation; Monocular images; Spatial coherence; Sliced depth
AB Monocular depth estimation from a single still image is one of the most challenging fundamental problems in scenes understanding. As a pixel level regression problem, the inherent continuous large range of depth itself causes three main difficulties: (1) The unbalance between large value and small value during regressing; (2) Exploiting multi-scale contextual information; (3) Preserving spatial and semantic structures. To overcome these difficulties, this paper presents a novel spatially coherent sliced network for monocular depth estimation (SCS-Net). It first uses feature pyramids network to form the feature fusions of hierarchical feature maps. Then, the depth is sliced to supervise the estimation in different ranges generated from the feature fusions of multi-scale contexts. The holistic depth is invoked as the supervised signal of aggregated feature maps to ensure the learning of global structure of the scene. The self-spatial-attention mechanism further takes advantage of the semantics of objects and the spatial pixel relations to maintain the coherence of space and semantics in depth sliced estimation. Finally, the regulations of second-order depth information further make the estimated bound-aries not too smooth. Numerous ablation experiments and comparisons on three popular indoor and outdoor benchmark datasets indicate the effectiveness and robustness of the proposed approach.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Su, Wen] Zhejiang Sci Tech Univ, Fac Mech Engn & Automation, Hangzhou 310018, Zhejiang, Peoples R China.
   [Zhang, Haifeng; Yu, Jun; Wang, Zengfu] Univ Sci & Technol China, Dept Automation, Hefei 230016, Anhui, Peoples R China.
   [Su, Yuan] Xian Technol Univ, Sch Optoelect Engn, Xian 710000, Shaanxi, Peoples R China.
C3 Zhejiang Sci-Tech University; Chinese Academy of Sciences; University of
   Science & Technology of China, CAS; Xi'an Technological University
RP Su, W (corresponding author), Zhejiang Sci Tech Univ, Fac Mech Engn & Automation, Hangzhou 310018, Zhejiang, Peoples R China.
EM wensu@zstu.edu.cn; hfz@mail.ustc.edu.cn; yuansu0329@gmail.com;
   harryjun@ustc.edu.cn; zfwang@ustc.edu.cn
RI Wang, Zengfu/C-8618-2017
OI Wang, Zengfu/0000-0003-0424-3010; Su, Wen/0000-0001-6787-4384
FU National Natural Science Foundation of China [62006209]; Natural Science
   Foundation of Zhejiang Province of China [LQ20F020001]; Science
   Foundation of Zhejiang Sci-Tech University [18022225-Y]; Strategic
   Priority Research Program of the Chinese Academy of Sciences
   [XDC08020400]
FX * This work is supported by the National Natural Science Foundation of
   China No. 62006209, Natural Science Foundation of Zhejiang Province of
   China No. LQ20F020001, the Science Foundation of Zhejiang Sci-Tech
   University No. 18022225-Y and Strategic Priority Research Program of the
   Chinese Academy of Sciences No. XDC08020400. *
CR [Anonymous], 2010, NIPS
   Borghi G, 2020, ADV INTELL SYST COMP, V1131, P104, DOI 10.1007/978-3-030-39512-4_17
   Cao YZH, 2018, IEEE T CIRC SYST VID, V28, P3174, DOI 10.1109/TCSVT.2017.2740321
   Chen XT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P694
   da Silva SPP, 2020, IEEE SENS J, V20, P12040, DOI 10.1109/JSEN.2020.2964735
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Fanello SR, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601223
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hedau V, 2010, LECT NOTES COMPUT SC, V6316, P224, DOI 10.1007/978-3-642-15567-3_17
   Hu JJ, 2019, IEEE WINT CONF APPL, P1043, DOI 10.1109/WACV.2019.00116
   Jiao JB, 2018, LECT NOTES COMPUT SC, V11219, P55, DOI 10.1007/978-3-030-01267-0_4
   Johnston A, 2020, PROC CVPR IEEE, P4755, DOI 10.1109/CVPR42600.2020.00481
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Kim Y, 2018, IEEE T IMAGE PROCESS, V27, P4131, DOI 10.1109/TIP.2018.2836318
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Li B, 2015, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2015.7298715
   Li J, 2017, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2017.365
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu J, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103922
   Mathew A, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103934
   Nekrasov V, 2019, IEEE INT CONF ROBOT, P7101, DOI [10.1109/icra.2019.8794220, 10.1109/ICRA.2019.8794220]
   Poggi M., P IEEECVF C COMPUTER, P3227
   Ramamonjisoa M., 2020, P IEEE CVF C COMP VI, P14648
   Ramirez PZ, 2019, LECT NOTES COMPUT SC, V11363, P298, DOI 10.1007/978-3-030-20893-6_19
   Roy A, 2016, PROC CVPR IEEE, P5506, DOI 10.1109/CVPR.2016.594
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Schwing AG, 2012, LECT NOTES COMPUT SC, V7577, P299, DOI 10.1007/978-3-642-33783-3_22
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sun Y, 2020, IEEE IPCCC, DOI 10.1109/IPCCC50635.2020.9391527
   Tian Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P90, DOI 10.1007/978-3-030-58568-6_6
   Wang LJ, 2020, PROC CVPR IEEE, P538, DOI 10.1109/CVPR42600.2020.00062
   Wang P, 2015, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2015.7298897
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xia ZH, 2020, PROC CVPR IEEE, P62, DOI 10.1109/CVPR42600.2020.00014
   Xu D., P IEEE CONFER ENCE C, P5354
   Xu D, 2018, PROC CVPR IEEE, P3917, DOI 10.1109/CVPR.2018.00412
   Yude Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12272, DOI 10.1109/CVPR42600.2020.01229
   Zhang ZY, 2018, IEEE T IMAGE PROCESS, V27, P3691, DOI 10.1109/TIP.2018.2821979
   Zhou WH, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103874
NR 43
TC 2
Z9 2
U1 3
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104487
DI 10.1016/j.imavis.2022.104487
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800012
DA 2024-07-18
ER

PT J
AU Wu, BY
   Wang, YX
AF Wu, Bingyuan
   Wang, Yongxiong
TI Rich global feature guided network for monocular depth estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Monocular depth estimation; Transformer; Large kernel convolution
   attention; Global feature
AB Monocular depth estimation is a classical but challenging task in the field of computer vision. In recent years, Convolutional Neural Network (CNN) based models have been developed to estimate high-quality depth map from a single image. Most recently, some Transformer based models have led to great improvements. All the re-searchers are looking for a better way to handle the global processing of information which is crucial for depth relation inference but of high computational complexity. In this paper, we take advantage of both the Trans-former and CNN then propose a novel network architecture, called Rich Global Feature Guided Network (RGFN), with which rich global features are extracted from both encoder and decoder. The framework of the RGFN is the typical encoder-decoder for dense prediction. A hierarchical transformer is implemented as the en-coder to capture multi-scale contextual information and model long-range dependencies. In the decoder, the Large Kernel Convolution Attention (LKCA) is adopted to extract global features from different scales and guide the network to recover fine depth maps from low spatial resolution feature maps progressively. What's more, we apply the depth-specific data augmentation method, Vertical CutDepth, to boost the performance. Ex-perimental results on both the indoor and outdoor datasets demonstrate the superiority of the RGFN compared to other state-of-the-art models. Compared with the most recent method AdaBins, RGFN improves the RMSE score by 4.66% on the KITTI dataset and 4.67% on the NYU Depth v2 dataset.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Wu, Bingyuan; Wang, Yongxiong] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Wang, YX (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai 200093, Peoples R China.
EM wyxiong@usst.edu.cn
RI Yuan, Yu/KBQ-0606-2024
FU Natural Science Foundation of Shanghai [22ZR1443700]
FX Acknowledgements This work is sponsored by Natural Science Foundation of
   Shanghai under Grant No. 22ZR1443700.
CR Bhat SF, 2021, PROC CVPR IEEE, P4008, DOI 10.1109/CVPR46437.2021.00400
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Chibane J, 2020, PROC CVPR IEEE, P6968, DOI 10.1109/CVPR42600.2020.00700
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Eigen D, 2014, ADV NEUR IN, V27
   Feng D, 2021, IEEE T INTELL TRANSP, V22, P1341, DOI 10.1109/TITS.2020.2972974
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Guo MH, 2022, Arxiv, DOI arXiv:2202.09741
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiao JB, 2018, LECT NOTES COMPUT SC, V11219, P55, DOI 10.1007/978-3-030-01267-0_4
   Kim D., 2022, arXiv
   Kingma D. P., 2014, arXiv
   Laga H, 2022, IEEE T PATTERN ANAL, V44, P1738, DOI 10.1109/TPAMI.2020.3032602
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee Jin Han, 2019, arXiv
   Paszke A, 2019, ADV NEUR IN, V32
   Ranftl R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12159, DOI 10.1109/ICCV48922.2021.01196
   Ruofei Du, 2020, UIST '20: Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology, P829, DOI 10.1145/3379337.3415881
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saxena A., 2005, ADV NEURAL INFORM PR, V18
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tan MX, 2019, PR MACH LEARN RES, V97
   van Dijk T, 2019, IEEE I CONF COMP VIS, P2183, DOI 10.1109/ICCV.2019.00227
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang W., 2021, P IEEECVF INT C COMP
   Xie EZ, 2021, ADV NEUR IN, V34
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
NR 34
TC 5
Z9 5
U1 4
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2022
VL 125
AR 104520
DI 10.1016/j.imavis.2022.104520
EA JUL 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3Y7JW
UT WOS:000843898700003
DA 2024-07-18
ER

PT J
AU Bouraffa, T
   Feng, ZH
   Yan, LP
   Xia, YQ
   Xiao, B
AF Bouraffa, Tayssir
   Feng, Zihang
   Yan, Liping
   Xia, Yuanqing
   Xiao, Bo
TI Multi-feature fusion tracking algorithm based on peak-context learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Correlation filter; Kernel trick; Elastic net;
   Context-aware; Feature fusion
ID OBJECT TRACKING
AB Object tracking is considered a critical process in most applications of computer vision. Recently, tracking algorithms that include correlation filter in their frameworks have gained massive popularity due to their high efficiency. The previous algorithms aim to learn the correlation filter by leveraging over all features of the target and its neighbors. However, in this paper, a new tracking algorithm that merges an elastic net constraint and a contextual information into the training scheme is proposed to estimate the target location successfully. The novel optimization problem can significantly strengthen the peak value of the target and effectively eliminate the distractive features. Moreover, most of the correlation filter trackers only use one single feature, which has poor ability under a sophisticated environment. For this reason, a multi-feature fusion strategy is proposed in the framework that embeds multiple features to enhance the tracking performance. Consequently, a multi- scale adaptive model is implemented to improve the tracking stability through scale variations. Besides, an updating mechanism is applied within the proposed framework to reduce the tracking drift. Extensive quantitative and qualitative experiments on challenging benchmarks show that this unified tracker model achieves impressive performance compared to correlation filter and deep trackers.(c) 2022 Published by Elsevier B.V.
C1 [Bouraffa, Tayssir; Feng, Zihang; Yan, Liping; Xia, Yuanqing] Beijing Inst Technol, Sch Automat, Key Lab Intelligent Control Decis Complex Syst, Beijing 100081, Peoples R China.
   [Xiao, Bo] Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Beijing 100876, Peoples R China.
C3 Beijing Institute of Technology; Beijing University of Posts &
   Telecommunications
RP Yan, LP (corresponding author), Beijing Inst Technol, Sch Automat, Key Lab Intelligent Control Decis Complex Syst, Beijing 100081, Peoples R China.
EM ylp@bit.edu.cn
OI xia, yuqin/0009-0007-4022-9175
FU National Key Research and Develop-ment Program of China
   [2018AAA0103203]; National Natural Science Foundation of China
   [62073036, 62076031]; Beijing Natural Science Foundation of China
   [4202071]
FX Acknowledgments This work was supported by the National Key Research and
   Develop-ment Program of China under Grant 2018AAA0103203, the National
   Natural Science Foundation of China under Grant 62073036 and 62076031,
   and the Beijing Natural Science Foundation of China under Grant 4202071.
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Bouraffa T, 2021, IEEE T CYBERNETICS, V51, P5105, DOI 10.1109/TCYB.2019.2935347
   Chen Z, 2018, INFORMATION, V9, DOI 10.3390/info9100241
   Choi J, 2018, PROC CVPR IEEE, P479, DOI 10.1109/CVPR.2018.00057
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Danelljan M., 2014, BRIT MACH VIS C, P1, DOI DOI 10.5244/C.28.65
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Fan H, 2017, IEEE T CIRC SYST VID, V27, P1018, DOI 10.1109/TCSVT.2016.2515738
   Fu Z., 2021, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P13774
   Gundogdu E, 2018, IEEE T IMAGE PROCESS, V27, P2526, DOI 10.1109/TIP.2018.2806280
   Guo DY, 2021, PROC CVPR IEEE, P9538, DOI 10.1109/CVPR46437.2021.00942
   Hare S, 2016, IEEE T PATTERN ANAL, V38, P2096, DOI 10.1109/TPAMI.2015.2509974
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kass M, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778837
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Kristan M, 2016, IEEE T PATTERN ANAL, V38, P2137, DOI 10.1109/TPAMI.2016.2516982
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Linyu Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P759, DOI 10.1007/978-3-030-58555-6_45
   Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI [10.1109/TPAMI.2018.2865311, 10.1109/INTMAG.2018.8508195]
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Nousi P, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103933
   Qiang W., ARXIV PREPRINT ARXIV
   Shuai J., 2021, PROC IEEE C COMPUT V, P6709
   Shuai Jia, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P69, DOI 10.1007/978-3-030-58529-7_5
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Sui Y, 2018, IEEE T CYBERNETICS, V48, P1290, DOI 10.1109/TCYB.2017.2690860
   Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang N, 2019, PROC CVPR IEEE, P1308, DOI 10.1109/CVPR.2019.00140
   Weiss B, 2006, ACM T GRAPHIC, V25, P519, DOI 10.1145/1141911.1141918
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu T., 2021, COMPUTING RES REPOSI
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9836, DOI 10.1109/ICCV48922.2021.00971
   Zhang Z., 2021, P IEEECVF INT C COMP
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou JH, 2020, AAAI CONF ARTIF INTE, V34, P13017
   Zhou Z., IEEE CVF INT C COMP, P9866
NR 53
TC 6
Z9 6
U1 2
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104468
DI 10.1016/j.imavis.2022.104468
EA MAY 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L9ND
UT WOS:000799606300006
DA 2024-07-18
ER

PT J
AU Cetinkaya, B
   Kalkan, S
   Akbas, E
AF Cetinkaya, Bedrettin
   Kalkan, Sinan
   Akbas, Emre
TI Does depth estimation help object detection?
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Depth estimation; RGB-D
AB Ground-truth depth, when combined with color data, helps improve object detection accuracy over baseline models that only use color. However, estimated depth does not always yield improvements. Many factors affect the performance of object detection when estimated depth is used. In this paper, we comprehensively investigate these factors with detailed experiments, such as using ground-truth vs. estimated depth, effects of different state -of-the-art depth estimation networks, effects of using different indoor and outdoor RGB-D datasets as training data for depth estimation, and different architectural choices for integrating depth to the base object detector network. We propose an early concatenation strategy of depth, which yields higher mAP than previous works' while using significantly fewer parameters. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Cetinkaya, Bedrettin; Kalkan, Sinan; Akbas, Emre] Middle East Tech Univ Ankara, Dept Comp Engn, Ankara, Turkey.
C3 Middle East Technical University
RP Cetinkaya, B (corresponding author), Middle East Tech Univ Ankara, Dept Comp Engn, Ankara, Turkey.
EM bedrettin.cetinkaya@metu.edu.tr
RI Akbas, Emre/B-6857-2008; KALKAN, Sinan/AAC-3625-2019
OI Akbas, Emre/0000-0002-3760-6722; Kalkan, Sinan/0000-0003-0915-5917
FU Scientific and Technological Research Council of Turkey (TUBITAK)
   [117E054]
FX This work was supported by the Scientific and Technological Research
   Council of Turkey (TUBITAK) through the project title "Object Detection
   in Videos with Deep Neural Networks" with grant number 117E054. The
   numerical calculations reported in this paper were fully performed at
   TUBITAK ULAKBIM, High Performance and Grid Computing Center (TRUBA
   resources).
CR [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2008, The PASCAL visual object classes challenge 2008 (VOC2008) results
   [Anonymous], 2012, LECT NOTES COMPUT SC, DOI [10.1007/978-3-642-33715-4_54, DOI 10.1007/978-3-642-33715-4_54]
   Cao YZH, 2017, IEEE T IMAGE PROCESS, V26, P836, DOI 10.1109/TIP.2016.2621673
   Chen Xiaozhi., P IEEE C COMPUTER VI, P1907
   Ding M., 2020, P IEEE CVF C COMP VI, P1000
   Eigen D., P IEEE INT C COMPUTE, P2650
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Girshick R., 2014, P 2014 IEEE C COMPUT, P580, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R., P IEEE INT C COMPUTE, P1440
   Godard C., 2017, P IEEE C COMPUTER VI
   Gupta S., P IEEE C COMPUTER VI, P564
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hou SH, 2018, NEUROCOMPUTING, V286, P58, DOI 10.1016/j.neucom.2018.01.055
   Hu J., IEEE WINTER C APPL C, P1043
   Hu J., ARXIV PREPRINT ARXIV
   Kerl C, 2013, IEEE INT CONF ROBOT, P3748, DOI 10.1109/ICRA.2013.6631104
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lasinger K., ARXIV PREPRINT ARXIV
   Li P., P IEEECVF C COMPUTER, P7644
   Li Z., P IEEE C COMPUTER VI, P2041
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Lin T.Y., 2017, P IEEE C COMP VIS PA, P2117
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YX, 2021, IEEE ROBOT AUTOM LET, V6, P919, DOI 10.1109/LRA.2021.3052442
   Miangoleh S. Mahdi H., 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P9680, DOI 10.1109/CVPR46437.2021.00956
   Ranftl R., ARXIV PREPRINT ARXIV
   Reading Cody., Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P8555
   Redmon J., 2016, P IEEE C COMP VIS PA, P779, DOI DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren XF, 2012, PROC CVPR IEEE, P2759, DOI 10.1109/CVPR.2012.6247999
   Saxena A., COMPUTER VISION 2007, P1
   Saxena A., 2006, NIPS, P1161, DOI DOI 10.1109/TPAMI.2015.2505283A
   Shi YG, 2022, NEUROCOMPUTING, V471, P219, DOI 10.1016/j.neucom.2021.11.048
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song S., P IEEE C COMPUTER VI, P567
   Watson J., P IEEE INT C COMPUTE, P2162
   Zheng C., P EUR C COMP VIS ECC, P767
NR 41
TC 1
Z9 1
U1 4
U2 43
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104427
DI 10.1016/j.imavis.2022.104427
EA MAR 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0Z8DH
UT WOS:000791301700002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Guo, AB
   Guo, LJ
   Zhang, R
   Wang, YR
   Gao, SC
AF Guo, Aibin
   Guo, Lijun
   Zhang, Rong
   Wang, Yirui
   Gao, Shangce
TI Self-trained prediction model and novel anomaly score mechanism for
   video anomaly detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Anomaly detection; Unsupervised method; Memory module; Reconstruction;
   Self-training mechanism
ID EVENT DETECTION
AB Video anomaly detection is important in various practical applications. This paper proposes an unsupervised method for video anomaly detection. In the core of the method lies a new prediction model for anomaly detection with novel anomaly score mechanism and self-training mechanism combined with prediction model. In the first stage, we use two conventional unsupervised anomaly detection methods to obtain pseudo normal and anoma-lous frames from the original unlabeled data. In the second stage, we train the prediction model with the pseudo normal frames to learn normal patterns. In the last stage, a three-branch decision module is constructed using prediction model and decision function to calculate the anomaly score of frames and update the pseudo frames for subsequent iterative training. The model then enters the second stage, until the last iterative training is com-pleted. After several iterative training and evaluations, the optimal anomaly scores of the original unlabeled data are finally obtained, and a stable model is generated at the same time. Experimental results on four real-world video datasets demonstrate that the proposed method outperforms state-of-the-art methods without labeled data by a significant margin.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Guo, Aibin; Guo, Lijun; Zhang, Rong; Wang, Yirui] Ningbo Univ, Ningbo, Peoples R China.
   [Gao, Shangce] Univ Toyama, Toyama, Japan.
C3 Ningbo University; University of Toyama
RP Guo, LJ (corresponding author), Ningbo Univ, Ningbo, Peoples R China.
EM guolijun@nbu.edu.cn
RI Wang, Yirui/AAI-4618-2020; GAO, Shangce/I-3422-2012
OI Wang, Yirui/0000-0001-5767-3343; GAO, Shangce/0000-0001-5042-3261
FU Zhejiang Provincial Public Welfare Technology Research Project
   [LGF21F020008]; Ningbo Municipal Natural Science Foundation of China
   [2018A610057]
FX Acknowledgment This research work is supported by the Zhejiang
   Provincial Public Welfare Technology Research Project (No. LGF21F020008)
   and the Ningbo Municipal Natural Science Foundation of China
   (No.2018A610057) .
CR Abati D, 2019, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2019.00057
   Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   [Anonymous], 1997, NEURAL COMPUT
   Bin Zhao, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3313, DOI 10.1109/CVPR.2011.5995524
   Borghesi A, 2019, AAAI CONF ARTIF INTE, P9428
   Cheng KW, 2015, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2015.7298909
   Chong YS, 2017, LECT NOTES COMPUT SC, V10262, P189, DOI 10.1007/978-3-319-59081-3_23
   Cong Y, 2011, PROC CVPR IEEE, P1807, DOI 10.1109/CVPR.2011.5995434
   Dodge J., 2016, P 2016 C EMPIRICAL M
   Fan CY, 2019, PROC CVPR IEEE, P1999, DOI 10.1109/CVPR.2019.00210
   Feng J.-C, P IEEE CVF C COMP VI, P14009
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Ionescu RT, 2017, IEEE I CONF COMP VIS, P2914, DOI 10.1109/ICCV.2017.315
   King DB, 2015, ACS SYM SER, V1214, P1
   Kingma DP, 2013, ARXIV
   Köpüklü O, 2021, IEEE WINT CONF APPL, P91, DOI 10.1109/WACV48630.2021.00014
   Kriegel H.-P., 2011, P 11 SIAM INT C DAT
   Krishnan Dilip, ARXIV PREPRINT ARXIV
   Kumar A, 2016, PR MACH LEARN RES, V48
   Lin H., 2016, P 24 ACM INT C MULT, P536
   Liu FT, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2133360.2133363
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu Y., BMVC 2018, P71
   Loshchilov I, 2016, ARXIV
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Lv H, P IEEE CVF C COMP VI, P15425
   Mansour RF, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104229
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   Pang G, P IEEE CVF C COMP VI, P12173
   Pang GS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439950
   Pang GS, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOP (ICDMW), P623, DOI 10.1109/ICDMW.2015.62
   Park Hyunjong, 2020, IEEECVF C COMPUTER V, P2
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Ramachandra B, 2020, IEEE WINT CONF APPL, P2587, DOI 10.1109/WACV45572.2020.9093417
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sabokrou M, 2018, PROC CVPR IEEE, P3379, DOI 10.1109/CVPR.2018.00356
   Santoro A, 2016, PR MACH LEARN RES, V48
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun QR, 2017, PATTERN RECOGN, V64, P187, DOI 10.1016/j.patcog.2016.09.016
   Nguyen TN, 2019, IEEE I CONF COMP VIS, P1273, DOI 10.1109/ICCV.2019.00136
   Veeramachaneni K, 2016, 2016 IEEE 2ND INTERNATIONAL CONFERENCE ON BIG DATA SECURITY ON CLOUD (BIGDATASECURITY), IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE AND SMART COMPUTING (HPSC), AND IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT DATA AND SECURITY (IDS), P49, DOI 10.1109/BigDataSecurity-HPSC-IDS.2016.79
   Wu P., 2020, COMPUTER VISION ECCV, P322
   Xu D., 2015, arXiv preprint arXiv:1510.01553
   Zhang JG, 2019, IEEE IMAGE PROC, P4030, DOI [10.1109/ICIP.2019.8803657, 10.1109/icip.2019.8803657]
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhu X, 2009, Synthesis Lectures on Artificial Intelligence and Machine Learning, V3, P1, DOI 10.1007/978-3-031-01548-9
NR 53
TC 14
Z9 15
U1 2
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104391
DI 10.1016/j.imavis.2022.104391
EA FEB 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400010
DA 2024-07-18
ER

PT J
AU Shi, W
   Liu, H
   Liu, MY
AF Shi, Wei
   Liu, Hong
   Liu, Mengyuan
TI IRANet: Identity-relevance aware representation for cloth-changing
   person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cloth-changing person re-identification; Identity-relevance; Feature
   representation
AB Existing person re-identification methods mainly focus on searching the target person across disjoint camera views in a short period of time. With this setting, these methods rely on the assumption that both query and gallery images of the same person have the same clothing. To tackle the challenges of clothing changes over a long duration, this paper proposes an identity-relevance aware neural network (IRANet) for cloth-changing person re-identification. Specifically, a human head detection module is designed to localize the human head part with the help of the human parsing estimation. The detected human head part contains abundant identity information, including facial features and head type. Then, raw person images in conjunction with detected head areas are respectively transformed into feature representation with the feed-forward network. The learned features of raw person images contain more attributes of global context, meanwhile the learned features of head areas contain more identity-relevance attributes. Finally, a head-guided attention module is employed to guide the global features learned by raw person images to focus more on the identity-relevance head areas. The proposed method achieves mAP accuracy of 25.4% on the Celeb-reID-light dataset, 19.0% on the Celeb-reID dataset, and 53.0% (Cloth-changing setting) on the PRCC dataset, which shows the superiority of our approach for the cloth changing person re-identification task. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Shi, Wei; Liu, Hong] Peking Univ, Shenzhen Grad Sch, Key Lab Machine Percept, Beijing 100871, Peoples R China.
   [Liu, Mengyuan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Shenzhen 518107, Peoples R China.
C3 Peking University; Sun Yat Sen University
RP Liu, H (corresponding author), Peking Univ, Shenzhen Grad Sch, Key Lab Machine Percept, Beijing 100871, Peoples R China.
EM pkusw@pku.edu.cn; hongliu@pku.edu.cn; nkliuyifang@gmail.com
RI Shi, Wei/AAV-5582-2020; Liu, Mengyuan/HZL-2276-2023
OI Liu, Hong/0000-0002-7498-6541
FU National Key R&D Program of China [2020AAA0108904]; Science and
   Technology Plan of Shenzhen [JCYJ20190808182209321]
FX This work is supported by National Key R&D Program of China (No.
   2020AAA0108904), and Science and Technology Plan of Shenzhen (No.
   JCYJ20190808182209321).
CR [Anonymous], 2007, P IEEE INT WORKSH PE
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen DP, 2015, PROC CVPR IEEE, P1565, DOI 10.1109/CVPR.2015.7298764
   Chen D, 2018, LECT NOTES COMPUT SC, V11211, P764, DOI 10.1007/978-3-030-01234-2_45
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Fangbin Wan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P3620, DOI 10.1109/CVPRW50498.2020.00423
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Herzog F., P IEEE INT C IM PROC, P2021
   Hong PX, 2021, PROC CVPR IEEE, P10508, DOI 10.1109/CVPR46437.2021.01037
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang Y, 2020, IEEE T CIRC SYST VID, V30, P3459, DOI 10.1109/TCSVT.2019.2948093
   Jin X., CLOTH CHANGING PERSO
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li YJ, 2021, IEEE WINT CONF APPL, P2431, DOI 10.1109/WACV48630.2021.00248
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Munjal B, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103932
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Qian X., 2020, P AS C COMP VIS
   Quispe R, 2021, INT C PATT RECOG, P2980, DOI 10.1109/ICPR48806.2021.9412017
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Shi W, 2020, NEUROCOMPUTING, V415, P1, DOI 10.1016/j.neucom.2020.07.062
   Shizhen Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P647, DOI 10.1007/978-3-030-58539-6_39
   Shu XJ, 2021, IEEE SIGNAL PROC LET, V28, P1365, DOI 10.1109/LSP.2021.3091924
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang H., IMAGE VISION COMPUT, V111
   Wang X, 2019, PROC CVPR IEEE, P5017, DOI 10.1109/CVPR.2019.00516
   Xu BQ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P673, DOI 10.1145/3394171.3414056
   Xu W., P INT JOINT C ART IN, P2021
   Xue J, 2018, IEEE COMPUT SOC CONF, P2193, DOI 10.1109/CVPRW.2018.00285
   Yang QZ, 2021, IEEE T PATTERN ANAL, V43, P2029, DOI 10.1109/TPAMI.2019.2960509
   Ye HR, 2021, IEEE T IMAGE PROCESS, V30, P1583, DOI 10.1109/TIP.2020.3045261
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhou JM, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103931
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
NR 47
TC 16
Z9 18
U1 4
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104335
DI 10.1016/j.imavis.2021.104335
EA NOV 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA XF7PZ
UT WOS:000724261200003
DA 2024-07-18
ER

PT J
AU Zhang, J
   Shi, YJ
   Zhang, Q
   Cui, L
   Chen, Y
   Yi, YG
AF Zhang, Jin
   Shi, Yanjiao
   Zhang, Qing
   Cui, Liu
   Chen, Ying
   Yi, Yugen
TI Attention guided contextual feature fusion network for salient object
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; Fully convolutional neural network; Attention
   mechanism; Feature fusion
ID CONVOLUTIONAL NEURAL-NETWORK; MODEL
AB In recent years, the Convolutional Neural Network (CNN) has been widely used in various visual tasks because of its powerful feature extraction ability. Salient object detection methods based on CNN have also achieved great performance. Although a large number of feature information can be obtained through CNN, the key to improve the quality of the saliency maps is how to make full use of the high and low-level features and their relationships. Some previous works merged high and low-level features without processing the features, which resulted in the blurring of the saliency map, and even the inability to distinguish the foreground from the background in a complex environment. In order to solve the above problem, we propose an Attention guided Contextual Feature Fusion Network (ACFFNet) for salient object detection. There are mainly three modules in the proposed ACFFNet, including the Multi -field Channel Attention (MCA) module, Contextual Feature Fusion (CFF) module, and the feature Self-Refinement (SR) module. The MCA module selects features from different receptive fields, the CFF module can efficiently aggregate contextual features, and the SR module is able to repair the holes in the prediction maps caused by the contradictory response of different layers. In addition, we propose a Cross-Consistency Enhancement (CCE) loss to guide the network to focus on more detailed information and highlight the difference between foreground and background. Experimental results on six benchmark datasets show that the proposed method outperforms the state-of-the-art methods. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhang, Jin; Shi, Yanjiao; Zhang, Qing; Cui, Liu; Chen, Ying] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
   [Yi, Yugen] Jiangxi Normal Univ, Sch Software, Nanchang 330022, Jiangxi, Peoples R China.
C3 Shanghai Institute of Technology; Jiangxi Normal University
RP Shi, YJ (corresponding author), Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
EM shiyanjiao616@163.com
OI Yi, Yugen/0000-0002-1049-5022; Yi, Yugen/0000-0001-9828-0319
FU National Natural Science Foundation of China [61806126, 61903256,
   61976140, 61973307, 62062040]; Natural Science Foundation of Shanghai
   [19ZR1455300]
FX This work was supported by the National Natural Science Foundation of
   China (61806126, 61903256, 61976140, 61973307, 62062040) and Natural
   Science Foundation of Shanghai (19ZR1455300).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Chu X, 2017, PROC CVPR IEEE, P5669, DOI 10.1109/CVPR.2017.601
   Cui W, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11091044
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu KR, 2019, NEUROCOMPUTING, V356, P69, DOI 10.1016/j.neucom.2019.04.062
   Gehring J, 2017, PR MACH LEARN RES, V70
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou SH, 2017, IEEE I CONF COMP VIS, P502, DOI 10.1109/ICCV.2017.62
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XW, 2019, IEEE T INTELL TRANSP, V20, P1010, DOI 10.1109/TITS.2018.2838132
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li RH, 2017, VISUAL COMPUT, V33, P1155, DOI 10.1007/s00371-016-1278-0
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu GH, 2015, PATTERN RECOGN, V48, P2554, DOI 10.1016/j.patcog.2015.02.005
   Liu GH, 2014, PROCEEDINGS OF 2013 INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CLOUD COMPUTING COMPANION (ISCC-C), P728, DOI 10.1109/ISCC-C.2013.21
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu JJ, 2020, IEEE T IMAGE PROCESS, V29, P8652, DOI 10.1109/TIP.2020.3017352
   Liu N., 2021, IEEE INT C COMP VIS, P4722
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu Y, 2019, IEEE T CIRC SYST VID, V29, P1023, DOI 10.1109/TCSVT.2018.2823769
   Lu X., 2020, ECCV, V12348, P661, DOI DOI 10.1007/978-3-030-58580-8_39
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Miao Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P374, DOI 10.1007/978-3-030-58604-1_23
   Mohammadi S, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107303
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin X., BOUNDARY AWARE SEGME
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Seitz SM, 2002, INT J COMPUT VISION, V48, P115, DOI 10.1023/A:1016046923611
   Sheffer A, 2002, ACM T GRAPHIC, V21, P874, DOI 10.1145/571647.571651
   Simonyan K, 2015, IEEE INT C ICLR
   Soleymani R, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107146
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Truong BT, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1198302.1198305
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wang Wenguan, 2018, IEEE Trans Image Process, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784
   Wang YM, 2000, IEEE T PATTERN ANAL, V22, P738, DOI 10.1109/34.865192
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Yu YS, 2019, IEEE ACCESS, V7, P63155, DOI 10.1109/ACCESS.2019.2915607
   Zhang JX, 2014, IEEE IMAGE PROC, P1175, DOI 10.1109/ICIP.2014.7025234
   Zhang K., 2020, P IEEE CVF C COMP VI, P9050
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang W, 2010, IEEE T MULTIMEDIA, V12, P300, DOI 10.1109/TMM.2010.2047607
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhao Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P455, DOI 10.1007/978-3-030-58610-2_27
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
   Zhuge M., ARXIV PREPRINT ARXIV, V2021
NR 76
TC 20
Z9 21
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104337
DI 10.1016/j.imavis.2021.104337
EA NOV 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA XF7PZ
UT WOS:000724261200004
DA 2024-07-18
ER

PT J
AU Liu, G
   Han, J
   Rong, WZ
AF Liu, Gen
   Han, Jin
   Rong, Wenzhong
TI Feedback-driven loss function for small object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Small object detection; Loss function; Feedback-driven; Loss
   distribution balance
AB In the recent years, Convolutional Neural Network-based object detection has experienced impressive progress. Despite these improvements, the performance on the small object detection leaves much to be desired, small ob-jects are often missed or wrongly detected. The reasonable explanation is that the supervisory signals on the small objects are insufficient, and through the analysis of loss distribution over different scales in the iterations, there is a significant gap between the loss provided by the small objects and large objects. In order to balance the loss distribution and alleviate the insufficient supervisory on the small objects, a Feedback-driven loss function is presented in this paper. The Feedback-driven loss function uses the loss distribution information as the feedback signal, compared with the original loss function, the Feedback-driven loss function can supervise small objects more effectively, and train the detectors in a more balanced way. Experiments have been conducted on various detectors, backbones, training periods and datasets. Compared to the current state-of-the-art method, the novel Feedback-driven loss function can achieve 2.3% relative improvement on the Mean Average Precision, and espe-cially 3.5% improvement on the detection of small objects, with nearly no additional computation both in training and testing stages.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Gen; Han, Jin; Rong, Wenzhong] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266000, Peoples R China.
C3 Shandong University of Science & Technology
RP Liu, G (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266000, Peoples R China.
EM lg97@sdust.edu.cn; shnk123@163.com; sdhtrwz@sdust.edu.cn
FU Ministry of Education, China [201901055015]; Shandong Provincial
   Education Department [ADYAL17034]; Natural Science Foundation of
   Shandong Province [ZR2020KE023]; ShandongUniversity of Science and
   Technology [JXTD20170503]
FX The authorwould like to acknowledge the support of theMinistry of
   Education, China (201901055015), Shandong Provincial Education
   Department (ADYAL17034), Natural Science Foundation of Shandong Province
   (ZR2020KE023) and ShandongUniversity of Science and Technology
   (JXTD20170503). We also thank Yonghao Yang, Enshuang Liu and Yuan Shu
   for their valuable suggestions and favors.
CR Bai YC, 2018, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2018.00010
   Bochkovskiy A., 2020, PREPRINT
   Carion Nicolas, 2020, EUR C COMP VIS ECCV, DOI DOI 10.1007/978-3-030-58452-8_13
   Deng C., 2020, PROC INT C LEARN REP, P1
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan BB, 2021, P I MECH ENG D-J AUT, V235, P708, DOI 10.1177/0954407020950054
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong YQ, 2021, IEEE WINT CONF APPL, P1159, DOI 10.1109/WACV48630.2021.00120
   Han K., 2020, Advances in neural information processing systems, P19353
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jian Ding, 2021, ARXIV210212219
   Kisantal M., 2019, P 9 INT C ADV COMP I, DOI 10.5121/csit.2019.91713
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu ZM, 2020, IEEE COMPUT SOC CONF, P4422, DOI 10.1109/CVPRW50498.2020.00521
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Singh B, 2018, 32 C NEURAL INFORM P
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Yazdan R, 2021, ISPRS J PHOTOGRAMM, V171, P18, DOI 10.1016/j.isprsjprs.2020.10.003
   Yu X., 2020, P IEEE CVF WINT C AP
   Zhang, 2019, ARXIV PREPRINT ARXIV
   Zhang Hongyi, 2017, ARXIV171009412
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang Zhishuai, 2020, P IEEE CVF WINT C AP
   Zhou K, 2016, DESTECH TRANS COMP
   Zoph Barret, 2020, EUR C COMP VIS
NR 33
TC 20
Z9 24
U1 9
U2 78
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104197
DI 10.1016/j.imavis.2021.104197
EA MAY 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700003
DA 2024-07-18
ER

PT J
AU Kurmi, VK
   Subramanian, VK
   Namboodiri, VP
AF Kurmi, Vinod K.
   Subramanian, Venkatesh K.
   Namboodiri, Vinay P.
TI Informative discriminator for domain adaptation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CNN; Domain adaptation; Adversarial learning; Discriminator; Ensemble
   method; Object recognition
AB In this paper, we consider the problem of domain adaptation for multi-class classification, where we are provided a labeled set of examples in a source dataset and target dataset with no supervision. We tackle the mode collapse problem in adapting the classifier across domains. In this setting, we propose an adversarial learning-based approach using an informative discriminator. Our observation relies on the analysis that shows if the discriminator has access to all the information available, including the class structure present in the source dataset, then it can guide the transformation of features of the target set of classes to a more structured adapted space. Further, by training the informative discriminator using the more robust source samples, we are able to obtain better domain invariant features. Using this formulation, we achieve state-of-the-art results for the standard evaluation on benchmark datasets. We also provide detailed analysis, which shows that using all the labeled information results in an improved domain adaptation. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Kurmi, Vinod K.; Subramanian, Venkatesh K.; Namboodiri, Vinay P.] Indian Inst Technol Kanpur, Kanpur, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur
RP Kurmi, VK (corresponding author), Indian Inst Technol Kanpur, Kanpur, Uttar Pradesh, India.
EM vinodkk@iitk.ac.in; venkats@iitk.ac.in; vinaypn@iitk.ac.in
RI KURMI, VINOD K/AAY-7289-2021
OI Namboodiri, Vinay/0000-0001-5262-9722
CR [Anonymous], 2016, ADV NEUR IN
   [Anonymous], 2017, P INT C MACH LEARN
   [Anonymous], 2018, PR MACH LEARN RES
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arjovsky M., ARXIV PREPRINT ARXIV
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bergamo Alessandro, 2010, ADV NEURAL INFORM PR, V23
   Bousmalis K, 2017, PROC CVPR IEEE, P95, DOI 10.1109/CVPR.2017.18
   Carlucci FM, 2017, IEEE I CONF COMP VIS, P5077, DOI 10.1109/ICCV.2017.542
   Chen CQ, 2019, PROC CVPR IEEE, P627, DOI 10.1109/CVPR.2019.00072
   Chen QC, 2018, PROC CVPR IEEE, P7976, DOI 10.1109/CVPR.2018.00832
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004
   Fu Y, 2018, EUR C COMP VIS ECCV
   Fua P, 2018, SHARING WEIGHTS DEEP
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Ghifary M, 2016, LECT NOTES COMPUT SC, V9908, P597, DOI 10.1007/978-3-319-46493-0_36
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Haeusser P, 2017, IEEE I CONF COMP VIS, P2784, DOI 10.1109/ICCV.2017.301
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hoffmann A., 2001, EMCL '01: Proceedings of the 12th European Conference on Machine Learning, P203
   Jinyu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P480, DOI 10.1007/978-3-030-58583-9_29
   Kang GL, 2018, LECT NOTES COMPUT SC, V11215, P420, DOI 10.1007/978-3-030-01252-6_25
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurmi VK, 2019, IEEE IJCNN
   Kurmi VK, 2019, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2019.00058
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li HL, 2018, PROC CVPR IEEE, P5400, DOI 10.1109/CVPR.2018.00566
   Li S, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P729, DOI 10.1145/3343031.3351070
   Li Yanghao, 2016, Revisiting batch normalization for practical domain adaptation
   Liu Y, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278091
   Long M, 2016, PROCEEDINGS OF SYMPOSIUM OF POLICING DIPLOMACY AND THE BELT & ROAD INITIATIVE, 2016, P136
   Long MS, 2018, ADV NEUR IN, V31
   Long MS, 2019, IEEE T PATTERN ANAL, V41, P3071, DOI 10.1109/TPAMI.2018.2868685
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Ma XH, 2019, PROC CVPR IEEE, P8258, DOI 10.1109/CVPR.2019.00846
   Murez Z, 2018, PROC CVPR IEEE, P4500, DOI 10.1109/CVPR.2018.00473
   Namboodiri, CURRICULUM BASED DRO
   Odena A, 2017, PR MACH LEARN RES, V70
   Park SW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040688
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835
   Radford A., 2015, ARXIV
   Rahman MM, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107124
   Ren C.-X, P IEEE CVF C COMP VI, P13936
   Rozantsev A, 2018, PROC CVPR IEEE, P4339, DOI 10.1109/CVPR.2018.00456
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K., 2017, Adversarial dropout regularization
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Saito K, 2017, PR MACH LEARN RES, V70
   Sankaranarayanan S, 2018, PROC CVPR IEEE, P8503, DOI 10.1109/CVPR.2018.00887
   Shu Y, 2019, AAAI CONF ARTIF INTE, V33, P4951
   Sun BC, 2017, ADV COMPUT VIS PATT, P153, DOI 10.1007/978-3-319-58347-1_8
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Sutton, ADV NEURAL INF PROCE
   Tzeng E., ARXIV PREPRINT ARXIV
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Volpi R, 2018, PROC CVPR IEEE, P5495, DOI 10.1109/CVPR.2018.00576
   Wen J, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3849
   Wong, IEEE T IMAGE PROCESS
   Wu HR, 2020, KNOWL-BASED SYST, V191, DOI 10.1016/j.knosys.2019.105155
   Wu Yuan, 2020, ECCV
   Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151
   Yan H, 2020, UNSUPERVISED DOMAIN
   Yan HL, 2017, PROC CVPR IEEE, P945, DOI 10.1109/CVPR.2017.107
   Yun Luo, 2008, 2008 IEEE Intelligent Vehicles Symposium (IV), P214, DOI 10.1109/IVS.2008.4621136
   Zhang J, 2018, PROC CVPR IEEE, P8156, DOI 10.1109/CVPR.2018.00851
   Zhang L, 2019, REGULARIZED DEEP TRA
   Zhang YB, 2019, PROC CVPR IEEE, P5026, DOI 10.1109/CVPR.2019.00517
   Zhang Y, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103974
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 75
TC 3
Z9 3
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104180
DI 10.1016/j.imavis.2021.104180
EA MAY 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700010
DA 2024-07-18
ER

PT J
AU Riaz, S
   Park, U
   Natarajan, P
AF Riaz, Sidra
   Park, Unsang
   Natarajan, Prem
TI Improving face verification using facial marks and deep CNN: IARPA Janus
   benchmark-A
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unconstrained dataset; Face verification; Facial mark; Face recognition;
   IJB-A dataset
ID SOFT BIOMETRIC TRAITS; RECOGNITION
AB Face verification performance by human brain has been shown to be much better than most of the state-of-theart approaches in computer vision. Performance improvement of automated face recognition (FR) systems that may equal or surpass the human intellect is the key goal of this research. We present our face verification system using facial mark (FM) combined with deep convolutional neural network (DCNN) approach to improve the overall FR accuracy. We propose to use FM (e.g., scars, moles and freckles) for face matching in the wild where the FM detection is performed on mean faces as well as affine aligned normalized facial images. The FR experiments are carried out on IARPA Janus Benchmark-A (IJB-A) dataset which includes real-world unconstrained images from 500 subjects. The IJB-A datasets includes full pose, expression, and illumination variations which are much harder than traditional FERET and Mugshot datasets. We evaluated the average FR performance using a weighted score-level fusion of FM and DCNN based recognition methods. The experimental evaluations on FERET, CFM and Mugshot datasets show higher performances than state-of-the-art FM approaches with 99.23%, 94.64% and 97.86% accuracies in Rank-1 evaluations, respectively. Our FR performance of FM + DCNN (86.46% in TAR, 91.23% in Rank-1, 96.57% in Rank-5, 98.65% in Rank-10) is shown to be higher than state-ofthe-art (83.80% in TAR@1%FAR, 90.30% in Rank-1, 96.5% in Rank-5, and 97.7% in Rank-10). Experimental results after fusion of FM + DCNN on IJB-A dataset show 2.66% FR performance improvement from the DCNN only recognition in terms of TAR@1%FAR. (c) 2020 Published by Elsevier B.V.
C1 [Riaz, Sidra; Park, Unsang] Sogang Univ, Dept Comp Sci & Engn, 35 Baekbeom Ro, Seoul, South Korea.
   [Natarajan, Prem] Univ Southern Calif, Inst Informat Sci, Marina Del Rey, CA USA.
C3 Sogang University; University of Southern California
RP Park, U (corresponding author), Sogang Univ, Dept Comp Sci & Engn, 35 Baekbeom Ro, Seoul, South Korea.
EM sidra@sogang.ac.kr; unsangpark@sogang.ac.kr; pnataraj@isi.edu
FU ICT R&D By the Institute for Information & communications Technology
   Promotion(IITP) - Korea government (MSIT) [2020-0-00113]; Office of the
   Director of National Intelligence (ODNI), Intelligence Advanced Research
   Projects Activity (IARPA), via IARPA contract [2014-14071600011]
FX This work was supported by the ICT R&D By the Institute for Information
   & communications Technology Promotion(IITP) grant funded by the Korea
   government (MSIT) [Project Number : 2020-0-00113, Project Name :
   Development of data augmentation technology by using heterogeneous
   information and data fusions], and the Office of the Director of
   National Intelligence (ODNI), Intelligence Advanced Research Projects
   Activity (IARPA), via IARPA contract number 2014-14071600011. The views
   and conclusions contained herein are those of the authors and should not
   be interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of ODNI, IARPA, or the U.S.
   Government. The U.S. Government is authorized to reproduce and
   distribute reprints for Governmental purpose notwithstanding any
   copyright annotation thereon.
CR [Anonymous], 2018, COSFACE LARGE MARGIN
   [Anonymous], 2015, DEEPID3 FACE RECOGNI
   [Anonymous], 2015, MULTIVIEW FACE DETEC
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   [Anonymous], 2015, KOREA JAPAN JT WORK, DOI DOI 10.1109/FCV.2015.7103755
   Bansal A., 2017, ARXIVBS1705074262017
   Cao ZB, 2013, IEEE INT C BIOINFORM
   Chen J, 2016, MOB INF SYST, V2016, DOI 10.1155/2016/5894752
   Chiang PH, 2006, IEEE ICC, P1350
   Dantcheva A., 2010, BAG SOFT BIOMETRICS
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Dugelay Jean-Luc, 2015, 2015 IEEE International Conference on Signal and Image Processing Applications (ICSIPA). Proceedings, DOI 10.1109/ICSIPA.2015.7412149
   Fabiola B.-R., 2017, PATTERN RECOGN LETT, V113, P3, DOI [10.1016/j.patrec.2017.05.005, DOI 10.1016/J.PATREC.2017.05.005]
   Gogoi UR, 2015, PROCEDIA COMPUT SCI, V46, P1546, DOI 10.1016/j.procs.2015.02.080
   Gong S., 2019, ARXIVABS190207327
   Grm K, 2018, IET BIOMETRICS, V7, P81, DOI 10.1049/iet-bmt.2017.0083
   Heflin B., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P31, DOI 10.1109/BTAS.2012.6374555
   Jain AK, 2004, LECT NOTES COMPUT SC, V3087, P259
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jain AK, 2009, IEEE IMAGE PROC, P37, DOI 10.1109/ICIP.2009.5413921
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Lee JE, 2008, PROC CVPR IEEE, P373
   LI HX, 2015, PROC CVPR IEEE, P5325, DOI DOI 10.1109/CVPR.2015.7299170
   Liu W., 2018, ARXIV170408063V4CSCV
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Z, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P244, DOI 10.1109/ICIVC.2017.7984554
   Niinuma K, 2010, IEEE T INF FOREN SEC, V5, P771, DOI 10.1109/TIFS.2010.2075927
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Piernas Juan., 2007, SC 07, P1, DOI DOI 10.1145/1362622.1362660
   Ramesha K., 2010, INT J COMPUTER THEOR, V2, P798, DOI [10.7763/IJCTE.2010.V2.243, DOI 10.7763/IJCTE.2010.V2.243]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Xiong Xuehan, 2013, 2013 IEEE C IEEE
   Zeinstra C G, 2018, Forensic Sci Rev, V30, P21
   Zhang Z, 2009, LECT NOTES COMPUT SC, V5558, P424, DOI 10.1007/978-3-642-01793-3_44
NR 37
TC 4
Z9 4
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104020
DI 10.1016/j.imavis.2020.104020
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800016
OA Bronze
DA 2024-07-18
ER

PT J
AU Wang, YF
   Li, HD
   Wei, Y
   Wang, CY
   Wang, L
AF Wang, Yuefeng
   Li, Huadong
   Wei, Ying
   Wang, Chuyuan
   Wang, Lin
TI Vehicle re-identification based on unsupervised local area detection and
   view discrimination
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vehicle re-identification; Unsupervised; Discriminatory local area; View
   discrimination; Cross-view
AB Vehicle re-identification is an important part of intelligent transportation. Although much work has been done on this subject in recent years, vehicle re-identification is still a challenging task due to its obvious illumination change, high similarity between inter-class and great changes under different views. As discriminatory local areas and vehicle view information is the key to improving the above issues, it is desirable to create a model which considers both local details and cross-view situation. In this paper, we built a vehicle re-identification framework based on unsupervised local area detection and view discrimination. First, we combine the convolution features of multiple vehicle images by channel to generate joint channel features, and constructs a discriminating region detector unsupervised by clustering the channel covariance vectors generated between the joint channel features. In the next stage, the irregular shape detection results are converted to rectangular discriminative region by using a novel local region integration algorithm. These rectangular discriminative regions are fed into a multi-branch network to extract the local-global features which contains rich detail information. Furthermore, we generate the view features by regarding the detected discriminative areas as keypoints and construct the unsupervised view discriminator. By using the view information of the vehicle, we designed a view discrimination based reranking algorithm, which effectively reduces the error rate of identification due to view variant. In order to prove the validity of our method, we have done extensive experiments on VehicleID and VERI-Wild dataset. Experimental results show that our method is superior to other existing vehicle re identification algorithms. (c) 2020 Published by Elsevier B.V.
C1 [Wang, Yuefeng; Li, Huadong; Wei, Ying; Wang, Chuyuan; Wang, Lin] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110004, Peoples R China.
   [Wei, Ying] Minist Educ, Key Lab Med Imaging Calculat, Shenyang 110004, Peoples R China.
C3 Northeastern University - China
RP Wei, Y (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110004, Peoples R China.
EM weiying@ise.neu.edu.cn
RI wang, yue/ISA-4119-2023; WANG, YUE/GWQ-9256-2022
FU National Natural Science Foundation of China [61871106]
FX This work was supported by the National Natural Science Foundation of
   China under Grant NO.61871106.
CR Bai Y, 2018, IEEE T MULTIMEDIA, V20, P2385, DOI 10.1109/TMM.2018.2796240
   Bertozzi M, 1997, J SYST ARCHITECT, V43, P317, DOI 10.1016/S1383-7621(96)00106-3
   Buluswar SD, 1998, ENG APPL ARTIF INTEL, V11, P245, DOI 10.1016/S0952-1976(97)00079-1
   Ding SY, 2015, PATTERN RECOGN, V48, P2993, DOI 10.1016/j.patcog.2015.04.005
   Guo HY, 2019, IEEE T IMAGE PROCESS, V28, P4328, DOI 10.1109/TIP.2019.2910408
   He B, 2019, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2019.00412
   Ho CK, 2015, IEEE C ELEC DEVICES, P178, DOI 10.1109/EDSSC.2015.7285079
   Kalinke Thomas., 1998, IEEE Intelligent Vehicles Symposium, P341
   Khorramshahi P., 2019, CVPR WORKSH, P239
   Khorramshahi P, 2019, IEEE I CONF COMP VIS, P6131, DOI 10.1109/ICCV.2019.00623
   Li X, 2017, J ELECTR COMPUT ENG, V2017, P1, DOI 10.1155/2017/5232507
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin WY, 2017, IEEE T IMAGE PROCESS, V26, P2438, DOI 10.1109/TIP.2017.2683063
   Liu HY, 2016, PROC CVPR IEEE, P2167, DOI 10.1109/CVPR.2016.238
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XD, 2018, COMPLEXITY, DOI 10.1155/2018/5145348
   Liu XD, 2013, C IND ELECT APPL, P1221
   Liu XC, 2016, LECT NOTES COMPUT SC, V9906, P869, DOI 10.1007/978-3-319-46475-6_53
   Lou YH, 2019, PROC CVPR IEEE, P3230, DOI 10.1109/CVPR.2019.00335
   Peng JJ, 2019, NEUROCOMPUTING, V359, P427, DOI 10.1016/j.neucom.2019.06.013
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Wang ZD, 2017, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2017.49
   Wei XS, 2019, LECT NOTES COMPUT SC, V11362, P575, DOI 10.1007/978-3-030-20890-5_37
   Wei XS, 2017, IEEE T IMAGE PROCESS, V26, P2868, DOI 10.1109/TIP.2017.2688133
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Yuan YH, 2017, IEEE I CONF COMP VIS, P814, DOI 10.1109/ICCV.2017.94
   Zapletal D, 2016, IEEE COMPUT SOC CONF, P1568, DOI 10.1109/CVPRW.2016.195
   Zhang X., 2019, CoRR
   Zhao Yanzhu, 2019, IEEE T INTELLIGENT T, V2019
   Zheng A., 2019, ARXIV190508997
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou Y, 2018, IEEE T IMAGE PROCESS, V27, P3275, DOI 10.1109/TIP.2018.2819820
   Zhou Y, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00679
   Zhu JQ, 2020, IEEE T INTELL TRANSP, V21, P410, DOI 10.1109/TITS.2019.2901312
   Zhu JQ, 2018, IEEE T CIRC SYST VID, V28, P3183, DOI 10.1109/TCSVT.2017.2734740
   ZIELKE T, 1993, CVGIP-IMAG UNDERSTAN, V58, P177, DOI 10.1006/ciun.1993.1037
NR 38
TC 2
Z9 2
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104008
DI 10.1016/j.imavis.2020.104008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800015
DA 2024-07-18
ER

PT J
AU Sun, P
   Zheng, YB
   Zhou, ZT
   Xu, WY
   Ren, Q
AF Sun, Peng
   Zheng, Yongbin
   Zhou, Zongtan
   Xu, Wanying
   Ren, Qiang
TI R<SUP>4</SUP> Det: Refined single-stage detector with feature recursion
   and refinement for rotating object detection in aerial images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Rotating object detection in aerial images and videos; Single-stage
   detector; A novel encoder-decoder architecture; Recursive feature
   pyramid; Recursive feature contact; RetinaNet-based rotation detection;
   Feature refinement
AB The detection of objects with multi-orientations and multi-scales in aerial images is receiving increasing attention because of numerous useful applications in computer vision, image understanding, satellite remote sensing and surveillance. However, such detection can be exceedingly challenging because of a birds eye view, multiscale rotating objects with large aspect ratios, dense distributions and extremely imbalanced categories. Despite the considerable progress that has been made, detection performance falls considerably below that required for real-world applications. In this paper, we propose an accurate and fast end-to-end detector to address the aforementioned challenges. Our contributions are threefold. First, inspired by the looking and thinking twice mechanism, recursive neural networks and the DetectoRS detector, we propose a novel encoder-decoder based architecture by introducing the recursive feature pyramid into a single-stage object detection framework. The improved backbone network can generate increasingly powerful multi-scale representations for classification and regression. Second, we propose a refined single-stage detectorwith feature recursion and refinement for rotating objects. Third, we use instance balance to improve focal loss, thereby optimizing the loss in the correct direction. Extensive experiments on two challenging aerial image object detection public datasets, DOTA and HRSC2016, show that the proposed R4Det detector achieves the state-of-the-art accuracy while running very fast. Moreover, further experiments show that our detector is more robust to adversarial image patch attacks than the previous state-of-art detector. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Sun, Peng; Zheng, Yongbin; Zhou, Zongtan; Xu, Wanying; Ren, Qiang] Natl Univ Def Technol, Coll Intelligence Sci & Technol, Changsha 410073, Peoples R China.
C3 National University of Defense Technology - China
RP Zheng, YB (corresponding author), Natl Univ Def Technol, Coll Intelligence Sci & Technol, Changsha 410073, Peoples R China.
EM sunpeng@nudt.edu.cn; zybnudt@nudt.edu.cn
RI xu, wanying/JXM-0113-2024
OI Peng, Sun/0000-0002-2105-4636
FU National Nature Science Foundation of China [61403412]
FX Manuscript received September 22, 2020. This work was supported in part
   by National Nature Science Foundation of China under Grant 61403412.
CR Ajaya A., 2020, ARXIV200813671
   [Anonymous], 2013, OVERFEAT INTEGRATED
   Cai ZW, 2021, IEEE T PATTERN ANAL, V43, P1483, DOI 10.1109/TPAMI.2019.2956516
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Deng D, 2018, AAAI CONF ARTIF INTE, P6773
   Ding J, 2019, PROC CVPR IEEE, P2844, DOI 10.1109/CVPR.2019.00296
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Jiang YY, 2018, INT C PATT RECOG, P3610, DOI 10.1109/ICPR.2018.8545598
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lezi W., 2019, IMAGE VIS COMPUT, V87, P37
   Liao MH, 2018, PROC CVPR IEEE, P5909, DOI 10.1109/CVPR.2018.00619
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lin Y., 2019, ARXIV191200969
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YD, 2020, AAAI CONF ARTIF INTE, V34, P11653
   Liu ZK, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P324, DOI 10.5220/0006120603240331
   Ma JQ, 2018, IEEE T MULTIMEDIA, V20, P3111, DOI 10.1109/TMM.2018.2818020
   Qian W., 2019, ARXIV191108299
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Thys S, 2019, IEEE COMPUT SOC CONF, P49, DOI 10.1109/CVPRW.2019.00012
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Wan Y, 2018, IEEE INT CONF AUTOM, P397, DOI 10.1145/3238147.3238206
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xia GS, 2017, IEEE T GEOSCI REMOTE, V55, P3965, DOI 10.1109/TGRS.2017.2685945
   Xianxu H., 2020, IMAGE VIS COMPUT, V99
   Xu H, 2020, INT J AUTOM COMPUT, V17, P151, DOI 10.1007/s11633-019-1211-x
   Xu YF, 2020, INT J NEUROSCI, V130, P852, DOI 10.1080/00207454.2019.1707819
   Yang X., 2019, ARXIV190805612, P3163
   Yang X, 2019, IEEE I CONF COMP VIS, P8231, DOI 10.1109/ICCV.2019.00832
   Zaremba W., 2014, ARXIV
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZH, 2018, IEEE GEOSCI REMOTE S, V15, P1745, DOI 10.1109/LGRS.2018.2856921
   Zhu Y, 2020, INT ORTHOP, V44, P1565, DOI 10.1007/s00264-020-04575-0
NR 43
TC 25
Z9 27
U1 2
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104036
DI 10.1016/j.imavis.2020.104036
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000015
DA 2024-07-18
ER

PT J
AU Hou, XX
   Liu, JX
   Xu, BL
   Wang, XL
   Liu, BZ
   Qiu, GP
AF Hou, Xianxu
   Liu, Jingxin
   Xu, Bolei
   Wang, Xiaolong
   Liu, Bozhi
   Qiu, Guoping
TI Class-aware domain adaptation for improving adversarial robustness
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Domain adaptation; Adversarial robustness
AB Recent works have demonstrated convolutional neural networks are vulnerable to adversarial examples, i.e., inputs to machine learning models that an attacker has intentionally designed to cause the models to make a mistake. To improve the adversarial robustness of neural networks, adversarial training has been proposed to train networks by injecting adversarial examples into the training data. However, adversarial training could overfit to a specific type of adversarial attack and also lead to standard accuracy drop on clean images. To this end, we propose a novel Class-Aware Domain Adaptation (CADA) method for adversarial defense without directly applying adversarial training. Specifically, we propose to learn domain-invariant features for adversarial examples and dean images via a domain discriminator. Furthermore, we introduce a class-aware component into the discriminator to increase the discriminative power of the network for adversarial examples. We evaluate our newly proposed approach using multiple benchmark datasets. The results demonstrate that our method can significantly improve the state-of-the-art of adversarial robustness for various attacks and maintain high performances on clean images. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Hou, Xianxu] Shenzhen Univ, Coll Comp Sci & Software Engn, Shenzhen, Peoples R China.
   [Hou, Xianxu; Liu, Jingxin; Xu, Bolei; Liu, Bozhi; Qiu, Guoping] Shenzhen Univ, Coll Elect & Informat Engn, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.
   [Wang, Xiaolong] IBM Corp, San Jose, CA USA.
   [Qiu, Guoping] Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen, Peoples R China.
   [Qiu, Guoping] Univ Nottingham, Sch Comp Sci, Nottingham, England.
C3 Shenzhen University; Shenzhen University; International Business
   Machines (IBM); Shenzhen Institute of Artificial Intelligence & Robotics
   for Society; University of Nottingham
RP Qiu, GP (corresponding author), Shenzhen Univ, Coll Elect & Informat Engn, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.
EM guoping.qiu@nottingham.ac.uk
RI Xu, Bolei/GRO-1172-2022
OI Qiu, Guoping/0000-0002-5877-5648; Liu, Jingxin/0000-0001-6071-9197
CR [Anonymous], 2017, ICCV
   [Anonymous], 180701069 CORR
   [Anonymous], 2018, ICLR
   [Anonymous], IEEE T EVOL COMPUT
   [Anonymous], 2019, CVPR
   [Anonymous], 2019, CVPR
   [Anonymous], 2006, ADV NEURAL INFORM PR
   [Anonymous], ARXIV180206806
   [Anonymous], 2019, CVPR
   [Anonymous], ARXIV180206430
   [Anonymous], ARXIV180306373
   [Anonymous], 2019, ICLR
   [Anonymous], 2016, ECCV
   [Anonymous], ARXIV171202779
   [Anonymous], ICLR
   [Anonymous], ARXIV161101236
   [Anonymous], 2017, ICLR WORKSH
   [Anonymous], 2018, DEEP LEARNING MODELS
   [Anonymous], 2018, CVPR
   [Anonymous], 2018, CVPR
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Goodfellow I., 2014, ADV NEURAL INF PROCE, V27, DOI DOI 10.1145/3422622
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   Kingma D. P., 2015, INT C LEARNING REPRE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu GX, 2019, IFIP ADV INF COMM TE, V562, P19, DOI 10.1007/978-3-030-22312-0_2
   Papernot N, 2016, P IEEE S SECUR PRIV, P582, DOI 10.1109/SP.2016.41
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Sun B., 2019, CVPR
   Szegedy C., 2014, ICLR
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang YT, 2020, NEUROCOMPUTING, V382, P87, DOI 10.1016/j.neucom.2019.11.051
NR 33
TC 4
Z9 4
U1 3
U2 44
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2020
VL 99
AR 103926
DI 10.1016/j.imavis.2020.103926
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LZ3LW
UT WOS:000541130800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jia, S
   Bruce, NDB
AF Jia, Sen
   Bruce, Neil D. B.
TI EML-NET: An Expandable Multi-Layer NETwork for saliency prediction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Saliency detection; Scalability; Loss function
ID CONVOLUTIONAL NEURAL-NETWORK; VISUAL-ATTENTION; ALLOCATION
AB Existing advanced saliency systems have been proposed using Convolutional Neural Networks (CNNs), the prior knowledge of objectness is crucial for saliency detection. However, we show that the use of objectness may also limit the power of CNNs on the images which do not contain a salient object. Besides, one previous study has shown applying a deeper CNN model may not improve the performance, the reason behind could be due to the limited training data. In this work, we aim at investigating the effect of prior knowledge from other domains and proposing a multi-modality system. Our work shows the depth of the model still plays an important role in saliency detection when the training data is large enough. To do this in a sophisticated manner can be complex, and also result in unwieldy networks or produce competing objectives that are hard to balance. For the scalability, our multi-modality system is trained in an almost end-to-end piece-wise fashion. The encoder and decoder components are separately trained to deal with complexity tied to the computational paradigm and required space. Therefore, our system can be easily extended to include a variety of prior knowledge for saliency detection. Besides, we also propose a combined saliency loss based on modifications of Pearson correlation and normalized scanpath saliency. Our experiment shows the combined loss can train a CNN model more comprehensively for saliency detection. We denote our expandable multi-layer network as EML-NET and our method achieves the state-of-the-art results on the public saliency benchmarks, SALICON, MIT300 and CAT2000. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Jia, Sen; Bruce, Neil D. B.] Ryerson Univ, Dept Comp Sci, Toronto, ON, Canada.
   [Bruce, Neil D. B.] Vector Inst, Toronto, ON, Canada.
C3 Toronto Metropolitan University; Vector Institute for Artificial
   Intelligence
RP Jia, S (corresponding author), Ryerson Univ, Dept Comp Sci, Toronto, ON, Canada.
EM sen.jia@ryerson.ca; bruce@ryerson.ca
RI Bruce, Neil DB/K-2062-2015
OI Jia, Sen/0000-0001-7104-034X
CR [Anonymous], ABS170101081 CORR
   [Anonymous], ICLR WORKSH
   [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], ABS14115878 CORR
   [Anonymous], ABS170502544 CORR
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2016, P EUROPEAN C COMPUTE
   [Anonymous], ABS161001708 CORR
   [Anonymous], 2015, CVPR 2015 WORKSHOP F
   [Anonymous], ABS160901064 CORR
   [Anonymous], ABS161109571 CORR
   [Anonymous], ABS180710657 CORR
   Borji A, 2013, J VISION, V13, DOI 10.1167/13.10.18
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Bruce N., 2010, Journal of Vision, V7, P950, DOI [10.1167/7.9.950, DOI 10.1167/7.9.950]
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Gao D., 2005, P ADV NEUR INF PROC, P481
   Garcia-Diaz A, 2012, IMAGE VISION COMPUT, V30, P51, DOI 10.1016/j.imavis.2011.11.007
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jetley S, 2016, PROC CVPR IEEE, P5753, DOI 10.1109/CVPR.2016.620
   Jia S, 2018, MULTIMED TOOLS APPL, V77, P14859, DOI 10.1007/s11042-017-5070-6
   Jia S, 2017, IEEE IMAGE PROC, P765, DOI 10.1109/ICIP.2017.8296384
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Judd T, 2012, MIT TECHNICAL REPORT
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kummerer M, 2016, ABS161001563 CORR
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Nasrinpour HR, 2015, IEEE IMAGE PROC, P4947, DOI 10.1109/ICIP.2015.7351748
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Parkhurst DJ, 2003, SPATIAL VISION, V16, P125, DOI 10.1163/15685680360511645
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Tavakoli HR, 2017, NEUROCOMPUTING, V244, P10, DOI 10.1016/j.neucom.2017.03.018
   Tseng PH, 2009, J VISION, V9, DOI 10.1167/9.7.4
   Valenti R, 2009, IEEE I CONF COMP VIS, P2185, DOI 10.1109/ICCV.2009.5459240
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Yao XW, 2017, IEEE T IMAGE PROCESS, V26, P3196, DOI 10.1109/TIP.2017.2694222
   Yu SX, 2009, LECT NOTES COMPUT SC, V5875, P157, DOI 10.1007/978-3-642-10331-5_15
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 65
TC 78
Z9 83
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103887
DI 10.1016/j.imavis.2020.103887
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Huang, RY
   Yu, KF
   Huang, XY
   Zou, WC
   Wang, YH
AF Huang, Rongyong
   Yu, Kefu
   Huang, Xueyong
   Zou, Wencai
   Wang, Yinghui
TI Combining Landsat images with historic records to estimate the live
   coral cover of Luhuitou fringing reef in Northern South China Sea
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Coral reefs; Satellite images; Live coral cover; South China Sea
ID INDEX
AB As an efficient indicator of coral reef health, live coral cover (LCC) is regularly surveyed and recorded by many coral reef documents. However, there usually exist some blanks for the historic records, while current in-field surveys are impossible to fill the blanks. To overcome such difficulties, we focus on exploiting the potential of optical satellite images. The purpose is to fill the blanks of the records over the past and further estimate the LCC in future. As historic records were usually lack of accurate geographical locations to match to the satellite images, a spectral index was defined based on the mean of the subsurface remote sensing reflectance. The index was then used to link the LCC with the satellite images by a cubic polynomial function. Thereafter, the LCC and the coefficients of the polynomial function were finally estimated by simultaneously combining the mean subsurface remote sensing reflectance, the historic LCC records, and the constraints among LCC in adjacent years. Experiments on a series of Landsat images of Luhuitou fringing reef (1973 to 2018) demonstrated that the proposed method is effective and feasible, where the introduction of the satellite images can greatly improve the accuracy. The Root Mean Square Error (RMSE), Mean Absolute Error (MAE), and Mean Relative Errors (MRE) of the LCC were able to reach 5.4%, 4.0%, and 15.9% respectively. This is regarded as the first test on LCC estimation by combining such a long-term LCC records with a series of satellite images. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Huang, Rongyong; Yu, Kefu; Huang, Xueyong; Zou, Wencai; Wang, Yinghui] Guangxi Univ, Guangxi Lab Study Coral Reefs South China Sea, Nanning 530004, Peoples R China.
   [Huang, Rongyong; Yu, Kefu; Huang, Xueyong; Zou, Wencai; Wang, Yinghui] Guangxi Univ, Coral Reef Res Ctr China, Nanning 530004, Peoples R China.
   [Huang, Rongyong; Yu, Kefu; Huang, Xueyong; Zou, Wencai; Wang, Yinghui] Guangxi Univ, Sch Marine Sci, Nanning 530004, Peoples R China.
   [Yu, Kefu] Qingdao Natl Lab Marine Sci & Technol, Lab Marine Geol, Qingdao 266061, Shandong, Peoples R China.
C3 Guangxi University; Guangxi University; Guangxi University; Laoshan
   Laboratory
RP Yu, KF (corresponding author), Guangxi Univ, Guangxi Lab Study Coral Reefs South China Sea, Nanning 530004, Peoples R China.
EM kefuyu@scsio.ac.cn
FU Natural Science Foundation of China [91428203, 41766007]; Guangxi
   Scientific Projects [AD17129063]; Guangxi Innovative Development Grand
   Grant [AA17204074, AA18118038]; Natural Science Foundation of Guangxi
   Province, China [2016GXNSFBA380031]
FX This work is financially supported by the Natural Science Foundation of
   China (Nos. 91428203 and 41766007), the Guangxi Scientific Projects (No.
   AD17129063), the Guangxi Innovative Development Grand Grant (Nos.
   AA17204074 and AA18118038), and the Natural Science Foundation of
   Guangxi Province, China (No. 2016GXNSFBA380031). We appreciate for USGS
   (https://earthexplorer.usgs.gov/) for providing the Landsat images, and
   special thanks are given to the anonymous reviewers and members of the
   editorial board for their suggestions of improving this article.
CR [Anonymous], 2008, STATUS CORAL REEFS W
   Araújo Paulo Victor do Nascimento, 2016, RGCI, V16, P5, DOI 10.5894/rgci629
   Clark CD, 2000, INT J REMOTE SENS, V21, P2321, DOI 10.1080/01431160050029602
   Collet A, 2012, ACTES RECH SCI SOC, P12
   Collin A., 2011, GEOSC REM SENS S VAN
   CONNELL JH, 1978, SCIENCE, V199, P1302, DOI 10.1126/science.199.4335.1302
   English S., 1997, Manual for survey of tropical marine resources, V2nd
   Gapper JJ, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111774
   Hamel MA, 2010, MAR POLLUT BULL, V60, P1397, DOI 10.1016/j.marpolbul.2010.07.002
   Huang RY, 2018, OPT EXPRESS, V26, pA374, DOI 10.1364/OE.26.00A374
   Huang RY, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9070750
   Joyce KE, 2013, REMOTE SENS-BASEL, V5, P6116, DOI 10.3390/rs5116116
   Joyce KE, 2013, J APPL REMOTE SENS, V7, DOI 10.1117/1.JRS.7.073590
   LI Y, 2017, TROP GEOGR, V37, P70, DOI DOI 10.3964/J.ISSN.1000-0593(2017)01-0070-05
   Lucas MQ, 2015, J MAR SCI ENG, V3, P1, DOI 10.3390/jmse3010001
   Lyzenga D.R., 1981, International Journal Remote Sensing, V2, P71, DOI [DOI 10.1080/01431168108948342, 10.1080/01431168108948342]
   LYZENGA DR, 1978, APPL OPTICS, V17, P379, DOI 10.1364/AO.17.000379
   Mumby PJ, 2004, CORAL REEFS, V23, P171, DOI 10.1007/s00338-004-0382-1
   Pandolfi JM, 2003, SCIENCE, V301, P955, DOI 10.1126/science.1085706
   Scopélitis J, 2010, MAR POLLUT BULL, V60, P1956, DOI 10.1016/j.marpolbul.2010.07.033
   Shi Q., 2010, Journal of Tropical Geography, V30, P486
   WANG GZ, 2001, CORAL REEF SEDIMENTO
   Wang RH, 2006, CHINESE SCI BULL, V51, P75, DOI 10.1007/s11434-006-8210-3
   Xavier AC, 2004, INT J REMOTE SENS, V25, P1661, DOI 10.1080/01431160310001620803
   [杨华 Yang Hua], 2017, [生态环境学报, Ecology and Environmental Sciences], V26, P253
   Yu KF, 2010, J QUATERNARY SCI, V25, P1284, DOI 10.1002/jqs.1410
   Yu KF, 2012, SCI CHINA EARTH SCI, V55, P1217, DOI 10.1007/s11430-012-4449-5
   Yun C., 2014, CAN J REMOTE SENS, V35, P435
   Zhang QM, 2001, CHINESE SCI BULL, V46, P97, DOI 10.1007/BF03187245
   Zhao MX, 2016, MAR FRESHWATER RES, V67, P1888, DOI 10.1071/MF15110
   Zhao MX, 2012, J COASTAL RES, V28, P1088, DOI 10.2112/JCOASTRES-D-10-00172.1
NR 31
TC 2
Z9 2
U1 1
U2 39
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2019
VL 92
AR 103812
DI 10.1016/j.imavis.2019.09.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JW2JO
UT WOS:000502884200003
DA 2024-07-18
ER

PT J
AU Jiang, M
   Shang, YY
   Guo, GD
AF Jiang, Min
   Shang, Yuanyuan
   Guo, Guodong
TI On visual BMI analysis from facial images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual BMI estimation; Facial images; Facial representations; FIW-BMI
   database
ID BODY-MASS INDEX; CANCER; RISK
AB Automatically assessing body mass index (BMI) from facial images is an interesting and challenging problem in computer vision. Facial feature extraction is an important step for visual BMI estimation. This work studies the visual BMI estimation problem based on the characteristics and performance of different facial representations, which has not been well studied yet. Various facial representations, including geometry based representations and deep learning based, are comprehensively evaluated and analyzed from three perspectives: the overall performance on visual BMI prediction, the redundancy in facial representations and the sensitivity to head pose changes. The experiments are conducted on two databases: a new dataset we collected, called the FIW-BMI and an existing large dataset Morph II. Our studies provide some deep insights into the facial representations for visual BMI analysis: 1) The deep model based methods perform better than geometry based methods. Among them, the VGG-Face and Arcface show more robustness than others in most cases; 2) Removing the redundancy in VGG-Face representation can increase the accuracy and efficiency in BMI estimation: 3) Large head poses lead to low performance for BMI estimation. The Arcface, VGG-Face and PIGF are more robust than the others to head pose variations. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Jiang, Min; Shang, Yuanyuan; Guo, Guodong] Capital Normal Univ, Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Jiang, Min; Guo, Guodong] West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
C3 Capital Normal University; West Virginia University
RP Guo, GD (corresponding author), West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
EM minjiang.aca@gmail.com; syy@bao.ac.cn; guodong.guo@mail.wvu.edu
RI JIANG, MIN/KSM-4856-2024
FU NSF [IIS-1450620]; NSF-CITeR grant; WV-HEPC grant
FX The work was partly supported by an NSF grant IIS-1450620, an NSF-CITeR
   grant, and an WV-HEPC grant. The authors would also like to thank the
   editors and anonymous reviewers for their suggestions to improved the
   manuscript.
CR Amos B., 2016, OPENFACE GEN PURPOSE
   [Anonymous], 2017, CVPR
   [Anonymous], 2018, Arcface: Additive angular margin loss for deep face recognition
   Arnold M, 2016, CANCER EPIDEMIOL, V41, P8, DOI 10.1016/j.canep.2016.01.003
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Barr ML, 2018, TECHNOLOGIES, V6, DOI 10.3390/technologies6030083
   Bishop C. M., 2006, PATTERN RECOGN
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Coetzee V, 2010, PERCEPTION, V39, P51, DOI 10.1068/p6560
   Coetzee V, 2009, PERCEPTION, V38, P1700, DOI 10.1068/p6423
   Dantcheva A, 2018, INT C PATT RECOG, P3555, DOI 10.1109/ICPR.2018.8546159
   De Marsico M., 2011, Proceedings of the 3rd International ACM Workshop on Multimedia in Forensics and Intelligence, P7
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Henderson AJ, 2016, PHILOS T R SOC B, V371, DOI 10.1098/rstb.2015.0380
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kocabey E., 2017, 11 INT AAAI C WEB SO
   Lee BJ, 2014, BMC COMPLEM ALTERN M, V14, DOI 10.1186/1472-6882-14-248
   Mayer C, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0169336
   Meigs JB, 2006, J CLIN ENDOCR METAB, V91, P2906, DOI 10.1210/jc.2006-0594
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pham D. D., 2011, EVID BASED COMPLEMEN, V2011
   Renehan AG, 2008, LANCET, V371, P569, DOI 10.1016/S0140-6736(08)60269-X
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Wen LY, 2013, IMAGE VISION COMPUT, V31, P392, DOI 10.1016/j.imavis.2013.03.001
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wolffhechel K, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0140347
   Wolk R, 2003, CIRCULATION, V108, P2206, DOI 10.1161/01.CIR.0000095270.85646.E8
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 32
TC 13
Z9 15
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 183
EP 196
DI 10.1016/j.imavis.2019.07.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900016
OA Bronze
DA 2024-07-18
ER

PT J
AU Jribi, M
   Rihani, A
   Ben Khlifa, A
   Ghorbel, F
AF Jribi, Majdi
   Rihani, Amal
   Ben Khlifa, Ameni
   Ghorbel, Faouzi
TI An SE(3) invariant description for 3D face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-polar; Invariance; Face recognition; Geodesic potential;
   Curvature; Parameterization
ID KEYPOINT DETECTION; REPRESENTATION; REGISTRATION; DENSE; DEEP
AB Here, we intend to introduce a novel 3D face description which is invariant under the Special Euclidean group SE(3) and independent to the original surface parameterization. It is well known that it is too difficult to define a relative invariant parameterization of a general curved surface. In the present work, we introduce the multi-polar geodesic representation of R-3 surfaces. It allows to reach an isotropic canonical parameterization relatively to SE(3) due to the fact that the face surfaces can be easily assumed to be a graph of a function from R-2 to R. The principal curvature fields according to a three-polar parameterization are considered. A statistical study is made to choose a good configuration of reference points. The performances of the novel description are tested on the standard database FRGC v2.0. Many recognition scenarios are established. The obtained results are very competitive with the state of the art. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Jribi, Majdi; Rihani, Amal; Ben Khlifa, Ameni; Ghorbel, Faouzi] La Manouba Univ, ENSI, GRIFT Res Grp, CRISTAL Lab, La Manouba 2010, Tunisia.
C3 Universite de la Manouba
RP Jribi, M (corresponding author), La Manouba Univ, ENSI, GRIFT Res Grp, CRISTAL Lab, La Manouba 2010, Tunisia.
EM majdi.jribi@ensi.rnu.tu
OI Ghorbel, Faouzi/0000-0002-6364-1089
CR Achermann B, 2000, INT C PATT RECOG, P809, DOI 10.1109/ICPR.2000.906199
   [Anonymous], 2009, P INT C BIOM THEOR A
   [Anonymous], 2005, CVPR WORKSH
   [Anonymous], P 2008 8 IEEE INT C, DOI DOI 10.1109/AFGR.2008.4813324
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berretti S, 2013, COMPUT GRAPH-UK, V37, P509, DOI 10.1016/j.cag.2013.04.001
   Berretti S, 2010, IEEE T PATTERN ANAL, V32, P2162, DOI 10.1109/TPAMI.2010.43
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Cardia N. B., 2017, UTILIZING DEEP LEARN, P135
   Chang KI, 2006, IEEE T PATTERN ANAL, V28, P1695, DOI 10.1109/TPAMI.2006.210
   Creusot C, 2013, INT J COMPUT VISION, V102, P146, DOI 10.1007/s11263-012-0605-9
   CRIMMINS TR, 1982, IEEE T SYST MAN CYB, V12, P848, DOI 10.1109/TSMC.1982.4308918
   Elaiwat S, 2015, PATTERN RECOGN, V48, P1235, DOI 10.1016/j.patcog.2014.10.013
   Elyan E, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P246, DOI 10.1109/CW.2009.48
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Florian S., 2015, FACENET UNIFIED EMBE, P815
   Gadacha W, 2012, IEEE MEDITERR ELECT, P649, DOI 10.1109/MELCON.2012.6196515
   Ganguly S., 2014, ICTACT J IMAGE VIDEO, V4
   Ghorbel F, 1998, ANN TELECOMMUN, V53, P242
   GHORBEL F, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P130, DOI 10.1109/ICPR.1992.201944
   Ghorbel F, 2013, ANN TELECOMMUN, V68, P219, DOI 10.1007/s12243-012-0335-6
   Gilani SZ, 2018, PROC CVPR IEEE, P1896, DOI 10.1109/CVPR.2018.00203
   Gilani SZ, 2018, IEEE T PATTERN ANAL, V40, P1584, DOI 10.1109/TPAMI.2017.2725279
   Gilani SZ, 2017, PATTERN RECOGN, V69, P238, DOI 10.1016/j.patcog.2017.04.013
   Hu JL, 2017, IMAGE VISION COMPUT, V60, P48, DOI 10.1016/j.imavis.2016.08.007
   Huang D., 2010, Consumer Communications and Networking Conference (CCNC), P1
   Huang D, 2012, IEEE T INF FOREN SEC, V7, P1551, DOI 10.1109/TIFS.2012.2206807
   Huang WL, 2012, IMAGE VISION COMPUT, V30, P355, DOI 10.1016/j.imavis.2012.03.004
   Jai M., 2013, THESIS
   Jribi M., 2013, P INT C SYST CONT SI, V13
   Jribi M., 2014, P 22 INT C CENTR EUR
   Kim D., 2017, ARXIV170310714
   Lei YJ, 2016, PATTERN RECOGN, V52, P218, DOI 10.1016/j.patcog.2015.09.035
   Lei YJ, 2013, PATTERN RECOGN, V46, P24, DOI 10.1016/j.patcog.2012.06.023
   Li HB, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P234, DOI 10.1109/BTAS.2017.8272703
   Li HB, 2015, INT J COMPUT VISION, V113, P128, DOI 10.1007/s11263-014-0785-6
   Lin SW, 2013, ADV INTELL SYST, V193, P289
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Mohammadzade H, 2013, IEEE T PATTERN ANAL, V35, P381, DOI 10.1109/TPAMI.2012.107
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Mundy J., 1992, GEOMETRIC INVARIANCE
   Mundy JosephL., 1994, APPL INVARIANCE COMP
   Passalis G., 2005, CVPR 05, P171
   Perakis P, 2013, IEEE T PATTERN ANAL, V35, P1552, DOI 10.1109/TPAMI.2012.247
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Samir C, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P450, DOI 10.1109/ICME.2005.1521457
   Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P66, DOI 10.1109/38.90568
   Spivak M., 1979, COMPREHENSIVE INTRO, VII
   Srivastava A, 2009, J MATH IMAGING VIS, V33, P253, DOI 10.1007/s10851-008-0073-6
   Struik D.J., 2012, Lectures on Classical Differential Geometry
   Sukno FM, 2015, IEEE T CYBERNETICS, V45, P1717, DOI 10.1109/TCYB.2014.2359056
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang YH, 2017, J MATH IMAGING VIS, V59, P211, DOI 10.1007/s10851-017-0728-2
   Tung T., 2005, International Journal of Shape Modeling, V11, P91, DOI 10.1142/S0218654305000748
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
NR 61
TC 3
Z9 3
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 106
EP 119
DI 10.1016/j.imavis.2019.06.016
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900010
DA 2024-07-18
ER

PT J
AU Li, HY
   Tian, YK
   Mueller, K
   Chen, X
AF Li, Heyi
   Tian, Yunke
   Mueller, Klaus
   Chen, Xin
TI Beyond saliency: Understanding convolutional neural networks from
   saliency prediction on layer-wise relevance propagation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional neural networks; Deep learning understanding; Salient
   relevance map; Attention area
ID VISUAL-ATTENTION; CLASSIFICATION
AB Despite the tremendous achievements of deep convolutional neural networks (CNNs) in many computer vision tasks, understanding how they actually work remains a significant challenge. In this paper, we propose a novel two-step understanding method, namely Salient Relevance (SR) map, which aims to shed light on how deep CNNs recognize images and learn features from areas, referred to as attention areas, therein. Our proposed method starts out with a layer-wise relevance propagation (LRP) step which estimates a pixel-wise relevance map over the input image. Following, we construct a context-aware saliency map, SR map, from the LRP-generated map which predicts areas close to the foci of attention instead of isolated pixels that LRP reveals. In human visual system, information of regions is more important than of pixels in recognition. Consequently, our proposed approach closely simulates human recognition. Experimental results using the ILSVRC2012 validation dataset in conjunction with two well-established deep CNN models, AlexNet and VGG-16, clearly demonstrate that our proposed approach concisely identifies not only key pixels but also attention areas that contribute to the underlying neural network's comprehension of the given images. As such, our proposed SR map constitutes a convenient visual interface which unveils the visual attention of the network and reveals which type of objects the model has learned to recognize after training. The source code is available at https://github.com/HeylLi/Salient-Relevance-Propagation. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Li, Heyi; Mueller, Klaus] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
   [Li, Heyi; Tian, Yunke; Chen, Xin] Midea Emerging Technol Corp, San Jose, CA 95134 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP Chen, X (corresponding author), Midea Emerging Technol Corp, San Jose, CA 95134 USA.
EM heyli@cs.stonybrook.edu; yunke.tian@midea.com;
   mueller@cs.stonybrook.edu; chen1.xin@midea.com
OI Chen, Xin/0000-0003-1950-2468; Li, Heyi/0000-0002-2979-0849
FU Midea Corporate Research Center University Program; NSF [IIS 1527200];
   MSIP (Ministry of Science, ICT and Future Planning), Korea, under the
   "ITCCP Program"
FX This work is supported by Midea Corporate Research Center University
   Program. We would also like to show our gratitude to Prof. Tengyu Ma for
   his comments on an earlier version of the manuscript.r This research was
   also partially supported by NSF grant IIS 1527200, as well as the MSIP
   (Ministry of Science, ICT and Future Planning), Korea, under the "ITCCP
   Program" directed by NIPA.
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2013, PRINCIPLES GESTALT P
   [Anonymous], 2014, WORKSH INT C LEARN R
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2015, ICML WORKSH DEEP LEA
   [Anonymous], ICML WORKSH VIS DEEP
   [Anonymous], 2017, NEURIPS
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], NIPS WORKSH 2017 EXP
   [Anonymous], ARXIV170505598V2
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carrasco M, 2011, VISION RES, V51, P1484, DOI 10.1016/j.visres.2011.04.012
   Chen ZH, 2013, NEUROCOMPUTING, V99, P298, DOI 10.1016/j.neucom.2012.08.001
   Cho K, 2015, IEEE T MULTIMEDIA, V17, P1875, DOI 10.1109/TMM.2015.2477044
   Colombo J, 2001, ANNU REV PSYCHOL, V52, P337, DOI 10.1146/annurev.psych.52.1.337
   Dosovitskiy A, 2016, PROC CVPR IEEE, P4829, DOI 10.1109/CVPR.2016.522
   Erhan D., 2009, Bernoulli
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Han JW, 2018, IEEE SIGNAL PROC MAG, V35, P84, DOI 10.1109/MSP.2017.2749125
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Harley AW, 2015, LECT NOTES COMPUT SC, V9474, P867, DOI 10.1007/978-3-319-27857-5_77
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kahng M, 2018, IEEE T VIS COMPUT GR, V24, P88, DOI 10.1109/TVCG.2017.2744718
   Kim Y., 2017, INT C LEARNING REPRE
   Lee S-I, 2017, P 31 INT C NEURAL IN, P4765
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li HY, 2017, NEUROCOMPUTING, V226, P212, DOI 10.1016/j.neucom.2016.11.056
   Liu MC, 2017, IEEE T VIS COMPUT GR, V23, P91, DOI 10.1109/TVCG.2016.2598831
   Mahendran A, 2016, INT J COMPUT VISION, V120, P233, DOI 10.1007/s11263-016-0911-8
   Montavon G, 2017, PATTERN RECOGN, V65, P211, DOI 10.1016/j.patcog.2016.11.008
   Mukherjee P, 2017, IMAGE VISION COMPUT, V61, P82, DOI 10.1016/j.imavis.2017.02.008
   Oh K, 2016, IMAGE VISION COMPUT, V54, P31, DOI 10.1016/j.imavis.2016.07.007
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pezzotti N, 2018, IEEE T VIS COMPUT GR, V24, P98, DOI 10.1109/TVCG.2017.2744358
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shrikumar A, 2017, PR MACH LEARN RES, V70
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Terzic K, 2017, IMAGE VISION COMPUT, V67, P43, DOI 10.1016/j.imavis.2017.09.007
   Tissera MD, 2016, NEUROCOMPUTING, V174, P42, DOI 10.1016/j.neucom.2015.03.110
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu SQ, 2017, NEUROCOMPUTING, V219, P88, DOI 10.1016/j.neucom.2016.09.010
   Zhu ZF, 2014, IMAGE VISION COMPUT, V32, P180, DOI 10.1016/j.imavis.2013.12.015
NR 47
TC 17
Z9 18
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR-APR
PY 2019
VL 83-84
BP 70
EP 86
DI 10.1016/j.imavis.2019.02.005
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HW6TR
UT WOS:000466824000007
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Torres, MT
   Valstar, M
   Henry, C
   Ward, C
   Sharkey, D
AF Torres, Mercedes Torres
   Valstar, Michel
   Henry, Caroline
   Ward, Carole
   Sharkey, Don
TI Postnatal gestational age estimation of newborns using Small Sample Deep
   Learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Computer vision; Deep learning; Small sample; Gestational age
AB A baby's gestational age determines whether or not they are premature, which helps clinicians decide on suitable post-natal treatment. The most accurate dating methods use Ultrasound Scan (USS) machines, but these are expensive, require trained personnel and cannot always be deployed to remote areas. In the absence of USS, the Ballard Score, a postnatal clinical examination, can be used. However, this method is highly subjective and results vary widely depending on the experience of the examiner. Our main contribution is a novel system for automatic postnatal gestational age estimation using small sets of images of a newborn's face, foot and ear. Our two-stage architecture makes the most out of Convolutional Neural Networks trained on small sets of images to predict broad classes of gestational age, and then fuses the outputs of these discrete classes with a baby's weight to make fine-grained predictions of gestational age using Support Vector Regression. On a purpose-collected dataset of 130 babies, experiments show that our approach surpasses current automatic state-of-the-art postnatal methods and attains an expected error of 6 days. It is three times more accurate than the Ballard method. Making use of images improves predictions by 33% compared to using weight only. This indicates that even with a very small set of data, our method is a viable candidate for postnatal gestational age estimation in areas were USS is not available. (C) 2018 Published by Elsevier B.V.
C1 [Torres, Mercedes Torres; Valstar, Michel] Univ Nottingham, Sch Comp Sci, Nottingham, England.
   [Henry, Caroline; Ward, Carole; Sharkey, Don] Univ Nottingham, Sch Med, Nottingham, England.
C3 University of Nottingham; University of Nottingham
RP Torres, MT (corresponding author), Univ Nottingham, Sch Comp Sci, Nottingham, England.
EM mercedes.torrestorres@nottingham.ac.uk
OI Valstar, Michel/0000-0003-2414-161X; Sharkey, Don/0000-0002-4989-8697
FU RCUK through the Horizon Digital Economy Research grants [EP/G065802/1,
   EP/M000877/1]; Grand Challenges Exploration grant from the Bill and
   Melinda Gates Foundation [OPP1119369]; Bill and Melinda Gates Foundation
   [OPP1119369] Funding Source: Bill and Melinda Gates Foundation; EPSRC
   [EP/M02315X/1, EP/G065802/1] Funding Source: UKRI
FX This work was supported by the RCUK through the Horizon Digital Economy
   Research grants (EP/G065802/1, EP/M000877/1). This research was funded
   by a Grand Challenges Exploration grant from the Bill and Melinda Gates
   Foundation (OPP1119369).
CR [Anonymous], NEWBORN BABY DANDERY
   [Anonymous], 2012, Born Too Soon
   [Anonymous], P 7 INT C AUT FAC
   [Anonymous], P CVPR WORKSH
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], ACAD RADIOL, DOI DOI 10.1016/S1076-6332(03)00671-8
   [Anonymous], IEEE INT CONF AUTOMA
   Awad M., 2015, Neural Information Processing-Letters and Reviews, P67, DOI [DOI 10.1007/978-1-4302-5990-94, 10.1007/978-1-4302-5990-9_4, DOI 10.1007/978-1-4302-5990-9_4]
   BALLARD JL, 1991, J PEDIATR-US, V119, P417, DOI 10.1016/S0022-3476(05)82056-6
   Black RE, 2003, LANCET, V361, P2226, DOI 10.1016/S0140-6736(03)13779-8
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   CAMPBELL S, 1985, OBSTET GYNECOL, V65, P613
   Crum WR, 2006, IEEE T MED IMAGING, V25, P1451, DOI 10.1109/TMI.2006.880587
   DUBOWITZ LM, 1970, J PEDIATR-US, V77, P1, DOI 10.1016/S0022-3476(70)80038-5
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Hao Liu, 2017, 2017 12th IEEE International Conference on Automatic Face & Gesture Recognition (FG 2017), P157, DOI 10.1109/FG.2017.28
   Jones G, 2003, LANCET, V362, P65, DOI 10.1016/S0140-6736(03)13811-1
   KRAMER MS, 1988, JAMA-J AM MED ASSOC, V260, P3306, DOI 10.1001/jama.260.22.3306
   Lee ACC, 2016, PEDIATRICS, V138, DOI 10.1542/peds.2015-3303
   Lynch CD, 2007, PAEDIATR PERINAT EP, V21, P86, DOI 10.1111/j.1365-3016.2007.00865.x
   Oza S, 2015, B WORLD HEALTH ORGAN, V93, P19, DOI 10.2471/BLT.14.139790
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   SCHEUER JL, 1980, ANN HUM BIOL, V7, P257, DOI 10.1080/03014468000004301
   Smistad E, 2015, MED IMAGE ANAL, V20, P1, DOI 10.1016/j.media.2014.10.012
   Taylor RAM, 2010, ANN TROP PAEDIATR, V30, P197, DOI 10.1179/146532810X12786388978526
   Wang XL, 2017, IEEE INT CONF AUTOMA, P566, DOI 10.1109/FG.2017.141
   Wang XL, 2015, IEEE WINT CONF APPL, P534, DOI 10.1109/WACV.2015.77
NR 29
TC 12
Z9 12
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR-APR
PY 2019
VL 83-84
BP 87
EP 99
DI 10.1016/j.imavis.2018.09.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA HW6TR
UT WOS:000466824000008
PM 31762527
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Mendonça, M
   Oliveira, L
AF Mendonca, Marcelo
   Oliveira, Luciano
TI ISEC: Iterative over-segmentation via edge clustering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Superpixels; Video object segmentation
AB Several image pattern recognition tasks rely on superpixel generation as a fundamental step. Image analysis based on superpixels facilitates domain-specific applications, also speeding up the overall processing time of the task. Recent superpixel methods have been designed to fit boundary adherence, usually regulating the size and shape of each superpixel in order to mitigate the occurrence of undersegmentation failures. Super pixel regularity and compactness sometimes imposes an excessive number of segments in the image, which ultimately decreases the efficiency of the final segmentation, specially in video segmentation. We propose here a novel method to generate superpixels, called iterative over-segmentation via edge clustering (ISEC), which addresses the over-segmentation problem from a different perspective in contrast to recent stateof-the-art approaches. ISEC iteratively clusters edges extracted from the image objects, providing adaptive superpixels in size, shape and quantity, while preserving suitable adherence to the real object boundaries. All this is achieved at a very low computational cost Experiments show that ISEC stands out from existing methods, meeting a favorable balance between segmentation stability and accurate representation of motion discontinuities, which are features specially suitable to video segmentation. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Mendonca, Marcelo; Oliveira, Luciano] Univ Fed Bahia, Intelligent Vis Res Lab, Salvador, BA, Brazil.
C3 Universidade Federal da Bahia
RP Oliveira, L (corresponding author), Univ Fed Bahia, Intelligent Vis Res Lab, Salvador, BA, Brazil.
EM lrebouca@ufba.br
RI Oliveira, Luciano R/K-8496-2012
OI Oliveira, Luciano R/0000-0001-7183-8853
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], BMVC
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   Bódis-Szomorú A, 2015, PROC CVPR IEEE, P2011, DOI 10.1109/CVPR.2015.7298812
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Cui BE, 2018, IEEE T GEOSCI REMOTE, V56, P3233, DOI 10.1109/TGRS.2018.2796069
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fracastoro G, 2015, IEEE IMAGE PROC, P2631, DOI 10.1109/ICIP.2015.7351279
   Gadde R, 2016, LECT NOTES COMPUT SC, V9905, P597, DOI 10.1007/978-3-319-46448-0_36
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Giraud R, 2017, IEEE T IMAGE PROCESS, V26, P4068, DOI 10.1109/TIP.2017.2708504
   Gould S., 2014, SUPERPIXEL GRAPH LAB, P632, DOI [10.1007/978-3-319-10590-1_41, DOI 10.1007/978-3-319-10590-1_41]
   Ji SY, 2014, COMPUT MATH METHOD M, V2014, DOI 10.1155/2014/747549
   Khoreva A, 2016, LECT NOTES COMPUT SC, V9915, P773, DOI 10.1007/978-3-319-49409-8_64
   Li ZQ, 2015, PROC CVPR IEEE, P1356, DOI 10.1109/CVPR.2015.7298741
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   MEYER F, 1992, IEE CONF PUBL, V354, P303
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Moore AP, 2010, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2010.5539890
   Neubert P, 2014, INT C PATT RECOG, P996, DOI 10.1109/ICPR.2014.181
   Neubert P, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.54
   Nguyen BP, 2016, BMC SYST BIOL, V10, DOI 10.1186/s12918-016-0372-2
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Rubio A, 2016, INT C PATT RECOG, P2824, DOI 10.1109/ICPR.2016.7900064
   Santos M, 2013, IEEE INT VEH SYM, P527, DOI 10.1109/IVS.2013.6629521
   Schick A, 2012, INT C PATT RECOG, P930
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   Tian ZQ, 2016, IEEE T MED IMAGING, V35, P791, DOI 10.1109/TMI.2015.2496296
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Vedaldi A., 2008, Quick shift and kernel methods for mode seeking, P705, DOI DOI 10.1007/978-3-540-88693-8_52
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   Wang MR, 2017, SIGNAL PROCESS-IMAGE, V56, P28, DOI 10.1016/j.image.2017.04.007
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
NR 35
TC 3
Z9 4
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2018
VL 80
BP 45
EP 57
DI 10.1016/j.imavis.2018.09.015
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HF6VQ
UT WOS:000454376800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Crosswhite, N
   Byrne, J
   Stauffer, C
   Parkhi, O
   Cao, Q
   Zisserman, A
AF Crosswhite, Nate
   Byrne, Jeffrey
   Stauffer, Chris
   Parkhi, Omkar
   Cao, Qiong
   Zisserman, Andrew
TI Template adaptation for face verification and identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Face recognition; Biometrics; Face verification
AB Face recognition performance evaluation has traditionally focused on one-to-one verification, popularized by the Labeled Faces in the Wild data set [1] for imagery and the YouTubeFaces data set [2] for videos. In contrast, the newly released IJB-A face recognition data set [3] unifies evaluation of one-to-many face identification with one-to-one face verification over templates, or sets of imagery and videos for a subject. In this paper, we study the problem of template adaptation, a form of transfer learning to the set of media in a template. Extensive performance evaluations on IJB-A show a surprising result, that perhaps the simplest method of template adaptation, combining deep convolutional network features with template specific linear SVMs, outperforms the state-of-the-art by a wide margin. We study the effects of template size, negative set construction and classifier fusion on performance, then compare template adaptation to convolutional networks with metric learning, 2D and 3D alignment. Our unexpected conclusion is that these other methods, when combined with template adaptation, all achieve nearly the same top performance on IJB-A for template-based face verification and identification. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Crosswhite, Nate; Byrne, Jeffrey] Syst & Technol Res, Woburn, MA 01801 USA.
   [Stauffer, Chris] Visionary Syst & Res, Framingham, MA USA.
   [Parkhi, Omkar; Cao, Qiong; Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Oxford, England.
C3 University of Oxford
RP Byrne, J (corresponding author), Syst & Technol Res, Woburn, MA 01801 USA.
EM jeffrey.byrne@stresearch.com
FU Office of the Director of National Intelligence (ODNI), Intelligence
   Advanced Research Projects Activity (IARPA) [2014-14071600010]
FX This research is based upon work supported by the Office of the Director
   of National Intelligence (ODNI), Intelligence Advanced Research Projects
   Activity (IARPA) under contract number 2014-14071600010. The views and
   conclusions contained herein are those of the authors and should not be
   interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of ODNI, IARPA, or the U.S.
   Government. The U.S. Government is authorized to reproduce and
   distribute reprints for Governmental purpose notwithstanding any
   copyright annotation thereon.
CR [Anonymous], 2018, 11 IAPR INT C BIOM
   [Anonymous], 2015, CVPR
   [Anonymous], 2014, LEARNING FACE REPRES
   [Anonymous], CVPR
   [Anonymous], ECCV
   [Anonymous], 2015, ARXIV14043840
   [Anonymous], 2015, BMVC
   [Anonymous], 2015, CVPR
   [Anonymous], [No title captured]
   [Anonymous], 2014, CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], 2013, ICML
   [Anonymous], 2011, ICCV
   [Anonymous], 2015, CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], 2017, L2 CONSTRAINED SOFTM
   [Anonymous], WACV
   [Anonymous], ICCV
   [Anonymous], 2014, 8009 NIST
   Chatfield K., 2015, INT J MULTIMED INF R
   Chen J., 2015, ICCV WORKSH CHALEARN
   Chen V. PJ., 2016, WACV
   Crosswhite N., 2016, Template adaptation for face verification and identification
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Hayat M., 2017, CVPR
   Hu G., 2015, ICCV WORKSH CHALEARN
   Huang G.B., 2008, PROC WORKSHOP FACES
   Kobayashi T., 2015, CVPR
   Phillips J., 2015, BTAS
   RoyChowdry A., 2016, WACV
   Sankaranarayanan S., 2016, Triplet similarity embedding for face verification
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Sun Y., 2014, DEEPID3 FACE RECOGNI
   Taigman Y., 2014, CVPR
   Whitelam C., 2017, CVPR WORKSH BIOM
   Wolf L., 2011, CVPR
   Wolf L, 2011, PAMI, V33
   Xiong L., 2017, A good practice towards top performance of face recognition: Transferred deep feature fusion
   Zinkevich M., 2011, NIPS
NR 39
TC 28
Z9 34
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 35
EP 48
DI 10.1016/j.imavis.2018.09.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fernandez-Lopez, A
   Sukno, FM
AF Fernandez-Lopez, Adriana
   Sukno, Federico M.
TI Survey on automatic lip-reading in the era of deep learning
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Automatic lip-reading; Audio-visual corpora; Visual speech decoding;
   Deep learning systems; Multi-view lip-reading
ID AUDIOVISUAL SPEECH RECOGNITION; ACTIVE APPEARANCE MODELS;
   FEATURE-EXTRACTION; DATABASE; FEATURES
AB In the last few years, there has been an increasing interest in developing systems for Automatic Lip-Reading (ALR). Similarly to other computer vision applications, methods based on Deep Learning (DL) have become very popular and have permitted to substantially push forward the achievable performance. In this survey, we review ALR research during the last decade, highlighting the progression from approaches previous to DL (which we refer to as traditional) toward end-to-end DL architectures. We provide a comprehensive list of the audio-visual databases available for lip-reading, describing what tasks they can be used for, their popularity and their most important characteristics, such as the number of speakers, vocabulary size, recording settings and total duration. In correspondence with the shift toward DL, we show that there is a clear tendency toward large-scale datasets targeting realistic application settings and large numbers of samples per class. On the other hand, we summarize, discuss and compare the different ALR systems proposed in the last decade, separately considering traditional and DL approaches. We address a quantitative analysis of the different systems by organizing them in terms of the task that they target (e.g. recognition of letters or digits and words or sentences) and comparing their reported performance in the most commonly used datasets. As a result, we find that DL architectures perform similarly to traditional ones for simpler tasks but report significant improvements in more complex tasks, such as word or sentence recognition, with up to 40% improvement in word recognition rates. Hence, we provide a detailed description of the available ALR systems based on end-to-end DL architectures and identify a tendency to focus on the modeling of temporal context as the key to advance the field. Such modeling is dominated by recurrent neural networks due to their ability to retain context at multiple scales (e.g. short- and long-term information). In this sense, current efforts tend toward techniques that allow a more comprehensive modeling and interpretability of the retained context. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Fernandez-Lopez, Adriana; Sukno, Federico M.] Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona, Spain.
C3 Pompeu Fabra University
RP Sukno, FM (corresponding author), Univ Pompeu Fabra, Dept Informat & Commun Technol, Barcelona, Spain.
EM adriana.fernandez@upf.edu; federico.sukno@upf.edu
RI Sukno, Federico/AAM-4440-2021
OI Sukno, Federico/0000-0002-2029-1576
FU Spanish Ministry of Economy and Competitiveness, Spain
   [TIN2017-90124-P]; Ramon y Cajal Programme; Maria de Maeztu Units of
   Excellence Programme [MDM-2015-0502]; Kristina project - European Union
   Horizon 2020 - Research and Innovation Framework Programme [645012];
   H2020 - Industrial Leadership [645012] Funding Source: H2020 -
   Industrial Leadership
FX This work is partly supported by the Spanish Ministry of Economy and
   Competitiveness, Spain under project grant TIN2017-90124-P, the Ramon y
   Cajal Programme, the Maria de Maeztu Units of Excellence Programme
   (MDM-2015-0502), and the Kristina project funded by the European Union
   Horizon 2020 - Research and Innovation Framework Programme under grant
   agreement No. 645012.
CR Almajai I, 2016, INT CONF ACOUST SPEE, P2722, DOI 10.1109/ICASSP.2016.7472172
   [Anonymous], 2012, INT CONF ACOUST SPEE
   [Anonymous], 2004, ICMI'04-Sixth International Conference on Multimodal Interfaces, DOI [DOI 10.1145/1027933.1027972, 10.1145/1027933.1027972]
   [Anonymous], 2018, P INT
   [Anonymous], 2000, AUDIO-VISUAL SPEECH RECOGNITION
   [Anonymous], 2016, ASIAN C COMPUTER VIS
   [Anonymous], 2009, INT C AUDITORY VISUA
   [Anonymous], 2015, PROC C AUDITORY VIS
   [Anonymous], P INT C FAC AN AN AU
   [Anonymous], 2004, Issues in visual and audio-visual speech processing
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], P IEEE OSA OFC NFOEC
   [Anonymous], THESIS
   [Anonymous], 2018, P INT
   [Anonymous], 2017, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-54427-4_21
   Antonakos Epameinondas, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163162
   Assael Y. M., 2017, P GPU TECHN C
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Bailly-Bailliére E, 2003, LECT NOTES COMPUT SC, V2688, P625
   Bear H. L., 2017, P C FAC AN AN AUD VI
   Bear HL, 2017, SPEECH COMMUN, V95, P40, DOI 10.1016/j.specom.2017.07.001
   Bear HL, 2016, INT CONF ACOUST SPEE, P2009, DOI 10.1109/ICASSP.2016.7472029
   Bear HL, 2014, LECT NOTES COMPUT SC, V8888, P230, DOI 10.1007/978-3-319-14364-4_22
   Benezeth Y., 2011, THESIS
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Biswas A, 2015, COMPUT ELECTR ENG, V47, P35, DOI 10.1016/j.compeleceng.2015.08.009
   Bocquelet F, 2016, PLOS COMPUT BIOL, V12, DOI 10.1371/journal.pcbi.1005119
   Bowden R., 2013, CRIME FIGHTING DEFEN, V8901
   Bozkurt, 2007, 3DTV C, P1
   Buchan JN, 2007, SOC NEUROSCI-UK, V2, P1, DOI 10.1080/17470910601043644
   Cappelletta L, 2011, EUR SIGNAL PR CONF, P2109
   Chitu A., 2012, Speech Enhancement, Modeling And Recognition, P95
   Chitu AG, 2010, LECT NOTES ARTIF INT, V6231, P259, DOI 10.1007/978-3-642-15760-8_33
   Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Chung Joon Son, 2016, P AS C COMP VIS, P251, DOI DOI 10.1007/978-3-319-54427-4_19
   Chung Joon Son, 2017, P BRIT MACH VIS C
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Cox S., 2008, The challenge of multispeaker lip-reading
   Czyzewski A, 2017, J INTELL INF SYST, V49, P167, DOI 10.1007/s10844-016-0438-z
   Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479
   Ephrat A., 2017, P INT WORKSH COMP VI
   ERBER NP, 1975, J SPEECH HEAR DISORD, V40, P481, DOI 10.1044/jshd.4004.481
   Estellers V, 2012, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2012-51
   Estellers V, 2011, EUR SIGNAL PR CONF, P1065
   Estellers V, 2012, IEEE T AUDIO SPEECH, V20, P1145, DOI 10.1109/TASL.2011.2172427
   Estival D., 2014, P INT C LANG RES EV
   Eveno N, 2004, IEEE T CIRC SYST VID, V14, P706, DOI 10.1109/TCSVT.2004.826754
   Fernandez-Lopez A, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P52, DOI 10.5220/0006102100520063
   Fernandez-Lopez A, 2017, IEEE INT CONF AUTOMA, P208, DOI 10.1109/FG.2017.34
   FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796
   Fox NA, 2005, LECT NOTES COMPUT SC, V3546, P777
   Fung H. L., 2018, P INT C AC SPEECH SI
   Gabbay A., 2017, P INT WORKSH COMP VI
   Georgakis Christos, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4828, DOI 10.1109/ICASSP.2014.6854519
   Georgakis C, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1177, DOI 10.1145/2647868.2655026
   Georgakis C, 2016, IEEE T CYBERNETICS, V46, P2758, DOI 10.1109/TCYB.2015.2488592
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1049/cp:19991218, 10.1162/089976600300015015]
   Goecke R., 2004, Proc. of the International Conference on Spoken Language Processing (ICSLP), V3, P2525, DOI 10.21437/Interspeech.2004-433
   Gowdy J. N., 2004, P INT C AC SPEECH SI, V1, P1
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Gurban M, 2009, IEEE T SIGNAL PROCES, V57, P4765, DOI 10.1109/TSP.2009.2026513
   Hannun A., 2014, P INT C MACH LEARN
   Harte N, 2015, IEEE T MULTIMEDIA, V17, P603, DOI 10.1109/TMM.2015.2407694
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hilder S., 2009, AVSP, P86
   Hong XP, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P321
   Howell D, 2016, IMAGE VISION COMPUT, V51, P1, DOI 10.1016/j.imavis.2016.03.003
   HU D, 2016, PROC CVPR IEEE, P3574, DOI DOI 10.1109/CVPR.2016.389
   Huang J, 2004, SPEECH COMMUN, V44, P83, DOI 10.1016/j.specom.2004.10.007
   Huang J, 2013, INT CONF ACOUST SPEE, P7596, DOI 10.1109/ICASSP.2013.6639140
   Ian Y., 2010, P INT C AUD VIS SPEE
   Igras Magdalena, 2012, Studia Informatica, V33, P163
   Jaurnard-Hakoun A, 2016, INTERSPEECH, P1467, DOI 10.21437/Interspeech.2016-385
   Jeffers J., 1971, SPEECHREADING LIPREA
   Kolossa D., 2009, P INT C AUD VIS SPEE, P117
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar K, 2007, INT CONF ACOUST SPEE, P429
   Kuwabara H., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P560, DOI 10.1109/ICASSP.1989.266488
   Lee B., 2004, P INT
   Lee D., 2016, P AS C COMP VIS SPRI, P290
   Lesani F.S., 2015, 2015 9 INT C ECOMMER, P1, DOI DOI 10.1109/ECDC.2015.7156322
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lucey P., 2007, P 8 ANN C INT SPEECH, P650
   Lucey P.J., 2008, PATCH BASED ANAL VIS
   Lucey P, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P24, DOI 10.1109/MMSP.2006.285261
   Lucey P, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P2679
   Luettin J, 1996, INT CONF ACOUST SPEE, P817, DOI 10.1109/ICASSP.1996.543246
   Marcheret E, 2007, INT CONF ACOUST SPEE, P945
   Mase K., 1991, Systems and Computers in Japan, V22, P67
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Mathulaprangsan S, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON ORANGE TECHNOLOGIES (ICOT), P22, DOI 10.1109/ICOT.2015.7498485
   Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900
   Mattos AB, 2018, 15TH INTERNATIONAL WEB FOR ALL CONFERENCE (W4A) 2018, DOI 10.1145/3192714.3192824
   McCool C, 2012, IEEE INT CONF MULTI, P635, DOI 10.1109/ICMEW.2012.116
   MCGURK H, 1976, NATURE, V264, P746, DOI 10.1038/264746a0
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   MOLL KL, 1971, J ACOUST SOC AM, V50, P678, DOI 10.1121/1.1912683
   Moon S., 2015, MMML WORKSH NEUR INF
   Mroueh Y, 2015, INT CONF ACOUST SPEE, P2130, DOI 10.1109/ICASSP.2015.7178347
   Navarathna R., 2011, INTERSPEECH, P2241
   Nefian AV, 2002, EURASIP J APPL SIG P, V2002, P1274, DOI 10.1155/S1110865702206083
   Nefian AV, 2002, INT CONF ACOUST SPEE, P2013
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Ninomiya H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P563
   Noda K, 2014, INTERSPEECH, P1149
   Noda K, 2015, APPL INTELL, V42, P722, DOI 10.1007/s10489-014-0629-7
   Ong EJ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.55
   Ong Eng-Jon, 2011, COMP VIS WORKSH ICCV, P958
   Ordóñez FJ, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16010115
   Orozco J, 2015, IMAGE VISION COMPUT, V42, P47, DOI 10.1016/j.imavis.2015.07.002
   Orozco J, 2013, IMAGE VISION COMPUT, V31, P322, DOI 10.1016/j.imavis.2013.02.001
   Ortega A., 2004, Proc. of the International Conference on Language Resources and Evaluation (LREC), V3, P763
   Papaefthymiou G, 2008, 2008 10TH INTERNATIONAL CONFERENCE ON PROBABILISTIC METHODS APPLIED TO POWER SYSTEMS, P9
   Papandreou G, 2009, IEEE T AUDIO SPEECH, V17, P423, DOI 10.1109/TASL.2008.2011515
   Pass A, 2010, IEEE IMAGE PROC, P2417, DOI 10.1109/ICIP.2010.5650963
   Patterson EK, 2002, INT CONF ACOUST SPEE, P2017
   Pei YR, 2013, IEEE I CONF COMP VIS, P129, DOI 10.1109/ICCV.2013.23
   Petridis S., 2017, P INT C AUD VIS SPEE
   Petridis S., 2018, P INT C AC SPEECH SI
   Petridis S., 2017, P BRIT MACH VIS C
   Petridis S, 2017, INT CONF ACOUST SPEE, P2592, DOI 10.1109/ICASSP.2017.7952625
   Petridis S, 2016, INT CONF ACOUST SPEE, P2304, DOI 10.1109/ICASSP.2016.7472088
   Petrovska-Delacretaz D., 2008, 2008 IEEE 2 INT C BI, P1
   Pietikainen M., 2015, 11 IEEE INT C WORKSH, P1, DOI DOI 10.1109/FG.2015.7163155
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Rahmani MH, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P195, DOI 10.1109/PRIA.2017.7983045
   Rekik A, 2016, MULTIMED TOOLS APPL, V75, P8609, DOI 10.1007/s11042-015-2774-3
   Rekik A, 2014, LECT NOTES COMPUT SC, V8815, P21, DOI 10.1007/978-3-319-11755-3-3
   Rodriguez-Ortiz IR, 2008, SPAN J PSYCHOL, V11, P488, DOI 10.1017/S1138741600004492
   Ronquest RE, 2010, ATTEN PERCEPT PSYCHO, V72, P1601, DOI 10.3758/APP.72.6.1601
   Sagonas C, 2016, IMAGE VISION COMPUT, V47, P3, DOI 10.1016/j.imavis.2016.01.002
   Sahu V, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON GREEN HIGH PERFORMANCE COMPUTING (ICGHPC)
   Saitoh T., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1356, DOI 10.1109/ICPR.2010.335
   Sanderson C., 2004, VIDTIMIT DATABASE
   Sengupta S., 2012, INT J APPL INF SYST, P2249
   Seymour R, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/810362
   Shao X, 2008, SPEECH COMMUN, V50, P337, DOI 10.1016/j.specom.2007.11.002
   Srivastava R. K., 2015, ADV NEURAL INFORM PR, P2377, DOI DOI 10.48550/ARXIV.1505.00387
   Stafylakis T, 2017, INTERSPEECH, P3652, DOI 10.21437/Interspeech.2017-85
   Sterpu G., 2017, P INT C AUD VIS SPEE
   Stewart D, 2014, IEEE T CYBERNETICS, V44, P175, DOI 10.1109/TCYB.2013.2250954
   Sui C, 2017, SPEECH COMMUN, V90, P26, DOI 10.1016/j.specom.2017.01.005
   Sui C, 2015, IEEE I CONF COMP VIS, P154, DOI 10.1109/ICCV.2015.26
   SUMBY WH, 1954, J ACOUST SOC AM, V26, P212, DOI 10.1121/1.1907309
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Takashima Y, 2016, INTERSPEECH, P277, DOI 10.21437/Interspeech.2016-721
   Tamura S., 2010, P INT C AUD VIS SPEE
   Thangthai K, 2017, INTERSPEECH, P3657, DOI 10.21437/Interspeech.2017-106
   Trojanova J., 2008, P INT C LANG RES EV
   Twaddell WF, 1936, LANGUAGE, V12, P53, DOI 10.2307/409020
   Tzimiropoulos G, 2017, INT J COMPUT VISION, V122, P17, DOI 10.1007/s11263-016-0950-1
   Verkhodanova V, 2016, LECT NOTES COMPUT SC, V9811, P338, DOI 10.1007/978-3-319-43958-7_40
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vorwerk A., 2010, P INT C LANG RES EV
   Wand M., 2018, P INT C AC SPEECH SI
   Wand M, 2017, INTERSPEECH, P3662, DOI 10.21437/Interspeech.2017-421
   Wand M, 2016, INT CONF ACOUST SPEE, P6115, DOI 10.1109/ICASSP.2016.7472852
   Wang SL, 2008, IEEE T CIRC SYST VID, V18, P1760, DOI 10.1109/TCSVT.2008.2004924
   Wong YW, 2011, PATTERN RECOGN LETT, V32, P1503, DOI 10.1016/j.patrec.2011.06.011
   Wu PP, 2016, IEEE T MULTIMEDIA, V18, P326, DOI 10.1109/TMM.2016.2520091
   Wu Y., 2017, Proc. 2017 IEEE Conf. Computer Communications (INFOCOM), P1, DOI 10.1109/infocom.2017.8057072
   Xu K, 2018, IEEE INT CONF AUTOMA, P548, DOI 10.1109/FG.2018.00088
   Yao X. L. H., 2008, P C INF SCI
   Yau WC, 2007, LECT NOTES COMPUT SC, V4673, P832
   Yu X, 2016, IEEE T PATTERN ANAL, V38, P2212, DOI 10.1109/TPAMI.2015.2509999
   Yun Fu, 2007, Proceedings 2007 IEEE International Conference on Image Processing, ICIP 2007, P325
   Yuxuan Lan, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P432, DOI 10.1109/ICME.2012.192
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhou Z., IEEE T PATTERN ANAL, V36
   Zhou ZH, 2011, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2011.5995345
   Zhou ZH, 2014, IMAGE VISION COMPUT, V32, P590, DOI 10.1016/j.imavis.2014.06.004
   Ziheng Zhou, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P523, DOI 10.1109/ICPR.2010.133
NR 176
TC 62
Z9 67
U1 3
U2 49
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2018
VL 78
BP 53
EP 72
DI 10.1016/j.imavis.2018.07.002
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV5LO
UT WOS:000446143900005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Serdouk, Y
   Nemmour, H
   Chibani, Y
AF Serdouk, Yasmine
   Nemmour, Hassiba
   Chibani, Youcef
TI Handwritten signature verification using the quad-tree histogram of
   templates and a Support Vector-based artificial immune classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Artificial Immune Recognition System; Handwritten signature
   verification; Histogram Of Templates; Support Vector decision
ID OFF-LINE SIGNATURE; RECOGNITION SYSTEM; PATTERN-RECOGNITION; MACHINES;
   SVM; CLASSIFIERS; COMBINATION; PARAMETERS
AB This work proposes a novel system for off-line handwritten signature verification. A new descriptor founded on a quad-tree structure of the Histogram Of Templates (HOT) is introduced. For the verification step, we propose a robust implementation of the Artificial Immune Recognition System (AIRS). This classifier is inspired from the natural immune system, which generates antibodies to protect the human body against antigens. The AIRS training develops new memory cells that are subsequently used to recognize data through a k Nearest Neighbor (kNN) classification. Presently, to get a robust verification, the kNN classification is substituted by a Support Vector (SV) decision, yielding the AIRSV classifier. Experiments are performed on three datasets, namely, MCYT-75, GPDS-300 and GPDS-4000. AIRSV performance is assessed comparatively to both conventional AIRS as well as SVM. Obtained results demonstrated that AIRSV is more effective than classical AIRS. Moreover, the proposed signature verification system gives similar and sometimes better performance than SVM as well as the state-of-the-art methods. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Serdouk, Yasmine; Nemmour, Hassiba; Chibani, Youcef] USTHB, Fac Elect & Comp Sci, LISIC, Bab Ezzouar El Alia BP 32, Algiers 16111, Algeria.
C3 University Science & Technology Houari Boumediene
RP Serdouk, Y (corresponding author), USTHB, Fac Elect & Comp Sci, LISIC, Bab Ezzouar El Alia BP 32, Algiers 16111, Algeria.
EM yserdouk@usthb.dz; hnemmour@usthb.dz; ychibani@usthb.dz
RI Chibani, Youcef/AAC-3617-2019; Nemmour, Hassiba/AAC-4941-2019; Nemmour,
   Hassiba/AAC-2518-2019
OI Chibani, Youcef/0000-0002-7957-7456; Nemmour,
   Hassiba/0000-0001-6583-5402; 
CR Alonso-Fernandez F, 2007, IEEE IMAGE PROC, P369
   Ancona N, 2003, IMAGE VISION COMPUT, V21, P675, DOI 10.1016/S0262-8856(03)00063-5
   [Anonymous], THESIS
   [Anonymous], 2000, NATURE STAT LEARNING, DOI DOI 10.1007/978-1-4757-3264-1
   Baltzakis H, 2001, ENG APPL ARTIF INTEL, V14, P95, DOI 10.1016/S0952-1976(00)00064-6
   Bertolini D, 2010, PATTERN RECOGN, V43, P387, DOI 10.1016/j.patcog.2009.05.009
   Bharathi RK, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2063, DOI 10.1109/ICACCI.2013.6637499
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Chen GY, 2007, IMAGE VISION COMPUT, V25, P960, DOI 10.1016/j.imavis.2006.07.009
   Deng PS, 1999, COMPUT VIS IMAGE UND, V76, P173, DOI 10.1006/cviu.1999.0799
   Favorskaya M, 2014, FRONT ARTIF INTEL AP, V262, P421, DOI 10.3233/978-1-61499-405-3-421
   Ferrer M. A., GRUPO PROCESADO DIGI
   Ferrer MA, 2005, IEEE T PATTERN ANAL, V27, P993, DOI 10.1109/TPAMI.2005.125
   Ferrer MA, 2015, IEEE T PATTERN ANAL, V37, P667, DOI 10.1109/TPAMI.2014.2343981
   Ferrer MA, 2012, IEEE T INF FOREN SEC, V7, P966, DOI 10.1109/TIFS.2012.2190281
   Findik O, 2011, EXPERT SYST APPL, V38, P1942, DOI 10.1016/j.eswa.2010.07.126
   Frias-Martinez E, 2006, ENG APPL ARTIF INTEL, V19, P693, DOI 10.1016/j.engappai.2005.12.006
   Guerbai Y, 2015, PATTERN RECOGN, V48, P103, DOI 10.1016/j.patcog.2014.07.016
   Hafemann LG, 2016, INT C PATT RECOG, P2989, DOI 10.1109/ICPR.2016.7900092
   Hu J, 2013, PROC INT CONF DOC, P1345, DOI 10.1109/ICDAR.2013.272
   Impedovo D., 2008, 11 INT C FRONT HANDW, P19
   Justino EJR, 2005, PATTERN RECOGN LETT, V26, P1377, DOI 10.1016/j.patrec.2004.11.015
   Kessentini Y, 2015, PATTERN RECOGN, V48, P534, DOI 10.1016/j.patcog.2014.08.010
   Kodaz H, 2009, EXPERT SYST APPL, V36, P3086, DOI 10.1016/j.eswa.2008.01.026
   Kumar R, 2012, PATTERN RECOGN LETT, V33, P301, DOI 10.1016/j.patrec.2011.10.009
   Nemmour H, 2013, 2013 INTERNATIONAL CONFERENCE ON ELECTRONICS, COMPUTER AND COMPUTATION (ICECCO), P164, DOI 10.1109/ICECCO.2013.6718254
   Nguyen Vu, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1300, DOI 10.1109/ICDAR.2009.123
   Polat K, 2008, EXPERT SYST APPL, V34, P2039, DOI 10.1016/j.eswa.2007.02.009
   Pourshahabi MR, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P670, DOI 10.1109/SoCPaR.2009.132
   Prakash H. N., 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P121, DOI 10.1109/ICDAR.2009.67
   Ruiz-Del-Solar J, 2008, LECT NOTES COMPUT SC, V5197, P22, DOI 10.1007/978-3-540-85920-8_3
   Saidi M., 2011, INT C INF TECHN ITS, P2
   Sanchez-Reillo R, 2016, IMAGE VISION COMPUT, V55, P34, DOI 10.1016/j.imavis.2016.03.011
   Serdouk Y, 2016, EXPERT SYST APPL, V51, P186, DOI 10.1016/j.eswa.2016.01.001
   Serdouk Y, 2015, PROC INT CONF DOC, P196, DOI 10.1109/ICDAR.2015.7333751
   Serdouk Y, 2014, 2014 6TH INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION (SOCPAR), P118, DOI 10.1109/SOCPAR.2014.7007991
   Tang SP, 2010, INT CONF ACOUST SPEE, P2186, DOI 10.1109/ICASSP.2010.5495685
   Yilmaz M. B., 2011, P INT JOINT C BIOMET, P1
   Yilmaz MB, 2016, INFORM FUSION, V32, P109, DOI 10.1016/j.inffus.2016.02.003
   Zhao WX, 2011, ARTIF INTELL MED, V52, P1, DOI 10.1016/j.artmed.2011.03.001
NR 40
TC 27
Z9 28
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2017
VL 66
BP 26
EP 35
DI 10.1016/j.imavis.2017.08.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FJ9AO
UT WOS:000413060000003
DA 2024-07-18
ER

PT J
AU Bourlai, T
   Hornak, LA
AF Bourlai, Thirimachos
   Hornak, Lawrence A.
TI Face recognition outside the visible spectrum
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Biometrics Conference
CY OCT, 2015
CL London, ENGLAND
DE Face recognition; Ultraviolet imagery; Visible imagery; Near infrared
   imagery; Short-wave infrared imagery; Mid-wave infrared imagery;
   Long-wave infrared imagery; Cross-scenario face matching; Night-time
   imaging; Long-distance imaging
AB Automated face recognition (FR) is a well-studied problem, with a history of more than three decades. Facial recognition software that uses two dimensional (2D) images has advanced significantly in terms of accuracy over recent years. Despite the steps forward, face recognition is still not considered to be a solved problem for the cases of (i) difficult exposure conditions, such as during night-time, or in environments with unconstrained lighting, (ii) when operating at long standoff distances or at variable distances from the camera, and (iii) when using different camera sensors that operate in the same or different spectral bands. In practical forensic scenarios, it is often the case that investigators need to operate in difficult conditions, where face images captured in the aforementioned challenging cases need to be matched against good quality face images (gallery set) and where, grouping of the data in the context of demographic information (in terms of gender, ethnicity or other soft biometrics) may also be used in order to assist law enforcement officials, forensic investigators and security personnel in subject identification. In fact, in such practical scenarios, human recognition based solely on visible spectral images may not be feasible. Hence, an attractive solution is to develop efficient FR systems that can work in different practical scenarios. While different systems have been discussed and proposed over the years, an interesting approach is to increase the plurality of the source data, or in other words, start using data captured by camera sensors that cover a broad range of the electromagnetic spectrum that falls outside the visible band, including the ultraviolet (UV) and the infrared (IR) band. Thus, FR outside the visible spectrum is considered an area of growing research interest. This is further supported by the burgeoning market of camera sensors that continues to open new opportunities, at different spectral and spatial scales, in a large number of applications including those in security, forensics and defense. In light of these thoughts, the focus of this work is to expose readers to a plethora of FR advancements when operating outside the visible spectrum and our perspective on where this field is going. The discussion will include the latest studies in the UV (100-400 nm), active IR band (0.7-2.5 mu m) and, finally, the passive IR band, or more specifically, the mid-wave IR (3-5 mu m) and long-wave IR (8-14 mu m) bands. The discussion will also include research work that involves same-spectral and cross spectral matching scenarios, where, first, face images (probes) are acquired under controlled or difficult conditions as explained above, including dealing with uncooperative subjects, and adverse environments. Then, depending on the FR scenario, the acquired probe images are matched against mug shots collected in a controlled indoor environment using a conventional camera. This paper will start by briefly covering different multi-spectral FR systems and, then, discussing various related topics (ranging from data acquisition sets, up to system performance). The paper will also suggest needed new avenues of inquiry in the context of current work in multi-spectral FR system. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Bourlai, Thirimachos] West Virginia Univ, Benjamin M Salter Coll Engn & Mineral Resources, POB 6070, Morgantown, WV 26506 USA.
   [Hornak, Lawrence A.] Univ Georgia, Coll Engn, 130 Paul D Coverdell Ctr, Athens, GA 30602 USA.
C3 West Virginia University; University System of Georgia; University of
   Georgia
RP Bourlai, T (corresponding author), West Virginia Univ, Benjamin M Salter Coll Engn & Mineral Resources, POB 6070, Morgantown, WV 26506 USA.
EM ThBourlai@mail.wvu.edu; lahornak@uga.edu
OI Bourlai, Thirimachos/0000-0001-8751-0836
FU Division Of Computer and Network Systems; Direct For Computer & Info
   Scie & Enginr [1066197] Funding Source: National Science Foundation
CR [Anonymous], 2014, 8009 NIST INT
   Ao M., 2009, Advances in Computer Vision and Pattern Recognition Series
   Burgener J., 2006, APPL BIOSAF, V11, P228, DOI [10.1177/153567600601100413, DOI 10.1177/153567600601100413]
   Chang H, 2008, IEEE IMAGE PROC, P2756, DOI 10.1109/ICIP.2008.4712365
   CHEN X, 2003, IEEE INT WORKSH AN M
   Cooksey CC, 2013, PROC SPIE, V8734, DOI 10.1117/12.2015821
   David W., 2016, FACE RECOGNITION IMA
   Fulton JE, 1997, DERMATOL SURG, V23, P163, DOI 10.1111/j.1524-4725.1997.tb00013.x
   Grother P.J., 2010, NISTIR7709 INT
   Kalka NathanD., 2011, BIOMETRICS IJCB 2011, P1, DOI DOI 10.1109/1JCB.2011.6117586
   Klare B., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1513, DOI 10.1109/ICPR.2010.374
   Lemoff B.E., 2013, SPIE DEFENSE SECURIT
   Méndez H, 2009, LECT NOTES COMPUT SC, V5558, P327, DOI 10.1007/978-3-642-01793-3_34
   Narang N, 2015, PROC SPIE, V9472, DOI 10.1117/12.2177135
   Nicolò F, 2012, IEEE T INF FOREN SEC, V7, P1717, DOI 10.1109/TIFS.2012.2213813
   Osia N, 2014, IMAGE VISION COMPUT, V32, P847, DOI 10.1016/j.imavis.2014.06.010
   Selinger A., 2004, 2004 C COMP VIS PATT, P129
   Trujillo L., 2005, P IEEE COMP SOC C CO, P1, DOI [10.1109/CVPR.2005.415, DOI 10.1109/CVPR.2005.415]
   Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977
NR 19
TC 9
Z9 13
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
BP 14
EP 17
DI 10.1016/j.imavis.2016.03.017
PN 1
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA ED8BO
UT WOS:000389097100005
OA hybrid
DA 2024-07-18
ER

PT J
AU Nie, WZ
   Liu, AA
   Li, WH
   Su, YT
AF Nie, Weizhi
   Liu, Anan
   Li, Wenhui
   Su, Yuting
TI Cross-view action recognition by cross-domain learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross-domain; Human action recognition; Action classifier
ID REPRESENTATION
AB This paper proposes a novel cross-view human action recognition method by discovering and sharing common knowledge among different video sets captured in multiple viewpoints. We treat a specific view as target domain and the others as source domains and consequently formulate the cross-view action recognition into the cross-domain learning framework. First, the classic bag-of-visual word framework is implemented for visual feature extraction in individual viewpoints. Then, we add two transformation matrices in order to transform original action feature from different views into one common feature space, and also combine the original feature and the transformation feature to proposed the new feature mapping function for target and auxiliary domains respectively. Finally, we proposed a new method to learn the two transformation matrices in model training step based on the standard SVM solver and generate the final classifier for each human action. Extensive experiments are implemented on IXMAS, and TJU. The experimental results demonstrate that the proposed method can consistently outperform the state-of-the-arts. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Nie, Weizhi; Liu, Anan; Li, Wenhui; Su, Yuting] Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Nie, WZ; Liu, AA (corresponding author), Tianjin Univ, Sch Elect Informat Engn, Tianjin, Peoples R China.
EM weizhinie@tju.edu.cn; anan0422@gmail.com
RI LI, Wenhui/JCD-9947-2023; Nie, Weizhi/ABF-5316-2021
OI nie, weizhi/0000-0002-0578-8138
FU National Natural Science Foundation of China [61472275, 61502337,
   61100124]; Tianjin Research Program of Application Foundation and
   Advanced Technology [15JCYBJC16200]; China Scholarship Council
   [201506255073]; Tianjin University [2014XRG-0046]
FX This work was supported in part by the National Natural Science
   Foundation of China (61472275, 61502337, 61100124), the Tianjin Research
   Program of Application Foundation and Advanced Technology
   (15JCYBJC16200), the grant of China Scholarship Council (201506255073),
   and the grant of Elite Scholar Program of Tianjin University
   (2014XRG-0046).
CR Amiri SM, 2012, IEEE IMAGE PROC, P1421, DOI 10.1109/ICIP.2012.6467136
   [Anonymous], ENCY DATABASE SYSTEM
   [Anonymous], 2012, P 2012 ASIA PACIFIC
   [Anonymous], BIOL INSPIRED COGNIT
   [Anonymous], REAL TIME SKELETON T
   [Anonymous], 2012, ICML
   Benmokhtar R, 2014, MULTIMED TOOLS APPL, V69, P253, DOI 10.1007/s11042-012-1022-3
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Cilla R, 2012, NEUROCOMPUTING, V75, P78, DOI 10.1016/j.neucom.2011.03.051
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Gao Z, 2015, SIGNAL PROCESS, V112, P83, DOI 10.1016/j.sigpro.2014.08.034
   Gong WJ, 2010, LECT NOTES COMPUT SC, V6169, P290, DOI 10.1007/978-3-642-14061-7_28
   Gourgari S, 2013, IEEE COMPUT SOC CONF, P676, DOI 10.1109/CVPRW.2013.102
   Holte M. B., 2011, 2011 International Conference on 3D Imaging, Modeling, Processing, Visualization and Transmission (3DIMPVT), P342, DOI 10.1109/3DIMPVT.2011.50
   Jin Choi, 2008, International Journal of Virtual Reality, V7, P71
   Konecny J., 2013, ABS131241902013 CORR
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Liang X., 2013, ACM International Conference on Multimedia, P263
   Liu A. A., 2016, IEEE T PATTERN ANAL, V1
   Liu AA, 2015, IEEE T CYBERNETICS, V45, P1194, DOI 10.1109/TCYB.2014.2347057
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Onishi K, 2008, INT C PATT RECOG, P1466
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Reddy KK, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P106, DOI 10.1109/AVSS.2012.40
   Shao L., 2015, INT J COMPUT VIS
   Sharma G., 2013, 2013 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), DOI DOI 10.1109/CVPR.2013.90
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Trindade L, 2013, INT CONF MACH LEARN, P277, DOI 10.1109/ICMLC.2013.6890481
   Wang H., 2009, BMVC
   Weinland D, 2010, LECT NOTES COMPUT SC, V6313, P635
   Wu D, 2014, NEUROCOMPUTING, V127, P98, DOI 10.1016/j.neucom.2013.08.038
   Xu N., 2015, Proceedings of the 23rd acm international conference on multimedia, P1195, DOI DOI 10.1145/2733373.2806315
   Yan Zhu, 2010, Computer Vision - ACCV 2010. 10th Asian Conference on Computer Vision. Revised Selected Papers, P660, DOI 10.1007/978-3-642-19309-5_51
   Yoon SM, 2010, LECT NOTES COMPUT SC, V6111, P189, DOI 10.1007/978-3-642-13772-3_20
   Zhang XR, 2013, PATTERN RECOGN, V46, P1819, DOI 10.1016/j.patcog.2012.10.011
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
NR 40
TC 18
Z9 21
U1 3
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 109
EP 118
DI 10.1016/j.imavis.2016.04.011
PN 2
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300009
DA 2024-07-18
ER

PT J
AU Xu, TT
   Zhu, F
   Wong, EK
   Fang, Y
AF Xu, Tiantian
   Zhu, Fan
   Wong, Edward K.
   Fang, Yi
TI Dual many-to-one-encoder-based transfer learning for cross-dataset human
   action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross-dataset; Action recognition; Neural network; Transfer learning;
   Domain adaptation
ID DOMAIN ADAPTATION; DESCRIPTORS; IMAGES
AB The emergence of large-scale human action datasets poses a challenge to efficient action labeling. Hand labeling large-scale datasets is tedious and time consuming; thus a more efficient labeling method would be beneficial. One possible solution is to make use of the knowledge of a known dataset to aid the labeling of a new dataset. To this end, we propose a new transfer learning method for cross-dataset human action recognition. Our method aims at learning generalized feature representation for effective cross-dataset classification. We propose a novel dual many-to-one encoder architecture to extract generalized features by mapping raw features from source and target datasets to the same feature space. Benefiting from the favorable property of the proposed many-to-one encoder, cross-dataset action data are encouraged to possess identical encoded features if the actions share the same class labels. Experiments on pairs of benchmark human action datasets achieved state-of-the-art accuracy, proving the efficacy of the proposed method. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Xu, Tiantian; Zhu, Fan; Wong, Edward K.; Fang, Yi] NYU Multimedia & Visual Comp Lab, Abu Dhabi, U Arab Emirates.
   [Zhu, Fan; Fang, Yi] New York Univ Abu Dhabi, Dept Elect & Comp Engn, Abu Dhabi, U Arab Emirates.
   [Xu, Tiantian; Wong, Edward K.] NYU, Dept Comp Sci & Engn, Tandon Sch Engn, New York, NY 10003 USA.
C3 New York University Abu Dhabi; New York University; New York University
   Tandon School of Engineering
RP Fang, Y (corresponding author), New York Univ Abu Dhabi, C1-156,POB 129188, Abu Dhabi, U Arab Emirates.
EM yfang@nyu.edu
RI Xu, Tiantian/GVT-4682-2022; zhu, fan/HMK-5557-2023
CR Al-Halah Z, 2014, INT C PATT RECOG, P2775, DOI 10.1109/ICPR.2014.478
   [Anonymous], 2011, Third International Conference on Adaptive and Self-Adaptive Systems and Applications (ADAPTIVE2011)
   [Anonymous], 2015, IEEE MTT S INT MICR
   Cao LL, 2010, PROC CVPR IEEE, P1998, DOI 10.1109/CVPR.2010.5539875
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   Cook D, 2013, KNOWL INF SYST, V36, P537, DOI 10.1007/s10115-013-0665-3
   Derpanis KG, 2010, PROC CVPR IEEE, P1990, DOI 10.1109/CVPR.2010.5539874
   Dollar P., 2005, VISUAL SURVEILLANCE, V14, P65, DOI DOI 10.1109/VSPETS.2005.1570899
   Duan LX, 2012, IEEE T NEUR NET LEAR, V23, P504, DOI 10.1109/TNNLS.2011.2178556
   Duan LX, 2012, PROC CVPR IEEE, P1338, DOI 10.1109/CVPR.2012.6247819
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Duan LX, 2009, PROC CVPR IEEE, P1375, DOI [10.1109/CVPRW.2009.5206747, 10.1109/CVPR.2009.5206747]
   Fang Y, 2015, PROC CVPR IEEE, P2319, DOI 10.1109/CVPR.2015.7298845
   Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gao Tianshi., 2012, Eccv 2012, P1
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333
   Hu DH, 2011, PERVASIVE MOB COMPUT, V7, P344, DOI 10.1016/j.pmcj.2010.11.005
   Jain AK, 1996, COMPUTER, V29, P31, DOI 10.1109/2.485891
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Jiang Z, 2011, P IEEE INT FREQ CONT, P323, DOI 10.1109/ICMLA.2011.51
   Klaser A, 2008, BR MACH VIS C
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kulis B, 2011, PROC CVPR IEEE, P1785, DOI 10.1109/CVPR.2011.5995702
   Lam A, 2011, LECT NOTES COMPUT SC, V6494, P157, DOI 10.1007/978-3-642-19318-7_13
   Laptev I, 2006, LECT NOTES COMPUT SC, V3667, P91
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LeCun Y., 1988, EFFICIENT BACKPROP, P9
   Li W, 2014, IEEE T PATTERN ANAL, V36, P1134, DOI 10.1109/TPAMI.2013.167
   Lim JosephJ., 2012, Advances in Neural Information Processing Systems 26 (NIPS 2012), P1
   Lin XM, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON IT IN MEDICINE & EDUCATION, VOLS 1 AND 2, PROCEEDINGS, P659, DOI 10.1109/ITIME.2009.5236340
   Liu C, 2010, IMAGE VISION COMPUT, V28, P825, DOI 10.1016/j.imavis.2009.07.009
   Liu L., 2015, IEEE T CYBERN
   Liu YM, 2011, IEEE T PATTERN ANAL, V33, P1022, DOI 10.1109/TPAMI.2010.142
   Nater F., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1737, DOI 10.1109/ICCVW.2011.6130459
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Rodriguez M. D., 2008, 26 IEEE C COMP VIS P
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Salakhutdinov R., 2009, ARTIFICIAL INTELLIGE, V5, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Shao L., 2014, IEEE TRANS CIRCUITS
   Shao L., 2015, IJCV
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Smith LindsayI., 2002, Cornell University, USA, V51, P52
   Sultani W, 2014, PROC CVPR IEEE, P764, DOI 10.1109/CVPR.2014.103
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Tommasi T, 2013, IEEE I CONF COMP VIS, P897, DOI 10.1109/ICCV.2013.116
   van Kasteren TLM, 2010, LECT NOTES COMPUT SC, V6030, P283, DOI 10.1007/978-3-642-12654-3_17
   Wang H., 2009, BMVC
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wu Chun, 2010, Proceedings 2010 International Conference on Challenges in Environmental Science and Computer Engineering (CESCE 2010), P142, DOI 10.1109/CESCE.2010.72
   Yang J., 2007, P 15 ACM INT C MULT, P188
   Zhang Z, 2013, PROC CVPR IEEE, P2690, DOI 10.1109/CVPR.2013.347
   Zheng JJ, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.125
   Zhu F., 2014, ICPR INT C PATT REC
NR 64
TC 24
Z9 29
U1 2
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 127
EP 137
DI 10.1016/j.imavis.2016.01.001
PN 2
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300011
DA 2024-07-18
ER

PT J
AU Fredriksson, J
   Larsson, V
   Olsson, C
   Enqvist, O
   Kahl, F
AF Fredriksson, Johan
   Larsson, Viktor
   Olsson, Carl
   Enqvist, Olof
   Kahl, Fredrik
TI Efficient algorithms for robust estimation of relative translation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Structure from motion; Epipolar geometry; Branch and bound; Two-view
   geometry
ID OPTIMIZATION
AB One of the key challenges for structure from motion systems in order to make them robust to failure is the ability to handle outliers among the correspondences. In this paper we present two new algorithms that find the optimal solution in the presence of outliers when the camera undergoes a pure translation. The first algorithm has polynomial-time computational complexity, independently of the amount of outliers. The second algorithm does not offer such a theoretical complexity guarantee, but we demonstrate that it is magnitudes faster in practice. No random sampling approaches such as RANSAC are guaranteed to find an optimal solution, while our two methods do. We evaluate and compare the algorithms both on synthetic and real experiments. We also embed the algorithms in a larger system, where we optimize for the rotation angle as well (the rotation axis is measured by other means). The experiments show that for problems with a large amount of outliers, the RANSAC estimates may deteriorate compared to our optimal methods. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Fredriksson, Johan; Larsson, Viktor; Olsson, Carl; Kahl, Fredrik] Lund Univ, S-22100 Lund, Sweden.
   [Enqvist, Olof; Kahl, Fredrik] Chalmers Univ Technol, Gothenburg, Sweden.
C3 Lund University; Chalmers University of Technology
RP Fredriksson, J (corresponding author), Lund Univ, S-22100 Lund, Sweden.
EM johanf@maths.lth.se; viktorl@maths.lth.se; calle@maths.lth.se;
   olof.enqvist@chalmers.se; fredrik.kahl@chalmers.se
FU Swedish Research Council [2012-4213, 4215]; Crafoord Foundation
   [20150601]
FX This work has been funded by the Swedish Research Council (grant no.
   2012-4213 and grant no. 4215) and the Crafoord Foundation (grant no.
   20150601).
CR Agarwal S., 2010, INT C COMP VIS
   Agarwal S., 2008, C COMP VIS PATT REC
   Avrithis Y, 2014, INT J COMPUT VISION, V107, P1, DOI 10.1007/s11263-013-0659-3
   Bazin JC, 2013, IEEE T PATTERN ANAL, V35, P1565, DOI 10.1109/TPAMI.2012.264
   Berg M., 2008, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-3-540-77974-2
   Breuel T. M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P445, DOI 10.1109/CVPR.1992.223152
   Breuel TM, 2003, COMPUT VIS IMAGE UND, V90, P258, DOI 10.1016/S1077-3142(03)00026-2
   Chin T.-J., 2015, IEEE C COMP VIS PATT
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Enqvist O., 2012, EUR C COMP VIS
   Enqvist O., 2011, NONSEQUENTIAL STRUCT
   Enqvist O., 2009, BRIT MACH VIS C BMVC
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fraundorfer F., 2010, EUR C COMP VIS
   Fredriksson J., 2014, C COMP VIS PATT REC
   Fredriksson J., 2015, COMPUTER VISION PATT
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9
   Kahl F, 2008, IEEE T PATTERN ANAL, V30, P1603, DOI 10.1109/TPAMI.2007.70824
   Ke Q, 2007, IEEE T PATTERN ANAL, V29, P1834, DOI 10.1109/TPAMI.2007.1083
   Li H., 2009, INT C COMP VIS KYOT
   Li H.D., 2007, C COMP VIS PATT REC
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MARTINEC D, 2007, C COMP VIS PATT REC
   Naroditsky O, 2012, IEEE T PATTERN ANAL, V34, P818, DOI 10.1109/TPAMI.2011.226
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Olsson C., 2010, C COMP VIS PATT REC
   Olsson C., 2008, C COMP VIS PATT REC
   Olsson C, 2010, J MATH IMAGING VIS, V38, P35, DOI 10.1007/s10851-010-0207-5
   Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131
   Pham T.T., 2012, IEEE C COMP VIS PATT
   Rother C, 2002, INT J COMPUT VISION, V49, P117, DOI 10.1023/A:1020189404787
   Schonberger J.L., 2015, GERM C PATT REC GCPR
   Sim K., 2006, 2006 IEEE COMPUTER S, V1, P485
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Stewénius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005
   Yang JL, 2014, LECT NOTES COMPUT SC, V8689, P111, DOI 10.1007/978-3-319-10590-1_8
   Yu J, 2011, PROC CVPR IEEE
   Zheng Y., 2011, IEEE C COMP VIS PATT
NR 41
TC 4
Z9 4
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 114
EP 124
DI 10.1016/j.imavis.2016.05.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400009
DA 2024-07-18
ER

PT J
AU Stefic, D
   Patras, I
AF Stefic, Daria
   Patras, Ioannis
TI Action recognition using saliency learned from recorded human gaze
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Saliency; Support Vector Machine (SVM); Latent
   variable; 3D Convolutional Neural Network (3D CNN)
AB This paper addresses the problem of recognition and localization of actions in image sequences, by utilizing, in the training phase only, gaze tracking data of people watching videos depicting the actions in question. First, we learn discriminative action features at the areas of gaze fixation and train a Convolutional Network that predicts areas of fixation (i.e. salient regions) from raw image data. Second, we propose a Support Vector Machine-based recognition method for joint recognition and localization, in which the bounding box of the action in question is considered as a latent variable. In our formulation the optimization attempts to both minimize the classification cost and maximize the saliency within the bounding box. We show that the results obtained with the optimization where saliency within the bounding box is maximized outperform the results obtained when saliency within the bounding box is not maximized, i.e. when only classification cost is minimized. Furthermore, the results that we obtain outperform the state-of-the-art results on the UCF sports dataset. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Stefic, Daria; Patras, Ioannis] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.
C3 University of London; Queen Mary University London
RP Stefic, D (corresponding author), Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.
EM d.stefic@qmul.ac.uk
OI Patras, Ioannis/0000-0003-3913-4738
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aggarwal J.K., 2006, P INT C COMP VIS PAT
   [Anonymous], P IEEE WORKSH MOT VI
   [Anonymous], 2010, P PYTHON SCI COMPUTI
   [Anonymous], P EUR C COMP VIS
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2012, DEEP LEARNING UNSUPE
   [Anonymous], ARXIV14054506
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], ARXIV14111045
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2009, P 26 ANN INT C MACHI
   Assari S., 2014, P INT C COMP VIS PAT
   Baccouche M., 2011, P WORKSH HUM BEH UND
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Christian S., 2004, P INT C PATT REC, P2
   Duong D.Q.P.T.V., 2005, P INT C COMP VIS PAT
   Fathi A., 2012, P EUR C COMP VIS
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gilbert A, 2011, IEEE T PATTERN ANAL, V33, P883, DOI 10.1109/TPAMI.2010.144
   HONGENG S, 2003, P INT C COMP VIS
   Jain M., 2014, P INT C COMP VIS PAT
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A., 2014, P INT C COMP VIS PAT
   Klami A., 2008, P INT C MULT INF RET
   Koelstra S., 2009, WORKSH IM AN MULT IN
   Kovashka A., 2010, P INT C COMP VIS PAT
   Krizhevsky A., 2012, ADV NEURAL INFORM PR, P1097
   Kuehne H., 2014, P INT C COMP VIS PAT
   Lan T., 2011, P INT C COMP VIS
   Lan Z., 2015, P INT C COMP VIS PAT
   Laptev I, 2008, P INT C COMP VIS PAT
   LAPTEV I, 2003, P INT C COMP VIS
   Le QV, 2011, PROC CVPR IEEE
   Lin Y., 2014, P AAAI WORKSH COGN C
   Niebles J, 2010, P EUR C COMP VIS
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oneata D., 2013, P INT C COMP VIS
   Pirsiavash H., 2014, P INT C COMP VIS PAT
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Quattoni A., IEEE TPAMI
   Raptis M., 2012, P INT C COMP VIS PAT
   Rodriguez M.D., 2008, P INT C COMP VIS PAT
   Sadeghi M., 2009, P SPIE, V7260
   Sapienza M., 2012, P BRIT MACH VIS C, DOI DOI 10.5244/C.26.123
   Schmid C., 2013, P INT C COMP VIS
   Schmid C., 2011, P INT C COMP VIS PAT
   Shapovalova N., 2012, P EUR C COMP VIS
   Shapovalova N., 2013, P NEUR INF PROC SYST
   Shen C, 2012, DEEP LEARN UNS FEAT
   Shen CY, 2014, NEUROCOMPUTING, V138, P61, DOI 10.1016/j.neucom.2013.09.053
   Sminchisescu C., CVIU
   Song Y., 2013, P INT C COMP VIS PAT
   Sun J., 2009, P INT C COMP VIS PAT
   Sun L., 2014, P INT C COMP VIS PAT
   Szegedy C., 2013, P NEUR INF PROC SYST
   Tang K., 2012, P INT C COMP VIS PAT
   Tran D., 2014, P INT C LEARN REPR
   Vig E., 2014, P INT C COMP VIS PAT
   Vig E., 2012, P EUR C COMP VIS
   Vo N.N., 2014, P INT C COMP VIS PAT
   Vrochidis S., 2012, P INT WORKSH IM AN M
   Wang H., 2009, BMVC
   Wang H., 2015, ARXIV150405524
   Wang Y., IEEE TPAMI
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yuan J., 2009, P INT C COMP VIS PAT
   Zhang Y., 2010, P EYE TRACK RES APPL
NR 68
TC 8
Z9 8
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 195
EP 205
DI 10.1016/j.imavis.2016.06.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, FY
   Shen, CH
   Reid, I
   van den Hengel, A
AF Liu, Fayao
   Shen, Chunhua
   Reid, Ian
   van den Hengel, Anton
TI Online unsupervised feature learning for visual tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object tracking; Unsupervised feature learning; Dictionary learning
AB We propose a method for visual tracking-by-detection based on online feature learning. Our learning framework performs feature encoding with respect to an over-complete dictionary, followed by spatial pyramid pooling. We then learn a linear classifier based on the resulting feature encoding. Unlike previous work, we learn the dictionary online and update it to help capture the appearance of the tracked target as well as the background. In more detail, given a test image window, we extract local image patches from it and each local patch is encoded with respect to the dictionary. The encoded features are then pooled over a spatial pyramid to form an aggregated feature vector. Finally, a simple linear classifier is trained on these features. Our experiments show that the proposed powerful albeit simple tracker, outperforms all the state-of-the-art tracking methods that we have tested. Moreover, we evaluate the performance of different dictionary learning and feature encoding methods in the proposed tracking framework, and analyze the impact of each component in the tracking scenario. In particular, we show that a small dictionary, learned and updated online is as effective and more efficient than a huge dictionary learned offline. We further demonstrate the flexibility of feature learning by showing how it can be used within a structured learning tracking framework. The outcome is one of the best trackers reported to date, which facilitates the advantages of both feature learning and structured output prediction. We also implement a multi-object tracker, which achieves state-of-the-art performance. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Liu, Fayao; Shen, Chunhua; Reid, Ian; van den Hengel, Anton] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
C3 University of Adelaide
RP Shen, CH (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
EM chunhua.shen@adelaide.edu.au
OI van den Hengel, Anton/0000-0003-3027-8364; Reid, Ian/0000-0001-7790-6423
FU ARC [FT120100969]
FX This work is in part supported by ARC Grant FT120100969.
CR Aharon M., IEEE Transactions on signal processing
   [Anonymous], 2009, P IEEE C COMP VIS PA
   [Anonymous], 2011, P INT C MACH LEARN
   [Anonymous], 2011, P IEEE C COMP VIS PA
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], 2010, P IEEE C COMP VIS PA
   Avidan S., IEEE T PATTERN ANAL
   Bao C., 2012, P IEEE INT C COMP VI
   Coates A., P INT C ART INT STAT, V15
   Efron B., ANN STAT
   Gao H, 2013, IEEE SYMP COMMUN VEH
   Grabner H., 2006, BRIT C COMP VIS
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Jia X., 2012, P IEEE C COMP VIS PA
   Li X., 2013, PROC IEEE CONF COMP
   Li X, 2013, ACM T INTEL SYST TEC, V4, DOI 10.1145/2508037.2508039
   Liu L., 2011, P IEEE INT C COMP VI
   Mairal J., J MACH LEARN RES
   Mei X., IEEE T PATTERN ANAL
   Mroueh Y., 2012, P ADV NEUR INF PROC
   Ning T. D. Zhang, 2012, P IEEE C COMP VIS PA
   Ross D.A., INT J COMP VIS
   Sevilla-Lara L., 2012, P IEEE C COMP VIS PA
   Shabou A., 2012, P IEEE C COMP VIS PA
   Sohn K., 2011, P IEEE INT C COMP VI
   Wang Naiyan Jingdong, 2013, P IEEE INT C COMP VI
   Wang Q, IEEE T IMAGE P
   Yao R., 2012, P EUR C COMP VIS
   Yao R., 2013, P IEEE C COMP VIS PA
   Ye J., P ADV NEUR INF PROC
   Zhang L., 2013, P IEEE C COMP VIS PA
   Zhong W., 2012, P IEEE C COMP VIS PA
   Zou H., 2005, J R STAT SOC B
NR 33
TC 10
Z9 11
U1 0
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2016
VL 51
BP 84
EP 94
DI 10.1016/j.imavis.2016.04.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4HB
UT WOS:000378455900008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Roy, PP
   Rayar, F
   Ramel, JY
AF Roy, Partha Pratim
   Rayar, Frederic
   Ramel, Jean-Yves
TI Word spotting in historical documents using primitive codebook and
   dynamic programming
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Word spotting; Document indexing; Approximate string matching;
   Coarse-to-fine
ID RECOGNITION; RETRIEVAL
AB Word searching and indexing in historical document collections are a challenging problem because text characters are often touching or broken due to degradation or aging effects. In this paper, we present a novel approach towards word spotting using text line decomposition into character primitives and string matching. The text lines are initially separated by a segmentation process. Then each text line is described as sequences of primitive labels which correspond to single characters or parts of characters. These representative primitives are considered from a codebook of shapes generated from training pages taken from the collection. During indexation, the text lines are transcribed into strings of primitives in off-line stage and stored in files. For this purpose, an efficient indexation strategy using multi-label approach is used by a combination of two-level analysis of the primitives: coarse and fine levels. During retrieval, the query word image is encoded into strings of coarse and fine primitives chosen according to the codebook. Finally, a dynamic programming method based on approximate string matching is used to find similar primitive sequences in the text lines from the collection in runtime. We present the experimental evaluation on datasets of real life document images, gathered from historical books of different scripts. Experimental results show that the method is robust in searching text in noisy documents. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Roy, Partha Pratim; Rayar, Frederic; Ramel, Jean-Yves] Univ Tours, Lab Informat, Tours, France.
C3 Universite de Tours
RP Roy, PP (corresponding author), Univ Tours, Lab Informat, Tours, France.
EM partha.roy@univ-tours.fr
RI Ramel, Jean-Yves/AAF-1204-2020; Roy, Partha Pratim/AAV-9061-2020; Roy,
   Partha Pratim/GPF-4253-2022; Roy, Partha Pratim/AAW-2994-2020
OI Ramel, Jean-Yves/0000-0003-4427-4612; Roy, Partha
   Pratim/0000-0002-5735-5254
FU AAP program of Universite Francois Rabelais, Tours, France
   [AAP-UFRT-2010-06]; Google Digital Humanities Research Awards
FX This work has been supported by the AAP program of Universite Francois
   Rabelais, Tours, France (2010-2011) (AAP-UFRT-2010-06) and by the Google
   Digital Humanities Research Awards (2010) given to the Computer Science
   Laboratory of Tours (RFAI team). Thanks to CESR for providing datasets
   and valuable discussions which helped us to improve our system.
CR Adamek T, 2007, INT J DOC ANAL RECOG, V9, P153, DOI 10.1007/s10032-006-0024-y
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cao H., 2007, TEMPLATE FREE WORD S
   Chang TC, 1999, INT J PATTERN RECOGN, V13, P833, DOI 10.1142/S021800149900046X
   Fischer A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3416, DOI 10.1109/ICPR.2010.834
   Frinken V, 2012, IEEE T PATTERN ANAL, V34, P211, DOI 10.1109/TPAMI.2011.113
   Gatos Basilis, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P271, DOI 10.1109/ICDAR.2009.236
   HALL PAV, 1980, COMPUT SURV, V12, P381, DOI 10.1145/356827.356830
   Huang L, 2013, IMAGE VISION COMPUT, V31, P958, DOI 10.1016/j.imavis.2013.10.003
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Konidaris T, 2007, INT J DOC ANAL RECOG, V9, P167, DOI 10.1007/s10032-007-0042-4
   Leydier Y, 2009, PATTERN RECOGN, V42, P2089, DOI 10.1016/j.patcog.2009.01.026
   Liang Y, 2012, PATTERN RECOGN, V45, P4225, DOI 10.1016/j.patcog.2012.05.024
   Lu SJ, 2008, IEEE T PATTERN ANAL, V30, P1913, DOI 10.1109/TPAMI.2008.89
   Lu Y, 2002, INT C PATT RECOG, P57, DOI 10.1109/ICPR.2002.1047794
   Manmatha R., 1997, Word spotting: Indexing handwritten archives
   Marti UV, 2001, INT J PATTERN RECOGN, V15, P65, DOI 10.1142/S0218001401000848
   Moghaddam Reza Farrahi, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P511, DOI 10.1109/ICDAR.2009.104
   Mohamad RAH, 2009, IEEE T PATTERN ANAL, V31, P1165, DOI 10.1109/TPAMI.2008.136
   Nakayama T., 1994, 4 C APPL NAT LANG PR, P22
   Pal U, 2003, PATTERN RECOGN LETT, V24, P261, DOI 10.1016/S0167-8655(02)00240-4
   Pinzon Yoan, 2006, ALGORITHMS APPROXIMA
   Ramel JY, 2007, INT J DOC ANAL RECOG, V9, P243, DOI 10.1007/s10032-007-0040-6
   Rath T., 2005, INT J DOC ANAL RECOG, V9, P139
   Rath T. M., 2004, Proceedings of Sheffield SIGIR 2004. The Twenty-Seventh Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P369, DOI 10.1145/1008992.1009056
   Rath TM, 2003, PROC CVPR IEEE, P521
   Rothfeder J.L., 2003, P C COMPUTER VISION, P30
   Roy P. P., 2012, Proceedings of the 10th IAPR International Workshop on Document Analysis Systems (DAS 2012), P150, DOI 10.1109/DAS.2012.17
   Roy PP, 2011, PROC INT CONF DOC, P678, DOI 10.1109/ICDAR.2011.142
   Rusiñol M, 2011, PROC INT CONF DOC, P63, DOI 10.1109/ICDAR.2011.22
   Terasawa Kengo, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P116, DOI 10.1109/ICDAR.2009.118
   Williams W. J., 2000, Information Retrieval, V2, P207, DOI 10.1023/A:1009958827317
   Zhang B., 2004, WORD IMAGE RETRIEVAL, P45
NR 34
TC 12
Z9 12
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2015
VL 44
BP 15
EP 28
DI 10.1016/j.imavis.2015.09.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CZ5EK
UT WOS:000367125100002
DA 2024-07-18
ER

PT J
AU Celikkale, B
   Erdem, A
   Erdem, E
AF Celikkale, Bora
   Erdem, Aykut
   Erdem, Erkut
TI Predicting memorability of images using attention-driven spatial pooling
   and image semantics
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image understanding; Image memorability; Visual saliency; Spatial
   pooling; Semantic features
ID PREVIOUSLY ATTENDED OBJECTS; VISUAL-ATTENTION; MEMORY; SCENE; SALIENCY
AB In daily life, humans demonstrate an amazing ability to remember images they see on magazines, commercials, TV, web pages, etc. but automatic prediction of intrinsic memorability of images using computer vision and machine learning techniques has only been investigated very recently. Our goal in this article is to explore the role of visual attention and image semantics in understanding image memorability. In particular, we present an attention-driven spatial pooling strategy and show that considering image features from the salient parts of images improves the results of the previous models. We also investigate different semantic properties of images by carrying out an analysis of a diverse set of recently proposed semantic features which encode meta-level object categories, scene attributes, and invoked feelings. We show that these features which are automatically extracted from images provide memorability predictions as nearly accurate as those derived from human annotations. Moreover, our combined model yields results superior to those of state-of-the art fully automatic models. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Celikkale, Bora; Erdem, Aykut; Erdem, Erkut] Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
C3 Hacettepe University
RP Erdem, E (corresponding author), Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM ibcelikkale@cs.hacettepe.edu.tr; aykut@cs.hacettepe.edu.tr;
   erkut@cs.hacettepe.edu.tr
RI Erdem, Erkut/A-2291-2012; Erdem, Aykut/A-2290-2012
OI Erdem, Erkut/0000-0002-6744-8614; CELIKKALE, ISMAIL
   BORA/0000-0002-2281-8773; Erdem, Aykut/0000-0002-6280-8422
CR Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2007, 2007 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2007.383198
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2010, P 27 INT C MACHINE L
   [Anonymous], 2010, P NIPS
   [Anonymous], 2011, ADV NEURAL INF PROCE, DOI DOI 10.21236/ADA554133
   Bergamo A., 2010, NIPS 2010, P2088
   Bergamo A, 2012, PROC CVPR IEEE, P3085, DOI 10.1109/CVPR.2012.6248040
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borth D., 2013, P 21 ACM INT C MULTI, P223, DOI 10.1145/2502081.2502282
   Brady TF, 2008, P NATL ACAD SCI USA, V105, P14325, DOI 10.1073/pnas.0803390105
   Cohen MA, 2011, PSYCHOL SCI, V22, P1165, DOI 10.1177/0956797611419168
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Einhäuser W, 2008, J VISION, V8, DOI 10.1167/8.2.2
   Elazary L, 2008, J VISION, V8, DOI 10.1167/8.3.3
   Erdem A., 2013, COMP VIS PATT REC WO, P1
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Hollingworth A, 2001, PSYCHON B REV, V8, P761, DOI 10.3758/BF03196215
   Hollingworth A, 2002, J EXP PSYCHOL HUMAN, V28, P113, DOI 10.1037//0096-1523.28.1.113
   Inoue K, 2012, VIS COGN, V20, P94, DOI 10.1080/13506285.2011.640648
   Isola P, 2014, IEEE T PATTERN ANAL, V36, P1469, DOI 10.1109/TPAMI.2013.200
   Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim J., P 21 ACM INT C MULT, P761
   Kocak A., 2014, TOP SALIENCY ESTIMAT
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mancas M, 2013, IEEE IMAGE PROC, P196, DOI 10.1109/ICIP.2013.6738041
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Patterson G, 2014, INT J COMPUT VISION, V108, P59, DOI 10.1007/s11263-013-0695-z
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   POTTER MC, 1976, J EXP PSYCHOL-HUM L, V2, P509, DOI 10.1037/0278-7393.2.5.509
   SCHYNS PG, 1994, PSYCHOL SCI, V5, P195, DOI 10.1111/j.1467-9280.1994.tb00500.x
   SHEPARD RN, 1967, J VERB LEARN VERB BE, V6, P156, DOI 10.1016/S0022-5371(67)80067-7
   STANDING L, 1973, Q J EXP PSYCHOL, V25, P207, DOI 10.1080/14640747308400340
   Torralba A, 2006, PSYCHOL REV, V113, P766, DOI 10.1037/0033-295X.113.4.766
   Wolfe JM, 2007, VISION RES, V47, P955, DOI 10.1016/j.visres.2006.11.025
   Wolfe JM, 1998, CURR BIOL, V8, pR303, DOI 10.1016/S0960-9822(98)70192-7
   Xu J, 2014, J VISION, V14, DOI 10.1167/14.1.28
   Yang JM, 2012, PROC CVPR IEEE, P2296, DOI 10.1109/CVPR.2012.6247940
   Zhao Q, 2012, J VISION, V12, DOI 10.1167/12.6.22
NR 43
TC 16
Z9 16
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2015
VL 42
BP 35
EP 46
DI 10.1016/j.imavis.2015.07.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CT2BV
UT WOS:000362607900004
DA 2024-07-18
ER

PT J
AU Hung, MH
   Hsieh, CH
AF Hung, Mao-Hsiung
   Hsieh, Chaur-Heh
TI A novel algorithm for defect inspection of touch panels
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic optical inspection; Defect inspection; Touch panel
ID SURFACE INSPECTION; VISUAL INSPECTION; SYSTEM
AB Automatic optical inspection plays an important role to control the appearance quality of wide range of products in the product process. Recently, the high popularity of srnartphones and information appliances drives significant demand of touch panels. However, the traditional frequency-based method which exploits the line structure feature of texture images is not effective for the defect detection of touch panels. The paper presents a novel spatial domain algorithm to inspect the defects on touch panel. By utilizing the characteristics of periodic patterns of the sensing circuits, an adaptive model for each pattern is learned online to effectively extract defects. The experimental results indicate that our proposed method achieves accurate detection with efficient computation. In addition, the users pay very little effort for the testing of different panel products. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Hung, Mao-Hsiung] Fujian Univ Technol, Coll Informat Sci & Engn, Fuzhou 350118, Peoples R China.
   [Hsieh, Chaur-Heh] Ming Chuan Univ, Dept Comp & Commun Engn, Guishan 333, Taoyuan County, Taiwan.
C3 Fujian University of Technology
RP Hsieh, CH (corresponding author), Ming Chuan Univ, Dept Comp & Commun Engn, 5 Deming Rd, Guishan 333, Taoyuan County, Taiwan.
EM hsiehch@mail.mcu.edu.tw
FU Ministry of Science and Technology [MOST 103-2221-E-130-006]
FX The authors would like to express their sincere thanks to the anonymous
   reviewers for their invaluable comments, which truly helped towards an
   effective presentation of this paper. This work was supported in part by
   the Ministry of Science and Technology Granted MOST 103-2221-E-130-006.
CR [Anonymous], WORLD APPL SCI J
   [Anonymous], 2008, ELCVIA Electron. Lett. Comput. Vis. Image Anal, DOI DOI 10.5565/REV/ELCVIA.268
   Brzakovic D, 1996, PATTERN RECOGN, V29, P1401, DOI 10.1016/0031-3203(95)00166-2
   Campbell JG, 1998, OPT ENG, V37, P2536, DOI 10.1117/1.601692
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chang C.Y., 2012, US Patent, Patent No. [8,217,902, 8217902]
   Chen C., 2009, US Patent App., Patent No. [12/112,950, 12112950]
   Chen Y.-C., 2011, Int. J. Phys. Sci., V6, P5141
   Ghazvini M., 2009, WORLD ACAD SCI ENG T, V37, P901, DOI [10.5281/zenodo.1328348,901-904, DOI 10.5281/ZENODO.1328348]
   Hu S.H., 2014, US Patent App, Patent No. [13/895,333, 13895333]
   Kim Y.S., 2013, US Patent App., Patent No. [13/427,840, 13427840]
   Lee C.J., 2011, US Patent App., Patent No. [13/074,042, 13074042]
   Lin HD, 2007, IMAGE VISION COMPUT, V25, P1785, DOI 10.1016/j.imavis.2007.02.002
   Lin HD, 2012, J IND PROD ENG, V29, P291, DOI 10.1080/10170669.2012.700528
   Lin YK, 2013, RELIAB ENG SYST SAFE, V118, P51, DOI 10.1016/j.ress.2013.04.007
   Mackey B.L., 2006, US Patent, Patent No. [7,129,935, 7129935]
   Mak KL, 2008, ROBOT CIM-INT MANUF, V24, P359, DOI 10.1016/j.rcim.2007.02.019
   Metz CE, 1978, SEMINARS NUCL MED, VVIII
   Nahm D.S., 2012, WO Patent App., Patent No. [PCT/KR2012/004,604, 2012004604]
   Nam D.S., 2014, US Patent App., Patent No. [13/704,585, 13704585]
   Shuyue Chen, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P97, DOI 10.1109/IASP.2010.5476155
   Speck D.A., 2007, US Patent, Patent No. [7,202,859, 7202859]
   Steger C., 2008, Machine Vision Algorithms and Applications
   Tsai DM, 1999, IMAGE VISION COMPUT, V18, P49, DOI 10.1016/S0262-8856(99)00009-8
   Tsai DM, 2001, PATTERN RECOGN, V34, P1285, DOI 10.1016/S0031-3203(00)00071-6
   Wong WK, 2009, EXPERT SYST APPL, V36, P3845, DOI 10.1016/j.eswa.2008.02.066
   Yang X.F., 2014, US Patent App, Patent No. [14/069,486, 14069486]
NR 28
TC 10
Z9 13
U1 0
U2 19
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2015
VL 41
BP 11
EP 25
DI 10.1016/j.imavis.2015.06.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CQ4ST
UT WOS:000360595600002
DA 2024-07-18
ER

PT J
AU Caron, G
   Dame, A
   Marchand, E
AF Caron, Guillaume
   Dame, Amaury
   Marchand, Eric
TI Direct model based visual tracking and pose estimation using mutual
   information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Tracking; 3D pose estimation; Mutual information
AB This paper deals with model-based pose estimation (or camera localization). We propose a direct approach that takes into account the image as a whole. For this, we consider a similarity measure, the mutual information. Mutual information is a measure of the quantity of information shared by two signals (or two images in our case). Exploiting this measure allows our method to deal with different image modalities (real and synthetic). Furthermore, it handles occlusions and illumination changes. Results with synthetic (benchmark) and real image sequences, with static or mobile camera, demonstrate the robustness of the method and its ability to produce stable and precise pose estimations. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Caron, Guillaume; Dame, Amaury; Marchand, Eric] INRIA Rennes, IRISA, Lagadic, Rennes, France.
   [Caron, Guillaume] Univ Picardie Jules Verne, MIS Lab, Amiens, France.
   [Dame, Amaury] Univ Oxford, Act Vis Grp, Oxford, England.
C3 Universite de Picardie Jules Verne (UPJV); University of Oxford
RP Caron, G (corresponding author), 33 Rue St Leu, F-80039 Amiens, France.
EM guillaume.caron@u-picardie.fr; adame@robots.ox.ac.uk;
   eric.marchand@irisa.fr
RI Marchand, Eric/AAF-2809-2019
OI Marchand, Eric/0000-0001-7096-5236
CR Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Chaumette F, 2006, IEEE ROBOT AUTOM MAG, V13, P82, DOI 10.1109/MRA.2006.250573
   Collewet C, 2011, IEEE T ROBOT, V27, P828, DOI 10.1109/TRO.2011.2112593
   Comport AI, 2010, INT J ROBOT RES, V29, P245, DOI 10.1177/0278364909356601
   Comport AI, 2006, IEEE T VIS COMPUT GR, V12, P615, DOI 10.1109/TVCG.2006.78
   Dame Amaury, 2010, 2010 9th IEEE International Symposium on Mixed and Augmented Reality (ISMAR). Science & Technology Papers, P47, DOI 10.1109/ISMAR.2010.5643550
   Dame A, 2011, IEEE T ROBOT, V27, P958, DOI 10.1109/TRO.2011.2147090
   David P., 2010, ARM SCI C, P428
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   Dowson N, 2008, IEEE T PATTERN ANAL, V30, P180, DOI 10.1109/TPAMI.2007.70757
   Dowson N, 2006, LECT NOTES COMPUT SC, V3951, P365
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   European Spatial Agency (ESA), 2011, GAL GEN INTR
   Frontoni Emanuele, 2010, 2010 IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA 2010), P428, DOI 10.1109/MESA.2010.5551994
   Georgel P. F., 2008, P BRIT MACH VIS C, P1
   Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759
   Jiang B., 2006, INT C COMP GRAPH VIR, P104
   Karlsson N., 2005, IEEE INT C ROB AUT B
   Lapreste J. T., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P998
   Lemaire T., 2007, INT C ROB AUT ROM IT
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Lhuillier M, 2008, COMPUT VIS IMAGE UND, V109, P186, DOI 10.1016/j.cviu.2007.05.004
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   Panin G, 2008, INT J COMPUT VISION, V78, P107, DOI 10.1007/s11263-007-0083-7
   Petit A, 2012, IEEE INT C INT ROBOT, P4483, DOI 10.1109/IROS.2012.6386083
   Pluim JPW, 1999, PROC SPIE, V3661, P56, DOI 10.1117/12.348605
   Pressigout M, 2007, INT J ROBOT RES, V26, P689, DOI 10.1177/0278364907080477
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Silveira G, 2008, IEEE T ROBOT, V24, P969, DOI 10.1109/TRO.2008.2004829
   Triggs B., 2000, BUNDLE ADJUSTMENT MO
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
NR 33
TC 54
Z9 55
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2014
VL 32
IS 1
BP 54
EP 63
DI 10.1016/j.imavis.2013.10.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AB0RV
UT WOS:000331500700005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, F
   Lu, HC
   Yang, MH
AF Yang, Fan
   Lu, Huchuan
   Yang, Ming-Hsuan
TI Learning structured visual dictionary for object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object tracking; Bag of features; Appearance model; Geometric
   relationship
ID MODEL
AB In this paper, we propose a visual tracking algorithm by incorporating the appearance information gathered from two collaborative feature sets and exploiting its geometric structures. A structured visual dictionary (SVD) can be learned from both appearance and geometric structure, thereby enhancing its discriminative strength between the foreground object and the background. Experimental results show that the proposed tracking algorithm using SVD (SVDTrack) performs favorably against the state-of-the-art methods. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Yang, Fan; Lu, Huchuan] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116024, Peoples R China.
   [Yang, Ming-Hsuan] Univ Calif Merced, Merced, CA 95344 USA.
C3 Dalian University of Technology; University of California System;
   University of California Merced
RP Yang, MH (corresponding author), Univ Calif Merced, Merced, CA 95344 USA.
EM mhyang@ucmerced.edu
RI Yang, Ming-Hsuan/T-9533-2019; Yang, Ming-Hsuan/AAE-7350-2019; LU,
   Jia-Hong/X-1395-2019
OI Yang, Ming-Hsuan/0000-0003-4848-2304; LU, Jia-Hong/0000-0002-1147-125X
CR [Anonymous], 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, DOI [10.1109/CVPR.2006.312, DOI 10.1109/CVPR.2006.312]
   [Anonymous], 2010, CVPR
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2006, P IEEE C COMPUTER VI
   [Anonymous], 2004, ECCV
   [Anonymous], 2009, ICCV
   Avidan S, 2005, PROC CVPR IEEE, P494
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Belongie S, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P20, DOI 10.1109/IVL.2000.853834
   Cehovin L, 2011, IEEE I CONF COMP VIS, P1363, DOI 10.1109/ICCV.2011.6126390
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Duy-Nguyen Ta, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2937, DOI 10.1109/CVPRW.2009.5206831
   Fan Yang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P153, DOI 10.1109/ICPR.2010.46
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fergus R, 2005, IEEE I CONF COMP VIS, P1816
   Grabner M., 2007, CVPR, P1
   He W, 2009, IEEE I CONF COMP VIS, P1586, DOI 10.1109/ICCV.2009.5459360
   Hua G., 2006, IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR), V1, P650
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lim Jongwoo., 2005, Advances in Neural Information Processing Systems, P793
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu L., 2007, CVPR
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Özuysal M, 2006, LECT NOTES COMPUT SC, V3953, P592, DOI 10.1007/11744078_46
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Song XA, 2008, LECT NOTES COMPUT SC, V5304, P642, DOI 10.1007/978-3-540-88690-7_48
   Tran S., 2007, ICCV
   Wang G., 2006, CVPR, P1597
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Yang M., 2008, CVPR
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 39
TC 18
Z9 21
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2013
VL 31
IS 12
BP 992
EP 999
DI 10.1016/j.imavis.2013.09.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 282DU
UT WOS:000329151300009
DA 2024-07-18
ER

PT J
AU Liu, RS
   Lin, ZC
   Zhang, W
   Tang, KW
   Su, ZX
AF Liu, Risheng
   Lin, Zhouchen
   Zhang, Wei
   Tang, Kewei
   Su, Zhixun
TI Toward designing intelligent PDEs for computer vision: An optimal
   control approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optimal control; PDEs; Computer vision; Image processing
AB Many computer vision and image processing problems can be posed as solving partial differential equations (PDEs). However, designing a PDE system usually requires high mathematical skills and good insight into the problems. In this paper, we consider designing PDEs for various problems arising in computer vision and image processing in a lazy manner: learning PDEs from training data via an optimal control approach. We first propose a general intelligent PDE system which holds the basic translational and rotational invariance rule for most vision problems. By introducing a PDE-constrained optimal control framework, it is possible to use the training data resulting from multiple ways (ground truth, results from other methods, and manual results from humans) to learn PDEs for different computer vision tasks. The proposed optimal control based training framework aims at learning a PDE-based regressor to approximate the unknown (and usually nonlinear) mapping of different vision tasks. The experimental results show that the learnt PDEs can solve different vision problems reasonably well. In particular, we can obtain PDEs not only for problems that traditional PDEs work well but also for problems that PDE-based methods have never been tried before, due to the difficulty in describing those problems in a mathematical way. (C) 2012 Elsevier B.V. All rights reserved.
C1 Dalian Univ Technol, Fac Elect Informat & Elect Engn, Dalian, Peoples R China.
   [Lin, Zhouchen] Peking Univ, Sch EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.
   [Zhang, Wei] Chinese Univ Hong Kong, Dept Informat Engn, Hong Kong, Hong Kong, Peoples R China.
   [Liu, Risheng; Tang, Kewei; Su, Zhixun] Dalian Univ Technol, Sch Math Sci, Dalian, Peoples R China.
C3 Dalian University of Technology; Peking University; Chinese University
   of Hong Kong; Dalian University of Technology
RP Lin, ZC (corresponding author), Peking Univ, Sch EECS, Key Lab Machine Percept MOE, Beijing 100871, Peoples R China.
EM rsliu0705@gmail.com; zlin@pku.edu.cn; wzhang009@gmail.com;
   tkwliaoning@gmail.com; zxsu@dlut.edu.cn
RI Zhang, Wayne/GXM-6869-2022; Zhang, Wayne/AAF-3407-2019; Zhang,
   Wayne/AAY-7082-2021
OI Zhang, Wayne/0000-0002-8415-1062; Zhang, Wayne/0000-0002-8415-1062
FU National Natural Science Foundation of China [61272341, 61231002,
   61173103]; Training Program of the Major Research Plan of the National
   Natural Science Foundation of China [U0935004, 91230103]; Fundamental
   Research Funds for the Central Universities
FX This work is partially supported by the National Natural Science
   Foundation of China (Grant Nos. 61272341, 61231002, and 61173103),
   (Grant No. U0935004), the Training Program of the Major Research Plan of
   the National Natural Science Foundation of China (Grant No. 91230103)
   and the Fundamental Research Funds for the Central Universities. The
   first author would also like to thank the support from China Scholarship
   Council.
CR Ababnah A, 2011, IEEE T SYST MAN CY A, V41, P97, DOI 10.1109/TSMCA.2010.2049992
   Ambrosio L., 1992, COMMUN PURE APPL MAT, V7, P105
   [Anonymous], 1971, Optimal Control Theory: An Introduction
   [Anonymous], NIPS
   [Anonymous], 2005, CVPR
   [Anonymous], 1971, GRUNDLEHREN MATH WIS
   [Anonymous], 1997, ALGORITHMS IMAGE PRO
   [Anonymous], 2007, LARGE SCALE KERNEL M
   [Anonymous], 2000, SIGGRAPH
   [Anonymous], 2001, ICCV
   [Anonymous], 2011, ICCV
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chen T.F., 2005, IMAGE PROCESSING ANA
   *COR CORP, COR PHOT LIB
   Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241
   Gunturk BK, 2002, IEEE T IMAGE PROCESS, V11, P997, DOI 10.1109/TIP.2002.801121
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   JAIN AK, 1977, J OPTIMIZ THEORY APP, V23, P65, DOI 10.1007/BF00932298
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Li X, 2005, IEEE T IMAGE PROCESS, V14, P370, DOI 10.1109/TIP.2004.840683
   Liu R., 2010, ECCV
   Menon D, 2007, IEEE T IMAGE PROCESS, V16, P132, DOI 10.1109/TIP.2006.884928
   Mumford D., 1985, CVPR
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   Olver P.J., 2000, Applications of Lie Group to Differential Equations, V107
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sapiro G., 2001, Geometric Partial Differential Equations and Image Analysis
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Stoer J., 1998, INTRO NUMERICAL ANAL
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   ter Haar Romeny B., 1994, GEOMETRY DRIVEN DIFF
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Wazwaz AM, 2009, NONLINEAR PHYS SCI, P1, DOI 10.1007/978-3-642-00251-9
NR 35
TC 21
Z9 23
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2013
VL 31
IS 1
BP 43
EP 56
DI 10.1016/j.imavis.2012.09.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 084RP
UT WOS:000314557100004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Srivastava, A
   Turaga, P
   Kurtek, S
AF Srivastava, Anuj
   Turaga, Pavan
   Kurtek, Sebastian
TI On advances in differential-geometric approaches for 2D and 3D shape
   analyses and activity recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Analytic manifolds; Riemannian shape metrics; Elastic shape analysis;
   Video analysis; Activity recognition; Static and video image data
ID INVARIANT RECOGNITION; REGISTRATION; MODELS; FRAMEWORK; MANIFOLDS;
   SYSTEMS; METRICS; REPRESENTATIONS; STATISTICS; DISTANCES
AB In this paper we summarize recent advances in shape analysis and shape-based activity recognition problems with a focus on techniques that use tools from differential geometry and statistics. We start with general goals and challenges faced in shape analysis, followed by a summary of the basic ideas, strengths and limitations, and applications of different mathematical representations used in shape analyses of 2D and 3D objects. These representations include point sets, curves, surfaces, level sets, deformable templates, medial representations, and other feature-based methods. We discuss some common choices of Riemannian metrics and computational tools used for evaluating geodesic paths and geodesic distances for several of these shape representations. Then, we study the use of Riemannian frameworks in statistical modeling of variability within shape classes. Next, we turn to models and algorithms for activity analysis from various perspectives. We discuss how mathematical representations for human shape and its temporal evolutions in videos lead to analyses over certain special manifolds. We discuss the various choices of shape features, and parametric and non-parametric models for shape evolution, and how these choices lead to appropriate manifold-valued constraints. We discuss applications of these methods in gait-based biometrics, action recognition, and video summarization and indexing. For reader convenience, we also provide a short overview of the relevant tools from geometry and statistics on manifolds in the Appendix. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Srivastava, Anuj; Kurtek, Sebastian] Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA.
   [Turaga, Pavan] Arizona State Univ, Sch Arts Media Engn & Elect Engn, Tempe, AZ USA.
C3 State University System of Florida; Florida State University; Arizona
   State University; Arizona State University-Tempe
RP Srivastava, A (corresponding author), Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA.
EM anuj@stat.fsu.edu; pturaga@asu.edu; skurtek@stat.fsu.edu
RI Srivastava, Anuj/L-4705-2019; Turaga, Pavan/W-6186-2019
OI Turaga, Pavan/0000-0002-5263-5943; Srivastava, Anuj/0000-0001-7406-0338
FU ONR grant [ONR N00014-09-10664]; Division Of Mathematical Sciences;
   Direct For Mathematical & Physical Scien [0915003] Funding Source:
   National Science Foundation
FX This research was supported in part by an ONR grant ONR N00014-09-10664.
   The authors would like to thank Prof. Rama Chellappa for his
   encouragement and support in writing this paper. They also thank the
   reviewers for their help in improving this paper.
CR Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006
   Aggarwal G, 2004, INT C PATT RECOG, P175, DOI 10.1109/ICPR.2004.1333732
   AMIT Y, 1991, J AM STAT ASSOC, V86, P376, DOI 10.2307/2290581
   [Anonymous], P SIGGRAPH
   [Anonymous], 2010, Shapes and diffeomorphisms
   [Anonymous], 1996, The Statistical Theory of Shape
   [Anonymous], 2003, Geometric Level Set Methods in Imaging, Vision, and Graphics
   [Anonymous], 2007, IEEE INT C COMP VIS
   [Anonymous], 1999, Shape and Shape Theory
   [Anonymous], 1993, General pattern theory
   [Anonymous], 2004, THESIS U N CAROLINA
   Baloch S, 2010, IEEE T IMAGE PROCESS, V19, P1191, DOI 10.1109/TIP.2009.2039372
   Bauer M., 2011, 3 MICCAI WORKSH MATH, P182
   Baumberg A. M., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P194, DOI 10.1109/MNRAO.1994.346236
   Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa
   Begelfor Evgeni, 2006, P IEEE C COMP VIS PA, V2, P2087, DOI DOI 10.1109/CVPR.2006.50
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bissacco A, 2001, PROC CVPR IEEE, P52
   Bobick A., 2003, AUDIO VIDEO BASED BI
   Bouix S, 2005, NEUROIMAGE, V25, P1077, DOI 10.1016/j.neuroimage.2004.12.051
   BRECHBUHLER C, 1995, COMPUT VIS IMAGE UND, V61, P154, DOI 10.1006/cviu.1995.1013
   BROCKETT RW, 1972, SIAM J CONTROL, V10, P265, DOI 10.1137/0310021
   Bronstein AM, 2007, IEEE T VIS COMPUT GR, V13, P902, DOI 10.1109/TVCG.2007.1041
   Bronstein AM, 2006, SIAM J SCI COMPUT, V28, P1812, DOI 10.1137/050639296
   Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Cates J., 2006, P MICCAI WORKSH MATH, P90
   Cates J., 2008, P 11 INT C MED IM CO
   Chang W, 2008, COMPUT GRAPH FORUM, V27, P1459, DOI 10.1111/j.1467-8659.2008.01286.x
   Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x
   Chaudhry R, 2010, LECT NOTES COMPUT SC, V6312, P735, DOI 10.1007/978-3-642-15552-9_53
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Christensen GE, 2001, IEEE T MED IMAGING, V20, P568, DOI 10.1109/42.932742
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cremers D, 2002, LECT NOTES COMPUT SC, V2351, P93
   CREMERS D, 2003, 2 IEEE WORKSH VAR GE
   Davatzikos C, 1996, J COMPUT ASSIST TOMO, V20, P88, DOI 10.1097/00004728-199601000-00017
   Davies RH, 2010, IEEE T MED IMAGING, V29, P961, DOI 10.1109/TMI.2009.2035048
   Drira H., 2010, P BRIT MACH VIS C
   Drira H., 2009, P INT C COMP VIS
   Drira H, 2009, LECT NOTES COMPUT SC, V5558, P357, DOI 10.1007/978-3-642-01793-3_37
   Dryden IL., 1998, Statistical Shape Analysis
   DUNCAN TE, 1979, J OPTIMIZ THEORY APP, V27, P399, DOI 10.1007/BF00933032
   DUNCAN TE, 1988, SYST CONTROL LETT, V10, P257, DOI 10.1016/0167-6911(88)90015-1
   DUNCAN TE, 1977, INFORM CONTROL, V35, P182, DOI 10.1016/S0019-9958(77)90066-3
   Elgammal A, 2007, COMPUT VIS IMAGE UND, V106, P31, DOI 10.1016/j.cviu.2005.09.010
   Fletcher PT, 2007, SIGNAL PROCESS, V87, P250, DOI 10.1016/j.sigpro.2005.12.018
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Floater MS, 2005, MATH VIS, P157, DOI 10.1007/3-540-26808-1_9
   Gerig G., 2001, PROC MICCAI, P24
   Gomes J., 2002, BIOM IM 2002 5 IEEE
   Gorczowski K, 2010, IEEE T PATTERN ANAL, V32, P652, DOI 10.1109/TPAMI.2009.92
   Grenander U, 1998, IEEE T PATTERN ANAL, V20, P790, DOI 10.1109/34.709572
   Grenander U, 1998, Q APPL MATH, V56, P617, DOI 10.1090/qam/1668732
   Grenander U., 1981, Lectures in Pattern Theory
   Grenander U., 1976, LECT PATTERN THEORY, VI,II
   Grenander U., 1990, HANDS THEORETIC STUD
   Grenander U., 1994, J R STAT SOC, V56
   Hallinan P., 1999, Two and Three-dimensional Patterns of the Face
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Hilaga M, 2001, COMP GRAPH, P203, DOI 10.1145/383259.383282
   Huang QX, 2008, COMPUT GRAPH FORUM, V27, P1449, DOI 10.1111/j.1467-8659.2008.01285.x
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555
   Jian B, 2005, IEEE I CONF COMP VIS, P1246
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Joshi SC, 1997, INT J PATTERN RECOGN, V11, P1317, DOI 10.1142/S0218001497000615
   Joshi SH, 2007, LECT NOTES COMPUT SC, V4679, P387
   Joshi SH, 2007, PROC CVPR IEEE, P1643
   Kanatani K., 1990, Group-Theoretical Methods in Image Understanding
   Kelemen A, 1999, IEEE T MED IMAGING, V18, P828, DOI 10.1109/42.811260
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   Kim VG, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964974
   Klassen E, 2006, LECT NOTES COMPUT SC, V3951, P95
   Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333
   Kurtek S., 2011, LECT NOTES COMPUTER, V6801
   Kurtek S, 2012, IEEE T PATTERN ANAL, V34, P1717, DOI 10.1109/TPAMI.2011.233
   Kurtek S, 2011, IEEE T MED IMAGING, V30, P849, DOI 10.1109/TMI.2010.2099130
   Kurtek S, 2010, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2010.5539778
   Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1393, DOI 10.1109/TPAMI.2006.184
   LE HL, 1993, ANN STAT, V21, P1225, DOI 10.1214/aos/1176349259
   LEONARD NE, 1995, IEEE T AUTOMAT CONTR, V40, P1539, DOI 10.1109/9.412625
   Li RN, 2009, PROC CVPR IEEE, P2442
   Lipman Y., 2009, ACM T GRAPHIC, V28, P72
   Lipman Y, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1805964.1805971
   Liu XW, 2004, IEEE T PATTERN ANAL, V26, P662, DOI 10.1109/TPAMI.2004.1273986
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Lui YM, 2008, LECT NOTES COMPUT SC, V5303, P44, DOI 10.1007/978-3-540-88688-4_4
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Malladi R, 1996, J MATH IMAGING VIS, V6, P269, DOI 10.1007/BF00119843
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Mémoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y
   Mennuci A.C.G., 2009, METRICS CURVES SHAPE
   Michor PW, 2006, J EUR MATH SOC, V8, P1, DOI 10.4171/JEMS/37
   MILLER MI, 1993, P NATL ACAD SCI USA, V90, P11944, DOI 10.1073/pnas.90.24.11944
   Miller MI, 2001, INT J COMPUT VISION, V41, P61, DOI 10.1023/A:1011161132514
   Mio W, 2004, PROC CVPR IEEE, P10
   Mio W, 2007, INT J COMPUT VISION, V73, P307, DOI [10.1007/s11263-006-9968-0, 10.1007/s11263-006-996S-0]
   Moakher M, 2005, SIAM J MATRIX ANAL A, V26, P735, DOI 10.1137/S0895479803436937
   Moakher M, 2002, SIAM J MATRIX ANAL A, V24, P1, DOI 10.1137/S0895479801383877
   Osher S., 2006, Level Set Methods and Dynamic Implicit Surfaces
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Raudseps J.G., 1965, 18016ASTIAAD462877 O
   Samir C, 2006, IEEE T PATTERN ANAL, V28, P1858, DOI 10.1109/TPAMI.2006.235
   Samir C, 2009, INT J COMPUT VISION, V82, P80, DOI 10.1007/s11263-008-0187-8
   Schwartzman A., 2006, THESIS STANFORD
   SHAH J, 2006, WORKSH MATH FDN COMP
   Shah J, 2008, Q APPL MATH, V66, P123
   Sharon E, 2006, INT J COMPUT VISION, V70, P55, DOI 10.1007/s11263-006-6121-z
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P66, DOI 10.1109/38.90568
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   Siddiqi K, 2008, MACH VISION APPL, V19, P261, DOI 10.1007/s00138-007-0097-8
   Soatto S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P439, DOI 10.1109/ICCV.2001.937658
   Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86
   Srivastava A, 2005, NEUROCOMPUTING, V67, P136, DOI 10.1016/j.neucom.2004.11.036
   Srivastava A, 2009, J MATH IMAGING VIS, V33, P253, DOI 10.1007/s10851-008-0073-6
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Srivastava A, 2009, IEEE T PATTERN ANAL, V31, P1616, DOI 10.1109/TPAMI.2008.223
   Styner M., 2006, MICCAI OP SCI WORKSH
   Su J., IMAGE VISION COMPUT
   Sundaramoorthi G., 2009, TRACKING DEFORMING O
   Tagare HD, 2009, J MATH IMAGING VIS, V34, P61, DOI 10.1007/s10851-008-0129-7
   Tari Z., 1996, IEEE WORKSH MATH MET
   Toyama K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P50, DOI 10.1109/ICCV.2001.937599
   Trouve A, 1998, INT J COMPUT VISION, V28, P213, DOI 10.1023/A:1008001603737
   Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Vaillant M, 2005, LECT NOTES COMPUT SC, V3565, P381
   Vaswani N, 2005, IEEE T IMAGE PROCESS, V14, P1603, DOI 10.1109/TIP.2005.852197
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Veeraraghavan A., 2006, CVPR 06, P959, DOI [DOI 10.1109/CVPR.2006.304, 10.1109/CVPR.2006.304]
   Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143
   Vercauteren T, 2008, LECT NOTES COMPUT SC, V5241, P754, DOI 10.1007/978-3-540-85988-8_90
   Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040
   Vereauteren T, 2007, LECT NOTES COMPUT SC, V4792, P319
   Walsh G., 1993, P ACC
   Windheuser T., 2011, COMP GRAPH FOR P S G
   Windheuser T., 2011, INT C COMP VIS ICCV
   Xie Q., 2012, WORKSH BIOM IM REG
   Yi S., 2011, EUR 2011 WORKSH 3D O
   Yoshizawa Shin., 2005, S SOLID PHYS MODELIN, P227, DOI [10.1145/1060244.1060270, DOI 10.1145/1060244.1060270]
   Younes L, 1999, IMAGE VISION COMPUT, V17, P381, DOI 10.1016/S0262-8856(98)00125-5
   Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685
   Younes L, 2008, REND LINCEI-MAT APPL, V19, P25
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Yushkevich P, 2003, IMAGE VISION COMPUT, V21, P17, DOI 10.1016/S0262-8856(02)00135-X
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zeng Y, 2010, PROC CVPR IEEE, P382, DOI 10.1109/CVPR.2010.5540189
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang H, 2008, COMPUT GRAPH FORUM, V27, P1431, DOI 10.1111/j.1467-8659.2008.01283.x
   Zhang H., 2010, P EUR STAT OF THE AR
   Zhao HK, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P194, DOI 10.1109/VLSM.2001.938900
NR 156
TC 23
Z9 25
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2012
VL 30
IS 6-7
SI SI
BP 398
EP 416
DI 10.1016/j.imavis.2012.03.006
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 977BA
UT WOS:000306630100004
DA 2024-07-18
ER

PT J
AU Hmam, H
   Kim, J
AF Hmam, Hatem
   Kim, Jijoong
TI Optimal non-iterative pose estimation via convex relaxation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pose estimation; PnP; Robotics; Semidefinite programming; Sum-of-squares
   programming
ID GLOBAL OPTIMIZATION; MOMENTS
AB In this paper we present a convex relaxation method that globally solves for the camera position and orientation given a set of image pixel measurements associated with a scene of reference points of known three-dimensional positions. The approach formulates the pose optimization problem as a semidefinite positive relaxation (SDR) program. A comprehensive comparative performance analysis, carried out in the computer simulations section, demonstrates the superior performance of the relaxation method over existing approaches. The computational complexity of the method is O(n), where n is the number of reference points, and is applicable to both coplanar and non-coplanar reference point configurations. The average run-time recorded is 50 ms for an average point count of 100. Crown Copyright (C) 2010 Published by Elsevier B.V. All rights reserved.
C1 [Hmam, Hatem; Kim, Jijoong] Def Sci & Technol Org, Edinburgh, SA 5111, Australia.
C3 Defence Science & Technology
RP Hmam, H (corresponding author), Def Sci & Technol Org, Edinburgh, SA 5111, Australia.
EM hatem.hmam@dsto.defence.gov.au
OI Hatem, Hmam/0000-0001-8652-6828
CR [Anonymous], INT J COMPUTER VISIO
   [Anonymous], 2006, 14 MED C CONTR AUT M, DOI DOI 10.1109/MED.2006.328769
   [Anonymous], 2008, BRIT MACH VIS C
   Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992
   Boyd S., 2004, CONVEX OPTIMIZATION
   ENQVIST O, 2008, EUR C COMP VIS MARS
   Enqvist O., 2009, INT C COMP VIS
   GROSSBERG MD, 2001, IEEE INT C COMP VIS, P1100
   HARALICK RM, 1991, C COMP VIS PATT REC, P298
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9
   Henrion D, 2009, OPTIM METHOD SOFTW, V24, P761, DOI 10.1080/10556780802699201
   HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127
   Kahl F, 2007, INT J COMPUT VISION, V74, P3, DOI 10.1007/s11263-006-0015-y
   Lasserre JB, 2001, SIAM J OPTIMIZ, V11, P796, DOI 10.1137/S1052623400366802
   LAURENT M, 2005, SIAM C OPT STOCKH
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   Prajna Stephen, 2004, SOSTOOLS: sum of squares optimization toolbox for matlab
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   STURM JF, 1990, OPTIMIZATION METHODS, P625
NR 21
TC 28
Z9 38
U1 0
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2010
VL 28
IS 11
BP 1515
EP 1523
DI 10.1016/j.imavis.2010.03.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 639KD
UT WOS:000280972800002
DA 2024-07-18
ER

PT J
AU Chen, JD
   Khatibi, S
   Kulesza, W
AF Chen, Jiandan
   Khatibi, Siamak
   Kulesza, Wlodek
TI Depth reconstruction uncertainty analysis and improvement - The
   dithering approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth reconstruction; Quantization uncertainty; Dither; Iso-disparity
   planes
AB The depth spatial quantization uncertainty is one of the factors which influence the depth reconstruction accuracy caused by a discrete sensor. This paper discusses the quantization uncertainty distribution, introduces a mathematical model of the uncertainty interval range, and analyzes the movements of the sensors in an Intelligent Vision Agent System. Such a system makes use of multiple sensors which control the deployment and autonomous servo of the system. This paper proposes a dithering algorithm which reduces the depth reconstruction uncertainty. The algorithm assures high accuracy from a few images taken by low-resolution sensors. The dither signal is estimated and then generated through an analysis of the iso-disparity planes. The signal allows for control of the camera movement. The proposed approach is validated and compared with a direct triangulation method. The simulation results are reported in terms of depth reconstruction error statistics. The physical experiment shows that the dithering method reduces the depth reconstruction error. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Chen, Jiandan; Khatibi, Siamak; Kulesza, Wlodek] Blekinge Inst Technol, SE-37179 Karlskrona, Sweden.
C3 Blekinge Institute Technology
RP Chen, JD (corresponding author), Blekinge Inst Technol, SE-37179 Karlskrona, Sweden.
EM jian.d.chen@bth.se
RI Khatibi, Siamak/AAC-8824-2021; Kulesza, Wlodek J/I-5372-2018
OI Kulesza, Wlodek J./0000-0003-3262-3221
FU Lovstrom at Blekinge Institute of Technology, Sweden
FX The authors wish to acknowledge Prof. Stefan Andersson-Engels, Pontus
   Svenmarker and Haiyan Xie at the Division of Atomic Physics, Lund
   University, Sweden for lending their expertise regarding the necessary
   laboratory equipment. The authors would also like to thank Dr. Benny
   Lovstrom at Blekinge Institute of Technology, Sweden and Dr. Fredrik
   Bergholm for valuable discussion and support. Finally, we would like to
   thank Dr. Johan Hoglund for his comments.
CR [Anonymous], EUR S POINT BAS GRAP
   [Anonymous], THESIS U PENNSYLVANI
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Basu A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P755, DOI 10.1109/ICPR.1996.546125
   Ben-Ezra M, 2005, IEEE T PATTERN ANAL, V27, P977, DOI 10.1109/TPAMI.2005.129
   CARBONE P, 1994, IEEE T INSTRUM MEAS, V43, P389, DOI 10.1109/19.293456
   CARBONE P, 1998, ELSEVIER MEASUREMENT, V23, P131
   CHEN J, 2007, P 3DTV C TRUE VIS CA
   Chen JD, 2007, PROC SPIE, V6739, DOI 10.1117/12.738138
   Chen J, 2007, VISAPP 2007: PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOLUME IU/MTSV, P480
   Chen T., 2000, P SPIE SENSORS CAMER, V3965
   Francisco A, 1998, INT J COMPUT VISION, V29, P181, DOI 10.1023/A:1008084713069
   HOOK RN, 2000, P ASTR DAT AN SOFTW, V216
   Klarquist WN, 1998, IEEE T ROBOTIC AUTOM, V14, P755, DOI 10.1109/70.720351
   Kulesza Wlodek, 2008, Stereo Vision, P153
   LIU XD, 1995, IEEE T PATTERN ANAL, V17, P629, DOI 10.1109/34.387511
   Mariottini GL, 2005, IEEE ROBOT AUTOM MAG, V12, P26, DOI 10.1109/MRA.2005.1577022
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Rodriguez J. J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P153, DOI 10.1109/CVPR.1988.196229
   Vandewalle P, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/71459
   WAGDY MF, 1989, IEEE T INSTRUM MEAS, V38, P850, DOI 10.1109/19.31003
   Wannamaker RA, 2000, IEEE T SIGNAL PROCES, V48, P499, DOI 10.1109/78.823976
   WANNAMAKER RA, 2003, THESIS U WATERLOO CA
   Yang CC, 2001, J ROBOTIC SYST, V18, P1, DOI 10.1002/1097-4563(200101)18:1<1::AID-ROB1>3.0.CO;2-O
NR 24
TC 8
Z9 10
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2010
VL 28
IS 9
BP 1377
EP 1385
DI 10.1016/j.imavis.2010.03.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 620NN
UT WOS:000279506700005
DA 2024-07-18
ER

PT J
AU Peng, XM
   Bennamoun, M
   Ma, QA
   Lei, Y
   Zhang, QH
   Chen, WF
AF Peng, Xiaoming
   Bennamoun, Mohammed
   Ma, Qian
   Lei, Ying
   Zhang, Qiheng
   Chen, Wufan
TI Drift-correcting template update strategy for precision feature point
   tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature point tracking; Template matching; Template update strategy
ID IMAGE SEQUENCES
AB In this paper we present a drift-correcting template update strategy for precisely tracking a feature point in 2D image sequences. The proposed strategy greatly complements one of the latest published template update strategies by incorporating a robust non-rigid image registration step. Previous strategies use the first template to correct drifts in the current template; however, the drift still builds up when the first template becomes different from the current one particularly in a long image sequence. In our strategy the first template is updated timely when it is revealed to be quite different from the current template and henceforth the updated first template is used to correct template drifts in subsequent frames. Our method runs fast on a 3.0 GHz desktop PC, using about 0.03 s on average to track a feature point in a frame (under the assumption of a general affine transformation model, 61 x 61 pixels in template size) and less than 0.1 s to update the first template. The proposed template update strategy can be implemented either serially or in parallel. Quantitative evaluation results show the proposed method in precision tracking of a distinctive feature point whose appearance is constantly changing. Qualitative evaluation results show that the proposed method has a more sustained ability to track a feature point than two previous template update strategies. We also revealed the limitations of the proposed template update strategy by tracking feature points on a human's face. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Peng, Xiaoming; Lei, Ying; Chen, Wufan] Univ Elect Sci & Technol China, Coll Automat, Chengdu 610054, Sichuan, Peoples R China.
   [Peng, Xiaoming; Bennamoun, Mohammed] Univ Western Australia, Sch Comp Sci & Software Engn, Crawley, WA 6009, Australia.
   [Ma, Qian; Zhang, Qiheng] Chinese Acad Sci, Inst Opt & Elect, Lab 5, Chengdu 610209, Sichuan, Peoples R China.
C3 University of Electronic Science & Technology of China; University of
   Western Australia; Chinese Academy of Sciences; Institute of Optics &
   Electronics, CAS
RP Peng, XM (corresponding author), Univ Elect Sci & Technol China, Coll Automat, 4 Sect 2,N Jianshe Rd, Chengdu 610054, Sichuan, Peoples R China.
EM peng@csse.uwa.edu.au
RI Bennamoun, Mohammed/C-2789-2013
OI Bennamoun, Mohammed/0000-0002-6603-3257
FU Institute of Optics and Electronics (IOE); Chinese Academy of Sciences
   (CAS); national 973 project [2010CB732501]; University of Electronic
   Science and Technology of China [L08010701JX0761]
FX The work presented in this paper was partly supported by a research
   grant from the Institute of Optics and Electronics (IOE), Chinese
   Academy of Sciences (CAS), a national 973 project (Grant No.
   2010CB732501), and a research fund from University of Electronic Science
   and Technology of China (Grant No. L08010701JX0761). The authors would
   also like to thank the anonymous reviewers for their valuable comments
   and suggestions that make the paper much better.
CR Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Chetverikov D, 1998, INT C PATT RECOG, P1436, DOI 10.1109/ICPR.1998.711973
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Iqbal A., 2007, 8th Pacific Conference on Earthquake Engineering, P1
   Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625
   Kybic J, 2003, IEEE T IMAGE PROCESS, V12, P1427, DOI 10.1109/TIP.2003.813139
   Lee T, 2009, IEEE T VIS COMPUT GR, V15, P355, DOI 10.1109/TVCG.2008.190
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, PATTERN RECOGN, V29, P627, DOI 10.1016/0031-3203(95)00115-8
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   McCane B, 2002, INT J COMPUT VISION, V49, P79, DOI 10.1023/A:1019833915960
   Meltzer J, 2004, LECT NOTES COMPUT SC, V3021, P215
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Periaswamy S, 2003, IEEE T MED IMAGING, V22, P865, DOI 10.1109/TMI.2003.815069
   Rahimi A, 2008, COMPUT VIS IMAGE UND, V109, P97, DOI 10.1016/j.cviu.2006.12.004
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schreiber D, 2007, PATTERN RECOGN LETT, V28, P1483, DOI 10.1016/j.patrec.2007.03.007
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Singh M, 2005, PATTERN RECOGN LETT, V26, P1995, DOI 10.1016/j.patrec.2005.03.015
   Skrypnyk I, 2004, ISMAR 2004: THIRD IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, P110, DOI 10.1109/ISMAR.2004.53
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4
   Tissainayagam P, 2004, IMAGE VISION COMPUT, V22, P663, DOI 10.1016/j.imavis.2004.02.001
   Tomasi C, 1991, DETECTION TRACKING P
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   YAO YS, 1995, IEEE T IMAGE PROCESS, V4, P1382, DOI 10.1109/83.465103
   Zhang JZ, 2002, IEEE T SYST MAN CY C, V32, P392, DOI 10.1109/TSMCC.2002.806058
   ZHENG QF, 1995, INT J COMPUT VISION, V15, P31, DOI 10.1007/BF01450849
NR 33
TC 7
Z9 9
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1280
EP 1292
DI 10.1016/j.imavis.2010.01.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400010
DA 2024-07-18
ER

PT J
AU Wang, XY
   Wang, YX
   Yun, JJ
AF Wang, Xing-Yuan
   Wang, Yuan-Xing
   Yun, Jiao-Jiao
TI An improved no-search fractal image coding method based on a fitting
   plane
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fractal image coding; No-search; Quadtree; Gray-level transform; Fitting
   plane
AB In this paper a fast and efficient no-search fractal image coding method based on a modified gray-level transform which uses a fitting plane is presented. The improved gray-level transform can reduce the minimum matching error between a given range block and its corresponding domain block, and thus, it can enhance the possibility of successful domain-range matching. In comparison with our previous scheme which uses an adaptive plane, the improved scheme results in a considerable acceleration of the encoding process, decreases the compression ratio and improves the quality of the reconstructed images in the meanwhile. Comparing with Furao's no-search scheme, our improved scheme can get higher PSNR at higher bpp and almost the same PSNR at lower bpp. Although it uses more transform coefficients, such a fitting plane method can speed up the encoding process with the quality of the reconstructed images improved. Crown Copyright (C) 2010 Published by Elsevier B.V. All rights reserved.
C1 [Wang, Xing-Yuan; Wang, Yuan-Xing; Yun, Jiao-Jiao] Dalian Univ Technol, Dept Elect & Informat Engn, Dalian 116024, Peoples R China.
C3 Dalian University of Technology
RP Wang, XY (corresponding author), Dalian Univ Technol, Dept Elect & Informat Engn, Dalian 116024, Peoples R China.
EM wangxy@dlut.edu.cn; wangyuanxing2005@126.com
RI Wang, Xing-yuan/I-6353-2015
FU National Natural Science Foundation of China [60973152, 60573172];
   Superior University Doctoral Subject Special Scientific Research
   Foundation of China [20070141014]; Natural Science Foundation of
   Liaoning Province [20082165]
FX This research is supported by the National Natural Science Foundation of
   China (No: 60973152, 60573172), the Superior University Doctoral Subject
   Special Scientific Research Foundation of China (No: 20070141014) and
   the Natural Science Foundation of Liaoning Province (No: 20082165).
CR Barnsley M.F., 1993, FRACTAL EVERYWHERE, V2, P84
   BARNSLEY MF, 1988, BYTE             JAN, P215
   Barnsley MF., 1993, Fractals Everywhere
   JACKSON DJ, 2007, HARDWARE ARCHITECTUR
   MONRO DM, 1994, P IEEE INT C AC SPEE, V5, P557
   MONRO DM, 1992, C FRACT ENG EC POL M
   MONRO DM, 1993, P ICASSP, V5, P169
   Shen FR, 2004, SIGNAL PROCESS-IMAGE, V19, P393, DOI 10.1016/j.image.2004.02.002
   TAMAS K, 2008, IMAGE VISION COMPUT, V26, P1129
   Tong CS, 2001, IEEE T IMAGE PROCESS, V10, P1269, DOI 10.1109/83.941851
   Wang XY, 2008, COMPUT GRAPH-UK, V32, P445, DOI 10.1016/j.cag.2008.02.004
   WU X, 2004, P INT C IM SCI SYST, V2, P324
   WU X, 2004, P 19 INT C COMP THEI, V1, P6
NR 13
TC 51
Z9 54
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1303
EP 1308
DI 10.1016/j.imavis.2010.01.008
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400012
DA 2024-07-18
ER

PT J
AU Lucey, S
   Wang, Y
   Saragih, J
   Cohn, JF
AF Lucey, Simon
   Wang, Yang
   Saragih, Jason
   Cohn, Jeffery F.
TI Non-rigid face tracking with enforced convexity and local appearance
   consistency constraint
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Constrained local models; Convex quadratic fitting; Non-rigid face
   tracking
ID MODELS
AB Convex quadratic fitting (CQF) has demonstrated great success recently in the task of non-rigidly registering a face in a still image using a constrained local model (CLM). A CLM is a commonly used model for non-rigid object registration and contains two components: (i) local patch-experts that model the appearance of each landmark in the object, and (ii) a global shape prior describing how each of these landmarks can vary non-rigidly. Conventional CLMs can be used in non-rigid facial tracking applications through a track-by-detection strategy. However, the registration performance of such a strategy is susceptible to local appearance ambiguity. Since there is no motion continuity constraint between neighboring frames of the same sequence, the resultant object alignment might not be consistent from frame to frame and the motion field is not temporally smooth. In this paper, we extend the CQF fitting method into the spatio-temporal domain by enforcing the appearance consistency constraint of each local patch between neighboring frames. More importantly, we show, as in the original CQF formulation, that the global warp update can be optimized jointly in an efficient manner. Finally, we demonstrate that our approach receives improved performance for the task of non-rigid facial motion tracking on the videos of clinical patients. (C) 2009 Published by Elsevier B.V.
C1 [Lucey, Simon; Wang, Yang; Saragih, Jason; Cohn, Jeffery F.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Lucey, S (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM slucey@cs.cmu.edu; wangy@cs.cmu.edu; jsaragih@andrew.cmu.edu;
   jeffcohn@cs.cmu.edu
RI Saragih, Jason/B-7539-2011; Lucey, Simon M/B-7556-2011; Lucey,
   Simon/HDO-1716-2022
OI Lucey, Simon/0000-0002-6326-042X
FU NIH [R01 MH51435]; CIHR [145703]
FX The authors would like to thank Mark Cox for the helpful discussions.
   This work was partially supported by NIH Grant No. R01 MH51435 and CIHR
   Grant No. 145703.
CR [Anonymous], CVPR
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], CVPR
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Baker S, 2004, IEEE T PATTERN ANAL, V26, P1380, DOI 10.1109/TPAMI.2004.77
   BAKER S, 2004, LUCAS KANADE 20 YE 1
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   Cootes T., 1995, COMPUTER VISION IMAG, V61
   Cootes T.F., 1998, COMPUTER VISION ECCV, V1407, P484, DOI [DOI 10.1007/BFB0054760, DOI 10.1109/34.927467]
   DOWSON NDH, 2006, BMVC
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   GROSS R, 2007, CMURITR0708
   Gu Lie., 2007, IEEE C COMPUTER VISI, P1
   Kokkinos I, 2007, IEEE I CONF COMP VIS, P282
   Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34
   LIU X, 2007, CVPR, P1
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   MATTHEWS I, 2004, IJCV, V1, P135
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Theobald BJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P149
   Walker KN, 2002, IMAGE VISION COMPUT, V20, P435, DOI 10.1016/S0262-8856(02)00014-8
   WANG Y, 2007, IEEE WORKSH NONR REG
   Wang Y, 2008, PROC CVPR IEEE, P3621
   Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167
   XIAO J, 2004, CVPR
   ZHOU Y, 2003, CVPR, V1, P109
NR 28
TC 12
Z9 15
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 781
EP 789
DI 10.1016/j.imavis.2009.09.009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900007
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Tan, HK
   Ngo, CW
AF Tan, Hung-Khoon
   Ngo, Chong-Wah
TI Localized matching using Earth Mover's Distance towards discovery of
   common patterns from small image samples
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Common Pattern Discovery; Earth Mover's Distance; Localized matching;
   Local Flow Maximization; Expectation-maximization
AB This paper proposes a new approach for the discovery of common patterns in a small set of images by region matching. The issues in feature robustness, matching robustness and noise artifact are addressed to delve into the potential of using regions as the basic matching unit. We novelly employ the many-to-many (M2M) matching strategy, specifically with the Earth Mover's Distance (EMD), to increase resilience towards the structural inconsistency from improper region segmentation. However, the matching pattern of M2M is dispersed and unregulated in nature, leading to the challenges of mining a common pattern while identifying the underlying transformation. To avoid analysis on unregulated matching, we propose localized matching for the collaborative mining of common patterns from multiple images. The patterns are refined iteratively using the expectation-maximization algorithm by taking advantage of the "crowding" phenomenon in the EMD flows. Experimental results show that our approach can handle images with significant image noise and background clutter. To pinpoint the potential of Common Pattern Discovery (CPD), we further use image retrieval as an example to show the application of CPD for pattern learning in relevance feedback. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Tan, Hung-Khoon; Ngo, Chong-Wah] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Tan, HK (corresponding author), City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
EM hktan@cs.cityu.edu.hk; cwngo@cs.cityu.edu.hk
OI Ngo, Chong Wah/0000-0003-4182-8261
FU Research Grants Council of the Hong Kong Special Administrative Region,
   China [118905]
FX The work described in this paper was fully supported by a grant from the
   Research Grants Council of the Hong Kong Special Administrative Region,
   China (CityU 118905).
CR Andrews S., 2002, NIPS, P577
   [Anonymous], 1998, LEARNING GRAPHICAL M
   [Anonymous], BMVC
   [Anonymous], COMPUTER VISION PATT
   Berg AC, 2005, PROC CVPR IEEE, P26
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   CHEVALEYRE Y, 2001, LECT NOTES ARTIFICIA, V2056
   Cohen S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1076, DOI 10.1109/ICCV.1999.790393
   Felzenszwalb PF, 1998, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.1998.698594
   GRAUMAN K, 2004, COMPUTER VISION PATT
   HE X, 2004, ACM INT C MULT, V1, P39
   HONG P, 2002, WORKSH DISCR MATH DA
   Hong PY, 2004, DISCRETE APPL MATH, V139, P113, DOI 10.1016/j.dam.2002.11.007
   HUANG TS, 2001, INT C IM PROC
   Jiang H, 2004, INT C PATT RECOG, P658, DOI 10.1109/ICPR.2004.1334615
   JIANG H, 2003, INT C VIS INF SYST, P446
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MARON O, 1998, ICML, P341
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mchugh J.A., 1990, ALGORITHMIC GRAPH TH
   McLachlan G. J., 1997, The EM Algorithm and Extensions, V473, P486
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   PONCE J, 2006, SPRINGER VERLAG LECT, V4170
   QUACK T, 2007, INT C COMP VIS
   RATAN A, 1999, P COMP VIS PATT REC, V1, P423
   Rubner L. J., 1997, P ARPA IM UND WORKSH, P661
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   RUBNER Y, 2001, IEEE T PATTERN ANAL, V23, P1281
   RUI Y, 1999, ACM INT C MULT, V3, P2
   Steinbach M., 2000, P KDD WORKSH TEXT MI
   Swain D., 1990, 3 INT C COMPUTER VIS, P390, DOI [DOI 10.1109/ICCV.1990.139558, 10.1109/ICCV.1990.139558]
   Tan HK, 2005, IEEE I CONF COMP VIS, P1222
   Yang C., 2005, ACM INT C MULT
   Yuan JS, 2007, IEEE I CONF COMP VIS, P321
   Zhang Q, 2002, ADV NEUR IN, V14, P1073
   ZHANG Q, 2002, ICML, P682
   Zhao WL, 2007, IEEE T MULTIMEDIA, V9, P1037, DOI 10.1109/TMM.2007.898928
NR 37
TC 23
Z9 23
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1470
EP 1483
DI 10.1016/j.imavis.2009.01.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800006
OA Green Published
DA 2024-07-18
ER

PT J
AU Aptoula, E
   Lefèvre, S
AF Aptoula, E.
   Lefevre, S.
TI On the morphological processing of hue
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Colour mathematical morphology; Hue ordering; Hue weighting; Polar
   colour spaces; Chromaticity
ID MATHEMATICAL MORPHOLOGY; COLOR; OPERATORS
AB Although polar colour spaces are being increasingly used in the context of colour mathematical morphology, mainly due to their intuitiveness, the processing of the circular hue band continues to be their main drawback. In this paper, we discuss the two principal problems concerning the morphological processing of hue, first its lack of a lattice structure, which we propose to introduce by means of a distance based formulation from multiple representative reference hue points. And second, the distinction of chromatic from achromatic pixels, since the hue component is of no significance for "low" saturation levels. For this purpose, we present a new weighting scheme, based on the combination of saturation and luminance channels. Application results on texture classification, asserting the superior performance of this approach, are also included. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Aptoula, E.; Lefevre, S.] CNRS ULP, LSIIT, UMR 7005, F-67412 Illkirch Graffenstaden, France.
C3 Universites de Strasbourg Etablissements Associes; Universite de
   Strasbourg; Centre National de la Recherche Scientifique (CNRS)
RP Lefèvre, S (corresponding author), CNRS ULP, LSIIT, UMR 7005, Blvd Sebastien Brant,POB 10413, F-67412 Illkirch Graffenstaden, France.
EM lefevre@lsiit.u-strasbg.fr
RI Aptoula, Erchan/AAI-1070-2020; Lefevre, Sebastien/S-9444-2017
OI Aptoula, Erchan/0000-0001-6168-2883; Lefevre,
   Sebastien/0000-0002-2384-8202
CR Angulo J, 2005, COMPUT IMAGING VIS, V30, P387
   ANGULO J, 2003, THESIS ECOLE MINES P
   [Anonymous], P 8 COMP VIS WINT WO
   [Anonymous], 1992, R. woods digital image processing
   Aptoula E, 2007, PATTERN RECOGN, V40, P2914, DOI 10.1016/j.patcog.2007.02.004
   CARRON T, 1995, THESIS U SAVOIE FRAN
   GOUTSIAS J, 1995, COMPUT VIS IMAGE UND, V62, P326, DOI 10.1006/cviu.1995.1058
   HANBURY A, 2002, THESIS ECOLE MINES P
   HANBURY A, 2003, P DAGM MAGD GERM
   Hanbury A., 2002, IMAGE ANAL STEREOL, V21, P201, DOI DOI 10.5566/IAS.V21.P201-206
   Hanbury A., 2001, P 12 BRIT MACH VIS C
   Hanbury AG, 2001, IEEE T IMAGE PROCESS, V10, P1842, DOI 10.1109/83.974569
   Louverdis G, 2002, PATTERN RECOGN, V35, P1733, DOI 10.1016/S0031-3203(01)00166-2
   Mäenpää T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   PETERS A, 1997, P SPIE NONLINEAR IMA, V3026
   RONSE C, 1990, SIGNAL PROCESS, V21, P129, DOI 10.1016/0165-1684(90)90046-2
   Serra J., 1993, MATH MORPHOLOGY IMAG, P483
   Vardavoulia MI, 2002, PATTERN ANAL APPL, V5, P271, DOI 10.1007/s100440200024
   WHEELER M, 2000, IEEE P NAT AER EL C, V1
   [No title captured]
NR 20
TC 22
Z9 27
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1394
EP 1401
DI 10.1016/j.imavis.2008.12.007
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jean, F
   Bergevin, R
   Albu, AB
AF Jean, Frederic
   Bergevin, Robert
   Albu, Alexandra Branzan
TI Computing and evaluating view-normalized body part trajectories
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Body parts trajectories; View-invariance; Normalization; Gait
ID GAIT RECOGNITION; MOTION
AB This paper proposes an approach to compute and evaluate view-normalized body part trajectories of pedestrians from monocular video sequences. The proposed approach uses the 2D trajectories of both feet and of the head extracted from the tracked silhouettes. On that basis, it segments the walking trajectory into piecewise linear segments. Finally, a normalization process is applied to head and feet trajectories over each obtained straight walking segment. View normalization makes head and feet trajectories appear as if seen from a fronto-parallel viewpoint. The latter is assumed to be optimal for gait modeling and identification purposes. The proposed approach is fully automatic as it requires neither manual initialization nor camera calibration. An extensive experimental evaluation of the proposed approach confirms the validity of the normalization process. (C) 2008 Elsevier BY. All rights reserved.
C1 [Jean, Frederic; Bergevin, Robert] Univ Laval, Comp Vis & Syst Lab, Dept Elect & Comp Engn, Quebec City, PQ G1K 7P4, Canada.
   [Albu, Alexandra Branzan] Univ Victoria, Lab Appl Comp Vis Algorithms, Dept Elect & Comp Engn, Victoria, BC V8W 3P6, Canada.
C3 Laval University; University of Victoria
RP Jean, F (corresponding author), Univ Laval, Comp Vis & Syst Lab, Dept Elect & Comp Engn, Quebec City, PQ G1K 7P4, Canada.
EM fjean@gel.ulaval.ca; bergevin@gel.ulaval.ca; aalbu@ece.uvic.ca
OI Bergevin, Robert/0000-0002-1115-7471
FU Natural Sciences and Engineering Research Council of Canada; Fonds
   Quebecois de la Recherche Sur la Nature et les Technologies; Precarn
   Inc.
FX This work is supported by Natural Sciences and Engineering Research
   Council of Canada, Fonds Quebecois de la Recherche Sur la Nature et les
   Technologies, and by Precarn Inc.
CR ALBU AB, 2006, P IEEE INT C PATT RE
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], P 4 ACM INT WORKSH V
   [Anonymous], P IEEE C COMP VIS PA
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   BenAbdelkader C., 2002, LNCS, V2359, P155
   Bissacco A, 2001, PROC CVPR IEEE, P52
   Collins RT, 2000, IEEE T PATTERN ANAL, V22, P745, DOI 10.1109/TPAMI.2000.868676
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Han J, 2005, PATTERN RECOGN LETT, V26, P615, DOI 10.1016/j.patrec.2004.09.011
   HAN X, 2006, P IEEE C CYB INT SYS, P1
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hild M, 2004, INT C PATT RECOG, P231, DOI 10.1109/ICPR.2004.1333746
   Jean F, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P144, DOI 10.1109/CRV.2005.24
   Jean F, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P89, DOI 10.1109/CRV.2007.19
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Johnson AY, 2001, LECT NOTES COMPUT SC, V2091, P301
   Kale A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P143, DOI 10.1109/AVSS.2003.1217914
   KALE A, 2004, GAIT BASED HUMAN IDE
   Lee CS, 2005, LECT NOTES COMPUT SC, V3546, P395
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Makihara Y, 2006, INT C PATT RECOG, P96
   Murray M P, 1967, Am J Phys Med, V46, P290
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   Urtasun R, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P17, DOI 10.1109/AFGR.2004.1301503
   Yoo J., 2003, P INT SOC BIOM 19 C
   YU S, 2004, P 3 INT C IM GRAPH H, P282
   ZHANG R, 2004, P IEEE C COMP VIS PA, V1, P18
   Zivkovic Z., 2004, P IEEE INT C PATT RE
NR 31
TC 50
Z9 52
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1272
EP 1284
DI 10.1016/j.imavis.2008.11.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200004
DA 2024-07-18
ER

PT J
AU Bulò, SR
   Torsello, A
   Pelillo, M
AF Bulo, Samuel Rota
   Torsello, Andrea
   Pelillo, Marcello
TI A game-theoretic approach to partial clique enumeration
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Maximal clique enumeration; Maximum clique problem; Evolutionary game
   theory; Evolutionary stable strategy
ID MAXIMUM CLIQUE; MODEL; STRATEGIES; ALGORITHM; GRAPHS; SHAPE
AB In many computer vision and pattern recognition applications using graph-based representations, it is of great interest to be able to extract the k largest cliques in a graph. However, most methods are geared either towards extracting a single clique of maximum size, or enumerating all cliques, without following any particular order. In this paper, we present a novel approach for partial clique enumeration, which is the problem of extracting the k largest cliques of a graph. Our approach is based on a continuous formulation of the clique problem developed in the 1960s by Motzkin and Straus, and is able to avoid extracting the same clique multiple times. This is done by casting the problem into a game-theoretic framework, where stable strategies are in correspondence with maximal cliques, and by iteratively rendering the extracted solutions unstable. The approach has been tested on the maximum clique problem and compared against several state-of-the-art algorithms both on random as well as DIMACS benchmark graphs. Further, we applied our enumerative heuristic to the matching of shapes using the shock-graph representation. The results confirm the effectiveness of the approach. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Bulo, Samuel Rota; Torsello, Andrea; Pelillo, Marcello] Univ Ca Foscari Venezia, Dipartimento Informat, I-30172 Venice, Italy.
C3 Universita Ca Foscari Venezia
RP Bulò, SR (corresponding author), Univ Ca Foscari Venezia, Dipartimento Informat, Via Torino 155, I-30172 Venice, Italy.
EM srotabul@dsi.unive.it; torsello@dsi.unive.it; pelillo@dsi.unive.it
RI Bulò, Samuel Rota/G-1014-2010; Torsello, Andrea/K-6352-2016
OI Rota Bulo, Samuel/0000-0002-2372-1367; Torsello,
   Andrea/0000-0001-9189-4924
CR AMBLER AP, 1982, P 3 INT J C ART INT, P298
   [Anonymous], 2006, CVPR 06 P IEEE COMP
   AUGUSTSO.JG, 1970, J ACM, V17, P571, DOI 10.1145/321607.321608
   Barrow H. G., 1976, Information Processing Letters, V4, P83, DOI 10.1016/0020-0190(76)90049-1
   BAUM LE, 1968, PAC J MATH, V27, P211, DOI 10.2140/pjm.1968.27.211
   BAUM LE, 1967, B AM MATH SOC, V73, P360, DOI 10.1090/S0002-9904-1967-11751-8
   Bertoni A, 2002, ALGORITHMICA, V33, P71, DOI 10.1007/s00453-001-0105-8
   Bolles R., 1982, INT J ROBOTICS RES, V1, P57
   Bomze I.M., 1997, DEV GLOBAL OPTIMIZAT, P95
   Bomze I. M., 1999, HDB COMBINATORIAL OP, P1, DOI DOI 10.1007/978-1-4757-3023-4_1
   Bomze IM, 1997, J GLOBAL OPTIM, V10, P143, DOI 10.1023/A:1008230200610
   Bomze IM, 2000, IEEE T NEURAL NETWOR, V11, P1228, DOI 10.1109/72.883403
   Bomze IM, 2002, DISCRETE APPL MATH, V121, P27, DOI 10.1016/S0166-218X(01)00233-5
   BONNER RE, 1964, IBM J RES DEV, V8, P22, DOI 10.1147/rd.81.0022
   BROCKINGTON M, 1996, CLIQUES COLORING SAT, P75
   BRON C, 1973, COMMUN ACM, V16, P575, DOI 10.1145/362342.362367
   Busygin S, 2006, DISCRETE APPL MATH, V154, P2080, DOI 10.1016/j.dam.2005.04.010
   CHIN RT, 1986, COMPUT SURV, V18, P67, DOI 10.1145/6462.6464
   DMITRY D, 2006, P 21 INT C COMP LING, P297
   FUNABIKI N, 1992, J PARALLEL DISTR COM, V14, P340, DOI 10.1016/0743-7315(92)90072-U
   Gibbons LE, 1997, MATH OPER RES, V22, P754, DOI 10.1287/moor.22.3.754
   Hammersley J., 1971, Markov fields on finite graphs and lattices
   HARARY F, 1957, SOCIOMETRY, V20, P205, DOI 10.2307/2785673
   Hastad J, 1996, AN S FDN CO, P627, DOI 10.1109/SFCS.1996.548522
   Hofbauer J., 1988, THEORY EVOLUTION DYN
   HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855
   JAGOTA A, 1995, IEEE T NEURAL NETWOR, V6, P724, DOI 10.1109/72.377977
   Jagota A., 1996, CLIQUES COLORING SAT, V26, P169
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   JOHNSON DS, 1988, INFORM PROCESS LETT, V27, P119, DOI 10.1016/0020-0190(88)90065-8
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   Kopf R., 1987, Foundations of Control Engineering, V12, P167
   Luenberger DG, 1984, LINEAR NONLINEAR PRO
   MOTZKIN TS, 1965, CANADIAN J MATH, V17, P533, DOI 10.4153/CJM-1965-053-6
   NINA M, 2004, MACH LEARN, V56, P115
   OGAWA H, 1986, PATTERN RECOGN, V19, P35, DOI 10.1016/0031-3203(86)90029-4
   Okubo Y, 2003, LECT NOTES ARTIF INT, V2843, P418
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   Pekergin F, 1999, IEEE T CIRCUITS-I, V46, P677, DOI 10.1109/81.768824
   Pelillo M, 1999, NEURAL COMPUT, V11, P1933, DOI 10.1162/089976699300016034
   Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105
   Pelillo M., 1995, Journal of Artificial Neural Networks, V2, P313
   Pelillo M., 1996, Journal of Artificial Neural Networks, V2, P411
   Pelillo M, 2006, NEURAL COMPUT, V18, P1215, DOI 10.1162/neco.2006.18.5.1215
   RADIG B, 1984, PATTERN RECOGN, V17, P161, DOI 10.1016/0031-3203(84)90043-8
   Shi XH, 2006, APPL MATH COMPUT, V180, P676, DOI 10.1016/j.amc.2006.01.009
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   SUETENS P, 1992, COMPUT SURV, V24, P5, DOI 10.1145/128762.128763
   TAYLOR PD, 1978, MATH BIOSCI, V40, P145, DOI 10.1016/0025-5564(78)90077-9
   TOMITA E, 1988, UECTRC5
   Torsello A, 2003, PATTERN RECOGN LETT, V24, P1089, DOI 10.1016/S0167-8655(02)00255-6
   Wang RL, 2003, NEURAL COMPUT, V15, P1605, DOI 10.1162/089976603321891828
   Weibull J.W., 1997, Evolutionary Game Theory
NR 53
TC 27
Z9 28
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 911
EP 922
DI 10.1016/j.imavis.2008.10.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300009
OA Green Published
DA 2024-07-18
ER

PT J
AU Derpanis, KG
   Wildes, RP
   Tsotsos, JK
AF Derpanis, Konstantinos G.
   Wildes, Richard P.
   Tsotsos, John K.
TI Definition and recovery of kinematic features for recognition of
   American sign language movements
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gesture recognition; Motion estimation; Human computer interaction
   (HCI); Linguistics; American sign language (ASL)
ID HIDDEN MARKOV-MODELS; MOTION; FRAMEWORK; TRACKING; SHAPE
AB An approach to recognizing human hand gestures from a monocular temporal sequence of images is presented. Of concern is the representation and recognition of hand movements that are used in single-handed American sign language (ASL). The approach exploits previous linguistic analysis of manual languages that decompose dynamic gestures into their static and dynamic components. The first level of decomposition is in terms of three sets of primitives, hand shape, location and movement. Further levels of decomposition involve the lexical and sentence levels and are beyond the scope of the present paper. We propose and subsequently demonstrate that given a monocular gesture sequence, kinematic features can be recovered from the apparent motion that provide distinctive signatures for 14 primitive movements of ASL. The approach has been implemented in software and evaluated on a database of 592 gesture sequences with an overall recognition rate of 86% for fully automated processing and 97% for manually initialized processing. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Derpanis, Konstantinos G.] York Univ, Dept Comp Sci & Engn, Toronto, ON M3J 1P3, Canada.
   York Univ, CVR, Toronto, ON M3J 1P3, Canada.
C3 York University - Canada; York University - Canada
RP Derpanis, KG (corresponding author), York Univ, Dept Comp Sci & Engn, 4700 Keele St, Toronto, ON M3J 1P3, Canada.
EM kosta@cs.yorku.ca
RI Tsotsos, John/N-1131-2019; Tsotsos, John K/G-3436-2011; Tsotsos,
   John/HTO-0616-2023
OI Tsotsos, John/0000-0002-8621-9147; 
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   Aris R., 1989, VECTORS TENSORS BASI
   BADLER N, 1975, TR80 U TOR DEP COMP
   Bauer B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P440, DOI 10.1109/AFGR.2000.840672
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   BECKER DA, 1997, SENSEI REAL TIME REC
   BERGEN JR, 1992, P EUR C COMP VIS, V1, P5
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   BLACK MJ, 1998, P EUROP C COMP VIS, V2, P909
   Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892
   Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057
   BOWDEN R, 2004, P ECCV, V1, P390
   Christy S, 1996, IEEE T PATTERN ANAL, V18, P1098, DOI 10.1109/34.544079
   Cutler R, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P416, DOI 10.1109/AFGR.1998.670984
   Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109
   Davis J, 1999, INT J PATTERN RECOGN, V13, P381, DOI 10.1142/S0218001499000227
   DERPANIS K, 2002, TRCS200402 YORK U
   Derpanis KG, 2004, LECT NOTES COMPUT SC, V3021, P282
   Elgammal A, 2003, PROC CVPR IEEE, P571
   FANG G, 2002, P IEEE INT C AUT FAC, P297
   Fels SS, 1998, IEEE T NEURAL NETWOR, V9, P205, DOI 10.1109/72.655042
   Grobel K, 1997, IEEE SYS MAN CYBERN, P162, DOI 10.1109/ICSMC.1997.625742
   Gupta N, 2002, IETE J RES, V48, P237, DOI 10.1080/03772063.2002.11416282
   Han J., 2012, Data Mining, P393, DOI [DOI 10.1016/B978-0-12-381479-1.00009-5, 10.1016/B978-0-12-381479-1.00009-5]
   Herpers R, 2001, IMAGE VISION COMPUT, V19, P793, DOI 10.1016/S0262-8856(00)00107-4
   HOLDEN EJ, 2005, IEEE WORKSH MOT VID, V2, P183, DOI DOI 10.1109/ACVM0T.2005.30
   Hong Pengyu, 2000, P 4 IEEE INT C AUT F, P410
   Horn B.K.P, 1986, Robot Vision
   Huang CL, 2001, MACH VISION APPL, V12, P243, DOI 10.1007/s001380050144
   Huber P.J., 1977, ROBUST STAT PROCEDUR
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jahne B., 1991, DIGITAL IMAGE PROCES
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   KOENDERINK JJ, 1976, J OPT SOC AM, V66, P717, DOI 10.1364/JOSA.66.000717
   KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377
   KOLLNIG H, 1994, P EUR C COMP VIS, VB, P338
   LAWN JM, 1994, P EUR C COMP VIS, VA, P205
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   LONGUETHIGGINS HC, 1980, PROC R SOC SER B-BIO, V208, P385, DOI 10.1098/rspb.1980.0057
   Lu S, 2003, PROC CVPR IEEE, P443
   Mammen J., 2002, P NAT C COMM JAN, P35
   MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/ciun.1994.1042
   Nam Y, 1999, IEEE T SYST MAN CY A, V29, P514, DOI 10.1109/3468.784178
   Negahdaripour S., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P132, DOI 10.1109/WVM.1991.212778
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098
   POIZNER H, 1981, J EXP PSYCHOL HUMAN, V7, P430, DOI 10.1037/0096-1523.7.2.430
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   REHG J, 1994, P EUROPEAN C COMPUTE, VB, P35
   SCHLENZIG J, 1994, P AS C SIGN SYST COM
   Shah M., 1997, Motion-Based Recognition, P1
   SHAPIRO LS, 1993, AFFINE ANAL IMAGE SE
   Sminchisescu C, 2003, PROC CVPR IEEE, P69
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   STENGER BDR, 2001, P BRIT MACH VIS C
   Stokoe W., 1965, DICT AM SIGN LANGUAG
   Tanibata N., 2002, PROC INT C VISION IN, P391
   TSOTSOS JK, 1980, IEEE T PATTERN ANAL, V2, P563, DOI 10.1109/TPAMI.1980.6447704
   Valli C., 2000, Linguistics of American Sign Language
   Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895
   Waldron M. B., 1995, IEEE Transactions on Rehabilitation Engineering, V3, P261, DOI 10.1109/86.413199
   WAXMAN AM, 1985, INT J ROBOT RES, V4, P72, DOI 10.1177/027836498500400306
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   WONG KY, 2002, P 15 INT C VIS INT, P80
   WONG S, 2005, P IEEE INT WORKSH HU, P170
   Wong S.-F., 2005, P BRIT MACH VIS C OX, V1, P379
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Yeasin M, 2000, PATTERN RECOGN, V33, P1805, DOI 10.1016/S0031-3203(99)00175-2
   ZHU Y, 2000, P 4 INT C AUT FAC GE, P544
NR 73
TC 10
Z9 10
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1650
EP 1662
DI 10.1016/j.imavis.2008.04.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500008
DA 2024-07-18
ER

PT J
AU Oh, HJ
   Lee, KM
   Lee, SU
AF Oh, Hyun Jun
   Lee, Kyoung Mu
   Lee, Sang Uk
TI Occlusion invariant face recognition using selective local non-negative
   matrix factorization basis images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; occlusion invariant; selective local non-negative
   matrix; factorization
ID REPRESENTATION; PARTS
AB In this paper, we propose a novel occlusion invariant face recognition algorithm based on Selective Local Non-negative Matrix Factorization (S-LNMF) technique. The Proposed algorithm is composed of two phases: the occlusion detection phase and the selective LNMF-based recognition phase. We use a local approach to effectively detect partial occlusions in an input face image. A face image is first divided into a finite number of disjointed local patches, and then each patch is represented by PCA (Principal Component Analysis), obtained by corresponding occlusion-free patches of training images. And the 1-NN threshold classifier is used for occlusion detection for each patch in the corresponding PCA space. In the recognition phase, by employing the LNMF-based face representation, we exclusively use the LNMF bases of occlusion-free image patches for face recognition. Euclidean nearest neighbor rule is applied for the matching.
   We have performed experiments on AR face database that includes many occluded face images by sunglasses and scarves. The experimental results demonstrate that the proposed local patch-based occlusion detection technique works well and the S-LNMF method shows superior performance to other conventional approaches. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Lee, Kyoung Mu] Seoul Natl Univ, Dept Elect Eng, Seoul 151600, South Korea.
   Seoul Natl Univ, ASRI, Seoul 151600, South Korea.
C3 Seoul National University (SNU); Seoul National University (SNU)
RP Lee, KM (corresponding author), Seoul Natl Univ, Dept Elect Eng, Gwanak POB 34, Seoul 151600, South Korea.
EM purete5@nate.com; kyoungmu@snu.ac.kr; sanguk@sting.snu.ac.kr
RI Lee, Kyoung Mu/AAC-4063-2020
OI Lee, Kyoung Mu/0000-0001-7210-1036
CR [Anonymous], P 3 WORKSH EMP EV ME
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Duda R. O., 2000, PATTERN CLASSIFICATI
   JAIN A, 1982, FUNDAMENTALS DIGITAL
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Lee D.D., 2000, NIPS 00, P535
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830
   Leonardis A, 1996, PROC CVPR IEEE, P453, DOI 10.1109/CVPR.1996.517111
   Li SZ, 2001, PROC CVPR IEEE, P207
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   MARTTINEZ AM, 1998, 24 CVC
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   PENEV P, 1996, NEURAL SYST, V7, P1
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Stockman George, 2001, Computer Vision
   TARRES F, 2005, 47 INT S ELMAR 2005
   Tax D., 1998, P 4 ANN C ADV SCH CO
   Tax D., 2001, One-class classification: Concept-learning in the absence of counter-examples
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
NR 22
TC 71
Z9 82
U1 0
U2 18
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1515
EP 1523
DI 10.1016/j.imavis.2008.04.016
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000007
DA 2024-07-18
ER

PT J
AU Maddalena, L
   Petrosino, A
AF Maddalena, Lucia
   Petrosino, Alfredo
TI Restoration of blue scratches in digital image sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE colour digital film restoration; blue scratch; scratch detection;
   scratch removal
ID JOINT INTERPOLATION; VECTOR-FIELDS; RECONSTRUCTION
AB In this paper, we consider the problem of detecting and removing blue scratches from digital image sequences. In particular, we propose a detection method and a removal method that strongly rely on the specific features of such scratches. Evaluation of the proposed methods, in terms of both accuracy and performance timings, and numerical experiments on real images are reported. (c) 2006 Elsevier B.V. All rights reserved.
C1 [Maddalena, Lucia] ICAR, Inst High Performance Comp & Networking, Natl Res Council, I-80131 Naples, Italy.
   [Petrosino, Alfredo] Univ Naples Parthenope, Dept Appl Sci, I-80133 Naples, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Calcolo e Reti ad
   Alte Prestazioni (ICAR-CNR); Parthenope University Naples
RP Maddalena, L (corresponding author), ICAR, Inst High Performance Comp & Networking, Natl Res Council, Via P Castellino 111, I-80131 Naples, Italy.
EM lucia.maddalena@na.icar.cnr.it; alfredo.petrosino@uniparthenope.it
RI Maddalena, Lucia/K-5508-2013
OI Maddalena, Lucia/0000-0002-0567-4624
FU Regional Competence Centre for the Development and Transfer of
   Innovation Applied to Cultural and Environmental Heritage (INNOVA);
   Regione Campania, Italy
FX The authors would like to express their gratitude to the anonymous
   referees for their useful suggestions. This work has been partially
   supported by the Regional Competence Centre for the Development and
   Transfer of Innovation Applied to Cultural and Environmental Heritage
   (INNOVA) funded by Regione Campania, Italy.
CR ANZALONE A, 2001, P IASTED VIIP01 SPAI, P565
   Ballester C, 2003, MULTISCALE MODEL SIM, V2, P80, DOI 10.1137/S1540345903422458
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Bornard R., 2002, P ACM INT C MULTIMED, P355
   Bretschneider T, 2000, P IM VIS COMP NZ, P38
   Bruni V, 2004, IEEE T IMAGE PROCESS, V13, P44, DOI 10.1109/TIP.2003.817231
   *DFR LAB, ICAR CNR NAPL
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   FERRANDIERE ED, 1997, THESIS ECOLE NATL SU
   Joyeux L., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P548, DOI 10.1109/CVPR.1999.786991
   Joyeux L, 2002, MACH VISION APPL, V13, P119, DOI 10.1007/s001380100067
   Joyeux L, 2001, IMAGE VISION COMPUT, V19, P503, DOI 10.1016/S0262-8856(00)00091-3
   JOYEUX L, 2000, THESIS U ROCHELLE
   Kao O., 2000, Proceedings of the International Conference on Imaging Science, Systems, and Technology. CISST'2000, P171
   Kokaram A., 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P73
   Kokaram A, 2002, IEEE IMAGE PROC, P325
   Kokaram A., 1998, Motion Picture Restoration
   KOKARAM AC, 1995, IEEE T IMAGE PROCESS, V4, P1496, DOI 10.1109/83.469931
   Machi A., 2002, Proceedings of the Fourth IASTED International Conference Signal and Image Processing, P254
   Maddalena L, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P547, DOI 10.1109/ICIAP.2001.957067
   Masnou S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P259, DOI 10.1109/ICIP.1998.999016
   MORRIS RD, 1995, THESIS U CAMBRIDGE
   MORRIS RD, 1996, P ICIP 96, V1, P801
   Rosenthal Laura J., 1996, Playwrights and Plagiarists in Early Modern England: Gender, Authority, Literary Property, P20
   Saito T, 2000, INT C PATT RECOG, P13, DOI 10.1109/ICPR.2000.903476
   SAPIRO G, 2002, SIAM NEWS, P35
   SHEN J, 2003, SIAM NEWS, P36
   Tegolo D, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P507, DOI 10.1109/ICIAP.2001.957060
   *U KOBL LAND I COM, COL TEXT AN
   *U SO CAL EL ENG D, USC SIPI IM DAT
   VERDERA J, 2003, P IEEE INT C IM PROC, P14
   Wang Z, 2004, SIGNAL PROCESS-IMAGE, V19, P121, DOI 10.1016/S0923-5965(03)00076-6
NR 32
TC 5
Z9 5
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1314
EP 1326
DI 10.1016/j.imavis.2006.04.013
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700002
DA 2024-07-18
ER

PT J
AU Kotsia, I
   Buciu, L
   Pitas, L
AF Kotsia, Irene
   Buciu, Loan
   Pitas, Loannis
TI An analysis of facial expression recognition under partial facial image
   occlusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE facial expression recognition; Gabor filters; Discriminant Non-negative
   Matrix Factorization; support vector machines; partial occlusion
ID NONNEGATIVE MATRIX; AUTOMATIC-ANALYSIS; INFORMATION; FACTORIZATION;
   SEQUENCES
AB In this paper, an analysis of the effect of partial occlusion on facial expression recognition is investigated. The classification from partially occluded images in one of the six basic facial expressions is performed using a method based on Gabor wavelets texture information extraction, a supervised image decomposition method based on Discriminant Non-negative Matrix Factorization and a shape-based method that exploits the geometrical displacement of certain facial features. We demonstrate how partial occlusion affects the above mentioned methods in the classification of the six basic facial expressions, and indicate the way partial occlusion affects human observers when recognizing facial expressions. An attempt to specify which part of the face (left, right, lower or upper region) contains more discriminant information for each facial expression, is also made and conclusions regarding the pairs of facial expressions misclassifications that each type of occlusion introduces, are drawn. (c) 2008 Published by Elsevier B.V.
C1 [Kotsia, Irene; Buciu, Loan; Pitas, Loannis] Aristotle Univ Thessaloniki, Dept Informat, Thessaloniki 54124, Greece.
C3 Aristotle University of Thessaloniki
RP Kotsia, I (corresponding author), Aristotle Univ Thessaloniki, Dept Informat, Box 451, Thessaloniki 54124, Greece.
EM ekotsia@aiia.csd.auth.gr; pitas@aiia.csd.auth.gr
CR [Anonymous], 2005, ICME
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], P 12 BRIT MACH VIS C
   [Anonymous], 1999, INTEL CORPORATION MI
   ASTERIADIS S, 2006, P 2 IEEE EURASIP INT
   BARTLETT MS, 2003, WORKSH COMP VIS PATT, P1295
   Buciu I, 2006, J VIS COMMUN IMAGE R, V17, P958, DOI 10.1016/j.jvcir.2006.06.001
   BUCIU I, 2005, IEEE INT C AC SPEECH
   BUCIU I, 2004, MLSP SAO LUFS BRAZ
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   COLLINS M, 2000, COMPUTATIONAL LEARIN, P158
   Cover T. M, 1969, LEARNING PATTERN REC
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   DONOHO D, 2004, ADV NEURAL INFORM PR, V17
   Duc B, 1999, IEEE T IMAGE PROCESS, V8, P504, DOI 10.1109/83.753738
   Ekman P., 1975, EMOTION HUMAN FACE
   Ekman P., 1982, UNMASKING FACE
   Fellenz W., 1999, Computational Intelligence and Applications
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kotsia I, 2008, PATTERN RECOGN, V41, P833, DOI 10.1016/j.patcog.2007.06.026
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Kotsia I, 2007, IEEE T INF FOREN SEC, V2, P588, DOI 10.1109/TIFS.2007.902017
   KRINIDIS S, IEEE T MULTIME UNPUB
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li SZ, 2001, PROC CVPR IEEE, P207
   Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Michel P., 2003, Proceedings of the 5th international conference on Multimodal interfaces, P258, DOI DOI 10.1145/958432.958479
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Pentland A, 2000, COMPUTER, V33, P50, DOI 10.1109/2.820039
   Weston J., 1999, P ESANN99 BRUSS BELG
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zafeiriou S, 2006, IEEE T NEURAL NETWOR, V17, P683, DOI 10.1109/TNN.2006.873291
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
NR 40
TC 129
Z9 143
U1 2
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 1052
EP 1067
DI 10.1016/j.imavis.2007.11.004
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800017
DA 2024-07-18
ER

PT J
AU Wang, XY
   Hou, LM
   Wu, J
AF Wang, Xiang-yang
   Hou, Li-min
   Wu, Jun
TI A feature-based robust digital image watermarking against geometric
   attacks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image watermarking; geometric attack; image feature; normalization
ID SCALE
AB Based on scale space theory and an image normalization technique, a new feature-based image watermarking scheme robust to general geometric attacks is proposed in this paper. First, the Harris - Laplace detector is utilized to extract steady feature points from the host image; then, the local feature regions (LFR) are ascertained adaptively according to the characteristic scale theory, and they are normalized by an image normalization technique; finally, according to the predistortion compensation theory, several copies of the digital watermark are embedded into the nonoverlapped normalized LFR by comparing the DFT mid-frequency magnitudes. Experimental results show that the proposed scheme is not only invisible and robust against common signals processing methods such as median filtering, sharpening, noise adding, and JPEG compression etc., but also robust against the general geometric attacks such as rotation, translation, scaling, row or column removal, shearing, local geometric distortion and combination attacks etc. (c) 2008 Published by Elsevier B.V.
C1 [Wang, Xiang-yang; Hou, Li-min; Wu, Jun] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian 116029, Peoples R China.
C3 Liaoning Normal University
RP Wang, XY (corresponding author), Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210093, Peoples R China.
EM wxy37@126.com
CR Barni M., 2005, LECT NOTES COMPUTER, V3710
   Bas P, 2002, IEEE T IMAGE PROCESS, V11, P1014, DOI 10.1109/TIP.2002.801587
   Dong P, 2005, IEEE T IMAGE PROCESS, V14, P2140, DOI 10.1109/TIP.2005.857263
   Ji Z, 2002, 2002 IEEE REGION 10 CONFERENCE ON COMPUTERS, COMMUNICATIONS, CONTROL AND POWER ENGINEERING, VOLS I-III, PROCEEDINGS, P921, DOI 10.1109/TENCON.2002.1180271
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Kim HS, 2003, IEEE T CIRC SYST VID, V13, P766, DOI 10.1109/TCSVT.2003.815955
   Kutter M., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P320, DOI 10.1109/ICIP.1999.821622
   LEE HY, 2005, 4 INT WORKSH INT WOR, P418
   Licks V, 2005, IEEE MULTIMEDIA, V12, P68, DOI 10.1109/MMUL.2005.46
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   [刘九芬 Liu Jiufen], 2004, [电子与信息学报, Journal of electronics & information technology], V26, P1495
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Pereira S., 1999, IST SPIE EL IM 99 SE
   Ruanaidh JJKO, 1998, SIGNAL PROCESS, V66, P303, DOI 10.1016/S0165-1684(98)00012-7
   Simitopoulos D, 2003, IEEE T CIRC SYST VID, V13, P732, DOI 10.1109/TCSVT.2003.815947
   Son YH, 2003, P 2002 INT C CONTR A, P1140
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   WEINHEIMER J, 2004, ROBUST FEATURE BASED
NR 18
TC 31
Z9 42
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 980
EP 989
DI 10.1016/j.imavis.2007.10.014
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800011
DA 2024-07-18
ER

PT J
AU Li, Y
   Hung, YS
   Lee, S
AF Li, Y.
   Hung, Y. S.
   Lee, Sukhan
TI A stratified self-calibration method for circular motion in spite of
   varying intrinsic parameters
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE circular motion; self-calibration; affine reconstruction; metric
   reconstruction; plane at infinity; varying intrinsic parameters
ID RECONSTRUCTION; CAMERA
AB Self-calibration for imaging sensors is essential to many computer vision applications. In this paper, a new stratified self-calibration method is proposed for a camera undergoing circular motion with varying intrinsic parameters. It is shown that the plane at infinity in a projective frame can be identified by (i) known rotation angles between any two views and (ii) square pixel assumption of the camera. Once the plane at infinity is identified, the calibration matrices of the cameras and the upgrade to a metric reconstruction can be readily obtained. The proposed method is rather flexible in that it allows not only the focal length but also the principal point to vary from image to image. Experimental results for both synthetic data and real images are provided to show the performance of the proposed method. (c) 2008 Elsevier B.V. All rights reserved.
C1 [Li, Y.] S China Univ Technol, Sch Comp Sci Engn, Guangzhou, Guangdong, Peoples R China.
   [Hung, Y. S.; Lee, Sukhan] Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Hong Kong, Peoples R China.
   [Hung, Y. S.; Lee, Sukhan] Sungkyunkwan Univ, Intelligent Syst Res Ctr, Suwon, South Korea.
C3 South China University of Technology; University of Hong Kong;
   Sungkyunkwan University (SKKU)
RP Li, Y (corresponding author), S China Univ Technol, Sch Comp Sci Engn, Guangzhou, Guangdong, Peoples R China.
EM yanlieee@scut.edu.cn; yshung@eee.hku.hk; Lsh@ece.skku.ac.kr
RI Hung, Yeung Sam/C-1852-2009
CR Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694
   Colombo C, 2005, IEEE T PATTERN ANAL, V27, P99, DOI 10.1109/TPAMI.2005.14
   Dai ST, 2001, IEEE INT CONF ROBOT, P2165, DOI 10.1109/ROBOT.2001.932944
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   Fitzgibbon A., 1998, LECT NOTES COMPUTER, V1506, P155
   Frahm JM, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1418
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley R. I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P510, DOI 10.1109/ICCV.1999.791264
   Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362
   Heyden A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P339, DOI 10.1109/ICPR.1996.546045
   Kahl F, 2000, J MATH IMAGING VIS, V13, P131, DOI 10.1023/A:1026524030731
   Li Y, 2004, LECT NOTES COMPUT SC, V3175, P318
   Liu Y, 2000, INT C PATT RECOG, P865, DOI 10.1109/ICPR.2000.903680
   Mendonça PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461
   MENDONCA PRS, 1999, C COMP VIS PATT REC, V1, P500
   Pollefeys M, 1999, IEEE T PATTERN ANAL, V21, P707, DOI 10.1109/34.784285
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   POLLEFEYS M, 1997, P INT C COMP AN IM P, P175
   Seo Y, 2001, IEE P-VIS IMAGE SIGN, V148, P166, DOI 10.1049/ip-vis:20010078
   STEIN GP, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P230, DOI 10.1109/ICCV.1995.466781
   STURM P, 1997, P C COMP VIS PATT RE, P609
   TANG WK, 2002, LNCS, V2449, P387
   Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388
NR 24
TC 6
Z9 8
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 731
EP 739
DI 10.1016/j.imavis.2007.12.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900001
DA 2024-07-18
ER

PT J
AU Hong, SH
   Park, RH
   Yang, S
   Kim, JY
AF Hong, Sung-Ho
   Park, Rae-Hong
   Yang, Seungjoon
   Kim, Jun-Yong
TI Image interpolation using interpolative classified vector quantization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE interpolation; vector quantization; interpolative classified vector
   quantization
ID SUPERRESOLUTION; RECONSTRUCTION; ALGORITHM
AB According to advances in digital imaging technology, interest in high-resolution (HR) images has been increased. Various methods that convert low-resolution (LR) images to HR ones have been presented. In this paper, to reduce the computational load we propose a vector quantization (VQ) based algorithm that reconstructs an interpolation image by adding to an initially interpolated image high-frequency components predicted from training with a number of example image sets. The proposed interpolative classified VQ (ICVQ) algorithm combines interpolative VQ with classified VQ. With a number of (LR and HR) example image sets, we construct two types of (LR and HR) codebooks. Comparative experiments with three conventional image interpolation algorithms show that the proposed interpolation algorithms using ICVQ effectively preserve edges to which the human visual system is sensitive. The proposed algorithm can be applicable to various image- and video-based applications such as digital camera and digital television. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Hong, Sung-Ho; Park, Rae-Hong; Kim, Jun-Yong] Sogang Univ, Dept Elect Engn, Seoul 100611, South Korea.
   [Park, Rae-Hong] Sogang Univ, Interdisciplinary Program Integrated Biotechnol, Seoul 100611, South Korea.
   [Yang, Seungjoon] Samsung Elect Co Ltd, Digital Media R&D Ctr, Suwon 442742, Gyeonggi Do, South Korea.
C3 Sogang University; Sogang University; Samsung; Samsung Electronics
RP Park, RH (corresponding author), Sogang Univ, Dept Elect Engn, CPO Box 1142, Seoul 100611, South Korea.
EM shong@sogang.ac.kr; rhpark@sogang.ac.kr; syang@samsung.com;
   jykimfv@sogang.ac.kr
RI Yang, Seungjoon/G-1217-2010; Park, Rae-Hong/Q-7908-2019
OI Park, Rae-Hong/0000-0002-4792-2980
CR Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Carey WK, 1999, IEEE T IMAGE PROCESS, V8, P1293, DOI 10.1109/83.784441
   Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P376, DOI 10.1109/83.661188
   Dai DQ, 1998, SIGNAL PROCESS, V67, P109, DOI 10.1016/S0165-1684(98)00025-5
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   Gray RM, 1984, IEEE ASSP MAG, V4, P4, DOI DOI 10.1109/MASSP.1984.1162229
   HANG HM, 1987, IEEE T COMMUN, V33, P465
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Leung WYV, 2001, OPT ENG, V40, P547, DOI 10.1117/1.1353799
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Meijering E, 2002, P IEEE, V90, P319, DOI 10.1109/5.993400
   Meijering EHW, 1999, IEEE T IMAGE PROCESS, V8, P192, DOI 10.1109/83.743854
   Ngan KN, 1992, IEEE T IMAGE PROCESS, V1, P269, DOI 10.1109/83.148602
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   RAMAMURTHI B, 1986, IEEE T COMMUN, V34, P1105, DOI 10.1109/TCOM.1986.1096468
   RAMAMURTHI B, 1986, IEEE T ACOUST SPEECH, V34, P1258, DOI 10.1109/TASSP.1986.1164961
   Sheppard DG, 2000, IEEE T IMAGE PROCESS, V9, P295, DOI 10.1109/83.821746
   Sheppard DG, 1998, IEEE T IMAGE PROCESS, V7, P119, DOI 10.1109/83.650857
   Thurnhofer S, 1996, OPT ENG, V35, P1862, DOI 10.1117/1.600619
NR 21
TC 15
Z9 20
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 228
EP 239
DI 10.1016/j.imavis.2007.05.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500007
DA 2024-07-18
ER

PT J
AU Maillot, NE
   Thonnat, M
AF Maillot, Nicolas Eric
   Thonnat, Monique
TI Ontology based complex object recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE ontology; machine learning; categorization; cognitive vision
AB This paper presents a new approach for object categorization involving the following aspects of cognitive vision: learning, recognition and knowledge representation. A major element of our approach is a visual concept ontology composed of several types of concepts (spatial concepts and relations, color concepts and texture concepts). Visual concepts contained in this ontology can be seen as an intermediate layer between domain knowledge and image processing procedures. Machine learning techniques are used to solve the symbol grounding problem (i.e. linking meaningfully symbols to sensory information). This paper shows, how a new object categorization system is set up by a knowledge acquisition and learning phase and then used by an object categorization phase. (c) 2006 Elsevier B.V. All rights reserved.
C1 INRIA Sophia Antipolis Orion Team 2004, F-06902 Sophia Antipolis, France.
RP Maillot, NE (corresponding author), INRIA Sophia Antipolis Orion Team 2004, Route Lucioles BP 93, F-06902 Sophia Antipolis, France.
EM maillot@sophia.inria.fr; monique.thonnat@sophia.inria.fr
CR Choi E, 2003, PATTERN RECOGN, V36, P1703, DOI 10.1016/S0031-3203(03)00035-9
   Cohn AG, 2001, FUND INFORM, V46, P1
   CSURKA G, 2004, PATT REC MACH LEARN
   Di Sciascio E, 2002, J ARTIF INTELL RES, V16, P209, DOI 10.1613/jair.902
   DUBUISSON B, 1993, PATTERN RECOGN, V26, P155, DOI 10.1016/0031-3203(93)90097-G
   Gruber T.R., 1993, Formal Ontology in Conceptual Analysis and Knowledge Representation
   HUDELOT C, 2003, INT C TOOLS ART INT
   LIU S, 1994, TENTH CONFERENCE ON ARTIFICIAL INTELLIGENCE FOR APPLICATIONS, PROCEEDINGS, P358, DOI 10.1109/CAIA.1994.323653
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Maillot N, 2005, LECT NOTES COMPUT SC, V3568, P629
   MAILLOT N, 2003, LECT NOTES COMPUTER, V2626
   MARDIA K, 2002, PATTERN RECOGN, P147
   Matsuyama Takashi., 1990, SIGMA KNOWLEDGE BASE
   Miller G., 1976, Language and perception
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   PUDIL P, 1994, PATTERN RECOGN LETT, V15, P1119, DOI 10.1016/0167-8655(94)90127-9
   Rao AR, 1996, VISION RES, V36, P1649, DOI 10.1016/0042-6989(95)00202-2
   Shekhar C, 1999, IMAGE VISION COMPUT, V17, P667, DOI 10.1016/S0262-8856(98)00137-1
   THONNAT M, 1989, LECT NOTE PHYS, P329
NR 19
TC 68
Z9 71
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 102
EP 113
DI 10.1016/j.imavis.2005.07.027
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ciria, JC
   De Miguel, A
   Domínguez, E
   Francés, AR
   Quintero, A
AF Ciria, J. C.
   De Miguel, A.
   Dominguez, E.
   Frances, A. R.
   Quintero, A.
TI Local characterization of a maximum set of digital (26,6)-surfaces
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE discrete surface; (26,6)-adjacency; strongly separating; continuous
   analogue
ID SURFACES; Z(3)
AB We introduce a new family Y of surfaces in the discrete space Z(3) for the usual (26,6)-adjacency that strictly contains the family of simplicity 26-surfaces and other objects considered as surfaces in the literature. Actually, Y characterizes the strongly 6-separating objects of a family S-u of digital surfaces defined by means of continuous analogues. The family Su consists of all objects whose continuous analogue is a surface in some homogeneous (26,6)-connected digital space as defined in the approach to Digital Topology introduced in [R. Ayala, E. Dominguez, A.R. Frances, A. Quintero, Weak Lighting Functions and Strong 26-surfaces. Theoretical Computer Science 283 (2002) 29-66.]. Therefore, Y is the largest possible set of surfaces in Z3 in that setting. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Zaragoza, Fac Ciencias, Dept Informat & Ingn Sistemas, E-50009 Zaragoza, Spain.
   Univ Seville, Fac Matemat, Dept Geometria & Topol, E-41080 Seville, Spain.
C3 University of Zaragoza; University of Sevilla
RP Francés, AR (corresponding author), Univ Zaragoza, Fac Ciencias, Dept Informat & Ingn Sistemas, E-50009 Zaragoza, Spain.
EM jcciria@unizar.es; admiguel@unizar.es; noesis@unizar.es;
   afrances@unizar.es; quintero@us.es
RI Cosculluela, José Carlos Ciria/K-5296-2014
OI Quintero Toscano, Antonio Rafael/0000-0003-2240-2951; Dominguez Murillo,
   Eladio/0000-0002-3270-899X
CR Ayala R, 2002, THEOR COMPUT SCI, V283, P29, DOI 10.1016/S0304-3975(01)00051-2
   Ayala R., 1997, LECT NOTES COMPUTER, V1347, P139
   AYALA R, 2001, INT J PATTER RECOG A, V15, P1
   Bertrand G, 1999, J MATH IMAGING VIS, V11, P207, DOI 10.1023/A:1008348318797
   Brimkov VE, 2004, LECT NOTES COMPUT SC, V3322, P276
   Ciria JC, 2004, LECT NOTES COMPUT SC, V3322, P291
   CIRIA JC, UNIVERSAL DIGITAL SP
   CIRIA JC, 2002, LECT NOTES COMPUTER, V2301, P45
   Couprie M, 1998, P SOC PHOTO-OPT INS, V3454, P40, DOI 10.1117/12.323265
   DOMINGUEZ E, 2001, LECT NOTES COMPUTER, V2243, P3
   Frank E, 1995, J PRACTICAL PSYCHIAT, V1, P20
   Kenmochi Y, 2005, LECT NOTES COMPUT SC, V3429, P335
   KONG TY, 1985, COMPUT VISION GRAPH, V29, P60, DOI 10.1016/S0734-189X(85)90151-3
   MALANDAIN G, 1993, INT J COMPUT VISION, V10, P183, DOI 10.1007/BF01420736
   Malgouyres R, 1996, THEOR COMPUT SCI, V163, P303, DOI 10.1016/0304-3975(96)00021-7
   MORGENTHALER DG, 1981, INFORM CONTROL, V51, P227, DOI 10.1016/S0019-9958(81)90290-4
   Rourke C.P., 1972, INTRO PIECEWISE LINE, V69
NR 17
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1685
EP 1697
DI 10.1016/j.imavis.2006.06.024
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200015
DA 2024-07-18
ER

PT J
AU Brasnett, P
   Mihaylova, L
   Bull, D
   Canagarajah, N
AF Brasnett, Paul
   Mihaylova, Lyudmila
   Bull, David
   Canagarajah, Nishan
TI Sequential Monte Carlo tracking by fusing multiple cues in video
   sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE particle filtering; tracking in video sequences; colour; texture; edges;
   multiple cues; Bhattacharyya distance
ID VISUAL TRACKING; OBJECT TRACKING; MEAN SHIFT; COLOR; INTEGRATION;
   TEXTURE
AB This paper presents visual cues for object tracking in video sequences using particle filtering. A consistent histogram-based framework is developed for the analysis of colour, edge and texture cues. The visual models for the cues are learnt from the first frame and the tracking can be carried out using one or more of the cues. A method for online estimation of the noise parameters of the visual models is presented along with a method for adaptively weighting the cues when multiple models are used. A particle filter (PF) is designed for object tracking based on multiple cues with adaptive parameters. Its performance is investigated and evaluated with synthetic and natural sequences and compared with the mean-shift tracker. We show that tracking with multiple weighted cues provides more reliable performance than single cue tracking. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Lancaster, Dept Commun Syst, Lancaster LA1 4WA, England.
   Univ Bristol, Dept Elect & Elect Engn, Bristol BS8 1UB, Avon, England.
C3 Lancaster University; University of Bristol
RP Brasnett, P (corresponding author), Univ Lancaster, Dept Commun Syst, Lancaster LA1 4WA, England.
EM paul.brasnett@vil.ite.mee.com; mila.mihaylova@lancaster.ac.uk
RI Mihaylova, Lyudmila/A-3512-2008
OI Mihaylova, Lyudmila/0000-0001-5856-2223
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bar-Shalom Y, 2001, ESTIMATION APPL TRAC
   Bar-Shalom Yaakov., 1993, ESTIMATION TRACKING
   Bergman N., 1999, THESIS LINKOPING U L
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Brasnett P, 2005, PROC SPIE, V5685, P430, DOI 10.1117/12.585882
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1998, PROC 5 EUROPEAN C CO, V1, P893
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   KARASARIDIS A, 1996, P ICASSP ATL GA MAY
   Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847
   MANDUCHI R, 1999, P IEEE INT C COMP VI
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Ozyildiz E, 2002, PATTERN RECOGN, V35, P2013, DOI 10.1016/S0031-3203(01)00181-9
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Poon E, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P151, DOI 10.1109/MOTION.2002.1182228
   Porter R., 1997, THESIS U BRISTOL
   Saber E, 1998, J ELECTRON IMAGING, V7, P684, DOI 10.1117/1.482605
   SCOTT DW, 1992, SER PROBABILITY MATH
   Shen C, 2003, P 7 DIG IM COMP TECH
   SHI X, 2003, P IEEE WORKSH STAT A, V8
   Spengler M, 2003, MACH VISION APPL, V14, P50, DOI 10.1007/s00138-002-0095-9
   Toyama K, 1999, INT J COMPUT VISION, V35, P45, DOI 10.1023/A:1008159011682
   Triesch J, 2001, NEURAL COMPUT, V13, P2049, DOI 10.1162/089976601750399308
   WAN E, 2001, UNSCENTED KALMAN FIL, V7, P221
NR 32
TC 115
Z9 141
U1 1
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1217
EP 1227
DI 10.1016/j.imavis.2006.07.017
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Angulo, J
   Serra, J
AF Angulo, Jesus
   Serra, Jean
TI Modelling and segmentation of colour images in polar representations
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE colour mathematical morphology; colour segmentation; saturation; norms;
   bi-variate histograms; jump connection
ID MORPHOLOGICAL OPERATORS; REFLECTION; GEOMETRY; HUE
AB The suitability of polar representation for quantitative image processing tasks is investigated. The classical colour polar-based representations (HLS, HSV, etc.) lead to brightness and saturation with nonconsistent properties. After a short critical analysis of the gamma correction, a new polar representation using the L-1 norm is proposed. It satisfies several quantitative requirements.
   The relevance of this representation is demonstrated by means of luminance/saturation histograms, which exhibit typical alignments. Their physical interpretation leads to a model for light reception in terms of linearly regionalized spectra. A full example illustrates the application of the histogram approach.
   Colour images are multivariable functions, and for segmenting them one must go through a reducing step. It is classically obtained by calculating a gradient module, which is then segmented as a grey tone image. An alternative solution is proposed. It is based on separated segmentations, followed by a final merging into a unique partition. The generalisation of the top-hat transformation for extracting colour details is also considered. These new marginal colour operators take advantage of an adaptive combination of the chromatic and the achromatic (or the spectral and the spatio-geometric) colour components. (c) 2006 Elsevier B.V. All rights reserved.
C1 Ecole Mines Paris, Ctr Morphol Math, F-77300 Fontainebleau, France.
   ESIEE, Lab A2SI, F-93162 Noisy Le Grand, France.
C3 Universite PSL; MINES ParisTech; Universite Gustave-Eiffel; ESIEE Paris
RP Angulo, J (corresponding author), Ecole Mines Paris, Ctr Morphol Math, 35 Rue St Honore, F-77300 Fontainebleau, France.
EM jesus.angulo@ensmp.fr; jean.serra@ensmp.fr
CR Angulo J., 2004, Traitement du Signal, V21, P583
   Angulo J, 2005, COMPUT IMAGING VIS, V30, P387
   Angulo J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P125
   ANGULO J, 2003, THESIS ECOLE MINES P
   ANGULO J, 2003, O INT WORKSH SEM PRO, P59
   [Anonymous], 2003, Digital Video and HDTV Algorithms and Interfaces
   Berwick D, 2004, COMPUT VIS IMAGE UND, V94, P28, DOI 10.1016/j.cviu.2003.10.008
   BEUCHER S, 1992, P ISMM 94 KLUW 1994, P433
   CARRON T, 1994, IEEE IMAGE PROC, P977, DOI 10.1109/ICIP.1994.413699
   CARRON T, 1995, THESIS U SAVOIE
   CELNEK M, 1990, GRAPHICS IMAGE PROCE, V52, P145
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   CHOQUET G, 1966, TOPOLOGY
   CIE (Commission Internationale de l'Eclairage), 1986, COLORIMETRY
   DEMARTY CH, 1998, P INT S MATH MORPH I, P231
   Finlayson G, 2003, PATTERN RECOGN LETT, V24, P1679, DOI 10.1016/S0167-8655(02)00324-0
   Finlayson GD, 2001, INT J COMPUT VISION, V42, P127, DOI 10.1023/A:1011120214885
   Garrido L, 1998, SIGNAL PROCESS, V66, P157, DOI 10.1016/S0165-1684(98)00004-8
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   Gevers T, 2003, IEEE T MULTIMEDIA, V5, P237, DOI 10.1109/TMM.2003.811620
   GOUTSIAS J, 1995, COMPUT VIS IMAGE UND, V62, P326, DOI 10.1006/cviu.1995.1058
   HANBURY A, 2003, P DAGM S VIENN APR 2
   Hanbury AG, 2001, IEEE T IMAGE PROCESS, V10, P1842, DOI 10.1109/83.974569
   HEALEY G, 1989, J OPT SOC AM A, V6, P920, DOI 10.1364/JOSAA.6.000920
   Heijmans HJAM, 2002, J MATH IMAGING VIS, V17, P55, DOI 10.1023/A:1020726725590
   HENDER J, 1976, THESIS CANEGIE MELLO
   KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279
   Lambert P, 1999, PATTERN RECOGN, V32, P1857, DOI 10.1016/S0031-3203(99)00010-2
   LEVKOWITZ H, 1993, CVGIP-GRAPH MODEL IM, V55, P271, DOI 10.1006/cgip.1993.1019
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Maxwell BA, 1997, COMPUT VIS IMAGE UND, V65, P269, DOI 10.1006/cviu.1997.0573
   Meyer F, 2004, J MATH IMAGING VIS, V20, P59, DOI 10.1023/B:JMIV.0000011319.21884.39
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   MEYER F, 1977, QUANTITATIVE ANAL MI, P374
   Newton I., 1671, Philosophical transactions of the Royal Society of London, V80, P3075, DOI DOI 10.1098/RSTL.1671.0072
   Obein G, 2002, PERCEPTION, V31, P65
   Peters RA, 1997, P SOC PHOTO-OPT INS, V3026, P84, DOI 10.1117/12.271144
   RISSON V, 2001, THESIS ECOLE MINES P
   Ronse C, 2005, J MATH IMAGING VIS, V22, P283, DOI 10.1007/s10851-005-4895-1
   Serra J, 2006, J MATH IMAGING VIS, V24, P83, DOI 10.1007/s10851-005-3616-0
   Serra J., 2000, Fundamenta Informaticae, V41, P147
   SERRA J, 2002, N3402MM CMM
   SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409
   SHIH TY, 1995, PHOTOGRAMM ENG REM S, V61, P1223
   Smith A.R., 1978, P 5 ANN C COMP GRAPH, V12, P12, DOI [10.1145/965139.807361, DOI 10.1145/965139.807361]
   Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172
   Talbot H., 1998, MATH M ORPHOLOGY ITS, P27
   TOMINAGA S, 1991, IEEE T PATTERN ANAL, V13, P658, DOI 10.1109/34.85656
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   TREMEAU A, 2004, IMAGE NUMERIQUE COUL
   Tsang WH, 1997, PATTERN RECOGN LETT, V18, P165, DOI 10.1016/S0167-8655(96)00125-0
   WILSON SS, 1992, IEEE T PATTERN ANAL, V14, P636, DOI 10.1109/34.141554
   WYSECKI G, 1982, COLOR SCI CONCEPTS M
NR 53
TC 50
Z9 54
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 475
EP 495
DI 10.1016/j.imavis.2006.07.018
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600010
DA 2024-07-18
ER

PT J
AU Souvenir, R
   Pless, R
AF Souvenir, Richard
   Pless, Robert
TI Image distance functions for manifold learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE isomap; manifolds; non-parametric registration
AB Many natural image sets are samples of a low-dimensional manifold in the space of all possible images. When the image data set is not a linear combination of a small number of basis images, linear dimensionality reduction techniques such as PCA and ICA fail and non-linear dimensionality reduction techniques are required to automatically determine the intrinsic structure of the image set. Recent techniques such as ISOMAP and LLE provide a mapping between the images and a low-dimensional parameterization of the images. This paper specializes general manifold learning by considering a small set of image distance measures that correspond to key transformation groups observed in natural images. This results in more meaningful embeddings for a variety of applications. (c) 2006 Elsevier B.V.. All rights reserved.
C1 Washington Univ, Dept Comp Sci & Engn, St Louis, MO 63130 USA.
C3 Washington University (WUSTL)
RP Pless, R (corresponding author), Washington Univ, Dept Comp Sci & Engn, 1 Brookings Dr,Campus Box 1045, St Louis, MO 63130 USA.
EM pless@cse.wustl.edu
RI Pless, Robert B/I-4698-2013
CR [Anonymous], 1996, Elements of pattern theory
   [Anonymous], 1997, Modern multidimensional scaling: Theory and applications
   [Anonymous], CVPRIP
   BELKIN M, 2002, ADV NEURAL INFORMATI
   BENGIO Y, 2004, ADV NEURAL INFORMATI, V16
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   LIM IS, 2003, P 16 IEEE S COMP BAS
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   TEH YW, 2003, ADV NEURAL INFORMATI, V15
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Thompson DW, 1917, on Growth and Form
   Trouve A, 1998, INT J COMPUT VISION, V28, P213, DOI 10.1023/A:1008001603737
   TROUVE A, 2002, 20022003 U PR LAB AN
   Weinberger K.Q., 2004, Computer Vision and Pattern Recognition
NR 14
TC 32
Z9 36
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 365
EP 373
DI 10.1016/j.imavis.2006.01.016
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100012
DA 2024-07-18
ER

PT J
AU Liu, YH
AF Liu, Yonghuai
TI Automatic registration of overlapping 3D point clouds using closest
   points
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D point clouds; automatic registration; SoftAssign; EMICP;
   combinatorial optimization; entropy maximization; deterministic
   annealing; optimised k-D tree
ID FREE-FORM CURVES; ACCURATE REGISTRATION; RANGE; REPRESENTATION;
   ALGORITHM; OBJECTS; ICP
AB While the SoftAssign algorithm imposes a two-way constraint embedded into the deterministic annealing scheme and the EMICP algorithm imposes a one-way constraint, they represent the state of the art technique for the automatic registration of overlapping free form shapes. They both have a time complexity of O(n(2)). While the former has a space complexity also of O(n(2)), the latter has a space complexity of O(n). The heavy demand for computation and storage memory renders either the SoftAssign or EMICP algorithm to hardly operate on whole shapes with thousands of points. In this case, they often have to reduce the number of points to an order of 100s on the free form shapes to be registered. This paper proposes using closest points in conjunction with either the one-way or two-way constraint for the automatic registration of overlapping 3D point clouds and thus, combining the accuracy of both the SoftAssign and EMICP algorithms with the efficiency of the traditional ICP algorithm. A comparative study based on both synthetic data and real images has shown that the proposed algorithm does not significantly sacrifice accuracy and stability of either the SoftAssign or EMICP algorithm, but gains remarkable efficiency of the traditional ICP algorithm for the automatic registration of overlapping 3D point clouds. Since, the proposed algorithm is of general use and has an advantage of easy implementation, it is likely to become in the future a benchmark for the automatic registration of overlapping 3D point clouds. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Coll Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
C3 Aberystwyth University
RP Liu, YH (corresponding author), Univ Coll Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
EM yyl@aber.ac.uk
RI Liu, Yonghuai/ABF-3794-2020
CR [Anonymous], P 18 INT JOINT C ART
   ASHBROOK AP, 1998, P 5 ECCV, V2, P185
   Bengtsson M., 2001, Soft Computing, V5, P215, DOI 10.1007/s005000100084
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Chui H, 2003, MED IMAGE ANAL, V7, P113, DOI 10.1016/S1361-8415(02)00102-0
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Chvatal V., 1983, Linear programming
   DAVID P, 2003, P CVPR, V2, P422
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DEWAELE G, 2004, ECCV, V1, P495
   Dorai C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P770, DOI 10.1109/ICPR.1996.546128
   Feldmar J, 1997, COMPUT VIS IMAGE UND, V65, P403, DOI 10.1006/cviu.1996.0499
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Gelfand N, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P260, DOI 10.1109/IM.2003.1240258
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806
   Huber DF, 2003, IMAGE VISION COMPUT, V21, P637, DOI 10.1016/S0262-8856(03)00060-X
   JAYNES ET, 1957, PHYS REV, V106, P620, DOI 10.1103/PhysRev.106.620
   Johna S, 1999, CRIT CARE, V3, P135, DOI 10.1186/cc366
   JONSSON A, 1999, IEEE T PAMI, V21, P433
   JONSSON H, 2001, 0116 LUND U DEP THEO
   LIN Z, 1986, P 8 ICPR, P303
   Liu LH, 2000, 2000 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2000), VOLS 1-3, PROCEEDINGS, P2280, DOI 10.1109/IROS.2000.895308
   LIU Y, 2004, P ICRA, P2285
   Liu YH, 2004, INT C PATT RECOG, P128
   Liu YH, 2004, ROBOT AUTON SYST, V47, P11, DOI 10.1016/j.robot.2004.02.002
   Liu YH, 2004, PATTERN RECOGN, V37, P211, DOI 10.1016/S0031-3203(03)00239-5
   Liu YH, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P187
   Lucchese L, 2002, IEEE T PATTERN ANAL, V24, P1468, DOI 10.1109/TPAMI.2002.1046160
   Luck J., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3739, DOI 10.1109/ROBOT.2000.845314
   MITCHELL TM, 1997, DECISION TREE LEARNI, pCH3
   Nishino K., 2002, Proceedings of the Fifth Asian Conference on Computer Vision, P454
   Page D., 2003, Sensor Review, V23, P223, DOI 10.1108/02602280310481841
   PAJDLA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P390, DOI 10.1109/ICCV.1995.466913
   Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346
   Puzicha J, 1999, COMPUT VIS IMAGE UND, V76, P213, DOI 10.1006/cviu.1999.0805
   PUZICHA J, 1997, P 15 IMACS WORLD C S, V6, P445
   Rodrigues MA, 2002, ROBOT AUTON SYST, V39, P37, DOI 10.1016/S0921-8890(02)00173-2
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sallans B, 2004, J MACH LEARN RES, V5, P1063
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243
   Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108
   SINKHORN R, 1964, ANN MATH STAT, V35, P876, DOI 10.1214/aoms/1177703591
   Sun Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P263, DOI 10.1109/ICCV.2001.937634
   Surmann H, 2003, ROBOT AUTON SYST, V45, P181, DOI 10.1016/j.robot.2003.09.004
   TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   WHITAKER RT, 1999, P 3DIM, P348
   Wyngaerd J. V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P301, DOI 10.1109/ICCV.1999.791234
   Yamany SM, 2002, IEEE T PATTERN ANAL, V24, P1105, DOI 10.1109/TPAMI.2002.1023806
   Yang R, 1998, IEEE INT CONF ROBOT, P3115, DOI 10.1109/ROBOT.1998.680904
   Yeomans JM, 1992, Statistical mechanics of phase transitions
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 57
TC 63
Z9 71
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 762
EP 781
DI 10.1016/j.imavis.2006.01.009
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400010
DA 2024-07-18
ER

PT J
AU Pieczynski, W
   Benboudjema, D
AF Pieczynski, W
   Benboudjema, D
TI Multisensor triplet Markov fields and theory of evidence
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multisensor hidden Markov fields; pairwise Markov fields; triplet Markov
   fields; Bayesian classification; Dempster-Shafer fusion; theory of
   evidence; statistical unsupervised non-stationary image segmentation
ID DEMPSTER-SHAFER FUSION; IMAGE SEGMENTATION; CLASSIFICATION; CHAINS;
   RESTORATION
AB Hidden Markov Fields (HMF) are widely applicable to various problems of image processing. In such models, the hidden process of interest X is a Markov field, which must be estimated from its observable noisy version Y. The success of HMF is due mainly to the fact that X remains Markov conditionally on the observed process, which facilitates different processing strategies such as Bayesian segmentation. Such models have been recently generalized to 'Pairwise' Markov fields (PMF), which offer similar processing advantages and superior modeling capabilities. In this generalization. one directly assumes the Markovianity of the pair (X, Y). Afterwards, 'Triplet' Markov fields (TMF) have been proposed, in which the distribution of (X,Y) is the marginal distribution of a Markov field (X,U,Y), where U is an auxiliary random field. So U can have different interpretations and, when the set of its values is not too complex, X can still be estimated from Y. The aim of this paper is to show some connections between TMF and the Dempster-Shafer theory of evidence. It is shown that TMF allow one to perform the Dempster-Shafer fusion in different general situations, possibly involving several sensors. As a consequence, Bayesian segmentation strategies remain applicable. (C) 2005 Elsevier B.V. All rights reserved.
C1 Inst Natl Telecommun, Dept CITI, GET, F-91000 Evry, France.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   SudParis
RP Pieczynski, W (corresponding author), Inst Natl Telecommun, Dept CITI, GET, 9 Rue Charles Fourier, F-91000 Evry, France.
EM wojciech.pieczynski@int-evry.fr
RI Pieczynski, Wojciech/AAW-4428-2020
CR [Anonymous], 2003, Image analysis, random fields and Markov chain Monte Carlo methods: a mathematical introduction
   [Anonymous], 1998, CWI Quaterly
   [Anonymous], 2002, SPIES INT S REM SENS
   Benboudjema D, 2005, COMPUT VIS IMAGE UND, V99, P476, DOI 10.1016/j.cviu.2005.04.003
   BENBOUDJEMA D, 2005, INT C IM PROC ICIP 2
   Bendjebbour A, 2001, IEEE T GEOSCI REMOTE, V39, P1789, DOI 10.1109/36.942557
   Delmas JP, 1997, IEEE T SIGNAL PROCES, V45, P2613, DOI 10.1109/78.640732
   Denoeux T, 1999, INT J APPROX REASON, V20, P79, DOI 10.1016/S0888-613X(98)10023-3
   Foucher S, 2002, IEEE T INSTRUM MEAS, V51, P277, DOI 10.1109/19.997824
   FOUQUE L, 2000, P 3 INT C INF FUS FU, V1
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Guan J.W., 1991, EVIDENCE THEORY ITS
   Janez F, 1998, INT J APPROX REASON, V18, P1, DOI 10.1016/S0888-613X(97)10001-9
   Lanchantin P., 2005, Traitement du Signal, V22, P15
   Lanchantin P, 2005, IEEE T SIGNAL PROCES, V53, P3091, DOI 10.1109/TSP.2005.851131
   Landgrebe D, 2002, IEEE SIGNAL PROC MAG, V19, P17, DOI 10.1109/79.974718
   LE S, 1998, PATTERN RECOGN, V31, P1811
   McLachlan G., 1997, SERIES PROBABILITY S
   Melas DE, 2002, IEEE T SIGNAL PROCES, V50, P357, DOI 10.1109/78.978390
   Perrin S, 2004, IEEE T SYST MAN CY C, V34, P485, DOI 10.1109/TSMCC.2004.829266
   Pieczynski W, 2004, CR MATH, V339, P797, DOI 10.1016/j.crma.2004.10.013
   Pieczynski W, 2003, IEEE T PATTERN ANAL, V25, P634, DOI 10.1109/TPAMI.2003.1195998
   Pieczynski W, 2000, IEEE T IMAGE PROCESS, V9, P308, DOI 10.1109/83.821750
   Pieczynski W., 2000, Machine Graphics & Vision, V9, P705
   PIECZYNSKI W, UNPUB INT J APPROXIM
   PIECZYNSKI W, 2000, P IEEE SW S IM AN IN, P247
   PIECZYNSKI W, 2005, MODELING NON STATION
   Richards JA, 2005, IEEE T GEOSCI REMOTE, V43, P422, DOI 10.1109/TGRS.2004.837326
   Ruan S, 2000, IEEE T MED IMAGING, V19, P1179, DOI 10.1109/42.897810
   Sarkar A, 2005, IEEE T IMAGE PROCESS, V14, P634, DOI 10.1109/TIP.2005.846032
   Schweizer SM, 2001, IEEE T IMAGE PROCESS, V10, P584, DOI 10.1109/83.913593
   Shafer G, 1976, MATH THEORY EVIDENCE, DOI DOI 10.1080/00401706.1978.10489628
   SMETS P, 1993, INT J APPROX REASON, V9, P1, DOI 10.1016/0888-613X(93)90005-X
   SMETS P, 1994, ARTIF INTELL, V66, P191, DOI 10.1016/0004-3702(94)90026-4
   Tupin F, 1999, IEEE T GEOSCI REMOTE, V37, P1327, DOI 10.1109/36.763297
   Yager R., 1994, ADV DEMPSTER SHAFER
   Zhu HW, 2005, IEEE T GEOSCI REMOTE, V43, P1874, DOI 10.1109/TGRS.2005.848706
NR 37
TC 23
Z9 24
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 61
EP 69
DI 10.1016/j.imavis.2005.09.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200006
DA 2024-07-18
ER

PT J
AU Goshtasby, AA
AF Goshtasby, AA
TI Fusion of multi-exposure images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image fusion; image entropy; image information; image blending;
   multi-exposure
AB A method for fusing multi-exposure images of a static scene taken by a stationary camera into an image with maximum information content is introduced. The method partitions the image domain into uniform blocks and for each block selects the image that contains the most information within that block. The selected images are then blended together using monotonically decreasing blending functions that are centered at the blocks and have a sum of 1 everywhere in the image domain. The optimal block size and width of the blending functions are determined using a gradient-ascent algorithm to maximize information content in the fused image. (c) 2005 Elsevier B.V. All rights reserved.
C1 Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.
C3 University System of Ohio; Wright State University Dayton
RP Wright State Univ, Dept Comp Sci & Engn, 303 Russ Engn Ctr, Dayton, OH 45435 USA.
EM ardeshir@cs.wright.edu
CR [Anonymous], EUR 2002 SEP
   [Anonymous], 1949, MATH MODEL COMMUNICA
   CASTLEMAN KR, 1996, DIGITAL IMAGE PROCES, P569
   Connolly C, 1997, IEEE T IMAGE PROCESS, V6, P1046, DOI 10.1109/83.597279
   DICARLO JM, 2002, P SPIE IMAGE SENSORS, V3965, P392
   FRIEDEN BR, 1972, J OPT SOC AM, V62, P511, DOI 10.1364/JOSA.62.000511
   GORDON WJ, 1974, COMPUT AIDED GEOM D, P95, DOI DOI 10.1016/B978-0-12-079050-0.50011-4
   GOSHTASBY A, 1988, IEEE T GEOSCI REMOTE, V26, P60, DOI 10.1109/36.3000
   GOSHTASBY A, 1993, INT J COMPUT VISION, V10, P233, DOI 10.1007/BF01539537
   HALL EL, 1974, IEEE T COMPUT, VC 23, P207, DOI 10.1109/T-C.1974.223892
   HALL EL, 1979, COMPUTER IMAGE PROCE, P29
   Harder R., 1797, J AIRCRAFT, V9, P189, DOI [10.2514/3.44330, DOI 10.2514/3.44330, 10.2514/3.44330.]
   Hill B, 1992, ACM T GRAPHIC, V11, P373
   KASSON JM, 1992, ACM T GRAPHIC, V11, P373, DOI 10.1145/146443.146479
   Mann S, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P193, DOI 10.1109/ICIP.1996.560417
   MANN S, 1993, P 46 ANN IS T C CAMB
   Robertson M.A., 1999, PROCEEDING ICIP, P159
   Szeliski R, 2004, Patent, Patent No. [US6687400B1, 6687400]
   Xiang ZG, 1997, ACM T GRAPHIC, V16, P260, DOI 10.1145/256157.256159
NR 19
TC 228
Z9 272
U1 2
U2 42
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2005
VL 23
IS 6
BP 611
EP 618
DI 10.1016/j.imavis.2005.02.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 924CA
UT WOS:000228955100006
DA 2024-07-18
ER

PT J
AU Li, BH
   Meng, QG
   Holstein, H
AF Li, BH
   Meng, QG
   Holstein, H
TI Reconstruction of segmentally articulated structure in freeform movement
   with low density feature points
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE articulated point matching; non-rigid pose estimation; affine
   transformation; motion tracking and object recognition; motion capture
ID HUMAN MOTION; REGISTRATION
AB Though a large body of research has focused on tracking and identifying objects from the domain of colour or grey-scale images, there is a relative dearth in the literature on complex articulated/non-rigid motion reconstruction from a collection of low density feature points. In this paper, we propose a segment-based articulated matching algorithm to establish a crucial self-initialising identification in model-based point-feature tracking of articulated motion with near-rigid segments. We avoid common assumptions such as pose similarity or small motion with respect to the model, and assume no prior knowledge of a specific movement from which to restrict pose identification. Experimental results based on synthetic pose and real-world human motion capture data demonstrate the ability of the algorithm to perform the identification task. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
C3 Aberystwyth University
RP Univ Wales, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
EM bal@aber.ac.uk; qqm@aber.ac.uk; hoh@aber.ac.uk
CR Aggarwal J. K., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P2, DOI 10.1109/MNRAO.1994.346261
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BOXER L, 1999, P SPIE VIS GEOM, P168
   Campbell RJ, 2001, COMPUT VIS IMAGE UND, V81, P166, DOI 10.1006/cviu.2000.0889
   CEDRAS C, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P214, DOI 10.1109/CVPR.1994.323832
   Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Grimson W., 1990, OBJECT RECOGNITION C
   HERDA L, 2000, P COMP AN PHIL US
   LI B, 2003, THESIS U WALES ABERY
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Mount DM, 1999, PATTERN RECOGN, V32, P17, DOI 10.1016/S0031-3203(98)00086-7
   PITIOT A, 2003, 2 INT WORKSH BIOM IM
   RAMANAN D, 2003, P IEEE INT C COMP VI
   Rangarajan A, 1997, Med Image Anal, V1, P379
   Richards JG, 1999, HUM MOVEMENT SCI, V18, P589, DOI 10.1016/S0167-9457(99)00023-8
   Ringer M., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P172
   Rodrigues M, 2002, COMPUT VIS IMAGE UND, V87, P1, DOI 10.1006/cviu.2002.0978
   SEETHARAMAN G, 2000, P INT C IM PROC, P1233
   Zhang LJ, 2003, IEEE SYS MAN CYBERN, P4057
NR 23
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 749
EP 759
DI 10.1016/j.imavis.2004.02.013
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300002
DA 2024-07-18
ER

PT J
AU Davies, RH
   Twining, CJ
   Allen, PD
   Cootes, TF
   Taylor, CJ
AF Davies, RH
   Twining, CJ
   Allen, PD
   Cootes, TF
   Taylor, CJ
TI Building optimal 2D statistical shape models
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE statistical shape models; active shape models; point distribution models
AB Statistical shape models are used widely as a basis for segmenting and interpreting images. A major drawback of the approach is the need, during training, to establish a dense correspondence across a training set of segmented shapes. We show that model construction can be treated as an optimisation problem, automating the process and guaranteeing the effectiveness of the resulting models. This is achieved by optimising an objective function with respect to the correspondence. We use an information theoretic objective function that directly promotes desirable features of the model. This is coupled with an effective method of manipulating correspondence, based on re-parameterising each training shape, to build optimal statistical shape models. The method is evaluated on several training sets of shapes, showing that it constructs better models than alternative approaches. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Manchester, Manchester M13 9PT, Lancs, England.
C3 University of Manchester
RP Univ Manchester, Stopford Bldg,Oxford Rd, Manchester M13 9PT, Lancs, England.
EM chris.taylor@man.ac.uk
RI Twining, Carole J/F-7423-2012; Rohlf, F J/A-8710-2008; Taylor,
   Chris/A-3909-2009
OI Allen, Danny/0000-0002-6200-0925; Cootes, Timothy/0000-0002-2695-9063;
   Taylor, Chris/0000-0001-7867-9533
CR [Anonymous], 1992, NUMERICAL RECIPES C
   BAUMBERG A, 1994, EUR C COMP VIS, P299
   BENAYOUN S, 1994, INT C PATT RECOG, P730, DOI 10.1109/ICPR.1994.576422
   Bookstein F L, 1997, Med Image Anal, V1, P225
   COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Davies RH, 2002, LECT NOTES COMPUT SC, V2352, P3
   Davies RH, 2002, IEEE T MED IMAGING, V21, P525, DOI 10.1109/TMI.2002.1009388
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   HANSEN M, 1998, MODEL SELECTION PRIN
   HILL A, 1994, BMVC94 - PROCEEDINGS OF THE 5TH BRITISH MACHINE VISION CONFERENCE, VOLS 1 AND 2, P429
   Kambhamettu C., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P222, DOI 10.1109/CVPR.1992.223271
   Kelemen A, 1999, IEEE T MED IMAGING, V18, P828, DOI 10.1109/42.811260
   Kotcheff A C, 1998, Med Image Anal, V2, P303
   LUTKENHONER B, 1991, ACTA OTO-LARYNGOL, P52
   Rangarajan A, 1997, LECT NOTES COMPUT SC, V1230, P29
   RISSANEN J, 1983, ANN STAT, V11, P416, DOI 10.1214/aos/1176346150
   Rissanen J., 1989, WORLD SCI SERIES COM, V15
   Rissanen JJ, 1996, IEEE T INFORM THEORY, V42, P40, DOI 10.1109/18.481776
   RUECKERT D, 2001, MICCAI, P77
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Tagare HD, 1999, IEEE T MED IMAGING, V18, P570, DOI 10.1109/42.790457
   WANG Y, 2002, P IEEE C COMPUTER VI, V2, P644
NR 23
TC 33
Z9 37
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1171
EP 1182
DI 10.1016/j.imavis.2003.09.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100012
DA 2024-07-18
ER

PT J
AU Papaioannou, G
   Karabassi, EA
AF Papaioannou, G
   Karabassi, EA
TI On the automatic assemblage of arbitrary broken solid artefacts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE curve matching; depth buffer; range maps; optimisation methods; surface
   matching
ID OBJECTS; RECONSTRUCTION; SURFACE; REGISTRATION; RECOGNITION; ORIENTATION
AB Presented here is a fast method that combines curve matching techniques with a surface matching algorithm to estimate the positioning and respective matching error for the joining of three-dimensional fragmented objects. Furthermore, this paper describes how multiple joints are evaluated and how the broken artefacts are clustered and transformed to form potential solutions of the assemblage problem. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Athens, Fac Sci, Dept Informat & Telecommun, Athens 15784, Greece.
C3 National & Kapodistrian University of Athens
RP Univ Athens, Fac Sci, Dept Informat & Telecommun, Panepistimioupolis Ilisia, Athens 15784, Greece.
EM georgep@di.uoa.gr
RI Papaioannou, Georgios/AAH-9642-2021
OI Papaioannou, Georgios/0000-0003-4774-0746
CR AYACHE N, 1986, IEEE T PATTERN ANAL, V8, P44, DOI 10.1109/TPAMI.1986.4767751
   Barequet G, 1997, IEEE T PATTERN ANAL, V19, P929, DOI 10.1109/34.615444
   Benjemaa R, 1999, IMAGE VISION COMPUT, V17, P113, DOI 10.1016/S0262-8856(98)00115-2
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Burel G, 1995, GRAPH MODEL IM PROC, V57, P400, DOI 10.1006/gmip.1995.1034
   Faugeras O.D., 1983, P 8 INT JOINT C ARTI, V2, P996
   FREEMAN H, 1978, PATTERN RECOGN, V10, P159, DOI 10.1016/0031-3203(78)90024-9
   Hori K., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P440, DOI 10.1109/CVPR.1999.784718
   HORN BKP, 1984, P IEEE, V72, P1671, DOI 10.1109/PROC.1984.13073
   HORN BKP, 1987, J OPT SOC AM A, V4, P629, DOI 10.1364/JOSAA.4.000629
   KALVIN A, 1986, INT J ROBOT RES, V5, P38, DOI 10.1177/027836498600500403
   KALVIN AD, 1997, P COMP APPL ARCH CAA
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   KISHON E, 1987, P AAAI WORKSHOP SPAT, P250
   LEITAO HCG, 2000, P 8 INT C CENTR EUR, P389
   LO CH, 1989, IEEE T PATTERN ANAL, V11, P1053, DOI 10.1109/34.42836
   Papaioannou G, 2002, IEEE T PATTERN ANAL, V24, P114, DOI 10.1109/34.982888
   Papaioannou G, 2000, INT C PATT RECOG, P734, DOI 10.1109/ICPR.2000.905491
   Papaioannou G., 2000, P INT C COMP GRAPH A, P117
   Papaionnou G, 2001, IEEE COMPUT GRAPH, V21, P53, DOI 10.1109/38.909015
   Siarry P, 1997, ACM T MATH SOFTWARE, V23, P209, DOI 10.1145/264029.264043
   Üçoluk G, 1999, COMPUT GRAPH-UK, V23, P573, DOI 10.1016/S0097-8493(99)00075-8
   WOLFSON HJ, 1990, IEEE T PATTERN ANAL, V12, P483, DOI 10.1109/34.55108
   Wolfson HJ, 1997, IEEE COMPUT SCI ENG, V4, P10, DOI 10.1109/99.641604
NR 24
TC 39
Z9 51
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2003
VL 21
IS 5
BP 401
EP 412
DI 10.1016/S0262-8856(03)00008-8
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 676DA
UT WOS:000182735600001
OA Green Published
DA 2024-07-18
ER

PT J
AU Kasemir, KU
   Betzler, K
AF Kasemir, KU
   Betzler, K
TI Detecting ellipses of limited eccentricity in images with high noise
   levels
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE ellipse detection; Hough transform; differential evolution
ID HOUGH TRANSFORM
AB We present a newly developed algorithm for the detection of elliptical shapes in images in the presence of high noise levels. The algorithm combines a modified version of the Hough transform with a genetic algorithm, namely Differential Evolution. Suggestions for a parallel implementation are given. In our implementation the algorithm is restricted due to the technical problem to be solved, yet it can be easily generalized to arbitrary ellipse detection. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Osnabruck, Fachbereich Phys, D-49069 Osnabruck, Germany.
C3 University Osnabruck
RP Betzler, K (corresponding author), Univ Osnabruck, Fachbereich Phys, Barbarastr 7, D-49069 Osnabruck, Germany.
CR Ballard D.H., 1982, Computer Vision
   Goulermas JY, 1998, IMAGE VISION COMPUT, V16, P615, DOI 10.1016/S0262-8856(98)00075-4
   Guil N, 1997, PATTERN RECOGN, V30, P1729, DOI 10.1016/S0031-3203(96)00191-4
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   KALVIAINEN H, 1995, IMAGE VISION COMPUT, V13, P239, DOI 10.1016/0262-8856(95)99713-B
   Nair PS, 1996, PATTERN RECOGN LETT, V17, P777, DOI 10.1016/0167-8655(96)00014-1
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   PRICE K, 1997, DOBBS J, V4, P18
   Reichert A, 1996, FERROELECTRICS, V184, P21, DOI 10.1080/00150199608230241
   ROBERT A, 1997, TR9701 CIIPS U W AUS
   Wohlecke M, 1996, APPL PHYS B-LASERS O, V63, P323, DOI 10.1007/BF01828734
   YUEN HK, 1989, IMAGE VISION COMPUTI, V7
NR 12
TC 23
Z9 26
U1 3
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 10
PY 2003
VL 21
IS 2
BP 221
EP 227
AR PII S0262-8856(02)00155-5
DI 10.1016/S0262-8856(02)00155-5
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 655CP
UT WOS:000181534000007
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Fang, YC
   Cao, YT
   Wu, JH
AF Zhang, Yaofang
   Fang, Yuchun
   Cao, Yiting
   Wu, Jiahua
TI RBGAN: Realistic-generation and balanced-utility GAN for face
   de-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face de-identification; Privacy protection; Data utility preservation;
   Disentangled representation; Symmetric consistency
AB The rise of computer vision technologies and surveillance devices has led to numerous studies on vision, but it also raises privacy concerns, especially regarding facial identity information. Protecting the privacy of face identity information has prompted the development of face de-identification, which faces two main challenges. The first challenge is the realism of the generated images, while the second challenge is finding the proper balance between privacy protection and preserving data utility. To address these challenges, we propose a face de-identification model called Realistic-Generation and Balanced-Utility GAN (RBGAN). RBGAN includes a disentangled module and a symmetric-consistency-guided generation module, which aim to preserve multiple attributes while generating realistic de-identified images. We design an attribute-specialized encoder to obtain the disentangled representation of identity and attribute to balance privacy protection and data utility preservation. To generate realistic de-identified images, we incorporate symmetric consistency and face reconstruction into the face de-identification process using the Generative Adversarial Network (GAN). The disentangled module can extract richer representation, and the symmetric-consistency-guided generation module can construct more facial details. As a result, our proposed RBGAN can generate de-identified face images that closely resemble real faces and are difficult to detect by visual systems. Experiments conducted on benchmark face datasets demonstrate the effectiveness of our model in generating realistic images while preserving multiple attributes.
C1 [Zhang, Yaofang; Fang, Yuchun; Cao, Yiting; Wu, Jiahua] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
C3 Shanghai University
RP Fang, YC (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
EM ycfang@shu.edu.com
FU National Natural Science Foundation of China [61976132, 61991411,
   U1811461]; Natural Science Foundation of Shanghai [19ZR1419200]; High
   Performance Computing Center of Shanghai University and Shanghai
   Engineering Research Center of Intelligent Computing System
   [19DZ2252600]
FX The work is supported by the National Natural Science Foundation of
   China under Grant No.: 61976132, 61991411 and U1811461, and the Natural
   Science Foundation of Shanghai under Grant No.: 19ZR1419200. We
   appreciate the High Performance Computing Center of Shanghai University
   and Shanghai Engineering Research Center of Intelligent Computing System
   No.: 19DZ2252600 for providing the computing resources.
CR Agarwal A, 2021, SIGNAL IMAGE VIDEO P, V15, P951, DOI 10.1007/s11760-020-01819-9
   Athalye A, 2018, PR MACH LEARN RES, V80
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Dang Z., 2022, arXiv
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Dovgard R, 2004, LECT NOTES COMPUT SC, V3022, P99
   Du L, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Fang YC, 2019, COMM COM INF SC, V1142, P13, DOI 10.1007/978-3-030-36808-1_2
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gross R., 2006, 2006 C COMPUTER VISI, P161
   Gross R., 2008, 2008 IEEE C COMP VIS, P1
   Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227
   Harguess J., 2011, CVPR 2011 WORKSH IEE, P66
   Hensel M, 2017, ADV NEUR IN, V30
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Hukkelås H, 2020, LECT NOTES COMPUT SC, V11844, P565, DOI 10.1007/978-3-030-33720-9_44
   Huynh-Thu Q, 2008, ELECTRON LETT, V44, P800, DOI 10.1049/el:20080522
   Karras T, 2018, Arxiv, DOI [arXiv:1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Khojaste MH, 2022, Arxiv, DOI arXiv:2201.03353
   Kingma D. P., 2014, arXiv
   Kuang ZZ, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3182, DOI 10.1145/3474085.3475464
   Lai Zihang, 2021, ICCV, P9730
   Lang O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P673, DOI 10.1109/ICCV48922.2021.00073
   Lee S, 2013, IMAGE VISION COMPUT, V31, P357, DOI 10.1016/j.imavis.2013.02.003
   Li D., 2023, P IEEE CVF C COMP VI, P8093
   Liu P, 2023, INT J MACH LEARN CYB, V14, P419, DOI 10.1007/s13042-022-01552-4
   Liu YP, 2017, Arxiv, DOI arXiv:1611.02770
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Locatello F, 2019, PR MACH LEARN RES, V97
   Ma T., 2021, arXiv
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Maximov M, 2020, PROC CVPR IEEE, P5446, DOI 10.1109/CVPR42600.2020.00549
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Moosavi-Dezfooli SM, 2017, PROC CVPR IEEE, P86, DOI 10.1109/CVPR.2017.17
   Neves JC, 2020, IEEE J-STSP, V14, P1038, DOI 10.1109/JSTSP.2020.3007250
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Pan YL, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909866
   Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49
   Rim D, 2016, IMAGE VISION COMPUT, V52, P125, DOI 10.1016/j.imavis.2016.04.017
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shoshan A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14063, DOI 10.1109/ICCV48922.2021.01382
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sweeney L, 2002, INT J UNCERTAIN FUZZ, V10, P557, DOI 10.1142/S0218488502001648
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xian TT, 2022, NEURAL NETWORKS, V148, P129, DOI 10.1016/j.neunet.2022.01.011
   Xie XM, 2023, INFORM PROCESS MANAG, V60, DOI 10.1016/j.ipm.2022.103154
   Yang JC, 2022, IMAGE VISION COMPUT, V127, DOI 10.1016/j.imavis.2022.104566
   Yang JJ, 2022, ALEX ENG J, V61, P8417, DOI 10.1016/j.aej.2022.02.007
   Yi D, 2014, Arxiv, DOI arXiv:1411.7923
   Zang XH, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104330
   Zhang J, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104513
NR 60
TC 0
Z9 0
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104868
DI 10.1016/j.imavis.2023.104868
EA NOV 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DC4M6
UT WOS:001129820300001
DA 2024-07-18
ER

PT J
AU Fang, MZ
   Gao, W
   Feng, ZR
AF Fang, Mengzhu
   Gao, Wei
   Feng, Zirui
TI Deep robust multi-channel learning subspace clustering networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Subspace clustering; Deep networks; Unsupervised learning; Multi-channel
   learning; Convolutional auto-encoder; Feature extraction
ID MOTION SEGMENTATION; REPRESENTATIONS; IDENTIFICATION; FACTORIZATION;
   MODELS
AB Subspace clustering methods are now widely used for unsupervised high-dimensional data processing in computer vision and other domains. Deep subspace clustering methods based on auto-encoder networks have made a significant improvement in nonlinear subspace clustering problems in comparison to previous works. However, these methods ignore the valid information lost during feature extraction, resulting in incomplete information and imprecise feature representations for subspace clustering. In addition, the clustering performance of the existing clustering methods is excessively dependent on hyper-parameters, making training difficult and unstable. In this paper, we propose Deep Robust Multi-Channel Learning Subspace Clustering Networks (DRMCLSC), a novel deep subspace clustering network for learning more comprehensive feature representations with good robustness for subspace clustering. The multi-channel learning strategy allows the model to extract, retain and fuse features simultaneously, enabling all valid information from the sample data to be obtained. Moreover, the multi-channel learning structure of the proposed method produces a more stable integration network that is less dependent on hyper-parameters and more resistant to training errors than previous works. Extensive experimental results on four benchmark datasets demonstrate the proposed method is superior and more effective than the state-of-the-art subspace clustering methods.
C1 [Fang, Mengzhu; Gao, Wei] Northeast Normal Univ, Sch Math & Stat, Changchun 130024, Jilin, Peoples R China.
   [Feng, Zirui] Loughborough Univ, Sch Business & Econ, Loughborough LE11 3TU, England.
C3 Northeast Normal University - China; Loughborough University
RP Gao, W (corresponding author), Northeast Normal Univ, Sch Math & Stat, Changchun 130024, Jilin, Peoples R China.
EM fangmz209@nenu.edu.cn; gaow@nenu.edu.cn
FU National Natural Science Foun-dation of China [11871141]
FX Acknowledgment The research was supported by the National Natural
   Science Foun-dation of China (No. 11871141) .
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Baek S, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108041
   Bako L, 2008, LECT NOTES COMPUT SC, V4981, P43
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Chen GL, 2009, INT J COMPUT VISION, V81, P317, DOI 10.1007/s11263-008-0178-9
   Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999
   Dang ZY, 2020, PROC CVPR IEEE, P6657, DOI 10.1109/CVPR42600.2020.00669
   Dizaji KG, 2017, IEEE I CONF COMP VIS, P5747, DOI 10.1109/ICCV.2017.612
   Elhamifar Ehsan, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2790, DOI 10.1109/CVPRW.2009.5206547
   Elhamifar E, 2013, IEEE T PATTERN ANAL, V35, P2765, DOI 10.1109/TPAMI.2013.57
   Feng JS, 2014, PROC CVPR IEEE, P3818, DOI 10.1109/CVPR.2014.482
   Guo XF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1753
   Hastie T, 1998, STAT SCI, V13, P54
   Hinton G.E., 2017, Encyclopedia of Machine Learning and Data Mining
   Ho J, 2003, PROC CVPR IEEE, P11, DOI 10.1109/cvpr.2003.1211332
   Nguyen H, 2015, NEUROCOMPUTING, V155, P32, DOI 10.1016/j.neucom.2014.12.051
   Hu H, 2014, PROC CVPR IEEE, P3834, DOI 10.1109/CVPR.2014.484
   Huang WT, 2019, IEEE SIGNAL PROC LET, V26, P1628, DOI 10.1109/LSP.2019.2941368
   Ji P., 2017, COMPUTER VISION PATT
   Ji P, 2017, ADV NEUR IN, V30
   Ji P, 2014, IEEE WINT CONF APPL, P461, DOI 10.1109/WACV.2014.6836065
   Kanatani K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P586, DOI 10.1109/ICCV.2001.937679
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li CS, 2021, AAAI CONF ARTIF INTE, V35, P8340
   Li CG, 2018, INT C PATT RECOG, P2093, DOI 10.1109/ICPR.2018.8545800
   Li CG, 2017, IEEE T IMAGE PROCESS, V26, P2988, DOI 10.1109/TIP.2017.2691557
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Lu CY, 2012, LECT NOTES COMPUT SC, V7578, P347, DOI 10.1007/978-3-642-33786-4_26
   Lv JC, 2021, IEEE T IMAGE PROCESS, V30, P5252, DOI 10.1109/TIP.2021.3079800
   Ma Y, 2007, IEEE T PATTERN ANAL, V29, P1546, DOI 10.1109/TP'AMI.2007.1085
   MacQueen J, 1965, P 5 BER S MATH STAT, P281
   McWilliams B, 2014, DATA MIN KNOWL DISC, V28, P736, DOI 10.1007/s10618-013-0317-y
   Mo QY, 2012, LECT NOTES COMPUT SC, V7578, P402, DOI 10.1007/978-3-642-33786-4_30
   Fard MM, 2018, Arxiv, DOI arXiv:1806.10069
   Nayar Sheila J., 1996, Columbia object image library (coil100)
   Ochs P., 2012, COMPUTER VISION PATT
   Patel VM, 2014, IEEE IMAGE PROC, P2849, DOI 10.1109/ICIP.2014.7025576
   Peng X, 2018, IEEE T IMAGE PROCESS, V27, P5076, DOI 10.1109/TIP.2018.2848470
   Purkait P, 2017, IEEE T PATTERN ANAL, V39, P1697, DOI 10.1109/TPAMI.2016.2614980
   Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shawe-Taylor John, 2004, KERNEL METHODS PATTE
   Valanarasu JMJ, 2021, IEEE WINT CONF APPL, P746, DOI 10.1109/WACV48630.2021.00079
   Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244
   Vidal R, 2004, P AMER CONTR CONF, P547
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Vidal R, 2011, IEEE SIGNAL PROC MAG, V28, P52, DOI 10.1109/MSP.2010.939739
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wu JL, 2019, IEEE I CONF COMP VIS, P8149, DOI 10.1109/ICCV.2019.00824
   Xiao SJ, 2016, IEEE T NEUR NET LEAR, V27, P2268, DOI 10.1109/TNNLS.2015.2472284
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Yang B, 2017, PR MACH LEARN RES, V70
   Yang X, 2019, PROC CVPR IEEE, P4061, DOI 10.1109/CVPR.2019.00419
   Yin M, 2016, PROC CVPR IEEE, P5157, DOI 10.1109/CVPR.2016.557
   You C, 2016, PROC CVPR IEEE, P3918, DOI 10.1109/CVPR.2016.425
   Zhang JJ, 2019, PROC CVPR IEEE, P5468, DOI 10.1109/CVPR.2019.00562
   Zhang T, 2019, LECT NOTES COMPUT SC, V11365, P466, DOI 10.1007/978-3-030-20873-8_30
   Zhou L, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4440
   Zhou P, 2018, PROC CVPR IEEE, P1596, DOI 10.1109/CVPR.2018.00172
NR 63
TC 2
Z9 2
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104769
DI 10.1016/j.imavis.2023.104769
EA JUL 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P5GN2
UT WOS:001050959400001
DA 2024-07-18
ER

PT J
AU Yang, JQ
   Shen, Q
   Xie, C
AF Yang, Jingqi
   Shen, Qi
   Xie, Cheng
TI Generation-based contrastive model with semantic alignment for
   generalized zero-shot learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Zero-shot learning; Image classification; Visual computing; Contrastive
   learning
AB Generalized zero-shot learning (GZSL) is an important research area in image computing, video processing, multimedia understanding, and other visual computing tasks. GZSL normally uses transferable semantic features to represent the visual features to predict unseen classes without training the unseen samples. The state-of-the-art zero-shot learning methods combine Generative Adversarial Network (GAN) and Contrastive Learning (CL) together to deeply transfer semantic features to visual features. However, the combined GAN module and CL module inevitably encounter the "semantic-visual inconsistent problem" in both the feature-generating process and the contrastive learning process. To handle the above problems, we propose the generation-based contrastive model with semantic alignment for generalized zero-shot learning. The proposed network is based on existing ZSL models combining GAN and CL, but with two additional alignment modules that are Feedback Alignment Module (FAM) and Negative sample Alignment Module (NAM). FAM applies an MLP (Multilayer Perceptron) to align the synthesized visual feature back to its semantic feature for keeping the semantic-visual consistency in the generator. NAM provides a new contrastive learning mechanism to align the negative pairs for keeping semanticvisual consistency during contrastive learning. Experimental results on massive real-world datasets show the proposed method achieves the new state-of-the-art in the field of generalized zero-shot learning. The source code of the proposed method is available athttps://github.com/yangjingqi99/GCSA.
C1 [Yang, Jingqi; Shen, Qi; Xie, Cheng] Ynunan Univ, Kunming, Peoples R China.
RP Xie, C (corresponding author), Ynunan Univ, Kunming, Peoples R China.
EM yangjingqi@mail.ynu.edu.cn; miracleshen@mail.ynu.edu.cn;
   xiecheng@ynu.edu.cn
OI Xie, Cheng/0000-0002-4484-7428
CR Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Chen SM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P122, DOI 10.1109/ICCV48922.2021.00019
   Chen Z, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3413, DOI 10.1145/3394171.3413813
   Ding ZM, 2019, PROC CVPR IEEE, P6184, DOI 10.1109/CVPR.2019.00635
   Dinu Georgiana, 2014, arXiv
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Finch K, 2020, ANIMALS-BASEL, V10, DOI 10.3390/ani10112029
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Gao R, 2020, IEEE T IMAGE PROCESS, V29, P3665, DOI 10.1109/TIP.2020.2964429
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu Y.-C., 2020, ARXIV
   Han ZY, 2021, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR46437.2021.00240
   Han ZY, 2021, NEUROCOMPUTING, V430, P150, DOI 10.1016/j.neucom.2020.10.080
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Keqing, 2020, P 28 INT C COMP LING, P1461
   Gulrajani I, 2017, ADV NEUR IN, V30
   Jiang HJ, 2019, IEEE I CONF COMP VIS, P9764, DOI 10.1109/ICCV.2019.00986
   Kim Y., 2020, Advances in Neural Information Processing Systems, V33
   Kwon G., 2022, IEEE Transactions on Image Processing
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Le Cacheux Y, 2019, IEEE I CONF COMP VIS, P10332, DOI 10.1109/ICCV.2019.01043
   Li JJ, 2022, IEEE T CYBERNETICS, V52, P8167, DOI 10.1109/TCYB.2021.3050803
   Li JJ, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1587, DOI 10.1145/3343031.3350901
   Li Y, 2023, IEEE T MULTIMEDIA, V25, P1600, DOI 10.1109/TMM.2021.3139211
   Liu C, 2021, AAAI CONF ARTIF INTE, V35, P8635
   Liu J., 2021, 2021 IEEE INT C MULT
   Liu JR, 2022, IEEE MULTIMEDIA, V29, P69, DOI 10.1109/MMUL.2022.3155541
   Liu SC, 2018, ADV NEUR IN, V31
   Liu Y, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3038
   Liu Y, 2019, IEEE I CONF COMP VIS, P6697, DOI 10.1109/ICCV.2019.00680
   Liu ZZ, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103924
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Norouzi M, 2014, Arxiv, DOI arXiv:1312.5650
   Pambala AK, 2020, IEEE WINT CONF APPL, P1226, DOI [10.1109/WACV45572.2020.9093625, 10.1109/wacv45572.2020.9093625]
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Schönfeld E, 2019, PROC CVPR IEEE, P8239, DOI 10.1109/CVPR.2019.00844
   Shaobo Min, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12661, DOI 10.1109/CVPR42600.2020.01268
   Skorokhodov I, 2021, Arxiv, DOI arXiv:2006.11328
   Sylvain T, 2019, Arxiv, DOI arXiv:1912.12179
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang CQ, 2021, Arxiv, DOI arXiv:2104.01832
   Wang J, 2021, IEEE INT CONF COMP V, P885, DOI 10.1109/ICCVW54120.2021.00104
   Wang ZY, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2080, DOI 10.1145/3459637.3482471
   Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xie GS, 2022, IEEE T NEUR NET LEAR, V33, P2903, DOI 10.1109/TNNLS.2020.3046924
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Xu B., 2022, IEEE transactions on neural networks and learning systems, DOI 10.1109/TNNLS.2022.3142181
   Yang Z., 2022, IMAGE VIS COMPUT
   Yucel MK, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104392
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhu PK, 2019, PROC CVPR IEEE, P2990, DOI 10.1109/CVPR.2019.00311
   Zhu YZ, 2018, PROC CVPR IEEE, P1004, DOI 10.1109/CVPR.2018.00111
   Zongyan Han, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12862, DOI 10.1109/CVPR42600.2020.01288
NR 59
TC 0
Z9 0
U1 6
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104758
DI 10.1016/j.imavis.2023.104758
EA JUL 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N9RV1
UT WOS:001040307700001
OA Bronze
DA 2024-07-18
ER

PT J
AU Huang, XP
   Wang, Q
   Chen, JX
   Chen, LN
   Chen, ZY
AF Huang, Xuping
   Wang, Qian
   Chen, Junxi
   Chen, Lingna
   Chen, Zhiyi
TI Effective hybrid attention network based on pseudo-color enhancement in
   ultrasound image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ultrasound image; UNet; Attention; Pseudo-color enhancement; CNNs
ID NET
AB Ultrasound image segmentation plays a vital role in the early diagnosis of human diseases. It helps diagnose many diseases, such as breast cancer, hemangioma, and other gynecological disorders. However, the intrinsic imaging characteristics of ultrasound images result in substantially lower resolution and clarity than CT, MRI, and other imaging modalities, and they are sensitive to interference from external influences. With its inherent artifacts, blurred lesion boundaries, and uneven intensity distribution, ultrasound images present a challenging task when it comes to segmenting lesion areas accurately. In recent years, convolutional neural networks (CNNs) have achieved remarkable results in medical image segmentation tasks. However, CNNs are limited in capturing the remote dependencies of the input image, leading to degraded accuracy in segmenting ultrasound lesions. In this paper, we developed a deep convolutional neural network that incorporates the pseudo-color enhancement algorithm and hybrid attention modules that enhance the network's ability to extract fine features and remote modeling capabilities. We propose a novel multi-scale channel attention-based decoder that efficiently uses the feature maps from the encoder as a complement and fuses them with the upsampled feature maps. The hybrid attention combination captures cross-channel interactions efficiently and enhances the context modeling capability, further improving the extraction of coarse and delicate features, and resulting in significant performance improvements. We found that the dice performance improved by 2.54%, 2.47%, 1.39%, 0.99%, and 1.23% on the BUL, BUSI, Hemangioma, BP, and VUI. Results from four public datasets and one self-collected dataset indicate that the proposed method outperforms other medical image segmentation methods for ultrasound image lesion segmentation.
C1 [Huang, Xuping; Chen, Lingna] Univ South China, Comp Sch, Hengyang 421001, Peoples R China.
   [Wang, Qian] Univ South China, Affiliated Hosp 1, Hengyang 421001, Peoples R China.
   [Chen, Junxi] Univ South China, Nanhua Hosp, Hengyang 421001, Peoples R China.
   [Chen, Zhiyi] Univ South China, Affiliated Hosp 7, Changsha 410000, Peoples R China.
C3 University of South China; University of South China; University of
   South China; University of South China
RP Chen, LN (corresponding author), Univ South China, Comp Sch, Hengyang 421001, Peoples R China.; Chen, ZY (corresponding author), Univ South China, Affiliated Hosp 7, Changsha 410000, Peoples R China.
EM linda_cjx@163.com; winchen@vip.163.com
FU National Natural Science Foundation of China [61504055, 61701218];
   Natural Science Foundation of Hunan Province of China [2020JJ4514,
   2020JJ4519]; Postgraduate Research Innovation Project of Hunan Province
   of China [CX20200934]; Hunan provincial base for scientific and
   technological innovation cooperation
FX This study was funded by the National Natural Science Foundation of
   China (Grant Nos. 61504055 and 61701218) , the Natural Science
   Foundation of Hunan Province of China (Grant Nos. 2020JJ4514 and
   2020JJ4519) , and Postgraduate Research Innovation Project of Hunan
   Province of China (Grant Nos. CX20200934) . This study was also funded
   by Hunan provincial base for scientific and technological innovation
   cooperation.
CR Abraham N, 2019, 2019 3RD INTERNATIONAL CONFERENCE ON IMAGING, SIGNAL PROCESSING AND COMMUNICATION (ICISPC), P85, DOI 10.1109/ICISPC.2019.8935668
   Al-Dhabyani W, 2020, DATA BRIEF, V28, DOI 10.1016/j.dib.2019.104863
   Amiri M, 2020, INT J COMPUT ASS RAD, V15, P981, DOI 10.1007/s11548-020-02158-3
   Awasthi N, 2022, IEEE T ULTRASON FERR, V69, P2115, DOI 10.1109/TUFFC.2022.3169684
   Baby M, 2017, 2017 INTERNATIONAL CONFERENCE OF ELECTRONICS, COMMUNICATION AND AEROSPACE TECHNOLOGY (ICECA), VOL 1, P107, DOI 10.1109/ICECA.2017.8203654
   Byra M, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102027
   Cao Hu, 2023, Computer Vision - ECCV 2022 Workshops: Proceedings. Lecture Notes in Computer Science (13803), P205, DOI 10.1007/978-3-031-25066-8_9
   Chen F, 2022, COMPUT METH PROG BIO, V214, DOI 10.1016/j.cmpb.2021.106580
   Chen GP, 2022, COMPUT BIOL MED, V141, DOI 10.1016/j.compbiomed.2021.105140
   Dai DW, 2022, MED IMAGE ANAL, V75, DOI 10.1016/j.media.2021.102293
   Dai JB, 1996, P SOC PHOTO-OPT INS, V2898, P186, DOI 10.1117/12.253399
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gooding MJ, 2008, ULTRASOUND MED BIOL, V34, P183, DOI 10.1016/j.ultrasmedbio.2007.07.023
   Guo LB, 2021, MED IMAGE ANAL, V71, DOI 10.1016/j.media.2021.102042
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang AY, 2022, QUANT IMAG MED SURG, V12, P3138, DOI 10.21037/qims-21-1074
   Iqbal A, 2022, J KING SAUD UNIV-COM, V34, P7283, DOI 10.1016/j.jksuci.2021.10.002
   Lee H, 2020, IEEE T ULTRASON FERR, V67, P1344, DOI 10.1109/TUFFC.2020.2972573
   Lehmann TM, 1997, IMAGE VISION COMPUT, V15, P251, DOI 10.1016/S0262-8856(96)01120-1
   Li HM, 2020, IEEE J BIOMED HEALTH, V24, P974, DOI 10.1109/JBHI.2019.2946092
   Li YP, 2021, I S BIOMED IMAGING, P611, DOI 10.1109/ISBI48211.2021.9434086
   Manh V, 2022, IEEE T ULTRASON FERR, V69, P2611, DOI 10.1109/TUFFC.2022.3190012
   Mi SY, 2021, LECT NOTES COMPUT SC, V12905, P313, DOI 10.1007/978-3-030-87240-3_30
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mishra D, 2019, IEEE T BIO-MED ENG, V66, P1637, DOI 10.1109/TBME.2018.2877577
   Mou L, 2021, MED IMAGE ANAL, V67, DOI 10.1016/j.media.2020.101874
   Negi A, 2020, ARAB J SCI ENG, V45, P6399, DOI 10.1007/s13369-020-04480-z
   Oktay O, 2018, Arxiv, DOI arXiv:1804.03999
   Petit O, 2021, LECT NOTES COMPUT SC, V12966, P267, DOI 10.1007/978-3-030-87589-3_28
   Qiu Y, 2021, AAAI CONF ARTIF INTE, V35, P4846
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Slabaugh G, 2009, ULTRASOUND MED BIOL, V35, P781, DOI 10.1016/j.ultrasmedbio.2008.10.014
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang P, 2021, IEEE T ULTRASON FERR, V68, P3549, DOI 10.1109/TUFFC.2021.3098308
   Valanarasu JMJ, 2022, LECT NOTES COMPUT SC, V13435, P23, DOI 10.1007/978-3-031-16443-9_3
   Valanarasu JMJ, 2021, LECT NOTES COMPUT SC, V12901, P36, DOI 10.1007/978-3-030-87193-2_4
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang HN, 2022, AAAI CONF ARTIF INTE, P2441
   Wang HY, 2022, INT CONF ACOUST SPEE, P2390, DOI 10.1109/ICASSP43922.2022.9746172
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang ZY, 2021, Arxiv, DOI arXiv:2002.07703
   Xian M, 2018, PATTERN RECOGN, V79, P340, DOI 10.1016/j.patcog.2018.02.012
   Xu CB, 2022, BIOMED SIGNAL PROCES, V71, DOI 10.1016/j.bspc.2021.103178
   Xue C, 2021, MED IMAGE ANAL, V70, DOI 10.1016/j.media.2021.101989
   Yap MH, 2018, IEEE J BIOMED HEALTH, V22, P1218, DOI 10.1109/JBHI.2017.2731873
   Yu Q., 2021, arXiv
   Zhang X., 2008, INFRARED MAT DEVICES, V6835, P403
   Zhou Q, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107777
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
NR 50
TC 3
Z9 3
U1 6
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104742
DI 10.1016/j.imavis.2023.104742
EA JUL 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N5KF7
UT WOS:001037392200001
DA 2024-07-18
ER

PT J
AU Wang, ZA
   Shi, S
   Zhai, ZR
   Wu, YN
   Yang, R
AF Wang, Zhongan
   Shi, Shuai
   Zhai, Zirong
   Wu, Yingna
   Yang, Rui
TI ArCo: Attention-reinforced transformer with contrastive learning for
   image captioning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image captioning; Visual attention; Transformer; Contrastive learning
AB Image captioning is a significant step toward achieving automatic interactions between humans and com-puters, in which a textual sequence of the content of an image is generated. Recently, the transformer-based encoder-decoder paradigm has made great achievements in image captioning. This method is usually trained with a cross-entropy loss function. However, for various captions of images with the same meaning, the computed losses may be different. The result is that the descriptions of images tend to be consistent, which limits the diversity of image captioning. In this paper, we present an attention-reinforced trans-former, a transformer-based architecture for image captioning. The architecture improves the image encoding stage, which exploits the relationships between image regions by integrating a feature attention block (FAB). During the training phase, we trained the model with a combination of cross-entropy loss and contrastive loss. We experimentally explored the performance of ArCo and other fully attentive models. We also validated the baseline of the transformer for image captioning with different pre-trained models. Our proposed approach was demonstrated to achieve a new state-of-the-art performance on the offline 'Karpathy' test split and online test server.(c) 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Wang, Zhongan; Shi, Shuai; Zhai, Zirong; Wu, Yingna; Yang, Rui] ShanghaiTech Univ, Shanghai 201210, Peoples R China.
C3 ShanghaiTech University
RP Zhai, ZR (corresponding author), ShanghaiTech Univ, Shanghai 201210, Peoples R China.
EM zhaizr@shanghaitech.edu.cn
FU ShanghaiTech University; CAS Interdisciplinary Innovation Team Project
   [JCTD-2020-10]
FX We gratefully acknowledge ShanghaiTech University start-up funding for
   financial support. The authors also thank the support from CAS
   Interdisciplinary Innovation Team Project (JCTD-2020-10)
CR Aker A, 2010, ACL 2010: 48TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P1250
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen Ting, 2020, ADV NEURAL INFORM PR, V33, P22243
   Chi ZW, 2021, Arxiv, DOI arXiv:2007.07834
   Choi Y, 2011, P 15 C COMPUTATIONAL, P220
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fang HC, 2020, Arxiv, DOI arXiv:2005.12766
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Gan C, 2017, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2017.108
   Giorgi J, 2021, Arxiv, DOI arXiv:2006.03659
   Gong YC, 2014, LECT NOTES COMPUT SC, V8692, P529, DOI 10.1007/978-3-319-10593-2_35
   Trinh TH, 2019, Arxiv, DOI arXiv:1906.02940
   Hendrycks D., 2016, PREPRINT
   Herdade S, 2019, ADV NEUR IN, V32
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Jaiswal A, 2021, TECHNOLOGIES, V9, DOI 10.3390/technologies9010002
   Jia C, 2021, PR MACH LEARN RES, V139
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kuznetsova P., 2012, Long Papers, P359
   Lample G, 2019, Arxiv, DOI arXiv:1901.07291
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li Y., 2018, EUR C COMP VIS ECCV, P684
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin T.-Y., 2014, CoRR, P740
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo YP, 2021, Arxiv, DOI arXiv:2101.06462
   Mikolov Tomas, 2013, Advances in Neural Information Processing Systems, P3111, DOI DOI 10.48550/ARXIV.1310.4546
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Papineni K., 2002, P ACL, P311
   Radford A, 2021, PR MACH LEARN RES, V139
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Song ZL, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5056, DOI 10.1145/3474085.3475607
   Sun C, 2015, IEEE I CONF COMP VIS, P2596, DOI 10.1109/ICCV.2015.298
   Tian Y., 2020, NeurIPS, V33, P6827
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yang ZL, 2016, ADV NEUR IN, V29
   Yang ZP, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108545
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
   Zhou Y., 2022, arXiv
NR 52
TC 6
Z9 6
U1 1
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104570
DI 10.1016/j.imavis.2022.104570
EA NOV 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500002
DA 2024-07-18
ER

PT J
AU Li, Z
   Wu, X
   Wang, JJ
   Guo, YK
AF Li, Zhi
   Wu, Xing
   Wang, Jianjia
   Guo, Yike
TI Weather-degraded image semantic segmentation with multi-task knowledge
   distillation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Adverse weather; Road scene; Knowledge distillation; Image enhancement;
   Semantic segmentation
AB The semantic segmentation of degraded image in adverse weather is of great importance for the navigation sys-tem of autonomous driving. However, weather-degraded images increase the difficulty of semantic segmenta-tion as well as decrease the accuracy. It is natural to integrate image enhancement into degraded image semantic segmentation to improve the accuracy, which is computation intensive and time consuming. To meet the challenge, we propose a fast degraded image semantic segmentation with Multi-Task Knowledge Distillation called MTKD. The proposed MTKD method encourages image enhancement and semantic segmentation net-works to learn from each other to make full use of the correlation between two tasks. Additionally, we propose shift operator to realize a lightweight model design. Extensive experiments demonstrate that the proposed MTKD outperforms state-of-the-art methods not only with better semantic segmentation performance but also with higher speed in weather-degraded images, which achieves 0.038 s in semantic segmentation for a 2048 x 1024 image.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Li, Zhi; Wu, Xing; Wang, Jianjia] Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
   [Wu, Xing] Zhejiang Lab, Hangzhou, Zhejiang, Peoples R China.
   [Wu, Xing; Wang, Jianjia] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai, Peoples R China.
   [Guo, Yike] Hong Kong Baptist Univ, Kowloon Tong, Hong Kong, Peoples R China.
C3 Shanghai University; Zhejiang Laboratory; Shanghai University; Hong Kong
   Baptist University
RP Wu, X (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai, Peoples R China.
EM xingwu@shu.edu.cn
RI guo, yi/KHC-4669-2024
FU National Natural Science Foundation of China [62172267]; National Key
   R&D Program of China [2019YFE0190500]; Natural Science Foundation of
   Shanghai, China [20ZR1420400]; State Key Program of National Natural
   Science Foundation of China [61936001]; Shanghai Pujiang Program
   [21PJ1404200]; Key Research Project of Zhejiang Laboratory [2021PE0AC02]
FX This work is supported by the National Natural Science Foundation of
   China (Grant No. 62172267), the National Key R&D Program of China (Grant
   No. 2019YFE0190500), the Natural Science Foundation of Shanghai, China
   (Grant No. 20ZR1420400), the State Key Program of National Natural
   Science Foundation of China (Grant No. 61936001), the Shanghai Pujiang
   Program (Grant No. 21PJ1404200), the Key Research Project of Zhejiang
   Laboratory (No. 2021PE0AC02).
CR Ashok Anubhav, 2017, PROC INT C LEARN REP
   Ba LJ, 2014, ADV NEUR IN, V27
   Bruggemann D, 2023, Arxiv, DOI arXiv:2207.06825
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen TQ, 2016, Arxiv, DOI [arXiv:1511.05641, DOI 10.48550/ARXIV.1511.05641]
   Chen XL, 2020, NEUROCOMPUTING, V403, P268, DOI 10.1016/j.neucom.2020.03.067
   Choudhary T, 2020, ARTIF INTELL REV, V53, P5113, DOI 10.1007/s10462-020-09816-7
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Fan MY, 2021, PROC CVPR IEEE, P9711, DOI 10.1109/CVPR46437.2021.00959
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Glodek M, 2015, NEUROCOMPUTING, V161, P17, DOI 10.1016/j.neucom.2015.01.076
   Guo DZ, 2020, IEEE T IMAGE PROCESS, V29, P782, DOI 10.1109/TIP.2019.2936111
   Hao SJ, 2020, NEUROCOMPUTING, V406, P302, DOI 10.1016/j.neucom.2019.11.118
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Lee S, 2022, PROC CVPR IEEE, P18889, DOI 10.1109/CVPR52688.2022.01834
   Li SY, 2019, PROC CVPR IEEE, P3833, DOI 10.1109/CVPR.2019.00396
   Li X, 2018, LECT NOTES COMPUT SC, V11211, P262, DOI 10.1007/978-3-030-01234-2_16
   Li XW, 2022, IMAGE VISION COMPUT, V122, DOI 10.1016/j.imavis.2022.104444
   Liu Y, 2020, NEUROCOMPUTING, V415, P106, DOI 10.1016/j.neucom.2020.07.048
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, 10.48550/arXiv.1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Ren DW, 2019, PROC CVPR IEEE, P3932, DOI 10.1109/CVPR.2019.00406
   Romero A, 2015, Arxiv, DOI arXiv:1412.6550
   Sakaridis C, 2018, LECT NOTES COMPUT SC, V11217, P707, DOI 10.1007/978-3-030-01261-8_42
   Sakaridis C, 2018, INT J COMPUT VISION, V126, P973, DOI 10.1007/s11263-018-1072-8
   Shehata MS, 2008, IEEE T INTELL TRANSP, V9, P349, DOI 10.1109/TITS.2008.915644
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Valada Abhinav, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4644, DOI 10.1109/ICRA.2017.7989540
   Wu X, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20143819
   Wu X, 2020, KNOWL-BASED SYST, V196, DOI 10.1016/j.knosys.2019.105201
   Xi X, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104466
   Xiao CJ, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104470
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang WH, 2020, IEEE T PATTERN ANAL, V42, P1377, DOI 10.1109/TPAMI.2019.2895793
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Yang Z, 2020, NEUROCOMPUTING, V412, P262, DOI 10.1016/j.neucom.2020.06.036
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1612.03928
   Zamir Syed Waqas, 2021, 2021 IEEE CVF C COMP
   Zhang H, 2018, PROC CVPR IEEE, P695, DOI 10.1109/CVPR.2018.00079
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
NR 42
TC 4
Z9 4
U1 5
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104554
DI 10.1016/j.imavis.2022.104554
EA SEP 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300009
DA 2024-07-18
ER

PT J
AU Zhao, ZH
   Cheng, SM
   Li, LH
AF Zhao, Zhihao
   Cheng, Samuel
   Li, Lihua
TI Robust depth estimation on real-world light field images using Gaussian
   belief propagation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Light field; Depth estimation; Optical flow; Real-world; Gaussian belief
   propagation
AB Depth estimation on light field images has been well researched on synthetic datasets. However, existing methods often fail on real-world light field images because of the real-world noises. Due to the lack of real-world light field image datasets for depth estimation, the learning-based methods, e.g., convolutional neural net-works, are not capable of performing well on real-world light field images with only synthetic datasets available. In this paper, we adopt the optical flow estimation method to estimate depth from light field images since (i) the existing optical flow methods have shown robustness with significant real-world noises; (ii) the adopted optical flow estimation method does not require any training data, thus not limited to the synthetic datasets. The depth can be solved via the approach of optical flow estimation because (i) a sub-aperture image array can be converted from a light field image; (ii) the optical flow between every two adjacent sub-aperture images of the image array is exactly the disparity between the two images. Furthermore, since a sub-aperture array contains numerous ad-jacent image pairs, numerous optical flow maps can be generated from the sub-aperture array. We show the depth can be well refined from these numerous optical flow maps through modeling these maps in a single graphical model (a pairwise Gaussian MRF to be precise) and inferencing this graphical model by Gaussian belief propagation (GaBP). Experiments show that i) the proposed method achieves better depth estimation than the state-of-the-art methods on real-world light field images; ii) the proposed method can estimate the depth of ob-jects at a far distance (3.5-9.5 m) much more accurately than the state-of-the-art convolutional neural networks.Published by Elsevier B.V.
C1 [Zhao, Zhihao; Cheng, Samuel] Univ Oklahoma, Dept Elect & Comp Engn, Norman, OK 73019 USA.
   [Li, Lihua] Shenzhen Technol Univ, Sino German Coll Intelligent Mfg, Shenzhen 518118, Guangdong, Peoples R China.
C3 University of Oklahoma System; University of Oklahoma - Norman; Shenzhen
   Technology University
RP Cheng, SM (corresponding author), Univ Oklahoma, Dept Elect & Comp Engn, Norman, OK 73019 USA.; Li, LH (corresponding author), Shenzhen Technol Univ, Sino German Coll Intelligent Mfg, Shenzhen 518118, Guangdong, Peoples R China.
EM zhihao.zhao@ou.edu; samuel.cheng@ou.edu; lilihua@sztu.edu.cn
OI Cheng, Samuel/0000-0002-5439-1137
FU Natural Science Foundation of Top Talent of SZTU [20211061010009]
FX Acknowledgments This work was supported in part by the Natural Science
   Foundation of Top Talent of SZTU (grant no. 20211061010009) .
CR [Anonymous], 2013, ANN WORKSH VIS MOD V
   [Anonymous], 2006, DIGITAL LIGHT FIELD
   Bickson D., 2008, Gaussian belief propagation: Theory and application
   Bok Y, 2017, IEEE T PATTERN ANAL, V39, P287, DOI 10.1109/TPAMI.2016.2541145
   Chen C, 2014, PROC CVPR IEEE, P1518, DOI 10.1109/CVPR.2014.197
   Chen JX, 2021, AAAI CONF ARTIF INTE, V35, P1009
   Chen Y., 2017, IRISH MACHINE VISION
   Criminisi A, 2005, COMPUT VIS IMAGE UND, V97, P51, DOI 10.1016/j.cviu.2004.06.001
   Heber S, 2017, IEEE I CONF COMP VIS, P2271, DOI 10.1109/ICCV.2017.247
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jeon HG, 2019, IEEE T PATTERN ANAL, V41, P297, DOI 10.1109/TPAMI.2018.2794979
   Jeon HG, 2015, PROC CVPR IEEE, P1547, DOI 10.1109/CVPR.2015.7298762
   Johannsen O, 2016, PROC CVPR IEEE, P3262, DOI 10.1109/CVPR.2016.355
   Kim C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461926
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   Kondermann D, 2016, IEEE COMPUT SOC CONF, P19, DOI 10.1109/CVPRW.2016.10
   Lin HT, 2015, IEEE I CONF COMP VIS, P3451, DOI 10.1109/ICCV.2015.394
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Navarro J, 2017, IEEE T IMAGE PROCESS, V26, P1873, DOI 10.1109/TIP.2017.2666041
   Shi JL, 2019, IEEE T IMAGE PROCESS, V28, P5867, DOI 10.1109/TIP.2019.2923323
   Shin C, 2018, PROC CVPR IEEE, P4748, DOI 10.1109/CVPR.2018.00499
   Srinivasan PP, 2015, IEEE I CONF COMP VIS, P3496, DOI 10.1109/ICCV.2015.399
   Strecke M, 2017, PROC CVPR IEEE, P2529, DOI 10.1109/CVPR.2017.271
   Sun X., 2016, INT JOINT C NEURAL N
   Tao MW, 2017, IEEE T PATTERN ANAL, V39, P546, DOI 10.1109/TPAMI.2016.2554121
   Tao MW, 2013, IEEE I CONF COMP VIS, P673, DOI 10.1109/ICCV.2013.89
   Tian JD, 2017, IEEE I CONF COMP VIS, P2420, DOI 10.1109/ICCV.2017.263
   Tsai D, 2017, IEEE ROBOT AUTOM LET, V2, P912, DOI 10.1109/LRA.2017.2654544
   Tsai YJ, 2020, AAAI CONF ARTIF INTE, V34, P12095
   Wang TC, 2016, LECT NOTES COMPUT SC, V9907, P121, DOI 10.1007/978-3-319-46487-9_8
   Wang TC, 2016, IEEE T PATTERN ANAL, V38, P2170, DOI 10.1109/TPAMI.2016.2515615
   Wang TC, 2015, IEEE I CONF COMP VIS, P3487, DOI 10.1109/ICCV.2015.398
   Wanner S, 2013, LECT NOTES COMPUT SC, V8142, P1, DOI 10.1007/978-3-642-40602-7_1
   Wanner S, 2013, PROC CVPR IEEE, P1011, DOI 10.1109/CVPR.2013.135
   Wanner S, 2012, PROC CVPR IEEE, P41, DOI 10.1109/CVPR.2012.6247656
   Zhang S, 2016, COMPUT VIS IMAGE UND, V145, P148, DOI 10.1016/j.cviu.2015.12.007
   Zhou W, 2017, ELECT IMAGING, V2017, P94
   Zhou WH, 2017, IEEE IMAGE PROC, P1632, DOI 10.1109/ICIP.2017.8296558
   Zhu H, 2017, IEEE J-STSP, V11, P965, DOI 10.1109/JSTSP.2017.2730818
NR 40
TC 3
Z9 3
U1 5
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104447
DI 10.1016/j.imavis.2022.104447
EA APR 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L0BW
UT WOS:000798959000001
DA 2024-07-18
ER

PT J
AU Li, XW
   Yi, S
   Zhang, RX
   Fu, XZ
   Jiang, H
   Wang, CH
   Liu, ZQ
   Gao, J
   Yu, J
   Yu, M
   Yu, RG
AF Li, Xuewei
   Yi, Song
   Zhang, Ruixuan
   Fu, Xuzhou
   Jiang, Han
   Wang, Chenhan
   Liu, Zhiqiang
   Gao, Jie
   Yu, Jian
   Yu, Mei
   Yu, Ruiguo
TI Dynamic sample weighting for weakly supervised object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Weakly supervised learning; Object detection; Dynamic sample weighting;
   Multiple instance learning
AB The framework based on Multiple Instance Learning (MIL) greatly improves the performance of Weakly Supervised Object Detection (WSOD), which enjoys a promising development. However, the detection results tend to be the most discriminative parts of the object, which is still an open problem. In this paper, we analyze the causes of the problem from the perspective of sample balance. Considering the inaccuracy of pseudo supervised information in WSOD, a Dynamic Sample Weighting strategy (DSW) is proposed to focus on samples which closely cover the object, making the detection results cover the object more comprehensively. The performance of DSW on PASCAL VOC 2007, PASCAL VOC 2012 and MS-COCO is significantly enhanced through the simple and effective method in this paper. Code will be made available.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Li, Xuewei; Yi, Song; Zhang, Ruixuan; Fu, Xuzhou; Liu, Zhiqiang; Gao, Jie; Yu, Jian; Yu, Mei; Yu, Ruiguo] Tianjin Univ, Coll Intelligence & Comp, Tianjin Key Lab Cognit Comp & Applicat, Tianjin Key Lab Adv Networking, Tianjin 300350, Peoples R China.
   [Jiang, Han; Wang, Chenhan] Beijing AXIS Technol Co Ltd, Beijing 100089, Peoples R China.
C3 Tianjin University
RP Yu, M (corresponding author), Tianjin Univ, Coll Intelligence & Comp, Tianjin Key Lab Cognit Comp & Applicat, Tianjin Key Lab Adv Networking, Tianjin 300350, Peoples R China.
EM yumei@tju.edu.cn
RI Zhang, Ruixuan/IAP-8273-2023
OI Zhang, Ruixuan/0000-0002-7827-4365
FU National Natural Science Foundation of China [61877043]; Tianjin
   Technical Export Project [20YDTPJC01570, 21YDTPJC00090]
FX This work was supported in part by a grant from the National Natural
   Science Foundation of China (No. 61877043) and by the grants from the
   Tianjin Technical Export Project (No. 20YDTPJC01570, No. 21YDTPJC00090).
CR [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Arbelaez P.A., IEEE C COMPUTER VISI, P328
   Bilen H., IEEE C COMPUTER VISI, P2846
   Chen Z., IEEE C COMP VIS PATT, P12992
   Diba A., IEEE C COMPUTER VISI, P5131
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Girshick R., IEEE International Conference on Computer Vision (ICCV), P1440
   He Kaiming., 2017, IEEE International Conference on Computer Vision (ICCV), P2980
   Huang Z., 2020, P 34 INT C NEUR INF, V33, P16797
   Ke W., IEEE WINTER C APPL C, P1305
   Kosugi S., IEEE INT C COMPUTER, P6063
   Li B., AAAI C ARTIFICIAL IN, P8577
   Lin C., AAAI C ARTIFICIAL IN, P11482
   Lin D., IEEE C COMP VIS PATT, P11580
   Lin T., IEEE International Conference on Computer Vision ICCV, P2999
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Pang J., IEEE C COMPUTER VISI, P821
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren Z., IEEE C COMP VIS PATT, P10595
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sammut C., 2017, ENCY MACHINE LEARNIN, DOI DOI 10.1007/978-1-4899-7687-1_68
   Shen Y., IEEE C COMPUTER VISI, P697
   Shen Y., EUR C COMP VIS 2020, P118
   Shrivastava A., IEEE C COMPUTER VISI, P761
   Tan M., IEEE C COMP VIS PATT, P10778
   Tang P., IEEE C COMPUTER VISI, P3059
   Tang P., EUROPEAN C COMPUTER, P370
   Tang P, 2020, IEEE T PATTERN ANAL, V42, P176, DOI 10.1109/TPAMI.2018.2876304
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wan F., IEEE C COMPUTER VISI, P2199
   Wan F, 2019, IEEE T PATTERN ANAL, V41, P2395, DOI 10.1109/TPAMI.2019.2898858
   Yan G., IEEE INT C COMPUTER, P9833
   Yang K., IEEE INT C COMPUTER, P8371
   Yin YF, 2021, AAAI CONF ARTIF INTE, V35, P3190
   Zeng Z., IEEE INT C COMPUTER, P8292
   Zhang DW, 2022, IEEE T PATTERN ANAL, V44, P5866, DOI 10.1109/TPAMI.2021.3074313
   Zhang DW, 2022, IEEE T PATTERN ANAL, V44, P3349, DOI 10.1109/TPAMI.2020.3046647
   Zhang DW, 2020, IEEE T NEUR NET LEAR, V31, P5549, DOI 10.1109/TNNLS.2020.2969483
   Zhang X., IEEE C COMPUTER VISI, P4262
NR 40
TC 4
Z9 4
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104444
DI 10.1016/j.imavis.2022.104444
EA APR 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1F1NU
UT WOS:000794942300005
DA 2024-07-18
ER

PT J
AU Yuan, QL
   Zhang, HL
AF Yuan, Qiang-Lin
   Zhang, Han-Ling
TI RAMT-GAN: Realistic and accurate makeup transfer with generative
   adversarial network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic facial makeup; Style transfer; Generative adversarial network;
   Image-to-image transformation
AB ABSTR A C T Automatic makeup transfer aims to precisely transfer the makeup style from a given reference makeup face image to a source image while preserving face identity and background information. Current works have achieved promising results in makeup transfer by using deep learning techniques. However, existing methods are focused on only one or two requirements, thus cannot simultaneously achieve face identity preservation, background retention, and accurate makeup transfer. Besides, it is also difficult to acquire a pair of well-aligned face images with different makeup styles. Aimed at these problems, we propose RAMT-GAN (Realistic and Accurate Makeup Transfer Generative Adversarial Network), a GAN-based image transformation framework for achieving realistic and accurate makeup style transfer. Specifically, we utilize a dual input/output network that builds on the BeautyGAN architecture to achieve cross-domain image transformation. Then, identity preser-vation loss and background invariant loss are introduced in RAMT-GAN to help synthesize realistic and accurate face makeup images. Extensive experiments demonstrate that the proposed makeup transfer model can synthe-size makeup faces with accurate reference style as well as maintaining the identity information and the back-ground information.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yuan, Qiang-Lin] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha, Peoples R China.
   [Zhang, Han-Ling] Hunan Univ, Sch Design, Changsha, Peoples R China.
C3 Hunan University; Hunan University
RP Zhang, HL (corresponding author), Hunan Univ, Sch Design, Changsha, Peoples R China.
EM yuanqianglin@hnu.edu.cn; hlzhangmail@163.com
FU National Key R&D Program of China [2021YFF0900600]; Key R&D Program of
   Hunan [2022SK2104]; Leading plan for scientific and technological
   innovation of high-techindustries of Hunan [2022GK4010]; National
   Natural Science Foun-dation of China [61672222]
FX This work was supported by funds for National Key R&D Program of China
   (2021YFF0900600) , Key R&D Program of Hunan (2022SK2104) , Leading plan
   for scientific and technological innovation of high-tech industries of
   Hunan (2022GK4010) , the National Natural Science Foundation of China
   (61672222) .
CR Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chang Z, 2018, IEEE WCNC
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Goodfellow L.J., 2014, NIPS
   Gu Q, 2019, IEEE I CONF COMP VIS, P10480, DOI 10.1109/ICCV.2019.01058
   Guo D, 2009, PROC CVPR IEEE, P73, DOI 10.1109/CVPRW.2009.5206833
   Horita D, 2020, ARXIV PREPRINT ARXIV
   Huang ZC, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1258
   Jiang WT, 2020, PROC CVPR IEEE, P5193, DOI 10.1109/CVPR42600.2020.00524
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Khan A., 2016, ARXIV PREPRINT ARXIV
   Kingma D. P., 2014, arXiv
   Kips R, 2020, ECCV
   Li C, 2015, PROC CVPR IEEE, P4621, DOI 10.1109/CVPR.2015.7299093
   Li TT, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P645, DOI 10.1145/3240508.3240618
   Liao J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073683
   Liu Si, 2016, IJCAI
   Long YS, 2016, IEEE INT CONF CON AU, P1, DOI [10.1007/s00170-016-9151-x, 10.1109/VLSI-TSA.2016.7480514, 10.1109/ICCA.2016.7505243]
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Miyato T, 2018, INT C LEARN REPR
   Park DY, 2019, PROC CVPR IEEE, P5873, DOI 10.1109/CVPR.2019.00603
   Simonyan K, 2015, IEEE INT C ICLR
   Tong WS, 2007, PACIFIC GRAPHICS 2007: 15TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, P211, DOI 10.1109/PG.2007.31
   Wei Z, 2017, PROC CVPR IEEE, P3947, DOI 10.1109/CVPR.2017.420
   Zhang Hongyi, 2019, INT C LEARN REPR
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao HH, 2020, VISUAL COMPUT, V36, P1307, DOI 10.1007/s00371-019-01726-2
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 29
TC 8
Z9 9
U1 4
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104400
DI 10.1016/j.imavis.2022.104400
EA FEB 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500006
DA 2024-07-18
ER

PT J
AU Goyal, G
   Noceti, N
   Odone, F
AF Goyal, Gaurvi
   Noceti, Nicoletta
   Odone, Francesca
TI Cross-view action recognition with small-scale datasets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross-view action recognition; Pre-trained deep features; Transfer
   learning; Multiview action recognition
AB Cross-view action recognition refers to the task of recognizing actions observed from view-points that are unfa-miliar to the system. To address the complexity of the problem, state of the art methods often rely on large-scale datasets, where the variability of viewpoints is appropriately represented. However, this comes to a significant price, in terms of computational power, time, costs, energy for both gathering data annotation and training the model. We propose a methodological pipeline that tackles the same challenges with specific focus on small-scale datasets and attention to the amount of resources required. The core idea of our method is to transfer knowledge from an intermediate, pre-trained representation, under the hypothesis that it already may implicitly incorporate relevant cues for the task. We rely on an effective domain adaptation strategy coupled with the de-sign of a robust classifier that promotes view-invariant properties and allows us to efficiently generalise to action recognition to unseen viewpoints. In contrast to other state-of-art methods employing also alternative data mo-dalities, our approach is purely video-based and thus has a wider field of applications. We present a thorough ex-perimental analysis justifying the choices on the design of the pipeline, and providing a comparison with existing approaches in the two main scenarios of one-one learning and multiple view learning, where our approach pro-vides superior performance.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Goyal, Gaurvi; Noceti, Nicoletta; Odone, Francesca] Univ Genoa, MaLGa Machine Learning Genova Ctr, 35 Via Dodecaneso, I-16146 Genoa, Italy.
C3 University of Genoa
RP Noceti, N (corresponding author), Univ Genoa, MaLGa Machine Learning Genova Ctr, 35 Via Dodecaneso, I-16146 Genoa, Italy.
EM nicoletta.noceti@unige.it
OI Goyal, Gaurvi/0000-0003-2700-0791
FU Fondazione Cariplo [2018-0858]; AFOSR [FA8655-20-1-7035]
FX This work has been carried out at the Machine Learning Genoa (MaLGa)
   center, Universita di Genova (IT). It has been supported by Fondazione
   Cariplo with the project "Stairway to elders: bridging space, time and
   emotions in their social environment for wellbeing", grant no.
   2018-0858, and by AFOSR, with the project "Cognitively-inspired
   architectures for humanmotion understanding", grant n. FA8655-20-1-7035.
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2712608
   [Anonymous], 2012, CoRR
   Baradel F, 2018, PROC CVPR IEEE, P469, DOI 10.1109/CVPR.2018.00056
   Baradel F, 2017, IEEE INT CONF COMP V, P604, DOI 10.1109/ICCVW.2017.77
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cai LQ, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.051218
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cherla Srikanth, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563179
   Deng J., 2009, IEEE C COMP VIS PATT
   Dhiman C, 2020, IEEE T IMAGE PROCESS, V29, P3835, DOI 10.1109/TIP.2020.2965299
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ganin Y, 2016, J MACH LEARN RES, V17
   Gedamu K, 2021, PATTERN RECOGN, V118, DOI 10.1016/j.patcog.2021.108043
   Goyal Gaurvi, 2020, 2020 25th International Conference on Pattern Recognition (ICPR), P3690, DOI 10.1109/ICPR48806.2021.9412776
   Grossi G, 2020, PATTERN RECOGN LETT, V137, P61, DOI 10.1016/j.patrec.2019.03.016
   Gupta A, 2014, PROC CVPR IEEE, P2601, DOI 10.1109/CVPR.2014.333
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Hara K., 2017, ABS171109577 CORR
   Huang C.-H., 2012, RECOGNIZING ACTIONS
   Huang KQ, 2012, IEEE T IMAGE PROCESS, V21, P2187, DOI 10.1109/TIP.2011.2176346
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Ji YL, 2020, IEEE T CIRC SYST VID, V30, P2114, DOI 10.1109/TCSVT.2019.2912988
   Ji YL, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1510, DOI 10.1145/3240508.3240675
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Kay W., 2017, ARXIV170506950
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kong Y., 2018, ARXIV180611230
   Kong Y, 2017, IEEE T IMAGE PROCESS, V26, P3028, DOI 10.1109/TIP.2017.2696786
   Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822
   Li J., 2018, P ADV NEUR INF PROC, V31, P1254
   Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011
   Li Yanghao, 2016, Revisiting batch normalization for practical domain adaptation
   Liang B, 2015, 2015 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P76
   Liang D., 2020, P IEEE C COMP VIS PA
   Liu J, 2019, INT J COMPUT VISION, V127, P1545, DOI 10.1007/s11263-019-01192-2
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2018, PROC CVPR IEEE, P1159, DOI 10.1109/CVPR.2018.00127
   Marsella Antonio., Proceedings of the 36th Annual ACM Symposium on Applied Computing, P1046
   Nehaniv CL, 2002, FROM ANIM ANIMAT, P41
   Nicora E, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00776-9
   Puig X, 2018, PROC CVPR IEEE, P8494, DOI 10.1109/CVPR.2018.00886
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Rahmani H, 2018, IEEE T PATTERN ANAL, V40, P667, DOI 10.1109/TPAMI.2017.2691768
   Rahmani H, 2015, PROC CVPR IEEE, P2458, DOI 10.1109/CVPR.2015.7298860
   Rai N., P IEEE CVF C COMP VI, P11184
   de Souza CR, 2017, PROC CVPR IEEE, P2594, DOI 10.1109/CVPR.2017.278
   Rogez G, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P324, DOI 10.1109/AVSS.2007.4425331
   Roh MC, 2010, PATTERN RECOGN LETT, V31, P639, DOI 10.1016/j.patrec.2009.11.017
   Schatz Kara Marie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P410, DOI 10.1007/978-3-030-58583-9_25
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Syeda-Mahmood T, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P64, DOI 10.1109/EVENT.2001.938868
   Ullah A, 2021, NEUROCOMPUTING, V435, P321, DOI 10.1016/j.neucom.2019.12.151
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varol G, 2021, INT J COMPUT VISION, V129, P2264, DOI 10.1007/s11263-021-01467-7
   Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293
   Vyas Shruti, 2020, P EUR C COMP VIS
   Wang DG, 2018, LECT NOTES COMPUT SC, V11213, P457, DOI 10.1007/978-3-030-01240-3_28
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang Y., 2016, P BRIT MACH VIS C RI, DOI DOI 10.5244/C.30.108
   Wang Y., IEEE T NEURAL NETWOR, P1
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu D, 2014, NEUROCOMPUTING, V127, P98, DOI 10.1016/j.neucom.2013.08.038
   Wu X., 2012, VIEW INVARIANT ACTIO
   Xu G., 2017, ASIAN C COMPUTER VIS, P477
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Yilmaz A, 2005, IEEE I CONF COMP VIS, P150
   Yin J, 2019, ARXIV PREPRINT ARXIV
   Zach C., 2017, JOINT PATTERN RECOGN, P214
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhang J., 2016, ICRA
   Zhang JT, 2018, IEEE T IMAGE PROCESS, V27, P4709, DOI 10.1109/TIP.2018.2836323
   Zhang Z, 2013, PROC CVPR IEEE, P2690, DOI 10.1109/CVPR.2013.347
   Zheng JJ, 2013, IEEE I CONF COMP VIS, P3176, DOI 10.1109/ICCV.2013.394
   Zheng JJ, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.125
NR 81
TC 5
Z9 6
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104403
DI 10.1016/j.imavis.2022.104403
EA FEB 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500005
OA Bronze
DA 2024-07-18
ER

PT J
AU Sharma, H
   Jalal, AS
AF Sharma, Himanshu
   Jalal, Anand Singh
TI A survey of methods, datasets and evaluation metrics for visual question
   answering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Natural language processing; Deep neural networks;
   World knowledge; Attention
ID ATTENTION; LANGUAGE; FUSION
AB Visual Question Answering (VQA) is a multi-disciplinary research problem that has captured the attention of both computer vision as well as natural language processing researchers. In Visual Question Answering, a system is given an image; a question in a natural language related to that image as an input, and the VQA system is required to give an answer in natural language as an output. A VQA algorithm may require common sense reasoning over the information contained in the image and world knowledge to produce the right answer. In this paper, we have discussed some of the core concepts used in VQA systems and present a comprehensive survey of efforts in the past to address this problem. Apart from traditional VQA models, we have also discussed visual question answering models that require reading texts present in images and evaluated on recently developed datasets like TextVQA, ST-VQA, and OCR-VQA. Apart from standard datasets discussed in previous surveys, we have also discussed some new datasets developed in 2019 and 2020 such as GQA, OK-VQA, TextVQA, ST-VQA, and OCR-VQA. The new evaluation metrics such as BLEU, MPT, METEOR, Average Normalized Levenshtein Similarity (ANLS), Validity, Plausibility, Distribution, Consistency, Grounding, F1-Score are explained together with the evaluation metrics discussed by previous surveys. We conclude our survey with a discussion on open issues in each phase of the VQA task and present some promising future directions. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Sharma, Himanshu; Jalal, Anand Singh] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
C3 GLA University
RP Sharma, H (corresponding author), GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
EM himanshu.sharma@gla.ac.in; asjalal@gla.ac.in
RI Martsenyuk, Vasyl P/D-6964-2015
OI Jalal, Anand/0000-0002-7469-6608; Sharma, Himanshu/0000-0002-3745-7616
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Andreas J., 2016, P 2016 C N AM CHAPT, P1545, DOI DOI 10.18653/V1/N16-1181
   ANDREAS J, 2015, ARXIV151102799
   Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12
   [Anonymous], Simple baseline for visual question answering
   [Anonymous], 2018, DUAL RECURRENT ATTEN
   [Anonymous], 2018, ARXIV180307724
   [Anonymous], 2016, ARXIV160603647
   [Anonymous], 2018, ARXIV181209681
   [Anonymous], 2018, ABS180908697 CORR
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Atkinson A., 2017, Figureqa: An annotated figure dataset for visual reasoning
   Bai X, 2018, IEEE ACCESS, V6, P66322, DOI 10.1109/ACCESS.2018.2878899
   Bai YL, 2018, LECT NOTES COMPUT SC, V11216, P21, DOI 10.1007/978-3-030-01258-8_2
   Bai ZW, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107538
   Battaglia P., NIPS 2017, P4974
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Biten AF, 2019, IEEE I CONF COMP VIS, P4290, DOI 10.1109/ICCV.2019.00439
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Cao LF, 2017, LECT NOTES COMPUT SC, V10538, P248, DOI 10.1007/978-3-319-68155-9_19
   Cer D, 2018, CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018): PROCEEDINGS OF SYSTEM DEMONSTRATIONS, P169
   Charikar M, 2004, THEOR COMPUT SCI, V312, P3, DOI 10.1016/S0304-3975(03)00400-6
   Chaturvedi I, 2019, PATTERN RECOGN LETT, V125, P264, DOI 10.1016/j.patrec.2019.04.024
   Chen K., 2015, Abc-cnn: An attention based convolutional neural network for visual question answering
   Chen X., P IEEE CVF C COMP VI, P10876
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Conneau A., 2017, P 2017 C EMPIRCAL ME, P670, DOI [DOI 10.18653/V1/D17-1070, 10.18653/v1/d17-1070]
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Desta MT, 2018, IEEE WINT CONF APPL, P1814, DOI 10.1109/WACV.2018.00201
   Devlin J., 2018, BERT PRE TRAINING DE
   Dey A.U., 2019, Pattern Recognition Letters, V149, P164, DOI DOI 10.1016/J.PATREC.2021.06.011
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Fang ZW, 2019, PATTERN RECOGN, V90, P404, DOI 10.1016/j.patcog.2019.01.038
   Forsbom E., P WORKSH MACH TRANSL, P29
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gao CY, 2022, IEEE T PATTERN ANAL, V44, P9603, DOI 10.1109/TPAMI.2021.3132034
   Gao H., 2015, INT C NEURAL INF PRO, P2296
   Gao LL, 2020, NEUROCOMPUTING, V391, P227, DOI 10.1016/j.neucom.2018.11.102
   Gao LL, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1742, DOI 10.1145/3240508.3240687
   Gao P, 2019, PROC CVPR IEEE, P6632, DOI 10.1109/CVPR.2019.00680
   Gao P, 2018, LECT NOTES COMPUT SC, V11205, P485, DOI 10.1007/978-3-030-01246-5_29
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gómez L, 2018, LECT NOTES COMPUT SC, V11218, P728, DOI 10.1007/978-3-030-01264-9_43
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Gu G, 2017, IEEE INT CON MULTI, P997, DOI 10.1109/ICME.2017.8019540
   Gupta N, 2020, NEURAL COMPUT APPL, V32, P17899, DOI 10.1007/s00521-019-04515-z
   Gurari D, 2018, PROC CVPR IEEE, P3608, DOI 10.1109/CVPR.2018.00380
   Han W., 2020, COLING
   Hasan Sadid A, 2018, CLEF WORKING NOTES
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hong J, 2020, NEUROCOMPUTING, V402, P366, DOI 10.1016/j.neucom.2020.03.098
   Hong YN, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1645, DOI 10.1109/ICCV48922.2021.00169
   Hosseinabad SH, 2021, VISUAL COMPUT, V37, P119, DOI 10.1007/s00371-019-01786-4
   Hu R., P IEEE CVF C COMP VI, P9992
   Hu RH, 2019, IEEE I CONF COMP VIS, P10293, DOI 10.1109/ICCV.2019.01039
   Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93
   Huasong Z., 2020, IEEE T MULTIMEDIA, V23, P1264
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Husdon D., 2018, ICLR
   Ilievski I., 2017, NEURIPS, P551
   Ilievski I, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P415, DOI 10.1145/3126686.3126695
   Ilievski Ilija., 2016, A focused dynamic attention model for visual question answering
   Iwana B.K., 2016, JUDGING BOOK BY ITS
   Jabri A, 2016, LECT NOTES COMPUT SC, V9912, P727, DOI 10.1007/978-3-319-46484-8_44
   Jiang A., 2015, ARXIV PREPRINT ARXIV
   Jiang L., 2017, ARXIV170801336
   Jin J.-H., 2018, BILINEAR ATTENTION N
   Johnson J, 2017, IEEE I CONF COMP VIS, P3008, DOI 10.1109/ICCV.2017.325
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Jun SH, 2017, ICEC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON ELECTRONIC COMMERCE, DOI 10.1145/3154943.3154947
   Kafle K, 2018, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2018.00592
   Kafle K, 2017, IEEE I CONF COMP VIS, P1983, DOI 10.1109/ICCV.2017.217
   Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005
   Kafle K, 2016, PROC CVPR IEEE, P4976, DOI 10.1109/CVPR.2016.538
   Karatzas D, 2015, PROC INT CONF DOC, P1156, DOI 10.1109/ICDAR.2015.7333942
   Karatzas D, 2013, PROC INT CONF DOC, P1484, DOI 10.1109/ICDAR.2013.221
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kazemi V., 2017, ARXIV170403162
   Kembhavi A, 2016, LECT NOTES COMPUT SC, V9908, P235, DOI 10.1007/978-3-319-46493-0_15
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kiros Ryan., 2015, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems, P3294
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar V, 2016, INT CONF ADVAN COMPU
   Lancaster H.O., 2005, Encyclopedia of biostatistics, V2
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lehmann J, 2015, SEMANT WEB, V6, P167, DOI 10.3233/SW-140134
   Li G., 2017, ARXIV PREPRINT ARXIV
   Li H, 2019, PROC CVPR IEEE, P6312, DOI 10.1109/CVPR.2019.00648
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li MF, 2018, LECT NOTES COMPUT SC, V11166, P750, DOI 10.1007/978-3-030-00764-5_69
   Li Q, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3300938
   Li R., 2016, Advances in Neural Information Processing Systems, V29, P4655
   Liang JW, 2018, PROC CVPR IEEE, P6135, DOI 10.1109/CVPR.2018.00642
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin X, 2016, LECT NOTES COMPUT SC, V9906, P261, DOI 10.1007/978-3-319-46475-6_17
   Lin Y., IJCAI 2018, P4216
   Lin Y., 2014, TEXTVQA CHALLENGE 20
   Lioutas V, 2018, PATTERN RECOGN LETT, V111, P51, DOI 10.1016/j.patrec.2018.04.031
   Liu F., P 28 ACM INT C MULT, P4060
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Liu Y, 2021, IEEE T CYBERNETICS, V51, P5585, DOI 10.1109/TCYB.2020.2988896
   Liu Y, 2020, KNOWL-BASED SYST, V207, DOI 10.1016/j.knosys.2020.106339
   Lobry S, 2020, IEEE T GEOSCI REMOTE, V58, P8555, DOI 10.1109/TGRS.2020.2988782
   Logeswaran L., 2018, 6 INT C LEARN REPR I
   Lu JS, 2019, ADV NEUR IN, V32
   Lu JS, 2016, ADV NEUR IN, V29
   Lu P, 2018, AAAI CONF ARTIF INTE, P7218
   Ma C, 2018, PROC CVPR IEEE, P6975, DOI 10.1109/CVPR.2018.00729
   Ma L, 2016, AAAI CONF ARTIF INTE, P3567
   Malinowski M., P 27 INT C NEUR INF, P1682
   Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Manmadhan S, 2020, ARTIF INTELL REV, V53, P5705, DOI 10.1007/s10462-020-09832-7
   Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331
   Marneffe M.C., COL 2008 P WORKSH CR, P1
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Mikolov T., 2013, INT C LEARN REPR SCO, DOI 10.48550/ARXIV.1301.3781
   Mingrui Lao, 2018, IEEE Access, V6, P31516, DOI 10.1109/ACCESS.2018.2844789
   Mishra A., 2019, 2019 INT C DOCUMENT, P947
   Mishra A, 2013, IEEE I CONF COMP VIS, P3040, DOI 10.1109/ICCV.2013.378
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Narasimhan M, 2018, ADV NEUR IN, V31
   Narasimhan M, 2018, LECT NOTES COMPUT SC, V11212, P460, DOI 10.1007/978-3-030-01237-3_28
   Noh H, 2016, PROC CVPR IEEE, P30, DOI 10.1109/CVPR.2016.11
   Norcliffe-Brown W, 2018, ADV NEUR IN, V31
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Patil C, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3383465
   Peng L, 2019, MULTIMED TOOLS APPL, V78, P3843, DOI 10.1007/s11042-018-6389-3
   Pennington J., 2014, P C EMP METH NAT LAN, P1532, DOI DOI 10.3115/V1/D14-1162
   Perez E, 2018, AAAI CONF ARTIF INTE, P3942
   Pirsiavash H., 2009, NIPS 2009, P1482
   Radford Alec, 2018, IMPROVING LANGUAGE U, DOI DOI 10.18653/V1/N18-1202
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren H., 2018, ARXIV PREPRINT ARXIV
   Ren M., 2015, Proc Adv Neural Inf Process Syst, V1, P5
   Ren MY, 2015, ADV NEUR IN, V28
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruwa N, 2019, NEUROCOMPUTING, V330, P305, DOI 10.1016/j.neucom.2018.11.049
   Ruwa N, 2018, IEEE 1ST CONFERENCE ON MULTIMEDIA INFORMATION PROCESSING AND RETRIEVAL (MIPR 2018), P170, DOI 10.1109/MIPR.2018.00038
   Saito K, 2017, IEEE INT CON MULTI, P829, DOI 10.1109/ICME.2017.8019436
   Santoro A, 2016, PR MACH LEARN RES, V48
   Schwartz I., NIPS 2017, P3667
   Shah M, 2019, PROC CVPR IEEE, P6642, DOI 10.1109/CVPR.2019.00681
   Sharma H, 2022, MULTIMED TOOLS APPL, V81, P34775, DOI 10.1007/s11042-021-11276-2
   Sharma H, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104165
   Shi Y., ECCV 2018, P158
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Shrestha R, 2019, PROC CVPR IEEE, P10464, DOI 10.1109/CVPR.2019.01072
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh A., 2018, SYSML WORKSH NEURIPS, V2018
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Song J., IJCAI 2018, P906
   Su Z, 2018, PROC CVPR IEEE, P7736, DOI 10.1109/CVPR.2018.00807
   Sun B, 2020, J VIS COMMUN IMAGE R, V73, DOI 10.1016/j.jvcir.2020.102762
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tandon N, 2014, WSDM'14: PROCEEDINGS OF THE 7TH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P523, DOI 10.1145/2556195.2556245
   Tandon N, 2014, AAAI CONF ARTIF INTE, P166
   Teney D., 2016, arXiv
   Teney D., 2018, P EUR C COMP VIS, P219
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Tommasi T, 2019, INT J COMPUT VISION, V127, P38, DOI 10.1007/s11263-018-1096-0
   Toor AS, 2019, MULTIMED TOOLS APPL, V78, P2921, DOI 10.1007/s11042-018-6097-z
   Urooj A., P IEEE CVF C COMP VI, P8465
   Vaswani A, 2017, ADV NEUR IN, V30
   Veit Andreas, 2016, Coco-text: Dataset and benchmark for text detection and recognition in natural images
   Vu MH, 2020, IEEE T MED IMAGING, V39, P2856, DOI 10.1109/TMI.2020.2978284
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wang Peng., 2015, Explicit knowledge-based reasoning for visual question answering
   Whitehead S., 2021, CVPR, P5632
   Wu CF, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P519, DOI 10.1145/3240508.3240513
   Wu CF, 2019, AAAI CONF ARTIF INTE, P8997
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   WU ZB, 1994, 32ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, P133
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Xu Huijuan, 2016, ECCV 2016 2 WORKSHOP
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Z., 2019, ARX560IV181209681V2
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yi KX, 2018, ADV NEUR IN, V31
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu DC, 2018, IEEE IMAGE PROC, P2286, DOI 10.1109/ICIP.2018.8451516
   Yu DF, 2017, PROC CVPR IEEE, P4187, DOI 10.1109/CVPR.2017.446
   Yu J, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107563
   Yu L., 2015, Visual madlibs: Fill in the blank image generation and question answering
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688
   Zhang DX, 2019, INFORM FUSION, V52, P268, DOI 10.1016/j.inffus.2019.03.005
   Zhang P., P IEEE CVF C COMP VI, P5579
   Zhang P, 2016, PROC CVPR IEEE, P5014, DOI 10.1109/CVPR.2016.542
   Zhang W., 2020, KNOWL-BASED SYST
   Zhang WF, 2020, INFORM FUSION, V55, P116, DOI 10.1016/j.inffus.2019.08.009
   Zhang Y., 2018, 6 INT C LEARN REPR I
   Zhu C, 2017, IEEE I CONF COMP VIS, P1300, DOI 10.1109/ICCV.2017.145
   Zhu XQ, 2022, MINIM INVASIV THER, V31, P262, DOI 10.1080/13645706.2020.1780452
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 211
TC 16
Z9 16
U1 7
U2 45
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104327
DI 10.1016/j.imavis.2021.104327
EA OCT 2021
PG 34
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WU6KE
UT WOS:000716651500001
DA 2024-07-18
ER

PT J
AU Wu, H
   Miao, YB
   Fu, RC
AF Wu, Hang
   Miao, Yubin
   Fu, Ruochong
TI Point cloud completion using multiscale feature fusion and
   cross-regional attention
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D vision; Point cloud completion; Conditional local feature;
   Cross-regional attention
AB Raw point clouds obtained from real-world scanning are always incomplete and ununiformly distributed, which would result in structural losses of object shapes and bring about difficulties in further high-level 3D vision tasks. Therefore, a learning-based method called CRA-Net is proposed in this paper to repair partial point clouds and predict complete object shapes. Compared with most existing networks that only leverage global features, CRA-Net successfully utilizes local features to restore clearer details of object shapes with low instability. First, we propose an adaptive neighborhood query method that is able to adjust query centers and radiuses to cover different object shapes and acquire balanced local regions. Second, we build a parallel encoder to extract multiscale features from the input. Third, we design a cross-regional attention module based on graph attention network. It quantifies underlying relationships among all the local features under certain conditions interpreted by global features. Based on such relationships, each conditional local feature vector is able to search across the regions and selectively absorb other local features. Fourth, we design a coarse decoder to collect these cross region features and generate the skeleton of complete point cloud. Finally, we refine the coarse point cloud by comparing it with the input, and up sample it using folding-based layers.
   Our network is first trained and tested on manually made partial-complete point clouds pairs generated by the scanning process of a virtual LiDAR on eight categories of objects. Then it is tested on real-world point clouds of indoor and outdoor scenes. Compared with existing representative methods, our CRA-Net always restores the most accurate point clouds with the clearest details.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wu, Hang; Miao, Yubin; Fu, Ruochong] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Miao, YB (corresponding author), Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.
EM ybmiao@sjtu.edu.cn
FU National Natural Science Foundation of China [51975361]
FX This work is supported by National Natural Science Foundation of China
   (Grant NO. 51975361).
CR Achlioptas P, 2018, PR MACH LEARN RES, V80
   Angel Chang., 2015, SHAPENET INFORM RICH
   [Anonymous], 2018, PointSIFT: A SIFT-like Network Module for 3D Point Cloud Semantic Segmentation
   Aoki Y, 2019, PROC CVPR IEEE, P7156, DOI 10.1109/CVPR.2019.00733
   Clevert D., 2016, ARXIV151107289
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Defferrard M, 2016, ADV NEUR IN, V29
   Dubé R, 2017, IEEE INT C INT ROBOT, P1004, DOI 10.1109/IROS.2017.8202268
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Firman M, 2016, PROC CVPR IEEE, P5431, DOI 10.1109/CVPR.2016.586
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Gottschalk S., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P171, DOI 10.1145/237170.237244
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   Han XG, 2017, IEEE I CONF COMP VIS, P85, DOI 10.1109/ICCV.2017.19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kipf TN, 2017, INT C LEARN REPR
   Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Petar P.V., 2018, INT C LEARN REPR 201
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Ritter Jack., 1990, Graphics gems, V1, P301, DOI DOI 10.1016/B978-0-08-050753-8.50063-2
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Sarmad M, 2019, PROC CVPR IEEE, P5891, DOI 10.1109/CVPR.2019.00605
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sock J, 2017, IEEE INT CONF COMP V, P2228, DOI 10.1109/ICCVW.2017.260
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Stutz D, 2018, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2018.00209
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Varley J, 2017, IEEE INT C INT ROBOT, P2442, DOI 10.1109/IROS.2017.8206060
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang XG, 2020, PROC CVPR IEEE, P787, DOI 10.1109/CVPR42600.2020.00087
   Wang Y., 2018, ARXIV2018180107829
   Wu H., 2020, 2020 INT C PATT REC
   Wu H, 2021, PROC SPIE, V11605, DOI 10.1117/12.2586422
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yi L, 2019, PROC CVPR IEEE, P3942, DOI 10.1109/CVPR.2019.00407
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhang J., 2014, ROBOTICS SCI SYSTEMS, P9, DOI 10.15607/RSS.2014.X.007
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zitian Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7659, DOI 10.1109/CVPR42600.2020.00768
NR 50
TC 13
Z9 15
U1 1
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104193
DI 10.1016/j.imavis.2021.104193
EA MAY 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700004
DA 2024-07-18
ER

PT J
AU Kerim, A
   Celikcan, U
   Erdem, E
   Erdem, A
AF Kerim, Abdulrahman
   Celikcan, Ufuk
   Erdem, Erkut
   Erdem, Aykut
TI Using synthetic data for person tracking under adverse weather
   conditions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person tracking; Synthetic data; Rendering; Procedural generation
AB Robust visual tracking plays a vital role in many areas such as autonomous cars, surveillance and robotics. Recent trackers were shown to achieve adequate results under normal tracking scenarios with clear weather conditions, standard camera setups and lighting conditions. Yet, the performance of these trackers, whether they are corre-lation filter-based or learning-based, degrade under adverse weather conditions. The lack of videos with such weather conditions, in the available visual object tracking datasets, is the prime issue behind the low perfor-mance of the learning-based tracking algorithms. In this work, we provide a new person tracking dataset of real-world sequences (PTAW172Real) captured under foggy, rainy and snowy weather conditions to assess the performance of the current trackers. We also introduce a novel person tracking dataset of synthetic sequences (PTAW217Synth) procedurally generated by our NOVA framework spanning the same weather conditions in varying severity to mitigate the problem of data scarcity. Our experimental results demonstrate that the perfor-mances of the state-of-the-art deep trackers under adverse weather conditions can be boosted when the avail-able real training sequences are complemented with our synthetically generated dataset during training. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Kerim, Abdulrahman; Celikcan, Ufuk; Erdem, Erkut] Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
   [Erdem, Aykut] Koc Univ, Dept Comp Engn, Istanbul, Turkey.
   [Kerim, Abdulrahman] Univ Lancaster, Sch Comp & Commun, Lancaster, England.
C3 Hacettepe University; Koc University; Lancaster University
RP Celikcan, U (corresponding author), Hacettepe Univ, Dept Comp Engn, TR-06800 Ankara, Turkey.
EM a.kerime@lancaster.ac.uk; ufuk.celikcan@gmail.com;
   erkut@cs.hacettepe.edu.tr; aerdem@ku.edu.tr
RI Erdem, Erkut/A-2291-2012; Celikcan, Ufuk/H-1191-2017; Erdem,
   Aykut/A-2290-2012
OI Erdem, Erkut/0000-0002-6744-8614; Celikcan, Ufuk/0000-0001-6421-185X;
   Kerim, Abdulrahman/0000-0003-0141-9543; Erdem, Aykut/0000-0002-6280-8422
FU TUBITAK-1001 Program [217E029]; GEBIP 2018 fellowship of Turkish Academy
   of Sciences; BAGEP 2021 Award of the Science Academy
FX This work was supported in part by TUBITAK-1001 Program (Grant No.
   217E029), GEBIP 2018 fellowship of Turkish Academy of Sciences awarded
   to E. Erdem, and BAGEP 2021 Award of the Science Academy awarded to A.
   Erdem.
CR Abu Alhaija H, 2018, INT J COMPUT VISION, V126, P961, DOI 10.1007/s11263-018-1070-x
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2018, EUR C COMP VIS
   Barbosa IB, 2018, COMPUT VIS IMAGE UND, V167, P50, DOI 10.1016/j.cviu.2017.12.002
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P205, DOI 10.1007/978-3-030-58592-1_13
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Cheung E, 2016, LECT NOTES COMPUT SC, V9914, P709, DOI 10.1007/978-3-319-48881-3_50
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Dutta A, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P2276, DOI 10.1145/3343031.3350535
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Gaidon A, 2016, PROC CVPR IEEE, P4340, DOI 10.1109/CVPR.2016.470
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Kang JK, 2019, IEEE ACCESS, V7, P57972, DOI 10.1109/ACCESS.2019.2914670
   Kerim A, 2021, COMPUT GRAPH FORUM, V40, P258, DOI 10.1111/cgf.14271
   Li AN, 2016, IEEE T PATTERN ANAL, V38, P335, DOI 10.1109/TPAMI.2015.2417577
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Microsoft, MICR ROCK AV LIB GIT
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Richter SR, 2017, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2017.243
   de Souza CR, 2017, PROC CVPR IEEE, P2594, DOI 10.1109/CVPR.2017.278
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695
   Varol G, 2017, PROC CVPR IEEE, P4627, DOI 10.1109/CVPR.2017.492
   Walker J, 2015, IEEE I CONF COMP VIS, P2443, DOI 10.1109/ICCV.2015.281
   Worlds P., ENV WEBP
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Zhang LC, 2019, IEEE T IMAGE PROCESS, V28, P1837, DOI 10.1109/TIP.2018.2879249
   Zissermann A., VGG Image Annotator VIA
NR 38
TC 9
Z9 9
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104187
DI 10.1016/j.imavis.2021.104187
EA MAY 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700012
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Toshpulatov, M
   Lee, W
   Lee, S
AF Toshpulatov, Mukhiddin
   Lee, Wookey
   Lee, Suan
TI Generative adversarial networks and their application to 3D face
   generation: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Generative adversarial networks; Generator; Discriminator; Deep neural
   network; Deep learning
ID MORPHABLE MODEL; EXPRESSION; RECOGNITION; MIXTURE; CLASSIFICATION;
   GEOCHEMISTRY; PREDICTION; ALIGNMENT; DATABASE; SOLVER
AB Generative adversarial networks (GANs) have been extensively studied in recent years and have been used to address several problems in the fields of image generation and computer vision. Despite significant advancements in computer vision, applying GANs to real-world problems such as 3D face generation remains a challenge. Owing to the proliferation of fake images generated by GANs, it is important to analyze and build a taxonomy for providing an overall view of GANs. This, in turn, would facilitate many interesting applications, including virtual reality, augmented reality, computer games, teleconferencing, virtual try-on, special effects in movies, and 3D avatars. This paper reviews and discusses GANs and their application to 3D face generation. We aim to compare existing GANs methods in terms of their application to 3D face generation, investigate the related theoretical issues, and highlight the open research problems. Authors provided both qualitative and quantitative evaluations of the proposed approach. They claimed their results show the higher quality of the synthesized data compared to state-ofthe-art ones. ? 2021 Elsevier B.V. All rights reserved.
C1 [Toshpulatov, Mukhiddin; Lee, Wookey] Inho Univ, Biomed Sci & Engn, 100 Inha Ro, Incheon 22212, South Korea.
   [Lee, Suan] Semyung Univ, Sch Comp Sci, Jecheon 27136, South Korea.
C3 Semyung University
RP Lee, W (corresponding author), Inho Univ, Biomed Sci & Engn, 100 Inha Ro, Incheon 22212, South Korea.; Lee, S (corresponding author), Semyung Univ, Sch Comp Sci, Jecheon 27136, South Korea.
EM mukhiddin1979@inha.edu; trinity@inha.ac.kr; suanlee@semyung.ac.kr
RI Lee, Suan/AAG-9499-2019
OI Lee, Suan/0000-0002-3047-1167
FU Ministry of Education of the Republic of Korea; National Research
   Foundation of Korea [NRF 019S1A5C2A03081234]
FX This work was supported by the Ministry of Education of the Republic of
   Korea and the National Research Foundation of Korea (NRF
   019S1A5C2A03081234) .
CR Abrevaya VF, 2019, IEEE I CONF COMP VIS, P9418, DOI 10.1109/ICCV.2019.00951
   Ak KE, 2019, IEEE I CONF COMP VIS, P10540, DOI 10.1109/ICCV.2019.01064
   Alberry Hesham A., 2018, Future Computing and Informatics Journal, V3, P159, DOI 10.1016/j.fcij.2018.03.001
   Algadhy R, 2019, INT CONF ACOUST SPEE, P2367, DOI 10.1109/ICASSP.2019.8682455
   Almalioglu Y, 2019, IEEE INT CONF ROBOT, P5474, DOI [10.1109/icra.2019.8793512, 10.1109/ICRA.2019.8793512]
   [Anonymous], 2008, P 25 INT C MACHINE L, DOI [10.1145/1390156.1390273, DOI 10.1145/1390156.1390273]
   [Anonymous], 2017, 2017 14 IEEE INT C A
   [Anonymous], 2018, ADV NEUR IN
   [Anonymous], 2016, ICML
   [Anonymous], 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00105
   [Anonymous], 2018, Advances in neural information processing systems
   [Anonymous], 2013, 2013 10 IEEE INT C W, DOI [10.1109/FG.2013.6553805, DOI 10.1109/FG.2013.6553805]
   Anoosheh A, 2018, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2018.00122
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Arbel Michael, 2018, Advances in Neural Information Processing Systems, P6700
   Arjovsky M, 2017, ARXIV E PRINTS ART A
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Bardsley JM, 2008, INVERSE PROBL IMAG, V2, P167
   Barlow HB, 1989, NEURAL COMPUT, V1, P295, DOI 10.1162/neco.1989.1.3.295
   Barsoum E, 2018, IEEE COMPUT SOC CONF, P1499, DOI 10.1109/CVPRW.2018.00191
   Berthelot D., 2017, ARXIV PREPRINT ARXIV, P10717
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Bolton RN, 2003, J RETAILING, V79, P213, DOI 10.1016/j.jretai.2003.09.005
   Booth J, 2018, INT J COMPUT VISION, V126, P233, DOI 10.1007/s11263-017-1009-7
   Booth J, 2017, PROC CVPR IEEE, P5464, DOI 10.1109/CVPR.2017.580
   Booth J, 2016, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2016.598
   Booth J, 2014, IEEE IMAGE PROC, P4672, DOI 10.1109/ICIP.2014.7025947
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Brownlee J., 2020, CALCULATE FEATURE IM
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao J., 2019, Adv. Neural Inf. Proces. Syst., P1776
   Cao YJ, 2019, IEEE ACCESS, V7, P14985, DOI 10.1109/ACCESS.2018.2886814
   Cao Y, 2018, PROC CVPR IEEE, P1287, DOI 10.1109/CVPR.2018.00140
   Cevher V., 2018, INT C MACH LEARN 201, P2810
   Che Tong, 2016, CoRR
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Chen YZ, 2018, IEEE T POWER SYST, V33, P3265, DOI 10.1109/TPWRS.2018.2794541
   Cheng SY, 2018, PROC CVPR IEEE, P5117, DOI 10.1109/CVPR.2018.00537
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   Choi J, 2019, IEEE I CONF COMP VIS, P502, DOI 10.1109/ICCV.2019.00059
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Christmas, BMVC 2012, P1
   Dai GX, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P672, DOI 10.1145/3123266.3123334
   Dai H, 2020, INT J COMPUT VISION, V128, P547, DOI 10.1007/s11263-019-01260-7
   Dai H, 2017, IEEE I CONF COMP VIS, P3104, DOI 10.1109/ICCV.2017.335
   Danelakis A, 2016, PATTERN RECOGN, V52, P174, DOI 10.1016/j.patcog.2015.10.012
   De Cao N., 2018, arXiv, P11973
   Degottex G, 2018, IEEE W SP LANG TECH, P603, DOI 10.1109/SLT.2018.8639609
   Deng J., 2019, P IEEE C COMPUTER VI, P4690
   Deng JK, 2018, PROC CVPR IEEE, P7093, DOI 10.1109/CVPR.2018.00741
   Deng Y., P IEEE C COMP VIS PA
   Deprelle T., 2019, ADV NEURAL INFORM PR, P7433
   Dhall A., 2017, P 19 ACM INT C MULT, P524, DOI [10.1145/3136755.3143004, DOI 10.1145/3136755.3143004]
   DHANWADA KR, 1995, ONCOGENE, V11, P1947
   Di Mattia F., 2019, CORR, P11632
   Di X, 2018, INT C PATT RECOG, P1079, DOI 10.1109/ICPR.2018.8545081
   Dimitrakopoulos P, 2020, INT CONF ACOUST SPEE, P3182, DOI [10.1109/ICASSP40776.2020.9053325, 10.1109/icassp40776.2020.9053325]
   Ding L, 2020, J IMAGING SCI TECHN, V64, DOI 10.2352/J.ImagingSci.Technol.2020.64.3.030505
   Dinh L., ARXIV PREPRINT ARXIV
   Doersch C., ARXIV PREPRINT ARXIV
   Dollar P., 2017, P IEEE INT C COMP VI
   Du SY, 2010, PATTERN RECOGN LETT, V31, P791, DOI 10.1016/j.patrec.2010.01.020
   Egger B., 2019, ARXIV PREPRINT ARXIV
   Esteban Cristobal, 2017, REAL VALUED MED TIME
   Favaro, ARXIV PREPRINT ARXIV
   Fedus W., 2017, ARXIV171008446
   Ferrari Claudio, 2018, Smart Multimedia. First International Conference, ICSM 2018. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11010), P320, DOI 10.1007/978-3-030-04375-9_27
   Ferrera C, 2017, INT J CARDIOL, V249, P410, DOI 10.1016/j.ijcard.2017.09.170
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Foody GM, 2006, REMOTE SENS ENVIRON, V104, P1, DOI 10.1016/j.rse.2006.03.004
   Gao W., 2007, IEEE T SYSTEMS MAN C, V38, P149, DOI DOI 10.1109/TSMCA.2007.909557
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gauthier J., 2014, Class Project for Stanford CS231N: Convolutional Neural Networks for Visual Recognition, P2
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874
   Ghafoorian M, 2019, LECT NOTES COMPUT SC, V11129, P256, DOI 10.1007/978-3-030-11009-3_15
   Ghahramani Z, 2004, LECT NOTES ARTIF INT, V3176, P72
   Ghazi MM, 2016, IEEE COMPUT SOC CONF, P102, DOI 10.1109/CVPRW.2016.20
   Gillies D.F., 2010, Technological Reports, P1
   Goldberg Y., 2017, Synthesis Lectures on Human Language Technologies, V10, P1, DOI [10.2200/S00762ED1V01Y201703HLT037, DOI 10.2200/S00762ED1V01Y201703HLT037, 10.1007/978-3-031-02165-7]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Gui J., ARXIV PREPRINT ARXIV
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   Han XF, 2021, IEEE T PATTERN ANAL, V43, P1578, DOI 10.1109/TPAMI.2019.2954885
   Han ZY, 2018, MED IMAGE ANAL, V50, P23, DOI 10.1016/j.media.2018.08.005
   Handrich S, 2020, PROCEDIA COMPUT SCI, V170, P634, DOI 10.1016/j.procs.2020.03.134
   Hensel M, 2017, ADV NEUR IN, V30
   Ho Jonathan, 2019, Axial attention in multidimensional transformers
   Hu GS, 2016, LECT NOTES COMPUT SC, V9912, P73, DOI 10.1007/978-3-319-46484-8_5
   Hu YX, 2008, INT C PATT RECOG, P460
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Huh M, 2019, PROC CVPR IEEE, P1476, DOI 10.1109/CVPR.2019.00157
   Huszar F., P IEEE C COMP VIS PA, P4681
   Huynh L, 2018, PROC CVPR IEEE, P8407, DOI 10.1109/CVPR.2018.00877
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Izutov E., 2018, CORR
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jahn RG, 2007, EXPLORE-NY, V3, P244, DOI 10.1016/j.explore.2007.03.009
   Jeni Laszlo A., 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163142
   Jiankang Deng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P741, DOI 10.1007/978-3-030-58621-8_43
   Jo Y, 2019, IEEE I CONF COMP VIS, P1745, DOI 10.1109/ICCV.2019.00183
   Jolicoeur-Martineau A., ARXIV PREPRINT ARXIV
   Juefei-Xu F., 2018, Asian Conference on Computer Vision, P3
   Kaneko T, 2017, PROC CVPR IEEE, P7006, DOI 10.1109/CVPR.2017.741
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kaya H, 2017, IMAGE VISION COMPUT, V65, P66, DOI 10.1016/j.imavis.2017.01.012
   Kim T., 2017, P 34 INT C MACH LEAR, P1857, DOI DOI 10.1109/WPT.2017.7953894
   Kim Y, 2014, ARXIV PREPRINT ARXIV, DOI 10.3115/v1/D14-1181
   Kingma DP, 2014, ADV NEUR IN, V27
   Kneyber MCJ, 2017, INTENS CARE MED, V43, P1764, DOI 10.1007/s00134-017-4920-z
   Knyaz VA, 2019, LECT NOTES COMPUT SC, V11129, P601, DOI 10.1007/978-3-030-11009-3_37
   Kolesnikov A., 2017, P 34 INT C MACH LEAR, V70, P1905
   Kollias D., 2018, PROC EUR C COMP VIS
   Kollias D, 2020, INT J COMPUT VISION, V128, P1455, DOI 10.1007/s11263-020-01304-3
   Kollias D, 2019, INT J COMPUT VISION, V127, P907, DOI 10.1007/s11263-019-01158-4
   Kollias Dimitrios, 2020, IEEE Transactions on Affective Computing
   Komkov Stepan, 2019, ARXIV190808705
   Koppen P, 2018, PATTERN RECOGN, V74, P617, DOI 10.1016/j.patcog.2017.09.006
   Kossaifi J, 2017, IMAGE VISION COMPUT, V65, P23, DOI 10.1016/j.imavis.2017.02.001
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurach K., 2018, GAN LANDSCAPE LOSSES
   Kusner Matt J, 2016, ARXIV161104051
   Lahiri A, 2017, IEEE COMPUT SOC CONF, P794, DOI 10.1109/CVPRW.2017.110
   Lattas A., ARXIV PREPRINT ARXIV
   Li F, 2017, COMPUT PHYS COMMUN, V214, P6, DOI 10.1016/j.cpc.2017.01.001
   Li PP, 2018, INT C PATT RECOG, P1073, DOI 10.1109/ICPR.2018.8545119
   Li RH, 2019, IEEE I CONF COMP VIS, P7202, DOI 10.1109/ICCV.2019.00730
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li XY, 2017, GEOL J, V52, P286, DOI 10.1002/gj.3054
   Li X, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104077
   Liao JJZ, 2000, PDA J PHARM SCI TECH, V54, P23
   Lin CH, 2018, PROC CVPR IEEE, P9455, DOI 10.1109/CVPR.2018.00985
   LIN LI, 1989, BIOMETRICS, V45, P255, DOI 10.2307/2532051
   LIN LIK, 1992, BIOMETRICS, V48, P599, DOI 10.2307/2532314
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu H, 2019, IET IMAGE PROCESS, V13, P2662, DOI 10.1049/iet-ipr.2018.6545
   Liu KL, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104005
   Liu M.-Y., 2016, P ADV NEUR INF PROC, P469
   Liu N., 2020, ARXIV PREPRINT ARXIV, P11488
   Liu Y, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104087
   Liu YF, 2019, PROC CVPR IEEE, P11869, DOI 10.1109/CVPR.2019.01215
   Liu Z., 2018, LARGE SCALE CELEBFAC
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Lu YY, 2018, LECT NOTES COMPUT SC, V11216, P293, DOI 10.1007/978-3-030-01258-8_18
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Marafioti A., 2019, P MACHINE LEARNING R, P4352
   Matuszewski BJ, 2012, IMAGE VISION COMPUT, V30, P713, DOI 10.1016/j.imavis.2012.02.002
   Mescheder L, 2018, PR MACH LEARN RES, V80
   Minnen D, 2018, ADV NEUR IN, V31
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Mittal P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104046
   Mohamed S., ARXIV PREPRINT ARXIV
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Moschoglou S., 2019, ARXIV PREPRINT ARXIV
   Moubayed SA., 2008, Ninth Annual Conference of the International Speech Communication Association
   Mukhiddin T, 2020, INT CONF BIG DATA, P487, DOI 10.1109/BigComp48618.2020.00-19
   Tran NT, 2018, LECT NOTES COMPUT SC, V11218, P387, DOI 10.1007/978-3-030-01264-9_23
   Nickerson CAE, 1997, BIOMETRICS, V53, P1503, DOI 10.2307/2533516
   Nomani H, 2018, 2018 INTERNATIONAL CONFERENCE ON ADVANCES IN COMMUNICATION AND COMPUTING TECHNOLOGY (ICACCT), P426, DOI 10.1109/ICACCT.2018.8529358
   Odena A., INT C MACH LEARN PML, P2642
   Papamakarios G., 2017, Advances in Neural Information Processing Systems, P2338, DOI DOI 10.48550/ARXIV.1705.07057
   Pardo-Castellote G, 2003, 23RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS WORKSHOPS, P200
   Park SW, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040688
   Ploumpis S, 2019, PROC CVPR IEEE, P10926, DOI 10.1109/CVPR.2019.01119
   Prabhu V.U., 2019, ARXIV190712917
   Prajwal KR, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1428, DOI 10.1145/3343031.3351066
   Prenger R, 2019, INT CONF ACOUST SPEE, P3617, DOI [10.1109/ICASSP.2019.8683143, 10.1109/icassp.2019.8683143]
   Pumarola A, 2018, LECT NOTES COMPUT SC, V11214, P835, DOI 10.1007/978-3-030-01249-6_50
   Qian YC, 2019, PROC CVPR IEEE, P9843, DOI 10.1109/CVPR.2019.01008
   Qin Y., 2018, ARXIV PREPRINT ARXIV
   Qiu Haonan, 2019, ARXIV190607927
   Radford A., 2015, ARXIV151106434
   Rasheed A., ARXIV PREPRINT ARXIV
   Razavi A, 2019, ADV NEUR IN, V32
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Reed S, 2017, PR MACH LEARN RES, V70
   Reed S, 2016, PR MACH LEARN RES, V48
   Reimann C, 2000, ENVIRON GEOL, V39, P1001, DOI 10.1007/s002549900081
   Rezende Danilo Jimenez, 2014, ARXIV14014082
   Riaz S, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104020
   Roldán V, 2015, AM J MED, V128, P1237, DOI 10.1016/j.amjmed.2015.05.036
   Rosca M., 2017, Variational approaches for auto-encoding generative adversarial networks
   Roth K, 2017, ADV NEUR IN, V30
   Salimans T, 2016, ADV NEUR IN, V29
   Salimans Tim, 2017, ICLR
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Shamai G, 2019, ACM T MULTIM COMPUT, V15, DOI 10.1145/3337067
   Shen Yujun, 2020, P IEEE CVF C COMP VI, P9243, DOI DOI 10.1109/CVPR42600.2020.00926
   Smith K.E., 2020, ARXIV200616477
   Smith W.A., 2020, EUR C COMP VIS SPRIN, P690
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Spadoni F., 2007, P EVA, P11
   Speth J., 2019, CVPR WORKSH
   Stahl A, 2017, COMPUT PHYS COMMUN, V212, P269, DOI 10.1016/j.cpc.2016.10.024
   STANISWALIS JG, 1989, J AM STAT ASSOC, V84, P276, DOI 10.2307/2289874
   Stone Z, 2010, P IEEE, V98, P1408, DOI 10.1109/JPROC.2010.2044551
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Tanchenko A, 2014, J VIS COMMUN IMAGE R, V25, P874, DOI 10.1016/j.jvcir.2014.01.008
   Tang H., 2018, P AS C COMP VIS ACCV, P3
   Tellamekala Mani Kumar, 2019, INT CONF AFFECT, P1
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Trân AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   Tran L, 2019, IEEE T PATTERN ANAL, V41, P3007, DOI 10.1109/TPAMI.2018.2868350
   Truong K. T., 2018, VIDEO BASED FACE REC
   Turaga DS, 2004, SIGNAL PROCESS-IMAGE, V19, P173, DOI 10.1016/j.image.2003.09.001
   Ulyanov Dmitry, 2016, arXiv
   Usman B, 2019, IEEE I CONF COMP VIS, P9449, DOI 10.1109/ICCV.2019.00954
   van den Oord A, 2016, ADV NEUR IN, V29
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Venkatesh YV, 2012, PATTERN RECOGN LETT, V33, P1785, DOI 10.1016/j.patrec.2012.05.015
   WALLACH D, 1989, ECOL MODEL, V44, P299, DOI 10.1016/0304-3800(89)90035-5
   Wang H., ARXIV PREPRINT ARXIV
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang JR, 2019, IEEE ACCESS, V7, P111168, DOI 10.1109/ACCESS.2019.2924003
   Wang Rui, 2020, Res Sq, DOI 10.21203/rs.3.rs-49671/v1
   Wang S.-Y., 2020, CVPR, P8695
   Wang WS, 2019, IEEE T VEH TECHNOL, V68, P11679, DOI 10.1109/TVT.2019.2948911
   Wang ZH, 2021, IEEE T PATTERN ANAL, V43, P3365, DOI 10.1109/TPAMI.2020.2982166
   Wang Zhuoran, 2017, P C EMP METH NAT LAN, P617, DOI [DOI 10.18653/V1/D17-1065, 10.18653/v1/D17-1065]
   Wang ZW, 2018, PROC CVPR IEEE, P7939, DOI 10.1109/CVPR.2018.00828
   Wen Y., 2019, Advances in Neural Information Processing Systems, P5266
   Weng L., Flow-Based Deep Generative Models
   Wiatrak M., 2019, ARXIV191000927
   Williams B. L., 1989, US Patent, Patent No. [4,868,866, 4868866]
   Wu FZ, 2019, PATTERN RECOGN LETT, V125, P766, DOI 10.1016/j.patrec.2019.07.017
   Wu G, 2005, IEEE T KNOWL DATA EN, V17, P786, DOI 10.1109/TKDE.2005.95
   Wu Zheng, 2019, Advanced Technology of Electrical Engineering and Energy, V38, P1, DOI 10.12067/ATEEE1808029
   Xuan-Phung Huynh, 2016, International Conference on Information Science and Applications (ICISA) 2016. LNEE 376, P441, DOI 10.1007/978-981-10-0557-2_44
   Yamaguchi S, 2018, ACM T GRAPH TOG, V37, P1
   Yang C., BMVC 2018, P110
   Yang C, 2019, IEEE T IMAGE PROCESS, V28, P4845, DOI 10.1109/TIP.2019.2914583
   Yang ZC, 2018, 32 C NEURAL INFORM P, V31
   Yanga Y., ARXIV PREPRINT ARXIV
   Yeh RA, 2017, PROC CVPR IEEE, P6882, DOI 10.1109/CVPR.2017.728
   Yin XX, 2017, HEALTH INFOR SCI, P1, DOI [10.1109/ICCV.2017.430, 10.1007/978-3-319-57027-3_1]
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu SQ, 2017, IEEE COMPUT SOC CONF, P532, DOI 10.1109/CVPRW.2017.80
   Yuan XW, 2019, IEEE I CONF COMP VIS, P10061, DOI 10.1109/ICCV.2019.01016
   Zafeiriou S, 2017, IEEE COMPUT SOC CONF, P1980, DOI 10.1109/CVPRW.2017.248
   Zhang G, 2018, LECT NOTES COMPUT SC, V11210, P422, DOI 10.1007/978-3-030-01231-1_26
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Y., ARXIV PREPRINT ARXIV
   Zhao Y, 2018, IEEE ACCESS, V6, P60478, DOI 10.1109/ACCESS.2018.2872060
   Zhou J., 2020, HEART SOUND SEGMENTA
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
   Zhou YQ, 2017, INT CONF AFFECT, P370, DOI 10.1109/ACII.2017.8273626
   Zhu D., 2018, NEGATIVE LOG LIKELIH
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Y., IMAGE VISION COMPUT, V104, DOI [10.1016/j. imavis.2020.104023, 2020, DOI 10.1016/J.IMAVIS.2020.104023,2020]
NR 260
TC 20
Z9 20
U1 4
U2 42
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104119
DI 10.1016/j.imavis.2021.104119
EA MAR 2021
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600007
DA 2024-07-18
ER

PT J
AU Nguyen-Meidine, L
   Belal, A
   Kiran, M
   Dolz, J
   Blais-Morin, LA
   Granger, E
AF Nguyen-Meidine, Le Thanh
   Belal, Atif
   Kiran, Madhu
   Dolz, Jose
   Blais-Morin, Louis-Antoine
   Granger, Eric
TI Knowledge distillation methods for efficient unsupervised adaptation
   across multiple domains
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Convolutional NNs; Knowledge distillation; Unsupervised
   domain adaptation; CNN acceleration and compression
AB Beyond the complexity of CNNs that require training on large annotated datasets, the domain shift between design and operational data has limited the adoption of CNNs in many real-world applications. For instance, in person re-identification, videos are captured over a distributed set of cameras with non-overlapping viewpoints. The shift between the source (e.g. lab setting) and target (e.g. cameras) domains may lead to a significant decline in recognition accuracy. Additionally, state-of-the-art CNNs may not be suitable for such real-time applications given their computational requirements. Although several techniques have recently been proposed to address domain shift problems through unsupervised domain adaptation (UDA), or to accelerate/compress CNNs through knowledge distillation (KD), we seek to simultaneously adapt and compress CNNs to generalize well across multiple target domains. In this paper, we propose a progressive KD approach for unsupervised single target DA (STDA) and multi-target DA (MTDA) of CNNs. Our method for KD-STDA adapts a CNN to a single target domain by distilling from a larger teacher CNN, trained on both target and source domain data in order to maintain its consistency with a common representation. This method is extended to address MTDA problems, where multiple teachers are used to distill multiple target domain knowledge to a common student CNN. A different target domain is assigned to each teacher model for UDA, and they alternatively distill their knowledge to the student model to preserve specificity of each target, instead of directly combining the knowledge from each teacher using fusion methods. Our proposed approach is compared against state-of-the-art methods for compression and STDA of CNNs on the Office31 and ImageClef-DA image classification datasets. It is also compared against stateof-the-art methods for MTDA on Digits, Office31, and OfficeHome. In both settings ? KD-STDA and KD-MTDA ? results indicate that our approach can achieve the highest level of accuracy across target domains, while requiring a comparable or lower CNN complexity. ? 2021 Published by Elsevier B.V.
C1 [Nguyen-Meidine, Le Thanh; Kiran, Madhu; Dolz, Jose; Granger, Eric] Ecole Technol Super, Lab Imagerie Vis & Intelligence Artificielle LIVI, Montreal, PQ, Canada.
   [Blais-Morin, Louis-Antoine] Genetec Inc, Montreal, PQ, Canada.
   [Belal, Atif] Aligarh Muslim Univ, Aligarh, Uttar Pradesh, India.
C3 University of Quebec; Ecole de Technologie Superieure - Canada; Aligarh
   Muslim University
RP Nguyen-Meidine, L (corresponding author), 1100 Notre Dame St W, Montreal, PQ H3C 1K3, Canada.
EM le-thanh.nguyen-meidine.1@ens.etsmtl.ca; abelal@myamu.ac.in;
   madhu.kiran.1@ens.etsmtl.ca; jose.dolz@etsmtl.ca;
   lablaismorin@genetec.com; eric.granger@etsmtl.ca
RI Belal, Atif/CAF-5285-2022; Dolz, Jose/Y-5756-2019
OI Dolz, Jose/0000-0002-2436-7750; Granger, Eric/0000-0001-6116-7945
FU Mathematics of Information Technology and Complex Systems (MITACS);
   Natural Sciences and Engineering Research Council of Canada (NSERC)
FX This research was partially supported by the Mathematics of Information
   Technology and Complex Systems (MITACS) and the Natural Sciences and
   Engineering Research Council of Canada (NSERC) organizations.
CR Allen-Zhu Z., 2019, NIPS
   [Anonymous], 2019, CoRR
   Benaim Sagie, 2017, Advances in neural information processing systems, P752
   Bousmalis K., 2016, Unsupervised pixel-level domain adaptation with generative adversarial networks
   Chen ZL, 2019, PROC CVPR IEEE, P2243, DOI 10.1109/CVPR.2019.00235
   Dean J., 2015, NIPS DEEP LEARNING R
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004
   Dong X., 2019, NIPS
   Franco J, 2021, PHYSIOTHER THEOR PR, V37, P1419, DOI 10.1080/09593985.2019.1709234
   Fu H, 2019, PROC CVPR IEEE, P2422, DOI [10.1109/CVPR.2019.00253, 10.1109/cvpr.2019.00253]
   Ganin Y., 2015, PRLM
   Ganin Yaroslav, 2016, JMLR, V17, P2096, DOI DOI 10.1007/978-3-319-58347-1_10
   Gholami B., 2018, CORR
   Han, 2015, LEARNING BOTH WEIGHT
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Heo Byeongho, 2019, ICCV
   Hoffman J., 2018, PMLR
   Hong WX, 2018, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2018.00145
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jaderberg M., 2014, CORR
   LeCun Y., CORTES MNIST HANDWRI
   Li D, 2017, IEEE I CONF COMP VIS, P5543, DOI 10.1109/ICCV.2017.591
   Li Y., 2016, ICLR, P1, DOI DOI 10.48550/ARXIV.1511.05493
   Liu Z., 2019, ICLR
   Liu Z., 2020, ICPR
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Long MJ, 2018, METALS-BASEL, V8, DOI 10.3390/met8030182
   Ma Xinhong, 2019, P IEEE CVF C COMP VI
   Mekhazni Djebril, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P159, DOI 10.1007/978-3-030-58583-9_10
   Molchanov P, 2019, PROC CVPR IEEE, P11256, DOI 10.1109/CVPR.2019.01152
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Nguyen-Meidine L.T., 2020, IJCNN
   Orbes-Arteaga M., 2019, ARXIV190807355
   Orbes-Arteainst M, 2019, LECT NOTES COMPUT SC, V11796, P68, DOI 10.1007/978-3-030-32695-1_8
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Peng X., 2019, INT C MACH LEARN, P5102
   Ruder S, 2017, arXiv preprint arXiv:1706.05098
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Saito K., 2017, PMLR
   Shen Jian, 2017, 27 INT C FIELD PROGR, DOI [DOI 10.23919/FPL.2017.8056853, 10.23919/ FPL.2017.8056853]
   Singh P, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103857
   Stock P., 2020, ICLR UNPUB
   Tian Q, 2018, IMAGE VISION COMPUT, V77, P45, DOI 10.1016/j.imavis.2018.06.008
   Toldo M, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103889
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wei K.-Y., 2018, BMVC, P100
   Wen W, 2017, IEEE I CONF COMP VIS, P658, DOI 10.1109/ICCV.2017.78
   Yu C., 2019, ARXIV190901700
   Zhang Y, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103974
   Zhao R., 2019, PMLR
NR 51
TC 10
Z9 10
U1 6
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104096
DI 10.1016/j.imavis.2021.104096
EA FEB 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zong, M
   Wang, RL
   Chen, XB
   Chen, Z
   Gong, YH
AF Zong, Ming
   Wang, Ruili
   Chen, Xiubo
   Chen, Zhe
   Gong, Yuanhao
TI Motion saliency based multi-stream multiplier ResNets for action
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Motion saliency; Spatiotemporal interactive
   information; Multiplicative connections
ID NETWORK; CURVATURE
AB In this paper, we propose a Motion Saliency based multi-stream Multiplier ResNets (MSM-ResNets) for action recognition. The proposed MSM-ResNets model consists of three interactive streams: the appearance stream, motion stream and motion saliency stream. Similar to conventional two-stream CNNs models, the appearance stream and motion stream are responsible for capturing the appearance information and motion information, re-spectively, while the motion saliency stream is responsible for capturing the salient motion information. In par-ticular, to effectively utilize the spatiotemporal interactive information between different streams, the proposed MSM-ResNets model establishes interactive connections between different streams instead of fusing three streams at the final output layer. Two kinds of different multiplicative connections are injected, the first one is to inject multiplicative connections from the motion stream to the appearance stream, while the second one is to inject multiplicative connections from the motion saliency stream to the motion stream. Experimental results verify the effectiveness of the proposed MSM-ResNets on two standard action recognition datasets: UCF101 and HMDB51. ? 2021 Elsevier B.V. All rights reserved.
C1 [Zong, Ming; Wang, Ruili] Massey Univ, Sch Nat & Computat Sci, Auckland, New Zealand.
   [Chen, Xiubo] Beijing Univ Posts & Telecommun, Informat Secur Ctr, State Key Lab Networking & Switching Technol, Beijing, Peoples R China.
   [Chen, Zhe] Hohai Univ, Coll Comp & Informat, Nanjing, Peoples R China.
   [Gong, Yuanhao] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen, Guangdong, Peoples R China.
C3 Massey University; Beijing University of Posts & Telecommunications;
   Hohai University; Shenzhen University
RP Wang, RL (corresponding author), Massey Univ, Sch Nat & Computat Sci, Auckland, New Zealand.
EM Ruili.wang@massey.ac.nz
RI Gong, Yuanhao/AAD-1736-2020
OI Gong, Yuanhao/0000-0001-5702-1927
FU National Key R&D Program of China [2018YFC1508603]; National Natural
   Science Foundation of China [61907031, 62073120]; Natural Science
   Foundation of Jiangsu Province [SBK2020022539]; Fundamental Research
   Funds for the Central Universities [B200202181]; China Scholarship
   Council (CSC); New Zealand China Doctoral Research Scholarship
FX This work was in part Supported by the National Key R&D Program of China
   under Grant 2018YFC1508603, the National Natural Science Foundation of
   China under Grants 61907031 and 62073120, Natural Science Foundation of
   Jiangsu Province SBK2020022539, Fundamental Research Funds for the
   Central Universities B200202181, the China Scholarship Council (CSC) ,
   and the New Zealand China Doctoral Research Scholarship.
CR [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen Z, 2019, INFORM SCIENCES, V483, P65, DOI 10.1016/j.ins.2018.12.047
   Chen Z, 2016, OPT LASER TECHNOL, V80, P1, DOI 10.1016/j.optlastec.2015.12.013
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2018, PROC CVPR IEEE, P7844, DOI 10.1109/CVPR.2018.00818
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong YH, 2019, SIGNAL PROCESS, V164, P329, DOI 10.1016/j.sigpro.2019.06.020
   Gong YH, 2019, IEEE T CIRC SYST VID, V29, P2205, DOI 10.1109/TCSVT.2018.2866866
   Gong YH, 2017, IEEE T IMAGE PROCESS, V26, P1786, DOI 10.1109/TIP.2017.2658954
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kay W., 2017, CORR ABS170506950
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Liu Z., 2019, AS C PATT REC, P74
   Liu Z, 2020, NANO SEL, V1, P244, DOI 10.1002/nano.202000011
   Maczyta L, 2019, PATTERN RECOGN LETT, V128, P298, DOI 10.1016/j.patrec.2019.09.016
   Shamsolmoali P, 2021, IEEE T GEOSCI REMOTE, V59, P4673, DOI 10.1109/TGRS.2020.3016086
   Shamsolmoali P, 2019, SIGNAL PROCESS-IMAGE, V79, P13, DOI 10.1016/j.image.2019.08.008
   Shamsolmoali P, 2019, NEUROCOMPUTING, V366, P140, DOI 10.1016/j.neucom.2019.07.094
   Shamsolmoali P, 2019, IEEE J-STARS, V12, P3219, DOI 10.1109/JSTARS.2019.2925841
   Simonyan K, 2014, ADV NEUR IN, V27
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian CW, 2020, KNOWL-BASED SYST, V205, DOI 10.1016/j.knosys.2020.106235
   Tian Y, 2022, IEEE T INTELL TRANSP, V23, P165, DOI 10.1109/TITS.2020.3009000
   Tian Y, 2020, NEUROCOMPUTING, V417, P202, DOI 10.1016/j.neucom.2020.07.078
   Tian Y, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107158
   Tian Y, 2019, IEEE T INTELL TRANSP, V20, P4466, DOI 10.1109/TITS.2018.2886283
   Tian Y, 2019, J ARTIF INTELL RES, V64, P181, DOI 10.1613/jair.1.11338
   Tian Y, 2018, NEUROCOMPUTING, V318, P297, DOI 10.1016/j.neucom.2018.08.067
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Varol G, 2018, IEEE T PATTERN ANAL, V40, P1510, DOI 10.1109/TPAMI.2017.2712608
   Wang DH, 2017, INFORM SCIENCES, V417, P55, DOI 10.1016/j.ins.2017.07.003
   Wang DH, 2017, IEEE T CYBERNETICS, V47, P3466, DOI 10.1109/TCYB.2017.2734043
   Wang HH, 2017, IEEE T CYBERNETICS, V47, P3568, DOI 10.1109/TCYB.2016.2570808
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   You BD, 2018, PROCEEDINGS OF 2018 2ND INTERNATIONAL CONFERENCE ON DIGITAL TECHNOLOGY IN EDUCATION (ICDTE 2018), P1, DOI 10.1145/3284497.3284498
   Zhang SC, 2018, IEEE T NEUR NET LEAR, V29, P1774, DOI 10.1109/TNNLS.2017.2673241
   Zhang YS, 2020, IEEE T MULTIMEDIA, V22, P2844, DOI 10.1109/TMM.2020.2966887
   Zheng H, 2020, INFORM SCIENCES, V533, P60, DOI 10.1016/j.ins.2020.04.041
   Zhu XF, 2020, WORLD WIDE WEB, V23, P1969, DOI 10.1007/s11280-019-00731-8
   Zong M, 2021, NEURAL COMPUT APPL, V33, P5167, DOI 10.1007/s00521-020-05313-8
NR 52
TC 33
Z9 33
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104108
DI 10.1016/j.imavis.2021.104108
EA JAN 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RD1DC
UT WOS:000633227000006
DA 2024-07-18
ER

PT J
AU Zhou, L
   Shao, XY
   Mao, QR
AF Zhou, Ling
   Shao, Xiuyan
   Mao, Qirong
TI A survey of micro-expression recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Micro-expression recognition; Deep learning; Micro-expression datasets;
   Survey
ID OPTICAL-FLOW; DYNAMICS; FEATURES; MODEL
AB The limited capacity to recognize micro-expressions with subtle and rapid motion changes is a long-standing problem that presents a unique challenge for expression recognition systems and even for humans. The problem regarding micro-expression is less covered by research when compared to macro-expression. Nevertheless, micro-expression recognition (MER) is imperative to exploit the full potential of expression recognition for real-world applications. Recent MER systems generally focus on three important issues: overfitting caused by a lack of sufficient training data, the imbalanced distribution of samples, and robust features for improving the accuracy of recognition. In this paper, we provide a comprehensive survey on MER, including datasets and algorithms that provide insights into these intrinsic problems. First, we introduce the available datasets that are widely used in the literature. We then describe the pre-processing in the standard pipeline of an MER system. For the state of the art in MER, we divide the existing novel algorithms into 6 different tasks according to the type of classes and evaluation protocols. Detailed experiment settings and competitive performances for those 6 tasks are summarized in this section. Finally, we review the remaining challenges and corresponding opportunities in this field as well as future directions for the design of robust MER systems. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zhou, Ling] Jiangsu Univ, Sch Comp Sci & Commun Engn, Zhenjiang, Jiangsu, Peoples R China.
   [Shao, Xiuyan] Southeast Univ, Nanjing, Jiangsu, Peoples R China.
   [Mao, Qirong] Jiangsu Univ, Jiangsu Engn Res Ctr, Sch Comp Sci & Commun Engn, Big Data Ubiquitous Percept & Intelligent Agr App, Zhenjiang, Jiangsu, Peoples R China.
C3 Jiangsu University; Southeast University - China; Jiangsu University
RP Mao, QR (corresponding author), Jiangsu Univ, Jiangsu Engn Res Ctr, Sch Comp Sci & Commun Engn, Big Data Ubiquitous Percept & Intelligent Agr App, Zhenjiang, Jiangsu, Peoples R China.
EM 2111808003@stmail.ujs.edu.cn; xitiyan_shao@seu.edu.cn; mao_qr@ujs.edu.cn
FU National Natural Science Foundation of China [61672267, U1836220];
   Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [KYCX19 1616]; Qing Lan Talent Programof Jiangsu Province; Jiangsu
   Engineering Research Center of big data ubiquitous perception and
   intelligent agriculture applications; National Natural Science
   Foundation of China, Zhishan Youth Scholar Program of Southeast
   University [72001040]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61672267, Grant U1836220, in part by the
   Postgraduate Research & Practice Innovation Program of Jiangsu Province
   under Grant KYCX19 1616, Qing Lan Talent Programof Jiangsu Province,
   Jiangsu Engineering Research Center of big data ubiquitous perception
   and intelligent agriculture applications, and the National Natural
   Science Foundation of China under Grant 72001040, Zhishan Youth Scholar
   Program of Southeast University.
CR Aifanti N., 2010, P 11 INT WORKSH IM A, DOI DOI 10.1371/JOURNAL.PONE.0009715
   Allaert B, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 5, P235, DOI 10.5220/0006127402350242
   Ngo ACL, 2017, IEEE T AFFECT COMPUT, V8, P396, DOI 10.1109/TAFFC.2016.2523996
   Ngo ACL, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1246, DOI 10.1109/ICDSP.2015.7252080
   Ngo ACL, 2016, INT CONF ACOUST SPEE, P1243, DOI 10.1109/ICASSP.2016.7471875
   Annoni J, 2016, IEEE DECIS CONTR P, P6506, DOI 10.1109/CDC.2016.7799270
   [Anonymous], 2016, CORR
   [Anonymous], 2014, Proceedings of the Asian Conference on Computer Vision
   [Anonymous], 2012, UCF101 DATASET 101 H
   [Anonymous], 2019, P INT C AUT FAC GEST
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Barron J. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P236, DOI 10.1109/CVPR.1992.223269
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Davison AK, 2018, J IMAGING, V4, DOI 10.3390/jimaging4100119
   Davison AK, 2018, IEEE T AFFECT COMPUT, V9, P116, DOI 10.1109/TAFFC.2016.2573832
   Davison C, 2014, TRANSLATION AS COLLABORATION: VIRGINIA WOOLF, KATHERINE MANSFIELD AND S. S. KOTELIANSKY, P111
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Duque CA, 2020, PATTERN RECOGN LETT, V135, P382, DOI 10.1016/j.patrec.2020.05.008
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Ekman P., 2009, TELLING LIES CLUES D
   Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630
   Fangbing Qu, 2018, IEEE Transactions on Affective Computing, V9, P424, DOI 10.1109/TAFFC.2017.2654440
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Fu X., 2013, P 2013 INT C WORKSHO, P1
   Gan YS, 2019, SIGNAL PROCESS-IMAGE, V74, P129, DOI 10.1016/j.image.2019.02.005
   Goh KM, 2020, VISUAL COMPUT, V36, P445, DOI 10.1007/s00371-018-1607-6
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He JC, 2017, PATTERN RECOGN, V66, P44, DOI 10.1016/j.patcog.2016.11.029
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang XH, 2019, IEEE T AFFECT COMPUT, V10, P32, DOI 10.1109/TAFFC.2017.2713359
   Huang XH, 2017, 2017 INTERNATIONAL CONFERENCE ON THE FRONTIERS AND ADVANCES IN DATA SCIENCE (FADS), P198, DOI 10.1109/FADS.2017.8253219
   Huang XH, 2016, NEUROCOMPUTING, V175, P564, DOI 10.1016/j.neucom.2015.10.096
   Husak J.M. Petr, 2017, P 2017 COMP VIS WINT
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jain DK, 2018, PATTERN RECOGN LETT, V115, P92, DOI 10.1016/j.patrec.2018.02.004
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Khor HQ, 2018, IEEE INT CONF AUTOMA, P667, DOI 10.1109/FG.2018.00105
   Kim DH, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P382, DOI 10.1145/2964284.2967247
   Le Ngo AC, 2018, IEEE INT CONF AUTOMA, P650, DOI 10.1109/FG.2018.00102
   Li J, 2019, PATTERN ANAL APPL, V22, P1331, DOI 10.1007/s10044-018-0757-5
   Li K., 2019, Austral. J. Intell. Inf. Process. Syst., V15, P41
   Li X., 2017, IEEE Transactions on Affective Computing
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Li YT, 2018, IEEE IMAGE PROC, P3094, DOI 10.1109/ICIP.2018.8451376
   Liong S., 2019, P 2019 IEEE INT C AU, P1
   Liong S., 2019, CORR
   Liong ST, 2018, SIGNAL PROCESS-IMAGE, V62, P82, DOI 10.1016/j.image.2017.11.006
   Liong ST, 2017, ASIAPAC SIGN INFO PR, P534, DOI 10.1109/APSIPA.2017.8282090
   Liong ST, 2014, I S INTELL SIG PROC, P180, DOI 10.1109/ISPACS.2014.7024448
   Liong ST, 2015, LECT NOTES COMPUT SC, V9009, P644, DOI 10.1007/978-3-319-16631-5_47
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Liu Y, 2019, ADV CIV ENG, V2019, DOI 10.1155/2019/5205276
   Lo L., 2020, CORR
   Lu H, 2018, SIGNAL PROCESS-IMAGE, V67, P108, DOI 10.1016/j.image.2018.05.014
   Lu ZY, 2014, INT CONF COMM SYST, P690, DOI 10.1109/CSNT.2014.145
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Nag S, 2019, INT CONF ACOUST SPEE, P2022, DOI 10.1109/ICASSP.2019.8683737
   Oh YH, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01128
   Päivärinta J, 2011, LECT NOTES COMPUT SC, V6688, P360, DOI 10.1007/978-3-642-21227-7_34
   Park SY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P911, DOI 10.1145/2733373.2806362
   Peng M, 2018, IEEE INT CONF AUTOMA, P657, DOI 10.1109/FG.2018.00103
   Peng M, 2017, FRONT PSYCHOL, V8, DOI 10.3389/fpsyg.2017.01745
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018
   POLIKOVSKY S., 2009, 3 INT C IM CRIM DET, P1, DOI [10.1049/ic.2009.0244, DOI 10.1049/IC.2009.0244]
   Polikovsky S, 2013, IEICE T INF SYST, VE96D, P81, DOI 10.1587/transinf.E96.D.81
   Reddy S.P.T., 2019, CORR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   See J, 2019, IEEE INT CONF AUTOMA, P647
   Senst T, 2012, IEEE T CIRC SYST VID, V22, P1377, DOI 10.1109/TCSVT.2012.2202070
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sun K, 2019, ARXIV190805081
   Szegedy C., 2015, P 2015 INT C COMPUTE, P1
   Takalkar M, 2018, MULTIMED TOOLS APPL, V77, P19301, DOI 10.1007/s11042-017-5317-2
   Verma M., 2020, CORR
   Verma M, 2020, IEEE T IMAGE PROCESS, V29, P1618, DOI 10.1109/TIP.2019.2912358
   Wang SJ, 2018, NEUROCOMPUTING, V312, P251, DOI 10.1016/j.neucom.2018.05.107
   Wang SJ, 2016, NEUROCOMPUTING, V214, P218, DOI 10.1016/j.neucom.2016.05.083
   Wang SJ, 2015, IEEE T IMAGE PROCESS, V24, P6034, DOI 10.1109/TIP.2015.2496314
   Wang SJ, 2015, LECT NOTES COMPUT SC, V8925, P325, DOI 10.1007/978-3-319-16178-5_23
   Wang SJ, 2014, INT C PATT RECOG, P4678, DOI 10.1109/ICPR.2014.800
   Wang Y., LECT NOTES COMPUTER, V11961, P266
   Wang YD, 2017, MULTIMED TOOLS APPL, V76, P21665, DOI 10.1007/s11042-016-4079-6
   Wang YD, 2015, LECT NOTES COMPUT SC, V9003, P525, DOI 10.1007/978-3-319-16865-4_34
   Wang Y, 2015, PLOS ONE, V10, DOI [10.1371/journal.pone.0138035, 10.1371/journal.pone.0124566, 10.1371/journal.pone.0116359]
   Wu HY, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185561
   Wu Q, 2011, LECT NOTES COMPUT SC, V6975, P152, DOI 10.1007/978-3-642-24571-8_16
   Xia Z., 2020, CORR
   Xia Z., 2019, P 3 INT C BIOM ENG A, P56
   Xia ZQ, 2020, IEEE T MULTIMEDIA, V22, P626, DOI 10.1109/TMM.2019.2931351
   Xu F, 2017, IEEE T AFFECT COMPUT, V8, P254, DOI 10.1109/TAFFC.2016.2518162
   Yan WJ, 2015, LECT NOTES COMPUT SC, V8925, P296, DOI 10.1007/978-3-319-16178-5_20
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yap MH, 2018, IEEE INT CONF AUTOMA, P675, DOI 10.1109/FG.2018.00106
   Yu J., 2020, ARXIV200504370
   Yu Y, 2018, J INTELL FUZZY SYST, V35, P4773, DOI 10.3233/JIFS-172307
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
   Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58
   Zhou L, 2019, IEEE INT CONF MULTI, P102, DOI 10.1109/ICMEW.2019.00025
   Zhou LT, 2019, INT WORK CONTENT MUL
   Zhou ZH, 2011, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.2011.5995345
   Zong Y, 2019, ICMR'19: PROCEEDINGS OF THE 2019 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P354, DOI 10.1145/3323873.3326590
   Zong Y, 2018, IEEE T MULTIMEDIA, V20, P3160, DOI 10.1109/TMM.2018.2820321
   Zong Y, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P872, DOI 10.1145/3123266.3123367
   Zong Y, 2018, IEEE T IMAGE PROCESS, V27, P2484, DOI 10.1109/TIP.2018.2797479
NR 112
TC 21
Z9 22
U1 4
U2 84
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104043
DI 10.1016/j.imavis.2020.104043
EA JAN 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800002
DA 2024-07-18
ER

PT J
AU Esfahani, MA
   Wu, KY
   Yuan, SH
   Wang, H
AF Esfahani, Mandi Abolfazli
   Wu, Keyu
   Yuan, Shenghai
   Wang, Han
TI DeepDSAIR: Deep 6-DOF camera relocalization using deblurred
   semantic-aware image representation for large-scale outdoor environments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep Neural Network (DNN); Convolutional Neural Network (CNN); Camera
   relocalization; Pose regression; Loop closure; Visual odometry
ID LOCALIZATION; RECOGNITION; NETWORKS; BAGS
AB Deep Learning methods can deploy a fast, robust and lightweight model to solve the problem of 6-DOF camera relocalization in large-scale outdoor environments. However, two significant characteristics of captured images in a large-scale outdoor environment are moving objects, which should not include in the representation of an environment, and also motion blur which widely exists in the images captured with moving cameras. None of the existing approaches study and investigate these two problems in their method. This paper, for the first time, proposes a deep network architecture that is trained based on the knowledge achieved by combining deblurring and semantic segmentation modules and examines the effect of this combination on a challenging dataset. Results show approximately 20 and 50% improvement in camera position and orientation re-localization error respectively. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Esfahani, Mandi Abolfazli; Wu, Keyu; Yuan, Shenghai; Wang, Han] Nanyang Technol Univ, Dept Elect & Elect Engn, Singapore, Singapore.
C3 Nanyang Technological University
RP Wang, H (corresponding author), Nanyang Technol Univ, Dept Elect & Elect Engn, Singapore, Singapore.
EM mahdi001@ntu.edu.sg; wukeyu@ntu.edu.sg; syuan003@ntu.edu.sg;
   hw@ntu.edu.sg
RI han, wang/GXV-3286-2022; Wang, Han/GPW-9809-2022; Wang, Han/A-5016-2011;
   Yuan, Shenghai/JDM-6241-2023; han, wang/GXV-3327-2022
OI Wang, Han/0000-0001-5448-9903; Yuan, Shenghai/0009-0003-1887-6342; 
CR Alehdaghi M, 2015, 2015 5TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P295, DOI 10.1109/ICCKE.2015.7365845
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, P ICCV OCT
   [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.322
   [Anonymous], 2018, ARXIV180610556
   [Anonymous], 2014, ARXIV14111509
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2018, P IEEE C COMPUTER VI
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, P ROBOTICS SCI SYSTE
   [Anonymous], P AS C COMP VIS
   [Anonymous], 2018, ARXIV180509806
   [Anonymous], ROBOTICS SCI SYSTEMS
   [Anonymous], 2017, INTEGRAL METHODS SCI, DOI DOI 10.1007/978-3-319-59387-6_6
   Arandjelovic R, 2018, IEEE T PATTERN ANAL, V40, P1437, DOI [10.1109/TPAMI.2017.2711011, 10.1109/CVPR.2016.572]
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Boateng P, 2017, MEGAPROJECT RISK ANALYSIS AND SIMULATION: A DYNAMIC SYSTEMS APPROACH, P223
   Cao S, 2014, PROC CVPR IEEE, P461, DOI 10.1109/CVPR.2014.66
   Cao S, 2013, PROC CVPR IEEE, P700, DOI 10.1109/CVPR.2013.96
   Cummins M, 2008, INT J ROBOT RES, V27, P647, DOI 10.1177/0278364908090961
   Cupec R, 2015, INT J ROBOT RES, V34, P674, DOI 10.1177/0278364914548708
   Donoser M, 2014, PROC CVPR IEEE, P516, DOI 10.1109/CVPR.2014.73
   Esfahani MA, 2018, IEEE INT CONF CON AU, P81, DOI 10.1109/ICCA.2018.8444299
   Esfahani MA, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420550022
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gálvez-López D, 2012, IEEE T ROBOT, V28, P1188, DOI 10.1109/TRO.2012.2197158
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goldstein A, 2012, LECT NOTES COMPUT SC, V7576, P622, DOI 10.1007/978-3-642-33715-4_45
   Gronát P, 2013, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2013.122
   Guzman-Rivera A, 2014, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR.2014.146
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Kendall A, 2016, IEEE INT CONF ROBOT, P4762, DOI 10.1109/ICRA.2016.7487679
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Kukelova Z, 2013, IEEE I CONF COMP VIS, P2816, DOI 10.1109/ICCV.2013.350
   Li PL, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P11, DOI 10.1109/ISMAR.2017.18
   Li RH, 2018, IEEE T AUTOM SCI ENG, V15, P651, DOI 10.1109/TASE.2017.2664920
   Li YP, 2012, LECT NOTES COMPUT SC, V7572, P15, DOI 10.1007/978-3-642-33718-5_2
   Li YP, 2010, LECT NOTES COMPUT SC, V6312, P791
   Lim H, 2012, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2012.6247782
   Liu PD, 2017, IEEE INT C INT ROBOT, P1746, DOI 10.1109/IROS.2017.8205988
   Looser S, 2017, CSR SUSTAIN ETHIC, P3, DOI 10.1007/978-3-319-52839-7_1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Mur-Artal R, 2014, IEEE INT CONF ROBOT, P846, DOI 10.1109/ICRA.2014.6906953
   Paszke A., 2017, NIPS W
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sattler T, 2017, PROC CVPR IEEE, P6175, DOI 10.1109/CVPR.2017.654
   Sattler T, 2016, PROC CVPR IEEE, P1582, DOI 10.1109/CVPR.2016.175
   Sattler T, 2015, IEEE I CONF COMP VIS, P2102, DOI 10.1109/ICCV.2015.243
   Sattler T, 2011, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2011.6126302
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Sünderhauf N, 2015, IEEE INT C INT ROBOT, P4297, DOI 10.1109/IROS.2015.7353986
   Svärm L, 2017, IEEE T PATTERN ANAL, V39, P1455, DOI 10.1109/TPAMI.2016.2598331
   Tao X, 2018, PROC CVPR IEEE, P8174, DOI 10.1109/CVPR.2018.00853
   Torii A, 2013, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2013.119
   Walch F, 2017, IEEE I CONF COMP VIS, P627, DOI 10.1109/ICCV.2017.75
   Wang S, 2017, INT CONF ACOUST SPEE, P436, DOI 10.1109/ICASSP.2017.7952193
   Weyand T, 2016, LECT NOTES COMPUT SC, V9912, P37, DOI 10.1007/978-3-319-46484-8_3
   Williams B, 2009, ROBOT AUTON SYST, V57, P1188, DOI 10.1016/j.robot.2009.06.010
   Zamir AR, 2014, IEEE T PATTERN ANAL, V36, P1546, DOI 10.1109/TPAMI.2014.2299799
   Zamir AR, 2010, LECT NOTES COMPUT SC, V6314, P255, DOI 10.1007/978-3-642-15561-1_19
   Zhang W, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P33, DOI 10.1109/3dpvt.2006.80
   Zhou BL, 2014, ADV NEUR IN, V27
NR 66
TC 8
Z9 8
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 120
EP 130
DI 10.1016/j.imavis.2019.06.014
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900011
DA 2024-07-18
ER

PT J
AU Nayak, SR
   Mishra, J
   Palai, G
AF Nayak, Soumya Ranjan
   Mishra, Jibitesh
   Palai, Gopinath
TI Analysing roughness of surface through fractal dimension: A review
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Fractal dimension; Box counting method; Dividers method; Probability
   density function; Color fractal dimension
ID BOX-COUNTING METHOD; MAGNETIC-RESONANCE IMAGES; TRABECULAR
   BONE-STRUCTURE; TEXTURE ANALYSIS; CEREBRAL-CORTEX; WHITE-MATTER; BREAST
   MASSES; CLASSIFICATION; IMPLEMENTATION; ALGORITHM
AB In last three decades, fractal geometry (FG) has been the focus of attention by several researchers owing to it exhibiting excellent properties and robust application with respect to current research scenario. Fractal Dimension (FD) plays a vital role in order to analyse complex objects that are found in nature which was failed to be analysed by Euclidian geometry. FD is an imperative aspect of FG to provide indicative application in different areas of research including image processing, pattern recognition, computer graphics and many more. Analysis of an image is an important technique of image processing to describe image features like texture, roughness, smoothness etc., and is only possible through FG. Due to this reason many more technique were evolved to estimate the fractal dimension. The main aim of this article is to give a comprehensive review, which summarizes recent research progress on analysis of surface roughness and an overview of different concepts, and the way they work and their benefits and their limitations, and also we deliver how the different concepts taken into consideration to estimate FD depend upon different algorithms. This article also discusses several factors affecting FD estimation; types of similarity property, spatial resolution, sampling process, region of interest, spectral band and box-height criteria are discussed. Furthermore, we have tried to present the application area oriented versus core area of FG. There are several contradictory results found in many kinds of literature on the influence of different parameters while conducting FD analysis. Mainly it has been observed that the FD estimation will be affected by texture property, gray scale range, color property, color distance and the other parameters which are already mentioned. Hence this article will be beneficial for researchers in order to select precise FD estimation. However different algorithms lead to different results even with the use of the same kind of database images, so selection of appropriate technique is a major challenge for accurate estimation. Therefore an in-depth and proper understanding is required in order to choose the appropriate algorithm and also a robust algorithm for analysing roughness in better and precise way needs to be developed. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Nayak, Soumya Ranjan] Chitkara Univ, Inst Engn & Technol, Rajpura 140401, Punjab, India.
   [Mishra, Jibitesh] Coll Engn & Technol, Techno Campus, Bhubaneswar 751029, Odisha, India.
   [Palai, Gopinath] Gandhi Inst Technol Adv, Dept Elect & Commun Engn, Bhubaneswar, India.
C3 Chitkara University, Punjab; Gandhi Institute For Technological
   Advancement
RP Palai, G (corresponding author), Gandhi Inst Technol Adv, Dept Elect & Commun Engn, Bhubaneswar, India.
EM soumya.nayak@chitkara.edu.in; jmishra@cet.edu.in; gpalai28@gmail.com
RI Nayak, Soumya Ranjan/S-5908-2018; Mishra, Jibitesh/AAV-1916-2021
OI Nayak, Soumya Ranjan/0000-0002-4155-884X; Mishra,
   Jibitesh/0000-0003-2761-470X
CR Ai T, 2014, APPL SURF SCI, V314, P610, DOI 10.1016/j.apsusc.2014.06.152
   Alevizos PD, 2010, INT J BIFURCAT CHAOS, V20, P4067, DOI 10.1142/S0218127410028197
   Ambika DR, 2011, INT J COMPUT APPL, V16, P45
   Anderson JL, 1997, J AM COLL CARDIOL, V30, P226, DOI 10.1016/S0735-1097(97)00108-3
   Annadhason A., 2012, INT J RES MANAGEMENT, V2, P110
   [Anonymous], COMPUT MATH METHODS
   [Anonymous], 2016, Perspect. Sci, DOI DOI 10.1016/J.PISC.2016.04.092
   [Anonymous], 1997, CHINESE SIGNAL PROCE
   [Anonymous], 2003, MEASUREMENT SCI REV
   Anulty P. M., 1992, PHYS REV A, V46, P63523
   Appleby S, 1996, GEOGR ANAL, V28, P147
   Asvestas P, 1998, J VIS COMMUN IMAGE R, V9, P392, DOI 10.1006/jvci.1998.0394
   Asvestas P, 1999, PATTERN RECOGN LETT, V20, P347, DOI 10.1016/S0167-8655(99)00004-5
   Babadagli T, 2001, FRACTALS, V9, P105, DOI 10.1142/S0218348X01000464
   Backes AR, 2009, INT J PATTERN RECOGN, V23, P1145, DOI 10.1142/S0218001409007508
   BARNSLEY MF, 1985, P ROY SOC LOND A MAT, V399, P243, DOI 10.1098/rspa.1985.0057
   BENHAMOU CL, 1994, J BONE MINER RES, V9, P1909
   Bisoi AK, 2001, PATTERN RECOGN LETT, V22, P631, DOI 10.1016/S0167-8655(00)00132-X
   Biswas MK, 1998, PATTERN RECOGN LETT, V19, P309, DOI 10.1016/S0167-8655(98)00002-6
   BOULIGAND G, 1929, B SCI MATH, V52, P185
   Buczkowski S, 1998, PATTERN RECOGN, V31, P411, DOI 10.1016/S0031-3203(97)00054-X
   BULLMORE E, 1994, PSYCHOL MED, V24, P771, DOI 10.1017/S0033291700027926
   CALDWELL CB, 1990, PHYS MED BIOL, V35, P235, DOI 10.1088/0031-9155/35/2/004
   Chang SJ, 2009, LECT NOTES ARTIF INT, V5773, P488, DOI 10.1007/978-3-642-04380-2_56
   Chappard D, 2001, BONE, V28, P72, DOI 10.1016/S8756-3282(00)00438-5
   CHAUDHURI BB, 1995, IEEE T PATTERN ANAL, V17, P72, DOI 10.1109/34.368149
   CHEN CC, 1989, IEEE T MED IMAGING, V8, P133, DOI 10.1109/42.24861
   CHEN SS, 1993, IEEE T PATTERN ANAL, V15, P1087, DOI 10.1109/34.254066
   Chen WS, 2003, OPT ENG, V42, P2452, DOI 10.1117/1.1585061
   Chung HW, 2002, J CEREBR BLOOD F MET, V22, P361, DOI 10.1097/00004647-200203000-00014
   CLARKE KC, 1986, COMPUT GEOSCI, V12, P713, DOI 10.1016/0098-3004(86)90047-6
   COOK MJ, 1995, EUR NEUROL, V35, P327, DOI 10.1159/000117155
   De Santis A., 1997, Ann. Geophys, V15, P811, DOI [10.4401/ag-3882, DOI 10.4401/AG-3882]
   Dong PL, 2008, ADV SPACE RES, V41, P1733, DOI 10.1016/j.asr.2007.04.090
   DUBUC B, 1989, PROC R SOC LON SER-A, V425, P113, DOI 10.1098/rspa.1989.0101
   Dubuc B., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V845, P241, DOI 10.1117/12.976511
   DUMITRESCU D, 1993, J MATH ANAL APPL, V176, P359, DOI 10.1006/jmaa.1993.1220
   Eshel A, 1998, PLANT CELL ENVIRON, V21, P247, DOI 10.1046/j.1365-3040.1998.00252.x
   Foroutan-pour K, 1999, APPL MATH COMPUT, V105, P195, DOI 10.1016/S0096-3003(98)10096-6
   Free SL, 1996, CEREB CORTEX, V6, P830, DOI 10.1093/cercor/6.6.830
   GAGNEPAIN JJ, 1986, WEAR, V109, P119, DOI 10.1016/0043-1648(86)90257-7
   Gong, 2005, GEOGRAPHIC INFORM SC, V11, P87
   Gonzato G, 1998, COMPUT GEOSCI, V24, P95, DOI 10.1016/S0098-3004(97)00137-4
   GOODCHILD MF, 1980, J INT ASS MATH GEOL, V12, P85, DOI 10.1007/BF01035241
   Górski AZ, 2006, J ANAT, V208, P353, DOI 10.1111/j.1469-7580.2006.00529.x
   GRASSBERGER P, 1993, INT J MOD PHYS C, V4, P515, DOI 10.1142/S0129183193000525
   Grossu IV, 2013, COMPUT PHYS COMMUN, V184, P1812, DOI 10.1016/j.cpc.2013.02.026
   Hasegawa M, 1996, WEAR, V192, P40, DOI 10.1016/0043-1648(95)06768-X
   Hearn D., COMPUTER GRAPHICS, P382
   HUANG ZH, 1990, SCRIPTA METALL MATER, V24, P967, DOI 10.1016/0956-716X(90)90284-N
   Iftekharuddin KM, 2003, MACH VISION APPL, V13, P352, DOI 10.1007/s00138-002-0087-9
   Iftekharuddin KM, 2000, P ANN INT IEEE EMBS, V22, P3064, DOI 10.1109/IEMBS.2000.901528
   IMRE A, 1992, SCRIPTA METALL MATER, V27, P1713, DOI 10.1016/0956-716X(92)90007-2
   Imre AR, 2004, ACTA BIOTHEOR, V52, P41, DOI 10.1023/B:ACBI.0000015911.56850.0f
   Ivanovici M, 2011, IEEE T IMAGE PROCESS, V20, P227, DOI 10.1109/TIP.2010.2059032
   JAGGI S, 1993, COMPUT GEOSCI, V19, P745, DOI 10.1016/0098-3004(93)90048-A
   Jennane R, 2007, MED IMAGE ANAL, V11, P91, DOI 10.1016/j.media.2006.11.001
   Jie Feng, 1996, Proceedings of the 13th International Conference on Pattern Recognition, P854, DOI 10.1109/ICPR.1996.547197
   JIN XC, 1995, PATTERN RECOGN LETT, V16, P457, DOI 10.1016/0167-8655(94)00119-N
   Jong S. M. D., 1995, ENG REMOTE SENS, V61, P1041
   Ju WX, 2009, COMPUT GEOSCI-UK, V35, P1224, DOI 10.1016/j.cageo.2008.09.008
   Kaewaramsri Y., 2015, RECENT ADV INFORM CO, VVolume 361, DOI [10.1007/978-3-319-19024-2_6, DOI 10.1007/978-3-319-19024-2_6]
   Kalmanti E, 2007, IN VIVO, V21, P641
   KEDZIA A, 2002, MED SCI MONITOR, V8, P46
   King RD, 2009, BRAIN IMAGING BEHAV, V3, P154, DOI 10.1007/s11682-008-9057-9
   Kolibal J, 1998, COMPUT GEOSCI, V24, P785, DOI 10.1016/S0098-3004(98)00063-6
   Kolmogoroff AN, 1940, CR ACAD SCI URSS, V26, P115
   Kotowski P, 2006, INT J FRACTURE, V141, P269, DOI 10.1007/s10704-006-8264-x
   Kruger A, 1996, COMPUT PHYS COMMUN, V98, P224, DOI 10.1016/0010-4655(96)00080-X
   Lai K, 2016, P IEEE 10 INT C SENS, P1
   Lam N. S. N., 1997, ACSM ASPRS ANN CONV, V5, P377
   Lam Nina Siu-Ngan, 2002, Cartogr. Geogr. Inf. Sci, V29, P25, DOI DOI 10.1559/152304002782064600
   LAM NSN, 1990, PHOTOGRAMM ENG REM S, V56, P187
   Lamani D., 2015, J IMAGE GRAPHICS SIG, V7, P9
   Lespessailles E, 1998, J BIOMECH, V31, P817, DOI 10.1016/S0021-9290(98)00074-8
   Li H, 1997, P IEEE EMBS, V18, P1111, DOI 10.1109/IEMBS.1996.652732
   Li H, 2007, ACAD RADIOL, V14, P513, DOI 10.1016/j.acra.2007.02.003
   Li J, 2006, IEEE IMAGE PROC, P3029, DOI 10.1109/ICIP.2006.313005
   LIEBOVITCH LS, 1989, PHYS LETT A, V141, P386, DOI 10.1016/0375-9601(89)90854-2
   Liu J, 2001, WOOD FIBER SCI, V33, P213
   Liu JZ, 2003, BIOPHYS J, V85, P4041, DOI 10.1016/S0006-3495(03)74817-6
   Liu Y, 2015, RARE METAL MAT ENG, V44, P800, DOI 10.1016/S1875-5372(15)30050-3
   Liu Y, 2014, J VIS COMMUN IMAGE R, V25, P1102, DOI 10.1016/j.jvcir.2014.03.008
   Long M, 2013, RADIOENGINEERING, V22, P208
   LONGLEY PA, 1989, GEOGR ANAL, V21, P47
   Lopes R, 2009, MED IMAGE ANAL, V13, P634, DOI 10.1016/j.media.2009.05.003
   LOPES R, 2007, EUROPEAN J NUCL MED, V34, P394
   Madzin H, 2008, IFMBE PROC, V21, P587
   Majumdar S, 1999, MED PHYS, V26, P1330, DOI 10.1118/1.598628
   Mandelbrot B. B., 1983, The fractal geometry of nature
   MANDELBROT BB, 1984, NATURE, V308, P721, DOI 10.1038/308721a0
   Mavroforakis ME, 2006, ARTIF INTELL MED, V37, P145, DOI 10.1016/j.artmed.2006.03.002
   MILNE BT, 1992, AM NAT, V139, P32, DOI 10.1086/285312
   MOLTENO TCA, 1993, PHYS REV E, V48, pR3263, DOI 10.1103/PhysRevE.48.R3263
   Mukherjee K, 2013, J INDIAN SOC REMOTE, V41, P249, DOI 10.1007/s12524-012-0225-4
   Mukherjee K, 2012, GEOCARTO INT, V27, P515, DOI 10.1080/10106049.2011.642411
   Myint SW, 2003, INT J REMOTE SENS, V24, P1925, DOI 10.1080/01431160210155992
   Nayak S., 2017, J TEXT I, DOI [10.1080/004050002017.1418710, DOI 10.1080/004050002017.1418710]
   Nayak S., 2019, ICI GLOBAL, P181
   Nayak Soumya Ranjan, 2016, 2016 International Conference on Signal Processing, Communication, Power and Embedded System (SCOPES), P1109, DOI 10.1109/SCOPES.2016.7955614
   Nayak SR, 2015, 2015 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND NETWORKS (CINE), P156, DOI 10.1109/CINE.2015.37
   Nayak SR, 2018, OPTIK, V166, P110, DOI 10.1016/j.ijleo.2018.03.106
   Nayak SR, 2018, OPTIK, V162, P196, DOI 10.1016/j.ijleo.2018.02.066
   Nayak SR, 2018, OPTIK, V161, P136, DOI 10.1016/j.ijleo.2018.02.024
   Nayak SR, 2018, J INFORM OPTIM SCI, V39, P113, DOI 10.1080/02522667.2017.1372155
   Nguyen TA, 2005, P ANN INT IEEE EMBS, P3210, DOI 10.1109/IEMBS.2005.1617159
   Nikolaidis N. S., 2011, APPL MATH COMPUT, P1
   NORMANT F, 1991, PHYS REV A, V43, P6518, DOI 10.1103/PhysRevA.43.6518
   Novianto S, 2003, PATTERN RECOGN LETT, V24, P365, DOI 10.1016/S0167-8655(02)00261-1
   Oczeretko E, 2001, FOLIA HISTOCHEM CYTO, V39, P75
   Ostwald MJ, 2013, ENVIRON PLANN B, V40, P644, DOI 10.1068/b38124
   Ouyang XL, 1998, MED PHYS, V25, P2037, DOI 10.1118/1.598391
   PANDE CS, 1987, J MATER SCI LETT, V6, P295, DOI 10.1007/BF01729330
   Panigrahy C., 2017, ENTROY, V19, P1
   Peitgen H.-O., 1992, Fractals for the classroom: part two: complex systems and mandelbrot set
   Peleg S, 1984, IEEE Trans Pattern Anal Mach Intell, V6, P518, DOI 10.1109/TPAMI.1984.4767557
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   Phothisonothai M, 2007, J PHYSIOL SCI, V57, P217, DOI 10.2170/physiolsci.RP006307
   PICKOVER CA, 1986, COMPUT GRAPH, V10, P51, DOI 10.1016/0097-8493(86)90068-3
   Prabhu S, 2011, J BRAZ SOC MECH SCI, V33, P459, DOI 10.1590/S1678-58782011000400009
   Prigarin SM, 2008, NUMER ANAL APPL, V1, P163, DOI 10.1134/S1995423908020079
   Pruess S, 2007, FRACTALS EARTH SCI, V3, P65
   Rangayyan RM, 2005, INT CONGR SER, V1281, P1041, DOI 10.1016/j.ics.2005.03.329
   Roy A.G., 1987, P AUTOMATED CARTOGRA, P68
   RUSSELL DA, 1980, PHYS REV LETT, V45, P1175, DOI 10.1103/PhysRevLett.45.1175
   Sandau K, 1997, J MICROSC-OXFORD, V186, P164, DOI 10.1046/j.1365-2818.1997.1270685.x
   Sankar Deepa, 2010, International Journal of Computer Information Systems and Industrial Management Applications, V2, P11
   SARKAR N, 1994, IEEE T SYST MAN CYB, V24, P115, DOI 10.1109/21.259692
   SARKAR N, 1992, PATTERN RECOGN, V25, P1035, DOI 10.1016/0031-3203(92)90066-R
   SASAJIMA K, 1992, INT J MACH TOOL MANU, V32, P125, DOI 10.1016/0890-6955(92)90069-S
   Shelberg M.C., 1983, Proceedings of the Sixth International Symposium on Computer-Assisted Cartography (Auto-Carto 6), P319
   SMITH TG, 1993, J COMP NEUROL, V331, P402, DOI 10.1002/cne.903310309
   SMITH TG, 1994, BRAIN RES, V634, P181, DOI 10.1016/0006-8993(94)91921-6
   Solberg AHS, 1997, IEEE T GEOSCI REMOTE, V35, P475, DOI 10.1109/36.563288
   Soltys Z, 2001, J NEUROSCI RES, V63, P90, DOI 10.1002/1097-4547(20010101)63:1<90::AID-JNR11>3.0.CO;2-9
   SPANOS L, 1994, J VAC SCI TECHNOL A, V12, P2646, DOI 10.1116/1.579084
   Stach S, 2001, MATER CHARACT, V46, P163, DOI 10.1016/S1044-5803(01)00119-X
   Stachowiak GW, 2001, WEAR, V249, P194, DOI 10.1016/S0043-1648(01)00562-2
   Strauss A. D., 2003, HARMONIC FRACTAL IMA, P42
   Sun JL, 2012, IERI PROC, V3, P41, DOI 10.1016/j.ieri.2012.09.008
   Sun W, 2006, INT J REMOTE SENS, V27, P4963, DOI 10.1080/01431160600676695
   Sun WX, 2006, PHOTOGRAMM ENG REM S, V72, P373, DOI 10.14358/PERS.72.4.373
   Tanki Nobuyoshi, 2006, Igaku Butsuri, V26, P207
   TAYLOR CC, 1991, J ROY STAT SOC B MET, V53, P353
   Turcotte D. L, 1997, FRACTALS CHAOS GEOLO
   Turcotte D.L., 1995, FRACTALS CHAOS GEOLO
   Tzeng YC, 2012, IEEE GEOSCI REMOTE S, V9, P272, DOI 10.1109/LGRS.2011.2166243
   Voss R., 1986, Scaling Phenomena in Disordered Systems, V133, P1
   Voss R., 1988, SCI FRACTAL IMAGES, P21, DOI DOI 10.1007/978-1-4612-3784-6_1
   Wang E, 2014, TECTONICS, V33, P686, DOI 10.1002/2013TC003337
   Wang Jinan, 1999, J UNIV SCI TECHNOL B, V21, P6
   Wilkie JR, 2004, MED PHYS, V31, P882, DOI 10.1118/1.1650529
   Woraratpanya K., 2012, INVIT PAP, V10, P5
   Xie HP, 1998, PHYS LETT A, V242, P41, DOI 10.1016/S0375-9601(98)00098-X
   Xie HP, 1999, INT J SOLIDS STRUCT, V36, P3073, DOI 10.1016/S0020-7683(98)00141-3
   Yang ZY, 2001, INT J ROCK MECH MIN, V38, P1201, DOI 10.1016/S1365-1609(02)00006-0
   Yang ZY, 2001, ROCK MECH ROCK ENG, V34, P323, DOI 10.1007/s006030170004
   Yasar F, 2006, DENTOMAXILLOFAC RAD, V35, P1, DOI 10.1259/dmfr/97652136
   Yu L, 2005, PATTERN RECOGN, V38, P1791, DOI 10.1016/j.patcog.2005.03.015
   Yum MK, 2002, J CARDIOVASC ELECTR, V13, P788, DOI 10.1046/j.1540-8167.2002.00788.x
   Zaho X., 2016, FRACTALS, V24, P1
   Zhang L, 2007, NEUROBIOL AGING, V28, P1543, DOI 10.1016/j.neurobiolaging.2006.06.020
   [张亚衡 Zhang Yaheng], 2005, [岩石力学与工程学报, Chinese Journal of Rock Mechanics and Engineering], V24, P3192
   Zheng Jin-ling, 2014, MAT REV, V25, P139
   Zhou HW, 2003, SURF REV LETT, V10, P751, DOI 10.1142/S0218625X03005591
   Zhuang XD, 2004, ARTIF INTELL MED, V32, P29, DOI [10.1016/j.artmed.2004.01.016, 10.1016/j.artmed. 2004.01.016]
   Zook JM, 2005, MAGN RESON IMAGING, V23, P671, DOI 10.1016/j.mri.2005.04.002
NR 167
TC 61
Z9 65
U1 6
U2 71
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 21
EP 34
DI 10.1016/j.imavis.2019.06.015
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900003
DA 2024-07-18
ER

PT J
AU Yu, CY
   Yao, CT
   Pei, MT
   Jia, YD
AF Yu, Changyong
   Yao, Chengtang
   Pei, Mingtao
   Jia, Yunde
TI Diffusion-based kernel matrix model for face liveness detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face liveness detection; Anisotropic diffusion; Kernel matrix model; DK
   feature
ID SINGLE IMAGE; RECOGNITION
AB Face recognition and verification systems are vulnerable to video spoofing attacks. In this paper, we present a diffusion-based kernel matrix model for face liveness detection. We use the anisotropic diffusion to enhance the edges of each frame in a video, and the kernel matrix model to extract the video features which we call the diffusion kernel (DK) features. The DK features reflect the inner correlation of the face images in the video. We employ a generalized multiple kernel learning method to fuse the DK features and the deep features extracted from convolution neural networks to achieve better performance. Our experimental evaluation on two publicly available datasets shows that the proposed method outperforms the state-of-art face liveness detection methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Yu, Changyong; Yao, Chengtang; Pei, Mingtao; Jia, Yunde] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Pei, MT (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM peimt@bit.edu.cn
CR Alotaibi A, 2017, SIGNAL IMAGE VIDEO P, V11, P713, DOI 10.1007/s11760-016-1014-2
   Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   [Anonymous], PROC CVPR IEEE
   [Anonymous], EXPERT SYSTEMS APPL
   [Anonymous], MULTIMEDIA TOOLS APP
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Bengio S., 2004, PROC SPEAKER LANG RE
   Bharadwaj S, 2013, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2013.23
   Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740
   Chingovska Ivana, 2012, BIOSIG
   De Marsico M, 2014, IMAGE VISION COMPUT, V32, P1161, DOI 10.1016/j.imavis.2013.12.014
   Fei P., 2017, Multimedia Tools and Applications, P1
   Haykin S, 2004, Neural Networks, V2, P41, DOI DOI 10.5555/541500
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Kim YS, 2009, J OPT SOC AM A, V26, P760, DOI 10.1364/JOSAA.26.000760
   Kollreider K, 2009, IMAGE VISION COMPUT, V27, P233, DOI 10.1016/j.imavis.2007.05.004
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Kondor Risi, 2003, ICML, P361
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Ning X, 2018, PROCEEDINGS OF THE 7TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS (ICPRAM 2018), P317, DOI 10.5220/0006568103170323
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Pan G, 2007, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2007.4409068
   Peixoto Bruno, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3557, DOI 10.1109/ICIP.2011.6116484
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Singh AK, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROPAGATION AND COMPUTER TECHNOLOGY (ICSPCT 2014), P592, DOI 10.1109/ICSPCT.2014.6884911
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Varma M., 2009, P 26 ANN INT C MACHI, P1065
   Vazquez-Fernandez E, 2016, IMAGE VISION COMPUT, V55, P31, DOI 10.1016/j.imavis.2016.03.018
   Wang L, 2015, IEEE I CONF COMP VIS, P4570, DOI 10.1109/ICCV.2015.519
   Yeh CH, 2018, IEEE WINT CONF APPL, P49, DOI 10.1109/WACV.2018.00012
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
NR 36
TC 7
Z9 8
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 88
EP 94
DI 10.1016/j.imavis.2019.06.009
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900008
DA 2024-07-18
ER

PT J
AU Abu Mallouh, A
   Qawagneh, Z
   Barkana, BD
AF Abu Mallouh, Arafat
   Qawagneh, Zakariya
   Barkana, Buket D.
TI Utilizing CNNs and transfer learning of pre-trained models for age range
   classification from unconstrained face images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Age range classification; CNNs; Deep learning; Deep neural networks
   (DNNs); Face recognition
ID NETWORKS
AB Automatic age classification from real-world and wild face images is a challenging task and has an increasing importance due to its wide range of applications in current and future lifestyles. As a result of increasing age specific human-computer interactions, it is expected that computerized systems should be capable of estimating the age from face images and respond accordingly. Over the past decade, many research studies have been conducted on automatic age classification from face images. However, the performance of the developed age classification systems suffered due to the absence of large, comprehensive benchmarks. In this work, we propose and show that pre-trained CNNs which were trained on large benchmarks for different purposes can be retrained and fine-tuned for age range classification from unconstrained face images. Also, we propose to reduce the dimension of the output of the last convolutional layer in pre-trained CNNs to improve the performance of the designed CNNs architectures. The experimental results show significant improvements in exact and 1-off accuracies on the Adience benchmark. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Abu Mallouh, Arafat] Manhattan Coll, Comp Sci Dept, Riverdale, NY 10471 USA.
   [Qawagneh, Zakariya] SUNY Coll Brockport, Dept Comp Sci, Brockport, NY 14420 USA.
   [Barkana, Buket D.] Univ Bridgeport, Elect Engn Dept, Bridgeport, CT 06604 USA.
C3 Manhattan College; State University of New York (SUNY) System; State
   University of New York (SUNY) Brockport; University of Bridgeport
RP Barkana, BD (corresponding author), Univ Bridgeport, Elect Engn Dept, Bridgeport, CT 06604 USA.
EM aabumallouh01@manhattan.edu; zqawagneh@brockport.edu; bdbarkana@aol.com
CR Alnajar F, 2012, IMAGE VISION COMPUT, V30, P946, DOI 10.1016/j.imavis.2012.07.009
   [Anonymous], P AS C COMP VIS 2014
   [Anonymous], P BRIT MACH VIS C 20
   [Anonymous], P 14 ACM INT C MULT
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], BRIT MACH VIS C
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], 2010, Proc. MPVA
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Bin Iqbal MT, 2017, IEEE T INF FOREN SEC, V12, P2505, DOI 10.1109/TIFS.2017.2695456
   Cao LJ, 2003, NEUROCOMPUTING, V55, P321, DOI 10.1016/S0925-2312(03)00433-8
   Chao WL, 2013, PATTERN RECOGN, V46, P628, DOI 10.1016/j.patcog.2012.09.011
   Chen JC, 2016, INT CONF BIOMETR THE
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Escalera Sergio, 2015, P IEEE INT C COMPUTE, P1
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Farkas LG, 1994, Anthropometry of Head and Face, Vsecond
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1383
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Gao F, 2008, PROCEEDINGS OF THE ASME INTERNATIONAL MECHANICAL ENGINERING CONGRESS AND EXPOSITION 2007, VOL 9, PTS A-C, P133
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Ghodsi A., 2006, DIMENSIONALITY REDUC, V37, P38
   Glorot X., 2010, P INT C ART INT STAT, P249
   Gunay A., 23 INT S COMPUTER IN, P1
   Guo GD, 2009, IEEE I CONF COMP VIS, P1986, DOI 10.1109/ICCV.2009.5459438
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Han H, 2013, 2013 INTERNATIONAL CONFERENCE ON ADVANCED CLOUD AND BIG DATA (CBD), P77, DOI 10.1109/CBD.2013.12
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Hayashi J, 2002, SICE 2002: PROCEEDINGS OF THE 41ST SICE ANNUAL CONFERENCE, VOLS 1-5, P13
   Hayashi J., 2001, Proceedings Seventh International Conference on Virtual Systems and Multimedia, P439, DOI 10.1109/VSMM.2001.969698
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Liu H, 2018, IEEE T INF FOREN SEC, V13, P292, DOI 10.1109/TIFS.2017.2746062
   Liu X, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P258, DOI 10.1109/ICCVW.2015.42
   Pandey A, 2015, 8th International Symposium on Visual Information Communication and Interaction (VINCI 2015), P109, DOI 10.1145/2801040.2801049
   Qawaqneh Z, 2017, EXPERT SYST APPL, V85, P76, DOI 10.1016/j.eswa.2017.05.037
   Ramanathan N., 2006, 2006 IEEE COMP SOC C, V1, P387
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scherbaum K, 2007, COMPUT GRAPH FORUM, V26, P285, DOI 10.1111/j.1467-8659.2007.01050.x
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Suo J., 2008, Automatic Face and Gesture Recognition, P1
   Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853
   Yan SC, 2008, INT CONF ACOUST SPEE, P737
   Zhu LN, 2016, INT C PATT RECOG, P3282, DOI 10.1109/ICPR.2016.7900141
NR 51
TC 27
Z9 27
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 41
EP 51
DI 10.1016/j.imavis.2019.05.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400005
DA 2024-07-18
ER

PT J
AU Matkowski, WM
   Chan, FKS
   Kong, AWK
AF Matkowski, Wojciech Michal
   Chan, Frodo Kin Sun
   Kong, Adams Wai Kin
TI A study on wrist identification for forensic investigation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Criminal and victim identification; Forensics; Wrist
ID PATTERNS; RECOGNITION; ROTATION; TEXTURE; SCALE
AB Criminal and victim identification based on crime scene images is an important part of forensic investigation. Criminals usually avoid identification by covering their faces and tattoos in the evidence images, which are taken in uncontrolled environments. Existing identification methods, which make use of biometric traits, such as vein, skin mark, height, skin colour, weight, race, etc., are considered for solving this problem. The soft biometric traits, including skin colour, gender, height, weight and race, provide useful information but not distinctive enough. Veins and skin marks are limited to high resolution images and some body sites may neither have enough skin marks nor clear veins. Terrorists and rioters tend to expose their wrists in a gesture of triumph, greeting or salute, while paedophiles usually show them when touching victims. However, wrists were neglected by the biometric community for forensic applications. In this paper, a wrist identification algorithm, which includes skin segmentation, key point localisation, image to template alignment, large feature set extraction, and classification, is proposed. The proposed algorithm is evaluated on NTU-Wrist-Image-Database-v1, which consists of 3945 images from 731 different wrists, including 205 pairs of wrist images collected from the Internet, taken under uneven illuminations with different poses and resolutions. The experimental results show that wrist is a useful clue for criminal and victim identification. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Matkowski, Wojciech Michal; Chan, Frodo Kin Sun; Kong, Adams Wai Kin] Nanyang Technol Univ, Sch Comp Sci & Engn, Block N4,Nanyang Ave, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Matkowski, WM (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Block N4,Nanyang Ave, Singapore 639798, Singapore.
EM matk0001@e.ntu.edu.sg
RI Matkowski, Wojciech/AAX-5437-2020
FU Ministry of Education, Singapore through Academic Research Fund Tier 2
   [MOE2016-T2-1-042(S)]
FX This work is partially supported by the Ministry of Education, Singapore
   through Academic Research Fund Tier 2, MOE2016-T2-1-042(S).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], ADMISSIBILITY DIGITA
   [Anonymous], 80 PERCENT DARK WEB
   [Anonymous], 2015, P INT C LEARN REP IC
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], DAILY MAIL ONLINE
   [Anonymous], INTRO ALGORITHMS
   [Anonymous], ARXIV160208325
   [Anonymous], 2014, ICLR
   [Anonymous], INT S CIRC SYST
   Bouchrika I, 2011, J FORENSIC SCI, V56, P882, DOI 10.1111/j.1556-4029.2011.01793.x
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chan FKS, 2017, IEEE T INF FOREN SEC, V12, P1900, DOI 10.1109/TIFS.2017.2692684
   Chan FKS, 2015, 2015 EUROPEAN INTELLIGENCE AND SECURITY INFORMATICS CONFERENCE (EISIC), P137, DOI 10.1109/EISIC.2015.17
   Dubey SR, 2014, IEEE T IMAGE PROCESS, V23, P5323, DOI 10.1109/TIP.2014.2358879
   Fei LK, 2019, IEEE T SYST MAN CY-S, V49, P346, DOI 10.1109/TSMC.2018.2795609
   Fei LK, 2016, PATTERN RECOGN, V49, P89, DOI 10.1016/j.patcog.2015.08.001
   GELADI P, 1986, ANAL CHIM ACTA, V185, P1, DOI 10.1016/0003-2670(86)80028-9
   Hengyi Zhang, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P77, DOI 10.1109/BTAS.2012.6374560
   Kang WX, 2014, IEEE T INF FOREN SEC, V9, P1974, DOI 10.1109/TIFS.2014.2361020
   Kruppa H., 2002, ANN S PATTERN RECOGN, DOI [DOI 10.1007/3-540-45783-6, 10.1007/3-540-45783-6.]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Minaee S, 2015, IEEE SIG PROC MED
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nhat Quang Huynh, 2014, 2014 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM). Proceedings, P167, DOI 10.1109/CIBIM.2014.7015459
   Nurhudatiana A, 2015, IEEE T INF FOREN SEC, V10, P916, DOI 10.1109/TIFS.2014.2387575
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliveira GL, 2016, IEEE INT CONF ROBOT, P1634, DOI 10.1109/ICRA.2016.7487304
   Paulino AA, 2013, IEEE T INF FOREN SEC, V8, P31, DOI 10.1109/TIFS.2012.2223678
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Qu HN, 2010, PATTERN RECOGN, V43, P3448, DOI 10.1016/j.patcog.2010.05.002
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Scheirer WJ, 2011, IEEE T PATTERN ANAL, V33, P1689, DOI 10.1109/TPAMI.2011.54
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su H, 2014, IEEE T INF FOREN SEC, V9, P666, DOI 10.1109/TIFS.2014.2306591
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tang CY, 2011, PROC CVPR IEEE, P665, DOI 10.1109/CVPR.2011.5995531
   Wang J, 2010, APPL MECH MATER, V36, P96, DOI [10.4028/www.scientific.net/AMM.36.96, 10.1109/ICICTA.2010.35]
   Woodard DL, 2005, PROC CVPR IEEE, P1030
   Wu XQ, 2014, PATTERN RECOGN, V47, P3314, DOI 10.1016/j.patcog.2014.04.008
   Zhang L, 2010, PATTERN RECOGN, V43, P2560, DOI 10.1016/j.patcog.2010.01.020
NR 42
TC 7
Z9 7
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 96
EP 112
DI 10.1016/j.imavis.2019.05.005
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kagawade, VC
   Angadi, SA
AF Kagawade, Vishwanath C.
   Angadi, Shanmukhappa A.
TI Multi-directional local gradient descriptor: A new feature descriptor
   for face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gradient features; Face representation; Symbolic data objects;
   Viola-Jones; Binary pattern
ID REPRESENTATION; PATTERNS
AB The performance of the face recognition systems is vulnerable to occlusion, light and expression changes and such constraints need to be handled effectively in a robust face recognition system. This paper presents a new multi -directional local gradient descriptor (MLGD) method for face recognition based on local directional gradient features that exploit the edges/line information in multiple directions. The proposed technique exploits advantage of similarity of a face image in small blocks. The weighted gradient features of face images in different directions and zones are computed based on co -relation between pixel elements. These features referred to as multi -directional local gradient descriptor (MLGD), which capture adequate edge information by integrating different directional gradients. Further, the directional gradient features extracted through MLGD operator are represented as a symbolic data object. The face identification is carried out by using the symbolic object representation of test image and employing a symbolic similarity measure. The experimental results on AR (97.33%) and LFW (97.25%) benchmark face databases demonstrate that the symbolic data representation of the new directional gradient magnitude of face image significantly improves the recognition performance as compared to local gradient descriptors and other state-of-the-art methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Kagawade, Vishwanath C.] Basaveshwar Engn Coll, Dept Comp Applicat, Bagalkot, India.
   [Angadi, Shanmukhappa A.] VTU, Ctr Post Grad Studies, Dept Comp Sci & Engn, Belagavi, India.
C3 Visvesvaraya Technological University
RP Kagawade, VC (corresponding author), Basaveshwar Engn Coll, Dept Comp Applicat, Bagalkot, India.
EM vishwanath.1312@gmail.com
RI Kagawade, Vishwanath/J-8227-2019; Angadi, Shanmukhappa/AAA-2457-2020
OI Kagawade, Vishwanath/0000-0002-7934-8629; Angadi,
   Shanmukhappa/0000-0001-9756-9786
CR Angadi Shanmukhappa, 2016, INT J TECHNOLOGY SCI, VIX, P50
   Angadi SA, 2017, PATTERN RECOGN, V71, P235, DOI 10.1016/j.patcog.2017.06.014
   [Anonymous], MULTIMEDIA TOOLS APP
   [Anonymous], 2015, COMPUTER VISION PATT
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   Dahmane M, 2014, PROCEDIA COMPUT SCI, V39, P12, DOI 10.1016/j.procs.2014.11.004
   Dinesh M. S., 2000, PREMI 2005, P338
   Ding CX, 2018, IEEE T PATTERN ANAL, V40, P1002, DOI 10.1109/TPAMI.2017.2700390
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Ding Zhengming, 2015, DISCRIMINATIVE LOW R
   Du B, 2017, IEEE T CYBERNETICS, V47, P1017, DOI 10.1109/TCYB.2016.2536638
   Du B, 2017, IEEE T CYBERNETICS, V47, P14, DOI 10.1109/TCYB.2015.2496974
   Fan KC, 2014, IEEE T IMAGE PROCESS, V23, P2877, DOI 10.1109/TIP.2014.2321495
   GOWDA KC, 1991, PATTERN RECOGN, V24, P567, DOI 10.1016/0031-3203(91)90022-W
   Hiremath PS, 2006, LECT NOTES COMPUT SC, V4338, P641
   Hiremath PS, 2008, LECT NOTES COMPUT SC, V5259, P982, DOI 10.1007/978-3-540-88458-3_89
   Hiremath PS, 2005, LECT NOTES COMPUT SC, V3776, P266
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang WL, 2017, PATTERN RECOGN, V68, P126, DOI 10.1016/j.patcog.2017.03.010
   Jabid T, 2010, ETRI J, V32, P784, DOI 10.4218/etrij.10.1510.0132
   Jadoon W, 2015, NEURAL COMPUT APPL, V26, P1991, DOI 10.1007/s00521-015-1843-x
   Kiranagi Guru D. S, 2010, INT J COMPUT APPL, V1
   Li ZK, 2017, PATTERN ANAL APPL, V20, P101, DOI 10.1007/s10044-015-0470-6
   Liang Yunjuan, 2012, AISC, V165, P385, DOI [10.1007/978-3-642-29637-6_49, DOI 10.1007/978-3-642-29637-6_49]
   Liu Z, 2015, NEURAL COMPUT APPL, V26, P2013, DOI 10.1007/s00521-015-1863-6
   Martinez A. M., 1998, THE AR DATABASE
   Murala S, 2012, IEEE T IMAGE PROCESS, V21, P2874, DOI 10.1109/TIP.2012.2188809
   Nagabhushan P, 2006, LECT NOTES COMPUT SC, V4223, P937
   Nagabhushan P, 2005, LECT NOTES COMPUT SC, V3776, P388
   NAGABHUSHAN P, 1995, PATTERN RECOGN LETT, V16, P219, DOI 10.1016/0167-8655(94)00085-H
   Nagabhushan P., 2005, PATT REC MACH INT P, DOI [10.1007/11590316_59, DOI 10.1007/11590316_59]
   Rao G. Raghavendra, 1998, IEA AIE, V1, P487
   Ravi T. V., 2000, Intelligent Data Engineering and Automated - IDEAL 2000. Data Mining, Financial Engineering, and Intelligent Agents. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.1983), P35
   Ravi TV, 1999, PATTERN RECOGN LETT, V20, P659, DOI 10.1016/S0167-8655(99)00027-6
   Rikhtegar A, 2016, IET COMPUT VIS, V10, P559, DOI 10.1049/iet-cvi.2015.0037
   Surinta O, 2015, ENG APPL ARTIF INTEL, V45, P405, DOI 10.1016/j.engappai.2015.07.017
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Vikram T. N., 2007, ICADL, P499
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang MS, 2012, FUZZY SET SYST, V203, P49, DOI 10.1016/j.fss.2012.04.006
   Yang-Mao SF, 2007, LECT NOTES COMPUT SC, V4901, P290
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zhenhua Chai, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P639, DOI 10.1007/978-3-642-37444-9_50
   1995, PATTERN RECOGN LETT, V16, P647
   1995, PATTERN RECOGN, V28, P1277
   2017, PATTERN RECOGN, V66, P313, DOI DOI 10.1016/J.PATCOG.2016.12.029
   2015, PROCEDIA COMPUTER SC, V48, P644, DOI DOI 10.1016/J.PROCS.2015.04.147
   1992, IEEE T SYST MAN CYBE, V22, P368
NR 48
TC 9
Z9 9
U1 1
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR-APR
PY 2019
VL 83-84
BP 39
EP 50
DI 10.1016/j.imavis.2019.02.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HW6TR
UT WOS:000466824000004
DA 2024-07-18
ER

PT J
AU Garcia, N
   Vogiatzis, G
AF Garcia, Noa
   Vogiatzis, George
TI Learning non-metric visual similarity for image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image retrieval; Visual similarity; Non-metric learning
ID FEATURES
AB Measuring visual similarity between two or more instances within a data distribution is a fundamental task in image retrieval. Theoretically, non-metric distances are able to generate a more complex and accurate similarity model than metric distances, provided that the non-linear data distribution is precisely captured by the system. In this work, we explore neural networks models for learning a non-metric similarity function for instance search. We argue that non-metric similarity functions based on neural networks can build a better model of human visual perception than standard metric distances. As our proposed similarity function is differentiable, we explore a real end-to-end trainable approach for image retrieval, i.e. we learn the weights from the input image pixels to the final similarity score. Experimental evaluation shows that non-metric similarity networks are able to learn visual similarities between images and improve performance on top of state-of-the-art image representations, boosting results in standard image retrieval datasets with respect standard metric distances. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Garcia, Noa; Vogiatzis, George] Aston Univ, Birmingham B4 7ET, W Midlands, England.
C3 Aston University
RP Garcia, N (corresponding author), Aston Univ, Birmingham B4 7ET, W Midlands, England.
EM garciadn@aston.ac.uk; g.vogiatzis@aston.ac.uk
OI Vogiatzis, George/0000-0002-3226-0603
CR ARANDJELOVIC R, 2012, PROC CVPR IEEE, P2911, DOI DOI 10.1109/CVPR.2012.6248018
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Bhagat PK, 2018, IMAGE VISION COMPUT, V80, P1, DOI 10.1016/j.imavis.2018.09.017
   Bojarski Mariusz, 2016, arXiv
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Deng DG, 2018, IMAGE VISION COMPUT, V70, P11, DOI 10.1016/j.imavis.2017.12.005
   Dong Xu-sheng, 2018, Instrument Technique and Sensor, P1
   Dong XY, 2019, IEEE T IMAGE PROCESS, V28, P518, DOI 10.1109/TIP.2018.2867747
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Gavet Y, 2014, MACH VISION APPL, V25, P1953, DOI 10.1007/s00138-014-0625-2
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Han XF, 2015, PROC CVPR IEEE, P3279, DOI 10.1109/CVPR.2015.7298948
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jimenez A., 2017, BMVC
   Joe Yue-Hei Ng, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P53, DOI 10.1109/CVPRW.2015.7301272
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulis B, 2013, FOUND TRENDS MACH LE, V5, P287, DOI 10.1561/2200000019
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Liu Y, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P43, DOI 10.1145/2671188.2749300
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LUO WJ, 2016, PROC CVPR IEEE, P5695, DOI DOI 10.1109/CVPR.2016.614
   McFee B., 2010, ICML, P775
   Mohedano E, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P327, DOI 10.1145/2911996.2912061
   Movshovitz-Attias Y, 2017, IEEE I CONF COMP VIS, P360, DOI 10.1109/ICCV.2017.47
   Noh H, 2017, IEEE I CONF COMP VIS, P3476, DOI 10.1109/ICCV.2017.374
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Philbin J, 2008, PROC CVPR IEEE, P2285
   Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Razavian A. S., 2016, ITE Trans. Media Technol. Appl., V4, P251, DOI [DOI 10.3169/MTA.4.251, 10.3169/mta.4.251]
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salvador A, 2016, IEEE COMPUT SOC CONF, P394, DOI 10.1109/CVPRW.2016.56
   Santoro A., 2017, Advances in Neural Information Processing Systems
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   TAN X, 2006, P IEEE COMP SOC C CO, P138
   Thewlis J., 2016, P BRIT MACH VIS C
   Tolias G., 2016, Conference Track Proceedings,
   TVERSKY A, 1982, PSYCHOL REV, V89, P123, DOI 10.1037/0033-295X.89.2.123
   Vinyals O., 2016, ADV NEURAL INFORM PR, P3630, DOI DOI 10.48550/ARXIV.1606.04080
   Wan J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P157, DOI 10.1145/2647868.2654948
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wu P., 2013, P 21 ACM INT C MULT, P153, DOI DOI 10.1145/2502081.2502112
   Xie LX, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P3, DOI 10.1145/2671188.2749289
   Xu YJ, 2018, IEEE T IMAGE PROCESS, V27, P4933, DOI 10.1109/TIP.2018.2846664
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zagoruyko S., 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
NR 62
TC 23
Z9 26
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2019
VL 82
BP 18
EP 25
DI 10.1016/j.imavis.2019.01.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HU1RT
UT WOS:000465050200002
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Harvey, FG
   Roy, J
   Kanaa, D
   Pal, C
AF Harvey, Felix G.
   Roy, Julien
   Kanaa, David
   Pal, Christopher
TI Recurrent semi-supervised classification and constrained adversarial
   generation with motion capture data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Motion capture; Semi-supervised learning; Recurrent
   neural networks; Generative adversarial networks; Transition generation
AB We explore recurrent encoder multi-decoder neural network architectures for semi-supervised sequence classification and reconstruction. We find that the use of multiple reconstruction modules helps models generalize in a classification task when only a small amount of labeled data is available, which is often the case in practice. Such models provide useful high-level representations of motions allowing clustering, searching and faster labeling of new sequences. We also propose a new, realistic partitioning of a well-known, high quality motion-capture dataset for better evaluations. We further explore a novel formulation for future-predicting decoders based on conditional recurrent generative adversarial networks, for which we propose both soft and hard constraints for transition generation derived from desired physical properties of synthesized future movements and desired animation goals. We find that using such constraints allow to stabilize the training of recurrent adversarial architectures for animation generation. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Harvey, Felix G.; Roy, Julien; Kanaa, David; Pal, Christopher] Polytech Montreal, 2900 Edouard Montpetit Blvd, Montreal, PQ H3T 1J4, Canada.
   [Harvey, Felix G.; Roy, Julien; Pal, Christopher] Montreal Inst Learning Algorithms, 2920 Chemin Tour, Montreal, PQ H3T 1J4, Canada.
C3 Universite de Montreal; Polytechnique Montreal; Universite de Montreal
RP Harvey, FG (corresponding author), Polytech Montreal, 2900 Edouard Montpetit Blvd, Montreal, PQ H3T 1J4, Canada.
EM felix.gingras-harvey@polymtl.ca
OI G. Harvey, Felix/0000-0002-2720-4324
FU Ubisoft; Natural Sciences and Engineering Research Council of Canada
   under the Collaborative Research and Development program; Natural
   Sciences and Engineering Research Council of Canada under the Discovery
   Grant program; Mitacs Accelerate program [IT08585]
FX We thank Ubisoft and the Natural Sciences and Engineering Research
   Council of Canada for support under the Collaborative Research and
   Development program and the Discovery Grant program. We also thank the
   Mitacs Accelerate (IT08585) program for support. Finally, we want to
   thank the authors of the Theano framework [50].
CR [Anonymous], ARXIV160909444
   [Anonymous], 2016, ARXIV160402808
   [Anonymous], 2017, ARXIV170402827
   [Anonymous], 2017, P AAAI
   [Anonymous], 2015, ARXIV150204681
   [Anonymous], ARXIV160505396
   [Anonymous], 2017, CVPR
   [Anonymous], 2016, ARXIV160307772
   [Anonymous], IEEE T VIS COMPUT GR
   [Anonymous], 2010, P NIPS WORKSH DEEP L
   [Anonymous], 2014, INT C MACH LEARN ICM
   [Anonymous], 2007, DOCUMENTATION MOCAP
   [Anonymous], 2016, ARXIV160905473
   [Anonymous], 2015, BENCHMARKING LSTM NE
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], 2016, ARXIV160502688
   Barnachon M, 2014, PATTERN RECOGN, V47, P238, DOI 10.1016/j.patcog.2013.06.020
   Bengio Y., 2007, Advances in neural information processing systems, P153, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Chaudhry R, 2013, IEEE COMPUT SOC CONF, P471, DOI 10.1109/CVPRW.2013.153
   Chen X, 2013, LECT NOTES COMPUT SC, V7944, P640
   Cho K, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P122
   Cotter SF, 2005, IEEE T SIGNAL PROCES, V53, P2477, DOI 10.1109/TSP.2005.849172
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Fragkiadaki K, 2015, IEEE I CONF COMP VIS, P4346, DOI 10.1109/ICCV.2015.494
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Graves A., 2008, ADV NEURAL INFORM PR, V20, P1
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu JF, 2015, PROC CVPR IEEE, P5344, DOI 10.1109/CVPR.2015.7299172
   Huang X., 2016, Stacked generative adversarial networks
   Hung CC, 2012, NEURON, V74, P1099, DOI 10.1016/j.neuron.2012.04.029
   Ijjina EP, 2016, PATTERN RECOGN LETT, V83, P268, DOI 10.1016/j.patrec.2016.03.021
   Jain A, 2016, PROC CVPR IEEE, P5308, DOI 10.1109/CVPR.2016.573
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   LeCun Y, 1998, LECT NOTES COMPUT SC, V1524, P9, DOI 10.1007/3-540-49430-8_2
   Lehrmann AM, 2014, PROC CVPR IEEE, P1314, DOI 10.1109/CVPR.2014.171
   Li Zimo, 2017, ARXIV170705363
   Liu J., 2017, IEEE T PATTERN ANAL
   Mahasseni B, 2016, PROC CVPR IEEE, P3054, DOI 10.1109/CVPR.2016.333
   Martinez J, 2017, PROC CVPR IEEE, P4674, DOI 10.1109/CVPR.2017.497
   Radford A., 2016, COMPUT SCI
   Sak H., 2014, ARXIV14021128CSSTAT
   Sutskever I, 2014, ADV NEUR IN, V27
   Sutskever Ilya, 2011, P 28 INT C MACH LEAR, P1017
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Zhang SY, 2017, IEEE WINT CONF APPL, P148, DOI 10.1109/WACV.2017.24
NR 56
TC 2
Z9 4
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2018
VL 78
BP 42
EP 52
DI 10.1016/j.imavis.2018.07.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV5LO
UT WOS:000446143900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rodríguez, P
   Bautista, MA
   Gonzàlez, J
   Escalera, S
AF Rodriguez, Pau
   Bautista, Miguel A.
   Gonzalez, Jordi
   Escalera, Sergio
TI Beyond one-hot encoding: Lower dimensional target embedding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Error correcting output codes; Output embeddings; Deep learning;
   Computer vision
ID DEPENDENT DESIGN; OUTPUT; CLASSIFICATION; ECOC
AB Target encoding plays a central role when learning Convolutional Neural Networks. In this realm, one-hot encoding is the most prevalent strategy due to its simplicity. However, this so widespread encoding schema assumes a flat label space, thus ignoring rich relationships existing among labels that can be exploited during training. In large-scale datasets, data does not span the full label space, but instead lies in a low-dimensional output manifold. Following this observation, we embed the targets into a low-dimensional space, drastically improving convergence speed while preserving accuracy. Our contribution is two fold: (i) We show that random projections of the label space are a valid tool to find such lower dimensional embeddings, boosting dramatically convergence rates at zero computational cost; and (ii) we propose a normalized eigenrepresentation of the class manifold that encodes the targets with minimal information loss, improving the accuracy of random projections encoding while enjoying the same convergence rates. Experiments on CIFAR-100, CUB200-2011, Imagenet, and MIT Places demonstrate that the proposed approach drastically improves convergence speed while reaching very competitive accuracy rates. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Rodriguez, Pau; Gonzalez, Jordi; Escalera, Sergio] Univ Autonoma Barcelona, Comp Vis Ctr, Campus UAB,Edifici O,Cerdanyola Valles S-N, E-08193 Barcelona, Spain.
   [Bautista, Miguel A.] Heidelberg Univ, Heidelberg Collaboratory Image Proc, Heidelberg, Germany.
   [Escalera, Sergio] Univ Barcelona, Barcelona, Spain.
C3 Centre de Visio per Computador (CVC); Autonomous University of
   Barcelona; Ruprecht Karls University Heidelberg; University of Barcelona
RP Rodríguez, P (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, Campus UAB,Edifici O,Cerdanyola Valles S-N, E-08193 Barcelona, Spain.
EM pau.rodriguez@cvc.uab.cat; miguel.bautista@iwr.uni-heidelberg.de;
   gonzalez@cvc.uab.cat; sescalera@cvc.uab.cat
RI Gonzàlez, Jordi/I-1812-2015; Rodríguez López, Pau/I-2762-2015; Escalera,
   Sergio/L-2998-2015
OI Gonzàlez, Jordi/0000-0001-8033-0306; Rodríguez López,
   Pau/0000-0002-1689-8084; Escalera, Sergio/0000-0003-0617-8873
FU Spanish project [TIN2015-65464-R]; Secretaria d'Universitats i Recerca
   del Departament d'Economia i Coneixement de la Generalitat de Catalunya
   [2016FI_B 01163]; COST Action [IC1307]; COST (European Cooperation in
   Science and Technology); NVIDIA Corporation; GTX TITAN GPU
FX Authors acknowledge the support of the Spanish project TIN2015-65464-R
   (MINECO FEDER), the 2016FI_B 01163 grant (Secretaria d'Universitats i
   Recerca del Departament d'Economia i Coneixement de la Generalitat de
   Catalunya), and the COST Action IC1307 iV&L Net (European Network on
   Integrating Vision and Language) supported by COST (European Cooperation
   in Science and Technology). We also gratefully acknowledge the support
   of NVIDIA Corporation with the donation of a Tesla K40 GPU and a GTX
   TITAN GPU, used for this research.
CR Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   Allwein E., 2002, JMLR, V1, P113
   Bautista MA, 2012, PATTERN RECOGN LETT, V33, P693, DOI 10.1016/j.patrec.2011.09.023
   [Anonymous], SPECTRAL ERROR CORRE
   [Anonymous], ICCV 15 P IEEE 15 IN
   [Anonymous], P 2008 IEEE C COMP V
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], HDB BRAIN THEORY NEU
   [Anonymous], 2015, P INT C COMP VIS ICC
   [Anonymous], 2010, CALTECH UCSD BIRDS 2
   [Anonymous], 2010, Advances in Neural Information Processing Systems
   [Anonymous], 2007, Proceedings of the 24th interna- tional conference on Machine learning
   Bai XL, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0436-2
   Bose R. C., 1960, Inf. Control, V3, P79, DOI DOI 10.1016/S0019-9958(60)90287-4
   Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281
   Deng J, 2014, LECT NOTES COMPUT SC, V8689, P48, DOI 10.1007/978-3-319-10590-1_4
   Dietterich T. G., 1995, Journal of Artificial Intelligence Research, V2, P263
   Escalera S, 2008, IEEE T PATTERN ANAL, V30, P1041, DOI 10.1109/TPAMI.2008.38
   Eun Bae Kong, 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P313
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Ghaderi R, 2000, INT C PATT RECOG, P203, DOI 10.1109/ICPR.2000.906048
   Hastie T, 1998, ANN STAT, V26, P451
   Hsu Daniel J, 2009, Proc. of Neural Information Processing Systems, P772
   Huiqun Deng, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4291, DOI 10.1109/ICPR.2010.1043
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jiang ZL, 2017, IEEE WINT CONF APPL, P207, DOI 10.1109/WACV.2017.30
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Kankuekul P, 2012, PROC CVPR IEEE, P3657, DOI 10.1109/CVPR.2012.6248112
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lin Kevin, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P27, DOI 10.1109/CVPRW.2015.7301269
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mikolov T, 2013, ICLR WORKSHOP POSTER
   Pujol O, 2006, IEEE T PATTERN ANAL, V28, P1007, DOI 10.1109/TPAMI.2006.116
   Rohrbach M, 2011, PROC CVPR IEEE, P1641, DOI 10.1109/CVPR.2011.5995627
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Smith RS, 2015, NEUROCOMPUTING, V150, P440, DOI 10.1016/j.neucom.2014.07.066
   Srivastava N., 2013, NIPS, P2094
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Vijayanarasimhan Sudheendra, 2014, ARXIV14127479
   Weinberger K., 2009, P INT C NEUR INF PRO, P1737
   Weston J, 2011, IJCAI
   Weston J, 2010, MACH LEARN, V81, P21, DOI 10.1007/s10994-010-5198-3
   Windeatt T., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P165, DOI 10.1049/cp:20030513
   Xiao TJ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P177, DOI 10.1145/2647868.2654926
   Yang S, 2015, AAAI CONF ARTIF INTE, P3848
   Yu XD, 2010, LECT NOTES COMPUT SC, V6315, P127
   Zhou BL, 2014, ADV NEUR IN, V27
NR 51
TC 188
Z9 205
U1 10
U2 57
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2018
VL 75
BP 21
EP 31
DI 10.1016/j.imavis.2018.04.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GM3LM
UT WOS:000438006100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wu, YH
   Shah, SK
   Kakadiaris, IA
AF Wu, Yuhang
   Shah, Shishir K.
   Kakadiaris, Ioannis A.
TI GoDP: Globally Optimized Dual Pathway deep network architecture for
   facial landmark localization in-the-wild
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Facial landmark localization; Face alignment; Face
   recognition
ID FACE ALIGNMENT; POSE
AB Facial landmark localization is a fundamental module for pose-invariant face recognition. The most common approach for facial landmark detection is cascaded regression, which is composed of two steps: feature extraction and facial shape regression. Recent methods employ deep convolutional networks to extract robust features for each step, while the whole system could be regarded as a deep cascaded regression architecture. In this work, instead of employing a deep regression network, a Globally Optimized Dual-Pathway (GoDP) deep architecture is proposed to identify the target pixels through solving a cascaded pixel labeling problem without resorting to high-level inference models or complex stacked architecture. The proposed end-to-end system relies on distance-aware soft-max functions and dual-pathway proposal-refinement architecture. Results show that it outperforms the state-of-the-art cascaded regression-based methods on multiple in-the-wild face alignment databases. The model achieves 1.84 normalized mean error (NME) on the AFLW database [1], which outperforms 3DDFA [2] by 61.8%. Experiments on face identification demonstrate that GoDP, coupled with DPM-headhunter [3], is able to improve rank-1 identification rate by 44.2% compare to Dlib [4] toolbox on a challenging database. (C) 2017 Published by Elsevier B.V.
C1 [Wu, Yuhang; Shah, Shishir K.; Kakadiaris, Ioannis A.] Univ Houston, Dept Comp Sci, Computat Biomed Lab, 4849 Calhoun Rd, Houston, TX 77004 USA.
C3 University of Houston System; University of Houston
RP Kakadiaris, IA (corresponding author), Univ Houston, Dept Comp Sci, Computat Biomed Lab, 4849 Calhoun Rd, Houston, TX 77004 USA.
EM ywu35@central.uh.edu; sshah@central.uh.edu; ikakadia@central.uh.edu
OI Shah, Shishir/0000-0003-4093-6906; Kakadiaris,
   Ioannis/0000-0002-0591-1079
FU U.S. Department of Homeland Security [2015-ST-061-BSH001]
FX This material is based upon work supported by the U.S. Department of
   Homeland Security under grant award number 2015-ST-061-BSH001. This
   grant is awarded to the Borders, Trade, and Immigration (BTI) Institute:
   A DHS Center of Excellence led by the University of Houston, and
   includes support for the project "Image and Video Person Identification
   in an Operational Environment: Phase I" awarded to the University of
   Houston. The views and conclusions contained in this document are those
   of the authors and should not be interpreted as necessarily representing
   the official policies, either expressed or implied, of the U.S.
   Department of Homeland Security.
CR [Anonymous], P EUR C COMP VIS ZUR
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P BRIT MACH VIS C YO
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P INT C COMP VIS SAN
   [Anonymous], P INT JOINT C BIOM D
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-46484-8_29
   [Anonymous], P NEUR INF PROC SYST
   [Anonymous], P P INT C BIOM THEOR
   [Anonymous], P ANN C NEUR INF PRO
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], P 12 IEEE C AUT FAC
   [Anonymous], 2016, CORR
   [Anonymous], P BRIT MACH VIS C YO
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Chu X, 2016, PROC CVPR IEEE, P4715, DOI 10.1109/CVPR.2016.510
   Feng ZH, 2017, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2017.392
   Ghiasi G, 2016, LECT NOTES COMPUT SC, V9907, P519, DOI 10.1007/978-3-319-46487-9_32
   Haoqiang Fan, 2016, Image and Vision Computing, V47, P27, DOI 10.1016/j.imavis.2015.11.004
   Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454
   Kakadiaris IA, 2017, COMPUT VIS IMAGE UND, V154, P137, DOI 10.1016/j.cviu.2016.04.012
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Peng X, 2016, LECT NOTES COMPUT SC, V9905, P38, DOI 10.1007/978-3-319-46448-0_3
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Shi YC, 2018, IEEE T INF FOREN SEC, V13, P1626, DOI 10.1109/TIFS.2018.2796999
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Toderici G, 2010, PROC CVPR IEEE, P2721, DOI 10.1109/CVPR.2010.5539995
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Wang DY, 2017, IEEE T PATTERN ANAL, V39, P1122, DOI 10.1109/TPAMI.2016.2582166
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wu YH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA), DOI 10.1109/ISBA.2016.7477244
   Xiao ST, 2016, LECT NOTES COMPUT SC, V9905, P57, DOI 10.1007/978-3-319-46448-0_4
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang W, 2016, PROC CVPR IEEE, P3073, DOI 10.1109/CVPR.2016.335
   Yiming Wu, 2015, 2015 IEEE Transportation Electrification Conference and Expo (ITEC), P1, DOI 10.1109/ITEC.2015.7165794
   Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244
   Zhang J, 2016, PROC CVPR IEEE, P3428, DOI 10.1109/CVPR.2016.373
   Zhou EJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P386, DOI 10.1109/ICCVW.2013.58
   Zhu SZ, 2016, PROC CVPR IEEE, P3409, DOI 10.1109/CVPR.2016.371
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 52
TC 5
Z9 7
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2018
VL 73
BP 1
EP 16
DI 10.1016/j.imavis.2017.12.002
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GH7SF
UT WOS:000433653000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fanani, N
   Stüerck, A
   Ochs, M
   Bradler, H
   Mester, R
AF Fanani, Nolang
   Stuerck, Alina
   Ochs, Matthias
   Bradler, Henry
   Mester, Rudolf
TI Predictive monocular odometry (PMO): What is possible without RANSAC and
   multiframe bundle adjustment?
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual odometry; Monocular visual odometry; SLAM; Pose prediction; Joint
   epipolar tracking; Ground plane estimation; Driver assistance
AB Visual odometry using only a monocular camera faces more algorithmic challenges than stereo odometry. We present a robust monocular visual odometry framework for automotive applications. An extended propagation-based tracking framework is proposed which yields highly accurate (unscaled) pose estimates. Scale is supplied by ground plane pose estimation employing street pixel labeling using a convolutional neural network (CNN). The proposed framework has been extensively tested on the KITTI dataset and achieves a higher rank than current published state-of-the-art monocular methods in the KITTI odometry benchmark. Unlike other VO/SLAM methods, this result is achieved without loop closing mechanism, without RANSAC and also without multiframe bundle adjustment. Thus, we challenge the common belief that robust systems can only be built using iterative robustification tools like RANSAC. (C) 2017 Published by Elsevier B.V.
C1 [Fanani, Nolang; Stuerck, Alina; Ochs, Matthias; Bradler, Henry; Mester, Rudolf] Goethe Univ, Visual Sensor & Informat Proc Lab, Frankfurt, Germany.
   [Mester, Rudolf] Linkoping Univ, Comp Vis Lab, ISY, Linkoping, Sweden.
C3 Goethe University Frankfurt; Linkoping University
RP Mester, R (corresponding author), Goethe Univ, Visual Sensor & Informat Proc Lab, Frankfurt, Germany.
EM mester@vsi.cs.uni-frankfurt.de
RI Mester, Rudolf/D-6035-2011
OI Mester, Rudolf/0000-0002-6932-0606
CR [Anonymous], 2016, Revised Selected Papers
   Barnada M, 2015, IEEE INT VEH SYM, P481, DOI 10.1109/IVS.2015.7225731
   Bradler H., 2017, P WINT C APPL COMP V, P652
   Bradler H., 2016, THESIS
   Bradler H, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P106, DOI 10.1109/ICCVW.2015.24
   Buczko M, 2016, IEEE INT VEH SYM, P478, DOI 10.1109/IVS.2016.7535429
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Eggert DW, 1997, MACH VISION APPL, V9, P272, DOI 10.1007/s001380050048
   Engel J., 2017, ARXIV160702565
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Fanani N., 2017, P INT VEH S 4
   Fanani N, 2016, IEEE INT VEH SYM, P933, DOI 10.1109/IVS.2016.7535500
   Fanani N, 2015, LECT NOTES COMPUT SC, V9474, P115, DOI 10.1007/978-3-319-27857-5_11
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frost DP, 2016, IEEE INT CONF ROBOT, P4770, DOI 10.1109/ICRA.2016.7487680
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Klein George, 2007, P1
   MIRABDOLLAH MH, 2015, PROC GERM CONF PATT, V9358, P297, DOI DOI 10.1007/978-3-319-24947-6_24
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Ochs M., 2015, PAC RIM S PSIVT, P368
   Piccini T., 2014, ECCV WORKSH COMP VIS, P652
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Song SY, 2016, IEEE T PATTERN ANAL, V38, P730, DOI 10.1109/TPAMI.2015.2469274
   Song SY, 2013, IEEE INT CONF ROBOT, P4698, DOI 10.1109/ICRA.2013.6631246
   Trummer M, 2009, LECT NOTES COMPUT SC, V5575, P460, DOI 10.1007/978-3-642-02230-2_47
   van den Brand J., 2016, ACCV WORKSH, P477
   Yamaguchi K, 2013, PROC CVPR IEEE, P1862, DOI 10.1109/CVPR.2013.243
NR 31
TC 19
Z9 19
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2017
VL 68
SI SI
BP 3
EP 13
DI 10.1016/j.imavis.2017.08.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FR9UP
UT WOS:000419418900002
DA 2024-07-18
ER

PT J
AU Deng, T
   Cai, JF
   Cham, TJ
   Zheng, JM
AF Deng, Teng
   Cai, Jianfei
   Cham, Tat-Jen
   Zheng, Jianmin
TI Multiple consumer-grade depth camera registration using everyday objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth camera; Depth camera calibration; Multi-depth camera registration
AB The registration of multiple consumer-grade depth sensors is a challenging task due to noisy and systematic distortions in depth measurements. Most of the existing works heavily rely on large number of checkerboard observations for calibration and registration of multiple depth cameras, which is tedious and not flexible. In this paper, we propose a more practical method for conducting and maintaining registration of multi-depth sensors, via replacing checkerboards with everyday objects found in the scene, such as regular furniture. Particularly, high quality pre-scanned 3D shapes of standard furniture are used as calibration targets. We propose a unified framework that jointly computes the optimal extrinsic calibration and depth correction parameters. Experimental results show that our proposed method significantly outperforms state-of-the-art depth.camera registration methods. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Deng, Teng] Nanyang Technol Univ, Inst Media Innovat, Singapore, Singapore.
   Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
C3 Nanyang Technological University; Nanyang Technological University
RP Deng, T (corresponding author), Nanyang Technol Univ, Inst Media Innovat, Singapore, Singapore.
EM dengteng@ntu.edu.sg
RI Zheng, Jianmin/A-3717-2011; Teng, Deng/JCD-6210-2023; Cai,
   Jianfei/A-3691-2011
OI Zheng, Jianmin/0000-0002-5062-6226; Cai, Jianfei/0000-0002-9444-3763;
   Cham, Tat-Jen/0000-0001-5264-2572
FU Singapore MoE AcRF Tier 1 Grants [RG138/14]; BeingTogether Centre;
   National Research Foundation, Prime Minister's Office, Singapore under
   its International Research Centres in Singapore Funding Initiative
FX This research is partially supported by Singapore MoE AcRF Tier 1 Grants
   RG138/14 and the BeingTogether Centre, a collaboration between Nanyang
   Technological University (NTU) Singapore and University of North
   Carolina (UNC) at Chapel Hill. The BeingTogether Centre is supported by
   the National Research Foundation, Prime Minister's Office, Singapore
   under its International Research Centres in Singapore Funding
   Initiative.
CR Avetisyan R., 2014, CALIBRATIN DEPTH CAM
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Beck S, 2015, P IEEE VIRT REAL ANN, P151, DOI 10.1109/VR.2015.7223340
   Besl P.J., 1992, IEEE TPAMI
   Bouguet J.-Y., 2004, CAMERA CALIBRATION T
   Bradski G, 2000, THE OPENCV LIB
   Deng T., 2014, MULT EXP ICME 2014 I, P1
   Drost B., 2010, Proc. 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.2010.5540108
   Herrera D., 2012, IEEE TPAMI
   Horn Berthold K. P., 1987, J OPT SOC AM A
   Izadi S, 2011, P UIST, P559, DOI DOI 10.1145/2047196.2047270
   Jin BW, 2014, LECT NOTES COMPUT SC, V8693, P788, DOI 10.1007/978-3-319-10602-1_51
   Kuster C., 2011, FREECAM HYBRID CAMER
   Maimone A., 2012, COMPUT GRAPH
   Mateos G.G., 2000, CAMERA CALIBRATION T
   Pomerleau Franccois., 2013, AUTON ROBOT, P1
   Salas-Moreno RF, 2013, PROC CVPR IEEE, P1352, DOI 10.1109/CVPR.2013.178
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   Teichman A., 2013, UNSUPERVISED INTRINS
   Zhang Cha., 2014, Computer Vision and Machine Learning with RGB-D Sensors, P47
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou QY, 2014, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2014.65
NR 23
TC 6
Z9 6
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2017
VL 62
BP 1
EP 7
DI 10.1016/j.imavis.2017.03.005
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EX3GV
UT WOS:000403121500001
DA 2024-07-18
ER

PT J
AU Lillo, I
   Niebles, JC
   Soto, A
AF Lillo, Ivan
   Niebles, Juan Carlos
   Soto, Alvaro
TI Sparse composition of body poses and atomic actions for human activity
   recognition in RGB-D videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Activity recognition; Hierarchical recognition model; RGB-D videos
AB This paper presents an approach to recognize human activities using body poses estimated from RGB-D data. We focus on recognizing complex activities composed of sequential or simultaneous atomic actions characterized by body motions of a single actor. We tackle this problem by introducing a hierarchical compositional model that operates at three levels of abstraction. At the lowest level, geometric and motion descriptors are used to learn a dictionary of body poses. At the intermediate level, sparse compositions of these body poses are used to obtain meaningful representations for atomic human actions. Finally, at the highest level, spatial and temporal compositions of these atomic actions are used to represent complex human activities.
   Our results show the benefits of using a hierarchical model that exploits the sharing and composition of body poses into atomic actions, and atomic actions into activities.
   A quantitative evaluation using two benchmark datasets illustrates the advantages of our model to perform action and activity recognition. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Lillo, Ivan; Soto, Alvaro] Pontificia Univ Catolica Chile, 4860 Vicuna Mackenna, Santiago, Chile.
   [Niebles, Juan Carlos] Univ Norte, Barranquilla, Colombia.
   [Niebles, Juan Carlos] Stanford Univ, Stanford, CA USA.
C3 Pontificia Universidad Catolica de Chile; Universidad del Norte
   Colombia; Stanford University
RP Lillo, I (corresponding author), Pontificia Univ Catolica Chile, 4860 Vicuna Mackenna, Santiago, Chile.
EM ialillo@uc.cl; njuan@uninorte.edu.co; asoto@ing.puc.cl
RI Niebles, Juan Carlos/AAT-5882-2021; Soto, Alvaro M/D-1406-2014
OI Niebles, Juan Carlos/0000-0001-8225-9793; 
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2011, IEEE Transactions on Visualization and Computer Graphics, DOI DOI 10.1109/TVCG.2010.272
   [Anonymous], 2015, ICCVW
   [Anonymous], KIN WIND SDK
   [Anonymous], IEEE C COMP VIS PATT
   BOUREAU YL, 2010, PROC CVPR IEEE, P2559, DOI DOI 10.1109/CVPR.2010.5539963
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Escorcia Victor, 2012, Proceedings of the 2012 Construction Research Congress, P879
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lillo I, 2014, PROC CVPR IEEE, P812, DOI 10.1109/CVPR.2014.109
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Lu CW, 2014, PROC CVPR IEEE, P772, DOI 10.1109/CVPR.2014.104
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Luo JJ, 2014, PATTERN RECOGN LETT, V50, P139, DOI 10.1016/j.patrec.2014.03.024
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Savarese S., 2006, P 2006 IEEE COMPUTER, V2, P2033, DOI DOI 10.1109/CVPR.2006.102
   Shotton J., 2011, COMMUN ACM, P116
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Tsochantaridis I., 2004, ICML, P104
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214
   Wei P, 2013, IEEE I CONF COMP VIS, P3136, DOI 10.1109/ICCV.2013.389
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yu T., 2009, P 26 ANN INT C MACH, P1169, DOI DOI 10.1145/1553374.1553523
   Yuille AL, 2003, NEURAL COMPUT, V15, P915, DOI 10.1162/08997660360581958
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 42
TC 42
Z9 45
U1 1
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2017
VL 59
BP 63
EP 75
DI 10.1016/j.imavis.2016.11.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EP9IS
UT WOS:000397687900005
DA 2024-07-18
ER

PT J
AU Kim, H
   Jo, J
   Toh, KA
   Kim, J
AF Kim, Hyunjun
   Jo, Jaeik
   Toh, Kar-Ann
   Kim, Jaihie
TI Eye detection in a facial image under pose variation based on
   multi-scale iris shape feature
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Eye detection; Eye localization; Facial feature detection; Eye
   verification
ID LOCALIZATION; ROBUST; SCALE
AB The accurate location of eyes in a facial image is important to many human facial recognition-related applications, and has attracted considerable research interest in computer vision. However, most prevalent methods are based on the frontal pose of the face, where applying them to non-frontal poses can yield erroneous results.
   In this paper, we propose an eye detection method that can locate the eyes in facial images captured at various head poses. Our proposed method consists of two stages: eye candidate detection and eye candidate verification. In eye candidate detection, eye candidates are obtained by using multi-scale iris shape features and integral image. The size of the iris in face images varies as the head pose changes, and the proposed multi-scale iris shape feature method can detect the eyes in such cases. Since it utilizes the integral image, its computational cost is relatively low. The extracted eye candidates are then verified in the eye candidate verification stage using a support vector machine (SVM) based on the feature-level fusion of a histogram of oriented gradients (HOG) and cell mean intensity features.
   We tested the performance of the proposed method using the Chinese Academy of Sciences' Pose, Expression, Accessories, and Lighting (CAS-PEAL) database and the Pointing'04 database. The results confirmed the superiority of our Method over the conventional Haar-like detector and two hybrid eye detectors under relatively extreme head pose variations. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Kim, Hyunjun; Jo, Jaeik; Toh, Kar-Ann; Kim, Jaihie] Yonsei Univ, Sch Elect & Elect Engn, Seoul 03722, South Korea.
C3 Yonsei University
RP Kim, J (corresponding author), Yonsei Univ, Sch Elect & Elect Engn, Seoul 03722, South Korea.
EM kimhj8574@gmail.com; jaeik@yonsei.ac.kr; katoh@yonsei.ac.kr;
   jhkim@yonsei.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [2016R1A2B4006320]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Science, ICT & Future Planning (No. 2016R1A2B4006320).
CR Alonso-Fernandez F., 2015, PATTERN RECOGN LETT
   Bhattacharyya A., 1946, INDIAN J STAT, V7, P40
   Chen S, 2015, IMAGE VISION COMPUT, V33, P68, DOI 10.1016/j.imavis.2014.10.007
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Cootes T.F., 1998, COMPUTER VISION ECCV, V1407, P484, DOI [DOI 10.1007/BFB0054760, DOI 10.1109/34.927467]
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Oliveira LS, 2012, IEEE SYS MAN CYBERN, P840, DOI 10.1109/ICSMC.2012.6377832
   Efraty B, 2011, IEEE IMAGE PROC, P569, DOI 10.1109/ICIP.2011.6116612
   Efraty B., INT C AUT FAC GEST R, P278
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Gourier N, 2004, ICPR INT WORKSH VIS, P1
   Homg W.B., 2012, WSEAS T INF SCI APPL, V9, P2224
   Ito Y, 2012, INT C PATT RECOG, P1795
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jesorsky O., 2001, AUDIO VIDEO BASED BI, P90
   Jian M., 2013, FAST EYE DETECTION L, P89
   Jing MQ, 2010, INT J PATTERN RECOGN, V24, P475, DOI 10.1142/S0218001410008020
   Jo J, 2015, PATTERN RECOGN, V48, P73, DOI 10.1016/j.patcog.2014.07.013
   Jo J, 2014, EXPERT SYST APPL, V41, P1139, DOI 10.1016/j.eswa.2013.07.108
   Jo J, 2011, OPT ENG, V50, DOI 10.1117/1.3657506
   Kim BS, 2010, IEEE T CONSUM ELECTR, V56, P2498, DOI 10.1109/TCE.2010.5681133
   Kroon B, 2009, COMPUT VIS IMAGE UND, V113, P921, DOI 10.1016/j.cviu.2009.03.013
   Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6
   Monzo D, 2011, MACH VISION APPL, V22, P471, DOI 10.1007/s00138-010-0273-0
   Mu K, 2013, INT J SECUR APPL, V7, P363
   Naruniec J, 2010, INT J ELECTRON TELEC, V56, P267, DOI 10.2478/v10177-010-0035-y
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ross A., 2004, P BIOM CONS C BCC
   San N.N., 2014, IJCCER, V2, P52
   Savakis A, 2014, PROC SPIE, V9027, DOI 10.1117/12.2036824
   Shin KY, 2013, OPT ENG, V52, DOI 10.1117/1.OE.52.4.047201
   Skodras E, 2015, IMAGE VISION COMPUT, V36, P51, DOI 10.1016/j.imavis.2015.01.006
   Song FY, 2013, PATTERN RECOGN, V46, P3157, DOI 10.1016/j.patcog.2013.05.009
   Takano H., 2013, J INT COUNCIL ELECT, V3, P179
   Tan XY, 2009, PROC CVPR IEEE, P1621, DOI 10.1109/CVPRW.2009.5206818
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J., 2013, International Journal of Signal Processing, Image Processing and Pattern Recognition, V6, P323
   Wang P., 2005, 2005 IEEE COMP SOC C, P164
   Ye ZF, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P699
   Zhao SY, 2006, INT C PATT RECOG, P481
NR 44
TC 19
Z9 19
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 147
EP 164
DI 10.1016/j.imavis.2016.10.003
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800012
DA 2024-07-18
ER

PT J
AU Song, JK
   Gao, LL
   Zou, FH
   Yan, Y
   Sebe, N
AF Song, Jingkuan
   Gao, Lianli
   Zou, Fuhao
   Yan, Yan
   Sebe, Nicu
TI Deep and fast: Deep learning hashing with semi-supervised graph
   construction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Hashing; Multimedia retrieval
AB Learning-based hashing methods are becoming the mainstream for approximate scalable multimedia retrieval. They consist of two main components: hash codes learning for training data and hash functions learning for new data points. Tremendous efforts have been devoted to designing novel methods for these two components, i.e., supervised and unsupervised methods for learning hash codes, and different models for inferring hashing functions. However, there is little work integrating supervised and Unsupervised hash codes learning into a single framework. Moreover, the hash function learning component is usually based on hand-crafted visual features extracted from the training images. The performance of a content-based image retrieval system crucially depends on the feature representation and such hand-crafted visual features may degrade the accuracy of the hash functions. In this paper, we propose a semi-supervised deep learning hashing (DLH) method for fast multimedia retrieval. More specifically, in the first component, we utilize both visual and label information to learn an optimal similarity graph that can more precisely encode the relationship among training data, and then generate the hash codes based on the graph. In the second stage, we apply a deep convolutional network to simultaneously learn a good multimedia representation and a set of hash functions. Extensive experiments on five popular datasets demonstrate the superiority of our DLH over both supervised and unsupervised hashing methods. (C) 2016 Published by Elsevier B.V.
C1 [Song, Jingkuan; Yan, Yan; Sebe, Nicu] Univ Trento, Trento, Italy.
   [Gao, Lianli] Univ Elect Sci & Technol China, Chengdu, Peoples R China.
   [Zou, Fuhao] Huazhong Univ Sci & Technol, Wuhan, Peoples R China.
C3 University of Trento; University of Electronic Science & Technology of
   China; Huazhong University of Science & Technology
RP Gao, LL (corresponding author), 2006,Xiyuan Ave,West Hitech Zone, Chengdu 611731, Peoples R China.
EM jingkuan.song@unitn.it; lianli.gao@uestc.edu.cn
RI Sebe, Niculae/KEC-2000-2024
OI Sebe, Niculae/0000-0002-6597-7248
CR [Anonymous], 2008, NIPS
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, CVPR
   [Anonymous], ABS14094842 CORR
   [Anonymous], 2011, P 19 ACM INT C MULT
   [Anonymous], 2013, CVPR
   [Anonymous], 2009, ICCV
   [Anonymous], ICC
   [Anonymous], 2012, CVPR
   [Anonymous], ARXIV14085093
   [Anonymous], 2010, CVPR
   [Anonymous], TCYB
   [Anonymous], 2014, AAAI
   [Anonymous], 2014, ACM Multimedia
   [Anonymous], 2009, NIPS
   [Anonymous], 2010, SIGIR
   [Anonymous], AAAI
   [Anonymous], 2011, ICML
   [Anonymous], TNNLS
   [Anonymous], CVPR 2014
   [Anonymous], ICML
   [Anonymous], ACM COMPUTING SURVEY
   [Anonymous], 2013, CVPR
   [Anonymous], 2006, 2006 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2006.264
   [Anonymous], TPAMI
   [Anonymous], 2015, CVPR
   [Anonymous], ABS14082927 CORR
   Böhm C, 2001, ACM COMPUT SURV, V33, P322, DOI 10.1145/502807.502809
   Cappelli R, 2011, IEEE T SYST MAN CY B, V41, P1511, DOI 10.1109/TSMCB.2011.2155648
   Gao LL, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P903, DOI 10.1145/2733373.2806360
   Gao LL, 2015, PROC CVPR IEEE, P4371, DOI 10.1109/CVPR.2015.7299066
   Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu L, 2015, IEEE T IMAGE PROCESS, V24, P956, DOI 10.1109/TIP.2015.2390975
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Zhang LN, 2012, IEEE T SYST MAN CY B, V42, P282, DOI 10.1109/TSMCB.2011.2165335
   Zhang S., 2012, ECCV
   Zhou W., 2010, ACM MULTIMEDIA
   Zhu XF, 2014, IEEE T IMAGE PROCESS, V23, P3737, DOI 10.1109/TIP.2014.2332764
NR 39
TC 20
Z9 21
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 101
EP 108
DI 10.1016/j.imavis.2016.02.005
PN 2
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300008
DA 2024-07-18
ER

PT J
AU Bouachir, W
   Bilodeau, GA
AF Bouachir, Wassim
   Bilodeau, Guillaume-Alexandre
TI Exploiting structural constraints for visual object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object tracking; Structure-aware tracker; Keypoint; SIFT; Keypoint
   layout
ID FEATURES
AB This paper presents a novel structure-aware method for visual tracking. The proposed tracker relies on keypoint regions as salient and stable elements that encode the object structure efficiently. In addition to the object structural properties, the appearance model also includes global color features that we first use in a probabilistic approach to reduce the search space. The second step of our tracking procedure is based on keypoint matching to provide a preliminary prediction of the target state. Final prediction is then achieved by exploiting object structural constraints, where target keypoints vote for the corrected object location. Once the object location is obtained, we update the appearance model and structural properties, allowing tracking targets with changing appearance and non-rigid structures. Extensive experiments demonstrate that the proposed Structure-Aware Tracker (SAT) outperforms recent state-of-the-art trackers in challenging scenarios, especially when the target is partly occluded and in moderately crowded scenes. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Bouachir, Wassim; Bilodeau, Guillaume-Alexandre] Ecole Polytech, Dept Comp & Software Engn, LITIV Lab, Montreal, PQ H3C 3A7, Canada.
C3 Universite de Montreal; Polytechnique Montreal
RP Bouachir, W (corresponding author), Ecole Polytech, Dept Comp & Software Engn, LITIV Lab, POB 6079,Stn Ctr Ville, Montreal, PQ H3C 3A7, Canada.
EM wassim.bouachir@polymtl.ca; gabilodeau@polymtl.ca
FU FRQ-NT; NSERC [311869-2010]
FX This work was supported by a scholarship from FRQ-NT and partially
   supported by NSERC discovery grant no. 311869-2010.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Belagiannis V, 2012, LECT NOTES COMPUT SC, V7575, P842, DOI 10.1007/978-3-642-33765-9_60
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Bouachir W., 2014, IEEE WINT C APPL COM
   Bouachir W, 2013, 2013 INTERNATIONAL CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P45, DOI 10.1109/CRV.2013.18
   Cerman L, 2009, LECT NOTES COMPUT SC, V5575, P291, DOI 10.1007/978-3-642-02230-2_30
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Geng C, 2009, IEEE IMAGE PROC, P3313, DOI 10.1109/ICIP.2009.5413956
   Grabner H, 2010, PROC CVPR IEEE, P1285, DOI 10.1109/CVPR.2010.5539819
   Gu S, 2011, PROC CVPR IEEE, P1169, DOI 10.1109/CVPR.2011.5995599
   Guo YW, 2014, COMPUT VIS IMAGE UND, V118, P128, DOI 10.1016/j.cviu.2013.09.007
   Hager GD, 2004, PROC CVPR IEEE, P790
   Hare S, 2012, PROC CVPR IEEE, P1894, DOI 10.1109/CVPR.2012.6247889
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Qiu-Hong Zhou, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P545, DOI 10.1109/FG.2011.5771456
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari A, 2010, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2010.5539937
   Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879
   Stiefelhagen R., 2007, CVPR, P1, DOI 10.1109/CVPR.2007.383502
   Sun HM, 2010, PATTERN RECOGN, V43, P1413, DOI 10.1016/j.patcog.2009.09.022
   Wang S, 2011, IEEE I CONF COMP VIS, P1323, DOI 10.1109/ICCV.2011.6126385
   Wen LY, 2012, LECT NOTES COMPUT SC, V7575, P716, DOI 10.1007/978-3-642-33765-9_51
   Yang F, 2013, IMAGE VISION COMPUT, V31, P992, DOI 10.1016/j.imavis.2013.09.008
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Yi K.M., 2013, INT C COMP VIS ICCV
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 37
TC 2
Z9 2
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2015
VL 43
BP 39
EP 49
DI 10.1016/j.imavis.2015.09.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CY0AU
UT WOS:000366069200004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Xiao, B
   Wang, GY
   Li, WS
AF Xiao, Bin
   Wang, Guo-yin
   Li, Wei-sheng
TI Radial shifted Legendre moments for image analysis and invariant image
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Orthogonal moments; Legendre moments; Shifted Legendre polynomials;
   Image reconstruction; Invariant image recognition; Moment invariants
ID PSEUDO-ZERNIKE MOMENTS; FOURIER-MELLIN MOMENTS; PATTERN-RECOGNITION;
   SCALE INVARIANTS; FAST COMPUTATION; RECONSTRUCTION
AB The rotation, scaling and translation invariant property of image moments has a high significance in image recognition. Legendre moments as a classical orthogonal moment have been widely used in image analysis and recognition. Since Legendre moments are defined in Cartesian coordinate, the rotation invariance is difficult to achieve. In this paper, we first derive two types of transformed Legendre polynomial: substituted and weighted radial shifted Legendre polynomials. Based on these two types of polynomials, two radial orthogonal moments, named substituted radial shifted Legendre moments and weighted radial shifted Legendre moments (SRSLMs and WRSLMs) are proposed. The proposed moments are orthogonal in polar coordinate domain and can be thought as generalized and orthogonalized complex moments. They have better image reconstruction performance, lower information redundancy and higher noise robustness than the existing radial orthogonal moments. At last, a mathematical framework for obtaining the rotation, scaling and translation invariants of these two types of radial shifted Legendre moments is provided. Theoretical and experimental results show, the superiority of the proposed methods in terms of image reconstruction capability and invariant recognition accuracy under both noisy and noise-free conditions. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Xiao, Bin; Wang, Guo-yin; Li, Wei-sheng] Chongqing Univ Posts & Telecommun, Chongqing Key Lab Computat Intelligence, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Xiao, B (corresponding author), Chongqing Univ Posts & Telecommun, Chongqing Key Lab Computat Intelligence, Chongqing 400065, Peoples R China.
EM xiaobin@cqupt.edu.cn
RI Xiao, Bin/E-2722-2012
OI Wang, Guoyin/0000-0002-8521-5232
FU National Natural Science Foundation of China [61201383, 61272195];
   Chongqing Research Program of Application Foundation and Advanced
   Technology [cstc2013jcyjA40048]; Natural Science Foundation of Chongqing
   University of Posts and Telecommunications [2012-80]
FX This work was supported by the National Natural Science Foundation of
   China (61201383, 61272195), Chongqing Research Program of Application
   Foundation and Advanced Technology (cstc2013jcyjA40048) and the Natural
   Science Foundation of Chongqing University of Posts and
   Telecommunications (2012-80). The authors would like to thank the
   anonymous referees for their valuable comments and suggestions.
CR Abramowitz M., 1964, APPL MATH SER, V55
   ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594
   Al-Rawi MS, 2010, J REAL-TIME IMAGE PR, V5, P3, DOI 10.1007/s11554-009-0118-0
   Belkasim S, 2007, PATTERN RECOGN LETT, V28, P1969, DOI 10.1016/j.patrec.2007.05.010
   Choi MS, 2002, PATTERN RECOGN, V35, P119, DOI 10.1016/S0031-3203(01)00025-5
   Chong CW, 2003, PATTERN ANAL APPL, V6, P176, DOI 10.1007/s10044-002-0183-5
   Chong CW, 2004, PATTERN RECOGN, V37, P119, DOI 10.1016/j.patcog.2003.06.003
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Ghorbel F, 2006, PATTERN RECOGN LETT, V27, P1361, DOI 10.1016/j.patrec.2006.01.001
   Hosny KM, 2011, J REAL-TIME IMAGE PR, V6, P73, DOI 10.1007/s11554-009-0135-z
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   Qu YD, 2005, IMAGE VISION COMPUT, V23, P11, DOI 10.1016/j.imavis.2004.07.003
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Shu HZ, 2007, PATTERN RECOGN, V40, P670, DOI 10.1016/j.patcog.2006.05.035
   Shu HZ, 2007, IEEE ENG MED BIOL, V26, P70, DOI 10.1109/EMB.2007.906026
   Shu HZ, 2000, PATTERN RECOGN, V33, P341, DOI 10.1016/S0031-3203(99)00044-8
   Singh C, 2010, PATTERN RECOGN, V43, P2497, DOI 10.1016/j.patcog.2010.02.005
   Teague M.R., 1980, OPTICAL SOC AM, V70, P920
   Xiao B, 2012, PATTERN RECOGN, V45, P314, DOI 10.1016/j.patcog.2011.06.017
   Xiao B, 2010, PATTERN RECOGN, V43, P2620, DOI 10.1016/j.patcog.2010.03.013
   Yang B, 2011, SIGNAL PROCESS, V91, P2290, DOI 10.1016/j.sigpro.2011.04.012
   Yang GY, 2006, PATTERN RECOGN, V39, P74, DOI 10.1016/j.patcog.2005.08.008
   Yap PT, 2007, IEEE T PATTERN ANAL, V29, P2057, DOI 10.1109/TPAMI.2007.70709
   Yap PT, 2005, IEEE T PATTERN ANAL, V27, P1996, DOI 10.1109/TPAMI.2005.232
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
   Zhang H, 2010, IMAGE VISION COMPUT, V28, P38, DOI 10.1016/j.imavis.2009.04.004
   Zhang H, 2011, IEEE T IMAGE PROCESS, V20, P2189, DOI 10.1109/TIP.2011.2118216
   Zhang H, 2010, IEEE T IMAGE PROCESS, V19, P596, DOI 10.1109/TIP.2009.2036702
NR 30
TC 49
Z9 52
U1 1
U2 29
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 994
EP 1006
DI 10.1016/j.imavis.2014.09.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600003
DA 2024-07-18
ER

PT J
AU Liu, JJ
   Liu, B
   Zhang, ST
   Yang, F
   Yang, P
   Metaxas, DN
   Neidle, C
AF Liu, Jingjing
   Liu, Bo
   Zhang, Shaoting
   Yang, Fei
   Yang, Peng
   Metaxas, Dimitris N.
   Neidle, Carol
TI Non-manual grammatical marker recognition based on multi-scale,
   spatio-temporal analysis of head pose and facial expressions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE American Sign Language (ASL); Non-manual grammatical markers; Eyebrow
   height; Head gestures; Facial expressions; Conditional Random Field
   (CRF)
ID FEATURES; MOTION; FACE
AB Changes in eyebrow configuration, in conjunction with other facial expressions and head gestures, are used to signal essential grammatical information in signed languages. This paper proposes an automatic recognition system for non-manual grammatical markers in American Sign Language (ASL) based on a multi-scale, spatio-temporal analysis of head pose and facial expressions. The analysis takes account of gestural components of these markers, such as raised or lowered eyebrows and different types of periodic head movements. To advance the state of the art in non-manual grammatical marker recognition, we propose a novel multi-scale learning approach that exploits spatio-temporally low-level and high-level facial features. Low-level features are based on information about facial geometry and appearance, as well as head pose, and are obtained through accurate 3D deformable model-based face tracking. High-level features are based on the identification of gestural events, of varying duration, that constitute the components of linguistic non-manual markers. Specifically, we recognize events such as raised and lowered eyebrows, head nods, and head shakes. We also partition these events into temporal phases. We separate the anticipatory transitional movement (the onset) from the linguistically significant portion of the event, and we further separate the core of the event from the transitional movement that occurs as the articulators return to the neutral position towards the end of the event (the offset). This partitioning is essential for the temporally accurate localization of the grammatical markers, which could not be achieved at this level of precision with previous computer vision methods. In addition, we analyze and use the motion patterns of these non-manual events. Those patterns, together with the information about the type of event and its temporal phases, are defined as the high-level features. Using this multi-scale, spatio-temporal combination of low- and high-level features, we employ learning methods for accurate recognition of non-manual grammatical markers in ASL sentences. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Liu, Jingjing; Liu, Bo; Yang, Fei; Yang, Peng; Metaxas, Dimitris N.] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ USA.
   [Zhang, Shaoting] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
   [Neidle, Carol] Boston Univ, Dept Romance Studies, Linguist Program, Boston, MA 02215 USA.
C3 Rutgers University System; Rutgers University New Brunswick; University
   of North Carolina; University of North Carolina Charlotte; Boston
   University
RP Zhang, ST (corresponding author), Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
EM szhang16@cs.uncc.edu
RI yang, zhou/KBB-6972-2024
OI Neidle, Carol/0000-0002-8844-9085; Zhang, Shaoting/0000-0002-8719-448X
FU National Science Foundation [IIS-1064965, IIS-1065013, CNS-1059281,
   CNS-1059218, IIS-0964597, IIS-0964385]; National Space Biomedical
   Research Institute through NASA NCC [9-58]; Center for Identification
   Technology Research, a National Science Foundation (NSF)
   Industry/University Cooperative Research Center; University of North
   Carolina at Charlotte; Division Of Computer and Network Systems; Direct
   For Computer & Info Scie & Enginr [1059218] Funding Source: National
   Science Foundation; Div Of Information & Intelligent Systems; Direct For
   Computer & Info Scie & Enginr [1064965, 1065013, 0964385] Funding
   Source: National Science Foundation
FX This project was partially supported by grants from National Science
   Foundation (IIS-1064965, IIS-1065013, CNS-1059281, CNS-1059218,
   IIS-0964597, IIS-0964385), National Space Biomedical Research Institute
   through NASA NCC 9-58, the Center for Identification Technology
   Research, a National Science Foundation (NSF) Industry/University
   Cooperative Research Center, and funds provided by the University of
   North Carolina at Charlotte. We gratefully acknowledge invaluable
   assistance from Rachel Benedict, Braden Painter, Joan Nash, Donna
   Riggle, Jessica Scott, Indya Oliver, Corbin Kuntze, Emma Preston, Tory
   Sampson, and many other BU students.
CR Altun Y., 2003, ICML
   [Anonymous], HDB PATTERN RECOGNIT
   [Anonymous], 2006, P ACMSIGKDD INT C KN
   [Anonymous], THESIS U CALIFORNIA
   [Anonymous], P 8 IEEE INT C AUT F
   [Anonymous], 1978, Understanding language through sign language research
   [Anonymous], 2001, PROC 18 INT C MACH L
   Aran O, 2009, LECT NOTES ARTIF INT, V5085, P134
   Baker C., 1978, Understanding Language through Sign Language Research, P27
   Baker-Shenk C., 1980, American sign language: A teacher's resource text on grammar and culture
   Baker-Shenk C., 1983, MICROANALYSIS NONMAN
   Chen SZ, 2013, IMAGE VISION COMPUT, V31, P175, DOI 10.1016/j.imavis.2012.06.014
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P., 2002, FACIAL ACTION CODING
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kanaujia A, 2006, LECT NOTES COMPUT SC, V4338, P492
   Kelly D., 2009, AUTOMATIC RECOGNITIO
   Kendall M. G., 1948, RANK CORRELATION MET
   Li CS, 2012, PROC CVPR IEEE, P2570, DOI 10.1109/CVPR.2012.6247975
   Liddell S., 1980, American Sign Language syntax
   Lien JJJ, 1998, PROC CVPR IEEE, P853, DOI 10.1109/CVPR.1998.698704
   Liu J. J., 2013, P IEEE INT C WORKSH
   Liu Jian-zheng, 2011, Proceedings of the 2011 Seventh International Conference on Networked Computing and Advanced Information Management (NCM), P232
   Metaxas D, 2012, P INT C LANG RES EV
   Metaxas D, 2013, IMAGE VISION COMPUT, V31, P421, DOI 10.1016/j.imavis.2013.03.005
   Michael N, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.124
   Michael N, 2009, ASSETS'09: PROCEEDINGS OF THE 11TH INTERNATIONAL ACM SIGACCESS CONFERENCE ON COMPUTERS AND ACCESSIBILITY, P75
   Michael Nicholas, 2010, 4 WORKSH REPR PROC S
   Morimoto C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P461, DOI 10.1109/ICPR.1996.546990
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Neidle C., 2009, P ESSLLI WORKSH FORM
   Neidle C.J., 2000, The Syntax of American Sign Language: Functional Categories and Hierarchical Structure
   Neidle Carol, 2002, 11 BOST U AM SIGN LA
   Rudovic O, 2012, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2012.6247983
   Schmidt M., 2008, CONDITIONAL RANDOM F
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   Nguyen TD, 2011, LECT NOTES COMPUT SC, V6495, P665, DOI 10.1007/978-3-642-19282-1_53
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Vogler Christian, 2008, Universal Access in the Information Society, V6, P363, DOI 10.1007/s10209-007-0096-6
   Vogler C., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P116, DOI 10.1109/ICCV.1999.791206
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Zhou F, 2010, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2010.5539966
NR 50
TC 17
Z9 19
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 671
EP 681
DI 10.1016/j.imavis.2014.02.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700006
DA 2024-07-18
ER

PT J
AU Sun, LJ
   Liang, XH
   Zhao, QP
AF Sun, Linjia
   Liang, Xiaohui
   Zhao, Qinping
TI Automatic sub-category partitioning and parts localization for learning
   a robust object model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object model; Topic model; Layout topic; Sub-category partitioning; Part
   localization
AB This paper introduces a novel topic model for learning a robust object model. In this hierarchical model, the layout topic is used to capture the local relationships among a limited number of parts when the part topic is used to locate the potential part regions. Naturally, an object model is represented as a probability distribution over a set of parts with certain layouts. Rather than a monolithic model, our object model is composed of multiple sub-category models designed to capture the significant variations in appearance and shape of an object category. Given a set of object instances with a bounding box, an iterative learning process is proposed to divide them into several sub-categories and learn the corresponding sub-category models without any supervision. Through an experiment in object detection, the learned object model is examined and the results highlight the advantages of our present method compared with others. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Sun, Linjia; Liang, Xiaohui; Zhao, Qinping] Beihang Univ, Sch Comp Sci & Engn, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
C3 Beihang University
RP Liang, XH (corresponding author), POB 6863,37 Xueyuan Rd, Beijing 100191, Peoples R China.
EM Ixh@vrlab.buaa.edu.cn
OI liang, xiaohui/0000-0001-6351-2538
FU National Natural Science Foundation of China [61170186]; Beijing Natural
   Science Foundation [4112032]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No. 61170186) and also was supported by the Beijing Natural
   Science Foundation (Grant No. 4112032) (Researches on Human Body
   Segmentation Methods in Natural Environment based on Computer Vision).
CR Andreetto M, 2012, IEEE T PATTERN ANAL, V34, P1842, DOI 10.1109/TPAMI.2011.268
   [Anonymous], ICARO IMAGE COLLECTI
   [Anonymous], NIPS
   [Anonymous], CVPR
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Du N, 2007, PROCEEDINGS OF THE IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE, P100, DOI 10.1109/WI.2007.36
   Everingham Mark, 2007, PASCAL VISUAL OBJECT
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Ferrari V, 2001, PROC CVPR IEEE, P226
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Fritz M., 2008, CVPR, P1
   Glasner D, 2011, IEEE I CONF COMP VIS, P1275, DOI 10.1109/ICCV.2011.6126379
   Grauman K, 2007, J MACH LEARN RES, V8, P725
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Larlus D, 2009, IMAGE VISION COMPUT, V27, P523, DOI 10.1016/j.imavis.2008.04.022
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Long Zhu, 2010, 2010 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1919, DOI 10.1109/CVPR.2010.5539865
   Lopez-Sastre R. J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1052, DOI 10.1109/ICCVW.2011.6130367
   Özuysal M, 2009, PROC CVPR IEEE, P778, DOI 10.1109/CVPRW.2009.5206633
   Ott P, 2011, PROC CVPR IEEE, P1513, DOI 10.1109/CVPR.2011.5995357
   Savarese S, 2007, IEEE I CONF COMP VIS, P1245
   Schnitzspan P, 2010, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2010.5540220
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sudderth EB, 2008, INT J COMPUT VISION, V77, P291, DOI 10.1007/s11263-007-0069-5
   Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309
   Todorovic Sinisa., 2008, CVPR
   Tran D, 2010, LECT NOTES COMPUT SC, V6314, P227, DOI 10.1007/978-3-642-15561-1_17
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Wang Y, 2011, PROC CVPR IEEE, P1705, DOI 10.1109/CVPR.2011.5995519
   Zhang N, 2012, PROC CVPR IEEE, P3665, DOI 10.1109/CVPR.2012.6248364
NR 32
TC 0
Z9 0
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2014
VL 32
IS 9
BP 579
EP 589
DI 10.1016/j.imavis.2014.06.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AO6QY
UT WOS:000341477800003
DA 2024-07-18
ER

PT J
AU Zhu, Y
   Chen, WB
   Guo, GD
AF Zhu, Yu
   Chen, Wenbin
   Guo, Guodong
TI Evaluating spatiotemporal interest point features for depth-based action
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Spatiotemporal interest point (STIP); Detectors;
   Descriptors; STIP features; RGB-D sensor; Evaluation; STIP feature
   refinement; Feature fusion
AB Human action recognition has lots of real-world applications, such as natural user interface, virtual reality, intelligent surveillance, and gaming. However, it is still a very challenging problem. In action recognition using the visible light videos, the spatiotemporal interest point (STIP) based features are widely used with good performance. Recently, with the advance of depth imaging technology, a new modality has appeared for human action recognition. It is important to assess the performance and usefulness of the STIP features for action analysis on the new modality of 3D depth map. In this paper, we evaluate the spatiotemporal interest point (STIP) based features for depth-based action recognition. Different interest point detectors and descriptors are combined to form various STIP features. The bag-of-words representation and the SVM classifiers are used for action learning. Our comprehensive evaluation is conducted on four challenging 3D depth databases. Further, we use two schemes to refine the STIP features, one is to detect the interest points in RGB videos and apply to the aligned depth sequences, and the other is to use the human skeleton to remove irrelevant interest points. These refinements can help us have a deeper understanding of the STIP features on 3D depth data. Finally, we investigate a fusion of the best STIP features with the prevalent skeleton features, to present a complementary use of the STIP features for action recognition on 3D data. The fusion approach gives significantly higher accuracies than many state-of-the-art results. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Zhu, Yu; Chen, Wenbin; Guo, Guodong] W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
C3 West Virginia University
RP Guo, GD (corresponding author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
EM guodong.guo@mail.wvu.edu
RI Guo, Guodong/M-5066-2015
OI Guo, Guodong/0000-0001-9583-0055
CR [Anonymous], BMVC BRIT MACH VIS C
   [Anonymous], 2013, IEEE C COMP VIS PATT
   [Anonymous], 2008, BRIT MACH VIS C
   [Anonymous], P INT JOINT C ART IN
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bingbing Ni, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1147, DOI 10.1109/ICCVW.2011.6130379
   Breiman L., 2001, Mach. Learn., V45, P5
   Devanne M, 2013, LECT NOTES COMPUT SC, V8158, P456, DOI 10.1007/978-3-642-41190-8_49
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Jhuang H., 2007, IEEE 11 CONE COMPUTE, P1
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2004, INT C PATT RECOG, P52, DOI 10.1109/ICPR.2004.1334003
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2006, LECT NOTES COMPUT SC, V3667, P91
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Miranda L., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P268, DOI 10.1109/SIBGRAPI.2012.44
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Seidenari L, 2013, IEEE COMPUT SOC CONF, P479, DOI 10.1109/CVPRW.2013.77
   Shabani A. H., 2012, 2012 Canadian Conference on Computer and Robot Vision, P468, DOI 10.1109/CRV.2012.69
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Vieira Antonio W., 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P252, DOI 10.1007/978-3-642-33275-3_31
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wong S. F., 2007, IEEE 11 CONE COMPUTE, P1
   Xia L., 2012, CVPR 2012 HAU3D Workshop, P20
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, J VIS COMMUN IMAGE R, V25, P2, DOI 10.1016/j.jvcir.2013.03.001
   Zhang H., 2011, P 2011 IEEE RSJ INT, P2044, DOI [DOI 10.1109/IROS.2011.6094489, 10.1109/IROS.2011.6094489]
   Zhao YX, 2012, ADV DIFFER EQU-NY, P1, DOI 10.1186/1687-1847-2012-15
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 38
TC 89
Z9 94
U1 0
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 453
EP 464
DI 10.1016/j.imavis.2014.04.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600001
DA 2024-07-18
ER

PT J
AU Wen, LY
   Guo, GD
AF Wen, Lingyun
   Guo, Guodong
TI A computational approach to body mass index prediction from face images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Body mass index (BMI); Facial features; BMI prediction; Machine vision;
   Large database
ID ACTIVE SHAPE MODELS; AGE
AB Human faces encode plenty of useful information. Recent studies in psychology and human perception have found that facial features have relations to human weight or body mass index (BMI). These studies focus on finding the correlations between facial features and the BMI. Motivated by the recent psychology studies, we develop a computational method to predict the BMI from face images automatically. We formulate the BMI prediction from facial features as a machine vision problem, and evaluate our approach on a large database with more than 14,500 face images. A promising result has been obtained, which demonstrates the feasibility of developing a computational system for BMI prediction from face images at a large scale. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Wen, Lingyun; Guo, Guodong] W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
C3 West Virginia University
RP Guo, GD (corresponding author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
EM guodong.guo@mail.wvu.edu
RI Guo, Guodong/M-5066-2015
OI Guo, Guodong/0000-0001-9583-0055
FU NSF CITeR grant; NIJ [2010-DD-BX-0161]; Direct For Computer & Info Scie
   & Enginr; Division Of Computer and Network Systems [1066197] Funding
   Source: National Science Foundation
FX The authors would like to thank K. Ricanek for providing the MORPH
   database for this study. The work is partially supported by an NSF CITeR
   grant and an NIJ grant 2010-DD-BX-0161. The authors are grateful to the
   anonymous reviewers for their detailed comments and suggestions to
   improve the paper.
CR [Anonymous], 1998, STAT LEARNING THEORY
   Coetzee V, 2010, PERCEPTION, V39, P51, DOI 10.1068/p6560
   Coetzee V, 2009, PERCEPTION, V38, P1700, DOI 10.1068/p6423
   COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Duong Duc P., 2011, EVIDENCE BASED COMPL
   DURBIN J, 1950, BIOMETRIKA, V37, P409, DOI 10.1093/biomet/37.3-4.409
   Gallagher D, 1996, AM J EPIDEMIOL, V143, P228, DOI 10.1093/oxfordjournals.aje.a008733
   Guo G. -D., 2010, IEEE INT WORKSH AN M
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   KEYS A, 1972, J CHRON DIS, V25, P329, DOI 10.1016/0021-9681(72)90027-6
   Mahoor M. H., 2006, Proceedings of the 7th International Conference on Automatic Face and Gesture Recognition
   MILBORROW S, 2007, THESIS U CAPE TOWN
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Navidi W., 2008, Statistics for Engineers and Scientists, V2
   Rasmussen C. E., 2006, GAUSSIAN PROCESSES M, V1
   Renehan A.G., 2008, Lancet, V2008, P536
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   RODGERS JL, 1988, AM STAT, V42, P59, DOI 10.2307/2685263
   Sebire NJ, 2001, INT J OBESITY, V25, P1175, DOI 10.1038/sj.ijo.0801670
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Viola P., 2001, P 2001 IEEE COMP VIS
   Wilcox RR, 2010, FUNDAMENTAL OF MODERN STATISTICAL METHODS: SUBSTANTIALLY IMPROVING POWER AND ACCURACY, SECOND EDITION, P1, DOI 10.1007/978-1-4419-5525-8
   Zebrowitz LA, 2006, SOC COGNITION, V24, P657, DOI 10.1521/soco.2006.24.5.657
NR 24
TC 50
Z9 64
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2013
VL 31
IS 5
BP 392
EP 400
DI 10.1016/j.imavis.2013.03.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 154YR
UT WOS:000319713100003
DA 2024-07-18
ER

PT J
AU Alcantarilla, PF
   Bergasa, LM
   Davison, AJ
AF Alcantarilla, Pablo F.
   Bergasa, Luis M.
   Davison, Andrew J.
TI Gauge-SURF descriptors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gauge coordinates; Scale space; Feature descriptors; Integral image
ID IMAGE; SCALE
AB In this paper, we present a novel family of multiscale local feature descriptors, a theoretically and intuitively well justified variant of SURF which is straightforward to implement but which nevertheless is capable of demonstrably better performance with comparable computational cost. Our family of descriptors, called Gauge-SURF (G-SURF), is based on second-order multiscale gauge derivatives. While the standard derivatives used to build a SURF descriptor are all relative to a single chosen orientation, gauge derivatives are evaluated relative to the gradient direction at every pixel. Like standard SURF descriptors, G-SURF descriptors are fast to compute due to the use of integral images, but have extra matching robustness due to the extra invariance offered by gauge derivatives. We present extensive experimental image matching results on the Mikolajczyk and Schmid dataset which show the clear advantages of our family of descriptors against first-order local derivatives based descriptors such as: SURF, Modified-SURF (M-SURF) and SIFT, in both standard and upright forms. In addition, we also show experimental results on large-scale 3D Structure from Motion (SfM) and visual categorization applications. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Alcantarilla, Pablo F.] Univ Auvergne, ISIT UMR CNRS 6284, Clermont Ferrand, France.
   [Bergasa, Luis M.] Univ Alcala, Dept Elect, Madrid, Spain.
   [Davison, Andrew J.] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
C3 Universite Clermont Auvergne (UCA); Universidad de Alcala; Imperial
   College London
RP Alcantarilla, PF (corresponding author), Univ Auvergne, ISIT UMR CNRS 6284, Clermont Ferrand, France.
EM pablofdezalc@gmail.com; luism.bergasa@uah.es; ajd@doc.ic.ac.uk
RI Bergasa, Luis M./H-9810-2013
OI Bergasa, Luis M./0000-0002-0087-3077; Fernandez Alcantarilla,
   Pablo/0000-0001-7185-2911
FU Spanish Ministerio de Economia y Competitividad through the project
   ADD-Gaze [TRA2011-29001-C04-01]; Comunidad de Madrid through the project
   Robocity2030 [S2009/DPI-1559]; ERC [210346]; European Research Council
   (ERC) [210346] Funding Source: European Research Council (ERC)
FX This work has been financed with funds from the Spanish Ministerio de
   Economia y Competitividad through the project ADD-Gaze
   (TRA2011-29001-C04-01), as well as from the Comunidad de Madrid through
   the project Robocity2030 (S2009/DPI-1559). Andrew J. Davison would like
   to acknowledge support from ERC Starting Grant 210346. The authors would
   also like to thank colleagues at Imperial College London for many
   discussions.
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Agrawal M., 2008, EUR C COMP VIS ECCV
   ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   Angeli A, 2008, IEEE T ROBOT, V24, P1027, DOI 10.1109/TRO.2008.2004514
   [Anonymous], 2007, 070012 UCLA CSD
   [Anonymous], 2006, P 1 INT WORKSH MOB V
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Berg AC, 2001, PROC CVPR IEEE, P607
   Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P376, DOI 10.1109/83.661188
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   DAMON J, 1995, J DIFFER EQUATIONS, V115, P368, DOI 10.1006/jdeq.1995.1019
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Dreuw P., 2009, BRIT MACH VIS C BMVC
   Evans C., 2009, CSTR09001 U BRIST
   Fergus R, 2003, PROC CVPR IEEE, P264
   Florack L. M. J., 1993, Journal of Mathematical Imaging and Vision, V3, P327, DOI 10.1007/BF01664793
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Goesele M., 2007, P INT C COMP VIS ICC, P14
   Goesele M., 2006, COMP VIS PATT REC 20, P2402, DOI DOI 10.1109/CVPR.2006.199
   Hua G., 2007, INT C COMP VIS ICCV
   Kaess M, 2009, IEEE INT CONF ROBOT, P973
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Kuijper A, 2009, IMAGE VISION COMPUT, V27, P1023, DOI 10.1016/j.imavis.2008.09.003
   Lewis D.D, 1998, EUR C MACH LEARN, P4
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu R., 2009, WRI GLOB C INT SYST
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Nasrabadi N.M, 2007, Pattern recognition and machine learning, V16
   NISTER D, 2004, IEEE C COMP VIS PATT
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Platel B., 2006, EUR C COMP VIS ECCV
   ROTHWELL CA, 1992, LECT NOTES COMPUT SC, V588, P757
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Schmid C., 1995, Matching by local invariants
   ter Haar Romeny B.M., 2003, MULTISCALE COMPUTER
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Van Gool L., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P642, DOI 10.1007/BFb0015574
   Vedaldi A., VLFEAT OPEN PORTABLE
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yebes J., 2011, IEEE INT VEH S 4
NR 47
TC 24
Z9 29
U1 1
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2013
VL 31
IS 1
BP 103
EP 116
DI 10.1016/j.imavis.2012.11.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 084RP
UT WOS:000314557100008
DA 2024-07-18
ER

PT J
AU Alnajar, F
   Shan, CF
   Gevers, T
   Geusebroek, JM
AF Alnajar, Fares
   Shan, Caifeng
   Gevers, Theo
   Geusebroek, Jan-Mark
TI Learning-based encoding with soft assignment for age estimation under
   unconstrained imaging conditions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Age estimation; Codebook; Local features; Face
ID CLASSIFICATION; IMAGES
AB In this paper we propose to adopt a learning-based encoding method for age estimation under unconstrained imaging conditions. A similar approach [Cao et al., 2010] is applied to face recognition in real-life face images. However, the feature vectors are encoded in hard manner i.e. each feature vector is assigned to one code. The face is divided into patches where a code histogram is built for each patch. However, the codebook is learned using sample features from the entire face.
   Therefore, we propose an approach to extract robust and discriminative facial features and use soft encoding. Instead of learning a codebook from the entire face, we extract and learn multiple codebooks for individual face patches. The encoding is done by a weighting scheme in which each pixel is softly assigned to multiple candidate codes. Finally, orientation histogram of local gradients in neighborhood has been introduced as feature vector for code learning.
   On a large scale face dataset which contains 2744 real-life faces, the age group classification using our method achieves an absolute(relative) improvement of 3.6%(6.5%) over the best reported results [Shan, 2010]. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Alnajar, Fares; Gevers, Theo; Geusebroek, Jan-Mark] Univ Amsterdam, Inst Informat, NL-1098 XH Amsterdam, Netherlands.
   [Alnajar, Fares; Shan, Caifeng] Philips Res, NL-5656 AE Eindhoven, Netherlands.
C3 University of Amsterdam; Philips; Philips Research
RP Alnajar, F (corresponding author), Univ Amsterdam, Inst Informat, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
EM F.Alnajar@uva.nl
RI Shan, Caifeng/W-6178-2019
OI Shan, Caifeng/0000-0002-2131-1671
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], IEEE INT C AUT FAC G
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Choi SE, 2011, PATTERN RECOGN, V44, P1262, DOI 10.1016/j.patcog.2010.12.005
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Freund Y., 2007, Advances in Neural Information Processing Systems
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Gao W, 2009, LECT NOTES COMPUT SC, V5558, P169, DOI 10.1007/978-3-642-01793-3_18
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Huang Gary B., 2007, TECHNICAL REPORT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Meng X, 2006, INT C PATT RECOG, P536
   Ni B., 2009, Proceedings of the 17th ACM international conference on Multimedia, P85
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Shan C., 2010, ACM WORKSH MULT PERV
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Xie SF, 2009, SIGNAL PROCESS, V89, P2333, DOI 10.1016/j.sigpro.2009.02.016
   Yan S, 2008, PR IEEE COMP DESIGN, P142, DOI 10.1109/ICCD.2008.4751853
   Yan SC, 2008, INT CONF ACOUST SPEE, P737
   Yan SC, 2009, IEEE T IMAGE PROCESS, V18, P202, DOI 10.1109/TIP.2008.2006400
   Yang ZG, 2007, LECT NOTES COMPUT SC, V4642, P464
NR 28
TC 34
Z9 36
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 946
EP 953
DI 10.1016/j.imavis.2012.07.009
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800003
DA 2024-07-18
ER

PT J
AU Liu, W
   Ribeiro, E
AF Liu, Wei
   Ribeiro, Eraldo
TI A survey on image-based continuum-body motion estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Nonrigid image registration; Continuum motion; Meshless registration
   methods
ID OPTICAL-FLOW ESTIMATION; RADIAL BASIS FUNCTIONS; NONRIGID REGISTRATION;
   FLUID MOTION; ELASTIC REGISTRATION; DEFORMABLE MODELS; FIELD ANALYSIS;
   SHAPE; INTENSITY; ALGORITHM
AB This paper presents a survey of the state-of-the-art in motion estimation of continuum objects such as elastic solids (e.g., human organs, skin, and biomedical tissues) and fluids (e.g., clouds, ocean flows, and air flows). The survey is focused on the estimation methodologies, rather than on specific applications. We begin by summarizing the main components and challenges of continuum-motion estimation, and structure our review around these components. We provide a classification of the related work according to their solutions to these challenges. A discussion on the methodologies for quantitative evaluation of methods is also provided. Finally, we conclude the survey by pointing out some open problems in continuum-motion estimation. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Liu, Wei; Ribeiro, Eraldo] Florida Inst Technol, Dept Comp Sci, Comp Vis & Bioinspired Comp Lab, Melbourne, FL 32901 USA.
C3 Florida Institute of Technology
RP Ribeiro, E (corresponding author), Florida Inst Technol, Dept Comp Sci, Comp Vis & Bioinspired Comp Lab, Melbourne, FL 32901 USA.
EM eribeiro@cs.fit.edu
RI Ribeiro, Eraldo/A-1490-2016
OI Ribeiro, Eraldo/0000-0002-6008-3990
CR Ackerman MJ, 1998, P IEEE, V86, P504, DOI 10.1109/5.662875
   Alexa M, 2003, IEEE T VIS COMPUT GR, V9, P3, DOI 10.1109/TVCG.2003.1175093
   AMODEI L, 1991, J APPROX THEORY, V67, P51, DOI 10.1016/0021-9045(91)90025-6
   Andreopoulos A, 2008, MED IMAGE ANAL, V12, P335, DOI 10.1016/j.media.2007.12.003
   [Anonymous], 2009, INT C MAN SER SCI
   [Anonymous], THESIS YALE U
   [Anonymous], MODELLIERUNG WEICHGE
   [Anonymous], INT C FUNCT MAPP HUM
   [Anonymous], P 25 ANN C COMP GRAP
   [Anonymous], IJCC WORKSH DIG ENG
   [Anonymous], P VIS MOD VIS C
   [Anonymous], 1968, P 1968 ACM NAT C
   [Anonymous], MED IMAGE COMPUTING
   [Anonymous], MED IMAGE COMPUTING
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], IEEE T VISUALIZATION
   [Anonymous], SCALE SPACE VARIATIO
   ARAD N, 1994, CVGIP-GRAPH MODEL IM, V56, P161, DOI 10.1006/cgip.1994.1015
   Arganda-Carreras I, 2006, LECT NOTES COMPUT SC, V4241, P85
   Arsigny V, 2005, LECT NOTES COMPUT SC, V3749, P115
   Ashburner J, 2007, NEUROIMAGE, V38, P95, DOI 10.1016/j.neuroimage.2007.07.007
   BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3
   Baker Simon, 2007, 2007 11th IEEE International Conference on Computer Vision, P1
   Bharatha A, 2001, MED PHYS, V28, P2551, DOI 10.1118/1.1414009
   Bischoff S, 2005, ACM T GRAPHIC, V24, P1332, DOI 10.1145/1095878.1095883
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Botsch M, 2005, COMPUT GRAPH FORUM, V24, P611, DOI 10.1111/j.1467-8659.2005.00886.x
   Brendel B, 2002, Comput Aided Surg, V7, P146, DOI 10.1002/igs.10038
   Brock KK, 2005, MED PHYS, V32, P1647, DOI 10.1118/1.1915012
   Broit C., 1981, Optimal registration of deformed images
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Buhmann M.D., 2003, C MO AP C M, V12, DOI 10.1017/CBO9780511543241
   Bullmore ET, 1999, HUM BRAIN MAPP, V7, P38, DOI 10.1002/(SICI)1097-0193(1999)7:1<38::AID-HBM4>3.3.CO;2-H
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Castillo E, 2009, J MED BIOL ENG, V29, P222
   Chandrashekara R, 2003, LECT NOTES COMPUT SC, V2732, P599
   Chen T, 2008, LECT NOTES COMPUT SC, V5242, P313, DOI 10.1007/978-3-540-85990-1_38
   Chen T, 2009, LECT NOTES COMPUT SC, V5761, P43, DOI 10.1007/978-3-642-04268-3_6
   Chen T, 2010, MED PHYS, V37, P197, DOI 10.1118/1.3271389
   Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985
   Christensen GE, 2006, LECT NOTES COMPUT SC, V4057, P128
   Christensen GE, 1996, IEEE T IMAGE PROCESS, V5, P1435, DOI 10.1109/83.536892
   Cohen-Steiner D, 2004, ACM T GRAPHIC, V23, P905, DOI 10.1145/1015706.1015817
   Corpetti T, 2002, IEEE T PATTERN ANAL, V24, P365, DOI 10.1109/34.990137
   Corpetti T, 2000, INT C PATT RECOG, P1033, DOI 10.1109/ICPR.2000.903722
   Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4
   Cremers D, 2003, IMAGE VISION COMPUT, V21, P77, DOI 10.1016/S0262-8856(02)00128-2
   Cuzol A, 2007, INT J COMPUT VISION, V75, P329, DOI 10.1007/s11263-007-0037-0
   Cuzol A, 2009, IEEE T PATTERN ANAL, V31, P1278, DOI 10.1109/TPAMI.2008.152
   D'Agostino E., 2002, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2002. 5th International Conference. Proceedings, Part II (Lecture Notes in Computer Science Vol.2489), P541
   Davatzikos C, 1997, COMPUT VIS IMAGE UND, V66, P207, DOI 10.1006/cviu.1997.0605
   DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811
   Devlaminck V, 1999, IEEE SIGNAL PROC LET, V6, P162, DOI 10.1109/97.769358
   Eils R, 2003, J CELL BIOL, V161, P477, DOI 10.1083/jcb.200302097
   Farnebäck G, 2006, LECT NOTES COMPUT SC, V4190, P857
   Fleishman S, 2005, ACM T GRAPHIC, V24, P544, DOI 10.1145/1073204.1073227
   Fleute M, 1999, LECT NOTES COMPUT SC, V1679, P138
   Gholipour A, 2007, IEEE T MED IMAGING, V26, P427, DOI 10.1109/TMI.2007.892508
   Grenander U, 1998, Q APPL MATH, V56, P617, DOI 10.1090/qam/1668732
   Gu XJ, 2010, PHYS MED BIOL, V55, P207, DOI 10.1088/0031-9155/55/1/012
   Haber E, 2006, SIAM J SCI COMPUT, V27, P1594, DOI 10.1137/040608106
   Hagemann A, 1999, IEEE T MED IMAGING, V18, P875, DOI 10.1109/42.811267
   Hansen MS., 2008, Computer Vision and Pattern Recognition, P1
   Heitz D, 2010, EXP FLUIDS, V48, P369, DOI 10.1007/s00348-009-0778-3
   Hellier P, 2003, IEEE T MED IMAGING, V22, P1120, DOI 10.1109/TMI.2003.816961
   Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201
   Hoey J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1086
   Holden M, 2008, IEEE T MED IMAGING, V27, P111, DOI 10.1109/TMI.2007.904691
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huang XL, 2006, IEEE T PATTERN ANAL, V28, P1303, DOI 10.1109/TPAMI.2006.171
   Irgens F., 2008, Continuum mechanics
   Isambert T, 2008, LECT NOTES COMPUT SC, V5305, P665, DOI 10.1007/978-3-540-88693-8_49
   Isambert T, 2007, IEEE IMAGE PROC, P1069
   Kihl O, 2008, IEEE IMAGE PROC, P857, DOI 10.1109/ICIP.2008.4711890
   Kim J, 2004, IEEE T MED IMAGING, V23, P1430, DOI 10.1109/TMI.2004.835313
   Klein A, 2010, NEUROIMAGE, V51, P214, DOI 10.1016/j.neuroimage.2010.01.091
   Klein A, 2009, NEUROIMAGE, V46, P786, DOI 10.1016/j.neuroimage.2008.12.037
   Klein S, 2007, I S BIOMED IMAGING, P1300, DOI 10.1109/ISBI.2007.357098
   Klein S, 2010, IEEE T MED IMAGING, V29, P196, DOI 10.1109/TMI.2009.2035616
   Kobbelt L, 2004, COMPUT GRAPH-UK, V28, P801, DOI 10.1016/j.cag.2004.08.009
   Kobbelt LP, 2000, COMPUT GRAPH FORUM, V19, pC249, DOI 10.1111/1467-8659.00417
   Koch R. M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P421, DOI 10.1145/237170.237281
   LANCASTER P, 1981, MATH COMPUT, V37, P141, DOI 10.1090/S0025-5718-1981-0616367-1
   Levin D, 1998, MATH COMPUT, V67, P1517, DOI 10.1090/S0025-5718-98-00974-0
   Li B, 2008, LECT NOTES COMPUT SC, V5242, P880
   Li F, 2010, PROC CVPR IEEE, P2448, DOI 10.1109/CVPR.2010.5539942
   Liu G.-R., 2009, Meshfree Methods: Moving Beyond the Finite Element Method
   Liu HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P289, DOI 10.1109/ICCV.2003.1238357
   Liu M.B., 2003, SMOOTHED PARTICLE HY
   Liu W, 2010, LECT NOTES COMPUT SC, V6454, P262, DOI 10.1007/978-3-642-17274-8_26
   Liu W, 2010, LECT NOTES COMPUT SC, V6454, P242, DOI 10.1007/978-3-642-17274-8_24
   Losasso F, 2004, ACM T GRAPHIC, V23, P457, DOI 10.1145/1015706.1015745
   Maes F, 2003, P IEEE, V91, P1699, DOI 10.1109/JPROC.2003.817864
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Makram-Ebeid S., 2007, IEEE INT C COMPUTER, P1
   McInerney T, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P171, DOI 10.1109/MMBIA.1996.534069
   Melenk JM, 1996, COMPUT METHOD APPL M, V139, P289, DOI 10.1016/S0045-7825(96)01087-0
   Metaxas D.N., 1997, PHYS BASED DEFORMABL
   Meyer C R, 1997, Med Image Anal, V1, P195, DOI 10.1016/S1361-8415(97)85010-4
   Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Myronenko A, 2010, IEEE T MED IMAGING, V29, P1882, DOI 10.1109/TMI.2010.2053043
   Nealen A, 2006, COMPUT GRAPH FORUM, V25, P809, DOI 10.1111/j.1467-8659.2006.01000.x
   Nir T, 2008, INT J COMPUT VISION, V76, P205, DOI 10.1007/s11263-007-0051-2
   Noh J., 2000, P ACM S VIRTUAL REAL, P166, DOI DOI 10.1145/502390.502422.7
   Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293
   Okamoto K., 2000, Journal of Visualization, V3, P115, DOI 10.1007/BF03182404
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Papadakis N, 2008, SIAM J IMAGING SCI, V1, P343, DOI 10.1137/080713896
   Pennec X, 2001, INTERNATIONAL WORKSHOP ON MEDICAL IMAGING AND AUGMENTED REALITY, PROCEEDINGS, P79, DOI 10.1109/MIAR.2001.930268
   Penney GP, 1998, IEEE T MED IMAGING, V17, P586, DOI 10.1109/42.730403
   Periaswamy S, 2006, MED IMAGE ANAL, V10, P452, DOI 10.1016/j.media.2005.03.006
   Petrila T., 2005, Basics of fluid mechanics and introduction to computational fluid dynamics
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Pock T, 2007, LECT NOTES COMPUT SC, V4792, P511
   Prastawa M, 2005, LECT NOTES COMPUT SC, V3749, P26
   RAO AR, 1992, IEEE T PATTERN ANAL, V14, P693, DOI 10.1109/34.142908
   Roche A, 2001, IEEE T MED IMAGING, V20, P1038, DOI 10.1109/42.959301
   Rohde GK, 2003, IEEE T MED IMAGING, V22, P1470, DOI 10.1109/TMI.2003.819299
   Rohr K, 2001, IEEE T MED IMAGING, V20, P526, DOI 10.1109/42.929618
   Rose CF, 2001, COMPUT GRAPH FORUM, V20, pC239
   Rudin W., 2006, REAL COMPLEX ANAL
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Rueckert D., 2001, 4 INT C MEDICAL IMAG, V2208, P77
   Rueckert D, 2006, LECT NOTES COMPUT SC, V4191, P702
   Ruhnau P, 2005, EXP FLUIDS, V38, P21, DOI 10.1007/s00348-004-0880-5
   Ruhnau P, 2007, EXP FLUIDS, V42, P61, DOI 10.1007/s00348-006-0220-z
   Ruhnau P, 2007, MEAS SCI TECHNOL, V18, P755, DOI 10.1088/0957-0233/18/3/027
   Salomon D., 2006, Curves and Surfaces for Computer Graphics
   Schnabel J. A., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P344
   Schnabel JA, 2003, IEEE T MED IMAGING, V22, P238, DOI 10.1109/TMI.2002.808367
   Sermesant M, 2003, MED IMAGE ANAL, V7, P475, DOI 10.1016/S1361-8415(03)00068-9
   Shams R, 2010, IEEE SIGNAL PROC MAG, V27, P50, DOI 10.1109/MSP.2009.935387
   Shattuck DW, 2008, NEUROIMAGE, V39, P1064, DOI 10.1016/j.neuroimage.2007.09.031
   Shekarforoush H, 1996, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.1996.517123
   Shen DG, 2002, IEEE T MED IMAGING, V21, P1421, DOI 10.1109/TMI.2002.803111
   Shi PC, 1999, INT J COMPUT VISION, V35, P87, DOI 10.1023/A:1008163112590
   SHU CF, 1994, IEEE T PATTERN ANAL, V16, P946, DOI 10.1109/34.310692
   Sorzano COS, 2005, IEEE T BIO-MED ENG, V52, P652, DOI 10.1109/TBME.2005.844030
   Sun Y, 2010, IEEE T SYST MAN CY A, V40, P461, DOI 10.1109/TSMCA.2010.2041659
   SUTER D, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P939, DOI 10.1109/CVPR.1994.323929
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Thomas M, 2005, MEAS SCI TECHNOL, V16, P865, DOI 10.1088/0957-0233/16/3/031
   TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471
   Van Hecke W, 2009, NEUROIMAGE, V46, P692, DOI 10.1016/j.neuroimage.2009.02.032
   Vercauteren T, 2008, LECT NOTES COMPUT SC, V5241, P754, DOI 10.1007/978-3-540-85988-8_90
   Vercauteren T, 2009, NEUROIMAGE, V45, pS61, DOI 10.1016/j.neuroimage.2008.10.040
   Vermeer KA, 2004, COMPUT BIOL MED, V34, P209, DOI 10.1016/S0010-4825(03)00055-6
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Wand M, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1516522.1516526
   Wang JG, 2002, COMPUT METHOD APPL M, V191, P2611, DOI 10.1016/S0045-7825(01)00419-4
   Wang JG, 2002, INT J NUMER METH ENG, V54, P1623, DOI 10.1002/nme.489
   Wang JZ, 1996, PHYS MED BIOL, V41, P1045, DOI 10.1088/0031-9155/41/6/008
   Wang XX, 2008, LECT NOTES COMPUT SC, V5241, P636, DOI 10.1007/978-3-540-85988-8_76
   Wei Liu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P185, DOI 10.1109/ICPR.2010.54
   Welch W., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P247, DOI 10.1145/192161.192216
   Wendland H., 1995, Advances in Computational Mathematics, V4, P389, DOI 10.1007/BF02123482
   Wendland H, 1999, MATH COMPUT, V68, P1521, DOI 10.1090/S0025-5718-99-01102-3
   Wendland H., 2004, Scattered data approximation, DOI [10.1017/CBO9780511617539, DOI 10.1017/CBO9780511617539]
   Wildes RP, 2000, COMPUT VIS IMAGE UND, V80, P246, DOI 10.1006/cviu.2000.0874
   Wong KY, 2009, PATTERN RECOGN, V42, P1371, DOI 10.1016/j.patcog.2008.11.037
   Wong KKL, 2009, PLOS ONE, V4, DOI 10.1371/journal.pone.0004747
   Yi Z, 2009, PROC CVPR IEEE, P2200, DOI 10.1109/CVPRW.2009.5206637
   Yin YB, 2009, MED PHYS, V36, P4213, DOI 10.1118/1.3193526
   Yuan J, 2007, SIAM J SCI COMPUT, V29, P2283, DOI 10.1137/060660709
   Zhang YJ, 2005, COMPUT METHOD APPL M, V194, P5083, DOI 10.1016/j.cma.2004.11.026
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 170
TC 12
Z9 15
U1 0
U2 40
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2011
VL 29
IS 8
BP 509
EP 523
DI 10.1016/j.imavis.2011.03.003
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 822RB
UT WOS:000295066200002
DA 2024-07-18
ER

PT J
AU Qing, CM
   Jiang, JM
AF Qing, Chunmei
   Jiang, Jianmin
TI An EDBoost algorithm towards robust face recognition in JPEG compressed
   domain
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Discrete cosine transform (DCT); Face recognition; AdaBoost; Fisher's
   linear discriminant (FLD); Principal component analysis (PCA);
   Independent component analysis (ICA); Euclidean distance (ED); EDBoost
ID ILLUMINATION; EIGENFACES; IMAGES
AB In this paper, we describe a novel multiclass boosting algorithm. EDBoost, to achieve robust face recognition directly in JPEG compressed domain. In comparison with existing boosting algorithms, the proposed EDBoost exploits Euclidean distance (ED) to eliminate non-effective weak classifiers in each iteration of the boosted learning, and hence improves both feature selection and classifier learning by using fewer weak classifiers and producing lower error rates. When applied to face recognition, the EDBoost algorithm is capable of selecting the most discriminative DCT features directly in JPEG compressed domain to achieve high recognition performances. In addition, a new DC replacement scheme is also proposed to reduce the effect of illumination changes. In comparison with the existing techniques, the proposed scheme achieves robust face recognition without losing the important information carried by all DC coefficients. Extensive experiments support the conclusion that the proposed algorithm outperforms all representative existing techniques in terms of boosted learning, multiclass classification, lighting effect reduction and face recognition rates. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Qing, Chunmei; Jiang, Jianmin] Univ Bradford, Digital Media & Syst Res Inst, Bradford BD7 1DP, W Yorkshire, England.
C3 University of Bradford
RP Qing, CM (corresponding author), Univ Bradford, Digital Media & Syst Res Inst, Bradford BD7 1DP, W Yorkshire, England.
EM qingchunmei99@hotmail.com
FU EU [IST-4027312]
FX The authors wish to acknowledge the financial support under EU IST FP-6
   Research Programme with funding under the integrated project: LIVE
   (contract no. IST-4027312).
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Aslam J.A., 2000, P 13 ANN C COMPUTATI, P200
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Breiman L, 1998, BIOMETRICS, DOI [10.1201/9781315139470, DOI 10.2307/2530946]
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Choi SI, 2007, PATTERN RECOGN, V40, P2118, DOI 10.1016/j.patcog.2006.11.020
   EIBL G, 2001, MACHINE LEARNING P 1, P109
   Eickeler S., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P672, DOI 10.1109/ICIP.1999.821721
   Eickeler S, 2000, IMAGE VISION COMPUT, V18, P279, DOI 10.1016/S0262-8856(99)00055-4
   ER KJ, 2005, IEEE T NEURAL NETWOR, V16, P679
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Jing XY, 2004, IEEE T SYST MAN CY B, V34, P2405, DOI 10.1109/TSMCB.2004.837586
   Kivinen J., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, P134, DOI 10.1145/307400.307424
   Kohavi R., 1995, P 14 INT JOINT C ART, P1137
   Kohir VV, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P226
   Lai JH, 2001, PATTERN RECOGN, V34, P95, DOI 10.1016/S0031-3203(99)00200-9
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Liu DH, 2005, PATTERN RECOGN, V38, P1705, DOI 10.1016/j.patcog.2005.03.009
   Molleda Yadira Condes, 2008, ICPR, P1
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   QING C, 2007, 2 INT C SEM DIG MED, P272
   Schapire R.E., 1997, P 14 INT C MACHINE L, P322
   Schapire RE, 2003, LECT NOTES STAT, V171, P149, DOI 10.1007/978-0-387-21579-2_9
   Shen L., 2004, Proc. of Image and Vision Computing NewZealand, P77
   Shen LL, 2006, PATTERN RECOGN LETT, V27, P1758, DOI 10.1016/j.patrec.2006.02.005
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tsapatsoulis N, 1998, INT CONF ACOUST SPEE, P2701, DOI 10.1109/ICASSP.1998.678080
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang P, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P356
   Yang WG, 2002, IEEE PHOTONIC TECH L, V14, P215, DOI 10.1109/68.980526
   Zhao JL, 2003, PATTERN RECOGN LETT, V24, P2703, DOI 10.1016/S0167-8655(03)00113-2
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou D, 2006, PATTERN RECOGN LETT, V27, P536, DOI 10.1016/j.patrec.2005.09.015
NR 40
TC 4
Z9 4
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1659
EP 1670
DI 10.1016/j.imavis.2010.05.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300008
DA 2024-07-18
ER

PT J
AU Saeedi, J
   Moradi, MH
   Faez, K
AF Saeedi, Jamal
   Moradi, Mohammad Hassan
   Faez, Karim
TI A new wavelet-based fuzzy single and multi-channel image denoising
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image denoising; Dual-tree discrete wavelet transform; Fuzzy membership
   function; Multi-channel image
ID BIVARIATE SHRINKAGE; NOISE-REDUCTION; SPARSE
AB In this paper, we propose a new wavelet shrinkage algorithm based on fuzzy logic. In particular, intra-scale dependency within wavelet coefficients is modeled using a fuzzy feature. This feature space distinguishes between important coefficients, which belong to image discontinuity and noisy coefficients. We use this fuzzy feature for enhancing wavelet coefficients' information in the shrinkage step. Then a fuzzy membership function shrinks wavelet coefficients based on the fuzzy feature. In addition, we extend our noise reduction algorithm for multi-channel images. We use inter-relation between different channels as a fuzzy feature for improving the denoising performance compared to denoising each channel, separately. We examine our image denoising algorithm in the dual-tree discrete wavelet transform, which is the new shiftable and modified version of discrete wavelet transform. Extensive comparisons with the state-of-the-art image denoising algorithm indicate that our image denoising algorithm has a better performance in noise suppression and edge preservation. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Saeedi, Jamal; Faez, Karim] Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Moradi, Mohammad Hassan] Amirkabir Univ Technol, Dept Bioelect Biomed Engn, Tehran, Iran.
C3 Amirkabir University of Technology; Amirkabir University of Technology
RP Saeedi, J (corresponding author), Amirkabir Univ Technol, Dept Elect Engn, 424 Hafez Ave, Tehran, Iran.
EM jamal.saeedi@yahoo.com; mhmoradi@aut.ac.ir; kfaez@aut.ac.ir
RI cai, bo/G-1491-2010; faez, karim/K-5117-2019; Moradi, Mohammad
   Hassan/N-6073-2018
OI faez, karim/0000-0002-1159-4866; Moradi, Mohammad
   Hassan/0000-0002-3386-4003
CR [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], 1993, INTRO FUZZY CONTROL, DOI DOI 10.1007/978-3-662-11131-4
   [Anonymous], 2005, Fuzzy expert systems and fuzzy reasoning
   Blu T, 2007, IEEE T IMAGE PROCESS, V16, P2778, DOI 10.1109/TIP.2007.906002
   Chen GY, 2005, PATTERN RECOGN, V38, P115, DOI 10.1016/j.patcog.2004.05.009
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   Dugad R., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P152, DOI 10.1109/ICIP.1999.819568
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   FAN G, 2001, IEEE SIGNAL PROCESS, P125
   Fan GL, 2001, IEEE T SIGNAL PROCES, V49, P115, DOI 10.1109/78.890351
   Hajek P., 1998, Metamathematics of Fuzzy Logic
   Jun L., 2005, 2005 INSTRUMENTATION, P2019
   Kim SD, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P37, DOI 10.1109/ISCAS.1999.779937
   Kingsbury N, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P375, DOI 10.1109/ICIP.2000.899397
   Kingsbury N, 2001, APPL COMPUT HARMON A, V10, P234, DOI 10.1006/acha.2000.0343
   Ling WK, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P531, DOI 10.1109/ISIMP.2001.925450
   Luisier F, 2008, IEEE T IMAGE PROCESS, V17, P482, DOI 10.1109/TIP.2008.919370
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MEGURO M, 2001, IEICE T FUND ELECTR, V2, P424
   Ojo OA, 2000, IEEE T CONSUM ELECTR, V46, P474, DOI 10.1109/30.883396
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   SCHULTE S, 2006, NEW FUZZY BASED WAVE, P12
   Schulte S, 2007, IEEE T IMAGE PROCESS, V16, P1425, DOI 10.1109/TIP.2007.891807
   Selesnick IW, 2002, IEEE T SIGNAL PROCES, V50, P1144, DOI 10.1109/78.995070
   Sendur L, 2002, IEEE SIGNAL PROC LET, V9, P438, DOI 10.1109/LSP.2002.806054
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   SHUTAO L, 2000, P IEEE INT C SIGN PR, V2, P1133
   SIMONCELLI EP, 1992, IEEE T INFORM THEORY, V38, P587, DOI 10.1109/18.119725
   STEIN CM, 1981, ANN STAT, V9, P1135, DOI 10.1214/aos/1176345632
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Vertan C, 1997, IEE CONF PUBL, P313, DOI 10.1049/cp:19970906
   WONG YF, 1995, P IEEE INT C IM PROC, V2, P2129
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zadeh LotfiA., 1974, IFIP C, P591
   Zhang L, 2003, PATTERN RECOGN, V36, P1737, DOI 10.1016/S0031-3203(02)00350-3
   ZLOKOLICA, 2002, P IEEE BEN SIGN PROC, V2, P221
   [No title captured]
NR 40
TC 30
Z9 32
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1611
EP 1623
DI 10.1016/j.imavis.2010.04.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300004
DA 2024-07-18
ER

PT J
AU Faille, F
   Petrou, M
AF Faille, Flore
   Petrou, Maria
TI Derivative-based imaging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image reconstruction; Hexagonal grids; Bio-inspired vision; Derivative
   sensors
ID MOTION DETECTION; SILICON RETINA; EYE-MOVEMENTS; CHIP; SYSTEM; CONTRAST;
   SENSOR
AB We present a new biologically inspired imaging framework which uses sensor motion in a constructive way, contrary to most current imaging techniques. In addition to measuring light intensity, the spatial derivatives of the scene are estimated by measuring the temporal derivatives of the output of the vibrating photoreceptors. This is inspired from the fixational eye movements of the human visual system. When motion is known, these measured spatial derivatives can be used to improve the quality of the intensity image, as well as for object and pattern recognition tasks. This image reconstruction is based on integrating the derivatives while using the measured intensities as integration constants. The results of the imaging framework and of the reconstruction step are high quality images of the light intensities and of its spatial derivatives, which is relevant for further scene understanding. The advantages and the potential of this new imaging framework are shown in many simulations in this paper. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Faille, Flore; Petrou, Maria] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
C3 Imperial College London
RP Petrou, M (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
EM maria.petrou@imperial.ac.uk
FU EPSRC; EPSRC [EP/E045472/1] Funding Source: UKRI
FX This work was supported by an EPSRC translation grant.
CR Barbaro M, 2005, EURASIP J APPL SIG P, V2005, P1062, DOI 10.1155/ASP.2005.1062
   BOAHEN KA, 1992, ADV NEUR IN, V4, P764
   CHONG CP, 1992, IEEE J SOLID-ST CIRC, V27, P93, DOI 10.1109/4.109560
   Culurciello E, 2003, IEEE J SOLID-ST CIRC, V38, P281, DOI 10.1109/JSSC.2002.807412
   DELBRUCK T, 1993, IEEE T NEURAL NETWOR, V4, P529, DOI 10.1109/72.217194
   DELBRUCK T, 1991, P SOC PHOTO-OPT INS, V1541, P92, DOI 10.1117/12.49323
   DEUTSCHMANN RA, 1998, P 1998 INT S CIRC SY, P649
   DUBOIS J, 2006, P 2 INT WORKSH REC C, P177
   Dunbabin M, 2004, IEEE INT CONF ROBOT, P3609, DOI 10.1109/ROBOT.2004.1308812
   Etienne-Cummings R, 2000, IEEE T CIRCUITS-II, V47, P504, DOI 10.1109/82.847066
   EtienneCummings R, 1997, IEEE T CIRCUITS-I, V44, P55, DOI 10.1109/81.558442
   Funatsu E, 1999, JPN J APPL PHYS 2, V38, pL938, DOI 10.1143/JJAP.38.L938
   Gopalan A, 2003, ANALOG INTEGR CIRC S, V37, P243, DOI 10.1023/A:1026278027466
   Higgins CM, 1999, IEEE T CIRCUITS-II, V46, P677, DOI 10.1109/82.769776
   Hongler MO, 2003, IEEE T PATTERN ANAL, V25, P1051, DOI 10.1109/TPAMI.2003.1227982
   Hoshino K, 2000, J MICROELECTROMECH S, V9, P32, DOI 10.1109/84.825774
   Hubei D.H., 1988, EYE BRAIN VISION
   Iida F, 2003, ROBOT AUTON SYST, V44, P201, DOI 10.1016/S0921-8890(03)00070-8
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Kadyrov A, 2004, INT C PATT RECOG, P64
   Katartzis A, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P1, DOI 10.1016/B978-0-12-372529-5.00007-X
   Katsaggelos AggelosK., 2007, SUPER RESOLUTION IMA
   Kimura H, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, PROCEEDINGS, P333
   Kramer J, 1996, IEEE T PATTERN ANAL, V18, P455, DOI 10.1109/34.491628
   Kramer J, 1997, IEEE T CIRCUITS-II, V44, P86, DOI 10.1109/82.554431
   Kramer J, 1998, P SOC PHOTO-OPT INS, V3410, P134, DOI 10.1117/12.324013
   KRAMER J, 1995, IEEE INT SYMP CIRC S, P413, DOI 10.1109/ISCAS.1995.521538
   Kramer J, 2002, IEEE T CIRCUITS-II, V49, P612, DOI 10.1109/TCSII.2002.807270
   Landolt O, 2001, 2001 CONFERENCE ON ADVANCED RESEARCH IN VLSI, PROCEEDINGS, P249, DOI 10.1109/ARVLSI.2001.915565
   Landolt O, 2001, AUTON ROBOT, V11, P233, DOI 10.1023/A:1012482822516
   LICHSTEINER P, 2006, P 2006 IEEE INT SOL
   Lichtsteiner P, 2008, IEEE J SOLID-ST CIRC, V43, P566, DOI 10.1109/JSSC.2007.914337
   Ma SY, 1999, IEEE J SOLID-ST CIRC, V34, P1415, DOI 10.1109/4.792618
   Marr D., 1982, Vision
   Martinez-Conde S, 2004, NAT REV NEUROSCI, V5, P229, DOI 10.1038/nrn1348
   Mead C., 1989, ANALOG VLSI NEURAL S, P30
   Mehta S, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL IV, P784
   Middleton L., 2005, Hexagonal Image Processing: A Practical Approach
   Moini A., 2000, VISION CHIPS
   MOINI A, 1993, P 1993 INT S VLSI TE, P283
   PAILLET F, 1999, P 12 ANN IEEE INT AS, P304
   Park DS, 2003, SENSOR ACTUAT A-PHYS, V108, P75, DOI [10.1016/S0924-4247(03)00292-9, 10.1016/S0924-42(03)00292-9]
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Petrou M, 2008, INTERNATIONAL SYMPOSIUM OF INFORMATION TECHNOLOGY 2008, VOLS 1-4, PROCEEDINGS, P9
   Petrou M, 2008, ARTECH HSE BIOINF BI, P1
   PROKOPOWICZ PN, 1995, INT J COMPUT VISION, V16, P191, DOI 10.1007/BF01539626
   Rucci M, 2007, NATURE, V447, P851, DOI 10.1038/nature05866
   Ruffier F, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, P846
   SANDINI G, 2002, SENSORS SENSING BIOL
   Sarpeshkar R, 1996, P IEEE, V84, P969, DOI 10.1109/5.503298
   SICARD G, 1999, P 25 EUR SOL STAT CI, P306
   Snyder WE, 1999, PROC SPIE, V3661, P716, DOI 10.1117/12.348629
   Stanacevic M, 2005, IEEE T CIRCUITS-I, V52, P2148, DOI 10.1109/TCSI.2005.853356
   STOCKER AA, 2003, P 2003 INT S CIRC SY, P25
   Van der Spiegel J., 1989, ANALOG VLSI IMPLEMEN, P189
   WASHISU K, 2004, Patent No. 6704501
   Yakovleff AJS, 1998, ANALOG INTEGR CIRC S, V15, P183, DOI 10.1023/A:1008203907863
   Yitzhaky Y, 2000, OPT ENG, V39, P2083, DOI 10.1117/1.1305319
NR 58
TC 0
Z9 0
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2010
VL 28
IS 9
BP 1396
EP 1412
DI 10.1016/j.imavis.2010.03.002
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 620NN
UT WOS:000279506700007
DA 2024-07-18
ER

PT J
AU Cousty, J
   Najman, L
   Couprie, M
   Clément-Guinaudeau, S
   Goissen, T
   Garot, J
AF Cousty, J.
   Najman, L.
   Couprie, M.
   Clement-Guinaudeau, S.
   Goissen, T.
   Garot, J.
TI Segmentation of 4D cardiac MRI: Automated method based on
   spatio-temporal watershed cuts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cardiac imagery; 4D-cine-MRI; 4D watershed cut; Discrete mathematical
   morphology
ID MAGNETIC-RESONANCE IMAGES; LEFT-VENTRICLE; SHORT-AXIS; MODEL; ALGORITHM;
   REGISTRATION; TRACKING
AB Based on discrete mathematical morphology, we introduce in this paper a new watershed framework which allows for segmenting spatio-temporal images, that we apply to medical image analysis. Specifically, we propose a new automated and fast procedure to segment the left ventricular myocardium in 4D (3D+t) cine-MRI sequences. Both quantitative and qualitative evaluation are provided. Thanks to the comparison with manual segmentation performed by two cardiologists, we demonstrate the accuracy of the proposed method. The relevance of the ejection fraction and myocardium mass measured from segmentations is also assessed. Furthermore, we show that the proposed 4D procedure allows to keep the temporal coherency between the successive 3D segmentations obtained along the time sequence. In an effort to promote open science, both the data and the software are available on-line. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Cousty, J.; Najman, L.; Couprie, M.] Univ Paris Est, ESIEE Paris Cite Descartes, Equipe A3SI, Lab Informat Gaspard Monge, F-93162 Noisy Le Grand, France.
   [Clement-Guinaudeau, S.; Goissen, T.; Garot, J.] Creteil & Mondor Univ Hosp, AP HP, Fac Med, INSERM,U660, Creteil, France.
C3 Universite Gustave-Eiffel; ESIEE Paris; Institut National de la Sante et
   de la Recherche Medicale (Inserm); Universite
   Paris-Est-Creteil-Val-de-Marne (UPEC); Assistance Publique Hopitaux
   Paris (APHP); Hopital Universitaire Henri-Mondor - APHP
RP Najman, L (corresponding author), Univ Paris Est, ESIEE Paris Cite Descartes, Equipe A3SI, Lab Informat Gaspard Monge, BP99, F-93162 Noisy Le Grand, France.
EM j.cousty@esiee.fr; l.najman@esiee.fr; m.couprie@esiee.fr
RI Najman, Laurent/AAB-4212-2020
OI Najman, Laurent/0000-0002-6190-0235
FU ANR [SURF-NT05-2_45825]
FX This work was partially supported by ANR Grant SURF-NT05-2_45825. It
   results of a collaboration between the cardiology department of the
   Henri Mondor Hospital and the Discrete Geometry and Imagery group of the
   Gaspard-Monge Institute at ESIEE.
CR ALLENE C, 2009, IMAGE VISION COMPUT, P1
   [Anonymous], 2001, Interactive graph cuts for optimal boundary & region segmentation of objects in nd images, DOI DOI 10.1109/ICCV.2001.937505
   [Anonymous], INSIGHT J
   Aspert N, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P705, DOI 10.1109/ICME.2002.1035879
   Beare R, 2006, IEEE T PATTERN ANAL, V28, P1063, DOI 10.1109/TPAMI.2006.132
   Bertrand G, 2005, J MATH IMAGING VIS, V22, P217, DOI 10.1007/s10851-005-4891-5
   BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P1003, DOI 10.1016/0167-8655(94)90032-9
   Beucher S., 1979, Use of watersheds in contour detection
   BEUCHER S, 1993, MATH MORPHOLOGY IMAG, P443
   Bonilha L, 2004, HUM BRAIN MAPP, V22, P145, DOI 10.1002/hbm.20023
   Brent R. P., 1973, Algorithms for Minimization without Derivatives
   BUSER PT, 1989, J AM COLL CARDIOL, V13, P1294, DOI 10.1016/0735-1097(89)90304-5
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   Couprie C, 2009, IEEE I CONF COMP VIS, P731, DOI 10.1109/ICCV.2009.5459284
   Couprie M, 2005, J MATH IMAGING VIS, V22, P231, DOI 10.1007/s10851-005-4892-4
   Couprie M, 1997, P SOC PHOTO-OPT INS, V3168, P136, DOI 10.1117/12.292778
   COUPRIE M, 2006, IEEE 19 BRAZ S COMP, P307
   Couprie M, 2007, IMAGE VISION COMPUT, V25, P1543, DOI 10.1016/j.imavis.2006.06.020
   COUSTY J, IEEE T PATT IN PRESS
   Cousty J, 2007, LECT NOTES COMPUT SC, V4466, P474
   Cousty J, 2009, IEEE T PATTERN ANAL, V31, P1362, DOI 10.1109/TPAMI.2008.173
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Daragon X, 2003, LECT NOTES COMPUT SC, V2886, P236
   de Pablo MMG, 2005, COMPUT CARDIOL, V32, P399
   Dokládal P, 2003, PATTERN RECOGN, V36, P2463, DOI 10.1016/S0031-3203(03)00118-3
   Falcao AX, 2004, IEEE T MED IMAGING, V23, P1100, DOI 10.1109/TMI.2004.829335
   Fritscher KD, 2005, LECT NOTES COMPUT SC, V3504, P113
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Graves M J, 2000, J Magn Reson Imaging, V12, P232
   Hirata T, 1996, INFORM PROCESS LETT, V58, P129, DOI 10.1016/0020-0190(96)00049-X
   Kaus MR, 2004, MED IMAGE ANAL, V8, P245, DOI 10.1016/j.media.2004.06.015
   KISSI A, 2009, RITS
   KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3
   Lorenzo-Valdés M, 2004, MED IMAGE ANAL, V8, P255, DOI 10.1016/j.media.2004.06.005
   Lötjönen J, 2004, MED IMAGE ANAL, V8, P371, DOI 10.1016/j.media.2004.06.013
   Lynch M, 2006, COMPUT BIOL MED, V36, P389, DOI 10.1016/j.compbiomed.2005.01.005
   Mäkelä T, 2003, MED IMAGE ANAL, V7, P377, DOI 10.1016/S1361-8415(03)00012-4
   Marak L., 2009, MICCAI 2009 Workshop on Cardiac MR Left Ventricle Segmentation Challenge, P1
   MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9
   Meijster A, 2000, COMP IMAG VIS, V18, P331
   Mitchell SC, 2002, IEEE T MED IMAGING, V21, P1167, DOI 10.1109/TMI.2002.804425
   Mitchell SC, 2001, IEEE T MED IMAGING, V20, P415, DOI 10.1109/42.925294
   Montagnat J, 2005, MED IMAGE ANAL, V9, P87, DOI 10.1016/j.media.2004.06.025
   Montillo A, 2002, LECT NOTES COMPUT SC, V2488, P620, DOI 10.1007/3-540-45786-0_77
   Najman L, 2005, DISCRETE APPL MATH, V147, P301, DOI 10.1016/j.dam.2004.09.017
   Nguyen HT, 2003, IEEE T PATTERN ANAL, V25, P330, DOI 10.1109/TPAMI.2003.1182096
   Noble NMI, 2003, ACAD RADIOL, V10, P1349, DOI 10.1016/S1076-6332(03)00537-3
   Passat N, 2007, IMAGE VISION COMPUT, V25, P512, DOI 10.1016/j.imavis.2006.03.008
   Plueimpitiwiriyawej C, 2005, IEEE T MED IMAGING, V24, P593, DOI 10.1109/TMI.2005.843740
   RADAU P, MIDDAS J IN PRESS
   SAITO T, 1994, PATTERN RECOGN, V27, P1551, DOI 10.1016/0031-3203(94)90133-3
   SCHAERER J, 2008, THESIS INSA LYON
   Schaerer J, 2007, P ANN INT IEEE EMBS, P4488, DOI 10.1109/IEMBS.2007.4353336
   Serra J, 2006, J MATH IMAGING VIS, V24, P83, DOI 10.1007/s10851-005-3616-0
   Serra Jean, 1988, Theoretical Advances, V2
   Soille P., 1999, Morphological Image Analysis: Principles and Applications, Vvol 2
   Tanki Nobuyoshi, 2005, Magn Reson Med Sci, V4, P191, DOI 10.2463/mrms.4.191
   Udupa JK, 2006, COMPUT MED IMAG GRAP, V30, P75, DOI 10.1016/j.compmedimag.2005.12.001
   Üzümcü M, 2006, INVEST RADIOL, V41, P52, DOI 10.1097/01.rli.0000194070.88432.24
   Vachier C, 2005, J MATH IMAGING VIS, V22, P251, DOI 10.1007/s10851-005-4893-3
   van Assen HC, 2006, MED IMAGE ANAL, V10, P286, DOI 10.1016/j.media.2005.12.001
   van der Geest RJ, 2004, J CARDIOVASC MAGN R, V6, P609, DOI 10.1081/JCMR-120038082
   vanderGeest RJ, 1997, J COMPUT ASSIST TOMO, V21, P756, DOI 10.1097/00004728-199709000-00019
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   von Berg J, 2005, LECT NOTES COMPUT SC, V3504, P1
   Zhu Y, 2007, I S BIOMED IMAGING, P185, DOI 10.1109/ISBI.2007.356819
NR 66
TC 65
Z9 72
U1 2
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1229
EP 1243
DI 10.1016/j.imavis.2010.01.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400006
DA 2024-07-18
ER

PT J
AU Al-Hudhud, G
   Ibrahim, MK
   Al-Akaidi, M
AF Al-Hudhud, G.
   Ibrahim, M. K.
   Al-Akaidi, M.
TI Automatic production of quantisation matrices based on perceptual
   modelling of wavelet coefficients for grey scale images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image compression; Statistical modelling of wavelet coefficients;
   Adaptive quantisation
AB Wavelet domain statistical models have been shown to be useful for certain applications, e.g. image compression, watermarking and Gaussian noise reduction. One of the main problems for wavelet-based compression is to overcome quantisation error efficiently. Inspired by Weber-Fechners Law, we introduce a logarithmic model that approximates the non-linearity of human perception and partially precompensates for the effect of the display device. A logarithmic transfer function is proposed in order to spread the coefficients distribution in the wavelet domain in compliance with the human perceptual attributes. The standard deviation sigma of the logarithmically-scaled coefficients in a subband represents the average difference from the mean of the coefficients in that subband. The standard deviation is chosen as a measure of the visibility threshold within this subband. Computing the Values of sigma's for all subbands results in a quantisation matrix for a chosen image. The quantisation matrix is then scaled by a factor rho in order to provide the best trade-off between the visual quality and the bit-rate of the processed image. A major advantage of this model is to allow for observing the visibility threshold and automatically produce the quantisation matrix that is content dependant and scalable without further interaction from the user. The experimental results have proven the model works for any wavelet. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Al-Hudhud, G.] Al Ahliyya Amman Univ, Fac Informat Technol, Software Engn Dept, Amman 11941, Jordan.
   [Ibrahim, M. K.; Al-Akaidi, M.] De Montfort Univ, Fac Comp Sci & Engn, Sch Technol, Leicester LE1 9BH, Leics, England.
C3 Al-Ahliyya Amman University; De Montfort University
RP Al-Hudhud, G (corresponding author), Al Ahliyya Amman Univ, Fac Informat Technol, Software Engn Dept, POB 1782, Amman 11941, Jordan.
EM ghudhoud@ammanu.edu.jo; ibrahim@dmu.ac.uk; mma@dmu.ac.uk
RI Al-Hudhud, Ghada/Q-4714-2017
OI Al-Hudhud, Ghada/0000-0002-2810-6582
CR AHUMADA AJ, 1992, P SOC PHOTO-OPT INS, P111
   ALBANESI MG, 2002, PATTERN RECOGNITION, V36
   ANDREOPOULOS I, 2000, IEEE INT S CIRC SYST
   BEYLKIN G, 2001, WAVELET TRANSFORMS C
   Bloch C., 2007, HDRI HDB HIGH DYNAMI
   BUCCIGROSSI RW, 1999, IEEE IMAGE PROCESSIN, P8
   CALDERBANK R, 1997, INT C IM PROC, V1
   CHANDLER DM, 2002, P INT C IM PROC
   Chipman H.A., 1997, J. Am. Statist. Assoc, V92, p1413C1421
   Jakulin Aleks, 2002, BASE LINE JPEG JPEG2
   Jameson D., 1972, HDB SENSORY PHYSL
   JORDON E, 1981, VISION RES, V21
   KONDO H, 2000, INT C COMM TECHN, V1
   LAM E, 2004, IEE P VISION IMAGE S, V151
   Li J, 2000, IEEE T IMAGE PROCESS, V9, P1604, DOI 10.1109/83.862641
   Liu Z, 2006, IEEE T IMAGE PROCESS, V15, P1763, DOI 10.1109/TIP.2006.873460
   Malfait M, 1997, IEEE T IMAGE PROCESS, V6, P549, DOI 10.1109/83.563320
   Mallat S.G. A., 1989, IEEE T PATTERN ANAL, V11, P7
   Martin MB, 2001, IEEE T IMAGE PROCESS, V10, P500, DOI 10.1109/83.913585
   Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332
   Nadenau MJ, 2003, IEEE T IMAGE PROCESS, V12, P58, DOI 10.1109/TIP.2002.807358
   PETERSON HA, 1993, SID
   Portilla J, 2002, IMAGE DENOISING USIN
   Reichel J, 2001, IEEE T IMAGE PROCESS, V10, P383, DOI 10.1109/83.908504
   Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100
   SCHLICK C, 1994, 5 EUR WORKSH REND DA
   Simoncelli E, 1996, P IEEE INT C IM PROC
   STEVENS SS, 1963, J OPTICAL SOC AM, V53
   Strela V, 1999, IEEE T IMAGE PROCESS, V8, P548, DOI 10.1109/83.753742
   STRELA V, 2000, P SPIEMEETING SAN DI
   VETTERLI M, 2000, WAVELETS SUBBAND COD, pCH7
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Watson AB, 1997, IEEE T IMAGE PROCESS, V6, P1164, DOI 10.1109/83.605413
NR 33
TC 1
Z9 2
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 644
EP 653
DI 10.1016/j.imavis.2009.10.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600010
DA 2024-07-18
ER

PT J
AU Chen, C
   Zhuang, YT
   Xiao, J
AF Chen, Cheng
   Zhuang, Yueting
   Xiao, Jun
TI Silhouette representation and matching for 3D pose discrimination - A
   comparative study
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pose inferring; Motion recovery; Shape analysis; Comparative study;
   Performance evaluation
ID HUMAN MOTION; SHAPE REPRESENTATION; TRACKING; RECOGNITION;
   CLASSIFICATION; DESCRIPTORS; RETRIEVAL; FEATURES
AB Inferring 3D human poses from marker-free images is an important but challenging task. A large body of algorithms has been proposed to that end, among which the discriminative methods using silhouettes as visual inputs are an important category. For these methods, silhouette representation and matching is very important. An effective silhouette representation method computes discriminative and compact silhouette descriptors which are used for learning the silhouette-pose mapping, and a good silhouette matching algorithm enables effective comparison and search in the example database. However, there has not been an extensive study on the abundance of shape analysis techniques in the context of pose discrimination. In this paper, we give a systematic study on the performances of shape representation and matching algorithms for pose discrimination, and we explore the influences of different realistic factors encountered in practical systems, such as yaw angle, camera tilt, silhouette noise, and the selection of training examples. We conduct various quantitative evaluations using synthetic and real silhouettes based on HumanEva dataset. Our work provides new insights into pose inferring algorithms and the designing and building of practical systems. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Chen, Cheng; Zhuang, Yueting; Xiao, Jun] Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Peoples R China.
C3 Zhejiang University
RP Chen, C (corresponding author), Zhejiang Univ, Inst Artificial Intelligence, Hangzhou 310027, Peoples R China.
EM cchen@cs.zju.edu.cn; yzhuang@cs.zju.edu.cn; junx@cs.zju.edu.cn
CR Agarwal A, 2006, LECT NOTES COMPUT SC, V3851, P50
   Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Agarwal A, 2006, LECT NOTES COMPUT SC, V3951, P30
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], IEEE C COMP VIS PAT, DOI DOI 10.1109/CVPR.2006.68
   [Anonymous], 2007, P CVPR 2 WORKSH EV A
   ARKIN EM, 1991, IEEE T PATTERN ANAL, V13, P209, DOI 10.1109/34.75509
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BISSACCO A, 2007, IEEE COMP SOC C COMP
   BO L, 2008, IEEE COMP SOC C COMP
   BREGONZIO M, 2009, IEEE COMP SOC C COMP
   CHEN C, 2008, IEEE COMP SOC C COMP
   CHEN CC, 1993, PATTERN RECOGN, V26, P683, DOI 10.1016/0031-3203(93)90121-C
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de León RD, 2000, INT C PATT RECOG, P709, DOI 10.1109/ICPR.2000.903643
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Elgammal A, 2004, PROC CVPR IEEE, P681
   Fathi A, 2007, IEEE I CONF COMP VIS, P1917
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410
   GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194
   Gond L, 2008, LECT NOTES COMPUT SC, V5098, P370, DOI 10.1007/978-3-540-70517-8_36
   Gorelick L, 2006, IEEE T PATTERN ANAL, V28, P1991, DOI 10.1109/TPAMI.2006.253
   Grauman K, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P641
   Howe NR, 2007, IMAGE VISION COMPUT, V25, P331, DOI 10.1016/j.imavis.2005.10.006
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Isard M, 2003, PROC CVPR IEEE, P613
   JOO JM, 2006, IND DATA, V9, P76
   KANAUJIA A, 2007, IEEE COMP SOC C COMP
   KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lee MW, 2009, IEEE T PATTERN ANAL, V31, P27, DOI 10.1109/TPAMI.2008.35
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LV F, 2007, IEEE COMP SOC C COMP
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Nayak S, 2009, IEEE T PATTERN ANAL, V31, P795, DOI 10.1109/TPAMI.2008.80
   NIBLACK W, 1995, ICIP 95, V3, P3352
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   NING H, 2008, IEEE COMP SOC C COMP
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Okada R, 2008, LECT NOTES COMPUT SC, V5303, P434, DOI 10.1007/978-3-540-88688-4_32
   Ong EJ, 2006, COMPUT VIS IMAGE UND, V104, P178, DOI 10.1016/j.cviu.2006.08.004
   Park SH, 2007, MACH VISION APPL, V18, P151, DOI 10.1007/s00138-006-0055-x
   Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166
   POPPE R, 2005, CTIT TECHNICAL REPOR, P19
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Poppe R, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P541
   Ren L, 2005, ACM T GRAPHIC, V24, P1303, DOI 10.1145/1095878.1095882
   Rosales R, 2000, PROC CVPR IEEE, P721, DOI 10.1109/CVPR.2000.854946
   Rosales R, 2006, INT J COMPUT VISION, V67, P251, DOI 10.1007/s11263-006-5165-4
   Sanderson C, 2004, PROCEEDINGS OF THE 2004 INTELLIGENT SENSORS, SENSOR NETWORKS & INFORMATION PROCESSING CONFERENCE, P173
   SCASSELLATI B, 1994, P SOC PHOTO-OPT INS, V2185, P2, DOI 10.1117/12.171777
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Serre T, 2005, PROC CVPR IEEE, P994
   Shahabi C, 2007, MULTIMED TOOLS APPL, V32, P29, DOI 10.1007/s11042-006-0070-y
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Sigal L, 2004, PROC CVPR IEEE, P421
   Sigal Leonid., 2006, HUMANEVA SYNCHRONIZE, DOI DOI 10.1007/S11263-009-0273-6
   Sminchisescu C, 2005, PROC CVPR IEEE, P390
   SMINCHISESCU C, 2006, IEEE COMP SOC C COMP, V2, P1743
   SMINCHISESCU C, 2001, IEEE INT C COMP VIS, V1, P447
   SUN Y, 2006, BRIT MACH VIS C, P641
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   WILLEMS G, 2008, EUR C COMP VIS, V2, P650
   Wong S, 2007, 2007 INTERNATIONAL SYMPOSIUM ON VLSI TECHNOLOGY, SYSTEMS AND APPLICATIONS (VLSI-TSA), PROCEEDINGS OF TECHNICAL PAPERS, P66
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1094, DOI 10.1109/ICCV.2003.1238471
   Ye Z, 2007, IEEE WRK SIG PRO SYS, P1
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang DS, 2003, J VIS COMMUN IMAGE R, V14, P41, DOI 10.1016/S1047-3203(03)00003-8
   Zhao X, 2008, PATTERN RECOGN, V41, P2470, DOI 10.1016/j.patcog.2008.01.004
NR 80
TC 8
Z9 9
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 654
EP 667
DI 10.1016/j.imavis.2009.10.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600011
DA 2024-07-18
ER

PT J
AU Mahmood, MT
   Choi, TS
AF Mahmood, Muhammad Tariq
   Choi, Tae-Sun
TI 3D shape recovery from image focus using kernel regression in eigenspace
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D shape; Focus measure; PCA; Shape from focus; Kernel regression
ID 3-DIMENSIONAL SHAPE; DEPTH MAP; MICROSCOPY
AB Shape from focus (SFF) is one of the optical passive methods for three dimensional (3D) shape recovery of an object from its two dimensional (2D) images. The focus measure plays important role in SFF algorithms. Mostly, conventional focus measures are based on gradient, so their performance is restricted under noisy conditions. Moreover, SFF methods also suffer from loss of focus information due to discreteness. This paper introduces a new SFF method based on principal component analysis (PCA) and kernel regression. The focus values are computed through PCA by considering a sequence of small 3D neighborhood for each object point. We apply unsupervised regression through Nadaraya and Watson Estimate (NWE) on depth Values to get a refined 3D shape of the object. It reduces the effect of noise within a small surface area as well as approximates the accurate 3D shape by exploiting the depth dependencies in the neighborhood. Performance of the proposed scheme is investigated in the presence of different types of noises and textured areas. Experimental results demonstrate effectiveness of the proposed approach. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Mahmood, Muhammad Tariq; Choi, Tae-Sun] Gwangju Inst Sci & Technol, Sch Informat & Mechatron, Signal & Image Proc Lab, Kwangju 500712, South Korea.
C3 Gwangju Institute of Science & Technology (GIST)
RP Choi, TS (corresponding author), Gwangju Inst Sci & Technol, Sch Informat & Mechatron, Signal & Image Proc Lab, 261 Cheomdan Gwagiro, Kwangju 500712, South Korea.
EM tariq@gist.ac.kr; tschoi@gist.ac.kr
RI Mahmood, Muhammad Tariq/F-8534-2012
OI Mahmood, Muhammad Tariq/0000-0001-6814-3137; Choi,
   Tae-Sun/0000-0001-7496-2438
FU Korean Research Foundation [KRF-2008-314-D00404]
FX This work was supported by the Korean Research Foundation Grant funded
   by the Korean Government (KRF-2008-314-D00404).
CR Abadpour A, 2008, IMAGE VISION COMPUT, V26, P878, DOI 10.1016/j.imavis.2007.10.013
   Ahmad MB, 2005, IEEE T CIRC SYST VID, V15, P566, DOI 10.1109/TCSVT.2005.844450
   Ahmad MB, 2007, IEEE T CONSUM ELECTR, V53, P1, DOI 10.1109/TCE.2007.339492
   [Anonymous], 2 INT S IM SIGN PROC
   Asif M, 2001, IEEE T IMAGE PROCESS, V10, P1670, DOI 10.1109/83.967395
   Bernd Jahne, 2005, Digital Image Processing, a Systematic Approach to Digital Image Processing/Uses Examples and Images to Illustrate Basic Concepts
   Boissenin M, 2007, IMAGE VISION COMPUT, V25, P1107, DOI 10.1016/j.imavis.2006.03.009
   Choi TS, 2000, OPT ENG, V39, P1321, DOI 10.1117/1.602498
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   KROTKOV E, 1987, INT J COMPUT VISION, V1, P223, DOI 10.1007/BF00127822
   Mahmood MT, 2009, OPT ENG, V48, DOI 10.1117/1.3130232
   Mahmood MT, 2008, MICROSC RES TECHNIQ, V71, P897, DOI 10.1002/jemt.20635
   Malagón-Borja L, 2009, IMAGE VISION COMPUT, V27, P2, DOI 10.1016/j.imavis.2007.03.004
   Malik AS, 2008, PATTERN RECOGN, V41, P2200, DOI 10.1016/j.patcog.2007.12.014
   Malik AS, 2007, PATTERN RECOGN, V40, P154, DOI 10.1016/j.patcog.2006.05.032
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   SUBBARAO M, 1995, IEEE T PATTERN ANAL, V17, P266, DOI 10.1109/34.368191
   SUBBARAO M, 1994, MACH VISION APPL, V7, P277, DOI 10.1007/BF01213418
   Sun Y, 2004, MICROSC RES TECHNIQ, V65, P139, DOI 10.1002/jemt.20118
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Xie H, 2007, MICROSC RES TECHNIQ, V70, P987, DOI 10.1002/jemt.20506
   Zhang Y, 2000, IMAGE VISION COMPUT, V18, P959, DOI 10.1016/S0262-8856(00)00038-X
   Zhao H, 2008, IMAGE VISION COMPUT, V26, P1285, DOI 10.1016/j.imavis.2008.03.007
   Zhu J, 2008, IEEE T SYST MAN CY B, V38, P1639, DOI 10.1109/TSMCB.2008.927279
   15 IEEE INT C IM PRO
NR 25
TC 9
Z9 12
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 634
EP 643
DI 10.1016/j.imavis.2009.10.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600009
DA 2024-07-18
ER

PT J
AU Alenyà, G
   Torras, C
AF Alenya, G.
   Torras, C.
TI Camera motion estimation by tracking contour deformation: Precision
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Egomotion estimation; Active contours; Precision analysis; Unscented
   transformation
ID NONLINEAR TRANSFORMATION; COVARIANCES; FILTERS
AB An algorithm to estimate camera motion from the progressive deformation of a tracked contour in the acquired video stream has been previously proposed. It relies on the fact that two views of a plane are related by an affinity, whose six parameters can be used to derive the six degrees-of-freedom of camera motion between the two views. In this paper we evaluate the accuracy of the algorithm. Monte Carlo simulations show that translations parallel to the image plane and rotations about the optical axis are better recovered than translations along this axis, which in turn are more accurate than rotations out of the plane. Concerning covariances, only the three less precise degrees-of-freedom appear to be correlated. In order to obtain means and covariances of 3D motions quickly on a working robot system, we resort to the Unscented Transformation (UT) requiring only 13 samples per view, after validating its usage through the previous Monte Carlo simulations. Two sets of experiments have been performed: short-range motion recovery has been tested using a Staubli robot arm in a controlled lab setting, while the precision of the algorithm when facing long translations has been assessed by means of a vehicle-mounted camera in a factory floor. In the latter more unfavourable case, the obtained errors are around 3%, which seems accurate enough for transferring operations. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Alenya, G.; Torras, C.] UPC, CSIC, Inst Robot & Informat Ind, Barcelona 08028, Spain.
C3 Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut
   de Robotica i Informatica Industrial (IRII); Universitat Politecnica de
   Catalunya
RP Alenyà, G (corresponding author), UPC, CSIC, Inst Robot & Informat Ind, Llorens & Artigas 4-6, Barcelona 08028, Spain.
EM galenya@iri.upc.edu; torras@iri.upc.edu
RI Torras, Carme/M-1794-2014; Alenya, Guillem/ABH-1090-2020; Alenyà,
   Guillem/A-5087-2010
OI Torras, Carme/0000-0002-2933-398X; Alenya, Guillem/0000-0002-6018-154X;
   Alenyà, Guillem/0000-0002-6018-154X
CR Alberich-Carramiñana M, 2008, COMPUT VIS IMAGE UND, V112, P195, DOI 10.1016/j.cviu.2008.02.007
   Alenyà G, 2005, IEEE INT CONF ROBOT, P3528
   Alenyà G, 2004, J ROBOTIC SYST, V21, P23, DOI 10.1002/rob.10125
   [Anonymous], 1996, Computer graphics: principles and practice
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], P INT C AC SPEECH SI
   Blake A., 1998, ACTIVE CONTOURS
   Brooks MJ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P302, DOI 10.1109/ICCV.2001.937533
   Chojnacki W, 2000, IEEE T PATTERN ANAL, V22, P1294, DOI 10.1109/34.888714
   CLARKE J, 1998, 216198 U OXF DEP ENG
   Criminisi A., 2001, DISTINGUISHED DISSER
   Drummond T, 2000, INT J COMPUT VISION, V37, P21, DOI 10.1023/A:1008125412549
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gonçalves N, 2003, ROBOT AUTON SYST, V45, P23, DOI 10.1016/S0921-8890(03)00065-4
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Julier S, 2000, IEEE T AUTOMAT CONTR, V45, P477, DOI 10.1109/9.847726
   Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797
   Kanazawa Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P301, DOI 10.1109/ICCV.2001.937640
   KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377
   Lefebvre T, 2002, IEEE T AUTOMAT CONTR, V47, P1406, DOI 10.1109/TAC.2002.800742
   LIU YC, 1990, IEEE T PATTERN ANAL, V12, P28, DOI 10.1109/34.41381
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Martínez E, 2001, PATTERN RECOGN, V34, P1585, DOI 10.1016/S0031-3203(00)00093-5
   MORRIS DD, 1999, VISION ALGORITHMS TH
   PAPADOPOULO T, 2000, RR3961 INRIA
   Sciavicco L., 2000, MODELING CONTROL ROB
   SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553
   Sim R, 2005, IEEE INT CONF ROBOT, P661
   Tordoff B, 2004, IEEE T PATTERN ANAL, V26, P98, DOI 10.1109/TPAMI.2004.1261082
   TORR PHS, 1993, P SOC PHOTO-OPT INS, V2059, P432, DOI 10.1117/12.150246
   van der Merwe R., 2001, P INT C AC SPEECH SI
   Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463
   Weng Juyang., 1993, MOTION STRUCTURE IMA
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
NR 36
TC 1
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 474
EP 490
DI 10.1016/j.imavis.2009.07.011
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300018
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Montabone, S
   Soto, A
AF Montabone, Sebastian
   Soto, Alvaro
TI Human detection using a mobile platform and novel features derived from
   a visual saliency mechanism
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human detection; Visual saliency; Visual features; Moving cameras
ID TRACKING; VISION; SYSTEM; STEREO
AB Human detection is a key ability to an increasing number of applications that operates in human inhabited environments or needs to interact with a human user. Currently, most successful approaches to human detection are based on background substraction techniques that apply only to the case of static cameras or cameras with highly constrained motions. Furthermore, many applications rely on features derived from specific human poses, such as systems based on features derived from the human face which is only visible when a person is facing the detecting camera. In this work, we present a new computer vision algorithm designed to operate with moving cameras and to detect humans in different poses under partial or complete view of the human body. We follow a standard pattern recognition approach based on four main steps: (i) preprocessing to achieve color constancy and stereo pair calibration, (ii) segmentation using depth continuity information, (iii) feature extraction based on visual saliency, and (iv) classification using a neural network. The main novelty of our approach lies in the feature extraction step, where we propose novel features derived from a visual saliency mechanism. In contrast to previous works, we do not use a pyramidal decomposition to run the saliency algorithm, but we implement this at the original image resolution using the so-called integral image. Our results indicate that our method: (j) outperforms state-of-the-art techniques for human detection based on face detectors, (ii) outperforms state-of-the-art techniques for complete human body detection based on different set of visual features, and (iii) operates in real time onboard a mobile platform, such as a mobile robot (15 fps). (C) 2009 Elsevier B.V. All rights reserved.
C1 [Montabone, Sebastian; Soto, Alvaro] Pontificia Univ Catolica Chile, Dept Comp Sci, Santiago 22, Chile.
C3 Pontificia Universidad Catolica de Chile
RP Montabone, S (corresponding author), Pontificia Univ Catolica Chile, Dept Comp Sci, Casilla 306, Santiago 22, Chile.
EM samontab@puc.cl; asoto@ing.puc.cl
RI Soto, Alvaro M/D-1406-2014
FU FONDECYT [1070760]; Anillos [ACT-32]
FX This work was partially funded by FONDECYT grant 1070760 and Anillos
   ACT-32.
CR [Anonymous], 2001, OPENCV OP SOURC COMP
   [Anonymous], P 5 INT C COMP VIS S
   [Anonymous], 2000, Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations
   Asoh H, 2001, IEEE INTELL SYST, V16, P46, DOI 10.1109/5254.956081
   BELLOTTO N, 2005, IEEE J INTELLIGENT C, V1
   Bennewitz M, 2005, IEEE-RAS INT C HUMAN, P418
   Burgard W, 1999, ARTIF INTELL-AMST, V114, P3, DOI 10.1016/S0004-3702(99)00070-3
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Espinace P, 2008, ROBOT AUTON SYST, V56, P538, DOI 10.1016/j.robot.2008.03.004
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   FRINTROP S, 2005, THESIS RHEINISCHE FR
   Gandhi T, 2007, IEEE T INTELL TRANSP, V8, P413, DOI 10.1109/TITS.2007.903444
   Gavrila DM, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P13
   Gerónimo D, 2007, LECT NOTES COMPUT SC, V4477, P547
   HOLLINGER G, 2006, INT C INT ROB SYST
   Huang YP, 2005, EURASIP J APPL SIG P, V2005, P2322, DOI 10.1155/ASP.2005.2322
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L., 2004, NEUROMORPHIC ENG, V1, P10
   KADIR T, 2004, P EUR C COMP VIS ECC
   Konolige K., 2007, Sri small vision system users manual
   Lang S., 2003, P 5 INT C MULTIMODAL, P28, DOI DOI 10.1145/958432.958441
   Mataric MJ, 2007, J NEUROENG REHABIL, V4, DOI 10.1186/1743-0003-4-5
   Mikolajczyk K., 2002, P EUR C COMP VIS ECC
   Muñoz-Salinas R, 2007, IMAGE VISION COMPUT, V25, P995, DOI 10.1016/j.imavis.2006.07.012
   OGALE N, 2006, THESIS U MARYLAND
   Palmer S., 1999, VISION SCI PHOTONS P
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   PSZCZOLKOWSKI S, 2007, LECT NOTES COMPUTER
   RAJAGOPALAN AN, 2001, INSA A J SPECIAL ISS, V67, P157
   RAJAGOPALAN AN, 1999, P IEEE INT JOINT C N
   SCHAFFALITZKY F, 2002, P EUR C COMP VIS ECC
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vezhnevets V., 2003, GRAPHICON03, P85
   VIOLA P, 2001, P IEEE C COMP VIS PA, P228
   VIOLA P, 2003, INT C COMP VIS ICCV0
   WALTHER D, 2004, P EUR C COMP VIS ECC
   Wilhelm T, 2004, ROBOT AUTON SYST, V48, P31, DOI 10.1016/j.robot.2004.05.004
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Zhao L, 2000, IEEE T INTELL TRANSP, V1, P148, DOI 10.1109/6979.892151
NR 40
TC 84
Z9 95
U1 0
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 391
EP 402
DI 10.1016/j.imavis.2009.06.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300010
DA 2024-07-18
ER

PT J
AU Shin, Y
   Kim, Y
   Kim, EY
AF Shin, Yunhee
   Kim, Youngrae
   Kim, Eun Yi
TI Automatic textile image annotation by predicting emotional concepts from
   visual features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic image annotation; Affective features; Emotion recognition;
   Textile image retrieval: neural network
ID RETRIEVAL
AB This paper presents an emotion prediction system that can automatically predict certain human emotional concepts from a given textile. The main application motivating this study is textile image annotation, which has recently rapidly expanded in relation to the Web. In the proposed method, color and pattern are used as cues to predict the emotional semantics associated with an image, where these features are extracted using a color quantization and a multi-level wavelet transform, respectively. The extracted features are then applied to three representative classifiers: K-means clustering, Naive Bayesian, and a multi-layered perceptron (MLP), all of which are widely used in data mining. When evaluating the proposed emotion prediction method using 3600 textile images, the MLP produces the best performance. Thereafter, the proposed MLP-based method is compared with other methods that only use color or pattern, and the proposed method shows the best performance with an accuracy of above 92%. Therefore, the results confirm that the proposed method can be effectively applied to the commercial textile industry and image retrieval. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Kim, Eun Yi] Konkuk Univ, Sch Internet & Multimedia Eng, Dept Adv Technol Fus, Visual Informat Proc Lab, Seoul 143701, South Korea.
C3 Konkuk University
RP Kim, EY (corresponding author), Konkuk Univ, Sch Internet & Multimedia Eng, Dept Adv Technol Fus, Visual Informat Proc Lab, 1 Hwayang Dong, Seoul 143701, South Korea.
EM eykim@konkuk.ac.kr
RI Kim, Eun Yi/D-9437-2011; Shin, Yunhee/D-9445-2011
OI Kim, Eun Yi/0000-0002-6944-5863
FU Korea Government (MOST) [R01-2007-000-20997-0]
FX The authors give a thank to the assistance of Prof. Jee In Kim and Prof.
   Karpjoo Jeong of Konkuk University at the early stage in this work, and
   acknowledge the thoughtful comments of Dr. Soo-jeong Kim. This work was
   supported by the Korea Science and Engineering Foundation (KOSEF) grant
   funded by the Korea Government (MOST) (No. R01-2007-000-20997-0).
CR [Anonymous], 1991, Color Image Scale
   [Anonymous], 1995, 11 C UNC ART INT SAN, DOI DOI 10.1109/TGRS.2004.834800
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   [Anonymous], 2009, 13th international conference on Intelligent user interfaces, Canary Islands
   BAUER HU, 1990, P INT JOINT C NEUR N, P131
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   DAPOS O, 2008, COLOUR DESIGN CREATI, V1, P1
   Datta D, 2006, J COMPUT THEOR NANOS, V3, P301, DOI 10.1166/jctn.2006.3012
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Dawes J, 2008, INT J MARKET RES, V50, P61, DOI 10.1177/147078530805000106
   Eakins J., 1999, Content based image retrieval: A report to the JISC technology applications programme
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   JING F, 2003, P INT C IM VID RETR, P206
   JING Y, 2007, P 6 INT C IM VID RET
   KAWAMOTO N, 1993, COLOR RES APPL, V18, P260, DOI 10.1002/col.5080180409
   Kherfi ML, 2004, ACM COMPUT SURV, V36, P35, DOI 10.1145/1013208.1013210
   Kim EY, 2005, LECT NOTES ARTIF INT, V3613, P1077
   KIM NY, 2007, P IEEE INT S CONS EL, P1
   KIM S, 2007, THESIS KONKUK GRADUA
   KOBAYASHI S, 1997, P AIC COL 97 KYOT, P727
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Li J, 2008, IEEE T PATTERN ANAL, V30, P985, DOI 10.1109/TPAMI.2007.70847
   Likert R., 1932, Arch. Psychol., V22, P44, DOI DOI 10.4135/9781412961288.N454
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   PARK S, 1999, THESIS YONSEI GRADUA
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   SAUX B. L, 2002, P INT IEEE C PATT RE
   Shin Y, 2008, PATTERN RECOGN LETT, V29, P1784, DOI 10.1016/j.patrec.2008.05.011
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Um J, 2002, COLOR RES APPL, V27, P208, DOI 10.1002/col.10052
   Wang S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P587
NR 33
TC 31
Z9 33
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 526
EP 537
DI 10.1016/j.imavis.2009.08.009
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300022
DA 2024-07-18
ER

PT J
AU de Almeida, P
AF de Almeida, Pedro
TI A knowledge-based approach to the iris segmentation problem
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris; Segmentation; Knowledge-based; Expert system; Intelligent image
   analysis
AB This paper describes a knowledge-based approach to the problem of locating and segmenting the iris in images showing close-up human eyes. This approach is inspired in the expert system's paradigm but, due the specific processing problems associated with image analysis, uses direct encoding of the "decision rules", instead of a classic, formalized, knowledge base. The algorithm involves a succession of phases that deal with image pre-processing, pupil location, iris location, combination of pupil and iris, eyelids detection, and filtering of reflections. The development was iterative, based on successive improvements tested over a set of training images. The results that were achieved indicate that this global approach can be useful to solve image analysis problems over which human "experts" have better performance than the present computer-based solutions. (C) 2009 Elsevier B.V. All rights reserved.
C1 Univ Beira Interior, Dep Informat, P-6200 Covilha, Portugal.
C3 Universidade da Beira Interior
RP de Almeida, P (corresponding author), Univ Beira Interior, Dep Informat, P-6200 Covilha, Portugal.
EM palmeida@di.ubi.pt
OI de Almeida, Pedro/0000-0003-4553-2783
FU Portuguese Fundacao para a Ciencia e Tecnologia (FCT); Fundo Europeu de
   Desenvolvimento Regional (FEDER) [PTDC/EIA/69106/2006]; Fundação para a
   Ciência e a Tecnologia [PTDC/EIA/69106/2006] Funding Source: FCT
FX I acknowledge the support of the Portuguese Fundacao para a Ciencia e
   Tecnologia (FCT) and Fundo Europeu de Desenvolvimento Regional (FEDER),
   project PTDC/EIA/69106/2006.
CR [Anonymous], P IEEE 1 INT C BIOM
   BUCHANAN BG, 1988, ANNU REV COMPUT SCI, V3, P23, DOI 10.1146/annurev.cs.03.060188.000323
   FEIGENBAUM EA, 1977, P 5 INT JOINT C ART, P1014
   Giarratano J.C., 2005, EXPERT SYSTEMS PRINC
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
NR 5
TC 23
Z9 29
U1 2
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2010
VL 28
IS 2
BP 238
EP 245
DI 10.1016/j.imavis.2009.07.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 538GR
UT WOS:000273173100005
DA 2024-07-18
ER

PT J
AU Cao, XC
   Wu, L
   Xiao, JJ
   Foroosh, H
   Zhu, JU
   Li, XH
AF Cao, Xiaochun
   Wu, Lin
   Xiao, Jiangjian
   Foroosh, Hassan
   Zhu, Jigui
   Li, Xiaohong
TI Video synchronization and its application to object transfer
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fundamental ratios; Video synchronization; Camera motion analysis
AB In video post-production applications, camera motion analysis and alignment are important in order to ensure the geometric correctness and temporal consistency. In this paper, we trade some generality in estimating and aligning camera motion for reduced computational complexity and increased image-based nature. The main contribution is to use fundamental ratios to synchronize video sequences of distinct scenes captured by cameras undergoing similar motions. We also present a simple method to align 3D camera trajectories when the fundamental ratios are not able to match the noisy trajectories. Experimental results show that our method can accurately synchronize sequences even when the scenes are totally different and have dense depths. An application on 3D object transfer is also demonstrated. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Cao, Xiaochun; Wu, Lin; Li, Xiaohong] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
   [Xiao, Jiangjian] Sarnoff Corp, Princeton, NJ 08540 USA.
   [Foroosh, Hassan] Univ Cent Florida, Computat Imaging Lab, Orlando, FL 32816 USA.
   [Zhu, Jigui] Tianjin Univ, State Key Lab Precis Measuring Technol & Instrume, Tianjin 300072, Peoples R China.
C3 Tianjin University; Sarnoff Corporation; State University System of
   Florida; University of Central Florida; Tianjin University
RP Cao, XC (corresponding author), Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
EM xcao@tju.edu.cn
RI Wu, Lin Yuanbo/HME-1691-2023
OI Wu, Lin Yuanbo/0000-0001-6119-058X
FU National Natural Science Foundation of China [50735003]; Tianjin
   University; State Key Laboratory of Precision Measuring Technology and
   Instruments open fund; International Science and Technology
   Collaboration Project of China and Finland [2006DFA12410]
FX This work was partially supported by National Natural Science Foundation
   of China (No. 50735003), Tianjin University 985 research fund, State Key
   Laboratory of Precision Measuring Technology and Instruments open fund,
   and the International Science and Technology Collaboration Project of
   China and Finland (No. 2006DFA12410).
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Bouthemy P, 1999, IEEE T CIRC SYST VID, V9, P1030, DOI 10.1109/76.795057
   Bryson A., 1999, Dynamic optimization Editorial
   Cao XC, 2005, VISUAL COMPUT, V21, P639, DOI 10.1007/s00371-005-0335-x
   CAO XC, 2005, TEXT RETR C TRECVID
   Carceroni RL, 2004, PROC CVPR IEEE, P746
   Caspi Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P76, DOI 10.1109/ICCV.2001.937607
   Caspi Y, 2000, PROC CVPR IEEE, P682, DOI 10.1109/CVPR.2000.854940
   CASPI Y, 2002, P VAMODS WORKSH ECCV
   Chuang YY, 2003, ACM T GRAPHIC, V22, P494, DOI 10.1145/882262.882298
   Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572
   Giese MA, 1999, IEEE WORKSHOP ON MULTI-VIEW MODELING & ANALYSIS OF VISUAL SCENES (MVIEW'99). PROCEEDINGS, P73, DOI 10.1109/MVIEW.1999.781085
   LAPTEV I, 2005, P IEEE ICCV, P816
   Levi N, 2003, PROC CVPR IEEE, P518
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mallon J, 2005, IMAGE VISION COMPUT, V23, P643, DOI 10.1016/j.imavis.2005.03.002
   Nicolas H, 2005, IEEE SIGNAL PROC LET, V12, P321, DOI 10.1109/LSP.2005.843778
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Rao C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P939
   ROTH G, 2002, EVOWORKSHOPS, P289
   Sand P, 2004, ACM T GRAPHIC, V23, P592, DOI 10.1145/1015706.1015765
   Stein G.P., 1998, DARPA IU WORKSHOP, P521
   Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087
   Tresadern P., 2003, Proceedings of the 14th British Machine Vision Conference, P629
   Tuytelaars T, 2004, PROC CVPR IEEE, P762
   WHITEHEAD A, 2005, P IEEE WACV MOTION, V20, P132
   Wolf L, 2002, LECT NOTES COMPUT SC, V2351, P370
   XIAO J, 2006, P IEEE VR
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 31
TC 8
Z9 8
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 92
EP 100
DI 10.1016/j.imavis.2009.04.015
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000010
DA 2024-07-18
ER

PT J
AU Heusch, G
   Marcel, S
AF Heusch, Guillaume
   Marcel, Sebastien
TI A novel statistical generative model dedicated to face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Local features; Statistical models; Bayesian Networks
ID AUTHENTICATION
AB In this paper, a novel statistical generative model to describe a face is presented, and is applied to the face authentication task. Classical generative models used so far in face recognition, such as Gaussian Mixture Models (GMMs) and Hidden Markov Models (HMMs) for instance, are making strong assumptions on the observations derived from a face image. Indeed, such models usually assume that local observations are independent, which is obviously not the case in a face. The presented model hence proposes to encode relationships between salient facial features by using a static Bayesian Network. Since robustness against imprecisely located faces is of great concern in a real-world scenario, authentication results are presented using automatically localised faces. Experiments conducted on the XM2VTS and the BANCA databases showed that the proposed approach is suitable for this task, since it reaches state-of-the-art results. We compare our model to baseline appearance-based systems (Eigenfaces and Fisherfaces) but also to classical generative models, namely GMM, HMM and pseudo-2DHMM. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Heusch, Guillaume; Marcel, Sebastien] IDIAP Res Inst, Ctr Parc, CH-1920 Martigny, Switzerland.
   [Heusch, Guillaume] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne
RP Heusch, G (corresponding author), IDIAP Res Inst, Ctr Parc, Rue Marconi 19,POB 592, CH-1920 Martigny, Switzerland.
EM heusch@idiap.ch
OI Marcel, Sebastien/0000-0002-2497-9140
FU Swiss National Science Foundation (SNSF); Swiss National Centre of
   Competence in Research (NCCR)
FX This work was supported by the GMFace project of the Swiss National
   Science Foundation (SNSF) and by the Swiss National Centre of Competence
   in Research (NCCR) on "Interactive Multimodal Information Management
   (IM2)".<SUP>1</SUP> Softwares were implemented using the TorchVision
   library<SUP>2</SUP> and experiments were carried out using the PyVerif
   biometric verification toolkit.<SUP>3</SUP>
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], INT C MACH LEARN ICM
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   [Anonymous], EUR C COMP VIS
   Bailly-Bailliére E, 2003, LECT NOTES COMPUT SC, V2688, P625
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bengio S., 2004, P OD SPEAK LANG REC
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Cardinaux F, 2006, IEEE T SIGNAL PROCES, V54, P361, DOI 10.1109/TSP.2005.861075
   CARDINAUX F, 2003, INT C AUD VID BAS BI
   Cohen I, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA121
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   COWELL GC, 1999, PROBABILISTIC NETWOR
   Dechter R, 1996, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P211
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Eickeler S, 2000, IMAGE VISION COMPUT, V18, P279, DOI 10.1016/S0262-8856(99)00055-4
   Fröba B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P91, DOI 10.1109/AFGR.2004.1301514
   Gauvain JL, 1994, IEEE T SPEECH AUDI P, V2, P291, DOI 10.1109/89.279278
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Heckerman D., 1999, LEARNING GRAPHICAL M, P301
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Heusch G, 2007, LECT NOTES COMPUT SC, V4642, P878
   Heusch G, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P9
   Huang C, 1996, INT J APPROX REASON, V15, P225, DOI 10.1016/S0888-613X(96)00069-2
   Jordan MI, 1999, MACH LEARN, V37, P183, DOI 10.1023/A:1007665907178
   KEOMANY J, 2006, 0607 RR IDIAP RES I
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   Martínez A, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P35, DOI 10.1109/IVL.1999.781120
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Messer K, 2004, INT C PATT RECOG, P523, DOI 10.1109/ICPR.2004.1333826
   Messer K, 2004, LECT NOTES COMPUT SC, V3072, P8
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   MESSER K, 2003, INT C AUD VID BAS BI, P1056
   Nefian AV, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, pA133
   Nefian AV, 2000, IEEE IMAGE PROC, P33, DOI 10.1109/ICIP.2000.900885
   Nefian AV, 1998, INT CONF ACOUST SPEE, P2721, DOI 10.1109/ICASSP.1998.678085
   Pearl J., 1988, PROBABILISTIC REASON
   PHILLIPS PJ, 1999, NEURAL INFORMATION P, P803
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Rodriguez Y, 2006, IMAGE VISION COMPUT, V24, P882, DOI 10.1016/j.imavis.2006.02.012
   Rodriguez Y, 2006, LECT NOTES COMPUT SC, V3954, P321
   SAMARIA F, 1994, IMAGE VISION COMPUT, V12, P537, DOI 10.1016/0262-8856(94)90007-8
   Shen L, 2007, IMAGE VISION COMPUT, V25, P553, DOI 10.1016/j.imavis.2006.05.002
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wiskott L, 1999, INT SER COMPUTAT INT, P355
   Yang MH, 2000, IEEE IMAGE PROC, P37, DOI 10.1109/ICIP.2000.900886
   YANG MH, 2002, IEEE INT C AUT FAC G, P205
   Yow KC, 1997, IMAGE VISION COMPUT, V15, P713, DOI 10.1016/S0262-8856(97)00003-6
NR 49
TC 10
Z9 11
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 101
EP 110
DI 10.1016/j.imavis.2009.05.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Krishnamoorthi, R
   Kannan, N
AF Krishnamoorthi, R.
   Kannan, N.
TI A new integer image coding technique based on orthogonal polynomials
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image compression; Transform coding; Orthogonal polynomials;
   Signal-to-noise ratio
ID LOCAL SINE TRANSFORM; VECTOR QUANTIZATION; COMPRESSION; EFFICIENT;
   DESIGN; GENERATION
AB In this paper, a new image coding scheme based on orthogonal polynomials has been presented. From a set of orthogonal polynomial functions, we first obtain the polynomial operators and polynomial basis operators of different width to propose the polynomial transform coding. After applying the proposed transformation, the transform coefficients are threshold coded using quantization and bit allocation as in JPEG baseline system. The performance of the proposed transform coding is reported by computing peak signal-to-noise ratio (PSNR). The proposed coding scheme is also compared with other transform coding schemes such as Discrete Cosine Transform and Discrete Wavelet Transforms. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Krishnamoorthi, R.; Kannan, N.] Anna Univ, Comp Vis Lab, Dept Informat Technol, Bharathidasan Inst Technol, Tiruchirappalli 620024, Tamil Nadu, India.
C3 Anna University; Anna University of Technology Tiruchirappalli
RP Krishnamoorthi, R (corresponding author), Anna Univ, Comp Vis Lab, Dept Informat Technol, Bharathidasan Inst Technol, Tiruchirappalli 620024, Tamil Nadu, India.
EM rkrish26@hotmail.com
RI Natarajan, Kannan/AAZ-5740-2020
OI Natarajan, Kannan/0000-0001-7688-7662; Ramasamy,
   Krishnamoorthy/0000-0003-1823-5855
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   ANDREWS HC, 1968, INT C SYSTEM SCI, P677
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   BETHEL DM, 1995, INT CONF ACOUST SPEE, P2499, DOI 10.1109/ICASSP.1995.480056
   Bhattacharyya P, 1997, PATTERN RECOGN LETT, V18, P319, DOI 10.1016/S0167-8655(97)00016-0
   Candes E.J., 2002, New Tight Frames of Curvelets and Optimal Representations of Objects with Smooth Singularities
   CHAM WK, 1986, IEE PROC-F, V133, P264, DOI 10.1049/ip-f-1.1986.0043
   Christopoulos C, 2000, IEEE SIGNAL PROC LET, V7, P247, DOI 10.1109/97.863146
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Chrysafis C, 2000, IEEE T IMAGE PROCESS, V9, P378, DOI 10.1109/83.826776
   DAUBECHIES I, 1998, COMMUNICATIONS PURE, V41, P909
   DAVIS G, 1996, IEEE T IMAGE PROCESS, V5
   DEVORE RA, 1992, IEEE T INFORM THEORY, V38, P719, DOI 10.1109/18.119733
   Do MN, 2002, IEEE IMAGE PROC, P357
   Donoho DL, 1999, ANN STAT, V27, P859, DOI 10.1214/aos/1018031261
   Donoho DL, 1998, IEEE T INFORM THEORY, V44, P2435, DOI 10.1109/18.720544
   DONY RD, 1995, IEEE T IMAGE PROCESS, V4, P1358, DOI 10.1109/83.465101
   Goyal VK, 2001, IEEE SIGNAL PROC MAG, V18, P9, DOI 10.1109/79.952802
   HABIBI A, 1971, IEEE T COMMUN TECHN, VCO19, P50, DOI 10.1109/TCOM.1971.1090601
   Hong W, 2006, IEEE T IMAGE PROCESS, V15, P3655, DOI 10.1109/TIP.2006.882016
   HSIEH CH, 1991, PATTERN RECOGN LETT, V12, P605, DOI 10.1016/0167-8655(91)90014-D
   Hsieh CH, 1992, IEEE T CIRC SYST VID, V2, P401, DOI 10.1109/76.168905
   IAIN EG, 2003, H 264 MPEG 4 10
   JAIN AK, 1981, P IEEE, V69, P349, DOI 10.1109/PROC.1981.11971
   JAIN AK, 1986, IEEE T COMMUN, V34, P161
   KAUKORANTA T, 2000, IEEE T IMAGE PROCESS, V9, P254
   Krishnamoorthi R, 2007, PATTERN RECOGN LETT, V28, P771, DOI 10.1016/j.patrec.2006.10.009
   Krishnamoorthi R, 1998, INFORM SCIENCES, V112, P51, DOI 10.1016/S0020-0255(98)10022-1
   Krishnamoorthi R, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P490, DOI 10.1109/ICICS.1997.647146
   KRISHNAMOORTHI R, 1999, THESIS IIT KHARAGPUR
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Li RY, 2002, IMAGE VISION COMPUT, V20, P37, DOI 10.1016/S0262-8856(01)00075-0
   LO KT, 1995, IEE P-VIS IMAGE SIGN, V142, P22, DOI 10.1049/ip-vis:19951662
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   NETRAVALI AN, 1980, P IEEE, V68, P366, DOI 10.1109/PROC.1980.11647
   Oliver J, 2006, IEEE T CIRC SYST VID, V16, P1437, DOI 10.1109/TCSVT.2006.883505
   Pearlman W.A., 2001, P 22 PICT COD S PCS, P1
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   PRATT WK, 1974, IEEE T COMMUN, VCO22, P1075, DOI 10.1109/TCOM.1974.1092335
   PRATT WK, 1969, P IEEE, V57, P58, DOI 10.1109/PROC.1969.6869
   Ramakrishnan S, 1998, IEEE T IMAGE PROCESS, V7, P785, DOI 10.1109/83.679412
   Rao K.R, 2014, DISCRETE COSINE TRAN
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Saito N, 2006, APPL COMPUT HARMON A, V20, P41, DOI 10.1016/j.acha.2005.01.005
   Saito N, 2003, P SOC PHOTO-OPT INS, V5207, P495, DOI 10.1117/12.503962
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Sweldens W, 1996, APPL COMPUT HARMON A, V3, P186, DOI 10.1006/acha.1996.0015
   Vetterli Martin, 1995, Wavelets and Subband Coding
   VPREK P, 2000, IEEE SIGNAL PROCESSI, V7, P250
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Yamatani K, 2006, IEEE T IMAGE PROCESS, V15, P3672, DOI 10.1109/TIP.2006.882005
NR 51
TC 16
Z9 17
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 999
EP 1006
DI 10.1016/j.imavis.2008.08.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000002
DA 2024-07-18
ER

PT J
AU Yu, HC
   Bennamoun, M
   Chua, CS
AF Yu, Hongchuan
   Bennamoun, Mohammed
   Chua, Chin-Seng
TI An extension of min/max flow framework
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Min/max flow framework; Anisotropic diffusion; Boundary leaking; Image
   segmentation; Region tracking
ID IMAGE-ENHANCEMENT; EDGE-DETECTION; CURVATURE; TRACKING; SNAKES
AB In this paper, the min/max flow scheme for image restoration is revised. The novelty consists of the following three parts. The first is to analyze the reason of the speckle generation and then to modify the original scheme. The second is to point out that the continued application of this scheme Cannot result in an adaptive stopping of the curvature flow. This is followed by modifications of the original scheme through the introduction of the Gradient Vector Flow (GVF) field and the zero-crossing detector, so as to control the smoothing effect. Our experimental results with image restoration show that the proposed schemes can reach a steady state solution while preserving the essential structures of objects. The third is to extend the min/max flow scheme to deal with the boundary leaking problem, which is indeed an intrinsic shortcoming of the familiar geodesic active contour model. The min/max flow framework provides us with an effective way to approximate the optimal solution. From an implementation point of view, this extended scheme makes the speed function simpler and more flexible. The experimental results of segmentation and region tracking show that the boundary leaking problem can be effectively suppressed. Crown Copyright (C) 2008 Published by Elsevier B.V. All rights reserved.
C1 [Yu, Hongchuan] Bournemouth Univ, Sch Med, Poole BH12 5BB, Dorset, England.
   [Bennamoun, Mohammed] Univ Western Australia, Sch Comp Sci & Software Engn, Perth, WA 6009, Australia.
   [Chua, Chin-Seng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Bournemouth University; University of Western Australia; Nanyang
   Technological University
RP Yu, HC (corresponding author), Bournemouth Univ, Sch Med, Poole BH12 5BB, Dorset, England.
EM cnyuhc@yahoo.com; m.bennamoun@csse.uwa.edu.au; ECSChua@ntu.edu.sg
RI Bennamoun, Mohammed/C-2789-2013; Yu, Hongnian/AFV-5287-2022
OI Bennamoun, Mohammed/0000-0002-6603-3257; Yu,
   Hongnian/0000-0003-2894-2086; Yu, Hongchuan/0000-0002-6024-060X
CR ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   CHAN TF, 2001, IEEE T IMAGE PROCESS, V10
   Gilboa G, 2002, IEEE T IMAGE PROCESS, V11, P689, DOI 10.1109/TIP.2002.800883
   Gilboa G, 2002, LECT NOTES COMPUT SC, V2350, P399
   GRAYSON MA, 1989, ANN MATH, V129, P71, DOI 10.2307/1971486
   Kimmel R, 2003, INT J COMPUT VISION, V53, P225, DOI 10.1023/A:1023030907417
   Laidlaw DH, 1998, IEEE T MED IMAGING, V17, P74, DOI 10.1109/42.668696
   Lu CL, 2002, J VIS COMMUN IMAGE R, V13, P65, DOI 10.1006/jvci.2001.0476
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   Malladi R, 1996, GRAPH MODEL IM PROC, V58, P127, DOI 10.1006/gmip.1996.0011
   Malladi R, 1996, IEEE T IMAGE PROCESS, V5, P1554, DOI 10.1109/83.541425
   Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Paragios N., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P201, DOI 10.1109/ICPR.1996.546019
   Paragios N, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P67, DOI 10.1109/ICCV.2001.937500
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Roula MA, 2001, IEEE IMAGE PROC, P58, DOI 10.1109/ICIP.2001.958952
   Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193
   Sumengen B, 2002, IEEE IMAGE PROC, P105
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 27
TC 0
Z9 2
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 342
EP 353
DI 10.1016/j.imavis.2008.05.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhang, JG
   Gong, SG
AF Zhang, Jianguo
   Gong, Shaogang
TI People detection in low-resolution video with non-stationary background
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual surveillance; People detection; Bayesian fusion; Long term
   motion; AdaBoost
ID MOTION
AB In this paper, we present a framework for robust people detection in low resolution image sequences of highly cluttered dynamic scenes with non-stationary background. Our model utilizes appearance features together with short- and long-term motion information. In particular, we boost Integral Gradient Orientation histograms of appearance and short-term motion. Outputs from the detector are maintained by a tracker to correct any misdetections. A Bayesian model is then deployed to further fuse long-term motion information based on correlation. Experiments show that our model is more robust with better detection rate compared to the model of Viola et al. [Michael J. Jones Paul Viola, Daniel Snow, Detecting pedestrians using patterns of motion and appearance, International journal of Computer Vision 63(2) (2005) 153-161]. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Zhang, Jianguo] Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast BT7 1NN, Antrim, North Ireland.
   [Gong, Shaogang] Queen Mary Univ London, Dept Comp Sci, London E1 4NS, England.
C3 Queens University Belfast; University of London; Queen Mary University
   London
RP Zhang, JG (corresponding author), Queens Univ Belfast, Sch Elect Elect Engn & Comp Sci, Belfast BT7 1NN, Antrim, North Ireland.
EM j.zhang@ecit.qub.ac.uk; jgzhang@dcs.qmul.ac.uk
OI zhang, jianguo/0000-0001-9317-0268
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   [Anonymous], BRIT MACH VIS C
   [Anonymous], P IEEE COMP SOC C CO
   Cai YZ, 2006, LECT NOTES COMPUT SC, V3954, P107
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Gautama T, 2002, IEEE T NEURAL NETWOR, V13, P1127, DOI 10.1109/TNN.2002.1031944
   GAVRILA D, 1999, ICCV, P87
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   HOFFMAN DD, 1982, BIOL CYBERN, V42, P195
   ISARD M, 1996, EUR C COMP VIS, V1, P343
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Rowley HA, 1996, ADV NEUR IN, V8, P875
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Strens MJA, 2003, IMAGE VISION COMPUT, V21, P891, DOI 10.1016/S0262-8856(03)00075-1
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 23
TC 7
Z9 14
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 437
EP 443
DI 10.1016/j.imavis.2008.06.013
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600014
DA 2024-07-18
ER

PT J
AU Li, ST
   Yang, B
AF Li, Shutao
   Yang, Bin
TI Multifocus image fusion using region segmentation and spatial frequency
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image fusion; image segmentation; normalized cuts; multi-focus; digital
   cameras
ID PERFORMANCE; ALGORITHM
AB Image fusion is a process of combining complementary information from multiple images of the same scene into an image, so that the resultant image contains a more accurate description of the scene than any of the individual source images. In this paper, a new region-based multifocus image fusion method is proposed. The motivation of our proposed method lies in the fact that region-based image fusion methods could be more meaningful than pixel-based fusion methods which just consider individual pixels or associated local neighborhoods of pixels in the fusion process. The fusion process contains the following steps: firstly, multifocus images are fused using the simple average method. Then the intermediate fused image is segmented using the normalized cut method. Then the two source images are segmented according to the segmenting result of the intermediate fused image. Finally, the corresponding segmented regions of the source images are fused according to their spatial frequencies. Experimental results on several pairs of multi-focus image show that the proposed method can give good results. The proposed method is more robust to misregistration or slight motion of the object than the pixel-based method. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Li, Shutao; Yang, Bin] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University
RP Li, ST (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
EM shutao_li@yahoo.com.cn; yangbin01420@163.com
RI Li, Shutao/Y-3102-2019
OI Li, Shutao/0000-0002-0585-9848
CR Aggarwal J K., 1993, Multisensor Fusion for Computer Vision
   [Anonymous], P SOC INF DISPL C
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   DAVID AY, 1995, J OPT SOC AM A, V12, P1834
   De I, 2006, SIGNAL PROCESS, V86, P924, DOI 10.1016/j.sigpro.2005.06.015
   De I, 2006, IMAGE VISION COMPUT, V24, P1278, DOI 10.1016/j.imavis.2006.04.005
   Gabarda S, 2007, IMAGE VISION COMPUT, V25, P523, DOI 10.1016/j.imavis.2006.03.007
   GOSHTASBY A, 2006, P SOC PHOTO-OPT INS, V6229, P21
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Lewis J. J., 2004, Seventh International Conference on Information Fusion, P555
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li S., 2000, P 3 INT C VIS COMP, P93
   Li S, 2001, Information Fusion, V2, P169, DOI DOI 10.1016/S1566-2535(01)00038-0
   Li ST, 2004, IEEE T NEURAL NETWOR, V15, P1555, DOI 10.1109/TNN.2004.837780
   MATSOPOULOS GK, 1994, IEE P-VIS IMAGE SIGN, V141, P137, DOI 10.1049/ip-vis:19941184
   Nikolov S. G., 2004, Seventh International Conference on Information Fusion, P1072
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Petrovic V. S., 2003, Information Fusion, V4, P167, DOI 10.1016/S1566-2535(03)00035-6
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   Qu GH, 2002, ELECTRON LETT, V38, P313, DOI 10.1049/el:20020212
   Seales WB, 1996, P SOC PHOTO-OPT INS, V2905, P227, DOI 10.1117/12.256333
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Wang H, 2002, IEE P-VIS IMAGE SIGN, V149, P283, DOI 10.1049/ip-vis:20020612
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
NR 27
TC 328
Z9 372
U1 0
U2 76
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 971
EP 979
DI 10.1016/j.imavis.2007.10.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800010
DA 2024-07-18
ER

PT J
AU Feng, J
   Ip, HHS
   Lai, LY
   Linney, A
AF Feng, Jun
   Ip, Horace H. S.
   Lai, Lap Yi
   Linney, Alf
TI Robust point correspondence matching and similarity measuring for 3D
   models by relative angle-context distributions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D model matching; point correspondence; relative angle distribution;
   similarity analysis
ID OBJECT RECOGNITION; REGISTRATION; RECONSTRUCTION; REPRESENTATION;
   SEGMENTATION; SHAPES
AB Robust solutions for correspondence matching of deformable objects are prerequisite for many applications, particularly for analyzing and comparing soft tissue organs in the medical domain. However, this has proved very difficult for 3D model surfaces, especially for approximate symmetric organs such as the liver, the stomach and the head. In this paper, we propose a novel approach to establish the 3D point-correspondence for polygonal free-form models based on an analysis of the relative angle distribution around each vertex with respect to relative reference frame calculated from principal component analysis (PCA). Two kinds of distributions, the Relative Angle-Context Distribution (RACD) and the Neighborhood Relative Angle-Context Distribution (NRACD) have been defined respectively from the probability mass function of relative angles context. RACD describes the global geometric features while NRACD provides a hierarchical local to global shape description. The experiments and evaluation of adopting these features for the human head and liver models show that both distributions are capable of building robust point correspondence while the NRACD gives better performance because it contains additional information on the spatial relationship among vertices and has the ability to provide an effective neighborhood shape description. Furthermore, we propose a similarity measure between correspondence ready models based on relative angle-context distribution factors. The experimental results demonstrate that this approach is very promising for model analysis, 3D model retrieval and classification. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Feng, Jun; Ip, Horace H. S.; Lai, Lap Yi] City Univ Hong Kong, Dept Comp Sci, Image Comp Grp, Kowloon, Hong Kong, Peoples R China.
   [Feng, Jun] Northwest Univ, Sch Informat Technol, Xian, Peoples R China.
   [Ip, Horace H. S.] City Univ Hong Kong, Ctr Innovat Applicat Internet & Multimedia Techno, Kowloon, Hong Kong, Peoples R China.
   [Linney, Alf] UCL, Dept Med Phys & Bioengn, London, England.
C3 City University of Hong Kong; Northwest University Xi'an; City
   University of Hong Kong; University of London; University College London
RP Ip, HHS (corresponding author), City Univ Hong Kong, Dept Comp Sci, Image Comp Grp, Kowloon, Hong Kong, Peoples R China.
EM feng@cs.cityu.edu.hk; cship@cityu.edu.hk; lapyi@cs.cityu.edu.hk;
   alf@medphys.ucl.ac.uk
OI IP, Ho Shing Horace/0000-0002-1509-9002
CR Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Carcassoni M, 2003, IEEE T PATTERN ANAL, V25, P1609, DOI 10.1109/TPAMI.2003.1251153
   Christiansen H.N., 1978, CONVERSION OF COMPLEX CONTOUR LINE DEFINITIONS INTO POLYGONAL ELEMENT MOSAICS, V12, P187
   Chui H, 2003, MED IMAGE ANAL, V7, P113, DOI 10.1016/S1361-8415(02)00102-0
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Davies RH, 2002, IEEE T MED IMAGING, V21, P525, DOI 10.1109/TMI.2002.1009388
   DIMAURO EC, 1996, BRIT MACH VIS C, V1, P353
   DORAI C, 1995, IEEE COMP SOC INT S, P25
   DORNAIKA F, 1999, IEEE COMP SOC C COMP, V1, P70
   Evans A., 1993, BMVC 93, P429
   Feng J, 2005, COMPUT BIOL MED, V35, P915, DOI 10.1016/j.compbiomed.2004.05.003
   Feng J, 2005, LECT NOTES COMPUT SC, V3750, P279, DOI 10.1007/11566489_35
   Feng J, 2005, LECT NOTES COMPUT SC, V3568, P445
   Huet B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P563, DOI 10.1109/ICCV.1998.710773
   IP H, 1986, SERIAL SECTION RECON, P93
   Ip HHS, 1998, IMAGE VISION COMPUT, V16, P135, DOI 10.1016/S0262-8856(97)00051-6
   Ip HHS, 2001, COMPUTER GRAPHICS INTERNATIONAL 2001, PROCEEDINGS, P55, DOI 10.1109/CGI.2001.934658
   Ip HHS, 2002, P 15 INT C VIS INT, P314
   JERAIN CP, 1991, IEEE T SYST MAN CYB, V21, P572
   Lester H, 1999, PATTERN RECOGN, V32, P129, DOI 10.1016/S0031-3203(98)00095-8
   Liu TM, 2004, NEUROIMAGE, V22, P1790, DOI 10.1016/j.neuroimage.2004.04.020
   MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387
   Osada R, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P154, DOI 10.1109/SMA.2001.923386
   RIVLIN E, 1995, IEEE T PATTERN ANAL, V17, P226, DOI 10.1109/34.368188
   Rueckert D, 2003, IEEE T MED IMAGING, V22, P1014, DOI 10.1109/TMI.2003.815865
   SCALROFF S, IEEE T PATTERN ANAL, V17, P545
   Shen DG, 2000, IEEE T PATTERN ANAL, V22, P906, DOI 10.1109/34.868689
   Shen DG, 1999, IMAGE VISION COMPUT, V17, P489, DOI 10.1016/S0262-8856(98)00141-3
   Shen DG, 2000, PATTERN RECOGN, V33, P1909, DOI 10.1016/S0031-3203(99)00172-7
   Shen DG, 2001, IEEE T MED IMAGING, V20, P257, DOI 10.1109/42.921475
   Singh R, 2000, PATTERN RECOGN, V33, P1683, DOI 10.1016/S0031-3203(99)00143-0
   Walker K. N., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P271, DOI 10.1109/AFGR.2000.840646
   Weng N, 1997, IEEE T MED IMAGING, V16, P630, DOI 10.1109/42.640754
   Wong HS, 2004, PATTERN RECOGN, V37, P2307, DOI 10.1016/j.patcog.2004.05.004
   Xia J, 2001, IEEE T INF TECHNOL B, V5, P97, DOI 10.1109/4233.924800
NR 36
TC 20
Z9 32
U1 0
U2 19
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 761
EP 775
DI 10.1016/j.imavis.2007.08.018
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900004
DA 2024-07-18
ER

PT J
AU Shih, FY
   Zhang, K
AF Shih, Frank Y.
   Zhang, Kai
TI A distance-based separator representation for pattern classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE pattern representation; classification; support vector machine; PCA; LDA
AB In pattern classification, Principle Component Analysis (PCA) and Linear Discriminate Analysis (LDA) are commonly used to reduce the dimensionality of input feature space. However, there exist some problems such that how many eigen vectors are needed to be the most effective in the transformation map as well as the lack of optimal separability in low dimensional data. In this paper, we present a new distance-based separator representation to solve these problems. The representation frame structure keeps adjustment pertaining to the problem complexity, and its dimensionality corresponds to the number of classes. Experimental results show that the new representation outperforms the PCA and LDA representations in multi-class classification and low-dimensional classification. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Shih, Frank Y.; Zhang, Kai] New Jersey Inst Technol, Coll Computing Sci, Comp Vis Lab, Newark, NJ 07102 USA.
C3 New Jersey Institute of Technology
RP Shih, FY (corresponding author), New Jersey Inst Technol, Coll Computing Sci, Comp Vis Lab, Newark, NJ 07102 USA.
EM shih@njit.edu
RI Wang, Xiaojing/HNI-4384-2023
OI Wang, Xiaojing/0000-0001-6921-3619
CR [Anonymous], 1990, NEUROCOMPUTING, DOI [DOI 10.1007/978-3-642-76153-9_5, 10.1007/978-3-642-76153-9_5]
   BOTTOU L, 1994, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1994.576879
   Cheng SX, 2007, PATTERN RECOGN, V40, P964, DOI 10.1016/j.patcog.2006.06.016
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Herbrich Ralf, 2001, Learning kernel classifiers: theory and algorithms
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   VAPNIK VN, 1998, STAT LERANING THEORY
NR 7
TC 12
Z9 12
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 667
EP 672
DI 10.1016/j.imavis.2007.08.004
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900007
DA 2024-07-18
ER

PT J
AU Harker, M
   O'Leary, P
   Zsombor-Murray, P
AF Harker, Matthew
   O'Leary, Paul
   Zsombor-Murray, Paul
TI Direct type-specific conic fitting and eigenvalue bias correction
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE curve fitting; conics; constrained least squares
ID LEAST-SQUARES; ELLIPSES
AB A new method to fit specific types of conics to scattered data points is introduced. Direct, specific fitting of ellipses and hyperbolae is achieved by imposing a quadratic constraint on the conic coefficients, whereby an improved partitioning of the design matrix is devised so as to improve computational efficiency and numerical stability by eliminating redundant aspects of the fitting procedure. Fitting of parabolas is achieved by determining an orthogonal basis vector set in the Grassmannian space of the quadratic terms' coefficients. The linear combination of the basis vectors that fulfills the parabolic condition and has a minimum residual norm is determined using Lagrange multipliers. This is the first known direct solution for parabola specific fitting. Furthermore, the inherent bias of a linear conic fit is addressed. We propose a linear method of correcting this bias, producing better geometric fits which are still constrained to specific conic type. (c) 2007 Published by Elsevier B.V.
C1 [Harker, Matthew; O'Leary, Paul] Univ Leoben, Inst Automat, Leoben, Austria.
   [Zsombor-Murray, Paul] McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2T5, Canada.
C3 University of Leoben; McGill University
RP Harker, M (corresponding author), Univ Leoben, Inst Automat, Leoben, Austria.
EM matthew.harker@stud.unileoben.ac.at
RI Harker, Matthew/AAV-2565-2020; Harker, Matthew/Y-1713-2019; O'Leary,
   Paul L/K-4998-2012
OI Harker, Matthew/0000-0001-9620-438X; 
CR ANDREW W, 1995, BRIT MACH VIS C, P513
   BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0
   Chojnacki W, 2003, IEEE T PATTERN ANAL, V25, P1172, DOI 10.1109/TPAMI.2003.1227992
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   GANDER W, 1981, NUMER MATH, V36, P291, DOI 10.1007/BF01396656
   Golub G.H., 1989, MATRIX COMPUTATIONS
   GOLUB GH, 1987, GENERALIZATION ECKAR, V88, P317
   Halir R, 2000, NUMERICALLY STABLE D
   HARKER M, 2004, FITTING CONICS SPECI
   KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P320, DOI 10.1109/34.276132
   KLEIN F, 1940, ELEMENTARY MATH ADV
   Nievergelt Y, 2004, LINEAR ALGEBRA APPL, V378, P1, DOI 10.1016/j.laa.2003.08.022
   Nievergelt Y, 2001, LINEAR ALGEBRA APPL, V331, P43, DOI 10.1016/S0024-3795(01)00263-4
   O'Leary P, 2004, J ELECTRON IMAGING, V13, P492, DOI 10.1117/1.1758951
   OUELLETTE DV, 1981, LINEAR ALGEBRA APPL, V36, P187, DOI 10.1016/0024-3795(81)90232-9
   PILU M, 1996, IEEE ICIP LAUS SWITZ
   Rosin PL, 1996, GRAPH MODEL IM PROC, V58, P494, DOI 10.1006/gmip.1996.0041
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
NR 18
TC 30
Z9 34
U1 0
U2 18
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 372
EP 381
DI 10.1016/j.imavis.2006.12.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bauckhage, C
   Wachsmuth, S
   Hanheide, M
   Wrede, S
   Sagerer, G
   Heidemann, G
   Ritter, H
AF Bauckhage, C.
   Wachsmuth, S.
   Hanheide, M.
   Wrede, S.
   Sagerer, G.
   Heidemann, G.
   Ritter, H.
TI The visual active memory perspective on integrated recognition systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE cognitive vision; contextual reasoning; fusion; architecture; system
   integration
ID COARSE
AB Object recognition is the ability of a system to relate visual stimuli to its knowledge of the world. Although humans perform this task effortlessly and without thinking about it, a general algorithmic solution has not yet been found. Recently, a shift from devising isolated recognition techniques towards integrated systems could be observed [Y. Aloimonos, Active vision revisited, in: Y. Aloimonos (Ed.), Active Perception, Lawrence Efibaum, 1993, pp. 1-18; H. Christensen, Cognitive (vision) systems, ERCIM News (April, 2003). 1718]. The visual active memory (VAM) perspective refines this system view towards an interactive computational framework for recognition systems in human everyday environments. VAM is in line with the recently emerged Cognitive Vision paradigm [H. Christensen, Cognitive (vision) systems, ERCIM News (April, 2003). 17-18] which is concerned with vision systems that evaluate, gather and integrate contextual knowledge for visual analysis. It consists of active processes that generate knowledge by means of a tight cooperation of perception, reasoning, learning and prior models. In addition, VAM emphasizes the dynamic representation of gathered knowledge. The memory is assumed to be structured in a hierarchy of successive memory systems that mediate the modularly defined processing components of the recognition system. Recognition and learning take place in the stress field of objects, actions, activities, scene context, and user interaction. In this paper, we exemplify the VAM perspective by means of existing demonstrator systems. Assuming three different perspectives (biological foundation, system engineering, and computer vision), we will show that the VAM concept is central to the cognitive capabilities of the system and that it leads to a more general object recognition framework. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Bielefeld, Fac Technol Appl Comp Sci, D-33501 Bielefeld, Germany.
   Univ Bielefeld, Fac Technol, Neuroinformat Grp, D-33501 Bielefeld, Germany.
C3 University of Bielefeld; University of Bielefeld
RP Bauckhage, C (corresponding author), Deutsche Telekom AG Labs, Ernst Reuter Pl 7, D-10587 Berlin, Germany.
EM christian.bauckhage@telekom.de
RI Hanheide, Marc/AAO-9299-2021; Bauckhage, Christian/M-7872-2014
OI Hanheide, Marc/0000-0001-7728-1849; Bauckhage,
   Christian/0000-0001-6615-2128; Wachsmuth, Sven/0000-0001-5371-7214;
   Wrede, Sebastian/0000-0003-0029-8188
CR ALOIMONOS Y, 1993, ACTIVE PERCEPTION, P1
   [Anonymous], ADV COMPUT VIS
   Bauckhage C, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P9, DOI 10.1109/ICMI.2002.1166961
   Bekel H, 2004, LECT NOTES COMPUT SC, V3175, P447
   BERGEVIN R, 1993, IEEE T PATTERN ANAL, V15, P19, DOI 10.1109/34.184772
   BLACK M, 1998, P ECCV, P907
   CHEN J, 2004, CAPTECH 04, P26
   CHRISTENSEN H, 2003, ERCIM NEWS, P17
   Cockburn A., 2002, AGILE SOFTWARE DEV
   Crowley J. L., 2002, UbiComp 2002: Ubiquitous Computing. 4th International Conference. Proceedings (Lecture Notes in Computer Science Vol.2498), P117
   CROWLEY JL, 1995, VISION PROCESS
   Cruse H, 2003, COGNITIVE SCI, V27, P135, DOI 10.1016/S0364-0213(02)00110-6
   DRAPER B, 1994, P ICPR, V1, P833
   Fritsch J, 2004, INT C PATT RECOG, P930, DOI 10.1109/ICPR.2004.1334681
   FRITSCH J, 2003, THESIS BIELEFELD U
   Granlund GH, 2000, LECT NOTES COMPUT SC, V1888, P48
   Heidemann G., 2005, Pattern Recognition and Image Analysis, V15, P55
   HEIDEMANN G, 2003, P INT C COGN VIS SYS, P22
   Heidemann Gunther, 2004, P 6 INT C MULT INT I, P53, DOI DOI 10.1145/1027933.1027944
   HOOGS A, 2003, P CVPR, V2, P327
   Jensen F. V., 2007, Bayesian networks and decision graphs
   Kittler J, 2003, LECT NOTES COMPUT SC, V2709, P106
   LAURITZEN SL, 1995, COMPUT STAT DATA AN, V19, P191, DOI 10.1016/0167-9473(93)E0056-A
   List T, 2004, INT C PATT RECOG, P789, DOI 10.1109/ICPR.2004.1334335
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Murphy K, 2004, ADV NEUR IN, V16, P1499
   Nilsson NJ., 1998, ARTIF INTELL
   PONWEISER W, 2003, ICVS WORKSH COMP VIS
   Roy D., 2002, EVOLUTION COMMUNICAT, V4, P33
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SIEGL H, 2005, JOINT HUNG AUSTR C I, P11
   Ster T., 2003, P 5 INT C MULT INT, P180
   Tulving Endel, 1995, P839
   ULLMAN S, 1995, HIGH LEVEL VISION
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wrede S, 2004, INT C PATT RECOG, P757, DOI 10.1109/ICPR.2004.1334304
   Wrede S, 2004, INT C PATT RECOG, P761, DOI 10.1109/ICPR.2004.1334307
   2003, INTERNET COMMUNICATI
NR 38
TC 5
Z9 6
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 5
EP 14
DI 10.1016/j.imavis.2005.08.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100002
DA 2024-07-18
ER

PT J
AU Berthé, V
   Fiorio, C
   Jamet, D
   Philippe, F
AF Berthe, Valerie
   Fiorio, Christophe
   Jamet, Damien
   Philippe, Fabrice
TI On some applications of generalized functionality for arithmetic
   discrete planes
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE digital planes; arithmetic planes; local configurations; functionality
   of discrete planes
ID LOCAL CONFIGURATIONS; GRACEFUL PLANES; NAIVE PLANES
AB Naive discrete planes are well known to be functional on a coordinate plane. The aim of our paper is to extend the functionality concept to a larger family of arithmetic discrete planes, by introducing suitable projection directions (alpha(1,)alpha(2),alpha(3)) satisfying alpha(1)nu(1) + alpha(2)nu(2) + alpha(3)nu(3) = w. Several applications are considered. We first study certain local configurations, that is, the (m,n)-cubes introduced in Ref. [J. Vittone, J.-M. Chassery, (n,m)-cubes and Farey Nets for Naive Planes Understanding, in: DGCI 8th International Conference, Lecture Notes in Computer Science, vol. 1568, Springer-Verlag, 1999, pp. 76-87.]. We compute their number for a given (m,n) and study their statistical behaviour. We then apply functionality to formulate an algorithm for generating arithmetic discrete planes, inspired by Debled-Renesson [I. Debled-Renesson, Reconnaissance des Droites et Plans Discrets, These de doctorat, Universite Louis Pasteur, Strasbourg, France, 1995.]. We also prove that an arithmetic discrete plane may be endowed with a combinatorial surface structure, in the spirit of Ref. [Y. Kenmochi, A. Imiyam Combinatorial topologies for discrete planes, in: DGCI, IIth International Conference, DGCI 2003, Lecture Notes in Computer Science, vol. 2886, Springer-Verlag, 2003, pp. 144-153.]. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Montpellier 2, LIRMM, UMR 5506, F-34392 Montpellier 5, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite
   Paul-Valery; Universite Perpignan Via Domitia; Universite de Montpellier
RP Jamet, D (corresponding author), Univ Montpellier 2, LIRMM, UMR 5506, 161 Rue Ada, F-34392 Montpellier 5, France.
EM berthe@lirmm.fr; fiorio@lirmm.fr; jamet@lirmm.fr; philippe@lirmm.fr
RI Berthe, Valerie/T-3055-2019
OI Berthe, Valerie/0000-0001-5561-7882
CR Andres E, 1997, GRAPH MODEL IM PROC, V59, P302, DOI 10.1006/gmip.1997.0427
   Arnoux P, 2004, THEOR COMPUT SCI, V319, P145, DOI 10.1016/j.tcs.2004.02.017
   Barneva RP, 2000, THEOR COMPUT SCI, V246, P73, DOI 10.1016/S0304-3975(98)00346-6
   Berthé V, 2000, DISCRETE MATH, V223, P27, DOI 10.1016/S0012-365X(00)00039-X
   Berthé V, 2005, LECT NOTES COMPUT SC, V3429, P276
   Berthe V., 2001, Journal of Automata, Languages and Combinatorics, V6, P121
   BERTHE V, 2005, 5 INT C WORDS, V36, P163
   Brimkov VE, 2004, LECT NOTES COMPUT SC, V3322, P276
   Brimkov VE, 2002, PATTERN RECOGN LETT, V23, P623, DOI 10.1016/S0167-8655(01)00139-8
   Brimkov VE, 2002, THEOR COMPUT SCI, V283, P151, DOI 10.1016/S0304-3975(01)00061-5
   Brimkov VE, 1999, LECT NOTES COMPUT SC, V1568, P53
   Brimkov VE, 2000, VOLUME GRAPHICS, P51
   DEBLEDRENNESSON I, 1994, P SPIE, V2356
   DEBLEDRENNESSON I, 1995, THESIS U LOUIS PASTE
   DEBLEDRENNESSON I, 2003, ELECT NOTES DISCRETE, V12, P12
   Francon J, 1996, THEOR COMPUT SCI, V156, P159, DOI 10.1016/0304-3975(95)00059-3
   Françon J, 1999, LECT NOTES COMPUT SC, V1568, P425
   Francon J., 1996, LNCS, V1176, P141
   Gérard Y, 1999, LECT NOTES COMPUT SC, V1568, P65
   Jacob-Da Col MA, 2002, THEOR COMPUT SCI, V283, P183, DOI 10.1016/S0304-3975(01)00064-0
   Kenmochi Y, 2003, LECT NOTES COMPUT SC, V2886, P144
   KENMOCHI Y, 2000, P 9 INT C DISCR GEOM, P249
   Kuipers L., 1985, UNIFORM DISTRIBUTION
   Malgouyres R, 1999, INT J PATTERN RECOGN, V13, P465, DOI 10.1142/S0218001499000288
   MORGENTHALER DG, 1981, INFORM CONTROL, V51, P227, DOI 10.1016/S0019-9958(81)90290-4
   PYTHEAS N, 2002, LECT NOTES MATH, V1794
   REVEILLES JP, 1995, P SOC PHOTO-OPT INS, V2573, P23, DOI 10.1117/12.216425
   REVEILLES JP, 1991, THESIS LOUIS PASTEUR
   ROTE G, 1994, J NUMBER THEORY, V46, P196, DOI 10.1006/jnth.1994.1012
   SCHRAMM JM, 1997, LECT NOTES COMPUT SC, V1347, P87
   Vittone J, 2000, LECT NOTES COMPUT SC, V1953, P296
   Vittone J, 1999, LECT NOTES COMPUT SC, V1568, P76
   VITTONE J, 1997, LECT NOTES COMPUT SC, V1347, P99
   Vuillon L, 1999, B BELG MATH SOC-SIM, V6, P625, DOI 10.36045/bbms/1103055587
NR 34
TC 5
Z9 5
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1671
EP 1684
DI 10.1016/j.imavis.2006.06.023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kassim, AA
   Mannan, MA
   Mian, Z
AF Kassim, A. A.
   Mannan, M. A.
   Mian, Zhu
TI Texture analysis methods for tool condition monitoring
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE machine vision; texture analysis; tool wear monitoring
ID HOUGH TRANSFORM; IMAGE; SYSTEM
AB Tool wear dramatically affects the texture of the machined surface. Analyzing the texture of machined surfaces has been shown to be promising for tool wear monitoring. However, most methods have their limitations when applied to real environments, where the geometric features of machined surface depend on the machining operation, and where image quality is affected by illumination and other factors. Problems of non-uniform illumination and image noise can be reduced by applying image segmentation and image enhancement techniques. This paper discusses our work on statistical and structural approaches for analyzing machined surfaces and investigates the correlation between tool wear and quantities characterizing machined surfaces. The column projection method can be used for machined surfaces with highly repetitive and regular textures while the connectivity oriented fast Hough transform based method is able to characterize surfaces produced by various machining processes and conditions. Our results clearly indicate that tool condition monitoring which is defined as the ability to distinguish between a sharp, a semi-dull, or a dull tool can be successfully accomplished by analysis of statistical and structural information extracted from the machined surface. (C) 2006 Elsevier B.V. All rights reserved.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
   Natl Univ Singapore, Dept Mech Engn, Singapore 119260, Singapore.
C3 National University of Singapore; National University of Singapore
RP Kassim, AA (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 10 Kent Ridge Crescent, Singapore 119260, Singapore.
EM ashraf@nus.edu.sg
RI Mannan, Muhammad Adeel/HKE-6543-2023
OI Mannan, Muhammad Adeel/0000-0002-0811-4753; Kassim,
   Ashraf/0000-0001-7435-8564
CR Beyerer J, 1997, OPT ENG, V36, P85, DOI 10.1117/1.601602
   BYRNE G, 1995, ANN CIRP
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Choi E, 2000, INT GEOSCI REMOTE SE, P2146, DOI 10.1109/IGARSS.2000.858336
   CHU A, 1990, PATTERN RECOGN LETT, V11, P415, DOI 10.1016/0167-8655(90)90112-F
   Guillemaud R, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P872, DOI 10.1109/ICIP.1998.723695
   Jemielniak K, 1999, INT J ADV MANUF TECH, V15, P711, DOI 10.1007/s001700050123
   KALVIAINEN H, 1995, IMAGE VISION COMPUT, V13, P239, DOI 10.1016/0262-8856(95)99713-B
   Kalviainen H, 1997, PATTERN RECOGN LETT, V18, P77, DOI 10.1016/S0167-8655(96)00132-8
   Kassim AA, 2004, PATTERN RECOGN, V37, P1925, DOI 10.1016/j.patcog.2004.01.014
   Kurada S, 1997, TRIBOL INT, V30, P295, DOI 10.1016/S0301-679X(96)00058-8
   Kurada S, 1997, COMPUT IND, V34, P55, DOI 10.1016/S0166-3615(96)00075-9
   Lai SH, 2001, J ELECTRON IMAGING, V10, P359, DOI 10.1117/1.1313240
   Leon FP, 1997, P SOC PHOTO-OPT INS, V3100, P297, DOI 10.1117/12.287757
   Mannan MA, 2000, PATTERN RECOGN LETT, V21, P969, DOI 10.1016/S0167-8655(00)00050-7
   Pfeifer T, 2000, MEASUREMENT, V28, P209, DOI 10.1016/S0263-2241(00)00014-2
   Rafael C.G., 1993, DIGITAL IMAGE PROCES
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   Yang MY, 1998, CONTROL ENG PRACT, V6, P1389, DOI 10.1016/S0967-0661(98)00117-8
NR 19
TC 53
Z9 61
U1 1
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1080
EP 1090
DI 10.1016/j.imavis.2006.05.024
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300006
DA 2024-07-18
ER

PT J
AU Bevilacqua, V
   Mastronardi, G
   Piscopo, G
AF Bevilacqua, V.
   Mastronardi, G.
   Piscopo, G.
TI Evolutionary approach to inverse planning in coplanar radiotherapy
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE genetic algorithms; conformal; aperture-based; intensity modulated
   radiation therapy
ID BEAM ORIENTATION; OPTIMIZATION
AB A unified evolutionary approach to coplanar radiotherapy inverse planning is proposed. It consists of a genetic algorithm-based framework that solves with little modification treatment planning for three different kinds of radiation therapy: conformal, aperture-based and intensity modulated. Thanks to evolutionary optimisation techniques we have been able to search for full beam configurations, that is beam intensity, beam shape and especially beam orientation. Unlike some previous works found in literature, our proposed solution automatically determines exact beam angles not relaying solely on a geometrical basis but involving beam intensity profiles, thus considering the effective delivered dose. Our dose distribution model has been validated through comparison with commercial system: fixed the same beam configuration, both calculated beam shapes and DVH have been compared. Then we have tested the optimisation algorithm with real clinical cases: these involved both simple (convex target, far organs at risk) and complex (concave target, close organs at risk) ones. As stated by physician and by simulation with the same commercial system, our tools found good solutions in both cases using corresponding correct therapy. (c) 2006 Elsevier B.V. All rights reserved.
C1 Polytech Bari, Dept Elect & Elect Engn, I-70125 Bari, Italy.
C3 Politecnico di Bari
RP Bevilacqua, V (corresponding author), Polytech Bari, Dept Elect & Elect Engn, Via Orabona 4, I-70125 Bari, Italy.
EM bevilacqua@poliba.it
RI Bevilacqua, Vitoantonio/AAF-5588-2020; Bevilacqua,
   Vitoantonio/AAH-6468-2019
OI Bevilacqua, Vitoantonio/0000-0002-3088-0788
CR BEASLEY D, 1993, U COMPUT, V15, P58
   BRAUNSTEIN M, 2000, TOMOGRPAHIC INTENSIT
   Cotrutz C, 2003, PHYS MED BIOL, V48, P2987, DOI 10.1088/0031-9155/48/18/303
   Ezzell GA, 1996, MED PHYS, V23, P293, DOI 10.1118/1.597660
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Haas OCL, 1998, PHYS MED BIOL, V43, P2179, DOI 10.1088/0031-9155/43/8/013
   Knowles J, 1998, IEEE C EVOL COMPUTAT, P398, DOI 10.1109/ICEC.1998.699788
   Marzi S, 2001, Ann Ist Super Sanita, V37, P225
   Michalewicz Z., 1996, GENETIC ALGORITHMS D, DOI [DOI 10.1007/978-3-662-03315-9, 10.1007/978-3-662-03315-9]
   MILICKOVIC N, UNPUB INTENSITY MODU
   Pugachev A, 2002, INT J RADIAT ONCOL, V54, P1565, DOI 10.1016/S0360-3016(02)03917-2
   Pugachev A, 2001, INT J RADIAT ONCOL, V50, P551, DOI 10.1016/S0360-3016(01)01502-4
   SCHREIBMANN E, 2001, GEOMETRY BASED OPTIM
   WEBB S, 1994, PHYS MED BIOL, V39, P2229, DOI 10.1088/0031-9155/39/12/007
   Webb S., 2000, INTENSITY MODULATED
NR 15
TC 19
Z9 20
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 196
EP 203
DI 10.1016/j.imavis.2006.01.027
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700008
DA 2024-07-18
ER

PT J
AU Faria, LN
   Mascarenhas, NDA
   Morón, CE
   Saito, JH
   Rosa, RR
   Sawant, HS
AF Faria, Lilian N.
   Mascarenhas, Nelson D. A.
   Moron, Celio E.
   Saito, Jos H.
   Rosa, Reinaldo R.
   Sawant, Hanumant S.
TI A parallel application for 3D reconstruction of coronal loops using
   image morphing
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE coronal loops; 3D reconstruction; image processing; image morphing;
   parallel system
ID INTERPOLATION
AB This paper presents an approach for 3D reconstruction of X-ray tomographic images of coronal loops, observed on the solar atmosphere by the Japanese satellite Yohkoh. In this approach, the intermediate cross-sections images of the magnetic loop are generated with image morphing controlled by a Bezier curve in arc shape. Due to the high computational costs involved in the processing and visualization of solar images, a parallel application for 3D reconstruction of a coronal loop was implemented to execute in the Atlas parallel system. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Fed Sao Carlos, Dept Comp, BR-13565905 Sao Carlos, SP, Brazil.
   INPE, DAS, Inst Nacl Pesquisas Espaciais, BR-12201970 Sao Jose Dos Campos, Brazil.
   INPE, LAC, Div Astrofis, Lab Associado Comp & Matemat Aplicada, BR-12201970 Sao Jose Dos Campos, Brazil.
C3 Universidade Federal de Sao Carlos; Instituto Nacional de Pesquisas
   Espaciais (INPE); Instituto Nacional de Pesquisas Espaciais (INPE)
RP Faria, LN (corresponding author), Univ Fed Sao Carlos, Dept Comp, CP 676, BR-13565905 Sao Carlos, SP, Brazil.
EM lilian@dc.ufscar.br; nelson@dc.ufscar.br; celio@dc.ufscar.br;
   saito@dc.ufscar.br; reinaldo@lac.inpe.br; sawant@das.inpe.br
RI Rosa, Reinaldo Roberto/AAG-3004-2019; Rosa, Reinaldo/E-1524-2012; Faria,
   Lilian/KQU-7020-2024; ROSA, REINALDO Roberto/ABG-7411-2021
OI Rosa, Reinaldo Roberto/0000-0002-2962-4322; 
CR BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   *EONIC SOL, 2001, ATL SYST US GUID ATL
   Gomes J., 1998, WARPING MORPHING GRA
   Lee JY, 2001, J FOOD PROD MARK, V7, P3, DOI 10.1300/J038v07n01_02
   Lee S, 1996, IEEE T VIS COMPUT GR, V2, P337, DOI 10.1109/2945.556502
   Lee S.-Y., 1995, SIGGRAPH '95, P439
   LUO B, 1997, P IEEE 13 INT C DIG, P1145
   MORON C, 1997, P 9 S ARQ COMP PAD S, P605
   MORON CE, 2002, 12 BRAZ S COMP ARCH, P313
   Ribeiro JRP, 1998, LECT NOTES COMPUT SC, V1388, P994
   Rosa RR, 1999, INT J MOD PHYS C, V10, P147, DOI 10.1142/S0129183199000103
   Rosa RR, 2000, ADV SPACE RES, V25, P1917, DOI 10.1016/S0273-1177(99)00624-9
   RUPRECHT D, 1995, IEEE COMPUT GRAPH, V15, P37, DOI 10.1109/38.365004
   RUPRECHT D, 1994, J VISUAL COMP ANIMAT, V5, P167, DOI 10.1002/vis.4340050304
   Shepard D., 1968, P 1968 23 ACM NAT C, P517, DOI DOI 10.1145/800186.810616
   TSUNETA S, 1993, ASTROPHYS SPACE SC L, V184, P113
   UCHIDA Y, 1993, ASTROPHYS SPACE SC L, V184, P97
   *WIND RIV SYST, 2001, VIRTUOSO US GUID VER
   Wolberg G, 1998, VISUAL COMPUT, V14, P360, DOI 10.1007/s003710050148
   Wolberg G., 1990, Digital image warping
NR 20
TC 2
Z9 3
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 95
EP 102
DI 10.1016/j.imavis.2005.12.007
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600011
DA 2024-07-18
ER

PT J
AU Kim, BG
   Park, DJ
AF Kim, Byung-Gyu
   Park, Dong-Jo
TI Novel target segmentation and tracking based on fuzzy membership
   distribution for vision-based target tracking system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image segmentation; target detection; three-dimensional feature; fuzzy
   membership value; optimal membership value
AB One of the basic processes of a vision-based target tracking system is the detection process that separates an object from the background in a given image. A novel target detection technique for suppression of the background clutter is presented that uses a predicted point that is estimated from a tracking filter. For every pixel, the three-dimensional feature that is composed of the x-position, the y-position and the gray level of its position is used for evaluating the membership value that describes the probability of whether the pixel belongs to the target or to the background. These membership values are transformed into the membership level histogram. We suggest an asymmetric Laplacian model for the membership distribution of the background pixel and determine the optimal membership value for detecting the target region using the likelihood criterion. The proposed technique is applied to several infra-red image sequences and CCD image sequences to test segmentation and tracking. The feasibility of the proposed method is verified through comparison of the experimental results with the other techniques. (c) 2006 Elsevier B.V. All rights reserved.
C1 Elect & Telecommun Res Inst, Embedded Software Res Div, Taejon 305350, South Korea.
   Korea Adv Inst Sci & Technol, Dept Elect Engn & Comp Sci, Taejon 305701, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Korea Advanced Institute of Science & Technology (KAIST)
RP Kim, BG (corresponding author), Elect & Telecommun Res Inst, Embedded Software Res Div, 161 Gajeong Dong, Taejon 305350, South Korea.
EM bg.kim@ieee.org; djpark@eekaist.kaist.ac
CR ABUTALEB AS, 1989, COMPUT VISION GRAPH, V47, P22, DOI 10.1016/0734-189X(89)90051-0
   BARSHALOM Y, 1991, TRACKING DATA ASS
   Brink AD, 1996, PATTERN RECOGN, V29, P179, DOI 10.1016/0031-3203(95)00066-6
   DUDZIK MC, ELECT OPTICAL SYSTEM
   HUANG LK, 1995, PATTERN RECOGN, V28, P41, DOI 10.1016/0031-3203(94)E0043-K
   Jawahar CV, 1997, PATTERN RECOGN, V30, P1605, DOI 10.1016/S0031-3203(97)00004-6
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   KUMAR A, 1995, IEEE T PATTERN ANAL, V17, P182, DOI 10.1109/34.368171
   LIE WN, 1995, IEEE T IMAGE PROCESS, V4, P1036, DOI 10.1109/83.392347
   MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275
   MARDIA KV, 1988, IEEE T PATTERN ANAL, V10, P919, DOI 10.1109/34.9113
   MURTHY CA, 1990, PATTERN RECOGN LETT, V11, P197, DOI 10.1016/0167-8655(90)90006-N
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL SK, 1990, PATTERN RECOGN, V7, P77
   PUN T, 1981, COMPUT VISION GRAPH, V16, P210, DOI 10.1016/0146-664X(81)90038-1
   Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885
   VANRHEEDEN DR, 1988, IEEE T AERO ELEC SYS, V24, P177, DOI 10.1109/7.1051
   Wu XJ, 1999, PATTERN RECOGN, V32, P2055, DOI 10.1016/S0031-3203(97)00158-1
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   YANG JD, 1994, PATTERN RECOGN LETT, V15, P141, DOI 10.1016/0167-8655(94)90043-4
   YANOWITZ SD, 1989, COMPUT VISION GRAPH, V46, P82, DOI 10.1016/S0734-189X(89)80017-9
   Zhang XP, 2001, IEEE T IMAGE PROCESS, V10, P1020, DOI 10.1109/83.931096
NR 22
TC 15
Z9 18
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2006
VL 24
IS 12
BP 1319
EP 1331
DI 10.1016/j.imavis.2006.04.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 107AH
UT WOS:000242142600006
DA 2024-07-18
ER

PT J
AU Fuentes, LM
   Velastin, SA
AF Fuentes, Luis M.
   Velastin, Sergio A.
TI People tracking in surveillance applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Performance Evaluation of Tracking and Surveillance (PETS)
CY DEC09, 2001
CL Kauai, HI
SP IEEE
DE CCTV surveillance; tracking; automatic surveillance
AB This paper presents a real-time algorithm that allows robust tracking of multiple objects in complex environments. Foreground pixels are detected using luminance contrast and grouped into blobs. Blobs from two consecutive frames are matched creating the matching matrices. Tracking is performed using direct and inverse matching matrices. This method successfully solves blobs merging and splitting. Some application in automatic surveillance systems are suggested by linking trajectories and blob position information with the events to be detected. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Valladolid, Fac Ciencias, Dept Fis Aplicada, E-47071 Valladolid, Spain.
   Kingston Univ, Digitam Imaging Res Ctr, Kingston upon Thames KT1 2EE, Surrey, England.
C3 Universidad de Valladolid; Kingston University
RP Fuentes, LM (corresponding author), Univ Valladolid, Fac Ciencias, Dept Fis Aplicada, E-47071 Valladolid, Spain.
EM luis.fuentes@computer.org
RI Fuentes, Luis M./N-3987-2014; Elhamod, Mohannad/A-1904-2012
OI Fuentes, Luis M./0000-0002-5760-2200; VELASTIN, SERGIO
   ALEJANDRO/0000-0001-6775-7137
CR Agbinya JI, 1999, REAL-TIME IMAGING, V5, P295, DOI 10.1006/rtim.1998.0174
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   DELATORRE F, 1997, P S SIGN IM PROC GRE
   FUENTES LM, 2001, P 2 EUR WORKSH ADV V
   FUENTES LM, 2002, ASSESSMENT IMAGE PRO
   FUENTES LM, 2001, P WSES IEEE C SPEECH, P2231
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Huwer S, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P37, DOI 10.1109/VS.2000.856856
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   ROSALES R, 1998, P IEEE C COMP VIS PA
   Rota N, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P59, DOI 10.1109/VS.2000.856858
   WREN CR, 1997, T PATTERN ANAL MACHI, V17, P780
NR 14
TC 39
Z9 51
U1 1
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2006
VL 24
IS 11
BP 1165
EP 1171
DI 10.1016/j.imavis.2005.06.006
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 101CJ
UT WOS:000241716200002
DA 2024-07-18
ER

PT J
AU Ibrahim, M
   John, N
   Kabuka, M
   Younis, A
AF Ibrahim, M.
   John, N.
   Kabuka, M.
   Younis, A.
TI Hidden Markov models-based 3D MRI brain segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE hidden Markov models; image segmentation; medical imaging
ID TISSUE CLASSIFICATION; ADAPTIVE SEGMENTATION; IMAGES; FIELD; CHAINS
AB This paper introduces a 3D MRI segmentation algorithm based on Hidden Markov Models (HMMs). The mathematical models for the HMM that forms the basis of the segmentation algorithm for both the continuous and discrete cases are developed and contrasted with Hidden Markov Random Field in terms of complexity and extensibility to larger fields. The presented algorithm clearly demonstrates the capacity of HMM to tackle multi-dimensional classification problems.
   The HMM-based segmentation algorithm was evaluated through application to simulated brain images from the McConnell Brain Imaging Centre, Montreal Neurological Institute, McGill University as well as real brain images from the Internet Brain Segmentation Repository (IBSR), Harvard University. The HMM model exhibited high accuracy in segmenting the simulated brain data and an even higher accuracy when compared to other techniques applied to the IBSR 3D MRI data sets. The achieved accuracy of the segmentation results is attributed to the HMM foundation and the utilization of the 3D model of the data. The IBSR 3D MRI data sets encompass various levels of difficulty and artifacts that were chosen to pose a wide range of challenges, which required handling of sudden intensity variations and the need for global intensity level correction and 3D anisotropic filtering. During segmentation, each class of MR tissue was assigned to a separate HMM and all of the models were trained using the discriminative MCE training algorithm. The results were numerically assessed and compared to those reported using other techniques applied to the same data sets, including manual segmentations establishing the ground truth for real MR brain data. The results obtained using the HMM-based algorithm were the closest to the manual segmentation ground truth in terms of an objective measure of overlap compared to other methods. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Miami, Coll Engn, Dept Elect & Comp Engn, Coral Gables, FL 33146 USA.
C3 University of Miami
RP Kabuka, M (corresponding author), Univ Miami, Coll Engn, Dept Elect & Comp Engn, 1251 Mem Dr,Room 406, Coral Gables, FL 33146 USA.
EM m.kabuka@miami.edu
CR [Anonymous], 1994, P EUR C COMP VIS
   Bahl L, 1988, P IEEE, P49
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Derrode S, 2004, IEEE T SIGNAL PROCES, V52, P2477, DOI 10.1109/TSP.2004.832015
   Descombes X, 1998, IEEE T MED IMAGING, V17, P1028, DOI 10.1109/42.746636
   Fjortoft R, 2003, IEEE T GEOSCI REMOTE, V41, P675, DOI 10.1109/TGRS.2003.809940
   Giordana N, 1997, IEEE T PATTERN ANAL, V19, P465, DOI 10.1109/34.589206
   Grimson E, 1998, LECT NOTES COMPUT SC, V1496, P63, DOI 10.1007/BFb0056188
   Grimson WEL, 1997, INT J PATTERN RECOGN, V11, P1367, DOI 10.1142/S0218001497000639
   Guillemaud R, 1997, IEEE T MED IMAGING, V16, P238, DOI 10.1109/42.585758
   Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883
   John NM, 2003, J DIGIT IMAGING, V16, P365, DOI 10.1007/s10278-003-1664-9
   JOHN NM, 1999, THESIS U MIAMI
   Juang BH, 1997, IEEE T SPEECH AUDI P, V5, P257, DOI 10.1109/89.568732
   Katagiri S, 1998, P IEEE, V86, P2345, DOI 10.1109/5.726793
   Moretti B, 2000, MED IMAGE ANAL, V4, P303, DOI 10.1016/S1361-8415(00)00021-9
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rajapakse JC, 1997, IEEE T MED IMAGING, V16, P176, DOI 10.1109/42.563663
   Rajapakse JC, 2001, IEEE T BIO-MED ENG, V48, P1186, DOI 10.1109/10.951522
   Rajapakse JC, 1998, IMAGE VISION COMPUT, V16, P165, DOI 10.1016/S0262-8856(97)00067-X
   Ruan S, 2000, IEEE T MED IMAGING, V19, P1179, DOI 10.1109/42.897810
   Van Leemput K, 2003, IEEE T MED IMAGING, V22, P105, DOI 10.1109/TMI.2002.806587
   Van Leemput K, 1999, IEEE T MED IMAGING, V18, P897, DOI 10.1109/42.811270
   VANLEEMPUT K, 2001, LECT NOTES COMPUTER, V2208, P204
   Wang Y, 2001, IEEE T INF TECHNOL B, V5, P150, DOI 10.1109/4233.924805
   Warfield S, 1995, J Image Guid Surg, V1, P326, DOI 10.1002/(SICI)1522-712X(1995)1:6<326::AID-IGS4>3.0.CO;2-C
   Wells WM, 1996, IEEE T MED IMAGING, V15, P429, DOI 10.1109/42.511747
   Zavaljevski A, 2000, COMPUT MED IMAG GRAP, V24, P87, DOI 10.1016/S0895-6111(99)00042-7
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
NR 29
TC 45
Z9 46
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1065
EP 1079
DI 10.1016/j.imavis.2006.03.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300003
DA 2024-07-18
ER

PT J
AU Arandjelovic, O
   Cipolla, R
AF Arandjelovic, Ognjen
   Cipolla, Roberto
TI An information-theoretic approach to face recognition from face motion
   manifolds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; face motion manifolds; kernel; resistor-average
   distance
AB In this work, we consider face recognition from face motion manifolds (FMMs). The use of the resistor-average distance (RAD) as a dissimilarity measure between densities confined to FMMs is motivated in the proposed information-theoretic approach to modelling face appearance. We introduce a kernel-based algorithm that makes use of the simplicity of the closed-form expression for RAID between two Gaussian densities, while allowing for modelling of complex and nonlinear, but intrinsically low-dimensional manifolds. Additionally. it is shown how geodesically local FMM structure can be modelled, naturally leading to a stochastic algorithm for generalizing to unseen modes of data variation. Recognition performance of our method is demonstrated experimentally and is shown to exceed that of state-of-the-art algorithms. Recognition rate of 98% was achieved on a database of 100 people under varying illumination. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Cambridge, Cambridge CB1 1PZ, England.
C3 University of Cambridge
RP Arandjelovic, O (corresponding author), Univ Cambridge, Cambridge CB1 1PZ, England.
EM oa214@eng.cam.ac.uk; cipolla@eng.cam.ac.uk
RI Arandjelović, Ognjen/V-5255-2019
OI Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla,
   Roberto/0000-0002-8999-2151
CR [Anonymous], J MACHINE LEARNING R
   [Anonymous], P IEEE C COMP VIS PA
   ARANDJELOVIC O, 2005, P IEEE C COMP VIS PA
   BARRETT WA, 1998, SYSTEMS COMPUTERS, V1, P301
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   BOLME DS, 2003, THESIS COLORADO STAT
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Cover Thomas A., 1991, ELEM INF THEORY, DOI 10.1002/047174882X
   FISCHLER MA, 1981, IMAGE, V24, P381
   FROMHERZ T, SURVEY FACE RECOGITI
   FUKUI K, 2003, INT S ROB
   GROSS R, 2001, WORKSH EMP EV METH C, V1, P119
   Johnson D.H., 2001, SYMMETRIZING KULLBAC
   KEPENEKCI B, 2001, HESIS MIDDLE E TU
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Moghaddam B, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P30, DOI 10.1109/AFGR.1998.670921
   Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3
   Schölkopf B, 1999, ADVANCES IN KERNEL METHODS, P327
   Shakhnarovich G, 2002, LECT NOTES COMPUT SC, V2352, P851, DOI 10.1007/3-540-47977-5_56
   SIM T, 2004, IEEE WORKSH FAC PROC, P84
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   YAMAGUCHI O, 1998, IEEE INT C AUT FAC G, V10, P318
   Yambor W. S., 2000, Analysis of PCA-based and Fisher discriminant-based image recognition algorithms
   Yoshizawa S., 1999, SUT Journal of Mathematics, V35, P113
   ZHAO W, CARTR948
   Zhou SH, 2003, COMPUT VIS IMAGE UND, V91, P214, DOI 10.1016/S1077-3142(03)00080-8
NR 28
TC 17
Z9 18
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2006
VL 24
IS 6
BP 639
EP 647
DI 10.1016/j.imavis.2005.08.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 061NB
UT WOS:000238878200010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gomez, DD
   Carstensen, JM
   Ersboll, BK
AF Gomez, DD
   Carstensen, JM
   Ersboll, BK
TI Collecting highly reproducible images to support dermatological medical
   diagnosis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image acquisition; camera calibration; diffuse illumination; principal
   component analysis; independent component analysis; psoriasis
ID IMAGING-SYSTEM; ACQUISITION
AB In this article, an integrated imaging system for acquisition of accurate standardized images is proposed. The system also aims at making highly reproducible images over time, so images taken at different times can be compared. The system is made up of an integrating intensity sphere illumination together with a high resolution 3CCD color camera. The well-defined and diffuse illumination of the optically closed scene enhances the true color and avoids effects from specular reflections, shading and shadows. Two experiments are conducted to show the precision of the system and the Suitability of the collected images to track dermatological diseases, Results indicate that the developed equipment is an excellent tool for getting high quality digital images. Furthermore, the images collected with the equipment turn out to be a good source to characterize dermatological images. (c) 2005 Elsevier B.V. All rights reserved.
C1 Image Proc & Comp Vis, DK-2800 Lyngby, Denmark.
RP Image Proc & Comp Vis, Richard Peterson Plads, DK-2800 Lyngby, Denmark.
EM ddg@imm.dtu.dk; jmc@imm.dtu.dk; be@imm.dtu.dk
RI Delgado-Gómez, David/M-2045-2014
OI Ersboll, Bjarne Kjaer/0000-0003-1262-7890; Carstensen, Jens
   Michael/0000-0002-2535-3908; DELGADO-GOMEZ, DAVID/0000-0002-2976-2602
CR ACHA B, 2001, P 23 ANN EMBS INT C
   CAMISA C, 1998, HDB PSORIASIS
   ENGSTROM N, 1990, PATHOGENESIS OF WOUND AND BIOMATERIAL-ASSOCIATED INFECTIONS, P189
   FOLMHANSEN R, 1999, THESIS LYNGBY
   GRATTONI P, 1991, P 5 INT C ADV ROB, P19
   Gutenev A, 2001, COMPUT MED IMAG GRAP, V25, P495, DOI 10.1016/S0895-6111(01)00017-9
   Hansen GL, 1997, IEEE T MED IMAGING, V16, P78, DOI 10.1109/42.552057
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   JOHNSON R, 1995, APPL MULTIVARIATED S
   Jollife I., 2002, PRINCIPAL COMPONENT
   Maglogiannis Ilias, 2004, J Med Syst, V28, P455, DOI 10.1023/B:JOMS.0000041172.70027.a0
   MARSZALEC E, 1994, P 12 IAPR INT C PATT, V1, P32
   UMBAUGH S, 1989, IEEE ENG MED BIOL
   Vander Haeghen Y, 2000, IEEE T MED IMAGING, V19, P722, DOI 10.1109/42.875195
   Vrhel MJ, 1999, IEEE T IMAGE PROCESS, V8, P1796, DOI 10.1109/83.806624
NR 15
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 186
EP 191
DI 10.1016/j.imavis.2005.10.001
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900008
DA 2024-07-18
ER

PT J
AU Deléchelle, E
   Nunes, JC
   Lemoine, J
AF Deléchelle, E
   Nunes, JC
   Lemoine, J
TI Empirical mode decomposition synthesis of fractional processes in 1D-and
   2D-space
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE empirical mode decomposition; fractional processes synthesis; Gaussian
   and Brownian texture images
ID BROWNIAN-MOTION
AB We report here on image texture analysis and on numerical simulation of fractional Brownian textures based on the newly emerged Empirical Mode Decomposition (EMD). EMD introduced by N.E. Huang et al. is a promising tool to non-stationary signal representation as a sum of zero-mean AM-FM components called Intrinsic Mode Functions (IMF). Recent works published by P. Flandrin et al. relate that, in the case of fractional Gaussian noise (fGn), EMD acts essentially as a dyadic filter bank that can be compared to wavelet decompositions. Moreover, in the context of fGn identification, P. Handrin et al. show that variance progression across IMFs is related to Hurst exponent H through a scaling law. Starting with these recent results, we propose a new algorithm to generate fGn, and fractional Brownian motion (fBm) of Hurst exponent H from IMFs obtained from EMD of a White noise, i.e. ordinary Gaussian noise (fGn with H= 1/2). (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Paris 12, LERISS EA 412, F-94010 Creteil, France.
C3 Universite Paris-Est-Creteil-Val-de-Marne (UPEC)
RP Univ Paris 12, LERISS EA 412, Val de Marne 61,Ave Gen Gaulle, F-94010 Creteil, France.
EM nunes@univ-paris12.fr
RI Nunes, Jean-Claude/O-7431-2017
OI Nunes, Jean-Claude/0000-0001-6560-1518
CR [Anonymous], IEEE ICASSP
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   CHAUDHURI BB, 1993, IEE PROC-E, V140, P233, DOI 10.1049/ip-e.1993.0034
   DERICHE M, 1993, IEEE T SIGNAL PROCES, V41, P2977, DOI 10.1109/78.277804
   Flandrin P, 2004, IEEE SIGNAL PROC LET, V11, P112, DOI 10.1109/LSP.2003.821662
   FLANDRIN P, 1992, IEEE T INFORM THEORY, V38, P910, DOI 10.1109/18.119751
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   KASHYAP RL, 1984, IEEE T PATTERN ANAL, V6, P800, DOI 10.1109/TPAMI.1984.4767604
   KLINKENBERG B, 1992, EARTH SURF PROC LAND, V17, P217, DOI 10.1002/esp.3290170303
   LUNDAHL T, 1986, IEEE T MED IMAGING, V5, P152, DOI 10.1109/TMI.1986.4307764
   MANDELBROT BB, 1968, SIAM REV, V10, P422, DOI 10.1137/1010093
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   STEWART CV, 1993, P IEEE, V81, P1511, DOI 10.1109/5.241511
   Taqqu MS, 1995, FRACTALS, V3, P785, DOI 10.1142/S0218348X95000692
   WORNELL GW, 1992, IEEE T SIGNAL PROCES, V40, P611, DOI 10.1109/78.120804
   WORNELL GW, 1993, P IEEE, V81, P1428, DOI 10.1109/5.241506
   YOKOYA N, 1989, COMPUT VISION GRAPH, V46, P284, DOI 10.1016/0734-189X(89)90034-0
   [No title captured]
   [No title captured]
   [No title captured]
NR 20
TC 15
Z9 17
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2005
VL 23
IS 9
BP 799
EP 806
DI 10.1016/j.imavis.2005.05.012
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VF
UT WOS:000231400700004
DA 2024-07-18
ER

PT J
AU Lee, KL
   Chen, LH
AF Lee, KL
   Chen, LH
TI An efficient computation method for the texture browsing descriptor of
   MPEG-7
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image retrieval; texture browsing; MPEG-7; digital library
ID RETRIEVAL; FEATURES
AB In this paper, an efficient computation method for computing the texture browsing descriptor of MPEG-7 is provided. Texture browsing descriptor is used to characterize a texture's regularity, directionality and coarseness. To compute the regularity of textures, Fourier transform is first performed. To get more discriminative features for regularity computation, the Fourier spectrum is treated as an image and the Fourier transform is performed again to produce an enhanced Fourier spectrum. A regularity measure based on the variance of the radial wedge distribution is then calculated to determine the regularity of textures. For regular textures, the texture primitives are assumed to be parallelograms, the two dominant directions are extracted by Hough transform. A scale computation method is then provided to determine the scales corresponding to the two dominant directions. In addition, principal component analysis is provided to detect textures with only one dominant direction. Experiments of texture browsing, coarse classification of textures and similarity-based image-to-image matching are performed on the texture images of Brodatz album and Corel Gallery image database to demonstrate the efficiency and effectiveness of the proposed method. The proposed method can be used in the applications of texture browsing and texture retrieval. (c) 2005 Elsevier B.V. All rights reserved.
C1 Natl Chiao Tung Univ, Dept Comp & Informat Sci, Hsinchu 30050, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Natl Chiao Tung Univ, Dept Comp & Informat Sci, 1001 Ta Hsueh Rd, Hsinchu 30050, Taiwan.
EM lhehen@cc.nctu.edu.tw
CR [Anonymous], 159383 ISOIEC
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Brodatz P., 1966, Textures: A Photgraphic Album for Artists and Designers
   Chen C. H., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P1074
   CONNERS RW, 1980, COMPUT VISION GRAPH, V12, P224, DOI 10.1016/0146-664X(80)90013-1
   *ISO IEC JTCI SC29, 2001, MPEG 7 VIS EXP MOD X
   Lee K. L., 2002, Pattern Recognition and Image Analysis, V12, P400
   Levine MartinD., 1985, VISION MAN MACHINE
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   TAMURA H, 1978, IEEE T SYST MAN CYB, V8, P460, DOI 10.1109/TSMC.1978.4309999
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   Wu P, 2000, SIGNAL PROCESS-IMAGE, V16, P33, DOI 10.1016/S0923-5965(00)00016-3
NR 13
TC 18
Z9 22
U1 0
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2005
VL 23
IS 5
BP 479
EP 489
DI 10.1016/j.imavis.2004.12.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 917XA
UT WOS:000228501300003
DA 2024-07-18
ER

PT J
AU Arcelli, C
   Serino, L
AF Arcelli, C
   Serino, L
TI Skeletonization of labeled gray-tone images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE gray-tone image; distance transformation; sequential process; skeleton
ID DISTANCE TRANSFORMATIONS; DIGITAL IMAGES; SEGMENTATION; TOPOLOGY; BINARY
AB A gray-tone image including perceptually meaningful elongated regions can be represented by a set of line patterns, the skeleton, consisting of pixels having different gray-values and mostly placed along the central positions of the regions themselves. In this paper, the image is considered as piecewise constant and a labeled image is created by computing the geodesic distance transformation for each image subset with constant gray-value. A sequential skeletonization process is performed on the labeled image, by employing topology preserving removal operations repeatedly applied to subsets with increasing label value. To obtain a one-pixel-thick skeleton, the topology preservation constraint is disregarded in correspondence with certain configurations in the gray-tone image which would otherwise constitute irreducible patterns. (C) 2004 Elsevier B.V. All rights reserved.
C1 CNR, Ist Cibernet E Caianiello, I-80078 Naples, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Cibernetica
   "Eduardo Caianiello" (ICIB-CNR)
RP CNR, Ist Cibernet E Caianiello, I-80078 Naples, Italy.
EM car@imagm.cib.na.cnr.it; ls@imagm.cib.na.cnr.it
RI SERINO, LUCA/D-2167-2016
OI SERINO, LUCA/0000-0003-0077-1799
CR Arcelli C, 2003, LECT NOTES COMPUT SC, V2886, P298
   Arcelli C, 2001, INT J PATTERN RECOGN, V15, P643, DOI 10.1142/S0218001401001106
   ARCELLI C, 1984, P 7 INT C PATT REC M, P344
   Arcelli C., 1996, Topological Algorithms for Digital Image Processing, volume 19 of Machine Intelligence and Pattern Recognition, V19, P99
   Bertrand G, 1997, J ELECTRON IMAGING, V6, P395, DOI 10.1117/12.276856
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   DIBAJA EG, 1994, ASPECTS VISUAL FORM, P475
   ECKHARDT U, 1994, ASPECTS VISUAL FORM, P199
   GOETCHERIAN V, 1980, PATTERN RECOGN, V12, P7, DOI 10.1016/0031-3203(80)90049-7
   Kong T. Y., 1996, TOPOLOGICAL ALGORITH, P263
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   LEVI G, 1970, INFORM CONTROL, V17, P62, DOI 10.1016/S0019-9958(70)80006-7
   Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254
   PIPER J, 1987, PATTERN RECOGN, V20, P599, DOI 10.1016/0031-3203(87)90030-6
   Ranwez V, 2002, PATTERN RECOGN LETT, V23, P687, DOI 10.1016/S0167-8655(01)00146-5
   ROSENFELD A, 1983, PATTERN RECOGN, V16, P47, DOI 10.1016/0031-3203(83)90007-9
   Serra J., 1983, IMAGE ANAL MATH MORP
   Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598
   Toivanen PJ, 1996, PATTERN RECOGN LETT, V17, P437, DOI 10.1016/0167-8655(96)00010-4
   WANG L, 1993, CVGIP-IMAG UNDERSTAN, V58, P352, DOI 10.1006/ciun.1993.1047
   Wang Y, 1996, PATTERN RECOGN, V29, P1359, DOI 10.1016/0031-3203(95)00159-X
   Yokoi S., 1975, COMPUTER GRAPHICS IM, V4, P63, DOI DOI 10.1016/0146-664X(75)90022-2
NR 23
TC 6
Z9 6
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 159
EP 166
DI 10.1016/j.imavis.2004.06.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800007
DA 2024-07-18
ER

PT J
AU Zelek, JS
AF Zelek, JS
TI Towards Bayesian real-time optical flow
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE optical flow; Bayesian; real-time; particle filter
AB Optical flow is a pre-requisite for computing motion detection, time to collision, structure, focus of expansion as well as object segmentation. Unfortunately, most optical flow techniques do not provide accurate and dense measures that are useful for these types of computations. In addition, most techniques are also computationally slow. Albeit, one method proposed by Camus claims and is able to perform optical flow computations in real-time capitalizing on redundancies in the computation and spatial-temporal sampling trade-offs. It is a simple technique based on simulating various motions and computing the sum-difference of patches. The shortcoming of the Camus algorithm is that the produced field is not accurate and is arbitrary for aperture and blank wall situations. However, we show that the intermediate results from the Camus approach can be used as the factored samples for the likelihood probabilities that can be used in a Bayesian spatial and temporal propagation framework. The maximization/minimization of the likelihood is not able to differentiate arbitrary from zero flow situations. It is interesting to note that the shape of the likelihood pdf clearly identifies aperture and blank wall cases. A simple diffusion of the means of reliable flow vectors produces results that are suitable for motion detection but are inaccurate for flow determination. Similar past efforts (e.g. Singh) for flow propagation produced comparable results with a computationally more complicated propagation process. It is argued that a logic is required that takes the variances into consideration in addition to the means is required for the propagation process: first propagating spatial (to address aperture and blank wall problems) and subsequently temporal information in order to maximize the number of unimodal small variance nodes. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.
C3 University of Guelph
RP Univ Guelph, Sch Engn, Guelph, ON N1G 2W1, Canada.
EM jzelek@uoguelph.ca
CR [Anonymous], 1981, 7 INT JOINT C ARTIFI
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Berry D., 1988, STAT DECISION THEORY
   BIRCHFIELD S, 1998, 1998 IEEE COMP VIS P
   BLACK MJ, 1998, 1999 INT C COMP VIS
   Camus T, 1997, REAL-TIME IMAGING, V3, P71, DOI 10.1006/rtim.1996.0048
   FERNMULLER C, 1999, P IEEE WORKSH STAT C
   FREEMAN WT, 1999, ADV NEURAL INFORMATI, V11
   FREEMAN WT, 2000, TR200005A MERL
   Galvin B., 1998, P BRIT MACH VIS C BM
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   MacKay D.J. C., 1999, LEARNING GRAPHICAL M
   NESTARES O, 2000, P IEEE C COMP VIS PA, V2, P760
   Simoncelli E.P., 1999, HDB COMPUTER VISION, P397
   SIMONCELLI EP, 1993, THESIS MIT CAMBRIDGE
   Wallach H, 1935, PSYCHOL FORSCH, V20, P325, DOI 10.1007/BF02409790
   WEISS Y, 1998, 161L AI LAB MIT
   Weiss Y., 2001, PROBABILISTIC MODELS, P81
NR 21
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 1051
EP 1069
DI 10.1016/j.imavis.2004.03.017
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800011
DA 2024-07-18
ER

PT J
AU Crossley, S
   Seed, NL
   Thacker, NA
   Ivey, PA
AF Crossley, S
   Seed, NL
   Thacker, NA
   Ivey, PA
TI Improving accuracy, robustness and computational efficiency in 3D
   computer vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereo vision; structure from motion; temporal stereo
ID STEREO; DISPARITY; ALGORITHM; MOTION; IMAGES; SYSTEM
AB This paper analyses the strengths and weaknesses of some of the most popular traditional and contemporary 3D vision techniques for accuracy, robustness and computational efficiency. A novel technique is proposed that extends traditional stereo vision (SV) algorithms using some of the previously identified techniques resulting in improved robustness, accuracy and computational efficiency. The new multi-scale temporally constrained SV technique is then applied to a conventional SV algorithm and the performance improvements demonstrated. (C) 2004 Elsevier B.V. All rights reserved.
C1 ARM Ltd, Sheffield S10 2GW, S Yorkshire, England.
   Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 3JD, S Yorkshire, England.
   Univ Manchester, Div Imaging Sci & Biomed Engn, Manchester M13 9PT, Lancs, England.
C3 Arm Holdings; University of Sheffield; University of Manchester
RP Crossley, S (corresponding author), ARM Ltd, New Spring House,231 Glossop Rd, Sheffield S10 2GW, S Yorkshire, England.
EM simon.crossley@arm.com; n.seed@sheffield.ac.uk; neil.thacker@man.ac.uk
OI Seed, Nicholas Luke/0000-0003-4648-5616
CR BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032
   CANNY JF, 1985, IEEE T PATTERN ANAL, V8, P679
   DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615
   HARRIS AJ, 1998, P EUR SIM MULT, P417
   Ho AYK, 1996, PATTERN RECOGN, V29, P121, DOI 10.1016/0031-3203(95)00068-2
   Hung YP, 1995, LECT NOTES COMPUT SC, V1024, P25
   Illingworth J, 1998, ELECTRON COMMUN ENG, V10, P103, DOI 10.1049/ecej:19980303
   LACEY A, 2001, TINA 2001 CLOSDED LO, P203
   Lacey AJ, 1998, IMAGE VISION COMPUT, V16, P373, DOI 10.1016/S0262-8856(97)00068-1
   LANE RA, 1994, IMAGE VISION COMPUT, V12, P203, DOI 10.1016/0262-8856(94)90074-4
   LANE RA, 1995, THESIS U SHEFFIELD
   Levine M., 1973, COMPUT VISION GRAPH, V2, P131
   LIU J, 1993, SIGNAL PROCESS-IMAGE, V5, P305
   MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482
   MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032
   ONeill M, 1996, IMAGE VISION COMPUT, V14, P225, DOI 10.1016/0262-8856(95)01061-0
   POLLARD SB, 1991, IMAGE VISION COMPUT, V9, P58, DOI 10.1016/0262-8856(91)90050-Y
   POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449
   THACKER NA, 1992, P BR MACHINE VISION, P316
   Verri A., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P171
   XU G, 1987, IEEE T PATTERN ANAL, V9, P332, DOI 10.1109/TPAMI.1987.4767908
   Yi JW, 1997, IMAGE VISION COMPUT, V15, P181, DOI 10.1016/S0262-8856(96)01118-3
NR 24
TC 1
Z9 1
U1 2
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2004
VL 22
IS 5
BP 399
EP 412
DI 10.1016/j.imavis.2003.12.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 806GN
UT WOS:000220422500005
DA 2024-07-18
ER

PT J
AU Li, CT
   Chiao, R
AF Li, CT
   Chiao, R
TI Multiresolution genetic clustering algorithm for texture segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE texture segmentation; genetic algorithm; K-means clustering;
   multiresolution
ID RANDOM-FIELD MODELS; UNSUPERVISED SEGMENTATION; CLASSIFICATION
AB This work plans to approach the texture segmentation problem by incorporating genetic algorithm and K-means clustering method within a multiresolution structure. As the algorithm descends the multiresolution structure, the coarse segmentation results are propagated down to the lower levels so as to reduce the inherent class-position uncertainty and to improve the segmentation accuracy. The procedure is described as follows. In the first step, a quad-tree structure of multiple resolutions is constructed. Sampling windows of different sizes are utilized to partition the underlying image into blocks at different resolution levels and texture features are extracted from each block. Based on the texture features, a hybrid genetic algorithm is employed to perform the segmentation. While the select and mutate operators of the traditional genetic algorithm are adopted in this work, the crossover operator is replaced with K-means clustering method. In the final step, the boundaries and the segmentation result of the current resolution level are propagated down to the next level to act as contextual constraints and the initial configuration of the next level, respectively. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
   Chung Cheng Inst Technol, Dept Elect Engn, Taoyuan 33509, Taiwan.
C3 University of Warwick
RP Univ Warwick, Dept Comp Sci, Coventry CV4 7AL, W Midlands, England.
EM ctli@dcs.warwic.ac.uk
RI Li, Chang-Tsun/C-1125-2018
OI Li, Chang-Tsun/0000-0003-4735-6138
CR Andrey P, 1998, IEEE T PATTERN ANAL, V20, P252, DOI 10.1109/34.667883
   [Anonymous], GENETIC LEARNING ADA
   Bhattacharya U, 1997, IMAGE VISION COMPUT, V15, P937, DOI 10.1016/S0262-8856(97)00035-8
   BOUMAN C, 1991, IEEE T PATTERN ANAL, V13, P99, DOI 10.1109/34.67641
   CHEN JL, 1995, IEEE T IMAGE PROCESS, V4, P603, DOI 10.1109/83.382495
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871
   FOGEL DB, 1994, IEEE T NEURAL NETWOR, V5, P3, DOI 10.1109/72.265956
   GREFENSTETTE JJ, 1986, IEEE T SYST MAN CYB, V16, P122, DOI 10.1109/TSMC.1986.289288
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Krishna K, 1999, IEEE T SYST MAN CY B, V29, P433, DOI 10.1109/3477.764879
   Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696
   Li CT, 2001, SIGNAL PROCESS, V81, P609, DOI 10.1016/S0165-1684(00)00235-8
   Lu CS, 1997, PATTERN RECOGN, V30, P729, DOI 10.1016/S0031-3203(96)00116-1
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   Maulik U, 2000, PATTERN RECOGN, V33, P1455, DOI 10.1016/S0031-3203(99)00137-5
   Pal SK, 1998, IEEE T SYST MAN CY B, V28, P816, DOI 10.1109/3477.735391
   PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559
   RUDOLPH G, 1994, IEEE T NEURAL NETWOR, V5, P96, DOI 10.1109/72.265964
   SUZUKI J, 1995, IEEE T SYST MAN CYB, V25, P655, DOI 10.1109/21.370197
   Tian B, 1999, IEEE T NEURAL NETWOR, V10, P138, DOI 10.1109/72.737500
   Tseng LY, 2000, PATTERN RECOGN, V33, P1251, DOI 10.1016/S0031-3203(99)00105-3
   UNSER M, 1989, IEEE T PATTERN ANAL, V11, P717, DOI 10.1109/34.192466
   Visa A, 1998, INT C PATT RECOG, P1015, DOI 10.1109/ICPR.1998.711861
   Wang JP, 1998, IEEE T PATTERN ANAL, V20, P619, DOI 10.1109/34.683775
   Wilson R, 2003, IEEE T PATTERN ANAL, V25, P42, DOI 10.1109/TPAMI.2003.1159945
   Wilson R., 1988, IMAGE SEGMENTATION U
NR 27
TC 12
Z9 15
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2003
VL 21
IS 11
BP 955
EP 966
DI 10.1016/S0262-8856(03)00120-3
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 731CP
UT WOS:000185867200002
DA 2024-07-18
ER

PT J
AU Zitová, B
   Flusser, J
AF Zitová, B
   Flusser, J
TI Image registration methods:: a survey
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE image registration; feature detection; feature matching; mapping
   function; resampling
ID RADIAL BASIS FUNCTIONS; ELASTIC REGISTRATION; CONTROL-POINTS;
   PATTERN-RECOGNITION; SIMILARITY MEASURES; MAPPING FUNCTIONS; MATCHING
   IMAGES; FAST ALGORITHM; FUNDUS IMAGES; INVARIANT
AB This paper aims to present a review of recent as well as classic image registration methods. Image registration is the process of overlaying images (two or more) of the same scene taken at different times, from different viewpoints, and/or by different sensors. The registration geometrically align two images (the reference and sensed images). The reviewed approaches are classified according to their nature (area-based and feature-based) and according to four basic steps of image registration procedure: feature detection, feature matching, mapping function design, and image transformation and resampling. Main contributions, advantages, and drawbacks of the methods are mentioned in the paper. Problematic issues of image registration and outlook for the future research are discussed too. The major goal of the paper is to provide a comprehensive reference source for the researchers involved in image registration, regardless of particular application areas. (C) 2003 Elsevier B.V. All rights reserved.
C1 Acad Sci Czech Republ, Inst Informat Theory & Automat, Dept Image Proc, CR-18208 Prague 8, Czech Republic.
C3 Czech Academy of Sciences; Institute of Information Theory & Automation
   of the Czech Academy of Sciences
EM zitova@utia.cas.cz; flusser@utia.cas.cz
RI cai, bo/G-1491-2010; Zitova, Barbara/H-1871-2014; Flusser,
   Jan/F-6209-2014
OI Zitova, Barbara/0000-0003-0110-3741; Flusser, Jan/0000-0003-3747-9214
CR ABDELSAYED S, 1995, INT GEOSCI REMOTE SE, P1029, DOI 10.1109/IGARSS.1995.521129
   Alhichri HS, 2003, PATTERN RECOGN LETT, V24, P1181, DOI 10.1016/S0167-8655(02)00300-8
   Ali WSI, 1998, IEEE T MED IMAGING, V17, P957, DOI 10.1109/42.746628
   Althof RJ, 1997, IEEE T MED IMAGING, V16, P308, DOI 10.1109/42.585765
   Andresen PR, 2001, MED IMAGE ANAL, V5, P81, DOI 10.1016/S1361-8415(00)00036-0
   [Anonymous], 2001, Medical image registration
   Anuta P. E., 1970, IEEE T GEOSCI ELECTR, V8, P353, DOI 10.1109/TGE.1970.271435
   Appledorn CR, 1996, IEEE T MED IMAGING, V15, P369, DOI 10.1109/42.500145
   ARAD N, 1994, CVGIP-GRAPH MODEL IM, V56, P161, DOI 10.1006/cgip.1994.1015
   Audette MA, 2000, MED IMAGE ANAL, V4, P201, DOI 10.1016/S1361-8415(00)00014-1
   BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3
   BANERJEE S, 1995, PATTERN RECOGN LETT, V16, P1033, DOI 10.1016/0167-8655(95)00058-O
   BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923
   BARRODALE I, 1993, PATTERN RECOGN, V26, P375, DOI 10.1016/0031-3203(93)90045-X
   Barrow H. G., 1977, P IMAGE UNDERSTANDIN, P659
   BEATSON RK, 1992, COMPUT MATH APPL, V24, P7, DOI 10.1016/0898-1221(92)90167-G
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Bentoutou Y, 2002, PATTERN RECOGN, V35, P2853, DOI 10.1016/S0031-3203(02)00016-X
   Berthilsson R, 1998, INT C PATT RECOG, P1458, DOI 10.1109/ICPR.1998.711979
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bhattacharya D, 1997, PATTERN RECOGN, V30, P1373, DOI 10.1016/S0031-3203(96)00177-X
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   Bracewell R., 1965, The Fourier Transform and Its Applications
   BRIVIO PA, 1992, INT J REMOTE SENS, V13, P1853, DOI 10.1080/01431169208904234
   BroNielsen M, 1996, LECT NOTES COMPUT SC, V1131, P267
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Cain SC, 2001, IEEE T IMAGE PROCESS, V10, P1860, DOI 10.1109/83.974571
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CASTRO ED, 1987, IEEE T PATTERN ANAL, V9, P700, DOI DOI 10.1109/TPAMI.1987.4767966
   Chang SH, 1997, PATTERN RECOGN, V30, P311, DOI 10.1016/S0031-3203(96)00076-3
   CHEN QS, 1994, IEEE T PATTERN ANAL, V16, P1156
   Cheng FH, 1996, PATTERN RECOGN LETT, V17, P1429, DOI 10.1016/S0167-8655(96)00115-8
   CHENG JK, 1984, PATTERN RECOGN, V17, P149, DOI 10.1016/0031-3203(84)90042-6
   CIDECIYAN AV, 1995, IEEE ENG MED BIOL, V14, P52, DOI 10.1109/51.340749
   Dai XL, 1997, INT GEOSCI REMOTE SE, P243, DOI 10.1109/IGARSS.1997.615851
   Dai XL, 1999, IEEE T GEOSCI REMOTE, V37, P2351, DOI 10.1109/36.789634
   DANI P, 1995, PATTERN RECOGN, V28, P431, DOI 10.1016/0031-3203(94)00106-V
   Davatzikos C, 1996, IEEE T MED IMAGING, V15, P112, DOI 10.1109/42.481446
   Davis MH, 1997, IEEE T MED IMAGING, V16, P317, DOI 10.1109/42.585766
   Ding L, 2001, IMAGE VISION COMPUT, V19, P821, DOI 10.1016/S0262-8856(00)00101-3
   DJAMDJI JP, 1993, PHOTOGRAMM ENG REM S, V59, P645
   Dodgson NA, 1997, IEEE T IMAGE PROCESS, V6, P1322, DOI 10.1109/83.623195
   Dreschler L., 1981, P INTERANTIONAL JOIN, P692
   DUCHON J, 1976, REV FR AUTOMAT INFOR, V10, P5
   Ehlers M., 1994, Proceedings of the SPIE - The International Society for Optical Engineering, V2315, P814, DOI 10.1117/12.196779
   Ehlers M., 1991, P INT GEOSCIENCE REM, P2231
   Fitzpatrick J.M., 2001, MED IMAGE REGISTRATI, P117, DOI 10.1201/9781420042474.ch6
   Fitzpatrick JM, 1998, IEEE T MED IMAGING, V17, P694, DOI 10.1109/42.736021
   Fitzpatrick JM, 2001, IEEE T MED IMAGING, V20, P917, DOI 10.1109/42.952729
   FLUSSER J, 1994, IEEE T GEOSCI REMOTE, V32, P382, DOI 10.1109/36.295052
   FLUSSER J, 1993, PATTERN RECOGN, V26, P167, DOI 10.1016/0031-3203(93)90098-H
   FLUSSER J, 1995, PATTERN RECOGN LETT, V16, P893, DOI 10.1016/0167-8655(95)00032-C
   Flusser J, 2003, IEEE T PATTERN ANAL, V25, P234, DOI 10.1109/TPAMI.2003.1177154
   Flusser J, 1998, IEEE T PATTERN ANAL, V20, P590, DOI 10.1109/34.683773
   Flusser J, 1999, INT J PATTERN RECOGN, V13, P1123, DOI 10.1142/S021800149900063X
   FLUSSER J, 1992, PATTERN RECOGN, V25, P45, DOI 10.1016/0031-3203(92)90005-4
   FOGEL DN, 1996, P 3 INT C INT GIS EN
   Fonseca LMG, 1996, PHOTOGRAMM ENG REM S, V62, P1049
   Fonseca LMG, 1997, X BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P219, DOI 10.1109/SIGRA.1997.625182
   Fornefett M, 2001, IMAGE VISION COMPUT, V19, P87, DOI 10.1016/S0262-8856(00)00057-3
   Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953
   Forstner W., 1986, P ISPRS WORKSH FAST, P281
   Freeborough PA, 1996, J COMPUT ASSIST TOMO, V20, P1012, DOI 10.1097/00004728-199611000-00030
   Ghaffary BK, 1983, P SPIE APPL DIGITAL, V432, P222
   GOSHTASBY A, 1985, IEEE T PATTERN ANAL, V7, P338, DOI 10.1109/TPAMI.1985.4767663
   GOSHTASBY A, 1986, PATTERN RECOGN, V19, P459, DOI 10.1016/0031-3203(86)90044-0
   GOSHTASBY A, 1988, IMAGE VISION COMPUT, V6, P255, DOI 10.1016/0262-8856(88)90016-9
   GOSHTASBY A, 1986, IEEE T GEOSCI REMOTE, V24, P390, DOI 10.1109/TGRS.1986.289597
   GOSHTASBY A, 1987, PATTERN RECOGN, V20, P525, DOI 10.1016/0031-3203(87)90079-3
   GOSHTASBY A, 1988, IEEE T GEOSCI REMOTE, V26, P60, DOI 10.1109/36.3000
   GOSHTASBY A, 1985, IEEE T SYST MAN CYB, V15, P631, DOI 10.1109/TSMC.1985.6313439
   GOSHTASBY A, 1985, IEEE T PATTERN ANAL, V7, P738, DOI 10.1109/TPAMI.1985.4767734
   Govindu V, 1998, INT C PATT RECOG, P37, DOI 10.1109/ICPR.1998.711074
   Govindu V, 1999, IEEE T PATTERN ANAL, V21, P1031, DOI 10.1109/34.799909
   Grace, 1990, SPLINE MODELS OBSERV
   GREENGARD L, 1987, J COMPUT PHYS, V73, P325, DOI 10.1016/0021-9991(87)90140-9
   Grevera GJ, 1998, IEEE T MED IMAGING, V17, P642, DOI 10.1109/42.730408
   GRIFFIN PM, 1989, IEEE T SYST MAN CYB, V19, P1274, DOI 10.1109/21.44047
   GRIMSON WEL, 1982, PHILOS T ROY SOC B, V298, P395, DOI 10.1098/rstb.1982.0088
   Growe S, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P228, DOI 10.1109/ICIP.1997.632067
   Guest E, 2001, IEEE T PATTERN ANAL, V23, P165, DOI 10.1109/34.908967
   GULCH E, 1991, ISPRS J PHOTOGRAMM, V46, P1, DOI 10.1016/0924-2716(91)90002-D
   HANAIZUMI H, 1993, INT GEOSCI REMOTE SE, P1348, DOI 10.1109/IGARSS.1993.322087
   Harder R., 1797, J AIRCRAFT, V9, P189, DOI [10.2514/3.44330, DOI 10.2514/3.44330, 10.2514/3.44330.]
   Hellier P., 2000, 136830 IRISA PI
   Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201
   Holden M, 2000, IEEE T MED IMAGING, V19, P94, DOI 10.1109/42.836369
   Holm M., 1991, P INT GEOSCIENCE REM, P2439
   Holmes C.J., 1998, J COMPUT ASSIST TOMO, V22, P141
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Hsieh JW, 1997, COMPUT VIS IMAGE UND, V67, P112, DOI 10.1006/cviu.1996.0517
   HSIEH JW, 1996, P INT C PATT REC ICP, P765
   HSIEH YC, 1992, IEEE T PATTERN ANAL, V14, P214, DOI 10.1109/34.121790
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   HUSEBY RB, 1999, P INT GEOSC REM SENS, P330
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jenkinson M, 2001, MED IMAGE ANAL, V5, P143, DOI 10.1016/S1361-8415(01)00036-6
   Kaneko S, 2003, PATTERN RECOGN, V36, P1165, DOI 10.1016/S0031-3203(02)00081-X
   Kaneko S, 2002, PATTERN RECOGN, V35, P2223, DOI 10.1016/S0031-3203(01)00177-7
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4
   Kumar R, 1998, INT C PATT RECOG, P1393, DOI 10.1109/ICPR.1998.711963
   KYBIC J, 1999, P SPIE MTH IM WAV AP, P571
   LAVINE D, 1983, PATTERN RECOGN, V16, P289, DOI 10.1016/0031-3203(83)90034-1
   Le Moigne J, 1998, INT GEOSCI REMOTE SE, P315, DOI 10.1109/IGARSS.1998.702890
   Lehmann TM, 1998, INT C PATT RECOG, P344, DOI 10.1109/ICPR.1998.711151
   Lehmann TM, 2001, IEEE T MED IMAGING, V20, P660, DOI 10.1109/42.932749
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   LEMOIGNE J, 1994, P SOC PHOTO-OPT INS, V2242, P432, DOI 10.1117/12.170045
   Lester H, 1999, PATTERN RECOGN, V32, P129, DOI 10.1016/S0031-3203(98)00095-8
   LESTER H, 1997, P MED IM UND AN MIUA
   LI H, 1995, IEEE T IMAGE PROCESS, V4, P320, DOI 10.1109/83.366480
   LI SZ, 1992, PATTERN RECOGN, V25, P583, DOI 10.1016/0031-3203(92)90075-T
   LI SZ, 1992, P 2 EUR C COMP VIS E, P857
   Likar B, 1999, MED PHYS, V26, P1678, DOI 10.1118/1.598660
   Likar B, 2001, IMAGE VISION COMPUT, V19, P33, DOI 10.1016/S0262-8856(00)00053-6
   Little JA, 1997, COMPUT VIS IMAGE UND, V66, P223, DOI 10.1006/cviu.1997.0608
   Liu J, 2002, IEEE T MED IMAGING, V21, P462, DOI 10.1109/TMI.2002.1009382
   Lucchese L, 2002, IEEE T PATTERN ANAL, V24, P1468, DOI 10.1109/TPAMI.2002.1046160
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Maintz J B, 1996, Med Image Anal, V1, P151, DOI 10.1016/S1361-8415(96)80010-7
   Maintz JBA, 1996, IEEE T PATTERN ANAL, V18, P353, DOI 10.1109/34.491617
   MAITRE H, 1987, PATTERN RECOGN, V20, P443, DOI 10.1016/0031-3203(87)90071-9
   Manjunath BS, 1996, PATTERN RECOGN, V29, P627, DOI 10.1016/0031-3203(95)00115-8
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Matas J, 2002, INT C PATT RECOG, P363, DOI 10.1109/ICPR.2002.1047471
   MEDIONI G, 1984, IEEE T PATTERN ANAL, V6, P675, DOI 10.1109/TPAMI.1984.4767592
   Meijering EHW, 1999, IEEE T IMAGE PROCESS, V8, P192, DOI 10.1109/83.743854
   MITRA RS, 1991, PATTERN RECOGN, V24, P747, DOI 10.1016/0031-3203(91)90043-5
   Montesinos P, 2000, IMAGE VISION COMPUT, V18, P659, DOI 10.1016/S0262-8856(99)00070-0
   Moss S, 1997, PATTERN RECOGN LETT, V18, P1283, DOI 10.1016/S0167-8655(97)00102-5
   MURTAGH F, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL II, P174, DOI 10.1109/ICPR.1992.201748
   Nelson SJ, 1997, J COMPUT ASSIST TOMO, V21, P183, DOI 10.1097/00004728-199703000-00004
   NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8
   OGAWA H, 1984, PATTERN RECOGN, V17, P569, DOI 10.1016/0031-3203(84)90055-4
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Parker J, 1983, IEEE Trans Med Imaging, V2, P31, DOI 10.1109/TMI.1983.4307610
   Parsai EI, 1997, J NUCL MED, V38, P319
   Peckar W, 1999, J MATH IMAGING VIS, V10, P143, DOI 10.1023/A:1008375006703
   PELI T, 1981, P IEEE, V69, P483, DOI 10.1109/PROC.1981.12003
   Penney GP, 1998, IEEE T MED IMAGING, V17, P586, DOI 10.1109/42.730403
   Pluim JPW, 2001, IMAGE VISION COMPUT, V19, P45, DOI 10.1016/S0262-8856(00)00054-8
   POWELL MJD, 1992, DAMTP1992NA2 U CAMBR
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   PRATT WK, 1974, IEEE T AERO ELEC SYS, VAE10, P353, DOI 10.1109/TAES.1974.307828
   PRICE KE, 1985, IEEE T PATTERN ANAL, V7, P617, DOI 10.1109/TPAMI.1985.4767709
   RANADE S, 1980, PATTERN RECOGN, V12, P269, DOI 10.1016/0031-3203(80)90067-9
   Rangarajan A., 1999, MED IMAGE ANAL, V4, P1
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   REZAIE B, 1984, IEEE T AERO ELEC SYS, V20, P716, DOI 10.1109/TAES.1984.310454
   Ritter N, 1999, IEEE T MED IMAGING, V18, P404, DOI 10.1109/42.774168
   Roche A, 1998, LECT NOTES COMPUT SC, V1496, P1115, DOI 10.1007/BFb0056301
   Roche A, 2000, INT J IMAG SYST TECH, V11, P71, DOI 10.1002/(SICI)1098-1098(2000)11:1<71::AID-IMA8>3.0.CO;2-5
   Rohr K., 1994, Journal of Mathematical Imaging and Vision, V4, P139, DOI 10.1007/BF01249893
   Rohr K, 2001, IEEE T MED IMAGING, V20, P526, DOI 10.1109/42.929618
   Rohr K, 1996, LECT NOTES COMPUT SC, V1131, P297, DOI 10.1007/BFb0046967
   ROHR K, 2001, COMPUTATIONAL IMAGIN, V21
   Rohr K., 1996, P AACHEREN WORKSHOP, P41
   ROSENFELD A, 1977, IEEE T SYST MAN CYB, V7, P104
   Roux M, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P625, DOI 10.1109/ICIP.1996.560951
   Rueckert D, 1998, LECT NOTES COMPUT SC, V1496, P1144, DOI 10.1007/BFb0056304
   SATO J, 1995, IMAGE VISION COMPUT, V13, P341, DOI 10.1016/0262-8856(95)99721-C
   Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589
   Sester M., 1998, P S OBJ REC SCEN CLA
   Sharma R.K., 1997, P SOC INFORM DISPLAY, V28, P951, DOI DOI 10.1109/TPAMI.2006.100
   Shekhar C, 1999, PATTERN RECOGN, V32, P39, DOI 10.1016/S0031-3203(98)00089-2
   Shin DS, 1997, IEEE T GEOSCI REMOTE, V35, P997, DOI 10.1109/36.602542
   Shinagawa Y, 1998, IEEE T PATTERN ANAL, V20, P994, DOI 10.1109/34.713364
   Simper A., 1996, P IEEE INT C IM PROC, V2, P597
   SKEA D, 1993, PATTERN RECOGN, V26, P269, DOI 10.1016/0031-3203(93)90035-U
   Smith S.M., SUSAN Low Level Image Processing
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   STARINK JPP, 1995, PATTERN RECOGN, V28, P231, DOI 10.1016/0031-3203(94)00087-3
   STOCKMAN G, 1982, IEEE T PATTERN ANAL, V4, P229, DOI 10.1109/TPAMI.1982.4767240
   Stone HS, 1999, IEEE T PATTERN ANAL, V21, P1074, DOI 10.1109/34.799911
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Suk T, 2000, PATTERN RECOGN, V33, P251, DOI 10.1016/S0031-3203(99)00049-7
   Suk T, 1996, PATTERN RECOGN, V29, P361, DOI 10.1016/0031-3203(94)00094-8
   TAZA A, 1989, IEEE T SYST MAN CYB, V19, P1281, DOI 10.1109/21.44049
   Thépaut O, 2000, FOREST ECOL MANAG, V128, P93, DOI 10.1016/S0378-1127(99)00276-5
   Thevenaz P, 1998, IEEE T IMAGE PROCESS, V7, P27, DOI 10.1109/83.650848
   Thévenaz P, 2000, IEEE T MED IMAGING, V19, P739, DOI 10.1109/42.875199
   Thevenaz P, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P265, DOI 10.1109/ICIP.1996.559484
   Thevenaz P, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P833, DOI 10.1109/ICIP.1998.723645
   Thevenaz P, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC228
   Thevenaz P, 1997, P SOC PHOTO-OPT INS, V3169, P236, DOI 10.1117/12.292794
   THEVENAZ P, 2003, IN PRESS HDB MED IMA
   Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4
   TON JC, 1989, IEEE T GEOSCI REMOTE, V27, P642, DOI 10.1109/TGRS.1989.35948
   TORAICHI K, 1988, PATTERN RECOGN, V21, P275, DOI 10.1016/0031-3203(88)90062-3
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   TURCAJOVA R, 1996, P SPIE MATH IM WV AP
   TUYTELAARS T, 2003, IN PRESS INT J COMPU
   VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938
   VANDERBRUG GJ, 1977, IEEE T COMPUT, V26, P384, DOI 10.1109/TC.1977.1674847
   VANWIE P, 1977, IEEE T GEOSCI REMOTE, V15, P130, DOI 10.1109/TGE.1977.6498970
   Vasileisky A., 1998, P 2 C FUSION EARTH D, P59
   Vemuri BC, 2003, MED IMAGE ANAL, V7, P1, DOI 10.1016/S1361-8415(02)00063-4
   Ventura A. D., 1990, IEEE T GEOSCI REMOTE, V28, P305
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Vujovic N, 1997, IEEE T IMAGE PROCESS, V6, P1388, DOI 10.1109/83.624955
   WANG CY, 1983, PATTERN RECOGN, V16, P167, DOI 10.1016/0031-3203(83)90020-1
   Wang WH, 1997, PATTERN RECOGN LETT, V18, P269, DOI 10.1016/S0167-8655(97)00010-X
   West J, 1997, J COMPUT ASSIST TOMO, V21, P554, DOI 10.1097/00004728-199707000-00007
   West J, 1999, IEEE T MED IMAGING, V18, P144, DOI 10.1109/42.759119
   Whichello AP, 1998, INT C PATT RECOG, P1081, DOI 10.1109/ICPR.1998.711880
   WIEMKER R, 1996, INT ARCH PHOTOGRAMME, V31, P949
   Wolberg G., 2000, SPIE C AUTOMATIC TAR, P12
   Wolberg G., 2000, P IEEE INT C IM PROC
   Wollny G, 2002, IEEE T MED IMAGING, V21, P946, DOI 10.1109/TMI.2002.803113
   WONG RY, 1978, COMPUT VISION GRAPH, V8, P16, DOI 10.1016/S0146-664X(78)80028-8
   WONG RY, 1978, IEEE T COMPUT, V27, P359, DOI 10.1109/TC.1978.1675108
   Yang ZW, 1999, IEEE T IMAGE PROCESS, V8, P934, DOI 10.1109/83.772236
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P416, DOI 10.1109/83.491316
   Zana F, 1999, IEEE T MED IMAGING, V18, P419, DOI 10.1109/42.774169
   Zheng Q, 1993, IEEE T IMAGE PROCESS, V2, P311, DOI 10.1109/83.236535
   Zheng ZQ, 1999, PATTERN RECOGN LETT, V20, P149, DOI 10.1016/S0167-8655(98)00134-2
   Zhu YM, 2002, IEEE T MED IMAGING, V21, P174, DOI 10.1109/42.993135
   Ziou Djemel., Edge Detection Techniques - An Overview
   Zitová B, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P993, DOI 10.1109/ICIP.2002.1039142
   Zitová B, 1999, PATTERN RECOGN LETT, V20, P199, DOI 10.1016/S0167-8655(98)00135-4
NR 223
TC 4480
Z9 5605
U1 22
U2 861
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2003
VL 21
IS 11
BP 977
EP 1000
DI 10.1016/S0262-8856(03)00137-9
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 731CP
UT WOS:000185867200004
DA 2024-07-18
ER

PT J
AU Albamont, J
   Goshtasby, A
AF Albamont, J
   Goshtasby, A
TI A range scanner with a virtual laser
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE range scanner; volumetric representation; energy-minimizing model;
   multiview range data integration; estimation of missing range data;
   stereo correspondence
ID STEREO; MOSAICS
AB A scanner is developed that can capture range and color data from four sides of an object and combine the data into a model of the object. The scanner has four synchronous heads that scan an object from four sides in a coordinate system that is attached to the object. Data produced by the four heads automatically come together without the need for image registration. The uniqueness of the scanner is in its use of an imaginary (virtual) laser rather than a real one for scanning. Use of a virtual laser makes it possible to scan an object with detailed color and under bright lighting. Characteristics of the scanner are investigated and example images produced by the scanner are given. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.
C3 University System of Ohio; Wright State University Dayton
RP Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.
EM ardeshir@cs.wright.edu
CR AGIN G, 1972, AIM174 STANF U
   AGIN GJ, 1976, IEEE T COMPUT, V25, P439, DOI 10.1109/TC.1976.1674626
   Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146
   FRANKE R, 1982, MATH COMPUT, V38, P181, DOI 10.2307/2007474
   GOSHTASBY A, 1995, COMPUT AIDED DESIGN, V27, P363, DOI 10.1016/0010-4485(95)96800-2
   GOSHTASBY A, 1993, INT J COMPUT VISION, V10, P233, DOI 10.1007/BF01539537
   Goshtasby AA, 1997, IEEE T MED IMAGING, V16, P664, DOI 10.1109/42.640757
   Goshtasby AA, 1998, PATTERN RECOGN, V31, P1705, DOI 10.1016/S0031-3203(98)00047-8
   HARDY RL, 1990, COMPUT MATH APPL, V19, P163, DOI 10.1016/0898-1221(90)90272-L
   ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792
   Johna S, 1999, CRIT CARE, V3, P135, DOI 10.1186/cc366
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   KASS M, INT J COMPUT VIS, P321
   MARR D, 1979, PROC R SOC SER B-BIO, V204, P301, DOI 10.1098/rspb.1979.0029
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346
   Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880
   Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346
   Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424
   SHIRAI Y, 1972, PATTERN RECOGN, V4, P343, DOI 10.1016/0031-3203(72)90034-9
   SHIRAI Y, 1971, BR COMPUT SOC    SEP, P80
   Shum HY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P953, DOI 10.1109/ICCV.1998.710831
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Trucco E., 1998, INTRO TECHNIQUES 3D
NR 24
TC 5
Z9 5
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2003
VL 21
IS 3
BP 271
EP 284
AR PII S0262-8856(02)00158-0
DI 10.1016/S0262-8856(02)00158-0
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657GN
UT WOS:000181658100004
DA 2024-07-18
ER

PT J
AU Armangué, X
   Salvi, J
AF Armangué, X
   Salvi, J
TI Overall view regarding fundamental matrix estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE epipolar geometry; fundamental matrix; performance evaluation
ID CAMERA CALIBRATION; ACCURACY EVALUATION; EPIPOLAR GEOMETRY; ROBUST
   ESTIMATOR; UNCERTAINTY; MOTION; VISION
AB Epipolar geometry is a key point in computer vision and the fundamental matrix estimation is the only way to compute it. This article is a fresh look in the subject that overview classic and latest presented methods of fundamental matrix estimation which have been classified into linear methods, iterative methods and robust methods. All of these methods have been programmed and their accuracy analyzed in synthetic and real images. A summary including experimental results and algorithmic details is given and the whole code is available in Internet. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Girona, Inst Informat & Applicat, Comp Vis & Robot Grp, E-17071 Girona, Spain.
C3 Universitat de Girona
RP Salvi, J (corresponding author), Univ Girona, Inst Informat & Applicat, Comp Vis & Robot Grp, Avda Lluis Santalo,S-N, E-17071 Girona, Spain.
RI Salvi, Joaquim/L-2648-2014
OI Salvi, Joaquim/0000-0002-9482-7126
CR Batlle J, 1998, PATTERN RECOGN, V31, P963, DOI 10.1016/S0031-3203(97)00074-5
   Bober M, 1998, COMPUT VIS IMAGE UND, V72, P39, DOI 10.1006/cviu.1997.0670
   BROOKS MJ, 2000, P 8 IEEE INT C COMP, V1, P302
   BROOKS MJ, 1996, 4 EUR C COMP VIS CAM, V2, P415
   Chojnacki W, 2000, IEEE T PATTERN ANAL, V22, P1294, DOI 10.1109/34.888714
   CHOJNACKI W, 2002, VID PROC WORKSH ECCV
   Csurka G, 1997, COMPUT VIS IMAGE UND, V68, P18, DOI 10.1006/cviu.1997.0531
   DERICHE R, 1994, LECT NOTES COMPUTER, V800, P567
   Faugeras O, 1992, EUR C COMP VIS, P321
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Faugeras O. D., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P15
   FAUGERAS OD, 1992, LECTURE NOTES COMPUT, V588, P563
   HALL EL, 1982, COMPUTER, V15, P42
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley R., 1995, DEFENCE 8 POINT ALGO, p1064 
   HARTLEY R, 1994, LECT NOTES COMPUTER, V800, P471
   Hartley R.I., 1992, Estimation of Relative Camera Positions for Uncalibrated Cameras, P579
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P133, DOI 10.1109/34.574792
   HARTLEY RI, 1992, CVPR, P761
   HARTLEY RI, 1993, 2 EUR WORKSH APPL IN, P237
   HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368
   Huber P., 1981, Robust Statistics
   Ito M., 1991, Advanced Robotics, V5, P321, DOI 10.1163/156855391X00232
   JANG JH, 1996, IEEE INT C IM PROC L, V2, P297
   LI F, 1996, 4 EUR C COMP VIS CAM, V1, P157
   LI M, 1994, EUR C COMP VIS, V800, P543
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Luong Q. T., 1994, Lecture Notes in Comput. Sci., V800, P589
   Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818
   LUONG QT, 1994, LECT NOTES COMPUTER, V800, P577
   MOHR R, 1991, PATTERN RECOGN LETT, V12, P39, DOI 10.1016/0167-8655(91)90026-I
   MOSTELLER E, 1977, DATA ANAL REGRESSION
   ROUSSEEW PJ, 1987, ROBUST REGRESSION OU
   Salvi J, 2002, PATTERN RECOGN, V35, P1617, DOI 10.1016/S0031-3203(01)00126-1
   SALVI J, 1997, THESIS U GIRONA
   STEWART CV, 1995, IEEE T PATTERN ANAL, V17, P925, DOI 10.1109/34.464558
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Torr PHS, 2002, INT J COMPUT VISION, V50, P35, DOI 10.1023/A:1020224303087
   Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901
   ZHANG Z, 1996, INT C PATT REC VIENN, V1, P407
   Zhang Z., 1993, 2146 I NAT RECH INF
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   Zhang ZY, 1996, IEEE T ROBOTIC AUTOM, V12, P103, DOI 10.1109/70.481754
NR 46
TC 144
Z9 179
U1 0
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 10
PY 2003
VL 21
IS 2
BP 205
EP 220
AR PII S0262-8856(02)00154-3
DI 10.1016/S0262-8856(02)00154-3
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 655CP
UT WOS:000181534000006
DA 2024-07-18
ER

PT J
AU Marchant, JA
   Onyango, CM
AF Marchant, JA
   Onyango, CM
TI Model-based control of image acquisition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CCD; acquisition; control; camera; exposure; contrast; model
ID SYSTEM; SCENES
AB We propose two methods for controlling the acquisition of images using a camera/digitiser combination which seek to make good use of the dynamic range of the digitiser. The system controls are the black and white reference levels of the digitiser, and the exposure time of the CCD sensor. We use the grey level histogram to characterise the level of control.
   Both methods use models of the camera/digitiser and of the grey level distribution in the scene. These allow control values that will achieve a given result to be predicted from the current grab and used on the next one. Thus the methods use feed forward control, taking advantage of the models to achieve a fast response. The first method, pragmatic, attempts to adjust the controls to achieve target values of histogram position and scale. The second method, information theoretic seeks to maximise the information content of the histogram as measured by the entropy. An advantage of the information theoretic method is that it produces a single measure of performance. This we use in a strategy for including the exposure variable in the control system. Having a single measure avoids the difficult problem of choosing rather arbitrary weighting factors for the position and scale errors in the pragmatic method.
   We test both methods using stored images and simulating various grab conditions. Both methods perform well, resulting in effective control values from simulated grabs containing significant saturation. We test the second method on line using real grabs and show fast and accurate recovery from disturbances of illumination and scene content. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Silsoe Res Inst, Image Anal & Control Grp, Silsoe MK45 4HS, Beds, England.
RP Marchant, JA (corresponding author), Silsoe Res Inst, Image Anal & Control Grp, Wrest Pk, Silsoe MK45 4HS, Beds, England.
CR Beynon J.D. E., 1980, CHARGE COUPLED DEVIC
   CHO MH, 1999, P IS T SPIE C SENS C
   HAMMING RW, 1986, CODING INFORMATION T
   HARUKI T, 1992, IEEE T CONSUM ELECTR, V38, P624, DOI 10.1109/30.156746
   IMAIDE T, 1992, IEEE T CONSUM ELECTR, V38, P601, DOI 10.1109/30.156743
   KARUSLSKI KA, 1997, Patent No. 5610654
   KONDO T, 1978, Patent No. 4117500
   Kuno T, 1998, IEEE T CONSUM ELECTR, V44, P192, DOI 10.1109/30.663747
   Marchant JA, 2000, J OPT SOC AM A, V17, P1952, DOI 10.1364/JOSAA.17.001952
   Marchant JA, 2002, IMAGE VISION COMPUT, V20, P449, DOI 10.1016/S0262-8856(01)00088-9
   *MATR IM, 2000, APPL NOT OPT VID DIG
   Murino V, 1996, IEEE T IND ELECTRON, V43, P588, DOI 10.1109/41.538617
   *OMN, 2000, PROD SPEC OV7920 SIN
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
NR 14
TC 5
Z9 5
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 10
PY 2003
VL 21
IS 2
BP 161
EP 170
AR PII S0262-8856(02)00151-8
DI 10.1016/S0262-8856(02)00151-8
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 655CP
UT WOS:000181534000003
DA 2024-07-18
ER

PT J
AU Jin, XQ
   Zhang, DW
   Wu, QE
   Xiao, X
   Zhao, PS
   Zheng, ZL
AF Jin, Xiaoqiang
   Zhang, Dawei
   Wu, Qiner
   Xiao, Xin
   Zhao, Pengsen
   Zheng, Zhonglong
TI Improved SiamCAR with ranking-based pruning and optimization for
   efficient UAV tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Siamese network; Model pruning; Ranking loss; Attention mechanism
ID PLUS PLUS
AB UAV tracking is a burgeoning task with vast application prospects in various fields such as agriculture, navigation, and public safety. However, the computational constraints and limited processing speed of drones hinder the deployment of Siamese tracking algorithms. In order to better apply tracking algorithms to drone devices, this paper proposes a novel Ranking-Based SiamCAR (RB-SiamCAR) tracker. The RB-SiamCAR tracker achieves model compression by utilizing a ranking-based filter pruning method, which sorts the filters in the backbone network based on their importance and prunes the filters with low ranks for efficient feature extraction. Additionally, considering existing Siamese trackers overlook the correlation between positive and negative samples and the coherence between classification and localization, we introduce two ranking-based losses. The classification ranking loss ensures that the ranking of positive samples is higher than that of hard negative samples, allowing the tracker to successfully select foreground samples without being fooled by distractors. The IoUguided ranking loss aims to align the classification with the intersection over union (IoU) of the corresponding localizations of positive samples, enabling well-localized predictions to be represented by high classification confidence. To further enhance the tracking performance, we employ an effective channel attention module (ECA) that allows the network to automatically learn and focus on the most important channels for capturing more discriminative features. Experimental evaluations on UAV tracking benchmarks demonstrate that the proposed RB-SiamCAR outperforms existing state-of-the-art trackers. It is noteworthy that our RB-SiamCAR achieves an impressive tracking speed of nearly 100 fps. The experimental results validate its effectiveness and efficiency in UAV tracking applications.
C1 [Jin, Xiaoqiang; Zhang, Dawei; Wu, Qiner; Zhao, Pengsen; Zheng, Zhonglong] Zhejiang Normal Univ, Sch Comp Sci & Technol, Jinhua 321004, Peoples R China.
   [Zhang, Dawei; Xiao, Xin; Zheng, Zhonglong] Key Lab Intelligent Educ Technol & Applicat Zhejia, Jinhua 321004, Peoples R China.
C3 Zhejiang Normal University
RP Zhang, DW (corresponding author), Zhejiang Normal Univ, Sch Comp Sci & Technol, Jinhua 321004, Peoples R China.
EM davidzhang@zjnu.edu.cn
RI Zhang, Dawei/AHB-0326-2022
OI Zhang, Dawei/0000-0002-7593-1593
FU Zhejiang Provincial Natural Science Foundation of China [LQ23F020010,
   LZ22F020010]; Natural Science Foundation of China [62272419]
FX This research was supported in part by Zhejiang Provincial Natural
   Science Foundation of China under Grant No. LQ23F020010 and No.
   LZ22F020010, and in part by the Natural Science Foundation of China
   under Grant No. 62272419.
CR Aghasi A, 2017, ADV NEUR IN, V30
   Aghasi Alireza., 2017, NIPS
   Bingyan Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P429, DOI 10.1007/978-3-030-58542-6_26
   Cao ZA, 2021, IEEE INT C INT ROBOT, P3086, DOI 10.1109/IROS51168.2021.9636309
   Cao ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15437, DOI 10.1109/ICCV48922.2021.01517
   Chen ZD, 2023, IEEE T PATTERN ANAL, V45, P5158, DOI 10.1109/TPAMI.2022.3195759
   Cui Y, 2022, PROC ASIAN C COMPUT, P944
   Cui YM, 2022, Arxiv, DOI arXiv:2207.05252
   Fu CH, 2021, IEEE INT CONF ROBOT, P510, DOI 10.1109/ICRA48506.2021.9560756
   Gao S., 2021, Computer Vision and Pattern Recognition
   Guo DY, 2021, PROC CVPR IEEE, P9538, DOI 10.1109/CVPR46437.2021.00942
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Huang LH, 2020, AAAI CONF ARTIF INTE, V34, P11037
   Huang Zehao, 2018, EUR C COMP VIS ECCV, V2
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Lin SH, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2425
   Lin SH, 2019, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR.2019.00290
   Liu HaiJing Liu HaiJing, 2018, The Proceedings of the Fifteenth Congress of China Sheep Industry Development Sponsored by the China Animal Husbandry Association in 2018, Henan, China, 10-11 October, 2018, P13
   Liu N, 2020, AAAI CONF ARTIF INTE, V34, P4876
   Liu Z., 2018, NIPS
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Qin ZW, 2018, Arxiv, DOI [arXiv:1811.02639, DOI arXiv:1811.02639.null]
   Tang F, 2022, PROC CVPR IEEE, P8731, DOI 10.1109/CVPR52688.2022.00854
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang Q, 2019, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2019.00142
   Xing DT, 2022, IEEE WINT CONF APPL, P1898, DOI 10.1109/WACV51458.2022.00196
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang SD, 2022, VISUAL COMPUT, V38, P2107, DOI 10.1007/s00371-021-02271-7
   Yiming Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11920, DOI 10.1109/CVPR42600.2020.01194
   Yunhua Zhang, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P355, DOI 10.1007/978-3-030-01240-3_22
   Zhang CX, 2017, KNOWL-BASED SYST, V125, P13, DOI 10.1016/j.knosys.2017.03.031
   Zhang DW, 2021, NEUROCOMPUTING, V436, P260, DOI 10.1016/j.neucom.2020.11.046
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhou JH, 2020, AAAI CONF ARTIF INTE, V34, P13017
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 44
TC 2
Z9 2
U1 12
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104886
DI 10.1016/j.imavis.2023.104886
EA DEC 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FZ7J2
UT WOS:001149738900001
DA 2024-07-18
ER

PT J
AU Li, ZX
   Su, Q
   Chen, TY
AF Li, Zhixin
   Su, Qiang
   Chen, Tianyu
TI External knowledge-assisted Transformer for image captioning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image captioning; Knowledge reasoning; Object relation; Visual
   Transformer
AB Internal relationship exploring based on the descriptive region features of image objects and grid features have contributed significantly to the development of image captioning, especially when combined with Transformer architecture. However, when conducting self-attention calculation, most of these methods only consider the relationship intra-objects and ignore the connection between entities and background. Besides, the way of exploring the relation information inside the image can also be extended. In this paper, we introduce a novel Mixed Knowledge Relation Transformer (MKRT) to explore the relationship between objects from both internal attribute relationship and external the object-verb-subject relationship. Furthermore we embed the important image background information into the relation module. In MKRT, the semantic relation obtained from the external knowledge is incorporated into the relation modeling in the novel Mixed Knowledge Relation Attention (MKRA). To validate the effectiveness of our model, we conduct extensive experiments on the most popular MSCOCO dataset, and achieve 134.5 CIDEr score on the offline test split and 133.5 CIDEr (c40) score on the official online testing server.
C1 [Li, Zhixin; Su, Qiang; Chen, Tianyu] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Guangxi Normal University
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM lizx@gxnu.edu.cn; suq@stu.gxnu.edu.cn; tychen@stu.gxnu.edu.cn
FU National Natural Science Foundation of China [62276073, 61966004];
   Guangxi Natural Science Foundation [2019GXNSFDA245018]; Guangxi " Bagui
   Scholar " Teams for Innovation and Research Project
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 62276073, 61966004) , the Guangxi Natural Science Foundation
   (No. 2019GXNSFDA245018) , the Guangxi " Bagui Scholar " Teams for
   Innovation and Research Project, and the Guangxi Collabo- rative
   Innovation Center of Multi -source Information Integration and
   Intelligent Processing.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Chen TY, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104340
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Herdade S, 2020, Arxiv, DOI arXiv:1906.05963
   Huang FC, 2020, MACH LEARN, V109, P2313, DOI 10.1007/s10994-020-05919-y
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Ji JY, 2021, AAAI CONF ARTIF INTE, V35, P1655
   Jiang CH, 2018, Arxiv, DOI arXiv:1810.12681
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Liu JH, 2020, AAAI CONF ARTIF INTE, V34, P11588
   Luo YP, 2021, Arxiv, DOI arXiv:2101.06462
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Speer R, 2017, AAAI CONF ARTIF INTE, P4444
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176
   Wang WX, 2019, AAAI CONF ARTIF INTE, P8957
   Wei HY, 2020, COMPUT VIS IMAGE UND, V201, DOI 10.1016/j.cviu.2020.103068
   Wei JH, 2023, APPL INTELL, V53, P2706, DOI 10.1007/s10489-022-03624-y
   Xian TT, 2022, IEEE T CIRC SYST VID, V32, P5762, DOI 10.1109/TCSVT.2022.3155795
   Xian TT, 2022, NEURAL NETWORKS, V148, P129, DOI 10.1016/j.neunet.2022.01.011
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2019, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2019.00271
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zhou YAN, 2020, PROC CVPR IEEE, P4776, DOI 10.1109/CVPR42600.2020.00483
NR 34
TC 3
Z9 3
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104864
DI 10.1016/j.imavis.2023.104864
EA NOV 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Z7FJ1
UT WOS:001113691100001
DA 2024-07-18
ER

PT J
AU Tang, CR
   Xue, DY
   Chen, DY
AF Tang, Chunren
   Xue, Dingyu
   Chen, Dongyue
TI Fuzzy set-based Bernoulli Random Noise Weighted Loss for unsupervised
   person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fully unsupervised learning; Person re-identification; Fuzzy set;
   Feature learning
AB Clustering-based methods have achieved impressive performance on unsupervised person ReID task. However, most of these models suffer from noisy labels. In this paper, we propose a novel method to evaluate and suppress noisy labels. Since the feature network is barely trained and the clustering results are unreliable consequently, noisy samples can be hardly screened out with a hard threshold in the early stage of training. To address this issue, we construct a Noisy Label Fuzzy Set (NLFS) whose membership function can be used to evaluate the noise level of each sample. Furthermore, we propose a new loss function, referred to as Bernoulli Random Noise Weighted Loss (BRNWL), with which some samples with higher noise membership will be recognized as noisy samples in higher probability and assigned with corresponding weights to limit their contributions to the training. Through above improvements, randomness is introduced into the alternating update between the feature network and the clustering results, which can effectively prevent the model from trapping into local minima or vicious circles. Extensive experiments demonstrate that our method achieves state-of-the-art performance on popular ReID datasets.
C1 [Tang, Chunren; Xue, Dingyu; Chen, Dongyue] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
   [Chen, Dongyue] Northeastern Univ, Foshan Grad Sch Innovat, Foshan 528311, Guangdong, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Chen, DY (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Liaoning, Peoples R China.
EM 1910316@stu.neu.edu.cn
FU Fundamental Research Funds for the Central Universities [N2104027];
   Innovation Fund of Chinese Universities Industry University Research
   [2020HYA06003]; Guangdong Basic and Applied Basic Research Foundation
   [2021B1515120064]
FX This work was supported in part by The Fundamental Research Funds for
   the Central Universities (N2104027), Innovation Fund of Chinese
   Universities Industry University Research (2020HYA06003), Guangdong
   Basic and Applied Basic Research Foundation (2021B1515120064).
CR Backlund H., 2011, DATA MINING TNM033, V033, P11
   Behera NKS, 2021, PATTERN RECOGN LETT, V151, P163, DOI 10.1016/j.patrec.2021.08.007
   Chen H., 2022, IEEE Transactions on Pattern Analysis and Machine Intelligence
   Chen H, 2021, IEEE WINT CONF APPL, P1, DOI 10.1109/WACV48630.2021.00005
   Chen H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14940, DOI 10.1109/ICCV48922.2021.01469
   Chen H, 2021, PROC CVPR IEEE, P2004, DOI 10.1109/CVPR46437.2021.00204
   Chen T, 2020, PR MACH LEARN RES, V119
   Dai Z., 2022, P ASIAN C COMPUTER V, P1142
   Ding G., 2019, BMVC, V2, P8
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Goldberger J., 2016, INT C LEARN REPR
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P643, DOI 10.1007/978-3-030-58598-3_38
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2018, ADV NEUR IN, V31
   Huang Yangru, 2020, AAAI
   Jianing Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P483, DOI 10.1007/978-3-030-58586-0_29
   Kaiwei Zeng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13654, DOI 10.1109/CVPR42600.2020.01367
   Li H, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107614
   Li JN, 2022, IEEE T PATTERN ANAL, V44, P622, DOI 10.1109/TPAMI.2019.2929036
   Li Q, 2022, PATTERN RECOGN, V125, DOI 10.1016/j.patcog.2022.108521
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Patrini G, 2017, PROC CVPR IEEE, P2233, DOI 10.1109/CVPR.2017.240
   Reed H., 2014, arXiv
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sukhbaatar S, 2015, Arxiv, DOI [arXiv:1406.2080, 10.48550/arXiv.1406.2080]
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tanaka D, 2018, PROC CVPR IEEE, P5552, DOI 10.1109/CVPR.2018.00582
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang ML, 2021, AAAI CONF ARTIF INTE, V35, P2764
   Wang YS, 2019, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2019.00041
   Wei Hongxin, 2020, P IEEE C COMP VIS PA
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xuan SY, 2021, PROC CVPR IEEE, P11921, DOI 10.1109/CVPR46437.2021.01175
   Yin J., 2022, Pattern Recogn.: J. Pattern Recogn. Soc., P126
   Zhang ZL, 2018, ADV NEUR IN, V31
   Zheng KC, 2021, AAAI CONF ARTIF INTE, V35, P3538
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P72, DOI 10.1007/978-3-030-58621-8_5
NR 44
TC 1
Z9 1
U1 3
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104783
DI 10.1016/j.imavis.2023.104783
EA AUG 2023
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA R5SI1
UT WOS:001064945300001
DA 2024-07-18
ER

PT J
AU Wang, HF
   Li, HL
   Liu, WQ
   Gu, XF
AF Wang, Huafeng
   Li, Hanlin
   Liu, Wanquan
   Gu, Xianfeng
TI Temporal information oriented motion accumulation and selection network
   for RGB-based action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Motion accumulation; Selective network; Motion
ID REPRESENTATION
AB Numerous studies have highlighted the crucial role of motion information in accurate action recognition in videos. However, current methods heavily rely on temporal differences of features extracted by convolutional neural networks (CNNs) to represent motion, which may have two potential limitations: (1) incomplete representation of the moving target contour due to the difference operation, and (2) equal treatment of all extracted motion features, regardless of their relevance to the classification task, which may negatively impact performance. To address these limitations, we propose a novel approach called the Motion Accumulation and Selection Network (MAS-Net). Although our new approach also considers spatial attributes, it draws inspiration from the cumulative and selective nature of human visual attention, with a primary focus on capturing the temporal attributes of actions for recognition. Further, an motion selection module is exploited to prioritize relevant temporal features while filtering out irrelevant ones. Currently, there is a growing demand for action recognition with strong temporal information, as opposed to conventional scene-related datasets such as UCF-101 and HMDB-51. Therefore, we evaluated MAS-Net on benchmark video datasets that primarily emphasize temporal information, including Something-Something V1 & V2, Diving48, and Kinetics-400. Our experimental results demonstrate that MAS-Net achieves state-of-the-art performance on Something-Something V1 & V2 and Diving48 datasets. Furthermore, when compared to other 2D CNN-based models, MAS-Net exhibits competitive results on the Kinetics-400 dataset while maintaining computational efficiency. These findings highlight the effectiveness and efficiency of MAS-Net for temporal modeling in video analysis tasks.
C1 [Wang, Huafeng] North China Univ Technol, Sch Informat Technol, Beijing, Peoples R China.
   [Wang, Huafeng] Beihang Univ, Sch Software, Beijing, Peoples R China.
   [Li, Hanlin; Liu, Wanquan] Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou, Peoples R China.
   [Gu, Xianfeng] SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 North China University of Technology; Beihang University; Sun Yat Sen
   University; State University of New York (SUNY) System; State University
   of New York (SUNY) Stony Brook
RP Wang, HF (corresponding author), North China Univ Technol, Sch Informat Technol, Beijing, Peoples R China.; Wang, HF (corresponding author), Beihang Univ, Sch Software, Beijing, Peoples R China.; Liu, WQ (corresponding author), Sun Yat Sen Univ, Sch Intelligent Syst Engn, Guangzhou, Peoples R China.
EM wanghuafengbuaa@gmail.com; lihlin37@mail2.sysu.edu.cn;
   liuwq63@mail.sysu.edu.cn; gu@cs.stonybrook.edu
RI Li, Hanlin/GRS-2800-2022
OI Li, Hanlin/0000-0002-4079-3821
FU Beijing Municipal Education Commission Scientific Research Program
   [KM202110009001]; 2020 Hebei Provincial Science and Technology Plan
   Project [203777116D]
FX The authors would like to thank Mr. Tao Xia for his helpful discussions
   on experimental design and Mr. Ao Chen for his work on data preparation.
   This work was supported in part by the Beijing Municipal Education
   Commission Scientific Research Program under Grant KM202110009001 and
   the 2020 Hebei Provincial Science and Technology Plan Project under
   Grant 203777116D.
CR Abdari A, 2022, Arxiv, DOI arXiv:2209.14757
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Arunnehru J, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11152363
   Asghari-Esfeden S, 2020, IEEE WINT CONF APPL, P546, DOI 10.1109/WACV45572.2020.9093500
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Byvshev P, 2022, COMPUT VIS IMAGE UND, V220, DOI 10.1016/j.cviu.2022.103437
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen CF, 2021, PROC CVPR IEEE, P6161, DOI 10.1109/CVPR46437.2021.00610
   Choutas V, 2018, PROC CVPR IEEE, P7024, DOI 10.1109/CVPR.2018.00734
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Escorcia V, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P508, DOI 10.1109/ICCVW.2013.72
   Eyiokur FI, 2023, IMAGE VISION COMPUT, V130, DOI 10.1016/j.imavis.2022.104610
   Fan HQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6804, DOI 10.1109/ICCV48922.2021.00675
   Fan Q., 2019, Neural Information Processing Systems, V32, P2261
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He DL, 2019, AAAI CONF ARTIF INTE, P8401
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hou JY, 2018, IEEE T MULTIMEDIA, V20, P1537, DOI 10.1109/TMM.2017.2771462
   Hu H, 2019, IEEE I CONF COMP VIS, P3463, DOI 10.1109/ICCV.2019.00356
   Pham HH, 2018, COMPUT VIS IMAGE UND, V170, P51, DOI 10.1016/j.cviu.2018.03.003
   Ji XP, 2021, KNOWL-BASED SYST, V227, DOI 10.1016/j.knosys.2021.107040
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Junwu Weng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P363, DOI 10.1007/978-3-030-58571-6_22
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kim M., 2021, Adv. Neural Inf. Process. Syst, V34, P8046
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kwon H., 2020, P EUROPEAN C COMPUTE, P1933
   Lee MG, 2018, LECT NOTES COMPUT SC, V11214, P392, DOI 10.1007/978-3-030-01249-6_24
   Lee SH, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042278
   Li K., 2021, P INT C LEARNING REP
   Li M, 2017, PATTERN RECOGN LETT, V87, P195, DOI 10.1016/j.patrec.2016.07.021
   Li SJ, 2021, IEEE ROBOT AUTOM LET, V6, P1028, DOI 10.1109/LRA.2021.3056361
   Li XH, 2020, PROC CVPR IEEE, P1089, DOI 10.1109/CVPR42600.2020.00117
   Li Y, 2020, PROC CVPR IEEE, P906, DOI 10.1109/CVPR42600.2020.00099
   Li YW, 2018, LECT NOTES COMPUT SC, V11210, P520, DOI 10.1007/978-3-030-01231-1_32
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu Z, 2022, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR52688.2022.00320
   Liu ZY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13688, DOI 10.1109/ICCV48922.2021.01345
   Liu ZY, 2020, AAAI CONF ARTIF INTE, V34, P11669
   Luo CX, 2019, IEEE I CONF COMP VIS, P5511, DOI 10.1109/ICCV.2019.00561
   Ma AJ, 2013, IEEE T CIRC SYST VID, V23, P1447, DOI 10.1109/TCSVT.2013.2248494
   Miech A, 2019, IEEE I CONF COMP VIS, P2630, DOI 10.1109/ICCV.2019.00272
   Neimark D, 2021, IEEE INT CONF COMP V, P3156, DOI [arXiv:2102.00719, 10.1109/ICCVW54120.2021.00355]
   Ng JYH, 2018, IEEE WINT CONF APPL, P1577, DOI 10.1109/WACV.2018.00176
   Niu L, 2022, COMPUT VIS IMAGE UND, V215, DOI 10.1016/j.cviu.2021.103337
   Park E, 2016, IEEE WINT CONF APPL
   Patrick M, 2021, P INT C NEUR INF PRO, P12493
   Pham HH, 2022, Arxiv, DOI [arXiv:2208.03775, DOI 10.48550/ARXIV.2208.03775]
   Planamente M, 2022, IEEE WINT CONF APPL, P163, DOI 10.1109/WACV51458.2022.00024
   Plizzari C, 2022, PROC CVPR IEEE, P19903, DOI 10.1109/CVPR52688.2022.01931
   Plizzari C, 2021, COMPUT VIS IMAGE UND, V208, DOI 10.1016/j.cviu.2021.103219
   Purushwalkam S., 2016, arXiv
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Quan YH, 2019, COMPUT VIS IMAGE UND, V187, DOI 10.1016/j.cviu.2019.102794
   Ramanathan M, 2019, INT J BIOMETRICS, V11, P113, DOI 10.1504/IJBM.2019.099014
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sevilla-Lara Laura, 2019, Pattern Recognition. 40th German Conference, GCPR 2018. Proceedings: Lecture Notes in Computer Science (LNCS 11269), P281, DOI 10.1007/978-3-030-12939-2_20
   Shao H, 2020, AAAI CONF ARTIF INTE, V34, P11966
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Sudhakaran S, 2020, PROC CVPR IEEE, P1099, DOI 10.1109/CVPR42600.2020.00118
   Sun C, 2022, IEEE T MULTIMEDIA, V24, P274, DOI 10.1109/TMM.2021.3050067
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Tan H., 2021, arXiv
   Tong Z., 2022, NIPS, V15, P10078
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2020, PROC CVPR IEEE, P349, DOI 10.1109/CVPR42600.2020.00043
   Wang LM, 2021, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR46437.2021.00193
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang RQ, 2019, MULTIMED TOOLS APPL, V78, P9933, DOI 10.1007/s11042-018-6509-0
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang YZ, 2021, COMPUT VIS IMAGE UND, V213, DOI 10.1016/j.cviu.2021.103304
   Wang ZW, 2021, PROC CVPR IEEE, P13209, DOI 10.1109/CVPR46437.2021.01301
   Wei DF, 2022, COMPUT VIS IMAGE UND, V222, DOI 10.1016/j.cviu.2022.103484
   Wu WH, 2021, AAAI CONF ARTIF INTE, V35, P2943
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yan S, 2022, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR52688.2022.00333
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Zhang C, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P500, DOI 10.1145/3343031.3350876
   Zhang CH, 2021, PROC CVPR IEEE, P4484, DOI 10.1109/CVPR46437.2021.00446
   Zhang CY, 2022, IEEE T CYBERNETICS, V52, P398, DOI 10.1109/TCYB.2020.2973300
   Zhang HG, 2023, IET COMPUT VIS, V17, P222, DOI 10.1049/cvi2.12154
   Zhao Y, 2018, PROC CVPR IEEE, P6566, DOI 10.1109/CVPR.2018.00687
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou JX, 2022, COMPUT VIS IMAGE UND, V222, DOI 10.1016/j.cviu.2022.103491
   Zhu YS, 2023, IEEE T IMAGE PROCESS, V32, P496, DOI 10.1109/TIP.2022.3230249
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 101
TC 0
Z9 0
U1 8
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104785
DI 10.1016/j.imavis.2023.104785
EA AUG 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P8NB1
UT WOS:001053171600001
DA 2024-07-18
ER

PT J
AU Deng, Y
   Li, BX
   Yang, YH
   Zhao, X
AF Deng, Yong
   Li, Baoxing
   Yang, Yehui
   Zhao, Xu
TI Temporally consistent reconstruction of 3D clothed human surface with
   warp field
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Warp field; Normal maps; Implicit function; Temporally consistent
   information
AB Implicit functions are widely used in 3D human surface reconstruction due to their advantage to represent details. However, human reconstruction based on implicit functions struggles to maintain the integrity (unbroken body structure) and accuracy (no non-human parts) of human models. To address these issues, we propose a method, called TCR, for temporally consistent reconstruction of 3D clothed human surface with warp field. The fact that the general shape of a person does not change largely over time inspires us to exploit the temporally consistent shape information from previous frames to refine the human model of current frame. Therefore, we construct a canonical space and then store the shape information by updating the canonical model. To align the observed space with the canonical space, a warp field is firstly estimated for the forward and inverse warping of the human model. A probabilistic fusion strategy is then used to update the canonical model. In addition, the reconstructed result is further refined through the orthogonality constraints between the surface and its normal, which fully exploits the detailed information of estimated normal maps. Experiments on the Adobe and MonoPerfCap datasets show that TCR achieves the state-of-the-art performance. Furthermore, TCR is more robust and can maintain the integrity and accuracy of the reconstructed human body even with extreme poses and partial occlusions.
C1 [Deng, Yong; Li, Baoxing; Yang, Yehui; Zhao, Xu] Dept Automat, 800 Dongchuan Rd, Shanghai 201100, Peoples R China.
RP Zhao, X (corresponding author), Dept Automat, 800 Dongchuan Rd, Shanghai 201100, Peoples R China.
EM zhaoxu@sjtu.edu.cn
OI Deng, Yong/0009-0001-2148-3940
CR Alldieck T, 2019, IEEE I CONF COMP VIS, P2293, DOI 10.1109/ICCV.2019.00238
   Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Chen L, 2021, VIS INFORM, V5, P11, DOI 10.1016/j.visinf.2021.10.003
   Cheng ZQ, 2018, COMPUT GRAPH-UK, V71, P88, DOI 10.1016/j.cag.2017.11.008
   Choi H, 2021, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR46437.2021.00200
   Guan SY, 2021, PROC CVPR IEEE, P10467, DOI 10.1109/CVPR46437.2021.01033
   Gyeongsik Moon, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P752, DOI 10.1007/978-3-030-58571-6_44
   He T, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11026, DOI 10.1109/ICCV48922.2021.01086
   Huang Z, 2020, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR42600.2020.00316
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kim H, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3550454.3555511
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Li TY, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130813
   Liang JB, 2019, IEEE I CONF COMP VIS, P4351, DOI 10.1109/ICCV.2019.00445
   Loper M, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818013
   Newcombe RA, 2015, PROC CVPR IEEE, P343, DOI 10.1109/CVPR.2015.7298631
   Omran M, 2018, INT CONF 3D VISION, P484, DOI 10.1109/3DV.2018.00062
   Osman Ahmed A. A., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P598, DOI 10.1007/978-3-030-58539-6_36
   Pavlakos G, 2019, IEEE I CONF COMP VIS, P803, DOI 10.1109/ICCV.2019.00089
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Pavlakos G, 2018, PROC CVPR IEEE, P459, DOI 10.1109/CVPR.2018.00055
   Peng SD, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14294, DOI 10.1109/ICCV48922.2021.01405
   Pons-Moll G, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766993
   Robertini N, 2016, INT CONF 3D VISION, P166, DOI 10.1109/3DV.2016.25
   Romero J, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3130800.3130883
   Saito S, 2020, PROC CVPR IEEE, P81, DOI 10.1109/CVPR42600.2020.00016
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wan ZN, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13013, DOI 10.1109/ICCV48922.2021.01279
   Wu CL, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508418
   Xiu Yuliang, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P512, DOI 10.1109/CVPR52729.2023.00057
   Xiu YL, 2022, PROC CVPR IEEE, P13286, DOI 10.1109/CVPR52688.2022.01294
   Xu HY, 2020, PROC CVPR IEEE, P6183, DOI 10.1109/CVPR42600.2020.00622
   Xu WP, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3181973
   Yu T, 2021, PROC CVPR IEEE, P5742, DOI 10.1109/CVPR46437.2021.00569
   Zhang HW, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11426, DOI 10.1109/ICCV48922.2021.01125
   Zheng ZR, 2022, IEEE T PATTERN ANAL, V44, P3170, DOI 10.1109/TPAMI.2021.3050505
   Zheng ZR, 2019, IEEE I CONF COMP VIS, P7738, DOI 10.1109/ICCV.2019.00783
   Zhu H, 2019, PROC CVPR IEEE, P4486, DOI 10.1109/CVPR.2019.00462
   Zhuo Su, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P246, DOI 10.1007/978-3-030-58548-8_15
NR 42
TC 0
Z9 0
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104782
DI 10.1016/j.imavis.2023.104782
EA AUG 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P7PX8
UT WOS:001052567900001
DA 2024-07-18
ER

PT J
AU Tang, Y
   Chen, Y
   Xie, LB
AF Tang, Yuan
   Chen, Ying
   Xie, Linbo
TI Self-knowledge distillation based on knowledge transfer from soft to
   hard examples
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Model compression; Self-knowledge distillation; Hard examples; Class
   probability consistency; Memory bank
AB To fully exploit knowledge from self-knowledge distillation network in which a student model is progressively trained to distill its own knowledge without a pre-trained teacher model, a self-knowledge distillation method based on knowledge transfer from soft to hard examples is proposed. A knowledge transfer module is designed to exploit the dark knowledge of hard examples, which can force the class probability consistency between hard and soft examples. It reduces the confidence of wrong prediction by transferring the class information from soft probability distributions of auxiliary self-teacher network to classifier network (self-student network). Further-more, a dynamic memory bank for softened probability distribution is introduced, whose updating strategy is also presented. Experiments show the method improves the accuracy by 0.64% on classification datasets in aver-age and by 3.87% on fine-grained visual recognition tasks in average, which makes its performance superior to the state-of-the-arts.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Tang, Yuan; Chen, Ying] Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Peoples R China.
   [Xie, Linbo] Jiangnan Univ, Minist Educ, Engn Res Ctr Internet Things Technol Applicat, Wuxi 214122, Peoples R China.
C3 Jiangnan University; Jiangnan University
RP Chen, Y (corresponding author), Jiangnan Univ, Minist Educ, Key Lab Adv Proc Control Light Ind, Wuxi 214122, Peoples R China.
EM 6211905005@stu.jiangnan.edu.cn; chenying@jiangnan.edu.cn;
   xie_linbo@jiangnan.edu.cn
RI yuan, tang/KDO-4134-2024
FU National Natural Science Founda- tion of China [62173160]
FX This work was supported by the National Natural Science Founda- tion of
   China (Grant No. 62173160) .
CR Amik FR, 2022, Arxiv, DOI arXiv:2201.11319
   BenBaruch E., 2022, arXiv, DOI DOI 10.48550/ARXIV.2201.06945
   Chen D., 2022, P IEEE CVF C COMP VI, P11933
   Chen DF, 2021, AAAI CONF ARTIF INTE, V35, P7028
   Chen DF, 2020, AAAI CONF ARTIF INTE, V34, P3430
   Chung I, 2020, PR MACH LEARN RES, V119
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heo B, 2019, IEEE I CONF COMP VIS, P1921, DOI 10.1109/ICCV.2019.00201
   Hinton G., 2014, Distilling the knowledge in a neural network
   Hou YN, 2019, IEEE I CONF COMP VIS, P1013, DOI 10.1109/ICCV.2019.00110
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang T, 2022, Arxiv, DOI arXiv:2205.10536
   Ji M, 2021, PROC CVPR IEEE, P10659, DOI 10.1109/CVPR46437.2021.01052
   Khosla P., 2020, ADV NEURAL INF PROCE, V33, P18661
   Kim H., 2022, ARXIV
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lan X., 2018, Advances in Neural Information Processing Systems
   Lee H., INT C MACH LEARN PML, P5714
   Li S., 2022, IEEE Transactions on Neural Networks and Learning Systems, P1
   Liang JJ, 2022, LECT NOTES COMPUT SC, V13671, P104, DOI 10.1007/978-3-031-20083-0_7
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Miller R., 2019, ADV NEURAL INF PROCE, V32
   Mirzadeh SI, 2020, AAAI CONF ARTIF INTE, V34, P5191
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Park W, 2019, PROC CVPR IEEE, P3962, DOI 10.1109/CVPR.2019.00409
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Romero A, 2015, Arxiv, DOI arXiv:1412.6550
   Shen Y., 2022, P IEEE CVF C COMP VI, P11943
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Son W., 2021, P IEEE CVF INT C COM, P9395
   Sukmin Yun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13873, DOI 10.1109/CVPR42600.2020.01389
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Y., 2019, ARXIV
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Xu TB, 2019, AAAI CONF ARTIF INTE, P5565
   Yang C., 2022, IEEE T NEUR NET LEAR, V12, P1
   Yang C.-A., 2022, ARXIV
   Yang ZD, 2023, Arxiv, DOI arXiv:2303.13005
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yuan L, 2020, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR42600.2020.00396
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1612.03928
   Zhang LF, 2019, IEEE I CONF COMP VIS, P3712, DOI 10.1109/ICCV.2019.00381
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao BR, 2022, PROC CVPR IEEE, P11943, DOI 10.1109/CVPR52688.2022.01165
NR 50
TC 0
Z9 0
U1 8
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104700
DI 10.1016/j.imavis.2023.104700
EA MAY 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA J7NK9
UT WOS:001011451000001
DA 2024-07-18
ER

PT J
AU Lu, YH
   Jiang, MZ
   Liu, Z
   Mu, XY
AF Lu, Yunhua
   Jiang, Mingzi
   Liu, Zhi
   Mu, Xinyu
TI Dual-branch adaptive attention transformer for occluded person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Multi-headed self-attention; Transformer;
   Metric learning
AB Occluded person re-identification is still a common and challenging task because people are often occluded by some obstacles (e.g. cars and trees) in the real world. In order to locate the unoccluded parts and extract local fine-grained features of the occluded human body, State-of-the-Art (SOTA) methods usually use a pose estima-tion model, which usually causes additional bias and this two-stage architecture also complicates the model. To solve this problem, an end-to-end dual-branch Transformer network for occluded person re-identification is designed. Specifically, one of the branches is the transformer-based global branch, which is responsible for extracting global features, while in the other local branch, we design the Selective Token Attention (STA) module. STA can utilize the multi-headed self-attention mechanism to select discriminating tokens for effectively extracting the local features. Further, in order to alleviate the inconsistency between Softmax Loss and Triplet Loss convergence goals, Circle Loss is introduced to design the Goal Consistency Loss (GC Loss) to supervise the network. Experiments on four challenging datasets for Re-ID tasks (including occluded person Re-ID and holistic person Re-ID) illustrate that our method can achieve SOTA performance. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Lu, Yunhua; Jiang, Mingzi; Liu, Zhi; Mu, Xinyu] Chongqing Univ Technol, Sch Artificial Intelligence, 459 Pufu Ave, Chongqing 401120, Peoples R China.
C3 Chongqing University of Technology
RP Liu, Z (corresponding author), Chongqing Univ Technol, Sch Artificial Intelligence, 459 Pufu Ave, Chongqing 401120, Peoples R China.
EM yhlu@cqut.edu.cn; mingziJ@stu.cqut.edu.cn; liuzhi@cqut.edu.cn;
   muxy@2020.cqut.edu.cn
FU Natural Science Foundation of Chongqing, China [cstc2021jcyj-msxmX0605];
   Science and Technology Research Program of Chongqing Municipal Education
   Commission [2022CJZ042]; Scientific Research Foundation of Chongqing
   University of Technology [2020ZDZ026]
FX This research was funded partly by The Natural Science Foundation of
   Chongqing, China (Grant No. cstc2021jcyj-msxmX0605) , The Science and
   Technology Research Program of Chongqing Municipal Education Commission
   (Grant Nos. 2022CJZ042) , and The Scientific Research Foundation of
   Chongqing University of Technology (2020ZDZ026) .
CR Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Gao S, 2020, P IEEE CVF C COMP VI, P11744
   Girdhar R, 2019, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2019.00033
   He J, 2022, AAAI CONF ARTIF INTE, P852
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hou RB, 2022, IEEE T PATTERN ANAL, V44, P4894, DOI 10.1109/TPAMI.2021.3079910
   Jia MX, 2023, IEEE T MULTIMEDIA, V25, P1294, DOI 10.1109/TMM.2022.3141267
   Jia MX, 2021, AAAI CONF ARTIF INTE, V35, P1673
   Khorramshahi Pirazh, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P369, DOI 10.1007/978-3-030-58568-6_22
   Kuan Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P346, DOI 10.1007/978-3-030-58580-8_21
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Raghu M., 2021, NEURIPS, V34, P12116
   Shu X, 2020, MULTIMED TOOLS APPL, V79, P23617, DOI 10.1007/s11042-020-09018-x
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Sun PZ, 2021, Arxiv, DOI arXiv:2012.15460
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang GQ, 2020, PROC CVPR IEEE, P6677, DOI 10.1109/CVPR42600.2020.00671
   Wang HY, 2021, PROC CVPR IEEE, P5459, DOI 10.1109/CVPR46437.2021.00542
   Wang X., 2007 IEEE 11 INT C C, P1
   Yang K, 2022, IEEE T MULTIMEDIA, V24, P1956, DOI 10.1109/TMM.2021.3074239
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yuan D, 2022, NEUROCOMPUTING, V491, P44, DOI 10.1016/j.neucom.2022.03.055
   Yuan D, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3486678
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2016, Arxiv, DOI arXiv:1610.02984
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
NR 40
TC 10
Z9 10
U1 3
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2023
VL 131
AR 104633
DI 10.1016/j.imavis.2023.104633
EA FEB 2023
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 9Q1KZ
UT WOS:000944732200001
DA 2024-07-18
ER

PT J
AU Lin, CD
   Xiong, SW
AF Lin, Chengde
   Xiong, Shengwu
TI Controllable face editing for video reconstruction in human digital
   twins
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human digital twins; Video reconstruction; Controllable face editing;
   Generative adversarial networks
AB High fidelity and controllable manipulation are critical to facial video reconstruction in human digital twins. Current generative adversarial networks (GANs) have achieved impressive performance in realis-tic face generation with high resolution, motivating several recent works to perform face editing via pretrained GANs. However, existing works suffer identity loss and semantic entanglement while editing real faces. To tackle these limitations, we propose a framework to perform controllable facial editing in video reconstruction. First, we propose to train a semantic inversion network to embed the target attri-bute change into the latent space of GANs. Disentangled semantic manipulation is performed during the semantic inversion by changing only the target attribute with the other unrelated attributes kept. Furthermore, we propose a novel personalized GAN inversion for the real face cropped from videos via re-training the generator of GANs, which can embed the real face into the latent space of GANs and preserve identity details for the real face. Finally, the realistic edited face is fused back into the original video. We use the identity preservation rate and disentanglement rate to evaluate the performance of our con-trollable face editing. Both qualitative and quantitative evaluations show that our method achieves prom-inent identity preservation and semantic disentanglement in controllable face editing, outperforming recent state-of-the-art methods. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Lin, Chengde; Xiong, Shengwu] Wuhan Univ Technol, Sch Comp Sci & Arti fi cial Intelligence, Wuhan, Peoples R China.
   [Xiong, Shengwu] Wuhan Univ Technol, Sanya Sci & Educ Innovat Pk, Wuhan, Peoples R China.
C3 Wuhan University of Technology; Wuhan University of Technology
RP Xiong, SW (corresponding author), Wuhan Univ Technol, Sch Comp Sci & Arti fi cial Intelligence, Wuhan, Peoples R China.; Xiong, SW (corresponding author), Wuhan Univ Technol, Sanya Sci & Educ Innovat Pk, Wuhan, Peoples R China.
EM linchengde@whut.edu.cn; xiongsw@whut.edu.cn
RI Lin, CD/G-4112-2010; Xiong, Shou-Mei/A-4225-2009
FU NSFC [62176194, 62101393]; Major project of IoV [2020AAA001]; Sanya
   Science and Education Innovation Park of Wuhan University of Technology
   [2021KF0031]; CSTC [cstc2021jcyj-msxmX1148]; Open Project of Wuhan
   University of Technology Chongqing Research Institute [ZL2021-6]
FX This work was in part supported by NSFC (Grant No. 62176194, Grant
   No.62101393) , the Major project of IoV (Grant No. 2020AAA001) , Sanya
   Science and Education Innovation Park of Wuhan University of Technology
   (Grant No. 2021KF0031) , CSTC (Grant No. cstc2021jcyj-msxmX1148) and the
   Open Project of Wuhan University of Technology Chongqing Research
   Institute (ZL2021-6) .
CR Abdal R., IEEE C COMPUTER VISI, P8293
   Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Albraikan A., 2019, THESIS U OTTAWA, DOI 10.20381/ruor-23480
   Bau D., 2019, ICLR WORKSH, V2, P4
   Bau D, 2019, IEEE I CONF COMP VIS, P4501, DOI 10.1109/ICCV.2019.00460
   Bortolon M, 2021, J REAL-TIME IMAGE PR, V18, P345, DOI 10.1007/s11554-021-01095-x
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Lipton ZC, 2017, Arxiv, DOI [arXiv:1702.04782, 10.48550/arXiv.1702.04782]
   Chakshu NK, 2021, BIOMECH MODEL MECHAN, V20, P449, DOI 10.1007/s10237-020-01393-6
   Creswell A, 2019, IEEE T NEUR NET LEAR, V30, P1967, DOI 10.1109/TNNLS.2018.2875194
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Gu JJ, 2020, PROC CVPR IEEE, P3009, DOI 10.1109/CVPR42600.2020.00308
   Guan SY, 2020, Arxiv, DOI arXiv:2007.01758
   Han Y., 2021, ARXIV210512660, P715
   Harkonen E., 2020, P ADV NEUR INF PROC
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiapeng Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P592, DOI 10.1007/978-3-030-58520-4_35
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T., 2018, arXiv, DOI [10.48550/arXiv.1710.10196, DOI 10.48550/ARXIV.1710.10196]
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Li M., IEEE C COMPUTER VISI, P6529
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lv ZH, 2021, IEEE T IND INFORM, V17, P1496, DOI 10.1109/TII.2020.2994747
   Lv ZH, 2020, IEEE T IND INFORM, V16, P1957, DOI 10.1109/TII.2019.2913535
   Ma FC, 2018, ADV NEUR IN, V31
   Martinez-Velazquez Roberto., 2019, 2019 IEEE International Symposium on Medical Measurements and Applications (MeMeA). 2019 IEEE International Symposium on Medical Measurements and Applications (MeMeA), P1, DOI [DOI 10.1109/MEMEA.2019.8802162(CIT.ONP.186, 10.1109/MeMeA.2019.8802162, 10.1109/ MeMeA.2019.8802162 (cit. on p. 186]
   Mourtzis D., 2021, PROCEDIA CIRP, V104, P1686
   Pantraki E, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01207-4
   Pantraki E, 2019, INT CONF ACOUST SPEE, P8370, DOI [10.1109/ICASSP.2019.8682965, 10.1109/icassp.2019.8682965]
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   Perarnau G, 2016, Arxiv, DOI [arXiv:1611.06355, 10.48550/arXiv.1611.06355]
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Pernus M, 2023, Arxiv, DOI arXiv:2103.11135
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Roich Daniel, 2021, arXiv
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengan S, 2022, MULTIMED TOOLS APPL, V81, P26839, DOI 10.1007/s11042-021-10842-y
   Shengli W., 2021, Comput. Methods Programs Biomed. Update, V1, P2021, DOI DOI 10.1016/J.CMPBUP.2021.100014
   Simonyan K, 2018, INT C LEARNING REPRE
   Sparrow D., 2019, P INT C COMP MAN STE
   Tewari A, 2020, PROC CVPR IEEE, P6141, DOI 10.1109/CVPR42600.2020.00618
   Thomas R., TRAILER MOVIE HAWKEY
   Viazovetskyi Yuri, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P170, DOI 10.1007/978-3-030-58542-6_11
   Wachowski L., TRAILER MOVIE MATRIX
   Wang H., 2021, P IEEECVF C COMPUTER, P7872
   Xu YH, 2021, PROC CVPR IEEE, P4430, DOI 10.1109/CVPR46437.2021.00441
   Yang G., 2021, IEEE C COMP VIS PATT, P2951
   Yang N, 2021, IEEE SIGNAL PROC LET, V28, P553, DOI 10.1109/LSP.2021.3059371
   Yao Xu, 2021, P IEEE INT C COMP VI, P13789
   Yujun Shen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9240, DOI 10.1109/CVPR42600.2020.00926
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
   Zhuang P., 2021, INT C LEARNING REPRE
NR 54
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2022
VL 125
AR 104517
DI 10.1016/j.imavis.2022.104517
EA JUL 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3Y7JW
UT WOS:000843898700002
DA 2024-07-18
ER

PT J
AU Hejazi, SM
   Abhayaratne, C
AF Hejazi, Seyed Mostafa
   Abhayaratne, Charith
TI Handcrafted localized phase features for human action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Motion analysis; Phase analysis; Human action recognition; Handcrafted
   features
ID MOTION; REPRESENTATION; SURVEILLANCE; SALIENCE; POINTS
AB Human action recognition is one of the most important topics in computer vision. Monitoring elderly people and children, smart surveillance systems and human-computer interaction are a few examples of its applications. The aim of this study is to recognize human activities by utilizing the phase information extracted from the frequency domain of the video data as handcrafted features. Rather than estimating optical flow or computing motion vectors, we aim to utilize the localized phase information as descriptors of the motion dynamics of the scene. Phase correlation information extracted from each two co-sited blocks from each two consecutive frames of video clips were used to train a model using KNN classifier to model the action. To evaluate the performance of our method, an extensive work has been done on three large and complex datasets: UCF101, Kinetics-400 and Kinetics-700. The results show that our approach succeeds on recognizing human actions across all these datasets with high accuracy. (c) 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Hejazi, Seyed Mostafa; Abhayaratne, Charith] Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 3JD, South Yorkshire, England.
C3 University of Sheffield
RP Abhayaratne, C (corresponding author), Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 3JD, South Yorkshire, England.
EM c.abhayaratne@sheffield.ac.uk
RI Hejazi, Seyedsina/L-5162-2019
OI Hejazi, Seyedsina/0000-0003-1526-5629
CR Adeli V, 2019, IMAGE VISION COMPUT, V90, DOI 10.1016/j.imavis.2019.08.009
   Al-Obaidi S, 2020, IEEE ACCESS, V8, P213806, DOI 10.1109/ACCESS.2020.3039740
   Al-Obaidi S, 2019, INT CONF ACOUST SPEE, P2017, DOI 10.1109/ICASSP.2019.8682569
   Argyriou V, 2005, IEEE IMAGE PROC, P589
   Arnab A., 2021, 2021 IEEECVF INT C C, P6816, DOI [10.1109/ICCV48922.2021.00676, DOI 10.1109/ICCV48922.2021.00676]
   Bian W, 2012, IEEE T SYST MAN CY B, V42, P298, DOI 10.1109/TSMCB.2011.2166761
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Briassouli A, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P217
   Cai JX, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P660, DOI 10.1109/ACPR.2015.7486585
   Cardinaux F, 2011, J AMB INTEL SMART EN, V3, P253, DOI 10.3233/AIS-2011-0110
   CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Fathi A, 2008, PROC CVPR IEEE, P3064
   Feng H, 2021, IEEE T CYBERNETICS, V51, P5082, DOI 10.1109/TCYB.2019.2904901
   Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953
   Gang JL, 2021, IEEE ACCESS, V9, P127010, DOI 10.1109/ACCESS.2021.3111633
   Gowda SN, 2021, AAAI CONF ARTIF INTE, V35, P1451
   Haodong Duan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P670, DOI 10.1007/978-3-030-58555-6_40
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Iosifidis A, 2012, IEEE T INF FOREN SEC, V7, P530, DOI 10.1109/TIFS.2011.2175921
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Kay W., 2017, ARXIV170506950
   Kumari S., 2011, Proceedings of the 2011 Third National Conference on Computer Vision, Pattern Recognition, Image Processing and Graphics (NCVPRIPG 2011), P239, DOI 10.1109/NCVPRIPG.2011.58
   Lan T, 2011, IEEE I CONF COMP VIS, P2003, DOI 10.1109/ICCV.2011.6126472
   Li RN, 2012, PROC CVPR IEEE, P2855, DOI 10.1109/CVPR.2012.6248011
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Luo HN, 2022, IEEE T CIRC SYST VID, V32, P3073, DOI 10.1109/TCSVT.2021.3100842
   Majd M, 2020, NEUROCOMPUTING, V396, P224, DOI 10.1016/j.neucom.2018.10.095
   Martinez B, 2019, IEEE I CONF COMP VIS, P5481, DOI 10.1109/ICCV.2019.00558
   McNally W, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P49, DOI 10.1109/CRV.2019.00015
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Nowozin S, 2007, IEEE I CONF COMP VIS, P1727
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Pal Sandipan., 2015, Proceedings of the 9th International Conference on Distributed Smart Cameras, P62
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Rapantzikos K, 2009, PROC CVPR IEEE, P1454, DOI 10.1109/CVPRW.2009.5206525
   Ren J, 2016, INT J INTELL COMPUT, V9, P394, DOI 10.1108/IJICC-03-2016-0009
   Roshtkhari MJ, 2013, IMAGE VISION COMPUT, V31, P864, DOI 10.1016/j.imavis.2013.08.005
   Sargano AB, 2017, IEEE IJCNN, P463, DOI 10.1109/IJCNN.2017.7965890
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shabani A. H., 2012, 2012 Canadian Conference on Computer and Robot Vision, P468, DOI 10.1109/CRV.2012.69
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Siddiqi MH, 2019, COMPUT INTEL NEUROSC, V2019, DOI 10.1155/2019/8590560
   Sigal L, 2012, INT J COMPUT VISION, V98, P15, DOI 10.1007/s11263-011-0493-4
   Smaira L., A short note on the kinetics-700-2020 human action dataset
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stefic D, 2016, IMAGE VISION COMPUT, V52, P195, DOI 10.1016/j.imavis.2016.06.006
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Tran A., 2014, ACTION RECOGNITION F, DOI [10.48550/arXiv.1409.0908, DOI 10.48550/ARXIV.1409.0908]
   Tran KN, 2012, PATTERN RECOGN, V45, P2562, DOI 10.1016/j.patcog.2011.12.028
   Thi TH, 2012, IMAGE VISION COMPUT, V30, P1, DOI 10.1016/j.imavis.2011.12.006
   Ullah A, 2019, FUTURE GENER COMP SY, V96, P386, DOI 10.1016/j.future.2019.01.029
   Vlachos T, 2000, IEEE SIGNAL PROC LET, V7, P173, DOI 10.1109/97.847360
   Vrigkas M, 2015, FRONT ROBOT AI, DOI 10.3389/frobt.2015.00028
   Wang F, 2019, IEEE ACCESS, V7, P164876, DOI 10.1109/ACCESS.2019.2953113
   Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214
   Yan Shen, 2022, MULTIVIEW TRANSFORME
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhang B., ABS211207175 CORR
   Zhang CY, 2022, IEEE T CYBERNETICS, V52, P398, DOI 10.1109/TCYB.2020.2973300
   Ziaeefard M., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3720, DOI 10.1109/ICPR.2010.906
NR 64
TC 7
Z9 7
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104465
DI 10.1016/j.imavis.2022.104465
EA MAY 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L9ND
UT WOS:000799606300001
OA hybrid, Green Accepted
DA 2024-07-18
ER

PT J
AU Holkar, A
   Walambe, R
   Kotecha, K
AF Holkar, Ashwamegha
   Walambe, Rahee
   Kotecha, Ketan
TI Few-Shot learning for face recognition in the presence of image
   discrepancies for limited multi-class datasets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Few-Shot learning; Face recognition; Occlusion; Low light; Orientation;
   Siamese networks
ID EIGENFACES
AB One of the primary limitations of deep learning is data-hungry techniques. Deep learning approaches do not typically generalize well for limited datasets with fewer samples. Drawing the inspiration from the way human beings are capable of detecting a face from very few images seen in past (experience), Few-Shot Learning methods are reported in the literature. The problem is more challenging for face recognition tasks for limited dataset where the facial images are captured in various unfavorable conditions (i.e. discrepancies). To that end, in this work, we propose the Siamese Network-based Few-Shot Learning method for multi-class face recognition from a training dataset consisting of only a handful of images per class. We consider three such face image discrepancies namely, low light, head rotation and occlusion. Our work offers novelty primarily in the way the image discrepancies are overcome via Few-Shot learning while recognizing the face with reasonable accuracy. The results are obtained on our manually collected primary dataset (SCAAI_FSL) for multiple classes. Our approach presents a unique solution for face recognition tasks where the images in the training and testing dataset have different discrepancies which is the typical real-world scenario. We have experimented with various face embeddings models and demonstrated our approach for simultaneously handling multiple image discrepancies for SCAAI_FSL dataset and reported the testing accuracy of 72.72%.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Holkar, Ashwamegha; Walambe, Rahee; Kotecha, Ketan] Symbiosis Int Deemed Univ SIU, Symbiosis Ctr Appl Artificial Intelligence SCAAI, Pune, Maharashtra, India.
   [Walambe, Rahee; Kotecha, Ketan] Symbiosis Int Deemed Univ SIU, Symbiosis Inst Technol, Pune, Maharashtra, India.
C3 Symbiosis International University; Symbiosis International University;
   Symbiosis Institute of Technology (SIT)
RP Walambe, R; Kotecha, K (corresponding author), Symbiosis Int Deemed Univ SIU, Symbiosis Ctr Appl Artificial Intelligence SCAAI, Pune, Maharashtra, India.; Walambe, R; Kotecha, K (corresponding author), Symbiosis Int Deemed Univ SIU, Symbiosis Inst Technol, Pune, Maharashtra, India.
EM rahee.walambe@sitpune.edu.in; director@sitpune.edu.in
RI Walambe, Rahee/AAR-8150-2021; Kotecha, K/U-3927-2017
OI Walambe, Rahee/0000-0003-1745-5231; Kotecha, K/0000-0003-2653-3780
CR Altae-Tran H, 2017, ACS CENTRAL SCI, V3, P283, DOI 10.1021/acscentsci.6b00367
   [Anonymous], 1996, P BRIT MACH VIS C
   Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144
   Belhumeur P.N., 1997, P IEEE C COMP VIS PA, P52
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bertinetto L., 2016, Advances in neural information processing systems, P523
   Bledsoe W.W., 1964, MODEL METHOD FACIAL
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Bruner J., 1954, HDB SOCIAL PSYCHOL, P634
   Chen T, 2020, PR MACH LEARN RES, V119
   Craig J J., INTRO ROBOTICS MECH
   Darwin C., 1972, MAN ANIMALS
   Ding ZM, 2018, IEEE INT CONF AUTOMA, P1, DOI 10.1109/FG.2018.00011
   Dong XY, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P54, DOI 10.1145/3240508.3240527
   Duan Y, 2017, ADV NEUR IN, V30
   Ekman P., 1998, C DARWINS EXPRESSION, VThird
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fei-Fei L., P INT C DEV LEARN IC, P11
   Fink M., 2005, 2005 Advances in Neural Information Processing Systems, V17, P449
   Finn C, 2017, PR MACH LEARN RES, V70
   Fort Stanislav, PROTOTYPICAL 1 SHOT
   Galton Francis., 1888, NATURE, V61, P173
   Guo K, 2017, CAAI T INTELL TECHNO, V2, P39, DOI 10.1016/j.trit.2017.03.001
   Guo Yandong, ARXIV170705574
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Kaiser Lukasz, 2017, ICLR
   Kanade T., 1973, COMPUTER RECOGNITION
   Kar Nirmalya, 2012, INT J COMPUT COMMUN, DOI [10.7763/IJCCE.2012.V1.28, DOI 10.7763/IJCCE.2012.V1.28]
   Kelly M.D, 1970, AI130 STANF AI PROJ
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Kozerawski J, ARXIV PREPRINT ARXIV
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lake B.M., One shot learning of simple visual concepts
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liu Bo, P IEEE CVF C COMP VI
   Maheshwary S, 2018, COMPANION PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2018 (WWW 2018), P87, DOI 10.1145/3184558.3186942
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Nefian AV, 1998, INT CONF ACOUST SPEE, P2721, DOI 10.1109/ICASSP.1998.678085
   Ngan Mei, 8311 NIST
   Pfister T, 2014, LECT NOTES COMPUT SC, V8694, P814, DOI 10.1007/978-3-319-10599-4_52
   Phillips PJ, 1999, ADV NEUR IN, V11, P803
   SAMARIA F, 1994, IMAGE VISION COMPUT, V12, P537, DOI 10.1016/0262-8856(94)90007-8
   Samaria F., 1994, THESIS U CAMBRIDGE
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Simonyan K., ARXIV14091556V6CSCV
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Thakurdesai Nikhil, 2018, INT J COMPUT APPL, DOI [10. 5120/ijca2018918032, DOI 10.5120/IJCA2018918032]
   Triantafillou E, 2017, ADV NEUR IN, V30
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vartak Manasi, 2017, NEURIPS, P6904
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Wu Y, 2010, IEEE INT CONF ROBOT, P2889, DOI 10.1109/ROBOT.2010.5509429
   Yoon J, 2018, ADV NEUR IN, V31
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhao W, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P336, DOI 10.1109/AFGR.1998.670971
NR 62
TC 18
Z9 18
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104420
DI 10.1016/j.imavis.2022.104420
EA FEB 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500003
DA 2024-07-18
ER

PT J
AU Wang, NN
   Zhang, YX
AF Wang, Nannan
   Zhang, Yongxia
TI Adaptive and fast image superpixel segmentation approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image processing; Superpixels; Linear path; LBP; Contour density
ID CLASSIFICATION
AB Superpixel is one of the most popular image over-segmentations with broad applications in the computer vision field to reduce their computations by replacing pixels as primitives. The main concerns of one superpixel generation algorithm are its accuracy and efficiency. One of the most important things in superpixel accuracy is to fit the image boundaries tightly with a few pixels as possible (namely minimal contour density, which is measured by the percent of superpixel contour pixels in the whole image). In this paper, we propose a new fast algorithm based on the clustering method to produce superpixels accurately with low contour density. First, we adopt the linear path from a pixel to one superpixel seed to define a regular term and propose a new distance measurement between them. In addition, we introduce the gradient and Local Binary Pattern (LBP) features and propose formulas of parameters in the proposed method adaptively. In this way, we can use the new distance measurement to group pixels as initial regions adaptively and produce the final superpixels by merging those small ones. Finally, we test the new algorithm on two public datasets and compare it with the state-of-the-art. Our method can generate superpixels with lower contour density while being competitive in accuracy and computational time. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wang, Nannan] Shandong Management Univ, Dept Informat Engn, Jinan, Peoples R China.
   [Zhang, Yongxia] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
   [Zhang, Yongxia] Digital Media Technol Key Lab Shandong Prov, Jinan, Peoples R China.
C3 Shandong Management University; Shandong University of Finance &
   Economics
RP Zhang, YX (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
EM winolawang@163.com; sdu_zyx@hotmail.com
CR Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Conze PH, 2019, IMAGE VISION COMPUT, V89, P289, DOI 10.1016/j.imavis.2019.06.011
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fengting Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13961, DOI 10.1109/CVPR42600.2020.01398
   Giraud R, 2018, COMPUT VIS IMAGE UND, V170, P1, DOI 10.1016/j.cviu.2018.01.006
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   Hu YL, 2018, IMAGE VISION COMPUT, V70, P1, DOI 10.1016/j.imavis.2017.12.001
   Lee SH, 2017, PROC CVPR IEEE, P5863, DOI 10.1109/CVPR.2017.621
   Liang YL, 2016, IEEE T CIRC SYST VID, V26, P928, DOI 10.1109/TCSVT.2015.2406232
   Liu YJ, 2018, IEEE T PATTERN ANAL, V40, P653, DOI 10.1109/TPAMI.2017.2686857
   Liu YJ, 2016, PROC CVPR IEEE, P651, DOI 10.1109/CVPR.2016.77
   Mendonça M, 2018, IMAGE VISION COMPUT, V80, P45, DOI 10.1016/j.imavis.2018.09.015
   Oh KW, 2019, J REAL-TIME IMAGE PR, V16, P945, DOI 10.1007/s11554-016-0583-1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Peng JT, 2016, IEEE T CIRC SYST VID, V26, P917, DOI 10.1109/TCSVT.2015.2430631
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   [宋克臣 Song Kechen], 2013, [自动化学报, Acta Automatica Sinica], V39, P730
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Wang H, 2020, IEEE T CIRC SYST VID, V30, P822, DOI 10.1109/TCSVT.2019.2896438
   Wang LJ, 2018, IEEE T CYBERNETICS, V48, P1030, DOI 10.1109/TCYB.2017.2675910
   Wang W, 2018, IEEE T CIRC SYST VID, V28, P1609, DOI 10.1109/TCSVT.2017.2684759
   Wilms C, 2021, IMAGE VISION COMPUT, V114, DOI 10.1016/j.imavis.2021.104263
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Xue TF, 2019, IMAGE VISION COMPUT, V91, DOI 10.1016/j.imavis.2019.05.006
   Zhang YX, 2020, IET IMAGE PROCESS, V14, P4543, DOI 10.1049/iet-ipr.2020.1179
   Zhang YX, 2021, VISUAL COMPUT, V37, P1061, DOI 10.1007/s00371-020-01852-2
   Zhang YX, 2017, IEEE T CIRC SYST VID, V27, P1502, DOI 10.1109/TCSVT.2016.2539839
   Zhou XN, 2019, VISUAL COMPUT, V35, P385, DOI 10.1007/s00371-018-1471-4
NR 35
TC 3
Z9 3
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104315
DI 10.1016/j.imavis.2021.104315
EA OCT 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WL9GT
UT WOS:000710706800001
DA 2024-07-18
ER

PT J
AU Patro, BN
   Kurmi, VK
   Kumar, S
   Namboodiri, VP
AF Patro, Badri N.
   Kurmi, Vinod K.
   Kumar, Sandeep
   Namboodiri, Vinay P.
TI MUMC: Minimizing uncertainty of mixture of cues
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Uncertainty estimation; Mixture of cues; Visual Question Answering;
   Paraphrase; Visual Question Generation; LSTM; CNN; Encoder-decoder
AB Generating natural questions from an image is a semantic task that requires using vision and language modalities to learn multimodal representations. Images can have multiple visual and language cues such as places, captions, and tags. In this paper, we propose a principled deep Bayesian learning framework that combines these cues to produce natural questions. We observe that with the addition of more cues and by minimizing uncertainty in the among cues, the Bayesian network becomes more confident. We propose a Minimizing Uncertainty of Mixture of Cues (MUMC), that minimizes uncertainty present in a mixture of cues experts for generating probabilistic questions. This is a Bayesian framework and the results show a remarkable similarity to natural questions as validated by a human study. Ablation studies of our model indicate that a subset of cues is inferior at this task and hence the principled fusion of cues is preferred. Further, we observe that the proposed approach substantially improves over state-of-the-art benchmarks on the quantitative metrics (BLEU-n, METEOR, ROUGE, and CIDEr). Here, we provide project link for Deep Bayesian VQG: https://delta-lab-iitk.github.io/BVQG/. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Patro, Badri N.; Kurmi, Vinod K.] Indian Inst Technol Kanpur, Dept Elect Engn, Kanpur, Uttar Pradesh, India.
   [Namboodiri, Vinay P.] Indian Inst Technol Kanpur, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
   [Kumar, Sandeep] Indian Inst Technol Kanpur, Dept Math & Stat, Kanpur, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Kanpur; Indian Institute
   of Technology System (IIT System); Indian Institute of Technology (IIT)
   - Kanpur
RP Patro, BN (corresponding author), Indian Inst Technol Kanpur, Dept Elect Engn, Kanpur, Uttar Pradesh, India.
EM badri@iitk.ac.in; vinodkk@iitk.ac.in; sandepkr@iitk.ac.in;
   vpn22@bath.ac.uk
RI Kumar, Sandeep/IUQ-2320-2023; Patro, Badri Narayana/AAK-2539-2021;
   KURMI, VINOD K/AAY-7289-2021
OI Kumar, Sandeep/0000-0002-0848-632X; Patro, Badri
   Narayana/0000-0002-2585-7014; Namboodiri, Vinay/0000-0001-5262-9722
CR Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Aytar Y, 2018, IEEE T PATTERN ANAL, V40, P2303, DOI 10.1109/TPAMI.2017.2753232
   Baldacchino T, 2016, MECH SYST SIGNAL PR, V66-67, P178, DOI 10.1016/j.ymssp.2015.05.009
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Barber D., 1998, Neural Networks and Machine Learning. Proceedings, P215
   Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Chattopadhyay P., 2017, P 5 AAAI C HUM COMP
   Chen X, 2015, PROC CVPR IEEE, P2422, DOI 10.1109/CVPR.2015.7298856
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Denker J., 1991, Advances in Neural Information Processing Systems, P853, DOI DOI 10.5555/2986766.2986882
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Gal Y, 2016, ADV NEUR IN, V29
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gal Yarin, 2016, Uncertainty in deep learning
   Ganju S, 2017, PROC CVPR IEEE, P6422, DOI 10.1109/CVPR.2017.680
   Graves Alex, 2011, ADV NEURAL INFORM PR, P2348, DOI DOI 10.5555/2986459.2986721
   Hinton G. E., 1993, Proceeding of the Sixth Annual ACM Conference on Computational Learning Theory, P5, DOI 10.1145/168304.168306
   Jain U, 2017, PROC CVPR IEEE, P5415, DOI 10.1109/CVPR.2017.575
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kendall Alex, 2017, ADV NEURAL INFORM PR, V30, DOI DOI 10.5555/3295222.3295309
   Kim J., 2017, ICLR
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Kurmi VK, 2019, PROC CVPR IEEE, P491, DOI 10.1109/CVPR.2019.00058
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Malinin A, 2018, ADV NEUR IN, V31
   Mostafazadeh N, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P1802
   Neal R. M., 1993, Advances in Neural Information Processing Systems, P475
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Patro B., 2020, IEEE WINTER C APPL C
   Patro B.N., P 2018 C EMP METH NA, P4002
   Patro B, 2018, PROC CVPR IEEE, P7680, DOI 10.1109/CVPR.2018.00801
   Patro BN, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107586
   Patro BN, 2019, IEEE I CONF COMP VIS, P7443, DOI 10.1109/ICCV.2019.00754
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sutskever I, 2014, ADV NEUR IN, V27
   Tishby N., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P403, DOI 10.1109/IJCNN.1989.118274
   Ueda N, 2000, NEURAL NETWORKS FOR SIGNAL PROCESSING X, VOLS 1 AND 2, PROCEEDINGS, P145, DOI 10.1109/NNSP.2000.889405
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang Y., ARXIV PREPRINT ARXIV
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yuksel SE, 2012, IEEE T NEUR NET LEAR, V23, P1177, DOI 10.1109/TNNLS.2012.2200299
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang S., 2017, P 26 INT JOINT C ART
   Zhou B, ARXIV PREPRINT ARXIV
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 50
TC 1
Z9 1
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104280
DI 10.1016/j.imavis.2021.104280
EA SEP 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WC6NH
UT WOS:000704372400006
DA 2024-07-18
ER

PT J
AU Li, M
   Hu, XJ
   Dai, JZ
   Li, Y
   Du, SD
AF Li, Ming
   Hu, Xuejiao
   Dai, Jingzhao
   Li, Yang
   Du, Sidan
TI Omnidirectional stereo depth estimation based on spherical deep network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Omnidirectional depth estimation; Spherical convolutional network;
   Stereo matching; Cascade learning
ID ENERGY MINIMIZATION; RECONSTRUCTION
AB Omnidirectional depth estimation is an emerging research topic and has received significant attention in recent years. However, the existing methods were developed based on the theory of planar stereo matching; and introduce the nonlinear epipolar constraint and significant distortions of re-projections. In this paper, we propose a novel approach that use spherical CNNs and the epipolar constraint on sphere for omnidirectional depth estimation. We discuss the epipolar constraint for spherical stereo imaging and convert the nonlinear constraint on a planar projection to the linear constraint on a sphere. We then propose a Spherical Convolution Residual Network (SCRN) for omnidirectional depth estimation via the spherical linear epipolar constraint. The input equirectangular projection (ERP) images are sampled to spherical meshes and fed into SCRN to calculate spherical depth maps. For 2D visualization, we design a Planar Refinement Network (PRN) and adopt the cascade learning scheme to improve the accuracy of depth maps. This scheme reduces the errors caused by projection, interpolation, and the limitation of spherical representation. The experiment shows that our full scheme Cascade Spherical Depth Network (CSDNet) results in more accurate and detailed depth maps with lower errors, as compared to recent seminal works. Our approach yields the comparable performance to the other state-of-the-art works on the omnidirectional stereo datasets with less number of parameters. The effectiveness of the spherical network and the cascade learning scheme is validated, and the influence of spherical sampling density is also discussed. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Li, Ming; Hu, Xuejiao; Dai, Jingzhao; Li, Yang; Du, Sidan] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210046, Peoples R China.
C3 Nanjing University
RP Li, Y; Du, SD (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210046, Peoples R China.
EM yogo@nju.edu.cn; coff128@nju.edu.cn
RI Du, Sidan/JVN-2413-2024
OI Du, Sidan/0000-0002-7079-0066
CR Armeni Iro, 2017, arXiv
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Changhee Won, 2021, IEEE Transactions on Pattern Analysis and Machine Intelligence, V43, P3850, DOI 10.1109/TPAMI.2020.2992497
   Cheng XJ, 2020, IEEE T PATTERN ANAL, V42, P2361, DOI 10.1109/TPAMI.2019.2947374
   Cheng XJ, 2018, LECT NOTES COMPUT SC, V11220, P108, DOI 10.1007/978-3-030-01270-0_7
   Cohen T.S., 2018, P 6 INT C LEARN REPR, P1
   Coors B, 2018, LECT NOTES COMPUT SC, V11213, P525, DOI 10.1007/978-3-030-01240-3_32
   Defferrard M., 2020, INT C LEARN REPR ICL
   Eigen D, 2014, ADV NEUR IN, V27
   Esteves C, 2020, INT J COMPUT VISION, V128, P588, DOI 10.1007/s11263-019-01220-1
   Guan C., 2020, ABS200701475 ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang C. M., 2019, ARXIV190102039
   Jiang HL, 2021, IEEE ROBOT AUTOM LET, V6, P1519, DOI 10.1109/LRA.2021.3058957
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Kingma D. P., 2014, arXiv
   Kondor R., 2018, ADV NEURAL INFORM PR
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee Kyuho J., 2016, 2016 IEEE Hot Chips 28 Symposium (HCS), DOI 10.1109/HOTCHIPS.2016.7936225
   Li M, 2019, IEICE T INF SYST, VE102D, P1183, DOI 10.1587/transinf.2018EDP7273
   Li SG, 2008, IEEE T INTELL TRANSP, V9, P589, DOI 10.1109/TITS.2008.2006736
   Li Y, 2004, IEEE T PATTERN ANAL, V26, P45, DOI 10.1109/TPAMI.2004.1261078
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Michael M, 2013, IEEE INT VEH SYM, P1197, DOI 10.1109/IVS.2013.6629629
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schönbein M, 2014, IEEE INT C INT ROBOT, P716, DOI 10.1109/IROS.2014.6942637
   Skupin R, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Song SR, 2017, PROC CVPR IEEE, P190, DOI 10.1109/CVPR.2017.28
   Su Y.-C., 2017, ADV NEURAL INFORM PR, P529
   Wang FE, 2020, PROC CVPR IEEE, P459, DOI 10.1109/CVPR42600.2020.00054
   Wang FE, 2019, LECT NOTES COMPUT SC, V11365, P53, DOI 10.1007/978-3-030-20873-8_4
   Wang N.H., 2020, IEEE INT CONF ROBOT, P582, DOI 10.1109/ICRA40945.2020.9196975
   Won C., 2019, IEEE CVF INT C COMP
   Won C, 2019, IEEE INT CONF ROBOT, P6073, DOI [10.1109/ICRA.2019.8793823, 10.1109/icra.2019.8793823]
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhao Q, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1198
   Zioulis N., 2019, INT C 3D VIS 3DV
   Zioulis N, 2018, LECT NOTES COMPUT SC, V11210, P453, DOI 10.1007/978-3-030-01231-1_28
NR 45
TC 6
Z9 6
U1 2
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2021
VL 114
AR 104264
DI 10.1016/j.imavis.2021.104264
EA AUG 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UR9HP
UT WOS:000697051200001
DA 2024-07-18
ER

PT J
AU Liu, MY
   Yin, HJ
AF Liu, Mengyu
   Yin, Hujun
TI Efficient pyramid context encoding and feature embedding for semantic
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic segmentation; Convolutional neural networks; Pyramid context
   encoding; Real-time processing
AB For reality applications of semantic segmentation, inference speed and memory usage are two important factors. To address these challenges, we propose a lightweight feature pyramid encoding network (FPENet) for semantic segmentation with a good trade-off between accuracy and speed. We use a series of feature pyramid encoding (FPE) blocks to encode context at multiple scales in the encoder. Each FPE block consists of different depthwise dilated convolutions that perform as a spatial pyramid to extract features and reduce computational costs. During training, a one-shot neural architecture search algorithm is adopted to find the optimal structure for each FPE block from a large search space with a small search cost. After the search for the encoder, a mutual embedding upsample module is introduced in the decoder, consisting of two attention blocks. The encoder-decoder attention mechanism is used to help aggregate efficiently high-level semantic features and low-level spatial details. The proposed network outperforms the existing real-time methods with fewer parameters and improved inference speed on the Cityscapes and CamVid benchmark datasets. Specifically, it achieved 72.3% mean IoU on the Cityscapes test set with only 0.4 M parameters and 192.6 FPS speed on an Nvidia Titan V100 GPU, and 73.4% mean IoU with 116.2 FPS when running on higher resolution images.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Mengyu; Yin, Hujun] Univ Manchester, Dept Elect & Elect Engn, Manchester, Lancs, England.
C3 University of Manchester
RP Yin, HJ (corresponding author), Univ Manchester, Dept Elect & Elect Engn, Manchester, Lancs, England.
EM mengyu.liu@manchester.ac.uk; hujun.yin@manchester.ac.uk
OI Yin, Hujun/0000-0002-9198-5401
CR [Anonymous], 2017, AUTOMATIC DIFFERENTI
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Cai Han, 2019, INT C LEARN REPR
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen W., 2020, INT C LEARN REPR
   Chen X, 2019, IEEE I CONF COMP VIS, P1294, DOI 10.1109/ICCV.2019.00138
   Cipolla R., P BRIT MACH VIS C
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dean J., 2015, NIPS DEEP LEARNING R
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2019, PROC CVPR IEEE, P578, DOI 10.1109/CVPR.2019.00067
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Hubara I, 2018, J MACH LEARN RES, V18
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Jing WP, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104025
   Kurakin A., INT C MACH LEARN, P2902
   Le Q., INT C MACH LEARN, P549
   Li H., 2018, P BRIT MACH VIS C
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2018, IEEE T PATTERN ANAL, V40, P1352, DOI 10.1109/TPAMI.2017.2708714
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu H, 2019, INT C LEARNING REPRE, DOI DOI 10.1109/CVPR42600.2020.00243
   Liu HaiJing Liu HaiJing, 2018, The Proceedings of the Fifteenth Congress of China Sheep Industry Development Sponsored by the China Animal Husbandry Association in 2018, Henan, China, 10-11 October, 2018, P13
   Liu M., 2019, P BRIT MACH VIS C
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Paszke A., 2016, ARXIV160602147
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Pham Hieu., 2018, ICML, V80, P4095, DOI [https://doi.org/10.48550/arXiv.1802.03268, DOI 10.48550/ARXIV.1802.03268]
   Poudel R. P., 2018, ARXIV180504554
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shao X., IMAGE VIS COMPUT
   Sun J., P EUR C COMP VIS, P269
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wang, P IEEE C COMP VIS PA, P2604
   Wang J., ARXIV180900916, V2021
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Xiao B., 2020, ARXIV190807919
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zeiler MD, EUR C COMP VIS, P818
   Zhang YH, 2019, PROC CVPR IEEE, P11633, DOI 10.1109/CVPR.2019.01191
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zoph B., 2017, ICLR, P1, DOI DOI 10.1109/ICAIIC48513.2020.9065031
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zou Y., 2018, ARXIV1606
NR 63
TC 3
Z9 6
U1 1
U2 40
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104195
DI 10.1016/j.imavis.2021.104195
EA MAY 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dong, ZH
   Li, JP
   Fang, TY
   Shao, XL
AF Dong, Zihao
   Li, Jinping
   Fang, Tiyu
   Shao, Xiuli
TI Lightweight boundary refinement module based on point supervision for
   semantic segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic segmentation; Boundary refinement; Point supervision; Point
   convolution; Direction field
AB An effective semantic segmentation approach should contain fine object boundaries and continuous regions. However, recent mask-based segmentation cannot extract boundary features well on the coarse prediction, which causes obvious problems of blurry edges. Although several segmentation methods embed boundary de-tection branch to calculate contours directly, this type of architecture will lead to the increased computational complexity and miss the edge detailed information such as inter-class distinction. In order to obtain fine boundaries, we present a lightweight boundary refinement module with point supervision named BRPS to im-prove the boundary quality for the segmentation result generated by various existing segmentation models. Firstly, a direction field is learned to complete the initial feature rectification, which is defined as pointing away from the nearest object boundary to each pixel, where the weighted Euclidean and Cosine distance func-tion is used as the loss between predicted boundary pixels and Ground-truth labels. Then, point-based super-vised learning is performed at uncertain and certain locations including random distribution and key feature points based on a new point convolutional operation to output final crisp object boundaries. Finally, we verify that our BRPS module can effectively reduce the prediction errors for segmentation results generated from various state-of-the-art models such as DeepLabv3 and HRNet on the Pascal VOC2012, NYUD v2 datasets, City-scapes and BDD100K datasets.& nbsp; (c) 2021 Elsevier B.V. All rights reserved.
C1 [Dong, Zihao; Li, Jinping; Fang, Tiyu] Jinan Univ, Sch Informat Sci & Engn, Jinan 250022, Peoples R China.
   [Shao, Xiuli] Nankai Univ, Coll Comp Sci, Tianjin 300350, Peoples R China.
C3 University of Jinan; Nankai University
RP Dong, ZH (corresponding author), Jinan Univ, Sch Informat Sci & Engn, Jinan 250022, Peoples R China.
EM ise_dongzh@ujn.edu.cn
CR Acuna D, 2019, PROC CVPR IEEE, P11067, DOI 10.1109/CVPR.2019.01133
   Acuna D, 2018, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2018.00096
   Bearman Amy, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Bertasius G, 2016, PROC CVPR IEEE, P3602, DOI 10.1109/CVPR.2016.392
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chen L.-C., 2017, ARXIV170605587, DOI DOI 10.1109/ICC.2017.7997128
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dong ZH, 2019, IEEE ACCESS, V7, P147501, DOI 10.1109/ACCESS.2019.2946650
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Feng Cheng, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P108, DOI 10.1007/978-3-030-59719-1_11
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gupta S, 2015, INT J COMPUT VISION, V112, P133, DOI 10.1007/s11263-014-0777-6
   Kervadec H, 2019, PR MACH LEARN RES, V102, P285
   Kirillov A., 2020, P IEEECVF C COMPUTER, P9799, DOI DOI 10.48550/ARXIV.1912.08193
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Lai J., 2020, IEEE Trans. Image Process., V30, P431
   Liang Justin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9128, DOI 10.1109/CVPR42600.2020.00915
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2016, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2016.348
   Ling H, 2019, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR.2019.00540
   Luyan Liu, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12264), P332, DOI 10.1007/978-3-030-59719-1_33
   Marcos D, 2018, PROC CVPR IEEE, P8877, DOI 10.1109/CVPR.2018.00925
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sida Peng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8530, DOI 10.1109/CVPR42600.2020.00856
   Tianheng Cheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P660, DOI 10.1007/978-3-030-58568-6_39
   Wang J., 2020, IEEE T PATTERN ANAL, P5693
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Yuhui Yuan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P489, DOI 10.1007/978-3-030-58610-2_29
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhou P., 2020, P IEEE CVF C COMP VI, P10558
NR 37
TC 6
Z9 7
U1 1
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104169
DI 10.1016/j.imavis.2021.104169
EA APR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700010
DA 2024-07-18
ER

PT J
AU Liu, S
   Yang, JQ
   Agaian, SS
   Yuan, CH
AF Liu, Shao
   Yang, Jiaqi
   Agaian, Sos S.
   Yuan, Changhe
TI Novel features for art movement classification of portrait paintings
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image representations; Portrait art movement classification; Pattern
   recognition; Color feature; Texture feature; Feature selection
ID IMAGE; SCALE
AB The increasing availability of extensive digitized fine art collections opens up new research directions. In particular, correctly identifying the artistic style or art movement of paintings is crucial for large artistic database indexing, painter authentication, and mobile recognition of painters. Even though the implementation of CNN on artwork classification improved the performance dramatically compared to tradition classifier, the feature extraction methods are still valuable to help establishing better image representation for both common classifiers and neural networks. The main goal of this article is to present three novel features and a mature model structure for artistic movement recognition of portrait paintings. The proposed features include two unique color features and one texture feature: (a) Modified Color Distance (MCD), (b) ColorRatio Feature and (c) Weber's law Based Texture Feature. We demonstrate the superiority of our proposed method over the state-of-the-art approaches, and how successful our features are to support features from various neural networks. Another contribution of our work is a new portrait database that consists of 927 paintings from 6 different art movements. Extensive computer evaluations on this database show that we achieved an average accuracy of 98% for classifying two categories and 82.6% for classifying all 6 categories. Besides, our novel features improved the performance of pre trained CNN significantly.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Shao; Yang, Jiaqi] CUNY, Grad Ctr, New York, NY 10036 USA.
   [Agaian, Sos S.] CUNY, Coll Staten Isl, New York, NY USA.
   [Yuan, Changhe] CUNY, Queens Coll, New York, NY USA.
C3 City University of New York (CUNY) System; City University of New York
   (CUNY) System; College of Staten Island (CUNY); City University of New
   York (CUNY) System; Queens College NY (CUNY)
RP Yang, JQ (corresponding author), CUNY, Grad Ctr, New York, NY 10036 USA.
EM usaliushao@gmail.com; jyang2@gradcenter.cuny.edu;
   sos.agaian@csi.cuny.edu
RI Liu, Shao/JCE-2453-2023; Agaian, Sos s/IZE-1724-2023
OI Liu, Shao/0000-0002-7825-0881; Agaian, Sos s/0000-0003-4601-4507; YANG,
   JIAQI/0000-0002-2094-8515
CR A Sos S., 2000, IASTED INT C SIGN PR
   [Anonymous], 2016, Adaptive deep pyramid matching for remote sensing scene classification
   [Anonymous], 2012, J. Comput. Cult. Herit., DOI DOI 10.1145/2307723.2307726
   Arora RS, 2012, INT C PATT RECOG, P3541
   BOEY K, 2019, ELECT IMAGING, V13
   Chen L, 2017, ACM J COMPUT CULT HE, V10, DOI 10.1145/3003435
   Condorovici RG, 2015, J VIS COMMUN IMAGE R, V26, P222, DOI 10.1016/j.jvcir.2014.11.016
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Culjak M., 2011, 2011 Proceedings of 34th International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO 20111), P1634
   Florea Corneliu, 2016, CORR
   FUNT BV, 1995, IEEE T PATTERN ANAL, V17, P522, DOI 10.1109/34.391390
   Grigoryan Artyom, 2018, ELECT IMAGING, P1, DOI [10.2352/ISSN.2470-1173.2018.13.IPAS-383, DOI 10.2352/ISSN.2470-1173.2018.13.IPAS-383]
   Grigoryan AM, 2020, IEEE MULTIMEDIA, V27, P8, DOI 10.1109/MMUL.2019.2908624
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Huang YF, 2014, LECT NOTES ELECTR EN, V308, P159, DOI 10.1007/978-3-642-54900-7_23
   Karayev S., 2014, P BRIT MACH VIS C, P1, DOI [DOI 10.5244/C.28.122, 10.5244/c.28.122, 10.5244%2Fc.28.122, 10.5244/C.28.122]
   Khan FS, 2014, MACH VISION APPL, V25, P1385, DOI 10.1007/s00138-014-0621-6
   Kohl Jeanette, 2017, ARTIBUS HIST, V05, P2018
   Lecoutre A., 2017, ASIAN C MACHINE LEAR, P327
   Li Shan, 2018, ABS180408348 ARXIV
   Li XY, 2000, IEEE MULTIMEDIA, V7, P38, DOI 10.1109/93.848425
   Martinez-Conde Susana, 2015, WARPED PERCEPTIONS, V26, P23
   Milotta FLM, 2018, ACM J COMPUT CULT HE, V11, DOI 10.1145/3216463
   MRobert L., 2004, ART BRAIN
   Nanni L., 2020, GEN PURPOSE GENP BIO
   Novak C. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P599, DOI 10.1109/CVPR.1992.223129
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Rathore R, 2020, IEEE T VIS COMPUT GR, V26, P1226, DOI 10.1109/TVCG.2019.2934536
   Sanghavi F, 2017, PROC SPIE, V10221, DOI 10.1117/12.2262930
   Sartori A, 2016, IEEE MULTIMEDIA, V23, P44, DOI 10.1109/MMUL.2016.20
   Setlur V, 2016, IEEE T VIS COMPUT GR, V22, P698, DOI 10.1109/TVCG.2015.2467471
   Shamir L, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1670671.1670672
   Siddiquie B., 2009, The IEEE Winter Conference on Applications of Computer Vision (WACV) Workshop, P1, DOI DOI 10.1109/WACV.2009.5403040
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan WR, 2016, IEEE IMAGE PROC, P3703, DOI 10.1109/ICIP.2016.7533051
   Tang F, 2018, IEEE T VIS COMPUT GR, V24, P3019, DOI 10.1109/TVCG.2017.2774292
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   van Noord N, 2015, IEEE SIGNAL PROC MAG, V32, P46, DOI 10.1109/MSP.2015.2406955
   Wan QW, 2018, PROC SPIE, V10668, DOI 10.1117/12.2304898
   Wan QW, 2017, PROC SPIE, V10221, DOI 10.1117/12.2263598
   Wan Q, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON TEACHING, ASSESSMENT, AND LEARNING FOR ENGINEERING (TALE), P127, DOI 10.1109/TALE.2015.7386029
   Wang H, 2019, ACM J COMPUT CULT HE, V12, DOI 10.1145/3280790
   Yaniv J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322984
   Zhao Jing Liu Shan, 2019, J ELECTRON IMAGING, V280, DOI [10.1117/1.JEI.28.4.04300301-12-12, DOI 10.1117/1.JEI.28.4.04300301-12-12]
   Zhao YD, 2015, IEEE T VIS COMPUT GR, V21, P229, DOI 10.1109/TVCG.2014.2355221
   Zujovic J., 2009, P INT WORKSHOP MULTI, P1, DOI DOI 10.1109/MMSP.2009.5293271
NR 49
TC 13
Z9 13
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104121
DI 10.1016/j.imavis.2021.104121
EA MAR 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600012
DA 2024-07-18
ER

PT J
AU Zheng, QY
   Chen, Y
AF Zheng, Qiyuan
   Chen, Ying
TI Interactive multi-scale feature representation enhancement for small
   object detection*
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Small objects; Deep learning; Multi-scale feature
   fusion
AB In the field of detection, there is a wide gap between the performance of small objects and that of medium, large objects. Some studies show that this gap is due to the contradiction between the classification-based backbone and localization. Although the reduction in the feature map size is beneficial for the extraction of abstract features, it will cause the loss of detailed features in the localization as traversing the backbone. Therefore, an interactive multi-scale feature representation enhancement strategy is proposed. This strategy includes two modules: first a multi-scale auxiliary enhancement network is proposed for feature interaction under multiple inputs. We scale the input to multiple scales corresponding to the prediction layers, and only passes through the lightweight extraction module to extract more detailed features for enhancing the original futures. Moreover, an adaptive interaction module is designed to aggregate the features of adjacent layers. This approach provides flexibility in achieving the improvement of small objects detection ability without changing the original network structure. Comprehensive experimental results based on PASCAL VOC and MS COCO datasets show the effectiveness of the proposed method. ? 2021 Elsevier B.V. All rights reserved.
C1 [Zheng, Qiyuan; Chen, Ying] Jiangnan Univ, Key Lab Adv Proc Control Light Ind Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
C3 Jiangnan University
RP Chen, Y (corresponding author), Jiangnan Univ, Key Lab Adv Proc Control Light Ind Minist Educ, Wuxi 214122, Jiangsu, Peoples R China.
EM zhengqiyuan@stu.jiangnan.edu.cn; chenying@jiangnan.edu.cn
RI Ying, Chen/GRX-5695-2022; Chen, Ying/AAA-2911-2022
OI Chen, Ying/0000-0002-1674-0869
FU National Natural Science Foundation of China [61573168]
FX This work was supported by the National Natural Science Foundation of
   China (grant no. 61573168) .
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   [Anonymous], 2018, ARXIV180406215
   Bai Y, 2018, CHIN AUTOM CONGR, P4206, DOI 10.1109/CAC.2018.8623571
   Bochkovskiy A, 2020, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.2004.10934
   Dai Jifeng, 2016, Advances in Neural Information Processing Systems, DOI DOI 10.1016/J.JPOWSOUR.2007.02.075
   Duan K., 2019, IEEE T CIRCUITS SYST
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   Huang ZY, 2020, IEEE WINT CONF APPL, P1294, DOI [10.1109/WACV45572.2020.9093507, 10.1109/wacv45572.2020.9093507]
   Jeong J., 2017, P BRIT MACH VIS C, DOI [10.5244/C.31.76, DOI 10.5244/C.31.76]
   Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li WQ, 2019, IEEE IMAGE PROC, P3910, DOI [10.1109/ICIP.2019.8803543, 10.1109/icip.2019.8803543]
   Li Z., 2017, CORR
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mudassar BA, 2019, BMVC, P234
   Pan HD, 2020, SIGNAL PROCESS-IMAGE, V89, DOI 10.1016/j.image.2020.115987
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shi WX, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9204276
   Shrivastava A., 2016, ARXIV PREPRINT ARXIV
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Song KY, 2019, IEEE T CIRC SYST VID, V29, P2972, DOI 10.1109/TCSVT.2018.2875449
   Sun KK, 2021, IEEE T SYST MAN CY-S, V51, P3968, DOI 10.1109/TSMC.2019.2958072
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vinyals O., 2016, IEEE TPMAI, V39, P652, DOI DOI 10.1109/TPAMI.2016.2587640
   Wu XW, 2020, NEUROCOMPUTING, V401, P1, DOI 10.1016/j.neucom.2020.02.116
   Zhai SP, 2020, IEEE ACCESS, V8, P24344, DOI 10.1109/ACCESS.2020.2971026
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang Y, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11010009
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou P, 2018, PROC CVPR IEEE, P528, DOI 10.1109/CVPR.2018.00062
NR 48
TC 10
Z9 11
U1 0
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104128
DI 10.1016/j.imavis.2021.104128
EA FEB 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600008
DA 2024-07-18
ER

PT J
AU Zheng, MJ
   Lei, ZJ
   Zhang, K
AF Zheng, Minjuan
   Lei, Zhijun
   Zhang, Kun
TI Intelligent detection of building cracks based on deep learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Building crack detection; Multi-feature fusion; Image
   segmentation; RFCN; FCN; R-CNN
AB In order to solve the damage caused by the concrete structure, which leads to the reduction of the life of infrastructure, endangers the safety of pedestrians, and has a serious impact on the social economy, building crack detection-model of FCN (Fully Convolutional Networks), R-CNN (Regionswith CNN feature) and RFCN (Richer Fully Convolutional Networks) has been proposed based on the convolutional neural network model to amplify and extract the features of the data and previous studies. Through the training of building surface data such as roads, bridges, houses and dams, themodel is analyzed in terms ofmorphological and geometric indexes. Finally, the model of crack picture detection and segmentation based on deep learning is used for picture performance detection and comprehensive evaluation. The results show that: in the aspect of building gap detection, the RFCN model has the best processing effect, the gap recognition degree is higher, and the detail processing is better. In the aspect ofmodel evaluation index, the correct rate of RFCN model is increased by 10%, the accuracy rate is increased by 12%, the recall rate is increased by 8%, the loss rate is increased by 3%, and the overall stability is higher. In the aspect of comprehensive performance, the picture processing performance is better than the FCN model by 7% and better than the R-CNN model by 15%, and thememory share is 80%. The fusionmodel based on deep learning and picture processing has been improved in many aspects, which can provide strong theoretical support and practical value for the detection and research of concrete surface cracks such as bridges, dams, highways and houses. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Zheng, Minjuan; Lei, Zhijun; Zhang, Kun] Xian Shiyou Univ, Capital Construct Dept, Xian 710065, Shaanxi, Peoples R China.
C3 Xi'an Shiyou University
RP Zheng, MJ (corresponding author), Xian Shiyou Univ, Capital Construct Dept, Xian 710065, Shaanxi, Peoples R China.
EM mjzheng@xsyu.edu.cn
RI Zhang, Kun/HHS-5016-2022
CR Dung CV, 2019, AUTOMAT CONSTR, V99, P52, DOI 10.1016/j.autcon.2018.11.028
   Cha YJ, 2017, C PROC SOC EXP MECH, P71, DOI 10.1007/978-3-319-54777-0_9
   Cha YJ, 2017, COMPUT-AIDED CIV INF, V32, P361, DOI 10.1111/mice.12263
   Chaiyasarn K, 2018, INT J GEOMATE, V15, P240, DOI 10.21660/2018.51.35376
   Chen C, 2017, ATMOS ENVIRON, V170, P143, DOI 10.1016/j.atmosenv.2017.09.035
   da Costa AZ, 2020, BIOSYST ENG, V190, P131, DOI 10.1016/j.biosystemseng.2019.12.003
   Deng JH, 2020, COMPUT-AIDED CIV INF, V35, P373, DOI 10.1111/mice.12497
   Gavai G., 2019, ELECT IMAGING, V2019, P360
   Hao M, 2017, CYBERN INF TECHNOL, V17, P119, DOI 10.1515/cait-2017-0021
   He T, 2019, IEEE ACCESS, V7, P123453, DOI 10.1109/ACCESS.2019.2937461
   Hola J, 2019, ENG FAIL ANAL, V97, P1, DOI 10.1016/j.engfailanal.2018.12.007
   Jiao J, 2019, FRONT ARCHIT RES, V8, P348, DOI 10.1016/j.foar.2019.06.005
   Li JN, 2018, IEEE T MULTIMEDIA, V20, P985, DOI 10.1109/TMM.2017.2759508
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Masood A., 2020, IEEE T IND INFORM, P2240
   Hoang DN, 2018, ADV CIV ENG, V2018, DOI 10.1155/2018/3924120
   Onsachi J., 2018, AFR J ENV NAT SCI RE, V1, P76
   Qin HF, 2017, IEEE T INF FOREN SEC, V12, P1816, DOI 10.1109/TIFS.2017.2689724
   Sarker M., 2017, ISPRS INT ARCH PHOTO, VXLII-2/W8, P237, DOI [10.5194/isprs-archives-XLII-2-W8-237-2017, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W8-237-2017]
   Sharma A., 2020, ARCHITECTURE ART, P542
   Silvestre-Blanes J, 2019, AUTEX RES J, V19, P363, DOI 10.2478/aut-2019-0035
   Sivakumar A, 2007, CEMENT CONCRETE COMP, V29, P603, DOI 10.1016/j.cemconcomp.2007.03.006
   Sorensen D., 2019, AGUFM, V2019, P46
   Turkan Y, 2018, AUTOMAT CONSTR, V94, P191, DOI 10.1016/j.autcon.2018.06.017
   Wang XL, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON TRANSPORTATION INFORMATION AND SAFETY (ICTIS), P917, DOI 10.1109/ICTIS.2017.8047878
   Xu Y, 2019, STRUCT HEALTH MONIT, V18, P653, DOI 10.1177/1475921718764873
   Zhang A, 2017, COMPUT-AIDED CIV INF, V32, P805, DOI 10.1111/mice.12297
NR 27
TC 34
Z9 36
U1 1
U2 99
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 103987
DI 10.1016/j.imavis.2020.103987
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000005
DA 2024-07-18
ER

PT J
AU Yin, YS
   Antonio, J
AF Yin, Yongsheng
   Antonio, Juan
TI Application of 3D laser scanning technology for image data processing in
   the protection of ancient building sites through deep learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D laser measuring technology; Deep learning; Point cloud data; 3D model
   construction; Chinese traditional architecture; Architectural heritage
AB To study the conservation of architectural heritage, computer algorithms are used to process the artificial field measurements and reference data maps. A 3D virtual model of traditional architecture is constructed for the direct learning and feature extraction from image data through deep learning. A set of tools and processes for pixellevel image processing labeling arc proposed, and a label quality checking tool is written specially. Through the training method of transfer learning, the convergence speed and accuracy of the network are accelerated and improved. Based on the field data collection of the architectural heritage by a 3D laser scanner, the impacts of the number of stations, the number of targets, and the distance on the data scanning results are analyzed, thereby drawing the rules and principles of setting up the survey stations. While processing the point cloud data, for the redundant data and the rough difference points found in the original point cloud data, the program is written by the gross error elimination algorithm, which realizes the automatic elimination of the point cloud gross error data and provides a convenient method for data processing. The data collection, data processing, and model construction of architectural heritage are performed by the 3D laser scanner. The 3D models of traditional architecture with texture photos are obtained. The results show that through correlation error analysis and model evaluation, the requirements for the measurement of traditional architecture can be achieved. Therefore, the technology has a guiding significance for the conservation of traditional architecture, which proves that the 3D laser scanner has broad application prospects in the surveying and mapping of architectural heritage. (C) 2020 Published by Elsevier B.V.
C1 [Yin, Yongsheng] Tianjin Univ, Sch Architecture, Tianjin 300072, Peoples R China.
   [Yin, Yongsheng; Antonio, Juan] Univ Exeter, Coll Humanities, Exeter EX4 3RA, Devon, England.
C3 Tianjin University; University of Exeter
RP Yin, YS (corresponding author), Tianjin Univ, Sch Architecture, Tianjin 300072, Peoples R China.; Yin, YS (corresponding author), Univ Exeter, Coll Humanities, Exeter EX4 3RA, Devon, England.
EM yinyongsheng1989@126.com
FU Major Program of the National Social Science Foundation of China
   [14ZDB025]; National Natural Science Foundation of China [51508377];
   China Scholarship Council [201806250156]
FX Project supported by the Major Program of the National Social Science
   Foundation of China (NO. 14ZDB025), National Natural Science Foundation
   of China (NO. 51508377) and China Scholarship Council (NO.
   201806250156).
CR [Anonymous], FORESTS
   [Anonymous], 2019, QUFU SHIFAN DAXUE X, DOI DOI 10.3969/j.issn.1001-5337.2019.3.023
   Bacharidis K, 2018, ISPRS INT J GEO-INF, V7, DOI 10.3390/ijgi7040151
   Chen C, 2018, ROBOTICS, V7, DOI 10.3390/robotics7030045
   Chu X., 2018, Instrumentation Mesures Metrologies, V18, P113, DOI [10.3166/i2m.17.113-130, DOI 10.3166/I2M.17.113-130]
   Delegou ET, 2019, HERITAGE-BASEL, V2, P1211, DOI 10.3390/heritage2020079
   Deng YB, 2019, FORESTS, V10, DOI 10.3390/f10080660
   Forcellini D, 2019, INNOV INFRASTRUCT SO, V4, DOI 10.1007/s41062-019-0207-2
   Hess M, 2018, STRUCT INFRASTRUCT E, V14, P247, DOI 10.1080/15732479.2017.1349810
   Hoerner MR, 2018, AM J ROENTGENOL, V211, P1283, DOI 10.2214/AJR.17.19489
   Ishutov S, 2018, AAPG BULL, V102, P1, DOI 10.1306/0329171621117056
   Napolitano R, 2019, HERITAGE-BASEL, V2, P151, DOI 10.3390/heritage2010012
   Pan Y, 2019, REMOTE SENS-BASEL, V11, DOI 10.3390/rs11101204
   Qiu AG, 2018, OPEN GEOSCI, V10, P491, DOI 10.1515/geo-2018-0039
   Qiu ZX, 2018, FORESTS, V9, DOI 10.3390/f9120735
   Shanoer MM., 2018, The Egyptian Journal of Remote Sensing and Space Science, V21, P295
   Song LM, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18092981
   Wang FF, 2019, GEOTECH GEOL ENG, V37, P1483, DOI 10.1007/s10706-018-0701-x
   Wang JW, 2019, ACS SENSORS, V4, P1476, DOI 10.1021/acssensors.9b00681
   Wang J, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132588
   Zhang PH, 2018, OPEN GEOSCI, V10, P113, DOI 10.1515/geo-2018-0009
   Zhao C, 2019, HERIT SCI, V7, DOI 10.1186/s40494-019-0280-z
   Zhao GL, 2018, BIORESOURCES, V13, P1548, DOI 10.15376/biores.13.1.1548-1562
   Zhao Q, 2019, FORESTS, V10, DOI 10.3390/f10090767
   Zhou NQ, 2019, ADV STRUCT ENG, V22, P1225, DOI 10.1177/1369433218811533
   Zhu M, 2018, AIMS MATH, V3, P426, DOI 10.3934/Math.2018.3.426
NR 26
TC 21
Z9 23
U1 6
U2 93
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103969
DI 10.1016/j.imavis.2020.103969
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700005
DA 2024-07-18
ER

PT J
AU Fu, HC
   Zhou, WN
   Wang, XF
   Zhang, HL
AF Fu, Hengcheng
   Zhou, Wuneng
   Wang, Xiaofeng
   Zhang, Huanlong
TI Fast and robust visual tracking with hard balanced focal loss and guided
   domain adaption
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Siamese network; Domain adaptation; Hard balanced focal
   loss
ID OBJECT TRACKING; SIAMESE NETWORKS
AB Recently, Siamese networks based trackers have shown excellent performance in accuracy and speed. However, previous studies treat all training samples equally and use the general feature space without adapting to the specific video during tracking. These trackers ignore the class data imbalance during training and the feature space difference between the generic domain and the current tracking target domain, which limits the robustness of trackers. In this paper, we propose an algorithm for learning a discriminative and self-adaptive feature representation, in order to achieve accurate and robust tracking. During the off-line training stage, a hard balanced focal loss function is utilized to solve the positive-negative samples imbalance and the hard-easy negative samples imbalance. During the tracking phase, an off-line trained guided domain adaptation module is embedded into the Siamese networks, which can quickly transfer the feature space from the general domain to the current video domain by adjusting the search branch channel weights. Our networks are trained in an end-to-end manner and without online updating. Our tracker runs at 130 FPS while achieving favorable performance against the state-of-the-art methods on OTB-2013, OTB-2015, VOT-2016, VOT-2017, GOT-10 K and TC-128 benchmarks. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Fu, Hengcheng; Zhou, Wuneng; Wang, Xiaofeng] Donghua Univ, Coll Informat Sci & Technol, Shanghai 201620, Peoples R China.
   [Zhang, Huanlong] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, 5 Dongfeng Rd, Zhengzhou, Peoples R China.
   [Zhou, Wuneng] Donghua Univ, Engn Res Ctr Digitized Text & Fash Technol, Shanghai 201620, Peoples R China.
C3 Donghua University; Zhengzhou University of Light Industry; Donghua
   University
RP Zhou, WN; Wang, XF (corresponding author), Donghua Univ, Coll Informat Sci & Technol, Shanghai 201620, Peoples R China.
EM 2181342@mail.dhu.edu.cn; wnzhou@dhu.edu.cn; xiaofeng_wang@dhu.edu.cn
OI Wang, Xiaofeng/0000-0002-8134-0917
FU National Natural Science Foundation of China [61573095, 61903077,
   61873246]; Special Project Funding for the Shanghai Municipal Commission
   of Economy and Information Civil-Military Inosculation Project; Shanghai
   Sailing Program [19YF1402500]
FX This work is partially supported by the National Natural Science
   Foundation of China (No. 61573095, 61903077, 61873246), the Special
   Project Funding for the Shanghai Municipal Commission of Economy and
   Information Civil-Military Inosculation Project (No. JMRH-2018-1042) and
   the Shanghai Sailing Program (No.19YF1402500). Also, we are very
   grateful to editors and reviewers for their insightful comments and
   suggestions.
CR [Anonymous], 2019, ARXIV181011981
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Chen YH, 2018, PROC CVPR IEEE, P7892, DOI 10.1109/CVPR.2018.00823
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P621, DOI 10.1109/ICCVW.2015.84
   Dong XP, 2018, LECT NOTES COMPUT SC, V11217, P472, DOI 10.1007/978-3-030-01261-8_28
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Gao JY, 2017, IEEE T IMAGE PROCESS, V26, P1845, DOI 10.1109/TIP.2017.2656628
   Gundogdu E, 2018, IEEE T IMAGE PROCESS, V27, P2526, DOI 10.1109/TIP.2018.2806280
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang C, 2017, IEEE I CONF COMP VIS, P105, DOI 10.1109/ICCV.2017.21
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Kristan M, 2016, LECT NOTES COMPUT SC, V9914, P777, DOI 10.1007/978-3-319-48881-3_54
   Kuniaki S., 2016, P EUR C COMP VIS, P4
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Ma C, 2016, IEEE SIGNAL PROC LET, V23, P1454, DOI 10.1109/LSP.2016.2601691
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Pu S., 2018, ADV NEURAL INFORM PR, V31, P1931, DOI DOI 10.1016/J.PATCOG.2018.10.005
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Sun C, 2018, PROC CVPR IEEE, P8962, DOI 10.1109/CVPR.2018.00934
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wei DM, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278040
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang H., 2019, IEEE ACCESS, V7
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhu Z, 2018, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2018.00064
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
   Zuo WM, 2019, IEEE T PATTERN ANAL, V41, P1158, DOI 10.1109/TPAMI.2018.2829180
NR 55
TC 2
Z9 2
U1 1
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2020
VL 100
AR 103929
DI 10.1016/j.imavis.2020.103929
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA MY9GX
UT WOS:000558728800001
DA 2024-07-18
ER

PT J
AU Zhou, JM
   Roy, SK
   Fang, PF
   Harandi, M
   Petersson, L
AF Zhou, Jieming
   Roy, Soumava Kumar
   Fang, Pengfei
   Harandi, Mehrtash
   Petersson, Lars
TI Cross-Correlated Attention Networks for Person Re-Identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Attention; Feature extraction; Cross correlation; Person
   Re-Identification; Surveillance
AB Deep neural networks need to make robust inference in the presence of occlusion, background clutter, pose and viewpoint variations -to name a few- when the task of person re-identification is considered. Attention mechanisms have recently proven to be successful in handling the aforementioned challenges to some degree. However previous designs fail to capture inherent inter-dependencies between the attended features; leading to restricted interactions between the attention blocks. In this paper, we propose a new attention module called Cross-Correlated Attention (CCA); which aims to overcome such limitations by maximizing the information gain between different attended regions. Moreover, we also propose a novel deep network that makes use of different attention mechanisms to learn robust and discriminative representations of person images. The resulting model is called the Cross-Correlated Attention Network (COIN). Extensive experiments demonstrate that the CCAN comfortably outperforms current state-of-the-art algorithms by a tangible margin.
   Modeling the inherentspatial relations between different attended regions within the deep architecture. joint end-to-end cross correlated attention and representational learning. State-of-the-art results in terms of mAP and Rank-1 accuracies across several challenging datasets. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zhou, Jieming; Roy, Soumava Kumar; Fang, Pengfei] Australian Natl Univ, Canberra, ACT 2601, Australia.
   [Harandi, Mehrtash] Monash Univ, Wellington Rd, Clayton, Vic 3800, Australia.
   [Petersson, Lars] CSIRO, Data61, Canberra, ACT 2601, Australia.
C3 Australian National University; Monash University; Commonwealth
   Scientific & Industrial Research Organisation (CSIRO)
RP Zhou, JM (corresponding author), Australian Natl Univ, Canberra, ACT 2601, Australia.
EM Jieming.Zhou@anu.edu.au; Soumava.KumarRoy@anu.edu.au;
   Pengfei.Fang@anu.edu.au; mehrtash.harandi@monash.edu;
   lars.petersson@data61.csiro.au
RI Petersson, Lars/C-2568-2019; Fang, Pengfei/GQB-2393-2022; Harandi,
   Mehrtash/D-6586-2018
OI Petersson, Lars/0000-0002-0103-1904; Harandi,
   Mehrtash/0000-0002-6937-6300
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   Chang X., 2018, IEEE C COMP VIS PATT, V1
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen DP, 2016, PROC CVPR IEEE, P1268, DOI 10.1109/CVPR.2016.142
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   DeCann B, 2015, IET BIOMETRICS, V4, P209, DOI 10.1049/iet-bmt.2015.0061
   Fang W, 2019, ADJUNCT PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR-ADJUNCT 2019), P4, DOI 10.1109/ISMAR-Adjunct.2019.00016
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaderberg Max, 2015, ADV NEURAL INFORM PR, P8
   Kingma D. P., 2014, arXiv
   Li D., ARXIV160307054
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Li Y, 2014, TUMOR BIOL, V35, P10011, DOI 10.1007/s13277-014-1921-1
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Paszke Adam, 2017, NIPS W
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarfraz M. Saquib, 2018, IEEE C COMP VIS PATT, V1
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen YJ, 2018, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2018.00092
   Shen Yunhang, 2020, EUR C COMP VIS ECCV
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song HO, 2017, PROC CVPR IEEE, P2206, DOI 10.1109/CVPR.2017.237
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YJ, 2015, 2015 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING (GLOBALSIP), P820, DOI 10.1109/GlobalSIP.2015.7418311
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang H., ARXIV161201341
   Wang XL, 2017, PROC CVPR IEEE, P3366, DOI 10.1109/CVPR.2017.359
   Wang YZ, 2018, INT J COGN INFORM NA, V12, P14, DOI 10.4018/IJCINI.2018010102
   Wei L, 2016, PROCEEDINGS OF THE 23RD INTERNATIONAL BUSINESS ANNUAL CONFERENCE (2016), BKS ONE AND TWO, P79
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu CY, 2017, IEEE I CONF COMP VIS, P2859, DOI 10.1109/ICCV.2017.309
   Xiong K, 2014, NETW TELECOMMUN SER, P1, DOI 10.1002/9781118898598
   Xu X, 2015, IEEE ICC, P2048, DOI 10.1109/ICC.2015.7248627
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L., 2017, ARXIV170107732CSCV
   Zheng L., 2015, IEEE INT C COMP VIS
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng P, 2016, INT J INNOV, V4, P13, DOI 10.5585/iji.v4i1.79
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhou S, 2018, I C CONT AUTOMAT ROB, P407, DOI 10.1109/ICARCV.2018.8581098
NR 66
TC 13
Z9 14
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2020
VL 100
AR 103931
DI 10.1016/j.imavis.2020.103931
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA MY9GX
UT WOS:000558728800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Moreau, A
   Mancas, M
   Dutoit, T
AF Moreau, Ambroise
   Mancas, Matei
   Dutoit, Thierry
TI Depth prediction from 2D images: A taxonomy and an evaluation study
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth prediction; Machine learning; Deep learning; Computer vision
AB Among the various cues that help us understand and interact with our surroundings, depth is of particular importance. It allows us to move in space and grab objects to complete different tasks. Therefore, depth prediction has been an active research field for decades and many algorithms have been proposed to retrieve depth. Some imitate human vision and compute depth through triangulation on correspondences found between pixels or handcrafted features in different views of the same scene. Others rely on simple assumptions and semantic knowledge of the structure of the scene to get the depth information. Recently, numerous algorithms based on deep learning have emerged from the computer vision community. They implement the same principles as the non-deep learning methods and leverage the ability of deep neural networks of automatically learning important features that help to solve the task. By doing so, they produce new state-of-the-art results and show encouraging prospects. In this article, we propose a taxonomy of deep learning methods for depth prediction from 2D images. We retained the training strategy as the sorting criterion. Indeed, some methods are trained in a supervised manner which means depth labels are needed during training while others are trained in an unsupervised manner. In that case, the models learn to perform a different task such as view synthesis and depth is only a by-product of this learning. In addition to this taxonomy, we also evaluate nine models on two similar datasets without retraining. Our analysis showed that (i) most models are sensitive to sharp discontinuities created by shadows or colour contrasts and (ii) the post processing applied to the results before computing the commonly used metrics can change the model ranking. Moreover, we showed that most metrics agree with each other and are thus redundant. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Moreau, Ambroise; Mancas, Matei; Dutoit, Thierry] Univ Mons, ISIA Lab, Blvd Dolez 31, B-7000 Mons, Belgium.
C3 University of Mons
RP Moreau, A (corresponding author), Univ Mons, ISIA Lab, Blvd Dolez 31, B-7000 Mons, Belgium.
EM Ambroise.moreau@umons.ac.be; matei.mancas@umons.ac.be;
   thierry.dutoit@umons.ac.be
FU University of Mons, Belgium - European Regional Development Fund (ERDF)
   [ETR 1212 0000 3303]
FX Ambroise Moreau is funded through a PhD grant from the University of
   Mons, Belgium.; This research is partially funded by the European
   Regional Development Fund (ERDF) under the grant number ETR 1212 0000
   3303.
CR [Anonymous], 2009, CENGAGE LEARNING
   [Anonymous], MULTIPLE VIEW GEOMET
   Baker S, 2007, IEEE I CONF COMP VIS, P588, DOI 10.1109/cvpr.2007.383191
   Bianco S, 2018, J IMAGING, V4, DOI 10.3390/jimaging4080098
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   COREN S, 1972, PSYCHOL REV, V79, P359, DOI 10.1037/h0032940
   COURTNEY JW, 1984, PATTERN RECOGN, V17, P585, DOI 10.1016/0031-3203(84)90012-8
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Eigen D, 2014, ADV NEUR IN, V27
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285
   Fehn C., 2002, PROC INT BROADCAST C, P357
   Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430
   Gandhi T., 2006, INT TRANSP SYST C 20, P976
   Garg R, 2016, LECT NOTES COMPUT SC, V9912, P740, DOI 10.1007/978-3-319-46484-8_45
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Hoiem D, 2005, ACM T GRAPHIC, V24, P577, DOI 10.1145/1073204.1073232
   Howard J, 2012, FEW HONEST WORDS: THE KENTUCKY ROOTS OF POPULAR MUSIC, P1
   Kanade T, 2004, IEEE DECIS CONTR P, P1655, DOI 10.1109/CDC.2004.1430282
   Karsch K, 2014, IEEE T PATTERN ANAL, V36, P2144, DOI 10.1109/TPAMI.2014.2316835
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377
   Lafferty John D, 2001, P 18 INT C MACH LEAR, P282, DOI DOI 10.5555/645530.655813
   Lenz I, 2015, INT J ROBOT RES, V34, P705, DOI 10.1177/0278364914549607
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu FY, 2016, IEEE T PATTERN ANAL, V38, P2024, DOI 10.1109/TPAMI.2015.2505283
   Liu FY, 2015, PROC CVPR IEEE, P5162, DOI 10.1109/CVPR.2015.7299152
   Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Michels J., 2005, P 22 INT C MACHINE L, P593, DOI [10.1145/1102351.1102426, DOI 10.1145/1102351.1102426]
   OSHEA RP, 1994, VISION RES, V34, P1595, DOI 10.1016/0042-6989(94)90116-3
   Özyesil O, 2017, ACTA NUMER, V26, P305, DOI 10.1017/S096249291700006X
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Saxena A., 2006, NIPS, P1161, DOI DOI 10.1109/TPAMI.2015.2505283A
   Saxena A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2197
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   TROSCIANKO T, 1991, VISION RES, V31, P1923, DOI 10.1016/0042-6989(91)90187-A
   ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006
   Ummenhofer B, 2017, PROC CVPR IEEE, P5622, DOI 10.1109/CVPR.2017.596
   Vijayanarasimhan S., ARXIV170407804
   Wang CY, 2018, PROC CVPR IEEE, P2022, DOI 10.1109/CVPR.2018.00216
   Xie JY, 2016, LECT NOTES COMPUT SC, V9908, P842, DOI 10.1007/978-3-319-46493-0_51
   Yang Q., 2008, P BRIT MACH VIS C LE, P1, DOI [10.5244/C.22.72, DOI 10.5244/C.22.72]
   Zhang L, 2011, IEEE T BROADCAST, V57, P372, DOI 10.1109/TBC.2011.2122930
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 52
TC 0
Z9 0
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103825
DI 10.1016/j.imavis.2019.11.003
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000012
DA 2024-07-18
ER

PT J
AU Muhammad, S
   Dailey, MN
   Farooq, M
   Majeed, MF
   Ekpanyapong, M
AF Muhammad, Siraj
   Dailey, Matthew N.
   Farooq, Muhammad
   Majeed, Muhammad F.
   Ekpanyapong, Mongkol
TI Spec-Net and Spec-CGAN: Deep learning models for specularity removal
   from faces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Specularity; Dichromatic reflection model; Deep learning; Convolutional
   neural networks
ID REFLECTION COMPONENTS; IMAGE
AB The process of splitting an image into specular and diffuse components is a fundamental problem in computer vision, because most computer vision algorithms, such as image segmentation and tracking, assume diffuse surfaces, so existence of specular reflection can mislead algorithms to make incorrect decisions. Existing decomposition methods tend to work well for images with low specularity and high chromaticity, but they fail in cases of high intensity specular light and on images with low chromaticity. In this paper, we address the problem of removing high intensity specularity from low chromaticity images (faces). We introduce a new dataset, Spec-Face, comprising face images corrupted with specular lighting and corresponding ground truth diffuse images. We also introduce two deep learning models for specularity removal, Spec-Net and Spec-CGAN. Spec-Net takes an intensity channel as input and produces an output image that is very close to ground truth, while Spec-CGAN takes an RGB image as input and produces a diffuse image very similar to the ground truth RGB image. On Spec-Face, with Spec-Net, we obtain a peak signal-to-noise ratio (PSNR) of 3.979, a local mean squared error (LMSE) of 0.000071, a structural similarity index (SSIM) of 0.899, and a Frechet Inception Distance (FID) of 20.932. With Spec-CGAN, we obtain a PSNR of 3.360, a LMSE of 0.000098, a SSIM of 0.707, and a FID of 31.699. With Spec-Net and Spec-CGAN, it is now feasible to perform specularity removal automatically prior to other critical complex vision processes for real world images, i.e., faces. This will potentially improve the performance of algorithms later in the processing stream, such as face recognition and skin cancer detection. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Muhammad, Siraj; Dailey, Matthew N.; Farooq, Muhammad; Ekpanyapong, Mongkol] AIT, Pathum Thani, Thailand.
   [Muhammad, Siraj; Majeed, Muhammad F.] SBBU, Dept Comp Sci, Dir U, KP, Pakistan.
C3 Asian Institute of Technology
RP Muhammad, S (corresponding author), AIT, Pathum Thani, Thailand.
EM Siraj.Muhammad@ait.ac.th; mdailey@ait.ac.th; Muhammad.farooq@ait.ac.th;
   m.faran.majeed@ieee.org; mongkol@ait.ac.th
RI Farooq, Muhammad/JXN-5140-2024
OI Farooq, Muhammad/0000-0003-0704-3372; Majeed, Muhammad
   Faran/0000-0001-9734-1191
FU Shaheed Benazir Bhutto University, Sheringal, Dir(U), KP, Pakistan;
   Asian Institute of Technology (AIT)
FX This research was supported by graduate fellowships from Shaheed Benazir
   Bhutto University, Sheringal, Dir(U), KP, Pakistan and the Asian
   Institute of Technology (AIT) to Siraj Muhammad.
CR Akashi Y, 2016, COMPUT VIS IMAGE UND, V146, P77, DOI 10.1016/j.cviu.2015.09.001
   Angel Edward., 2008, Interactive Computer Graphics: A Top-Down Approach Using OpenGL, V5th
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2018, P EUR C COMP VIS ECC
   [Anonymous], P EUR C COMP VIS ECC
   Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Fu XY, 2017, PROC CVPR IEEE, P1715, DOI 10.1109/CVPR.2017.186
   Guo J, 2018, LECT NOTES COMPUT SC, V11208, P282, DOI 10.1007/978-3-030-01225-0_17
   Han S, 2012, PROC CVPR IEEE, P805, DOI 10.1109/CVPR.2012.6247752
   Hong H, 2018, IEEE T COMPUT AID D, V37, P2952, DOI 10.1109/TCAD.2018.2857339
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Kingma D. P., 2014, arXiv
   Li C, 2017, PROC CVPR IEEE, P2780, DOI 10.1109/CVPR.2017.297
   Meka A, 2018, PROC CVPR IEEE, P6315, DOI 10.1109/CVPR.2018.00661
   Miyazaki D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P982
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409
   Shen HL, 2008, PATTERN RECOGN, V41, P2461, DOI 10.1016/j.patcog.2008.01.026
   Shen HL, 2013, APPL OPTICS, V52, P4483, DOI 10.1364/AO.52.004483
   Shi J, 2017, PROC CVPR IEEE, P5844, DOI 10.1109/CVPR.2017.619
   Tan RT, 2005, IEEE T PATTERN ANAL, V27, P178, DOI 10.1109/TPAMI.2005.36
   Yang QX, 2015, IEEE T PATTERN ANAL, V37, P1304, DOI 10.1109/TPAMI.2014.2360402
   Yang QX, 2015, INT J COMPUT VISION, V112, P307, DOI 10.1007/s11263-014-0764-y
   Zhang C, 2011, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2011.5995704
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou BJ, 2013, J INF SCI ENG, V29, P835
NR 32
TC 15
Z9 17
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103823
DI 10.1016/j.imavis.2019.11.001
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000010
DA 2024-07-18
ER

PT J
AU Mhalla, A
   Chateau, T
   Ben Amara, NE
AF Mhalla, Ala
   Chateau, Thierry
   Ben Amara, Najoua Essoukri
TI Spatio-temporal object detection by deep learning: Video-interlacing to
   improve multi-object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-object tracking; Interlacing and inverse interlacing models;
   Specialization; Interlaced deep detector
AB Tracking-by-detection have become a hot topic of great interest to some computer vision applications in the recent years. Generally, the existing tracking-by-detection frameworks have difficulties with congestion, occlusion, and inaccurate detection in crowded scenes. In this paper, we propose a new framework for Multi-Object Tracking-by-Detection (MOT-bD) based on a spatio-temporal interlaced encoding video model and a specialized Deep Convolutional Neural Network (DCNN) detector. The spatio-temporal variation of objects between images are encoded into "interlaced images". A specialized "interlaced object" convolutional deep detector is trained to detect objects in interlaced images and a classical association algorithm to perform the association between detected objects, since interlaced objects are built to increase overlap during the association step which leads to improve the MOT performance over the same detector/association algorithm applied on non-interlaced images.
   The effectiveness and robustness of this contribution is demonstrated by experiments on popular tracking-by-detection datasets and benchmarks such as the PETS, TUD and the MOT17 benchmark. Experimental results demonstrate that interlacing video idea has many advantages to improve the tracking performances in terms of both precision and accuracy of tracking and illustrate that the "power of video-interlacing" outperforms several state-of-the-art tracking frameworks in multiple object tracking. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Mhalla, Ala; Chateau, Thierry] Univ Clermont Auvergne, Inst Pascal, F-63000 Clermont Ferrand, France.
   [Ben Amara, Najoua Essoukri] Univ Sousse, Natl Engn Sch Sousse, LATIS ENISo, Sousse, Tunisia.
C3 Universite Clermont Auvergne (UCA); Universite de Sousse
RP Mhalla, A (corresponding author), Univ Clermont Auvergne, Inst Pascal, F-63000 Clermont Ferrand, France.
EM ala.mhalla@uca.fr; thierry.chateau@uca.fr; najoua.benamara@eniso.rnu.tn
FU French government research program "Investissements d'avenir" through
   the IMobS3 Laboratory of Excellence [ANR-10-LABX-16-01]; European Union
   through the program Regional competitiveness and employment 2007-2013
   (ERDF - Auvergne region); Tunisian Ministry of Higher Education 82
   Scientific Research
FX This work is within the scope of a co -guardianship between the
   University of Sousse (Tunisia) and Clermont Auvergne University
   (France). It is sponsored by the French government research program
   "Investissements d'avenir" through the IMobS3 Laboratory of Excellence
   (ANR-10-LABX-16-01), by the European Union through the program Regional
   competitiveness and employment 2007-2013 (ERDF - Auvergne region), and
   by the Tunisian Ministry of Higher Education 82 Scientific Research.
CR Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583
   [Anonymous], IEEE T INTELLIGENT T
   [Anonymous], 2019, CVPR
   Badie J, 2014, 2014 11TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P25, DOI 10.1109/AVSS.2014.6918639
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bulò SR, 2017, PROC CVPR IEEE, P7082, DOI 10.1109/CVPR.2017.749
   Chari V, 2015, PROC CVPR IEEE, P5537, DOI 10.1109/CVPR.2015.7299193
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Dehghan A., 2017, IEEE T PATTERN ANAL
   Dorai Y, 2017, PROCEEDINGS OF THE 12TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISIGRAPP 2017), VOL 6, P492, DOI 10.5220/0006155204920498
   Ess A, 2008, PROC CVPR IEEE, P1857
   Ferris J, 2009, PALG STUD THEAT PERF, P1
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Han B, 2017, PROC CVPR IEEE, P521, DOI 10.1109/CVPR.2017.63
   Han M., 2004, IEEE C COMP VIS PATT, V1
   Henschel R, 2018, IEEE COMPUT SOC CONF, P1509, DOI 10.1109/CVPRW.2018.00192
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Huang Z., 2017, P IEEE C COMP VIS PA, P4021, DOI DOI 10.1109/CVPR.2017.510
   Ju J, 2017, J OPT SOC AM A, V34, P280, DOI 10.1364/JOSAA.34.000280
   Kalogerakis E, 2017, PROC CVPR IEEE, P6630, DOI 10.1109/CVPR.2017.702
   Kim C, 2015, IEEE I CONF COMP VIS, P4696, DOI 10.1109/ICCV.2015.533
   Kim IK, 2016, IEEE INT CONF CLOUD, P1, DOI [10.1109/CLOUD.2016.9, 10.1109/CLOUD.2016.0011]
   Kumar BGV, 2016, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2016.581
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Lee BJ, 2004, IEE P-RADAR SON NAV, V151, P344, DOI 10.1049/ip-rsn:20040894
   Li LQ, 2017, ITM WEB CONF, V12, DOI 10.1051/itmconf/20171205004
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   McLaughlin N, 2015, IEEE WINT CONF APPL, P71, DOI 10.1109/WACV.2015.17
   Mhalla A, 2017, COMPUT VIS IMAGE UND, V164, P3, DOI 10.1016/j.cviu.2017.06.008
   Milan A., 2016, ARXIV160300831
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Milan A, 2013, PROC CVPR IEEE, P3682, DOI 10.1109/CVPR.2013.472
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun Y., 2003, ADV NEURAL INFORM PR
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Tang SY, 2014, INT J COMPUT VISION, V110, P58, DOI 10.1007/s11263-013-0664-6
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Vermaak J, 2005, IEEE T AERO ELEC SYS, V41, P309, DOI 10.1109/TAES.2005.1413764
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Wang XY, 2014, IEEE ENER CONV, P17, DOI 10.1109/ECCE.2014.6953370
   Yoo H, 2017, IEEE T CIRC SYST VID, V27, P454, DOI 10.1109/TCSVT.2016.2593619
NR 55
TC 14
Z9 14
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 120
EP 131
DI 10.1016/j.imavis.2019.03.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400012
DA 2024-07-18
ER

PT J
AU Zhao, FD
   Tamaki, T
   Kurita, T
   Raytchev, B
   Kaneda, K
AF Zhao, Fangda
   Tamaki, Toru
   Kurita, Takio
   Raytchev, Bisser
   Kaneda, Kazufumi
TI Marker-based non-overlapping camera calibration methods with additional
   support camera views
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Non-overlapping camera calibration; AR marker; Pose estimation
ID GENERATION
AB Simple methods to calibrate non-overlapping cameras using markers on the cameras are proposed. By adding an augmented reality (AR) marker to a camera, we can find the transformation between the fixed AR marker and the camera. With such information, the relative pose between cameras can be found as long as the markers are visible to additional support cameras. The proposed method consists of two steps: (1) use of an extra support camera and a chessboard to find the transformation between the AR marker and the camera and (2) use of the transformation between markers to calibrate non-overlapping cameras. Compared to an existing method, the proposed method works stably and uses fewer images. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Zhao, Fangda; Tamaki, Toru; Kurita, Takio; Raytchev, Bisser; Kaneda, Kazufumi] Hiroshima Univ, Grad Sch Engn, 1-4-1 Kagamiyama, Higashihiroshima, Hiroshima 7398527, Japan.
C3 Hiroshima University
RP Zhao, FD; Tamaki, T (corresponding author), Hiroshima Univ, Grad Sch Engn, 1-4-1 Kagamiyama, Higashihiroshima, Hiroshima 7398527, Japan.
EM zhao@eml.hiroshima-u.ac.jp; tamaki@hiroshima-u.ac.jp
RI Tamaki, Toru/D-7091-2011; Kaneda, Kazufumi/J-5562-2015; Raytchev,
   Bisser/D-9164-2011; Kurita, Takio/D-8674-2012
OI Tamaki, Toru/0000-0001-9712-7777; Kurita, Takio/0000-0003-3982-6750
FU JSPS KAKENHI grant [JP26280061]; Grants-in-Aid for Scientific Research
   [16K00239, 26280061] Funding Source: KAKEN
FX This work was supported in part by JSPS KAKENHI grant number JP26280061.
CR Agrawal A, 2013, IEEE I CONF COMP VIS, P2368, DOI 10.1109/ICCV.2013.294
   Alcantarilla P.F., 2013, 5 WORKSH PLANN PERC
   Anjum N., 2007, 2007 IEEE INT C AC S
   [Anonymous], 2012, Ceres solver
   [Anonymous], 2016, IPSJ Trans. Comput.Vis. Appl.
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Ataer-Cansizoglu Esra, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P509, DOI 10.1109/3DV.2014.106
   Bradski G., 2000, Opencv. Dr. Dobb's journal of software tools
   Carrera G, 2011, IEEE INT CONF ROBOT, P2652, DOI 10.1109/ICRA.2011.5980294
   Esquivel S, 2007, LECT NOTES COMPUT SC, V4713, P82
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Furukawa Yasutaka., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587681
   Garrido-Jurado S, 2016, PATTERN RECOGN, V51, P481, DOI 10.1016/j.patcog.2015.09.023
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Heng L, 2013, IEEE INT C INT ROBOT, P1793, DOI 10.1109/IROS.2013.6696592
   KANATANI K, 1994, IEEE T PATTERN ANAL, V16, P543, DOI 10.1109/34.291441
   Kumar RK, 2008, PROC CVPR IEEE, P2602
   Lamprecht Bernhard, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P265, DOI 10.1109/ITSC.2007.4357679
   Lebraly P., 2010, PROCEEDINGS OF THE B, DOI DOI 10.1-10.12
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Ramalingam S., 2016, IEEE T PATTERN ANAL, P1
   Takahashi K., 2012, OPENCV LIBS NEW MIRR
   Takahashi K, 2012, PROC CVPR IEEE, P1051, DOI 10.1109/CVPR.2012.6247783
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao FD, 2016, IEEE IMAGE PROC, P1180, DOI 10.1109/ICIP.2016.7532544
NR 28
TC 17
Z9 20
U1 4
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2018
VL 70
BP 46
EP 54
DI 10.1016/j.imavis.2017.12.006
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GA7AR
UT WOS:000428487500005
DA 2024-07-18
ER

PT J
AU Han, J
   Zhang, ZX
   Cummins, N
   Ringeval, F
   Schuller, B
AF Han, Jing
   Zhang, Zixing
   Cummins, Nicholas
   Ringeval, Fabien
   Schuller, Bjoern
TI Strength modelling for real-world automatic continuous affect
   recognition from audiovisual signals
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Strength modelling; Support vector regression; Memory-enhanced;
   recurrent neural networks; Audiovisual affective computing
ID BIDIRECTIONAL LSTM
AB Automatic continuous affect recognition from audiovisual cues is arguably one of the most active research areas in machine learning. In addressing this regression problem, the advantages of the models, such as the global-optimisation capability of Support Vector Machine for Regression and the context-sensitive capability of memory-enhanced neural networks, have been frequently explored, but in an isolated way. Motivated to leverage the individual advantages of these techniques, this paper proposes and explores a novel framework, Strength Modelling, where two models are concatenated in a hierarchical framework. In doing this, the strength information of the first model, as represented by its predictions, is joined with the original features, and this expanded feature space is then utilised as the input by the successive model. A major advantage of Strength Modelling, besides its ability to hierarchically explore the strength of different machine learning algorithms, is that it can work together with the conventional feature- and decision level fusion strategies for multimodal affect recognition. To highlight the effectiveness and robustness of the proposed approach, extensive experiments have been carried out on two time- and value-continuous spontaneous emotion databases (RECOLA and SEMAINE) using audio and video signals. The experimental results indicate that employing Strength Modelling can deliver a significant performance improvement for both arousal and valence in the unimodal and bimodal settings. The results further show that the proposed systems is competitive or outperform the other state-of-the-art approaches, but being with a simple implementation. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Han, Jing; Zhang, Zixing; Cummins, Nicholas; Ringeval, Fabien; Schuller, Bjoern] Univ Passau, Chair Complex & Intelligent Syst, Innstr 41, D-94032 Passau, Germany.
   [Ringeval, Fabien] Univ Grenoble Alpes, Lab Informat Grenoble, 700 Ave Cent, F-38058 Grenoble, France.
   [Schuller, Bjoern] Imperial Coll London, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.
C3 University of Passau; Communaute Universite Grenoble Alpes; Institut
   National Polytechnique de Grenoble; Universite Grenoble Alpes (UGA);
   Centre National de la Recherche Scientifique (CNRS); Imperial College
   London
RP Zhang, ZX (corresponding author), Univ Passau, Chair Complex & Intelligent Syst, Innstr 41, D-94032 Passau, Germany.
EM zixing.zhang@uni-passau.de
RI Han, Jing/AAB-3944-2020; Cummins, Nicholas/AAC-6431-2019; Schuller,
   Björn Wolfgang/D-3241-2011
OI Han, Jing/0000-0001-5776-6849; Cummins, Nicholas/0000-0002-1178-917X;
   Schuller, Björn Wolfgang/0000-0002-6478-8699
FU EU's Horizon Programme through Innovative Action [645094]; EC's Seventh
   Framework Programme through ERC [338164]; Nvidia Corporation
FX This work was supported by the EU's Horizon 2020 Programme through the
   Innovative Action No. 645094 (SEWA) and the EC's Seventh Framework
   Programme through the ERC Starting Grant No. 338164 (iHEARu). We further
   thank the Nvidia Corporation for their support of this research by Tesla
   K40-type GPU donation.
CR [Anonymous], 2015, P 5 INT WORKSH AUD V, DOI DOI 10.1145/2808196.2811642
   [Anonymous], 2016, IJCAI
   [Anonymous], 2014, IEEE Sympos Comput Intell Ensemble Learn, DOI DOI 10.1109/CIEL.2014.7015739
   [Anonymous], 2013, 2013 10 IEEE INT C W, DOI [10.1109/FG.2013.6553805, DOI 10.1109/FG.2013.6553805]
   Chang CY, 2013, NEUROCOMPUTING, V122, P79, DOI 10.1016/j.neucom.2013.02.041
   Chao L, 2015, P 5 INT WORKSH AUD V, P65, DOI [DOI 10.1145/2808196.2811634, 10.1145/2808196.2811634]
   Cohen J, 2003, APPL MULTIPLE REGRES, DOI DOI 10.4324/9780203774441
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Gunes Hatice, 2010, International Journal of Strategic Synthetic Emotions, V1, P68, DOI 10.4018/jse.2010101605
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   Gunes H, 2009, IEEE T SYST MAN CY B, V39, P64, DOI 10.1109/TSMCB.2008.927269
   Gunn S.., 1998, Technical Report, V14, P5
   He Lang, 2015, P 5 INT WORKSH AUD V
   Hermansky H, 2000, INT CONF ACOUST SPEE, P1635, DOI 10.1109/ICASSP.2000.862024
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang Z, 2015, P 5 INT WORKSH AUD V, P41, DOI 10.1145/2808196.2811640
   Kumar N., 2014, P MEDIAEVAL BARC SPA
   Kursun O., 2009, P 9 INT C INF TECHN, P1
   Manandhar A., 2016, WORLD ACAD SCI ENG T, V10, P408
   Mariooryad S, 2015, IEEE T AFFECT COMPUT, V6, P97, DOI 10.1109/TAFFC.2014.2334294
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Nicolaou MA, 2012, IMAGE VISION COMPUT, V30, P186, DOI 10.1016/j.imavis.2011.12.005
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Petridis S, 2016, IEEE T AFFECT COMPUT, V7, P45, DOI 10.1109/TAFFC.2015.2446462
   Ringeval F, 2015, PATTERN RECOGN LETT, V66, P22, DOI 10.1016/j.patrec.2014.11.007
   Schuller B, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P865
   Schuller B., 2003, P IEEE INT C AC SPEE, VI, P1401
   Schuller B, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P449
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Soleymani M, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1161, DOI 10.1145/2647868.2655019
   Soleymani M, 2014, IEEE INT CON MULTI
   Tian LM, 2015, INT CONF AFFECT, P698, DOI 10.1109/ACII.2015.7344645
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Wei J., 2014, Signal and Information Processing Association Annual Summit and Conference (APSIPA), 2014 Asia-Pacific, P1
   Weninger F, 2015, J MACH LEARN RES, V16, P547
   Wöllmer M, 2013, IMAGE VISION COMPUT, V31, P153, DOI 10.1016/j.imavis.2012.03.001
   Wöllmer M, 2010, COGN COMPUT, V2, P180, DOI 10.1007/s12559-010-9041-8
   Wöllmer M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P597
   Wöllmer M, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P2463
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Wu CH, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.11
   Yang YH, 2008, IEEE T AUDIO SPEECH, V16, P448, DOI 10.1109/TASL.2007.911513
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang ZX, 2016, INT CONF ACOUST SPEE, P5185, DOI 10.1109/ICASSP.2016.7472666
   Zhang ZX, 2016, INTERSPEECH, P3593, DOI 10.21437/Interspeech.2016-998
   Zhang ZX, 2014, IEEE T CONSUM ELECTR, V60, P525, DOI 10.1109/TCE.2014.6937339
NR 50
TC 33
Z9 34
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2017
VL 65
SI SI
BP 76
EP 86
DI 10.1016/j.imavis.2016.11.020
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FJ3GM
UT WOS:000412618500009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sun, WC
   Su, F
AF Sun, Weichen
   Su, Fei
TI A novel companion objective function for regularization of deep
   convolutional neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional neural network; Regularization; Companion objective
   function; Classification
AB Regularization is an essential technique discussed in an attempt to solve the overfitting problem in deep convolutional neural networks (CNNs). In this paper, we proposed a novel companion objective function as a regularization strategy to boost the classification performance in deep CNNs. Three aspects of this companion objective function are studied. Firstly, we proposed two kinds of auxiliary supervision for convolutional filters and non-linear activations respectively in the companion objective function. Both of them enhanced the performance by aleviating the overfitting problem and auxiliary supervision for non-linear activations provided more efficiency. Secondly, regularization of auxiliary supervision in the pre-training phrase is discussed. With the assistance of auxiliary supervision, CNNs could obtain a more favorable initialization for end-to-end supervised fine-tuning. Finally, this companion objective function is verified to be compatible with other regularization strategies such as dropout and data augmentation. Experimental results on benchmark datasets (CIFAR-10 and CIFAR-100) demonstrated advantages of our proposed companion objective function as a regularization approach. (C) 2016 Published by Elsevier B.V.
C1 [Sun, Weichen; Su, Fei] Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing, Peoples R China.
   [Su, Fei] Beijing Univ Posts & Telecommun, Beijing Key Lab Network Syst & Network Culture, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications; Beijing University of
   Posts & Telecommunications
RP Su, F (corresponding author), Beijing Univ Posts & Telecommun, Sch Informat & Commun Engn, Beijing, Peoples R China.
EM sufei@bupt.edu.cn
FU Chinese National Natural Science Foundation [61372169, 61532018,
   61471049]; Special Funds of Beijing Municipal Co-construction Project
FX This work is supported by Chinese National Natural Science Foundation
   (61372169, 61532018, 61471049), and Special Funds of Beijing Municipal
   Co-construction Project 2016.
CR [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2014, ARXIV14127062
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 1985, CALIFORNIA U SAN DIE
   [Anonymous], IEEE T PATTERN ANAL
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Malinowski M, 2015, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2015.9
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
NR 13
TC 5
Z9 5
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 58
EP 63
DI 10.1016/j.imavis.2016.11.012
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800007
DA 2024-07-18
ER

PT J
AU Huang, D
   Zhang, RK
   Yin, YA
   Wang, YD
   Wang, YH
AF Huang, Di
   Zhang, Renke
   Yin, Yuan
   Wang, Yiding
   Wang, Yunhong
TI Local feature approach to dorsal hand vein recognition by Centroid-based
   Circular Key-point Grid and fine-grained matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hand vein recognition; Local feature matching; Centroid-based Circular
   Key-point; Grid (CCKG); Multi-task Sparse Representation Classifier;
   (MtSRC)
AB Due to the great progress made by local feature matching in both performance and robustness of dorsal hand vein recognition, this paper proposes a novel and effective approach for such an issue by improving two major steps of the SIFT-like framework, i.e. key-point detection and matching. For the former, a new key-point generation pattern, namely Centroid-based Circular Key-point Grid (CCKG), is presented, which efficiently localizes a certain number of points on the dorsal hand for the following SIFT feature extraction, leading to a discriminative description. In contrast to the existing key-point detectors, CCKG comprehensively accounts for the properties of the dorsal hand, including the vein network as well as the surrounding corium region, and hence achieves both good representativeness and low complexity. For the latter, a finegrained matching process is introduced which makes use of Multi-task Sparse Representation Classifier (MtSRC). Compared with the traditional coarse-grained one that counts the number of associated SIFT features between the gallery and probe dorsal hand images, MtSRC precisely calculates the error of each feature of the probe as reconstructed by the gallery features, and all the errors of the probe features are combined for similarity measurement, reaching a better accuracy in recognition. The proposed approach is evaluated on the NCUT Part A database and shows its effectiveness in both the identification and verification scenarios. Additionally, the experimental results achieved on the NCUT Part B dataset highlight its generality and robustness to low quality images. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Huang, Di] Beihang Univ, State Key Lab Software Dev Environm, Beijing 100191, Peoples R China.
   [Zhang, Renke; Yin, Yuan; Wang, Yunhong] Beihang Univ, Sch Comp Sci & Engn, IRIP Lab, Beijing 100191, Peoples R China.
   [Wang, Yiding] North China Univ Technol, Coll Inf Engn, Beijing 100041, Peoples R China.
C3 Beihang University; Beihang University; North China University of
   Technology
RP Wang, YH (corresponding author), Beihang Univ, Sch Comp Sci & Engn, IRIP Lab, Beijing 100191, Peoples R China.
EM yhwang@buaa.edu.cn
RI wang, yiran/IAP-0414-2023; Wang, Yiru/JMB-2281-2023; wang,
   yi/GVT-8516-2022; Wu, Yiping/JJF-6185-2023; Li, Shuya/JHT-2171-2023;
   Huang, Di/JBJ-3541-2023; Wang, Yin/HCI-9352-2022; wang,
   yixuan/GXW-2866-2022; Wang, Yixuan/GZK-6559-2022; Wang,
   Yijun/GXW-1763-2022; Wang, yanru/JAX-5241-2023
OI Wu, Yiping/0009-0000-6223-5786; Li, Shuya/0000-0001-5320-8452; Huang,
   Di/0000-0001-7877-7301; Yin, Yuan/0000-0003-1515-0696
FU National Natural Science Foundation of China [61540048, 61271368];
   Beijing Municipal Natural Science Foundation under Grants [4142032,
   KZ201410009012]; Research Program of State Key Laboratory of Software
   Development Environment under Grant [SKLSDE2015ZX-30]
FX This work was funded in part by the National Natural Science Foundation
   of China under Grants 61540048 and 61271368, the Beijing Municipal
   Natural Science Foundation under Grants 4142032 and KZ201410009012, the
   Research Program of State Key Laboratory of Software Development
   Environment under Grant SKLSDE2015ZX-30.
CR [Anonymous], 2014, DALTON T
   Cross J., 1995, INT CARN C SEC TECHN
   Edelman S, 1997, COMPLEX CELLS OBJECT
   Huang D., 2012, Asian Conference on Computer Vision, P430, DOI DOI 10.1007/978-3-642-37447-0_33
   Huang D, 2015, IEEE T CYBERNETICS, V45, P1823, DOI 10.1109/TCYB.2014.2360894
   Huang D, 2014, IEEE T IMAGE PROCESS, V23, P4680, DOI 10.1109/TIP.2014.2353814
   Huang D, 2012, IEEE T INF FOREN SEC, V7, P1551, DOI 10.1109/TIFS.2012.2206807
   Huang Di., 2011, CVPR 2011 WORKSHOPS, P1
   KUMAR A, 2009, IEEE S COMP INT SEC
   Kumar A, 2009, IEEE T IMAGE PROCESS, V18, P2127, DOI 10.1109/TIP.2009.2023153
   Ladoux P, 2009, IEEE INT C BIOM
   Li X, 2016, IEEE INT C IM PROC
   Lin CL, 2004, IEEE T CIRC SYST VID, V14, P199, DOI 10.1109/TCSVT.2003.821975
   Liu J., 2012, J COMPUT INF SYST, V8, P1545
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacGregor P., 1991, Adv. Imaging, V6, P52
   Malki S., 2007, SPIE INT S MICR NEW, V6590
   Miura N, 2004, MACH VISION APPL, V15, P194, DOI 10.1007/s00138-004-0149-2
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Pei JF, 2013, IEEE INT C BIOINFORM
   Roth P. M., ICGTR0108ICGTR0108
   Subramanian R. K., 2009, INT C IM SIGN PROC
   Tang Y., 2012, IEEE INT C PATT REC
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang K., 2006, INT C MECH AUT
   Wang L, 2008, PATTERN RECOGN, V41, P920, DOI 10.1016/j.patcog.2007.07.012
   Wang Y., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P367, DOI DOI 10.1109/ICB.2012.6199778
   Wang Y., 2010, INT C INT COMP
   Weng DW, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2409739
   Xiangrong Zhu, 2013, Advances in Multimedia Information Processing - PCM 2013. 14th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8294, P158, DOI 10.1007/978-3-319-03731-8_15
   Zhang R., 2016, IEEE INT C BIOM
   Zhang RK, 2015, INT CONF BIOMETR, P326, DOI 10.1109/ICB.2015.7139057
   Zhao S, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1172, DOI 10.1109/ICMLC.2008.4620581
   Zhu X., 2012, CHIN C BIOM REC
NR 36
TC 27
Z9 31
U1 0
U2 48
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 266
EP 277
DI 10.1016/j.imavis.2016.07.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700025
DA 2024-07-18
ER

PT J
AU Liu, ZY
   Bai, XZ
   Sun, CM
   Zhou, FG
   Li, YJ
AF Liu, Zhaoying
   Bai, Xiangzhi
   Sun, Changming
   Zhou, Fugen
   Li, Yujian
TI Infrared ship target segmentation through integration of multiple
   feature maps
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Infrared images; Ship target segmentation; Feature map integration;
   Thresholding
ID LEVEL SET METHOD; IMAGE SEGMENTATION; ACTIVE CONTOURS; ENHANCEMENT;
   SELECTION; ENTROPY; FUSION
AB We investigate the issue of ship target segmentation in infrared (IR) images, and propose an efficient method based on feature map integration. It consists of mainly two procedures: salient region detection based on multiple feature map integration and salient region segmentation based on locally adaptive thresholding. Firstly, a saliency map is constructed by integrating multiple features of IR ship targets, including gray level intensity, local contrast, salient linear structures, and edge strength. Secondly, we propose an adaptive thresholding method to segment each local salient region, and a target selection procedure based on shape features is used to remove background and obtain the true target. Experimental results show that the proposed method performs well for IR ship target segmentation. The advantage of the proposed method is demonstrated in both visual and quantitative comparisons, especially for IR images with a bright background or a ship target close to port. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Liu, Zhaoying; Li, Yujian] Beijing Univ Technol, Coll Comp Sci, Beijing 100124, Peoples R China.
   [Liu, Zhaoying; Bai, Xiangzhi; Zhou, Fugen] Beihang Univ, Image Proc Ctr, Beijing 100191, Peoples R China.
   [Bai, Xiangzhi; Zhou, Fugen] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Liu, Zhaoying; Sun, Changming] CSIRO Digital Prod Flagship, Locked Bag 17, N Ryde, NSW 1670, Australia.
C3 Beijing University of Technology; Beihang University; Beihang
   University; Commonwealth Scientific & Industrial Research Organisation
   (CSIRO)
RP Bai, XZ (corresponding author), Beihang Univ, Image Proc Ctr, Beijing 100191, Peoples R China.
EM jackybxz@buaa.edu.cn
RI Sun, Changming/A-3276-2008
OI Sun, Changming/0000-0001-5943-1989
FU National Natural Science Foundation of China [61271023]; Program for New
   Century Excellent Talents in University [NCET-13-0020]; China
   Postdoctoral Science Foundation [2015M580952]; China Scholarship Council
   [201306020106]
FX This work was performed under the sponsorship of National Natural
   Science Foundation of China (61271023), Program for New Century
   Excellent Talents in University (NCET-13-0020), China Postdoctoral
   Science Foundation (2015M580952) and China Scholarship Council
   (201306020106).
CR ARAKI S, 1993, SECOND IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2, P719, DOI 10.1109/FUZZY.1993.327400
   Arora S, 2008, PATTERN RECOGN LETT, V29, P119, DOI 10.1016/j.patrec.2007.09.005
   Bai XZ, 2012, OPT LASER TECHNOL, V44, P328, DOI 10.1016/j.optlastec.2011.07.009
   Bai XZ, 2011, INFRARED PHYS TECHN, V54, P61, DOI 10.1016/j.infrared.2010.12.001
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Benezeth Y, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3456695
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chang JS, 1997, IMAGE VISION COMPUT, V15, P23, DOI 10.1016/S0262-8856(96)01087-6
   Chaudhury KN, 2011, IEEE T IMAGE PROCESS, V20, P3376, DOI 10.1109/TIP.2011.2159234
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cui GM, 2015, OPT COMMUN, V341, P199, DOI 10.1016/j.optcom.2014.12.032
   Dickinson P, 2009, IMAGE VISION COMPUT, V27, P1326, DOI 10.1016/j.imavis.2008.12.001
   Dong FF, 2013, IMAGE VISION COMPUT, V31, P809, DOI 10.1016/j.imavis.2013.08.003
   Dupuis A, 2006, IMAGE VISION COMPUT, V24, P1053, DOI 10.1016/j.imavis.2006.02.027
   Feng D, 2005, PATTERN RECOGN LETT, V26, P597, DOI 10.1016/j.patrec.2004.11.002
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Li M, 2012, INFRARED PHYS TECHN, V55, P19, DOI 10.1016/j.infrared.2011.08.009
   Lin GF, 2014, INFORM FUSION, V20, P146, DOI 10.1016/j.inffus.2014.01.002
   Liu ZY, 2014, PATTERN RECOGN, V47, P2839, DOI 10.1016/j.patcog.2014.03.005
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pai YT, 2010, PATTERN RECOGN, V43, P3177, DOI 10.1016/j.patcog.2010.03.014
   Qi SX, 2013, IEEE GEOSCI REMOTE S, V10, P495, DOI 10.1109/LGRS.2012.2211094
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Su R, 2012, PATTERN RECOGN, V45, P3695, DOI 10.1016/j.patcog.2012.04.013
   Tao WB, 2007, OPT ENG, V46, DOI 10.1117/1.2823159
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang XP, 2011, OPT ENG, V50, DOI 10.1117/1.3582855
   Wang YH, 2001, PROC SPIE, V4550, P19, DOI 10.1117/12.441487
   Wu J, 2004, IEEE ROBIO 2004: Proceedings of the IEEE International Conference on Robotics and Biomimetics, P742
   Wu JW, 2011, OPT ENG, V50, DOI 10.1117/1.3578402
   Yang X, 2015, IEEE T IMAGE PROCESS, V24, P9, DOI 10.1109/TIP.2014.2372615
   Yang X, 2014, INFORM SCIENCES, V277, P794, DOI 10.1016/j.ins.2014.03.014
   Yang X, 2014, IEEE T IMAGE PROCESS, V23, P2854, DOI 10.1109/TIP.2014.2321506
   Yeh HH, 2012, IEEE IMAGE PROC, P1077, DOI 10.1109/ICIP.2012.6467050
   Yilmaz A, 2003, IMAGE VISION COMPUT, V21, P623, DOI 10.1016/S0262-8856(03)00059-3
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhang J, 2008, 2008 INTERNATIONAL MULTISYMPOSIUMS ON COMPUTER AND COMPUTATIONAL SCIENCES (IMSCCS), P102, DOI 10.1109/IMSCCS.2008.14
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zhou L, 2014, NEUROCOMPUTING, V135, P240, DOI 10.1016/j.neucom.2013.12.026
NR 40
TC 21
Z9 21
U1 5
U2 51
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR-MAY
PY 2016
VL 48-49
BP 14
EP 25
DI 10.1016/j.imavis.2015.12.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO4GS
UT WOS:000377740400002
DA 2024-07-18
ER

PT J
AU Zhou, Z
   Wang, Y
   Teoh, EK
AF Zhou, Zhi
   Wang, Yue
   Teoh, Eam Khwang
TI A framework for semantic people description in multi-camera surveillance
   systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE People re-identification; Human appearance model; Semantic features;
   Soft-biometric; Surveillance
ID PERSON REIDENTIFICATION; TRACKING
AB People re-identification has been a very active research topic recently in computer vision. It is an important application in surveillance systems with disjoint cameras. In this paper, a framework is proposed to extract descriptors of people in videos, which are based on soft-biometric traits and can be further used for people re identification or other applications. Soft-biometric based description is more invariant to changing factors than directly using low level features such as color and texture. The ensemble of a set of soft-biometric traits can achieve good performance in people re-identification. In the proposed method, the body of detected people is divided into three parts and the selected soft-biometric traits are extracted from each part. All traits are then combined to form the final descriptor, and people re-identification is performed based on the descriptor and Nearest Neighbor (NN) matching strategy. The experiments are carried out on SAIVT-SoftBio database which consists of videos from disjoint surveillance cameras, as well as some static image based datasets. An open ID recognition problem is also evaluated for the proposed method. Comparisons with some state-of-the-art methods are provided as well. The experiment results show the good performance of the proposed framework. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zhou, Zhi; Teoh, Eam Khwang] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Wang, Yue] Inst Infocomm Res I2R, Visual Comp Dept, Singapore 138632, Singapore.
C3 Nanyang Technological University; Agency for Science Technology &
   Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R)
RP Zhou, Z (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM zzhou5@e.ntu.edu.sg; ywang@i2r.a-star.edu.sg; eekteoh@ntu.edu.sg
CR Andriluka M., 2008, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)
   [Anonymous], I LIDS MULT CAM TRAC
   [Anonymous], 2008, Biometrics: Theory, Applications and Systems
   [Anonymous], 2007, 10 INT WORKSH PERF E
   [Anonymous], P BRIT MACH VIS C EM
   [Anonymous], ECCV WORKSH DEM 2012
   [Anonymous], P 11 ACM INT C MULT
   [Anonymous], IEEE INT C ADV VID S
   [Anonymous], ECCV WORKSH DEM 2012
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], ADV MULTIMEDIA INFOR
   [Anonymous], P 9 IEEE INT C COMP
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], P EUR SIG PROC C 201
   [Anonymous], IEEE INT C ADV VID S
   [Anonymous], IJCAI 2003
   [Anonymous], CAN SOFT BIOMETRIC T
   [Anonymous], 2013, Chengdu Archaeological Discovery, DOI DOI 10.1109/GEOINFORMATICS.2013
   [Anonymous], ECCV WORKSH DEM 2012
   [Anonymous], IEEE 11 INT C COMP V
   [Anonymous], 2 ACM IEEE INT C DIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], WORKSH APPL COMP VIS
   [Anonymous], 2012, DICTA
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   Bedagkar-Gala A, 2012, PATTERN RECOGN LETT, V33, P1908, DOI 10.1016/j.patrec.2011.09.005
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Bird ND, 2005, IEEE T INTELL TRANSP, V6, P167, DOI 10.1109/TITS.2005.848370
   Bissacco A, 2009, INT J COMPUT VISION, V85, P101, DOI 10.1007/s11263-009-0248-7
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damen D, 2012, IEEE T PATTERN ANAL, V34, P1056, DOI 10.1109/TPAMI.2011.205
   Dantcheva A, 2011, MULTIMED TOOLS APPL, V51, P739, DOI 10.1007/s11042-010-0635-7
   Denman S, 2007, PATTERN RECOGN LETT, V28, P1232, DOI 10.1016/j.patrec.2007.02.008
   Denman S, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P196, DOI 10.1109/DICTA.2009.38
   Doretto G, 2011, J AMB INTEL HUM COMP, V2, P127, DOI 10.1007/s12652-010-0034-y
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Haritaoglu I., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P102, DOI 10.1109/ICCV.1999.791204
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kviatkovsky Igor, 2013, IEEE Trans Pattern Anal Mach Intell, V35, P1622, DOI 10.1109/TPAMI.2012.246
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Lee CS, 2006, LECT NOTES COMPUT SC, V4069, P315
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Madden C, 2007, MACH VISION APPL, V18, P233, DOI 10.1007/s00138-007-0070-6
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Prosser B., 2010, PERSON RE IDENTIFICA, V2, P1
   Prosser B., 2008, P BMVC, V8, P164
   Schulz D, 2003, INT J ROBOT RES, V22, P99, DOI 10.1177/0278364903022002002
   Shakhnarovich G, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P16, DOI 10.1109/AFGR.2002.1004124
   Simi Wang, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1876, DOI 10.1109/ICCVW.2011.6130477
   Sobottka K, 1998, SIGNAL PROCESS-IMAGE, V12, P263, DOI 10.1016/S0923-5965(97)00042-8
   Tao DP, 2013, IEEE T CIRC SYST VID, V23, P1675, DOI 10.1109/TCSVT.2013.2255413
   Wang HZ, 2007, PATTERN RECOGN, V40, P1091, DOI 10.1016/j.patcog.2006.05.024
   Wang X, 2007, ADV INTEL SYS RES, DOI 10.2991/iske.2007.208
   Wang Y, 2014, I C OPTICAL INTERNET
   Zhao R, 2013, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2013.460
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
NR 61
TC 8
Z9 8
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2016
VL 46
BP 29
EP 46
DI 10.1016/j.imavis.2015.11.009
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DH3IJ
UT WOS:000372680400003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Murthy, OVR
   Goecke, R
AF Murthy, O. V. Ramana
   Goecke, Roland
TI Ordered trajectories for human action recognition with large number of
   classes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Dense trajectories; Large scale classification;
   Fisher vector; Bag-of-Words; SVM
ID MULTITARGET TRACKING; MOTION; ASSIGNMENT; OCCLUSIONS
AB Recently, a video representation based on dense trajectories has been shown to outperform other human action recognition methods on several benchmark datasets. The trajectories capture the motion characteristics of different moving objects in space and temporal dimensions. In dense trajectories, points are sampled at uniform intervals in space and time and then tracked using a dense optical flow field over a fixed length of L frames (optimally 15) spread overlapping over the entire video. However, among these base (dense) trajectories, a few may continue for longer than duration L, capturing motion characteristics of objects that may be more valuable than the information from the base trajectories. Thus, we propose a technique that searches for trajectories with a longer duration and refer to these as 'ordered trajectories'. Experimental results show that ordered trajectories perform much better than the base trajectories, both standalone and when combined. Moreover, the uniform sampling of dense trajectories does not discriminate objects of interest from the background or other objects. Consequently, a lot of information is accumulated, which actually may not be useful. This can especially escalate when there is more data due to an increase in the number of action classes. We observe that our proposed trajectories remove some background clutter, too. We use a Bag-of-Words framework to conduct experiments on the benchmark HMDB51, UCF50 and UCF101 datasets containing the largest number of action classes to date. Further, we also evaluate three state-of-the art feature encoding techniques to study their performance on a common platform. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Murthy, O. V. Ramana; Goecke, Roland] Univ Canberra, ESTeM, Vis & Sensing, Human Ctr Technol Res Ctr, Canberra, ACT 2601, Australia.
   [Goecke, Roland] Australian Natl Univ, IHCC, CECS, Canberra, ACT 0200, Australia.
C3 University of Canberra; Australian National University
RP Murthy, OVR (corresponding author), Univ Canberra, ESTeM, Vis & Sensing, Human Ctr Technol Res Ctr, Canberra, ACT 2601, Australia.
EM O.V.RamanaMurthy@ieee.org; roland.goecke@ieee.org
RI Goecke, Roland/F-7499-2013; oruganti, venkata ramana
   murthy/AAJ-4314-2020
OI Goecke, Roland/0000-0003-2279-7041; oruganti, venkata ramana
   murthy/0000-0002-9616-7942
CR [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], COMBINED ORDERED IMP
   [Anonymous], INT C IM PROC ICIP
   Basharat A, 2014, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2014.6836016
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Huang T, 1998, ARTIF INTELL, V103, P77, DOI 10.1016/S0004-3702(98)00067-8
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jiang YG, 2012, LECT NOTES COMPUT SC, V7576, P425, DOI 10.1007/978-3-642-33715-4_31
   Kaucic R, 2005, PROC CVPR IEEE, P990
   Kliper-Gross O, 2012, LECT NOTES COMPUT SC, V7577, P256, DOI 10.1007/978-3-642-33783-3_19
   Kuehne H., 2011, P INT C COMP VIS
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Liu L, 2013, IEEE T CYBERNETICS, V43, P1860, DOI 10.1109/TSMCB.2012.2231959
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Matikainen P, 2010, LECT NOTES COMPUT SC, V6311, P508, DOI 10.1007/978-3-642-15549-9_37
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Peng XJ, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.59
   Perera AGA, 2006, IEEE COMP SOC C COMP, P666
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Ramana O.V. Murthy, 2013, INT C COMP VIS WORKS
   Raptis M, 2012, PROC CVPR IEEE, P1242, DOI 10.1109/CVPR.2012.6247807
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Shi F, 2013, PROC CVPR IEEE, P2595, DOI 10.1109/CVPR.2013.335
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stauffer C., 2003, IEEE CVPRW, V4, P35
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Uemura H, 2008, BMVC 2008 P BRIT MAC, DOI [10.5244/C.22.30, DOI 10.5244/C.22.30]
   Ullah M.M., 2010, IEEE BRIT MACHINE VI, P1
   Vig E, 2012, LECT NOTES COMPUT SC, V7578, P84, DOI 10.1007/978-3-642-33786-4_7
   Wang H., 2013, LEAR INRIA SUBMISSIO
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Zhang S, 2015, PATTERN RECOGN, V48, P580, DOI 10.1016/j.patcog.2014.08.013
   Zhao ZP, 2008, INT C PATT RECOG, P737
   Zhu J, 2013, SENSORS-BASEL, V13, P14398, DOI 10.3390/s131114398
NR 53
TC 13
Z9 15
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2015
VL 42
BP 22
EP 34
DI 10.1016/j.imavis.2015.06.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CT2BV
UT WOS:000362607900003
DA 2024-07-18
ER

PT J
AU Li, LY
   Li, S
   Fu, Y
AF Li, Liangyue
   Li, Sheng
   Fu, Yun
TI Learning low-rank and discriminative dictionary for image classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sparse representation; Dictionary learning; Low-rank regularization;
   Image classification
ID FACE RECOGNITION; LEAST-SQUARES; SPARSE REPRESENTATION; MATRIX
   COMPLETION; ALGORITHMS
AB Dictionary learning plays a crucial role in sparse representation based image classification. In this paper, we propose a novel approach to learn a discriminative dictionary with low-rank regularization on the dictionary. Specifically, we apply Fisher discriminant function to the coding coefficients to make the dictionary more discerning, that is, a small ratio of the within-class scatter to between-class scatter. In practice, noisy information in the training samples will undermine the discriminative ability of the dictionary. Inspired by the recent advances in low-rank matrix recovery theory, we apply low-rank regularization on the dictionary to tackle this problem. The iterative projection method (IPM) and inexact augmented Lagrange multiplier (ALM) algorithm are adopted to solve our objective function. The proposed discriminative dictionary learning with low-rank regularization ((DLR2)-L-2-R-2) approach is evaluated on four face and digit image datasets in comparison with existing representative dictionary learning and classification algorithms. The experimental results demonstrate the superiority of our approach. Published by Elsevier B.V.
C1 [Li, Liangyue; Li, Sheng; Fu, Yun] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
C3 Northeastern University
RP Fu, Y (corresponding author), Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
EM liangyue@ece.neu.edu; shengli@ece.neu.edu; yunfu@ece.neu.edu
RI Li, Liangyue/AAE-9722-2022; Li, Liangyue/AFE-8490-2022
OI Li, Liangyue/0000-0001-7630-8851; Li, Liangyue/0000-0001-7630-8851
FU NSF CNS [1314484]; Office of Naval Research [N00014-12-1-1028]; Air
   Force Office of Scientific Research [FA9550-12-1-0201]; U.S. Army
   Research Office [W911NF-13-1-0160]; IC Postdoctoral Research Fellowship
   [2011-11071400006]; Division Of Computer and Network Systems; Direct For
   Computer & Info Scie & Enginr [1314484] Funding Source: National Science
   Foundation
FX This research is supported in part by the NSF CNS award 1314484, Office
   of Naval Research award N00014-12-1-1028, Air Force Office of Scientific
   Research award FA9550-12-1-0201, the U.S. Army Research Office under
   grant number W911NF-13-1-0160 and IC Postdoctoral Research Fellowship
   award 2011-11071400006.
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], CVPR
   [Anonymous], CVPR
   [Anonymous], 2010, CVPR
   [Anonymous], 2011, ICCV
   [Anonymous], 2010, ARXIV10073753
   [Anonymous], IEEE T SIGNAL PROCES
   [Anonymous], ICASSP
   [Anonymous], TECHNICAL REPORT
   [Anonymous], DISCRIMINATIVE DICT
   [Anonymous], 1983, SOV MATH DOKL
   [Anonymous], ICDM
   [Anonymous], 2010, P ACM MULTIMEDIA
   [Anonymous], THESIS MIT
   Becker SR, 2011, MATH PROGRAM COMPUT, V3, P165, DOI 10.1007/s12532-011-0029-5
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bertsekas D. P., 1982, REINFORCEMENT LEARNI
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2010, IEEE T INFORM THEORY, V56, P2053, DOI 10.1109/TIT.2010.2044061
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981
   CHEN S, 1989, INT J CONTROL, V50, P1873, DOI 10.1080/00207178908953472
   Davis G, 1997, CONSTR APPROX, V13, P57, DOI 10.1007/BF02678430
   Donoho DL, 2008, IEEE T INFORM THEORY, V54, P4789, DOI 10.1109/TIT.2008.929958
   Donoho DL, 2009, P NATL ACAD SCI USA, V106, P18914, DOI 10.1073/pnas.0909892106
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Efron B, 2004, ANN STAT, V32, P407, DOI 10.1214/009053604000000067
   Elad M, 2007, APPL COMPUT HARMON A, V23, P346, DOI 10.1016/j.acha.2007.02.002
   FRISCH KR, 1955, COMMUNICATION   0513
   Guo H., 2013, Asian Conference on Computer VisionACCV, P328
   Jafari MG, 2011, IEEE J-STSP, V5, P1025, DOI 10.1109/JSTSP.2011.2157892
   Jiang ZL, 2011, PROC CVPR IEEE, P1697, DOI 10.1109/CVPR.2011.5995354
   KARMARKAR N, 1984, COMBINATORICA, V4, P373, DOI 10.1007/BF02579150
   Keshavan RH, 2010, J MACH LEARN RES, V11, P2057
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lewicki MS, 1999, J OPT SOC AM A, V16, P1587, DOI 10.1364/JOSAA.16.001587
   Lewicki MS, 2000, NEURAL COMPUT, V12, P337, DOI 10.1162/089976600300015826
   Lin, 2010, ARXIV10095055
   Liu G., 2010, P INT C MACH LEARN, P663
   Ma L, 2012, PROC CVPR IEEE, P2586, DOI 10.1109/CVPR.2012.6247977
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   Murray JF, 2001, CONF REC ASILOMAR C, P347, DOI 10.1109/ACSSC.2001.986949
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Osborne MR, 2000, IMA J NUMER ANAL, V20, P389, DOI 10.1093/imanum/20.3.389
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sim Terence., 2002, The cmu pose, illumination, and expression (pie) database
   Studer C, 2012, INT CONF ACOUST SPEE, P3341, DOI 10.1109/ICASSP.2012.6288631
   Wagner A, 2012, IEEE T PATTERN ANAL, V34, P372, DOI 10.1109/TPAMI.2011.112
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yang A.Y., 2008, CVPRW
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yuan L, 2012, BMC BIOINFORMATICS, V13, DOI 10.1186/1471-2105-13-107
   Zhang HC, 2011, IEEE I CONF COMP VIS, P770, DOI 10.1109/ICCV.2011.6126315
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang ZD, 2012, INT J COMPUT VISION, V99, P1, DOI 10.1007/s11263-012-0515-x
   Zhuang LS, 2012, PROC CVPR IEEE, P2328, DOI 10.1109/CVPR.2012.6247944
NR 61
TC 90
Z9 97
U1 0
U2 45
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 814
EP 823
DI 10.1016/j.imavis.2014.02.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700018
DA 2024-07-18
ER

PT J
AU Suau, X
   Alcoverro, M
   López-Méndez, A
   Ruiz-Hidalgo, J
   Casas, JR
AF Suau, Xavier
   Alcoverro, Marcel
   Lopez-Mendez, Adolfo
   Ruiz-Hidalgo, Javier
   Casas, Josep R.
TI Real-time fingertip localization conditioned on hand gesture
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hand gesture recognition; Fingertip classification; Range camera;
   Interactivity; Dataset
ID RECOGNITION
AB A method to obtain accurate hand gesture classification and fingertip localization from depth images is proposed. The Oriented Radial Distribution feature is utilized, exploiting its ability to globally describe hand poses, but also to locally detect fingertip positions. Hence, hand gesture and fingertip locations are characterized with a single feature calculation. We propose to divide the difficult problem of locating fingertips into two more tractable problems, by taking advantage of hand gesture as an auxiliary variable. Along with the method we present the ColorTip dataset, a dataset for hand gesture recognition and fingertip classification using depth data. ColorTip contains sequences where actors wear a glove with colored fingertips, allowing automatic annotation. The proposed method is evaluated against recent works in several datasets, achieving promising results in both gesture classification and fingertip localization. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Suau, Xavier; Alcoverro, Marcel; Ruiz-Hidalgo, Javier; Casas, Josep R.] Univ Politecn Cataluna, ES-08034 Barcelona, Spain.
   [Lopez-Mendez, Adolfo] FFZOO SCP, Barcelona 08173, Spain.
C3 Universitat Politecnica de Catalunya
RP Suau, X (corresponding author), Univ Politecn Cataluna, 1-3 Jordi Girona, ES-08034 Barcelona, Spain.
EM xavier.suau@upc.edu
RI Casas, Josep R./A-2851-2010
OI Casas, Josep R./0000-0003-4639-6904
FU European Union [248138]; Spanish Ministerio de Ciencia e Innovacion
   [TEC2010-18094]
FX The research leading to these results has received funding from the
   European Union's Seventh Framework Programme (FP7/2007-2013) under grant
   agreement no. 248138.; This work has been partially supported by the
   Spanish Ministerio de Ciencia e Innovacion, under project TEC2010-18094.
CR [Anonymous], P ICCV
   [Anonymous], 2012, P IEEE COMP SOC C CO
   [Anonymous], 3 D GESTURE BASED SC
   Apple Inc, 2012, MAG TRACKP
   Baak A, 2011, MPI INFORM DATA DRIV
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Ganapathi V., 2010, Computer Vision and Pattern Recognition (CVPR 2010), P755, DOI DOI 10.1109/CVPR.2010.5540141
   Hackenberg G, 2011, P IEEE VIRT REAL ANN, P19, DOI 10.1109/VR.2011.5759431
   Keskin C, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130391
   Kollorz Eva, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P334, DOI 10.1504/IJISTA.2008.021296
   Liu X. LX., 2004, HAND GESTURE RECOGNI
   Malassiotis S, 2008, IMAGE VISION COMPUT, V26, P1027, DOI 10.1016/j.imavis.2007.11.007
   MCGREGOR JJ, 1982, SOFTWARE PRACT EXPER, V12, P23, DOI 10.1002/spe.4380120103
   MIT, 2011, FING DET DEM
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   Pugeault N, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130290
   Ren Z., 2011, P 19 ACM INT C MULTI, P1093
   Rusu Radu Bogdan, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P47, DOI 10.1109/ICCVW.2009.5457718
   Rusu R.B., 2009, THESIS TU MUENCHEN
   Rusu RB, 2010, IEEE INT C INT ROBOT, P2155, DOI 10.1109/IROS.2010.5651280
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Schwarz L A., IMAGE VISION COMPUTI
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Suau X, 2012, IEEE T MULTIMEDIA, V1, P1
   Suau X., 2012, ICASSP
   Suau X, 2012, LECT NOTES COMPUT SC, V7585, P602, DOI 10.1007/978-3-642-33885-4_62
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Ulrich Neumann ZhenyaoMoand., 2006, IEEE Conference on Computer Vision and Pattern Recognition, P1499, DOI DOI 10.1109/CVPR.2006.237
   Van den Bergh M., 2011, 2011 IEEE WORKSHOP A, P66, DOI DOI 10.1109/WACV.2011.5711485
   Van den Bergh M., 2009, WORKSH APPL COMP VIS, P1
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Zhang C., 2013, HISTOGRAM 3D FACETS
   Zhu XL, 2012, INT C PATT RECOG, P2989
NR 36
TC 23
Z9 24
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 522
EP 532
DI 10.1016/j.imavis.2014.04.015
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jung, C
   Kim, W
   Yoo, S
   Kim, C
AF Jung, Chanho
   Kim, Wonjun
   Yoo, Seungwoo
   Kim, Changick
TI A novel monochromatic cue for detecting regions of visual interest
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Regions of interest (ROIs); Monochromatic cues; Visual attention;
   Taxonomy; Performance comparison of algorithms and systems
ID SPATIOTEMPORAL SALIENCY DETECTION; ATTENTION; IMAGE; COLOR; MODEL
AB Finding regions of interest (ROIs) is a fundamentally important problem in the area of computer vision and image processing. Previous studies addressing this issue have mainly focused on investigating chromatic cues to characterize visually salient image regions, while less attention has been devoted to monochromatic cues. The purpose of this paper is the study of monochromatic cues, which have the potential to complement chromatic cues, for the detection of ROIs in an image. This paper first presents a taxonomy of existing ROI detection approaches using monochromatic cues, ranging from well-known algorithms to the most recently published techniques. We then propose a novel monochromatic cue for ROI detection. Finally, a comparative evaluation has been conducted on large scale challenging test sets of real-world natural scenes. Experimental results demonstrate that the use of our proposed monochromatic cue yields a more accurate identification of ROIs. This paper serves as a benchmark for future research on this particular topic and a steppingstone for developers and practitioners interested in adopting monochromatic cues to ROI detection systems and methodologies. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Jung, Chanho] ETRI, IT Convergence Technol Res Lab, Taejon 305700, South Korea.
   [Kim, Wonjun] SAIT, Future IT Res Ctr, Adv Media Lab, Seoul, South Korea.
   [Yoo, Seungwoo] Qualcomm Res Korea, Seoul, South Korea.
   [Kim, Changick] Korea Adv Inst Sci & Technol, Dept Elect Engn, Taejon 305732, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Qualcomm; Korea Advanced Institute of Science & Technology (KAIST)
RP Jung, C (corresponding author), ETRI, IT Convergence Technol Res Lab, Taejon 305700, South Korea.
EM peterjung@etri.re.kr; jazznova@kaist.ac.kr; yoos@qti.qualcomm.com;
   changick@kaist.ac.kr
RI Kim, Wonjun/JXN-3386-2024; Kim, Changick/C-1779-2011
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Bian P, 2009, LECT NOTES COMPUT SC, V5506, P251, DOI 10.1007/978-3-642-02490-0_31
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Caron Y, 2007, PATTERN RECOGN, V40, P2521, DOI 10.1016/j.patcog.2007.01.004
   Cheng M.-M., 2014, IEEE T PATTERN UNPUB
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Cohen Y, 2003, PATTERN RECOGN, V36, P2349, DOI 10.1016/S0031-3203(03)00120-1
   Draper BA, 2005, COMPUT VIS IMAGE UND, V100, P152, DOI 10.1016/j.cviu.2004.08.006
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Feng SH, 2010, SIGNAL PROCESS, V90, P1, DOI 10.1016/j.sigpro.2009.05.017
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gopalakrishnan V, 2009, IEEE T MULTIMEDIA, V11, P892, DOI 10.1109/TMM.2009.2021726
   Guo CL, 2008, PROC CVPR IEEE, P2908
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jost T, 2005, COMPUT VIS IMAGE UND, V100, P107, DOI 10.1016/j.cviu.2004.10.009
   Jung C, 2010, IEEE INT CON MULTI, P590, DOI 10.1109/ICME.2010.5582577
   Kim W, 2011, IEEE T CIRC SYST VID, V21, P446, DOI 10.1109/TCSVT.2011.2125450
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Ma Q, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3302129
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Mancas M, 2006, IEEE IMAGE PROC, P445, DOI 10.1109/ICIP.2006.312489
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Ninassi A, 2007, IEEE IMAGE PROC, P733
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin JZ, 2010, PATTERN RECOGN, V43, P1874, DOI 10.1016/j.patcog.2009.11.009
   Reynolds JH, 2003, NEURON, V37, P853, DOI 10.1016/S0896-6273(03)00097-7
   Rosin PL, 2009, PATTERN RECOGN, V42, P2363, DOI 10.1016/j.patcog.2009.04.021
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Shi LF, 2011, OPT ENG, V50, DOI 10.1117/1.3590723
   Snowden RJ, 2002, PSYCHOL SCI, V13, P180, DOI 10.1111/1467-9280.00433
   Tian LH, 2011, SIGNAL PROCESS-IMAGE, V26, P427, DOI 10.1016/j.image.2011.06.001
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu YN, 2010, OPT LETT, V35, P475, DOI 10.1364/OL.35.000475
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 51
TC 3
Z9 3
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2014
VL 32
IS 6-7
BP 405
EP 413
DI 10.1016/j.imavis.2014.04.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AJ4QM
UT WOS:000337660900003
DA 2024-07-18
ER

PT J
AU Quan, YH
   Xu, Y
   Sun, YP
AF Quan, Yuhui
   Xu, Yong
   Sun, Yuping
TI A distinct and compact texture descriptor
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Texture description; Local binary pattern; Fractal dimension;
   Multi-fractal analysis; Texture classification
ID GRAY-SCALE; CLASSIFICATION; VIEWPOINT
AB In this paper, a statistical approach to static texture description is developed, which combines a local pattern coding strategy with a robust global descriptor to achieve highly discriminative power, invariance to photometric transformation and strong robustness against geometric changes. Built upon the local binary patterns that are encoded at multiple scales, a statistical descriptor, called pattern fractal spectrum, characterizes the self-similar behavior of the local pattern distributions by calculating fractal dimension on each type of pattern. Compared with other fractal-based approaches, the proposed descriptor is compact, highly distinctive and computationally efficient. We applied the descriptor to texture classification. Our method has demonstrated excellent performance in comparison with state-of-the-art approaches on four challenging benchmark datasets. (C) 2014 Elsevier BM. All rights reserved.
C1 [Quan, Yuhui; Xu, Yong; Sun, Yuping] S China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
C3 South China University of Technology
RP Xu, Y (corresponding author), S China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Guangdong, Peoples R China.
EM yuhui.quan@mail.scut.edu.cn; yxu@scut.edu.cn; sun.yp@mail.scut.edu.cn
RI Sun, Yuping/I-6693-2019; Sun, Yuping/IZD-7776-2023
OI Sun, Yuping/0000-0003-3010-329X; Sun, Yuping/0000-0003-3010-329X
FU National Nature Science Foundations of China [61273255, 61211130308,
   61070091]; Fundamental Research Funds for the Central Universities(SCUT)
   [2013ZG0011]; GuangDong Technological Innovation Project [2013KJCX0010]
FX This paper has been recommended for acceptance by Sinisa Todorovic, PhD.
   Project supported by National Nature Science Foundations of
   China(61273255, 61211130308 and 61070091), Fundamental Research Funds
   for the Central Universities(SCUT 2013ZG0011) and GuangDong
   Technological Innovation Project(2013KJCX0010).
CR Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], 2007, Computer Vision
   [Anonymous], P INT C COMP VIS NIC
   [Anonymous], 1999, FRACTAL GEOMETRY NAT
   Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005
   Dana KJ, 1998, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.1998.698669
   Deguy S., 2000, P BMVC, P1
   Falconer K.J., 1997, TECHNIQUES FRACTAL G
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Ji H, 2013, IEEE T IMAGE PROCESS, V22, P286, DOI 10.1109/TIP.2012.2214040
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Kaplan LM, 1999, IEEE T IMAGE PROCESS, V8, P1572, DOI 10.1109/83.799885
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lazebnik S., 2006, DISCRIMINATIVE FRAME, P423
   Lazebnik S., 2006, LOCAL SEMILOCAL GLOB
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Levy Vehel J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P661, DOI 10.1109/CVPR.1992.223207
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liao S, 2007, INT CONF ACOUST SPEE, P1221
   Maenpaa T., 2003, The Local binary pattern approach to texture analysis: Extenxions and applications
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Mindru F, 2004, COMPUT VIS IMAGE UND, V94, P3, DOI 10.1016/j.cviu.2003.10.011
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2000, LECT NOTES COMPUT SC, V1842, P404
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   Xu Y., 2006, 2006 IEEE COMP SOC C, P1932
   Xu Y, 2012, COMPUT VIS IMAGE UND, V116, P999, DOI 10.1016/j.cviu.2012.05.003
   Xu Y, 2010, PROC CVPR IEEE, P161, DOI 10.1109/CVPR.2010.5540217
   Xu Y, 2009, PROC CVPR IEEE, P573, DOI 10.1109/CVPRW.2009.5206741
   Xu Y, 2009, INT J COMPUT VISION, V83, P85, DOI 10.1007/s11263-009-0220-6
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1
NR 40
TC 19
Z9 19
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2014
VL 32
IS 4
BP 250
EP 259
DI 10.1016/j.imavis.2014.02.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AG0MN
UT WOS:000335109700003
DA 2024-07-18
ER

PT J
AU Pedronette, DCG
   Penatti, OAB
   Torres, RD
AF Guimaraes Pedronette, Daniel Carlos
   Penatti, Otavio A. B.
   Torres, Ricardo da S.
TI Unsupervised manifold learning using Reciprocal kNN Graphs in image
   re-ranking and rank aggregation tasks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Content-based image retrieval; Re-ranking; Rank aggregation
ID SHAPE; RECOGNITION; CLASSIFICATION; RETRIEVAL
AB In this paper, we present an unsupervised distance learning approach for improving the effectiveness of image retrieval tasks. We propose a Reciprocal kNN Graph algorithm that considers the relationships among ranked lists in the context of a k-reciprocal neighborhood. The similarity is propagated among neighbors considering the geometry of the dataset manifold. The proposed method can be used both for re-ranking and rank aggregation tasks. Unlike traditional diffusion process methods, which require matrix multiplication operations, our algorithm takes only a subset of ranked lists as input, presenting linear complexity in terms of computational and storage requirements. We conducted a large evaluation protocol involving shape, color, and texture descriptors, various datasets, and comparisons with other post-processing approaches. The re-ranking and rank aggregation algorithms yield better results in terms of effectiveness performance than various state-of-the-art algorithms recently proposed in the literature, achieving bull's eye and MAP scores of 100% on the well-known MPEG-7 shape dataset (C) 2013 Elsevier B.V. All rights reserved.
C1 [Guimaraes Pedronette, Daniel Carlos] Univ Estadual Paulista UNESP, Dept Stat Appl Math & Comp, BR-13506900 Rio Claro, SP, Brazil.
   [Penatti, Otavio A. B.; Torres, Ricardo da S.] Univ Estadual Campinas, IC, RECOD Lab, BR-13083852 Campinas, SP, Brazil.
   [Penatti, Otavio A. B.] SAMSUNG Res Inst, BR-13097104 Campinas, SP, Brazil.
C3 Universidade Estadual Paulista; Universidade Estadual de Campinas
RP Pedronette, DCG (corresponding author), Univ Estadual Paulista UNESP, Dept Stat Appl Math & Comp, Av 24-A,1515, BR-13506900 Rio Claro, SP, Brazil.
EM daniel@rc.unesp.br; penatti@ic.unicamp.br; rtorres@ic.unicamp.br
RI Pedronette, Daniel C. G./E-7817-2015; Pedronette, Daniel/X-9057-2019
OI Pedronette, Daniel C. G./0000-0002-2867-4838; Pedronette,
   Daniel/0000-0002-2867-4838
FU AMD; FAEPEX; CAPES; FAPESP; CNPq
FX Authors thank AMD, FAEPEX, CAPES, FAPESP, and CNPq for financial
   support.
CR Almeida J, 2010, CIKM, P1365
   [Anonymous], 2012, IEEE C COMP VIS PATT
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Bai XA, 2010, LECT NOTES COMPUT SC, V6313, P328
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Chatzichristofis Savvas A., 2008, 2008 Ninth International Workshop on Image Analysis for Multimedia Interactive Services (WIAMIS), P191, DOI 10.1109/WIAMIS.2008.24
   Chatzichristofis SA, 2008, LECT NOTES COMPUT SC, V5008, P312
   Gopalan R, 2010, LECT NOTES COMPUT SC, V6313, P286
   Pedronette DCG, 2012, INFORM SCIENCES, V207, P19, DOI 10.1016/j.ins.2012.04.032
   Hoi SCH, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823752
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Jegou H, 2010, IEEE T PATTERN ANAL, V32, P2, DOI 10.1109/TPAMI.2008.285
   Jiang JY, 2011, IEEE I CONF COMP VIS, P794, DOI 10.1109/ICCV.2011.6126318
   Kontschieder Peter, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P655
   Kovalev V, 1998, 1998 MULTIMEDIA MODELING, PROCEEDINGS, P32, DOI 10.1109/MULMM.1998.722972
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling HB, 2010, LECT NOTES COMPUT SC, V6313, P411
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Nister David, 2006, CVPR
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Page L., 1999, 422 STANF INFOLAB ST
   Pedronette D.C.G., 2010, INT JOINT C COMP VIS, V1, P197
   Penatti O.A.B., PATTERN RECOGNITION
   Penatti OAB, 2011, LECT NOTES COMPUT SC, V7042, P240, DOI 10.1007/978-3-642-25085-9_28
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Rocha A, 2008, LECT NOTES COMPUT SC, V5259, P77, DOI 10.1007/978-3-540-88458-3_8
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Stehling R. O., 2002, Proceedings of the Eleventh International Conference on Information and Knowledge Management. CIKM 2002, P102, DOI 10.1145/584792.584812
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tao B, 2000, J VIS COMMUN IMAGE R, V11, P327, DOI 10.1006/jvci.1999.0448
   Torres RD, 2007, IMAGE VISION COMPUT, V25, P3, DOI 10.1016/j.imavis.2005.12.010
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J., EUR C COMP VIS ECCV
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
   Wang JY, 2011, PATTERN RECOGN, V44, P2367, DOI 10.1016/j.patcog.2011.02.007
   Xingwei Yang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2369, DOI 10.1109/CVPR.2011.5995325
   Yang XW, 2008, LECT NOTES COMPUT SC, V5305, P788, DOI 10.1007/978-3-540-88693-8_58
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Zagoris Konstantinos, 2010, Proceedings of the 14th Panhellenic Conference on Informatics (PCI 2010), P143, DOI 10.1109/PCI.2010.38
   Zhang ST, 2012, LECT NOTES COMPUT SC, V7573, P660, DOI 10.1007/978-3-642-33709-3_47
NR 46
TC 37
Z9 37
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2014
VL 32
IS 2
BP 120
EP 130
DI 10.1016/j.imavis.2013.12.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AD0DS
UT WOS:000332905300003
DA 2024-07-18
ER

PT J
AU Petridis, S
   Martinez, B
   Pantic, M
AF Petridis, Stavros
   Martinez, Brais
   Pantic, Maja
TI The MAHNOB Laughter database
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Laughter; Audiovisual; Thermal; Database; Audiovisual automatic laughter
   speech discrimination
ID EXPRESSION RECOGNITION; SPEECH; FEATURES
AB Laughter is clearly an audiovisual event, consisting of the laughter vocalization and of facial activity, mainly around the mouth and sometimes in the upper face. A major obstacle in studying the audiovisual aspects of laughter is the lack of suitable data. For this reason, the majority of past research on laughter classification/detection has focused on audio-only approaches. A few audiovisual studies exist which use audiovisual data from existing corpora of recorded meetings. The main problem with such data is that they usually contain large head movements which make audiovisual analysis very difficult. In this work, we present a new publicly available audiovisual database, the MAHNOB laughter database, suitable for studying laughter. It contains 22 subjects who were recorded while watching stimulus material, using two microphones, a video camera and a thermal camera. The primary goal was to elicit laughter, but in addition, posed smiles, posed laughter, and speech were recorded as well. In total, 180 sessions are available with a total duration of 3 h and 49 min. There are 563 laughter episodes, 849 speech utterances, 51 posed laughs, 67 speech-laughs episodes and 167 other vocalizations annotated in the database. We also report baseline experiments for audio, visual and audiovisual approaches for laughter-vs-speech discrimination as well as further experiments on discrimination between voiced laughter, unvoiced laughter and speech. These results suggest that the combination of audio and visual information is beneficial in the presence of acoustic noise and helps discriminating between voiced laughter episodes and speech utterances. Finally, we report preliminary experiments on laughter-vs-speech discrimination based on thermal images. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Petridis, Stavros; Martinez, Brais; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
   [Pantic, Maja] Univ Twente, EEMCS, Enschede, Netherlands.
C3 Imperial College London; University of Twente
RP Petridis, S (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
EM stavros.petridis04@imperial.ac.uk; b.martinez@imperial.ac.uk;
   m.pantic@imperial.ac.uk
FU European Research Council [ERC-2007-StG-203143]; EPSRC [EP/H016988/1];
   EC [231287]; EPSRC [EP/J017787/1, EP/H016988/1] Funding Source: UKRI
FX This work was supported by the European Research Council under the ERC
   Starting Grant agreement no. ERC-2007-StG-203143 (MAHNOB). The work of
   S. Petridis and B. Martinez is also supported in part by EPSRC grant
   EP/H016988/1: Pain rehabilitation: E/Motion-based automated coaching and
   EC's 7th Framework Programme [FP7/2007-2013] under the grant agreement
   no 231287 (SSPNet).
CR [Anonymous], 2008, P 10 INT C MULT INT
   [Anonymous], PHONETICS LAUGHING
   [Anonymous], P INT C CYB IEEE
   [Anonymous], 2001, Emotions, qualia, and consciousness, DOI [DOI 10.1142/9789812810687_0033, 10.1142/9789812810687_0033]
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], 2005, P INT C METH TECHN B
   [Anonymous], 2008, HONEST SIGNALS, DOI DOI 10.7551/MITPRESS/8022.001.0001
   [Anonymous], 2000, Laughter: A Scientific Investigation
   [Anonymous], 2007, P CIKM
   Bachorowski JA, 2001, J ACOUST SOC AM, V110, P1581, DOI 10.1121/1.1391244
   Bachorowski JA, 2001, PSYCHOL SCI, V12, P252, DOI 10.1111/1467-9280.00346
   Bickley CA., 1992, 2 INT C SPOK LANG PR 2 INT C SPOK LANG PR
   Brugman H., 2004, 4 INT C LANG RES EV
   Campbell N, 2009, LECT NOTES ARTIF INT, V5509, P176, DOI 10.1007/978-3-642-04793-0_11
   Carletta J, 2005, LECT NOTES COMPUT SC, V3869, P28
   De La Torre F, 2009, P 2009 3 INT C AFF C, P1, DOI 10.1109/ACII.2009.5349358
   Dupont S, 2000, IEEE T MULTIMEDIA, V2, P141, DOI 10.1109/6046.865479
   Eibl-Eibesfeldt I., 1973, SOCIAL COMMUNICATION, P163
   Eyben F, 2011, INT CONF ACOUST SPEE, P5844
   Fisher R.A., 1935, DESIGN EXPT
   Gatica-Perez D, 2009, IMAGE VISION COMPUT, V27, P1775, DOI 10.1016/j.imavis.2009.01.004
   González-Jiménez D, 2007, IEEE T INF FOREN SEC, V2, P413, DOI 10.1109/TIFS.2007.903543
   Grammer K., 1990, NAT RLICHKEIT SPRACH, P192
   Hernández B, 2007, COMPUT VIS IMAGE UND, V106, P258, DOI 10.1016/j.cviu.2006.08.012
   Hudenko WJ, 2009, J AUTISM DEV DISORD, V39, P1392, DOI 10.1007/s10803-009-0752-1
   Johnson D., 2011, TECHNICAL REPORT
   Kennedy L., 2004, NIST M REC WORKSH
   Kipper S, 2003, J NONVERBAL BEHAV, V27, P255, DOI 10.1023/A:1027384817134
   Knox M.T., 2007, INTERSPEECH, P2973
   Knox MT, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P797
   Laskowski K, 2008, LECT NOTES COMPUT SC, V5237, P149, DOI 10.1007/978-3-540-85853-9_14
   Laskowski K, 2009, INT CONF ACOUST SPEE, P4765, DOI 10.1109/ICASSP.2009.4960696
   Lichtenauer J, 2011, IMAGE VISION COMPUT, V29, P666, DOI 10.1016/j.imavis.2011.07.004
   Liu Y, 2006, COMPUT SPEECH LANG, V20, P468, DOI 10.1016/j.csl.2005.06.002
   Makagon MM, 2008, J ACOUST SOC AM, V124, P472, DOI 10.1121/1.2932088
   Martinez Brais., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - Workshops, CVPRW 2010, P48
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   MOWRER DE, 1987, J NONVERBAL BEHAV, V11, P191, DOI 10.1007/BF00990237
   NIEMITZ C, 1990, Z SEMIOTIK, V12, P323
   Niewiadomski R., 2010, INT C LANG RES EV
   Nwokah EE, 1999, J SPEECH LANG HEAR R, V42, P880, DOI 10.1044/jslhr.4204.880
   Owren MJ, 2001, EMO SOC BEH, P152
   Pantic M., 2009, IEEE INT C AFF COMP, V2
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Pantic M, 2009, IEEE SIGNAL PROC MAG, V26, P173, DOI 10.1109/MSP.2009.934186
   Patras I, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P97, DOI 10.1109/AFGR.2004.1301515
   Petridis S, 2009, IEEE INT CON MULTI, P1444, DOI 10.1109/ICME.2009.5202774
   Petridis S., 2011, IEEE INT C AUT FAC G
   Petridis S., 2011, THESIS IMPERIAL COLL
   Petridis S, 2011, IEEE T MULTIMEDIA, V13, P216, DOI 10.1109/TMM.2010.2101586
   Petridis S, 2010, INT CONF ACOUST SPEE, P5254, DOI 10.1109/ICASSP.2010.5494992
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Rabiner Lawrence, 2010, Digital Processing of Speech Signals
   Reuderink B, 2008, LECT NOTES COMPUT SC, V5237, P137, DOI 10.1007/978-3-540-85853-9_13
   RIEDMILLER M, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P586, DOI 10.1109/ICNN.1993.298623
   Rothgänger H, 1998, NATURWISSENSCHAFTEN, V85, P394, DOI 10.1007/s001140050522
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Scherer S, 2009, COGN SYST MONOGR, V6, P111
   Schuller B, 2008, LECT NOTES ARTIF INT, V5078, P99, DOI 10.1007/978-3-540-69369-7_12
   Schuller B, 2009, IMAGE VISION COMPUT, V27, P1760, DOI 10.1016/j.imavis.2009.02.013
   Sundaram S, 2007, J ACOUST SOC AM, V121, P527, DOI 10.1121/1.2390679
   Szameitat DP, 2009, J ACOUST SOC AM, V126, P354, DOI 10.1121/1.3139899
   Tilmanne J., 2010, J MULTIMODAL USER IN, P1
   Trouvain J., 2003, P INT C PHON SCI, P2793
   Truong KP, 2007, SPEECH COMMUN, V49, P144, DOI 10.1016/j.specom.2007.01.001
   Tsiamyrtzis P, 2007, INT J COMPUT VISION, V71, P197, DOI 10.1007/s11263-006-6106-y
   Valstar MF, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P38
   Vettin J, 2004, J NONVERBAL BEHAV, V28, P93, DOI 10.1023/B:JONB.0000023654.73558.72
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Weenink D., 2005, TECH REP
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Zeng ZH, 2008, IEEE T MULTIMEDIA, V10, P570, DOI 10.1109/TMM.2008.921737
NR 72
TC 68
Z9 70
U1 1
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2013
VL 31
IS 2
BP 186
EP 202
DI 10.1016/j.imavis.2012.08.014
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 102KN
UT WOS:000315843600008
OA Green Published
DA 2024-07-18
ER

PT J
AU Chane, CS
   Mansouri, A
   Marzani, FS
   Boochs, F
AF Chane, Camille Simon
   Mansouri, Alamin
   Marzani, Franck S.
   Boochs, Frank
TI Integration of 3D and multispectral data for cultural heritage
   applications: Survey and perspectives
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cultural heritage; Multispectral imaging; 3D digitization; Registration;
   Data fusion; Photogrammetry
ID SPECTRAL REFLECTANCE; MAGNETIC POSITION; IMAGING-SYSTEM; COLOR-SIGNAL;
   CALIBRATION; RECONSTRUCTION; SURFACE; MODEL; ILLUMINATION; REGISTRATION
AB Cultural heritage is increasingly put through imaging systems such as multispectral cameras and 3D scanners. Though these acquisition systems are often used independently, they collect complementary information (spectral vs. spatial) used for the study, archiving and visualization of cultural heritage. Recording 3D and multispectral data in a single coordinate system enhances the potential insights in data analysis.
   We present the state of the art of such acquisition systems and their applications for the study of cultural heritage. We also describe existing registration techniques that can be used to obtain 3D models with multispectral texture and explore the idea of optically tracking acquisition systems to ensure an easy and precise registration. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Chane, Camille Simon; Marzani, Franck S.] Univ Bourgogne, Le2i, UFR Sci & Tech, Batiment Mirande,BP 47870, F-21078 Dijon, France.
   [Chane, Camille Simon; Boochs, Frank] Univ Appl Sci Mainz, Inst Spatial Informat & Surveying Technol, I3mainz, Mainz, Germany.
   [Mansouri, Alamin] Univ Bourgogne, Le2i, F-89010 Auxerre, France.
C3 Universite de Bourgogne; Universite de Bourgogne
RP Chane, CS (corresponding author), Univ Bourgogne, Le2i, UFR Sci & Tech, Batiment Mirande,BP 47870, F-21078 Dijon, France.
EM camille.simon@u-bourgogne.fr; alamin.mansouri@u-bourgogne.fr;
   franck.mrzani@u-bourgogne.fr; frank.boochs@geoinform.fh-mainz.de
FU Conseil Regional de Bourgogne (France) and i3mainz; Institute for
   Spatial Information and Surveying Technology (Germany)
FX The authors are grateful for the financial support provided by the
   Conseil Regional de Bourgogne (France) and i3mainz, Institute for
   Spatial Information and Surveying Technology (Germany).
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Andreetto M, 2004, IEEE T IMAGE PROCESS, V13, P352, DOI 10.1109/TIP.2003.821351
   Bajcsy R, 1996, INT J COMPUT VISION, V17, P241, DOI 10.1007/BF00128233
   Barni M, 2005, IEEE SIGNAL PROC MAG, V22, P141, DOI 10.1109/MSP.2005.1511835
   Beraldin JA, 2000, ISPRS J PHOTOGRAMM, V55, P230, DOI 10.1016/S0924-2716(00)00013-7
   Bernardini F, 2002, IEEE COMPUT GRAPH, V22, P59, DOI 10.1109/38.974519
   Bernardini F, 2002, COMPUT GRAPH FORUM, V21, P149, DOI 10.1111/1467-8659.00574
   Bernardini F, 2001, IEEE T VIS COMPUT GR, V7, P318, DOI 10.1109/2945.965346
   Berns R., 2005, P 10 C INT COLOUR AS, P369
   Berns Roy S., 2008, CGIV 2008/MCS'08. 4th European Conference on Colour in Graphics, Imaging and Vision. 10th International Symposium on Multispectral Colour Science, P484
   Berns Roy., 2005, 14 TRIENNIAL M CONSE, P743
   Berns RoyS., 2005, P NATL ACAD SCI SACK, V12, P105
   Berns RS, 2001, J IMAGING SCI TECHN, V45, P305
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bianco S, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2982004
   Blais F, 2008, LASERS IN THE CONSERVATION OF ARTWORKS, P435
   BLAIS F, 2005, INT WORKSH REC MOD V, P101
   Blais F, 2006, MACH VISION APPL, V17, P395, DOI 10.1007/s00138-006-0025-3
   Bloechl K., 2010, P SOC PHOTO-OPT INS, V7531
   Boochs F., 2009, ROBOTICS APPL
   Bouchard MB, 2009, OPT EXPRESS, V17, P15670, DOI 10.1364/OE.17.015670
   Brauers J., 2006, 12 WORKSH FARBB
   Brauers J, 2008, IEEE T IMAGE PROCESS, V17, P2368, DOI 10.1109/TIP.2008.2006605
   Brauers J, 2008, 2008 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS & INTERPRETATION, P85, DOI 10.1109/SSIAI.2008.4512291
   Brauers J, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.031103
   Brauers J, 2008, IEEE IMAGE PROC, P525, DOI 10.1109/ICIP.2008.4711807
   Brusco N, 2006, MACH VISION APPL, V17, P373, DOI 10.1007/s00138-006-0026-2
   Callieri M, 2004, IEEE COMPUT GRAPH, V24, P16, DOI 10.1109/MCG.2004.1274056
   CHANG PR, 1995, IEEE T IMAGE PROCESS, V4, P81, DOI 10.1109/83.350812
   Cheung V, 2005, J OPT SOC AM A, V22, P1231, DOI 10.1364/JOSAA.22.001231
   Clarke T., 2000, Int. Arch. Photogramm. Remote Sens, V33, P137
   Colantoni P., 2006, PROC 14 EUR C SIGNAL, P1
   Connah D, 2005, PROC SPIE, P65, DOI 10.1117/12.586315
   Corsini M, 2009, COMPUT GRAPH FORUM, V28, P1755, DOI 10.1111/j.1467-8659.2009.01552.x
   Cotte P, 2006, Archiving 2006: Final Program and Proceedings, P228
   Cotte P., 2003, Final Program and Proceedings of the Digital Photography Conference 2003, P161
   Cotte P., 2006, 3 EUR C COL GRAPH IM, P311
   Day E. A., 2003, THESIS
   DELANEY JK, 2005, P NATL ACAD SCI USA, P120
   Drew MS, 2007, J OPT SOC AM A, V24, P294, DOI 10.1364/JOSAA.24.000294
   Du H, 2009, IEEE I CONF COMP VIS, P175, DOI 10.1109/ICCV.2009.5459162
   Easton RL, 2004, 32ND APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P111
   Everdell N.L., 2009, P SOC PHOTO-OPT INS, V7371
   Franken T, 2005, VISUAL COMPUT, V21, P619, DOI 10.1007/s00371-005-0309-z
   Fraunhofer, 2011, HANDL OPT 3D SCANN K
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Guarnieri A, 2003, INT ARCH PHOTOGRAMME, VXXXIV, P176
   Guidi G., 2003, P 9 INT S VIRT REAL, P85
   Guidi G, 2006, MACH VISION APPL, V17, P349, DOI 10.1007/s00138-006-0029-z
   Haneishi H, 2000, APPL OPTICS, V39, P6621, DOI 10.1364/AO.39.006621
   Hardeberg J.Y., 1999, THESIS
   Hardeberg JY, 2002, OPT ENG, V41, P2532, DOI 10.1117/1.1503346
   Hawkins Tim, 2001, P C VIRT REAL ARCH C, P333, DOI DOI 10.1145/584993.585053
   Hefele J, 2001, PROC SPIE, V4189, P170, DOI 10.1117/12.417194
   Hefele J., 2002, INT ARCH PHOTOGRAM 5, VXXXIV, P33
   HO JA, 1990, IEEE T PATTERN ANAL, V12, P966, DOI 10.1109/34.58869
   Ikeuchi K, 2007, INT J COMPUT VISION, V75, P189, DOI 10.1007/s11263-007-0039-y
   Imai F.H., 2003, TECHNICAL REPORT
   Imai F.H., 1999, Proc of the International Symposium on Multispectral Imaging and Color Reproduction for Digital Archives, P42
   Imai FH, 2000, J IMAGING SCI TECHN, V44, P280
   Imai FH, 2001, PICS 2001: IMAGE PROCESSING, IMAGE QUALITY, IMAGE CAPTURE, SYSTEMS CONFERENCE, PROCEEDINGS, P185
   Imai FH, 2002, PROC SPIE, V4421, P504, DOI 10.1117/12.464766
   Jordan Johannes, 2010, VMV 2010 VISION MODE, P259
   Kawakami R., 2001, IEEE C COMP VIS PATT, P2329
   Kim SJ, 2010, IEEE T VIS COMPUT GR, V16, P1441, DOI 10.1109/TVCG.2010.172
   Koller D., 2006, J ROMAN ARCHAEOL S3, P237
   Lahanier C., 2005, P 14 TRIENN ICOM CC, P30
   Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849
   LEVOY M, 2002, INTERACTIVE KIOSK TR
   Li RJ, 2010, LECT NOTES COMPUT SC, V6436, P381
   Lin S, 2001, PROC CVPR IEEE, P341
   Lu Z, 2010, PROC CVPR IEEE, P1205, DOI 10.1109/CVPR.2010.5539829
   Maas HG, 1997, P SOC PHOTO-OPT INS, V3174, P106, DOI 10.1117/12.279771
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   MALONEY LT, 1986, J OPT SOC AM A, V3, P29, DOI 10.1364/JOSAA.3.000029
   Mansouri A, 2005, IEEE IMAGE PROC, P2053
   Mansouri A, 2005, INT J ROBOT AUTOM, V20, P94, DOI 10.2316/Journal.206.2005.2.206-2784
   Mansouri A, 2005, OPT ENG, V44, DOI 10.1117/1.1839889
   Mansouri A, 2007, IEEE MULTIMEDIA, V14, P40, DOI 10.1109/MMUL.2007.22
   Martinez K, 2002, P IEEE, V90, P28, DOI 10.1109/5.982403
   Miao LD, 2004, IEEE IMAGE PROC, P3343
   Nehab D, 2005, ACM T GRAPHIC, V24, P536, DOI 10.1145/1073204.1073226
   Novati G, 2005, INT J DIGIT LIBRARIE, V5, P167, DOI 10.1007/s00799-004-0103-y
   Ohta Y., 1994, P 3 EUR C COMP VIS, V2, P234
   Palma G, 2010, EUR IT CHAPT C, V7010, P89
   Palma G, 2010, ACM J COMPUT CULT HE, V3, DOI 10.1145/1841317.1841321
   Paperno E, 2001, IEEE T MAGN, V37, P1938, DOI 10.1109/20.951014
   Park IC, 2007, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD.2007.4601872
   Pavlidis G, 2007, J CULT HERIT, V8, P93, DOI 10.1016/j.culher.2006.10.007
   Pelagotti A, 2008, IEEE SIGNAL PROC MAG, V25, P27, DOI 10.1109/MSP2008-923095
   Poger S., 2001, IEEE C COMP VIS PATT
   Pollefeys M, 2003, IEEE COMPUT GRAPH, V23, P20, DOI 10.1109/MCG.2003.1198259
   Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346
   Pulli K., 1997, THESIS
   RAAB FH, 1979, IEEE T AERO ELEC SYS, V15, P709, DOI 10.1109/TAES.1979.308860
   Rapantzikos K, 2005, IEEE IMAGE PROC, P1813
   Remondino F., 2009, 9 C OPT 3D MEAS TECH
   Remondino F, 2008, IEEE SIGNAL PROC MAG, V25, P55, DOI 10.1109/MSP.2008.923093
   Ribés A, 2005, J IMAGING SCI TECHN, V49, P563
   Rocchini C, 2002, VISUAL COMPUT, V18, P186, DOI 10.1007/s003710100146
   Rocchini C, 2001, COMPUT GRAPH FORUM, V20, pC299
   Rocchini C., 2001, ICHIM 01, P265
   Rushmeier H., 1999, P 2 INT C 3 D DIG IM, P98
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Schechner YY, 2002, IEEE T PATTERN ANAL, V24, P1334, DOI 10.1109/TPAMI.2002.1039205
   Schutze R., 2009, 9 C OPT 3D MEAS TECH
   Seulin R, 2006, IMAGING SCI J, V54, P111, DOI 10.1179/174313106X98755
   Shen HL, 2007, OPT EXPRESS, V15, P15545, DOI 10.1364/OE.15.015545
   Sherman JT, 2007, IEEE T MAGN, V43, P2725, DOI 10.1109/TMAG.2007.893314
   Shi MH, 2002, J OPT SOC AM A, V19, P645, DOI 10.1364/JOSAA.19.000645
   Sitnik R., 2010, P SOC PHOTO-OPT INS, V7526
   Tan RT, 2005, IEEE T PATTERN ANAL, V27, P178, DOI 10.1109/TPAMI.2005.36
   Taylor JC, 2003, ASTM STAND NEWS, V31, P14
   Tominaga S, 1996, J OPT SOC AM A, V13, P2163, DOI 10.1364/JOSAA.13.002163
   TOMINAGA S, 1989, J OPT SOC AM A, V6, P576, DOI 10.1364/JOSAA.6.000576
   Tominaga S, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.3036180
   Tonsho K., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4663, P370, DOI 10.1117/12.453008
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   WOLFF LB, 1990, IEEE T PATTERN ANAL, V12, P1059, DOI 10.1109/34.61705
   Yamaguchi M, 2008, J IMAGING SCI TECHN, V52, DOI 10.2352/J.ImagingSci.Technol.(2008)52:1(010201)
   Zhang XD, 2008, J OPT SOC AM A, V25, P371, DOI 10.1364/JOSAA.25.000371
   Zhao Y, 2007, COLOR RES APPL, V32, P343, DOI 10.1002/col.20341
   Zheng JY, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P348, DOI 10.1109/MMCS.1998.693663
   Zuzak KJ, 2009, PROC SPIE, V7210, DOI 10.1117/12.810068
NR 125
TC 58
Z9 60
U1 1
U2 53
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2013
VL 31
IS 1
BP 91
EP 102
DI 10.1016/j.imavis.2012.10.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 084RP
UT WOS:000314557100007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jeni, LA
   Lorincz, A
   Nagy, T
   Palotai, Z
   Sebok, J
   Szabó, Z
   Takács, D
AF Jeni, Laszlo A.
   Lorincz, Andras
   Nagy, Tamas
   Palotai, Zsolt
   Sebok, Judit
   Szabo, Zoltan
   Takacs, Daniel
TI 3D shape estimation in video sequences provides high precision
   evaluation of facial expressions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Constrained Local Model; Shape information; Action unit recognition;
   Emotion classification; CK; BU-4DFE
ID RECOGNITION
AB Person independent and pose invariant estimations of facial expressions and action unit (AU) intensity estimation are important for situation analysis and for automated video annotation. We evaluated raw 2D shape data of the CK+ database, used Procrustes transformation and the multi-class SVM leave-one-out method for classification. We found close to 100% performance demonstrating the relevance and the strength of details of the shape. Precise 3D shape information was computed by means of constrained local models (CLM) on video sequences. Such sequences offer the opportunity to compute a time-averaged '3D personal mean shape' (PMS) from the estimated CLM shapes, which - upon subtraction - gives rise to person independent emotion estimation. On CK+ data PMS showed significant improvements over AU0 normalization: performance reached and sometimes surpassed state-of-the-art results on emotion classification and on AU intensity estimation. 3D PMS from 3D CLM offers pose invariant emotion estimation that we studied by rendering a 3D emotional database for different poses and different subjects from the BU 4DFE database. Frontal shapes derived from CLM fits of the 3D shape were evaluated. Results demonstrate that shape estimation alone can be used for robust, high quality pose invariant emotion classification and AU intensity estimation. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Jeni, Laszlo A.] Univ Tokyo, Tokyo 1138654, Japan.
   [Lorincz, Andras; Nagy, Tamas; Sebok, Judit; Szabo, Zoltan; Takacs, Daniel] Eotvos Lorand Univ, H-1364 Budapest, Hungary.
C3 University of Tokyo; Eotvos Lorand University
RP Jeni, LA (corresponding author), Univ Tokyo, Tokyo 1138654, Japan.
EM laszlo.jeni@ieee.org; andras.lorincz@elte.hu; bkil.hu@gmail.com;
   palotai@sparsense.com; dymorse@gmail.com; szzoli@cs.elte.hu;
   takacsd@gmail.com
RI Levendovics, Tamas/ABB-2564-2021; Lorincz, Andras/H-4125-2012
OI Levendovics, Tamas/0000-0002-5485-9588; Lorincz,
   Andras/0000-0002-1280-3447; Jeni, Laszlo A./0000-0002-2830-700X
FU European Union; European Social Fund [TAMOP 4.2.1./B-09/1/KMR-2010-0003,
   KMOP 1.2-08/1-2008-002]
FX We are grateful to Jason Saragih for providing his CLM code for our
   work. Research was supported by the European Union and cofinanced by the
   European Social Fund (grant agreement numbers TAMOP
   4.2.1./B-09/1/KMR-2010-0003 and KMOP 1.2-08/1-2008-002).
CR [Anonymous], J NEURAL SYST
   [Anonymous], 2011, 2011 INT C EL MACH S, DOI [10.1109/MWSCAS.2011.6026417, DOI 10.1109/MWSCAS.2011.6026417]
   [Anonymous], IEEE INT WORKSH BENC
   [Anonymous], WORKSH GEST REC CVPR
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Chang Y, 2006, IMAGE VISION COMPUT, V24, P605, DOI 10.1016/j.imavis.2005.08.006
   Chew Sien W., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P915, DOI 10.1109/FG.2011.5771373
   Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   Ekman P., 2005, WHAT FACE REVEALS BA
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   McLellan T, 2010, COGNITION EMOTION, V24, P1277, DOI 10.1080/02699930903306181
   Rudovic O, 2010, LECT NOTES COMPUT SC, V6312, P350, DOI 10.1007/978-3-642-15552-9_26
   Sandbach G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P406, DOI 10.1109/FG.2011.5771434
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Sun Y, 2010, IEEE T SYST MAN CY A, V40, P461, DOI 10.1109/TSMCA.2010.2041659
   Susskind JM, 2007, NEUROPSYCHOLOGIA, V45, P152, DOI 10.1016/j.neuropsychologia.2006.05.001
   Taheri S., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P306, DOI 10.1109/FG.2011.5771415
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Vuong Le, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P414, DOI 10.1109/FG.2011.5771435
   Whitehill J, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P97
   Yin L., 2008, 8 IEEE INT C AUTOMAT, P1
   Zheng WM, 2010, LECT NOTES COMPUT SC, V6316, P490, DOI 10.1007/978-3-642-15567-3_36
NR 34
TC 28
Z9 30
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2012
VL 30
IS 10
BP 785
EP 795
DI 10.1016/j.imavis.2012.02.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 027YD
UT WOS:000310389100010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cremers, D
AF Cremers, Daniel
TI Optimal solutions for semantic image decomposition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optimization; Efficient algorithms; Convexity; Semantic labeling
AB Bridging the gap between low-level and high-level image analysis has been a central challenge in computer vision throughout the last decades. In this article I will point out a number of recent developments in low-level image analysis which open up new possibilities to bring together concepts of high-level and low-level vision. The key observation is that numerous multi-label optimization problems can nowadays be efficiently solved in a near-optimal manner, using either graph-theoretic algorithms or convex relaxation techniques. Moreover, higher-level semantic knowledge can be learned and imposed on the basis of such multi-label formulations. (c) 2012 Elsevier B.V. All rights reserved.
C1 Tech Univ Munich, Dept Comp Sci, Munich, Germany.
C3 Technical University of Munich
RP Cremers, D (corresponding author), Tech Univ Munich, Dept Comp Sci, Munich, Germany.
EM cremers@tum.de
OI Cremers, Daniel/0000-0002-3079-7984
CR [Anonymous], 1987, Visual Reconstruction
   Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673
   Chambolle A., 2008, TR200805 U BONN DEP
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2010.5540067
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Klodt M, 2011, IEEE I CONF COMP VIS, P2236, DOI 10.1109/ICCV.2011.6126502
   Ladicky L., 2008, EUR C COMP VIS
   Lellmann J., 2008, CONVEX MULTICLASS IM
   Liu XQ, 2010, IEEE T PATTERN ANAL, V32, P1182, DOI 10.1109/TPAMI.2009.120
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Nieuwenhuis C., IEEE T PATT IN PRESS
   Strekalovskiy E., 2011, IEEE INT C COMP VIS
   Zach C., 2008, WORKSH VIS MOD VIS O
NR 15
TC 1
Z9 2
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 476
EP 477
DI 10.1016/j.imavis.2011.12.011
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100007
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Hauberg, S
   Sommer, S
   Pedersen, KS
AF Hauberg, Soren
   Sommer, Stefan
   Pedersen, Kim Steenstrup
TI Natural metrics and least-committed priors for articulated tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Articulated tracking; Brownian motion on Riemannian manifolds;
   Manifold-valued stochastic differential equations; Numerical solutions
   to SDEs
ID HUMAN MOTION
AB In articulated tracking, one is concerned with estimating the pose of a person in every frame of a film. This pose is most often represented as a kinematic skeleton where the joint angles are the degrees of freedom. Least-committed predictive models are then phrased as a Brownian motion in joint angle space. However, the metric of the joint angle space is rather unintuitive as it ignores both bone lengths and how bones are connected. As Brownian motion is strongly linked with the underlying metric, this has severe impact on the predictive models. We introduce the spatial kinematic manifold of joint positions, which is embedded in a high dimensional Euclidean space. This Riemannian manifold inherits the metric from the embedding space, such that distances are measured as the combined physical length that joints travel during movements. We then develop a least-committed Brownian motion model on the manifold that respects the natural metric. This model is expressed in terms of a stochastic differential equation, which we solve using a novel numerical scheme. Empirically, we validate the new model in a particle filter based articulated tracking system. Here, we not only outperform the standard Brownian motion in joint angle space, we are also able to specialise the model in ways that otherwise are both difficult and expensive in joint angle space. (c) 2011 Elsevier B.V. All rights reserved.
C1 [Hauberg, Soren; Sommer, Stefan; Pedersen, Kim Steenstrup] Univ Copenhagen, Dept Comp Sci, eSci Ctr, Copenhagen, Denmark.
C3 University of Copenhagen
RP Hauberg, S (corresponding author), Univ Copenhagen, Dept Comp Sci, eSci Ctr, Univ Pk 5, Copenhagen, Denmark.
EM hauberg@diku.dk; sommer@diku.dk; kimstp@diku.dk
RI Hauberg, Søren/L-2104-2016; Steenstrup Pedersen, Kim/L-8748-2016;
   Sommer, Stefan/G-3138-2013
OI Steenstrup Pedersen, Kim/0000-0003-3713-0960; Sommer,
   Stefan/0000-0001-6784-0328
CR ABEND W, 1982, BRAIN, V105, P331, DOI 10.1093/brain/105.2.331
   [Anonymous], 2007, Proceedings of Machine Learning Research
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Brubaker MA, 2010, INT J COMPUT VISION, V87, P140, DOI 10.1007/s11263-009-0274-5
   Cappé O, 2007, P IEEE, V95, P899, DOI 10.1109/JPROC.2007.893250
   Engell-Norregård M, 2011, COMPUT GRAPH-UK, V35, P288, DOI 10.1016/j.cag.2010.12.011
   Erleben Kenny., 2005, Physics-based animation
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Grochow K, 2004, ACM T GRAPHIC, V23, P522, DOI 10.1145/1015706.1015755
   Hairer E., 2004, Geometric Numerical Integration (Springer Series in Computational Mathematics)
   Hauberg S, 2011, LECT NOTES COMPUT SC, V6494, P758, DOI 10.1007/978-3-642-19318-7_59
   Hauberg S, 2011, INT J COMPUT VISION, V94, P317, DOI 10.1007/s11263-011-0433-3
   Hauberg S, 2010, LECT NOTES COMPUT SC, V6311, P425, DOI 10.1007/978-3-642-15549-9_31
   Herda L, 2004, LECT NOTES COMPUT SC, V3022, P405
   Hsu E. P., 2002, Stochastic Analysis on Manifolds
   Huckemann S, 2010, STAT SINICA, V20, P1
   Kjellström H, 2010, PROC CVPR IEEE, P747, DOI 10.1109/CVPR.2010.5540140
   Kloeden PE., 1992, STOCHASTIC DIFFERENT
   Lu Z., 2008, ADV NEURAL INFORM PR, P1705
   Mardia K. V., 1999, DIRECTIONAL STAT, DOI DOI 10.1002/9780470316979
   MILLER MI, 1995, IEEE T SIGNAL PROCES, V43, P2678, DOI 10.1109/78.482117
   MORASSO P, 1981, EXP BRAIN RES, V42, P223
   Nocedal J., 1999, NUMERICAL OPTIMIZATI, DOI [DOI 10.1007/B98874, 10.1007/b98874]
   Oksendal B., 1989, STOCHASTIC DIFFERENT, VSecond
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Sato K., 1999, CAMBRIDGE STUDIES AD, V68
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Sminchisescu C., 2004, Proc. 21st International Conference on Machine Learning, P96
   Urtasun R, 2005, IEEE I CONF COMP VIS, P403
   Urtasun R., 2006, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2006.15
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Yamamoto M, 2000, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.2000.855813
   Zhang F, 2007, LECT NOTES COMPUT SC, V4679, P303
NR 33
TC 12
Z9 12
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2012
VL 30
IS 6-7
SI SI
BP 453
EP 461
DI 10.1016/j.imavis.2011.11.009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 977BA
UT WOS:000306630100008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fu, Y
   Hsiang, TR
AF Fu, Yu
   Hsiang, Tien-Ruey
TI A fast robot homing approach using sparse image waypoints
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image sequence-based navigation; Sparse waypoints; Log-polar transform
ID NAVIGATION; VISION
AB This paper proposes a fast image sequence-based navigation approach for a flat route represented in sparse waypoints. Instead of purely optimizing the length of the path, this paper aims to speed up the navigation by lengthening the distance between consecutive waypoints. When local visual homing in a variable velocity is applied for robot navigation between two waypoints, the robot's speed changes according to the distance between waypoints. Because long distance implies large scale difference between the robot's view and the waypoint image, log-polar transform is introduced to find a correspondence between images and infer a less accurate motion vector. In order to maintain the navigation accuracy, our prior work on local visual homing with SIFT feature matching is adopted when the robot is relatively close to the waypoint. Experiments support the proposed navigation approach in a multiple-waypoint route. Compared to other prior work on visual homing with SIFT feature matching, the proposed navigation approach requires fewer waypoints and the navigation speed is improved without compromising the accuracy in navigation. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Fu, Yu] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
   [Hsiang, Tien-Ruey] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology
RP Fu, Y (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM D9407201@mail.ntust.edu.tw; trhsiang@mail.ntust.edu.tw
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Argyros AA, 2005, AUTON ROBOT, V19, P7, DOI 10.1007/s10514-005-0603-7
   Booij O, 2007, IEEE INT CONF ROBOT, P3927, DOI 10.1109/ROBOT.2007.364081
   Chen ZC, 2009, IEEE T ROBOT, V25, P749, DOI 10.1109/TRO.2009.2017140
   Chung S.-L., 2009, P 6 INT C UB ROB AMB, P163
   Colafrancesco M., 2009, ICRA 2009 WORKSH SAF
   Courbon J, 2008, AUTON ROBOT, V25, P253, DOI 10.1007/s10514-008-9093-8
   Erinc G, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P5807, DOI 10.1109/IROS.2009.5354301
   Fontanelli D, 2009, INT J ROBOT RES, V28, P802, DOI 10.1177/0278364908097660
   Fraundorfer F, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3878
   Goedemé T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9
   Hutchinson S., 2009, IEEE T SYSTEMS B PP, V99, P1
   Ido Junichi, 2009, International Journal of Robotics Research, V28, P315, DOI 10.1177/0278364908095841
   López-Nicolás G, 2008, ROBOT AUTON SYST, V56, P592, DOI 10.1016/j.robot.2007.10.005
   Lopez-Nicolás G, 2010, MECHATRONICS, V20, P315, DOI 10.1016/j.mechatronics.2010.01.005
   Mariottini GL, 2007, IEEE T ROBOT, V23, P87, DOI 10.1109/TRO.2006.886842
   Matsumoto Y, 2003, MACH VISION APPL, V14, P121, DOI 10.1007/s00138-002-0104-z
   Möller R, 2009, ROBOT AUTON SYST, V57, P87, DOI 10.1016/j.robot.2008.02.001
   Remazeilles A, 2007, ROBOT AUTON SYST, V55, P345, DOI 10.1016/j.robot.2006.10.002
   Royer E, 2007, INT J COMPUT VISION, V74, P237, DOI 10.1007/s11263-006-0023-y
   Sagüés C, 2005, ROBOT AUTON SYST, V50, P41, DOI 10.1016/j.robot.2004.08.005
   SCHWARTZ EL, 1980, VISION RES, V20, P645, DOI 10.1016/0042-6989(80)90090-5
   SEGVIC S, 2007, P IEEE C COMP VIS PA, P1
   Traver VJ, 2010, ROBOT AUTON SYST, V58, P378, DOI 10.1016/j.robot.2009.10.002
   Yu Fu, 2010, 2010 IEEE International Conference on Systems, Man and Cybernetics (SMC 2010), P493, DOI 10.1109/ICSMC.2010.5642030
   Zhang Alan M., 2009, International Journal of Robotics Research, V28, P331, DOI 10.1177/0278364908098412
   Zokai S, 2005, IEEE T IMAGE PROCESS, V14, P1422, DOI 10.1109/TIP.2005.854501
NR 27
TC 3
Z9 3
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2012
VL 30
IS 2
BP 109
EP 121
DI 10.1016/j.imavis.2012.02.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 934ZJ
UT WOS:000303486200005
DA 2024-07-18
ER

PT J
AU Tseng, CC
   Lien, JJJ
AF Tseng, Chien-Chung
   Lien, Jenn-Jier James
TI Colored exaggerative caricature creation using inter- and
   intra-correlations of feature shapes and positions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Caricaturing method; Inter- and intra-correlations; Principle component
   analysis
AB This paper develops a system comprising a statistics-based exaggerative (SBE) module and a non-photorealistic rendering (NPR) module for the automatic creation of colored facial caricatures with exaggerated facial features and individual facial details such as beards and moles. Unlike previous research that focused on the inter-correlation (the difference between the facial features of input image and those of the mean face in the training database), the SBE module exaggerates the input image utilizing an iterative approach based on both inter- and intra-correlations of the facial features. The intra-correlation considered in this study makes the comparison with other features within the same input image, and has the effect of exaggerating the major facial features while simultaneously subduing the visual impact of non-major facial features. The NPR module consists of a black-and-white sketch creation process and a colored facial cartoon creation process. The results of the two processes are combined to generate a colored cartoon-like sketch, which is then warped into a colored exaggerative facial caricature based on the corresponding exaggerative shape and position created by the SBE module. The experimental results demonstrate that the proposed method can emphasize the major characteristics of a face better than previous methods that only considered feature inter-correlation. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Tseng, Chien-Chung; Lien, Jenn-Jier James] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
C3 National Cheng Kung University
RP Tseng, CC (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 70101, Taiwan.
EM ed@csie.ncku.edu.tw
CR AKLEMAN E, 1997, P ACM SIGGRAPH 97, P145
   [Anonymous], 2002, PROC 10 ACM INT C MU
   [Anonymous], 2000, STAT MODELS APPEARAN
   BLOMMAERT F J J, 1990, Spatial Vision, V5, P15, DOI 10.1163/156856890X00066
   Brennan S. E., 1982, THESIS MIT CAMBRIDGE
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chen H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P433, DOI 10.1109/ICCV.2001.937657
   Chen Hong., 2004, P 3 INT S NONPHOTORE, P95, DOI DOI 10.1145/987
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DeCarlo D, 2002, ACM T GRAPHIC, V21, P769, DOI 10.1145/566570.566650
   Gao Y., 2003, IEEE T SYST MAN CY A, V33
   Goldstein E.B., 2001, Sensation and perception, V6th
   Gooch B, 2004, ACM T GRAPHIC, V23, P27, DOI 10.1145/966131.966133
   Hsu RL, 2003, IEEE T PATTERN ANAL, V25, P1388, DOI 10.1109/TPAMI.2003.1240113
   Kondo T, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P283, DOI 10.1109/IM.1997.603877
   Koshimizu H., 1999, P IEEE INT C SYST MA, P294
   Lai K.H., 2006, P ACTA COMP INT
   Li T.-Y., 2004, P AS C COMP VIS, V2, P89
   Liang L, 2002, 10TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P386, DOI 10.1109/PCCGA.2002.1167882
   Liu J., 2006, ACM MULTIMEDIA, P683
   Liu JF, 2009, LECT NOTES COMPUT SC, V5371, P413
   Martinez A., 1998, AR FACE DATABASE
   MAURO R, 1992, MEM COGNITION, V20, P433, DOI 10.3758/BF03210927
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   Ni F, 2008, INT J PATTERN RECOGN, V22, P1647, DOI 10.1142/S0218001408006867
   Obaid Mohammad., 2009, P INT C ADV COMPUTER, P285, DOI [10.1145/1690388.1690437, DOI 10.1145/1690388.1690437]
   Pujol A, 2000, INT C PATT RECOG, P1072, DOI 10.1109/ICPR.2000.905657
   Qu YG, 2006, ACM T GRAPHIC, V25, P1214, DOI 10.1145/1141911.1142017
   Redman L., 1984, DRAW CARICATURES
   Roh MC, 2007, INT J PATTERN RECOGN, V21, P1017, DOI 10.1142/S0218001407005818
   Sadimon SB, 2010, 2010 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW 2010), P383, DOI 10.1109/CW.2010.33
   Shet R. N., 2005, IEE International Conference on Visual Information Engineering (VIE 2005) (CP No.509), P23, DOI 10.1049/cp:20050066
   Smitaveja J, 2009, PROCEEDINGS OF THE 8TH IEEE/ACIS INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION SCIENCE, P660, DOI 10.1109/ICIS.2009.147
   STEVENAGE SV, 1995, BRIT J PSYCHOL, V86, P127, DOI 10.1111/j.2044-8295.1995.tb02550.x
   Wang HJ, 2007, INT J PATTERN RECOGN, V21, P1127, DOI 10.1142/S0218001407005880
   Winnemöller H, 2006, ACM T GRAPHIC, V25, P1221, DOI 10.1145/1141911.1142018
   Wyszecki G. W., 1982, QUANTITATIVE DATA FO
   Xie J., 2009, Proceedings of the ACM International Conference on Multimedia, DOI 10.1145/1631272.1631403
   Xu GZ, 2004, ELECTRON COMM JPN 3, V87, P43, DOI 10.1002/ecjc.20088
   Chen YL, 2006, IEEE SYS MAN CYBERN, P866, DOI 10.1109/ICSMC.2006.384498
NR 40
TC 10
Z9 12
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2012
VL 30
IS 1
BP 15
EP 25
DI 10.1016/j.imavis.2011.11.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900WC
UT WOS:000300921400002
DA 2024-07-18
ER

PT J
AU Ngan, HYT
   Pang, GKH
   Yung, NHC
AF Ngan, Henry Y. T.
   Pang, Grantham K. H.
   Yung, Nelson H. C.
TI Automated fabric defect detection-A review
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Fabric defect detection; Textile; Motif-based; Automation; Quality
   control; Manufacturing
ID SURFACE INSPECTION; NEURAL-NETWORK; PATTERN-RECOGNITION; WAVELET
   RECONSTRUCTION; MACHINE VISION; GABOR FILTERS; FOURIER; SYSTEM;
   CLASSIFICATION; REGULARITY
AB This paper provides a review of automated fabric defect detection methods developed in recent years. Fabric defect detection, as a popular topic in automation, is a necessary and essential step of quality control in the textile manufacturing industry. In categorizing these methods broadly, a major group is regarded as non-motif-based while a minor group is treated as motif-based. Non-motif-based approaches are conventional, whereas the motif-based approach is novel in utilizing motif as a basic manipulation unit. Compared with previously published review papers on fabric inspection, this paper firstly offers an up-to-date survey of different defect detection methods and describes their characteristics, strengths and weaknesses. Secondly, it employs a wider classification of methods and divides them into seven approaches (statistical, spectral, model-based, learning, structural, hybrid, and motif-based) and performs a comparative study across these methods. Thirdly, it also presents a qualitative analysis accompanied by results, including detection success rate for every method it has reviewed. Lastly, insights, synergy and future research directions are discussed. This paper shall benefit researchers and practitioners alike in image processing and computer vision fields in understanding the characteristics of the different defect detection approaches. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Ngan, Henry Y. T.; Pang, Grantham K. H.] Univ Hong Kong, Dept Elect & Elect Engn, Ind Automat Res Lab, Hong Kong, Hong Kong, Peoples R China.
   [Yung, Nelson H. C.] Univ Hong Kong, Dept Elect & Elect Engn, Lab Intelligent Transportat Syst Res, Hong Kong, Hong Kong, Peoples R China.
C3 University of Hong Kong; University of Hong Kong
RP Ngan, HYT (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Ind Automat Res Lab, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
EM ngan.henry@gmail.com; gpang@eee.hku.hk; nyung@eee.hku.hk
RI Yung, Nelson Hon Ching/C-1873-2009; Ngan, Henry Y.T./B-3394-2012; Pang,
   Grantham Kwok Hung/C-1860-2009
OI Ngan, Henry Y.T./0000-0003-0382-952X; Pang, Grantham Kwok
   Hung/0000-0003-2257-2301
CR Aguilar N, 2004, P SOC PHOTO-OPT INS, V5622, P177, DOI 10.1117/12.591177
   ALAPURANEN P, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P371, DOI 10.1109/ICPR.1992.201578
   Alata O, 2005, PATTERN RECOGN LETT, V26, P1069, DOI 10.1016/j.patrec.2004.10.002
   Amet AL, 1998, 1998 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P205, DOI 10.1109/IAI.1998.666886
   [Anonymous], 2010, MATHWORLD
   [Anonymous], 2010, BRODATZ TEXTURE DATA
   BASU M, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P421, DOI 10.1109/ICPR.1992.202013
   Baykal IC, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL V, PROCEEDINGS, P665
   Baykal IC, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL III, CONFERENCE PROCEEDINGS, P292
   Bennamoun M, 1998, IEEE SYS MAN CYBERN, P4340
   Bennamoun M., 2003, SYST ANAL MODEL SIMU, V43, P1581, DOI [10.1080/0232929032000115083, DOI 10.1080/0232929032000115083]
   Bodnarova A, 2002, PATTERN RECOGN, V35, P2973, DOI 10.1016/S0031-3203(02)00017-1
   Bodnarova A, 2000, INT CONF ACOUST SPEE, P3606, DOI 10.1109/ICASSP.2000.860182
   Bodnarova A, 1998, IEEE SYS MAN CYBERN, P4423, DOI 10.1109/ICSMC.1998.727546
   Bollinger J., 2001, BOLLINGER BOLLINGER
   BRADSHAW M, 1995, MECHATRONICS, V5, P233, DOI 10.1016/0957-4158(95)00004-O
   Bu HG, 2009, ENG APPL ARTIF INTEL, V22, P224, DOI 10.1016/j.engappai.2008.05.006
   Cai JH, 2002, PATTERN RECOGN, V35, P725, DOI 10.1016/S0031-3203(01)00071-1
   Campbell J., 1997, ISSC, P241
   Campbell J.G., 1997, INFM97002 U ULST MAG
   Castellini C, 1996, OPT LASER ENG, V24, P19, DOI 10.1016/0143-8166(95)00044-O
   Castilho HP, 2007, LECT NOTES COMPUT SC, V4633, P1297
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chan H.W., 2005, Proceedings, 2005 ASCE Construction Research Congress, P1
   CHAUDHURI BB, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P358, DOI 10.1109/ICPR.1992.201575
   Chen C.H., 1993, HDB PATTERN RECOGNIT
   Chenoweth D.L, 1995, P IEEE AER APPL C, V2, P227
   Chetverikov D, 2002, PATTERN RECOGN, V35, P2165, DOI 10.1016/S0031-3203(01)00188-1
   Chetverikov D, 2000, INT C PATT RECOG, P521, DOI 10.1109/ICPR.2000.905390
   Chetverikov D, 2000, IMAGE VISION COMPUT, V18, P975, DOI 10.1016/S0262-8856(00)00041-X
   CHIN RT, 1982, IEEE T PATTERN ANAL, V4, P557, DOI 10.1109/TPAMI.1982.4767309
   Chiu SH, 2002, TEXT RES J, V72, P253, DOI 10.1177/004051750207200312
   Ciamberlini C, 1996, P SOC PHOTO-OPT INS, V2786, P9, DOI 10.1117/12.248573
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P803, DOI 10.1109/34.85670
   Conci A, 1998, COMPUT NETWORKS ISDN, V30, P1887, DOI 10.1016/S0169-7552(98)00211-6
   Conners R. W., 1989, SOUTHEASTCON '89 Proceedings. Energy and Information Technologies in the Southeast (Cat. No.89CH2672-4), P1080, DOI 10.1109/SECON.1989.132576
   DARWISH AM, 1988, IEEE T PATTERN ANAL, V10, P56, DOI 10.1109/34.3867
   Deng HW, 2004, IEEE T PATTERN ANAL, V26, P951, DOI 10.1109/TPAMI.2004.30
   Ding LH, 2002, PROC SPIE, V4875, P789, DOI 10.1117/12.477071
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   Escofet J, 1998, OPT ENG, V37, P2297, DOI 10.1117/1.601751
   Farooq U, 2004, T I MEAS CONTROL, V26, P119, DOI 10.1191/0142331204tm112oa
   Funck JW, 2003, COMPUT ELECTRON AGR, V41, P157, DOI 10.1016/S0168-1699(03)00049-8
   Gonzalez R. C., 2002, DIGITAL IMAGE PROCES
   Gururajan A, 2008, TEXT RES J, V78, P782, DOI 10.1177/0040517507090786
   Hajimowlana SH, 1999, 1998 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, P318, DOI 10.1109/MWSCAS.1998.759496
   Han Y, 2007, IMAGE VISION COMPUT, V25, P1239, DOI 10.1016/j.imavis.2006.07.028
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Haykin S., 1999, NEURAL NETWORKS COMP, DOI [10.1017/S0269888998214044, DOI 10.1017/S0269888998214044]
   Hoffer LM, 1996, OPT ENG, V35, P3183, DOI 10.1117/1.601057
   Hong Kong Productivity Council, 2000, TEXT HDB 2000
   Huet F., 1996, P INT C IM PROC SWIT, V3, P49
   Ibrahim Z, 2002, IEEE ICIT' 02: 2002 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY, VOLS I AND II, PROCEEDINGS, P226, DOI 10.1109/ICIT.2002.1189895
   Jain A., 1989, Fundamental of digital image processing
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   JAIN AK, 1990, 1990 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS, P14, DOI [10.1109/ICSMC.1990.142050, 10.1016/0031-3203(91)90143-S]
   Jiahan Chen, 1988, Proceedings of the 1988 IEEE International Conference on Systems, Man, and Cybernetics (IEEE Cat. No.88CH2556-9), P29
   Kaneko H., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P1711, DOI 10.1109/ICASSP.1989.266778
   Karayiannis Y. A., 1999, ICECS'99. Proceedings of ICECS '99. 6th IEEE International Conference on Electronics, Circuits and Systems (Cat. No.99EX357), P765, DOI 10.1109/ICECS.1999.813221
   KASPARIS T, 1995, COMPUT ELECTR ENG, V21, P21, DOI 10.1016/0045-7906(94)00012-6
   Kindermann R., 1980, Markov random fields and their applications, V547, DOI DOI 10.1090/CONM/001
   Kubota T, 2002, IEEE SOUTHEASTCON 2002: PROCEEDINGS, P42, DOI 10.1109/SECON.2002.995555
   Kumar A, 2003, PATTERN RECOGN, V36, P1645, DOI 10.1016/S0031-3203(03)00005-0
   Kumar A, 2002, IEEE T IND APPL, V38, P425, DOI 10.1109/28.993164
   Kumar A, 2008, IEEE T IND ELECTRON, V55, P348, DOI 10.1109/TIE.1930.896476
   Kuo CFJ, 2003, TEXT RES J, V73, P461, DOI 10.1177/004051750307300515
   Kuo CFJ, 2003, TEXT RES J, V73, P238, DOI 10.1177/004051750307300307
   Kuo CFJ, 2003, TEXT RES J, V73, P147, DOI 10.1177/004051750307300209
   Lambert G, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P201, DOI 10.1109/ICIP.1997.632054
   Latif-Amet A, 2000, IMAGE VISION COMPUT, V18, P543, DOI 10.1016/S0262-8856(99)00062-1
   Liu Hui-xia, 2006, 2006 Chinese Control Conference (IEEE Cat. No. 06EX1310)
   Liu J, 2008, LECT NOTES ARTIF INT, V5009, P700
   Liu XP, 2008, TEXT RES J, V78, P320, DOI 10.1177/0040517507090495
   Liu YX, 2004, IEEE T PATTERN ANAL, V26, P354, DOI 10.1109/TPAMI.2004.1262332
   Lovergine FP, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P669, DOI 10.1109/ICIP.1997.638584
   Mak KL, 2008, ROBOT CIM-INT MANUF, V24, P359, DOI 10.1016/j.rcim.2007.02.019
   Mak KL, 2009, IMAGE VISION COMPUT, V27, P1585, DOI 10.1016/j.imavis.2009.03.007
   MAK KL, 2005, IEEE INT C IND TECHN, P799, DOI DOI 10.1109/ICIT.2005.1600745
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mandelbrot B.B., 1982, The fractal geometry of nature
   Marroquin JL, 2003, IEEE T PATTERN ANAL, V25, P1380, DOI 10.1109/TPAMI.2003.1240112
   Meylani R, 1996, ICECS 96 - PROCEEDINGS OF THE THIRD IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS, AND SYSTEMS, VOLS 1 AND 2, P976, DOI 10.1109/ICECS.1996.584549
   Meylani R, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P165, DOI 10.1109/ICIP.1996.560410
   Millán MS, 2004, PROC SPIE, V5622, P188, DOI 10.1117/12.590655
   MUFTI M, 1995, AUTOTESTCON '95 - SYSTEMS READINESS: TEST TECHNOLOGY FOR THE 21ST CENTURY, CONFERENCE RECORD, P169, DOI 10.1109/AUTEST.1995.522669
   NEUBAUER C, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P688, DOI 10.1109/ICPR.1992.201654
   Ngan H.Y.T., 2007, DEFECT DETECTION PAT, p24/1
   Ngan HYT, 2008, PATTERN RECOGN, V41, P1878, DOI 10.1016/j.patcog.2007.11.014
   Ngan HYT, 2006, OPT ENG, V45, DOI 10.1117/1.2345189
   Ngan HYT, 2010, PATTERN RECOGN, V43, P2132, DOI 10.1016/j.patcog.2009.12.001
   Ngan HYT, 2010, IEEE T AUTOM SCI ENG, V7, P58, DOI 10.1109/TASE.2008.2005418
   Ngan HYT, 2009, IEEE T AUTOM SCI ENG, V6, P131, DOI 10.1109/TASE.2008.917140
   Ngan HYT, 2005, PATTERN RECOGN, V38, P559, DOI 10.1016/j.patcog.2004.07.009
   Ngan HYT, 2004, 32ND APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P163
   Ogata N, 2005, I S INTELL SIG PROC, P65
   Ozdemir S., 1996, P IEEE C EM TECHN FA, V2, P697
   Polzleitner W, 2001, IEEE IJCNN, P750, DOI 10.1109/IJCNN.2001.939118
   Radovan S., 2001, P IEEE INT C IM PROC, V1, P788
   SANBY C, 1995, MECHATRONICS, V5, P215, DOI 10.1016/0957-4158(95)00012-T
   Sari-Sarraf H, 1998, PROC CVPR IEEE, P938, DOI 10.1109/CVPR.1998.698717
   Sari-Sarraf H, 1999, IEEE T IND APPL, V35, P1252, DOI 10.1109/28.806035
   Semnani D., 2009, ENG TECHNOL, V49, P897
   Serafim A. F. L., 1991, Proceedings IECON '91. 1991 International Conference on Industrial Electrlnics, Control and Instrumentation (Cat. No.91CH2976-9), P1842, DOI 10.1109/IECON.1991.239061
   SERAFIM AFL, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P41, DOI 10.1109/ICPR.1992.201923
   Serra J., 1982, IMAGE ANAL MATH MORP
   Stojanovic R, 2001, REAL-TIME IMAGING, V7, P507, DOI 10.1006/rtim.2001.0231
   Tai-Hoon Cho, 1991, IJCNN-91-Seattle: International Joint Conference on Neural Networks (Cat. No.91CH3049-4), P205, DOI 10.1109/IJCNN.1991.155177
   Tajeripour F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/783898
   Tao L., 1997, IEE C 10 FEB, p9/1
   THOMAS T, 1994, P SOC PHOTO-OPT INS, V2183, P2, DOI 10.1117/12.171200
   Tofang-Sazi K, 2001, Intell. Data Anal., V5, P355
   Toliyat HA, 2003, IEEE T IND APPL, V39, P1454, DOI 10.1109/TIA.2003.816474
   Truchetet F, 2004, PROC SPIE, V5607, P1, DOI 10.1117/12.580395
   Tsai DM, 2000, INT J ADV MANUF TECH, V16, P474, DOI 10.1007/s001700070055
   Tsai DM, 2003, PATTERN RECOGN LETT, V24, P2525, DOI 10.1016/S0167-8655(03)00098-9
   Tsai DM, 2002, INT J ADV MANUF TECH, V20, P664, DOI 10.1007/s001700200205
   Tsai DM, 2003, IMAGE VISION COMPUT, V21, P413, DOI 10.1016/S0262-8856(03)00003-9
   Tsai DM, 2003, IMAGE VISION COMPUT, V21, P307, DOI 10.1016/S0262-8856(03)00007-6
   Tsai DM, 1999, IMAGE VISION COMPUT, V18, P49, DOI 10.1016/S0262-8856(99)00009-8
   Tsai DM, 2001, PATTERN RECOGN, V34, P1285, DOI 10.1016/S0031-3203(00)00071-6
   TSAI IS, 1995, TEXT RES J, V65, P123, DOI 10.1177/004051759506500301
   Wang LZ, 1999, ACTA PHARMACOL SIN, V20, P171
   Weeks AR., 1996, FUNDAMENTALS ELECT I
   Wilson R, 2003, IEEE T PATTERN ANAL, V25, P42, DOI 10.1109/TPAMI.2003.1159945
   WOOD EJ, 1990, TEXT RES J, V60, P212, DOI 10.1177/004051759006000404
   Yang X.Z., 2003, THESIS U HONG KONG
   Yang XZ, 2004, PATTERN RECOGN, V37, P889, DOI 10.1016/j.patcog.2003.10.011
   Yang XZ, 2002, OPT ENG, V41, P3116, DOI 10.1117/1.1517290
   Yazdi HR, 1998, REAL-TIME IMAGING, V4, P317, DOI 10.1016/S1077-2014(98)90002-X
   Yin Y, 2009, LECT NOTES COMPUT SC, V5552, P694, DOI 10.1007/978-3-642-01510-6_78
   Yuan Shu, 2004, Fifth World Congress on Intelligent Control and Automation (IEEE Cat. No.04EX788), P3378
   Zeng PF, 2002, IEEE IND APPLIC SOC, P320, DOI 10.1109/IAS.2002.1044107
   Zhang Y, 2010, PATTERN RECOGN LETT, V31, P2033, DOI 10.1016/j.patrec.2010.05.030
   Zhang Y, 2010, LECT NOTES COMPUT SC, V5995, P635
   ZHANG YXF, 1995, TEXT RES J, V65, P1, DOI 10.1177/004051759506500101
   Zhou J., 2007, P SOC PHOTO-OPT INS, V6833
   Zhu D., 1991, Proceedings. The Twenty-Third Southeastern Symposium on System Theory, P75, DOI 10.1109/SSST.1991.138517
NR 138
TC 329
Z9 377
U1 12
U2 292
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2011
VL 29
IS 7
BP 442
EP 458
DI 10.1016/j.imavis.2011.02.002
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 786YW
UT WOS:000292344800002
DA 2024-07-18
ER

PT J
AU Flores, FC
   Lotufo, RD
AF Flores, Franklin Cesar
   Lotufo, Roberto de Alencar
TI Watershed from propagated markers: An interactive method to
   morphological object segmentation in image sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Morphological segmentation; Image sequences; Marker propagation; Motion
   estimation; Watershed from markers; Interactive segmentation
ID VIDEO SEGMENTATION; TRACKING; PERFORMANCE; COMPUTATION; MOTION
AB In this paper, it is introduced an interactive method to object segmentation in image sequences, by combining classical morphological segmentation with motion estimation - the watershed from propagated markers. In this method, the objects are segmented interactively in the first frame and the mask generated by its segmentation provides the markers that will be used to track and segment the object in the next frame. Besides the interactivity, the proposed method has the following important characteristics: generality, rapid response and progressive manual edition. This paper also introduces a new benchmark to do quantitative evaluation of assisted object segmentation methods applied to image sequences. The evaluation is done according to several criteria such as the robustness of segmentation and the easiness to segment the objects through the sequence. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Flores, Franklin Cesar] Univ Estadual Maringa, Dept Informat, BR-87020900 Maringa, Parana, Brazil.
   [Lotufo, Roberto de Alencar] Univ Estadual Campinas, Sch Elect & Comp Engn, BR-13081970 Campinas, SP, Brazil.
C3 Universidade Estadual de Maringa; Universidade Estadual de Campinas
RP Flores, FC (corresponding author), FEEC UNICAMP, Campinas, SP, Brazil.
EM fcflores@din.uem.br; lotufo@unicamp.br
RI cai, bo/G-1491-2010; Lotufo, Roberto/C-1496-2009
OI Lotufo, Roberto/0000-0002-5652-0852
CR [Anonymous], 1992, R. woods digital image processing
   [Anonymous], 1994, Morphological Image Operators
   [Anonymous], 1981, P 7 INT JOINT C ART
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Beucher S., 1992, MATH MORPHOLOGY IMAG, P433
   Correia P, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/82195
   Correia PL, 2003, IEEE T IMAGE PROCESS, V12, P186, DOI 10.1109/TIP.2002.807355
   Erdem ÇE, 2004, IEEE T IMAGE PROCESS, V13, P937, DOI 10.1109/TIP.2004.828427
   Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076
   Finch Christopher., 1984, SPECIAL EFFECTS Creating Movie Magic
   FLORES FC, 2006, J BRAZILIAN COMPUTER, V11, P53
   Gil S, 1996, PATTERN RECOGN, V29, P1285, DOI 10.1016/0031-3203(95)00151-4
   Graciano ABV, 2007, SIBGRAPI, P179, DOI 10.1109/SIBGPAPI.2007.43
   Gu C, 1998, IEEE T CIRC SYST VID, V8, P572, DOI 10.1109/76.718504
   HIGGINS WE, 1990, IEEE T MED IMAGING, V9, P384, DOI 10.1109/42.61754
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147
   Moscheni F, 1998, IEEE T PATTERN ANAL, V20, P897, DOI 10.1109/34.713358
   Patras I, 2001, IEEE T PATTERN ANAL, V23, P326, DOI 10.1109/34.910886
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Salembier P, 1999, IEEE T CIRC SYST VID, V9, P1147, DOI 10.1109/76.809153
   Salembier P, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P425
   SALEMBIER P, 1994, IEEE T IMAGE PROCESS, V3, P639, DOI 10.1109/83.334980
   Salembier P, 1997, IEEE T CIRC SYST VID, V7, P60, DOI 10.1109/76.554418
   Serra J., 1983, IMAGE ANAL MATH MORP
   Serra Jean, 1988, Theoretical Advances, V2
   Smith P, 2004, IEEE T PATTERN ANAL, V26, P479, DOI 10.1109/TPAMI.2004.1265863
   Villegas P, 2004, IEEE T IMAGE PROCESS, V13, P1092, DOI 10.1109/TIP.2004.828433
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 54
TC 16
Z9 20
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2010
VL 28
IS 11
BP 1491
EP 1514
DI 10.1016/j.imavis.2009.06.015
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 639KD
UT WOS:000280972800001
DA 2024-07-18
ER

PT J
AU Serra, J
AF Serra, Jean
TI Digital Steiner sets and Matheron semi-groups
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 8th International Symposium Mathematical Morphology
CY OCT 10-13, 2007
CL Rio de Janeiro, BRAZIL
DE Matheron semi-group; Granulometry; Digital; Convexity; Steiner;
   Reveilles plane; Connectivity
AB There are various ways to define digital convexity in Z(n). The proposed approach focuses on structuring elements (and not the sets under study), whose digital versions should allow to construct hierarchies of operators satisfying Matheron semi-groups law gamma(lambda)gamma(mu) = gamma(max(lambda,mu)), where is a size factor. In R(n) the convenient class is the Steiner one. Its elements are Minkowski sums of segments. We prove that it admits a digital equivalent when the segments of Z(n) are Bezout. The conditions under which the Steiner sets are convex in Z(n), and are connected, are established. The approach is then extended to structuring elements that vary according to the law of perspective, and also to anamorphoses, so that the digital Steiner class and its properties can extend to digital spaces as a sphere or a torus. (C) 2009 Elsevier B.V. All rights reserved.
C1 Univ Paris Est, LIGM, Equipe A3SI, ESIEE, Paris, France.
C3 Universite Gustave-Eiffel; ESIEE Paris; Ecole des Ponts ParisTech
RP Serra, J (corresponding author), Univ Paris Est, LIGM, Equipe A3SI, ESIEE, Paris, France.
EM j.serra@esiee.fr
CR [Anonymous], RANDOM SETS INTEGRAL
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 1990, THESIS ECOLE MINES P
   Borgefors G, 1996, COMPUT VIS IMAGE UND, V64, P368, DOI 10.1006/cviu.1996.0065
   ECKARDT U, 2001, LECT NOTES COMPUTER, V2243, P209
   HEIJMANS H, 1990, COMPUTER VISION GRAP, V3, P245
   Jones R, 1996, COMP IMAG VIS, P263
   Kiselman CO, 2004, LECT NOTES COMPUT SC, V3322, P443
   MATHERON G, 1990, N2390G EC MIN PAR 1
   MATHERON G, 1996, N2390G EC MIN PAR 2
   MELIN E, 2005, MATH SCANDINAVICA
   Murota K., 2003, SIAM Monographs on Discrete Mathematics and Applications
   REVEILLES JP, 1991, THESIS U L PASTEUR S
   RONSE C, 1991, CVGIP-IMAG UNDERSTAN, V54, P74, DOI 10.1016/1049-9660(91)90076-2
   ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845
   Serra J, 1999, LECT NOTES COMPUT SC, V1568, P191
   Serra J., 1983, IMAGE ANAL MATH MORP
   SERRA J, 2007, CONVEXES DIGITAUX ST
   Soille P, 2001, IEEE T PATTERN ANAL, V23, P1313, DOI 10.1109/34.969120
   Soille P, 1996, IEEE T PATTERN ANAL, V18, P562, DOI 10.1109/34.494646
   TALBOT H, 1993, ANAL MORPHOLOGIQUE F
NR 21
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2010
VL 28
IS 10
SI SI
BP 1452
EP 1459
DI 10.1016/j.imavis.2009.06.016
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 638YK
UT WOS:000280936300004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kozakaya, T
   Shibata, T
   Yuasa, M
   Yamaguchi, O
AF Kozakaya, Tatsuo
   Shibata, Tomoyuki
   Yuasa, Mayumi
   Yamaguchi, Osamu
TI Facial feature localization using weighted vector concentration approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial feature localization; Weighted vector concentration
ID HISTOGRAMS; MODELS
AB We propose an efficient and generic facial feature localization method based on a weighted vector concentration approach. Our method does not require any specific priors on facial shape but implicitly learns its structural information from a training data. Unlike previous work, facial feature points are globally estimated by the concentration of directional vectors from sampling points on a face region, and those vectors are weighted by using local likelihood patterns which discriminate the appropriate position of the feature points. The directional vectors and local likelihood patterns are provided through nearest neighbor search between local patterns around the sampling points and a trained codebook of extended templates. The combination of the global vector concentration and the verification with the local likelihood patterns achieves robust facial feature point detection. We demonstrate that our method outperforms state-of-the-art method based on the Active Shape Models in our evaluation. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Kozakaya, Tatsuo; Shibata, Tomoyuki; Yuasa, Mayumi; Yamaguchi, Osamu] Toshiba Co Ltd, Ctr Corp Res & Dev, Saiwai Ku, Kawasaki, Kanagawa 2128582, Japan.
C3 Toshiba Corporation
RP Kozakaya, T (corresponding author), Toshiba Co Ltd, Ctr Corp Res & Dev, Saiwai Ku, 1 Komukai Toshiba Cho, Kawasaki, Kanagawa 2128582, Japan.
EM tatsuo.kozakaya@toshiba.co.jp
CR Salah AA, 2007, ANN TELECOMMUN, V62, P83
   [Anonymous], 2003, MRS P
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   Asteriadis S, 2009, PATTERN RECOGN, V42, P1388, DOI 10.1016/j.patcog.2009.01.009
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   CHANDRASEKHAR V, 2009, P COMP VIS PATT REC
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   COOTES TF, 1999, P BRIT MACH VIS C, V1, P173
   Cristinacce D., 2003, BRIT MACHINE VISION, V1, P231
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hu YX, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P843
   KOZAKAYA T, 2008, P IEEE COMP VIS PATT
   Kozakaya T, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P163
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   MILBORROW S, 2007, STASM SOFTWARE LIB
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Mita T, 2005, IEEE I CONF COMP VIS, P1619
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vogel J, 2006, PATTERN RECOGN, V39, P897, DOI 10.1016/j.patcog.2005.10.024
   Wu H, 2008, PROC CVPR IEEE, P3200
   YAN S, 2003, P IEEE INT C COMP VI, V1, P51
NR 29
TC 17
Z9 21
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 772
EP 780
DI 10.1016/j.imavis.2009.09.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900006
DA 2024-07-18
ER

PT J
AU Proença, H
   Alexandre, LA
AF Proenca, Hugo
   Alexandre, Luis A.
TI Iris recognition: Analysis of the error rates regarding the accuracy of
   the segmentation stage
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Image segmentation; Iris recognition
AB Iris recognition has been widely used in several scenarios with very satisfactory results. As it is one of the earliest stages, the image segmentation is in the basis of the process and plays a crucial role in the success of the recognition task. In this paper we analyze the relationship between the accuracy of the iris segmentation process and the error rates of three typical iris recognition methods. We selected 5000 images of the UBIRIS, CASIA and ICE databases that the used segmentation algorithm can accurately segment and artificially simulated four types of segmentation inaccuracies. The obtained results allowed us to conclude about a strong relationship between translational segmentation inaccuracies - that lead to errors in phase - and the recognition error rates. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Proenca, Hugo; Alexandre, Luis A.] Univ Beira Interior, Dept Comp Sci, Inst Telecommun, Networks & Multimedia Grp, P-6200 Covilha, Portugal.
C3 Universidade da Beira Interior
RP Proença, H (corresponding author), Univ Beira Interior, Dept Comp Sci, Inst Telecommun, Networks & Multimedia Grp, P-6200 Covilha, Portugal.
EM hugomcp@di.ubi.pt; lfbaa@di.ubi.pt
RI Proença, Hugo/F-9499-2010; Alexandre, Luis/E-8770-2013
OI Proença, Hugo/0000-0003-2551-8570; Alexandre, Luis/0000-0002-5133-5025
FU FCT-Fundacao para a Ciencia e Tecnologia; FEDER [PTDC/EIA/69106/2006];
   Fundação para a Ciência e a Tecnologia [PTDC/EIA/69106/2006] Funding
   Source: FCT
FX We acknowledge the financial support given by "FCT-Fundacao para a
   Ciencia e Tecnologia" and "FEDER" in the scope of the
   PTDC/EIA/69106/2006 research project "BIOREC: Non-Cooperative Biometric
   Recognition".
CR ALI J, 2003, AMO ADV MODELING OPT, V6, P93
   [Anonymous], 2004, P 17 INT C PATT REC
   Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573
   Camus TA, 2002, INT C PATT RECOG, P389, DOI 10.1109/ICPR.2002.1044732
   *CHIN AC SCI I AUT, 2004, CASIA IR IM DAT
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Du YZ, 2004, PROC SPIE, V5612, P104, DOI 10.1117/12.578789
   Kim J, 2004, J VLSI SIG PROC SYST, V38, P147, DOI 10.1023/B:VLSI.0000040426.72253.b1
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Ma L, 2002, INT C PATT RECOG, P414, DOI 10.1109/ICPR.2002.1048327
   Martin RocheC., 2002, IEEE AEROSP ELECT SY, V17, P3
   MIRA J, 2003, P SIBRAPI, P391
   *NAT I STAND TECHN, 2006, IR CHALL EV
   Nishino K, 2004, ACM T GRAPHIC, V23, P704, DOI 10.1145/1015706.1015783
   Proença H, 2006, IEE P-VIS IMAGE SIGN, V153, P199, DOI 10.1049/ip-vis:20050213
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   PROENCA H, 2007, P 1 INT C BIOM THEOR, P414
   VATSA M, 2005, INT J SIGNAL PROCESS, V2, P66
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
NR 20
TC 45
Z9 47
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 202
EP 206
DI 10.1016/j.imavis.2009.03.003
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000019
DA 2024-07-18
ER

PT J
AU Gonzalez-Diaz, R
   Jimenez, MJ
   Medrano, B
   Real, P
AF Gonzalez-Diaz, R.
   Jimenez, M. J.
   Medrano, B.
   Real, P.
TI A tool for integer homology computation: λ-AT-model
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Algebraic topological model; nD digital image; Integer homology; Chain
   complex
AB In this paper, we formalize the notion of lambda-AT-model (where lambda is a non-null integer) for a given chain complex, which allows the computation of homological information in the integer domain avoiding using the Smith Normal Form of the boundary matrices. We present an algorithm for computing such a model, obtaining Betti numbers, the prime numbers p involved in the invariant factors of the torsion subgroup of homology, the amount of invariant factors that are a power of p and a set of representative cycles of generators of homology mod p, for each p. Moreover, we establish the minimum valid lambda for such a construction, what cuts down the computational costs related to the torsion subgroup. The tools described here are useful to determine topological information of nD structured objects such as simplicial, cubical or simploidal complexes and are applicable to extract such an information from digital pictures. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Gonzalez-Diaz, R.; Jimenez, M. J.; Medrano, B.; Real, P.] Univ Seville, Appl Math Dept 1, E-41012 Seville, Spain.
C3 University of Sevilla
RP Gonzalez-Diaz, R (corresponding author), Univ Seville, Appl Math Dept 1, Campus Reina Merdedes, E-41012 Seville, Spain.
EM rogodi@us.es; majiro@us.es; belenmg@us.es; real@us.es
RI Gonzalez-Diaz, Rocio/I-1632-2012; Jimenez, Maria-Jose/L-3813-2014; Real,
   Pedro/F-7078-2012
OI Gonzalez-Diaz, Rocio/0000-0001-9937-0033; Jimenez,
   Maria-Jose/0000-0001-7316-117X; Real, Pedro/0000-0002-6853-0505; Medrano
   Garfia, Belen/0000-0002-1465-7471
CR [Anonymous], 1995, Homology, Classics in Mathematics
   DAHMEN WA, 1982, SIAM J NUMER ANAL, V19, P993, DOI 10.1137/0719072
   Dumas JG, 2001, J SYMB COMPUT, V32, P71, DOI 10.1006/jsco.2001.0451
   González-Díaz R, 2005, DISCRETE APPL MATH, V147, P245, DOI 10.1016/j.dam.2004.09.014
   Gonzalez-Diaz R, 2003, LECT NOTES COMPUT SC, V2886, P92
   González-Díaz R, 2009, DISCRETE APPL MATH, V157, P490, DOI 10.1016/j.dam.2008.05.029
   Gonzalez- Diaz R., 2003, HOMOL HOMOTOPY APPL, V5, P83
   Gonzalez-Diaz R, 2007, LECT NOTES COMPUT SC, V4538, P330
   González-Díaz R, 2006, LECT NOTES COMPUT SC, V4245, P199
   GONZALEZDIAZ R, ELECT J IMAGEN A
   GUI X, 1997, P 1997 INT S SYMB AL
   ILIOPOULOS CS, 1989, SIAM J COMPUT, V18, P658, DOI 10.1137/0218045
   Massey WS, 1991, GRADUATE TEXTS MATH, V127
   MUNKRES J. R., 1984, Elements of Algebraic Topology
   Peltier S, 2006, COMPUT GRAPH-UK, V30, P62, DOI 10.1016/j.cag.2005.10.011
   Peltier S, 2006, LECT NOTES COMPUT SC, V4245, P235
   SERGERAERT F, 1987, CR ACAD SCI I-MATH, V304, P319
   Storjohann A., 1996, P INT S SYMBOLIC ALG, P267
NR 18
TC 5
Z9 5
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 837
EP 845
DI 10.1016/j.imavis.2008.10.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lozano, MA
   Escolano, F
   Bonev, B
   Suau, P
   Aguilar, W
   Saez, JM
   Cazorla, MA
AF Lozano, M. A.
   Escolano, F.
   Bonev, B.
   Suau, P.
   Aguilar, W.
   Saez, J. M.
   Cazorla, M. A.
TI Region and constellations based categorization of images with
   unsupervised graph learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Image categorization; Clustering of graphs; EM algorithms
ID SCALE; SEGMENTATION; LOCALIZATION; SOFTASSIGN; SALIENCY
AB in this paper, we address the problem of image categorization with a fast novel method based on the unsupervised clustering of graphs in the context of both region-based segmentation and the constellation approach to object recognition. Such method is an EM central clustering algorithm which builds prototypical graphs on the basis of either Softassign or fast matching with graph transformations. We present two realistic applications and their experimental results: categorization of image segmentations and visual localization. We compare our graph prototypes with the set median graphs. Our results reveal that, on the one hand, structure extracted from images improves appearance-based visual localization accuracy. On the other hand, we show that the cost of our central graph clustering algorithm is the cost of a pairwise algorithm. We also discuss how the method scales with an increasing amount of images. In addition, we address the scientific question of what are the bounds of structural learning for categorization. Our in-depth experiments both for region-based and feature-based image categorization, will show that such bounds depend hardly on structural variability. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Lozano, M. A.; Escolano, F.; Bonev, B.; Suau, P.; Saez, J. M.; Cazorla, M. A.] Univ Alicante, Dpto Ciencia Computac & Inteligencia Artificial, E-03080 Alicante, Spain.
   [Aguilar, W.] Univ Nacl Autonoma Mexico, Inst Invest Matemat Aplicadas & Sistemas, Mexico City 04510, DF, Mexico.
C3 Universitat d'Alacant; Universidad Nacional Autonoma de Mexico
RP Lozano, MA (corresponding author), Univ Alicante, Dpto Ciencia Computac & Inteligencia Artificial, E-03080 Alicante, Spain.
EM malozano@dccia.ua.es; sco@dccia.ua.es; boyan@dccia.ua.es;
   pablo@dccia.ua.es; weam@turing.iimas.unam.mx; jmsaez@dccia.ua.es;
   miguel@dccia.ua.es
RI Aguilar, Wendy/IAR-2558-2023; Cazorla, Miguel/B-4464-2013; Lozano,
   Miguel Angel/F-1258-2017
OI Aguilar, Wendy/0000-0003-1867-8859; Cazorla, Miguel/0000-0001-6805-3633;
   Lozano, Miguel Angel/0000-0002-4757-5587
CR AGUILAR W, 2006, THESIS UNAM MEXICO
   Aguilar W, 2007, LECT NOTES COMPUT SC, V4538, P25
   [Anonymous], 1996, HIGH LEVEL VISION OB
   Bonev B, 2007, LECT NOTES COMPUT SC, V4538, P340
   BONEV B, 2006, 7 WORKSH PHYS AG LAS, P59
   BOSCH A, 2006, P EUR C COMP VIS GRA
   Bunke H, 2003, LECT NOTES COMPUT SC, V2726, P235
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   Chung F.R.K., 1997, C BOARD MATH SCI CBM, V92
   Crandall D, 2005, PROC CVPR IEEE, P10
   Escolano F, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1721
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fergus R, 2005, PROC CVPR IEEE, P380
   Fergus R, 2003, PROC CVPR IEEE, P264
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Greenspan H, 2004, COMPUT VIS IMAGE UND, V93, P86, DOI 10.1016/j.cviu.2003.08.004
   Jain BJ, 2004, MACH LEARN, V56, P169, DOI 10.1023/B:MACH.0000033119.52532.ce
   Jiang XY, 2001, IEEE T PATTERN ANAL, V23, P1144
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kondor R. I., 2002, P 19 INT C MACH LEAR, P315
   Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946
   Kosecká J, 2005, ROBOT AUTON SYST, V52, P27, DOI 10.1016/j.robot.2005.03.008
   LEUNG TK, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P637, DOI 10.1109/ICCV.1995.466878
   Li FY, 2006, IEEE INT CONF ROBOT, P3405, DOI 10.1109/ROBOT.2006.1642222
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lozano MA, 2006, PATTERN RECOGN, V39, P539, DOI 10.1016/j.patcog.2005.10.008
   Lozano MA, 2004, LECT NOTES COMPUT SC, V3138, P76
   Lozano MA, 2003, LECT NOTES COMPUT SC, V2726, P247
   LOZANO MA, KERNELIZED GRA UNPUB
   MARAGOS KP, 2006, P INT C COMP VIS PAT, P1893
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Murphy K., 2004, Advances in Neural Information Processing Systems, V16
   Rangarajan A, 1999, NEURAL COMPUT, V11, P1455, DOI 10.1162/089976699300016313
   Sala P, 2006, IEEE T ROBOT, V22, P334, DOI 10.1109/TRO.2005.861480
   SE S, 2002, IEEE ESJ INT C INT R
   SIMS R, 2001, IMAGE VISION COMPUT, V19, P733
   Suau P, 2008, IMAGE VISION COMPUT, V26, P1207, DOI 10.1016/j.imavis.2008.01.010
   Torsello A, 2006, IEEE T PATTERN ANAL, V28, P954, DOI 10.1109/TPAMI.2006.125
   Torsello A, 2007, INT J COMPUT VISION, V72, P259, DOI 10.1007/s11263-006-8929-y
   Wang JQ, 2006, IEEE T SYST MAN CY B, V36, P413, DOI 10.1109/TSMCB.2005.859085
   ZHANG W, 2006, INT S 3D DATA PROC V
   ZIVKOVIC BZ, 2005, P ANN C ADV SCH COMP
NR 44
TC 5
Z9 6
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 960
EP 978
DI 10.1016/j.imavis.2008.09.011
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300013
DA 2024-07-18
ER

PT J
AU Shen, HY
   Coughlan, J
   Ivanchenko, V
AF Shen, Huiying
   Coughlan, James
   Ivanchenko, Volodymyr
TI Figure-ground segmentation using factor graphs
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Figure-ground segmentation; Belief propagation; Factor graphs; Text
   detection
AB Foreground-background segmentation has recently been applied [S.X. Yu, J. Shi, Object-specific figure-ground segregation, Computer Vision and Pattern Recognition (CVPR), 2003; S. Kumar, M. Hebert, Man-made structure detection in natural images using a causal multiscale random field, Computer Vision and Pattern Recognition (CVPR), 2003] to the detection and segmentation of specific objects or structures of interest from the background as an efficient alternative to techniques such as deformable templates [A.L Yuille. Deformable templates for face recognition. Journal of Cognitive Neuroscience 3 (1) (1991)]. We introduce a graphical model (i.e. Markov random field)-based formulation of structure-specific figure-ground segmentation based on simple geometric features extracted from an image, such as local configurations of linear features, that are characteristic of the desired figure structure. Our formulation is novel in that it is based on factor graphs, which are graphical models that encode interactions among arbitrary numbers of random variables. The ability of factor graphs to express interactions higher than pairwise order (the highest order encountered in most graphical models used in computer vision) is useful for modeling a variety of pattern recognition problems. In particular, we show how this property makes factor graphs a natural framework for performing grouping and segmentation, and demonstrate that the factor graph framework emerges naturally from a simple maximum entropy model of figure-ground segmentation.
   We cast our approach in a learning framework, in which the contributions of multiple grouping cues are learned from training data, and apply our framework to the problem of finding printed text in natural scenes. Experimental results are described, including a performance analysis that demonstrates the feasibility of the approach. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Shen, Huiying; Coughlan, James; Ivanchenko, Volodymyr] Smith Kettlewell Eye Res Inst, Rehabil Engn Res Ctr, San Francisco, CA 94115 USA.
C3 The Smith-Kettlewell Eye Research Institute
RP Coughlan, J (corresponding author), Smith Kettlewell Eye Res Inst, Rehabil Engn Res Ctr, 2318 Fillmore St, San Francisco, CA 94115 USA.
EM coughlan@ski.org
RI Ivanchenko, Vladimir/L-5254-2017
OI Ivanchenko, Vladimir/0000-0002-1844-5433
FU NEI NIH HHS [R01 EY018345, R21 EY015187-01A2, R01 EY018345-01, R21
   EY015187] Funding Source: Medline
CR AGARWAL S, 2005, CVPR, V2, P838
   [Anonymous], 2 WORKSH APPL COMP V
   Bishop C.M., 2006, J ELECTRON IMAGING, V16, P049901, DOI DOI 10.1117/1.2819119
   Chen XR, 2004, PROC CVPR IEEE, P366
   Coughlan JM, 2002, LECT NOTES COMPUT SC, V2352, P453
   Cover T. M., 1991, ELEMENTS INFORM THEO
   FELZENSZWALB P, 2004, P 2004 IEEE COMP SOC, V1
   GAO J, 2001, P 2001 IEEE COMP SOC, V2
   He XM, 2004, PROC CVPR IEEE, P695
   Ivanchenko V, 2008, 4 IEEE WORKSH EMB CO
   Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3
   Kschischang FR, 2001, IEEE T INFORM THEORY, V47, P498, DOI 10.1109/18.910572
   Kumar S, 2003, PROC CVPR IEEE, P119
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Liang J., 2005, International Journal on Document Analysis and Recognition, V7, P84, DOI 10.1007/s10032-004-0138-z
   MURPHY KP, 1999, UNCERTAINTY AI
   QUATTONI A, 2004, NEURAL INFORM PROCES, V17, P1097
   RATNAPARKHI A, 9708 U PENNS I RES C
   SHEN H, 2006, INT C PATT REC ICPR, V4, P113
   Shen H, 2007, WORKSH GRAPH BAS REP
   SHENTAL N, 2003, NEURAL INFORM PROCES
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SIGAL L, 2003, NEURAL INFORM PROCES, V16, P1539
   SUN J, 2002, EUR C COMP VIS ECCV, P450
   WU V, 1997, FINDING TEXT IMAGES, P3
   YEDIDIA JS, 2003, TR2001022 MERL, P239
   Yu SX, 2003, PROC CVPR IEEE, P39
   YUILLE AL, 1991, J COGNITIVE NEUROSCI, V3, P59, DOI 10.1162/jocn.1991.3.1.59
   Zhang Z, 2004, PROC CVPR IEEE, P10
   Zheng YF, 2003, PROC INT CONF DOC, P599
NR 30
TC 5
Z9 5
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 854
EP 863
DI 10.1016/j.imavis.2009.02.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300004
PM 20160994
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Masood, A
   Sarfraz, M
AF Masood, Asif
   Sarfraz, Muhammad
TI Capturing outlines of 2D objects with Bezier cubic approximation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cubic Bezier curves; Corner points; Control point search; Subdivision
ID CHAIN CODES; ALGORITHM; SHAPE; REPRESENTATION; BOUNDARY; POINTS
AB An object capturing technique using cubic Bezier is presented in this paper. Proposed technique produces set of data points which are the control points of approximating Bezier curve. The control points are determined by an efficient search algorithm producing optimal curves. Approximation process is simplified by decomposition of outline into smaller curves. The decomposition/subdivision is performed on detected corner points as a preprocessing step. Further subdivision is done by recursive algorithm during the approximation process. Proposed algorithm has various advantages like computational efficiency, better shape representation, low approximation error and high compression ratio. This is demonstrated in comparison with other algorithms. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Sarfraz, Muhammad] Kuwait Univ, Dept Informat Sci, Kuwait 13060, Kuwait.
   [Masood, Asif] Natl Univ Sci & Technol, Dept Comp Sci, Mil Coll Signals, Rawalpindi, Pakistan.
C3 Kuwait University; National University of Sciences & Technology -
   Pakistan
RP Sarfraz, M (corresponding author), Kuwait Univ, Dept Informat Sci, Adailia Campus,POB 5969, Kuwait 13060, Kuwait.
EM amasood@mcs.edu.pk; prof.m.sarfraz@gmail.com
CR [Anonymous], 1987, An Introduction to Splines for use in Computer Graphics Geometric Modeling
   Avrahami G., 1991, Raster Imaging and Digital Typography II, P54
   BEUS HL, 1987, PATTERN RECOGN, V20, P291, DOI 10.1016/0031-3203(87)90004-5
   Bezier P., 1972, Numerical Control: Mathematics and Applications
   CARLOS A, 1990, IEEE T PATTERN ANAL, V12, P1190
   CHETVERIKOV D, 1999, P 23 WORKSH AUSTR PA, P175
   Cronin TM, 1999, PATTERN RECOGN LETT, V20, P617, DOI 10.1016/S0167-8655(99)00025-2
   DAVIS LS, 1979, IEEE T PATTERN ANAL, V1, P60, DOI 10.1109/TPAMI.1979.4766876
   Farin G., 1994, CURVES SURFACES COMP
   Farin G., 2001, Curves and Surfaces for CAGD: A Practical Guide, Vfifth
   FREEMAN H, 1977, IEEE T COMPUT, V26, P297, DOI 10.1109/TC.1977.1674825
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Gregory J. A., 1990, Computer-Aided Geometric Design, V7, P1, DOI 10.1016/0167-8396(90)90017-L
   GREGORY JA, 1986, COMPUT AIDED DESIGN, V18, P53, DOI 10.1016/S0010-4485(86)80012-4
   Hearn D., 1997, Computer graphics
   HOLZLE GE, 1983, COMPUT AIDED DESIGN, V15, P295, DOI 10.1016/0010-4485(83)90018-0
   HUSSAIN F, 2000, IEEE P INT C INF VIS
   ITOH K, 1994, ELECTR PUB ORG DISS, V6, P195
   KANEKO T, 1985, IEEE T COMMUN, V33, P697, DOI 10.1109/TCOM.1985.1096361
   KARTIKEYAN B, 1989, IEEE T PATTERN ANAL, V11, P977, DOI 10.1109/34.35501
   KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390
   KOENDERINK JJ, 1979, BIOL CYBERN, V32, P211, DOI 10.1007/BF00337644
   KOPLOWITZ J, 1981, IEEE T PATTERN ANAL, V3, P180, DOI 10.1109/TPAMI.1981.4767075
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   Masood A, 2005, LECT NOTES COMPUT SC, V3687, P550
   MASOOD A, 2006, P 7 INT C COMP VIS P
   NEUHOFF DL, 1985, IEEE T INFORM THEORY, V31, P53, DOI 10.1109/TIT.1985.1056998
   Plass M., 1983, Computer Graphics, V17, P229, DOI 10.1145/964967.801153
   PRASAD R, 1989, P IEEE PAC RIM C COM, P138
   Quddus A, 1999, ELECTRON LETT, V35, P287, DOI 10.1049/el:19990121
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P443, DOI 10.1016/0167-8655(92)90051-Z
   SAGHRI JA, 1981, IEEE T PATTERN ANAL, V3, P533, DOI 10.1109/TPAMI.1981.4767146
   Sarfraz M., 2004, Proceedings. 2004 International Conference on Information and Communication Technologies: From Theory to Applications (IEEE Cat. No.04EX852), P539, DOI 10.1109/ICTTA.2004.1307870
   Sarfraz M, 2005, PROCEEDINGS OF THE 8TH JOINT CONFERENCE ON INFORMATION SCIENCES, VOLS 1-3, P1649
   Sarfraz M, 2004, FUTURE GENER COMP SY, V20, P1327, DOI 10.1016/j.future.2004.05.024
   Sarfraz M, 2003, ADVANCES IN SOFT COMPUTING: ENGINEERING DESIGN AND MANUFACTURING, P109
   Sarfraz M, 2003, INFORM SCIENCES, V150, P177, DOI 10.1016/S0020-0255(02)00376-6
   Sarfraz M, 2002, INFORM SCIENCES, V140, P269, DOI 10.1016/S0020-0255(01)00176-1
   Sarfraz M, 2002, COMPUT GRAPH-UK, V26, P795, DOI 10.1016/S0097-8493(02)00134-6
   Sarfraz M, 2001, FIFTH INTERNATIONAL CONFERENCE ON INFORMATION VISUALISATION, PROCEEDINGS, P738, DOI 10.1109/IV.2001.942138
   Sarfraz M, 2000, CISST'2000: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS, AND TECHNOLOGY, VOLS I AND II, P87
   SARFRAZ M, 2000, P 3 KFUPM WORKSH INF, P83
   SARFRAZ M, 2002, P INT C COMP GRAPH I, P204
   SARFRAZ M, 2004, P INT C INF COMP SCI
   SARFRAZ M, 2004, INT J IMAGE GRAPHICS
   Sarfraz M, 2006, COMPUT IMAGING VIS, V32, P528
   Schneider P.J., 1990, Graphics gems, V1, P612
   Sohel F.A., 2005, P IEEE INT C AC SPEE
   Tang YY, 2001, IEEE T PATTERN ANAL, V23, P1443, DOI 10.1109/34.977567
NR 49
TC 15
Z9 16
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 704
EP 712
DI 10.1016/j.imavis.2008.07.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000011
DA 2024-07-18
ER

PT J
AU Pei, W
   Zhu, YY
   Liu, C
   Xia, ZY
AF Pei, Wei
   Zhu, Yongying
   Liu, Chong
   Xia, Zeyi
TI Non-uniformity correction for SLM microscopic images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Non-uniformity correction; Vector median filter; SLM microscopic image;
   Image model
ID IMPULSIVE NOISE; REDUCTION
AB The distributions of irradiance on the image plane decrease away from the center of the image even if the scene is a uniform white field. This crucial problem is posed in SLM microscopic images analyses, such as edge detection and stereo matching. This paper analyses the noise sources based on the structure of SLM, establishes an image model and explores the variation of random noise with various magnifications. Then a non-uniformity correction method which combines a fitting calibration algorithm and an extended vector median filter speeded up with a fast algorithm is used to remove noise. The experimental results demonstrate the validity of our theoretical model and the effectiveness of non-uniformity correction method of the SLM micro stereovision system. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Pei, Wei] Dalian Maritime Univ, Environm Sci & Engn Coll, Dalian 116026, Peoples R China.
   [Zhu, Yongying] Dalian Fisheries Univ, Dept Civil Engn, Dalian, Peoples R China.
   [Liu, Chong; Xia, Zeyi] Dalian Univ Technol, Res Ctr Microsyst Technol, Dalian, Peoples R China.
C3 Dalian Maritime University; Dalian Ocean University; Dalian University
   of Technology
RP Pei, W (corresponding author), Dalian Maritime Univ, Environm Sci & Engn Coll, 1 Linghai Rd, Dalian 116026, Peoples R China.
EM peiwei2002@163.com
FU National Natural Science Foundation of China [50275023]
FX The authors thank the reviewers for their valuable comments and
   suggestions. The work is supported by the National Natural Science
   Foundation of China under Grant No. 50275023.
CR ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   BARDOS AJ, 1997, P 6 INT C IM PROC IT, V2, P708
   Danuser Gaudenz, 1995, SPIE, V2412, P123
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   Kamberova G., 1998, Empirical Evaluation Techniques in Computer Vision
   KAMBEROVA G, 1997, UNDERSTANDING SYSTEM
   KIM NH, 1990, IEEE T SYST MAN CYB, V20, P475, DOI 10.1109/21.52557
   Lukac R, 2002, CGIV'2002: FIRST EUROPEAN CONFERENCE ON COLOUR IN GRAPHICS, IMAGING, AND VISION, CONFERENCE PROCEEDINGS, P86
   Lukac R., 2002, Pattern Recognition and Image Analysis, V12, P279
   LUKAC R, 2001, P EUR C CIRC THEOR D, V3, P137
   LUKAC R, 2002, ISSUE COLOUR IMAGE P, V11, P311
   MULLIKIN JC, 1994, P SOC PHOTO-OPT INS, V2173, P73, DOI 10.1117/12.175165
   PEI W, 2005, CHIN MECH ENG, V16, P67
   Pitas I, 1991, IEEE T CIRC SYST VID, V1, P247, DOI 10.1109/76.97987
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   RAN M, 1998, J HUAQIAO U NAT SCI, V19, P169
   Seibert JA, 1998, P SOC PHOTO-OPT INS, V3336, P348, DOI 10.1117/12.317034
   Smolka B, 2002, PATTERN RECOGN, V35, P1771, DOI 10.1016/S0031-3203(01)00169-8
   Smolka B, 2001, OPT ENG, V40, P902, DOI 10.1117/1.1367347
   SMOLKA B, 2002, P DSP2002 SANT GREEC, V2, P939
   TANG KJ, 1995, IEEE T IMAGE PROCESS, V4, P788, DOI 10.1109/83.388080
   Tomazevic D, 2000, INT C PATT RECOG, P564, DOI 10.1109/ICPR.2000.903608
   Young I.T., 1998, FUNDAMENTALS IMAGE P
NR 23
TC 4
Z9 6
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 782
EP 789
DI 10.1016/j.imavis.2008.08.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000017
DA 2024-07-18
ER

PT J
AU Pavlou, M
   Allinson, NM
AF Pavlou, Maria
   Allinson, Nigel M.
TI Automated encoding of footwear patterns for fast indexing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pattern matching; Footwear; Quantization; Shoe print; Kernel
ID IMAGE-DATABASE; CLASSIFICATION; SHOE; ALGORITHM; SCENE
AB The rapid and robust identification of a suspect's footwear while he/she is in police custody is an essential component in any system that makes full use of the footwear marks recovered from crime scenes. Footwear is an important source of forensic intelligence and, sometimes, evidence. Here, we present an automated system for shoe model identification from outsole impressions taken directly from suspect's shoes that can provide information in a timely manner, while a suspect is in custody. Currently the process of identifying the shoe model from the 1000 s of recorded model types is a time-consuming manual task. The underlying methodology is based on large numbers of localized features located using MSER feature detectors. These features are transformed into robust SIFT descriptors and encoded relative to a feature codebook forming histogram representations of each shoe pattern. This representationist facilitates fast indexing of footwear patterns whilst a finer search proceeds by comparing the correspondence between footwear patterns in a short-list through the application of modified constrained spectral correspondence methods. The effectiveness of this approach is illustrated for a reference dataset of 374 different shoe model patterns, from which 87% first-rank performance and 92% top-eight rank performance are achieved. Practical aspects of the system and future developments are also discussed. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Pavlou, Maria; Allinson, Nigel M.] Univ Sheffield, Dept Elect & Elect Engn, Sheffield S1 3JD, S Yorkshire, England.
C3 University of Sheffield
RP Pavlou, M (corresponding author), Univ Sheffield, Dept Elect & Elect Engn, Mappin St, Sheffield S1 3JD, S Yorkshire, England.
EM m.pavlou@sheffield.ac.uk; n.allinson@sheffield.ac.uk
OI Allinson, Nigel/0000-0002-4775-8332
FU UK Engineering and Physical Sciences Research Council [EP/D03633X];
   Association of Chief Police Officers; EPSRC [EP/E02839X/1] Funding
   Source: UKRI
FX The work was funded by the UK Engineering and Physical Sciences Research
   Council (Grant reference EP/D03633X) in collaboration with the UK Home
   Office Police Standards Unit (now the National Policing Improvement
   Agency) and the Association of Chief Police Officers. We also thank
   Police Scientific Support staff, in particular Kath Mashiter, Karen Stow
   and Danyela Kellett, for their insights into the needs and challenges of
   forensic footwear evidence.
CR Alexander A, 1999, IEE CONF PUBL, P638, DOI 10.1049/cp:19990401
   [Anonymous], FOOTWEAR MISSED EVID
   Ashley W, 1996, FORENSIC SCI INT, V82, P7, DOI 10.1016/0379-0738(96)01962-7
   Bodziak WilliamJ., 2000, Footwear Impression Evidence: Detection, Recovery, and Examination, V2nd
   Bouridane A, 2000, IEEE IMAGE PROC, P474, DOI 10.1109/ICIP.2000.900998
   Cassidy MJ., 1980, FOOTWEAR IDENTIFICAT
   Crookes D, 2007, NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, PROCEEDINGS, P67
   de Chazal P, 2005, IEEE T PATTERN ANAL, V27, P341, DOI 10.1109/TPAMI.2005.48
   Dix A., 2004, Human-computer interaction
   Everingham M., 2006, PASCAL VISUAL OBJECT
   Flach JM, 2003, IEEE INTELL SYST, V18, P94, DOI 10.1109/MIS.2003.1179200
   *FOR SCI SERV, DAT TAK UK NAT SHOEW
   Geradts Z, 1996, FORENSIC SCI INT, V82, P21, DOI 10.1016/0379-0738(96)01963-9
   Girod A, 1996, FORENSIC SCI INT, V82, P59
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kulkarni SR, 1998, IEEE T INFORM THEORY, V44, P2178, DOI 10.1109/18.720536
   MIKKONEN S, 1994, J FORENSIC SCI, V39, P1227
   Mikkonen S, 1996, FORENSIC SCI INT, V82, P67, DOI 10.1016/0379-0738(96)01968-8
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   MILLER GA, 1956, PSYCHOL REV, V63, P81, DOI 10.1037/h0043158
   *NEATPRINTS LTD, PRINTSC
   PAVLOU M, 2006, P INT DAT ENG AUT LE
   Pilu M, 1997, PROC CVPR IEEE, P261, DOI 10.1109/CVPR.1997.609330
   Poggio T, 2004, NATURE, V428, P419, DOI 10.1038/nature02341
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   SAWYER N, 1995, P EUR CONV SEC DET, P86
   SCOTT GL, 1991, P ROY SOC B-BIOL SCI, V244, P21, DOI 10.1098/rspb.1991.0045
   Ullman Shimon, 1979, INTERPRETATION VISUA, DOI [DOI 10.7551/MITPRESS/3877.001.0001, DOI 10.1016/0013-4694(80)90055-3]
   ZHANG L, 2005, UK WORKSH COMP INT U
NR 32
TC 31
Z9 34
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 402
EP 409
DI 10.1016/j.imavis.2008.06.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600010
DA 2024-07-18
ER

PT J
AU Vildjiounaite, E
   Kyllönen, V
   Ailisto, H
AF Vildjiounaite, Elena
   Kyllonen, Vesa
   Ailisto, Heikki
TI Empirical evaluation of combining unobtrusiveness and security
   requirements in multimodal biometric systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Multimodal fusion; Cascade
AB Unobtrusive user authentication is more convenient than explicit interaction and can also increase system security because it can be performed frequently, unlike the current "once explicitly and for a long time" practice. Existing unobtrusive biometrics (e.g., face, voice, gait) do not perform sufficiently well for high-security applications, however, while reliable biometric authentication (e.g., fingerprint or iris) requires explicit user interaction. This work presents experiments with a cascaded multimodal biometric system, which first performs unobtrusive user authentication and requires explicit interaction only when the unobtrusive authentication fails. Experimental results obtained for a database of 150 users show that even with a fairly low performance of unobtrusive modalities (Equal Error Rate above 10%). the cascaded system is capable of satisfying a security requirement of a False Acceptance Rate less than 0.1% with an overall False Rejection Rate of less than 0.2%, while authenticating unobtrusively in 65% of cases. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Vildjiounaite, Elena; Kyllonen, Vesa; Ailisto, Heikki] Tech Res Ctr Finland, Oulu 90571, Finland.
C3 VTT Technical Research Center Finland
RP Vildjiounaite, E (corresponding author), Tech Res Ctr Finland, Kaitovayla 1,POB 1100, Oulu 90571, Finland.
EM elena.vildjiounaite@vtt.fi; vesa.kyllonen@vtt.fi; heikki.ailisto@vtt.fi
OI Ailisto, Heikki/0000-0003-3521-7392
CR Ailisto H., 2004, P 3 NORDIC C HUMAN C, P327, DOI [10.1145/1028014.1028065, DOI 10.1145/1028014.1028065]
   [Anonymous], 2004, IEEE T CIRCUITS SYST
   Bengio S., 2002, Information Fusion, V3, P267, DOI 10.1016/S1566-2535(02)00089-1
   Chatzis V, 1999, IEEE T SYST MAN CY A, V29, P674, DOI 10.1109/3468.798073
   Erzin E, 2005, IEEE T MULTIMEDIA, V7, P840, DOI 10.1109/TMM.2005.854464
   FIERREZAGUILAR J, 2007, PATTERN RECOGN, V40, P1382
   FIERREZAGUILAR J, 2005, PATTERN RECOGNITION, V26
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295, DOI 10.1109/34.735803
   HUANG L, 2004, IEEE WORKSH FAC PROC
   Jain AK, 2004, COMMUN ACM, V47, P34, DOI 10.1145/962081.962102
   Jain AK, 2002, IEEE IMAGE PROC, P57
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   KOREMAN J, 2006, 2 WORKSH MULT US AUT
   Miller A., 2004, Network Security, P8, DOI 10.1016/S1353-4858(04)00103-5
   POH N, 2005, CAN CHIMERIC PERSONS
   POH S, 2004, LNCS, V3361, P159
   ROLI F, 2002, 3 INT WORKSH MULT CL, P252
   Snelick R, 2005, IEEE T PATTERN ANAL, V27, P450, DOI 10.1109/TPAMI.2005.57
   TAKAHASHI K, 2004, P SPIE, V5404
   Wang YH, 2003, LECT NOTES COMPUT SC, V2688, P805
NR 20
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 2
PY 2009
VL 27
IS 3
SI SI
BP 279
EP 292
DI 10.1016/j.imavis.2007.12.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 393QA
UT WOS:000262386600007
DA 2024-07-18
ER

PT J
AU Park, J
   Kim, C
   Na, J
   Yi, J
   Turk, M
AF Park, Jiyoung
   Kim, Cheolhwon
   Na, Jackeun
   Yi, Juneho
   Turk, Matthew
TI Using structured light for efficient depth edge detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE depth edge detection; structured light
ID 3D; RECOGNITION; IMAGES
AB This research describes a novel approach that accurately detects depth edges with Cluttered inner texture edges effectively ignored. We strategically project structured light and exploit distortion of the light pattern in the structured light image along depth discontinuities to reliably detect depth edges. In practice, distortion along depth discontinuities may not occur or be large enough to detect depending oil the distance from the camera or projector. We present methods that guarantee the occurrence of the distortion along depth discontinuities for a continuous range of object location. Experimental results show that the proposed method accurately detects depth edges of shapes of human hands and bodies as well as general objects. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Na, Jackeun; Yi, Juneho] Sungkyunkwan Univ, Sch Informat & Commun Engn, Seoul, South Korea.
   [Park, Jiyoung] Elect & Telecommun Res Inst, Digital Content Res Div, Taejon, South Korea.
   [Turk, Matthew] Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
C3 Sungkyunkwan University (SKKU); Electronics & Telecommunications
   Research Institute - Korea (ETRI); University of California System;
   University of California Santa Barbara
RP Yi, J (corresponding author), Sungkyunkwan Univ, Sch Informat & Commun Engn, Seoul, South Korea.
EM jhyi@skku.edu
OI Turk, Matthew/0000-0002-4198-8401
FU Korea Science and Engineering Foundation (KOSEF)
FX This work was supported in part by the Korea Science and Engineering
   Foundation (KOSEF) through the Biometrics Engineering Research Center
   (BERC) at Yonsei University.
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   [Anonymous], IEEE COMP VIS PATT R
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177
   Cass TA, 1998, IEEE T PATTERN ANAL, V20, P1265, DOI 10.1109/34.730560
   FERIS R, 2004, IEEE WORKSH REAL TIM
   FROHLINGHAUS T, 1996, 13 INT C PATT REC, VA, P451
   Harding K.G., 1991, Proceedings of SPIE, vol. 1614 of Optics, V1614, P265
   HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433
   Park J, 2005, LECT NOTES COMPUT SC, V3804, P737
   Petkov N, 1997, BIOL CYBERN, V76, P83, DOI 10.1007/s004220050323
   Raskar R, 2004, ACM T GRAPHIC, V23, P679, DOI 10.1145/1015706.1015779
   Ryu J, 2006, IEICE T FUND ELECTR, VE89A, P678, DOI 10.1093/ietfec/e89-a.3.678
   VIEIRA MB, 2005, IEEE INT WORKSH PROJ
   Weiss I, 2001, IEEE T PATTERN ANAL, V23, P116, DOI 10.1109/34.908963
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035
NR 19
TC 14
Z9 18
U1 5
U2 20
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1449
EP 1465
DI 10.1016/j.imavis.2008.01.006
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000001
DA 2024-07-18
ER

PT J
AU Lu, N
   Feng, ZR
AF Lu, Na
   Feng, Zuren
TI Mathematical model of blob matching and modified Bhattacharyya
   coefficient
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE blob matching; Bhattacharyya coefficient; similarity measure;
   mathematical model
ID PROTOCOL
AB A mathematical model of blob matching is developed in this paper. Based on the model, the matching performance of Bhattacharyya coefficient is analyzed and evaluated. The numerical critical conditions of biased matching and mistaken matching for Bhattacharyya coefficient are given. According to the model analysis, a modified version of Bhattacharyya coefficient is proposed, which improves the matching performance relative to the original one. The numerical analysis based on the new model and visual experiments both demonstrate the superior performance of the modified Bhattacharyya coefficient. (c) 2008 Elsevier B.V. All rights reserved.
C1 [Lu, Na; Feng, Zuren] Xi An Jiao Tong Univ, Syst Engn Inst, State Key Lab Mfg Syst Engn, Xian 710049, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Lu, N (corresponding author), Xi An Jiao Tong Univ, Syst Engn Inst, State Key Lab Mfg Syst Engn, Xian 710049, Shaanxi, Peoples R China.
EM lnlunar@yahoo.com.cn
RI Lu, Na/KMA-3229-2024
FU National Natural Science Foundation of China [60475023]; National
   Doctoral Foundation of China [20050698032]
FX This research is supported by National Natural Science Foundation of
   China under Grant No. 60475023 and National Doctoral Foundation of China
   under Grant No. 20050698032.
CR BROWN RL, 1995, IEEE T SYST MAN CYB, V25, P523, DOI 10.1109/21.364867
   Chen HT, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P717, DOI 10.1109/ICCV.2001.937697
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Crouzil A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P632, DOI 10.1109/ICPR.1996.546101
   He YL, 2006, IEEE T PATTERN ANAL, V28, P850, DOI 10.1109/TPAMI.2006.119
   JOUKHADAR A, 1999, P IEEE INT C INT ROB, V3, P1810
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Khalid MS, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P209, DOI 10.1109/ISPA.2005.195411
   Liu TL, 2004, IEEE T PATTERN ANAL, V26, P397, DOI 10.1109/TPAMI.2004.1262335
   Nguyen HT, 2006, INT J COMPUT VISION, V69, P277, DOI 10.1007/s11263-006-7067-x
   Shekhar C, 1998, INT C PATT RECOG, P146, DOI 10.1109/ICPR.1998.711101
   Skerl D, 2003, LECT NOTES COMPUT SC, V2717, P330
   Skerl D, 2004, INT C PATT RECOG, P794, DOI 10.1109/ICPR.2004.1334648
   Skerl D, 2006, IEEE T MED IMAGING, V25, P779, DOI 10.1109/TMI.2006.874963
   THEODORIDIS S, 2003, PATTERN RECOGN, P337
   WAGNER R, 1992, IEEE T BIO-MED ENG, V39, P1313, DOI 10.1109/10.184709
NR 17
TC 2
Z9 2
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1421
EP 1434
DI 10.1016/j.imavis.2008.01.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700010
DA 2024-07-18
ER

PT J
AU Pomares, J
   Gil, P
   García, GJ
   Sebastián, JM
   Torres, F
AF Pomares, J.
   Gil, P.
   Garcia, G. J.
   Sebastian, J. M.
   Torres, F.
TI Improving detection of surface discontinuities in visual-force control
   systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE surface discontinuity recognition; visual-force fusion; visual robot
   guidance
AB In this paper, a new approach to detect surface discontinuities in a visual-force control task is described. A task which consists in tracking a surface using visual-force information is shown. In this task, in order to reposition the robot tool with respect to the surface it is necessary to determine the surface discontinuities. This paper describes a new method to detect surface discontinuities employing sensorial information obtained from a force sensor, a camera and structured light. This method has proved to be more robust than previous systems even in situations where high frictions occur. (c) 2008 Published by Elsevier B.V.
C1 [Pomares, J.; Gil, P.; Garcia, G. J.; Torres, F.] Univ Alicante, Syst Engn & Signal Theory Dept, E-03080 Alicante, Spain.
   [Sebastian, J. M.] Univ Politecn Madrid, DISAM, Madrid 28006, Spain.
C3 Universitat d'Alacant; Universidad Politecnica de Madrid
RP Pomares, J (corresponding author), Univ Alicante, Syst Engn & Signal Theory Dept, POB 99, E-03080 Alicante, Spain.
EM jpomares@ua.es; Pablo.Gil@ua.es; gjgg@ua.es; jsebas@etsii.upm.es;
   Fernando.Torres@ua.es
RI Sebastian, Jose/JAN-9958-2023; Pomares, Jorge/H-3291-2015; Pomares,
   Jorge/AAP-2219-2021; Garcia, Gabriel/GWZ-5540-2022; Gil,
   Pablo/J-1286-2014; Torres, Fernando/L-1798-2014; Sebastian, Jose
   Maria/L-1407-2014; Garcia, Gabriel J./I-1994-2015
OI Pomares, Jorge/0000-0002-7523-9118; Pomares, Jorge/0000-0002-7523-9118;
   Gil, Pablo/0000-0001-9288-0161; Torres, Fernando/0000-0002-6261-9939;
   Sebastian, Jose Maria/0000-0002-6608-5989; Garcia, Gabriel
   J./0000-0002-3919-9606
FU Spanish MCYT project [DPI2005-06222]
FX This work was funded by the Spanish MCYT project "Diseno, Implementacion
   y Experimentacion de Escenarios de Manipulacion Inteligentes para
   Aplicaciones de Ensamblado y Desensamblado Automatico" (DPI2005-06222).
CR BEHRINGER R, 1995, P INT S INT VEH DETR
   Bruyninckx H, 1996, IEEE T ROBOTIC AUTOM, V12, P581, DOI 10.1109/70.508440
   CHAVEZ E, 1999, TRDCC993 U CHIL DEP
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   FAUGUERAS O, 1995, INT J PATTERN RECOGN, V2, P485
   GIL P, 2006, INT C COMP VIS THEOR, V1, P501
   HANDBURY A, 2001, N0401NM CTR MORPH MA
   HARTLEY R, 2000, MULTIPLE VIEW GEOMET, P91
   HERSHBERGER J, 1993, P 5 S DAT HANDL, P134
   HOGAN N, 1985, J DYN SYST-T ASME, V107, P1, DOI 10.1115/1.3140702
   Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972
   Khadraoui D, 1996, IEEE T ROBOTIC AUTOM, V12, P743, DOI 10.1109/70.538978
   Krupa A, 2003, IEEE T ROBOTIC AUTOM, V19, P842, DOI 10.1109/TRA.2003.817086
   Mezouar Y, 2002, IEEE T ROBOTIC AUTOM, V18, P534, DOI 10.1109/TRA.2002.802218
   Morel G, 1998, IEEE INT CONF ROBOT, P1743, DOI 10.1109/ROBOT.1998.677418
   Namiki A, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P3195, DOI 10.1109/ROBOT.1999.774085
   OLSSON T, 2004, P IEEE RSJ INT C INT, P798
   Pagès J, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2676
   Pomares J, 2005, IEEE T SYST MAN CY C, V35, P4, DOI 10.1109/TSMCC.2004.840045
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Tsuji T, 1997, IEEE INT CONF ROBOT, P2571, DOI 10.1109/ROBOT.1997.619348
   WHITNEY DE, 1977, J DYN SYST MEAS CONT, P97
   WILLSKY AS, 1976, IEEE T AUTOMAT CONTR, V21, P108, DOI 10.1109/TAC.1976.1101146
   Zhao Y, 2004, IEEE INT CONF ROBOT, P261, DOI 10.1109/ROBOT.2004.1307161
NR 26
TC 5
Z9 5
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1435
EP 1447
DI 10.1016/j.imavis.2008.01.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700011
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Kurdthongmee, W
AF Kurdthongmee, W.
TI A novel Kohonen SOM-based image compression architecture suitable for
   moderate density FPGAs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image quantization; image compression; FPGA-based implementation;
   Kohonen self-organizing map
ID SELF-ORGANIZING MAP; COLOR QUANTIZATION; IMPLEMENTATION
AB Kohonen self-organizing map (K-SOM) has proved to be suitable for lossy compression of digital images. The main drawback of this technique is that it is a very computationally intensive task if software implementation is performed alone. Fortunately, the structure is fairly easy to convert into parallel processing units. However, it consumes much of a microchip's internal resources and results in utilizing more than a single microchip to realize the structure in pure hardware. Previously proposed K-SOM realizations were mainly targeted on implementing on an ASIC (Application Specific Integrated Circuit) with low restriction on resource utilization. In this paper, we, in contrast, propose a novel architecture of K-SOM which compromises between image quality, frame rate throughput and FPGA's resource utilization. The architecture is based on unsigned integer arithmetic in all operations and has been successfully synthesized on a single moderate resource FPGA with acceptable image quality and frame rate. (C) 2007 Elsevier B.V. All rights reserved.
C1 Walailak Univ, Sch Engn & Resources Management, Div Comp Engn, Tha Sa La 80160, Nakron Si Thamm, Thailand.
C3 Walailak University
RP Kurdthongmee, W (corresponding author), Walailak Univ, Sch Engn & Resources Management, Div Comp Engn, 222 Thaibury, Tha Sa La 80160, Nakron Si Thamm, Thailand.
EM kwattana@wu.ac.th
RI Kurdthongmee, Wattanapong/GLU-5669-2022
OI Kurdthongmee, Wattanapong/0000-0001-6467-1039
CR [Anonymous], P IEEE INT C NEURAL
   DEKKER AH, 1994, NETWORK-COMP NEURAL, V5, P351, DOI 10.1088/0954-898X/5/3/003
   Honkela T., THESIS HELSINKI U TE
   KANJANAWANISHKU.K, 2004, J VISUAL COMMUNICATI
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Kurdthongmee W, 2006, MICROPROCESS MICROSY, V30, P234, DOI 10.1016/j.micpro.2005.12.005
   Kurdthongmee W, 2005, MICROPROCESS MICROSY, V29, P327, DOI 10.1016/j.micpro.2004.12.002
   *OP ORG, OP SD RAM CONTR MOD
   Pei SC, 1998, IEEE T CIRC SYST VID, V8, P191, DOI 10.1109/76.664104
   PEIRIS V, 1994, P IEEE WORLD C COMP, P2064
   SOUDRIS D, 2000, P 10 INT WORKSH PATM, P243
   Sudha N, 2004, REAL-TIME IMAGING, V10, P31, DOI 10.1016/j.rti.2003.12.001
   Sudha N, 2003, J SYST ARCHITECT, V48, P337, DOI 10.1016/S1383-7621(03)00021-3
   *XIL INC, XIL VIRT 2 PROF FPGA
NR 14
TC 10
Z9 10
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1094
EP 1105
DI 10.1016/j.imavis.2007.11.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300003
DA 2024-07-18
ER

PT J
AU Liang, BD
   Chung, R
AF Liang, Bodong
   Chung, Ronald
TI Viewpoint determination of image by interpolation over sparse samples
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE function interpolation; viewpoint determination
ID POSE ESTIMATION; SCATTERED DATA; MOTION
AB We address the problem of determining the viewpoint of an image without referencing to or estimating explicitly the 3-D structure pictured in the image. Used for reference are instead a number of sample snapshots of the scene, each supplied with the associated viewpoint. By viewing image and its associated viewpoint as the input and output of a function, and the reference snapshot-viewpoint pairs as input-output samples of that function, we have a natural formulation of the problem as an interpolation one. The interpolation formulation allows imaging details like camera intrinsic parameters to be unknown, and the specification or the desired viewpoint to be not necessarily in metric terms. We describe an interpolation-based mechanism that determines the viewpoint of any given input image, which has the property that it fits all the given input-output reference samples exactly. Experimental results on benchmarking image datasets show that the mechanism is effective in reaching quality viewpoint solution even with only a few reference snapshots. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Liang, Bodong; Chung, Ronald] Chinese Univ Hong Kong, Dept Mech & Automat Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese University of Hong Kong
RP Chung, R (corresponding author), Chinese Univ Hong Kong, Dept Mech & Automat Engn, Shatin, Hong Kong, Peoples R China.
EM bdliang@mae.cuhk.edu.hk; rchung@mae.cuhk.edu.hk
RI Chung, Chi-Kit Ronald/C-7702-2011
CR [Anonymous], P ECCV
   [Anonymous], STATE ART NUMERICAL
   Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992
   Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   COHEN MF, 2000, P INT WORKSH HUM MOD, P87
   Dyn N., 1987, TOPICS MULTIVARIATE, P47, DOI DOI 10.1016/B978-0-12-174585-1.50009-9
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Fiore PD, 2001, IEEE T PATTERN ANAL, V23, P140, DOI 10.1109/34.908965
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351
   KUMAR R, 1994, CVGIP-IMAG UNDERSTAN, V60, P313, DOI 10.1006/ciun.1994.1060
   LIANG B, 2003, P 2003 IEEE INT AUT, P81
   LIANG B, 2004, P 2004 IEE RSJ INT C, P2319
   MICCHELLI CA, 1986, CONSTR APPROX, V2, P11, DOI 10.1007/BF01893414
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Rose C, 1998, IEEE COMPUT GRAPH, V18, P32, DOI 10.1109/38.708559
   Rousseeuw P. J., 1987, ROBUST REGRESSION OU
   RUPRECHT D, 1995, IEEE COMPUT GRAPH, V15, P37, DOI 10.1109/38.365004
   Schaback R., 1995, Ser. Approx. Decompos, V6, P491
   Simon G, 2002, IEEE COMPUT GRAPH, V22, P46, DOI 10.1109/MCG.2002.1046628
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 27
TC 1
Z9 2
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 941
EP 954
DI 10.1016/j.imavis.2007.10.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800008
DA 2024-07-18
ER

PT J
AU Tresadern, PA
   Reid, ID
AF Tresadern, Philip A.
   Reid, Ian D.
TI Camera calibration from human motion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE self-calibration; human motion analysis
AB This paper presents a method for the self-calibration of non-rigid affine structure to a Euclidean co-ordinate frame from only two views by enforcing constraints derived from the known structure of the human body, such as piecewise rigidity and approximate symmetry. We show that the proposed algorithm is considerably more efficient yet equally accurate when compared to previous methods. The resulting structure and motion is then refined further using a full bundle adjustment to give maximum likelihood values for body segment lengths and joint angles. A quantitative analysis is presented using synthetic data whilst qualitative results are demonstrated for real examples of human motion. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Tresadern, Philip A.] Univ Salford, Ctr Rehabil & Human Performance Res, Salford M6 6PU, Lancs, England.
   [Reid, Ian D.] Univ Oxford, Act Vis Lab, Oxford OX1 3PJ, England.
C3 University of Salford; University of Oxford
RP Tresadern, PA (corresponding author), Univ Salford, Ctr Rehabil & Human Performance Res, Salford M6 6PU, Lancs, England.
EM p.tresadem@salford.ac.uk
OI Reid, Ian/0000-0001-7790-6423
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Caspi Y, 2006, INT J COMPUT VISION, V68, P53, DOI 10.1007/s11263-005-4842-z
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Liebowitz D, 2003, INT J COMPUT VISION, V51, P171, DOI 10.1023/A:1021897717694
   Morris DD, 1998, PROC CVPR IEEE, P289, DOI 10.1109/CVPR.1998.698622
   Quan L, 1996, INT J COMPUT VISION, V19, P93, DOI 10.1007/BF00131149
   Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600
   REID I, 1996, LNCS, V1065, P647
   Ronfard R, 2002, LECT NOTES COMPUT SC, V2353, P700
   Rosales R, 2000, PROC CVPR IEEE, P721, DOI 10.1109/CVPR.2000.854946
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Sinha SN, 2004, PROC CVPR IEEE, P195
   Sminchisescu C, 2005, PROC CVPR IEEE, P390
   Stenger B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1063
   Sullivan J, 2002, LECT NOTES COMPUT SC, V2350, P629
   Taylor CJ, 2000, COMPUT VIS IMAGE UND, V80, P349, DOI 10.1006/cviu.2000.0878
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Tresadern P, 2004, PROC CVPR IEEE, P128
   Tresadern P., 2003, Proceedings of the 14th British Machine Vision Conference, P629
   Tuytelaars T, 2004, PROC CVPR IEEE, P762
   WANG R, 2005, P 16 BRIT VIS C OXF
   Zelnik-Manor L, 2003, PROC CVPR IEEE, P287
NR 23
TC 10
Z9 13
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 851
EP 862
DI 10.1016/j.imavis.2007.10.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, XY
   Ren, H
   Li, B
AF Yang, Xiaoyuan
   Ren, Hui
   Li, Bo
TI Embedded zerotree wavelets coding based on adaptive fuzzy clustering for
   image compression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image compression; fuzzy c-means clustering; embedded zerotree wavelets
   coding
ID EFFICIENT
AB In this paper, a new quantization approach based on an adaptive fuzzy c-means clustering for image compression is presented. The fuzzy cluster theory is applied to quantizing the wavelet coefficients of low-frequency subband after the image has been decomposed by wavelet transform. The method can automatically label the importance degree of coefficients of wavelets, and get new constraints on membership condition by weighted average method of the importance and 1 (q(k) = theta((1))(k). 1 + theta((2))(k) . lambda(k), theta((1))(k) + theta((2))(k) = 1). Based on this condition, we cluster again. The proof of convergence of the algorithm is given. The experimental results show that exacter reconstructed values of wavelet coefficients can be obtained at low bit-rates, the subjective and objective quality of the reconstructed image is improved. This technique is shown to yield PSNR of reconstructed images improvement from 0.2 dB to 2.8 dB. This paper has brought about some new ideas in combining the fuzzy cluster algorithm with the embedded zerotree wavelets algorithm. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Yang, Xiaoyuan; Ren, Hui] Beihang Univ, Sch Sci, Dept Math, Minist Educ,Key Lab Math Informat & Behav Semant, Beijing 100083, Peoples R China.
   [Li, Bo] Beihang Univ, Sch Engn & Comp Sci, Digital Media Lab, Beijing 100083, Peoples R China.
C3 Beihang University; Beihang University
RP Yang, XY (corresponding author), Beihang Univ, Sch Sci, Dept Math, Minist Educ,Key Lab Math Informat & Behav Semant, Beijing 100083, Peoples R China.
EM xiaoyuanyang@vip.163.com
RI Li, Bo/AAA-8968-2020
OI Li, Bo/0000-0002-7294-6888
CR AARON TD, 2003, IEEE T IMAGE PROCESS, V12, P489
   AARON TD, 2003, IEEE T IMAGE PROCESS, V12, P420
   Bezdek James C., 1981, PATTERN RECOGN
   Bezdek JC., 1992, FUZZY MODELS PATTERN
   CHIU SL, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P1240, DOI 10.1109/FUZZY.1994.343644
   Chrysafis C, 1997, IEEE DATA COMPR CONF, P241, DOI 10.1109/DCC.1997.582047
   Gröll L, 2005, IEEE T FUZZY SYST, V13, P717, DOI 10.1109/TFUZZ.2005.856560
   JOHN AR, 2006, IEEE T IMAGE PROCESS, V15, P2131
   Pal NR, 1996, NEURAL NETWORKS, V9, P787, DOI 10.1016/0893-6080(95)00094-1
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Peng KW, 2004, IEEE T IMAGE PROCESS, V13, P1011, DOI 10.1109/TIP.2004.828441
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Tu CJ, 2002, IEEE T IMAGE PROCESS, V11, P1271, DOI 10.1109/TIP.2002.804279
   WEI W, 1994, PATTERN RECOGN, V27, P1567, DOI 10.1016/0031-3203(94)90134-1
   WEISI L, 2006, IEEE T IMAGE PROCESS, V15, P2513
   Wu X., 1997, P 31 ASILOMAR C SIGN, V2, P1378, DOI DOI 10.1109/DCC.1997.582047
   Wu XL, 1999, IEEE DATA COMPR CONF, P102, DOI 10.1109/DCC.1999.755659
   Xiao SK, 2006, IEEE T IMAGE PROCESS, V15, P3253, DOI 10.1109/TIP.2006.882028
   Yoo Y, 1999, IEEE T IMAGE PROCESS, V8, P1702, DOI 10.1109/83.806617
NR 21
TC 13
Z9 14
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 812
EP 819
DI 10.1016/j.imavis.2007.08.019
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900008
DA 2024-07-18
ER

PT J
AU Wang, YQ
AF Wang Yuanqing
TI Estimating the minimum redundancy in stereo image pair
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereo image; stereo image compression; residual image; Gaussian
   function; image characteristics
ID COMPRESSION
AB The raw data in binocular stereo image sequences is twice as that of monocular images, the large amount of information should be reduced. As a result there has been increasing attention given to image compression methods specialized to stereo pairs. Much of this work has concentrated on improving the disparity compensation process and codes the residual image similarly to a monocular image where one view is used to predict another, and the difference is coded. The residual image is usually composed primarily of strong vertical direction edge components surrounded by large areas of near zero intensity. The residual images have different characteristics, but they behave uniquely statistical regularity. This property is demonstrated experimentally in the paper. Two interested statistical variables are described, the one is the total number (N) of the pixels with near zero intensity in the residual image and other is the coordinate displacements (Delta x,Delta y) between the left and right image frames for get the residual image. Experimental results indicate that the curve between the parameters N and variables (Delta x, Delta y) may be fit by Gaussian function. The maximum of the variable N corresponding to the optimal displacements (Delta x(op),Delta y(op)) may be estimated by the Gaussian approximation. An algorithm is further provided to quickly predict the minimal redundancy of the residual image and the corresponding displacement. It is shown how such characteristics may be of great benefit to quickly achieve the higher compression ratio. (C) 2007 Elsevier B.V. All rights reserved.
C1 Nanjing Univ, Dept Elect Sci & Engn, Nanjing 210093, Peoples R China.
C3 Nanjing University
RP Wang, YQ (corresponding author), Nanjing Univ, Dept Elect Sci & Engn, Nanjing 210093, Peoples R China.
EM yqwang@nju.edu.cn
CR FOK S, 2002, THESIS U WATERLOO ON
   Frajka T, 2003, OPT ENG, V42, P182, DOI 10.1117/1.1526492
   Hawkins R., 2002, THESIS AUSTR NATL U
   KONRAD J, 2000, P SPIE STEREOSCOPIC, V3957, P1
   Moellenhoff MS, 1998, SIGNAL PROCESS-IMAGE, V14, P55, DOI 10.1016/S0923-5965(98)00028-9
   Siegel M, 1997, P SOC PHOTO-OPT INS, V3012, P227, DOI 10.1117/12.274461
   SIEGEL MW, 1994, P SOC PHOTO-OPT INS, V2177, P258, DOI 10.1117/12.173899
NR 7
TC 1
Z9 1
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 725
EP 730
DI 10.1016/j.imavis.2006.08.008
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900012
DA 2024-07-18
ER

PT J
AU Long, X
   Cleveland, WL
   Yao, YL
AF Long, Xi
   Cleveland, W. Louis
   Yao, Y. Lawrence
TI Multiclass cell detection in bright field images of cell mixtures with
   ECOC probability estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE cell detection; Error Correcting Output Coding (ECOC); multiclass
   classification; support vector machines
AB To achieve high throughput with robotic systems based on optical microscopy, it is necessary to replace the human observer with computer vision algorithms that can identify and localize individual cells as well as carry out additional studies on these cells in relation to biochemical parameters. The latter task is best accomplished with the use of fluorescent probes. Since the number of fluorescence channels is limited, it is highly desirable to accomplish the cell identification and localization task with transmitted light microscopy. In previous work, we developed algorithms for automatic detection of unstained cells of a single type in bright field images [X. Long, W.L. Cleveland, Y.L. Yao, A new preprocessing approach for cell recognition, IEEE Transactions on Information Technology in Biomedicine 9 (3) (2005) 407-412; X Long, W.L. Cleveland, Y.L. Yao, Automatic detection of unstained viable cells in bright field images using a support vector machine with an improved training procedure, Computers in Biology and Medicine 36 (2006) 339-362]. Here we extend this technology to facilitate identification and localization of multiple cell types. We formulate the detection of multiple cell types in mixtures as a supervised, multiclass pattern recognition problem and solve it by extension of the Error Correcting Output Coding (ECOC) method to enable probability estimation. The use of probability estimation provides both cell type identification as well as cell localization relative to pixel coordinates. Our approach has been systematically studied under different overlap conditions and outperforms several commonly used methods, primarily due to the reduction of inconsistent labeling by introducing redundancy. Its speed and accuracy are sufficient for use in some practical systems. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Long, Xi; Yao, Y. Lawrence] Columbia Univ, Dept Mech Engn, New York, NY 10027 USA.
   [Cleveland, W. Louis] St Lukes Roosevelt Hosp, Dept Med, New York, NY 10019 USA.
   [Cleveland, W. Louis] Columbia Univ, New York, NY 10019 USA.
C3 Columbia University; Mount Sinai St. Luke's; Mount Sinai West; Columbia
   University
RP Cleveland, WL (corresponding author), Columbia Univ, Dept Mech Engn, 220 Mudd,MC4703, New York, NY 10027 USA.
EM xl2002@columbia.edu; wlcl@columbia.edu
CR Aha DW, 1997, AI APPLICATIONS, V11, P13
   Allwein E., 2002, JMLR, V1, P113
   [Anonymous], 1998, STAT LEARNING THEORY
   BAKIRI G, 1999, ACHIEVING HIGH ACCUR
   BERGER A, 1999, IJCAI99
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   CHAKRABORTY DP, 1989, MED PHYS, V16, P561, DOI 10.1118/1.596358
   CLEVELAND WL, 1983, J IMMUNOL METHODS, V56, P221
   Dietterich TG, 1994, J ARTIF INTELL RES, V2, P263
   Eun Bae Kong, 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P313
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   GHANI R, 2000, P 17 INT C MACH LEAR, P303
   Guruswami V., 1999, Proceedings of the Twelfth Annual Conference on Computational Learning Theory, P145, DOI 10.1145/307400.307429
   Hastie Trevor., 1998, ADV NEURAL INFORM PR, V10
   HUANG TK, 2004, GEN BRADLEY TERRY MO
   James G, 1998, J COMPUT GRAPH STAT, V7, P377, DOI 10.2307/1390710
   Kittler J, 2001, PROC CVPR IEEE, P755
   Long X, 2006, COMPUT BIOL MED, V36, P339, DOI 10.1016/j.compbiomed.2004.12.002
   Long X, 2005, IEEE T INF TECHNOL B, V9, P407, DOI 10.1109/TITB.2005.847502
   Mishell B., 1980, SELECTED METHODS CEL
   Nattkemper TW, 2001, IEEE T INF TECHNOL B, V5, P138, DOI 10.1109/4233.924804
   Tax DMJ, 2002, INT C PATT RECOG, P124, DOI 10.1109/ICPR.2002.1048253
   VALENTINI GM, 2002, LECT NOTES COMPUTER
NR 24
TC 14
Z9 15
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 578
EP 591
DI 10.1016/j.imavis.2007.07.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100010
DA 2024-07-18
ER

PT J
AU Nickel, K
   Stiefelhagen, R
AF Nickel, Kai
   Stiefelhagen, Rainer
TI Visual recognition of pointing gestures for human-robot interaction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE person tracking; gesture recognition; head orientation; human-robot
   interaction
AB In this paper, we present an approach for recognizing pointing gestures in the context of human-robot interaction. In order to obtain input features for gesture recognition, we perform visual tracking of head, hands and head orientation. Given the images provided by a calibrated stereo camera, color and disparity information are integrated into a multi-hypothesis tracking framework in order to find the 3D-positions of the respective body parts. Based on the hands' motion, an HMM-based classifier is trained to detect pointing gestures. We show experimentally that the gesture recognition performance can be improved significantly by using information about head orientation as an additional feature. Our system aims at applications in the field of human-robot interaction, where it is important to do run-on recognition in real-time, to allow for robot egomotion and not to rely on manual initialization. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Karlsruhe, Interact Syst Labs, D-76131 Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Nickel, K (corresponding author), Univ Karlsruhe, Interact Syst Labs, D-76131 Karlsruhe, Germany.
EM nickel@ira.uka.de; stiefel@ira.uka.de
CR [Anonymous], P 13 ICPR
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], IEEE C COMP VIS PATT
   ASFOUR T, 2001, P 2 IEEE RAS C HUM R
   BARBER P, 1976, PERCEPTION INFORMATI, pCH4
   BECKER DA, 1997, 426 MIT
   BRUMITT B, 2000, IEEE PERSONAL COMMUN
   CAMPBELL LW, 1996, 2 INT WORKSH FAC GES
   Cipolla R., 1994, Proceedings of IAPR Workshop on Machine Vision Applications, P163
   Glenstrup A.J., 1995, Eye controlled media: Present and future state
   HOLZAPFEL H, 2004, 6 INT C MULT INT STA
   Kahn RE, 1996, PROC CVPR IEEE, P734, DOI 10.1109/CVPR.1996.517154
   MAGLIO PP, 2000, P INT C MULT INT
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   PODDAR I, 1998, NATURAL GESTURE SPE
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   SEEMANN E, 2004, 6 INT C AUT FAC GEST
   STARNER T, 1994, VISUAL RECOGNITION A
   STIEFELHAGE R, 2000, INT C PATT REC ICPR
   VIOLA P, 2001, ICCV WORKSH STAT COM
   Wilson AD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P329, DOI 10.1109/ICCV.1998.710739
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   YANG W, 1997, CMUCS97146
   Yarbus A.L., 1967, EYE MOVEMENTS VISION, DOI [10.1007/978-1-4899-5379-7, DOI 10.1007/978-1-4899-5379-7]
NR 24
TC 155
Z9 190
U1 0
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 3
PY 2007
VL 25
IS 12
BP 1875
EP 1884
DI 10.1016/j.imavis.2005.12.020
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220BD
UT WOS:000250131000006
DA 2024-07-18
ER

PT J
AU Stenger, B
   Thayananthan, A
   Torr, PHS
   Cipolla, R
AF Stenger, B.
   Thayananthan, A.
   Torr, P. H. S.
   Cipolla, R.
TI Estimating 3D hand pose using hierarchical multi-label classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE computer vision; pose estimation; hand detection; multi-class
   classification; human-computer interaction
ID TRACKING
AB This paper presents an analysis of the design of classifiers for use in a hierarchical object recognition approach. In this approach, a cascade of classifiers is arranged in a tree in order to recognize multiple object classes. We are interested in the problem of recognizing multiple patterns as it is closely related to the problem of locating an articulated object. Each different pattern class corresponds to the hand in a different pose, or set of poses. For this problem obtaining labelled training data of the hand in a given pose can be problematic. Given a parametric 3D model, generating training data in the form of example images is cheap, and we demonstrate that it can be used to design classifiers almost as good as those trained using non-synthetic data. We compare a variety of different template-based classifiers and discuss their merits. (C) 2006 Elsevier B.V. All rights reserved.
C1 Toshiba Cambrige Res Lab, Cambridge CB2 3NH, England.
   Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
   Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England.
C3 Toshiba Corporation; University of Cambridge; Oxford Brookes University
RP Stenger, B (corresponding author), Toshiba Cambrige Res Lab, 1 Guildhall Str, Cambridge CB2 3NH, England.
EM bjorn@cantab.net; at315@eng.cam.ac.uk; philiptorr@brookes.ac.uk;
   cipolla@eng.cam.ac.uk
RI Arandjelović, Ognjen/V-5255-2019
OI Arandjelović, Ognjen/0000-0002-9314-194X; Cipolla,
   Roberto/0000-0002-8999-2151
CR [Anonymous], 2004, THESIS U CAMBRIDGE
   Athitsos V, 2003, PROC CVPR IEEE, P432
   Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125
   Barrow H. G., 1977, P IMAGE UNDERSTANDIN, P659
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Crow F. C., 1984, Computers & Graphics, V18, P207
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Felzenszwalb PF, 2001, PROC CVPR IEEE, P1056
   Gavrila D., 2000, Pedestrian Detection from a Moving Vehicle, V1843, P37
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Huttenlocher D. P., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P93, DOI 10.1109/ICCV.1993.378231
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   HUTTENLOCHER DP, 1997, ARPA IM UND WORKSH N, P1179
   Isard M., 1996, Proceedings of the European Conference on Computer Vision (ECCV), P343
   JERMYN IH, 1999, P 7 INT C COMP VIS C, V1, P20
   Jojic N, 2000, PROC CVPR IEEE, P26, DOI 10.1109/CVPR.2000.854728
   JULIER SJ, 1997, THESIS U OXFORD
   MACCORMICK J, 2000, P EUR C COMP VIS, V2, P3
   Olson CF, 1997, IEEE T IMAGE PROCESS, V6, P103, DOI 10.1109/83.552100
   Romdhani S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P695, DOI 10.1109/ICCV.2001.937694
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Stenger B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1063
   Stenger B, 2001, PROC CVPR IEEE, P310
   THAYANANTHAN A, 2003, P BRIT MACH VIS C, V2, P589
   Toyama K, 2002, INT J COMPUT VISION, V48, P9, DOI 10.1023/A:1014899027014
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Williams O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P353
NR 28
TC 17
Z9 21
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 3
PY 2007
VL 25
IS 12
BP 1885
EP 1894
DI 10.1016/j.imavis.2005.12.018
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220BD
UT WOS:000250131000007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Castellani, U
   Fusiello, A
   Gherardi, R
   Murino, V
AF Castellani, U.
   Fusiello, A.
   Gherardi, R.
   Murino, V.
TI Automatic selection of MRF control parameters by reactive tabu search
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE parameter estimation; Markov random fields; reactive tabu search
ID STEREO
AB This paper presents an optimization technique to automatically select a set of control parameters for a Markov random field. The method is based on the reactive tabu search strategy, and requires to define a suitable fitness function that measures the performance of the MRF algorithm with a given parameters set. The technique is applied to stereo matching thanks to the availability of ground truth disparity maps. Experiments with synthetic and real images illustrate the approach. (c) 2007 Published by Elsevier B.V.
C1 Univ Verona, Dipartimento Informat, I-37134 Verona, Italy.
C3 University of Verona
RP Gherardi, R (corresponding author), Univ Verona, Dipartimento Informat, Str Grazie 15, I-37134 Verona, Italy.
EM gherardi@sci.univr.it
RI Murino, Vittorio/A-5570-2011; Fusiello, Andrea/GOJ-9893-2022
OI Fusiello, Andrea/0000-0003-2963-0316; Murino,
   Vittorio/0000-0002-8645-2328
CR [Anonymous], 1995, Markov random field modeling in computer vision
   Battiti R., 1994, ORSA Journal on Computing, V6, P126, DOI 10.1287/ijoc.6.2.126
   Boykov Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P377, DOI 10.1109/ICCV.1999.791245
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Cinque L, 2000, INT C PATT RECOG, P474, DOI 10.1109/ICPR.2000.905379
   Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040
   Duda D.G., 2001, PATTERN CLASSIFICATI, V2nd
   Faugeras O., 1993, REAL TIME CORRELATIO
   FELZENSZWALB P, INT C COMP VIS PATT
   Fua P., 1991, P 12 INT JOINT C ART, P1292
   Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428
   Fusiello A, 2001, LECT NOTES COMPUT SC, V2134, P91
   GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GLOVER F, 1986, COMPUT OPER RES, V13, P533, DOI 10.1016/0305-0548(86)90048-1
   Glover F., 1998, Handbook of combinatorial optimization
   HERTZ A, 1995, CH1015 EPFL DEP MATH
   INTILLE SS, 1994, EUR C COMP VIS STOCK, P179
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   MARROQUINE JK, 1985, THESIS MIT
   Pronzato GL, 1997, IEE CONF PUBL, P356, DOI 10.1049/cp:19970915
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
NR 23
TC 7
Z9 9
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1824
EP 1832
DI 10.1016/j.imavis.2007.04.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900011
DA 2024-07-18
ER

PT J
AU Vidal, J
   Crespo, J
   Maojo, V
AF Vidal, Javier
   Crespo, Jose
   Maojo, Victor
TI A shape interpolation technique based on inclusion relationships and
   median sets
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE image processing; interpolation; shape interpolation; mathematical
   morphology; median set
AB Some image processing and analysis applications require performing image interpolation. This paper focuses on interpolation approaches that treat the shapes and the structures of binary images. A summary of some interpolation methods is presented, and their behavior concerning inclusion relationships and homotopy issues is studied. An inclusion relationship property that considers these aspects is introduced in this work. Furthermore, a complete technique based on this property in a recursive manner is presented. The paper shows that such a property can improve shape interpolation results in a relatively easy manner, particularly those concerning inclusion relationships between shapes. Several experimental results are provided. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Politecn Madrid, Fac Informat, Artificial Intelligence Lab, E-28660 Madrid, Spain.
   Univ Concepcion, Dept Comp Sci, Concepcion, Chile.
C3 Universidad Politecnica de Madrid; Universidad de Concepcion
RP Vidal, J (corresponding author), Univ Politecn Madrid, Fac Informat, Artificial Intelligence Lab, E-28660 Madrid, Spain.
EM jvidal@infomed.dia.fi.upm.es; jcrespo@fi.upm.es; vmaojo@fi.upm.es
RI Maojo, Victor/JXY-6220-2024
OI Maojo, Victor/0000-0001-5103-4292
CR [Anonymous], 2003, MORPHOLOGICAL IMAGE
   BEUCHER S, 1994, INTERPOLATIONS ENSEM
   Chatzis V, 2000, IEEE T MED IMAGING, V19, P699, DOI 10.1109/42.875192
   Chatzis V, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P939, DOI 10.1109/MMCS.1999.778615
   EDWARD R, 2003, HANDS MORPHOLOGICAL
   GUO JF, 1995, COMPUT MED IMAG GRAP, V19, P267, DOI 10.1016/0895-6111(95)00007-D
   HERMAN GT, 1992, IEEE COMPUT GRAPH, V12, P69, DOI 10.1109/38.135915
   IWANOWSKI M, 2000, INT S MATH MORPH PAL, P445
   Iwanowski M, 2002, P INT C COMP VIS GRA
   IWANOWSKI M, 2000, THESIS WARSAW U TECH
   Lee TY, 2000, IEEE T MED IMAGING, V19, P711, DOI 10.1109/42.875193
   Meijering E, 2002, P IEEE, V90, P319, DOI 10.1109/5.993400
   MEYER F, 1994, N1694MM
   Migeon B, 1998, P ANN INT IEEE EMBS, V20, P585, DOI 10.1109/IEMBS.1998.745463
   SERRA J, 1994, N1594MM
   SERRA J, 1988, MATH MORPHOLOGY, V2
   SERRA J, 1982, MATH MORPHOLOGY, V1
   SERRA J, 1998, MATH MORPHOLOGY APPL
   Soille P., 1991, Journal of Visual Communication and Image Representation, V2, P138, DOI 10.1016/1047-3203(91)90004-Y
   Vidal J, 2005, COMP IMAG VIS, V30, P53
   Vidal J, 2005, LECT NOTES COMPUT SC, V3429, P206
NR 21
TC 3
Z9 3
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1530
EP 1542
DI 10.1016/j.imavis.2006.06.017
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200003
DA 2024-07-18
ER

PT J
AU Yin, JP
   Zhu, E
   Yang, XJ
   Zhang, GM
   Hu, CF
AF Yin, Jianping
   Zhu, En
   Yang, Xuejun
   Zhang, Guomin
   Hu, Chunfeng
TI Two steps for fingerprint segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fingerprint segmentation; remaining ridges; spurious minutiae
ID IMAGE SEGMENTATION; ENHANCEMENT; MINUTIAE
AB A fingerprint image usually consists of different regions: non-ridge regions, high quality ridge regions, and low quality ridge regions. Fingerprint segmentation is usually to exclude non-ridge regions and unrecoverable low quality ridge regions as background so as to avoid detecting false features. In ridge regions, including high quality and low quality, there are often some remaining ridges which are the afterimage of the previously scanned finger and are expected to be excluded as background. However, existing segmentation methods do not take this case into consideration, and often, the remaining ridge regions are falsely taken as foreground. This paper proposes two steps for fingerprint segmentation to exclude the remaining ridge region from the foreground. The non-ridge regions and unrecoverable low quality ridge regions are removed as background in the first step, and then the foreground produced by the first step is further analyzed so as to remove the remaining ridge region. The experimental results showed the effectiveness of the proposed method in segmenting the remaining ridges as background and in turn producing much less spurious minutiae than the existing method. (C) 2006 Elsevier B.V. All rights reserved.
C1 Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Peoples R China.
C3 National University of Defense Technology - China
RP Zhu, E (corresponding author), Natl Univ Def Technol, Sch Comp Sci, Changsha 410073, Peoples R China.
EM nudt_en@263.net
RI YANG, Xue/HPI-0953-2023
CR Ailisto H., 2003, INT J IMAGE GRAPHICS, V3, P401
   [Anonymous], P 16 INT C PATT REC
   Bazen A.M., 2001, PROC WORKSHOP CIRCUI, P276
   Bazen AM, 2000, P PRORISC2000 11 ANN, P215
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Jain AK, 1997, PATTERN RECOGN, V30, P295, DOI 10.1016/S0031-3203(96)00068-4
   Jiang XD, 2001, PATTERN RECOGN, V34, P999, DOI 10.1016/S0031-3203(00)00050-9
   Klein S., 2002, P 13 ANN WORKSH CIRC, P310
   Maio D, 1997, IEEE T PATTERN ANAL, V19, P27, DOI 10.1109/34.566808
   MAIO D, 2004, P INT C BIOM AUTH
   Mehtre B. M., 1993, Machine Vision and Applications, V6, P124, DOI 10.1007/BF01211936
   MEHTRE BM, 1987, PATTERN RECOGN, V20, P429, DOI 10.1016/0031-3203(87)90069-0
   MEHTRE BM, 1989, PATTERN RECOGN, V22, P381, DOI 10.1016/0031-3203(89)90047-2
   MEHTRE BM, 1986, 2 INT C ADV PATT REC
   Ong TS, 2003, LECT NOTES ARTIF INT, V2903, P624
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   RATHA NK, 1995, PATTERN RECOGN, V28, P1657, DOI 10.1016/0031-3203(95)00039-3
   Ren Q., 2002, P 3 WORKSH AUT ID AD, P137
   Wang L, 2004, LECT NOTES COMPUT SC, V3338, P414
   Yin YL, 2005, LECT NOTES COMPUT SC, V3546, P647
   Zhu E, 2005, LECT NOTES COMPUT SC, V3611, P65
   Zhu E, 2004, LECT NOTES COMPUT SC, V3212, P750
NR 22
TC 23
Z9 30
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1391
EP 1403
DI 10.1016/j.imavis.2006.10.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000002
DA 2024-07-18
ER

PT J
AU Tang, QL
   Sang, N
   Zhang, TX
AF Tang, Qiling
   Sang, Nong
   Zhang, Tianxu
TI Contour detection based on contextual influences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE contour detection; contextual influences; visual mechanisms;
   suppression; enhancement
ID PRIMARY VISUAL-CORTEX; RECEPTIVE-FIELD; EDGE-DETECTION; SURROUND
   SUPPRESSION; MACAQUE MONKEY; CELLS; INHIBITION; ORIENTATION; RESPONSES;
   SEGMENTATION
AB A contour detection model, inspired by the behavior of the primary visual cortex, is presented. The response of a central stimulus in the receptive field is affected by the presence of surrounding stimuli - for some stimulus conditions, the response is suppressed and for other conditions the response is enhanced. The visual mechanisms of contextual influences are utilized to extract "coherent" configurations. This is mainly due to the following two reasons: (1) on the one hand, a smooth contour can yield collinear excitation, which highlights smooth contours from irregularly textured surround; (2) on the other hand, similar orientation textures receive iso-orientation surround suppression and region boundary is subjected to the less inhibition, which makes boundary more salient for perceptual pop-out. Accordingly, smooth contours progressively stand out from their surround and at the same time textures are gradually suppressed by their surround through dynamic fine-tuning of contextual information. The proposed method which distinguishes between contours and texture edges is more effective for contour-based object recognition tasks. Initial experiments show that the model can be successfully applied to contour detection. Especially, when object contours are lumped together with unwantedly cluttered surround, the advantage of our approach is more prominent. This study provides a biological scheme for contour detection in computer vision. (c) 2006 Elsevier B.V. All rights reserved.
C1 Huazhong Univ Sci & Technol, Inst Pattern Recognit & Artificial Intelligence, Wuhan 430074, Peoples R China.
   Minist Educ Image Proc & Intelligent Control, Key Lab, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Sang, N (corresponding author), Huazhong Univ Sci & Technol, Inst Pattern Recognit & Artificial Intelligence, Wuhan 430074, Peoples R China.
EM tqlinn@sohu.com; nsang@hust.edu.cn
CR BLAKEMORE C, 1972, EXP BRAIN RES, V15, P439
   Bonneh Y, 1998, VISION RES, V38, P3541, DOI 10.1016/S0042-6989(98)00045-5
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan W, 2001, PATTERN RECOGN, V34, P2523, DOI 10.1016/S0031-3203(00)00155-2
   DAUGMAN JG, 1985, J OPT SOC AM, V2, P160
   DEVALOIS RL, 1982, VISION RES, V22, P531, DOI 10.1016/0042-6989(82)90112-2
   Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   GRINVALD A, 1994, J NEUROSCI, V14, P2545
   Hancock E. R., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P196, DOI 10.1109/CVPR.1991.139687
   HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L
   HIGGINS WE, 1994, PATTERN RECOGN, V27, P277, DOI 10.1016/0031-3203(94)90059-0
   IVERSON LA, 1995, IEEE T PATTERN ANAL, V17, P982, DOI 10.1109/34.464562
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   KAPADIA MK, 1995, NEURON, V15, P843, DOI 10.1016/0896-6273(95)90175-2
   KNIERIM JJ, 1992, J NEUROPHYSIOL, V67, P961, DOI 10.1152/jn.1992.67.4.961
   KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452
   Levitt JB, 1997, NATURE, V387, P73, DOI 10.1038/387073a0
   Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9
   Li ZP, 1999, NETWORK-COMP NEURAL, V10, P187, DOI 10.1088/0954-898X/10/2/305
   MARCELJA S, 1980, J OPT SOC AM, V70, P129
   MEHROTRA R, 1992, PATTERN RECOGN, V25, P1479, DOI 10.1016/0031-3203(92)90121-X
   MORRONE MC, 1988, PROC R SOC SER B-BIO, V235, P221, DOI 10.1098/rspb.1988.0073
   MOVSHON JA, 1978, J PHYSIOL-LONDON, V283, P53, DOI 10.1113/jphysiol.1978.sp012488
   NELSON JI, 1978, BRAIN RES, V139, P359, DOI 10.1016/0006-8993(78)90937-X
   Polat U, 1996, VISION RES, V36, P2099, DOI 10.1016/0042-6989(95)00281-2
   Polat U, 1998, NATURE, V391, P580, DOI 10.1038/35372
   POLLEN DA, 1982, VISION RES, V22, P101, DOI 10.1016/0042-6989(82)90172-9
   PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910
   RIZZOLATTI G, 1975, BRAIN RES, V88, P357, DOI 10.1016/0006-8993(75)90399-6
   TANG Q, 2005, INT S NEUR NETW ISNN, P316
   Wilkinson MHF, 1998, GRAPH MODEL IM PROC, V60, P385, DOI 10.1006/gmip.1998.0478
   Xing J, 2001, VISION RES, V41, P571, DOI 10.1016/S0042-6989(00)00270-4
NR 33
TC 24
Z9 30
U1 0
U2 13
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1282
EP 1290
DI 10.1016/j.imavis.2006.08.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000009
DA 2024-07-18
ER

PT J
AU Sun, J
   Smith, M
   Smith, L
   Farooq, A
AF Sun, Jiuai
   Smith, Melvyn
   Smith, Lyndon
   Farooq, Abdul
TI Examining the uncertainty of the recovered surface normal in three light
   photometric stereo
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE photometric stereo; illumination configuration; uncertainty; surface
   normal
ID ERROR ANALYSIS
AB Although the three light photometric stereo technique has been used in many applications, there is little published work concerned with characterizing the uncertainty of these systems due to the involvement of a number of complicating factors. This paper presents a methodology used to analyze the uncertainty of the recovered unit surface normal with respect to irradiance variance. Illumination configurations and the values of the composite albedo are found to directly affect the stability of the photometric stereo technique. An orthogonally distributed illumination arrangement is proven to be the theoretically optimal configuration. Further practical considerations are also identified. The derived general uncertainty expression can be easily employed to optimize the location of the light sources. Hence, the work is of significance for the development of practical industrial applications of photometric stereo, including metrology, reverse engineering and various surface inspection tasks. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ W England, Machine Vis Lab, Fac CEMS, Bristol BS16 1QY, Avon, England.
C3 University of West England
RP Sun, J (corresponding author), Univ W England, Machine Vis Lab, Fac CEMS, Bristol BS16 1QY, Avon, England.
EM jiuai2.sun@uwe.ac.uk
RI Farooq, Abdul/JOZ-2265-2023
OI Smith, Melvyn/0000-0002-5307-8288
CR Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898
   BARSKY S, 2006, IN PRESS J MATH IMAG
   CHANTLER MJ, 1995, IEE P-VIS IMAGE SIGN, V142, P199, DOI 10.1049/ip-vis:19952065
   COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6
   Drbohlav O, 2005, IEEE I CONF COMP VIS, P1707
   FAROOQ AR, 2001, P 17 NAT C MAN RES N, P447
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Golub G.H., 1989, MATRIX COMPUTATIONS
   JIANG XY, 1991, SIGNAL PROCESS, V23, P221, DOI 10.1016/0165-1684(91)90001-Y
   KAY G, 1994, CVGIP-IMAG UNDERSTAN, V59, P183, DOI 10.1006/ciun.1994.1012
   LEE KM, 1993, J OPT SOC AM A, V10, P855, DOI 10.1364/JOSAA.10.000855
   RAY R, 1983, IEEE T PATTERN ANAL, V5, P631, DOI 10.1109/TPAMI.1983.4767454
   Rushmeier H., 1997, Rendering Techniques '97. Proceedings of the Eurographics Workshop. Eurographics, P35
   SCHLUNS K, 1997, P DIG IM VIS COMP DI, P539
   SMITH ML, 2000, SURFACE INSPECTION T
   Spence A. D., 2003, 3 INT WORKSH TEXT AN, P89
   Tsumura N, 2003, ELEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING - SYSTEMS, TECHNOLOGIES, APPLICATIONS, P77
   Woodham R. J., 1978, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.155. Image Understanding Systems and Industrial Applications, P136
   WU J, 2003, THESIS H WATT U
NR 19
TC 19
Z9 29
U1 2
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1073
EP 1079
DI 10.1016/j.imavis.2006.04.024
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300005
DA 2024-07-18
ER

PT J
AU Wang, HL
   Kwong, S
   Kok, CW
AF Wang, Hanli
   Kwong, Sam
   Kok, Chi-Wah
TI Efficient predictive model of zero quantized DCT coefficients for fast
   video encoding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE discrete cosine transform (DCT); quantization (Q); zero quantized DCT
   (ZQDCT) coefficients; video encoding
ID DISTRIBUTIONS
AB Discrete cosine transform (DCT), quantization (Q), inverse quantization (IQ) and inverse DCT (IDCT) are the building blocks in video coding standards adopted by ITU-T and MEPG. Under these standards, a lot of computations are required to perform the DCT, Q, IQ and IDCT operations. With this concern, a novel statistical model based on Gaussian distribution is proposed to predict zero quantized DCT (ZQDCT) coefficients in order to reduce the computational complexity of video encoding. Compared with other predictive models in the literature, the proposed model can detect more ZQDCT coefficients. Simulation results demonstrate that the proposed statistical model is superior to others in terms of speeding up video encoders. Moreover, a hybrid model is derived based on the proposed statistical model and mathematical analysis of individual DCT coefficients to further improve the encoding efficiency. (C) 2006 Elsevier B.V. All rights reserved.
C1 City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Kwong, S (corresponding author), City Univ Hong Kong, Dept Comp Sci, Hong Kong, Hong Kong, Peoples R China.
EM cssamk@cityu.edu.hk
RI Wang, Hanli/G-5111-2014; Kwong, Sam/C-9319-2012; Kok,
   C.W./AAM-6407-2020; Wang, Hanli/K-5717-2019
OI Wang, Hanli/0000-0002-9999-4871; Kwong, Sam/0000-0001-7484-7261; Wang,
   Hanli/0000-0002-9999-4871
CR BIRNEY KA, 1995, IEEE T IMAGE PROCESS, V4, P186, DOI 10.1109/83.342184
   Chen HT, 1996, IEEE T CONSUM ELECTR, V42, P781, DOI 10.1109/30.536185
   EGGERTON JD, 1986, COMPUT ELECTR ENG, V12, P137, DOI 10.1016/0045-7906(86)90005-4
   EUDE T, 1994, P IEEE INT C AC SPEE, V5, P365
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   JINDAL M, 2003, INT C INF COMM SIGN, V3, P483
   Kim GY, 2004, IEEE IMAGE PROC, P453
   Lam EY, 2000, IEEE T IMAGE PROCESS, V9, P1661, DOI 10.1109/83.869177
   Lam EY, 2004, IEEE SIGNAL PROC LET, V11, P97, DOI 10.1109/LSP.2003.821789
   Malvar HS, 2003, IEEE T CIRC SYST VID, V13, P598, DOI 10.1109/TCSVT.2003.814964
   MULLER F, 1993, ELECTRON LETT, V29, P1935, DOI 10.1049/el:19931288
   Pao IM, 1999, IEEE T CIRC SYST VID, V9, P608, DOI 10.1109/76.767126
   REININGER RC, 1983, IEEE T COMMUN, V31, P835, DOI 10.1109/TCOM.1983.1095893
   Smoot SR, 1996, P SOC PHOTO-OPT INS, V2657, P403, DOI 10.1117/12.238737
   Sousa LA, 2000, ELECTRON LETT, V36, P306, DOI 10.1049/el:20000272
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P547, DOI 10.1109/TCSVT.2006.871390
   Yovanof GS, 1997, CONF REC ASILOMAR C, P601, DOI 10.1109/ACSSC.1996.601095
   Yu A, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P21, DOI 10.1145/266180.266326
   YU A, 1997, P PICT COD S SEPT, P159
   Zhou X, 1998, ELECTRON LETT, V34, P1839, DOI 10.1049/el:19981308
NR 20
TC 10
Z9 13
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 922
EP 933
DI 10.1016/j.imavis.2006.07.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600014
DA 2024-07-18
ER

PT J
AU Xiao, GY
   Ong, SH
   Foong, KWC
AF Xiao, Gaoyu
   Ong, S. H.
   Foong, K. W. C.
TI 3D registration of partially overlapping surfaces using a volumetric
   approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D registration; partially overlapping surface; volumetric; Euclidean
   distance field
ID REPRESENTATION SCHEME; OBJECT RECOGNITION; SIGNATURES; IMAGES
AB A novel volumetric approach for the 3D registration of a generic crown and a complete tooth of the same tooth type is presented. Unlike most existing 3D partial surface registration methods, our algorithm does not require the two surfaces to be instances of the same object, only that they are of the same class (i.e., a group of similar objects). The Euclidean distance fields of the two surfaces are computed, and a set of distance vectors within these distance fields are used to generate a series of candidate transformations. By verifying the set of candidate parameters, the one resulting in the smallest registration error is chosen as the optimal solution. An additional advantage of our algorithm is that initial pose estimation is not required. Its effectiveness is confirmed by a series of experiments. (C) 2006 Elsevier B.V. All rights reserved.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
   Bioinformat Inst, Singapore 138671, Singapore.
   Natl Univ Singapore, Div Bioengn, Singapore 119260, Singapore.
   Natl Univ Singapore, Dept Preventat Dent, Singapore 119260, Singapore.
C3 National University of Singapore; Agency for Science Technology &
   Research (A*STAR); A*STAR - Bioinformatics Institute (BII); National
   University of Singapore; National University of Singapore
RP Ong, SH (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
EM eleongsh@nus.edu.sg
RI Ong, Sim-Heng/R-9244-2019; Foong, Kelvin Weng Chiong/M-6740-2018
OI Ong, Sim-Heng/0000-0003-2766-8150; Foong, Kelvin Weng
   Chiong/0000-0002-7458-2061
CR Barber CB, 1996, ACM T MATH SOFTWARE, V22, P469, DOI 10.1145/235815.235821
   Barequet G, 1997, VISUALIZATION '97 - PROCEEDINGS, P363, DOI 10.1109/VISUAL.1997.663904
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Chen CS, 1999, IEEE T PATTERN ANAL, V21, P1229, DOI 10.1109/34.809117
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   GEIGER D, 1995, IEEE T PATTERN ANAL, V17, P294, DOI 10.1109/34.368194
   Greenspan M, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P442, DOI 10.1109/IM.2003.1240280
   Guéziec A, 1998, VISUALIZATION '98, PROCEEDINGS, P383, DOI 10.1109/VISUAL.1998.745327
   HEBERT M, 1995, IEEE T PATTERN ANAL, V17, P681, DOI 10.1109/34.391410
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Kondo T, 2004, IEEE T MED IMAGING, V23, P350, DOI 10.1109/TMI.2004.824235
   Krsek P, 2002, COMPUT VIS IMAGE UND, V87, P27, DOI 10.1006/cviu.2002.0980
   LAMDAN HJ, 1988, P IEEE INT C COMP VI, P238
   Masuda T, 2002, COMPUT VIS IMAGE UND, V87, P51, DOI 10.1006/cviu.2002.0982
   MOK V, 2002, SPIE INT S MED IM, P955
   Mokhtarian F, 2001, IMAGE VISION COMPUT, V19, P271, DOI 10.1016/S0262-8856(00)00076-7
   Nooruddin FS, 2003, IEEE T VIS COMPUT GR, V9, P191, DOI 10.1109/TVCG.2003.1196006
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Petrakis EGM, 2002, IEEE T PATTERN ANAL, V24, P1501, DOI 10.1109/TPAMI.2002.1046166
   Ruiz-Correa S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1126
   SAITO T, 1994, PATTERN RECOGN, V27, P1551, DOI 10.1016/0031-3203(94)90133-3
   STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785
   Sun Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P263, DOI 10.1109/ICCV.2001.937634
   THIRION JP, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P587, DOI 10.1109/CVPR.1994.323795
   Tubic D, 2003, COMPUT VIS IMAGE UND, V92, P56, DOI 10.1016/j.cviu.2003.07.001
   Vranic DV, 2001, 2001 IEEE FOURTH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P293, DOI 10.1109/MMSP.2001.962749
   Xiao G, 2005, COMPUT VIS IMAGE UND, V98, P271, DOI 10.1016/j.cviu.2004.10.001
   Yamany SM, 2002, IEEE T PATTERN ANAL, V24, P1105, DOI 10.1109/TPAMI.2002.1023806
NR 30
TC 12
Z9 12
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 934
EP 944
DI 10.1016/j.imavis.2006.07.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600015
DA 2024-07-18
ER

PT J
AU Lo Bosco, G
AF Lo Bosco, Giosue
TI An integrated fuzzy cells-classifier
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE clustering; classification; classifier fusion; fuzzy sets; genetic
   algorithms; multiple classifiers
AB This paper introduces a genetic algorithm able to combine different classifiers based on different distance functions. The use of a genetic algorithm is motivated by the fact that the combination phase is based on the optimization of a vote strategy. The method has been applied to the classification of four types of biological cells, results show an improvement of the recognition rate using the genetic algorithm combination strategy compared with the recognition rate of each single classifier. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Palermo, Dipartimento Matemat & Applicaz, I-90123 Palermo, Italy.
C3 University of Palermo
RP Lo Bosco, G (corresponding author), Univ Palermo, Dipartimento Matemat & Applicaz, Via Archirafi 34, I-90123 Palermo, Italy.
EM lobosco@math.unipa.it
CR [Anonymous], 1996, GENETIC ALGORITHMS D, DOI DOI 10.1007/978-3-662-03315-9_4
   [Anonymous], 1987, PATTERN RECOGNITION
   BACKER E, 1981, IEEE T PATTERN ANAL, V3, P66, DOI 10.1109/TPAMI.1981.4767051
   CANNON RL, 1986, IEEE T GEOSCI REMOTE, V24, P400, DOI 10.1109/TGRS.1986.289598
   Di Gesú V, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P44, DOI 10.1109/ICIAP.2003.1234023
   Dietterich TG, 2000, LECT NOTES COMPUT SC, V1857, P1, DOI 10.1007/3-540-45014-9_1
   DIGESU V, 1994, FUZZY SET SYST, V68, P293, DOI 10.1016/0165-0114(94)90185-6
   DIGESU V, 1991, LECT NOTES MED INFOR, P534
   DIGESU V, 2002, VISUAL ATTENTION MEC
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Hall LO, 1999, IEEE T EVOLUT COMPUT, V3, P103, DOI 10.1109/4235.771164
   HASHEM S, 1997, NEURAL COMPUT, V10, P519
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Janikow C.Z., 1991, ICGA, V1991, P31
   JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181
   Kuncheva LI, 2000, IEEE T EVOLUT COMPUT, V4, P327, DOI 10.1109/4235.887233
   RUSPINI EH, 1969, INFORM CONTROL, V15, P22, DOI 10.1016/S0019-9958(69)90591-9
   Schapire RE, 1998, ANN STAT, V26, P1651
   Valentini G, 2002, LECT NOTES COMPUT SC, V2486, P3
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   YAGER RR, 1980, J CYBERNETICS, V10, P17
NR 21
TC 4
Z9 4
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 214
EP 219
DI 10.1016/j.imavis.2006.01.031
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700010
DA 2024-07-18
ER

PT J
AU Silva, L
   Bellon, ORP
   Boyer, KL
AF Silva, L.
   Bellon, O. R. P.
   Boyer, K. L.
TI Multiview range image registration using the surface interpenetration
   measure
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE range images; multiview registration; simulated annealing; genetic
   algorithms; robust methods; surface interpenetration measure
ID GENETIC ALGORITHMS; MODEL; VIEWS
AB This paper presents a new method for the precise registration of multiple range images with low pairwise overlap. The method is based in enhanced genetic algorithms (GAs). The proposed technique minimizes the alignment error within the common overlap area among a set of views, which is computed by a novel robust figure of merit called the surface interpenetration measure (SIM). The key idea behind this measure is the observation that mean squared error alone is insufficient to evaluate the quality of a registration solution because it fails to account for the spatial distribution of the error. The new measure explicitly forces the solution to distribute the errors across the overlap area, producing more stable, reliable solutions that limit propagation and amplification of error in the multiview problem. Our approach is not dependent on GAs as the search mechanism, but because they search in a space of transformations, GAs are capable of registering surfaces with no need for prealignment. The need for prealignment is a major weakness of methods based on the iterative closest point (ICP) algorithm, the most popular family of methods to date. The experimental results confirm that the new method ensures more precise global alignments than combined sequential pairwise alignments for registration. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Fed Parana, Ctr Politecn, Dept Informat, BR-81531 Curitiba, Parana, Brazil.
   Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
C3 Universidade Federal do Parana; University System of Ohio; Ohio State
   University
RP Silva, L (corresponding author), Univ Fed Parana, Ctr Politecn, Dept Informat, Jardim Amer Caixa Postal 19092, BR-81531 Curitiba, Parana, Brazil.
EM luciano@inf.ufpr.br; olga@inf.ufpr.br; kim@ece.osu.edu
RI Silva, Luciano/A-4812-2010; Bellon, Olga R P/E-6564-2011
OI Silva, Luciano/0000-0001-6341-1323; 
CR Alba E, 2002, IEEE T EVOLUT COMPUT, V6, P443, DOI 10.1109/TEVC.2002.800880
   Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   Bernardini F, 2002, IEEE COMPUT GRAPH, V22, P59, DOI 10.1109/38.974519
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574
   BRUNNSTROM K, 1996, P 13 INT C PATT REC, V4, P689
   Chen XF, 2003, J CENT SOUTH UNIV T, V10, P145, DOI 10.1007/s11771-003-0057-z
   Dalley G, 2002, COMPUT VIS IMAGE UND, V87, P104, DOI 10.1006/cviu.2002.0986
   Dorai C, 1998, IEEE T PATTERN ANAL, V20, P83, DOI 10.1109/34.655652
   Eggert DW, 1998, COMPUT VIS IMAGE UND, V69, P253, DOI 10.1006/cviu.1998.0667
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Gotardo PFU, 2003, PROC CVPR IEEE, P33
   GOTARDO PFU, 2004, IEEE T SYSTEMS MAN B
   Huber DF, 2003, PROC CVPR IEEE, P858
   Ikeuchi Katsushii., 2001, Modeling from Reality
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849
   Man KF, 1996, IEEE T IND ELECTRON, V43, P519, DOI 10.1109/41.538609
   Masuoka S., 1995, Journal of Sensory Studies, V10, P295, DOI 10.1111/j.1745-459X.1995.tb00021.x
   Renders JM, 1996, IEEE T SYST MAN CY B, V26, P243, DOI 10.1109/3477.485836
   Robertson C, 2002, COMPUT VIS IMAGE UND, V87, P39, DOI 10.1006/cviu.2002.0981
   Rodrigues M, 2002, COMPUT VIS IMAGE UND, V87, P1, DOI 10.1006/cviu.2002.0978
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Sagawa R, 2005, IEEE T PATTERN ANAL, V27, P392, DOI 10.1109/TPAMI.2005.46
   Sawai H, 1999, GECCO-99: PROCEEDINGS OF THE GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P579
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108
   SILVA L, 2003, P 10 IEEE INT C IM P, V2, P711
   SILVA L, 2003, P IEEE CVPR WORKSH A
   Stoddart A. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P40, DOI 10.1109/ICPR.1996.546720
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   TURK G, 1994, P SIGGRAPH, V2, P311
NR 32
TC 15
Z9 20
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 114
EP 125
DI 10.1016/j.imavis.2005.12.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600013
DA 2024-07-18
ER

PT J
AU Abate, AF
   Distasi, R
   Nappi, M
   Riccio, D
AF Abate, Andrea F.
   Distasi, Riccardo
   Nappi, Michele
   Riccio, Daniel
TI Face authentication using speed fractal technique
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face identification; fractals; biometry
ID RECOGNITION
AB In this paper, a new fractal based recognition method, Face Authentication using Speed Fractal Technique (FAST), is presented. The main contribution is the good compromise between memory requirements, execution time and recognition ratio. FAST is based on Iterated Function Systems (IFS) theory, largely studied in still image compression and indexing, but not yet widely used for face recognition. Indeed, Fractals are well known to be invariant to a large set of global transformations. FAST is robust with respect to meaningful variations in facial expression and to the small changes of illumination and pose. Another advantage of the FAST strategy consists in the speed up that it introduces. The typical slowness of fractal image compression is avoided by exploiting only the indexing phase, which requires time O(D log (D)), where D is the size of the domain pool. Lastly, the FAST algorithm compares well to a large set of other recognition methods, as underlined in the experimental results. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Salerno, Dipartimento Matemat & Informat, I-84084 Fisciano, SA, Italy.
C3 University of Salerno
RP Nappi, M (corresponding author), Univ Salerno, Dipartimento Matemat & Informat, I-84084 Fisciano, SA, Italy.
EM abate@unisa.it; ricdis@unisa.it; mnappi@unisa.it; driccio@unisa.it
RI Riccio, Daniel/JGM-4522-2023; Nappi, Michele/X-3089-2019
OI Riccio, Daniel/0000-0002-5844-0602; Abate, Andrea
   F./0000-0002-0472-0318; Nappi, Michele/0000-0002-2517-2867
CR [Anonymous], 1996, P 13 INT C PATT REC, DOI DOI 10.1109/ICPR.1996.546848
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], 1998, FACE RECOGNITION
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BOLME D, 2003, P INT C VIS SYST GRA, P304
   Distasi R, 2003, IEEE T IMAGE PROCESS, V12, P373, DOI 10.1109/TIP.2003.811041
   EBRAHIMPOURKOML.H, 2001, P INT C IM PROC, V3, P58
   GOROWARA KK, 1988, P IEEE NAT AER EL C, V2, P754
   Lee HJ, 2001, IEEE IMAGE PROC, P998, DOI 10.1109/ICIP.2001.959216
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   NAVARRETE P, 2002, LECT NOTES ARTIF INT, V2275, P178
   Okada K., 1998, FACE RECOGNITION, P186
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   RICCIO D, 2003, P 12 INT C IM AN PRO, V1, P412
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhang J, 1997, P IEEE, V85, P1423, DOI 10.1109/5.628712
NR 20
TC 5
Z9 7
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 977
EP 986
DI 10.1016/j.imavis.2006.02.023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200007
DA 2024-07-18
ER

PT J
AU Küblbeck, C
   Ernst, A
AF Kueblbeck, Christian
   Ernst, Andreas
TI Face detection and tracking in video sequences using the modified census
   transformation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face detection; face tracking; census transformation; Kalman filter;
   illumination invariance
AB We present the combination of an illumination invariant approach to face detection combined with a tracking mechanism used for improving speed and accuracy of the system. We introduce illumination invariant local structure features for object detection. For an efficient computation we propose a modified census transform, which enhances the original work of Zabih and Woodfill [19] [Ramin Zabih, John Woodfill. A non-parametric approach to visual correspondence. IEEE Transactions on Pattern Analysis and Machine Intelligence, 1996.]. The tracking is performed by means of continuous detection. We show that the advent of new rapid detection algorithms may change the need for traditional tracking. Furthermore the mentioned problems have a natural solution within the presented tracking by continuous detection approach. The only assumption on the object to track is its maximal speed in the image plane, which can be set very generously. From this assumption we derive three conditions for a valid state sequence in time. To estimate the optimal state of a tracked face from the detection results a Kalman filter is used. This leads to an instant smoothing of the face trajectory. It can be shown experimentally that smoothing the face trajectories leads to a significant reduction of false detections compared to the static detector without the presented tracking extension. We further show how to exploit the highly redundant information in a natural video sequence to speed-up the execution of the static detector by a temporal scanning procedure which we call, 'slicing'. A demo program showing the outcomes of our work can be found in the inter-net under http://www.iis.fraunhofer.de/bv/biometrie/ for download. (c) 2005 Elsevier B.V. All rights reserved.
C1 Fraunhofer Inst Integrated Circuits, Dept Elect Imaging, D-91058 Erlangen, Germany.
C3 Fraunhofer Gesellschaft
RP Küblbeck, C (corresponding author), Fraunhofer Inst Integrated Circuits, Dept Elect Imaging, D-91058 Erlangen, Germany.
EM christian.kueblbeck@iis.fraunhofer.de
CR [Anonymous], 7 EUR C COMP VIS ECC
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811
   DORNAIKA F, 2003, 12 INT C IM AN PROC
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P260, DOI 10.1109/AFGR.1998.670958
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Fröba B, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P342, DOI 10.1109/AFGR.2002.1004177
   FROBA B, 2004, INT C AUT FAC GEST R
   Gelb A., 1989, Applied Optimal Estimation
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Li S., 2002, P 7 EUR C COMP VIS
   McKenna S, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P271, DOI 10.1109/AFGR.1996.557276
   Osuna E., 1997, SUPPORT VECTOR MACHI
   ROWLEY HA, 1999, THESIS CARNEGIEMELLO
   SCHNEIDERMANN H, 1998, INT C COMP VIS PATT
   SUNG KK, 1996, THESIS MIT
   VIOLA P, 2001, P IEEE C COPM VIS PA
   Yang MH, 2000, ADV NEUR IN, V12, P862
   Zabih Ramin, 1996, PAMI
NR 19
TC 88
Z9 105
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2006
VL 24
IS 6
BP 564
EP 572
DI 10.1016/j.imavis.2005.08.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 061NB
UT WOS:000238878200003
DA 2024-07-18
ER

PT J
AU Chen, TD
AF Chen, TD
TI An affine-model-based technique for fast DPIV computation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE flow visualization; total optical flow computation; DPIV
ID VELOCIMETRY; FLOW
AB It proposes a non-correlation, conceptually new, fast and efficient approach for DPIV, which takes the nature of flow into consideration. An incompressible affined flow model (IAFM) is introduced to describe a flow that incorporates constraints on the computation. This IAFM, combined with a modified optical flow method-named total optical flow computation (TOFC), provides a linear system solution to DPIV. Experiments on real images showed our method to be a very promising approach for DPIV. (C) 2006 Elsevier B.V. All rights reserved.
C1 Zhejiang Gongshang Univ, Inst Commun & Informat Technol, Hangzhou 310035, Peoples R China.
C3 Zhejiang Gongshang University
RP Chen, TD (corresponding author), Zhejiang Gongshang Univ, Inst Commun & Informat Technol, Hangzhou 310035, Peoples R China.
EM chentianding@163.com
CR FORD RM, 1995, GRAPH MODEL IM PROC, V57, P462, DOI 10.1006/gmip.1995.1040
   Fujita I., 1995, J FLOW VISUALIZATION, V2, P173, DOI [10.1615/JFlowVisImageProc.v2.i2.60, DOI 10.1615/JFLOWVISIMAGEPROC.V2.I2.60]
   FUYUKI M, 1995, J FLOW VISUALIZATION, V2, P187
   HAORN BKP, 1986, ROBOT VISION
   HELMAN J, 1989, IEEE T COMPUT, V22, P112
   KAGA A, 1993, J FLOW VISUALIZATION, V1, P253
   KAWASHIMA G, 1995, J FLOW VISUALIZATION, V2, P335
   KIMURA I, 1993, J FLOW VISUALIZATION, V1, P261
   NOGAWA H, 1997, IEEE T PAMI, V19
   Ohba K., 1993, J FLOW VISUALIZATION, V1, P253
   Ohba K., 1995, Journal of Flow Visualization and Image Processing, V2, P161, DOI [10.1615/JFlowVisImageProc.v2.i2.50, DOI 10.1615/JFLOWVISIMAGEPROC.V2.I2.50]
   RAO AR, 1992, IEEE T PAMI, V14, P583
   SHU CF, 1993, CVGIP-IMAG UNDERSTAN, V58, P383, DOI 10.1006/ciun.1993.1049
   VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781
   WILLERT CE, 1991, EXP FLUIDS, V10, P181
   YAMAMOTO F, 1996, J FLOW VISUALIZATION, V3, P65
   ZHANG J, 1994, CVPR 94, P310
NR 17
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 407
EP 410
DI 10.1016/j.imavis.2005.12.014
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600001
DA 2024-07-18
ER

PT J
AU Yun, EK
   Cho, SB
AF Yun, EK
   Cho, SB
TI Adaptive fingerprint image enhancement with fingerprint image quality
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE biometrics; fingerprint identification; fingerprint image quality; image
   enhancement; clustering
AB Accurate minutiae extraction from fingerprint images is heavily dependent on the quality of the fingerprint images. In order to improve the performance of the system, much effort has been made on the image enhancement algorithms. If the preprocessing is adaptive to the fingerprint image characteristics in the image enhancement step, the performance gets to be more robust. In this paper, we propose an adaptive preprocessing method, which extracts five features from the fingerprint images, analyzes image quality with clustering method, and enhances the images according to their characteristics. Experimental results indicate that the proposed method improves the performance of the fingerprint identification significantly. (C) 2005 Elsevier B.V. All rights reserved.
C1 Yonsei Univ, Dept Comp Sci, Biometr Engn Res Ctr, Seoul 120749, South Korea.
C3 Yonsei University
RP Yonsei Univ, Dept Comp Sci, Biometr Engn Res Ctr, 134 Shinchon Dong, Seoul 120749, South Korea.
EM ekfree@sclab.yonsei.ac.kr; sbcho@cs.yonsei.ac.kr
CR [Anonymous], FINGER PRINTS
   [Anonymous], 1992, NIST Special Database 4, NIST 8-bit Gray Scale Images of Fingerprint Image Groups (FIGS)
   BOLLE, 1999, Patent No. 596356
   Halici U, 1999, INT SER COMPUTAT INT, P1
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Ikeda N, 2002, INT C PATT RECOG, P752, DOI 10.1109/ICPR.2002.1048099
   JAIN AK, 2001, 3 INT C AUD VID BAS, P182
   Kang H, 2003, LECT NOTES COMPUT SC, V2688, P574
   Karu K, 1996, PATTERN RECOGN, V29, P389, DOI 10.1016/0031-3203(95)00106-9
   Lee H.C., 2001, Advances in Fingerprint Technology
   Lim E, 2002, IEEE IMAGE PROC, P469
   MILLIGAN GW, 1985, PSYCHOMETRIKA, V50, P159, DOI 10.1007/BF02294245
   MOJENA R, 1977, COMPUT J, V20, P359, DOI 10.1093/comjnl/20.4.359
   Rao A., 1990, TAXONOMY TEXTURE DES
   Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800
   RATHA NK, 1999, 21622 IBM RC
   Shen L.L., 2001, 3 INT C AVBPA 2001 J, P182
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
NR 18
TC 49
Z9 58
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 101
EP 110
DI 10.1016/j.imavis.2005.09.017
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200010
DA 2024-07-18
ER

PT J
AU Smith, ML
   Smith, LN
AF Smith, ML
   Smith, LN
TI Dynamic photometric stereo - a new technique for moving surface analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE dynamic photometric stereo; virtual point light source; narrow infrared
   photometric stereo
ID 3-DIMENSIONAL SHAPE; COLOR
AB This paper describes a novel approach for two- and three-dimensional surface data capture from moving surfaces based upon an evolution of the existing photometric stereo (PS) technique. Limitations in current methods are described, together with the potential benefits of applying PS and the particular need for a new dynamic form of the method. Important issues relating to conventional idealised PS model assumptions are considered in the context of realising useful practical application, including in particular the modelling of real illuminates. Several possible techniques for achieving dynamic PS are considered and a new technique termed narrow infrared photometric stereo (NIRPS) introduced. New potential application areas range from the continuous inspection of fast moving surfaces typically encountered in numerous industrial processes to three-dimensional surface topographic texture acquisition in the field using portable hand-held technology. A selection of experimental results is presented in the paper. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ W England, Fac Comp Engn & Math Sci, Machine Vis Lab, Bristol BS16 1QY, Avon, England.
C3 University of West England
RP Univ W England, Fac Comp Engn & Math Sci, Machine Vis Lab, DuPont Bldg,Frenchay Campus, Bristol BS16 1QY, Avon, England.
EM melvyn.smith@uwe.ac.uk
OI Smith, Melvyn/0000-0002-5307-8288
CR BAKSHI S, 1994, IEEE IMAGE PROC, P130, DOI 10.1109/ICIP.1994.413545
   Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898
   Barsky S, 2001, P SOC PHOTO-OPT INS, V4553, P10, DOI 10.1117/12.441595
   CHRISTENSEN PH, 1994, INT J COMPUT VISION, V13, P213, DOI 10.1007/BF01427152
   COLEMAN EN, 1982, COMPUT VISION GRAPH, V18, P309, DOI 10.1016/0146-664X(82)90001-6
   DETLEF P, 1999, Patent No. 0898163
   Drew MS, 2000, J OPT SOC AM A, V17, P1371, DOI 10.1364/JOSAA.17.001371
   DREW MS, 1992, 9207 LCCR TR S FRAS
   HORN BKP, 1989, 1105 MIT AI
   Mahdavieh Y., 1985, Proceedings of the 5th International Conference on Robot Vision and Sensory Controls - RoViSeC 5, P105
   MAHDAVIEH Y, 1984, THESIS U MANCHESTER
   PENTLAND AP, 1994, IEEE T PATTERN ANAL, V6
   SMITH M, 2003, MACHINING NATURAL ST
   SMITH ML, 2000, SENSOR REV, V20
   SMITH ML, 2004, COMPLEMENTARY TECHNO
   SMITH ML, 1999, IMAGE VISION COMPUTI, V17
   SMITH ML, 2000, SURFACE INSPECTION T
   SMITH ML, 2001, Patent No. 03012412
   Smithwick QYJ, 2002, P SOC PHOTO-OPT INS, V4613, P222, DOI 10.1117/12.465249
   Tian YL, 1997, J OPT SOC AM A, V14, P397, DOI 10.1364/JOSAA.14.000397
   TIMO P, 2000, Patent No. 1030173
   WOODHAM R, 1978, 479 MIT AI LAB
   YASUSHI T, 2001, 08016 IPSJ SIG
NR 23
TC 19
Z9 24
U1 1
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2005
VL 23
IS 9
BP 841
EP 852
DI 10.1016/j.imavis.2005.01.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VF
UT WOS:000231400700008
DA 2024-07-18
ER

PT J
AU Yuan, XJ
   Zhang, J
   Yuan, XH
   Buckles, BP
AF Yuan, XJ
   Zhang, J
   Yuan, XH
   Buckles, BP
TI Multi-scale feature identification using evolution strategies
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE feature identification; evolution strategies; Gabor filter bank
ID SEGMENTATION
AB An image usually contains a number of different features and regions. Many image-related applications, such as content-based image retrieval and MRI-based diagnosis, often require the ability to identify and mark features within the image. For images containing a specific sort of feature (e.g. convective storm) or region (e.g. earthquake debris), that feature or region is always located adjacent to other features and regions on the image.
   A generic framework for automatically identifying features in images based on evolutionary computation is proposed here. The significant characteristic of the method is that it does not require segmentation. We use evolution strategies as the optimization algorithm to identify features. The system is based on a conjecture that certain filters will give prominent responses to certain features. The identified features are represented as regions enclosed within the chosen search structure-the ellipse. By defining filter response criteria as the fitness function, evolution strategies succeeds in finding the feature in a Much more efficient way than, say, segmentation. (c) 2004 Elsevier B.V. All rights reserved.
C1 Tulane Univ, Dept Elect Engn & Comp Sci, New Orleans, LA 70118 USA.
   Tulane Univ, Dept Engn Mech, New Orleans, LA 70118 USA.
C3 Tulane University; Tulane University
RP Tulane Univ, Dept Elect Engn & Comp Sci, New Orleans, LA 70118 USA.
EM zhangj@eecs.tulane.edu
RI Yuan, Xiaohui/AAQ-1172-2020
OI Yuan, Xiaojing/0000-0001-9252-7552; Buckles, Bill/0000-0002-3385-9933;
   Yuan, Xiaohui/0000-0001-6897-4563
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   ANKENBRANDT CA, 1990, PATTERN RECOGN LETT, V11, P285, DOI 10.1016/0167-8655(90)90067-C
   [Anonymous], 1999, P 7 IEEE INTL C COMP
   [Anonymous], 1995, Evolution and Optimum Seeking, Sixth-Generation Computer Technology Series
   Back T., 1995, Evolutionary Algorithms in Theory and Practice: Evolution Strategies, Evolutionary Programming, Genetic Algorithms: Evolution Strategies, Evolutionary Programming, Genetic Algorithms
   BUCKLES BP, 1998, P JCIS 98 2 INT WORK, V2, P395
   Carson C, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P42, DOI 10.1109/IVL.1997.629719
   CHALERMWAT P, 1999, THESIS G MASON U
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DUNN D, 1995, IEEE T IMAGE PROCESS, V4, P947, DOI 10.1109/83.392336
   DUNN D, 1994, IEEE T PATTERN ANAL, V16, P130, DOI 10.1109/34.273736
   FORSYTH DA, 1996, P INT WORKSH OBJ REP, V2, P335
   HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5
   HOWE N, 1998, IEEE WORKSH CONT BAS
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kruizinga P., 1999, Proceedings 10th International Conference on Image Analysis and Processing, P142, DOI 10.1109/ICIAP.1999.797585
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   Ozcan E, 1997, PATTERN RECOGN LETT, V18, P987, DOI 10.1016/S0167-8655(97)00123-2
   Pauwels EJ, 1999, COMPUT VIS IMAGE UND, V75, P73, DOI 10.1006/cviu.1999.0763
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Shah S, 1997, PROC CVPR IEEE, P1014, DOI 10.1109/CVPR.1997.609454
   Singh M, 1997, ASIAN J CHEM, V9, P1
   UNSER M, 1990, IEEE T SYST MAN CYB, V20, P804, DOI 10.1109/21.105080
   YUE L, 1997, P 1997 INT C IM PROC, V3
NR 24
TC 13
Z9 17
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2005
VL 23
IS 6
BP 555
EP 563
DI 10.1016/j.imavis.2004.07.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 924CA
UT WOS:000228955100001
DA 2024-07-18
ER

PT J
AU Bloch, I
AF Bloch, I
TI Fuzzy spatial relationships for image processing and interpretation: a
   review
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE fuzzy spatial relationships; degree of intersection; degree of
   inclusion; degree of adjacency; distances; directional relative
   position; structural pattern recognition; image interpretation; spatial
   reasoning
ID HAUSDORFF-LIKE METRICS; RELATIVE POSITION; SIMILARITY MEASURES;
   DISTANCES; OBJECTS; SETS; RECOGNITION; REPRESENTATION; DEFINITION;
   INFERENCE
AB In spatial reasoning, relationships between spatial entities play a major role. In image interpretation, computer vision and structural recognition, the management of imperfect information and of imprecision constitutes a key point. This calls for the framework of fuzzy sets, which exhibits nice features to represent spatial imprecision at different levels, imprecision in knowledge and knowledge representation, and which provides powerful tools for fusion, decision-making and reasoning. In this paper, we review the main fuzzy approaches for defining spatial relationships including topological (set relationships, adjacency) and metrical relations (distances, directional relative position). (C) 2004 Elsevier B.V. All rights reserved.
C1 LTCI, CNRS, UMR 5141, Ecole Natl Super Telecommun,Dept TSI, F-75013 Paris, France.
C3 Centre National de la Recherche Scientifique (CNRS); IMT - Institut
   Mines-Telecom; Institut Polytechnique de Paris; Telecom Paris
RP LTCI, CNRS, UMR 5141, Ecole Natl Super Telecommun,Dept TSI, 46 Rue Barrault, F-75013 Paris, France.
EM isabelle.bloch@enst.fr
CR [Anonymous], 1978, Cogn. Sci, DOI [DOI 10.1207/S15516709COG0202_3, DOI 10.1207/S15516709COG02023, 10.1016/S0364-0213(78)80003-2]
   [Anonymous], 1979, Advances in Fuzzy Set Theory and Applications, DOI DOI 10.1142/9789814261302_0022
   BANDLER W, 1980, FUZZY SET SYST, V4, P13, DOI 10.1016/0165-0114(80)90060-3
   Bengoetxea E, 2002, PATTERN RECOGN, V35, P2867, DOI 10.1016/S0031-3203(01)00232-1
   BENOIT E, 1993, APPL ENSEMBLES FLOUS, P167
   BHANDARI D, 1992, PATTERN RECOGN LETT, V13, P857, DOI 10.1016/0167-8655(92)90085-E
   BINAGHI E, 1993, INT J INTELL SYST, V8, P749, DOI 10.1002/int.4550080702
   Bloch I, 1999, IEEE T PATTERN ANAL, V21, P657, DOI 10.1109/34.777378
   Bloch I, 2003, ADV IMAG ELECT PHYS, V128, P51, DOI 10.1016/S1076-5670(03)80063-0
   Bloch I, 2003, LECT NOTES COMPUT SC, V2886, P16
   BLOCH I, 1995, PATTERN RECOGN, V28, P1341, DOI 10.1016/0031-3203(94)00312-A
   Bloch I, 2003, PATTERN RECOGN, V36, P1563, DOI 10.1016/S0031-3203(02)00263-7
   Bloch I, 2003, ARTIF INTELL, V148, P141, DOI 10.1016/S0004-3702(03)00018-3
   Bloch I, 1999, INT J UNCERTAIN FUZZ, V7, P99, DOI 10.1142/S0218488599000088
   Bloch I, 1997, INT J UNCERTAIN FUZZ, V5, P615, DOI 10.1142/S0218488597000476
   Bloch I, 1999, PATTERN RECOGN, V32, P1873, DOI 10.1016/S0031-3203(99)00011-4
   BLOCH I, 1993, PATTERN RECOGN, V3, P137
   BLOCH I, 2000, 7 INT C PRINC KNOWL, P247
   BLOCH I, 1996, IEEE INT C IM PROC I, V2, P987
   BLOCH I, 1996, INFORMATION PROCESSI, P1307
   BLOCH I, 2002, J APPL NONCLASSICAL, V12, P399, DOI DOI 10.3166/JANCL.12.399-423
   BOUCHONMEUNIER B, 1993, SECOND IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2, P1225, DOI 10.1109/FUZZY.1993.327567
   BouchonMeunier B, 1996, FUZZY SET SYST, V84, P143, DOI 10.1016/0165-0114(96)00067-X
   Boxer L, 1997, PATTERN RECOGN LETT, V18, P115, DOI 10.1016/S0167-8655(97)00006-8
   Brass P, 2002, PATTERN RECOGN LETT, V23, P39, DOI 10.1016/S0167-8655(01)00117-9
   CAYROL M, 1982, KYBERNETES, V11, P103, DOI 10.1108/eb005612
   Cesar R, 2002, INT C PATT RECOG, P465, DOI 10.1109/ICPR.2002.1048339
   Chaudhuri BB, 1996, PATTERN RECOGN LETT, V17, P1157, DOI 10.1016/0167-8655(96)00077-3
   CHEN SM, 1995, FUZZY SET SYST, V72, P79, DOI 10.1016/0165-0114(94)00284-E
   Colliot O, 2004, FUZZY SET SYST, V147, P141, DOI 10.1016/j.fss.2003.07.003
   COLLIOT O, 2002, INFORMATION PROCESSI, V3, P1749
   Cortelazzo G, 1996, PATTERN RECOGN LETT, V17, P431, DOI 10.1016/0167-8655(95)00123-9
   CROSS V, 1995, ISUMA NAFIPS 95, P169
   De Luca A., 1972, Inf. Control, V20, P301, DOI [10.1016/S0019-9958(72)90199-4, DOI 10.1016/S0019-9958(72)90199-4]
   DEBARROS LC, 1997, 7 IFSA WORLD C PRAG, V2, P3
   DEMKO C, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P1665, DOI 10.1109/FUZZY.1995.409900
   DUBOIS D, 1988, FUZZY SET SYST, V28, P313, DOI 10.1016/0165-0114(88)90038-3
   DUBOIS D, 1991, FUZZY SET SYST, V40, P143, DOI 10.1016/0165-0114(91)90050-Z
   DUBOIS D, 1987, PATTERN RECOGN LETT, V6, P251, DOI 10.1016/0167-8655(87)90085-7
   DUBOIS D, 1992, DATA FUSION ROBOTICS
   Dubois D, 1980, Fuzzy sets and systems
   DUBOIS D, 1983, INT C SYST MAN CYB, P300
   Fan JL, 1998, PATTERN RECOGN LETT, V19, P793, DOI 10.1016/S0167-8655(98)00059-2
   Freeman J., 1975, Computer graphics and image processing, V4, P156, DOI DOI 10.1016/S0146-664X(75)80007-4
   Gerla G, 1998, INFORM SCIENCES, V106, P49, DOI 10.1016/S0020-0255(97)10003-2
   GOGUEN JA, 1969, SYNTHESE, V19, P325, DOI 10.1007/BF00485654
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   ISHIZUKA M, 1983, NEW GENERAT COMPUT, V1, P159, DOI 10.1007/BF03037422
   JAIN R, 1995, PROCEEDINGS OF 1995 IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I-IV, P1247, DOI [10.1109/FUZZY.1995.409843, 10.1117/12.205318]
   JAULENT MC, 1994, IPMU, P904
   KAUFMAN A, 1973, INTRO THEORY FUZZY S
   Kaufmann A., 1975, INTRO THEORY FUZZY S
   KELLER JM, 1995, ISUMA NAFIPS 95, P679
   KITAMOTO A, 1995, 9 SCAND C IM AN UPPS, P449
   KOCZY LT, 1988, PATTERN RECOGN LETT, V8, P21, DOI 10.1016/0167-8655(88)90019-0
   KOSKO B, 1990, INT J GEN SYST, V17, P211, DOI 10.1080/03081079008935108
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P222, DOI 10.1109/91.236554
   KUIPERS BJ, 1988, AI MAG, V9, P25
   Lowen R, 1998, FUZZY SET SYST, V99, P135, DOI 10.1016/S0165-0114(96)00399-5
   MAHER PE, 1993, INT J INTELL SYST, V8, P819, DOI 10.1002/int.4550080802
   MAN GT, 1993, 2 IEEE INT C FUZZ SY, P570
   Masson M, 2002, FUZZY SET SYST, V128, P339, DOI 10.1016/S0165-0114(01)00162-2
   Matsakis P, 1999, IEEE T PATTERN ANAL, V21, P634, DOI 10.1109/34.777374
   MIYAJIMA K, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P100, DOI 10.1109/FUZZY.1994.343710
   MIYAJIMA K, 1994, FUZZY SET SYST, V65, P225, DOI 10.1016/0165-0114(94)90021-3
   PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4
   Perchant A, 2002, FUZZY SET SYST, V128, P149, DOI 10.1016/S0165-0114(01)00131-2
   PUN ML, 1983, J MATH ANAL APPL, V91, P552
   ROSENFELD A, 1984, PATTERN RECOGN LETT, V2, P311, DOI 10.1016/0167-8655(84)90018-7
   ROSENFELD A, 1985, PATTERN RECOGN LETT, V3, P229, DOI 10.1016/0167-8655(85)90002-9
   ROSENFELD A, 1985, PATTERN RECOGN, V18, P169, DOI 10.1016/0031-3203(85)90041-X
   Serra J., 1982, IMAGE ANAL MATH MORP
   SINHA D, 1993, FUZZY SET SYST, V55, P15, DOI 10.1016/0165-0114(93)90299-W
   SOKIC C, 1997, 7 IFSA WORLD C PRAG, V4, P297
   Sridharan K, 1999, FUZZY SET SYST, V103, P427, DOI 10.1016/S0165-0114(97)00188-7
   TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750
   Udupa JK, 1996, GRAPH MODEL IM PROC, V58, P246, DOI 10.1006/gmip.1996.0021
   WALKER EL, 1996, FUZZY RELATIONS FEAT, P28
   Wang WJ, 1997, FUZZY SET SYST, V85, P305, DOI 10.1016/0165-0114(95)00365-7
   WANG XZ, 1995, FUZZY SET SYST, V73, P259, DOI 10.1016/0165-0114(94)00308-T
   WILLMOTT R, 1980, FUZZY SET SYST, V4, P31, DOI 10.1016/0165-0114(80)90061-5
   YAGER RR, 1992, INT J GEN SYST, V20, P341, DOI 10.1080/03081079208945039
   Young VR, 1996, FUZZY SET SYST, V77, P371, DOI 10.1016/0165-0114(95)00045-3
   ZABRODSKY H, 1995, IEEE T PATTERN ANAL, V17, P1154, DOI 10.1109/34.476508
   Zadeh L. A., 1978, Fuzzy Sets and Systems, V1, P3, DOI 10.1016/0165-0114(78)90029-5
   ZADEH LA, 1975, INFORM SCIENCES, V8, P199, DOI 10.1016/0020-0255(75)90046-8
   Zwick R., 1987, International Journal of Approximate Reasoning, V1, P221, DOI 10.1016/0888-613X(87)90015-6
NR 87
TC 137
Z9 149
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 89
EP 110
DI 10.1016/j.imavis.2004.06.013
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800002
DA 2024-07-18
ER

PT J
AU Joshi, MV
   Chaudhuri, S
   Panuganti, R
AF Joshi, MV
   Chaudhuri, S
   Panuganti, R
TI Super-resolution imaging: use of zoom as a cue
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Indian Conference on Vision, Graphics and Image Processing (ICVGIP)
CY DEC 16-18, 2002
CL Ahmedabad, INDIA
DE super-resolution; zooming; Markov random field; MAP estimation; mean
   correction
ID EFFICIENT SUPERRESOLUTION; RESOLUTION; RECONSTRUCTION; RESTORATION;
   VIDEO; RECOVERY; SEQUENCE; IMAGES; DEPTH
AB In this paper, we propose a novel technique for super-resolution imaging of a scene from observations at different zoom levels. Given a sequence of images with different zoom factors of a static scene, the problem is to obtain a picture of the entire scene at a resolution corresponding to the most zoomed image in the scene. We not only obtain the super-resolved image for known integer zoom factors, but also for unknown arbitrary zoom factors. We model the super-resolution image as a Markov random field (MRF) and a maximum a posteriori (MAP) estimation method is used to derive a cost function which is then optimized to recover the high-resolution field. The entire observation conforms to the same MRF, but is viewed at the different resolution pyramid. Since there is no relative motion between the scene and the camera, as is the case with most of the super-resolution techniques, we do away with the correspondence problem. Results of the experimentation on real data are presented. (C) 2004 Published by Elsevier B.V.
C1 Indian Inst Technol, Dept Elect Engn, Bombay 400076, Maharashtra, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bombay
RP Indian Inst Technol, Dept Elect Engn, Bombay 400076, Maharashtra, India.
EM mvjoshi@ee.iitb.ac.in; sc@ee.iitb.ac.in; rajkiran@ee.iitb.ac.in
CR AIZAWA K, 1992, P IEEE INT C AC SPEE, P289
   Altunbasak Y, 2002, IEEE T CIRC SYST VID, V12, P217, DOI 10.1109/76.999200
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   BROWN JL, 1981, IEEE T CIRCUITS SYST, V28, P101, DOI 10.1109/TCS.1981.1084954
   Capel D, 2001, PROC CVPR IEEE, P627
   Capel D, 1998, PROC CVPR IEEE, P885, DOI 10.1109/CVPR.1998.698709
   Chaudhuri S., 2001, SUPER RESOLUTION IMA
   Chiang MC, 1997, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.1997.609422
   Chiang MC, 2000, IMAGE VISION COMPUT, V18, P761, DOI 10.1016/S0262-8856(99)00044-X
   Chiang MC, 1996, IMAGE UNDERSTANDING WORKSHOP, 1996 PROCEEDINGS, VOLS I AND II, P843
   DELHERM C, 1996, 4 EUR C COMP VIS CAM, P427
   Dubes R.C., 1989, J APPL STAT, V16, P131, DOI DOI 10.1080/02664768900000014
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Elad M, 1999, IEEE T IMAGE PROCESS, V8, P387, DOI 10.1109/83.748893
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   FAYMAN JA, 1997, CIS9717 TR
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GERSWE DR, 1998, J OPT SOC AM, V15, P2620
   Hardie RC, 1997, IEEE T IMAGE PROCESS, V6, P1621, DOI 10.1109/83.650116
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Irani M., 1993, Journal of Visual Communication and Image Representation, V4, P324, DOI 10.1006/jvci.1993.1030
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   JOSHI MV, 2002, INDIAN C COMPUT VIS
   Kaulgud N., 2002, PROC 8 NATL C COMMUN, P120
   Kim SP, 1993, IEEE T IMAGE PROCESS, V2, P534, DOI 10.1109/83.242363
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   KOMATSU T, 1993, P IEEE, V1, P19
   LAVEST JM, 1993, IEEE T ROBOTIC AUTOM, V9, P196, DOI 10.1109/70.238283
   MA J, 1990, J OPT SOC AM A, V7, P1883, DOI 10.1364/JOSAA.7.001883
   Ng MK, 2002, INT J IMAG SYST TECH, V12, P35, DOI 10.1002/ima.10004
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P1299, DOI 10.1109/83.941854
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   PAPOULIS A, 1977, IEEE T CIRCUITS SYST, V24, P652, DOI 10.1109/TCS.1977.1084284
   Patti AJ, 1997, IEEE T IMAGE PROCESS, V6, P1064, DOI 10.1109/83.605404
   PELEG S, 1987, PATTERN RECOGN LETT, V5, P223, DOI 10.1016/0167-8655(87)90067-5
   Rajagopalan AN, 1998, INT J COMPUT VISION, V30, P175, DOI 10.1023/A:1008019215914
   Rajan D, 2003, IEEE SIGNAL PROC MAG, V20, P49, DOI 10.1109/MSP.2003.1203209
   Rajan D, 2001, SPRING INT SER ENG C, V632, P45
   Rajan D, 2002, J MATH IMAGING VIS, V16, P5, DOI 10.1023/A:1013961817285
   Rajan D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P113, DOI 10.1109/ICCV.2001.937506
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Segall CA, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P25, DOI 10.1109/ICIP.2001.958415
   Shechtman E, 2002, LECT NOTES COMPUT SC, V2350, P753
   Shekarforoush H, 1996, INT J COMPUT VISION, V19, P289, DOI 10.1007/BF00055148
   Shekarforoush H, 1999, J OPT SOC AM A, V16, P481, DOI 10.1364/JOSAA.16.000481
   SRINIVAS C, 1990, SPIE, V1360, P1416
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Tekalp A., 1992, PROC IEEE INT CONF A, V3, P169
   UR H, 1992, MODELS IMAGE PROCESS, V54, P181
   WILKES D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P938
   Wilson R.G., 1994, MODELING CALIBRATION
   WILSON RG, 1993, CMUCS93122
NR 55
TC 31
Z9 39
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2004
VL 22
IS 14
BP 1185
EP 1196
DI 10.1016/j.imavis.2004.03.025
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 882LG
UT WOS:000225939800005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ning, HZ
   Tan, TN
   Wang, L
   Hu, WM
AF Ning, HZ
   Tan, TN
   Wang, L
   Hu, WM
TI Kinematics-based tracking of human walking in monocular video sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE kinematics-based tracking; gait recognition; human model
ID GAIT RECOGNITION; MODELS
AB Human tracking is currently one of the most active research topics in computer vision. This paper proposed a kinematics-based approach to recovering motion parameters of people walking from monocular video sequences using robust image matching and hierarchical search. Tracking a human with unconstrained movements in monocular image sequences is extremely challenging. To reduce the search space, we design a hierarchical search strategy in a divide-and-conquer fashion according to the tree-like structure of the human body model. Then a kinematics-based algorithm is proposed to recursively refine the joint angles. To measure the matching error, we present a pose evaluation function combining both boundary and region information. We also address the issue of initialization by matching the first frame to six key poses acquired by clustering and the pose having minimal matching error is chosen as the initial pose. Experimental results in both indoor and outdoor scenes demonstrate that our approach performs well. (C) 2004 Published by Elsevier B.V.
C1 Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Zhongguancun E Rd 95, Beijing 100080, Peoples R China.
EM hzning@nlpr.ia.ac.cn; tnt@nlpr.ia.ac.cn; lwang@nlpr.ia.ac.cn;
   wmhu@nlpr.ia.ac.cn
RI Huang, Yan/HCH-6526-2022
OI Huang, Yan/0000-0002-8239-7229; Wang, Yunlong/0000-0002-3535-308X
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], P EUR C COMP VIS
   [Anonymous], P 5 AS C COMP VIS
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   Cheng JC, 1999, IEEE T MULTIMEDIA, V1, P144, DOI 10.1109/6046.766736
   COMANICIU D, 2000, P INT C COMP VIS PAT
   Delamarre Q, 2001, COMPUT VIS IMAGE UND, V81, P328, DOI 10.1006/cviu.2000.0892
   DELAMARRE Q, P 7 INT C COMP VIS I
   FOSTER J, 2001, P 3 INT C AUD VID BA, P312
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056
   HAYFRONACQUAH JB, 2001, P 3 INT C AUD VID BA, P272
   Hogg D., 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3
   HUANG Y, 2002, P INT C PATT REC
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jang DS, 2000, PATTERN RECOGN, V33, P1135, DOI 10.1016/S0031-3203(99)00100-4
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kepp, 2000, P 4 IEEE SW S IM AN, P291, DOI DOI 10.1109/IAI.2000.839618
   LEE HJ, 1985, COMPUT VISION GRAPH, V30, P148, DOI 10.1016/0734-189X(85)90094-5
   LEE L, 2002, ECCV WORKSH BIOM AUT
   LERASLE F, 1996, P 4 EUR C COMP VIS, P518
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Mori G., 2002, P EUR C COMP VIS
   NIAG H, 2002, 4 IEEE INT C MULT IN
   NING H, 2002, 17 IEEE REG 10 TECHN
   PLANKERS R, 2001, P 9 INT C COMP VIS I
   Segen J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P63, DOI 10.1109/ICPR.1996.546795
   SMINCHISESCU C, 2001, P INT C COMP VIS PAT
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   TOYAMA K, 2001, P INT C COMP VIS
   Wachter S, 1999, COMPUT VIS IMAGE UND, V74, P174, DOI 10.1006/cviu.1999.0758
   Wang L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1449, DOI 10.1109/ICCV.2003.1238660
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   YANG YH, 1992, MACH VISION APPL, V5, P17
   ZHAO T, 2002, P 5 AS C COMP VIS AC
NR 39
TC 51
Z9 65
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2004
VL 22
IS 5
BP 429
EP 441
DI 10.1016/j.imavis.2004.01.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 806GN
UT WOS:000220422500007
DA 2024-07-18
ER

PT J
AU Ellinas, JN
   Sangriotis, MS
AF Ellinas, JN
   Sangriotis, MS
TI Stereo image compression using wavelet coefficients morphology
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereo image compression; wavelet transform; morphology; disparity
AB In this paper, we propose a new stereo image compression scheme that is based on the wavelet transform of both images and the disparity estimation between the stereo pair subbands. The two images are decomposed by using a Discrete Wavelet Transform (DWT) and coded by employing the morphological representation of the wavelet coefficients, which is a technique that exploits the intraband-interband statistical properties of them. The progressive pixel-to-pixel evaluation of the disparity has been incorporated to the morphological coder so that a dense disparity field to be formed for every subband. The proposed method demonstrates very good performance as far as PSNR measures and visual quality are concerned and low complexity. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Athens, Dept Informat & Telecommun, Athens 15784, Greece.
C3 National & Kapodistrian University of Athens
RP Univ Athens, Dept Informat & Telecommun, Panepistimiopolis,Ilissia, Athens 15784, Greece.
EM sagri@di.uoa.gr
CR Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Aydinoglu H, 1998, IEEE T IMAGE PROCESS, V7, P506, DOI 10.1109/83.663495
   Boulgouris NV, 2002, IEEE T CIRC SYST VID, V12, P898, DOI 10.1109/TCSVT.2002.804895
   BOULGOURIS NV, 2000, ICIP, V3, P640
   Chai BB, 1999, IEEE T IMAGE PROCESS, V8, P774, DOI 10.1109/83.766856
   Frajka T, 2003, OPT ENG, V42, P182, DOI 10.1117/1.1526492
   Frajka Tamas, 2002, ICIP
   Jiang JM, 2002, IEEE T IMAGE PROCESS, V11, P123, DOI 10.1109/83.982820
   LUCAS B, 1981, P INT JOINT C ART IN, V1, P674
   LUKACS ME, 1986, P IEEE ICASSP 86, P521
   PERKINS MG, 1992, IEEE T COMMUN, V40, P684, DOI 10.1109/26.141424
   Ramchandran K, 1993, IEEE T IMAGE PROCESS, V2, P160, DOI 10.1109/83.217221
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Servetto SD, 1999, IEEE T IMAGE PROCESS, V8, P1161, DOI 10.1109/83.784429
   SETHURAMAN S, 1994, P S APPL SUBB WAV
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Starck J.-L., 1998, Image Processing and Data Analysis: The Multiscale Approach
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Woo O, 2000, IEEE T CIRC SYST VID, V10, P194, DOI 10.1109/76.825718
   Woo W, 1999, IEEE T CIRC SYST VID, V9, P861, DOI 10.1109/76.785724
   Yamaguchi H., 1991, Systems and Computers in Japan, V22, P53, DOI 10.1002/scj.4690221205
   YAMAGUCHI H, 1989, P ICASSP, P1976
NR 22
TC 32
Z9 38
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2004
VL 22
IS 4
BP 281
EP 290
DI 10.1016/j.imavis.2003.09.017
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 778FW
UT WOS:000189229700002
DA 2024-07-18
ER

PT J
AU Wang, Y
   Teoh, EK
   Shen, DG
AF Wang, Y
   Teoh, EK
   Shen, DG
TI Lane detection and tracking using B-Snake
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE lane detection; B-spline; snake; lane model; machine vision; intelligent
   vehicle
ID CONTOUR
AB In this paper, we proposed a B-Snake based lane detection and tracking algorithm without any cameras' parameters. Compared with other lane models, the B-Snake based lane model is able to describe a wider range of lane structures since B-Spline can form any arbitrary shape by a set of control points. The problems of detecting both sides of lane markings (or boundaries) have been merged here as the problem of detecting the mid-line of the lane, by using the knowledge of the perspective parallel lines. Furthermore, a robust algorithm, called CHEVP, is presented for providing a good initial position for the B-Snake. Also, a minimum error method by Minimum Mean Square Error (MMSE) is proposed to determine the control points of the B-Snake model by the overall image forces on two sides of lane. Experimental results show that the proposed method is robust against noise, shadows, and illumination variations in the captured road images. It is also applicable to the marked and the unmarked roads, as well as the dash and the solid paint line roads. (C) 2003 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 609798, Singapore.
   Univ Penn, Dept Radiol, Philadelphia, PA 19104 USA.
C3 Nanyang Technological University; University of Pennsylvania
RP Nanyang Technol Univ, Sch Elect & Elect Engn, Block S2,Nanyang Ave, Singapore 609798, Singapore.
EM s2633175g@ntu.edu.sg; eekteoh@ntu.edu.sg; dgshen@rad.upenn.edu
RI Shen, Dinggang/ABF-6812-2020
OI Shen, Dinggang/0000-0002-7934-5698
CR [Anonymous], 1987, An Introduction to Splines for use in Computer Graphics Geometric Modeling
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   Beucher S., 1994, P IEEE INTELLIGENT V, V94, P296
   Broggi A, 1995, J ARTIF INTELL RES, V3, P325, DOI 10.1613/jair.185
   Broggi A., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P84, DOI 10.1109/IVS.1995.528262
   Broggi A., 1995, P IEEE INT S COMP VI, P19
   DURIKOVIC R, 1995, VISUAL COMPUT, V11, P277, DOI 10.1007/BF01898405
   Jeong SG, 2001, 2001 IEEE INTELLIGENT TRANSPORTATION SYSTEMS - PROCEEDINGS, P508, DOI 10.1109/ITSC.2001.948710
   JUNG KD, 1996, P C INT VEH JAP, P189
   Kaliyaperumal K, 2001, IEEE T VEH TECHNOL, V50, P170, DOI 10.1109/25.917913
   KASKE A, 1997, QCAV, V9, P28
   KASKE A, 1995, IAR ANN M 95 NOV 199
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kluge K., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P54, DOI 10.1109/IVS.1995.528257
   Lai AHS, 2000, IEEE T SYST MAN CY B, V30, P539, DOI 10.1109/3477.865171
   Lakshmanan S, 1996, IEEE T PATTERN ANAL, V18, P438, DOI 10.1109/34.491625
   LAKSHMANAN S, 1995, INT CONF ACOUST SPEE, P2955, DOI 10.1109/ICASSP.1995.479465
   LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733
   LIOU SP, 1987, COMPUT VISION GRAPH, V39, P116, DOI 10.1016/S0734-189X(87)80205-0
   MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9
   Terzopoulos D., 1988, Visual Computer, V4, P306, DOI 10.1007/BF01908877
   Terzopoulos D., 1992, Active Vision, P3
   Wang Y, 2000, PATTERN RECOGN LETT, V21, P677, DOI 10.1016/S0167-8655(00)00021-0
   WANG Y, 2001, INT C IM PROC ICIP 2, P769
   WANG Y, 1998, IAPR WORKSH MACH VIS, P27
   Wang Y., 1998, IEEE INT C INTELLIGE, P51
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yu X., 1992, P INT VEH 92 S DETR, V1, P166
NR 28
TC 525
Z9 657
U1 2
U2 103
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2004
VL 22
IS 4
BP 269
EP 280
DI 10.1016/j.imavis.2003.10.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 778FW
UT WOS:000189229700001
DA 2024-07-18
ER

PT J
AU Yilmaz, A
   Shafique, K
   Shah, M
AF Yilmaz, A
   Shafique, K
   Shah, M
TI Target tracking in airborne forward looking infrared imagery
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT IEEE Workshop in Computer Vision Beyond the Visible Spectrum
CY DEC 14, 2001
CL KAUAI, HI
SP IEEE
DE FLIR imagery; target tracking; target detection; global motion
   compensation; mean-shift
ID ALGORITHM
AB In this paper. we propose a robust approach for tracking targets in forward looking infrared (FLIR) imagery taken from an airborne moving platform. First, the targets are detected using fuzzy clustering, edge fusion and local texture energy. The position and the size of the detected targets are then used to initialize the tracking algorithm. For each detected target, intensity and local standard deviation distributions are computed. and tracking is performed by computing the mean-shift vector that minimizes the distance between the kernel distribution for the target in the current frame and the model. In cases when the ego-motion of the sensor causes the target to move more than the operational limits of the tracking module, we perform a multi-resolution global motion compensation using the Gabor responses of the consecutive frames. The decision whether to compensate the sensor ego-motion is based on the distance measure computed from the likelihood of target and candidate distributions. To overcome the problems related to the changes in the target feature distributions, we automatically update the target model. Selection of the new target model is based on the same distance measure that is used for motion compensation. The experiments performed on the AMCOM FLIR data set show the robustness of the proposed method, which combines automatic model update and global motion compensation into one framework. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Univ Cent Florida, Dept Comp Sci, Orlando, FL 32816 USA.
EM yilmaz@cs.ucf.edu; khurram@cs.ucf.edu; shah@cs.ucf.edu
RI Yilmaz, Alper/B-5609-2013; Sahoo, Sarat Kumar/J-8765-2014
OI Sahoo, Sarat Kumar/0000-0001-5734-6844; Yilmaz,
   Alper/0000-0003-0755-2628; Shah, Mubarak/0000-0001-6172-5572
CR [Anonymous], ECCV 92
   BRAGANETO U, 1999, 33 C INF SCI SYST MA
   BRAITHWAITE RN, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P628, DOI 10.1109/CVPR.1994.323789
   CHEN JY, 1987, IEEE T AERO ELEC SYS, V23, P46, DOI 10.1109/TAES.1987.313335
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAVIES D, 1998, 9 BRIT MACH VIS C SE
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279
   Jepson AD, 2001, PROC CVPR IEEE, P415
   Laws KI., 1980, THESIS U SO CALIFORN
   Lim ET, 2000, P SOC PHOTO-OPT INS, V4025, P194, DOI 10.1117/12.391664
   LIM YW, 1990, PATTERN RECOGN, V23, P935, DOI 10.1016/0031-3203(90)90103-R
   LONGMIRE MS, 1988, APPL OPTICS, V27, P1141, DOI 10.1364/AO.27.001141
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Saber E, 1997, IMAGE VISION COMPUT, V15, P769, DOI 10.1016/S0262-8856(97)00019-X
   SHEKARFOROUSH H, 2000, IEEE INT C IM PROC, V3
   Strang G., 1996, Wavelets and Filter Banks
   Strehl A, 2000, MACH VISION APPL, V11, P267, DOI 10.1007/s001380050111
   TZANNES AP, 1999, P ICASSP
   YILMAZ A, 2002, AS C COMP VIS JAN, P284
   YILMAZ A, 2001, IEEE CVPR WORKSH COM
NR 25
TC 189
Z9 241
U1 0
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2003
VL 21
IS 7
BP 623
EP 635
DI 10.1016/S0262-8856(03)00059-3
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 706FR
UT WOS:000184443400006
DA 2024-07-18
ER

PT J
AU Zhang, CR
   Fang, Z
   Luo, XJ
   Liu, W
AF Zhang, Chengran
   Fang, Zheng
   Luo, Xingjian
   Liu, Wei
TI Accurate and robust visual SLAM with a novel ray-to-ray line measurement
   model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Point and line feature; Simultaneous localization and mapping; Visual
   inertial odometry; Optimization
ID STRUCTURE-FROM-MOTION; STRUCTURAL REGULARITY; SEGMENT DETECTOR;
   CORRESPONDENCES; DESCRIPTOR; VERSATILE; POINTS; CAMERA
AB Line feature is regarded as a more intuitive and accurate landmark than point feature in visual SLAM for its multiple-pixel comprehensiveness. However, uncertain factors, such as partial occlusion and noise, frequently hinder the mapping accuracy and destabilize the line-assisted SLAM system. Structural regulations and prior hypotheses are often used to tackle the issues, whereas only few people explore the impact of line feature optimization. In this paper, we attempt to improve the accuracy and robustness of visual SLAM system through line feature optimization process. First, a concise ray-to-ray residual model is proposed to replace the prevalent point-to-line model to integrally use line features. Second, the information matrix related to observation uncertainties is calculated to normalize the residual model, which aims to better balance the weights of different lines. Third, we add the line model to ORB-SLAM3 system and design the method of point-and-line based tracking and optimization. Finally, quantitative criteria are proposed to objectively evaluate the line feature map. Both synthetical and real datasets experiments are carried out to demonstrate the advantages of our algorithm in terms of camera ego-motion estimation and mapping. For camera ego-motion estimation experiments, the proposed ray-to-ray residual model produces more accurate results compared to state-of-the-art line-assisted SLAM/VIO algorithms. Furthermore, the model runs faster and obtains more robust results than the prevalent point-to-line reprojection residual model. For mapping experiments, quantitative criteria are proposed, which also open a new perspective to evaluate line-assisted SLAM systems, and give clues to evidence that the proposed method builds a more accurate line feature map.
C1 [Zhang, Chengran; Fang, Zheng; Liu, Wei] Northeastern Univ, Coll Informat Sci & Engn, 3-11, Wenhua Rd, Shenyang 110819, Liaoning, Peoples R China.
   [Fang, Zheng; Luo, Xingjian] Northeastern Univ, Fac Robot Sci & Engn, 195 Chuangxin Rd, Shenyang 110169, Liaoning, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Fang, Z (corresponding author), Northeastern Univ, Fac Robot Sci & Engn, 195 Chuangxin Rd, Shenyang 110169, Liaoning, Peoples R China.
EM zhangcr2729@foxmail.com; fangzheng@mail.neu.edu.cn; 1033699301@qq.com;
   lwei@reachauto.com
RI Zhang, Zhipeng/KHY-2239-2024; zhao, wenqing/KEZ-9488-2024; WEI,
   ZHEN/KHU-7176-2024; Liu, Jiacheng/KHX-5326-2024; feng,
   yue/KHV-4687-2024; zhou, chen/KHW-8121-2024; yang, xiao/KHT-9445-2024;
   Sun, Yang/KHY-5117-2024
OI Liu, Jiacheng/0000-0002-0518-3577; 
FU National Natural Science Foundation of China [62073066, U20A20197];
   Fundamental Research Funds for the Central Universities [N2226001]; 111
   Project [B16009]
FX * This work was supported in part by the National Natural Science
   Foundation of China under Grants 62073066 and U20A20197, in part by the
   Fundamental Research Funds for the Central Universities under Grant
   N2226001, and in part by 111 Project under Grant B16009.
CR Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   Bartoli A, 2005, COMPUT VIS IMAGE UND, V100, P416, DOI 10.1016/j.cviu.2005.06.001
   Burri M, 2016, INT J ROBOT RES, V35, P1157, DOI 10.1177/0278364915620033
   Campos C, 2021, IEEE T ROBOT, V37, P1874, DOI 10.1109/TRO.2021.3075644
   Fu Q., arXiv
   Gomez-Ojeda R, 2019, IEEE T ROBOT, V35, P734, DOI 10.1109/TRO.2019.2899783
   Grupp M., 2017, EVO PYTHON PACKAGE E
   Houben S, 2019, J REAL-TIME IMAGE PR, V16, P289, DOI 10.1007/s11554-015-0529-z
   Li H, 2019, IEEE INT C INT ROBOT, P6914, DOI [10.1109/IROS40897.2019.8968444, 10.1109/iros40897.2019.8968444]
   Li HA, 2019, IEEE INT CONF ROBOT, P2412, DOI [10.1109/icra.2019.8793716, 10.1109/ICRA.2019.8793716]
   Li HA, 2019, IEEE I CONF COMP VIS, P1646, DOI 10.1109/ICCV.2019.00173
   Li H, 2018, IEEE INT CONF ROBOT, P2518
   Lim H, 2021, IEEE INT CONF ROBOT, P11675, DOI 10.1109/ICRA48506.2021.9560911
   Lim H, 2022, IEEE ROBOT AUTOM LET, V7, P1518, DOI 10.1109/LRA.2022.3140816
   Liu JC, 2020, IEEE ROBOT AUTOM LET, V5, P6512, DOI 10.1109/LRA.2020.3014648
   Lu XH, 2017, IEEE WINT CONF APPL, P345, DOI 10.1109/WACV.2017.45
   Micusik B, 2017, INT J COMPUT VISION, V124, P65, DOI 10.1007/s11263-016-0971-9
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Pautrat R, 2021, PROC CVPR IEEE, P11363, DOI 10.1109/CVPR46437.2021.01121
   Pumarola A., 2017, P 2017 IEEE INT C RO, P4503, DOI DOI 10.1109/ICRA.2017.7989522
   Qin T, 2018, IEEE T ROBOT, V34, P1004, DOI 10.1109/TRO.2018.2853729
   Ruotsalainen L, 2012, INT C INDOOR POSIT
   Schubert D, 2018, IEEE INT C INT ROBOT, P1680, DOI 10.1109/IROS.2018.8593419
   Siyu Huang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P770, DOI 10.1007/978-3-030-58583-9_46
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang Q., 2020, arXiv
   Wang ZH, 2009, PATTERN RECOGN, V42, P941, DOI 10.1016/j.patcog.2008.08.035
   WENG JY, 1992, IEEE T PATTERN ANAL, V14, P318, DOI 10.1109/34.120327
   Xie SC, 2019, IEEE T INSTRUM MEAS, V68, P3661, DOI 10.1109/TIM.2018.2879705
   Xu B, 2022, IEEE ROBOT AUTOM LET, V7, P3483, DOI 10.1109/LRA.2022.3146893
   Xu C, 2017, IEEE T PATTERN ANAL, V39, P1209, DOI 10.1109/TPAMI.2016.2582162
   Yongduek Seo, 1996, Proceedings of the 13th International Conference on Pattern Recognition, P503, DOI 10.1109/ICPR.1996.546077
   Yu H, 2020, IEEE T INSTRUM MEAS, V69, P8962, DOI 10.1109/TIM.2020.2999137
   Zhang G, 2015, IEEE T ROBOT, V31, P1364, DOI 10.1109/TRO.2015.2489498
   Zhang LL, 2013, J VIS COMMUN IMAGE R, V24, P794, DOI 10.1016/j.jvcir.2013.05.006
   Zhou H, 2018, 2018 13TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P1148, DOI 10.1109/WCICA.2018.8630629
   Zhou HZ, 2015, IEEE T VEH TECHNOL, V64, P1364, DOI 10.1109/TVT.2015.2388780
   Zhou LP, 2021, IEEE ROBOT AUTOM LET, V6, P7113, DOI 10.1109/LRA.2021.3097052
   Zhou YC, 2019, IEEE I CONF COMP VIS, P962, DOI 10.1109/ICCV.2019.00105
   Zou DP, 2019, IEEE T ROBOT, V35, P999, DOI 10.1109/TRO.2019.2915140
   Zuo XX, 2017, IEEE INT C INT ROBOT, P1775, DOI 10.1109/IROS.2017.8205991
NR 41
TC 0
Z9 0
U1 5
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104837
DI 10.1016/j.imavis.2023.104837
EA OCT 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Y0BK4
UT WOS:001102007200001
DA 2024-07-18
ER

PT J
AU Degardin, B
   Lopes, V
   Proença, H
AF Degardin, Bruno
   Lopes, Vasco
   Proenca, Hugo
TI ATOM: Self-supervised human action recognition using atomic motion
   representation learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Atomic dynamics; Self-supervised learning; Graph convolutional networks;
   Human pose; Skeleton-based action recognition; Human behavior
   understanding
AB Self-supervised learning (SSL) is a promising method for gaining perception and common sense from unlabelled data. Existing approaches to analyzing human body skeletons address the problem similar to SSL models for image and video understanding, but pixel data is far more challenging than coordinates. This paper presents ATOM, an SSL model designed for skeleton-based data analysis. Unlike video-based SSL approaches, ATOM leverages atomic movements within skeleton actions to achieve a more fine-grained representation. The pro-posed architecture predicts the action order at the frame level, leading to improved perceptions and represen-tations of each action. ATOM outperforms state-of-the-art approaches in two well-known datasets (NTU RGB + D and NTU-120 RGB + D), and its weight transferability enables performance improvements on supervised and semi-supervised tasks, up to 4.4% (3.3% p.p.) and 14.1% (6.3% p.p.), respectively, in Top-1 Accuracy.
C1 [Degardin, Bruno; Lopes, Vasco; Proenca, Hugo] Univ Beira Interior, Covilha, Portugal.
   [Degardin, Bruno; Proenca, Hugo] IT Inst Telecomunicacoes, Aveiro, Portugal.
   [Degardin, Bruno; Lopes, Vasco] DeepNeuronic, Covilha, Portugal.
C3 Universidade da Beira Interior
RP Degardin, B (corresponding author), Univ Beira Interior, Covilha, Portugal.
EM bruno.degardin@ubi.pt
RI Proença, Hugo/F-9499-2010
OI Proença, Hugo/0000-0003-2551-8570; Degardin, Bruno/0000-0003-2462-7310
FU FCT/MEC; FEDER-PT2020 Partnership Agreement
   [CENTRO-01-0247-FEDER-113023]; EU [UIDB/50008/2020]; FCT-Fundacao para a
   Ciencia e Tecnologia [UI/BD/150765/2020, 2020.04588.BD]
FX This work was partially supported by the FCT/MEC through National Funds
   and by the FEDER-PT2020 Partnership Agreement under the Project
   CENTRO-01-0247-FEDER-113023-DeepNeuronic. This work was also supported
   by FCT/MCTES through national funds and co-funded by EU funds under the
   project UIDB/50008/2020. This research was also supported by
   FCT-Fundacao para a Ciencia e Tecnologia' through the research grant
   UI/BD/150765/2020' and 2020.04588.BD'.
CR Abu-El-Haija Sami, 2016, arXiv, DOI [DOI 10.48550/ARXIV.1609.08675, DOI 10.48550/-ARXIV.1609.08675]
   Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254
   Behrmann Nadine, 2021, P IEEE CVF WINT C AP, P1670
   Ben Tanfous A, 2022, IEEE WINT CONF APPL, P2888, DOI 10.1109/WACV51458.2022.00294
   Benaim S., 2020, CVPR, P9919
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Carreira J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1808.01340
   Carreira J, 2019, Arxiv, DOI arXiv:1907.06987
   Chen Z, 2021, AAAI CONF ARTIF INTE, V35, P1113, DOI 10.1145/3474085.3475574
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Chenyang Si, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P35, DOI 10.1007/978-3-030-58571-6_3
   Chi HG, 2022, PROC CVPR IEEE, P20154, DOI 10.1109/CVPR52688.2022.01955
   Degardin B., 2022, IEEECVF WINTER C APP, P1150
   Degardin B, 2021, IEEE T INF FOREN SEC, V16, P5442, DOI 10.1109/TIFS.2021.3130437
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gu CH, 2018, PROC CVPR IEEE, P6047, DOI 10.1109/CVPR.2018.00633
   He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hu K., 2021, P IEEECVF INT C COMP, P7939
   Jenni S, 2020, PROC CVPR IEEE, P6407, DOI 10.1109/CVPR42600.2020.00644
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kim D, 2019, AAAI CONF ARTIF INTE, P8545
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Kong Quan, 2020, Advances in Neural Information Processing Systems, V33, P8089
   Kun Su, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9628, DOI 10.1109/CVPR42600.2020.00965
   Lan ZZ, 2020, Arxiv, DOI arXiv:1909.11942
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Lee I, 2017, IEEE I CONF COMP VIS, P1012, DOI 10.1109/ICCV.2017.115
   Li C, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P786
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Liang HW, 2022, AAAI CONF ARTIF INTE, P1564
   Liang ZX, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104357
   Lin LL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2490, DOI 10.1145/3394171.3413548
   Lin Y., 2021, P IEEE INT C COMP VI, P8239
   Liu H, 2017, Arxiv, DOI arXiv:1705.08106
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu YH, 2019, Arxiv, DOI arXiv:1907.11692
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Raffel C, 2020, J MACH LEARN RES, V21
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Su YK, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13308, DOI 10.1109/ICCV48922.2021.01308
   Sun N, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104141
   Tran D, 2019, IEEE I CONF COMP VIS, P5551, DOI 10.1109/ICCV.2019.00565
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Walker J, 2015, IEEE I CONF COMP VIS, P2443, DOI 10.1109/ICCV.2015.281
   Wang XL, 2019, PROC CVPR IEEE, P2561, DOI 10.1109/CVPR.2019.00267
   Xu DJ, 2019, PROC CVPR IEEE, P10326, DOI 10.1109/CVPR.2019.01058
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang ZL, 2019, ADV NEUR IN, V32
   Zhang PF, 2020, PROC CVPR IEEE, P1109, DOI 10.1109/CVPR42600.2020.00119
   Zhang PF, 2017, IEEE I CONF COMP VIS, P2136, DOI [10.1109/ICCV.2017.233, 10.1109/ICCV.2017.231]
   Zhang X., 2020, P IEEE CVF C COMP VI, P14333, DOI DOI 10.1109/CVPR42600202001434
NR 65
TC 0
Z9 0
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104750
DI 10.1016/j.imavis.2023.104750
EA JUL 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P1ZO1
UT WOS:001048695100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Ferrante, M
   Boccato, T
   Spasov, S
   Duggento, A
   Toschi, N
AF Ferrante, Matteo
   Boccato, Tommaso
   Spasov, Simeon
   Duggento, Andrea
   Toschi, Nicola
TI VAESim: A probabilistic approach for self-supervised prototype discovery
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep clustering; Medical imaging; Variational autoencoders; Prototypes
   discovery
AB In medical image datasets, discrete labels are often used to describe a continuous spectrum of conditions, making unsupervised image stratification a challenging task. In this work, we propose VAESim, an architecture for image stratification based on a conditional variational autoencoder. VAESim learns a set of prototypical vectors during training, each associated with a cluster in a continuous latent space. We perform a soft assignment of each data sample to the clusters and reconstruct the sample based on a similarity measure between the sample embedding and the prototypical vectors. To update the prototypical embeddings, we use an exponential moving average of the most similar representations between actual prototypes and samples in the batch size. We test our approach on the MNIST handwritten digit dataset and the PneumoniaMNIST medical benchmark dataset, where we show that our method outperforms baselines in terms of kNN accuracy (up to +15% improvement in performance) and performs at par with classification models trained in a fully supervised way. Our model also outperforms current end-to-end models for unsupervised stratification.
C1 [Ferrante, Matteo; Boccato, Tommaso; Duggento, Andrea; Toschi, Nicola] Univ Roma Tor Vergata, Dept Biomed & Prevent, Rome, Italy.
   [Toschi, Nicola] MGH, Martinos Ctr Biomed Imaging, Boston, MA USA.
   [Toschi, Nicola] Harvard Med Sch, Boston, MA USA.
   [Spasov, Simeon] Univ Cambridge, Dept Comp Sci & Technol, Cambridge, England.
C3 University of Rome Tor Vergata; Harvard University; Harvard Medical
   School; University of Cambridge
RP Ferrante, M (corresponding author), Univ Roma Tor Vergata, Dept Biomed & Prevent, Rome, Italy.
EM matteo.ferrante@uniroma2.it
RI Toschi, Nicola/J-2555-2012; Ferrante, Matteo/HNS-3479-2023
OI Toschi, Nicola/0000-0003-1929-5833; 
FU European Union [101017727]
FX Part of this work is supported by the EXPERIENCE project (European
   Union's Horizon 2020 research and innovation program under grant
   agreement No. 101017727).
CR Ahn E, 2019, Arxiv, DOI [arXiv:1906.03359, 10.48550/arXiv.1906.03359]
   Ashwani Kumar Aggarwal P.J., 2022, Int J Biol Biomed, V7, P40
   Azizi S, 2021, Arxiv, DOI arXiv:2101.05224
   Bengfort Benjamin, 2018, Zenodo
   Biewald L., 2020, Experiment tracking with weights and biases
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Chen T, 2020, Arxiv, DOI [arXiv:2002.05709, DOI 10.48550/ARXIV.2002.05709]
   Chen T, 2020, Arxiv, DOI arXiv:2006.10029
   Dilokthanakul N., 2017, Deep unsupervised clustering with gaussian mixture variational autoencoders, P1
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fard MM, 2020, PATTERN RECOGN LETT, V138, P185, DOI 10.1016/j.patrec.2020.07.028
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   He KM, 2020, Arxiv, DOI arXiv:1911.05722
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, 10.48550/arxiv.1512.03385]
   Jiang ZX, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1965
   Kopf A, 2021, PLOS COMPUT BIOL, V17, DOI 10.1371/journal.pcbi.1009086
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lim KL, 2020, IEEE SIGNAL PROC LET, V27, P231, DOI 10.1109/LSP.2020.2965328
   Xiao J, 2023, MEASUREMENT, V214, DOI 10.1016/j.measurement.2023.112764
   Yang JC, 2022, Arxiv, DOI arXiv:2110.14795
NR 20
TC 1
Z9 1
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104746
DI 10.1016/j.imavis.2023.104746
EA JUL 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N8NF2
UT WOS:001039509600001
OA Green Published, hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Velda, V
   Immanuel, SA
   Hendria, WF
   Jeong, C
AF Velda, Vania
   Immanuel, Steve Andreas
   Hendria, Willy Fitra
   Jeong, Cheol
TI Improving distinctiveness in video captioning with text-video similarity
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Distinctiveness; Similarity scores; Video captioning; Video retrieval
AB Video captioning is a task of automatically describing visual content of a video with a sentence. Recent works in video captioning focus on improving the performance of sentence accuracy. However, the distinctiveness of sentence, i.e., highlighting unique and accurate details of video, in video captioning is still underexplored. This paper aims to improve sentence distinctiveness by incorporating video retrieval into the training process of the video captioning model. Specifically, the video retrieval will calculate similarity scores between the input text generated by the video captioning and videos. These similarity scores are then incorporated into the training loss of video captioning, which serves as distinctiveness constraint where the generated sentence and its corre-sponding video should have the highest similarity scores. To further improve the sentence distinctiveness, we additionally use reference scores, i.e., similarity scores between ground truth sentences and videos, as weights to scale the training loss of video captioning. This reference score serves as a target score for the model, indicating the desired level of distinctiveness for the generated sentence on how similar the generated sentence should be to the ground truth sentence for the corresponding video. Our qualitative and quantitative results show that our method improves sentence distinctiveness while simultaneously increasing its accuracy on MSVD and MSR-VTT datasets.& COPY; 2023 Published by Elsevier B.V.
C1 [Jeong, Cheol] Sejong Univ, Dept Intelligent Mechatron Engn, Seoul, South Korea.
   Sejong Univ, Dept Convergence Engn Intelligent Drone, Seoul, South Korea.
C3 Sejong University; Sejong University
RP Jeong, C (corresponding author), Sejong Univ, Dept Intelligent Mechatron Engn, Seoul, South Korea.
EM vaniavelda@sju.ac.kr; 22110338@sju.ac.kr; willyfitrahendria@sju.ac.kr;
   cheol.jeong@ieee.org
OI Immanuel, Steve/0009-0007-2160-9121; Hendria, Willy
   Fitra/0000-0002-6209-3981
FU Institute of Information amp; Communications Technology Planning amp;
   Evaluation (IITP) - Korea government (MSIT) [2021-0-02067]
FX This work was supported by Institute of Information & Communications
   Technology Planning & Evaluation (IITP) grant funded by the Korea
   government (MSIT) (No. 2021-0-02067, Next Generation AI for Multi
   -purpose Video Search, 70%) and (IITP-2023-RS-2022-00156345, ICT
   Challenge and Advanced Network of HRD, 30%) .
CR Bai Y, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3556, DOI 10.1145/3474085.3475519
   Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Celikyilmaz A, 2021, Arxiv, DOI arXiv:2006.14799
   Chen D., 2011, P 49 ANN M ASS COMP, P190
   Chen YY, 2018, LECT NOTES COMPUT SC, V11217, P367, DOI 10.1007/978-3-030-01261-8_22
   Cheng X., 2021, arXiv
   Dai B, 2017, ADV NEUR IN, V30
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Ding ST, 2019, FUTURE GENER COMP SY, V93, P583, DOI 10.1016/j.future.2018.10.054
   Dong J., 2018, P BMVC
   Dosovitskiy Alexey, 2021, ICLR
   Freitag M., PROC WNMT 2017, P56
   Lazaridou Angeliki, 2020, P 58 ANN M ASS COMP, P7663, DOI DOI 10.18653/V1/2020.ACL-MAIN.685
   Lee J, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4385
   Li L, 2022, IEEE T IMAGE PROCESS, V31, P2726, DOI 10.1109/TIP.2022.3158546
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin K, 2021, AAAI CONF ARTIF INTE, V35, P2047
   Lin K, 2022, PROC CVPR IEEE, P17928, DOI 10.1109/CVPR52688.2022.01742
   Lin KV, 2022, Arxiv, DOI arXiv:2111.13196
   Luo HS, 2022, NEUROCOMPUTING, V508, P293, DOI 10.1016/j.neucom.2022.07.028
   Luo HS, 2020, Arxiv, DOI arXiv:2002.06353
   Luo RT, 2018, PROC CVPR IEEE, P6964, DOI 10.1109/CVPR.2018.00728
   Niu T.-Z., 2023, ACM Trans. Multimedia Comput., Commun., Appl., V19, P1
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pasunuru R, 2017, ARXIV170802300, P979, DOI [10.18653/v1/D17-1103, DOI 10.18653/V1/D17-1103]
   Pei WJ, 2019, PROC CVPR IEEE, P8339, DOI 10.1109/CVPR.2019.00854
   Perez-Martin J, 2021, IEEE WINT CONF APPL, P3038, DOI 10.1109/WACV48630.2021.00308
   Perez-Martin J, 2021, INT C PATT RECOG, P5767, DOI 10.1109/ICPR48806.2021.9412898
   Radford A, 2021, PR MACH LEARN RES, V139
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Ryu H, 2021, AAAI CONF ARTIF INTE, V35, P2514
   Seo PH, 2022, PROC CVPR IEEE, P17938, DOI 10.1109/CVPR52688.2022.01743
   Song H, 2020, COMPUT ELECTR ENG, V84, DOI 10.1016/j.compeleceng.2020.106630
   Tang MK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4858, DOI 10.1145/3474085.3479207
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wang LM, 2019, IEEE T PATTERN ANAL, V41, P2740, DOI 10.1109/TPAMI.2018.2868668
   Wang ZA, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104570
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wu LJ, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P3612
   Xu J, 2016, PROC CVPR IEEE, P5288, DOI 10.1109/CVPR.2016.571
   Yan L., 2022, PROC IJCAI
   Yang B, 2021, AAAI CONF ARTIF INTE, V35, P3119
   Ye H., 2022, P IEEECVF C COMPUTER, P17939
   Zhang W, 2020, IEEE T PATTERN ANAL, V42, P3088, DOI 10.1109/TPAMI.2019.2920899
   Zhang ZQ, 2021, PROC CVPR IEEE, P9832, DOI 10.1109/CVPR46437.2021.00971
   Zhao Wentian, 2021, ADV NEUR IN, V34
NR 47
TC 0
Z9 0
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104728
DI 10.1016/j.imavis.2023.104728
EA JUN 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P9HV9
UT WOS:001053723700001
DA 2024-07-18
ER

PT J
AU Mocanu, B
   Tapu, R
   Zaharia, T
AF Mocanu, Bogdan
   Tapu, Ruxandra
   Zaharia, Titus
TI Multimodal emotion recognition using cross modal audio-video fusion with
   attention and deep metric learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Spatial attention; Channel attention; Temporal attention; Cross -modal
   fusion; Emotional metric constraint
ID FEATURES
AB In the last few years, the multi-modal emotion recognition has become an important research issue in the affec-tive computing community due to its wide range of applications that include mental disease diagnosis, human behavior understanding, human machine/robot interaction or autonomous driving systems. In this paper, we introduce a novel end-to-end multimodal emotion recognition methodology, based on audio and visual fusion designed to leverage the mutually complementary nature of features while maintaining the modality-specific in-formation. The proposed method integrates spatial, channel and temporal attention mechanisms into a visual 3D convolutional neural network (3D-CNN) and temporal attention into an audio 2D convolutional neural network (2D-CNN) to capture the intra-modal features characteristics. Further, the inter-modal information is captured with the help of an audio-video (A-V) cross-attention fusion technique that effectively identifies salient relation-ships across the two modalities. Finally, by considering the semantic relations between the emotion categories, we design a novel classification loss based on an emotional metric constraint that guides the attention generation mechanisms. We demonstrate that by exploiting the relations between the emotion categories our method yields more discriminative embeddings, with more compact intra-class representations and increased inter-class separability. The experimental evaluation carried out on the RAVDESS (The Ryerson Audio-Visual Database of Emotional Speech and Song), and CREMA-D (Crowd-sourced Emotional Multimodal Actors Dataset) datasets vali-dates the proposed methodology, which leads to average accuracy scores of 89.25% and 84.57%, respectively. In addition, when compared to state-of-the-art techniques, the proposed solution shows superior performances, with gains in accuracy ranging in the [1.72%, 11.25%] interval.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Mocanu, Bogdan] Univ Politehn Bucuresti, Fac ETTI, Telecommun Dept, 313 Splaiul Independentei, Bucharest, Romania.
   [Tapu, Ruxandra; Zaharia, Titus] Inst Polytech Paris, ARTEMIS Dept, Telecom SudParis, 9 Rue Charles Fourier, F-91000 Evry, France.
C3 National University of Science & Technology POLITEHNICA Bucharest; IMT -
   Institut Mines-Telecom; Institut Mines-Telecom Business School; Institut
   Polytechnique de Paris; Telecom SudParis
RP Tapu, R (corresponding author), Inst Polytech Paris, ARTEMIS Dept, Telecom SudParis, 9 Rue Charles Fourier, F-91000 Evry, France.
EM ruxandra.tapu@telecom-sudparis.eu
FU Romanian Ministry of Research, Innovation and Digitization, CNCS/CCCDI -
   UEFISCDI,within PNCDI III [PN-III-P1-1.1TE-2021-0393]
FX This work has been partially supported by a grant of the Romanian
   Ministry of Research, Innovation and Digitization, CNCS/CCCDI -
   UEFISCDI, project number PN-III-P1-1.1TE-2021-0393, within PNCDI III.
CR Abbasi NI, 2022, INT CONF ACOUST SPEE, P1725, DOI 10.1109/ICASSP43922.2022.9747102
   Abbasnejad I, 2017, IEEE INT CONF COMP V, P1609, DOI 10.1109/ICCVW.2017.189
   Antoniadis P., 2021, P IEEE 16 INT C AUT, P1, DOI 10.1109/FG52635.2021.9667014
   Atila O, 2021, APPL ACOUST, V182, DOI 10.1016/j.apacoust.2021.108260
   Atmaja BT, 2020, INT CONF ACOUST SPEE, P4482, DOI [10.1109/icassp40776.2020.9052916, 10.1109/ICASSP40776.2020.9052916]
   Bagheri E, 2020, ACM T INTERACT INTEL, V10, DOI 10.1145/3341198
   Bhavan A, 2019, KNOWL-BASED SYST, V184, DOI 10.1016/j.knosys.2019.104886
   Boersma P., 2018, Praat: doing phonetics by computer, DOI DOI 10.1097/AUD.0B013E31821473F7
   Cannon WB, 1927, AM J PSYCHOL, V39, P106, DOI 10.2307/1415404
   Cao HW, 2014, IEEE T AFFECT COMPUT, V5, P377, DOI 10.1109/TAFFC.2014.2336244
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chang X, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21165452
   Chen WD, 2022, INT CONF ACOUST SPEE, P6897, DOI 10.1109/ICASSP43922.2022.9746598
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Nguyen D, 2018, COMPUT VIS IMAGE UND, V174, P33, DOI 10.1016/j.cviu.2018.06.005
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Fu Z, 2021, arXiv
   Ghaleb E, 2020, IEEE IMAGE PROC, P251, DOI 10.1109/ICIP40778.2020.9191019
   Ghriss A, 2022, INT CONF ACOUST SPEE, P7347, DOI 10.1109/ICASSP43922.2022.9747637
   Glorot X., 2010, INT C ARTIFICIAL INT, P249
   Goncalves L, 2022, INT CONF ACOUST SPEE, P7357, DOI 10.1109/ICASSP43922.2022.9747157
   Gudmalwar A, 2022, INTERSPEECH, P1163, DOI 10.21437/Interspeech.2022-10769
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu D, 2022, INT CONF ACOUST SPEE, P7037, DOI 10.1109/ICASSP43922.2022.9747397
   Huang D.-Y., 2017, P 19 ACM INT C MULT, P577, DOI DOI 10.1145/3136755.3143012
   Huang J., 2017, P 7 ANN WORKSH AUD V, P11
   Huang J, 2020, INTERSPEECH, P4079, DOI 10.21437/Interspeech.2020-1391
   Huang J, 2018, INTERSPEECH, P3673, DOI 10.21437/Interspeech.2018-1432
   Issa D, 2020, BIOMED SIGNAL PROCES, V59, DOI 10.1016/j.bspc.2020.101894
   Jaderberg M, 2015, ADV NEUR IN, V28
   John V, 2022, INT C PATT RECOG, P2582, DOI 10.1109/ICPR56361.2022.9956730
   Kahou SE, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P543, DOI 10.1145/2522848.2531745
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Kingma D.P., 2014, C TRACK P 2014, P1
   Le HD, 2023, IEEE ACCESS, V11, P14742, DOI 10.1109/ACCESS.2023.3244390
   Li Y, 2022, INT CONF ACOUST SPEE, P7352, DOI 10.1109/ICASSP43922.2022.9746930
   Lian Z, 2018, PROCEEDINGS OF THE JOINT WORKSHOP OF THE 4TH WORKSHOP ON AFFECTIVE SOCIAL MULTIMEDIA COMPUTING AND FIRST MULTI-MODAL AFFECTIVE COMPUTING OF LARGE-SCALE MULTIMEDIA DATA (ASMMC-MMAC'18), P21
   Liu JX, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P6339, DOI 10.1109/ICASSP39728.2021.9413608
   Livingstone SR, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0196391
   Luna-Jiménez C, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167217
   Ma FY, 2023, IEEE T AFFECT COMPUT, V14, P1236, DOI 10.1109/TAFFC.2021.3122146
   Ma X, 2017, INTERSPEECH, P1238, DOI 10.21437/Interspeech.2017-619
   Mao QR, 2014, IEEE T MULTIMEDIA, V16, P2203, DOI 10.1109/TMM.2014.2360798
   Miao H., 2018, 2018 1 AS C AFF COMP, P1, DOI DOI 10.1109/ACIIASIA.2018.8470379
   Middya AI, 2022, KNOWL-BASED SYST, V244, DOI 10.1016/j.knosys.2022.108580
   Mikels JA, 2005, BEHAV RES METHODS, V37, P626, DOI 10.3758/BF03192732
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mirsamadi S, 2017, INT CONF ACOUST SPEE, P2227, DOI 10.1109/ICASSP.2017.7952552
   Miyoshi R, 2022, IEEE IMAGE PROC, P3261, DOI 10.1109/ICIP46576.2022.9897786
   Mocanu B, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21124233
   Mustaqeem, 2021, APPL SOFT COMPUT, V102, DOI 10.1016/j.asoc.2021.107101
   Nawab S. H., 1987, Advanced Topics in Signal Processing, P289
   Nguyen BT, 2017, INT CONF INFO SCI, P251, DOI 10.1109/ICIST.2017.7926765
   Parry J, 2022, INTERSPEECH, P1158, DOI 10.21437/Interspeech.2022-10581
   Parthasarathy S, 2021, IEEE W SP LANG TECH, P636, DOI 10.1109/SLT48900.2021.9383573
   Pepino L, 2021, INTERSPEECH, P3400, DOI 10.21437/Interspeech.2021-703
   Pourmirzaei Mahdi, 2021, arXiv
   Ren Z, 2020, INT CONF ACOUST SPEE, P7184, DOI [10.1109/ICASSP40776.2020.9054087, 10.1109/icassp40776.2020.9054087]
   Sahu S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4934, DOI 10.1109/ICASSP.2018.8462065
   Savchenko AV, 2022, IEEE T AFFECT COMPUT, V13, P2132, DOI 10.1109/TAFFC.2022.3188390
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Su BH, 2022, INTERSPEECH, P1153, DOI 10.21437/Interspeech.2022-10453
   Su L, 2021, Arxiv, DOI arXiv:2012.07175
   Sun LC, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4275, DOI 10.1109/ICASSP39728.2021.9414654
   Tautkute I, 2019, FUND INFORM, V168, P269, DOI 10.3233/FI-2019-1832
   Tzinis E, 2017, INT CONF AFFECT, P190, DOI 10.1109/ACII.2017.8273599
   Tzirakis P, 2021, INFORM FUSION, V68, P46, DOI 10.1016/j.inffus.2020.10.011
   Vaswani A, 2017, ADV NEUR IN, V30
   Venkataramanan K, 2019, Arxiv, DOI arXiv:1912.10458
   Wijayasingha Lahiru, 2021, Smart Health, V19, DOI 10.1016/j.smhl.2020.100165
   Xue F., 2021, P IEEE CVF INT C COM, P3581
   Yanan Wang, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P827, DOI 10.1145/3382507.3417960
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
   Zhao J, 2022, 2022 15TH IEEE/ACM INTERNATIONAL WORKSHOP ON NETWORK ON CHIP ARCHITECTURES (NOCARC 2022), P21, DOI 10.1109/NoCArc57472.2022.9911299
   Zhao JF, 2018, VISUAL COMPUT, V34, P1461, DOI 10.1007/s00371-018-1477-y
   Zhao JM, 2022, INT CONF ACOUST SPEE, P4703, DOI 10.1109/ICASSP43922.2022.9746910
   Zhao SC, 2020, AAAI CONF ARTIF INTE, V34, P303
   Zhu Y, 2020, Arxiv, DOI [arXiv:2012.06567, 10.48550/arXiv.2012.06567]
NR 84
TC 5
Z9 5
U1 11
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2023
VL 133
AR 104676
DI 10.1016/j.imavis.2023.104676
EA APR 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA F6XS5
UT WOS:000983760500001
OA Green Published, Bronze
DA 2024-07-18
ER

PT J
AU Aing, L
   Lie, WN
   Lin, GS
AF Aing, Lee
   Lie, Wen-Nung
   Lin, Guo-Shiang
TI Faster and finer pose estimation for multiple instance objects in a
   single RGB image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 6DoF object pose; Multiple instance objects; Bottom-up approaches; RGB
   image; 3D coordinate map; Instance masks
ID NETWORK
AB Determining the 6 degrees of freedom (6DoF) object pose parameters for multiple instance objects with high accu-racy and less time complexity is a challenging issue in robotics and computer vision. Many bottom-up approaches have been proposed for rapid multiple pose estimation but these are much less accurate than top-down approaches. Moreover, most post-processing is affected from more detected objects because non-maximum suppression is used. This study uses a bottom-up approach that is faster and more precise to estimate poses for multiple instance objects in a single RGB image. This method can overcome the occlusion/overlapping of instances in the same/different object category. Informative features and techniques including a semantic segmentation map, multi-keypoint vector fields, a 3D coordinate map, and diagonal graph clustering post-processing are proposed to segment the entire mask into instance masks at once and then to estimate the corresponding poses. The experimental results and ablation studies show that the proposed system features competitive accuracy at a speed of 24.7 frames per second for more than 7 objects using the Occlusion LINEMOD dataset.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Aing, Lee; Lie, Wen-Nung] Natl Chung Cheng Univ CCU, Dept Elect Engn, Chiayi, Taiwan.
   [Lie, Wen-Nung] Natl Chung Cheng Univ CCU, Ctr Innovat Res Aging Soc CIRAS, Chiayi, Taiwan.
   [Lie, Wen-Nung] Natl Chung Cheng Univ CCU, Adv Inst Mfg High tech Innovat AIM HI, Chiayi, Taiwan.
   [Lin, Guo-Shiang] Natl Chin Yi Univ Technol NCUT, Dept Comp Sci & Informat Engn, Taichung, Taiwan.
C3 National Chung Cheng University; National Chung Cheng University;
   National Chung Cheng University
RP Lie, WN (corresponding author), Natl Chung Cheng Univ CCU, Dept Elect Engn, Chiayi, Taiwan.
EM ainglee55@gmail.com; ieewnl@ccu.edu.tw; gslin@ncut.edu.tw
FU Center for Innovative Research on Aging Society (CIRAS); Advanced
   Institute of Manufacturing with High-tech Innovations (AIM-HI) from The
   Featured AreasResearch Center Program; Higher Education Sprout Project
   by the Ministry of Education (MOE) in Taiwan
FX This work was financially supported by the Center for Innovative
   Research on Aging Society (CIRAS), Advanced Institute of Manufacturing
   with High-tech Innovations (AIM-HI) from The Featured AreasResearch
   Center Program within the framework of the Higher Education Sprout
   Project by the Ministry of Education (MOE) in Taiwan.
CR Ackerman E., 2020, BOST
   Aing L, 2021, IEEE I C VI COM I PR, DOI 10.1109/VCIP53242.2021.9675316
   Aing L, 2021, IEEE ACCESS, V9, P77729, DOI 10.1109/ACCESS.2021.3082406
   Billings G, 2019, IEEE ROBOT AUTOM LET, V4, P3727, DOI 10.1109/LRA.2019.2928776
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Charco JL, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104182
   Dede MA, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104495
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fahim G, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104377
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo SX, 2022, IEEE T CIRC SYST VID, V32, P5293, DOI 10.1109/TCSVT.2022.3142787
   Gupta K, 2019, IEEE INT CONF COMP V, P2758, DOI 10.1109/ICCVW.2019.00337
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He Yang, 2020, CVPR, P2009
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Hodan Tomas, 2020, Computer Vision - ECCV 2020 Workshops. Proceedings. Lecture Notes in Computer Science (LNCS 12536), P577, DOI 10.1007/978-3-030-66096-3_39
   Hodan Tomas, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11700, DOI 10.1109/CVPR42600.2020.01172
   Hu YL, 2020, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR42600.2020.00300
   Hu YL, 2019, PROC CVPR IEEE, P3380, DOI 10.1109/CVPR.2019.00350
   Irie G, 2019, IEEE IMAGE PROC, P964, DOI [10.1109/ICIP.2019.8803059, 10.1109/icip.2019.8803059]
   Jiang ZH, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104127
   Kamousi P, 2016, COMP GEOM-THEOR APPL, V57, P1, DOI 10.1016/j.comgeo.2016.05.005
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Li Y, 2018, LECT NOTES COMPUT SC, V11210, P695, DOI [10.1007/s11263-019-01250-9, 10.1007/978-3-030-01231-1_42]
   Li ZG, 2020, IEEE INT CONF ROBOT, P8397, DOI [10.1109/ICRA40945.2020.9196953, 10.1109/icra40945.2020.9196953]
   Li ZG, 2019, IEEE I CONF COMP VIS, P7677, DOI 10.1109/ICCV.2019.00777
   Luo YM, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104390
   Meng CZ, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104085
   Oberweger M, 2018, LECT NOTES COMPUT SC, V11219, P125, DOI 10.1007/978-3-030-01267-0_8
   Park K, 2019, IEEE I CONF COMP VIS, P7667, DOI 10.1109/ICCV.2019.00776
   Park SM, 2022, IEEE ACCESS, V10, P4209, DOI 10.1109/ACCESS.2021.3140175
   Peng SD, 2022, IEEE T PATTERN ANAL, V44, P3212, DOI 10.1109/TPAMI.2020.3047388
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Reddy ND, 2019, PROC CVPR IEEE, P7318, DOI 10.1109/CVPR.2019.00750
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sun HW, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2022.104372
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Yang TY, 2019, PROC CVPR IEEE, P1087, DOI 10.1109/CVPR.2019.00118
   Zhang X, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103854
   Zhang X, 2019, IMAGE VISION COMPUT, V89, P1, DOI 10.1016/j.imavis.2019.06.013
   Zhou QY, 2018, Arxiv, DOI arXiv:1801.09847
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
NR 47
TC 4
Z9 4
U1 3
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2023
VL 130
AR 104618
DI 10.1016/j.imavis.2022.104618
EA JAN 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 8D6MM
UT WOS:000918404900001
DA 2024-07-18
ER

PT J
AU Huang, MK
   Li, GY
   Liu, Z
   Wu, Y
   Gong, C
   Zhu, LC
   Yang, Y
AF Huang, Mengke
   Li, Gongyang
   Liu, Zhi
   Wu, Yong
   Gong, Chen
   Zhu, Linchao
   Yang, Yi
TI Exploring viewport features for semi-supervised saliency prediction in
   omnidirectional images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Omnidirectional image; Saliency prediction; Semi-supervised learning
ID FIXATIONS; ATTENTION; MODEL
AB Compared with the annotated data for the 2D image saliency prediction task, the annotated data for training om-nidirectional image (or 360 degrees image) saliency prediction models are not sufficient. Most existing fully-supervised saliency prediction methods for omnidirectional images (ODIs) adopt a scheme, first training the methods on a labeled large 2D image saliency prediction dataset and then fine-tuning the methods on the labeled tiny ODI sa-liency prediction dataset. However, this strategy is time-consuming and may not inadequately mine the visual features built in ODIs. To explore the visual attributes targeted at ODIs and address the shortage of labels on these ODIs, in this paper, we propose an end-to-end semi-supervised network, namely VFNet, which relies on viewport features and only utilizes ODIs as training data, for ODI saliency prediction. Concretely, we adopt con-sistency regularization as our semi-supervised learning framework. The predictions between main and auxiliary saliency inference networks in the VFNet enforce consistency. Aiming at ODIs, we introduce a new form of per-turbation, i.e., DropView, to improve the effectiveness of consistency regularization. By randomly dropping out different 360 degrees cubemap viewport features before the auxiliary saliency inference network, the proposed DropView enhances the robustness of the final ODI saliency prediction. To adaptively interact with the equirectangular and different cubemap viewport features according to their contributions, we introduce a Viewport Feature Adaptive Integration (VFAI) module and deploy the VFAI module at different levels in the VFNet to raise the capacity of feature encoding of our VFNet. Compared with state-of-the-art fully-supervised methods, our VFNet with fewer labeled training data achieves competitive performance demonstrated by exten-sive experiments on two publicly available datasets. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Huang, Mengke; Li, Gongyang; Liu, Zhi; Wu, Yong] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Huang, Mengke; Li, Gongyang; Liu, Zhi; Wu, Yong] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Gong, Chen] Nanjing Univ Sci & Technol, Sch Comp Sci & Engn, Key Lab Intelligent Percept & Syst High Dimens Inf, PCA Lab,Minist Educ, Nanjing 210094, Peoples R China.
   [Gong, Chen] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Peoples R China.
   [Zhu, Linchao; Yang, Yi] Univ Technol Sydney, Australian Artificial Intelligence Inst, ReLER Lab, Ultimo, NSW 2007, Australia.
C3 Shanghai University; Shanghai University; Nanjing University of Science
   & Technology; Hong Kong Polytechnic University; University of Technology
   Sydney
RP Li, GY (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM huangmengke@shu.edu.cn; ligongyang@shu.edu.cn; liuzhisjtu@163.com;
   yong_wu@shu.edu.cn; chen.gong@njust.edu.cn; linchao.zhu@uts.edu.au;
   yi.yang@uts.edu.au
RI LIU, Zhi/D-4518-2012; GONG, CHEN/JDW-5727-2023; yang,
   yang/HGT-7999-2022; WU, YONG/GWM-4056-2022; Li, Gongyang/IXD-9078-2023;
   Zhu, Linchao/AAE-6700-2020
OI LIU, Zhi/0000-0002-8428-1131; WU, YONG/0000-0002-3256-6012; Zhu,
   Linchao/0000-0002-4093-7557
FU National Natural Science Foundation of China; China Postdoctoral Science
   Foundation;  [62171269];  [2022M722037]
FX Acknowledgements This work was supported in part by the National Natural
   Science Foundation of China under Grant 62171269, and in part by the
   China Postdoctoral Science Foundation under Grant 2022M722037.
CR Borji A., 2015, P CVPR WORKSH FUT DA
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Chao FY, 2021, IEEE T MULTIMEDIA, V23, P1811, DOI 10.1109/TMM.2020.3003642
   Chao FY, 2018, IEEE INT CONF MULTI
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen YZ, 2022, IMAGE VISION COMPUT, V125, DOI 10.1016/j.imavis.2022.104512
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Cornia M, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3177745
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Coutrot A., 2018, PROC INT C QUAL MULT, P1
   De Abreu A., 2017, INT WORK QUAL MULTIM, P1
   Deng J., 2009, IEEE C COMP VIS PATT
   Ding GQ, 2022, IMAGE VISION COMPUT, V120, DOI 10.1016/j.imavis.2022.104395
   Ghiasi G, 2018, ADV NEUR IN, V31
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Harel J., 2006, NEURAL INFORM PROCES
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia CC, 2020, IEEE T CIRC SYST VID, V30, P2801, DOI 10.1109/TCSVT.2019.2910208
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laine Samuli, 2017, 5 INT C LEARNING REP, DOI DOI 10.48550/ARXIV.1610.02242
   Larsson G., 2017, ICLR, P1
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Lebreton P, 2018, SIGNAL PROCESS-IMAGE, V69, P69, DOI 10.1016/j.image.2018.03.006
   Li GY, 2021, IEEE T IMAGE PROCESS, V30, P1461, DOI 10.1109/TIP.2020.3044440
   Li GY, 2019, NEUROCOMPUTING, V368, P180, DOI 10.1016/j.neucom.2019.08.051
   Li J, 2020, IEEE J-STSP, V14, P38, DOI 10.1109/JSTSP.2019.2957982
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lou JX, 2022, NEUROCOMPUTING, V494, P455, DOI 10.1016/j.neucom.2022.04.080
   Luo XH, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104491
   Maugey T, 2017, IEEE INT WORKSH MULT
   Meng M, 2022, IEEE T COGN DEV SYST, V14, P414, DOI 10.1109/TCDS.2020.3044313
   Monroy R, 2018, SIGNAL PROCESS-IMAGE, V69, P26, DOI 10.1016/j.image.2018.05.005
   Ouali Yassine, 2020, P IEEECVF C COMPUTER, DOI DOI 10.1109/CVPR42600.2020.01269
   Pan JT, 2018, Arxiv, DOI arXiv:1701.01081
   Paszke A, 2019, ADV NEUR IN, V32
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Qi L, 2020, IEEE T CIRC SYST VID, V30, P2815, DOI 10.1109/TCSVT.2020.2983600
   Rai Y, 2017, PROCEEDINGS OF THE 8TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'17), P205, DOI 10.1145/3083187.3083218
   Sitzmann V, 2018, IEEE T VIS COMPUT GR, V24, P1633, DOI 10.1109/TVCG.2018.2793599
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Startsev M, 2018, SIGNAL PROCESS-IMAGE, V69, P43, DOI 10.1016/j.image.2018.03.013
   Tarvainen A, 2017, ADV NEUR IN, V30
   Tompson J, 2015, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.2015.7298664
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wan L, 2013, P 30 INT C MACH LEAR, P1058, DOI DOI 10.5555/3042817.3043055
   Wang ZQ, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104149
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie Q., 2019, P ADV NEUR INF PROC
   Zhang J, 2019, IEEE T CIRC SYST VID, V29, P212, DOI 10.1109/TCSVT.2017.2771332
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
   Zhang RP, 2023, VISUAL COMPUT, V39, P1163, DOI 10.1007/s00371-021-02395-w
   Zhao FF, 2020, IEEE T COGN DEV SYST, V12, P124, DOI 10.1109/TCDS.2019.2939024
   Zhu LC, 2022, IEEE T PATTERN ANAL, V44, P273, DOI 10.1109/TPAMI.2020.3007511
NR 59
TC 1
Z9 1
U1 3
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104590
DI 10.1016/j.imavis.2022.104590
EA DEC 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7S6FQ
UT WOS:000910848000009
DA 2024-07-18
ER

PT J
AU Liu, PF
   Guo, YH
   Tan, JB
   Wang, WB
AF Liu, Pengfei
   Guo, Yuhan
   Tan, Jiubin
   Wang, Weibo
TI Loss reweight in scale dimension: A simple while effective feature
   selection strategy for anchor-free detectors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Feature selection; Deep learning
AB Feature selection plays an important role during training in object detection and it is becoming a hotspot these years. Here we present a simple yet effective feature selection strategy called Loss Reweight in Scale Dimen-sion(LRSD) and train a single-stage anchor-free detector, termed LRD. To optimize the heuristic-guided feature selection process across FPN levels, for each instance, LRD dynamically reweights the training loss of positive samples from selected top-k feature levels by introducing a reweight function. Because of its rigorous and non-linear mathematical properties, a precise sample loss reweighting procedure across scale dimension could be done. Without adding extra meta-nets or branches, LRD improves detection performance economically without sacrificing inference speed. Moreover, our detection framework can be further improved by recently proposed transformer-based feature extraction networks such as swin-transformer. Extensive experiments show that LRD achieves 40.4% AP at a speed of 16.7 fps with ResNet-50 as the backbone and helps to improve detection per-formance by around 1.9% similar to 2.6% compared with our baseline, symbolic one-stage anchor-free detector Foveabox using ResNet-101 as the backbone. Codes are released at (https://github.com/PanffeeReal/LRSD-LRD).(c) 2022 Elsevier B.V. All rights reserved.
C1 [Liu, Pengfei; Wang, Weibo] Harbin Inst Technol, Adv Nucl & New Energy Res Inst, Harbin 150001, Peoples R China.
   [Liu, Pengfei; Tan, Jiubin; Wang, Weibo] Harbin Inst Technol, Ctr Ultraprecis Optoelect Instrument Engn, Harbin 150001, Peoples R China.
   [Liu, Pengfei; Tan, Jiubin; Wang, Weibo] Harbin Inst Technol, Minist Ind & Informat Technol, Key Lab Ultraprecis Intelligent Instrumentat, Harbin 150001, Peoples R China.
   [Guo, Yuhan] Harbin Inst Technol, Sch Management, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology; Harbin
   Institute of Technology; Harbin Institute of Technology
RP Wang, WB (corresponding author), Harbin Inst Technol, Adv Nucl & New Energy Res Inst, Harbin 150001, Peoples R China.
EM wwbhit@hit.edu.cn
FU National Natural Science Foundation of China; CGN-HIT Advanced Nuclear
   and New Energy Research Institute;  [52275527,62205090,52275526]; 
   [CGN-HIT202201]
FX Acknowledgements This work is supported by National Natural Science
   Foundation of China (52275527,62205090,52275526) , CGN-HIT Advanced
   Nuclear and New Energy Research Institute (CGN-HIT202201) .
CR [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Chen K, 2019, Arxiv, DOI arXiv:1906.07155
   Chen Qiang., 2022, P IEEECVF C COMPUTER
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fu C.-Y., 2017, arXiv
   Ge Z, 2021, PROC CVPR IEEE, P303, DOI 10.1109/CVPR46437.2021.00037
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Kim K., 2020, EUROPEAN C COMPUTER
   Kong T, 2019, Arxiv, DOI arXiv:1901.06563
   Kong T, 2020, Arxiv, DOI [arXiv:1904.03797, DOI 10.48550/ARXIV.1904.03797]
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li HD, 2020, Arxiv, DOI arXiv:1912.05086
   Li Shuai., 2022, P IEEECVF C COMPUTER
   Li X, 2021, PROC CVPR IEEE, P11627, DOI 10.1109/CVPR46437.2021.01146
   Li XL, 2020, IEEE WIREL COMMUN, V27, P116, DOI 10.1109/MWC.001.2000076
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu ST, 2021, Arxiv, DOI arXiv:2011.13677
   Liu ZC, 2021, PR MACH LEARN RES, V139
   Ma YC, 2021, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR46437.2021.00176
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Redmon Joseph, 2017, PROC IEEE C COMPUT V
   Ren S., 2021, P IEEECVF C COMPUTER
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang WX, 2021, LECT NOTES COMPUT SC, V12901, P109, DOI 10.1007/978-3-030-87193-2_11
   Wu SK, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103911
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang SJ, 2020, I S MOD ANAL SIM COM, P1, DOI 10.1109/mascots50786.2020.9285955
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang XS, 2019, ADV NEUR IN, V32
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu BJ, 2020, Arxiv, DOI arXiv:2007.03496
   Zhu CC, 2019, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2019.00093
   Zhu Chenyang, 2020, P IEEE CVF C COMP VI, P8543
NR 47
TC 4
Z9 4
U1 4
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104593
DI 10.1016/j.imavis.2022.104593
EA NOV 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500012
DA 2024-07-18
ER

PT J
AU Mishra, RK
   Urolagin, S
   Jothi, JAA
   Gaur, P
AF Mishra, Ram Krishn
   Urolagin, Siddhaling
   Jothi, J. Angel Arul
   Gaur, Pramod
TI Deep hybrid learning for facial expression binary classifications and
   predictions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional neural network; Deep neural network; Deep neural hybrid
   learning; Transfer learning
ID FEATURE-EXTRACTION
AB Image processing is a technique used for applying different operations to an image to produce an improved image or extract relevant information. Image processing has multiple applications in numerous fields, such as robotics, vision, pattern recognition, video processing, and the medical industry. One prominent application of facial rec-ognition in image processing is identifying human expression. This research examines the accuracy of categoriz-ing human facial expressions as happy or angry with deep learning and transfer learning methods such as CNN, LSTM, Inception, ResNet, VGG, Xception, and InceptionResnet. The proposed deep hybrid learning (DHL) ap-proach classifies facial expressions using transfer learning and deep neural networks. This approach emphasizes the enhancement of prediction and classification by combining multiple deep learning models to perform better than a single model. The proposed model has a testing accuracy of 81.42% and a training accuracy of 95.93% with a multisource image dataset.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Mishra, Ram Krishn; Urolagin, Siddhaling; Jothi, J. Angel Arul; Gaur, Pramod] Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai 345055, U Arab Emirates.
RP Mishra, RK (corresponding author), Birla Inst Technol & Sci Pilani, Dept Comp Sci, Dubai Campus, Dubai 345055, U Arab Emirates.
EM rkmishra@dubai.bits-pilani.ac.in
RI Mishra, Dr. Ram Krishn/AAX-2543-2021
OI Mishra, Dr. Ram Krishn/0000-0002-7384-6635
CR [Anonymous], 2005, MULTIMODAL FACIAL FE
   [Anonymous], 2017, DIFF KINDS CONV FILT, P14
   Ansari AN, 2005, PATTERN RECOGN, V38, P2549, DOI 10.1016/j.patcog.2005.04.016
   Arokia Paul Rajan R., 2019, INDONES J ELECT ENG, V7, P742, DOI [10.11591/ijeei.v7i4.935, DOI 10.11591/IJEEI.V7I4.935]
   Asogwa T.C., 2007, INT J ADV RES COMPUT, V3297, P153, DOI [10.17148/IJARCCE, DOI 10.17148/IJARCCE]
   Bakshi U., 2014, International Journal of Emerging Trends Technology in Computer Science, P233
   Chen B., 2020, BATCH NORMALIZATION
   da Silva EAB, 2005, ELECTRICAL ENGINEERING HANDBOOK, P891, DOI 10.1016/B978-012170960-0/50064-5
   Dino H., 2020, TEST ENG MANAG, V83, P22319
   Gan CQ, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104342
   Gholamalinezhad H., POOLING METHODS DEEP
   Guo XJ, 2019, Arxiv, DOI [arXiv:1902.10859, DOI 10.48550/ARXIV.1902.10859]
   Heydarian M, 2022, IEEE ACCESS, V10, P19083, DOI 10.1109/ACCESS.2022.3151048
   Kumar Purushotam, 2021, arXiv
   Kumar P, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2020.101954
   Kumar P, 2021, J AMB INTEL HUM COMP, V12, P9555, DOI 10.1007/s12652-020-02696-3
   Labach A, 2019, Arxiv, DOI [arXiv:1904.13310, DOI 10.48550/ARXIV.1904.13310]
   Li B., 2021, International Journal of Cognitive Computing in Engineering, V2, P57
   Li THS, 2019, IEEE ACCESS, V7, P93998, DOI 10.1109/ACCESS.2019.2928364
   Makhija Y, 2019, ADV INTELL SYST COMP, V741, P1189, DOI 10.1007/978-981-13-0761-4_110
   Mao LC, 2019, IEEE ACCESS, V7, P172231, DOI 10.1109/ACCESS.2019.2956508
   Melinte DO, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082393
   Mishra NK, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104290
   Nasir N, 2021, I C DEV ESYST ENG, P464, DOI [10.1109/DESE54285.2021.9719523, 10.1109/DeSE54285.2021.9719523]
   Nguyen D, 2006, IEEE T SYST MAN CY B, V36, P902, DOI 10.1109/TSMCB.2005.862728
   Nitisha R.J.S.U., 2018, FACIAL EMOTION RECOG, V632, P43
   Priyadarshini I, 2021, EARTH SCI INFORM, V14, P735, DOI 10.1007/s12145-021-00579-5
   Ravi A, 2018, Arxiv, DOI arXiv:1812.06387
   Sengar S.S., 2021, DEEP LEARNING FRAMEW, DOI [10.5281/ZENODO.4893343, DOI 10.5281/ZENODO.4893343]
   Sengar S.S., 2021, IJCAI 2021 AI4ADWORK
   Sengar SS, 2020, MULTIMED TOOLS APPL, V79, P5919, DOI 10.1007/s11042-019-08506-z
   Seo KH, 2002, ISIE 2002: PROCEEDINGS OF THE 2002 IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS, VOLS 1-4, P457, DOI 10.1109/ISIE.2002.1026332
   Shih FY, 2008, INT J PATTERN RECOGN, V22, P515, DOI 10.1142/S0218001408006296
   Shyam P., 2022, arXiv
   Song ZJ, 2021, FRONT PSYCHOL, V12, DOI 10.3389/fpsyg.2021.759485
   Suganthi SRL, 2018, PROC IEEE INT SOFT, P99
   Taskiran M, 2020, DIGIT SIGNAL PROCESS, V106, DOI 10.1016/j.dsp.2020.102809
   Thakkar Vignesh, 2018, 2018 Fifth International Conference on Emerging Applications of Information Technology (EAIT). Proceedings, DOI 10.1109/EAIT.2018.8470438
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Xu J., UNDERSTANDING IMPROV
   Zhang JH, 2020, INFORM FUSION, V59, P103, DOI 10.1016/j.inffus.2020.01.011
NR 41
TC 10
Z9 10
U1 7
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104573
DI 10.1016/j.imavis.2022.104573
EA OCT 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6A7AA
UT WOS:000880802600001
DA 2024-07-18
ER

PT J
AU Chen, YQ
   Yu, XM
   Liu, S
   Gao, W
   Li, G
AF Chen, Yuanqi
   Yu, Xiaoming
   Liu, Shan
   Gao, Wei
   Li, Ge
TI Zero-shot unsupervised image-to-image translation via exploiting
   semantic attributes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image -to-image translation; Image synthesis; Zero-shot learning;
   Generative adversarial networks
ID GENERATIVE ADVERSARIAL NETWORKS; GAN; CLASSIFICATION
AB Recent studies have shown remarkable success in unsupervised image-to-image translation. However, if there is no access to enough images in target classes, learning a mapping from source classes to the target classes always suffers from mode collapse, especially the zero shot case, which limits the application of the existing methods. In this work, we propose a zero-shot unsupervised image-to-image translation framework to address this limita-tion, by effectively associating categories with their side information like attributes. To generalize the translator to previously unseen classes, we introduce two strategies for exploiting the semantic attribute space. First, we propose to preserve semantic relations to the visual space for effective guidance on where to map the input image. Second, expanding attribute space is introduced by utilizing attribute vectors of unseen classes, which al-leviates the mapping bias for unseen classes. Both of these strategies encourage the translator to explore the modes of unseen classes. Quantitative and qualitative results on different datasets validate the effectiveness of our proposed approach. Moreover, we demonstrate that our framework can be applied to fashion design task. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Chen, Yuanqi; Yu, Xiaoming; Gao, Wei; Li, Ge] Peking Univ, Sch Elect & Comp Engn, Shenzhen Grad Sch, Shenzhen 518055, Peoples R China.
   [Chen, Yuanqi; Yu, Xiaoming; Gao, Wei] Peng Cheng Lab, Shenzhen 518055, Peoples R China.
   [Liu, Shan] Tencent Inc, Shenzhen 518000, Peoples R China.
C3 Peking University; Peng Cheng Laboratory; Tencent
RP Li, G (corresponding author), Peking Univ, Sch Elect & Comp Engn, Shenzhen Grad Sch, Shenzhen 518055, Peoples R China.
EM geli@ece.pku.edu.cn
OI Chen, Yuanqi/0000-0003-1089-1313
FU National Key R&D Program of China [2020AAA0103501]
FX Acknowledgement This work was supported by National Key R&D Program of
   China (No. 2020AAA0103501) .
CR Ali-Gombe A, 2019, NEUROCOMPUTING, V361, P212, DOI 10.1016/j.neucom.2019.06.043
   Annadani Y, 2018, PROC CVPR IEEE, P7603, DOI 10.1109/CVPR.2018.00793
   Benaim L., P 31 INT C NEUR INF, P752
   Benaim S, 2018, ADV NEUR IN, V31
   Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Hensel M, 2017, ADV NEUR IN, V30
   Hong S., 2019, ICLR, P1
   Huang H, 2019, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2019.00089
   Huang XW, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS, TECHNOLOGIES AND APPLICATIONS (ICTA 2018), P172, DOI 10.1109/CICTA.2018.8706048
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Joseph K., 2018, ICML WORKSHOP
   Kim H, 2020, NEUROCOMPUTING, V411, P67, DOI 10.1016/j.neucom.2020.05.043
   Kim T, 2017, PR MACH LEARN RES, V70
   Kingma D. P., 2014, arXiv
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lample Guillaume, 2017, P ANN C NEUR INF PRO, P5967
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li X, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104077
   Lin JX, 2021, NEUROCOMPUTING, V461, P327, DOI 10.1016/j.neucom.2021.07.037
   Liu AH, 2018, ADV NEUR IN, V31
   Liu LL, 2019, NEUROCOMPUTING, V341, P156, DOI 10.1016/j.neucom.2019.03.011
   Liu MY, 2019, IEEE I CONF COMP VIS, P10550, DOI 10.1109/ICCV.2019.01065
   Liu ZZ, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103924
   Lu BY, 2019, PROC CVPR IEEE, P10217, DOI 10.1109/CVPR.2019.01047
   Mao Q, 2019, PROC CVPR IEEE, P1429, DOI 10.1109/CVPR.2019.00152
   Mariani G., 2018, Bagan: Data augmentation with balancing gan
   Mescheder L, 2018, PR MACH LEARN RES, V80
   Miyato T., 2018, INT C LEARN REPR ICL, P1
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Ouyang Y, 2019, IMAGE VISION COMPUT, V88, P113, DOI 10.1016/j.imavis.2019.05.007
   Radford Alec, 2015, arXiv preprint
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Romera-Paredes Bernardino, 2015, ICML
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Singh KK, 2019, PROC CVPR IEEE, P6483, DOI 10.1109/CVPR.2019.00665
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Verma VK, 2018, PROC CVPR IEEE, P4281, DOI 10.1109/CVPR.2018.00450
   Wah Catherine, 2011, Technical report
   Wu PW, 2019, IEEE I CONF COMP VIS, P5913, DOI 10.1109/ICCV.2019.00601
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Yu X., 2018, ASIAN C COMPUTER VIS, P341
   Yu Xiaoming, 2019, P ADV NEUR INF PROC, P2990
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhu JY, 2017, ADV NEUR IN, V30
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2016, LECT NOTES COMPUT SC, V9909, P597, DOI 10.1007/978-3-319-46454-1_36
NR 56
TC 1
Z9 1
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104489
DI 10.1016/j.imavis.2022.104489
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800011
DA 2024-07-18
ER

PT J
AU Qu, Z
   Gao, LY
   Wang, SY
   Yin, HN
   Yi, TM
AF Qu, Zhong
   Gao, Le-yuan
   Wang, Sheng-ye
   Yin, Hao-nan
   Yi, Tu-ming
TI An improved YOLOv5 method for large objects detection with multi-scale
   feature cross-layer fusion network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Feature extraction; Feature fusion; K-means;
   Autoanchor mechanism
ID CONVOLUTIONAL NETWORKS
AB SSD and YOLOv5 are the one-stage object detector representative algorithms. An improved one-stage object de-tector based on the YOLOv5 method is proposed in this paper, named Multi-scale Feature Cross-layer Fusion Net-work (M-FCFN). Firstly, we extract shallow features and deep features from the PANet structure for cross-layer fusion and obtain a feature scale different from 80 x 80, 40 x 40, and 20 x 20 as output. Then, according to the single shot multi-box detector, we propose the different scale features which are obtained by cross-layer fusion for dimension reduction and use it as another output for prediction. Therefore, two completely different feature scales are added as the output. Features of different scales are necessary for detecting objects of different sizes, which can increase the probability of object detection and significantly improve detection accuracy. Finally, aiming at the Autoanchor mechanism proposed by YOLOv5, we propose an EIOU k-means calculation. We have compared the four model structures of S, M, L, and X of YOLOv5 respectively. The problem of missed and false de-tections for large objects is improved which has better detection results. The experimental results show that our methods achieve 89.1% and 67.8% mAP@0.5 on the PASCAL VOC and MS COCO datasets. Compared with the YOLOv5_S, our methods improve by 4.4% and 1.4% mAP@ [0.5:0.95] on the PASCAL VOC and MS COCO datasets. Compared with the four models of YOLOv5, our methods have better detection accuracy for large objects. It should be more attention that our method on the large-scale mAP@ [0.5:0.95] is 5.4% higher than YOLOv5_S on the MS COCO datasets. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Qu, Zhong; Gao, Le-yuan; Wang, Sheng-ye; Yin, Hao-nan] Chongqing Univ Posts & Telecommun, Sch Software Engn, Chongqing 400065, Peoples R China.
   [Yi, Tu-ming] Southwest Comp Co Ltd, Inst Informat Technol, Chongqing 400060, Peoples R China.
C3 Chongqing University of Posts & Telecommunications
RP Qu, Z (corresponding author), Chongqing Univ Posts & Telecommun, Sch Software Engn, Chongqing 400065, Peoples R China.
EM quzhong@cqupt.edu.cn
RI zhang, jt/JVE-1333-2024
FU National Natural Science Foundation of China [62176034]
FX Acknowledgements This work is supported by the National Natural Science
   Foundation of China under Grant 62176034.
CR Amudhan AN, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104396
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Aziz L, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104287
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cao JL, 2019, IEEE I CONF COMP VIS, P9704, DOI 10.1109/ICCV.2019.00980
   Chai EH, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104317
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Dai JF, 2016, ADV NEUR IN, V29
   Fu C.-Y., 2017, DSSD: Deconvolutional Single Shot Detector
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Jeong J, 2017, IEEE INT C COMP VIS, DOI 10.5244/C.31.76
   Jocher G., 2021, YOLOV5
   Kim SW, 2018, LECT NOTES COMPUT SC, V11209, P239, DOI 10.1007/978-3-030-01228-1_15
   Li Z., 2017, CORR
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu YR, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104368
   Loshchilov Ilya, 2016, arXiv
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Paszke A., 2017, PROC 31 INT C NEURAL
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren W., 2021, P IEEE C COMPUTER VI
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang JF, 2021, PROC CVPR IEEE, P15844, DOI 10.1109/CVPR46437.2021.01559
   Yi JR, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102827
   Yu J.H., 2016, arXiv
   Zhang J, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104337
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang Z, 2019, Arxiv, DOI arXiv:1902.04103
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zheng G., 2021, arXiv
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 44
TC 27
Z9 27
U1 11
U2 155
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2022
VL 125
AR 104518
DI 10.1016/j.imavis.2022.104518
EA JUL 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3Y7JW
UT WOS:000843898700004
DA 2024-07-18
ER

PT J
AU Liang, YH
   Qin, GH
   Sun, MH
   Qin, J
   Yan, J
   Zhang, ZH
AF Liang, Yanhua
   Qin, Guihe
   Sun, Minghui
   Qin, Jun
   Yan, Jie
   Zhang, Zhonghan
TI Dual guidance enhanced network for light field salient object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Light field; Salient object detection; Convolutional neural network;
   Hierarchical interaction; Boundary-guided semantic accumulation
ID ATTENTION
AB Saliency detection models using light field data as input have not been thoroughly explored. Existing deep sa-liency models usually treat multi-focus images as independent information and extract their features separately, which may be cumbersome and over-rely on well-designed network structure. Besides, they do not fully explore the cross-modal complementarity and cross-level continuity of information, and rarely consider edge cues. Based on the above observations, in this paper, we investigate a novel Dual Guidance Enhanced Network (DGENet), which considers both spatial content and explicit boundary cues. Specifically, DGENet contains two key modules, i.e., the recurrent global-guided focus module (RGFM) and the boundary-guided semantic accumulation module (BSAM). These two modules are composed of multiple units, and the units in each module are not independent of each other. RGFM is used to distill out effective squeezed information of focal slices and RGB images between dif-ferent levels. The learned global context features guide the network to focus on the salient region via a progres-sive reverse attention-driven strategy. Furthermore, BSAM introduces salient edge features to guide the accumulation of salient object features to generate salient maps with sharp boundaries. Extensive experiments on three challenging light field datasets demonstrate that our DGENet is superior to cutting-edge 2D, 3D and 4D methods.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Liang, Yanhua; Qin, Guihe; Sun, Minghui; Yan, Jie; Zhang, Zhonghan] Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
   [Liang, Yanhua; Qin, Guihe; Sun, Minghui; Yan, Jie; Zhang, Zhonghan] Jilin Univ, Minist Educ, Key Lab Symbol Computat & Knowledge Engn, Changchun 130012, Peoples R China.
   [Qin, Jun] Changchun Univ Sci & Technol, Sch Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Jilin University; Jilin University; Changchun University of Science &
   Technology
RP Qin, GH; Sun, MH (corresponding author), Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
EM qingh@jlu.edu.cn; smh@jlu.edu.cn
RI yan, jy/ISS-1790-2023; yan, jie/HNJ-0097-2023
FU National Natural Science Founda-tion of China [61872164]
FX Acknowledgements This research is supported by the National Natural
   Science Founda-tion of China under Grant (No. 61872164) .
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen X., 2021, IMAGE VISION COMPUT, V110, P1
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Congcong Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P481, DOI 10.1007/978-3-030-58601-0_29
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Fan D.-P., MICCAI2020
   Fan DP, 2020, PROC CVPR IEEE, P2774, DOI 10.1109/CVPR42600.2020.00285
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Guanghai Liu, 2013, 2013 International Conference on Information Science and Cloud Computing Companion (ISCC-C), P728, DOI 10.1109/ISCC-C.2013.21
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Hou Qibin, 2021, CVPR
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang Y., 2021, ARXIV201004968V3
   Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Li Z, 2021, IEEE T IMAGE PROCESS, V30, P4587, DOI 10.1109/TIP.2021.3072811
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Piao YR, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P904
   Piao YR, 2020, AAAI CONF ARTIF INTE, V34, P11865
   Piao YR, 2020, IEEE T IMAGE PROCESS, V29, P1879, DOI 10.1109/TIP.2019.2942434
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Schilling H, 2018, PROC CVPR IEEE, P4530, DOI 10.1109/CVPR.2018.00476
   Shao L, 2006, PATTERN RECOGN, V39, P1932, DOI 10.1016/j.patcog.2006.04.010
   Sheng H, 2016, INT CONF ACOUST SPEE, P1631, DOI 10.1109/ICASSP.2016.7471953
   Shi C., 2021, IMAGE VISION COMPUT, V107, P1
   Shi XJ, 2015, ADV NEUR IN, V28
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Song HM, 2018, LECT NOTES COMPUT SC, V11215, P744, DOI 10.1007/978-3-030-01252-6_44
   Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984
   Wang AZ, 2017, NEURAL PROCESS LETT, V46, P1083, DOI 10.1007/s11063-017-9610-x
   Wang HQ, 2018, MULTIMED TOOLS APPL, V77, P14655, DOI 10.1007/s11042-017-5052-8
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang TT, 2019, IEEE I CONF COMP VIS, P8837, DOI 10.1109/ICCV.2019.00893
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang XW, 2022, MECH BASED DES STRUC, V50, P331, DOI 10.1080/15397734.2020.1717342
   Wang Z., 2021, IMAGE VISION COMPUT, V113, P1
   Wei J., 2020, P ASS ADV ART INT AA
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Yeung H. W. F., 2018, P EUR C COMP VIS, P137
   Yeung HWF, 2019, IEEE T IMAGE PROCESS, V28, P2319, DOI 10.1109/TIP.2018.2885236
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P4421, DOI 10.1109/TIP.2020.2970529
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zhang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2212
   Zhang M., 2019, P ADV NEURAL INFORM
   Zhang M, 2020, IEEE T IMAGE PROCESS, V29, P6276, DOI 10.1109/TIP.2020.2990341
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang Q., 2020, IEEE T CIRC SYST VID
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
NR 65
TC 4
Z9 5
U1 3
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2022
VL 118
AR 104352
DI 10.1016/j.imavis.2021.104352
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0F3OZ
UT WOS:000777273700005
DA 2024-07-18
ER

PT J
AU Tang, Q
   Liu, FG
   Zhang, T
   Jiang, J
   Zhang, Y
AF Tang, Quan
   Liu, Fagui
   Zhang, Tong
   Jiang, Jun
   Zhang, Yu
TI Attention-guided chained context aggregation for semantic segmentation*
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic segmentation; Multi-scale contexts; Series-parallel hybrid
   streams; Convolutional networks
ID NETWORK; MODEL
AB The way features propagate in Fully Convolutional Networks is of momentous importance to capture multi-scale contexts for obtaining precise segmentation masks. This paper proposes a novel series-parallel hybrid paradigm called the Chained Context Aggregation Module (CAM) to enrich feature representation. CAM gains features of various spatial scales through chain-connected ladder-style information flows and fuses them ina two-stage pro-cess, namely pre-fusion and re-fusion. The serial flow continuously increases receptive fields of output neurons and those in parallel encode different region-based contexts. Each information flow is a shallow encoder-decoder with appropriate down-sampling scales to sufficiently capture contextual information. We further adopt an attention model in CAM to guide feature re-fusion. Based on these developments, we construct the Chained Context Aggregation Network (CANet), which employs an asymmetric decoder to recover precise spatial details of prediction maps. We conduct extensive experiments on six challenging datasets, including Pascal VOC 2012, Pascal Context, Cityscapes, CamVid, SUN-RGBD and GATECH. Results evidence that CANet achieves state -of-the-art or competitive performance. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Tang, Quan; Liu, Fagui; Zhang, Tong; Jiang, Jun; Zhang, Yu] South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Zhang, Tong] Pazhou Lab, Guangzhou 510335, Peoples R China.
C3 South China University of Technology; Pazhou Lab
RP Liu, FG (corresponding author), South China Univ Technol, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM csquantang@mail.scut.edu.cn; fgliu@scut.edu.cn; tony@scut.edu.cn;
   junjiangscut@mail.com; csemoszy@mail.scut.edu.cn
RI Zhang, tong/IAP-2587-2023
OI Tang, Quan/0000-0003-4011-6166; Zhang, Yu/0000-0001-8034-5305; Liu,
   Fagui/0000-0003-1135-4982; Jiang, Jun/0000-0002-8406-994X
FU Guangdong Major Project of Basic and Applied Basic Research
   [2019B030302002]; Science and Technology Major Project of Guangzhou
   [202007030006]; Industrial Development Fund Project of Guangzhou
   [x2jsD8183470]; Engineering and Technology Research Center of Guangdong
   Province for Logistics Supply Chain and Internet of Things [GDDST [2016]
   176]; Hi-Tech Industrialization Entrepreneurial Team Project of Foshan
   Hi-Tech Zone [FSHT [2020] 88]; National Key Research and Development
   Program of China [2019YFA0706200, 2019YFB1703600]; National Natural
   Science Foundation of China [62076102, U1813203, U1801262]; National
   Natural Science Foundation of Guangdong for Distinguished Young Scholar
   [2020B1515020041]; Science and Technology Program of Guangzhou
   [202002030250]; Program for Guangdong Introducing Innovative and
   Enterpreneurial Teams [2019ZT08X214]; Guangdong-Hong Kong-Macao Greater
   Bay Area Center for Brain Science and Brain-Inspired Intelligence Fund
   [2019016]
FX This work was supported in part by the Guangdong Major Project of Basic
   and Applied Basic Research under Grant 2019B030302002, in part by the
   Science and Technology Major Project of Guangzhou under Grant
   202007030006, in part by the Industrial Development Fund Project of
   Guangzhou under Project x2jsD8183470, in part by the Engineering and
   Technology Research Center of Guangdong Province for Logistics Supply
   Chain and Internet of Things under Grant GDDST [2016] 176, in part by
   the Hi-Tech Industrialization Entrepreneurial Team Project of Foshan
   Hi-Tech Zone under Grant FSHT [2020] 88, in part by the National Key
   Research and Development Program of China under number 2019YFA0706200
   and 2019YFB1703600, in part by the National Natural Science Foundation
   of China grant under number 62076102, U1813203, and U1801262, in part by
   the National Natural Science Foundation of Guangdong for Distinguished
   Young Scholar under number 2020B1515020041, in part by the Science and
   Technology Program of Guangzhou under number 202002030250, in part by
   The Program for Guangdong Introducing Innovative and Enterpreneurial
   Teams (2019ZT08X214) , and in part by Guangdong-Hong Kong-Macao Greater
   Bay Area Center for Brain Science and Brain-Inspired Intelligence Fund
   (NO. 2019016) .
CR [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Brostow GJ, 2009, PATTERN RECOGN LETT, V30, P88, DOI 10.1016/j.patrec.2008.04.005
   Changqian Yu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12413, DOI 10.1109/CVPR42600.2020.01243
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen Tianqi, 2015, R package version 0.4-2 1.4, V1, P1
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Ding HH, 2019, IEEE I CONF COMP VIS, P6818, DOI 10.1109/ICCV.2019.00692
   Ding HH, 2018, PROC CVPR IEEE, P2393, DOI 10.1109/CVPR.2018.00254
   Fan H, 2018, IEEE T INTELL TRANSP, V19, P3475, DOI 10.1109/TITS.2017.2775628
   Fu J., 2019, P IEEE CVF C COMP VI
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu J, 2017, IEEE IMAGE PROC, P3085, DOI 10.1109/ICIP.2017.8296850
   Hariharan B, 2015, PROC CVPR IEEE, P447, DOI 10.1109/CVPR.2015.7298642
   He JJ, 2019, PROC CVPR IEEE, P7511, DOI 10.1109/CVPR.2019.00770
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2019, PROC CVPR IEEE, P558, DOI 10.1109/CVPR.2019.00065
   Hou QB, 2020, PROC CVPR IEEE, P4002, DOI 10.1109/CVPR42600.2020.00406
   Howard A. G., 2017, PREPRINT
   Hu J., P IEEE C COMPUTER VI, P7132
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Li H., 2019, P IEEE CVF C COMP VI, P9522, DOI [DOI 10.1109/CVPR.2019.00975, 10.1109/CVPR.2019.00975]
   Li XT, 2020, AAAI CONF ARTIF INTE, V34, P11418
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W., 2015, ARXIV150604579
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Nazir A, 2020, IEEE T IMAGE PROCESS, V29, P7192, DOI 10.1109/TIP.2020.2999854
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Pang YW, 2019, IEEE I CONF COMP VIS, P4229, DOI 10.1109/ICCV.2019.00433
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Raza SH, 2013, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2013.396
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Siam M, 2018, IEEE COMPUT SOC CONF, P700, DOI 10.1109/CVPRW.2018.00101
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Tang Q, 2022, IEEE T INTELL TRANSP, V23, P7008, DOI 10.1109/TITS.2021.3066401
   Tian Z, 2019, PROC CVPR IEEE, P3121, DOI 10.1109/CVPR.2019.00324
   Tran D, 2016, IEEE COMPUT SOC CONF, P402, DOI 10.1109/CVPRW.2016.57
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang J., 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00584
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yu CQ, 2018, PROC CVPR IEEE, P1857, DOI 10.1109/CVPR.2018.00199
   Yu F., 2015, ARXIV
   Zha S., ARXIV190704433, V2019
   Zhang F, 2019, IEEE I CONF COMP VIS, P6797, DOI 10.1109/ICCV.2019.00690
   Zhang H, 2019, PROC CVPR IEEE, P548, DOI 10.1109/CVPR.2019.00064
   Zhang H, 2018, PROC CVPR IEEE, P7151, DOI 10.1109/CVPR.2018.00747
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng SX, 2021, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR46437.2021.00681
   Zhou B., 2014, Adv Neural Inf Proces Syst27
   Zhou Q, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106682
   Zhou Q, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-019-2685-1
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 66
TC 14
Z9 15
U1 2
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104309
DI 10.1016/j.imavis.2021.104309
EA SEP 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WB1NI
UT WOS:000703345700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gu, HY
   Fu, GY
   Wang, X
   Zhu, J
AF Gu, Hongyang
   Fu, Guangyuan
   Wang, Xu
   Zhu, Jun
TI Learning auto-scale representations for person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Auto-scale learning; Neural architecture
   search; AutoML
ID NETWORK
AB Person re-identification (ReID) isa hot topic in computer vision. The data in the ReID is often collected from the cameras with different views and is affected by other environmental factors, which poses a significant challenge to ReID. The omni-scales proposed by OSNet can extract discriminative feature representations, which shows that omni-scales are adequate for the task of the ReID. However, the OSNet is mainly based on a manually de-signed network architecture. In the OSnet, each block uses the same architecture and has only four scale feature representations. Inspired by neural network architecture search (NAS), we propose a method of auto-scale rep-resentations for ReID. Specifically, we first design the auto-scale block, mainly composed of the Lite 3 & times; 3 oper-ations and the RCB 1 & times; 1 operations. The connection status among the Lite 3 & times; 3 operations is just our search space. Then we give our entire macro network architecture, the auto-scale network, which is mainly composed of 6 auto-scale blocks. Unlike other NAS-related work, each block in our search space does not need to share the same architecture but can maintain a different architecture. In the search process, we propose the entropy regu-larization, the validity regularization and the consistent regularization to alleviate the discretized gap, no valid path, and meaningless edges, respectively. Finally, we verify the effectiveness of the model we searched on four commonly used datasets. Our model can maintain the same 2.2 M parameters as OSNet but can achieve the performance of SOTA. The mAP on the Market1501 dataset can reach 88.7%. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Gu, Hongyang; Fu, Guangyuan; Wang, Xu] Xian Res Inst High Technol, Xian 710025, Shaanxi, Peoples R China.
   [Gu, Hongyang; Zhu, Jun] Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
C3 Rocket Force University of Engineering; Tsinghua University
RP Gu, HY (corresponding author), Xian Res Inst High Technol, Xian 710025, Shaanxi, Peoples R China.; Gu, HY (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM guhy18@mails.tsinghua.edu.cn
CR [Anonymous], 2017, 5 INT C LEARN REPR I
   Bender G, 2018, INT C MACH LEARN STO, P549
   Brock A., 2018, 6 INT C LEARN REPR I
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Ge YX, 2018, ADV NEUR IN, V31
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans A., ARXIV PREPRINT ARXIV
   Hou R., P IEEE C COMP VIS PA, P9317
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liu H., 2019, 7 INT C LEARN REPR I
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Luo WJ, 2016, ADV NEUR IN, V29
   Pham H, 2018, PR MACH LEARN RES, V80
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen YT, 2018, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2018.00241
   Shen YT, 2018, PROC CVPR IEEE, P6886, DOI 10.1109/CVPR.2018.00720
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wang YC, 2018, PROC CVPR IEEE, P1470, DOI 10.1109/CVPR.2018.00159
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Yu R, 2018, LECT NOTES COMPUT SC, V11220, P196, DOI 10.1007/978-3-030-01270-0_12
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 49
TC 2
Z9 2
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104241
DI 10.1016/j.imavis.2021.104241
EA JUL 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100010
DA 2024-07-18
ER

PT J
AU Sun, N
   Leng, L
   Liu, JX
   Han, G
AF Sun, Ning
   Leng, Ling
   Liu, Jixin
   Han, Guang
TI Multi-stream slowFast graph convolutional networks for skeleton-based
   action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Graph convolutional network; Human skeleton;
   SlowFast network; Attention
AB Recently, many efforts have been made to model spatial-temporal features from human skeleton for action recognition by using graph convolutional networks (GCN). Skeleton sequence can precisely represent human pose with a small number of joints while there is still a lot of redundancies across the skeleton sequence in the term of temporal dependency. In order to improve the effectiveness of spatial-temporal feature extraction from skeleton sequence, a SlowFast graph convolution network (SF-GCN) is proposed by implementing the architecture of SlowFast network, which is consisted of the Fast and Slow pathway, in the GCN model. The Fast pathway is a temporal attention embedded lightweight GCN for extracting the feature of fast temporal changes from the skeleton sequence with a high frame rate and fast refreshing speed. The Slow pathway is a spatial attention embedded GCN for extracting the feature of slow temporal changes from the skeleton sequence with a low frame rate and slow refreshing speed. The features of two pathways are fused by using lateral connection and weighted by using channel attention. Based on the aforementioned design, SF-GCN can achieve superior ability of feature extraction while the computational cost significantly drops. In addition to the coordinate information of joints, five high order sequences including edge, the spatial difference and temporal difference of joints and edges are induced to enhance the representation of human action. Six SF-GCNs are implemented for extracting spatial- temporal feature from six kinds of sequences and fused for skeleton-based action recognition, which is called multi-stream SlowFast graph convolutional networks (MSSF-GCN). Extensive experiments are conducted to evaluate the proposed method on three skeleton-based action recognition databases including NTU RGB + D, NTU RGB + D 120, and Skeleton-Kinetics. The results show that the proposed method is effective for skeleton based action recognition and can achieve the recognition accuracy with an obvious advantage in comparison with the state-of-the-art.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Sun, Ning; Liu, Jixin; Han, Guang] Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing 210003, Peoples R China.
   [Leng, Ling] Nanjing Univ Posts & Telecommun, Coll Commun & Informat Engn, Nanjing 210003, Peoples R China.
C3 Nanjing University of Posts & Telecommunications; Nanjing University of
   Posts & Telecommunications
RP Sun, N (corresponding author), Nanjing Univ Posts & Telecommun, Engn Res Ctr Wideband Wireless Commun Technol, Minist Educ, Nanjing 210003, Peoples R China.
EM sunning@njupt.edu.cn
RI LIU, Jixin/AHC-0596-2022
FU National Natural Science Foundation of China [61471206, 61871445];
   Natural Science Foundation of Jiangsu Province [BK20180088]; Scientific
   Research Foundation of Nanjing University of Posts and
   Telecommunications [NY218066]
FX This work was supported by the National Natural Science Foundation of
   China (Grant Nos. 61471206, 61871445) and the Natural Science Foundation
   of Jiangsu Province (Grant No. BK20180088) , and the Scientific Research
   Foundation of Nanjing University of Posts and Telecommunications (Grant
   No. NY218066) .
CR [Anonymous], 2017, KINETICS HUMAN ACTIO
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Bottou L, 2018, SIAM REV, V60, P223, DOI 10.1137/16M1080173
   Bruna J., 2013, INT C LEARNING REPRE
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Cheng K, 2020, PROC CVPR IEEE, P180, DOI 10.1109/CVPR42600.2020.00026
   Ding W., 2020, SIGNAL PROCESS IMAGE, V83, P115776
   Fan YB, 2020, IEEE ACCESS, V8, P15280, DOI 10.1109/ACCESS.2020.2968054
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gao X, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P601, DOI 10.1145/3343031.3351170
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Ke QH, 2018, IEEE T IMAGE PROCESS, V27, P2842, DOI 10.1109/TIP.2018.2812099
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Kipf TN, 2016, ARXIV
   LeCun Y., 2015, PREPRINT
   Li B, 2019, AAAI CONF ARTIF INTE, P8561
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu MY, 2017, PATTERN RECOGN, V68, P346, DOI 10.1016/j.patcog.2017.02.030
   Liu RN, 2020, IEEE T IND INFORM, V16, P87, DOI 10.1109/TII.2019.2915536
   Liu YS, 2019, EURASIP J WIREL COMM, DOI 10.1186/s13638-019-1419-z
   Meng FY, 2019, IEEE T IMAGE PROCESS, V28, P5281, DOI 10.1109/TIP.2019.2913544
   Naveenkumar M, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107125
   Niepert M, 2016, PR MACH LEARN RES, V48
   Papadopoulos K., 2019, ARXIV191209745
   Patrona F, 2018, PATTERN RECOGN, V76, P612, DOI 10.1016/j.patcog.2017.12.007
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Simonyan K, 2014, ADV NEUR IN, V27
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Wang HS, 2018, IEEE T IMAGE PROCESS, V27, P4382, DOI 10.1109/TIP.2018.2837386
   Wu BC, 2018, PROC CVPR IEEE, P9127, DOI 10.1109/CVPR.2018.00951
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Zhang Pengfei, 2019, ABS190401189 CORR
   Zhang XK, 2020, IEEE T NEUR NET LEAR, V31, P3047, DOI 10.1109/TNNLS.2019.2935173
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
NR 41
TC 20
Z9 20
U1 3
U2 42
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104141
DI 10.1016/j.imavis.2021.104141
EA MAR 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600012
DA 2024-07-18
ER

PT J
AU Li, X
   Fang, M
   Li, HK
AF Li, Xiao
   Fang, Min
   Li, Haikun
TI Bias alleviating generative adversarial network for generalized
   zero-shot classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Generalized zero shot classification; Generative adversarial network;
   Unseen visual prototypes; Cluster centers; Semantic relationships
AB Generalized zero-shot classification is predicting the labels of the test images coming from seen or unseen classes. The task is difficult because of the bias problem, that is, unseen samples are easily to be misclassified to seen classes. Many methods have handled the problem by training a generative adversarial network (GAN) to generate fake samples. However, the GAN model trained with seen samples might not be appropriate for generating unseen samples. For dealing with this problem, we learn a bias alleviating generative adversarial network for generalized zero-shot classification by generating seen and unseen samples, simultaneously. We train the generator to generate more realistic unseen samples by adding semantic similarity and cluster center regularizations to alleviate the bias problem. The semantic similarity regularization is to restrict the relationships of the generated unseen visual prototypes and seen visual prototypes by their class prototypes to avoid the generated unseen samples similar to the seen samples. The cluster center regularization is to utilize the cluster property of target data to make the generated unseen visual prototypes near to the most similar cluster centers, generating realistic unseen samples. From the experiments, we can see the proposed method achieves promising results. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Li, Xiao; Fang, Min; Li, Haikun] Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
C3 Xidian University
RP Fang, M (corresponding author), Xidian Univ, Sch Comp Sci & Technol, Xian 710071, Peoples R China.
EM mfang@mail.xidian.edu.cn
RI li, haikun/ADY-7816-2022
OI li, haikun/0000-0003-3827-6910
FU National Natural Science Foundation of China [61806155]; China
   Postdoctoral Science Foundation [2018M631125]; Fundamental Research
   Funds for the Central Universities [XJS200303]; National Natural Science
   Foundation of shaanxi province [2020JQ-323, 2020GY-062]; Nature Science
   Foundation of Anhui Province [1908085MF186]
FX This work is supported by National Natural Science Foundation of China
   under Grant no. 61806155, China Postdoctoral Science Foundation funded
   project under Grant no. 2018M631125, Fundamental Research Funds for the
   Central Universities under Grant no. XJS200303, National Natural Science
   Foundation of shaanxi province (Grant No. 2020JQ-323, 2020GY-062),
   Nature Science Foundation of Anhui Province under Grant no.
   1908085MF186.
CR Akata Zeynep, 2013, NIPS WORKSH OUTP REP
   [Anonymous], 2018, ECCV
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, ARXIV170400028CSLG
   Atzmon Y, 2019, PROC CVPR IEEE, P11663, DOI 10.1109/CVPR.2019.01194
   Changpinyo S, 2017, IEEE I CONF COMP VIS, P3496, DOI 10.1109/ICCV.2017.376
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4
   Ding ZM, 2017, PROC CVPR IEEE, P6005, DOI 10.1109/CVPR.2017.636
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Felix R, 2018, LECT NOTES COMPUT SC, V11210, P21, DOI 10.1007/978-3-030-01231-1_2
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Huang H, 2019, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2019.00089
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Li JJ, 2019, PROC CVPR IEEE, P7394, DOI 10.1109/CVPR.2019.00758
   Li X, 2018, KNOWL-BASED SYST, V160, P176, DOI 10.1016/j.knosys.2018.06.034
   Li X, 2017, NEUROCOMPUTING, V238, P76, DOI 10.1016/j.neucom.2017.01.038
   Liu SC, 2018, ADV NEUR IN, V31
   Liu ZZ, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103924
   Long Y, 2018, IEEE T PATTERN ANAL, V40, P2498, DOI 10.1109/TPAMI.2017.2762295
   Ni Jian, 2019, NEURIPS
   Norouzi M., 2014, P INT C LEARN REPR
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Paul A, 2019, PROC CVPR IEEE, P7049, DOI 10.1109/CVPR.2019.00722
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Schönfeld E, 2019, PROC CVPR IEEE, P8239, DOI 10.1109/CVPR.2019.00844
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Socher R., 2013, P 2013 C EMP METH NA, V2013, P1631, DOI DOI 10.1371/JOURNAL.PONE.0073791
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang DH, 2016, AAAI CONF ARTIF INTE, P2145
   Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xian Yongqin, 2018, PAMI
   Xu X, 2017, PROC CVPR IEEE, P2007, DOI 10.1109/CVPR.2017.217
   Yu Yunlong, 2018, IEEE T CYBERNETICS
   Zhang F., 2019, INT C MACHINE LEARNI, P7434
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhu Y., 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00111
NR 46
TC 6
Z9 6
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104077
DI 10.1016/j.imavis.2020.104077
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800011
DA 2024-07-18
ER

PT J
AU Wang, WH
AF Wang, Wenhao
TI Detection of panoramic vision pedestrian based on deep learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pedestrian detection; Panoramic vision; Switchable normalization;
   Convolutional neural networks; Deep learning
AB As the AI (artificial intelligence) develops, driverless vehicle technology is widely concerned, and the important problemthat needs to be solved in driverless technology is the detection of pedestrians in the panoramic vision of the vehicle, so the pedestrian detection technology of panoramic vision is explored based on the deep learning. Recently, anchor-free and one-stage detectors have been introduced into this area. However, their accuracies are unsatisfactory. Therefore, in order to enjoy the simplicity of anchor-free detectors and the accuracy of twostage ones simultaneously, someadaptations based on a detector, CSP (center and scale prediction) are proposed. The original CSP of pedestrian detector is improved to make the training process more robust. For example, we use SN layers to replace all BN layers and ResNet-101 is used as backbone based on the research of deep learning. Themain contributions of our paper are: (1) we improve the robustness of CSP andmake it easier to train. (2) we propose a novel method to predict width, namely compressing width. (3) we achieve the second best performance on CityPersons benchmark, i.e. 9.3% log-average miss rate (MR) on reasonable set, 8.7% MR on partial set and 5.6% MR on bare set, which shows an anchor-free and one-stage detector can still have high accuracy. (4) we explore some capabilities of switchable normalization which are not mentioned in its original paper. This study will provide important theoretical support and practical basis for pedestrian detection (c) 2020 Elsevier B.V. All rights reserved.
C1 [Wang, Wenhao] Beihang Univ, Sch Math Sci SMS, Beijing, Peoples R China.
C3 Beihang University
RP Wang, WH (corresponding author), Beihang Univ, Sch Math Sci SMS, Beijing, Peoples R China.
EM wangwenhao@buaa.edu.cn
FU School of Mathematical Sciences, Beihang University
FX We thank Informatization Office of Beihang University for the supply of
   High Performance Computing Platform, which have 32 Nvidia Tesla V100
   GPUs. This work is also supported by School of Mathematical Sciences,
   Beihang University.
CR [Anonymous], 2019, CORR
   [Anonymous], 2015, DENSEBOX UNIFYING LA
   [Anonymous], 2014, ARXIV14061134
   Braun M, 2019, IEEE T PATTERN ANAL, V41, P1844, DOI 10.1109/TPAMI.2019.2897684
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, PREPRINT
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   King DB, 2015, ACS SYM SER, V1214, P1
   Kong T., 2019, ARXIV190403797
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Lei B. J., 2016, ARXIV160706450
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Li ZM, 2018, LECT NOTES COMPUT SC, V11213, P339, DOI [10.1007/978-3-030-01240-3_21, 10.1007/978-3-030-01219-9_23]
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu ST, 2019, PROC CVPR IEEE, P6452, DOI 10.1109/CVPR.2019.00662
   Liu W, 2018, LECT NOTES COMPUT SC, V11218, P643, DOI 10.1007/978-3-030-01264-9_38
   Liu W, 2019, PROC CVPR IEEE, P5182, DOI 10.1109/CVPR.2019.00533
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu R, 2019, ARXIV191111985, P11
   Luo P., 2018, ARXIV
   Pang YW, 2019, IEEE I CONF COMP VIS, P4966, DOI 10.1109/ICCV.2019.00507
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salimans T, 2016, ADV NEUR IN, V29
   Santurkar S, 2018, ADV NEUR IN, V31
   Shao S, 2018, CROWDHUMAN BENCHMARK
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song T, 2018, LECT NOTES COMPUT SC, V11211, P554, DOI 10.1007/978-3-030-01234-2_33
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Tarvainen A, 2017, ADV NEUR IN, V30
   Ulyanov Dmitry, 2016, arXiv
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang XL, 2018, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2018.00811
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Xie J, 2020, ARXIV200109252
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhang SS, 2018, IEEE T PATTERN ANAL, V40, P973, DOI 10.1109/TPAMI.2017.2700460
   Zhang SS, 2017, PROC CVPR IEEE, P4457, DOI 10.1109/CVPR.2017.474
   Zhang SS, 2015, PROC CVPR IEEE, P1751, DOI 10.1109/CVPR.2015.7298784
   Zhang SF, 2018, LECT NOTES COMPUT SC, V11207, P657, DOI 10.1007/978-3-030-01219-9_39
   Zhou CL, 2019, IEEE I CONF COMP VIS, P9556, DOI 10.1109/ICCV.2019.00965
NR 53
TC 8
Z9 9
U1 2
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 103986
DI 10.1016/j.imavis.2020.103986
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000004
DA 2024-07-18
ER

PT J
AU Forcen, JI
   Pagola, M
   Barrenechea, E
   Bustince, H
AF Forcen, J., I
   Pagola, Miguel
   Barrenechea, Edurne
   Bustince, Humberto
TI <i>Co-occurrence</i> of deep convolutional features for image search
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Co-occurrence; Image retrieval; Feature aggregation; Pooling
AB Image search can be tackled using deep features from pre-trained Convolutional Neural Networks (CNN). The feature map from the last convolutional layer of a CNN encodes descriptive information from which a discriminative global descriptor can be obtained. We propose a new representation of co-occurrences from deep convolutional features to extract additional relevant information from this last convolutional layer. Combining this co-occurrence map with the feature map, we achieve an improved image representation. We present two different methods to get the co-occurrence representation, the first one based on direct aggregation of activations, and the second one, based on a trainable co-occurrence representation. The image descriptors derived from our methodology improve the performance in very well-known image retrieval datasets as we prove in the experiments. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Forcen, J., I] das Nano Veridas, Tajonar 31192, Spain.
   [Forcen, J., I; Pagola, Miguel; Barrenechea, Edurne; Bustince, Humberto] Univ Publ Navarra, Inst Smart Cities, Dept Estadist Informat & Matemat, Campus Arrosadia, Pamplona 31006, Spain.
   [Bustince, Humberto] King Abdullazih Univ, Jeddah, Saudi Arabia.
C3 Universidad Publica de Navarra
RP Forcen, JI (corresponding author), das Nano Veridas, Tajonar 31192, Spain.
EM jiforcen@das-nano.com; miguel.pagola@unavarra.es
RI Pagola, Miguel/F-9342-2016; Barrenechea, Edurne/H-4815-2011
CR Ahmed N, 2016, UBICOMP'16 ADJUNCT: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING, P1, DOI 10.1145/2968219.2971457
   [Anonymous], 28 BRIT MACH VIS C B
   [Anonymous], SALIENCY WEIGHTED CO
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2007, CVPR
   [Anonymous], P INT WORKSH CONT BA
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Babenko A, 2015, IEEE I CONF COMP VIS, P1269, DOI 10.1109/ICCV.2015.150
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Cao JJ, 2016, J HIGH ENERGY PHYS, P1, DOI 10.1007/JHEP03(2016)207
   Carreira J, 2012, LECT NOTES COMPUT SC, V7578, P430, DOI 10.1007/978-3-642-33786-4_32
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Elkerdawy S, 2019, LECT NOTES COMPUT SC, V11132, P664, DOI 10.1007/978-3-030-11018-5_54
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Gordo A, 2017, INT J COMPUT VISION, V124, P237, DOI 10.1007/s11263-017-1016-8
   Guillot-Soulez C., 2014, REV GESTION RESSOURC, V80, P33, DOI [10.3917/grhu.080.0033, DOI 10.3917/GRHU.080.0033, 10.3917/grhu.080.0033.]
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Kingma D.P., 2014, ARXIV14126980
   Koch G., 2015, PROC ICML DEEP LEARN, V2, P1
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Radenovic F, 2018, PROC CVPR IEEE, P5706, DOI 10.1109/CVPR.2018.00598
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Shih YF, 2017, PROC CVPR IEEE, P7302, DOI 10.1109/CVPR.2017.772
   Siméoni O, 2018, IEEE WINT CONF APPL, P1745, DOI 10.1109/WACV.2018.00194
   Simonyan K, 2015, IEEE INT C ICLR
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Tolias G., 2016, Conference Track Proceedings,
   Tolias G, 2014, PATTERN RECOGN, V47, P3466, DOI 10.1016/j.patcog.2014.04.007
   Yang Y., 2010, P 18 SIGSPATIAL INT, P270, DOI DOI 10.1145/1869790.1869829
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
NR 37
TC 12
Z9 12
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2020
VL 97
AR 103909
DI 10.1016/j.imavis.2020.103909
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR7TU
UT WOS:000535899900002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sahin, C
   Garcia-Hernando, G
   Sock, J
   Kim, TK
AF Sahin, Caner
   Garcia-Hernando, Guillermo
   Sock, Juil
   Kim, Tae-Kyun
TI A review on object pose recovery: From 3D bounding box detectors to full
   6D pose estimators
SO IMAGE AND VISION COMPUTING
LA English
DT Review
ID RECOGNITION; HISTOGRAMS; SHAPES
AB Object pose recovery has gained increasing attention in the computer vision field as it has become an important problem in rapidly evolving technological areas related to autonomous driving, robotics, and augmented reality. Existing review-related studies have addressed the problem at visual level in 2D, going through the methods which produce 2D bounding boxes of objects of interest in RGB images. The 2D search space is enlarged either using the geometry information available in the 3D space along with RGB (Mono/Stereo) images, or utilizing depth data from LIDAR sensors and/or RGB-D cameras. 3D bounding box detectors, producing category-level amodal 3D bounding boxes, are evaluated on gravity aligned images, while full 6D object pose estimators are mostly tested at instance-level on the images where the alignment constraint is removed. Recently, 6D object pose estimation is tackled at the level of categories. In this paper, we present the first comprehensive and most recent review of the methods on object pose recovery, from 3D bounding box detectors to full 6D pose estimators. The methods mathematically model the problem as a classification, regression, classification & regression, template matching, and point-pair feature matching task. Based on this, a mathematical-model-based categorization of the methods is established. Datasets used for evaluating the methods are investigated with respect to the challenges, and evaluation metrics are studied. Quantitative results of experiments in the literature are analyzed to show which category of methods best performs across what types of challenges. The analyses are further extended comparing two methods, which are our own implementations, so that the outcomes from the public results are further solidified. Current position of the field is summarized regarding object pose recovery, and possible research directions are identified. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Sahin, Caner; Garcia-Hernando, Guillermo; Sock, Juil; Kim, Tae-Kyun] Imperial Coll London, London, England.
C3 Imperial College London
RP Sahin, C (corresponding author), Imperial Coll London, Imperial Comp Vis & Learning Lab ICVL, Elect & Elect Engn Dept, London SW7 2AZ, England.
EM canersahin130@gmail.com; g.garcia-hernando@imperial.ac.uk;
   ju-il.sock08@imperial.ac.uk; tk.kim@imperial.ac.uk
RI Sahin, Caner/ABS-0159-2022; Kim, Tae-Kyun/HTL-2208-2023
OI Sahin, Caner/0000-0002-4591-7168; Kim, Tae-Kyun/0000-0002-7587-6053
CR [Anonymous], ICCV19
   [Anonymous], IEEE INT C 3D VIS
   [Anonymous], ECCV 2016
   [Anonymous], INT C ADV COMP ENT
   [Anonymous], ICCV WORKSH CONS DEP
   [Anonymous], CVPR 2012
   [Anonymous], BMVC 2018
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], ICCV 2013
   [Anonymous], IROS 2016
   [Anonymous], P ROB SCI SYST
   [Anonymous], 2017, INT J ROBOTICS RES
   [Anonymous], ECCV 2018
   [Anonymous], CVPR 2015
   [Anonymous], ACCV 2012
   [Anonymous], AS C COMP VIS 2010
   [Anonymous], ICCV 2015
   [Anonymous], 2011 IEEE RSJ INT C
   [Anonymous], ICRA 2018
   [Anonymous], P 2017 ACM IEEE INT
   [Anonymous], ROBOTIC GRASPING MAN
   [Anonymous], IROS 2016
   [Anonymous], P 14 IEEE INT C COMP
   [Anonymous], CVPR 2013
   [Anonymous], CVPR 2015
   [Anonymous], CVPR 2012
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], CVPR 2017
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], ICRA 2011
   [Anonymous], BMVC 2015
   [Anonymous], P AS C COMP VIS
   [Anonymous], 2013, DECISION FORESTCOM
   [Anonymous], ARXIV191010653
   [Anonymous], ECCVW 2016
   [Anonymous], IJRR 2012
   [Anonymous], 2017, 3 INT WORKSH REC 6D
   [Anonymous], ECCVW ACVR ECCV WORK
   [Anonymous], ECCV 2012
   [Anonymous], ECCVW R6D
   [Anonymous], INT C ROB AUT ICRA
   [Anonymous], RGB D IMAGE ANAL PRO
   [Anonymous], ECCV 2016
   [Anonymous], ECCV 2016
   [Anonymous], 2019, INT J COMPUT VISION
   [Anonymous], CVPR 2016
   [Anonymous], 4 INT WORKSH REC 6D
   [Anonymous], 3D DEEP LEARN WORKSH
   [Anonymous], 3D IMAGING MODELING
   [Anonymous], ICRA 2018
   [Anonymous], INT C ROB AUT
   [Anonymous], 2016, ROBOTICS AUTOMATION
   [Anonymous], ECCV 2014
   [Anonymous], ECCV 2014
   [Anonymous], ECCV 2014
   [Anonymous], ICCV19
   [Anonymous], INT C ROB AUT 2012
   [Anonymous], ARXIV191008811
   [Anonymous], CVPR 2016
   [Anonymous], ICRA 2017
   [Anonymous], CVPR 2009
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Asif U, 2017, IEEE T ROBOT, V33, P547, DOI 10.1109/TRO.2016.2638453
   Balntas V, 2017, IEEE I CONF COMP VIS, P3876, DOI 10.1109/ICCV.2017.416
   Birdal T, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P527, DOI 10.1109/3DV.2015.65
   Bleyer M, 2012, LECT NOTES COMPUT SC, V7576, P467, DOI 10.1007/978-3-642-33715-4_34
   Brégier R, 2017, IEEE INT CONF COMP V, P2209, DOI 10.1109/ICCVW.2017.258
   Breiman L., 2001, Mach. Learn., V45, P5
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Calli B, 2015, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS (ICAR), P510, DOI 10.1109/ICAR.2015.7251504
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Causo A., ICRA 2018
   Chabot F, 2017, PROC CVPR IEEE, P1827, DOI 10.1109/CVPR.2017.198
   Chen X., ADV NEURAL INFORM PR, P424
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Choi C, 2016, ROBOT AUTON SYST, V75, P595, DOI 10.1016/j.robot.2015.09.020
   Choi C, 2013, IEEE INT C INT ROBOT, P1568, DOI 10.1109/IROS.2013.6696558
   Choi C, 2012, IEEE INT C INT ROBOT, P3342, DOI 10.1109/IROS.2012.6386067
   Choudhary S, 2017, SPR PROC ADV ROBOT, V1, P729, DOI 10.1007/978-3-319-50115-4_63
   Criminisi A., 2013, DECISION FORESTCOM, DOI DOI 10.1007/978-1-4471-4929-3
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Deng J., CVPR 2009
   Deng Z, 2017, PROC CVPR IEEE, P398, DOI 10.1109/CVPR.2017.50
   Divvala SK, 2009, PROC CVPR IEEE, P1271, DOI 10.1109/CVPRW.2009.5206532
   Du XX, 2018, IEEE INT CONF ROBOT, P3194
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Gálvez-López D, 2016, ROBOT AUTON SYST, V75, P435, DOI 10.1016/j.robot.2015.08.009
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gupta S, 2015, PROC CVPR IEEE, P4731, DOI 10.1109/CVPR.2015.7299105
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Harley D, 2017, DIS'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON DESIGNING INTERACTIVE SYSTEMS, P1253, DOI 10.1145/3064663.3064680
   Hettiarachchi A, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P1957, DOI 10.1145/2858036.2858134
   Ho R, 2010, INTEGR CIRCUIT SYST, P3, DOI 10.1007/978-1-4419-6588-2_1
   Hodan T, 2017, IEEE WINT CONF APPL, P880, DOI 10.1109/WACV.2017.103
   Hodan T, 2015, IEEE INT C INT ROBOT, P4421, DOI 10.1109/IROS.2015.7354005
   Holz D., 2014, Gearing up and accelerating cross-fertilization between academic and industrial robotics research in Europe - Technology transfer experiments from the ECHORD project (v94 of Springer Tracts in Advanced Robotics)
   Hosseinzadeh M, 2019, IEEE INT CONF ROBOT, P7123, DOI [10.1109/ICRA.2019.8793728, 10.1109/icra.2019.8793728]
   Hu YL, 2019, PROC CVPR IEEE, P3380, DOI 10.1109/CVPR.2019.00350
   Jiang H, 2014, LECT NOTES COMPUT SC, V8691, P582, DOI 10.1007/978-3-319-10578-9_38
   Jiang H, 2013, PROC CVPR IEEE, P2171, DOI 10.1109/CVPR.2013.282
   Kanezaki A, 2018, PROC CVPR IEEE, P5010, DOI 10.1109/CVPR.2018.00526
   Kehl W, 2017, IEEE I CONF COMP VIS, P1530, DOI 10.1109/ICCV.2017.169
   Kendall A, 2015, IEEE I CONF COMP VIS, P2938, DOI 10.1109/ICCV.2015.336
   Khan SH, 2015, PROC CVPR IEEE, P4603, DOI 10.1109/CVPR.2015.7299091
   Kim E, 2011, IEEE INT C INT ROBOT, P3800, DOI 10.1109/IROS.2011.6048203
   Konishi Y, 2016, LECT NOTES COMPUT SC, V9905, P398, DOI 10.1007/978-3-319-46448-0_24
   Krähenbühl P, 2014, LECT NOTES COMPUT SC, V8693, P725, DOI 10.1007/978-3-319-10602-1_47
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Ku J, 2019, PROC CVPR IEEE, P11859, DOI 10.1109/CVPR.2019.01214
   Kundu A, 2018, PROC CVPR IEEE, P3559, DOI 10.1109/CVPR.2018.00375
   Lahoud J, 2017, IEEE I CONF COMP VIS, P4632, DOI 10.1109/ICCV.2017.495
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Leistner C, 2009, IEEE I CONF COMP VIS, P506, DOI 10.1109/ICCV.2009.5459198
   Li B, 2016, ROBOTICS: SCIENCE AND SYSTEMS XII
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955
   Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111
   Li MY, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18041045
   Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Lim J.J., ICCV 2013
   Lin DH, 2013, IEEE I CONF COMP VIS, P1417, DOI 10.1109/ICCV.2013.179
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Lindlbauer D, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173703
   Lindlbauer D, 2017, PROCEEDINGS OF THE 2017 ACM SIGCHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI'17), P3954, DOI 10.1145/3025453.3025795
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Matzen K, 2013, IEEE I CONF COMP VIS, P761, DOI 10.1109/ICCV.2013.99
   Mondragón IF, 2010, IEEE INT CONF ROBOT, P35, DOI 10.1109/ROBOT.2010.5509287
   Moosmann F, 2007, Adv Neural Inf Process Syst, P985
   Mousavian A, 2017, PROC CVPR IEEE, P5632, DOI 10.1109/CVPR.2017.597
   Muoz E, 2016, IEEE INT CONF ROBOT, P5623, DOI 10.1109/ICRA.2016.7487781
   Ni J, 2014, IEEE WINT CONF APPL, P1, DOI 10.1109/WACV.2014.6836125
   Papon J, 2015, IEEE I CONF COMP VIS, P774, DOI 10.1109/ICCV.2015.95
   Park Kiru, 2019, 2019 International Conference on Robotics and Automation (ICRA), P7207, DOI 10.1109/ICRA.2019.8794448
   Payet N, 2011, IEEE I CONF COMP VIS, P983, DOI 10.1109/ICCV.2011.6126342
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Qi CR, 2017, ADV NEUR IN, V30
   Qi CR, 2019, IEEE I CONF COMP VIS, P9276, DOI 10.1109/ICCV.2019.00937
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qu XZ, 2015, IEEE INT VEH SYM, P605, DOI 10.1109/IVS.2015.7225751
   Rad M, 2017, IEEE I CONF COMP VIS, P3848, DOI 10.1109/ICCV.2017.413
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren XF, 2013, PROC CVPR IEEE, P3246, DOI 10.1109/CVPR.2013.417
   Ren Z, 2016, PROC CVPR IEEE, P1525, DOI 10.1109/CVPR.2016.169
   Rios-Cabrera R, 2013, IEEE I CONF COMP VIS, P2048, DOI 10.1109/ICCV.2013.256
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu RB, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P3197
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005
   Sahin C, 2017, IMAGE VISION COMPUT, V63, P38, DOI 10.1016/j.imavis.2017.05.005
   Sahin C, 2013, IEEE IND ELEC, P4306, DOI 10.1109/IECON.2013.6699827
   Schwarz M, 2018, INT J ROBOT RES, V37, P437, DOI 10.1177/0278364917713117
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi WJ, 2018, IEEE T CLOUD COMPUT, V6, P19, DOI 10.1109/TCC.2015.2481432
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K., 2014, 14091556 ARXIV
   Song SY, 2015, PROC CVPR IEEE, P3734, DOI 10.1109/CVPR.2015.7298997
   Song SR, 2016, PROC CVPR IEEE, P808, DOI 10.1109/CVPR.2016.94
   Song SR, 2014, LECT NOTES COMPUT SC, V8694, P634, DOI 10.1007/978-3-319-10599-4_41
   Sra M, 2016, 22ND ACM CONFERENCE ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2016), P191, DOI 10.1145/2993369.2993372
   Sun Min., ECCV 2010
   Tateno K, 2017, PROC CVPR IEEE, P6565, DOI 10.1109/CVPR.2017.695
   Tekin B, 2018, PROC CVPR IEEE, P292, DOI 10.1109/CVPR.2018.00038
   Teng SY, 2018, UIST 2018: PROCEEDINGS OF THE 31ST ANNUAL ACM SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P5, DOI 10.1145/3242587.3242628
   Tjaden H, 2017, IEEE I CONF COMP VIS, P124, DOI 10.1109/ICCV.2017.23
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Ulrich M, 2012, IEEE T PATTERN ANAL, V34, P1902, DOI 10.1109/TPAMI.2011.266
   Vidal J, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18082678
   Wang C, 2019, PROC CVPR IEEE, P3338, DOI 10.1109/CVPR.2019.00346
   Wang D.Z., 2015, Robotics: Science and Systems, V1
   Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275
   Wang Y, 2019, PROC CVPR IEEE, P8063, DOI 10.1109/CVPR.2019.00826
   Wang ZX, 2019, IEEE INT C INT ROBOT, P1742, DOI [10.1109/IROS40897.2019.8968513, 10.1109/iros40897.2019.8968513]
   Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Xiang Y, 2015, PROC CVPR IEEE, P1903, DOI 10.1109/CVPR.2015.7298800
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
   Xiao R, 2018, IEEE T VIS COMPUT GR, V24, P1653, DOI 10.1109/TVCG.2018.2794222
   Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang B, 2018, PROC CVPR IEEE, P7652, DOI 10.1109/CVPR.2018.00798
   Zakharov S, 2017, IEEE INT C INT ROBOT, P552, DOI 10.1109/IROS.2017.8202207
   Zeng Andy, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1386, DOI 10.1109/ICRA.2017.7989165
   Zeng A., ICRA 2018
   Zhang YD, 2017, IEEE RAD FREQ INTEGR, P3, DOI 10.1109/RFIC.2017.7969002
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhu ML, 2014, IEEE INT CONF ROBOT, P3936, DOI 10.1109/ICRA.2014.6907430
   Zia MZ, 2014, PROC CVPR IEEE, P3678, DOI 10.1109/CVPR.2014.470
   Zingg S, 2010, IEEE INT CONF ROBOT, P3361, DOI 10.1109/ROBOT.2010.5509777
NR 206
TC 54
Z9 63
U1 7
U2 122
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2020
VL 96
AR 103898
DI 10.1016/j.imavis.2020.103898
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YN
UT WOS:000527905200002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bicego, M
   Grosso, E
AF Bicego, Manuele
   Grosso, Enrico
TI On the importance of local and global analysis in the judgment of
   similarity and dissimilarity of faces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face analysis; Biometrics; Image matching; Similarity-dissimilarity of
   visual content
ID RECOGNITION; PERCEPTION; FEATURES; REGRESSION; SELECTION; TIME; RACE
AB The ability to recognize faces and to detect differences and similarities between faces has proved to be fundamental in the evolution of humans and in the conditioning of their social behaviors. In this paper, we investigate basic mechanisms underlying this ability, focusing in particular on the relevance of local and global features and on some interesting differences characterizing judgments of similarity with respect to judgments of dissimilarity.
   In a first experiment, a set of participants is involved in order to evaluate the human response with respect to a simple judgment protocol based on two-alternative forced choice. Triplets of face stim uli are evaluated first with the aim of identifying (between two candidate faces) the face more similar to a reference face. The protocol is then repeated for the same triplets but involving a different set of participants and asking to identify the face less similar to a reference face. These visual judgments of similarity and dissimilarity are finally analyzed and compared with the results of a closely related computational experiment based on the same set of triplets: in this case, however, the similarity-dissimilarity measure is derived by automatically extracting facial points and matching with regression techniques (LASSO and Elastic Net) two configurations of image descriptors: the first capturing holistic information, the second capturing local information, that is few localized facial features.
   Our results suggest that computational models based on holistic cues (emphasizing the concept of the whole as a composed set of interdependent parts) better fit judgments of humans participating to the first experiment (similarity judgments). On the other hand, models based on spatially localized cues do not offer significant accuracy. Vice versa, computational models based on local cues better fit dissimilarity judgments and are less adequate to express similarity information. Notably, our results provide some empirical evidence that local and global cues are both important in face perception, but with different roles. This finding supports the hypothesis that similarity and dissimilarity should not merely be considered as opposing concepts, as they could derive from different processing paths. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Bicego, Manuele] Univ Verona, Dept Comp Sci, Verona, Italy.
   [Grosso, Enrico] Univ Sassari, Dept Agr, Sassari, Italy.
C3 University of Verona; University of Sassari
RP Bicego, M (corresponding author), Univ Verona, Dept Comp Sci, Verona, Italy.
EM manuele.bicego@univr.it
FU University of Sassari through the grant "Fondo di Ateneo per la ricerca
   2019
FX This research has been sponsored in part by the University of Sassari
   through the grant "Fondo di Ateneo per la ricerca 2019".
CR Baltrusaitis T, 2016, IEEE WINT CONF APPL
   Bicego M, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279920.1279925
   BRUCE V, 1986, BRIT J PSYCHOL, V77, P305, DOI 10.1111/j.2044-8295.1986.tb02199.x
   Calder AJ, 2005, NAT REV NEUROSCI, V6, P641, DOI 10.1038/nrn1724
   Collishaw SM, 2000, PERCEPTION, V29, P893, DOI 10.1068/p2949
   Dal Martello MF, 2015, J VISION, V15, DOI 10.1167/15.13.5
   Ding CX, 2016, ACM T INTEL SYST TEC, V7, DOI 10.1145/2845089
   Edelman S, 2012, FRONT COMPUT NEUROSC, V6, DOI 10.3389/fncom.2012.00045
   Ekman P., 2005, WHAT FACE REVEALS BA
   Fei Wang, 2012, Statistical Analysis and Data Mining, V5, P54, DOI 10.1002/sam.11135
   GOLDSTONE RL, 1991, COGNITIVE PSYCHOL, V23, P222, DOI 10.1016/0010-0285(91)90010-L
   Hernandez-Duran M., 2016, P IB C IM REC PROC, P217
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Jain A. K., 2011, HDB FACE RECOGNITION
   Jaworska N., 2009, QUANT METHODS PSYCHO, V5
   Jones M, 2007, COGNITIVE PSYCHOL, V55, P196, DOI 10.1016/j.cogpsych.2006.09.004
   Kumar J, 2015, PROCEDIA COMPUT SCI, V58, P486, DOI 10.1016/j.procs.2015.08.011
   Little AC, 2011, PHILOS T R SOC B, V366, P1634, DOI 10.1098/rstb.2010.0386
   Lorusso L, 2015, REV PHILOS PSYCHOL, V6, P317, DOI 10.1007/s13164-014-0229-9
   Lorusso L, 2011, PERCEPTION, V40, P1282, DOI 10.1068/p6916
   Martinez AM, 2017, CURR DIR PSYCHOL SCI, V26, P263, DOI 10.1177/0963721417698535
   Mathy F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00026
   OTOOLE AJ, 1994, MEM COGNITION, V22, P208, DOI 10.3758/BF03208892
   Ouyang SX, 2016, IMAGE VISION COMPUT, V56, P28, DOI 10.1016/j.imavis.2016.09.001
   Redfern AS, 2017, I-PERCEPTION, V8, DOI 10.1177/2041669517710663
   Rule NO, 2017, CURR DIR PSYCHOL SCI, V26, P211, DOI 10.1177/0963721417712542
   Ruys KI, 2008, EUR J SOC PSYCHOL, V38, P576, DOI 10.1002/ejsp.453
   Schwaninger A, 2009, COGNITIVE SCI, V33, P1413, DOI 10.1111/j.1551-6709.2009.01059.x
   SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P219, DOI 10.1007/BF02289621
   Simmons S, 2008, COGNITION, V108, P781, DOI 10.1016/j.cognition.2008.07.003
   Sormaz M, 2016, VISION RES, V127, P1, DOI 10.1016/j.visres.2016.07.002
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tistarelli M, 2000, IMAGE VISION COMPUT, V18, P299, DOI 10.1016/S0262-8856(99)00059-1
   Tistarelli M, 2009, IMAGE VISION COMPUT, V27, P222, DOI 10.1016/j.imavis.2007.05.006
   TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750
   VALENTINE T, 1991, Q J EXP PSYCHOL-A, V43, P161, DOI 10.1080/14640749108400966
   VOKEY JR, 1992, MEM COGNITION, V20, P291, DOI 10.3758/BF03199666
   Wang BJ, 2017, PATTERN ANAL APPL, V20, P495, DOI 10.1007/s10044-015-0515-x
   Wang H., 2017, IEEE ACCESS, V6, P6001
   Whelan R, 2008, PSYCHOL REC, V58, P475, DOI 10.1007/BF03395630
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Zhan C, 2013, ACM T APPL PERCEPT, V10, DOI 10.1145/2465780.2465782
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 46
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2019
VL 92
AR 103813
DI 10.1016/j.imavis.2019.09.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA JW2JO
UT WOS:000502884200005
DA 2024-07-18
ER

PT J
AU Zhao, Q
   Liu, JH
   Zhang, BX
   Lyu, SC
   Raoof, N
   Feng, WQ
AF Zhao, Qi
   Liu, Jiahui
   Zhang, Boxue
   Lyu, Shuchang
   Raoof, Nauman
   Feng, Wenquan
TI Interpretable Relative Squeezing bottleneck design for compact
   convolutional neural networks model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image recognition; Compact CNN; Relative-Squeezing bottleneck; Learned
   group convolutions
AB Convolutional neural networks (CNN) are mainly used for image recognition tasks. However, some huge models are infeasible for mobile devices because of limited computing and memory resources. In this paper, feature maps of DenseNet and CondenseNet are visualized. It could be observed that there are some feature channels in locked state and some have similar distribution property, which could be compressed further. Thus, in this work, a novel architecture - RSNet is introduced to improve the computing efficiency of CNNs. This paper proposes Relative-Squeezing (RS) bottleneck design, where the output is the weighted percentage of input channels. Besides, RSNet also contains multiple compression layers and learned group convolutions (LGCs). By eliminating superfluous feature maps, relative squeezing and compression layers only transmit the most significant features to the next layer. Less parameters are employed and much computation is saved. The proposed model is evaluated on three benchmark datasets: CIFAR-10, CIFAR-100 and ImageNet. Experiment results show that RSNet performs better with less parameters and FLOPs, compared to the state-of-the-art baseline, including CondenseNet, MobileNet and ShuffleNet. (C) 2019 The Authors. Published by Elsevier B.V.
C1 [Zhao, Qi; Liu, Jiahui; Zhang, Boxue; Lyu, Shuchang; Raoof, Nauman; Feng, Wenquan] Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhao, Q (corresponding author), Beihang Univ, Sch Elect & Informat Engn, Beijing 100191, Peoples R China.
EM zhaoqi@buaa.edu.cn
RI Jiahui, Liu/JEO-8250-2023; Lyu, Shuchang/JTD-3128-2023; Zhao,
   Qi/IQR-6252-2023; feng, wen/HTS-9745-2023
OI Lyu, Shuchang/0000-0001-9769-7083; Zhao, Qi/0000-0003-2521-9191; Feng,
   Wenquan/0000-0003-3669-6698
FU National Natural Science Foundation of China [61772052]
FX This work is supported by the National Natural Science Foundation of
   China grant 61772052.
CR [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.517
   [Anonymous], ACM J EM TECHN COMP
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2017, INT C LEARN REPR
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], ARXIV161106440
   [Anonymous], 1990, Adv Neural Inform Process Syst.
   [Anonymous], 2016, ADAPTIVE COMPUTATION
   [Anonymous], 2017, Mobilenets: Efficient Convolutional Neural Networks for Mobile Vision Applications
   Bucilua C., 2006, P 12 ACM SIGKDD INT, P535
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194
   Han S., 2015, ARXIV151000149
   Han S, 2015, P ADV NEUR INF PROC, V2015, P1135
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Hubara I, 2016, ADV NEUR IN, V29
   Iandola F.N., 2016, PROC INT C LEARN
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lin M., 2013, P 2 INT C LEARNING R
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Lyu HL, 2015, CHIN CONT DECIS CONF, P2885
   Mustafa HT, 2019, IMAGE VISION COMPUT, V85, P26, DOI 10.1016/j.imavis.2019.03.001
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Romero A., 2014, 3 INT C LEARN REPRES
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV
   Springenberg Jost Tobias, 2015, Striving for simplicity: The all convolutional net, DOI DOI 10.48550/ARXIV.1412.6806
   Srivastava RK, 2015, ARXIV150500387
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Thomee B, 2016, COMMUN ACM, V59, P64, DOI 10.1145/2812802
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 45
TC 9
Z9 9
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 276
EP 288
DI 10.1016/j.imavis.2019.06.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900022
OA hybrid
DA 2024-07-18
ER

PT J
AU Khalifa, AF
   Badr, E
   Elmandy, HN
AF Khalifa, Ali Farouk
   Badr, Eman
   Elmandy, Hesham N.
TI A survey on human detection surveillance systems for Raspberry Pi
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human detection; Machine learning; Raspberry Pi
ID PARTIALLY OCCLUDED HUMANS; BAYESIAN COMBINATION; MULTIPLE; IMAGE
AB Building reliable surveillance systems is critical for security and safety. A core component of any surveillance system is the human detection model. With the recent advances in the hardware and embedded devices, it becomes possible to make a real-time human detection system with low cost. This paper surveys different systems and techniques that have been deployed on embedded devices such as Raspberry Pi. The characteristics of datasets, feature extraction techniques, and machine learning models are covered. A unified dataset is utilized to compare different systems with respect to accuracy and performance time. New enhancements are suggested, and future research directions are highlighted. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Khalifa, Ali Farouk; Badr, Eman; Elmandy, Hesham N.] Cairo Univ, Fac Comp & Informat, Informat Technol Dept, Giza, Egypt.
C3 Egyptian Knowledge Bank (EKB); Cairo University
RP Khalifa, AF (corresponding author), Cairo Univ, Fac Comp & Informat, Informat Technol Dept, Giza, Egypt.
EM a.farouk@fci-cu.edu.eg
RI Badr, Eman/GZG-8430-2022; Elmahdy, Hesham N/ABG-8704-2021; Farouk,
   Ali/U-6551-2019
OI Badr, Eman/0000-0001-9531-2266; Elmahdy, Hesham/0000-0001-6633-1652
CR Aljasem DK, 2016, INT CONF INTEL ENVIR, P155, DOI 10.1109/IE.2016.33
   [Anonymous], 2014, 2014 IEEE INT S SAF
   Ansari AN, 2015, PROCEEDINGS OF 2015 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND INTERNET OF THINGS, P131, DOI 10.1109/ICAIOT.2015.7111554
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bhangale KB, 2014, INT J INNOV RES DEV, V3, P179
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chollet F., 2017, DEEP LEARNING PYTHON
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Oliveira DC, 2016, 2016 IEEE 19TH INTERNATIONAL SYMPOSIUM ON REAL-TIME DISTRIBUTED COMPUTING (ISORC 2016), P27, DOI 10.1109/ISORC.2016.14
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Nguyen DT, 2016, PATTERN RECOGN, V51, P148, DOI 10.1016/j.patcog.2015.08.027
   Ess A., 2007, P IEEE INT C COMP VI, DOI [10.1109/1CCV.2007.4409092, DOI 10.1109/1CCV.2007.4409092]
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang YZ, 2008, PROC CVPR IEEE, P2000
   Iandola F. N., 2016, ARXIV160207360, DOI 10.1007/978-3-319-24553-9
   Jansi P., 2017, INT J MOD TRENDS SCI, P3
   Jiang YS, 2015, PROC CVPR IEEE, P240, DOI 10.1109/CVPR.2015.7298620
   Lin Z, 2007, IEEE I CONF COMP VIS, P2301
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma Y.Q., 2014, Support vector machines applications, DOI [10.1007/978-3-319-02300-7, DOI 10.1007/978-3-319-02300-7]
   Melin P., 2005, STUDIES FUZZINESS SO, P172, DOI [10.1007/3-540-32367-8_3, DOI 10.1007/3-540-32367-8_3]
   Murugan KHS, 2017, 2017 THIRD INTERNATIONAL CONFERENCE ON SCIENCE TECHNOLOGY ENGINEERING & MANAGEMENT (ICONSTEM), P863, DOI 10.1109/ICONSTEM.2017.8261326
   Nikouei S. Y., 2018, ARXIV180500330, V1, P1
   Noman M, 2016, 2016 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA), P8
   Paisitkriangkrai S., 2008, IEEE INT S CIRC SYST, V28, P1863, DOI DOI 10.1109/ISCAS.2008.4542024
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Parekh H.S., 2014, INT J INNOVATIVE RES, V2, P2970
   Patel PB., 2016, INT J APPL INF SYST, V10, P37
   Paul M, 2013, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2013-11
   Reddy R., 2014, J INNOV ELECT COMMUN, V2, P56
   Rujikietgumjorn S., 2017, 2017 14 IEEE INT C A, DOI [10.1109/AVSS.2017.8078561, DOI 10.1109/AVSS.2017.8078561]
   Sabzmeydani P., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383134
   Saunders C., 1998, J MACH LEARN RES, V7, P1687
   Saypadith S, 2017, ASIAPAC SIGN INFO PR, P1707, DOI 10.1109/APSIPA.2017.8282308
   Shalev-Shwartz S., 2014, UNDERSTANDING MACHIN, DOI 10.1017/CBO9781107298019
   Singla N, 2014, International Journal of Information & Computation Technology, V4, P1559
   Theodoridis S, 2009, PATTERN RECOGNITION, 4RTH EDITION, P1
   Wang Liya, 2007, Plant Biology (Rockville), V2007, P189
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Wu B., 2007, P IEEE INT C COMP VI, DOI [10.1109/ICCV.2007.4409006, DOI 10.1109/ICCV.2007.4409006]
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
NR 47
TC 19
Z9 19
U1 3
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2019
VL 85
BP 1
EP 13
DI 10.1016/j.imavis.2019.02.010
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HZ9DE
UT WOS:000469155200001
DA 2024-07-18
ER

PT J
AU Yao, XX
   Wu, Q
   Zhang, P
   Bao, FX
AF Yao, Xunxiang
   Wu, Qiang
   Zhang, Peng
   Bao, Fangxun
TI Adaptive rational fractal interpolation function for image
   super-resolution via local fractal analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image super-resolution; Texture detail; Fractal function; Vertical
   scaling factor; Fractal dimension
ID DIMENSION
AB Image super-resolution aims to generate high-resolution image based on the given low-resolution image and to recover the details of the image. The common approaches include reconstruction-based methods and interpolation-based methods. However, these existing methods show difficulty in processing the regions of an image with complicated texture. To tackle such problems, fractal geometry is applied on image super-resolution, which demonstrates its advantages when describing the complicated details in an image. The common fractal-based method regards the whole image as a single fractal set. That is, it does not distinguish the complexity difference of texture across all regions of an image regardless of smooth regions or texture rich regions. Due to such strong presumption, it causes artificial errors while recovering smooth area and texture blurring at the regions with rich texture. In this paper, the proposed method produces rational fractal interpolation model with various setting at different regions to adapt to the local texture complexity. In order to facilitate such mechanism, the proposed method is able to segment the image region according to its complexity which is determined by its local fractal dimension. Thus, the image super-resolution process is cast to an optimization problem where local fractal dimension in each region is further optimized until the optimization convergence is reached. During the optimization (i.e. super-resolution), the overall image complexity (determined by local fractal dimension) is maintained. Compared with state-of-the-art method, the proposed method shows promising performance according to qualitative evaluation and quantitative evaluation. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Yao, Xunxiang; Wu, Qiang; Zhang, Peng] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.
   [Bao, Fangxun] Shandong Univ, Sch Math, Jinan, Shandong, Peoples R China.
C3 University of Technology Sydney; Shandong University
RP Yao, XX (corresponding author), Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.
EM Xunxiang.Yao@student.uts.edu.au
OI Wu, Qiang/0000-0001-5641-2483
FU National Natural Science Foundation of China [61672018]; China
   Scholarship Council
FX This work was supported by National Natural Science Foundation of China
   (No.61672018) and China Scholarship Council.
CR [Anonymous], 2014, ACCV WORKSH IM REST
   Bao FX, 2018, SCI CHINA INFORM SCI, V61, DOI 10.1007/s11432-017-9258-5
   BARNSLEY MF, 1986, CONSTR APPROX, V2, P303, DOI 10.1007/BF01893434
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Eberhart RC, 2001, IEEE C EVOL COMPUTAT, P81, DOI 10.1109/CEC.2001.934374
   Fattal R, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239546, 10.1145/1276377.1276496]
   Giachetti A, 2011, IEEE T IMAGE PROCESS, V20, P2760, DOI 10.1109/TIP.2011.2136352
   Giusto DD, 2005, IEEE T CONSUM ELECTR, V51, P103, DOI 10.1109/TCE.2005.1405706
   Gribbon KT, 2004, INT SYM ELECT DES TE, P126
   Han ZJ, 2001, IEEE T IND ELECTRON, V48, P920, DOI 10.1109/41.954556
   Han ZJ, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P222, DOI 10.1109/ICIP.1998.727171
   He H, 2011, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2011.5995713
   He L, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043035
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Jun-Jie Huang, 2017, 2017 IEEE Conference on Computer Vision and Pattern Recognition: Workshops (CVPRW), P1067, DOI 10.1109/CVPRW.2017.144
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Matsumoto S, 2012, OPTIM LETT, V6, P1265, DOI 10.1007/s11590-011-0371-6
   MCKEAN HP, 1955, DUKE MATH J, V22, P229
   Millán H, 2007, GEODERMA, V138, P185, DOI 10.1016/j.geoderma.2006.11.019
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P661, DOI 10.1109/TPAMI.1984.4767591
   Pickup LC, 2004, ADV NEUR IN, V16, P1587
   Ren HY, 2017, IEEE COMPUT SOC CONF, P1050, DOI 10.1109/CVPRW.2017.142
   SARKAR N, 1994, IEEE T SYST MAN CYB, V24, P115, DOI 10.1109/21.259692
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Tai YW, 2010, PROC CVPR IEEE, P2400, DOI 10.1109/CVPR.2010.5539933
   Tian YP, 2016, IEEE IMAGE PROC, P2827, DOI 10.1109/ICIP.2016.7532875
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tu GF, 2005, INT C COMMUN CIRCUIT, P701
   Wang Q, 2005, IEEE I CONF COMP VIS, P709
   Wang ZW, 2015, IEEE I CONF COMP VIS, P370, DOI 10.1109/ICCV.2015.50
   Wee YC, 2010, IEEE T CONSUM ELECTR, V56, P1537, DOI 10.1109/TCE.2010.5606294
   Wei XY, 2016, IEEE T IMAGE PROCESS, V25, P3723, DOI 10.1109/TIP.2016.2563178
   Wittenbrink CM, 1995, VISUALIZATION '95 - PROCEEDINGS, P77, DOI 10.1109/VISUAL.1995.480798
   Xie HP, 1997, FRACTALS, V5, P625, DOI 10.1142/S0218348X97000504
   Xu HT, 2013, IEEE T CIRC SYST VID, V23, P1740, DOI 10.1109/TCSVT.2013.2248305
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yao XX, 2018, MULTIMED TOOLS APPL, V77, P1971, DOI 10.1007/s11042-017-4379-5
   Yu L., 2013, IEEE International Conference on Multimedia and Expo Workshops, P1
   Zhang CM, 2013, IEEE IMAGE PROC, P1046, DOI 10.1109/ICIP.2013.6738216
   Zhang HC, 2013, IEEE T CYBERNETICS, V43, P1035, DOI 10.1109/TSMCB.2012.2222375
   Zhang KB, 2012, IEEE T IMAGE PROCESS, V21, P4544, DOI 10.1109/TIP.2012.2208977
   Zheng JY, 2019, IEEE ACCESS, V7, P8646, DOI 10.1109/ACCESS.2018.2890517
NR 45
TC 22
Z9 24
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2019
VL 82
BP 39
EP 49
DI 10.1016/j.imavis.2019.02.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HU1RT
UT WOS:000465050200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, NX
   Busso, C
AF Li, Nanxiang
   Busso, Carlos
TI Calibration free, user-independent gaze estimation with tensor analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE User-independent gaze estimation; Tensor analysis; LASSO regression;
   Domain adaptation; Human computer interaction
ID RECOGNITION; EIGENFACES; TRACKING
AB Human gaze directly signals visual attention, therefore, estimation of gaze has been an important research topic in fields such as human attention modeling and human-computer interaction. Accurate gaze estimation requires user, system and even session dependent parameters, which can be obtained by calibration process. However, this process has to be repeated whenever the parameter changes (head movement, camera movement, monitor movement). This study aims to eliminate the calibration process of gaze estimation by building a user-independent, appearance-based gaze estimation model. The system is ideal for multimodal interfaces, where the gaze is tracked without the cooperation from the users. The main goal is to capture the essential representation of the gaze appearance of the target user. We investigate the tensor analysis framework that decomposes the high dimension gaze data into different factors including individual differences, gaze differences, user-screen distances and session differences. The axis that is representative for a particular subject is automatically chosen in the tensor analysis framework using LASSO regression. The proposed approaches show promising results on capturing the test subject gaze changes. To address the estimation shift caused by the variations in individual heights, or relative position to the monitor, we apply domain adaptation to adjust the gaze estimation, observing further improvements. These promising results suggest that the proposed gaze estimation approach is a feasible and flexible scheme to facilitate gaze-based multimodal interfaces. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Li, Nanxiang; Busso, Carlos] Univ Texas Dallas, 800 W Campbell Rd, Richardson, TX 75080 USA.
C3 University of Texas System; University of Texas Dallas
RP Busso, C (corresponding author), Univ Texas Dallas, 800 W Campbell Rd, Richardson, TX 75080 USA.
EM busso@utdallas.edu
OI Busso, Carlos/0000-0002-4075-4072
CR [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2014, PROC INT C MULTIMODA
   [Anonymous], 1994, P 6 INT C NEUR INF P
   [Anonymous], 2007, Eye tracking methodology: Theory and practice, DOI DOI 10.1007/978-3-319-57883-5
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Beymer D, 2003, PROC CVPR IEEE, P451
   Castrillón M, 2007, J VIS COMMUN IMAGE R, V18, P130, DOI 10.1016/j.jvcir.2006.11.004
   Colombo C, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1314303.1314305
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hillman PM, 2003, ISPA 2003: PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, PTS 1 AND 2, P359
   Huang WM, 2000, INT C PATT RECOG, P722, DOI 10.1109/ICPR.2000.903019
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Li NX, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P91, DOI 10.1145/2522848.2522876
   Li NX, 2013, IEEE T MULTIMEDIA, V15, P1213, DOI 10.1109/TMM.2013.2241416
   Lu F, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.126
   Lu F, 2011, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2011.6126237
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Noris B, 2011, COMPUT VIS IMAGE UND, V115, P476, DOI 10.1016/j.cviu.2010.11.013
   Noureddin B, 2005, COMPUT VIS IMAGE UND, V98, P52, DOI 10.1016/j.cviu.2004.07.005
   Ohno T., 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P125, DOI 10.1145/507072.507098
   Ohno T., 2004, S EYE TRACK RES APPL, P115, DOI [10.1145/968363.968387, DOI 10.1145/968363.968387]
   Ono Y, 2006, LECT NOTES COMPUT SC, V4319, P178
   Pogalin E., 2006, 3 INT S 3D DAT PROC, P57, DOI 10.1109/3DPVT.2006.66
   Proscevicius T, 2010, ELEKTRON ELEKTROTECH, P67
   Rayner K, 2001, J EXP PSYCHOL-APPL, V7, P219, DOI 10.1037/1076-898X.7.3.219
   Rikert TD, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P436, DOI 10.1109/AFGR.1998.670987
   Salvucci D. D., 2000, CHI 2000 Conference Proceedings. Conference on Human Factors in Computing Systems. CHI 2000. The Future is Here, P273, DOI 10.1145/332040.332444
   Schiele B., 1995, Proc. IEEE Int'l. Conf. Automatic Face and Gesture Recognition, P344
   Scott D., 1991, Visual Search, Eye Movements and Display Units
   Skovsgaard H, 2011, BEHAV INFORM TECHNOL, V30, P821, DOI 10.1080/0144929X.2011.563801
   Sugano Y, 2008, LECT NOTES COMPUT SC, V5304, P656, DOI 10.1007/978-3-540-88690-7_49
   Tan KH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P191, DOI 10.1109/ACV.2002.1182180
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang J, 2007, ACM T MULTIM COMPUT, V3, DOI 10.1145/1314303.1314306
   Williams O., 2006, P IEEE C CVPR, V1, P230, DOI DOI 10.1109/CVPR.2006.285
   Wolf L., 2007, Computer Vision and Pattern Recognition, P1
   Wu H., 2006, LECT NOTES COMPUTER, V4843, P688, DOI [10.1007/978-3-540-76386-4_65, DOI 10.1007/978-3-540-76386-4_65]
   Xia DS, 2007, SNPD 2007: EIGHTH ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING, AND PARALLEL/DISTRIBUTED COMPUTING, VOL 1, PROCEEDINGS, P220, DOI 10.1109/SNPD.2007.237
   Xie J, 2007, PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS, P672, DOI 10.1109/ICIG.2007.160
   Yamazoe Hirotake, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563184
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
NR 43
TC 6
Z9 6
U1 1
U2 17
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2018
VL 74
BP 10
EP 20
DI 10.1016/j.imavis.2018.04.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GJ9UE
UT WOS:000435749600002
DA 2024-07-18
ER

PT J
AU Yang, Z
   Pun-Cheng, LSC
AF Yang, Zi
   Pun-Cheng, Lilian S. C.
TI Vehicle detection in intelligent transportation systems and its
   applications under varying environments: A review
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Vehicle detection; Computer vision; Intelligent Transportation Systems;
   Varying environments; Traffic surveillance
ID BRAKE-LIGHT DETECTION; ROAD; FEATURES; SEGMENTATION; CLASSIFICATION;
   SUBTRACTION; APPEARANCE; TRACKING; SHADOWS; MODEL
AB Robust and efficient vehicle detection in monocular vision is an important task in Intelligent Transportation Systems. With the development of computer vision techniques and consequent accessibility of video image data, new applications have been enabled to on-road vehicle detection algorithms. This paper provides a review of the literature in vehicle detection under varying environments. Due to the variability of on-road driving environments, vehicle detection may face different problems and challenges. Therefore, many approaches have been proposed, and can be categorized as appearance-based methods and motion-based methods. In addition, special illumination, weather and driving scenarios are discussed in terms of methodology and quantitative evaluation. In the future, efforts should be focused on robust vehicle detection approaches for various on-road conditions. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Yang, Zi; Pun-Cheng, Lilian S. C.] Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong Polytechnic University
RP Yang, Z (corresponding author), Hong Kong Polytech Univ, Dept Land Surveying & Geoinformat, Hong Kong, Hong Kong, Peoples R China.
EM 15900778r@connect.polyu.hk; lspun@polyu.edu.hk
FU The Hong Kong Polytechnic University [RUC3]; General Research Grant
   [BQ43R]
FX This work was supported by the studentship of The Hong Kong Polytechnic
   University (No. RUC3) and the General Research Grant (No. BQ43R).
CR Abolghasemi V, 2009, IMAGE VISION COMPUT, V27, P1134, DOI 10.1016/j.imavis.2008.10.012
   Acunzo David, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P654, DOI 10.1109/ITSC.2007.4357724
   Al-Maliki A., 2012, International Proceedings of Chemical, Biological and Environmental Engineering (IPCBEE), V37, P1
   [Anonymous], HONG KONG ETRANSPORT
   [Anonymous], INT J COMPUT APPL
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], 1999, COMP VIS PATT REC 19
   Arróspide J, 2013, J VIS COMMUN IMAGE R, V24, P1182, DOI 10.1016/j.jvcir.2013.08.001
   Arrospideh J., GIL VEHICLE DATABASE
   Asaidi H, 2014, J VISUAL LANG COMPUT, V25, P333, DOI 10.1016/j.jvlc.2014.02.001
   Atibi M, 2015, PROCEDIA COMPUT SCI, V73, P24, DOI 10.1016/j.procs.2015.12.044
   Barcellos P, 2015, EXPERT SYST APPL, V42, P1845, DOI 10.1016/j.eswa.2014.09.045
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bas E, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P1085
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bertozzi M, 2000, ROBOT AUTON SYST, V32, P1, DOI 10.1016/S0921-8890(99)00125-6
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Blanc N, 2007, 2007 IEEE INTELLIGENT VEHICLES SYMPOSIUM, VOLS 1-3, P1097
   Buch N, 2011, IEEE T INTELL TRANSP, V12, P920, DOI 10.1109/TITS.2011.2119372
   Cabani I, 2005, 2005 IEEE Intelligent Vehicles Symposium Proceedings, P278
   Celik T, 2010, IEEE T IND ELECTRON, V57, P3216, DOI 10.1109/TIE.2009.2038395
   Chang YT, 2007, INT C COMMUN CIRCUIT, P534, DOI 10.1109/ITSC.2007.4357745
   Chen DY, 2012, IEEE SENS J, V12, P3285, DOI 10.1109/JSEN.2012.2212971
   Chen DY, 2012, IEEE T INTELL TRANSP, V13, P1627, DOI 10.1109/TITS.2012.2199983
   Chen HT, 2016, IEEE SENS J, V16, P120, DOI 10.1109/JSEN.2015.2477412
   Cheon M, 2012, IEEE T INTELL TRANSP, V13, P1243, DOI 10.1109/TITS.2012.2188630
   Chong YW, 2013, NEUROCOMPUTING, V116, P144, DOI 10.1016/j.neucom.2011.11.036
   Collado JM, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P572
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Cucchiara R., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P119, DOI 10.1109/6979.880969
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Dalal N, 2005, 2005 IEEE CVPR 05, V1
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Fan QF, 2016, IEEE INT VEH SYM, P124, DOI 10.1109/IVS.2016.7535375
   Fortun Denis, 2015, Computer Vision and Image Understanding, V134, P1, DOI 10.1016/j.cviu.2015.02.008
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Fu H., 2016, NEUROCOMPUTING
   Fytsilis AL, 2016, ISPRS J PHOTOGRAMM, V119, P165, DOI 10.1016/j.isprsjprs.2016.06.001
   Garcia F, 2012, 2012 IEEE INTELLIGENT VEHICLES SYMPOSIUM (IV), P494, DOI 10.1109/IVS.2012.6232199
   Gleason J, 2011, IEEE INT CONF ROBOT, P2065
   Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794
   Harville M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P90, DOI 10.1109/ICIP.2001.958058
   Haselhoff A, 2009, IEEE INT VEH SYM, P261, DOI 10.1109/IVS.2009.5164288
   Horprasert T., 1999, Proceedings of IEEE ICCV Frame-Rate Workshop, P1
   López-Rubio FJ, 2015, IMAGE VISION COMPUT, V37, P31, DOI 10.1016/j.imavis.2015.03.001
   Jazayeri A, 2011, IEEE T INTELL TRANSP, V12, P583, DOI 10.1109/TITS.2011.2113340
   Ji WY, 2016, CAAI T INTELL TECHNO, V1, P162, DOI 10.1016/j.trit.2016.09.001
   Jia DY, 2016, NEUROCOMPUTING, V203, P1, DOI 10.1016/j.neucom.2016.03.045
   KAEMPCHEN N, 2004, IEEE INT C INT TRANS
   Kafer Eugen, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4234, DOI 10.1109/ICPR.2010.1029
   Karlsruhe Institute of Technology, IM SEQ SERV
   Khairdoost N., 2013, Signal Image Process, V4, P31, DOI DOI 10.5121/SIPIJ.2013.4403
   Khammari A., 2005, 2005 IEEE Intelligent Transportation Systems Conference (ITSC), P66
   Kilger M., 1992, Proceedings. IEEE Workshop on Applications of Computer Vision (Cat. No.92TH0446-5), P11, DOI 10.1109/ACV.1992.240332
   Kim JB, 2003, PATTERN RECOGN LETT, V24, P113, DOI 10.1016/S0167-8655(02)00194-0
   Kim K, 2004, IEEE IMAGE PROC, P3061
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   KUEHNLE A, 1991, PATTERN RECOGN LETT, V12, P249, DOI 10.1016/0167-8655(91)90039-O
   Kuo YC, 2011, COMPUT MATH APPL, V61, P2096, DOI 10.1016/j.camwa.2010.08.081
   Lan JH, 2014, OPTIK, V125, P289, DOI 10.1016/j.ijleo.2013.06.036
   Li J, 2008, NEUROCOMPUTING, V71, P1771, DOI 10.1016/j.neucom.2007.11.032
   Li XB, 2002, PATTERN RECOGN, V35, P967, DOI 10.1016/S0031-3203(01)00079-6
   Li Y, 2015, TRANSPORT RES C-EMER, V51, P19, DOI 10.1016/j.trc.2014.10.009
   Lin BF, 2012, IEEE T INTELL TRANSP, V13, P737, DOI 10.1109/TITS.2011.2182649
   Liu Y, 2013, 2013 9TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P391, DOI 10.1109/CIS.2013.89
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mandellos NA, 2011, EXPERT SYST APPL, V38, P1619, DOI 10.1016/j.eswa.2010.07.083
   Martínez J, 2014, ADV INTELL SYST, V279, P293, DOI 10.1007/978-3-642-54927-4_28
   Mikic I, 2000, INT C PATT RECOG, P321, DOI 10.1109/ICPR.2000.905341
   Mu KN, 2016, OPTIK, V127, P4794, DOI 10.1016/j.ijleo.2016.01.017
   Muyun Weng, 2010, 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P285, DOI 10.1109/CISP.2010.5648259
   Negri P, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/782432
   O'Malley R., 2008, P 1 INT S VEH COMP S, V2224
   O'Malley R, 2010, IEEE T INTELL TRANSP, V11, P453, DOI 10.1109/TITS.2010.2045375
   Pavlic M, 2013, IEEE INT VEH SYM, P481, DOI 10.1109/IVS.2013.6629514
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Qadri MT, 2009, 2009 INTERNATIONAL CONFERENCE ON EDUCATION TECHNOLOGY AND COMPUTER, PROCEEDINGS, P335, DOI 10.1109/ICETC.2009.54
   Qing Ming, 2011, 2011 6th International Forum on Strategic Technology (IFOST 2011), P729, DOI 10.1109/IFOST.2011.6021126
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Rybski PE, 2010, IEEE INT VEH SYM, P921, DOI 10.1109/IVS.2010.5547996
   Schamm T, 2010, IEEE INT VEH SYM, P418, DOI 10.1109/IVS.2010.5548013
   Seki M., 2003, Computer Vision and Pattern Recognition, V2, P11
   Semertzidis T, 2010, IET INTELL TRANSP SY, V4, P103, DOI 10.1049/iet-its.2008.0092
   Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007
   Shah M, 2015, IMAGE VISION COMPUT, V38, P52, DOI 10.1016/j.imavis.2015.02.001
   Shen X.L, VISION DETECTION LAN
   Sivaraman S, 2014, MACH VISION APPL, V25, P599, DOI 10.1007/s00138-011-0388-y
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1597, DOI 10.1109/TITS.2013.2264314
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Sivaraman S, 2012, IEEE INT C INTELL TR, P1519, DOI 10.1109/ITSC.2012.6338886
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Skodras E., 2012, 2012 International Conference on Systems, Signals and Image Processing (IWSSIP), P134
   Sun ZH, 2006, IEEE T IMAGE PROCESS, V15, P2019, DOI 10.1109/TIP.2006.877062
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Teoh SS, 2012, MACH VISION APPL, V23, P831, DOI 10.1007/s00138-011-0355-7
   Thammakaroon P, 2009, PROC IEEE INT SYMP, P217, DOI 10.1109/ISIE.2009.5218254
   Tian B, 2015, TRANSPORT RES C-EMER, V56, P80, DOI 10.1016/j.trc.2015.02.020
   Tsai LW, 2007, IEEE T IMAGE PROCESS, V16, P850, DOI 10.1109/TIP.2007.891147
   Tzomakas C., 1998, VEHICLE DETECTION TR
   Varadarajan S, 2015, PATTERN RECOGN, V48, P3488, DOI 10.1016/j.patcog.2015.04.016
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang CC, 2005, IEEE INT SYMP CIRC S, P356
   Wang H., 2015, BIOMED RES INT, V2015, P8, DOI [DOI 10.1016/J.PETR0L.2015.08.010, DOI 10.1016/J.JBI0MECH.2015.08.006]
   Wang H, 2015, OPTIK, V126, P386, DOI 10.1016/j.ijleo.2014.09.010
   Wang XM, 2016, NEUROCOMPUTING, V173, P450, DOI 10.1016/j.neucom.2015.04.117
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Wei Liu, 2007, Proceedings of the 2007 IEEE Intelligent Vehicles Symposium, P252
   Wen XZ, 2015, IEEE T CIRC SYST VID, V25, P508, DOI 10.1109/TCSVT.2014.2358031
   Xia YJ, 2016, SIGNAL PROCESS, V120, P672, DOI 10.1016/j.sigpro.2014.10.035
   Xia YJ, 2015, SIGNAL PROCESS, V112, P98, DOI 10.1016/j.sigpro.2014.07.025
   Yan G., 2016, OPTIK INT J LIGHT EL
   Yang Y, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.245
   Zhan W, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.1017
   Zhang W, 2010, DIGIT SIGNAL PROCESS, V20, P793, DOI 10.1016/j.dsp.2009.10.006
   Zhang W, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2731329
   Zhang XT, 2011, IEEE INT C INTELL TR, P1555, DOI 10.1109/ITSC.2011.6083135
   Zhao N, 2016, J VIS COMMUN IMAGE R, V37, P25, DOI 10.1016/j.jvcir.2015.04.011
   Zhou Y, 2016, LECT NOTES COMPUT SC, V9906, P278, DOI 10.1007/978-3-319-46475-6_18
   Zhu Y, 2006, IEEE T INTELL TRANSP, V7, P401, DOI 10.1109/TITS.2006.883936
   ZIELKE T, 1993, CVGIP-IMAG UNDERSTAN, V58, P177, DOI 10.1006/ciun.1993.1037
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 122
TC 140
Z9 147
U1 8
U2 114
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 143
EP 154
DI 10.1016/j.imavis.2017.09.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100012
DA 2024-07-18
ER

PT J
AU Ghiani, L
   Yambay, DA
   Mura, V
   Marcialis, GL
   Roli, F
   Schuckers, SA
AF Ghiani, Luca
   Yambay, David A.
   Mura, Valerio
   Marcialis, Gian Luca
   Roli, Fabio
   Schuckers, Stephanie A.
TI Review of the Fingerprint Liveness Detection (LivDet) competition
   series: 2009 to 2015
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fingerprint; Liveness detection; Biometric
ID VITALITY DETECTION; DESCRIPTOR; FEATURES
AB A spoof attack, a subset of presentation attacks, is the use of an artificial replica of a biometric in an attempt to circumvent a biometric sensor. Liveness detection, or presentation attack detection, distinguishes between live and fake biometric traits and is based on the principle that additional information can be garnered above and beyond the data procured by a standard authentication system to determine if a biometric measure is authentic.
   The goals for the Liveness Detection (LivDet) competitions are to compare software-based fingerprint liveness detection and artifact detection algorithms (Part 1), as well as fingerprint systems which incorporate liveness detection or artifact detection capabilities (Part 2), using a standardized testing protocol and large quantities of spoof and live tests. The competitions are open to all academic and industrial institutions which have a solution for either software-based or system-based fingerprint liveness detection. The LivDet competitions have been hosted in 2009, 2011, 2013 and 2015 and have shown themselves to provide a crucial look at the current state of the art in liveness detection schemes. There has been a noticeable increase in the number of participants in LivDet competitions as well as a noticeable decrease in error rates across competitions. Participants have grown from four to the most recent thirteen submissions for Fingerprint Part 1. Fingerprints Part 2 has held steady at two submissions each competition in 2011 and 2013 and only one for the 2015 edition. The continuous increase of competitors demonstrates a growing interest in the topic. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Ghiani, Luca; Mura, Valerio; Marcialis, Gian Luca; Roli, Fabio] Univ Cagliari, Dept Elect & Elect Engn, Cagliari, Italy.
   [Yambay, David A.; Schuckers, Stephanie A.] Clarkson Univ, Dept Elect & Comp Engn, Potsdam, NY 13676 USA.
C3 University of Cagliari; Clarkson University
RP Ghiani, L (corresponding author), Univ Cagliari, Dept Elect & Elect Engn, Cagliari, Italy.
EM luca.ghiani@diee.unica.it; yambayda@clarkson.edu;
   valerio.mura@diee.unica.it; marcialis@diee.unica.it; roli@diee.unica.it;
   sschucke@clarkson.edu
RI Marcialis, Gian Luca/ABB-3299-2020; Marcialis, Gian Luca/IZE-2107-2023;
   Schuckers, Stephanie/F-6197-2017
OI Schuckers, Stephanie/0000-0002-9365-9642; Ghiani,
   Luca/0000-0002-4636-8957; Marcialis, Gian Luca/0000-0002-8719-9643;
   ROLI, FABIO/0000-0003-4103-9190
FU Center for Identification Technology Research; National Science
   Foundation [1068055]; Regione Autonoma della Sardegna [CRP-59872, L.R.
   7/2007]; Direct For Computer & Info Scie & Enginr; Division Of Computer
   and Network Systems [1068055] Funding Source: National Science
   Foundation
FX The first and second author had equal contributions to the research.
   This work has been supported by the Center for Identification Technology
   Research and the National Science Foundation under Grant No. 1068055,
   and by the project "Computational quantum structures at the service of
   pattern recognition: modeling uncertainty"[CRP-59872] funded by Regione
   Autonoma della Sardegna, L.R. 7/2007, Bando 2012.
CR Alonso-Fernandez Fernando., 2013, Halmstad university submission to the first icb competition on iris recognition (icir2013)
   [Anonymous], IET BIOMETRICS
   [Anonymous], 2002, Inf. Secur. Tech. Rep., DOI DOI 10.1016/S1363-4127(02)00407-7
   [Anonymous], WORK C SMART RES ADV
   [Anonymous], 2013, C BIOMETRICS ICB 201
   [Anonymous], BIOM IJCB 2014 IEEE
   Cappelli R., 2007, BIOM TECHNOL TODAY, V15
   Chakka MM, 2011, BIOM IJCB 2011 INT J
   Coli P, 2007, LECT NOTES COMPUT SC, V4642, P722
   Coli P, 2008, INT J IMAGE GRAPH, V8, P495, DOI 10.1142/S0219467808003209
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Galbally J, 2012, FUTURE GENER COMP SY, V28, P311, DOI 10.1016/j.future.2010.11.024
   Ghiani L., EXPT RESULTS FINGERP, P210
   Gragnaniello D, 2014, ELECTRON LETT, V50, P439, DOI 10.1049/el.2013.4044
   Gragnaniello D, 2015, PATTERN RECOGN, V48, P1050, DOI 10.1016/j.patcog.2014.05.021
   Jia XF, 2014, LECT NOTES COMPUT SC, V8833, P216, DOI 10.1007/978-3-319-12484-1_24
   Jia XF, 2014, INFORM SCIENCES, V268, P91, DOI 10.1016/j.ins.2013.06.041
   Jiang Y., 2015, International Journal of Signal Processing, Image Processing and Pattern Recognition (2015)
   Johnson P., 2014, P INT C BIOM SPEC IN, P18
   Kallo P., 2001, US patent, Patent No. 6175641
   Marasco E., 2010, Biometric Measurements and Systems for Security and Medical Applications (BIOMS), 2010 IEEE Workshop on, P8
   Marasco E, 2012, PATTERN RECOGN LETT, V33, P1148, DOI 10.1016/j.patrec.2012.01.009
   Marcialis G., 2013, 6 IAPR IEEE INT C BI
   Marcialis G. L., 7 IEEE INT C BIOM TH
   Marcialis G. L., 2009, 1 INT FINGERPRINT LI
   Matsumoto T., P SPIE, V4677
   Nogueira RF, 2014, 2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS, P22, DOI 10.1109/BIOMS.2014.6951531
   Poh N, 2014, EUR SIGNAL PR CONF, P1377
   Rattani A, 2015, IEEE T INF FOREN SEC, V10, P2447, DOI 10.1109/TIFS.2015.2464772
   Sequeira AF, 2015, SENSORS-BASEL, V15, P14615, DOI 10.3390/s150614615
   Tan BZ, 2010, PATTERN RECOGN, V43, P2845, DOI 10.1016/j.patcog.2010.01.023
   Watson C., Users guide to nist biometric image software
   WILLIS D, 1998, NETWORK COMPUTIN JUN
   Yambay D., 2014, IEEE INT JOINT C BIO
   Yambay D., 2012, 5 IAPR IEEE INT C BI
   Zhang YL, 2014, LECT NOTES COMPUT SC, V8833, P191, DOI 10.1007/978-3-319-12484-1_21
NR 36
TC 71
Z9 74
U1 2
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 110
EP 128
DI 10.1016/j.imavis.2016.07.002
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700012
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Zhu, JQ
   Liao, SC
   Lei, Z
   Li, SZ
AF Zhu, Jianqing
   Liao, Shengcai
   Lei, Zhen
   Li, Stan Z.
TI Multi-label convolutional neural network based pedestrian attribute
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pedestrian attribute classification; Multi-label classification;
   Convolutional neural network
AB Recently, pedestrian attributes like gender, age, clothing etc., have been used as soft biometric traits for recognizing people. Unlike existing methods that assume the independence of attributes during their prediction, we propose a multi-label convolutional neural network(MLCNN) to predict multiple attributes together in a unified framework. Firstly, a pedestrian image is roughly divided into multiple overlapping body parts, which are simultaneously integrated in the multi-label convolutional neural network. Secondly, these parts are filtered independently and aggregated in the cost layer. The cost function is a combination of multiple binary attribute classification cost functions. Experiments show that the proposed method significantly outperforms the SVM based method on the PETA database. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zhu, Jianqing] Huaqiao Univ, Coll Engn, Quanzhou 362021, Fujian, Peoples R China.
   [Liao, Shengcai; Lei, Zhen; Li, Stan Z.] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Ctr Biometr & Secur Res, Beijing 100190, Peoples R China.
C3 Huaqiao University; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Liao, SC (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Ctr Biometr & Secur Res, Beijing 100190, Peoples R China.
EM jqzhu@hqu.edu.cn; scliao@nlpr.ia.ac.cn; zlei@nlpr.ia.ac.cn;
   szli@nlpr.ia.ac.cn
RI Li, SY/JPK-3839-2023; Zhu, Jianqing/AHA-0351-2022
OI Li, SY/0009-0000-9254-7115; Zhu, Jianqing/0000-0001-8840-3629; Liao,
   Shengcai/0000-0001-8941-2295
FU Scientific Research Funds of Huaqiao University [16BS108]; National
   Natural Science Foundation of China [61602191, 61375037, 61473291,
   61572501, 61502491, 61572536]; Chinese Academy of Sciences Project
   [KGZD-EW-102-2]
FX This work was supported in part by the Scientific Research Funds of
   Huaqiao University under the Grant 16BS108, in part by the National
   Natural Science Foundation of China under the Grants 61602191, 61375037,
   61473291, 61572501, 61502491 and 61572536, in part by the Chinese
   Academy of Sciences Project under the Grant KGZD-EW-102-2.
CR [Anonymous], ARXIV13124894
   [Anonymous], 2010, 2010 4 IEEE INT C BI
   [Anonymous], IEEE INT WORKSH PERF
   [Anonymous], 2006, PATTERN RECOGN, DOI DOI 10.1117/1.2819119
   [Anonymous], ARXIV14085093
   [Anonymous], ARXIV150100901
   [Anonymous], ARXIV12070580
   [Anonymous], 2013, 2013 7 INT C DISTR S
   Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44
   Dantcheva A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1356, DOI 10.1109/ICCVW.2011.6130409
   Dantcheva A., 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P511, DOI 10.1109/MMSP.2010.5662074
   Dean Jeffrey., 2012, Advances in Neural Information Processing Systems, V25, P1223
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Jaha ES, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Jaha ES, 2014, LECT NOTES COMPUT SC, V8897, P234, DOI 10.1007/978-3-319-13386-7_19
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Layne R, 2014, ADV COMPUT VIS PATT, P93, DOI 10.1007/978-1-4471-6296-4_5
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee H., 2009, P 26 ANN INT C MACH, P609
   Li AN, 2015, IEEE T CIRC SYST VID, V25, P869, DOI 10.1109/TCSVT.2014.2352552
   Liu CX, 2012, LECT NOTES COMPUT SC, V7583, P391, DOI 10.1007/978-3-642-33863-2_39
   Maji S., 2008, CVPR
   Martinson E, 2013, ACMIEEE INT CONF HUM, P49, DOI 10.1109/HRI.2013.6483501
   Reid DA, 2014, IEEE T PATTERN ANAL, V36, P1216, DOI 10.1109/TPAMI.2013.219
   Zhu J., 2014, P AS C COMP VIS, P545
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
   Zhu JQ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P331, DOI 10.1109/ICCVW.2013.51
NR 34
TC 79
Z9 87
U1 1
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 224
EP 229
DI 10.1016/j.imavis.2016.07.004
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700021
DA 2024-07-18
ER

PT J
AU Bengtsson, T
   McKelvey, T
   Lindström, K
AF Bengtsson, Tomas
   McKelvey, Tomas
   Lindstrom, Konstantin
TI On robust optical flow estimation on image sequences with differently
   exposed frames using primal-dual optimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optical flow estimation; High dynamic range; Temporal coherency;
   Primal-dual
AB Optical flow methods are used to estimate pixelwise motion information based on consecutive frames in image sequences. The image sequences traditionally contain frames that are similarly exposed. However, many real-world scenes contain high dynamic range content that cannot be captured well with a single exposure setting. Such scenes result in certain image regions being over- or underexposed, which can negatively impact the quality of motion estimates in those regions. Motivated by this, we propose to capture high dynamic range scenes using different exposure settings every other frame. A framework for OF estimation on such image sequences is presented, that can straightforwardly integrate techniques from the state-of-the-art in conventional OF methods. Different aspects of robustness of OF methods are discussed, including estimation of large displacements and robustness to natural illumination changes that occur between the frames, and we demonstrate experimentally how to handle such challenging flow estimation scenarios. The flow estimation is formulated as an optimization problem whose solution is obtained using an efficient primal-dual method. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Bengtsson, Tomas; McKelvey, Tomas] Chalmers Univ Technol, Gothenburg, Sweden.
   [Lindstrom, Konstantin] Volvo Cars AB, Gothenburg, Sweden.
C3 Chalmers University of Technology; Volvo
RP Bengtsson, T (corresponding author), Chalmers Univ Technol, Gothenburg, Sweden.
EM tomasbengtsson83@gmail.com
RI McKelvey, Tomas/B-6801-2016
OI McKelvey, Tomas/0000-0003-2982-5535
FU Swedish research agency VINNOVA [2013-04702]; Volvo Cars; Vinnova
   [2013-04702] Funding Source: Vinnova
FX This work is funded by the Swedish research agency VINNOVA under project
   2013-04702, and by Volvo Cars.
CR Allen E., 2012, MANUAL PHOTOGRAPHY D
   [Anonymous], FOUND TRENDS OPTIM, DOI DOI 10.1561/2400000003
   [Anonymous], 2015, Computer Graphics Forum
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bengtsson T, 2015, OPT ENG, V54, DOI 10.1117/1.OE.54.9.093103
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Boyd S., 2009, CONVEX OPTIMIZATION
   Bredies K, 2014, LECT NOTES COMPUT SC, V8293, P44, DOI 10.1007/978-3-642-54774-4_3
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Cremers D, 2005, INT J COMPUT VISION, V62, P249, DOI 10.1007/s11263-005-4882-4
   Crum WR, 2004, BRIT J RADIOL, V77, pS140, DOI 10.1259/bjr/25329214
   Demetz O, 2014, LECT NOTES COMPUT SC, V8689, P455, DOI 10.1007/978-3-319-10590-1_30
   Esser E, 2010, SIAM J IMAGING SCI, V3, P1015, DOI 10.1137/09076934X
   Geiger A., 2015, The KITTI vision Benchmark Suite
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Giachetti A, 1998, IEEE T ROBOTIC AUTOM, V14, P34, DOI 10.1109/70.660838
   Hadziabdic K., 2013, Proceedings of the 29th Spring Conference on Computer Graphics, P21
   Hafner D, 2014, INT C PATT RECOG, P2065, DOI 10.1109/ICPR.2014.360
   Harris C., 1988, P ALV VIS C, P5210
   Heidrich Wolfgang, ERIK REINHARD
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Li YY, 2009, COMMUN MATH SCI, V7, P741
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Muller Thomas, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P236, DOI 10.1007/978-3-642-23123-0_24
   Revaud J., 2015, ARXIV150102565
   Rockafellar T, 1997, CONVEX ANAL
   Salgado A, 2007, LECT NOTES COMPUT SC, V4739, P709
   Shulman D., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P81, DOI 10.1109/WVM.1989.47097
   Stoll Michael, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P1, DOI 10.1007/978-3-642-37431-9_1
   Vogel C, 2013, LECT NOTES COMPUT SC, V8142, P343, DOI 10.1007/978-3-642-40602-7_37
   Volz S, 2011, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2011.6126359
   Wedel A, 2011, STEREO SCENE FLOW FOR 3D MOTION ANALYSIS, P1, DOI 10.1007/978-0-85729-965-9
   Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Zhu M., 2008, EFFICIENT PRIMAL DUA, V34, P8
   Zimmer H, 2011, COMPUT GRAPH FORUM, V30, P405, DOI 10.1111/j.1467-8659.2011.01870.x
   [No title captured]
NR 42
TC 5
Z9 5
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 78
EP 88
DI 10.1016/j.imavis.2016.11.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wu, L
   Wang, Y
AF Wu, Lin
   Wang, Yang
TI Robust hashing for multi-view data: Jointly learning low-rank kernelized
   similarity consensus and hash functions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiple feature learning; Robust hashing; Low-rank recovery
ID REPRESENTATION
AB Learning hash functions/codes for similarity search over multi-view data is attracting increasing attention, where similar hash codes are assigned to the data objects characterizing consistently neighborhood relationship across views. Traditional methods in this category inherently suffer three limitations: 1) they commonly adopt a two-stage scheme where similarity matrix is first constructed, followed by a subsequent hash function learning; 2) these methods are commonly developed on the assumption that data samples with multiple representations are noise-free,which is not practical in real-life applications; and 3) they often incur cumbersome training model caused by the neighborhood graph construction using all N points in the database (O(N)). In this paper, we motivate the problem of jointly and efficiently training the robust hash functions over data objects with multi-feature representations which may be noise corrupted. To achieve both the robustness and training efficiency, we propose an approach to effectively and efficiently learning low-rank kemelizedl hash functions shared across views. Specifically, we utilize landmark graphs to construct tractable similarity matrices in multi-views to automatically discover neighborhood structure in the data. To learn robust hash functions, a latent low-rank kernel function is used to construct hash functions in order to accommodate linearly inseparable data. In particular, a latent kernelized similarity matrix is recovered by rank minimization on multiple kernel-based similarity matrices. Extensive experiments on real-world multi-view datasets validate the efficacy of our method in the presence of error corruptions. We use kernelized similarity rather than kernel, as it is not a squared symmetric matrix for data-landmark affinity matrix. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Wu, Lin] Univ Adelaide, Sch Comp Sci, Adelaide, SA, Australia.
   [Wu, Lin] Australian Ctr Robot Vis, Brisbane, Qld, Australia.
   [Wang, Yang] Univ New South Wales, Sch Comp Sci & Engn, Sydney, NSW, Australia.
C3 University of Adelaide; Australian Centre for Robotic Vision; University
   of New South Wales Sydney
RP Wu, L (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA, Australia.
EM lin.wu@adelaide.edu.au; wangy@cse.unsw.edu.au
RI Wu, Lin Yuanbo/HME-1691-2023
OI Wu, Lin Yuanbo/0000-0001-6119-058X
CR [Anonymous], 2008, NIPS
   [Anonymous], ICML
   [Anonymous], IJCAI
   [Anonymous], 2004, NIPS
   [Anonymous], ICML
   [Anonymous], 2011, ICML
   [Anonymous], 1998, P IEEE
   [Anonymous], 2009, ADV NEURAL INFORM PR
   [Anonymous], 2009, ICCV
   [Anonymous], 2015, MACH LEARN, DOI DOI 10.1007/s10994-014-5469-5
   [Anonymous], 2008, ICML
   [Anonymous], 2009, ACM CIVR
   [Anonymous], 2004, SOCG
   [Anonymous], 2010, ICML
   Bengio Y, 2004, NEURAL COMPUT, V16, P2197, DOI 10.1162/0899766041732396
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Deng Y, 2013, IEEE T NEUR NET LEAR, V24, P383, DOI 10.1109/TNNLS.2012.2235082
   Kim S, 2012, LECT NOTES COMPUT SC, V7576, P538, DOI 10.1007/978-3-642-33715-4_39
   Kumar A., 2011, ADV NEURAL INFORM PR, V24
   Kumar Shaishav, 2011, P 22 INT JOINT C ART, P1360, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-230
   LI S., 2015, SDM. SIAM, P748, DOI 10.1137/1.9781611974010.84
   Lin Z., 2010, ARXIV1009 5055
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu X, 2012, APPL MECH MATER, V174-177, P881, DOI 10.4028/www.scientific.net/AMM.174-177.881
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Masci J, 2014, IEEE T PATTERN ANAL, V36, P824, DOI 10.1109/TPAMI.2013.225
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ou MD, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P230
   Shen FM, 2013, PROC CVPR IEEE, P1562, DOI 10.1109/CVPR.2013.205
   Shen XB, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P831, DOI 10.1145/2733373.2806342
   Song J., 2011, P 19 ACM INT C MULT, P423, DOI DOI 10.1145/2072298.2072354
   Wang J, 2010, PROC CVPR IEEE, P3424, DOI 10.1109/CVPR.2010.5539994
   Wang QF, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3904
   Wang Y, 2016, KNOWL INF SYST, V46, P515, DOI 10.1007/s10115-015-0833-8
   Wang Y, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P981, DOI 10.1145/2647868.2654999
   Wang Y, 2015, IEEE T IMAGE PROCESS, V24, P3939, DOI 10.1109/TIP.2015.2457339
   Wang Y, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P805, DOI 10.1145/2505515.2505591
   Wei Y, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P791, DOI 10.1145/2623330.2623688
   Xia RK, 2014, AAAI CONF ARTIF INTE, P2149
   Xu C., 2013, arXiv
   Yang Wang, 2013, Advances in Knowledge Discovery and Data Mining. 17th Pacific-Asia Conference (PAKDD 2013). Proceedings, P449, DOI 10.1007/978-3-642-37456-2_38
   Ye GN, 2012, PROC CVPR IEEE, P3021, DOI 10.1109/CVPR.2012.6248032
   Zhang D, 2011, PROCEEDINGS OF THE 34TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR'11), P225
   Zhang Z, 2016, IEEE T IMAGE PROCESS, V25, P2429, DOI 10.1109/TIP.2016.2547180
   Zhang Z, 2015, KNOWL-BASED SYST, V86, P143, DOI 10.1016/j.knosys.2015.06.001
   Zhang Z, 2014, NEURAL NETWORKS, V53, P81, DOI 10.1016/j.neunet.2014.01.001
   Zheng S, 2015, AAAI CONF ARTIF INTE, P1973
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 50
TC 29
Z9 29
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 58
EP 66
DI 10.1016/j.imavis.2016.11.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sanchez-Reillo, R
AF Sanchez-Reillo, Raul
TI Signature analysis in the context of mobile devices
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Biometrics Conference
CY OCT, 2015
CL London, ENGLAND
DE Handwritten signature; Biometrics; Static signature recognition; Dynamic
   signature recognition; Forgeries; User confidence
ID RECOGNITION; ONLINE
AB Handwritten signature is one of the oldest means of the human being to both authenticate him/herself and state that a certain document has been understood and accepted. In the modem world, this biometric modality was translated to the use of peripheral pads that allow the signature to be performed by the user. However, in the recent years, the proliferation of mobile devices with touch screens has paved the path to deploy this biometric modality beyond the limits of a desktop. Bringing this biometric modality to mobile devices open several challenges, being some of them already covered, but some others needing further study. This paper provides an overview of these challenges and point to future research works that can help to the continuous deployment of this biometric modality. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Sanchez-Reillo, Raul] Univ Carlos III Madrid, Univ Grp Identificat Technol, Avda Univ 30, E-28911 Madrid, Spain.
C3 Universidad Carlos III de Madrid
RP Sanchez-Reillo, R (corresponding author), Univ Carlos III Madrid, Univ Grp Identificat Technol, Avda Univ 30, E-28911 Madrid, Spain.
EM rsreillo@ing.uc3m.es
RI Sanchez-Reillo, Raul/Z-3333-2019
OI Sanchez-Reillo, Raul/0000-0003-4239-985X
CR [Anonymous], 2014, IEEE INT JOINT C BIO, DOI DOI 10.1109/BTAS.2014.6996245
   [Anonymous], 2014, P 10 NCEE
   Blanco-Gonzalo R, 2014, IMAGE VISION COMPUT, V32, P1173, DOI 10.1016/j.imavis.2014.09.003
   Blanco-Gonzalo R, 2014, IET BIOMETRICS, V3, P139, DOI 10.1049/iet-bmt.2013.0044
   Campisi P., 2013, SECURITY PRIVACY BIO, VVol. 24
   Guerra-Casanova J, 2012, INT J INF SECUR, V11, P65, DOI 10.1007/s10207-012-0154-9
   Impedovo D, 2008, IEEE T SYST MAN CY C, V38, P609, DOI 10.1109/TSMCC.2008.923866
   Pascual-Gaspar JM, 2009, LECT NOTES COMPUT SC, V5558, P1180, DOI 10.1007/978-3-642-01793-3_119
   Plamondon R, 2000, IEEE T PATTERN ANAL, V22, P63, DOI 10.1109/34.824821
   Santo DianaEspirito., 2013, The Social Life of Spirits, P1
   Vera-Rodriguez R., 2015, BIOM FOR IWBF 2015 I, P1
NR 11
TC 4
Z9 4
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
BP 34
EP 37
DI 10.1016/j.imavis.2016.03.011
PN 1
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA ED8BO
UT WOS:000389097100010
DA 2024-07-18
ER

PT J
AU Moreno-Noguer, F
   Porta, JM
AF Moreno-Noguer, Francesc
   Porta, Josep M.
TI A Bayesian approach to simultaneously recover camera pose and non-rigid
   shape from monocular images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deformable surfaces; Pose estimation; Bayesian belief networks; SLAM
ID STRUCTURE-FROM-MOTION; MODELS; SURFACES
AB In this paper we bring the tools of the Simultaneous Localization and Map Building (SLAM) problem from a rigid to a deformable domain and use them to simultaneously recover the 3D shape of non-rigid surfaces and the sequence of poses of a moving camera. Under the assumption that the surface shape may be represented as a weighted sum of deformation modes, we show that the problem of estimating the modal weights along with the camera poses, can be probabilistically formulated as a maximum a posteriori estimate and solved using an iterative least squares optimization. In addition, the probabilistic formulation we propose is very general and allows introducing different constraints without requiring any extra complexity. As a proof of concept, we show that local inextensibility constraints that prevent the surface from stretching can be easily integrated.
   An extensive evaluation on synthetic and real data, demonstrates that our method has several advantages over current non-rigid shape from motion approaches. In particular, we show that our solution is robust to large amounts of noise and outliers and that it does not need to track points over the whole sequence nor to use an initialization close from the ground truth. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Moreno-Noguer, Francesc; Porta, Josep M.] CSIC UPC, Inst Robot & Informat Ind, Llorens Artigas 4-6, Barcelona 08028, Spain.
C3 Universitat Politecnica de Catalunya; Consejo Superior de
   Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i
   Informatica Industrial (IRII)
RP Moreno-Noguer, F (corresponding author), CSIC UPC, Inst Robot & Informat Ind, Llorens Artigas 4-6, Barcelona 08028, Spain.
EM fmoreno@iri.upc.edu; porta@iri.upc.edu
RI Porta, Josep M/L-5069-2014
FU Spanish Ministry of Economy and Competitiveness [RobInstruct
   TIN2014-58178-R, RobCab DPI2014-57220-C2-2-P]; ERA-net CHISTERA project
   [I-DRESS PCIN-2015-147]
FX This work has been partially funded by Spanish Ministry of Economy and
   Competitiveness under projects RobInstruct TIN2014-58178-R and RobCab
   DPI2014-57220-C2-2-P; and by the ERA-net CHISTERA project I-DRESS
   PCIN-2015-147.
CR Agudo A, 2016, IEEE T PATTERN ANAL, V38, P979, DOI 10.1109/TPAMI.2015.2469293
   Agudo A, 2012, PROC CVPR IEEE, P1418
   [Anonymous], 2007, ROBOTICS SCI SYSTEMS
   Barth AdamT., 2008, BodyNets'08: Proceedings of the ICST 3rd international conference on Body area networks, P1
   Bhat Kiran S., 2003, Proceedings of the 2003 ACM SIGGRAPH/Eurographics symposium on Computer animation, P37
   Biber P, 2009, INT J ROBOT RES, V28, P20, DOI 10.1177/0278364908096286
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Brand M, 2001, PROC CVPR IEEE, P456
   Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dani AP, 2011, IEEE DECIS CONTR P, P5005, DOI 10.1109/CDC.2011.6161117
   Davis T., 2009, ACM T MATH SOFTW, V38
   Dellaert F, 2006, INT J ROBOT RES, V25, P1181, DOI 10.1177/0278364906072768
   Ecker A, 2008, LECT NOTES COMPUT SC, V5302, P127, DOI 10.1007/978-3-540-88682-2_11
   Fayad J., 2010, EUR C COMP VIS
   Guan Peng, 2009, INT C COMP VIS
   Hartley R, 2008, LECT NOTES COMPUT SC, V5302, P276, DOI 10.1007/978-3-540-88682-2_22
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706
   Kawewong A, 2011, INT J ROBOT RES, V30, P33, DOI 10.1177/0278364910371855
   LEONARD JJ, 1992, INT J ROBOT RES, V11, P286, DOI 10.1177/027836499201100402
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   McInerney T., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P518, DOI 10.1109/ICCV.1993.378169
   Metaxas D., 1993, IEEE Transactions on Pattern Analysis and Machine Intelligence, V15, P580
   Moreno-Noguer F., 2007, INT C COMP VIS
   Moreno-Noguer F, 2013, IEEE T PATTERN ANAL, V35, P463, DOI 10.1109/TPAMI.2012.102
   Moreno-Noguer F, 2011, PROC CVPR IEEE, P1289, DOI 10.1109/CVPR.2011.5995532
   Moreno-Noguer F, 2010, LECT NOTES COMPUT SC, V6313, P370
   Moreno-Noguer F, 2009, PROC CVPR IEEE, P1842, DOI 10.1109/CVPRW.2009.5206758
   Muñoz E, 2009, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2009.5459366
   Newcombe RA, 2011, IEEE I CONF COMP VIS, P2320, DOI 10.1109/ICCV.2011.6126513
   Olson E, 2006, IEEE INT CONF ROBOT, P2262, DOI 10.1109/ROBOT.2006.1642040
   Paladini Marco, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2898, DOI 10.1109/CVPRW.2009.5206602
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P715, DOI 10.1109/34.85660
   PERRIOLLAT M, 2008, BRIT MACH VIS C
   Rabaud V, 2009, PROC CVPR IEEE, P2419
   Salzmann M, 2008, LECT NOTES COMPUT SC, V5305, P581, DOI 10.1007/978-3-540-88693-8_43
   Salzmann M, 2009, PROC CVPR IEEE, P1054, DOI 10.1109/CVPRW.2009.5206759
   Sánchez-Riera J, 2010, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2010.5539831
   SMITH RC, 1986, INT J ROBOT RES, V5, P56, DOI 10.1177/027836498600500404
   Tardós JD, 2002, INT J ROBOT RES, V21, P311, DOI 10.1177/027836402320556340
   Taylor J, 2010, PROC CVPR IEEE, P2761, DOI 10.1109/CVPR.2010.5540002
   Terzopoulos D., 1987, COMPUT GRAPH, P205, DOI DOI 10.1145/37402.37427
   Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Tsap LV, 2000, IEEE T PATTERN ANAL, V22, P526, DOI 10.1109/34.857007
   Walter MR, 2007, INT J ROBOT RES, V26, P335, DOI 10.1177/0278364906075026
   Xiao J, 2005, IEEE I CONF COMP VIS, P1075
   Zhang W., 2008, EUR C COMP VIS, P720
NR 50
TC 1
Z9 1
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 141
EP 153
DI 10.1016/j.imavis.2016.05.012
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400011
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hernandez, M
   Choi, J
   Medioni, G
AF Hernandez, Matthias
   Choi, Jongmoo
   Medioni, Gerard
TI Near laser-scan quality 3-D face reconstruction from a low-quality depth
   stream
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Kinect; 3D reconstruction; Face modeling
ID REGISTRATION
AB We propose a method to produce near laser-scan quality 3-D face models of a freely moving user with a low-cost, low resolution range sensor in real-time. Our approach does not require any prior knowledge about the geometry of a face and can produce faithful geometric models of any star-shaped object. We use a cylindrical representation, which enables us to efficiently process the 3-D mesh by applying 2-D filters.
   We use the first frame as a reference and incrementally build the model by registering each subsequent cloud of 3-D points to the reference using the ICP (Iterative Closest Point) algorithm implemented on a GPU (Graphics Processing Unit). The registered point clouds are merged into a single image through a cylindrical representation. The noise from the sensor and from the pose estimation error is removed with a temporal integration and a spatial smoothing of the successively incremented model. To validate our approach, we quantitatively compare our model to laser scans, and show comparable accuracy.(1) (C) 2015 Elsevier B.V. All rights reserved.
C1 [Hernandez, Matthias; Choi, Jongmoo; Medioni, Gerard] Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Hernandez, M (corresponding author), Univ So Calif, Inst Robot & Intelligent Syst, 3737 Watt Way PHE 222, Los Angeles, CA 90089 USA.
EM mtheman@usc.edu; jongmooc@usc.edu; medioni@usc.edu
FU HP Labs Innovation Research Program [CW 218094]; IT R&D program of
   MOTIE/KEIT [10041610]
FX This research is funded in part by HP Labs Innovation Research Program
   (CW 218094) and the IT R&D program of MOTIE/KEIT (10041610).
CR Alexander O, 2010, IEEE COMPUT GRAPH, V30, P20, DOI 10.1109/MCG.2010.65
   Amberg B., 2007, COMP VIS WORKSH ICCV
   Anasosalu PK, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P67, DOI 10.1109/ICCVW.2013.16
   Andersen M. R., 2012, ECETR6 AARH U DEP EN
   Arras K., 1998, EPFLASLTR9801R3 EC P
   Bleiweiss A., 2010, MULT SIGN PROC MMSP
   Bradley D., 2010, IEEE COMPUT GRAPH AP, V30
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Choi J., 2012, INT C PATT REC ICPR
   Choi J., 2012, IEEE WINT C APPL COM
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Gribbon KT, 2004, INT SYM ELECT DES TE, P126
   Hernandez M, 2012, EUR SIGNAL PR CONF, P1995
   Izadi S., 2011, ACM SIGGRAPH 23
   Kemelmacher-Shlizerman I., 2011, COMP VIS WORKSH ICCV
   Le V., 2010, INT C IM PROC
   Li BYL, 2013, IEEE WORK APP COMP, P186, DOI 10.1109/WACV.2013.6475017
   Li H, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618521
   Lin Y., 2010, IEEE C COMP VIS PATT
   Luebke D., 2007, IEEE COMPUT, P126
   Malassiotis S., 2004, ROBUST REAL TIME 3D
   Marcio A.C. S. S., 2013, SBC J 3D INTERACTIVE, V4, P2
   Medioni G, 2009, IEEE T SYST MAN CY A, V39, P12, DOI 10.1109/TSMCA.2008.2007979
   Meyer G., 2013, MULT EXP WORKSH ICME, P1
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Smisek J., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1154, DOI 10.1109/ICCVW.2011.6130380
   Solutions D., 2011, DEMONSTRATION SIGGRA
   Sun Q., 2012, IMAGE ANAL SIGNAL PR, P1, DOI [10.1109/IASP.2012.6425065, DOI 10.1109/IASP.2012.6425065]
   Tamaki T., 2010, IEEE C COMP VIS PATT
   Tang LA, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P467, DOI 10.1109/ICIP.1996.560532
   Tena J.-R., 2011, SIGGRAPH2011
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Williams L, 1990, COMPUT GRAPH, V24
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zollhofer M., 2011, COMPUT ANIMAT VIRTUA, V22
NR 37
TC 18
Z9 21
U1 0
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2015
VL 36
BP 61
EP 69
DI 10.1016/j.imavis.2014.12.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CG2GV
UT WOS:000353093800006
DA 2024-07-18
ER

PT J
AU Kordelas, GA
   Alexiadis, DS
   Daras, P
   Izquierdo, E
AF Kordelas, Georgios A.
   Alexiadis, Dimitrios S.
   Daras, Petros
   Izquierdo, Ebroul
TI Enhanced disparity estimation in stereo images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo vision; Stereo matching; Disparity estimation; Scanline
   optimization; Outliers handling
ID BELIEF PROPAGATION
AB This paper presents a novel stereo disparity estimation method, which combines three different cost metrics, defined using RGB information, the CENSUS transform, as well as Scale-Invariant Feature Transform coefficients. The selected cost metrics are aggregated based on an adaptive weight approach, in order to calculate their corresponding cost volumes. The resulting cost volumes are then merged into a combined one, following a novel twophase strategy, which is further refined by exploiting scanline optimization. A mean-shift segmentation-driven approach is exploited to deal with outliers in the disparity maps. Additionally, low-textured areas are handled using disparity histogram analysis, which allows for reliable disparity plane fitting on these areas. Finally, an efficient two-step approach is introduced to refine disparity discontinuities. Experiments performed on the four images of the Middlebury benchmark demonstrate the accuracy of this methodology, which currently ranks first among published methods. Moreover, this algorithm is tested on 27 additional Middlebury stereo pairs for evaluating thoroughly its performance. The extended comparison verifies the efficiency of this work. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Kordelas, Georgios A.; Alexiadis, Dimitrios S.; Daras, Petros] Ctr Res & Technol Hellas, Inst Informat Technol, GR-57001 Thessaloniki, Greece.
   [Kordelas, Georgios A.; Izquierdo, Ebroul] Queen Mary Univ London, Dept Elect Engn & Comp Sci, London E1 4NS, England.
C3 Centre for Research & Technology Hellas; University of London; Queen
   Mary University London
RP Kordelas, GA (corresponding author), Ctr Res & Technol Hellas, Inst Informat Technol, 6th Km CharilaouThermi, GR-57001 Thessaloniki, Greece.
EM kordelas@iti.gr; dalexiad@iti.gr; daras@iti.gr;
   ebroul.izquierdo@eecs.qmul.ac.uk
RI Daras, Petros/F-5284-2012
OI Daras, Petros/0000-0003-3814-6710
FU EU funded IP project REVERIE [287723]
FX This work was supported by the EU funded IP project REVERIE under
   contract 287723.
CR [Anonymous], ACCV
   [Anonymous], CVPR ECV WORKSH
   [Anonymous], 3DIMPVT
   [Anonymous], P IEEE PAC RIM S IM
   [Anonymous], FEATURE BASED STEREO
   [Anonymous], HYBRID PLANE FITTING
   [Anonymous], NONPARAMETRIC APPROA
   [Anonymous], VISUAL COMPUTER
   [Anonymous], 2008, CVPR
   [Anonymous], ELSEVIER SIGNAL PROC
   [Anonymous], ICCV WORKSH GPU COMP
   [Anonymous], ICIP
   [Anonymous], IEEE TIP
   [Anonymous], EVALUATION COST FUNC
   [Anonymous], 2015, IEEE CVPR
   [Anonymous], P IEEE PAC RIM S IM
   [Anonymous], 2006, P ECCV
   Bleyer M, 2010, PROC CVPR IEEE, P1570, DOI 10.1109/CVPR.2010.5539783
   Chang NYC, 2010, IEEE T CIRC SYST VID, V20, P792, DOI 10.1109/TCSVT.2010.2045814
   Christoudias CM, 2002, INT C PATT RECOG, P150, DOI 10.1109/ICPR.2002.1047421
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Fife WS, 2013, IEEE T CIRC SYST VID, V23, P60, DOI 10.1109/TCSVT.2012.2203197
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Geusebroek JM, 2003, IEEE T IMAGE PROCESS, V12, P938, DOI 10.1109/TIP.2003.812429
   Gong ML, 2007, INT J COMPUT VISION, V75, P283, DOI 10.1007/s11263-006-0032-x
   Heo YS, 2013, IEEE T PATTERN ANAL, V35, P1094, DOI 10.1109/TPAMI.2012.167
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hong L, 2004, PROC CVPR IEEE, P74
   Hosni A, 2013, COMPUT VIS IMAGE UND, V117, P620, DOI 10.1016/j.cviu.2013.01.007
   Hosni A, 2013, IEEE T PATTERN ANAL, V35, P504, DOI 10.1109/TPAMI.2012.156
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Hu XY, 2010, PROC CVPR IEEE, P1466, DOI 10.1109/CVPR.2010.5539798
   Hubert M, 2005, TECHNOMETRICS, V47, P64, DOI 10.1198/004017004000000563
   Humenberger M, 2010, COMPUT VIS IMAGE UND, V114, P1180, DOI 10.1016/j.cviu.2010.03.012
   Kim JC, 2005, PROC CVPR IEEE, P1075
   Klaus A, 2006, INT C PATT RECOG, P15
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   Kumar S, 2010, PATTERN RECOGN LETT, V31, P1445, DOI 10.1016/j.patrec.2010.03.019
   Mattoccia S, 2007, LECT NOTES COMPUT SC, V4844, P517
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   Min DB, 2010, SIGNAL PROCESS-IMAGE, V25, P130, DOI 10.1016/j.image.2009.10.001
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Tombari F., 2008, Computer Vision and Pattern Recognition, P1
   Uijlings JRR, 2010, IEEE T MULTIMEDIA, V12, P665, DOI 10.1109/TMM.2010.2052027
   Yang QQ, 2014, IMAGE VISION COMPUT, V32, P202, DOI 10.1016/j.imavis.2014.01.001
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
NR 48
TC 33
Z9 38
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2015
VL 35
BP 31
EP 49
DI 10.1016/j.imavis.2014.12.001
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CE4JD
UT WOS:000351796000004
DA 2024-07-18
ER

PT J
AU Li, ZX
   Wang, KQ
   Jia, WY
   Chen, HC
   Zuo, WM
   Meng, DY
   Sun, MG
AF Li, Zhaoxin
   Wang, Kuanquan
   Jia, Wenyan
   Chen, Hsin-Chen
   Zuo, Wangmeng
   Meng, Deyu
   Sun, Mingui
TI Multiview stereo and silhouette fusion via minimizing generalized
   reprojection error
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiview stereo; 3D reconstruction; Silhouette fusion; Convex
   relaxation; Reprojection error
ID MINIMIZATION; ALGORITHM
AB Accurate reconstruction of 3D geometrical shape from a set of calibrated 2D multiview images is an active yet challenging task in computer vision. The existing multiview stereo methods usually perform poorly in recovering deeply concave and thinly protruding structures, and suffer from several common problems like slow convergence, sensitivity to initial conditions, and high memory requirements. To address these issues, we propose a two-phase optimization method for generalized reprojection error minimization (TwGREM), where a generalized framework of reprojection error is proposed to integrate stereo and silhouette cues into a unified energy function. For the minimization of the function, we first introduce a convex relaxation on 3D volumetric grids which can be efficiently solved using variable splitting and Chambolle projection. Then, the resulting surface is parameterized as a triangle mesh and refined using surface evolution to obtain a high-quality 3D reconstruction. Our comparative experiments with several state-of-the-art methods show that the performance of TwGREM based 3D reconstruction is among the highest with respect to accuracy and efficiency, especially for data with smooth texture and sparsely sampled viewpoints. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Li, Zhaoxin; Wang, Kuanquan; Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Chen, Hsin-Chen; Sun, Mingui] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA USA.
   [Jia, Wenyan; Chen, Hsin-Chen; Sun, Mingui] Univ Pittsburgh, Dept Neurosurg, Pittsburgh, PA USA.
   [Meng, Deyu] Xi An Jiao Tong Univ, Inst Informat & Syst Sci, Xian 710049, Peoples R China.
C3 Harbin Institute of Technology; Pennsylvania Commonwealth System of
   Higher Education (PCSHE); University of Pittsburgh; Pennsylvania
   Commonwealth System of Higher Education (PCSHE); University of
   Pittsburgh; Xi'an Jiaotong University
RP Wang, KQ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
EM wangkq@hit.edu.cn
RI Wang, Kuanquan/JCE-9520-2023; Zuo, Wangmeng/B-3701-2008; Chen,
   Hsin-Chen/AAI-2765-2021
OI Jia, Wenyan/0009-0009-2260-0975
FU National Institutes of Health Grant of the United States [R01CA165255];
   National Natural Science Foundation of China [61173086, 61271093]
FX The authors thank Dr. Daniel Scharstein for evaluating our results on
   Middlebury datasets, Dr. Carlos Hernandez and Dr. Peng Song for
   providing us the twins and the captain datasets, respectively. This work
   was supported by National Institutes of Health Grant No. R01CA165255 of
   the United States, and the National Natural Science Foundation of China
   under Grant Nos. 61173086 and 61271093.
CR [Anonymous], OPT ENG
   [Anonymous], P 11 INT C COMP VIS
   Bradley D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360698
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Cremers D, 2011, IEEE T PATTERN ANAL, V33, P1161, DOI 10.1109/TPAMI.2010.174
   Delaunoy A, 2014, PROC CVPR IEEE, P1486, DOI 10.1109/CVPR.2014.193
   Delaunoy Amael., 2008, BMVC 2008-British Machine Vision Conference, P1
   Dyken C, 2008, COMPUT GRAPH FORUM, V27, P2028, DOI 10.1111/j.1467-8659.2008.01182.x
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183
   Gargallo P., 2007, PROC INT CONE COMPUT, P1
   Goldlücke B, 2007, IEEE T PATTERN ANAL, V29, P1194, DOI 10.1109/TPAMI.2007.1146.
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Jensen R, 2014, PROC CVPR IEEE, P406, DOI 10.1109/CVPR.2014.59
   Kolev K, 2014, PROC CVPR IEEE, P3946, DOI 10.1109/CVPR.2014.504
   Kolev K, 2010, LECT NOTES COMPUT SC, V6313, P538
   Kolev K, 2009, INT J COMPUT VISION, V84, P80, DOI 10.1007/s11263-009-0233-1
   Kushal A, 2006, LECT NOTES COMPUT SC, V3952, P563
   Lafarge F, 2010, PROC CVPR IEEE, P350, DOI 10.1109/CVPR.2010.5540193
   Lempitsky V, 2006, LECT NOTES COMPUT SC, V3953, P226, DOI 10.1007/11744078_18
   Liu YB, 2009, PROC CVPR IEEE, P2121, DOI [10.1109/CVPRW.2009.5206712, 10.1109/CVPR.2009.5206712]
   Matusik W, 2001, SPRING EUROGRAP, P115
   Micusík B, 2010, INT J COMPUT VISION, V89, P106, DOI 10.1007/s11263-010-0327-9
   Pons JP, 2007, INT J COMPUT VISION, V72, P179, DOI 10.1007/s11263-006-8671-5
   Pradeep V, 2013, INT SYM MIX AUGMENT, P83, DOI 10.1109/ISMAR.2013.6671767
   Rauh A, 2010, IEEE IMAGE PROC, P105, DOI 10.1109/ICIP.2010.5651855
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rothganger F, 2006, INT J COMPUT VISION, V66, P231, DOI 10.1007/s11263-005-3674-1
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   SEGAL M, 1992, COMP GRAPH, V26, P249, DOI 10.1145/142920.134071
   Seitz S. M., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P519
   Sinha SN, 2007, IEEE I CONF COMP VIS, P1318
   Song P, 2010, VISUAL COMPUT, V26, P1435, DOI 10.1007/s00371-010-0429-y
   Strecha C., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587706
   SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029
   Tanskanen P, 2013, IEEE I CONF COMP VIS, P65, DOI 10.1109/ICCV.2013.15
   Tarini M, 2002, VISION MODELING, AND VISUALIZATION 2002, PROCEEDINGS, P283
   Ummenhofer B, 2013, IEEE I CONF COMP VIS, P969, DOI 10.1109/ICCV.2013.124
   Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712
   Xu C, 2014, SCI WORLD J, DOI 10.1155/2014/171978
   Yang QX, 2012, PROC CVPR IEEE, P1402, DOI 10.1109/CVPR.2012.6247827
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zaharescu A, 2007, LECT NOTES COMPUT SC, V4844, P166
NR 46
TC 3
Z9 4
U1 2
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2015
VL 33
BP 1
EP 14
DI 10.1016/j.imavis.2014.10.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AZ5KY
UT WOS:000348261100001
PM 25558120
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kusakunniran, W
AF Kusakunniran, Worapan
TI Attribute-based learning for gait recognition using spatio-temporal
   interest points
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gait recognition; Human identification; Spatio-temporal; Attribute-based
   learning
ID SUPPORT VECTOR MACHINES; IMAGE; SHAPE; FEATURES; OBJECT
AB This paper proposes a new method to extract a gait feature from a raw gait video directly. The Space-Time Interest Points (STIPs) are detected where there are significant movements of human body along both spatial and temporal directions in local spatio-temporal volumes of a raw gait video. Then, a histogram of STIP descriptors (HSD) is constructed as a gait feature. In the classification stage, the support vector machine (SVM) is applied to recognize gaits based on HSDs. In this study, the standard multi-class (i.e. multiple subjects) classification can often be computationally infeasible at test phase, when gait recognition is performed by using every possible classifiers (i.e. SVM models) trained for all individual subjects. In this paper, the attribute-based classification is applied to reduce the number of SVM models needed for recognizing each probe gait. This process will significantly reduce the test-time computational complexity and also retain or even improve the recognition accuracy. When compared with other existing methods in the literature, the proposed method is shown to have the promising performance for the case of normal walking, and the outstanding performance for the cases of walking with variations such as walking with carrying a bag and walking with varying a type of clothes. (C) 2014 Elsevier B.V. All rights reserved.
C1 Mahidol Univ, Fac Informat & Commun Technol, Bangkok 10700, Thailand.
C3 Mahidol University
RP Kusakunniran, W (corresponding author), Mahidol Univ, Fac Informat & Commun Technol, Bangkok 10700, Thailand.
EM worapan.kus@mahidol.ac.th
OI Kusakunniran, Worapan/0000-0002-2896-611X
FU Mahidol University
FX This research project is supported by Mahidol University. This paper has
   been recommended for acceptance by Mark S Nixon.
CR [Anonymous], 2007, MULTICLASS CLASSIFIC
   [Anonymous], 2010, Advances in Neural Information Processing Systems
   Barron J.L., 20040122005 TIN
   Bashir K., 2008, BMVC, P1
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Begg R, 2003, TENCON IEEE REGION, P354, DOI 10.1109/TENCON.2003.1273344
   Begg RK, 2005, IEEE T BIO-MED ENG, V52, P828, DOI 10.1109/TBME.2005.845241
   BenAbdelkader C, 2004, EURASIP J APPL SIG P, V2004, P572, DOI 10.1155/S1110865704309236
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P267, DOI 10.1109/AFGR.2002.1004165
   Beygelzimer A., 2009, P 25 C UNC ART INT, P51
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Bouchrika I, 2007, LECT NOTES COMPUT SC, V4418, P150
   Chai Y., 2005, TENCON 2005 2005 IEEE Region 10, P1
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CH, 2011, PATTERN RECOGN, V44, P988, DOI 10.1016/j.patcog.2010.10.021
   Chen S, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1375
   [陈实 CHEN Shi], 2007, [模式识别与人工智能, Pattern Recognition and Artificial Intelligence], V20, P794
   Chin-Pan Huang, 2011, Proceedings of the 2011 First International Conference on Instrumentation, Measurement, Computer, Communication and Control (IMCCC 2011), P353, DOI 10.1109/IMCCC.2011.95
   Cormen T.H., 2009, INTRO ALGORITHMS
   Cunado D, 1997, LECT NOTES COMPUT SC, V1206, P95
   Dadashi F, 2009, PROCEEDINGS OF THE 2009 2ND INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOLS 1-9, P1283
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Das Choudhury S, 2012, PATTERN RECOGN, V45, P3414, DOI 10.1016/j.patcog.2012.02.032
   DeCann B., 2010, SPIE C BIOM TECHN HU
   Deng J, 2010, LECT NOTES COMPUT SC, V6315, P71, DOI 10.1007/978-3-642-15555-0_6
   Deng Jia, 2011, NIPS, P567
   Dupuis Y, 2013, IMAGE VISION COMPUT, V31, P580, DOI 10.1016/j.imavis.2013.04.001
   Geng X., 2007, IMAGE VISION COMPUT, P19
   Goffredo M, 2008, 2008 IEEE SECOND INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS (BTAS), P154
   GROSS R, 2001, CMUR1TR0118
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hu M., IEEE T SYST MAN CY B, V43
   Jeevan M, 2013, IEEE IMAGE PROC, P4195, DOI 10.1109/ICIP.2013.6738864
   Johnson AY, 2001, LECT NOTES COMPUT SC, V2091, P301
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   Kale A, 2003, LECT NOTES COMPUT SC, V2688, P706
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kim D, 2009, COMM COM INF SC, V61, P275
   Kovac J, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/484320
   Kusakunniran Worapan, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P17, DOI 10.1109/AVSS.2011.6027286
   Kusakunniran W, 2013, IEEE INT CON MULTI, DOI 10.1109/ICME.2013.6607438
   Kusakunniran W, 2014, IEEE T IMAGE PROCESS, V23, P696, DOI 10.1109/TIP.2013.2294552
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lee CP, 2014, J VIS COMMUN IMAGE R, V25, P822, DOI 10.1016/j.jvcir.2014.01.012
   Lee CP, 2013, PATTERN RECOGN LETT, V34, P663, DOI 10.1016/j.patrec.2013.01.013
   Lee H, 2008, INT J IMAG SYST TECH, V18, P237, DOI 10.1002/ima.20136
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Liu ZY, 2006, IEEE T PATTERN ANAL, V28, P863, DOI 10.1109/TPAMI.2006.122
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   Makihara Y., 2012, IPSJ T COMPUT VISION, V4, P53, DOI DOI 10.2197/IPSJTCVA.4.53
   Martín-Félez R, 2012, LECT NOTES COMPUT SC, V7572, P328, DOI 10.1007/978-3-642-33718-5_24
   Ning HZ, 2004, IMAGE VISION COMPUT, V22, P429, DOI 10.1016/j.imavis.2004.01.001
   Rifkin R, 2004, J MACH LEARN RES, V5, P101
   Rohrbach M, 2010, PROC CVPR IEEE, P910, DOI 10.1109/CVPR.2010.5540121
   Roy A, 2012, SIGNAL PROCESS, V92, P780, DOI 10.1016/j.sigpro.2011.09.022
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shaikh SH, 2014, 2014 INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING AND INTEGRATED NETWORKS (SPIN), P101, DOI 10.1109/SPIN.2014.6776930
   Sivapalan S., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P355, DOI 10.1109/AVSS.2011.6027350
   Su H, 2006, LECT NOTES COMPUT SC, V3972, P238
   Tafazzoli F, 2010, ENG APPL ARTIF INTEL, V23, P1237, DOI 10.1016/j.engappai.2010.07.004
   Tan DL, 2007, IEEE IMAGE PROC, P337
   Tan DL, 2007, LECT NOTES COMPUT SC, V4642, P673
   Tan DL, 2007, LECT NOTES COMPUT SC, V4642, P222
   Tan DL, 2006, INT C PATT RECOG, P1000
   Tan DL, 2007, PROC CVPR IEEE, P3843
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Veeraraghavan A, 2004, PROC CVPR IEEE, P730
   Venkat I, 2011, INT J COMPUT VISION, V91, P7, DOI 10.1007/s11263-010-0362-6
   Venkatesh B. S., 2002, P IND C COMP VIS GRA, P97
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wang H., 2009, BMVC
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2003, IEEE T IMAGE PROCESS, V12, P1120, DOI 10.1109/TIP.2003.815251
   Whytock T., 2012, UK COMP VIS STUD WOR
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Q., 2007, IMAGE VISION COMPUT, P152
   Xue ZJ, 2010, PATTERN RECOGN, V43, P2904, DOI 10.1016/j.patcog.2010.03.011
   Yam C., 2009, Enclycopedia of Biometrics, P633, DOI DOI 10.1007/978-0-387-73003-5_37
   Ye B, 2007, INT C WAVEL ANAL PAT, P1382
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
NR 86
TC 8
Z9 11
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1117
EP 1126
DI 10.1016/j.imavis.2014.10.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600013
DA 2024-07-18
ER

PT J
AU Yang, QQ
   Ji, P
   Li, DX
   Yao, SJ
   Zhang, M
AF Yang, Qingqing
   Ji, Pan
   Li, Dongxiao
   Yao, Shaojun
   Zhang, Ming
TI Fast stereo matching using adaptive guided filtering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo vision; Local method; Adaptive guided filtering; Parallel
   integral image; Weighted propagation
ID COST AGGREGATION; VARIABLE WINDOW; SUPPORT
AB Dense disparity map is required by many great 3D applications. In this paper, a novel stereo matching algorithm is presented. The main contributions of this work are three-fold. Firstly, a new cost-volume filtering method is proposed. A novel concept named "two-level local adaptation" is introduced to guide the proposed filtering approach. Secondly, a novel post-processing method is proposed to handle both occlusions and textureless regions. Thirdly, a parallel algorithm is proposed to efficiently calculate an integral image on GPU, and it accelerates the whole cost-volume filtering process. The overall stereo matching algorithm generates the state-of-the-art results. At the time of submission, it ranks the 10th among about 152 algorithms on the Middlebury stereo evaluation benchmark, and takes the 1st place in all local methods. By implementing the entire algorithm on the NVIDIA Tesla C2050 CPU, it can achieve over 30 million disparity estimates per second (MDE/s). (C) 2014 Elsevier B.V. All rights reserved.
C1 [Yang, Qingqing; Ji, Pan; Li, Dongxiao; Yao, Shaojun; Zhang, Ming] Zhejiang Univ, Inst Informat & Commun Engn, Hangzhou 310027, Peoples R China.
   [Yang, Qingqing; Ji, Pan; Li, Dongxiao; Yao, Shaojun; Zhang, Ming] Zhejiang Prov Key Lab Informat Network Technol, Hangzhou 310027, Peoples R China.
   [Yang, Qingqing] Zhejiang Univ, Sch Informat Sci & Engn, Ningbo Inst Technol, Ningbo 315100, Zhejiang, Peoples R China.
C3 Zhejiang University; Zhejiang University
RP Li, DX (corresponding author), Zhejiang Univ, Inst Informat & Commun Engn, Hangzhou 310027, Peoples R China.
EM qqyang@zju.edu.cn; zhedajipan@zju.edu.cn; lidx@zju.edu.cn;
   06gksyysj@st.zju.edu.cn; zhangm@zju.edu.cn
RI Yao, Shaojun/I-6257-2012; Ji, Pan/AAE-6930-2020
FU National Natural Science Foundation of China [60802013, 61072081,
   61271338]; National High Technology Research and Development Program
   (863) of China [2012AA011505]; National Science and Technology Major
   Project of the Ministry of Science and Technology of China
   [2009ZX01033-001-007]; Key Science and Technology Innovation Team of
   Zhejiang Province, China [2009R50003]; China Postdoctoral Science
   Foundation [20110491804, 2012150545]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant Nos. 60802013, 61072081, 61271338), the
   National High Technology Research and Development Program (863) of China
   (Grant No. 2012AA011505), the National Science and Technology Major
   Project of the Ministry of Science and Technology of China (Grant No.
   2009ZX01033-001-007), the Key Science and Technology Innovation Team of
   Zhejiang Province, China (Grant No. 2009R50003), and the China
   Postdoctoral Science Foundation (Grant Nos. 20110491804, 2012150545).
CR [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI [10.1109/CVPR.2008.4587843, DOI 10.1109/CVPR.2008.4587843]
   [Anonymous], IEEE INT C MULT EXP
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 1990, CMUCS90190 SCH COMP
   Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Boykov Y, 1998, IEEE T PATTERN ANAL, V20, P1283, DOI 10.1109/34.735802
   Crow F. C., 1984, Computers & Graphics, V18, P207
   De-Maeztu L, 2011, IEEE I CONF COMP VIS, P1708, DOI 10.1109/ICCV.2011.6126434
   Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428
   Gong ML, 2007, INT J COMPUT VISION, V75, P283, DOI 10.1007/s11263-006-0032-x
   Gong ML, 2007, IEEE T IMAGE PROCESS, V16, P879, DOI 10.1109/TIP.2006.891344
   Harris M., 2007, GPU GEMS, V3, P851
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hirschmüller H, 2007, PROC CVPR IEEE, P2134
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Kim JC, 2005, PROC CVPR IEEE, P1075
   Min DB, 2011, IEEE I CONF COMP VIS, P1567, DOI 10.1109/ICCV.2011.6126416
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Richardt C, 2010, LECT NOTES COMPUT SC, V6313, P510
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D., 2007, P IEEE C COMPUTER VI, P1
   Scharstein Daniel., MIDDLEBURY STEREO EV
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tombari F., 2008, Computer Vision and Pattern Recognition, P1
   Tombari F, 2007, LECT NOTES COMPUT SC, V4872, P427
   Veksler O, 2003, PROC CVPR IEEE, P556
   Weiss B, 2006, ACM T GRAPHIC, V25, P519, DOI 10.1145/1141911.1141918
   Yang Q, 2012, IEEE SYS MAN CYBERN, P1, DOI 10.1109/ICSMC.2012.6377667
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
NR 36
TC 64
Z9 76
U1 0
U2 51
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2014
VL 32
IS 3
BP 202
EP 211
DI 10.1016/j.imavis.2014.01.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AE3CG
UT WOS:000333854000004
DA 2024-07-18
ER

PT J
AU Toldo, R
   Fusiello, A
AF Toldo, Roberto
   Fusiello, Andrea
TI Image-consistent patches from unstructured points with J-linkage
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Robust model fitting; Surface reconstruction; Plane fitting; 3D modeling
ID MULTIPLE STRUCTURES; ROBUST ESTIMATION; MODEL
AB Going from unstructured cloud of points to surfaces is a challenging problem. However, as points are produced by a structure-and-motion pipeline, image-consistency is a powerful clue that comes to the rescue. In this paper we present a method for extracting planar patches from an unstructured cloud of points, based on the detection of image-consistent planar patches with J-linkage, a robust algorithm for multiple model fitting. The method integrates several constraints inside J-linkage, optimizes the position of the points with regard to image-consistency and deploys a hierarchical processing scheme that decreases the computational load. With respect to previous work this approach has the advantage of starting from sparse data. Several results show the effectiveness of the proposed approach. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Toldo, Roberto; Fusiello, Andrea] Univ Verona, Dipartimento Informat, I-37134 Verona, Italy.
C3 University of Verona
RP Fusiello, A (corresponding author), Univ Udine DIEGM, Udine, Italy.
EM roberto.toldo@3dflow.net; andrea.fusiello@uniud.it
RI Fusiello, Andrea/GOJ-9893-2022
OI Fusiello, Andrea/0000-0003-2963-0316
FU University of Verona; Gexcel s.r.l.
FX This research has been supported by the University of Verona and Gexcel
   s.r.l. under the "Joint Projects" scheme. The laser scanning of "Piazza
   Bra" has been conducted by Gexcel s.r.l. with the EU JRC - Ispra and the
   permission of the municipality of Verona. The laser data of the "Duomo
   di Pisa" comes from the "Cattedrale Digitale<SUP>9</SUP>" project, while
   the photo set is courtesy of the Visual Computing Lab (ISTI-CNR, Pisa).
CR [Anonymous], PATTERN REPRESENTATI
   [Anonymous], P INT C COMP VIS
   [Anonymous], PATTERN CLASSIFICATI
   [Anonymous], 2005, P IEEE INT C IM PROC
   Bartoli A, 2007, COMPUT VIS IMAGE UND, V105, P42, DOI 10.1016/j.cviu.2006.07.011
   Brenner Claus., 2006, Photogrammetric Computer Vision, P155
   Chauve AL, 2010, PROC CVPR IEEE, P1261, DOI 10.1109/CVPR.2010.5539824
   Chin TJ, 2009, IEEE I CONF COMP VIS, P413, DOI 10.1109/ICCV.2009.5459150
   Chin TJ, 2010, PROC CVPR IEEE, P3586, DOI 10.1109/CVPR.2010.5539931
   Cipolla R, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P25, DOI 10.1109/MMCS.1999.779115
   Cooper O., 2005, 7 IEEE WORKSH APPL C, V1
   Delong A, 2012, LECT NOTES COMPUT SC, V7572, P370, DOI 10.1007/978-3-642-33718-5_27
   Dick AR, 2004, INT J COMPUT VISION, V60, P111, DOI 10.1023/B:VISI.0000029665.07652.61
   Farenzena M., 2008, EUROGRAPHICS 2008 SH, P91
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fouhey D.F., 2011, THESIS MIDDLEBURY CO
   Furukawa Y., 2010, P IEEE C COMP VIS PA, P12
   Gallup D, 2010, PROC CVPR IEEE, P1418, DOI 10.1109/CVPR.2010.5539804
   Gherardi R, 2010, PROC CVPR IEEE, P1594, DOI 10.1109/CVPR.2010.5539782
   Häne C, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P563, DOI 10.1109/3DIMPVT.2012.55
   Han F., 2003, WORKSH HIGH LEV KNOW, V2
   Hilton A, 2005, IMAGE VISION COMPUT, V23, P900, DOI 10.1016/j.imavis.2005.05.018
   Kanazawa Y., 2004, Procedings of the British Machine Vision Conference, P247
   Kobbelt L, 1999, COMP GEOM-THEOR APPL, V14, P5, DOI 10.1016/S0925-7721(99)00032-2
   Morris D., 2000, P IEEE C COMP VIS PA, V1
   Müller P, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276484, 10.1145/1239451.1239536]
   Nakatsuji A, 2005, IEICE T INF SYST, VE88D, P2269, DOI 10.1093/ietisy/e88-d.10.2269
   Raguram R, 2011, IEEE I CONF COMP VIS, P1299, DOI 10.1109/ICCV.2011.6126382
   Schindler K, 2003, FIRST IEEE INTERNATIONAL WORKSHOP ON HIGHER-LEVEL KNOWLEDGE IN 3D MODELING AND MOTION ANALYSIS, PROCEEDINGS, P74, DOI 10.1109/HLK.2003.1240861
   Stewart CV, 1997, IEEE T PATTERN ANAL, V19, P818, DOI 10.1109/34.608280
   Strecha P.F.C., 2010, P 23 IEEE C COMP VIS
   Taylor C. J., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P659
   Tiana Y., 2009, 3D VIRTUAL RECONSTRU, V18
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Toldo R, 2010, LECT NOTES COMPUT SC, V6315, P589, DOI 10.1007/978-3-642-15555-0_43
   Toldo R, 2009, LECT NOTES COMPUT SC, V5716, P123, DOI 10.1007/978-3-642-04146-4_15
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Torr PHS, 1997, PROC CVPR IEEE, P47, DOI 10.1109/CVPR.1997.609296
   Pham TT, 2012, PROC CVPR IEEE, P710, DOI 10.1109/CVPR.2012.6247740
   van den Hengel A., 2007, P SIGGRAPH C, V26
   Wilczkowiak M, 2005, IEEE T PATTERN ANAL, V27, P194, DOI 10.1109/TPAMI.2005.40
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Zhang W, 2007, LECT NOTES COMPUT SC, V4358, P60
NR 43
TC 10
Z9 11
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 756
EP 770
DI 10.1016/j.imavis.2013.07.007
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fang, TH
   Zhao, X
   Ocegueda, O
   Shah, SK
   Kakadiaris, IA
AF Fang, Tianhong
   Zhao, Xi
   Ocegueda, Omar
   Shah, Shishir K.
   Kakadiaris, Ioannis A.
TI 3D/4D facial expression analysis: An advanced annotated face model
   approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Expression recognition; 3D face models; 40 face videos; Mesh
   registration
ID RECOGNITION; OBJECTS
AB Facial expression analysis has interested many researchers in the past decade due to its potential applications in various fields such as human-computer interaction, psychological studies, and facial animation. Three-dimensional facial data has been proven to be insensitive to illumination condition and head pose, and has hence gathered attention in recent years. In this paper, we focus on discrete expression classification using 3D data from the human face. The paper is divided in two parts. In the first part, we present improvement to the fitting of the Annotated Face Model (AFM) so that a dense point correspondence can be found in terms of both position and semantics among static 3D face scans or frames in 3D face sequences. Then, an expression recognition framework on static 3D images is presented. It is based on a Point Distribution Model (PDM) which can be built on different features. In the second part of this article, a systematic pipeline that operates on dynamic 3D sequences (4D datasets or 3D videos) is proposed and alternative modules are investigated as a comparative study. We evaluated both 3D and 4D Facial Expression Recognition pipelines on two publicly available facial expression databases and obtained promising results. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Fang, Tianhong; Zhao, Xi; Ocegueda, Omar; Shah, Shishir K.; Kakadiaris, Ioannis A.] Univ Houston, Computat Biomed Lab, Dept Comp Sci, Houston, TX 77004 USA.
C3 University of Houston System; University of Houston
RP Kakadiaris, IA (corresponding author), Univ Houston, Computat Biomed Lab, Dept Comp Sci, Houston, TX 77004 USA.
EM thfang@uh.edu; zhaoxi@ieee.org; jomaroceguedag@gmail.com;
   shah@cs.uh.edu; ioannisk@uh.edu
RI zhao, xi/E-9335-2013
OI zhao, xi/0000-0001-9983-6366; Kakadiaris, Ioannis/0000-0002-0591-1079;
   Shah, Shishir/0000-0003-4093-6906
FU Office of the Director of National Intelligence (ODNI); Intelligence
   Advanced Research Projects Activity (IARPA), through the Army Research
   Laboratory (ARL); University of Houston (UH) Eckhard Pfeiffer Endowment
   Fund
FX This research was funded in part by the Office of the Director of
   National Intelligence (ODNI), Intelligence Advanced Research Projects
   Activity (IARPA), through the Army Research Laboratory (ARL) and by the
   University of Houston (UH) Eckhard Pfeiffer Endowment Fund. All
   statements of fact, opinion or conclusions contained herein are those of
   the authors and should not be construed as representing the official
   views or policies of IARPA, the ODNI, the U.S. Government, or UH.
CR [Anonymous], 2010, IEEE CVPR 10 WORKSHO
   [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], P 24 INT S COMP INF
   [Anonymous], P INT C IM AN REC MO
   [Anonymous], P 8 IEEE INT C AUT F
   [Anonymous], P 9 IEEE C AUT FAC G
   [Anonymous], IEEE T PAMI
   [Anonymous], 2011, ACM T INTEL SYST TEC
   [Anonymous], P EUR WORKSH 3D OBJ
   [Anonymous], J COMPUT VISION
   [Anonymous], SUPPLEMENTARY DEMO V
   [Anonymous], P SOFT COMP COMP WOR
   [Anonymous], 1997, THESIS CARNEGIE MELL
   [Anonymous], J VIRTUAL REAL BROAD
   [Anonymous], P 23 INT S COMP INF
   [Anonymous], P 9 IEEE INT C AUT F
   [Anonymous], 2004, Technical Report
   Berretti S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BOURGAIN J, 1985, ISRAEL J MATH, V52, P46, DOI 10.1007/BF02776078
   Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Fang T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P603, DOI 10.1109/FG.2011.5771466
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goldfeather J, 2004, ACM T GRAPHIC, V23, P45, DOI 10.1145/966131.966134
   Gong B., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P569
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Harris C., 1988, ALVEY VISION C, P147151
   Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kharevych L, 2006, ACM T GRAPHIC, V25, P412, DOI 10.1145/1138450.1138461
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maalej Ahmed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4129, DOI 10.1109/ICPR.2010.1003
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Mpiperis I, 2008, IEEE T INF FOREN SEC, V3, P498, DOI 10.1109/TIFS.2008.924598
   Mpiperis I, 2008, INT CONF ACOUST SPEE, P2133, DOI 10.1109/ICASSP.2008.4518064
   Nair P, 2009, IEEE T MULTIMEDIA, V11, P611, DOI 10.1109/TMM.2009.2017629
   Ocegueda O, 2011, PROC CVPR IEEE, P641, DOI 10.1109/CVPR.2011.5995613
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Papaioannou G, 2002, IEEE T PATTERN ANAL, V24, P114, DOI 10.1109/34.982888
   Passalis G, 2007, IEEE T PATTERN ANAL, V29, P218, DOI 10.1109/TPAMI.2007.37
   Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49
   Perakis P, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P439
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Kassim SRA, 2006, IEEE IMAGE PROC, P661
   Rosato M., 2008, PROC 2 SUP ND SUP IE, P1
   Savran Arman, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1993, DOI 10.1109/ICCVW.2009.5457526
   Schneider D., 2008, P IEEE GLOB TEL C NE, P1
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Siarry P, 1997, ACM T MATH SOFTWARE, V23, P209, DOI 10.1145/264029.264043
   Soyel H, 2010, TURK J ELECTR ENG CO, V18, P1031, DOI 10.3906/elk-0908-158
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Tang H., 2008, PROC 8 SUP TH SUP IE, P1
   Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009
   Venkatesh Y. V., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3772, DOI 10.1109/ICPR.2010.919
   Venkatesh YV, 2009, PATTERN RECOGN LETT, V30, P1128, DOI 10.1016/j.patrec.2009.04.007
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wang P, 2007, PROC CVPR IEEE, P701
   Xi Zhao, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3724, DOI 10.1109/ICPR.2010.907
   Yin L., 2008, PROC 8 SUP TH SUP IE, P1
   Yin LJ, 2006, INT C PATT RECOG, P1248
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yin LJ, 2001, COMPUT VIS IMAGE UND, V84, P201, DOI 10.1006/cviu.2001.0949
   Ying ZL, 2008, INT CONF SIGN PROCES, P1462
   Zaharescu A, 2009, PROC CVPR IEEE, P373, DOI 10.1109/CVPRW.2009.5206748
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao X., 2010, HICSS, P1
   Zhao X, 2011, IEEE T SYST MAN CY B, V41, P1417, DOI 10.1109/TSMCB.2011.2148711
NR 74
TC 56
Z9 61
U1 1
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2012
VL 30
IS 10
BP 738
EP 749
DI 10.1016/j.imavis.2012.02.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 027YD
UT WOS:000310389100006
DA 2024-07-18
ER

PT J
AU Stratou, G
   Ghosh, A
   Debevec, P
   Morency, LP
AF Stratou, Giota
   Ghosh, Abhijeet
   Debevec, Paul
   Morency, Louis-Philippe
TI Exploring the effect of illumination on automatic expression recognition
   using the ICT-3DRFE database
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D facial database; Illumination effect; Image re-lighting;
   Facialexpression recognition; Ratio images
AB One of the main challenges in facial expression recognition is illumination invariance. Our long-term goal is to develop a system for automatic facial expression recognition that is robust to light variations. In this paper, we introduce a novel 3D Relightable Facial Expression (ICT-3DRFE) database that enables experimentation in the fields of both computer graphics and computer vision. The database contains 3D models for 23 subjects and 15 expressions, as well as photometric information that allow for photorealistic rendering. It is also facial action units annotated, using FACS standards. Using the ICT-3DRFE database we create an image set of different expressions/illuminations to study the effect of illumination on automatic expression recognition. We compared the output scores from automatic recognition with expert FACS annotations and found that they agree when the illumination is uniform. Our results show that the output distribution of the automatic recognition can change significantly with light variations and sometimes causes the discrimination of two different expressions to be diminished. We propose a ratio-based light transfer method, to factor out unwanted illuminations from given images and show that it reduces the effect of illumination on expression recognition. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Stratou, Giota; Ghosh, Abhijeet; Debevec, Paul; Morency, Louis-Philippe] Univ So Calif, Inst Creat Technol, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Stratou, G (corresponding author), Univ So Calif, Inst Creat Technol, Los Angeles, CA 90089 USA.
EM stratou@ict.usc.edu; ghosh@ict.usc.edu; debevec@ict.usc.edu;
   morency@ict.usc.edu
RI Morency, Louis-Philippe/B-2006-2008
FU U.S. Army Research, Development, and Engineering Command (RDECOM)
FX The authors would like to thank the following collaborators for their
   help on this paper: Ning Wang for the AU annotation of the database,
   Simon Lucey from CSIRO ICT Center (Australia) for the face tracking code
   used in this paper for sparse correspondence during image alignment,
   Cyrus Wilson and Jay Busch for help with processing of the acquired
   data. This material is based upon work supported by the U.S. Army
   Research, Development, and Engineering Command (RDECOM). The content
   does not necessarily reflect the position or the policy of the
   Government, and no official endorsement should be inferred.
CR ADINI Y, 1995, CS9321 WEIZM I SCI
   Anitha C., 2010, International Journal of Engineering Science and Technology, V2, P5158
   [Anonymous], 2010, COGNITION EMOTION
   [Anonymous], 2008, 8 INT C AUT FAC GEST
   [Anonymous], P 28 ANN C COMP GRAP
   [Anonymous], 2007, P 18 EUROGRAPHICS C, DOI [10.2312/EGWR/EGSR07/183-194., DOI 10.2312/EGWR/EGSR07/183-194.6]
   [Anonymous], CVONLINE ONLINE COMP
   Bartlett M., 2008, COMPUTER EXPRESSION
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Braje WL, 1998, PSYCHOBIOLOGY, V26, P371
   Chen XW, 2011, PROC CVPR IEEE, P281, DOI 10.1109/CVPR.2011.5995473
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P., 1982, EMOTION HUMAN FACE
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kumar R, 2010, PROC CVPR IEEE, P2606, DOI 10.1109/CVPR.2010.5539972
   Li HF, 2008, CURR MED RES OPIN, V24, P1, DOI 10.1088/0256-307X/24/3/072
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   Lucey S, 2010, IMAGE VISION COMPUT, V28, P781, DOI 10.1016/j.imavis.2009.09.009
   Lucey Simon., 2007, FACE RECOGNITION DEL, P275
   Lyons M., 1998, 3 INT C AUT FAC GEST
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   PANTIC M, 2005, P IEEE INT C MULTM E
   Peers P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239503
   Riklin-Raviv T., 1999, IEEE T PATTERN ANAL, V02, P262
   Sim T., 2002, P IEEE INT C AUT FAC
   Toderici G, 2010, PROC CVPR IEEE, P2721, DOI 10.1109/CVPR.2010.5539995
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1968, DOI 10.1109/TPAMI.2008.244
   Wen Z, 2003, PROC CVPR IEEE, P158
   Wilson CA, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1731047.1731055
   Yin L., 2006, 7 INT C AUT FAC GEST
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 33
TC 7
Z9 8
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2012
VL 30
IS 10
BP 728
EP 737
DI 10.1016/j.imavis.2012.02.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 027YD
UT WOS:000310389100005
DA 2024-07-18
ER

PT J
AU Yuille, AL
AF Yuille, A. L.
TI Computer vision needs a core and foundations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Core; Foundations
AB I argue that computer vision needs a core of techniques and foundational research to enable it to build on its current successes and achieve its enormous potential. "How do I know what papers to read in computer vision? There are so many. And they are so different." Graduate Student. Xi'An. China. November, 2011. (c) 2012 Published by Elsevier B.V.
C1 [Yuille, A. L.] Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.
   [Yuille, A. L.] Korea Univ, Dept Brain & Cognit Engn, Seoul, South Korea.
C3 University of California System; University of California Los Angeles;
   Korea University
RP Yuille, AL (corresponding author), Univ Calif Los Angeles, Dept Stat, Los Angeles, CA 90095 USA.
EM yuille@stat.ucla.edu
OI Yuille, Alan L./0000-0001-5207-9249
FU Korean Ministry of Education, Science, and Technology, under the
   National Research Foundation WCU program [R31-10008]
FX The ideas here were influenced by discussions with many people at the
   Frontiers of Computer Workshop. I like to acknowledge feedback from
   Daniel Kersten and the hospitality of the Department of Brain and
   Cognitive Engineering at Korea University where this opinion was written
   funded by Korean Ministry of Education, Science, and Technology, under
   the National Research Foundation WCU program R31-10008.
NR 0
TC 2
Z9 2
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 469
EP 471
DI 10.1016/j.imavis.2011.12.013
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100004
OA hybrid
DA 2024-07-18
ER

PT J
AU Strong, G
   Gong, ML
AF Strong, Grant
   Gong, Minglun
TI Similarity-based image organization and browsing using multi-resolution
   self-organizing map
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Similarity-based image browsing; Self-organizing map; General computing
   on GPU
ID RETRIEVAL
AB An algorithm is presented in this paper to facilitate the exploration of large image collections based on visual similarities. Starting with an unordered and unannotated set of images, the algorithm first extracts the salient details into feature vectors using both color and gradient information. The feature vectors are then used to train a self-organizing map which maps high-dimensional feature vectors onto a 2D canvas so that images with similar feature vectors are grouped together. When users browse the image collection, an image collage is generated that selects and displays the most pertinent set of images based on which portion of the 2D canvas is currently in view. Flowing from an overview to details is a seamless operation controlled simply by pan and zoom, with representative images selected in a consistent and predictable way. To make organizing larger image collections practical in interactive time, the organization algorithm is designed to run in parallel on graphics processing units. Overall this paper presents an end-to-end solution that facilitates the surfing of image collections in a fresh way. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Strong, Grant; Gong, Minglun] Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1C 5S7, Canada.
C3 Memorial University Newfoundland
RP Gong, ML (corresponding author), Mem Univ Newfoundland, Dept Comp Sci, St John, NF A1C 5S7, Canada.
EM strong@cs.mun.ca; gong@cs.mun.ca
RI cai, bo/G-1491-2010; Gong, Minglun/AAU-3103-2020
OI Gong, Minglun/0000-0001-5820-5381
CR *ALG GROUP, MDSJ JAV LIB MULT SC
   [Anonymous], 1995, SELF ORG MAPS
   [Anonymous], P ACM INT C IM VID R
   Borg I., 2005, Modern Multidimensional Scaling: Theory and Applications
   Camargo Jorge, 2009, P LAT AM C NETW EL M
   CAMPBELL A, 2005, P INT C INT DAT ENG, P343
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Gong ML, 2005, LECT NOTES COMPUT SC, V3656, P1217, DOI 10.1007/11559573_147
   HEESCH D, 2005, P INT C IM VID RETR, P609
   HEESCH D, 2004, P 26 EUR C IR RES SU, P253
   HEESCH D, 2004, P INT C IM VID RETR, P491
   Heesch D, 2008, MULTIMED TOOLS APPL, V40, P261, DOI 10.1007/s11042-008-0207-2
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   JANECEK P, 2003, P OTM WORKSH, P185
   Laaksonen J, 2000, PATTERN RECOGN LETT, V21, P1199, DOI 10.1016/S0167-8655(00)00082-9
   LAAKSONEN J, 2000, P 7 INT C NEUR INF P, P1333
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Liu HN, 2004, FIRST INTERNATIONAL CONFERENCE ON QUALITY OF SERVICE IN HETEROGENEOUS WIRED/WIRELESS NETWORKS, PROCEEDINGS, P84
   LUO Z, 2005, P EUR S ART NEUR NET
   Nguyen GP, 2008, J VISUAL LANG COMPUT, V19, P203, DOI 10.1016/j.jvlc.2006.09.002
   Pecenovic Z, 2000, LECT NOTES COMPUT SC, V1929, P279
   PRENTIS P, 2007, P INT WORKSH SELF OR
   RODDEN K, 2001, P P SIGCHI C HUM FAC
   SAMMON JW, 1969, IEEE T COMPUT, VC 18, P401, DOI 10.1109/T-C.1969.222678
   Santini S, 2000, IEEE MULTIMEDIA, V7, P26, DOI 10.1109/93.879766
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Strong G, 2010, LECT NOTES COMPUT SC, V6335, P424, DOI 10.1007/978-3-642-15470-6_44
   Strong G, 2008, LECT NOTES COMPUT SC, V5359, P390, DOI 10.1007/978-3-540-89646-3_38
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tan KL, 2001, MULTIMED TOOLS APPL, V14, P55, DOI 10.1023/A:1011359607594
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 32
TC 12
Z9 13
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2011
VL 29
IS 11
BP 774
EP 786
DI 10.1016/j.imavis.2011.08.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 864EE
UT WOS:000298219000006
DA 2024-07-18
ER

PT J
AU Makris, A
   Kosmopoulos, D
   Perantonis, S
   Theodoridis, S
AF Makris, Alexandros
   Kosmopoulos, Dimitrios
   Perantonis, Stavros
   Theodoridis, Sergios
TI A hierarchical feature fusion framework for adaptive visual tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Particle filter; Sequential Monte-Carlo
ID PARTICLE; MOTION
AB A Hierarchical Model Fusion (HMF) framework for object tracking in video sequences is presented. The Bayesian tracking equations are extended to account for multiple object models. With these equations as a basis a particle filter algorithm is developed to efficiently cope with the multi-modal distributions emerging from cluttered scenes. The update of each object model takes place hierarchically so that the lower dimensional object models, which are updated first, guide the search in the parameter space of the subsequent object models to relevant regions thus reducing the computational complexity. A method for object model adaptation is also developed. We apply the proposed framework by fusing salient points, blobs, and edges as features and verify experimentally its effectiveness in challenging conditions. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Makris, Alexandros; Kosmopoulos, Dimitrios; Perantonis, Stavros] NCSR Demokritos, Inst Informat & Telecommun, Computat Intelligence Lab, Athens 15310, Greece.
   [Makris, Alexandros; Theodoridis, Sergios] Univ Athens, Dept Informat, GR-15771 Athens, Greece.
C3 National Centre of Scientific Research "Demokritos"; National &
   Kapodistrian University of Athens
RP Makris, A (corresponding author), NCSR Demokritos, Inst Informat & Telecommun, Computat Intelligence Lab, Athens 15310, Greece.
EM amakris@iit.demokritos.gr; dkosmo@iit.demokritos.gr;
   sper@iit.demokritos.gr; stheodor@di.uoa.gr
RI Theodoridis, Sergios/C-3142-2016; Kosmopoulos, Dimitrios/P-4325-2015
OI Kosmopoulos, Dimitrios/0000-0003-3325-1247
CR Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116
   [Anonymous], 1998, LNCS, DOI DOI 10.1007/BFB0055711
   [Anonymous], 1994, P IEEE C COMP VIS PA
   [Anonymous], CRGTR931 U TOR
   [Anonymous], P IEEE INT C IM PROC
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Branson K, 2005, PROC CVPR IEEE, P1039
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Duffner S., 2009, P BRIT MASCH VIS C
   Gales MJF, 2006, COMPUT SPEECH LANG, V20, P22, DOI 10.1016/j.csl.2004.12.002
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Hall D., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P113
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Khan Z., 2004, CVPR 2004 P 2004 IEE, V2, pII, DOI [10.1109/CVPR.2004.1315271, DOI 10.1109/CVPR.2004.1315271]
   Li J, 2007, IMAGE VISION COMPUT, V25, P544, DOI 10.1016/j.imavis.2006.05.001
   Li PH, 2004, LECT NOTES COMPUT SC, V3179, P99
   Li Y, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P335
   Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847
   MacCormick J., 2000, IEEE European Conference on Computer Vision, P3, DOI DOI 10.1007/3-540-45053-X1
   Maggio E, 2007, IEEE T CIRC SYST VID, V17, P1348, DOI 10.1109/TCSVT.2007.903781
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moreno-Noguer F, 2008, IEEE T PATTERN ANAL, V30, P670, DOI 10.1109/TPAMI.2007.70727
   MORENONOGUER F, 2004, P 3 IEEE WORKSH ART
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Odobez JM, 2006, IEEE T IMAGE PROCESS, V15, P3514, DOI 10.1109/TIP.2006.877497
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Shen C, 2003, P 7 DIG IM COMP TECH, P399
   Spengler M., 2001, ICVS 01 P 2 INT WORK
   Stenger B., 2009, LEARNING TRACK MULTI, P2647
   Vermaak J, 2002, LECT NOTES COMPUT SC, V2350, P645
   Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin Z., 2008, LIKELIHOOD MAP FUSIO, P1
NR 36
TC 10
Z9 13
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2011
VL 29
IS 9
BP 594
EP 606
DI 10.1016/j.imavis.2011.07.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 836PI
UT WOS:000296123200003
DA 2024-07-18
ER

PT J
AU Li, ZC
   Qin, SY
   Itti, L
AF Li, Zhicheng
   Qin, Shiyin
   Itti, Laurent
TI Visual attention guided bit allocation in video compression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual attention; Video compression; Eye tracking; Video subjective
   quality
ID MODEL; REGIONS
AB A visual attention based bit allocation strategy for video compression is proposed Saliency based attention prediction is used to detect interesting regions in video From the top salient locations from the computed saliency map a guidance map is generated to guide the bit allocation strategy through a new constrained global optimization approach which can be solved in a closed form and independently of video frame content Fifty video sequences (300 frames each) and eye-tracking data from 14 subjects were collected to evaluate both the accuracy of the attention prediction model and the subjective quality of the encoded video Results show that the area under the curve of the guidance map is 0 773 +/- 0 002 significantly above chance (0 500) Using a new eye tracking-weighted PSNR (EWPSNR) measure of subjective quality more than 90% of the encoded video clips with the proposed method achieve better subjective quality compared to standard encoding with matched bit rate The improvement in EWPSNR is up to over 2 dB and on average 0 79 dB (C) 2010 Elsevier B V All rights reserved
C1 [Li, Zhicheng; Qin, Shiyin] Beihang Univ, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
   [Li, Zhicheng; Itti, Laurent] Univ So Calif, Dept Comp Sci, Los Angeles, CA 90089 USA.
C3 Beihang University; University of Southern California
RP Itti, L (corresponding author), Univ So Calif, Hedco Neurosci Bldg,Room HNB 07A,3641 Watt Way, Loa Angeles, CA 90089 USA.
RI Li, Zhicheng/D-2849-2012; qin, shi/JNY-1785-2023
OI Li, Zhicheng/0000-0003-4140-0580; 
FU NSF; ARO; DARPA; Natural Science Foundation of China (NSFC); China
   Scholarship Council (CSC)
FX This study was supported by NSF ARO DARPA Natural Science Foundation of
   China (NSFC) and China Scholarship Council (CSC) The authors affirm that
   the views expressed herein are solely their own and do not represent the
   views of the United States government or any agency thereof
CR BAMBER D, 1975, J MATH PSYCHOL, V12, P387, DOI 10.1016/0022-2496(75)90001-2
   Cerf Moran, 2008, Advances in Neural Information Processing Systems, V20, P241
   CHEN Z, P ISCAS 2007, P3634
   Chi MC, 2008, SIGNAL PROCESS-IMAGE, V23, P127, DOI 10.1016/j.image.2007.12.001
   Doulamis N, 1998, IEEE T CIRC SYST VID, V8, P928, DOI 10.1109/76.736718
   Ehinger KA, 2009, VIS COGN, V17, P945, DOI 10.1080/13506280902834720
   Hershler O, 2005, VISION RES, V45, P1707, DOI 10.1016/j.visres.2004.12.021
   Huang CM, 2007, IEEE T MULTIMEDIA, V9, P1113, DOI 10.1109/TMM.2007.902840
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2004, P SOC PHOTO-OPT INS, V5292, P272, DOI 10.1117/12.527057
   Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677
   *ITU T TECHN TUT, 2005, TUT OBJ PERC ASS VID
   Jiang MQ, 2006, IEEE T CIRC SYST VID, V16, P663, DOI 10.1109/TCSVT.2006.873159
   KARLSSON LS, 2007, THESIS SUNDSVALL SWE
   Kortum P, 1996, P SOC PHOTO-OPT INS, V2657, P350, DOI 10.1117/12.238732
   LAI KC, 2002, P INT C SIGN PROC AU, V1, P656
   LAI W, P IEEE INT C MULT EX
   Lee S, 2001, IEEE T IMAGE PROCESS, V10, P977, DOI 10.1109/83.931092
   LEE S, P IEEE INT C IM PROC, P90
   LI Z, P VIS SCI SOC ANN M
   Li Z., 2008, P VIS SCI SOC ANN M
   LIU T, P ICPR 2008, P1
   Liu Y, 2008, IEEE T CIRC SYST VID, V18, P134, DOI 10.1109/TCSVT.2007.913754
   MALVAR HS, P ICASSP 2004, P485
   Minoo K, 2005, P 39 AS C SIGN SYST
   Parkhurst DJ, 2002, HUM FACTORS, V44, P611, DOI 10.1518/0018720024497015
   PETERS J, P CVPR 2007
   Rauschenbach U, 1999, COMPUT GRAPH-UK, V23, P857, DOI 10.1016/S0097-8493(99)00116-8
   Sun Y, 2006, IEEE T MULTIMEDIA, V8, P1, DOI 10.1109/TMM.2005.861296
   Tang CW, 2006, IEEE T MULTIMEDIA, V8, P11, DOI 10.1109/TMM.2005.861295
   Tong L, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2238343
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   VRANJES M, P SYST SIGN IM PROC
   WANDELL B, 1995, FDN VISION SINAUER
   WANG N, P PCCAS 2000, P791
   Wang Y., 2002, VIDEO PROCESSING COM
   Watson AB, 2001, J ELECTRON IMAGING, V10, P20, DOI 10.1117/1.1329896
   Watson AB, 1998, P SOC PHOTO-OPT INS, V3299, P139, DOI 10.1117/12.320105
   WEBSTER AA, 1993, P SOC PHOTO-OPT INS, V1913, P15, DOI 10.1117/12.152700
   WEIGAND T, 2003, H264 ITUT
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Wolfe JM, 1998, CURR BIOL, V8, pR303, DOI 10.1016/S0960-9822(98)70192-7
NR 44
TC 176
Z9 199
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2011
VL 29
IS 1
BP 1
EP 14
DI 10.1016/j.imavis.2010.07.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 679BP
UT WOS:000284134700001
DA 2024-07-18
ER

PT J
AU Zhang, XJ
   Tay, LP
AF Zhang, Xuejie
   Tay, Leng Phuan
TI A spatial variant approach for vergence control in complex scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vergence control; Log polar transformation; Image pyramid; Disparity
   estimation
ID LAMINAR CORTICAL MODEL; LOG-POLAR IMAGES; VISUAL-CORTEX; SURFACE
   PERCEPTION; STRIATE CORTEX; FIELD; REPRESENTATION; STEREOPSIS;
   ALGORITHM; VISION
AB The flexibility in primate vision that utilizes active binocular vision is unparalleled even with modern fixed stereo-based vision systems However to follow the path of active binocular vision the difficulty of attaining fixative capabilities is of primary concern This paper presents a binocular vergence model that utilizes the retino-cortical log polar mapping in the primate vision system Individual images of the binocular pair were converted to multi resolution pyramids bearing a coarse to-fine architecture (low resolution to high resolution) and disparity estimation on these pyramidal resolutions was performed using normalized cross correlation on the log polar images The model was deployed on an actual binocular vergence system with independent pan tilt controls for each camera and the system was able to robustly verge on objects even in cluttered environment with real time performance This paper even presents the experimental results of the system functioning in unbalanced contrast exposures between the two cameras The results proved favorable for real world robotic vision applications where noise is prevalent The proposed vergence control model was also compared with a standard window based Cartesian stereo matching method and showed superior performance (C) 2010 Elsevier B V All rights reserved
C1 [Zhang, Xuejie; Tay, Leng Phuan] Nanyang Technol Univ, Sch Comp Engn, Blk N4,Nanyang Ave, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Tay, LP (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Blk N4,Nanyang Ave, Singapore 639798, Singapore.
RI Zhang, Xuejie/B-8890-2009
CR [Anonymous], USC SIPI IM DAT
   BERNARDINO A, 1996, INT C INT ROB SYST O
   Cao YQ, 2005, SPATIAL VISION, V18, P515, DOI 10.1163/156856805774406756
   Capurro C, 1997, INT J COMPUT VISION, V24, P79, DOI 10.1023/A:1007974208880
   Chen YH, 2004, NEURAL COMPUT, V16, P1545, DOI 10.1162/089976604774201596
   CHING WS, 1995, COMPUT VIS IMAGE UND, V62, P298, DOI 10.1006/cviu.1995.1056
   CHING WS, 1993, INT C COMP VIS BERL
   COOMBS DJ, 1990, IEEE INT S INT CONTR, P239
   DANIEL PM, 1961, J PHYSIOL-LONDON, V159, P203, DOI 10.1113/jphysiol.1961.sp006803
   DEANGELIS GC, 1991, NATURE, V352, P156, DOI 10.1038/352156a0
   Díaz J, 2007, BIOSYSTEMS, V87, P314, DOI 10.1016/j.biosystems.2006.09.028
   FISCHER B, 1973, VISION RES, V13, P2113, DOI 10.1016/0042-6989(73)90188-0
   Fleet DJ, 1996, VISION RES, V36, P1839, DOI 10.1016/0042-6989(95)00313-4
   FLEET DJ, 1993, IEEE T PATTERN ANAL, V15, P1253, DOI 10.1109/34.250844
   Grossberg S, 2003, VISION RES, V43, P801, DOI 10.1016/S0042-6989(03)00011-7
   GROSSO E, 1995, INT S COMP VIS COR G, P509
   HANSEN M, 1996, INT C PATT REC VIENN, P287
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Manzotti R, 2001, COMPUT VIS IMAGE UND, V83, P97, DOI 10.1006/cviu.2001.0924
   Marefat MM, 1997, PATTERN RECOGN, V30, P1829, DOI 10.1016/S0031-3203(97)00066-6
   MEHANIAN C, 1991, P SOC PHOTO-OPT INS, V1471, P200, DOI 10.1117/12.44879
   MONACO J, 2007, INT C IM PROC SAN AN, P549
   OHZAWA I, 1990, SCIENCE, V249, P1037, DOI 10.1126/science.2396096
   OLSON T, 1993, INT C COMP VIS NEW Y, P55
   PLATER JH, 1999, INT S INT CONTR INT, P272
   SCHWARTZ EL, 1977, BIOL CYBERN, V25, P181, DOI 10.1007/BF01885636
   SIEBERT JP, 1992, FOVEATED VERGENCE ST
   Squire L.R., 2003, FUNDAMENTAL NEUROSCI
   TAYLOR JR, 1994, IEEE C COMP VIS PATT, P540
   THEIMER WM, 1992, P SOC PHOTO-OPT INS, V1826, P76, DOI 10.1117/12.131588
   TOOTELL RBH, 1982, SCIENCE, V218, P902, DOI 10.1126/science.7134981
   Traver VJ, 2008, IMAGE VISION COMPUT, V26, P1354, DOI 10.1016/j.imavis.2007.11.009
   VANESSEN DC, 1984, VISION RES, V24, P429, DOI 10.1016/0042-6989(84)90041-5
   Yarbus A. L., 1967, Eye Movements and Vision
   YESHURUN Y, 1989, IEEE T PATTERN ANAL, V11, P759, DOI 10.1109/34.192471
   YIM C, 1994, IEEE SW S IM AN INT
   Zhang AXJ, 2006, IEEE IJCNN, P4277
   Zhang XJ, 2009, CYBERNET SYST, V40, P549, DOI 10.1080/01969720903068484
   1996, COMPUTATION LOG POLA
NR 39
TC 11
Z9 11
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2011
VL 29
IS 1
BP 64
EP 77
DI 10.1016/j.imavis.2010.08.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 679BP
UT WOS:000284134700006
DA 2024-07-18
ER

PT J
AU Kim, BK
   Park, RH
AF Kim, Baek-Kyu
   Park, Rae-Hong
TI Detection and correction of purple fringing using color desaturation in
   the <i>xy</i> chromaticity diagram and the gradient information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Purple fringing; Color artifact; Chromaticity diagram; Gradient
   information; Desaturation; Blooming
AB This paper proposes a method to detect and correct purple fringing, which is one of color artifacts due to characteristics of charge coupled device sensors in a digital camera. The proposed method consists of two steps: detection and correction of purple fringing. In the first step, we detect the purple fringed regions that satisfy specific properties: image regions with large gradient magnitudes and with the chromaticity values within the purple color range set in the CIE xy chromaticity diagram. In the second step, color of the purple fringed regions is corrected in the CIE xy chromaticity diagram by color desaturation of the detected pixels. The proposed method is able to detect purple fringe artifacts more precisely and correct them more naturally than existing methods. It can be used as a post processing in a digital camera. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Kim, Baek-Kyu; Park, Rae-Hong] Sogang Univ, Dept Elect Engn, Seoul 100611, South Korea.
   [Park, Rae-Hong] Sogang Univ, Interdisciplinary Program Integrated Biotechnol, Seoul 100611, South Korea.
C3 Sogang University; Sogang University
RP Park, RH (corresponding author), Sogang Univ, Dept Elect Engn, CPO Box 1142, Seoul 100611, South Korea.
EM ohn109@sogang.ac.kr; rhpark@sogang.ac.kr
RI Park, Rae-Hong/Q-7908-2019
OI Park, Rae-Hong/0000-0002-4792-2980
FU Second Brain Korea 21 Project
FX This work was supported in part by the Second Brain Korea 21 Project.
CR [Anonymous], P 16 EUR SIGN PROC C
   Boult T. E., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P684, DOI 10.1109/CVPR.1992.223201
   Chang L, 2003, P IEEE INT C INF COM, V1, P76
   FIORENTIN P, 2003, P IEEE INT C INSTR M, V2, P1087
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Green W.B., 1989, DIGITAL IMAGE PROCES
   Hunt R.W. G., 1998, Measuring Color, V3rd
   KANG S, 2007, P IEEE INT C COMP VI
   KANG S, 2007, Patent No. 20070153341
   Kelly KL, 1943, J OPT SOC AM, V33, P627, DOI 10.1364/JOSA.33.000627
   KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279
   Kwan C, 2004, IEEE IMAGE PROC, P2415
   Lee H C., 2005, Introduction to Color Imaging Science
   Lukac R, 2009, IMAGE PROCESS SER, P1
   Malacara Daniel., 2002, COLOR VISION COLORIM
   Reinhard E., 2008, Color Imaging: Fundamentals and Applications
   Sharma G, 2003, EL EN AP SI, P1
   Ware C., 2020, INFORM VISUALIZATION
NR 18
TC 19
Z9 25
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 952
EP 964
DI 10.1016/j.imavis.2009.11.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200010
DA 2024-07-18
ER

PT J
AU Yu, WR
   Xu, BG
AF Yu, Wurong
   Xu, Bugao
TI A portable stereo vision system for whole body surface imaging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Whole body scanner; 3D surface imaging; Stereo matching; Disparity
ID REGULARIZATION; SCANNER; SHAPE
AB This paper presents a whole body Surface imaging system based on stereo vision technology. We have adopted a compact and economical configuration which involves only four stereo units to image the frontal and rear sides of the body. The Success of the system depends on a stereo matching process that can effectively segment the body from the background in addition to recovering sufficient geometric details. For this purpose, we have developed a novel sub-pixel, dense stereo matching algorithm which includes two major phases. In the first phase, the foreground is accurately segmented with the help of a predefined virtual interface in the disparity space image, and a coarse disparity map is generated with block matching. In the second phase, local least squares matching is performed in combination with global optimization within a regularization framework, so as to ensure both accuracy and reliability. Our experimental results show that the system can realistically Capture smooth and complete whole body shapes with high accuracy. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Yu, Wurong; Xu, Bugao] Univ Texas Austin, Sch Human Ecol, Austin, TX 78712 USA.
C3 University of Texas System; University of Texas Austin
RP Xu, BG (corresponding author), Univ Texas Austin, Sch Human Ecol, Austin, TX 78712 USA.
EM bxu@mail.utexas.edu
FU NIDDK NIH HHS [R21 DK081206-01, R21 DK081206] Funding Source: Medline
CR [Anonymous], 1999, P 2 INT C 3 D DIG IM
   [Anonymous], 2 DIMENSIONAL SIGNAL
   [Anonymous], 1962, FLOWS NETWORKS
   [Anonymous], 2008, DEV 3 DIMENSIONAL AN
   [Anonymous], 1981, P 7 INT JOINT C ART
   Bleyer M, 2005, ISPRS J PHOTOGRAMM, V59, P128, DOI 10.1016/j.isprsjprs.2005.02.008
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Corazza S, 2006, ANN BIOMED ENG, V34, P1019, DOI 10.1007/s10439-006-9122-8
   Cordier F, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1159612
   Daanen HAM, 1998, DISPLAYS, V19, P111, DOI 10.1016/S0141-9382(98)00034-1
   DApuzzo N, 2006, P C 3D MOD PAR FRANC
   Dougherty ER, 2003, SPIE TUTORIAL TEXTS, VTT5
   FELZENSZWALB PF, 2004, P IEEE CVPR 2004
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Istook C.L., 2001, J FASH MARK MANAG, V5, P120, DOI DOI 10.1108/EUM0000000007283
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   KOLMOGOROV V, 2005, P IEEE COMP VIS PATT
   Lewis JP, 1994, PROC CANAD IMAG PROC, P120
   Lin MH, 2003, PROC CVPR IEEE, P710
   Magnenat-Thalmann N, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P2, DOI 10.1109/IM.2003.1240226
   Nehab D., 2005, INT C COMP VIS ICCV
   Paquette S, 1996, IEEE COMPUT GRAPH, V16, P11, DOI 10.1109/38.536269
   POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0
   ROBINETTE KM, 2008, 3 D SURFACE ANTHROPO
   Roy S, 1999, INT J COMPUT VISION, V34, P147, DOI 10.1023/A:1008192004934
   Schapira AHV, 2002, EUR J NEUROL, V9, P7, DOI 10.1046/j.1468-1331.9.s3.9.x
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Shewchuk J. R., 1994, INTRO CONJUGATE GRAD
   Shimizu M, 2005, INT J COMPUT VISION, V63, P207, DOI 10.1007/s11263-005-6878-5
   Stein AN, 2006, IEEE INT CONF ROBOT, P914, DOI 10.1109/ROBOT.2006.1641826
   Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P413, DOI 10.1109/TPAMI.1986.4767807
   Thalmann D, 1996, COMPUTER GRAPHICS INTERNATIONAL, PROCEEDINGS, P166, DOI 10.1109/CGI.1996.511798
   Wang J, 2006, AM J CLIN NUTR, V83, P809
   Wells JCK, 2008, INT J OBESITY, V32, P152, DOI 10.1038/sj.ijo.0803685
   Wells JCK, 2008, INT J OBESITY, V32, P232, DOI 10.1038/sj.ijo.0803727
   Wells JCK, 2000, ANN NY ACAD SCI, V904, P247
   Wells JCK, 2007, AM J CLIN NUTR, V85, P419, DOI 10.1093/ajcn/85.2.419
   Westerwee lJ, 1993, DIGITAL PARTICLE IMA
   Xu B., 2003, J TEXT I, V94, P72
   YEDIDIA JS, 2001, TR200116 MITS EL RES
   Yu WR, 2008, TEXT RES J, V78, P457, DOI 10.1177/0040517507087853
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 46
TC 25
Z9 29
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 605
EP 613
DI 10.1016/j.imavis.2009.09.015
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600006
PM 20161620
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Chen, JS
   Moon, YS
   Wong, MF
   Su, GD
AF Chen, Jiansheng
   Moon, Yiu-Sang
   Wong, Ming-Fai
   Su, Guangda
TI Palmprint authentication using a symbolic representation of images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Palmprint authentication; Symbolic representation; Time
   series
ID IDENTIFICATION; VERIFICATION; RECOGNITION
AB A new branch of biometrics, palmprint authentication, has attracted increasing amount of attention because palmprints are abundant of line features so that low resolution images can be used. In this paper, we propose a new texture based approach for palmprint feature extraction, template representation and matching. An extension of the SAX (Symbolic Aggregate approXimation), a time series technology, to 2D data is the key to make this new approach effective, simple, flexible and reliable. Experiments show that by adopting the simple feature of grayscale information only, this approach can achieve an equal error rate of 0.3%, and a rank one identification accuracy of 99.9% on a 7752 palmprint public database. This new approach has very low computational complexity so that it can be efficiently implemented on slow mobile embedded platforms. The proposed approach does not rely on any parameter training process and therefore is fully reproducible. What is more, besides the palmprint authentication, the proposed 2D extension of SAX may also be applied to other problems of pattern recognition and data mining for 2D images. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Chen, Jiansheng; Su, Guangda] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
   [Moon, Yiu-Sang] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Shatin, Hong Kong, Peoples R China.
   [Wong, Ming-Fai] Univ Toronto, Dept Comp Sci, Toronto, ON M5S 3G4, Canada.
C3 Tsinghua University; Chinese University of Hong Kong; University of
   Toronto
RP Chen, JS (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM jschen@cse.cuhk.edu.hk
FU Council of the Hong Kong Special Administrative Region, China [415205];
   Tsinghua University, China [053207002]; Chinese Academy of Sciences'
   Institute of Automation (CASIA)
FX The work described in this paper was substantially supported by a grant
   from the Research Grants Council of the Hong Kong Special Administrative
   Region, China (Project No. 415205). This work was also partially
   supported by a grant from Tsinghua University, China (Project No.
   053207002).; Portions of the research in this paper use the CASIA
   Palmprint Image Database collected by the Chinese Academy of Sciences'
   Institute of Automation (CASIA).
CR [Anonymous], 1982, Digital Picture Processing
   [Anonymous], 2003, Handbook of fingerprint recognition
   [Anonymous], CASIA Palmprint Image Database V1.0
   [Anonymous], Polyu palmprint dataset
   [Anonymous], 2001, P ACM SIGMOD C MAN D
   Bergroth L, 2000, SPIRE 2000: SEVENTH INTERNATIONAL SYMPOSIUM ON STRING PROCESSING AND INFORMATION RETRIEVAL - PROCEEDINGS, P39, DOI 10.1109/SPIRE.2000.878178
   Chan KC, 2004, IEEE T CIRC SYST VID, V14, P95, DOI 10.1109/TCSVT.2003.818358
   Chen Chi-Hau., 2005, Handbook of Pattern Recognition and Computer Vision, Vthird
   Chen JS, 2005, LECT NOTES COMPUT SC, V3546, P376
   Daugman J.G., 1994, U.S. Patent, Patent No. 5291560
   Han CC, 2004, IMAGE VISION COMPUT, V22, P909, DOI 10.1016/j.imavis.2004.05.008
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   HAN MH, 1990, PATTERN RECOGN, V23, P21, DOI 10.1016/0031-3203(90)90046-N
   Han YF, 2007, LECT NOTES COMPUT SC, V4642, P1164
   Han YF, 2007, LECT NOTES COMPUT SC, V4642, P1184
   Kong A, 2006, PATTERN RECOGN, V39, P478, DOI 10.1016/j.patcog.2005.08.014
   KONG A, 2004, P INT C PATT REC, V1, P23
   Kong AWK, 2004, LECT NOTES COMPUT SC, V3072, P761
   Li S. Z., 2004, HDB FACE RECOGNITION
   Li WX, 2005, IEEE T MULTIMEDIA, V7, P891, DOI 10.1109/TMM.2005.854380
   Li WX, 2002, INT J PATTERN RECOGN, V16, P417, DOI 10.1142/S0218001402001757
   Lin J., 2003, 8THACM SIGMOD WORKSH, DOI [10.1145/882082. 882086, DOI 10.1145/882082.882086]
   MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x
   Pan X, 2008, IMAGE VISION COMPUT, V26, P1261, DOI 10.1016/j.imavis.2008.03.001
   Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Tenenbaum JM, 1970, THESIS STANFORD U
   Wang Q., 2004, P IEEE INT C AC SPEE, V3, P525
   Wu XQ, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1253, DOI 10.1109/ICMLC.2002.1167403
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D., 2004, Palmprint Authentication
   ZHANG D, 2002, Patent No. 10253
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
NR 33
TC 33
Z9 35
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 343
EP 351
DI 10.1016/j.imavis.2009.06.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300006
DA 2024-07-18
ER

PT J
AU Millet, C
   Bloch, I
   Hède, P
   Moellic, PA
AF Millet, Christophe
   Bloch, Isabelle
   Hede, Patrick
   Moellic, Pierre-Alain
TI Automatic cleaning and segmentation of web images based on colors to
   build learning databases
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantics; Web images; Automatic segmentation; Sorting images
AB This article proposes a method to segment Internet images, that is, a group of images corresponding to a specific object (the query) containing a significant amount of irrelevant images. The segmentation algorithm we propose is a combination of two distinct methods based on color. The first one considers all images to classify pixels into two sets: object pixels and background pixels. The second method segments images individually by trying to find a central object. The final segmentation is obtained by intersecting the results from both. The segmentation results are then used to re-rank images and display a clean set of images illustrating the query. The algorithm is tested on various queries for animals, natural and man-made objects, and results are discussed, showing that the obtained segmentation results are suitable for object learning. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Millet, Christophe; Hede, Patrick; Moellic, Pierre-Alain] CEA, LIST, Lab Ingenierie Connaissance Multimedia Multilingu, F-92265 Fontenay Aux Roses, France.
   [Millet, Christophe; Bloch, Isabelle] ENST GET Telecom Paris, CNRS, UMR 5141, LTCI, F-75013 Paris, France.
C3 CEA; Universite Paris Saclay; Centre National de la Recherche
   Scientifique (CNRS)
RP Millet, C (corresponding author), CEA, LIST, Lab Ingenierie Connaissance Multimedia Multilingu, 18 Route Panorama,BP6, F-92265 Fontenay Aux Roses, France.
EM chr.millet@gmail.com; isabelle.bloch@enst.fr; patrick.hede@cea.fr;
   pierre-alain.moellic@cea.fr
RI cai, bo/G-1491-2010
CR Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Fellbaum C., 1998, WORDNET ELECT LEXICA, DOI DOI 10.7551/MITPRESS/7287.001.0001
   Griffin G., 2007, CALTECH 256 OBJECT C
   GRUBINGER M, 2006, INT WORKSH ONT 2006
   HANBURY A, 2006, PRIPTR102 TU WIEN
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lienhart R, 2002, J ELECTRON IMAGING, V11, P445, DOI 10.1117/1.1502259
   MILLET C, 2007, P RECH INF ASS ORD R
   POPESCU A, 2007, P RECH INF ASS ORD R
   Von Ahn L, 2004, P SIGCHI C HUM FACT, DOI DOI 10.1145/985692.985733
   VONAHN L, 2006, P SIGCHI C HUM FACT, P55, DOI DOI 10.1145/1124772.1124782
NR 12
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 317
EP 328
DI 10.1016/j.imavis.2009.06.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300004
DA 2024-07-18
ER

PT J
AU Zimmermann, K
   Svoboda, T
   Matas, J
AF Zimmermann, Karel
   Svoboda, Tomas
   Matas, Jiri
TI Anytime learning for the NoSLLiP tracker
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Tracking; Learning; Real time
AB We propose an anytime learning procedure for the Sequence of Learned Linear Predictors (SLLiP) tracker. Since learning might be time-consuming for large problems, we present an anytime learning algorithm which, after a very short initialization period, provides a solution with defined precision. As SLLiP tracking requires only a fraction of the processing power of an ordinary PC, the learning can continue in a parallel background thread continuously delivering improved, i.e. faster, SLLiPs with lower computational complexity and the same precision.
   The proposed approach is verified on publicly-available sequences with approximately 12,000 ground-truthed frames. The learning time is shown to be 20 times smaller than standard SLLiP learning based on linear programming, yet its robustness and accuracy is similar. Superiority in the frame-rate and robustness in comparison with the SIFT detector, Lucas-Kanade tracker and Jurie's tracker is also demonstrated. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Zimmermann, Karel; Svoboda, Tomas; Matas, Jiri] Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Ctr Machine Percept, CR-16635 Prague, Czech Republic.
C3 Czech Technical University Prague
RP Zimmermann, K (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Ctr Machine Percept, Karlovo Nam 13, CR-16635 Prague, Czech Republic.
EM zimmerk@cmp.felk.cvut.cz; svoboda@cmp.felk.cvut.cz;
   matas@cmp.felk.cvut.cz
RI , Matas/AAW-3282-2020; Zimmermann, Karel/AAF-1596-2021; Zimmermann,
   Karel/G-7963-2014; Svoboda, Tomas/H-1627-2012
OI Zimmermann, Karel/0000-0002-8898-4512; Matas, Jiri/0000-0003-0863-4844;
   Svoboda, Tomas/0000-0002-7184-1785
FU Czech Academy of Sciences [1ET101210407]; Czech Ministry of Education
   [1M0567]; EC [ICT-215078 DIPLECS, FP6-IST-004176 COSPAL]
FX K. Zimmermann was supported by Czech Academy of Sciences project
   1ET101210407, T. Svoboda by Czech Ministry of Education project 1M0567,
   J. Matas by EC projects ICT-215078 DIPLECS and FP6-IST-004176 COSPAL.
CR Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   ELLIS L, 2007, P 11 IEEE INT C COMP
   JURIE F, 2002, BRIT MACH VIS C, P123
   LAND AH, 1960, ECONOMETRICA, V28, P497, DOI 10.2307/1910129
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Matas J, 2006, LECT NOTES COMPUT SC, V4338, P445
   Williams O, 2005, IEEE T PATTERN ANAL, V27, P1292, DOI 10.1109/TPAMI.2005.167
   ZHOU SK, 2005, P 10 IEEE INT C COMP, V1, P541, DOI DOI 10.1109/ICCV.2005.117
   ZIMMERMANN K, 2007, P 11 IEEE INT C COMP
   ZIMMERMANN K, 2009, T PATTERN ANAL MACHI, V31
NR 12
TC 2
Z9 4
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 2
PY 2009
VL 27
IS 11
SI SI
BP 1695
EP 1701
DI 10.1016/j.imavis.2009.03.005
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 498HJ
UT WOS:000270127800006
DA 2024-07-18
ER

PT J
AU Ikizler, N
   Duygulu, P
AF Ikizler, Nazli
   Duygulu, Pinar
TI Histogram of oriented rectangles: A new pose descriptor for human action
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Human motion understanding; Pose descriptor
ID MODELS
AB Most of the approaches to human action recognition tend to form complex models which require lots of parameter estimation and computation time. In this study, we show that, human actions can be simply represented by pose without dealing with the complex representation of dynamics. Based on this idea, we propose a novel pose descriptor which we name as Histogram-of-Oriented-Rectangles (HOR) for representing and recognizing human actions in videos. We represent each human pose in an action sequence by oriented rectangular patches extracted over the human silhouette. We then form spatial oriented histograms to represent the distribution of these rectangular patches. We make use of several matching strategies to carry the information from the spatial domain described by the HOR descriptor to temporal domain. These are (i) nearest neighbor classification, which recognizes the actions by matching the descriptors of each frame, (ii) global histogramming, which extends the idea of Motion Energy Image proposed by Bobick and Davis to rectangular patches, (iii) a classifier-based approach using Support Vector Machines, and (iv) adaptation of Dynamic Time Warping on the temporal representation of the HOR descriptor. For the cases when pose descriptor is not sufficiently strong alone, such as to differentiate actions "jogging" and "running", we also incorporate a simple velocity descriptor as a prior to the pose based classification step. We test our system with different configurations and experiment on two commonly used action datasets: the Weizmann dataset and the KTH dataset. Results show that our method is superior to other methods on Weizmann dataset with a perfect accuracy rate of 100%, and is comparable to the other methods on KTH dataset with a very high success rate close to 90%. These results prove that with a simple and compact representation, we can achieve robust recognition of human actions, compared to complex representations. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Ikizler, Nazli; Duygulu, Pinar] Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
C3 Ihsan Dogramaci Bilkent University
RP Ikizler, N (corresponding author), Bilkent Univ, Dept Comp Engn, Ankara, Turkey.
EM inazli@cs.bilkent.edu.tr; duygulu@cs.bilkent.edu.tr
RI Ikizler-Cinbis, Nazli/E-8961-2013; Duygulu, Pinar/IZP-7770-2023;
   Duygulu, Pinar/N-2707-2013
OI Duygulu, Pinar/0000-0002-6420-2838
FU TUBITAK [104E065, 104E077, 105E065]
FX This work has been supported by TUBITAK grants 104E065, 104E077 and
   105E065.
CR [Anonymous], INT C COMP VIS
   [Anonymous], VIS SURV WORKSH
   [Anonymous], INT C COMP VIS
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Dalal N., 2005, IEEE C COMP VIS PATT
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Forsyth D., 2006, Foundations and Trends in Computer Graphics and Vision, V1, P1
   Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399
   Freeman W.T., 1995, Orientation histograms for hand gesture recognition
   Hong P., 2000, Automatic Face and Gesture Recognition, P410
   Hongeng S, 2004, COMPUT VIS IMAGE UND, V96, P129, DOI 10.1016/j.cviu.2004.02.005
   Hu W., 2004, IEEE Trans, on Systems, Man, and Cybernetics, V34
   IKIZIER N, 2007, IEEE C COMP VIS PATT
   Ikizler N, 2007, LECT NOTES COMPUT SC, V4814, P271
   JIANG CWN, 2007, INT C IM VID RETR
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5302, P318, DOI 10.1007/978-3-540-88682-2_25
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2007, IEEE I CONF COMP VIS, P2165
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Ling H., 2006, CVPR, V1, P246, DOI DOI 10.1109/CVPR.2006.99
   Monay F, 2007, IEEE T PATTERN ANAL, V29, P1802, DOI 10.1109/TPAMI.2007.1097
   NIEBLES J, 2006, BRIT MACH VIS C
   Niebles JC, 2007, PROC CVPR IEEE, P1235
   Oliver N, 2004, COMPUT VIS IMAGE UND, V96, P163, DOI 10.1016/j.cviu.2004.02.004
   Pinhanez C., 1997, DARPA IU WORKSHOP, P227
   Pinhanez CS, 1998, PROC CVPR IEEE, P898, DOI 10.1109/CVPR.1998.698711
   Polana R., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P2, DOI 10.1109/CVPR.1993.341009
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Ramanan D., 2005, IEEE C COMP VIS PATT
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Siskind JM, 2003, ARTIF INTELL, V151, P91, DOI 10.1016/S0004-3702(03)00112-7
   Sminchisescu C, 2005, IEEE I CONF COMP VIS, P1808
   Wang L., 2007, IEEE C COMP VIS PATT
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   WONG SF, 2007, IEEE C COMP VIS PATT
NR 41
TC 86
Z9 105
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1515
EP 1526
DI 10.1016/j.imavis.2009.02.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800010
DA 2024-07-18
ER

PT J
AU Araújo, ARF
   Costa, DC
AF Araujo, Aluizio R. F.
   Costa, Diogo C.
TI Local adaptive receptive field self-organizing map for image color
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Self-organizing map; Color segmentation; Adaptive receptive-field; Image
   processing
ID REDUCTION
AB A new self-organizing map with variable topology is introduced for image segmentation. The proposed network, called a Local Adaptive Receptive Field Self-organizing Map (LARFSOM), is a fast convergent network capable of color segmenting images satisfactorily, which has optimum self-adaptive topology and achieves good PSNR values. LARFSOM is compared to SOM, FS-SOM and GNG, self-organizing maps used for color segmentation. LARFSOM reached a higher color palette variance and a better 3D RGB color space distribution of learned data from the training images than the other models. LARFSOM was tested to segment images with different degrees of complexity and has given promising results. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Araujo, Aluizio R. F.; Costa, Diogo C.] Univ Fed Pernambuco, Ctr Informat Cin, Dept Sistemas Computacao, BR-50740540 Recife, PE, Brazil.
C3 Universidade Federal de Pernambuco
RP Araújo, ARF (corresponding author), Univ Fed Pernambuco, Ctr Informat Cin, Dept Sistemas Computacao, Av Prof Luis Freire,S-N,Cidade Univ, BR-50740540 Recife, PE, Brazil.
EM aluizioa@cin.ufpe.br; dcc@cin.ufpe.br
RI Costa, Diogo/AAB-6184-2020; Araujo, Aluizio Fausto Ribeiro/AAH-2078-2019
OI Araujo, Aluizio/0000-0002-1749-2174
CR [Anonymous], 1997, ALGORITHMS IMAGE PRO
   [Anonymous], JASC PAINT SHOP PRO
   [Anonymous], SELF ORGANIZING MAPS
   Atsalakis A, 2006, ENG APPL ARTIF INTEL, V19, P769, DOI 10.1016/j.engappai.2006.05.004
   Chang CH, 2005, IEEE T NEURAL NETWOR, V16, P237, DOI 10.1109/TNN.2004.836543
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   Dong G, 2005, IEEE T NEURAL NETWOR, V16, P925, DOI 10.1109/TNN.2005.849822
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   Fritzke B., 1995, Advances in Neural Information Processing Systems 7, P625
   FRITZKE B, 1997, HDB NEURAL COMPUTATI, P1
   Gervautz M., 1990, GLASSNER GRAPHICS GE, P287, DOI [10.1016/B978-0-08-050753-8.50061-9, DOI 10.1016/B978-0-08-050753-8.50061-9]
   Gonzalez R.C., 2000, Digital Image Processing, V2nd
   Haykin S., 1998, NEURAL NETWORKS COMP
   Kanjanawanishkul K, 2005, J VIS COMMUN IMAGE R, V16, P311, DOI 10.1016/j.jvcir.2004.07.002
   Krishnamurthy A. K., 1992, IEEE J SEL AREA COMM, V38, P25
   Marsland S, 2002, NEURAL NETWORKS, V15, P1041, DOI 10.1016/S0893-6080(02)00078-3
   *MATHW INC, 2004, MATL VER 7 0 1 IM PR
   Ong SH, 2002, IMAGE VISION COMPUT, V20, P279, DOI 10.1016/S0262-8856(02)00021-5
   Papamarkos N, 2002, IEEE T SYST MAN CY B, V32, P44, DOI 10.1109/3477.979959
   Wang CH, 2007, PATTERN RECOGN LETT, V28, P1616, DOI 10.1016/j.patrec.2007.04.005
   Yeo NC, 2005, IMAGE VISION COMPUT, V23, P1060, DOI 10.1016/j.imavis.2005.07.008
   Zagoris K, 2007, LECT NOTES ARTIF INT, V4571, P703
NR 22
TC 34
Z9 37
U1 1
U2 35
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1229
EP 1239
DI 10.1016/j.imavis.2008.11.014
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200001
DA 2024-07-18
ER

PT J
AU Kuijper, A
AF Kuijper, Arjan
TI Geometrical PDEs based on second-order derivatives of gauge coordinates
   in image processing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-resolution processing; Nonlinear scale space; Gauge coordinates;
   Geometric image evolution
ID SCALE-SPACE; EDGE-DETECTION; DIFFUSION; EQUATION; AXIOMS
AB In this work, we analyse a series of approaches to evolve images. It is motivated by combining Gaussian blurring, the Mean Curvature Motion, used for denoising and edge-preserving, and maximal blurring, used for inpainting. We investigate the generalised method using the combination of second-order derivatives in terms of gauge coordinates.
   For the qualitative behaviour, we derive a solution of the series and mention its properties briefly. Relations with anisotropy and general diffusion equations are discussed. Quantitative results are obtained by a novel implementation whose stability is analysed. The practical results are visualised on a real-life image, showing the expected qualitative behaviour. When a constraint is added that penalises the distance of the results to the input image, one can vary the desired amount of blurring and denoising. (C) 2008 Elsevier B.V. All rights reserved.
C1 Austrian Acad Sci, Johann RICAM, A-4040 Linz, Austria.
C3 Austrian Academy of Sciences
RP Kuijper, A (corresponding author), Austrian Acad Sci, Johann RICAM, Altenbergerstr 69, A-4040 Linz, Austria.
EM arjan.kuijper@ricam.oeaw.ac.at
RI Kuijper, Arjan/A-7814-2012
OI Kuijper, Arjan/0000-0002-6413-0061
FU Johann Radon Institute (RICAM) of the Austrian Academy of Sciences; FWF;
   Analyse von Digitaler Bilder mit Methoden der Differenzialgleichungen;
   WWTF
FX This work was supported by the Johann Radon Institute (RICAM) of the
   Austrian Academy of Sciences, and the Austrian Science Funding Agencies
   FWF, through the Wittgenstein Award (2000) of Peter Markowich, and FFG,
   through the Research & Development Project 'Analyse von Digitaler Bilder
   mit Methoden der Differenzialgleichungen', and the WWTF 'Five
   senses-Call 2006' project 'Mathematical Methods for Image Analysis and
   Processing in the Visual Arts'. Preliminary results appeared in [43].
CR Abramowitz M., 1972, Handbook of mathematical functions with formulas, graphs, and mathematical tables, V10th
   ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   [Anonymous], 2006, Mathematical problems in image processing: Partial differential equations and the calculus of variations
   [Anonymous], 1962, Bulletin of the Electrotechnical Laboratory
   [Anonymous], 2003, Front-End Vision and Multi-Scale Image Analysis
   ARONSSON G, 1968, ARK MAT, V7, P395, DOI 10.1007/BF02590989
   Barenblatt G.I., 1952, PRIKL, V16, P679
   Caselles V, 1998, IEEE T IMAGE PROCESS, V7, P376, DOI 10.1109/83.661188
   Cayley A., 1859, Philosophical Magazine, V18, P264
   Chen YM, 2006, SIAM J APPL MATH, V66, P1383, DOI 10.1137/050624522
   Duits R, 2004, J MATH IMAGING VIS, V20, P267, DOI 10.1023/B:JMIV.0000024043.96722.aa
   FLORACK L, 1997, IMAGE STRUCTURE COMP, V10
   GRIFFIN L, 2003, LECT NOTES COMPUTER, V2695
   Griffin LD, 2000, P ROY SOC A-MATH PHY, V456, P2995, DOI 10.1098/rspa.2000.0650
   Keeling SL, 2002, INVERSE PROBL, V18, P175, DOI 10.1088/0266-5611/18/1/312
   Kerckhove M., 2001, LECT NOTES COMPUTER, V2106
   Kim S, 2006, IEEE T IMAGE PROCESS, V15, P1163, DOI 10.1109/TIP.2005.864184
   Kimia BB, 1996, COMPUT VIS IMAGE UND, V64, P305, DOI 10.1006/cviu.1996.0062
   KIMMEL R, 2005, LECT NOTES COMPUTER, V59
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Kornprobst P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P458, DOI 10.1109/ICIP.1997.638807
   KUIJPER A, 2007, 14 INT C IM PROC ICI, V5, P257
   KUIJPER A, 2008, COMPUTER VI IN PRESS
   Kuijper A, 2007, LECT NOTES COMPUT SC, V4843, P230
   Lindeberg T., 1994, The Kluwer International Series in Engineering and Computer Science
   Maxwell J. C., 1870, LONDON EDINBURGH DUB, V40, P421, DOI DOI 10.1080/14786447008640422
   NIELSEN M, 1999, LECT NOTES COMPUTER, V1682
   Niessen WJ, 1997, INT J COMPUT VISION, V21, P187, DOI 10.1023/A:1007995731951
   Oberman AM, 2005, MATH COMPUT, V74, P1217, DOI 10.1090/S0025-5718-04-01688-6
   OLSEN OF, 1997, LECT NOTES COMPUTER, V1310, P6
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   ROMENY BMT, 1994, GEOMETRY DRIVEN DIFF, V1
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   SGALLARI F, 2007, LECT NOTES COMPUTER, V4485
   Sporring J., 1997, Computational Imaging and Vision, V8
   Vazquez J. L., 2006, Oxford Lecture Series in Mathematics and its Applications, V33
   Weickert J, 1999, J MATH IMAGING VIS, V10, P237, DOI 10.1023/A:1008344623873
   Weickert J., 1997, Scale-Space Theoryin Computer Vision. Scale-Space 1997, V1252
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Weisstein E. W., 2006, MATHWORLD WOLFRAM WE
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
NR 42
TC 21
Z9 24
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1023
EP 1034
DI 10.1016/j.imavis.2008.09.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000004
DA 2024-07-18
ER

PT J
AU Everingham, M
   Sivic, J
   Zisserman, A
AF Everingham, Mark
   Sivic, Josef
   Zisserman, Andrew
TI Taking the bite out of automated naming of characters in TV video
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 17th Annual British Machine Vision Conference
CY SEP, 2006
CL British Machine Vis Assoc, Edinburgh, SCOTLAND
HO British Machine Vis Assoc
DE Video indexing; Automatic annotation; Face recognition
ID FACE-RECOGNITION
AB We investigate the problem of automatically labelling appearances of characters in TV or film material with their names. This is tremendously challenging due to the huge variation in imaged appearance of each character and the weakness and ambiguity of available annotation. However, we demonstrate that high precision can be achieved by combining multiple sources of information, both visual and textual. The principal novelties that we introduce are: (i) automatic generation of time stamped character annotation by aligning subtitles and transcripts; (ii) strengthening the supervisory information by identifying when characters are speaking. In addition, we incorporate complementary cues of face matching and clothing matching to propose common annotations for face tracks, and consider choices of classifier which can potentially correct errors made in the automatic extraction of training data from the weak textual annotation. Results are presented on episodes of the TV series "Buffy the Vampire Slayer". (C) 2008 Elsevier B.V. All rights reserved.
C1 [Everingham, Mark; Sivic, Josef; Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England.
C3 University of Oxford
RP Everingham, M (corresponding author), Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
EM me@comp.leeds.ac.uk
CR [Anonymous], 2002, IEEE INT C AUT FAC G
   [Anonymous], 2006, P COMP VIS PATT REC
   [Anonymous], 2003, ACM Multimedia Conference
   APOSTOLOFF N, 2007, P BRIT MACH VIS C BM, P509
   Arandjelovic O, 2005, PROC CVPR IEEE, P860
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berg TL, 2004, PROC CVPR IEEE, P848
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   CRISTINACCE D, 2006, P 17 BRIT MACH VIS C, P929
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duygulu P, 2002, LECT NOTES COMPUT SC, V2353, P97
   Everingham M, 2005, IEEE I CONF COMP VIS, P1103
   Everingham M, 2005, IEE P-VIS IMAGE SIGN, V152, P902, DOI 10.1049/ip-vis:20045186
   Everingham M., 2006, BMVC, V2, P6
   Everingham M, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P441
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fitzgibbon A, 2002, LECT NOTES COMPUT SC, V2352, P304
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   JAFFRE G, 2004, P RIAO COUPL APPR CO, P314
   Kidron E, 2005, PROC CVPR IEEE, P88
   Leibe B, 2005, PROC CVPR IEEE, P878
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Meila M, 2001, J MACH LEARN RES, V1, P1, DOI 10.1162/153244301753344605
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x
   OZKAN D, 2006, P INT C IM VID RETR, P173
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Press W. H., 1988, Numerical Recipes
   Saenko K, 2005, IEEE I CONF COMP VIS, P1424, DOI 10.1109/ICCV.2005.251
   Shakhnarovich G., 2004, Handbook of Face Recognition
   Shawe-Taylor John, 2004, KERNEL METHODS PATTE
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sivic J, 2005, LECT NOTES COMPUT SC, V3568, P226
   Sivic Josef., 2006, British Machine Vision Conference, P909
   SONG Y, 2006, P ECCV, V3, P382
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Yang J, 2005, Proceedings of the 2005 International Conference on Active Media Technology (AMT 2005), P28
   Yang J, 2004, LECT NOTES COMPUT SC, V3115, P270
NR 41
TC 93
Z9 105
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 2
PY 2009
VL 27
IS 5
SI SI
BP 545
EP 559
DI 10.1016/j.imavis.2008.04.018
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 437WD
UT WOS:000265516700006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jin, LH
   Li, DH
   Song, EM
AF Jin, Lianghai
   Li, Dehua
   Song, Enmin
TI Combining vector ordering and spatial information for color image
   interpolation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Interpolation; Zooming; Color image processing; Vector filtering; Vector
   processing
AB A new idea for color image zooming techniques is introduced in this paper. Conventional interpolation techniques usually utilize only the spatial information of the neighborhood color pixels around the interpolation positions and do not consider their vectorial characteristics. This paper presents a novel color image interpolation method, which takes both the spatial information and vectorial characteristics into consideration. By combining the spatial distance and the vector-aggregated distance associated with each neighborhood color pixel, the proposed solution first determines the importance of each neighborhood pixel to the current interpolated pixel and then employs a data-adaptive vector filter to estimate the new interpolated pixel. The extensive simulation results demonstrate the validity of the proposed interpolator by yielding excellent visual effect and showing significant performance improvement over the conventional and other vector filtering based interpolation methods in terms of objective image quality measures. (C) 2008 Elsevier B.V. All rights reserved
C1 [Jin, Lianghai; Song, Enmin] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Hubei, Peoples R China.
   [Li, Dehua] Huazhong Univ Sci & Technol, Inst Pattern Recognit & Artificial Intelligence, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Jin, LH (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Luoyu Rd 1037, Wuhan 430074, Hubei, Peoples R China.
EM lhjin518@gmail.com
FU Hi-Tech Research and Development Program of China [2006AA02Z347]
FX This study was supported by the Hi-Tech Research and Development Program
   of China under Grant No. 2006AA02Z347.
CR ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Franzen O, 2001, PROC SPIE, V4304, P306, DOI 10.1117/12.424985
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   Jin LH, 2007, OPT ENG, V46, DOI 10.1117/1.2713400
   Karakos DG, 1997, IEEE T IMAGE PROCESS, V6, P1038, DOI 10.1109/83.597278
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Lehmann TM, 1999, IEEE T MED IMAGING, V18, P1049, DOI 10.1109/42.816070
   Lukac R, 2005, ISIE 2005: PROCEEDINGS OF THE IEEE INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS 2005, VOLS 1- 4, P1273
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   MAELAND E, 1988, IEEE T MED IMAGING, V7, P213, DOI 10.1109/42.7784
   Phu M. Q., 2004, Proceedings of 2004 International Symposium on Intelligent Signal Processing And Communication Systems ISPACS 2004 (IEEE Cat. No.04EX910), P390, DOI 10.1109/ISPACS.2004.1439083
   Plataniotis K., 2000, DIGITAL SIGNAL PROC, P25
   Plataniotis KN, 1999, P IEEE, V87, P1601, DOI 10.1109/5.784243
   Reichenbach SE, 2003, IEEE T IMAGE PROCESS, V12, P857, DOI 10.1109/TIP.2003.814248
   Trahanias PE, 1996, IEEE T IMAGE PROCESS, V5, P868, DOI 10.1109/83.503905
   Zeng B, 1998, OPT ENG, V37, P2472, DOI 10.1117/1.601771
NR 16
TC 7
Z9 10
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 410
EP 416
DI 10.1016/j.imavis.2008.06.007
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600011
DA 2024-07-18
ER

PT J
AU El Fkihi, S
   Daoudi, M
   Aboutajdine, D
AF El Fkihi, Sanaa
   Daoudi, Mohamed
   Aboutajdine, Driss
TI The mixture of <i>K</i>-Optimal-Spanning-Trees based probability
   approximation: Application to skin detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optimal-Spanning-Tree; Dependency tree; Probability mixture; Mixture of
   trees; Skin detection
AB This paper presents a new approach for machine learning to deal with the problem of classification and/or probability approximation. Our contribution is based on the Optimal-Spanning-Tree distributions that are widely used in many optimization areas. The rationale behind this study is that in some cases the approximation of true class probability given by an Optimal-Spanning-Tree is not unique and might be chosen randomly. Furthermore, the user can specify the error tolerance between the tree weights that he/she can accept to manage the information of these kinds of trees. Therefore, the main idea of this work consists in focusing and highlighting the performance of each possible K (K is an element of N) Optimal-Spanning-Tree and making some assumptions, to propose the mixture of the K-Optimal-SpanningTrees approximating the true class probability in a supervised algorithm.
   The theoretical proof of the K-Optimal-Spanning-Trees' mixture is given. Furthermore, the performance of our method is assessed for Skin/Non-Skin classification in the Compaq database by measuring the Receiver Operating Characteristic curve and its under area. These measures have proved better results of the proposed model compared with a random Optimal- Spanning-Tree model and the baseline one. (C) 2008 Elsevier B.V. All rights reserved.
C1 [El Fkihi, Sanaa; Daoudi, Mohamed] USTL, CNRS, UMR 8022, LIFL,TELECOM Lille 1,Inst TELECOM, F-59655 Villeneuve Dascq, France.
   [El Fkihi, Sanaa; Aboutajdine, Driss] Univ Mohammed 5, Fac Sci, GSCM, LRIT, Robat, Morocco.
C3 IMT - Institut Mines-Telecom; IMT Atlantique; Centre National de la
   Recherche Scientifique (CNRS); Universite de Lille
RP El Fkihi, S (corresponding author), USTL, CNRS, UMR 8022, LIFL,TELECOM Lille 1,Inst TELECOM, Rue G Marconi, F-59655 Villeneuve Dascq, France.
EM elfkihi@telecom-lille1.eu; daoudi@telecom-lille1.eu; aboutaj@ieee.org
RI EL FKIHI, Sanaa/KBQ-2521-2024; aboutajdine, driss/AAP-9051-2020; Daoudi,
   Mohammed/H-5935-2013
OI Daoudi, Mohammed/0000-0003-4219-7860
FU French Ministry for Foreign Affairs; MarocTelecom [10590805/PI]
FX This work was supported in France by 'programme Eiffel Doctorat' of
   French Ministry for Foreign Affairs and in Morocco by 'MarocTelecom'
   (Contract No. 10590805/PI).
CR [Anonymous], ELECT LETT COMPUTER
   BACH FR, 2002, P 18 C UNC ART INT
   CHOW CK, 1968, IEEE T INFORM THEORY, V14, P462, DOI 10.1109/TIT.1968.1054142
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cormen T.H., 1989, Introduction to Algorithms
   Cover T. M., 1991, ELEMENTS INFORM THEO
   ELFKIHI S, 2006, PROBABILITY APPROXIM, P767
   FRIEDMAN N, 2001, 17 C UNC ART INT SEA, P144
   GEIGER D, 1992, P 8 C UNC AI, P92
   Jedynak B, 2005, IMAGE VISION COMPUT, V23, P1122, DOI 10.1016/j.imavis.2005.06.010
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   KATOH N, 1981, SOC IND APPL MATH, V10
   Meila M, 2001, J MACH LEARN RES, V1, P1, DOI 10.1162/153244301753344605
   Pearl J., 1988, PROBABILISTIC REASON
   Sebe N, 2004, INT C PATT RECOG, P903, DOI 10.1109/ICPR.2004.1334405
   Terrillon J.-C., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P54, DOI 10.1109/AFGR.2000.840612
   Torsello A, 2006, IEEE T PATTERN ANAL, V28, P954, DOI 10.1109/TPAMI.2006.125
NR 17
TC 3
Z9 3
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1574
EP 1590
DI 10.1016/j.imavis.2008.02.003
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500003
DA 2024-07-18
ER

PT J
AU Picton, PD
   Capp, MD
AF Picton, Phil D.
   Capp, Michael D.
TI Relaying scene information to the blind via sound using cartoon depth
   maps
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE real-time vision; stereoscopic vision; blind navigation aids
ID AID
AB Important scene information may be relayed to a blind person via mobility aids that incorporates an image-to-sound mapping. However, these devices are frequently both tiring and stressful to use. Stereo depth maps are considered as a means of reducing the quantity of unnecessary information passed to the listener. A simple automated method for evaluating the effectiveness of edge depth maps is described, followed by an explanation of a new display technique, which combines a stereo edge depth map with a cartoon-like scene representation. Finally, experimental results are included that demonstrate the effectiveness of this representation. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Picton, Phil D.; Capp, Michael D.] Univ Northampton, Sch Appl Sci, Northampton NN2 6JD, England.
C3 University of Northampton
RP Picton, PD (corresponding author), Univ Northampton, Sch Appl Sci, St Georges Ave, Northampton NN2 6JD, England.
EM phil.picton@northampton.ac.uk
OI Picton, Phil/0000-0002-7067-1534
CR BENHAM TA, 1993, P INT C TECHN BLINDN, V1, P167
   BERGENDAHL J, 1997, THESIS MIT
   Capp M, 2000, ENG SCI EDUC J, V9, P137, DOI 10.1049/esej:20000306
   CAPP M, 2000, INT C COMP VIS PATT, V2, P248
   CAPP M, 2000, 10 INT MOB C WARW, P19
   CAPP M, 2000, THESIS LEICESTER U
   d'Albe Edmund Edward Fournier., 1924, The Moon Element: An Introduction to the Wonder of Selenium
   Fua P., 1993, Machine Vision and Applications, V6, P35, DOI 10.1007/BF01212430
   KAY L, 1984, IEE PROC-A, V131, P559, DOI 10.1049/ip-a-1.1984.0071
   MANORANJAN M, 1998, THESIS MEMORIAL U NE, P159
   MARSHALL S, 1985, COMP CONTR C VIS SYS
   MEIJER PBL, 1992, IEEE T BIO-MED ENG, V39, P112, DOI 10.1109/10.121642
   Molton N, 1998, IMAGE VISION COMPUT, V16, P251, DOI 10.1016/S0262-8856(97)00087-5
   MORAVEC HP, 1996, CMURITR9634, V1521, P44
   Nielsen L., 1987, Proceedings of the 5th Scandinavian Conference on Image Analysis, P383
   OHEA AR, 1994, THESIS OPEN U UK
   PEARSON DE, 1985, P IEEE, V73, P795, DOI 10.1109/PROC.1985.13202
   POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449
   Shoval S, 1998, IEEE T BIO-MED ENG, V45, P1376, DOI 10.1109/10.725334
   WARREN DH, 1984, EL SPAT SENS BLIND N
NR 20
TC 3
Z9 5
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 570
EP 577
DI 10.1016/j.imavis.2007.07.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100009
DA 2024-07-18
ER

PT J
AU Gao, ZY
   Gu, B
   Lin, JR
AF Gao, Zhiyong
   Gu, Bin
   Lin, Jiarui
TI Monomodal image registration using mutual information based methods
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image registration; mutual information; normalized mutual information;
   interpolation artefact
ID SIMILARITY MEASURES; HEAD
AB Image registration methods based on mutual information criteria, including mutual information and normalized mutual information, have been widely used in 3-D multimodal medical image registration and have shown promising results. Although they are also used in monomodal image registration, their performance is not as excellent as that in multimodal registration. There are many fluctuations in the registration function, which hinder the optimization procedure and lead to registration failure. This paper discusses this problem and ascribes it to interpolation artefacts and the variability of entropy. We implement experiments to evaluate the performance of the two similarity measures for 2-D and 3-D monomodal registration. To avoid the interpolation artefacts, we use pixels or voxels as the translation metric; to diminish the influence of entropy variability, we use normalized mutual information. The results show that, both for standard and normalized mutual information, the fluctuations caused by interpolation are fewer in the function of the registration without interpolation. Normalized mutual information has some similar properties to mutual information, but is almost invariant to the changing of entropy and appears to be more stable and robust than standard mutual information. These differences seem to indicate a preference for the normalized mutual information in monomodal registration. (c) 2006 Elsevier B.V. All rights reserved.
C1 [Gao, Zhiyong] S Cent Univ Nationalities, Coll Elect & Informat Engn, Wuhan 430074, Hubei, Peoples R China.
   [Gu, Bin; Lin, Jiarui] Huazhong Univ Sci & Technol, Inst Biomed Engn, Wuhan 430074, Hubei, Peoples R China.
C3 South Central Minzu University; Huazhong University of Science &
   Technology
RP Gao, ZY (corresponding author), S Cent Univ Nationalities, Coll Elect & Informat Engn, Wuhan 430074, Hubei, Peoples R China.
EM zhiyong_gao@163.com
CR Carrillo D, 2000, CR ACAD SCI II C, V3, P175, DOI 10.1016/S1387-1609(00)00137-7
   COLLIGNON A, 1995, COMP IMAG VIS, V3, P263
   Holden M, 2000, IEEE T MED IMAGING, V19, P94, DOI 10.1109/42.836369
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Maurer CR, 1997, IEEE T MED IMAGING, V16, P447, DOI 10.1109/42.611354
   Nikou C, 1999, PATTERN RECOGN, V32, P1351, DOI 10.1016/S0031-3203(98)00167-8
   Penney GP, 1998, IEEE T MED IMAGING, V17, P586, DOI 10.1109/42.730403
   Pluim JPW, 2000, COMPUT VIS IMAGE UND, V77, P211, DOI 10.1006/cviu.1999.0816
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Ritter N, 1999, IEEE T MED IMAGING, V18, P404, DOI 10.1109/42.774168
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Studholme C, 1997, MED PHYS, V24, P25, DOI 10.1118/1.598130
   VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938
   VIOLA P, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P16, DOI 10.1109/ICCV.1995.466930
   Wells W M 3rd, 1996, Med Image Anal, V1, P35
   West J, 1997, J COMPUT ASSIST TOMO, V21, P554, DOI 10.1097/00004728-199707000-00007
   West J, 1999, IEEE T MED IMAGING, V18, P144, DOI 10.1109/42.759119
NR 18
TC 39
Z9 46
U1 0
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 164
EP 173
DI 10.1016/j.imavis.2006.08.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500002
DA 2024-07-18
ER

PT J
AU Sage, K
   Howell, AJ
   Buxton, H
   Argyros, A
AF Sage, Kingsley
   Howell, A. Jonathan
   Buxton, Hilary
   Argyros, Antonis
TI Learning temporal structure for task based control
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE variable length Markov models; temporal learning; 3-d tracking; data
   association; task-based control
ID REPRESENTATION; MODELS
AB We present an extension for variable length Markov models (VLMMs) to allow for modelling of continuous input data and show that the generative properties of these VLMMs are a powerful tool for dealing with real world tracking issues. We explore methods for addressing the temporal correspondence problem in the context of a practical hand tracker, which is essential to support expectation in task-based control using these behavioural models. The hand tracker forms a part of a larger multi-component distributed system, providing 3-D hand position data to a gesture recogniser client. We show how the performance of such a hand tracker can be improved by using feedback from the gesture recogniser client. In particular, feedback based on the generative extrapolation of the recogniser's internal models is shown to help the tracker deal with mid-term occlusion. We also show that VLMMs can be used as a means to inform the prior in an expectation maximisation (EM) process used for joint spatial and temporal learning of image features. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Sussex, Ctr Res Cognit Sci, Dept Informat, Brighton BN1 9QH, E Sussex, England.
   Fdn Res & Technol Hellas, Inst Comp Sci, GR-71110 Iraklion, Greece.
C3 University of Sussex; Foundation for Research & Technology - Hellas
   (FORTH)
RP Sage, K (corresponding author), Univ Sussex, Ctr Res Cognit Sci, Dept Informat, Brighton BN1 9QH, E Sussex, England.
EM khs20@sussex.ac.uk; jonh@sussex.ac.uk; hilaryb@sussex.ac.uk;
   argyros@ics.forth.gr
RI Argyros, Antonis/GPK-4775-2022; Argyros, Antonis/AAD-9251-2019
OI Argyros, Antonis/0000-0001-8230-3192; 
CR ARGYROS M, 2004, P EUR C COMP VIS PRA, P368
   BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4
   Brand M, 1999, NEURAL COMPUT, V11, P1155, DOI 10.1162/089976699300016395
   Clouse DS, 1997, IEEE T NEURAL NETWOR, V8, P1065, DOI 10.1109/72.623208
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FREY B, 2002, ADV NEURAL INFORM PR
   FREY B, 2002, IEEE T PATTERN ANAL, P1
   Frey B. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P416, DOI 10.1109/CVPR.1999.786972
   Galata A, 2001, COMPUT VIS IMAGE UND, V81, P398, DOI 10.1006/cviu.2000.0894
   GONG SG, 1992, ECAI 92 - 10TH EUROPEAN CONFERENCE ON ARTIFICIAL INTELLIGENCE : PROCEEDINGS, P781
   Howarth RJ, 1998, ARTIF INTELL, V100, P5, DOI 10.1016/S0004-3702(98)00004-6
   Johnson N, 2002, IMAGE VISION COMPUT, V20, P889, DOI 10.1016/S0262-8856(02)00097-5
   JOJIC N, 2000, P IEEE C COMP VIS PA
   Moore D. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P80, DOI 10.1109/ICCV.1999.791201
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Ron D., 1994, NIPS, V6, P176
   Sage K, 2003, LECT NOTES ARTIF INT, V2915, P277
   SAGE K, IN PRESS COMPUTER VI
   SAGE K, 2004, P INT C PATT REC CAM
   STARNER T, 1995, P INT WORKSH AUT FAC, P189
   Vogler C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P363, DOI 10.1109/ICCV.1998.710744
NR 21
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 39
EP 52
DI 10.1016/j.imavis.2005.08.010
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100005
DA 2024-07-18
ER

PT J
AU Yamazoe, H
   Utsumi, A
   Hosaka, K
   Yachida, M
AF Yamazoe, Hirotake
   Utsumi, Akira
   Hosaka, Kenichi
   Yachida, Masahiko
TI A body-mounted camera system for head-pose estimation and user-view
   image synthesis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE body-mounted camera; head motion; user-view image; wearable system
AB In this paper, we propose a body-mounted system to capture user experience as audio/visual information. The proposed system consists of two cameras (head-detection and wide angle) and a microphone. The head-detection camera captures user head motions, while the wide angle color camera captures user frontal view images. An image region approximately corresponding to user view is then synthesized from the wide angle image based on estimated human head motions. The synthesized image and head-motion data are stored in a storage device with audio data. This system overcomes the disadvantages of head-mounted cameras in terms of ease of putting on/taking off the device. It also has less obtrusive visual impact on third persons. Using the proposed system, we can simultaneously record audio data, images in the user field of view, and head gestures (nodding, shaking, etc.) simultaneously. These data contain significant information for recording/analyzing human activities and can be used in wider application domains such as a digital diary or interaction analysis. Experimental results demonstrate the effectiveness of the proposed system. (C) 2006 Elsevier B.V. All rights reserved.
C1 ATR, Media Informat Sci Labs, Kyoto 6190288, Japan.
   Osaka Univ, Grad Sch Engn Sci, Osaka 5608531, Japan.
C3 Osaka University
RP Yamazoe, H (corresponding author), ATR, Media Informat Sci Labs, 2-2-2 Hikaridai,Seika Cho, Kyoto 6190288, Japan.
EM yamazoe@atr.jp
CR AIZAWA K, 2001, INT C MED FUT, P239
   Clarkson B, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P69, DOI 10.1109/ISWC.2000.888467
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Healey J, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P42, DOI 10.1109/ISWC.1998.729528
   LAMMING M, 1994, EPC1994103 CAMBR LAB
   MANN S, 2002, IEEE COMPUT, V30, P25
   NUMAZAKI J, 1998, P INT S WEAR COMP, P237
   NUMAZAKI S, 1998, P CHI 98, P237
   Starner T, 2000, FOURTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, DIGEST OF PAPERS, P87, DOI 10.1109/ISWC.2000.888469
   Starner T, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P50, DOI 10.1109/ISWC.1998.729529
   SUMI Y, 2003, UBICOMP 2003, P193
   YAMAZOE H, 2004, P AS C COMP VIS 2004, P682
NR 12
TC 5
Z9 9
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 3
PY 2007
VL 25
IS 12
BP 1848
EP 1855
DI 10.1016/j.imavis.2005.12.019
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220BD
UT WOS:000250131000003
DA 2024-07-18
ER

PT J
AU Miravet, C
   Rodríguez, FB
AF Miravet, Carlos
   Rodriguez, Francisco B.
TI A two-step neural-network based algorithm for fast image
   super-resolution
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE super-resolution; multi-layer perceptron; probabilistic neural network;
   sequence processing; image restoration
ID HIGH-RESOLUTION IMAGE; EFFICIENT SUPERRESOLUTION; RECONSTRUCTION;
   ENHANCEMENT; REDUCTION
AB We propose a novel, learning-based algorithm for image super-resolution. First, an optimal distance-based weighted interpolation of the image sequence is performed using a new neural architecture, hybrid of a multi-layer perceptron and a probabilistic neural network, trained on synthetic image data. Secondly, a linear filter is applied with coefficients learned to restore residual interpolation artifacts in addition to low-resolution blurring, providing noticeable improvements over lens-detector Wiener restorations. Our method has been evaluated on real visible and IR sequences with widely different contents, providing significantly better results that a two-step method with high computational requirements. Results were similar or better than those of a maximum-a-posteriori estimator, with a reduction in processing time by a factor of almost 300. This paves the way to high-quality, quasi-real time applications of super-resolution techniques. (C) 2007 Elsevier B.V. All rights reserved.
C1 Univ Autonoma Madrid, GNB, Escuela Politecn Super, E-28049 Madrid, Spain.
   SENER Ingn & Sistemas AS, Aerosp Div, Madrid 28760, Spain.
C3 Autonomous University of Madrid
RP Miravet, C (corresponding author), Univ Autonoma Madrid, GNB, Escuela Politecn Super, Crta Colmenar Km 15, E-28049 Madrid, Spain.
EM carlos.miravet@uam.es; f.rodriguez@uam.es
RI cai, bo/G-1491-2010; Rodriguez, Francisco de Borja/F-7812-2013
OI Rodriguez, Francisco de Borja/0000-0003-4053-099X
CR Alam MS, 2000, IEEE T INSTRUM MEAS, V49, P915, DOI 10.1109/19.872908
   [Anonymous], NEURAL NETWORKS PATT
   [Anonymous], 1987, PARALLEL DISTRIBUTED, DOI [10.7551/mitpress/5237.001.0001, DOI 10.7551/MITPRESS/5237.001.0001]
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   BISHOP CM, 2003, P ARTIF INTELL STAT
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   BORMAN S, 1998, P MIDW S CIRC SYST
   Candocia FM, 1999, IEEE T NEURAL NETWOR, V10, P372, DOI 10.1109/72.750566
   Capel D, 2001, PROC CVPR IEEE, P627
   Capel D, 2003, IEEE SIGNAL PROC MAG, V20, P75, DOI 10.1109/MSP.2003.1203211
   CAPEL D, 1998, P IEEE C COMP VIS PA
   CHAN RH, 1989, SIAM J SCI STAT COMP, V10, P104, DOI 10.1137/0910009
   Chiang MC, 2000, IMAGE VISION COMPUT, V18, P761, DOI 10.1016/S0262-8856(99)00044-X
   Dávila CA, 2000, APPL OPTICS, V39, P3473, DOI 10.1364/AO.39.003473
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Fausset L., 1994, FUNDAMENTALS NEURAL
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   GILLETT JC, 1995, OPT ENG, V34, P3130, DOI 10.1117/12.213590
   Gonzalez R.C., 1987, DIGITAL IMAGE PROCES, VSecond
   Granrath D, 1998, J OPT SOC AM A, V15, P791, DOI 10.1364/JOSAA.15.000791
   Gustafson SC, 2001, P SOC PHOTO-OPT INS, V4305, P39, DOI 10.1117/12.420942
   Hanke M., 1994, Numerical Algorithms, V7, P183, DOI 10.1007/BF02140682
   Hardie RC, 1998, OPT ENG, V37, P247, DOI 10.1117/1.601623
   Haykin S., 1998, NEURAL NETWORKS COMP
   Hecht-Nielsen R., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P593, DOI 10.1109/IJCNN.1989.118638
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hestenes M.R., 1980, CONJUGATE DIRECTION
   HOLST GC, 2006, ELECT OPTICAL IMAGIN
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   Huber P., 1981, Robust Statistics
   HUMMEL RA, 1987, COMPUT VISION GRAPH, V38, P66, DOI 10.1016/S0734-189X(87)80153-6
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jiji CV, 2004, INT J IMAG SYST TECH, V14, P105, DOI 10.1002/ima.20013
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kim KI, 2005, IEEE T PATTERN ANAL, V27, P1351, DOI 10.1109/TPAMI.2005.181
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   KOMATSU T, 1993, IEE PROC-I, V140, P19, DOI 10.1049/ip-i-2.1993.0005
   Lu Y, 2002, INT J IMAG SYST TECH, V12, P254, DOI 10.1002/ima.10033
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Miravet C, 2003, LECT NOTES COMPUT SC, V2714, P417
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   Nguyen N, 2000, CIRC SYST SIGNAL PR, V19, P321, DOI 10.1007/BF01200891
   PAPOULIS A, 1977, IEEE T CIRCUITS SYST, V24, P652, DOI 10.1109/TCS.1977.1084284
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Patti AJ, 1997, IEEE T IMAGE PROCESS, V6, P1064, DOI 10.1109/83.605404
   Patti AJ, 2001, IEEE T IMAGE PROCESS, V10, P179, DOI 10.1109/83.892456
   PICKUP LC, 2006, ADV NEURAL INFORM PR
   Plaziac N, 1999, IEEE T IMAGE PROCESS, V8, P1647, DOI 10.1109/83.799893
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Rosenfeld A., 1984, MULTIRESOLUTION IMAG
   Salari E, 2003, IEE P-VIS IMAGE SIGN, V150, P299, DOI 10.1049/ip-vis:20030524
   SCHULZ RR, 1996, IEEE T IMAGE PROCESS, V6, P996
   Shah NR, 1999, IEEE T IMAGE PROCESS, V8, P879, DOI 10.1109/83.766865
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   Staelin C., 2003, HPL200326R1 HP, P1
   STARK H, 1989, J OPT SOC AM A, V6, P1715, DOI 10.1364/JOSAA.6.001715
   Storey JC, 2001, P SOC PHOTO-OPT INS, V4540, P50, DOI 10.1117/12.450647
   Su CY, 2005, PATTERN RECOGN, V38, P813, DOI 10.1016/j.patcog.2004.11.007
   Szu H, 2001, OPT COMMUN, V198, P71, DOI 10.1016/S0030-4018(01)01497-3
   Tom BC, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB539
   UR H, 1992, CVGIP-GRAPH MODEL IM, V54, P181, DOI 10.1016/1049-9652(92)90065-6
NR 66
TC 21
Z9 29
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1449
EP 1473
DI 10.1016/j.imavis.2006.12.016
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000007
DA 2024-07-18
ER

PT J
AU Han, Y
   Shi, P
AF Han, Yanfang
   Shi, Pengfei
TI An adaptive level-selecting wavelet transform for texture defect
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE wavelet transform; co-occurrence matrix; defect detection; texture image
   processing
ID CLASSIFICATION
AB We present an effective approach based on wavelet transform (WT) to detect defects on images with high frequency texture background. The original image is decomposed at various levels by WT. Then, by selecting an appropriate level at which the approximation sub-image is reconstructed, textures on the background are effectively removed. Thus, the difficult texture defect detection problem can be settled by non-texture techniques. An adaptive level-selecting scheme is presented by analyzing the co-occurrence matrices (COM) of the approximation sub-images. Experiments are done to detect the stains and broken points on texture surfaces. Comparisons with frequency domain low and high pass filters show that our method is much more effective. (c) 2006 Elsevier B.V. All rights reserved.
C1 Shanghai Univ Sci & Technol, Inst Informat & Commun Engn, Shanghai 200030, Peoples R China.
   Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200030, Peoples R China.
C3 University of Shanghai for Science & Technology; Shanghai Jiao Tong
   University
RP Han, Y (corresponding author), Shanghai Univ Sci & Technol, Inst Informat & Commun Engn, Shanghai 200030, Peoples R China.
EM hyf@sjtu.edu.cn; pfshi@sjtu.edu.cn
CR Ahmadian A, 2003, P ANN INT IEEE EMBS, V25, P930, DOI 10.1109/IEMBS.2003.1279918
   Amet AL, 1998, 1998 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P205, DOI 10.1109/IAI.1998.666886
   AMON G, 2004, SIGNAL PROCESS, V84, P1225
   [Anonymous], IEEE T IMAGE PROCESS, DOI DOI 10.1109/83.753747
   [Anonymous], IMAGE MODELING
   Arivazhagan S, 2003, PATTERN RECOGN LETT, V24, P3197, DOI 10.1016/j.patrec.2003.08.005
   Bodnarova A, 1997, TENCON IEEE REGION, P307, DOI 10.1109/TENCON.1997.647318
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   FUKUNAGA K, 1975, IEEE T INFORM THEORY, V21, P32, DOI 10.1109/TIT.1975.1055330
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HISANAGA F, 2001, INT C ROB AUT SEOUL, P3529
   Huang Y, 2003, PATTERN RECOGN LETT, V24, P393, DOI 10.1016/S0167-8655(02)00263-5
   KARKANIS SA, 2000, P 26 EUR C MAASTR NE, V2, P423
   KUMAR A, 2001, P 36 IEEE IAS ANN M, P247
   Latif-Amet A, 2000, IMAGE VISION COMPUT, V18, P543, DOI 10.1016/S0262-8856(99)00062-1
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MEYLANI R, 1999, INT C IM PROC, V16, P165
   SOO BP, 2004, PATTERN RECOGN, V25, P287
   Stan S, 2002, PATTERN RECOGN LETT, V23, P1229, DOI 10.1016/S0167-8655(02)00070-3
NR 22
TC 77
Z9 85
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1239
EP 1248
DI 10.1016/j.imavis.2006.07.028
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000004
DA 2024-07-18
ER

PT J
AU Sang, N
   Li, H
   Peng, WX
   Zhang, TX
AF Sang, Nong
   Li, Heng
   Peng, Weixue
   Zhang, Tianxu
TI Knowledge-based adaptive thresholding segmentation of digital
   subtraction angiography images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE digital subtraction angiography; adaptive threshold; the busyness
ID PERFORMANCE
AB Vessel segmentation is the base of three dimensional reconstruction on digital subtraction angiography (DSA) images. In this paper we propose two simple but efficient methods of vessel segmentation for DSA images. The original DSA image is divided into several appropriate subimages according to a prior knowledge of the diameter of vessels. We introduce the vessels existence measure to determine whether each subimage contains vessels and then choose an optimal threshold, respectively, for every subimage previously determined to contain vessels. Finally, an overall binarization of the original image is achieved by combining the thresholded subimages. Experiments are implemented on cerebral and hepatic DSA images. The results demonstrate that our proposed methods yield better binary results than global thresholding methods and some other local thresholding methods do. (c) 2006 Elsevier B.V. All rights reserved.
C1 Huazhong Univ Sci & Technol, Inst Pattern Recognit & Artificial Intelligence, Wuhan 430074, Peoples R China.
   Huazhong Univ Sci & Technol, Minist Educ, Key Lab Image Proc & Intelligent Control, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Sang, N (corresponding author), Huazhong Univ Sci & Technol, Inst Pattern Recognit & Artificial Intelligence, Wuhan 430074, Peoples R China.
EM nsang@hust.edu.cn; joelhqlj@hotmail.com; weixuep@hotmail.com;
   txzhang@hust.edu.cn
CR [Anonymous], IEEE T SYST MAN CYBE
   Bernsen J, 1986, ICPR 86 P INT C PATT, P1251
   BRODY WR, 1982, IEEE T NUCL SCI, V29, P1176, DOI 10.1109/TNS.1982.4336336
   Chan FHY, 1998, IEEE T IMAGE PROCESS, V7, P468, DOI 10.1109/83.661196
   CHOW CK, 1972, COMPUT BIOMED RES, V5, P388, DOI 10.1016/0010-4809(72)90070-5
   Fernando SMX, 1982, P 6 INT C PATT REC
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   LEE SU, 1990, COMPUT VISION GRAPH, V52, P171, DOI 10.1016/0734-189X(90)90053-X
   Niblack W., 1986, INTRO DIGITAL IMAGE, P115
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   SANG N, 2005, P SPIE MIPPR 2005 IM, P9
   SANG N, 2005, P SPIE MIPPR 2005 GE, P8
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   WESZKA JS, 1978, IEEE T SYST MAN CYB, V8, P622, DOI 10.1109/TSMC.1978.4310038
   YANOWITZ SD, 1989, COMPUT VISION GRAPH, V46, P82, DOI 10.1016/S0734-189X(89)80017-9
NR 16
TC 32
Z9 42
U1 0
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1263
EP 1270
DI 10.1016/j.imavis.2006.07.026
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000007
DA 2024-07-18
ER

PT J
AU Muñoz-Salinas, R
   Aguirre, E
   García-Silvente, M
AF Munoz-Salinas, Rafael
   Aguirre, Eugenio
   Garcia-Silvente, Miguel
TI People detection and tracking using stereo vision and color
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE people detection; people tracking; stereo vision; human-machine
   interaction; color processing
ID MOBILE ROBOT NAVIGATION; FUZZY
AB People detection and tracking are important capabilities for applications that desire to achieve a natural human-machine interaction. Although the topic has been extensively explored using a single camera, the availability and low price of new commercial stereo cameras makes them an attractive sensor to develop more sophisticated applications that take advantage of depth information. This work presents a system able to visually detect and track multiple people using a stereo camera placed at an under-head position. This camera position is especially appropriated for human-machine applications that require interacting with people or to analyze human facial gestures. The system models the background as height map that is employed to easily extract foreground objects among which people are found using a face detector. Once a person has been spotted, the system is capable of tracking him while is still looking for more people. Our system tracks people combining color and position information (using the Kalman filter). Tracking based exclusively on position information is unreliable when people establish close interactions. Thus, we also include color information about the people clothes in order to increase the tracking robustness. The system has been extensively tested and the results show that the use of color greatly reduces the errors of the tracking system. Besides, the people detection technique employed, based on combining plan-view map information and a face detector, has proved in our experimentation to avoid false detections in the tests performed. Finally, the low computing time required for the detection and tracking process makes it suitable to be employed in real time applications. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
   Univ Granada, Dept Comp Sci & Artificial Intelligence, E-18071 Granada, Spain.
C3 Universidad de Cordoba; University of Granada
RP Muñoz-Salinas, R (corresponding author), Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
EM salinas@decsai.ugr.es; eaguirre@decsai.ugr.es;
   M.Garcia-Silvente@dec-sai.ugr.es
RI Muñoz-Salinas, Rafael/K-5999-2014; Garcia-Silvente, Miguel/C-2409-2012;
   Aguirre, Eugenio/C-6860-2012
OI Muñoz-Salinas, Rafael/0000-0002-8773-8571; Garcia-Silvente,
   Miguel/0000-0002-5467-6159; Aguirre, Eugenio/0000-0002-6706-8232
CR Aguirre E, 2000, INT J APPROX REASON, V25, P255, DOI 10.1016/S0888-613X(00)00056-6
   Aherne F., 1997, KYBERNETIKA, V32, P1
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], OPENCV OP SOURC COMP
   [Anonymous], BUMBLEBEE
   [Anonymous], IEEE 6 WORKSH MULT S
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C SYST MAN
   [Anonymous], IEEE INT C ROB AUT I
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 8 IEEE INT C COMP VI
   [Anonymous], THEORY PRACTICE
   [Anonymous], IEEE INT C ROB AUT I
   [Anonymous], GITGVU9919 GEORG TEC
   [Anonymous], WORKSH MOT VID COMP
   Argyros AA, 2004, APPL OPTICS, V43, P366, DOI 10.1364/AO.43.000366
   Burgard W, 1999, ARTIF INTELL-AMST, V114, P3, DOI 10.1016/S0004-3702(99)00070-3
   Darrell T, 2000, INT J COMPUT VISION, V37, P175, DOI 10.1023/A:1008103604354
   Foley J.D., 1982, Fundamentals of interactive computer graphics
   Foley J.D., 1990, Computer graphics: Principles and practice
   Fong T, 2003, ROBOT AUTON SYST, V42, P143, DOI 10.1016/S0921-8890(02)00372-X
   GarciaSilvente M, 1997, PATTERN RECOGN, V30, P367, DOI 10.1016/S0031-3203(96)00087-8
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Harville M, 2004, IMAGE VISION COMPUT, V22, P127, DOI 10.1016/j.imavis.2003.07.009
   Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3, DOI 10.1109/EVENT.2001.938860
   Hayashi K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P681, DOI 10.1109/AFGR.2004.1301613
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kruppa Hannes., 2003, JOINT IEEE INT WORKS
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Martinkauppi B, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P652, DOI 10.1109/ICIAP.2003.1234124
   MOHAN R, 1989, IEEE T PATTERN ANAL, V11, P113, DOI 10.1109/34.16708
   Muñoz-Salinas R, 2005, ROBOTICA, V23, P689, DOI 10.1017/S0263574704001390
   Nickel K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P565
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   RODRIGUEZ JJ, 1990, IEEE T PATTERN ANAL, V12, P467, DOI 10.1109/34.55106
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Snidaro L, 2005, IEEE T SYST MAN CY A, V35, P133, DOI 10.1109/TSMCA.2004.838478
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
NR 41
TC 91
Z9 127
U1 0
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 995
EP 1007
DI 10.1016/j.imavis.2006.07.012
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600020
DA 2024-07-18
ER

PT J
AU Nandi, AV
   Patnaik, LM
   Banakar, RM
AF Nandi, Anil V.
   Patnaik, L. M.
   Banakar, R. M.
TI Memory-efficient spatial prediction image compression scheme
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE spatial prediction; hierarchical tree; memory-efficient compression
AB In prediction phase, the hierarchical tree structure obtained from the test image is used to predict every central pixel of an image by its four neighboring pixels. The prediction scheme generates the predicted error image, to which the wavelet/sub-band coding algorithm can be applied to obtain efficient compression. In quantization phase, we used a modified SPIHT algorithm to achieve efficiency in memory requirements. The memory constraint plays a vital role in wireless and bandwidth-limited applications. A single reusable list is used instead of three continuously growing linked lists as in case of SPIHT. This method is error resilient. The performance is measured in terms of PSNR and memory requirements. The algorithm shows good compression performance and significant savings in memory. (C) 2006 Elsevier B.V. All rights reserved.
C1 Indian Inst Sci, Computat Neurobiol Grp, Supercomp Educ & Res Ctr, Microproc Applicat Lab, Bangalore 560012, Karnataka, India.
   BV Bhoomaraddi Coll Engn & Technol, Dept Elect & Commun Engn, Hubli 580031, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore; KLE Technological
   University
RP Patnaik, LM (corresponding author), Indian Inst Sci, Computat Neurobiol Grp, Supercomp Educ & Res Ctr, Microproc Applicat Lab, Bangalore 560012, Karnataka, India.
EM anilnandy@bvb.edu; lalit@micro.iisc.ernet.in; banakar@bvb.edu
RI Banakar, Rajeshwari/AAC-4764-2019; Banakar, Rajeshwari/AAU-1393-2020;
   UNIVERSITY, KLE TECHNOLOGICAL UNIVERSITY KLE TECHNOLOGICAL/AAM-4008-2021
OI Banakar, Rajeshwari/0000-0002-2423-6646; 
CR GANI F, 2005, IEEE INT C AC SPEECH, V2, P385
   GONZALEZ RC, 1993, DIGITAL IMAGE PROCES, P358
   Huang WC, 1998, SIGNAL PROCESS-IMAGE, V13, P171, DOI 10.1016/S0923-5965(97)00053-2
   KUO CH, 2002, IEEE T CIRCUITS SYST, V12
   Pennebaker W. B., 1992, JPEG STILL IMAGE DAT
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Wheeler FW, 2000, INT CONF ACOUST SPEE, P2047, DOI 10.1109/ICASSP.2000.859236
   WHEELER FW, 1999, 33 AS C SIGN SYST CO, V2, P1193
NR 10
TC 2
Z9 2
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 899
EP 906
DI 10.1016/j.imavis.2006.07.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600012
DA 2024-07-18
ER

PT J
AU Arce, E
   Marroquin, JL
AF Arce, Edgar
   Marroquin, J. L.
TI High-precision stereo disparity estimation using HMMF models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereo correspondence; disparity map; image segmentation; Markov random
   fields; Bayesian method; doubly stochastic prior model; parametric
   disparity model; subpixel disparity values; occluded regions
ID ALGORITHM
AB In this paper, stereo disparity reconstruction is formulated as a parametric segmentation problem in a Bayesian framework: the goal is to partition the reference image into a set of non-overlapping regions, inside each one of which a specific disparity model (which consists of two coupled membranes) is adjusted. The problem of simultaneously finding the regions and the parameters of the corresponding models is formulated using a novel probabilistic framework which uses a hidden Markov random measure field model, which allows one to efficiently find the optimal estimators by minimization of a differentiable cost function. This framework also allows for the explicit modeling of occlusions, consistency constraints and correspondence of disparity and intensity discontinuities. It is shown experimentally that this method produces competitive results, with respect to state-of-the-art methods, for discretized (integer) disparities and significantly better results for high-precision real-valued disparities. (c) 2006 Elsevier B.V. All rights reserved.
C1 Fac Ciencias, San Luis Potosi 78290, Mexico.
   Ctr Res Math, Guanajuato, Mexico.
RP Arce, E (corresponding author), Fac Ciencias, Av Salvador Nava Mtz SN,Zona Univ, San Luis Potosi 78290, Mexico.
EM arce@fciencias.uaslp.mx
RI Arce-Santana, Edgar/A-9740-2016
CR ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   [Anonymous], AIM351 STANF U ART I
   BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836
   Belhumeur P. N., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P506, DOI 10.1109/CVPR.1992.223143
   Bhat DN, 1996, PROC CVPR IEEE, P351, DOI 10.1109/CVPR.1996.517096
   Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296
   Birchfield S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1073, DOI 10.1109/ICCV.1998.710850
   BIRCHFIELD S, 1999, ICCV 99
   Black MJ, 1996, INT J COMPUT VISION, V19, P57, DOI 10.1007/BF00131148
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Bolles R.C., 1993, IUW, P263
   CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995
   FUAGERAS O, 1993, 3 DIMENSIONAL COMPUT
   GAMBLE E, 1987, 970 AI LAB
   GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683
   GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GRIMSON WEL, 1978, IMAGES SURFACES
   Gutiérrez S, 2004, IMAGE VISION COMPUT, V22, P183, DOI 10.1016/j.imavis.2003.08.006
   Horn B.K.P, 1986, Robot Vision
   Jahne B., 2002, DIGITAL IMAGE PROCES
   Julez B., 1971, Foundations of the Cyclopean Perception
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   LEE SH, 2002, IEEE ICIP, V2, P541
   LI SZ, 2002, MARKOV RANDOM FIELD
   LIN MH, 2003, IEEE COMP SOC C COMP, V1
   MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127
   Marroquin JL, 2003, IEEE T PATTERN ANAL, V25, P1380, DOI 10.1109/TPAMI.2003.1240112
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   OKUTOMI M, 1996, IEEE TPAMI, V16, P920
   POGGIO T, 1985, NATURE, V317, P314, DOI 10.1038/317314a0
   Scharstein D, 1998, INT J COMPUT VISION, V28, P155, DOI 10.1023/A:1008015117424
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Schoenberg IJ, 1973, Cardinal spline interpolation
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tao H, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P532, DOI 10.1109/ICCV.2001.937562
   Tardón LJ, 2004, IEEE T SYST MAN CY A, V34, P428, DOI 10.1109/TSMCA.2004.824872
   Trucco E., 1998, INTRO TECHNIQUES 3D
NR 40
TC 8
Z9 9
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 623
EP 636
DI 10.1016/j.imavis.2006.05.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200009
DA 2024-07-18
ER

PT J
AU Li, J
   Chua, CS
AF Li, Jiang
   Chua, Chin-Seng
TI Transductive local exploration particle filter for object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object tracking; particle filter; transductive learning; color model
   adaptation
AB Robust tracking of non-rigid objects in a dynamic environment is a challenging task. This paper presents a particle filter solution for non-stationary color tracking using a transductive local exploration algorithm. The target model is represented by a non-parametric density estimation and the similarity measure is based on a metric derived from mutual information. We employ a transductive inference to update the target model dynamically. Combining confidently labeled data and weighted unlabeled data, the proposed transductive inference offers an effective way to transduce object color model through the given observations in non-stationary color distributions. Better proposal distributions containing new observations are obtained through a method of local exploration. Targets can be tracked well despite severe occlusions or clutter. The way the transductive adaptable object model and local exploration particle filter are combined plays a decisive role in the robustness and efficiency of the tracker. In the presented tracking examples, the new approach successfully coped with target appearance variations, severe occlusions and clutters. (c) 2006 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chua, CS (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM ecschua@ntu.edu.sg
CR [Anonymous], 2000, CUEDFINFENGTR380
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], 1998, 4 IEEE WORKSH APPL C
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Bar-Shalom Y., 1988, TRACKING DATA ASS
   BUE A, 2002, IEEE INT C IM PROC, P429
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Gilks Walter R., 1995, Markov chain Monte Carlo in practice
   Greiffenhagen M, 2001, P IEEE, V89, P1498, DOI 10.1109/5.959343
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Hue C, 2002, IEEE T SIGNAL PROCES, V50, P309, DOI 10.1109/78.978386
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Li J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P949
   Li J., 2002, P 7 INT C CONTR AUT, P309
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Nummiaro K., 2002, Proceedings of International Workshop on Generative-Model-Based Vision, V2002/01, P53
   PEREZ, 2002, EUR C COMP VIS, P661
   Raja Y., 1998, PROC EUROPEAN C COMP, P460
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu Y, 2000, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2000.855823
NR 23
TC 8
Z9 9
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 544
EP 552
DI 10.1016/j.imavis.2006.05.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200003
DA 2024-07-18
ER

PT J
AU Chen, ZZ
   Pears, N
   Liang, BJ
AF Chen, Zezhi
   Pears, Nick
   Liang, Bojian
TI Monocular obstacle detection using reciprocal-polar rectification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE homography; fundamental matrix; obstacle avoidance; segmentation;
   reciprocal-polar rectification; image rectification
AB Our obstacle detection method is applicable to deliberative translation motion of a mobile robot and, in such motion, the epipole of each image of an image pair is coincident and termed the focus of expansion (FOE). We present an accurate method for computing the FOE and then we use this to apply a novel rectification to each image, called a reciprocal-polar (RP) rectification. When robot translation is parallel to the ground, as with a mobile robot, ground plane image motion in RP-space is a pure shift along an RP image scan line and hence can be recovered by a process of 1D correlation, even over large image displacements and without the need for corner matches. Furthermore, we show that the magnitude of these shifts follows a sinusoidal form along the second (orientation) dimension of the RP image. This gives the main result that ground plane motion over RP image space forms a 3D sinusoidal manifold. Simultaneous ground plane pixel grouping and recovery of the ground plane motion thus amounts to finding the FOE and then robustly fitting a 3D sinusoid to shifts of maximum correlation in RP space. The phase of the recovered sinusoid corresponds to the orientation of the vanishing line of the ground plane and the amplitude is related to the magnitude of the robot/camera translation. Recovered FOE, vanishing line and sinusoid amplitude fully define the ground plane motion (homography) across a pair of images and thus obstacles and ground plane can be segmented without any explicit knowledge of either camera parameters or camera motion. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
C3 University of York - UK
RP Chen, ZZ (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
EM chen@macs.hw.ac.uk; nep@cs.york.ac.uk; bojian@cs.york.ac.uk
CR [Anonymous], 2001, MULTIPLE VIEW GEOMET
   [Anonymous], 2002, P ECCV WORKSH VIS MO
   Chen ZZ, 2002, J IMAGING SCI TECHN, V46, P365
   CIPOLLA R, 1992, P 2 EUR C COMP VIS, P187
   CLARKE JC, 1997, THESIS U OXFORD
   COOMBS D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P276, DOI 10.1109/ICCV.1995.466774
   Criminisi A, 2000, INT J COMPUT VISION, V40, P123, DOI 10.1023/A:1026598000963
   David A. F., 2003, COMPUTER VISION MODE
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   GUERRERO JJ, 1998, P 3 IFAC S INT AUT V, P210
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164, DOI [10.1090/QAM/10666, DOI 10.1090/QAM/10666]
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810
   LIANG B, 2002, P IEEE INT C ROB AUT, V1, P205
   Liang BJ, 2002, P SOC PHOTO-OPT INS, V4875, P822, DOI 10.1117/12.477077
   LONGUETHIGGINS HC, 1996, P ROYAL SOC LOND B, V227, P399
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Nakai H, 2004, INT C PATT RECOG, P346, DOI 10.1109/ICPR.2004.1334538
   Pollefeys M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P496, DOI 10.1109/ICCV.1999.791262
   SANTOSVICTOR J, 1995, INT J COMPUT VISION, V14, P159, DOI 10.1007/BF01418981
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Sinclair D, 1996, INT J COMPUT VISION, V18, P77, DOI 10.1007/BF00126141
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Tang L, 2002, PATTERN RECOGN LETT, V23, P1169, DOI 10.1016/S0167-8655(02)00063-6
   TSAI RY, 1981, IEEE T ACOUST SPEECH, V29, P1147, DOI 10.1109/TASSP.1981.1163710
   Wilczkowiak M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P142, DOI 10.1109/ICCV.2001.937510
   Wolberg G, 2000, IEEE IMAGE PROC, P493, DOI 10.1109/ICIP.2000.901003
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   2002, J IMAGING SCI TECHNO, V46, P365
NR 32
TC 5
Z9 5
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2006
VL 24
IS 12
BP 1301
EP 1312
DI 10.1016/j.imavis.2006.04.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 107AH
UT WOS:000242142600004
DA 2024-07-18
ER

PT J
AU Dornaika, F
   Ahlberg, J
AF Dornaika, Fadi
   Ahlberg, Jorgen
TI Fitting 3D face models for tracking and active appearance model training
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D deformable models; active appearance models; model fitting; face
   tracking; analysis-by-synthesis approaches; training; directed search;
   heuristic search
AB In this paper, we consider fitting a 3D deformable face model to continuous video sequences for the tasks of tracking and training. We propose two appearance-based methods that only require a simple statistical facial texture model and do not require any information about an empirical or analytical gradient matrix, since the best search directions are estimated on the fly. The first method computes the fitting using a locally exhaustive and directed search where the 3D head pose and the facial actions are simultaneously estimated. The second method decouples the estimation of these parameters. It computes the 3D head pose using a robust feature-based pose estimator incorporating a facial texture consistency measure. Then, it estimates the facial actions with an exhaustive and directed search. Fitting and tracking experiments demonstrate the feasibility and usefulness of the developed methods. A performance evaluation also shows that the proposed methods can outperform the fitting based on an active appearance model search adopting a pre-computed gradient matrix. Although the proposed schemes are not as fast as the schemes adopting a directed continuous search, they can tackle many disadvantages associated with such approaches. (c) 2006 Elsevier B.V. All rights reserved.
C1 Autonomous Univ Barcelona, Comp Vis Ctr, E-08193 Barcelona, Spain.
   Swedish Def Res Agcy FOI, SE-58111 Linkoping, Sweden.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); FOI - Swedish Defence Research Agency
RP Dornaika, F (corresponding author), Autonomous Univ Barcelona, Comp Vis Ctr, Edifici O,Campus UAB, E-08193 Barcelona, Spain.
EM dornaika@cvc.uab.es; jorah1@foi.se
OI Ahlberg, Jorgen/0000-0002-6763-5487
CR Ahlberg J, 2002, EURASIP J APPL SIG P, V2002, P566, DOI 10.1155/S1110865702203078
   AHLBERG J, 2002, THESIS LINKOPING U S
   [Anonymous], 2001, LITHISYR2326 LINK U
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   Birchfield S., 1998, P IEEE C COMP VIS PA
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Cootes T., 1998, Proc. ECCV, V2, P484
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dornaika F, 2004, IEEE T SYST MAN CY B, V34, P1838, DOI 10.1109/TSMCB.2004.829135
   Dornaika F, 2004, INT J IMAGE GRAPHICS, V4, P499
   EDWARDS G, 1998, P IEEE INT C AUT FAC
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   GOKTURK S, 2001, P IEEE INT C COMP VI
   Jebara T., 1997, P IEEE C COMP VIS PA
   KAMPMANN M, 1997, P PICT COD S BERL GE
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   LU L, 2001, P IEEE WORKSH MOD VE
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   MCKENNA SJ, 1997, P INT C AUD VID BAS
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   OLIVIER N, 1997, P IEEE C COMP VIS PA
   PIGHIN F, 1999, P IEEE INT C COMP VI
   Ström J, 2002, EURASIP J APPL SIG P, V2002, P1039, DOI 10.1155/S1110865702206034
   STROM J, 2002, THESIS LINKOPING U S
   TAO H, 1998, P IEEE INT C AUT FAC
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
NR 29
TC 27
Z9 32
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 1010
EP 1024
DI 10.1016/j.imavis.2006.02.025
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200010
DA 2024-07-18
ER

PT J
AU Schrameck, M
   Voyles, R
   Myers, T
   Bodor, R
   Masoud, O
AF Schrameck, Michel
   Voyles, Richard
   Myers, Tom
   Bodor, Robert
   Masoud, Osama
TI Automatic Euclidean reconstruction for turn-table sequences by indirect
   epipolar search between pairs of views
SO IMAGE AND VISION COMPUTING
LA English
DT Article
ID RELATIVE ORIENTATION; FACTORIZATION METHOD; MOTION; SHAPE
AB A new method is described to solve the structure from motion problem when the camera is only subject to a negligible rotation around its optical axis (the 'roll' rotation). The indirect epipolar search is a four-dimensional search, where the parameters are the two angles corresponding to the two remaining rotation axes of each camera. By 'indirect', we mean that there is no explicit computation of fundamental matrices or epipole locations. The approach is interesting in the fact that the epipolar space scrutinized is much less sensitive to noise than the fundamental matrix space (which we call the 'direct' epipolar space). The method is particularly adapted to turn-table video-sequences, where the roll-rotation is nonexistent, but we will show that it could also be used with no a-priori knowledge of the camera motion. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.
   Point Cloud Inc, Plymouth, MN 55441 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Voyles, R (corresponding author), Univ Minnesota, Dept Comp Sci, Minneapolis, MN 55455 USA.
EM schramec@cs.umn.edu; voyles@cs.umn.edu
RI Voyles, Richard/I-4258-2016
OI Voyles, Richard/0000-0002-1871-9887
CR [Anonymous], CMURITR9922
   [Anonymous], 1988, ALVEY VIS C
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P IEEE CVF INT C COM
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   COSTEIRA J, 1994, CMUCS94220
   Dhond U. R., 1990, Proceedings 1990 IEEE International Conference on Robotics and Automation (Cat. No.90CH2876-1), P2045, DOI 10.1109/ROBOT.1990.126306
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   FAUGERAS OD, 1992, ECCV92
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FITZGIBBON A, 1999, AUTOMATIC 3 DIMENSIO
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   HORN BKP, 1991, J OPT SOC AM A, V8, P1630, DOI 10.1364/JOSAA.8.001630
   HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443
   JENNINGS C, 1996, STRUCTURE MOTION STE
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055
   MARYBANK SJ, 1992, INT J COMPUT VISION, V8, P123
   Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098
   ROBERT L, 1995, RR2584 I NAT RECH IN
   SCHMID C, 1998, GEOMETRY MATCHING CU
   SHUM HY, 1996, THESIS CMU
   SMITH P, EFFECTIVE CORNER MAT
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3
   TRIGGS B, FACTORIZATION METHOD
   URBAN M, CTUCMP19995 CZECH RE
   WENG J, 1989, IEEE TPAMI, V11
   WILLSON RG, 1993, CMUCS96122
   ZHANG Z, VIDERE ARTICLE
   ZHANG Z, 1994, 2273 INRIA
   ZHANG ZY, 1992, INT J ROBOT RES, V11, P269, DOI 10.1177/027836499201100401
   ZISSERMAN A, 1994, CASE AGAINST EPIPOLA
   ZISSERMAN A, 1999, VHS VRML 3 DIMENSION
NR 34
TC 0
Z9 0
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 693
EP 708
DI 10.1016/j.imavis.2005.12.011
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400005
DA 2024-07-18
ER

PT J
AU Chang, Y
   Hu, CB
   Feris, R
   Turk, M
AF Chang, Ya
   Hu, Changbo
   Feris, Rogerio
   Turk, Matthew
TI Manifold based analysis of facial expression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
ID RECOGNITION; SEQUENCES
AB We propose a novel approach for modeling, tracking, and recognizing facial expressions oil a low-dimensional expression manifold. A modified Lipschitz embedding is developed to embed aligned facial features in a low-dimensional space, while keeping the main structure of the manifold. In the embedded space, a complete expression sequence becomes a path on the expression manifold, emanating from a center that corresponds to the neutral expression. As an offline training stage. facial contour features are first clustered in this space. using a mixture model. For each cluster in the low-dimensional space, a specific ASM model is learned, in order to avoid incorrect matching due to non-linear image variations. A probabilistic model of transitions between the clusters and paths in the embedded space is then learned. Given a new expression sequence. we use ICondensation to track facial features, while recognizing facial expressions Simultaneously, within the common probabilistic framework. Experimental results demonstrate that our probabilistic facial expression model on the manifold significantly improves facial deformation tracking and expression recognition. We also synthesize image sequences of changing expressions through the manifold model. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
   Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
C3 University of California System; University of California Santa Barbara;
   Carnegie Mellon University
RP Chang, Y (corresponding author), Univ Calif Santa Barbara, Dept Comp Sci, Santa Barbara, CA 93106 USA.
EM yachang@cs.ucsb.edu
RI cai, chao/C-4840-2009
OI Turk, Matthew/0000-0002-4198-8401
CR [Anonymous], 1998, ECCV
   [Anonymous], P C ADV NEUR INF PRO
   BARTLETT MS, 2003, ADV NEURAL INFORMATI
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   Bertsekas D. P., 2000, Dynamic programming and optimal control, V1
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Blake A., 1998, ACTIVE CONTOURS
   BOURGAIN J, 1985, ISRAEL J MATH, V52, P46, DOI 10.1007/BF02776078
   BRAND M, 2002, CHARTING MANIFOLD NE, P15
   Chang Y., 2003, P IEEE INT WORKSH AN
   CHANG Y, 2004, P ITN C COMP VIS PAT
   CHUANG E, 2002, FACIAL EXPRESSION SP
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Cootes T., 1995, COMPUTER VISION IMAG, V61
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Ekman P, 1978, FACIAL ACTION CODING
   Ekman P., 1982, EMOTION HUMAN FACE
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232
   FASEL B, 2003, PATTERN RECOGN, P36
   FIDALEO D, 2003, ACM SIGMM MULTIMEDIA
   Hristescu G., 1999, CLUSTER PRESERVING E
   HU C, 2004, P IEEE WORKSH FAC PR
   Johnson W.B., 1984, CONTEMP MATH-SINGAP, V26, P189, DOI DOI 10.1090/CONM/026/737400
   LEE KC, 2003, P INT C COMP VIS PAT
   Li S.Z., 2001, P IEEE ICCV WORKSH R
   Li Y, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.35
   Li YM, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P40, DOI 10.1109/RATFG.2001.938908
   Linial M, 1997, J MOL BIOL, V268, P539, DOI 10.1006/jmbi.1997.0948
   LINIAL N, 1995, COMBINATORICA, V15, P215, DOI 10.1007/BF01200757
   LYONS MJ, 1998, P INT C AUT FAC GEST
   MYERS CS, 1981, AT&T TECH J, V60, P1389, DOI 10.1002/j.1538-7305.1981.tb00272.x
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Roweis S, 2002, ADV NEUR IN, V14, P889
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Russell JA, 2003, PSYCHOL REV, V110, P145, DOI 10.1037/0033-295X.110.1.145
   SCHMIDT K, 2001, INT C MULT EXP
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   WANG Q, 2003, P INT C COMP VIS PAT
   Yang M.H, 2002, INT C IM PROC
   Young F. W., 1987, Multidimensional scaling: History, theory, and applications, DOI 10.2307/2348396
   ZHANG Y, 2003, P INT C COMP VIS NIC
   ZHANG Z, 1998, P INT C AUT FAC GEST
   ZHOU S, 2003, COMPUTER VISION COMP, V91
NR 48
TC 103
Z9 127
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2006
VL 24
IS 6
BP 605
EP 614
DI 10.1016/j.imavis.2005.08.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 061NB
UT WOS:000238878200007
DA 2024-07-18
ER

PT J
AU Gross, R
   Matthews, I
   Baker, S
AF Gross, Ralph
   Matthews, Iain
   Baker, Simon
TI Active appearance models with occlusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE model-based face analysis; robust model fitting; fitting with occlusion
AB Active Appearance Models (AAMs) are generative parametric models that have been successfully used in the past to track faces in video. A variety of video applications are possible, including dynamic head pose and gaze estimation for real-time user interfaces. lip-reading, and expression recognition. To construct an AAM, a number of training images of faces with a mesh of canonical feature points (usually hand-marked) are needed. All feature points have to be visible in all training images. However, in many scenarios parts of the face may be occluded. Perhaps the most common cause of occlusion is 3D pose variation, which can cause self-occlusion of the face. Furthermore. tracking using standard AAM fitting algorithms often fails in the presence of even small occlusions. In this paper we propose algorithms to construct AAMs form occluded training images and to track faces efficiently in videos containing occlusion. We evaluate our algorithms both quantitatively and qualitatively and show successful real-time face tracking on a number of image sequences containing varying degrees and types of occlusions. (c) 2005 Elsevier B.V. All rights reserved.
C1 Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Gross, R (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM rgross@cs.cmu.edu; iainm@cs.cmu.edu; simonb@cs.cmu.edu
CR [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   BAKER S, 2003, CMURITR0301 CARN U R
   BAKER S, 2003, CMURITR0335 CARN U R
   Blackwood E, 1998, J HOMOSEXUAL, V36, P101, DOI 10.1300/J082v36n01_07
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   DUTTER R, 1981, J STAT COMPUT SIM, V13, P79, DOI 10.1080/00949658108810482
   EDWARDS GJ, 1999, ADV ACTIVE APPEARANC, P137
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   GROSS R, 2004, 1 IEEE WORKSH FAC PR
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Huber P., 1981, Robust Statistics
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Sclaroff S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1146, DOI 10.1109/ICCV.1998.710860
   SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651
NR 18
TC 74
Z9 90
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2006
VL 24
IS 6
BP 593
EP 604
DI 10.1016/j.imavis.2005.08.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 061NB
UT WOS:000238878200006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Iyer, S
   Sinha, SK
AF Iyer, S
   Sinha, SK
TI A robust approach for automatic detection and segmentation of cracks in
   underground pipeline images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE pipe crack detection; geometric modeling; mathematical morphology;
   curvature evaluation
ID AUGMENTED REALITY; STEREO; SYSTEM
AB Cracks in underground pipeline images are indicative of the condition of buried infrastructures like sewers and water mains. This paper presents a three step method to identify and extract crack-like structures from pipe images whose contrast have been enhanced. The proposed method is based on mathematical morphology and curvature evaluation that detects crack-like patterns in a noisy environment. Careful observation reveals that the cracks resemble a tree-like geometry in most cases which can be a usable feature for registration between successive images of the same region taken from various depths in the thickness of the buried pipe (313 visualization). In this study, segmentation is performed with respect to a precise geometric model to define crack-like patterns. Cracks in pipe images can be defined as clearly visible patterns (darkest in the image), locally linear and branching in a piece-wise fashion. First, the cracks are enhanced by mathematical morphology with respect to their spatial properties. In order to differentiate cracks from analogous background patterns, cross-curvature evaluation followed by linear filtering is performed. We discuss its implementation on 225 pipe images taken from various cities in North America and statistically evaluate its accuracy and robustness with respect to varying pipe background color, crack geometries and background noise. (c) 2005 Elsevier B.V. All rights reserved.
C1 Penn State Univ, Dept Civil & Environm Engn, PIRC, University Pk, PA 16802 USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE);
   Pennsylvania State University; Pennsylvania State University -
   University Park
RP Penn State Univ, Dept Civil & Environm Engn, PIRC, University Pk, PA 16802 USA.
EM shiv@psu.edu; sks15@psu.edu
CR ABAS FS, 2002, 14 INT C DIG SIGN PR, V1, P111
   [Anonymous], P INT ARCH PHOTOGRAM
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   *CERF, EV REP ONL
   Chae MJ, 2001, J COMPUT CIVIL ENG, V15, P4, DOI 10.1061/(ASCE)0887-3801(2001)15:1(4)
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Cheng HD, 1998, J COMPUT CIVIL ENG, V12, P145, DOI 10.1061/(ASCE)0887-3801(1998)12:3(145)
   Cooper D, 1998, MACH VISION APPL, V11, P53, DOI 10.1007/s001380050090
   Duran O, 2002, IEEE SENS J, V2, P73, DOI 10.1109/JSEN.2002.1000245
   ELBERLY D, 1994, J MATH IMAGING VIS, V4, P353
   FANG B, 2003, P INT C IM PROC ICIP
   FIEGUTH PW, 1999, P INT C IM PROC ICIP
   Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006
   Giakoumis I, 1998, ISCAS '98 - PROCEEDINGS OF THE 1998 INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-6, pC269
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   Heath MD, 1997, IEEE T PATTERN ANAL, V19, P1338, DOI 10.1109/34.643893
   HOFF W, 1989, IEEE T PATTERN ANAL, V11, P121, DOI 10.1109/34.16709
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kolesnik M., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1453, DOI 10.1109/ROBOT.2000.844802
   KOUTSOPOULOS HN, 1993, J TRANSP ENG-ASCE, V119, P868, DOI 10.1061/(ASCE)0733-947X(1993)119:6(868)
   Lawson SW, 1999, PROC SPIE, V3840, P133, DOI 10.1117/12.369273
   Lawson SW, 2002, PRESENCE-TELEOP VIRT, V11, P352, DOI 10.1162/105474602760204273
   Lengagne R., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P9, DOI 10.1109/ICPR.1996.545982
   LIU HC, 1990, IEEE T PATTERN ANAL, V12, P1072, DOI 10.1109/34.61706
   LOHMANN L, 1999, P 3 INT ICSC S SOFT
   López AM, 1999, IEEE T PATTERN ANAL, V21, P327, DOI 10.1109/34.761263
   MARAGOS P, 1990, P IEEE
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Matheron G., 1975, Random sets and integral geometry
   McKim R.A., 1997, J INFRASTRUCT SYST, V3, P119, DOI DOI 10.1061/(ASCE)1076-0342(1997)3:3(119)
   Merlet N, 1996, IEEE T PATTERN ANAL, V18, P426, DOI 10.1109/34.491623
   MOHAJERI MH, 1991, TRANSPORT RES REC, V1311, P120
   MONGA O, 1995, THIN NETS CREST LINE
   Moselhi O., 1999, Automation in Construction, V8, P581, DOI 10.1016/S0926-5805(99)00007-2
   NICKOLAY B, 1997, AUTOMATISIERUNGSTECH, V10, P490
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Paletta L., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P1087, DOI 10.1109/IROS.1999.812825
   RADU S, 2000, MARKOV POINT PROCESS
   Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800
   RuizdelSolar J, 1996, PATTERN RECOGN LETT, V17, P363, DOI 10.1016/0167-8655(95)00132-8
   Serra J., 1988, IMAGE ANAL MATH MORP
   SINHA SK, 2000, THESIS U WATERLOO CA
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   WALKER RS, 1991, TRANSPORT RES REC, V1311, P149
   Wiedemann C., 2003, International Archives of Photogrammetry Remote Sensing and Spatial Information Sciences, V34, P93
   WIRAHADIKUSUMAH R, 1996, J AUTOMAT CONSTR, V7, P259
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
NR 50
TC 113
Z9 131
U1 3
U2 43
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2005
VL 23
IS 10
BP 921
EP 933
DI 10.1016/j.imavis.2005.05.017
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 962PQ
UT WOS:000231745100006
DA 2024-07-18
ER

PT J
AU Yu, YH
   Chang, CC
   Hu, YC
AF Yu, YH
   Chang, CC
   Hu, YC
TI A genetic-based adaptive threshold selection method for dynamic path
   tree structured vector quantization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image compression; VQ; TSVQ; multi-path TSVQ
ID ENCODING ALGORITHMS; SPEECH
AB This paper presents an improvement method for enhancing the encoding time complexity of the dynamic path tree structured vector quantization (DPTSVQ) based on the same image quality. We call it the genetic-based adaptive threshold selection method (GATSM). DPTSVQ has successfully solved the disadvantage of the multi-path TSVQ. DPTSVQ uses a critical function and a fixed threshold to judge whether the number of search paths can be increased. However, in some cases, the fixed threshold scheme also brings the problem of increasing the encoding time.
   We thus propose GATSM to solve this problem by using a set of images to train the thresholds for adapting their real practical need. Our experimental results show that the encoding time complexity of GATSM is superior to DPTSVQ based on the same image quality. In addition. we compare the image quality of GATSM with the encoding algorithm with fast comparison (EAWFC) based on the same encoding time. Comparison results show that GATSM provides better image quality than that of EAWFC. (c) 2005 Elsevier B.V. All rights reserved.
C1 Providence Univ, Dept Comp Sci & Informat Engn, Taichung 433, Taiwan.
   Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 Providence University - Taiwan; National Chung Cheng University
RP Providence Univ, Dept Comp Sci & Informat Engn, Taichung 433, Taiwan.
EM yhyu@cs.ccu.edu.tw; ccc@cs.ccu.edu.tw; ychu@pu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023; Hu, Yu-Chen/AAT-5264-2020; Hui,
   Yu/JOZ-3598-2023
OI Hu, Yu-Chen/0000-0002-5055-3645; 
CR BEI CD, 1985, IEEE T COMMUN, V33, P1132, DOI 10.1109/TCOM.1985.1096214
   BUZO A, 1980, IEEE T ACOUST SPEECH, V28, P562, DOI 10.1109/TASSP.1980.1163445
   Chang CC, 1998, IEEE T CONSUM ELECTR, V44, P1201
   CHANG RF, 1992, IEE PROC-I, V139, P9, DOI 10.1049/ip-i-2.1992.0002
   Chin-Chen Chang, 1999, Proceedings of the 1999 ICPP Workshops on Collaboration and Mobile Computing (CMC'99). Group Communications (IWGC). Internet '99 (IWI'99). Industrial Applications on Network Computing (INDAP). Multimedia Network Systems (MMNS). Security (IWSEC). Parallel Computing '99 (IWPC'99). Parallel Execution on Reconfigurable Hardware (PERH), P536, DOI 10.1109/ICPPW.1999.800112
   Chon PA, 1996, IEEE T INFORM THEORY, V42, P1109, DOI 10.1109/18.508836
   CHOU PA, 1989, IEEE T ACOUST SPEECH, V37, P31, DOI 10.1109/29.17498
   CHOU PA, 1989, IEEE T INFORM THEORY, V35, P299, DOI 10.1109/18.32124
   CHOU PA, 1990, P INT C AC SPEECH SI, P197
   COSMAN PC, 1995, DATA COMPR C SNOWB U
   ELGAMAL AA, 1987, IEEE T INFORM THEORY, V33, P116, DOI 10.1109/TIT.1987.1057277
   EQUITZ WH, 1989, IEEE T ACOUST SPEECH, V37, P1568, DOI 10.1109/29.35395
   Garai G, 2002, IMAGE VISION COMPUT, V20, P265, DOI 10.1016/S0262-8856(02)00019-7
   Gray RM, 1998, IEEE T INFORM THEORY, V44, P2325, DOI 10.1109/18.720541
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Hu YC, 1999, IEEE T CONSUM ELECTR, V45, P219, DOI 10.1109/30.754439
   Huang CM, 1992, IEEE T IMAGE PROCESS, V1, P413, DOI 10.1109/83.148613
   KRISHNAMURTHY AK, 1990, IEEE J SEL AREA COMM, V8, P1449, DOI 10.1109/49.62823
   Lai JZC, 1997, IMAGE VISION COMPUT, V15, P867, DOI 10.1016/S0262-8856(97)00032-2
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Michalewicz Z., 1996, GENETIC ALGORITHMS D, DOI [DOI 10.1007/978-3-662-03315-9, 10.1007/978-3-662-03315-9]
   ORCHARD MT, 1991, INT CONF ACOUST SPEE, P2297, DOI 10.1109/ICASSP.1991.150755
   POGGI G, 1995, IEEE T IMAGE PROCESS, V4, P734, DOI 10.1109/83.388076
   RA SW, 1993, IEEE T CIRCUITS-II, V40, P576, DOI 10.1109/82.257335
   RISKIN EA, 1991, IEEE T SIGNAL PROCES, V39, P2500, DOI 10.1109/78.98004
   Shannon C. E., 1948, BELL SYST TECH J, V27, P379, DOI DOI 10.1002/J.1538-7305.1948.TB01338.X
   Vasconcelos JA, 2001, IEEE T MAGN, V37, P3414, DOI 10.1109/20.952626
   WU Y, 1996, IEEE INT C SYST MAN, V2, P1441
NR 28
TC 3
Z9 5
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2005
VL 23
IS 6
BP 597
EP 609
DI 10.1016/j.imavis.2005.02.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 924CA
UT WOS:000228955100005
DA 2024-07-18
ER

PT J
AU Sluzek, A
AF Sluzek, A
TI On moment-based local operators for detecting image patterns
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE moments; local operator; template matching; contour detection; object
   detection
ID HOUGH TRANSFORM; CORNER; IDENTIFICATION; RECOGNITION; EDGES
AB Local operators, template matching and moments are widely used in image processing. In this paper, they are combined into an efficient method of designing detectors for various image patterns. The method is using a circular window of the size corresponding to the problem requirements. For each location of the window, moment features are used to determine the optimum template that is subsequently matched to the actual content of the window to produce a 'pattern intensity' map. Theory and general recommendations are illustrated by results obtained for exemplary patterns. The method is also briefly compared to other techniques. (C) 2004 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Comp Engn, Blk N4,Nanyang Ave, Singapore 639798, Singapore.
EM assluzek@ntu.edu.sg
RI Sluzek, Andrzej S/A-3672-2011; SLUZEK, ANDRZEJ/Q-5398-2019
OI Sluzek, Andrzej S/0000-0003-4148-2600; SLUZEK,
   ANDRZEJ/0000-0003-4148-2600
CR [Anonymous], 2001, Probability, Random Variables, and Stochas- tic Processes
   Baker S, 1998, INT J COMPUT VISION, V27, P27, DOI 10.1023/A:1007901712605
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   CASH GL, 1987, COMPUT VISION GRAPH, V39, P291, DOI 10.1016/S0734-189X(87)80183-4
   CHEN WT, 1997, P DEP DEF BREAST CAN, P687
   DAVIES ER, 1988, IEE PROC-E, V135, P49, DOI 10.1049/ip-e.1988.0006
   DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733
   DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272
   Ghosal S, 1997, IEEE T IMAGE PROCESS, V6, P781, DOI 10.1109/83.585230
   HARALICK RM, 1984, IEEE T PATTERN ANAL, V6, P58, DOI 10.1109/TPAMI.1984.4767475
   Heyden A., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P895, DOI 10.1109/ICPR.1996.546153
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   HUECKEL MH, 1973, J ACM, V20, P634, DOI 10.1145/321784.321791
   JAIN AK, 1989, FUNDAMENTALS DIGITAL, P347
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   LIU ST, 1990, PATTERN RECOGN, V23, P441, DOI 10.1016/0031-3203(90)90066-T
   Parida L, 1998, IEEE T PATTERN ANAL, V20, P687, DOI 10.1109/34.689300
   ROHR K, 1992, INT J COMPUT VISION, V9, P213, DOI 10.1007/BF00133702
   ROHR K, 1992, IMAGE VISION COMPUT, V10, P66, DOI 10.1016/0262-8856(92)90001-J
   Rosin PL, 1999, COMPUT VIS IMAGE UND, V73, P291, DOI 10.1006/cviu.1998.0719
   Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118
   SLUZEK A, 1988, PATTERN RECOGN LETT, V7, P253, DOI 10.1016/0167-8655(88)90110-9
   SLUZEK A, 2002, P 7 INT C CONTR AUT, P320
   SLUZEK A, 2002, P INT C COMP VIS GRA, P16
   SLUZEK A, 1990, ZASTOSOWANIE METOD M, P19
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1986, COMPUT VISION GRAPH, V33, P318, DOI 10.1016/0734-189X(86)90180-5
   Zhenjiang M., 2000, Pattern Recognition Letters, V21, P169
NR 32
TC 21
Z9 23
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2005
VL 23
IS 3
BP 287
EP 298
DI 10.1016/j.imavis.2004.03.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NO
UT WOS:000227221800002
DA 2024-07-18
ER

PT J
AU Tubic, D
   Hébert, P
   Laurendeau, D
AF Tubic, D
   Hébert, P
   Laurendeau, D
TI 3D surface modeling from curves
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D modeling; surface reconstruction; 3D curves; geometric fusion; curve
   registration; volumetric representation
ID REGISTRATION; INTEGRATION; SET
AB Traditional approaches for surface reconstruction from range data require that the input data be either range images or unorganized sets of points. With these methods, range data acquired along curvilinear patterns cannot be used for surface reconstruction unless constraints are imposed on the shape of the patterns or on sensor displacement. This paper presents a novel approach for reconstructing a surface from a set of arbitrary, unorganized and intersecting curves. A strategy for updating the reconstructed surface during data acquisition is described as well. Curves are accumulated in a volumetric structure in which a vector field is built and updated. The information that is needed for efficient curve registration is also directly available in the vector field. The proposed modeling approach combines surface reconstruction and curve registration into a unified procedure. The algorithm implementing the approach is of linear complexity with respect to the number of input curves and makes it suitable for interactive modeling. Simulated data based on a set of six curvilinear patterns as well as data acquired with a range sensor are used to illustrate the various steps of the algorithm. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Laval, Dept Genie Eelect & Geenie Informat, Lab Vis & Syst Numer, Ste Foy, PQ G1K 7P4, Canada.
C3 Laval University
RP Tubic, D (corresponding author), Univ Laval, Dept Genie Eelect & Geenie Informat, Lab Vis & Syst Numer, Pavillon Pouliot 1114-J, Ste Foy, PQ G1K 7P4, Canada.
EM tdragan@gel.ulaval.ca
CR Alexa M, 2001, IEEE VISUAL, P21, DOI 10.1109/VISUAL.2001.964489
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   CUNNINGTON SJ, 1998, BMVC 98 P, V2, P790
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Do Carmo M., 1976, Differential Geometry of Curves and Surfaces
   Hall-Holt O, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P359, DOI 10.1109/ICCV.2001.937648
   Hebert P, 1998, P SOC PHOTO-OPT INS, V3313, P2, DOI 10.1117/12.302439
   Hébert P, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P5, DOI 10.1109/IM.2001.924380
   Hilton A, 2000, MACH VISION APPL, V12, P44, DOI 10.1007/s001380050123
   HOPPE H, 1992, COMP GRAPH, V26, P71, DOI 10.1145/142920.134011
   Kofman F, 1998, P SOC PHOTO-OPT INS, V3454, P99, DOI 10.1117/12.323279
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Masuda T, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P439, DOI 10.1109/TDPVT.2002.1024099
   Proesmans M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1081, DOI 10.1109/ICCV.1998.710851
   Roth G, 1997, PROC GRAPH INTERF, P173
   SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982
   Tubic D, 2003, COMPUT VIS IMAGE UND, V92, P56, DOI 10.1016/j.cviu.2003.07.001
   TUBIC D, 2002, P 3DPVT JUN, V1, P150
   TURK G, 1994, SIGGRAPH 94 C P, V26, P311
NR 19
TC 5
Z9 8
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 20
PY 2004
VL 22
IS 9
BP 719
EP 734
DI 10.1016/j.imavis.2004.03.006
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 834WE
UT WOS:000222440800004
DA 2024-07-18
ER

PT J
AU Hsieh, JW
AF Hsieh, JW
TI Fast stitching algorithm for moving object detection and mosaic
   construction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image registration; image-based rendering; mosaics; moving object
   detection; video retrieval
AB This paper proposes a novel edge-based stitching method to detect moving objects and construct mosaics from images. The method is a coarse-to-fine scheme which first estimates a good initialization of camera parameters with two complementary methods and then refines the solution through an optimization process. The two complementary methods are the edge alignment and correspondence-based approaches, respectively. The edge alignment method estimates desired image translations by checking the consistencies of edge positions between images. This method has better capabilities to overcome larger displacements and lighting variations between images. The correspondence-based approach estimates desired parameters from a set of correspondences by using a new feature extraction scheme and a new correspondence building method. The method can solve more general camera motions than the edge alignment method. Since these two methods are complementary to each other, the desired initial estimate can be obtained more robustly. After that, a Monte-Carlo style method is then proposed for integrating these two methods together. In this approach, a grid partition scheme is proposed to increase the accuracy of each try for finding the correct parameters. After that, an optimization process is then applied to refine the above initial parameters. Different from other optimization methods minimizing errors on the whole images, the proposed scheme minimizes errors only on positions of features points. Since the found initialization is very close to the exact solution and only errors on feature positions are considered, the optimization process can be achieved very quickly. Experimental results are provided to verify the superiority of the proposed method. (C) 2004 Elsevier B.V. All rights reserved.
C1 Yuan Ze Univ, Dept Elect Engn, Taoyuan, Taiwan.
C3 Yuan Ze University
RP Yuan Ze Univ, Dept Elect Engn, Taoyuan, Taiwan.
EM shieh@saturn.yzu.edu.tw
RI cai, bo/G-1491-2010
CR [Anonymous], 1992, NUMERICAL RECIPES C
   BONNET M, 1999, AD HOC M FEB, V636
   CHEN S, 2005, P SIGGRAPH 95, P29
   DAVIS J, 1998, IEEE P CVPR
   Hsieh JW, 1997, COMPUT VIS IMAGE UND, V67, P112, DOI 10.1006/cviu.1996.0517
   Hsu CT, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P887, DOI 10.1109/ICIP.2000.899856
   Irani M, 1998, P IEEE, V86, P905, DOI 10.1109/5.664279
   Jin J. S., 2000, IEEE Transactions on Intelligent Transportation Systems, V1, P32, DOI 10.1109/6979.869019
   Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163
   Nicolas H, 2001, IEEE T IMAGE PROCESS, V10, P1239, DOI 10.1109/83.935039
   Sawhney HS, 1996, IEEE T PATTERN ANAL, V18, P814, DOI 10.1109/34.531801
   Shum HY, 2000, INT J COMPUT VISION, V36, P101, DOI 10.1023/A:1008195814169
   Sonka M., 1993, IMAGE PROCESSING ANA
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Szeliski Richard., 1997, P SIGGRAPH 97 COMPUT, P251, DOI DOI 10.1145/258734.258861
   Zoghlami I, 1997, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.1997.609359
NR 16
TC 42
Z9 51
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2004
VL 22
IS 4
BP 291
EP 306
DI 10.1016/j.imavis.2003.09.018
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 778FW
UT WOS:000189229700003
DA 2024-07-18
ER

PT J
AU Hocaoglu, AK
   Gader, PD
AF Hocaoglu, AK
   Gader, PD
TI Domain learning using Choquet integral-based morphological shared weight
   neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT IEEE Workshop in Computer Vision Beyond the Visible Spectrum
CY DEC 14, 2001
CL KAUAI, HI
SP IEEE
DE domain learning; feature selection; fuzzy measures; landmines
ID GROUND-PENETRATING RADAR
AB Morphological shared weight networks (MSNNs) have been applied to many different problem domains, such as discriminating textures, target and hand written character recognition problems. MSNNs use morphological hit-and-miss transforms (HMT) as the activation functions in the feature extraction layer. However, conventional morphological filters have certain drawbacks. They are not robust and therefore are sensitive to noise. They may not tolerate small changes in gray values and shape. On the other hand, Choquet integral-based morphological operations (CMOs), a natural extension of classical morphological operations, are less sensitive to degradations in an image. The MSNN architecture is extended using CMOs in place of HMTs. These networks are referred to as Choquet morphological shared-weight neural networks (CMSNN). In a related paper, we compared the MSNN and CMSNN by extensive experimentation on the real world problem of land mine detection. In this paper, we discuss the problem of domain learning, which is related to feature importance. We provide examples of successes and failures of generalized mathematical morphology and the Choquet integral. These results are interesting, not only for purposes of robustness. but when viewed in the context of determining more valuable information sources. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
C3 State University System of Florida; University of Florida
RP Gader, PD (corresponding author), Univ Florida, Comp & Informat Sci & Engn Dept, Gainesville, FL 32611 USA.
EM khocaogl@cise.ufl.edu; pgader@cise.ufl.edu
RI Hocaoglu, Ali Köksal/AAG-5193-2021
CR [Anonymous], THESIS U MICHIGAN AN
   Gader PD, 2000, SIGNAL PROCESS, V80, P1069, DOI 10.1016/S0165-1684(00)00020-7
   Gader PD, 1995, NEURAL NETWORKS, V8, P1457, DOI 10.1016/0893-6080(95)00068-2
   Gader PD, 2001, IEEE T GEOSCI REMOTE, V39, P1231, DOI 10.1109/36.927446
   GILLIES AM, 1990, P IMAGE ALGEBRA MORP, V1350, P150
   GORMAN T, 1996, P SPIE C DET REM TEC, P443
   Grabisch M, 2000, IEEE T FUZZY SYST, V8, P627, DOI 10.1109/91.873585
   Grabisch M., 1994, Proceedings of the SPIE - The International Society for Optical Engineering, V2315, P128, DOI 10.1117/12.196709
   HOCAOGLU AK, 2000, THESIS U MISSOURI CO
   HOCAOGLU AK, UNPUB GEN MORPHOLOGI
   HOCAOGLU AK, 1997, P NAFIPS 97, P177
   KHABOU M, 1999, MACHINE VISION APPL
   Khabou MA, 1999, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS (CVBVS'99) - PROCEEDINGS, P101, DOI 10.1109/CVBVS.1999.781099
   PONT W, 1991, SPIE IMAGE ALGEBRA M, V2, P247
   Rappaport CM, 1996, P SOC PHOTO-OPT INS, V2747, P202, DOI 10.1117/12.243083
   Ritter G. X., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P709, DOI 10.1109/ICPR.1996.547657
   Ritter GX, 1998, IEEE T NEURAL NETWOR, V9, P281, DOI 10.1109/72.661123
   RIZKI MM, 1990, SPIE IMAGE ALGEBRA I, P150
   TAMBURINO LA, 1995, IEEE EXPERT, P63
   VOGT RC, 1990, SPIE IMAGE ALGEBRA M, P103
   Won YG, 1997, IEEE T NEURAL NETWOR, V8, P1195, DOI 10.1109/72.623220
   ZUMUDA MA, 1992, SPIE IMAGE ALGEBRA M, V3, P106
NR 22
TC 12
Z9 12
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2003
VL 21
IS 7
BP 663
EP 673
DI 10.1016/S0262-8856(03)00062-3
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 706FR
UT WOS:000184443400009
DA 2024-07-18
ER

PT J
AU Tabbone, S
   Wendling, L
AF Tabbone, S
   Wendling, L
TI Color and grey level object retrieval using a 3D representation of force
   histogram
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE photometric objects; object matching; force histogram; tridimensional
   signature
ID PATTERN-RECOGNITION; IMAGE RETRIEVAL; TEXTURE; FEATURES
AB A new method for both grey level and color object retrieval is presented in this paper. Our feature is based on previous works on force histogram notion which is extended here to handle with photometric information. This kind of feature has low computing time and allows keeping fundamental geometric transformations as scale, translation, symmetry and rotation. More precisely objects processed by defining a tridimensional signature which takes into account their photometric variations and their shapes. Experimental results show the promising aspect of our approach. (C) 2003 Published by Elsevier Science B.V.
C1 LORIA, F-54506 Vandoeuvre Les Nancy, France.
C3 Universite de Lorraine
RP LORIA, Campus Sci,BP 239, F-54506 Vandoeuvre Les Nancy, France.
EM tabbone@loria.fr; wendling@loria.fr
CR [Anonymous], THESIS U AMSTERDAM N
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   BHATTACHARJEE SK, 1999, THESIS EPFL LAUSANNE
   BIGUN J, 1996, IEEE INT C PATT REC, P346
   BRES S, 1999, 3 INT C VIS INF SYST, P427
   BRESENHAM JE, 1965, IBM SYST J, V4, P25, DOI 10.1147/sj.41.0025
   CHEN YQ, 1995, PATTERN RECOGN, V28, P537, DOI 10.1016/0031-3203(94)00116-4
   Derrode S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P877, DOI 10.1109/MMCS.1999.778603
   DUBOIS D, 1987, PATTERN RECOGN LETT, V6, P251, DOI 10.1016/0167-8655(87)90085-7
   Gevers T, 1999, IMAGE VISION COMPUT, V17, P475, DOI 10.1016/S0262-8856(98)00140-1
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   KATO T, 1992, SPIE, V1662
   Krishnapuram R., 1993, IEEE Transactions on Fuzzy Systems, V1, P222, DOI 10.1109/91.236554
   Lam CP, 1995, P 2 AS C COMP VIS, P214
   LONNESTAD T, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P676, DOI 10.1109/ICPR.1992.202077
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Manmatha R, 1998, P SOC PHOTO-OPT INS, V3299, P540, DOI 10.1117/12.320145
   Matsakis P, 1999, IEEE T PATTERN ANAL, V21, P634, DOI 10.1109/34.777374
   MATSAKIS P, 1998, THESIS U P SABATIER
   MEHROTRA R, 1995, COMPUTER, V28, P57, DOI 10.1109/2.410154
   NASTAR C, 1998, RETRIEVING IMAGES CO
   NAYAR SK, 1996, P ARPA IM UND WORKSH
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   PARK Y, 1997, P 8 DEXA TOUL FRANC, P225
   PETLAND AP, 1994, P SPIE C STOR RETR I, V2158, P34
   PICARD RW, 1995, MULTIMEDIA SYST, V3, P3, DOI 10.1007/BF01236575
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J., 1997, International Food Ingredients, P23
   Smith JR, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC528
   SRIHARI RK, 1995, P SOC PHOTO-OPT INS, V2410, P249
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   WELDON T, 1996, IN PRESS IEEE INT C, V4, P2245
   Wendling L, 2002, PATTERN RECOGN LETT, V23, P1687, DOI 10.1016/S0167-8655(02)00131-9
NR 35
TC 12
Z9 13
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2003
VL 21
IS 6
BP 483
EP 495
DI 10.1016/S0262-8856(03)00016-7
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 688BA
UT WOS:000183411300002
DA 2024-07-18
ER

PT J
AU Wu, WY
AF Wu, WY
TI Dominant point detection using adaptive bending value
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE bending value; region of support; dominant point; corner; polygonal
   approximation
ID PIECEWISE LINEAR-APPROXIMATION; POLYGONAL-APPROXIMATION; DIGITAL CURVES;
   DIGITIZED-CURVES; GENETIC ALGORITHMS; CORNER DETECTION
AB An efficient method for dominant point detection is proposed in this paper. The region of support for each point on curve is determined using bending value. The points with local maximum smoothing bending value can be located as the dominant points on the curve. The proposed algorithm needs no input parameter. The experimental results show that the new method is efficient and effective in detecting dominant points. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 I Shou Univ, Dept Ind Engn & Management, Kaohsiung 84008, Taiwan.
C3 I Shou University
RP Wu, WY (corresponding author), I Shou Univ, Dept Ind Engn & Management, Kaohsiung 84008, Taiwan.
CR ANSARI N, 1991, PATTERN RECOGN, V24, P441, DOI 10.1016/0031-3203(91)90057-C
   AOYAMA H, 1991, CVGIP-GRAPH MODEL IM, V53, P435, DOI 10.1016/1049-9652(91)90028-I
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   BELL B, 1990, IEEE T PATTERN ANAL, V12, P913, DOI 10.1109/34.57685
   DUNHAM JG, 1986, IEEE T PATTERN ANAL, V8, P67, DOI 10.1109/TPAMI.1986.4767753
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Hu JM, 1997, PATTERN RECOGN, V30, P701, DOI 10.1016/S0031-3203(96)00105-7
   Huang SC, 1999, PATTERN RECOGN, V32, P1409, DOI 10.1016/S0031-3203(98)00173-3
   KANKANHALLI MS, 1993, PATTERN RECOGN LETT, V14, P385, DOI 10.1016/0167-8655(93)90116-U
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P443, DOI 10.1016/0167-8655(92)90051-Z
   ROSENFELD A, 1975, IEEE T COMPUT, V24, P940, DOI 10.1109/T-C.1975.224342
   ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188
   ROSIN PL, 1989, IMAGE VISION COMPUT, V7, P109, DOI 10.1016/0262-8856(89)90004-8
   SKLANSKY J, 1980, PATTERN RECOGN, V12, P327, DOI 10.1016/0031-3203(80)90031-X
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Tsai D. M., 1996, PATTERN RECOGN, V29, P85
   WALL K, 1984, COMPUT VISION GRAPH, V28, P220, DOI 10.1016/S0734-189X(84)80023-7
   WANG MJJ, 1995, PATTERN RECOGN LETT, V16, P575, DOI 10.1016/0167-8655(95)80003-C
   WU WY, 1993, CVGIP-GRAPH MODEL IM, V55, P79, DOI 10.1006/cgip.1993.1006
   Xiao Y, 2001, PATTERN RECOGN LETT, V22, P299, DOI 10.1016/S0167-8655(00)00138-0
   Yin PY, 1999, INT J PATTERN RECOGN, V13, P1061, DOI 10.1142/S0218001499000598
   Zhu Y, 1997, IEE P-VIS IMAGE SIGN, V144, P8, DOI 10.1049/ip-vis:19970985
NR 23
TC 32
Z9 40
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2003
VL 21
IS 6
BP 517
EP 525
DI 10.1016/S0262-8856(03)00031-3
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 688BA
UT WOS:000183411300005
DA 2024-07-18
ER

PT J
AU Dosil, R
   Pardo, XM
AF Dosil, R
   Pardo, XM
TI Generalized ellipsoids and anisotropic filtering for segmentation
   improvement in 3D medical imaging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
ID SUPERQUADRICS; IMAGES; MODELS
AB Deformable models have demonstrated to be very useful techniques for image segmentation. However, they present several weak points. Two of the main problems with deformable models are the following: (1) results are often dependent on the initial model location. and (2) the generation of image potentials is very sensitive to noise. Modeling and preprocessing methods presented in this paper contribute to solve these problems. We propose an initialization tool to obtain a good approximation to global shape and location of a given object into a 3D image. We also introduce a novel technique for corner preserving anisotropic diffusion filtering to improve contrast and corner measures. This is useful for both guiding initialization (global shape) and subsequent deformation for fine tuning (local shape). (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Santiago de Compostela, Dept Elect & Computac, Santiago De Compostela 15782, Spain.
C3 Universidade de Santiago de Compostela
RP Univ Santiago de Compostela, Dept Elect & Computac, Campus Str, Santiago De Compostela 15782, Spain.
EM rdosil@usc.es; pardo@dec.usc.es
RI Dosil, Raquel/JSK-7672-2023; Pardo, Xose M./L-8567-2014
OI Dosil, Raquel/0000-0001-8171-9268; Pardo, Xose M./0000-0002-3997-5150
CR [Anonymous], IEEE INT C COMP VIS
   BAJCSY R, 1989, COMPUT VISION GRAPH, V46, P1, DOI 10.1016/S0734-189X(89)80014-3
   Bardinet E, 1995, 2617 INRIA
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   BOLLE RM, 1991, IEEE T PATTERN ANAL, V13, P1, DOI 10.1109/34.67626
   CHARBONNIER P, 1994, IEEE IMAGE PROC, P168
   Cootes T. F., 1993, Information Processing in Medical Imaging. 13th International Conference, IPMI '93 Proceedings, P33, DOI 10.1007/BFb0013779
   DELINGETTE H, 1998, P IEEE INT WORKSH MO
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   Goldberg D. E., 1999, GENETIC ALGORITHMS S
   GREEN PJ, 1990, IEEE T MED IMAGING, V9, P84, DOI 10.1109/42.52985
   Jaklic A., 2000, COMP IMAG VIS, V20
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KRISSIAN K, 1995, 3064 INRIA
   Leonardis A, 1997, IEEE T PATTERN ANAL, V19, P1289, DOI 10.1109/34.632988
   Linares P, 1998, COMPUT CARDIOL, V25, P657, DOI 10.1109/CIC.1998.731959
   MCINERNEY T, 1996, MED IMAGE ANAL, V1
   MONGA O, 1989, 1103 INRIA
   MONGA O, 1989, 1599 INRIA
   Neuenschwander W, 1997, COMPUT VIS IMAGE UND, V65, P237, DOI 10.1006/cviu.1996.0578
   Pardo XM, 2000, PATTERN RECOGN LETT, V21, P559, DOI 10.1016/S0167-8655(00)00020-9
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   SAINTMARC P, 1991, IEEE T PATTERN ANAL, V13, P514, DOI 10.1109/34.87339
   Sandor S, 1997, IEEE T MED IMAGING, V16, P41, DOI 10.1109/42.552054
   Solé AF, 2001, IEEE T MED IMAGING, V20, P86, DOI 10.1109/42.913175
   SOLINA F, 1990, IEEE T PATTERN ANAL, V12, P131, DOI 10.1109/34.44401
   Sporring J, 1998, INT C PATT RECOG, P652
   Staib LH, 1997, INT J PATTERN RECOGN, V11, P1247, DOI 10.1142/S0218001497000585
   Tek H, 1997, COMPUT VIS IMAGE UND, V65, P246, DOI 10.1006/cviu.1996.0579
   TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659
   Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3
   Weickert J., 1994, SCALE SPACE PROPERTI
   WHAITE P, 1991, IEEE T PATTERN ANAL, V13, P1038, DOI 10.1109/34.99237
NR 34
TC 5
Z9 5
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2003
VL 21
IS 4
BP 325
EP 343
DI 10.1016/S0262-8856(03)00006-4
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 669PH
UT WOS:000182359300002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tsai, DM
   Huang, TY
AF Tsai, DM
   Huang, TY
TI Automated surface inspection for statistical textures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE surface inspection; defect detection; statistical textures; Fourier
   transform; linage reconstruction
ID DEFECT DETECTION; GABOR FILTERS; CLASSIFICATION; SEGMENTATION; FEATURES;
   SCHEME
AB In this paper we present a global approach for the automatic inspection of defects in randomly textured surfaces which arise in sandpaper. castings, leather, and many industrial materials. The proposed method does not rely on local features of textures. It is based on a global image reconstruction scheme using the Fourier transform (FT). Since a statistical texture has the surface of random pattern. the spread of frequency components in the power spectrum space is isotropic and forms the shape approximate to a circle. By finding an adequate radius in the spectrum space, and setting the frequency components outside the selected circle to zero, we can remove the periodic. repetitive patterns of any statistical textures using the inverse FT. In the restored image. the homogeneous region in the original image will have an approximately uniform gray level, and yet the defective region will be distinctly preserved. This converts the difficult defect detection in textured images into a simple thresholding problem in nontextured images. The experimental results from a variety of real statistical textures have shown the efficacy of the proposed method. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Yuan Ze Univ, Dept Ind Engn & Management, Chungli 320, Taiwan.
C3 Yuan Ze University
RP Yuan Ze Univ, Dept Ind Engn & Management, 135 Yuan Tung Rd, Chungli 320, Taiwan.
EM iedmtsai@saturn.yzu.edu.tw
CR [Anonymous], 1992, R. woods digital image processing
   Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796
   Bodnarova A, 2000, INT CONF ACOUST SPEE, P3606, DOI 10.1109/ICASSP.2000.860182
   Brzakovic D, 1996, PATTERN RECOGN, V29, P1401, DOI 10.1016/0031-3203(95)00166-2
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chen CH, 1997, GRAPH MODEL IM PROC, V59, P349, DOI 10.1006/gmip.1997.0443
   Chen S., 1993, Pure and Applied Optics, V2, P429, DOI 10.1088/0963-9659/2/5/004
   CLARK M, 1987, PATTERN RECOGN LETT, V6, P261, DOI 10.1016/0167-8655(87)90086-9
   Clausi DA, 2000, PATTERN RECOGN, V33, P1835, DOI 10.1016/S0031-3203(99)00181-8
   COHEN FS, 1992, CVGIP-GRAPH MODEL IM, V54, P239, DOI 10.1016/1049-9652(92)90054-2
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   CONNERS RW, 1983, IEEE T PATTERN ANAL, V5, P573, DOI 10.1109/TPAMI.1983.4767446
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Escofet J, 1998, P SOC PHOTO-OPT INS, V3490, P207, DOI 10.1117/12.308923
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Iivarinen J, 2000, PROC SPIE, V4197, P140, DOI 10.1117/12.403757
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Lambert G, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P201, DOI 10.1109/ICIP.1997.632054
   Lee CS, 1997, IEICE T INF SYST, VE80D, P594
   LINNETT LM, 1995, IEE P-VIS IMAGE SIGN, V142, P1, DOI 10.1049/ip-vis:19951678
   LIU SS, 1990, COMPUT VISION GRAPH, V49, P52, DOI 10.1016/0734-189X(90)90162-O
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Maruo K, 1999, IEICE T ELECTRON, VE82C, P1003
   NEWMAN TS, 1995, COMPUT VIS IMAGE UND, V61, P231, DOI 10.1006/cviu.1995.1017
   OLSSON J, 1992, PROCEEDINGS OF THE 1992 INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, INSTRUMENTATION, AND AUTOMATION, VOLS 1-3, P1443, DOI 10.1109/IECON.1992.254389
   Paschos G, 2000, PATTERN RECOGN LETT, V21, P837, DOI 10.1016/S0167-8655(00)00043-X
   Pikaz A, 1997, GRAPH MODEL IM PROC, V59, P1, DOI 10.1006/gmip.1996.0410
   Pölzleitner W, 1999, P SOC PHOTO-OPT INS, V3837, P220, DOI 10.1117/12.360301
   PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910
   Ramana KV, 1996, PATTERN RECOGN, V29, P1447, DOI 10.1016/0031-3203(96)00008-8
   Sari-Sarraf H, 1998, PROC CVPR IEEE, P938, DOI 10.1109/CVPR.1998.698717
   SIEW LH, 1988, IEEE T PATTERN ANAL, V10, P92, DOI 10.1109/34.3870
   Tsai DM, 1999, IMAGE VISION COMPUT, V18, P49, DOI 10.1016/S0262-8856(99)00009-8
   VANHULLE MM, 1993, NEURAL NETWORKS, V6, P7, DOI 10.1016/S0893-6080(05)80070-X
   WECHSLER H, 1980, SIGNAL PROCESS, V2, P271, DOI 10.1016/0165-1684(80)90024-9
   Wilder J, 1989, MACHINE VISION INSPE, P237
   Wiltschi K, 2000, MACH VISION APPL, V12, P113, DOI 10.1007/s001380050130
NR 37
TC 167
Z9 195
U1 5
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2003
VL 21
IS 4
BP 307
EP 323
DI 10.1016/S0262-8856(03)00007-6
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 669PH
UT WOS:000182359300001
DA 2024-07-18
ER

PT J
AU Alshehri, F
   Muhammad, G
AF Alshehri, Fatima
   Muhammad, Ghulam
TI A few-shot learning-based ischemic stroke segmentation system using
   weighted MRI fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ischemic stroke segmentation; MRI; Few-shot learning; Convolutional
   neural network
ID LESION SEGMENTATION
AB Stroke, particularly ischemic stroke, is a major cause of disability and one of the leading causes of adult mortality worldwide. Early and prompt management of stroke patients can reduce the severity of the disease. Doctors usually determine the severity of a stroke by focusing on the region of interest (ROI) in the MRI or CT scan images. An accurate and effective automatic image segmentation system can assist medical professionals as well as automatic detection and classification systems. Deep learning is the current advanced approach for dealing with machine learning and artificial intelligence. However, conventional deep learning requires a large amount of data for training, and the amount of labeled data in the medical field is limited. In this paper, we propose a few-shot learning strategy and integrate it with a base convolutional neural network model, which utilizes a selfattention mechanism to segment MRI for ischemic stroke. By combining the base model with self-attention, we can focus more on the ROI and disregard less important features. Additionally, the proposed system only selects slices with lesions and ignores unlesioned slices. This helps to improve efficiency and reduce the computational load by eliminating the need to tune unnecessary parameters. To achieve even better results, the system also combines two weighted images, FLAIR and DWI, as an early fusion process. Experiments have shown that this approach leads to higher performance compared to using the same system without fusion. The proposed system is evaluated using a publicly available dataset, ISLES 2015 SSIS, and compared with other state-of-the-art (SOTA) systems. It achieves a dice coefficient score of 0.68, which is significantly better than that of other SOTA systems.
C1 [Alshehri, Fatima; Muhammad, Ghulam] King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh, Saudi Arabia.
C3 King Saud University
RP Muhammad, G (corresponding author), King Saud Univ, Coll Comp & Informat Sci, Dept Comp Engn, Riyadh, Saudi Arabia.
EM ghulam@ksu.edu.sa
RI Muhammad, Ghulam/H-5884-2011
FU King Saud University, Riyadh, Saudi Arabia [RSP2023R34]
FX The authors acknowledge the Researchers Supporting Project number
   (RSP2023R34), King Saud University, Riyadh, Saudi Arabia.
CR Aboudi F, 2022, INT C CONTROL DECISI, P724, DOI [10.1109/CoDIT55151.2022.9804030, 10.1109/CODIT55151.2022.9804030]
   Al Jowair H, 2023, IMAGE VISION COMPUT, V137, DOI 10.1016/j.imavis.2023.104767
   Al-Senani F, 2020, J STROKE CEREBROVASC, V29, DOI 10.1016/j.jstrokecerebrovasdis.2019.104465
   Boulahia SY, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01249-8
   Chen GX, 2020, NEUROIMAGE, V211, DOI 10.1016/j.neuroimage.2020.116620
   Cheng Ouyang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P762, DOI 10.1007/978-3-030-58526-6_45
   Clèrigues A, 2020, COMPUT METH PROG BIO, V194, DOI 10.1016/j.cmpb.2020.105521
   Deepa B, 2019, MULTIDIM SYST SIGN P, V30, P2081, DOI 10.1007/s11045-019-00642-x
   Du XQ, 2022, COMPUT MED IMAG GRAP, V101, DOI 10.1016/j.compmedimag.2022.102120
   Gaillard F., CT PERFUSION in Ischemic Stroke | Radiology Reference Article | Radiopaedia.org
   Gui YK, 2020, BRAIN RES BULL, V158, P122, DOI 10.1016/j.brainresbull.2020.03.009
   Hansen S, 2022, MED IMAGE ANAL, V78, DOI 10.1016/j.media.2022.102385
   He L, 2008, IMAGE VISION COMPUT, V26, P141, DOI 10.1016/j.imavis.2007.07.010
   Hemanth DJ, 2021, EVOL INTELL, V14, P1089, DOI 10.1007/s12065-020-00551-0
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu XJ, 2020, BMC MED IMAGING, V20, DOI 10.1186/s12880-020-0409-2
   Huang SC, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-00341-z
   Kanchana R, 2020, BIOMED ENG LETT, V10, P333, DOI 10.1007/s13534-020-00158-5
   Karthik R, 2020, COMPUT METH PROG BIO, V197, DOI 10.1016/j.cmpb.2020.105728
   Karthik R, 2019, APPL SOFT COMPUT, V84, DOI 10.1016/j.asoc.2019.105685
   Khadga R, 2022, Arxiv, DOI arXiv:2106.03223
   Khadka R, 2022, COMPUT BIOL MED, V143, DOI 10.1016/j.compbiomed.2022.105227
   Kumar A, 2020, COMPUT METH PROG BIO, V193, DOI 10.1016/j.cmpb.2020.105524
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Liu LL, 2020, MED IMAGE ANAL, V65, DOI 10.1016/j.media.2020.101791
   Liu LL, 2020, NEURAL COMPUT APPL, V32, P6545, DOI 10.1007/s00521-019-04096-x
   Liu WD, 2022, Arxiv, DOI arXiv:2108.08518
   Liu ZY, 2018, IEEE ACCESS, V6, P57006, DOI 10.1109/ACCESS.2018.2872939
   Maier O, 2017, MED IMAGE ANAL, V35, P250, DOI 10.1016/j.media.2016.07.009
   Nishio M, 2020, COMPUT METH PROG BIO, V196, DOI 10.1016/j.cmpb.2020.105711
   Provost C, 2019, STROKE, V50, P659, DOI 10.1161/STROKEAHA.118.023882
   Feyjie AR, 2020, Arxiv, DOI arXiv:2003.08462
   Radenovic F, 2019, IEEE T PATTERN ANAL, V41, P1655, DOI 10.1109/TPAMI.2018.2846566
   Raina K, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON BIOMEDICAL ENGINEERING SYSTEMS AND TECHNOLOGIES, VOL 2: BIOIMAGING, P116, DOI 10.5220/0008912101160122
   Ravi S., 2016, INT C LEARNING REPRE
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shah P.M., 2020, Advances in Computational Collective Intelligence, Communications in Computer and Information Science, DOI 10.1007/978-3-030-63119-2_23
   Snell J, 2017, ADV NEUR IN, V30
   Sun LY, 2022, COMPUT BIOL MED, V140, DOI 10.1016/j.compbiomed.2021.105067
   Tomasetti L, 2023, Arxiv, DOI arXiv:2303.01332
   Tomita N, 2020, NEUROIMAGE-CLIN, V27, DOI 10.1016/j.nicl.2020.102276
   Virani SS, 2021, CIRCULATION, V143, pe254, DOI 10.1161/CIR.0000000000000950
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu AM, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1029
   Yousufuddin M, 2019, AGING-US, V11, P2542, DOI 10.18632/aging.101931
   Zhang L, 2020, IEEE ACCESS, V8, P45715, DOI 10.1109/ACCESS.2020.2977415
   Zhang RZ, 2018, IEEE T MED IMAGING, V37, P2149, DOI 10.1109/TMI.2018.2821244
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
NR 48
TC 4
Z9 4
U1 4
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104865
DI 10.1016/j.imavis.2023.104865
EA NOV 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GA8P8
UT WOS:001150032000001
DA 2024-07-18
ER

PT J
AU Duan, Z
   Luo, XL
   Zhang, TP
AF Duan, Zhao
   Luo, Xiaoliu
   Zhang, Taiping
TI Multi-focus image fusion using structure-guided flow
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-focus image fusion; Capsule network; Structure information; Flow
   alignment module
ID PERFORMANCE; NETWORKS
AB Existing deep learning based methods have shown their advantages in multi-focus image fusion task. However, most methods still suffer from inaccurate focus region detection. In this paper, we employ the property of partwhole relationships embedded by the Capsule Network (CapsNet) to solve the problem. Specifically, we introduce CapsNet in multi-focus image fusion task, and design a structure-guided flow module, which fully utilizes structure information to help locate focus regions. CapsNet is introduced to extract structure features by supervising gradient information of the image. Compared with traditional convolutional neural networks (CNNs), CapsNet takes into account the correlation of features from different positions, such that it encodes more compact features. Once structure features are obtained, a flow alignment module is introduced to learn flow field between structure and image features, and propagate effectively structure features to image features to make confident focus region detection. Experimental results show the proposed method achieves robust fusion performance on three publicly available multi-focus datasets, and outperforms or is comparable to the state-of-the-art methods.
C1 [Duan, Zhao; Luo, Xiaoliu; Zhang, Taiping] Chongqing Univ, Sch Comp Sci, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Zhang, TP (corresponding author), Chongqing Univ, Sch Comp Sci, Chongqing 400044, Peoples R China.
EM duanzhao@cqu.edu.cn; luoxiaoliu@cqu.edu.cn; tpzhang@cqu.edu.cn
FU National Natural Science Foundation of China [62076043]
FX This work is supported by National Natural Science Foundation of China
   under Grant No. 62076043.
CR Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   Bharath A.A., 2018, INT C MED IM DEEP LE
   Cheng CY, 2023, INFORM FUSION, V92, P80, DOI 10.1016/j.inffus.2022.11.010
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Guo XP, 2019, IEEE T MULTIMEDIA, V21, P1982, DOI 10.1109/TMM.2019.2895292
   Han Y, 2013, INFORM FUSION, V14, P127, DOI 10.1016/j.inffus.2011.08.002
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hossny M, 2008, ELECTRON LETT, V44, P1066, DOI 10.1049/el:20081754
   Huang W, 2007, PATTERN RECOGN LETT, V28, P1123, DOI 10.1016/j.patrec.2007.01.013
   Kingma D. P., 2014, arXiv
   LaLonde R, 2018, Arxiv, DOI [arXiv:1804.04241, DOI 10.48550/ARXIV.1804.04241]
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li HG, 2019, IEEE SENS J, V19, P9755, DOI 10.1109/JSEN.2019.2928818
   Li JX, 2020, IEEE T IMAGE PROCESS, V29, P4816, DOI 10.1109/TIP.2020.2976190
   Li SS, 2008, 2008 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING, VOLS 1 AND 2, PROCEEDINGS, P167, DOI 10.1109/ICALIP.2008.4589989
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Li XS, 2021, SIGNAL PROCESS, V184, DOI 10.1016/j.sigpro.2021.108062
   Liu Y, 2022, IEEE T PATTERN ANAL, V44, P3688, DOI 10.1109/TPAMI.2021.3053577
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Ma B., 2020, arXiv
   Ma HY, 2020, IEEE T IMAGE PROCESS, V29, P8668, DOI 10.1109/TIP.2020.3018261
   Ma JY, 2021, IEEE T COMPUT IMAG, V7, P309, DOI 10.1109/TCI.2021.3063872
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Paszke Adam, 2017, NIPS W
   Petrovic V, 2005, IEEE I CONF COMP VIS, P1866
   Roy SK, 2023, IEEE Transactions on Geoscience and Remote Sensing, V61
   Sabour S, 2017, ADV NEUR IN, V30
   Singh M, 2019, IEEE I CONF COMP VIS, P340, DOI 10.1109/ICCV.2019.00043
   Tian J, 2012, SIGNAL PROCESS, V92, P2137, DOI 10.1016/j.sigpro.2012.01.027
   Wang Q, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P469, DOI 10.1016/B978-0-12-372529-5.00017-2
   Wu X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3124913
   Xiangtai Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P775, DOI 10.1007/978-3-030-58452-8_45
   Xiao B, 2021, IEEE T IMAGE PROCESS, V30, P163, DOI 10.1109/TIP.2020.3033158
   Xie HS, 2023, INFORM FUSION, V98, DOI 10.1016/j.inffus.2023.101835
   Xu S., 2020, arXiv
   Xydeas CS, 2000, ELECTRON LETT, V36, P308, DOI 10.1049/el:20000267
   Zhang H, 2021, INFORM FUSION, V66, P40, DOI 10.1016/j.inffus.2020.08.022
   Zhang H, 2020, AAAI CONF ARTIF INTE, V34, P12797
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhao WD, 2019, IEEE T CIRC SYST VID, V29, P1102, DOI 10.1109/TCSVT.2018.2821177
   Zhou JC, 2019, IEEE PHOTONICS J, V11, DOI 10.1109/JPHOT.2019.2950949
NR 47
TC 0
Z9 0
U1 8
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104814
DI 10.1016/j.imavis.2023.104814
EA SEP 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA S7OL9
UT WOS:001073026500001
DA 2024-07-18
ER

PT J
AU Wei, WY
   Xu, MY
   Wang, J
   Luo, XZ
AF Wei, Weiyi
   Xu, Mengyu
   Wang, Jian
   Luo, Xuzhe
TI Bidirectional Attentional Interaction Networks for RGB-D salient object
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RGB-D salient object detection; Cross-modality feature; Bidirectional
   interaction; Guidance aggregation
AB Aiming at the issues of insufficient cross-modality feature interaction and ineffective utilization of cross-modality data in RGB-D saliency object detection (SOD) tasks, we propose a Bidirectional Attentional Interaction Network (BAINet) for RGB-D SOD, which employs an encoder-decoder structure for bidirectional interaction of cross-modality features through a dual-branch progressive fusion approach. To begin with, based on the fact that RGB and depth information streams can complement each other, the bidirectional attention interaction module accomplishes bidirectional interaction between cross-modality features by capturing complementary cues from different modality data. In order to enhance the expressiveness of the fused RGB-D features, the global feature perception module endows the features with rich multi-scale contextual semantic information by enlarging the field of perception. In addition, exploring the correlation of cross-level features is vital to achieve accurate salient inference. Specifically, We introduce a cross-level guidance aggregation module to capture inter-layer de-pendencies and complete the integration of cross-level features, which effectively suppresses shallow cross-modality features and refines the saliency map during decoding. To improve the model training speed, a hybrid loss function is employed to train multi-branch saliency inference maps simultaneously. Extensive ex-periments on five publicly available datasets clearly show that the proposed model outperforms 18 state-of-the -art methods.
C1 [Wei, Weiyi; Xu, Mengyu; Wang, Jian; Luo, Xuzhe] Northwest Normal Univ, Lanzhou 730070, Gansu, Peoples R China.
C3 Northwest Normal University - China
RP Xu, MY (corresponding author), Northwest Normal Univ, Lanzhou 730070, Gansu, Peoples R China.
EM 2021222167@nwnu.edu.cn
RI wei, weiyi/JPL-6353-2023
CR Ao Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P346, DOI 10.1007/978-3-030-58610-2_21
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007
   Chen Q, 2021, AAAI CONF ARTIF INTE, V35, P1063
   Chen S., 2020, ECCV, P520, DOI DOI 10.1007/978-3-030-58598-3_31
   Chen ZY, 2021, IEEE T IMAGE PROCESS, V30, P7012, DOI 10.1109/TIP.2020.3028289
   Cheng MM, 2021, INT J COMPUT VISION, V129, P2622, DOI [10.1007/s11263-021-01490-8, 10.1109/ICCV.2017.487]
   Cheng Y, 2014, IEEE INT CON MULTI
   Chongyi Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P225, DOI 10.1007/978-3-030-58598-3_14
   Ciptadi A, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.112
   Cong RM, 2019, IEEE T CIRC SYST VID, V29, P2941, DOI 10.1109/TCSVT.2018.2870832
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Duan SS, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11131968
   Fan DP, 2018, Arxiv, DOI arXiv:1805.10421
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Fang X, 2022, Arxiv, DOI arXiv:2203.10785
   Feng D, 2016, PROC CVPR IEEE, P2343, DOI 10.1109/CVPR.2016.257
   Feng G, 2022, PATTERN RECOGN, V128, DOI 10.1016/j.patcog.2022.108666
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   Han YB, 2022, IEEE ACCESS, V10, P25435, DOI 10.1109/ACCESS.2022.3156935
   He JJ, 2019, IEEE I CONF COMP VIS, P3561, DOI 10.1109/ICCV.2019.00366
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Lang CY, 2012, LECT NOTES COMPUT SC, V7573, P101, DOI 10.1007/978-3-642-33709-3_8
   Li GY, 2021, IEEE T IMAGE PROCESS, V30, P3528, DOI 10.1109/TIP.2021.3062689
   Li GY, 2020, IEEE T IMAGE PROCESS, V29, P4873, DOI 10.1109/TIP.2020.2976689
   Liu D, 2021, IEEE T MULTIMEDIA, V23, P967, DOI 10.1109/TMM.2020.2991523
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu Z., 2022, MULTIMED TOOLS APPL, P1
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Sun P, 2021, PROC CVPR IEEE, P1407, DOI 10.1109/CVPR46437.2021.00146
   Takahashi N, 2021, Arxiv, DOI arXiv:2010.01733
   Tao Zhou, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10274, DOI 10.1109/CVPR42600.2020.01029
   Wang FY, 2022, IEEE T IMAGE PROCESS, V31, P1285, DOI 10.1109/TIP.2022.3140606
   Wei WY, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14112393
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiaoqi Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P646, DOI 10.1007/978-3-030-58542-6_39
   Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908
   Zhang C, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2094, DOI 10.1145/3474085.3475364
   Zhang J, 2022, IEEE T PATTERN ANAL, V44, P5761, DOI 10.1109/TPAMI.2021.3073564
   Zhang WB, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P731, DOI 10.1145/3474085.3475240
   Zhang Z, 2021, IEEE T IMAGE PROCESS, V30, P1949, DOI 10.1109/TIP.2021.3049959
NR 50
TC 2
Z9 2
U1 6
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104792
DI 10.1016/j.imavis.2023.104792
EA AUG 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA R1SB0
UT WOS:001062197900001
DA 2024-07-18
ER

PT J
AU Bai, GH
   Luo, YM
   Pan, XL
   Wang, J
   Guo, JM
AF Bai, Guihu
   Luo, Yanmin
   Pan, Xueliang
   Wang, Jia
   Guo, Jing-Ming
TI Real-time 3D human pose estimation without skeletal a priori structures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D Human pose estimation; Without human skeleton structure; Weight
   circular sharing; Weighted residual connection
AB This study is about real-time 2D-3D human pose estimation without using the a priori structure of the skeleton and with a low number of parameters for regression tasks. Current graph convolution-based 3D human pose tasks require structural knowledge of the skeleton, which limits the exploration of pose estimation for unknown structures. Inspired by tyre rotation and circular convolution, weights rotation is used to fully learn the potential connections between the human joints. We refer to this process as the weight cyclic sharing mechanism, a novel method for updating features. It does not require knowledge of the structure of the human skeleton and learns different constraints between joints with a low number of parameters. We propose an end-to-end weight circu-lar sharing network (WCirSNet) based on the weight circular sharing mechanism. We propose a simple and ef-ficient weighted residual block in this WCirSNet. The superiorities of the weight circular sharing mechanism and weighted residual block were verified by abundant ablation studies. Extensive evaluations on two challenging benchmark datasets (Human 3.6 M, MPI-INF-3DHP) show that the performance and generalization capabilities of our framework are superior to the results of many previously advanced methods.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Bai, Guihu; Luo, Yanmin; Pan, Xueliang; Wang, Jia] Huaqiao Univ, Coll Comp Sci & Technol, 668 Jimei Ave, Xiamen 361021, Fujian, Peoples R China.
   [Bai, Guihu; Luo, Yanmin; Pan, Xueliang; Wang, Jia] Huaqiao Univ, Key Lab Comp Vis & Pattern Recognit, 668 Jimei Ave, Xiamen 361021, Fujian, Peoples R China.
   [Guo, Jing-Ming] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
C3 Huaqiao University; Huaqiao University; National Taiwan University of
   Science & Technology
RP Luo, YM (corresponding author), Huaqiao Univ, Coll Comp Sci & Technol, 668 Jimei Ave, Xiamen 361021, Fujian, Peoples R China.; Guo, JM (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
EM lym@hqu.edu.cn; jmguo@seed.net.tw
RI xiao, ming/KHT-1774-2024; Liu, Jinyu/JYQ-6274-2024; Bai,
   Guihu/GSM-7354-2022
FU Natural Science Foundation of Fujian Province, China [2020J01082]
FX This work was supported by Natural Science Foundation of Fujian
   Province, China under grant 2020J01082.
CR Ailing Zeng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P507, DOI 10.1007/978-3-030-58568-6_30
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Bai GH, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104452
   Ben Gamra M, 2021, IMAGE VISION COMPUT, V114, DOI 10.1016/j.imavis.2021.104282
   Bracewell Ronald Newbold, 1986, The Fourier transform and its applications, V31999
   Bulat A, 2020, IEEE INT CONF AUTOMA, P8, DOI 10.1109/FG47880.2020.00014
   Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236
   Chen CH, 2019, PROC CVPR IEEE, P5707, DOI 10.1109/CVPR.2019.00586
   Chen T., 2021, IEEE T CIRC SYST VID
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chowdhary K.R., 2020, FUNDAMENTALS ARTIFIC, P603
   Ci H, 2019, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2019.00235
   Errity A., 2016, An Introduction to Cyberpsychology, P263
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Gong KH, 2021, PROC CVPR IEEE, P8571, DOI 10.1109/CVPR46437.2021.00847
   Gui LY, 2018, IEEE INT C INT ROBOT, P562, DOI 10.1109/IROS.2018.8594452
   Gyeongsik Moon, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12352), P752, DOI 10.1007/978-3-030-58571-6_44
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Pham HH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071825
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kenkun Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P318, DOI 10.1007/978-3-030-58607-2_19
   Kingma D. P., 2014, arXiv
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Lee K, 2018, LECT NOTES COMPUT SC, V11211, P123, DOI 10.1007/978-3-030-01234-2_8
   Li C, 2019, PROC CVPR IEEE, P9879, DOI 10.1109/CVPR.2019.01012
   Li SC, 2020, PROC CVPR IEEE, P6172, DOI 10.1109/CVPR42600.2020.00621
   Li W., 2022, IEEE T MULTIMEDIA, DOI [10.1109/TMM.2022.31412311-1, DOI 10.1109/TMM.2022.31412311-1]
   Liu JF, 2021, IEEE INT CONF ROBOT, P3374, DOI 10.1109/ICRA48506.2021.9561605
   Liu RX, 2020, PROC CVPR IEEE, P5063, DOI 10.1109/CVPR42600.2020.00511
   Lo Presti L, 2015, IMAGE VISION COMPUT, V44, P29, DOI 10.1016/j.imavis.2015.09.007
   Luo CX, 2018, Arxiv, DOI arXiv:1811.04989
   Luo YM, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104390
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Ma XX, 2021, PROC CVPR IEEE, P6234, DOI 10.1109/CVPR46437.2021.00617
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392410
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Nibali A, 2019, IEEE WINT CONF APPL, P1477, DOI 10.1109/WACV.2019.00162
   Ning GH, 2020, IEEE COMPUT SOC CONF, P4456, DOI 10.1109/CVPRW50498.2020.00525
   Oppenheim A. V., 1999, DISCRETE TIME SIGNAL, DOI DOI 10.1049/EP.1977.0078
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Romero Javier, 2009, 2009 9th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2009), P87, DOI 10.1109/ICHR.2009.5379596
   Sharma S, 2019, IEEE I CONF COMP VIS, P2325, DOI 10.1109/ICCV.2019.00241
   Si CY, 2019, PROC CVPR IEEE, P1227, DOI 10.1109/CVPR.2019.00132
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun N, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104141
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Trick, 1975, IEEE T ACOUST SPEECH, V23, P394, DOI DOI 10.1109/TASSP.1975.1162708
   Wandt B, 2019, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2019.00797
   Wang LY, 2019, IEEE INT CONF COMP V, P4024, DOI 10.1109/ICCVW.2019.00497
   Wehrbein T., 2021, ICCV, P11199
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yang ZX, 2021, PROC CVPR IEEE, P3906, DOI 10.1109/CVPR46437.2021.00390
   Zeng AL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11416, DOI 10.1109/ICCV48922.2021.01124
   Zhang ZQ, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104198
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zheng C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11636, DOI 10.1109/ICCV48922.2021.01145
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
   Zou Z., 2021, IEEECVF INT C COMPUT, p11 477
NR 68
TC 3
Z9 3
U1 5
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2023
VL 132
AR 104649
DI 10.1016/j.imavis.2023.104649
EA MAR 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 9Y4EG
UT WOS:000950411500001
DA 2024-07-18
ER

PT J
AU Eyiokur, FI
   Kantarc, A
   Erakin, ME
   Damer, N
   Ofli, F
   Imran, M
   Krizaj, J
   Salah, AA
   Waibel, A
   Struc, V
   Ekenel, HK
AF Eyiokur, Fevziye Irem
   Kantarc, Alperen
   Erakin, Mustafa Ekrem
   Damer, Naser
   Ofli, Ferda
   Imran, Muhammad
   Krizaj, Janez
   Salah, Albert Ali
   Waibel, Alexander
   Struc, Vitomir
   Ekenel, Hazim Kemal
TI A survey on computer vision based human analysis in the COVID-19 era
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; COVID-19; Human analysis; Masked faces; Survey
ID MASKED FACE RECOGNITION; IMAGE QUALITY; BIOMETRICS; ROBUST; OCCLUSION;
   CROWD
AB The emergence of COVID-19 has had a global and profound impact, not only on society as a whole, but also on the lives of individuals. Various prevention measures were introduced around the world to limit the transmission of the disease, including face masks, mandates for social distancing and regular disinfection in public spaces, and the use of screening applications. These developments also triggered the need for novel and improved computer vi-sion techniques capable of (i) providing support to the prevention measures through an automated analysis of visual data, on the one hand, and (ii) facilitating normal operation of existing vision-based services, such as bio-metric authentication schemes, on the other. Especially important here, are computer vision techniques that focus on the analysis of people and faces in visual data and have been affected the most by the partial occlusions introduced by the mandates for facial masks. Such computer vision based human analysis techniques include face and face-mask detection approaches, face recognition techniques, crowd counting solutions, age and expression estimation procedures, models for detecting face-hand interactions and many others, and have seen considerable attention over recent years. The goal of this survey is to provide an introduction to the problems induced by COVID-19 into such research and to present a comprehensive review of the work done in the computer vision based human analysis field. Particular attention is paid to the impact of facial masks on the performance of var-ious methods and recent solutions to mitigate this problem. Additionally, a detailed review of existing datasets useful for the development and evaluation of methods for COVID-19 related applications is also provided. Finally, to help advance the field further, a discussion on the main open challenges and future research direction is given at the end of the survey. This work is intended to have a broad appeal and be useful not only for computer vision researchers but also the general public.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Eyiokur, Fevziye Irem; Waibel, Alexander] Karlsruhe Inst Technol, Inst Anthropomat & Robot, Karlsruhe, Germany.
   [Kantarc, Alperen; Erakin, Mustafa Ekrem; Ekenel, Hazim Kemal] Istanbul Tech Univ, Dept Comp Engn, Istanbul, Turkey.
   [Damer, Naser] Fraunhofer Inst Comp Graph Res IGD, Darmstadt, Germany.
   [Damer, Naser] Tech Univ Darmstadt, Dept Comp Snence, Darmstadt, Germany.
   [Ofli, Ferda; Imran, Muhammad] HBKU, Qatar Comp Res Inst, Doha, Qatar.
   [Struc, Vitomir] Univ Ljubljana, Fac Elect Engn, Trazska Cesta 25, Ljubljana 1000, Slovenia.
   [Salah, Albert Ali] Univ Utrecht, Dept Informat & Comp Sci, Utrecht, Netherlands.
   [Salah, Albert Ali] Bogazici Univ, Dept Comp Engn, Istanbul, Turkey.
   [Waibel, Alexander] Carnegie Mellon Univ, Pittsburgh, PA USA.
C3 Helmholtz Association; Karlsruhe Institute of Technology; Istanbul
   Technical University; Fraunhofer Gesellschaft; Technical University of
   Darmstadt; Qatar Foundation (QF); Hamad Bin Khalifa University-Qatar;
   Qatar Computing Research Institute; University of Ljubljana; Utrecht
   University; Bogazici University; Carnegie Mellon University
RP Eyiokur, FI (corresponding author), Karlsruhe Inst Technol, Inst Anthropomat & Robot, Karlsruhe, Germany.
EM fevziye.yaman@kit.edu
RI Ofli, Ferda/G-2027-2017; EKENEL, HAZIM KEMAL/A-5293-2016; Salah, Albert
   Ali/ABH-5561-2020; Eyiokur, Fevziye Irem/JXL-8864-2024; Salah, Albert
   Ali/E-5820-2013
OI Ofli, Ferda/0000-0003-3918-3230; EKENEL, HAZIM
   KEMAL/0000-0003-3697-8548; Salah, Albert Ali/0000-0001-6342-428X;
   ERAKIN, Mustafa Ekrem/0000-0003-3101-9719
FU ARRS Research Programme [P2-0250 (B)]; ARRS-TUBITAK; TUBITAK [120N011];
   German Federal Ministry of Education and Research; Hessen State Ministry
   for Higher Education, Research and the Arts within their joint support
   of the National Research Center for Applied Cyber security ATHENE;
   EUCOST project Good Brother [19121]; Federal Ministry of Education and
   Research (BMBF) of Germany [01IS18040A]
FX This research was supported in parts by the ARRS Research Programme
   P2-0250 (B)"Metrology and Biometric Systems" and the additional funding
   provided for COVID-19 related research as well as the bilateral
   ARRS-TUBITAK funded project: Low Resolution Face Recog-nition (FaceLQ),
   with TUBITAK project number 120N011. This research work has been also
   partially funded by the German Federal Ministry of Education and
   Research and the Hessen State Ministry for Higher Education, Research
   and the Arts within their joint support of the National Research Center
   for Applied Cyber security ATHENE, and EUCOST project Good Brother
   (19121). The project on which this reportis based was also partially
   funded by the Federal Ministry of Education and Research (BMBF) of
   Germany under the number 01IS18040A.
CR Abate AF, 2023, MULTIMED TOOLS APPL, V82, P11305, DOI 10.1007/s11042-022-13559-8
   Abdrakhmanova M, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21103465
   Ahmad T., 2022, P IEEECVF C COMPUTER, P3900
   Al-Sa'd M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22020418
   Albiero V, 2022, IEEE T INF FOREN SEC, V17, P127, DOI 10.1109/TIFS.2021.3135750
   Aljundi R, 2019, PROC CVPR IEEE, P11246, DOI 10.1109/CVPR.2019.01151
   Almalki KJ, 2021, IEEE INT SM C CONF, DOI 10.1109/ISC253183.2021.9562953
   Alonso-Fernandez F, 2016, PATTERN RECOGN LETT, V82, P92, DOI 10.1016/j.patrec.2015.08.026
   Alzu'bi A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10212666
   Amin Prithvi N., 2021, 12CT, P1
   [Anonymous], 2008, PUBL ACT 095 994
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], 2021, IEEECVF INT C COMPUT, DOI [10.1109/ICCVW54120.2021, DOI 10.1109/ICCVW54120.2021]
   [Anonymous], Face mask detection dataset | kaggle
   [Anonymous], AIZOOTECH FACE MASK
   [Anonymous], 2018, NEC TECH J
   [Anonymous], FACE MASK LITE DATAS
   [Anonymous], 2021, INT IEEE JOINT C BIO, DOI [10.1109/IJCB52358.2021, DOI 10.1109/IJCB52358.2021]
   Anwar A, 2020, Arxiv, DOI arXiv:2008.11104
   Ardiansyah, 2021, INT CONF INFORM COMM, P129, DOI 10.1109/ICTS52701.2021.9607897
   Arteta C, 2014, LECT NOTES COMPUT SC, V8691, P504, DOI 10.1007/978-3-319-10578-9_33
   Babnik Z, 2022, EUR SIGNAL PR CONF, P1037
   Barros P, 2021, IEEE COMPUT SOC CONF, P1226, DOI 10.1109/CVPRW53098.2021.00134
   Barros Pablo, 2020, SN Comput Sci, V1, P321, DOI 10.1007/s42979-020-00325-6
   Batagelj B, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11052070
   Best-Rowden L, 2018, IEEE T INF FOREN SEC, V13, P3064, DOI 10.1109/TIFS.2018.2799585
   Beyan Cigdem, 2020, ICMI '20: Proceedings of the 2020 International Conference on Multimodal Interaction, P24, DOI 10.1145/3382507.3418876
   Bhargava A, 2021, MULTIMED TOOLS APPL, V80, P19931, DOI 10.1007/s11042-021-10714-5
   Bingshu Wang, 2022, IEEE Transactions on Artificial Intelligence, V3, P323, DOI 10.1109/TAI.2021.3139058
   Bo Y, 2021, IEEE IMAGE PROC, P240, DOI 10.1109/ICIP42928.2021.9506047
   Bo Yang, 2020, MUM 2020: 19th International Conference on Mobile and Ubiquitous Multimedia, P335, DOI 10.1145/3428361.3432075
   Boutros F, 2021, Arxiv, DOI arXiv:2112.06592
   Boutros F, 2022, IEEE COMPUT SOC CONF, P1577, DOI 10.1109/CVPRW56347.2022.00164
   Boutros F, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051921
   Boutros F, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108473
   Boutros F, 2021, 2021 INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2021), DOI 10.1109/IJCB52358.2021.9484337
   Boutros F, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104007
   Bukaty P., 2019, The California Consumer Privacy Act (CCPA): An implementation guide
   Cabani Adnane, 2021, Smart Health (Amst), V19, P100144, DOI 10.1016/j.smhl.2020.100144
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cavazos Jacqueline G, 2021, IEEE Trans Biom Behav Identity Sci, V3, P101, DOI 10.1109/TBIOM.2020.3027269
   Chang WY, 2021, IEEE INT CONF COMP V, P1468, DOI 10.1109/ICCVW54120.2021.00170
   Chong Li, 2020, Recent Trends in Intelligent Computing, Communication and Devices. Proceedings of ICCD 2018. Advances in Intelligent Systems and Computing (AISC 1031), P277, DOI 10.1007/978-981-13-9406-5_34
   Coelho LEL, 2021, SIBGRAPI, P239, DOI 10.1109/SIBGRAPI54419.2021.00040
   Cohn JF, 1999, PSYCHOPHYSIOLOGY, V36, P35, DOI 10.1017/S0048577299971184
   Costantino Antonio, 2021, IEEE DataPort, DOI 10.21227/8ATN-GN55
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Damer N., 2019, 2019 INT C BIOMETRIC, P1
   Damer N., 2016, P BRIT MACHINE VISIO
   Damer N., 2022, P IEEECVF C COMPUTER
   Damer N, 2022, IET BIOMETRICS, V11, P512, DOI 10.1049/bme2.12077
   Damer N, 2020, LECT NOTE INFORM, VP-306
   Damer N, 2021, IET BIOMETRICS, V10, P548, DOI 10.1049/bme2.12044
   Damer N, 2018, INT CONF BIOMETR THE
   Deng HX, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11167310
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng JK, 2021, IEEE INT CONF COMP V, P1437, DOI 10.1109/ICCVW54120.2021.00165
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Dharanesh S, 2021, 2021 IEEE VIRTUAL IEEE INTERNATIONAL SYMPOSIUM ON TECHNOLOGIES FOR HOMELAND SECURITY, DOI 10.1109/HST53381.2021.9619841
   Din NU, 2020, IEEE ACCESS, V8, P44276, DOI 10.1109/ACCESS.2020.2977386
   Dosi M., 2021, 2021 16 IEEE INT C A, P1
   Drozdowski P, 2021, I W BIOMETRIC FORENS, DOI 10.1109/IWBF50991.2021.9465073
   Drozdowski Pawel, 2020, IEEE Transactions on Technology and Society, V1, P89, DOI 10.1109/TTS.2020.2992344
   Ekenel HK, 2009, LECT NOTES COMPUT SC, V5558, P299, DOI 10.1007/978-3-642-01793-3_31
   Elbishlawi S, 2020, J IMAGING, V6, DOI 10.3390/jimaging6090095
   Eraktn Mustafa Ekrem, 2021, LECT NOTE INFORM, P1
   Eyiokur F.I., 2022, SIVIP, P1
   Fan XQ, 2021, IEEE SYS MAN CYBERN, P832, DOI 10.1109/SMC52423.2021.9659271
   Fan ZZ, 2022, NEUROCOMPUTING, V472, P224, DOI 10.1016/j.neucom.2021.02.103
   Fang M., 2021, FG, P1, DOI [DOI 10.1109/FG52635.2021.9667051, 10.1109/FG52635.2021.9667051]
   Fang ML, 2022, IEEE WINT CONF APPL, P1131, DOI 10.1109/WACV51458.2022.00120
   Fang ML, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108398
   Feng S, 2020, LANCET RESP MED, V8, P434, DOI 10.1016/S2213-2600(20)30134-X
   Fiaschi L, 2012, INT C PATT RECOG, P2685
   Fischer EP, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abd3083
   Fu BY, 2022, IEEE WINT CONF APPL, P1121, DOI 10.1109/WACV51458.2022.00119
   Fu BY, 2021, IEEE INT CONF AUTOMA, DOI 10.1109/FG52635.2021.9667088
   Ou FZ, 2021, PROC CVPR IEEE, P7666, DOI 10.1109/CVPR46437.2021.00758
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Ge SM, 2017, PROC CVPR IEEE, P426, DOI 10.1109/CVPR.2017.53
   Geng MY, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2246, DOI 10.1145/3394171.3413723
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Glowacka N, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196387
   Golwalkar R., AGE DETECTION FACE M
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Han C, 2021, IEEE SIGNAL PROC LET, V28, P190, DOI 10.1109/LSP.2020.3048608
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y., NEUROCOMPUTING
   Heilweil Rebecca, 2020, Big tech companies back away from selling facial recognition to police. That's progress
   Hernandez-Ortega J, 2019, INT CONF BIOMETR
   Honari S, 2018, PROC CVPR IEEE, P1546, DOI 10.1109/CVPR.2018.00167
   Hongxu Yin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8712, DOI 10.1109/CVPR42600.2020.00874
   Hsu GSJ, 2022, IEEE ACCESS, V10, P37938, DOI 10.1109/ACCESS.2022.3160828
   Hu H, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9455952
   Hu Y., 2021, arXiv
   Huang BJ, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P4240, DOI 10.1109/ICASSP39728.2021.9413893
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Huber M, 2021, IEEE INT CONF AUTOMA, DOI 10.1109/FG52635.2021.9667081
   Hussain S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083495
   ISO/IEC, 2016, ISO IEC JTC SC37 BIO
   ISO/IEC JTC1 SC37 Biometrics, 2017, 2382372017 ISOIEC
   Jarraya SK, 2021, CMC-COMPUT MATER CON, V66, P1315, DOI 10.32604/cmc.2020.013522
   Jiang M., 2020, arXiv
   Jiang XB, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10070837
   Jiang Y., 2022, MULTIMED TOOLS APPL, P1
   Jocher Glenn, 2021, Zenodo
   Joshi Aniruddha Srinivas, 2020, 2020 12th International Conference on Computational Intelligence and Communication Networks (CICN), P435, DOI 10.1109/CICN49253.2020.9242625
   Junayed MS, 2021, IEEE INT CONF AUTOMA
   Kantarci A, 2022, Arxiv, DOI arXiv:2211.01207
   Karasugi I. Putu Agi, 2020, Proceedings of the 16th European Conference on Computer Vision (ECCV 2020) Workshops. Lecture Notes in Computer Science (LNCS 12539), P261, DOI 10.1007/978-3-030-68238-5_19
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kim J, 2005, IEEE T PATTERN ANAL, V27, P1977, DOI 10.1109/TPAMI.2005.242
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Li B., PATTERN ANAL APPL, V24
   Li C., 2018, INT S ART INT ROB, P427
   Li XL, 2021, 2021 4TH INTERNATIONAL CONFERENCE ON ROBOTICS, CONTROL AND AUTOMATION ENGINEERING (RCAE 2021), P86, DOI 10.1109/RCAE53607.2021.9638866
   Li YD, 2021, APPL INTELL, V51, P3012, DOI 10.1007/s10489-020-02100-9
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Li ZZ, 2018, IEEE T PATTERN ANAL, V40, P2935, DOI 10.1109/TPAMI.2017.2773081
   Lin SF, 2001, IEEE T SYST MAN CY A, V31, P645, DOI 10.1109/3468.983420
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Loey M, 2021, SUSTAIN CITIES SOC, V65, DOI 10.1016/j.scs.2020.102600
   Lopez-Paz D, 2017, ADV NEUR IN, V30
   van de Ven GM, 2019, Arxiv, DOI arXiv:1904.07734
   Alvarez LM, 2021, 2021 1ST INTERNATIONAL CONFERENCE IN INFORMATION AND COMPUTING RESEARCH (ICORE 2021), P139, DOI 10.1109/ICORE54267.2021.00044
   Mare T., 2021, P NEURAL INFORM PROC, P1
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Meden B, 2021, IEEE T INF FOREN SEC, V16, P4147, DOI 10.1109/TIFS.2021.3096024
   Mei T, 2021, FACEX ZOO PYTORCH TO, P1
   Meng Q, 2021, PROC CVPR IEEE, P14220, DOI 10.1109/CVPR46437.2021.01400
   Minh-Nghia Nguyen, 2021, 2021 International Conference on System Science and Engineering (ICSSE), P221, DOI 10.1109/ICSSE52999.2021.9538435
   Mishra S, 2021, IEEE INT CONF AUTOMA
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Montero D., 2021, arXiv
   Mroueh Y, 2017, PR MACH LEARN RES, V70
   Nagrath P, 2021, SUSTAIN CITIES SOC, V66, DOI 10.1016/j.scs.2020.102692
   Natarajan A, 2021, NPJ DIGIT MED, V4, DOI 10.1038/s41746-021-00493-6
   Neto P.C., 2021, P 20 INT C BIOMETRIC, VP-315, P21
   Neto P.C., 2022, COMPETITION OCCLUDED
   Neto PC, 2021, IEEE INT CONF AUTOMA, DOI 10.1109/FG52635.2021.9666792
   Neto PCP, 2022, IEEE ACCESS, V10, P86222, DOI 10.1109/ACCESS.2022.3199014
   Ngan M., 2020, Ongoing face recognition vendor test (FRVT) part6B: Face recognition accuracy with face masks using post-COVID-19algorithms, DOI [10.6028/NIST.IR.8331, DOI 10.6028/NIST.IR.8331]
   Nguyen H.M., 2020, LECT NOTES COMPUT SC, V12668, P200
   Nguyen K.-D., 2021, P 2021 IEEE EMBS INT, P1, DOI [10.1109/BHI50953.2021.9508516, DOI 10.1109/BHI50953.2021.9508516]
   Nieto-Rodríguez A, 2015, LECT NOTES COMPUT SC, V9117, P138, DOI 10.1007/978-3-319-19390-8_16
   Niu ZD, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12020190
   Ou WH, 2014, PATTERN RECOGN, V47, P1559, DOI 10.1016/j.patcog.2013.10.017
   Pan L, 2020, AM J GASTROENTEROL, V115, P766, DOI 10.14309/ajg.0000000000000620
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Peng F, 2018, MULTIMED TOOLS APPL, V77, P8883, DOI 10.1007/s11042-017-4780-0
   Perpetuini D, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18063286
   Petrovic N., PREPRINTS
   Petrovic N., 2022, Viruses, Bacteria and Fungi in the Built Environment, P251
   Puc A, 2021, EUR SIGNAL PR CONF, P830, DOI 10.23919/Eusipco47968.2020.9287219
   Purnomo A.T., SENSORS-BASEL, V21
   Qian HJ, 2021, IEEE INT CONF COMP V, P1462, DOI 10.1109/ICCVW54120.2021.00169
   Qin BS, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185236
   Qiu HB, 2022, IEEE T PATTERN ANAL, V44, P6939, DOI 10.1109/TPAMI.2021.3098962
   Queiroz Leonardo, 2021, 2021 International Conference on Information and Digital Technologies (IDT), P142, DOI 10.1109/IDT52577.2021.9497521
   Raghavendra R, 2016, INT CONF IMAG PROC
   Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924
   Razavi Moein, 2022, SN Comput Sci, V3, P27, DOI 10.1007/s42979-021-00894-0
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J., 2017, P IEEE C COMP VIS PA, P7263
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezaei M, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10217514
   Robinson JP, 2020, IEEE COMPUT SOC CONF, P1, DOI 10.1109/CVPRW50498.2020.00008
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roy Biparnak, 2020, Trans Indian Natl Acad Eng, V5, P509, DOI 10.1007/s41403-020-00157-z
   Ryan D, 2009, 2009 DIGITAL IMAGE COMPUTING: TECHNIQUES AND APPLICATIONS (DICTA 2009), P81, DOI 10.1109/DICTA.2009.22
   Sabzmeydani P, 2007, PROC CVPR IEEE, P1251
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sathyamoorthy AJ, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0259713
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sha YY, 2021, IEEE INT CONF MULTI, DOI 10.1109/ICMEW53276.2021.9456012
   Sharma Renu, 2022, ARXIV
   Shin H, 2017, ADV NEUR IN, V30
   Shorten C, 2021, J BIG DATA-GER, V8, DOI 10.1186/s40537-020-00392-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Somaldo P, 2020, 2020 IEEE 8 R10 HUMA, P1, DOI [10.1109/R10-HTC49770.2020.9357040, DOI 10.1109/R10-HTC49770.2020.9357040]
   Song LX, 2019, IEEE I CONF COMP VIS, P773, DOI 10.1109/ICCV.2019.00086
   Song LS, 2019, AAAI CONF ARTIF INTE, P2506
   Struc Vitomir, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1334, DOI 10.1109/ICPR.2010.331
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tan W., 2020, 19 IEEE INT C MACH L
   Tan WJ, 2020, J PHYS CONF SER, V1634, DOI 10.1088/1742-6596/1634/1/012085
   Terhorst P., 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), P1
   Terhorst P, 2020, PROC CVPR IEEE, P5650, DOI 10.1109/CVPR42600.2020.00569
   Tomás J, 2021, HEALTHCARE-BASEL, V9, DOI 10.3390/healthcare9081050
   Ulhaq A, 2020, IEEE ACCESS, V8, P179437, DOI 10.1109/ACCESS.2020.3027685
   Utomo Y, 2021, 3RD INTERNATIONAL CONFERENCE ON CYBERNETICS AND INTELLIGENT SYSTEMS (ICORIS 2021), P419, DOI 10.1109/ICORIS52787.2021.9649622
   Valencia IJC, 2021, IEEE INT SM C CONF, DOI 10.1109/ISC253183.2021.9562868
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Vemury Arun, 2020, BIOMETRIC RALLY RESU
   Pham VQ, 2015, IEEE I CONF COMP VIS, P3253, DOI 10.1109/ICCV.2015.372
   Vinyals O., Adv. Neural Inf. Process. Syst., V29
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vrigkas M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22030896
   W.H. Organization, 2020, ADVICE USE MASKS CON
   Wang B, 2021, IEEE T INSTRUM MEAS, V70, DOI [10.1109/TIM.2020.3018831, 10.1109/TIM.2021.3069844]
   Wang C., 2021, arXiv
   Wang K, 2021, IEEE INT CONF COMP V, P1456, DOI 10.1109/ICCVW54120.2021.00168
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang Q, 2021, IEEE T PATTERN ANAL, V43, P2141, DOI 10.1109/TPAMI.2020.3013269
   Wang WQ, 2021, IEEE INT CONF COMP V, P1450, DOI 10.1109/ICCVW54120.2021.00167
   Wang ZK, 2021, Arxiv, DOI [arXiv:2101.00784, DOI 10.48550/ARXIV.2101.00784]
   Wang ZY, 2020, Arxiv, DOI arXiv:2003.09093
   Ward RJ, 2021, IEEE SENS J, V21, P24740, DOI 10.1109/JSEN.2021.3113467
   Wen T., 2021, 2021 IEEE INT C MULT, P1
   Widjaja J.T, 2021, DEV TRUSTWORTHY COVI
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Xiangyu Ma, 2021, 2021 IEEE Power & Energy Society General Meeting (PESGM), P1, DOI 10.1109/PESGM46819.2021.9638075
   Yang DF, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134608
   Yang S, 2016, PROC CVPR IEEE, P5525, DOI 10.1109/CVPR.2016.596
   Yolcu G, 2021, SAKARYA U J SCI, V25, P1394
   Yu J, 2021, IEEE INT CONF COMP V, P1531, DOI 10.1109/ICCVW54120.2021.00178
   Zhang C, 2021, PROC CVPR IEEE, P12450, DOI 10.1109/CVPR46437.2021.01227
   Zhang K., IEEE SIGNAL PROC LET, V23
   Zhang Liping, 2022, IEEE Transactions on Biometrics, Behavior, and Identity Science, V4, P30, DOI 10.1109/TBIOM.2021.3104014
   Zhang X, 2022, PATTERN RECOGN, V124, DOI 10.1016/j.patcog.2021.108415
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zheng TY, 2017, Arxiv, DOI arXiv:1708.08197
   Zhi RC, 2020, VISUAL COMPUT, V36, P1067, DOI 10.1007/s00371-019-01707-5
NR 228
TC 8
Z9 8
U1 2
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2023
VL 130
AR 104610
DI 10.1016/j.imavis.2022.104610
EA DEC 2022
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7Y3CM
UT WOS:000914761800001
PM 36540857
OA Green Published, Bronze, Green Submitted
DA 2024-07-18
ER

PT J
AU Yu, WY
   Po, LM
   Zhao, YZ
   Zhang, YJ
   Lau, KW
AF Yu, Wing-Yin
   Po, Lai-Man
   Zhao, Yuzhi
   Zhang, Yujia
   Lau, Kin-Wai
TI FEANet: Foreground-edge-aware network with DenseASPOC for human parsing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human parsing; Semantic segmentation; Foreground-edge awareness;
   Non-local operation
ID SEGMENTATION; OBJECTS
AB Human parsing has drawn a lot of attention from the public due to its critical role in high-level computer vision applications. Recent works demonstrated the effectiveness of utilizing context module and additional information in improving the performance of human parsing. However, ambiguous objects, small scaling and occlusion problems are still the bottlenecks. In this paper, we propose a novel framework called Foreground-Edge-Aware Network (FEANet) with DenseASPOC context module to further enhance the segmentation performance for human parsing. We claim that the fusion of foreground and edge information can effectively segment occluded regions by reducing the impact of pixels occupied by non-human object parts while persevering boundaries between each class. Moreover, we introduce the Dense Atrous Spatial Pyramid Object Context (DenseASPOC) module to address the problem of small and ambiguous objects by empowering feature extraction ability with solid spatial perception and semantic context information. We conducted comprehensive experiments on various human parsing benchmarks including both single-human and multi-human parsing. Both quantitative and qualitative results show that the proposed FEANet has superiority over the current methods. Moreover, detailed ablation studies report the effectiveness of the employment on each contribution.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Yu, Wing-Yin; Po, Lai-Man; Zhao, Yuzhi; Zhang, Yujia; Lau, Kin-Wai] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
   [Lau, Kin-Wai] TCL Corp Res Co Ltd, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Yu, WY (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM wingyinyu8-c@my.cityu.edu.hk; eelmpo@cityu.edu.hk;
   yzzhao2-c@my.cityu.edu.hk; yzhang2383-c@my.cityu.edu.hk;
   kinwailau6-c@my.cityu.edu.hk
RI Zhang, Yujia/K-5056-2016
OI Zhang, Yujia/0000-0003-3991-7388; LAU, Kin Wai/0000-0001-5364-5070; YU,
   Wing Yin/0000-0002-9559-1055; Zhao, Yuzhi/0000-0001-8561-2206
CR Berman M, 2018, PROC CVPR IEEE, P4413, DOI 10.1109/CVPR.2018.00464
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fang H.-S., 2018, ARXIV180504310
   Gong K, 2018, LECT NOTES COMPUT SC, V11208, P805, DOI 10.1007/978-3-030-01225-0_47
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain M.S., 2019, ARXIV190911932
   Huang X, 2019, COMM COM INF SC, V1142, P466, DOI 10.1007/978-3-030-36808-1_51
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Leo M, 2020, INFORMATION, V11, DOI 10.3390/info11030128
   Li Qizhu, 2017, BMVC
   Li TP, 2019, IEEE IMAGE PROC, P2961, DOI [10.1109/ICIP.2019.8804412, 10.1109/icip.2019.8804412]
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Liang XD, 2017, PROC CVPR IEEE, P2175, DOI 10.1109/CVPR.2017.234
   Liang XD, 2016, PROC CVPR IEEE, P3185, DOI 10.1109/CVPR.2016.347
   Liang XD, 2016, LECT NOTES COMPUT SC, V9905, P125, DOI 10.1007/978-3-319-46448-0_8
   Liang XD, 2016, IEEE T MULTIMEDIA, V18, P1175, DOI 10.1109/TMM.2016.2542983
   Liang XD, 2015, IEEE T PATTERN ANAL, V37, P2402, DOI 10.1109/TPAMI.2015.2408360
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin Z., 2017, PROC INT C LEARN REP
   Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748
   Liu XC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P338, DOI 10.1145/3343031.3350857
   Lou ZY, 2014, IEEE T MULTIMEDIA, V16, P2110, DOI 10.1109/TMM.2014.2363936
   Luo XH, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P654, DOI 10.1145/3240508.3240634
   Luo YW, 2018, LECT NOTES COMPUT SC, V11213, P424, DOI 10.1007/978-3-030-01240-3_26
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Nie XC, 2018, LECT NOTES COMPUT SC, V11209, P519, DOI 10.1007/978-3-030-01228-1_31
   Ruan T, 2019, AAAI CONF ARTIF INTE, P4814
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Xia FT, 2016, LECT NOTES COMPUT SC, V9909, P648, DOI 10.1007/978-3-319-46454-1_39
   Yamaguchi K, 2013, IEEE I CONF COMP VIS, P3519, DOI 10.1109/ICCV.2013.437
   Yamaguchi K, 2012, PROC CVPR IEEE, P3570, DOI 10.1109/CVPR.2012.6248101
   Yang L, 2019, PROC CVPR IEEE, P364, DOI 10.1109/CVPR.2019.00045
   Yang MK, 2018, PROC CVPR IEEE, P3684, DOI 10.1109/CVPR.2018.00388
   Yuan Y, 2018, OCNET OBJECT CONTEXT
   Yuan Y., 2019, CoRR, V2019
   Zhao B, 2016, IEEE T MULTIMEDIA, V18, P1111, DOI 10.1109/TMM.2016.2537783
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao J, 2017, IEEE COMPUT SOC CONF, P1595, DOI 10.1109/CVPRW.2017.204
   Zhu B., 2018, 32 AAAI C ART INT
   Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186
NR 49
TC 4
Z9 4
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104145
DI 10.1016/j.imavis.2021.104145
EA MAR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600001
DA 2024-07-18
ER

PT J
AU Meng, CZ
   Xu, WW
AF Meng, Chengzhe
   Xu, Weiwei
TI ScPnP: A non-iterative scale compensation solution for PnP problems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Perspective-n-point; Dixon resultant; Pose estimation
ID POSE ESTIMATION; REPRESENTATION; EFFICIENT; MOTION
AB This paper presents an accurate non-iterative method for the Perspective-n-Point problem(PnP). Our main idea is to mitigate scale bias by multiplying an independent inverse average depth variable onto the object space error. The introduced variable is of order 2 in the objective function and the optimality conditions constitute a polynomial system with three third-order and one first-order unknowns. Subsequently, we employ the Dixon resultant method to compute explicit expressions of the action matrix, the eigenvalue decomposition of which determines all the roots of the problem. We further extend this scale compensation technology to sphere cameras and contribute a uniform solver to PnP problems for both camera types. Experimental results confirm that our method is reliable and more accurate than state-of-the-art PnP algorithms. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Meng, Chengzhe; Xu, Weiwei] Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang University
RP Xu, WW (corresponding author), Zhejiang Univ, State Key Lab CAD & CG, Hangzhou, Zhejiang, Peoples R China.
EM xww@cad.zju.edu.cn
FU National Key R&D Program of China [2017YFB1002600]; NSFC [61732016]
FX Wewould like to thank the anonymous reviewers for their constructive
   comments. Weiwei Xu is partially supported by National Key R&D Program
   of China (2017YFB1002600), NSFC (No. 61732016).
CR Adbel-Asiz Y.I., 1971, PHOTOGRAMM ENG ROMOT, V81, P103
   Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992
   Bartoli A, 2005, COMPUT VIS IMAGE UND, V100, P416, DOI 10.1016/j.cviu.2005.06.001
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Choi C, 2012, INT J ROBOT RES, V31, P498, DOI 10.1177/0278364912437213
   Collet A, 2009, IEEE INT CONF ROBOT, P3534
   Cox D. A., 2006, USING ALGEBRAIC GEOM, V185
   Dixon L.A., 2020, P LOND MATH SOC, Vs2-7, P49
   Ferraz L, 2014, PROC CVPR IEEE, P501, DOI 10.1109/CVPR.2014.71
   Ferraz Luis, 2014, P BRIT MACH VIS C
   Fiore PD, 2001, IEEE T PATTERN ANAL, V23, P140, DOI 10.1109/34.908965
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   HARALICK RM, 1994, INT J COMPUT VISION, V13, P331, DOI 10.1007/BF02028352
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hesch JA, 2011, IEEE I CONF COMP VIS, P383, DOI 10.1109/ICCV.2011.6126266
   HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127
   Kapur D., 1994, ISSAC'94. Proceedings of the International Symposium on Symbolic and Algebraic Computation, P99, DOI 10.1145/190347.190372
   Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1_9
   Kroeger T, 2014, LECT NOTES COMPUT SC, V8693, P1, DOI 10.1007/978-3-319-10602-1_1
   Kukelova Z, 2008, LECT NOTES COMPUT SC, V5304, P302, DOI 10.1007/978-3-540-88690-7_23
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Li SQ, 2012, IEEE T PATTERN ANAL, V34, P1444, DOI 10.1109/TPAMI.2012.41
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   Lu Yang, 1996, NONLINEAR ALGEBRAIC
   Müller M, 2013, INT J COMPUT ASS RAD, V8, P663, DOI 10.1007/s11548-013-0828-4
   Qian J, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17092073
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Schöps T, 2019, PROC CVPR IEEE, P134, DOI 10.1109/CVPR.2019.00022
   Schwartz G, 2008, PUBLIC INVESTMENT AND PUBLIC-PRIVATE PARTNERSHIPS: ADDRESSING INFRASTRUCTURE CHALLENGES AND MANAGING FISCAL RISKS, P1
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   Van Gool Luc J., BMVC 2007, P1
   Wang P, 2018, PATTERN RECOGN LETT, V108, P31, DOI 10.1016/j.patrec.2018.02.028
   Zhang LL, 2014, J VIS COMMUN IMAGE R, V25, P904, DOI 10.1016/j.jvcir.2014.02.013
   Zheng YQ, 2013, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2013.291
   Zhou LP, 2019, IEEE INT C INT ROBOT, P6245, DOI [10.1109/IROS40897.2019.8968482, 10.1109/iros40897.2019.8968482]
NR 35
TC 7
Z9 7
U1 7
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104085
DI 10.1016/j.imavis.2020.104085
EA JAN 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700006
DA 2024-07-18
ER

PT J
AU Yaghoubi, E
   Borza, D
   Neves, J
   Kumar, A
   Proença, H
AF Yaghoubi, Ehsan
   Borza, Diana
   Neves, Joao
   Kumar, Aruna
   Proenca, Hugo
TI An attention-based deep learning model for multiple pedestrian
   attributes recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pedestrian attributes recognition; Multi-task learning; Visual
   surveillance
AB The automatic characterization of pedestrians in surveillance footage is a tough challenge, particularly when the data is extremely diverse with cluttered backgrounds, and subjects are captured from varying distances, under multiple poses, with partial occlusion. Having observed that the state-of-the-art performance is still unsatisfactory, this paper provides a novel solution to the problem, with two-fold contributions: 1) considering the strong semantic correlation between the different full-body attributes, we propose a multi-task deep model that uses an element-wise multiplication layer to extract more comprehensive feature representations. In practice, this layer serves as a filter to remove irrelevant background features, and is particularly important to handle complex, cluttered data; and 2) we introduce a weighted-sum term to the loss function that not only relativizes the contribution of each task but also is crucial for performance improvement in multiple-attribute inference settings. Our experiments were performed on two well-known datasets (RAP and PETA) and point for the superiority of the proposed method with respect to the state-of-the-art. The code is available at https://github.com/EhsanYaghoubi/MAN-PAR-. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Yaghoubi, Ehsan; Proenca, Hugo] IT Inst Telecomunicacoes, Aveiro, Portugal.
   [Yaghoubi, Ehsan; Proenca, Hugo] Univ Beira Interior, Covilha, Portugal.
   [Borza, Diana; Kumar, Aruna] Tech Univ Cluj Napoca, Cluj Napoca, Romania.
   [Neves, Joao] TomiWorld, Viseu, Portugal.
C3 Universidade da Beira Interior; Technical University of Cluj Napoca
RP Yaghoubi, E (corresponding author), IT Inst Telecomunicacoes, Aveiro, Portugal.
EM Ehsan.Yaghoubi@ubi.pt
RI Borza, Diana Laura/W-7283-2019; Yaghoubi, Ehsan/AAL-6698-2021; Neves,
   João/G-6477-2016; Proença, Hugo/F-9499-2010
OI Yaghoubi, Ehsan/0000-0003-3639-266X; Neves, João/0000-0003-0139-2213;
   Proença, Hugo/0000-0003-2551-8570
FU "Fundo Europeu de Desenvolvimento Regional (FEDER), Fundo de Coesao (FC)
   and Fundo Social Europeu (FSE)" [POCI-01-0247-FEDER-033395]; Fundacao
   para a Ciencia e a Tecnologia/Ministerio da Educacao e Ciencia
   (FCT/MEC); FEDER PT2020 partnership agreement [UID/EEA/50008/2019]
FX This research is funded by the "Fundo Europeu de Desenvolvimento
   Regional (FEDER), Fundo de Coesao (FC) and Fundo Social Europeu (FSE)"
   under the "PT2020 - Portugal 2020" Program, "IT: Instituto de
   Telecomunicacoes" and "TOMI: City's Best Friend" with reference
   POCI-01-0247-FEDER-033395. Also, the work is funded by Fundacao para a
   Ciencia e a Tecnologia/Ministerio da Educacao e Ciencia (FCT/MEC)
   through national funds and, when applicable, co-funded by the FEDER
   PT2020 partnership agreement under the project UID/EEA/50008/2019).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdulnabi AH, 2015, IEEE T MULTIMEDIA, V17, P1949, DOI 10.1109/TMM.2015.2477680
   [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], ARXIV13124400
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], MASK R CNN OBJECT DE
   Ben Mabrouk A, 2018, EXPERT SYST APPL, V91, P480, DOI 10.1016/j.eswa.2017.09.029
   Chen Y., 2018, VISAPP2018
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Gkioxari G, 2015, IEEE I CONF COMP VIS, P2470, DOI 10.1109/ICCV.2015.284
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KK, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1636, DOI 10.1145/3123266.3123424
   Kumar J, 2015, PROCEDIA COMPUT SCI, V58, P486, DOI 10.1016/j.procs.2015.08.011
   Layne R, 2014, ADV COMPUT VIS PATT, P93, DOI 10.1007/978-1-4471-6296-4_5
   Li DW, 2018, IEEE INT CON MULTI
   Li DW, 2019, IEEE T IMAGE PROCESS, V28, P1575, DOI 10.1109/TIP.2018.2878349
   Li DW, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P111, DOI 10.1109/ACPR.2015.7486476
   Li QZ, 2019, AAAI CONF ARTIF INTE, P8634
   Li YN, 2016, LECT NOTES COMPUT SC, V9910, P684, DOI 10.1007/978-3-319-46466-4_41
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu P., ARXIV180809102
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Miaomiao Lou, 2019, Artificial Intelligence and Security. 5th International Conference, ICAIS 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11632), P217, DOI 10.1007/978-3-030-24274-9_19
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruder S., ABS170605098 CORR
   Sarfraz M.S., ARXIV170706089
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sudowe Patrick, 2015, ICCV, P87
   Tan Z., IEEE T IMAGE PROCESS
   Wang JY, 2017, IEEE I CONF COMP VIS, P531, DOI 10.1109/ICCV.2017.65
   Wang X., ARXIV190107474
   Yang L., ARXIV160701437
   Zhao X, 2019, AAAI CONF ARTIF INTE, P9275
   Zhu JQ, 2017, IMAGE VISION COMPUT, V58, P224, DOI 10.1016/j.imavis.2016.07.004
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
   Zhu JQ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P331, DOI 10.1109/ICCVW.2013.51
NR 43
TC 11
Z9 13
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103981
DI 10.1016/j.imavis.2020.103981
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yang, C
   Lv, ZH
AF Yang, Chun
   Lv, Zhihan
TI Gender based face aging with cycle-consistent adversarial networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face aging; Age estimation; Image-to-Image translation; Age group
   classification; Cycle-Consistent Generative Adversarial Networks;
   Subjective test
ID AGE ESTIMATION
AB Face aging is a task which referred to image synthesis, and the challenge comes from the training dataset, most existing face aging works require paired face images which is difficult to collect. Face images with various ages of the same person can be considered as unpaired images which come from different domains. The degree of aging effect can be influenced by age, gender, race and some other factors. In this paper, we are committed to studying the impact of gender on face aging problem, which involves the processing and modeling of face images.
   It has been proved that Generative Adversarial Networks(GANs) is competitive in realistic image synthesis, and many works employed Cycle-Consistent Adversarial Networks(CycleGANs) have shown the high performance in unpaired image-to-image translation.
   To overcome current difficulties and improve the performance of existing models on the face aging tasks, we proposed an innovative Gender-based training method using CycleGAN by pairwise training CycleGAN over several age groups which are grouped by age and gender. We build a constraint model based on gender discrimination to better simulate the expected aging effect of face images.
   To evaluate our works using subjective method, we have set up a quantitative evaluation mechanism with participants involved in. Compared with other similar subjective evaluation methods, our method is more objective in the demonstration of experimental results. The experimental results show that our method has a more realistic and excellent performance compared to those using CycleGAN for face age synthesis directly. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Yang, Chun; Lv, Zhihan] Qingdao Univ, Qingdao, Peoples R China.
C3 Qingdao University
RP Lv, ZH (corresponding author), Qingdao Univ, Qingdao, Peoples R China.
EM lvzhihan@gmail.com
RI Lyu, Zhihan/I-3187-2014; Lv, Zhihan/GLR-6000-2022
OI Lyu, Zhihan/0000-0003-2525-3074; Lv, Zhihan/0000-0003-2525-3074
FU National Natural Science Foundation of China [61902203]; Key Research
   and Development Plan - Major Scientific and Technological Innovation
   Projects of ShanDong Province [2019JZZY020101]
FX This work was supported by National Natural Science Foundation of China
   (No. 61902203) and Key Research and Development Plan - Major Scientific
   and Technological Innovation Projects of ShanDong Province
   (2019JZZY020101).
CR Antipov G, 2017, IEEE IMAGE PROC, P2089, DOI 10.1109/ICIP.2017.8296650
   Antipov G, 2016, IEEE COMPUT SOC CONF, P801, DOI 10.1109/CVPRW.2016.105
   Arjovsky M., 2017, ARXIV170107875
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Goodfellow IJ, 2014, ADV NEUR IN, P2672, DOI DOI 10.1145/3422622
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ignatov A, 2018, IEEE COMPUT SOC CONF, P804, DOI 10.1109/CVPRW.2018.00112
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras T., 2018, INT CONFLEARN REPRES
   Kemelmacher-Shlizerman S.M.S.I., 2014, CVPR, V1, P2
   KWON YH, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P762, DOI 10.1109/CVPR.1994.323894
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Levi G, 2015, IEEE COMPUT SOC CONF
   Li C, 2016, LECT NOTES COMPUT SC, V9907, P702, DOI 10.1007/978-3-319-46487-9_43
   Liu MY, 2017, ADV NEUR IN, V30
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Palsson S, 2018, IEEE COMPUT SOC CONF, P2165, DOI 10.1109/CVPRW.2018.00282
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Radford A., 2015, ARXIV
   Reed S, 2016, PR MACH LEARN RES, V48
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Sage A, 2018, PROC CVPR IEEE, P5879, DOI 10.1109/CVPR.2018.00616
   Salimans T., 2016, P 30 C NEUR INF PROC, P2234
   Shu XB, 2015, IEEE I CONF COMP VIS, P3970, DOI 10.1109/ICCV.2015.452
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suo JL, 2010, IEEE T PATTERN ANAL, V32, P385, DOI 10.1109/TPAMI.2009.39
   Ulyanov Dmitry, 2016, ARXIV PREPRINT
   Wang W, 2016, PROC CVPR IEEE, P2378, DOI 10.1109/CVPR.2016.261
   Zhang Z., 2017, CVPR 2017
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, P2223, DOI DOI 10.1109/ICCV.2017.244
NR 36
TC 13
Z9 14
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2020
VL 100
AR 103945
DI 10.1016/j.imavis.2020.103945
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA MY9GX
UT WOS:000558728800007
DA 2024-07-18
ER

PT J
AU Luo, RH
   Huang, HL
   Wu, WZ
AF Luo, Ronghua
   Huang, Huailin
   Wu, WeiZeng
TI Salient object detection based on backbone enhanced network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; Deep learning; Backbone network; Over-fitting
ID ATTENTION; MODEL
AB The Convolutional Neural Networks (CNNs) with encoder-decoder architecture has shown powerful ability in semantic segmentation and it has also been applied in saliency detection. In most researches, the parameters of the backbone network which have been pre-trained on the ImageNet dataset will be retrained using the new training dataset to let CNNs adapt to the new task better. But the retraining will weaken generalization of the pre-trained backbone network and result in over-fitting, especially when the scale of the new training data is not very large. To make a balance between generalization and precision, and to further improve the performance of the CNNs with encoder-decoder architecture in salient object detection, we proposed a framework with enhanced backbone network (BENet). A encoder with structure of dual backbone networks (DBNs) is adopted in BENet to extract more diverse feature maps. In addition, BENet includes a connection module based on improved Res2Net to efficiently fuse feature maps from the two backbone networks and a decoder based on weighted multi-scale feedback module (WMFM) to perform synchronous learning. Our approach is extensively evaluated on six public datasets, and experimental results show significant and consistent improvements over the state-of-the-art methods without any additional supervision. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Luo, Ronghua; Huang, Huailin] South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
   [Wu, WeiZeng] Guangzhou Zhongzhi RongTong Financial Technol Co, 9 Kelin Rd, Guangzhou 510000, Peoples R China.
C3 South China University of Technology
RP Luo, RH; Huang, HL (corresponding author), South China Univ Technol, Guangzhou Higher Educ Mega Ctr, Sch Comp Sci & Engn, Guangzhou 510006, Peoples R China.
EM rhluo@scut.edu.cn; cs_hlhuang@163.com
RI ronghua, luo/AHI-6289-2022
FU National Natural Science Foundation of China [61372140]; Guangzhou
   Municipal Science and Technology Project [201802010073]
FX This work is partially supported by the National Natural Science
   Foundation of China (No. 61372140) and Guangzhou Municipal Science and
   Technology Project (No. 201802010073).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Bi S., 2014, J IMAGE GRAPH, V2
   Borji A, 2019, COMPUT VIS MEDIA, V5, P117, DOI 10.1007/s41095-019-0149-9
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Cheng, 2018, ADV NEURAL INF PROCE, P549, DOI 10.5555/3326943.3326994.
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Elder, 2010, P IEEE C COMP VIS PA, P49, DOI [10.1109/CVPRW.2010.5543739, DOI 10.1109/CVPRW.2010.5543739]
   Fan D.-P., 2019, CORR
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Gao S.-H., 2019, ARXIV190401169
   Goldberg A. B., 2010, Advances in Neural Information Processing Systems, P757
   He JF, 2012, PROC CVPR IEEE, P3005, DOI 10.1109/CVPR.2012.6248030
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Klein DA, 2011, IEEE I CONF COMP VIS, P2214, DOI 10.1109/ICCV.2011.6126499
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li X, 2018, LECT NOTES COMPUT SC, V11219, P370, DOI 10.1007/978-3-030-01267-0_22
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Rutishauser U, 2004, PROC CVPR IEEE, P37
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang ZQ, 2019, IEEE I CONF COMP VIS, P3977, DOI 10.1109/ICCV.2019.00408
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 52
TC 7
Z9 8
U1 1
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103876
DI 10.1016/j.imavis.2020.103876
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000004
DA 2024-07-18
ER

PT J
AU Chen, Z
   Edwards, A
   Gao, YS
   Zhang, K
AF Chen, Zhong
   Edwards, Andrea
   Gao, Yongsheng
   Zhang, Kun
TI Learning discriminative subregions and pattern orders for facial gender
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Discriminative subregions; Pattern order; Chain-type SVM; Feature vector
   selection; Facial gender classification
ID LOCAL BINARY PATTERNS; FACE-RECOGNITION; FEATURES; ROBUST; CLASSIFIERS;
   SELECTION; FUSION
AB Facial image-based gender classification has been widely used in many real-world applications. Most of the existing work, however, focuses on designing sophisticated or specific feature descriptors for the entire face, which neglects the discriminative information carried by facial components and pattern order combinations. To address the issue, in this paper, we first propose a generalized texture operator, i.e., the multi-spatial multi-order interlaced pattern (MMIP) matrix, to represent the gender information possessed by the facial subregions with textural pattern orders. A chain-type support vector machine (CSVM) based feature vector selection scheme, is then developed to highlight the gender characteristics. As a result, the discriminative subregions and pattern orders are constructed as the feature representation for facial gender classification. We evaluate our proposed method on four benchmark datasets (i.e., FRGC 2.0, FERET, LFW and UND) for gender classification and demonstrate its interpretability, effectiveness and efficiency compared with state-of-the-art methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Chen, Zhong; Edwards, Andrea; Zhang, Kun] Xavier Univ Louisiana, Dept Comp Sci, New Orleans, LA 70125 USA.
   [Gao, Yongsheng] Griffith Univ, Sch Engn, Brisbane, Qld 4111, Australia.
C3 Xavier University of Louisiana; Griffith University
RP Zhang, K (corresponding author), Xavier Univ Louisiana, Dept Comp Sci, New Orleans, LA 70125 USA.
EM kzhang@xula.edu
RI Gao, Yongsheng/A-1436-2008
OI Chen, Zhong/0000-0002-7483-9699; Gao, Yongsheng/0000-0002-5382-5351
FU DOD ARO grant, USA [W911NF-15-1-0510]; NIH grants, USA [2U54MD007595-11,
   5P20GM103424-17]
FX The authors would like to thank the editor and the anonymous reviewers
   for their critical and constructive comments and suggestions. This work
   was made possible by funding from the DOD ARO grant, USA,
   #W911NF-15-1-0510, and the NIH grants, USA, 2U54MD007595-11 and
   5P20GM103424-17.
CR Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010
   Andreu Y, 2014, IMAGE VISION COMPUT, V32, P27, DOI 10.1016/j.imavis.2013.11.001
   [Anonymous], 2005, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.268
   Ballihi L, 2012, IEEE T INF FOREN SEC, V7, P1766, DOI 10.1109/TIFS.2012.2209876
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Berbar MA, 2014, VISUAL COMPUT, V30, P19, DOI 10.1007/s00371-013-0774-8
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Hadid A, 2015, PATTERN RECOGN LETT, V68, P231, DOI 10.1016/j.patrec.2015.04.017
   Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707
   Han H, 2015, IEEE T PATTERN ANAL, V37, P1148, DOI 10.1109/TPAMI.2014.2362759
   Hasnat A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON INFORMATION PROCESSING (ICIP), P581, DOI 10.1109/INFOP.2015.7489451
   Hearst MA, 1998, IEEE INTELL SYST APP, V13, P18, DOI 10.1109/5254.708428
   Hu HF, 2011, PATTERN RECOGN LETT, V32, P1526, DOI 10.1016/j.patrec.2011.06.009
   Huang G. B., 2007, Technical Report, DOI 10.1.1. 122.8268
   Jain A, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P159, DOI 10.1109/AFGR.2004.1301524
   Kim SB, 2006, IEEE T KNOWL DATA EN, V18, P1457, DOI 10.1109/TKDE.2006.180
   Lapedriza A, 2006, INT C PATT RECOG, P834
   Li B, 2012, NEUROCOMPUTING, V76, P18, DOI 10.1016/j.neucom.2011.01.028
   Li Lu, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P48, DOI 10.1109/CSIE.2009.871
   Lian X.-C., 2008, International Conference on Neural Information Processing, Part II, P647
   Lu HC, 2008, J REAL-TIME IMAGE PR, V3, P109, DOI 10.1007/s11554-008-0072-2
   Luo L, 2015, PR MACH LEARN RES, V37, P938
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Mathanker SK, 2011, COMPUT ELECTRON AGR, V77, P60, DOI 10.1016/j.compag.2011.03.008
   Merkow J., 2010, Proc. 4th IEEE Conf. on BTAS, P1, DOI DOI 10.1109/BTAS.2010.5634509
   Mery D, 2015, PATTERN RECOGN LETT, V68, P260, DOI 10.1016/j.patrec.2015.05.005
   Moeini A, 2015, IET IMAGE PROCESS, V9, P690, DOI 10.1049/iet-ipr.2014.0733
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P707, DOI 10.1109/34.1000244
   Neumann J, 2005, MACH LEARN, V61, P129, DOI 10.1007/s10994-005-1505-9
   Özbudak Ö, 2010, IEEE MEDITERR ELECT, P26, DOI 10.1109/MELCON.2010.5476346
   Pernkopf F, 2005, PATTERN RECOGN, V38, P1, DOI 10.1016/j.patcog.2004.05.012
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Qian XM, 2011, PATTERN RECOGN, V44, P2502, DOI 10.1016/j.patcog.2011.03.029
   Rai P, 2014, J VIS COMMUN IMAGE R, V25, P1118, DOI 10.1016/j.jvcir.2014.03.009
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Shih HC, 2013, PATTERN RECOGN, V46, P519, DOI 10.1016/j.patcog.2012.08.003
   Shobeirinejad A., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1509, DOI 10.1109/ICPR.2010.1118
   Tapia JE, 2013, IEEE T INF FOREN SEC, V8, P488, DOI 10.1109/TIFS.2013.2242063
   Ueki K, 2004, INT C PATT RECOG, P446, DOI 10.1109/ICPR.2004.1333798
   Yang ZG, 2006, INT C PATT RECOG, P1099
   Zhang BC, 2010, IEEE T IMAGE PROCESS, V19, P533, DOI 10.1109/TIP.2009.2035882
   Zheng J, 2011, NEUROCOMPUTING, V74, P1926, DOI 10.1016/j.neucom.2010.07.032
NR 48
TC 1
Z9 1
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 144
EP 157
DI 10.1016/j.imavis.2019.06.012
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900013
OA Bronze, Green Published
DA 2024-07-18
ER

PT J
AU He, D
   Xu, K
   Wang, DD
AF He, Di
   Xu, Ke
   Wang, Dadong
TI Design of multi-scale receptive field convolutional neural network for
   surface inspection of hot rolled steels
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE AutoEncoder; Convolutional neural networks; Defect identification; Hot
   rolled steels; Surface inspection
ID TRANSFORM
AB Due to the large intra-class variations and unbalanced training samples, the accuracy of existing algorithms used in defect classification of hot rolled steels is unsatisfactory. In this paper, a new hierarchical learning framework is proposed based on convolutional neural networks to classify hot rolled defects. Multi-scale receptive field is introduced in the new framework to extract multi-scale features, which can better represent defects than the feature maps produced by a single convolutional layer. A group of AutoEncoders are trained to reduce the dimension of the extracted multi-scale features which improve the generalization ability under insufficient training samples. Besides, to mitigate the deviation caused by fine-tuning the pre-trained model with images of different context, we add a penalty term in the loss function, which is to reconstruct the input image from the feature maps produced by the pre-trained model, to help network encode more effective and structured information. The experiments with samples captured from two hot rolled production lines showed that the proposed framework achieved a classification rate of 97.2% and 97% respectively, which are much higher than the conventional methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [He, Di; Xu, Ke] Univ Sci & Technol Beijing, Collaborat Innovat Ctr Steel Technol, Beijing 100083, Peoples R China.
   [Wang, Dadong] Commonwealth Sci & Ind Res Org, Data61, Quantitat Imaging Res Team, Canberra, ACT, Australia.
C3 University of Science & Technology Beijing; Commonwealth Scientific &
   Industrial Research Organisation (CSIRO)
RP Xu, K (corresponding author), Univ Sci & Technol Beijing, Collaborat Innovat Ctr Steel Technol, Beijing 100083, Peoples R China.
EM xuke@ustb.edu.cn
RI Xu, Ke/GZM-9218-2022; Wang, Dadong/A-5173-2009
OI Xu, Ke/0000-0003-1809-7413; Wang, Dadong/0000-0003-0409-2259
FU National Natural Science Foundation of China [51674031]
FX This work is sponsored by the National Natural Science Foundation of
   China (no. 51674031).
CR Ai YH, 2013, J IRON STEEL RES INT, V20, P80, DOI 10.1016/S1006-706X(13)60102-8
   Ai YH, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.11.113605
   [Anonymous], INCEPTION V4 INCEPTI
   Girshick, 2014, P IEEE C COMP VIS PA
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Jun Deng, 2013, AFF COMP INT INT ACI
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin M., 2013, 13124400 ARXIV, P1
   Paulraj M. P., 2010, 6 INT C SIGN PROC IT
   Redmon, 2016, P IEEE C COMP VIS PA
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suvdaa B., 2012, Int. J. Softw. Eng. Its Appl, V6, P161
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian SY, 2017, METALS-BASEL, V7, DOI 10.3390/met7080311
   Van Hulle MM, 2012, Handbook of Natural Computing, V1, P585, DOI [10.1007/978-3-540-92910-919, DOI 10.1007/978-3-540-92910-919, 10.1007/978-3-540-92910-9_19]
   Xu K, 1999, J UNIV SCI TECHNOL B, V6, P296
   Xu K., 2002, J UNIV SCI TECHNOL B, V3
   Xu K, 2015, IMAGE VISION COMPUT, V35, P23, DOI 10.1016/j.imavis.2015.01.001
   Yun JP, 2009, NDT&E INT, V42, P389, DOI 10.1016/j.ndteint.2009.01.007
NR 24
TC 31
Z9 36
U1 3
U2 37
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 12
EP 20
DI 10.1016/j.imavis.2019.06.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900002
DA 2024-07-18
ER

PT J
AU Shen, ZY
   Han, SY
   Fu, LC
   Hsiao, PY
   Lau, YC
   Chang, SJ
AF Shen, Zong-Ying
   Han, Shiang-Yu
   Fu, Li-Chen
   Hsiao, Pei-Yung
   Lau, Yo-Chung
   Chang, Sheng-Jen
TI Deep convolution neural network with scene-centric and object-centric
   information for object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Convolutional neural networks; Real-time object
   detection; Scene information
AB In recent years, Deep Convolutional Neural Network (CNN) has shown an impressive performance on computer vision field. The ability of learning feature representations from large training dataset makes deep CNN outperform traditional hand-crafted features approaches on object classification and detection. However, computations for deep CNN models are time consuming due to their high complexity, which makes it hardly applicable to real world application, such as Advance Driver Assistance System (ADAS). To reduce the computation complexity, several fast object detection frameworks in the literature have been proposed, such as SSD and YOLO. Although these kinds of method can run at real-time, they usually struggle with dealing of small objects due to the difficulty of handling smaller input image size. Based on our observation, we propose a novel object detection framework which combines the feature representations learned from object-centric and scene-centric datasets with an aim to improve the accuracy on detecting especially small objects. The experimental results on MSCOCO dataset show that our method can actually improve the detection accuracy of small objects, which leads to better overall results. We also evaluate our method on PASCAL VOC 2012 datasets, and the results show that our method not only can achieve state-of-the-art accuracy but also most importantly presents in real-time. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Shen, Zong-Ying; Han, Shiang-Yu; Fu, Li-Chen] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Hsiao, Pei-Yung] Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
   [Lau, Yo-Chung; Chang, Sheng-Jen] Chunghwa Telecom Co Ltd, Telecommun Labs, Taipei, Taiwan.
C3 National Taiwan University; National University Kaohsiung; Chunghwa
   Telecom
RP Fu, LC (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM lichen@ntu.edu.tw
FU Ministry of Science and Technology, Taiwan, ROC [108-2634-F-002-016,
   108-2634-F-002-017, 107-2218-E-002-009, 103-2221-E-390-028-MY2,
   105-2221-E-390-024-MY3]
FX This work was partially sponsored by Ministry of Science and Technology,
   Taiwan, ROC, under grant 108-2634-F-002-016, 108-2634-F-002-017,
   107-2218-E-002-009, 103-2221-E-390-028-MY2 and 105-2221-E-390-024-MY3.
CR [Anonymous], 2017, COMPUT RES REPOS
   [Anonymous], REAL TIME ALGORITHM
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2015, COMPUTER SCI
   [Anonymous], PROC CVPR IEEE
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], ILSVRC 2010
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Denton E, 2014, ADV NEUR IN, V27
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Glorot X., 2010, P INT C ART INT STAT, P249
   Herranz L, 2016, PROC CVPR IEEE, P571, DOI 10.1109/CVPR.2016.68
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K., 2014, 14091556 ARXIV
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Xiao JX, 2016, INT J COMPUT VISION, V119, P3, DOI 10.1007/s11263-014-0748-y
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xue J, 2013, INTERSPEECH, P2364
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 33
TC 13
Z9 15
U1 2
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2019
VL 85
BP 14
EP 25
DI 10.1016/j.imavis.2019.03.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HZ9DE
UT WOS:000469155200002
DA 2024-07-18
ER

PT J
AU Dou, PF
   Kakadiaris, IA
AF Dou, Pengfei
   Kakadiaris, Ioannis A.
TI Multi-view 3D face reconstruction with deep recurrent neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Recurrent neural network; Long-short term memory; 3D face
   reconstruction; Face recognition
ID MODEL
AB Image-based 3D face reconstruction has great potential in different areas, such as facial recognition, facial analysis, and facial animation. Due to the variations in image quality, single-image-based 3D face reconstruction might not be sufficient to accurately reconstruct a 3D face. To overcome this limitation, multi-view 3D face reconstruction uses multiple images of the same subject and aggregates complementary information for better accuracy. Though appealing, there are multiple challenges in practice. Among these challenges, the most significant is the difficulty to establish coherent and accurate correspondence among a set of images, especially when these images are captured under unconstrained in-the-wild condition. This work proposes a method, Deep Recurrent 3D FAce Reconstruction (DRFAR), to solve the task of multi-view 3D face reconstruction using a subspace representation of the 3D facial shape and a deep recurrent neural network that consists of both a deep convolutional neural network (DCNN) and a recurrent neural network (RNN). The DCNN disentangles the facial identity and the facial expression components for each single image independently, while the RNN fuses identity-related features from the DCNN and aggregates the identity specific contextual information, or the identity signal, from the whole set of images to estimate the facial identity parameter, which is robust to variations in image quality and is consistent over the whole set of images. Experimental results indicate significant improvement over state-of-the-art in both the accuracy and the consistency of 3D face reconstruction. Moreover, face recognition results on 11B-A with the UR2D face recognition pipeline indicate that, compared to single-view 3D face reconstruction, the proposed multi-view 3D face reconstruction algorithm can improve the face identification accuracy of UR2D by two percentage points in Rank-1 identification rate. (C) 2018 Published by Elsevier B.V.
C1 [Dou, Pengfei; Kakadiaris, Ioannis A.] Univ Houston, Dept Comp Sci, Computat Biomed Lab, Houston, TX 77204 USA.
C3 University of Houston System; University of Houston
RP Kakadiaris, IA (corresponding author), Univ Houston, Dept Comp Sci, Computat Biomed Lab, Houston, TX 77204 USA.
EM ioannisk@uh.edu
RI Dou, Pengfei/AAW-5035-2020
OI Kakadiaris, Ioannis/0000-0002-0591-1079
FU U.S. Department of Homeland Security [2015-ST-061-BSH001]
FX This material is based upon the work supported by the U.S. Department of
   Homeland Security under Grant Award Number 2015-ST-061-BSH001. This
   grant is awarded to the Borders, Trade, and Immigration (BTI) Institute:
   A DHS Center of Excellence led by the University of Houston, and
   includes support for the project "Image and Video Person Identification
   in an Operational Environment: Phase 1" awarded to the University of
   Houston. The views and conclusions contained in this document are those
   of the authors and should not be interpreted as necessarily representing
   the official policies, either expressed or implied, of the U.S.
   Department of Homeland Security.
CR [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2017, ARXIV170511136
   [Anonymous], P INT JOINT C BIOM D
   [Anonymous], 2014, PROC BRIT MACHINE VI
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], P CVPR
   [Anonymous], P IEEE INT C COMP VI
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Brunton A., 2011, 2011 Canadian Conference on Computer and Robot Vision (CRV), P347, DOI 10.1109/CRV.2011.53
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Dou P., 2017, P INT JOINT C BIOM D
   Dou R, 2017, P IEEE C COMP VIS PA, P1
   Gao Y., 2016, PMLR, P350
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kemelmacher-Shlizerman I, 2013, IEEE I CONF COMP VIS, P3256, DOI 10.1109/ICCV.2013.404
   Kemelmacher-Shlizerman I, 2011, IEEE I CONF COMP VIS, P1746, DOI 10.1109/ICCV.2011.6126439
   King DB, 2015, ACS SYM SER, V1214, P1
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Lee SJ, 2011, PATTERN RECOGN, V44, P1470, DOI 10.1016/j.patcog.2010.11.012
   Li YZ, 2016, LECT NOTES COMPUT SC, V9907, P420, DOI 10.1007/978-3-319-46487-9_26
   Liang S, 2016, LECT NOTES COMPUT SC, V9906, P360, DOI 10.1007/978-3-319-46475-6_23
   Lin YP, 2010, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2010.5539793
   Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pascanu R., 2013, P INT C MACH LEARN A, P1
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Rana R., 2016, ARXIV161207778
   Richardson E., 2017, P IEEE C COMP VIS PA, P1
   Richardson E, 2016, INT CONF 3D VISION, P460, DOI 10.1109/3DV.2016.56
   Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455
   Roth J, 2015, PROC CVPR IEEE, P2606, DOI 10.1109/CVPR.2015.7298876
   Sánchez-Escobedo D, 2016, COMPUT VIS IMAGE UND, V142, P111, DOI 10.1016/j.cviu.2015.08.012
   Snape P, 2015, PROC CVPR IEEE, P91, DOI 10.1109/CVPR.2015.7298604
   Xiong L., 2017, CoRR, Vabs/1704.00438
   Yang C, 2013, IEEE IMAGE PROC, P3617, DOI 10.1109/ICIP.2013.6738746
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zeng D, 2017, IMAGE VISION COMPUT, V58, P193, DOI 10.1016/j.imavis.2016.03.001
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 42
TC 28
Z9 29
U1 0
U2 37
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2018
VL 80
BP 80
EP 91
DI 10.1016/j.imavis.2018.09.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HF6VQ
UT WOS:000454376800005
DA 2024-07-18
ER

PT J
AU Madadi, M
   Escalera, S
   Carruesco, A
   Andujar, C
   Baró, X
   Gonzàlez, J
AF Madadi, Meysam
   Escalera, Sergio
   Carruesco, Alex
   Andujar, Carlos
   Baro, Xavier
   Gonzalez, Jordi
TI Top-down model fitting for hand pose recovery in sequences of depth
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Hand pose recovery; Shape description; Depth image; Hand segmentation;
   Temporal modeling
AB State-of-the-art approaches on hand pose estimation from depth images have reported promising results under quite controlled considerations. In this paper we propose a two-step pipeline for recovering the hand pose from a sequence of depth images. The pipeline has been designed to deal with images taken from any viewpoint and exhibiting a high degree of finger occlusion. In a first step we initialize the hand pose using a part-based model, fitting a set of hand components in the depth images. In a second step we consider temporal data and estimate the parameters of a trained bilinear model consisting of shape and trajectory bases. We evaluate our approach on a new created synthetic hand dataset along with NYU and MSRA real datasets. Results demonstrate that the proposed method outperforms the most recent pose recovering approaches, including those based on CNNs. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Madadi, Meysam; Escalera, Sergio; Baro, Xavier; Gonzalez, Jordi] Comp Vis Ctr, Edifici 0,Campus UAB, Barcelona 08193, Catalonia, Spain.
   [Madadi, Meysam; Gonzalez, Jordi] UAB, Dept Comp Sci, Bellaterra 08193, Catalonia, Spain.
   [Escalera, Sergio] Univ Barcelona, Dept Math & Informat, Catalonia, Spain.
   [Carruesco, Alex; Andujar, Carlos] UPC BarcelonaTech, ViRVIG Moving Res Grp, Barcelona, Spain.
   [Baro, Xavier] Univ Oberta Catalunya, Catalonia, Spain.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Autonomous University of Barcelona; University of Barcelona;
   Universitat Politecnica de Catalunya; UOC Universitat Oberta de
   Catalunya
RP Madadi, M (corresponding author), Comp Vis Ctr, Edifici 0,Campus UAB, Barcelona 08193, Catalonia, Spain.; Madadi, M (corresponding author), UAB, Dept Comp Sci, Bellaterra 08193, Catalonia, Spain.
EM mmadadi@cvc.uab.es
RI Gonzàlez, Jordi/I-1812-2015; madadi, meysam/AAA-5358-2020; Escalera,
   Sergio/L-2998-2015; Baró, Xavier/A-4064-2011
OI Gonzàlez, Jordi/0000-0001-8033-0306; madadi, meysam/0000-0002-7384-5712;
   Baró, Xavier/0000-0001-5338-3007
FU MINECO/FEDER, UE [TIN2016-74946-P, TIN2015-65464-R]; CERCA
   Programme/Generalitat de Catalunya; NVIDIA Corporation
FX This work has been supported by TIN2016-74946-P and TIN2015-65464-R
   (MINECO/FEDER, UE) and CERCA Programme/Generalitat de Catalunya. We
   gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the GPU used for this research.
CR Akhter I, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2159516.2159523
   [Anonymous], 2016, CVPR
   [Anonymous], 2015, ICCV
   [Anonymous], ENCY MACHINE LEARNIN, DOI DOI 10.1007/978-0-387-30164-8_630
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cruz-Neira C., 1993, Computer Graphics Proceedings, P135, DOI 10.1145/166117.166134
   CRUZNEIRA C, 1992, COMMUN ACM, V35, P64, DOI 10.1145/129888.129892
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Gong W., 2016, SENSORS, V16
   Keskin C, 2012, LECT NOTES COMPUT SC, V7577, P852, DOI 10.1007/978-3-642-33783-3_61
   Kondori FA, 2015, PATTERN RECOGN LETT, V66, P91, DOI 10.1016/j.patrec.2015.03.013
   Neverova N, 2017, COMPUT VIS IMAGE UND, V164, P56, DOI 10.1016/j.cviu.2017.10.006
   Oberweger M., 2015, CV WINT WORKSH
   Oberweger M, 2015, IEEE I CONF COMP VIS, P3316, DOI 10.1109/ICCV.2015.379
   Oikonomidis I, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.101
   PALADINI M, 2010, EUR C COMP VIS, V6312, P15
   Perez-Sala X, 2014, SENSORS-BASEL, V14, P4189, DOI 10.3390/s140304189
   Qian Chen., 2014, CVPR
   Roditakis K., 2017, BMVC
   Rogez G., 2015, 1 PERSON POSE RECOGN
   SHARP T, 2015, ACM, P3633, DOI DOI 10.1145/2702123.2702179
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Shu X., 2014, CVPR, P23
   Sinha A, 2016, PROC CVPR IEEE, P4150, DOI 10.1109/CVPR.2016.450
   Sridhar S., 2013, INTERACTIVE MARKERLE
   Sun X., 2015, CASCADED HAND POSE R
   Supancic J.S., 2015, Depth-based hand pose estimation: methods, data, and challenges
   Tagliasacchi A, 2015, COMPUT GRAPH FORUM, V34, P101, DOI 10.1111/cgf.12700
   Tan DJ, 2016, PROC CVPR IEEE, P5610, DOI 10.1109/CVPR.2016.605
   Tang D., 2014, LATENT REGRESSION FO
   Tang DH, 2013, IEEE I CONF COMP VIS, P3224, DOI 10.1109/ICCV.2013.400
   TANG DH, 2015, P IEEE INT C COMP VI, P3325, DOI DOI 10.1109/ICCV.2015.380
   Tao L, 2013, DEFORMABLE SHAPE REC
   Taylor J, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925965
   Tkach A, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980226
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   Wan C., 2017, CROSSING NETS DUAL G
   Xia L., 2012, P IEEE C COMPUTER VI
   Xu C, 2013, IEEE I CONF COMP VIS, P3456, DOI 10.1109/ICCV.2013.429
   Ye Q, 2016, LECT NOTES COMPUT SC, V9912, P346, DOI 10.1007/978-3-319-46484-8_21
   Yuan S., 2018, HAND POSE ESTIMATION
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zhou F, 2014, LECT NOTES COMPUT SC, V8694, P62, DOI 10.1007/978-3-319-10599-4_5
   Zhou X., 2016, MODEL BASED DEEP HAN
NR 44
TC 7
Z9 8
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 63
EP 75
DI 10.1016/j.imavis.2018.09.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800006
OA Green Published
DA 2024-07-18
ER

PT J
AU Tsai, YH
   Lee, YC
   Ding, JJ
   Chang, RY
   Hsu, MC
AF Tsai, Yu-Hsuan
   Lee, Yih-Cherng
   Ding, Jian-Jiun
   Chang, Ronald Y.
   Hsu, Ming-Chen
TI Robust in-plane and out-of-plane face detection algorithm using frontal
   face detector and symmetry extension
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face detection; In-plane rotations; Out-of-plane rotation; Symmetry
   extension; Superpixel based face candidate
ID SKIN COLOR; EFFICIENT
AB Face detection plays an important role in many computer vision applications. In recent years, much research has focused on extending the well-established Adaboost face detector algorithm for multi-view face detection. However, detecting in-plane and out-of-plane rotated faces simultaneously is still a challenging task today. In this paper, a very robust multi-view face detection algorithm, with its core functionality based on frontal face detection, is proposed to simultaneously detect in-plane and out-of-plane rotated faces. Moreover, only the training data in the frontal face is needed and we do not require the training data from different in-plane or out-of-plane rotation angles. In the proposed algorithm, first, techniques such as the skin filter and entropy rate superpixels (ERSs) are applied to obtain face candidates. Then, angle compensation and refinement are applied to improve the accuracy of face detection in the in-plane case. Moreover, the symmetry extension technique, i.e., extending the face candidate with its flipped version to create a face similar to the frontal one, is applied to detect out-of-plane faces without the need of training data. Simulations on the FEI, Pointing'04, BaoFace, Group, Utrecht, and WWW datasets demonstrate the proposed algorithm's effectiveness and superior performance as compared to state-of-the-art face detection methods. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Tsai, Yu-Hsuan; Lee, Yih-Cherng; Ding, Jian-Jiun; Hsu, Ming-Chen] Natl Taiwan Univ, Grad Inst Commun Engn, Taipei, Taiwan.
   [Chang, Ronald Y.] Acad Sinica, Res Ctr Informat Technol Innovat, Taipei, Taiwan.
C3 National Taiwan University; Academia Sinica - Taiwan
RP Ding, JJ (corresponding author), Natl Taiwan Univ, Grad Inst Commun Engn, Taipei, Taiwan.
EM r04942105@ntu.edu.tw; d04942009@ntu.edu.tw; jjding@ntu.edu.tw;
   rchang@citi.sinica.edu.tw; anong9420@gmail.com
RI Chang, Ronald Y./ABH-9162-2020
OI Chang, Ronald Y./0000-0003-4620-6824
FU Ministry of Science and Technology, Taiwan, ROC [103-2221-E-002-121-MY3]
FX This work was supported by Ministry of Science and Technology, Taiwan,
   ROC, under the contract of 103-2221-E-002-121-MY3.
CR [Anonymous], BAO FACE DATABASE FA
   [Anonymous], 2003, P GRAPHICON 2003
   Ban Y, 2014, PATTERN RECOGN, V47, P1573, DOI 10.1016/j.patcog.2013.11.005
   Buciu I, 2006, SIGNAL PROCESS, V86, P2364, DOI 10.1016/j.sigpro.2005.11.005
   Cevikalp H, 2012, PROC CVPR IEEE, P3138, DOI 10.1109/CVPR.2012.6248047
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Chen JS, 2015, IEEE SIGNAL PROC LET, V22, P90, DOI 10.1109/LSP.2014.2347419
   Cheng G, 2016, IEEE T GEOSCI REMOTE, V54, P7405, DOI 10.1109/TGRS.2016.2601622
   Cheng HD, 2004, DIGIT SIGNAL PROCESS, V14, P158, DOI 10.1016/j.dsp.2003.07.002
   da Silva RDC, 2015, ICIMCO 2015 PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, VOL. 2, P210
   Davis L. S., 2017, P IEEE INT C COMPUTE
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Fu Y., 2010, Bioinformatics and Biomedical Engineering (ICBBE), 2010 4th International Conference, P1
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Ghiasi G, 2014, PROC CVPR IEEE, P1899, DOI 10.1109/CVPR.2014.306
   Ghimire D, 2013, J INF PROCESS SYST, V9, P141, DOI 10.3745/JIPS.2013.9.1.141
   Gourier N., 2004, P POINT ICPR INT WOR
   Han D, 2014, INT CONF ADV COMMUN, P682, DOI 10.1109/ICACT.2014.6779050
   Jalil A., 2006, IEEE INT C ENG INT S, P1
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Ko H. Y., 2016, APSIPA ASC, P1
   Liao SC, 2016, IEEE T PATTERN ANAL, V38, P211, DOI 10.1109/TPAMI.2015.2448075
   Liu SS, 2012, INT CONF CLOUD COMPU, P56, DOI 10.1109/CCIS.2012.6664367
   Marín-Jiménez MJ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.22
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Negri P, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/782432
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Orozco J, 2015, IMAGE VISION COMPUT, V42, P47, DOI 10.1016/j.imavis.2015.07.002
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pai YT, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1545, DOI 10.1109/ICME.2006.262838
   Powers DMW, 2020, J MACH LEARN TECHNOL, P37, DOI DOI 10.9735/2229-3981
   Seshadrinathan M., 2003, VID IM PROC MULT COM, V1, P405
   Thomaz CE, 2010, IMAGE VISION COMPUT, V28, P902, DOI 10.1016/j.imavis.2009.11.005
   Tsai CH, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P119, DOI 10.1109/ICDSP.2016.7868528
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yang B., 2014, PROC IEEE INT JOINT, P1
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zuo F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/736508
NR 40
TC 7
Z9 7
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2018
VL 78
BP 26
EP 41
DI 10.1016/j.imavis.2018.07.003
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV5LO
UT WOS:000446143900003
DA 2024-07-18
ER

PT J
AU Li, H
   Wang, P
   You, MY
   Shen, CH
AF Li, Hui
   Wang, Peng
   You, Mingyu
   Shen, Chunhua
TI Reading car license plates using deep neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Car plate detection and recognition; Convolutional neural networks;
   Recurrent neural networks; LSTM
ID CHARACTER SEGMENTATION; RECOGNITION; EXTRACTION; LOCALIZATION; ALGORITHM
AB In this work, we tackle the problem of car license plate detection and recognition in natural scene images based on the powerful deep neural networks (DNNs). Firstly, a 37-class convolutional neural network (CNN) is trained to detect characters in an image, which leads to a high recall compared with a binary text/nontext classifier. False positives are then eliminated effectively by a plate/non-plate CNN classifier. As to the license plate recognition, we regard the character string reading as a sequence labeling problem. Recurrent neural networks (RNNs) with long short-term memory (LSTM) are trained to recognize the sequential features extracted from the whole license plate via CNNs. The main advantage of this approach is that it is segmentation free. By exploring contextual information and avoiding errors caused by segmentation, this method performs better than conventional methods and achieves state-of-the-art recognition accuracy. (C) 2018 Elsevier B.V. All rights reserved.
C1 [You, Mingyu] Tongji Univ, Dept Control Sci & Engn, Shanghai 201804, Peoples R China.
   [Li, Hui; Wang, Peng; Shen, Chunhua] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
C3 Tongji University; University of Adelaide
RP You, MY (corresponding author), Tongji Univ, Dept Control Sci & Engn, Shanghai 201804, Peoples R China.
EM myyou@tongji.edu.cn
FU ARC Future Fellowship [FT120100969]
FX This work was in part supported by ARC Future Fellowship grant
   FT120100969.
CR Anagnostopoulos CNE, 2006, IEEE T INTELL TRANSP, V7, P377, DOI 10.1109/TITS.2006.880641
   Anagnostopoulos CNE, 2008, IEEE T INTELL TRANSP, V9, P377, DOI 10.1109/TITS.2008.922938
   Bai HL, 2004, INT C PATT RECOG, P831, DOI 10.1109/ICPR.2004.1334387
   Chen R., 2012, P INT C APPL PHYS IN
   Deb K, 2008, 2008 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS, VOLS 1-4, P600
   Du S, 2013, IEEE T CIRC SYST VID, V23, P322, DOI 10.1109/TCSVT.2012.2203741
   Giannoukos I, 2010, PATTERN RECOGN, V43, P3866, DOI 10.1016/j.patcog.2010.06.008
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Graves  A., 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Graves A, 2009, IEEE T PATTERN ANAL, V31, P855, DOI 10.1109/TPAMI.2008.137
   Guo JM, 2008, IEEE T VEH TECHNOL, V57, P1417, DOI 10.1109/TVT.2007.909284
   Hao Wooi Lim, 2010, 2010 IEEE Conference on Sustainable Utilization and Development in Engineering and Technology (STUDENT 2010), P95, DOI 10.1109/STUDENT.2010.5686998
   He P., 2015, TECHNICAL REPORT
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Jaderberg M, 2014, LECT NOTES COMPUT SC, V8692, P512, DOI 10.1007/978-3-319-10593-2_34
   Jia WJ, 2007, J NETW COMPUT APPL, V30, P1324, DOI 10.1016/j.jnca.2006.09.010
   Jiao JB, 2009, PATTERN RECOGN, V42, P358, DOI 10.1016/j.patcog.2008.08.016
   Le WC, 2006, INT C PATT RECOG, P324
   Li B, 2013, IEEE T INTELL TRANSP, V14, P1690, DOI 10.1109/TITS.2013.2267054
   Lin KH, 2010, IEEE IMAGE PROC, P3945, DOI 10.1109/ICIP.2010.5649878
   Lipton Z. C., 2015, ARXIV
   Lixia Liu, 2010, Proceedings of the 2010 Seventh International Conference on Computer Graphics, Imaging and Visualization (CGIV 2010), P157, DOI 10.1109/CGIV.2010.32
   Llorens D, 2005, LECT NOTES COMPUT SC, V3522, P571
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Rasheed S, 2012, LECT NOTES ENG COMP, P199
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Shuang Qiao, 2010, Proceedings of the 2010 Fifth International Conference on Frontier of Computer Science and Technology (FCST 2010), P489, DOI 10.1109/FCST.2010.75
   Su BL, 2015, LECT NOTES COMPUT SC, V9003, P35, DOI 10.1007/978-3-319-16865-4_3
   Sutskever I., 2014, P NEUR INF P SYST
   Tan JL, 2013, IEEE IMAGE PROC, P4549, DOI 10.1109/ICIP.2013.6738937
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang K., 2011, P IEEE INT C COMP VI
   Wang T, 2012, INT C PATT RECOG, P3304
   Wen Y, 2011, IEEE T INTELL TRANSP, V12, P830, DOI 10.1109/TITS.2011.2114346
   Yoon Y, 2011, IEEE SYS MAN CYBERN, P2192, DOI 10.1109/ICSMC.2011.6084002
   Yu S., 2015, PATTERN RECOGN, V48
   Zheng LH, 2013, J COMPUT SYST SCI, V79, P245, DOI 10.1016/j.jcss.2012.05.006
   Zhou WG, 2012, IEEE T IMAGE PROCESS, V21, P4269, DOI 10.1109/TIP.2012.2199506
NR 41
TC 69
Z9 79
U1 2
U2 81
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2018
VL 72
BP 14
EP 23
DI 10.1016/j.imavis.2018.02.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GE4DI
UT WOS:000431164100002
DA 2024-07-18
ER

PT J
AU Zhou, DF
   Frémont, V
   Quost, B
   Dai, YC
   Li, HD
AF Zhou, Dingfu
   Fremont, Vincent
   Quost, Benjamin
   Dai, Yuchao
   Li, Hongdong
TI Moving object detection and segmentation in urban environments from a
   moving platform
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Moving object detection; Ego-motion uncertainty; Motion segmentation
ID ACCURATE; SLAM
AB This paper proposes an effective approach to detect and segment moving objects from two time-consecutive stereo frames, which leverages the uncertainties in camera motion estimation and in disparity computation. First, the relative camera motion and its uncertainty are computed by tracking and matching sparse features in four images. Then, the motion likelihood at each pixel is estimated by taking into account the ego-motion uncertainty and disparity in computation procedure. Finally, the motion likelihood, color and depth cues are combined in the graph-cut framework for moving object segmentation. The efficiency of the proposed method is evaluated on the KITTI benchmarking datasets, and our experiments show that the proposed approach is robust against both global (camera motion) and local (optical flow) noise. Moreover, the approach is dense as it applies to all pixels in an image, and even partially occluded moving objects can be detected successfully. Without dedicated tracking strategy, our approach achieves high recall and comparable precision on the KITTI benchmarking sequences. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Zhou, Dingfu; Fremont, Vincent; Quost, Benjamin] Univ Technol Compiegne, Sorbonne Univ, CNRS, UMR 7253,Heudiasyc CS 60319, F-60203 Compiegne, France.
   [Zhou, Dingfu; Dai, Yuchao; Li, Hongdong] Australian Natl Univ, Res Sch Engn, Canberra, ACT, Australia.
   [Li, Hongdong] ARC Ctr Excellence Robot Vis, Brisbane, Qld, Australia.
C3 Universite de Technologie de Compiegne; Centre National de la Recherche
   Scientifique (CNRS); Sorbonne Universite; Australian National
   University; Australian Centre for Robotic Vision
RP Zhou, DF (corresponding author), Univ Technol Compiegne, Sorbonne Univ, CNRS, UMR 7253,Heudiasyc CS 60319, F-60203 Compiegne, France.; Zhou, DF (corresponding author), Australian Natl Univ, Res Sch Engn, Canberra, ACT, Australia.
EM dingfuzhou@gmail.com
RI Zhou, Dingfu/AAM-9192-2021; Dai, Yuchao/F-7832-2015
OI Dai, Yuchao/0000-0002-4432-7406; li, hongdong/0000-0003-4125-1554;
   FREMONT, Vincent/0000-0002-1627-2241
FU China Scholarship Council
FX This work was carried out within the framework of the Equipex ROBOTEX
   (ANR-10- EQPX-44-01). Dingfu Zhou was sponsored by the China Scholarship
   Council for 3.5 year's PhD study at HEUDIASYC laboratory in University
   of Technology of Compiegne.
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   [Anonymous], 2013, INT J ROBOT RES IJRR
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], P AS C COMP VIS, DOI DOI 10.1007/978-3-642-19315-6_3
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Bradski G., 2008, LEARNING OPENCV
   Bugeau A, 2009, COMPUT VIS IMAGE UND, V113, P459, DOI 10.1016/j.cviu.2008.11.005
   Clarke John C., 1998, 216198 U OXF DEP ENG, V2161, P98
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Geiger A, 2011, IEEE INT VEH SYM, P963, DOI 10.1109/IVS.2011.5940405
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   HARALICK RM, 2000, PERFORMANCE CHARACTE, P95
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Hoiem D, 2008, INT J COMPUT VISION, V80, P3, DOI 10.1007/s11263-008-0137-5
   Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46
   Hu ZC, 2005, 2005 IEEE Intelligent Vehicles Symposium Proceedings, P48
   Irani M, 1998, IEEE T PATTERN ANAL, V20, P577, DOI 10.1109/34.683770
   Kitt B., 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P1396, DOI 10.1109/ITSC.2010.5625265
   Kundu A, 2011, IEEE I CONF COMP VIS, P2080, DOI 10.1109/ICCV.2011.6126482
   Kundu A, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P4306, DOI 10.1109/IROS.2009.5354227
   Labayrade R, 2002, IV'2002: IEEE INTELLIGENT VEHICLE SYMPOSIUM, PROCEEDINGS, P646
   Lenz P, 2011, IEEE INT VEH SYM, P926, DOI 10.1109/IVS.2011.5940558
   Liang Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3033, DOI 10.1109/CVPR.2011.5995480
   Liu Ce, 2009, THESIS
   Mahalanobis P. C., 1936, P NATL I SCI INDIA, V2, P49
   Moqqaddem S., 2012, CURR ADV STEREO VIS, P161
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Namdev RK, 2012, IEEE INT CONF ROBOT, P4092, DOI 10.1109/ICRA.2012.6224800
   Rabe C, 2010, LECT NOTES COMPUT SC, V6314, P582, DOI 10.1007/978-3-642-15561-1_42
   Romero-Cano V, 2013, IEEE INT VEH SYM, P499, DOI 10.1109/IVS.2013.6629517
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Song SY, 2016, IEEE T PATTERN ANAL, V38, P730, DOI 10.1109/TPAMI.2015.2469274
   Talukder A., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P3718
   Vogel C, 2015, INT J COMPUT VISION, V115, P1, DOI 10.1007/s11263-015-0806-0
   Wedel A, 2011, STEREO SCENE FLOW FOR 3D MOTION ANALYSIS, P1, DOI 10.1007/978-0-85729-965-9
   Yang Z, 2008, INT C COMMUN CIRCUIT, P801
   Zhou DF, 2013, CONF CYBERN INTELL S, P24, DOI 10.1109/ICCIS.2013.6751573
   Zhou DF, 2014, IEEE INT VEH SYM, P1332, DOI 10.1109/IVS.2014.6856422
   Zivkovic Z, 2004, INT C PATT RECOG, P28, DOI 10.1109/ICPR.2004.1333992
NR 41
TC 31
Z9 34
U1 0
U2 22
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2017
VL 68
SI SI
BP 76
EP 87
DI 10.1016/j.imavis.2017.07.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FR9UP
UT WOS:000419418900008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ma, YX
   Guo, YL
   Lei, YJ
   Lu, M
   Zhang, J
AF Ma, Yanxin
   Guo, Yulan
   Lei, Yinjie
   Lu, Min
   Zhang, Jun
TI Efficient rotation estimation for 3D registration and global
   localization in structured point clouds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Structured point clouds; Small overlaps; Registration; Global
   localization; ICP; Direction angle
ID OBJECT RECOGNITION
AB Fully automatic 3D point cloud registration for structured scenes is a highly challenging task. In this paper, an efficient rotation estimation algorithm is proposed for point clouds of structured scenes. This algorithm fully employs the geometric information of structured environment. For rotation estimation, a direction angle is defined for a point cloud and then the rotation matrix is obtained by comparing the difference between the distributions of angles. The proposed rotation estimation algorithm is used for both 3D registration and global localization. To conduct a full 3D registration, the translation parameters are estimated by aligning the centers of the corresponding points while the rotation parameters are estimated by the proposed algorithm. For global localization, a translation estimation algorithm is proposed using projection information. The point clouds are projected onto the orthogonal plane and template matching is performed on the projection images to calculate the translation vector. Experiments have been conducted on two datasets. Experimental results demonstrate that the proposed algorithm outperforms the state-of-the-art approaches in terms of both accuracy, computational efficiency and robustness. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Ma, Yanxin; Guo, Yulan; Lu, Min; Zhang, Jun] Natl Univ Def Technol, Coll Elect Sci & Engn, Changsha, Hunan, Peoples R China.
   [Lei, Yinjie] Sichuan Univ, Coll Elect & Informat Engn, Chengdu, Sichuan, Peoples R China.
   [Guo, Yulan] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
C3 National University of Defense Technology - China; Sichuan University;
   Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Guo, YL (corresponding author), Natl Univ Def Technol, Coll Elect Sci & Engn, Changsha, Hunan, Peoples R China.
EM mayanxin@nudt.edu.cn; yulan.guo@nudt.edu.cn; yinjie@scu.edu.cn;
   lumin@nudt.edu.cn; zj67068@sina.com
RI Lu, min/JPL-4028-2023; guo, yu/GQZ-1392-2022
OI Zhou, Pei/0000-0002-3885-6512
FU National Natural Science Foundation of China [61602499, 61601488,
   61471371, 61403265]; National Postdoctoral Program for Innovative
   Talents [BX201600172]; Science and Technology Plan of Sichuan Province
   [2015SZ0226]
FX This work was supported by the National Natural Science Foundation of
   China (Nos. 61602499, 61601488, 61471371, 61403265), the National
   Postdoctoral Program for Innovative Talents (No. BX201600172), and the
   Science and Technology Plan of Sichuan Province (No. 2015SZ0226).
CR Andreasson H, 2010, ROBOT AUTON SYST, V58, P157, DOI 10.1016/j.robot.2009.09.011
   [Anonymous], 2006, 2006 IEEE COMPUTER S
   [Anonymous], 2011, P INT S MIX AUGM REA
   Bazin JC, 2010, COMPUT VIS IMAGE UND, V114, P254, DOI 10.1016/j.cviu.2009.04.006
   Bazin J.-C., 2012, ASIAN C COMPUTER VIS, P539
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Biswas J., 2012, 2012 IEEE International Conference on Robotics and Automation (ICRA), P1697, DOI 10.1109/ICRA.2012.6224766
   Bustos AP, 2014, PROC CVPR IEEE, P3930, DOI 10.1109/CVPR.2014.502
   Castle RO, 2010, IMAGE VISION COMPUT, V28, P1548, DOI 10.1016/j.imavis.2010.03.009
   Chen K, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661239
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Evangelidis GD, 2014, LECT NOTES COMPUT SC, V8695, P109, DOI 10.1007/978-3-319-10584-0_8
   Fang F, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P1541, DOI 10.1109/IROS.2006.282038
   Fox D, 1999, J ARTIF INTELL RES, V11, P391, DOI 10.1613/jair.616
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Granger S., 2002, P 7 EUR C COMP VIS E, V4, P69
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Guo YL, 2015, IEEE T INSTRUM MEAS, V64, P683, DOI 10.1109/TIM.2014.2358131
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Guo YL, 2014, IEEE T MULTIMEDIA, V16, P1377, DOI 10.1109/TMM.2014.2316145
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9
   Hernandez M, 2015, IMAGE VISION COMPUT, V36, P61, DOI 10.1016/j.imavis.2014.12.004
   Holz D, 2016, ADV INTELL SYST, V302, P1583, DOI 10.1007/978-3-319-08338-4_114
   Hoppe H., 1992, COMPUT GRAPH, V26, P2, DOI DOI 10.1145/142920.134011
   Jian B, 2011, IEEE T PATTERN ANAL, V33, P1633, DOI 10.1109/TPAMI.2010.223
   Kerl C, 2015, IEEE I CONF COMP VIS, P2264, DOI 10.1109/ICCV.2015.261
   Labbé M, 2014, IEEE INT C INT ROBOT, P2661, DOI 10.1109/IROS.2014.6942926
   Liu YH, 2006, IMAGE VISION COMPUT, V24, P762, DOI 10.1016/j.imavis.2006.01.009
   Lu M, 2016, IEEE GEOSCI REMOTE S, V13, P162, DOI 10.1109/LGRS.2015.2504268
   Ma Y., 2016, MICROWAVE S IMS, P1
   Ma YX, 2016, INT GEOSCI REMOTE SE, P6680, DOI 10.1109/IGARSS.2016.7730744
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Nascimento ER, 2012, IEEE INT C INT ROBOT, P1720, DOI 10.1109/IROS.2012.6385693
   Or-El R, 2015, PROC CVPR IEEE, P5407, DOI 10.1109/CVPR.2015.7299179
   Pomerleau F, 2013, AUTON ROBOT, V34, P133, DOI 10.1007/s10514-013-9327-2
   Pomerleau F, 2012, INT J ROBOT RES, V31, P1705, DOI 10.1177/0278364912458814
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Rusu RB, 2008, ROBOT AUTON SYST, V56, P927, DOI 10.1016/j.robot.2008.08.005
   SCHIELE B, 1994, IEEE INT CONF ROBOT, P1628, DOI 10.1016/0921-8890(94)90023-X
   Scrafin J, 2015, IEEE INT C INT ROBOT, P742, DOI 10.1109/IROS.2015.7353455
   Segal A., 2009, GENERALIZED ICP ROBO
   Strasdat H, 2012, IMAGE VISION COMPUT, V30, P65, DOI 10.1016/j.imavis.2012.02.009
   Tamaki T., 2010, Proceedings 2010 First International Conference on Networking and Computing (ICNC 2010), P179, DOI 10.1109/IC-NC.2010.60
   Yang JL, 2013, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2013.184
   Yu F, 2015, PROC CVPR IEEE, P1722, DOI 10.1109/CVPR.2015.7298781
NR 47
TC 10
Z9 10
U1 1
U2 38
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2017
VL 67
BP 52
EP 66
DI 10.1016/j.imavis.2017.09.003
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FM3DF
UT WOS:000414883800005
DA 2024-07-18
ER

PT J
AU Guo, J
   Cai, S
   Wu, ZH
   Liu, YC
AF Guo, Juan
   Cai, Shen
   Wu, Zhanhao
   Liu, Yuncai
TI A versatile homography computation method based on two real points
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camera calibration; Homography; Circular points; Pose estimation;
   Hyperbolic rotation; Rectangular hyperbolic points
AB In this paper, we present a novel 2D homography computation method based on two real points. The homography is thus decomposed into three parts. The two real points and their images can be utilized to compute the first and the last parts respectively, while other primitives (could be point(s), line(s) and conic) can be utilized to compute the middle part which is a hyperbolic similarity transformation. We introduce the proposed method in a 2D pattern with a conic and a coplanar line, and apply the method in various other geometric patterns. Subsequently, many plane-based vision tasks, such as camera calibration, pose estimation and metric rectification can be solved in a unified way as polynomial systems. The experiments with simulated and real data verify the correctness and the versatility of our algorithm. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Guo, Juan; Cai, Shen; Wu, Zhanhao] Donghua Univ, Sch Comp Sci & Technol, 2999 Renmin North Rd, Shanghai, Peoples R China.
   [Liu, Yuncai] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, 800 Dongchuan Rd, Shanghai, Peoples R China.
   [Guo, Juan] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai, Peoples R China.
C3 Donghua University; Shanghai Jiao Tong University; East China Normal
   University
RP Cai, S (corresponding author), Donghua Univ, Sch Comp Sci & Technol, 2999 Renmin North Rd, Shanghai, Peoples R China.
EM joann_g@163.com; hammer_cai@163.com; diyuguihou@163.com;
   whomliu@sjtu.edu.cn
OI Cai, Shen/0000-0001-5217-3155
FU China NSFC Program [61472075]; Fundamental Research Funds for the
   Central Universities [2232014D3-02]; Open Project Program of the
   National Laboratory of Pattern Recognition (NLPR)
FX This work was partially supported by China NSFC Program 61472075, the
   Fundamental Research Funds for the Central Universities 2232014D3-02,
   the Open Project Program of the National Laboratory of Pattern
   Recognition (NLPR). Thank.the anonymous reviewers very much for their
   constructive suggestions.
CR [Anonymous], 1999, proceedings of Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.1999.786974
   Bujnak M., 2008, Computer Vision and Pattern Recognition, P1
   Cai S, 2013, MACH VISION APPL, V24, P513, DOI 10.1007/s00138-012-0446-0
   Chum O, 2012, INT C PATT RECOG, P3236
   Decrouez M, 2012, INT C PATT RECOG, P2100
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Gurdjos P., 2006, EUR C COMP VIS ECCV
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Kim JS, 2010, COMPUT VIS IMAGE UND, V114, P803, DOI 10.1016/j.cviu.2010.03.004
   Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464
   Kuang YB, 2013, IEEE I CONF COMP VIS, P529, DOI 10.1109/ICCV.2013.71
   Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649
   Mufti F, 2012, ROBOT AUTON SYST, V60, P16, DOI 10.1016/j.robot.2011.08.009
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Wald H., 2008, ACM T MATH SOFTW, V35
   Wu YH, 2006, J MATH IMAGING VIS, V24, P131, DOI 10.1007/s10851-005-3617-z
   Wu YH, 2006, IMAGE VISION COMPUT, V24, P319, DOI 10.1016/j.imavis.2005.11.008
   Ying X., 2007, INT C INT ROB SYST
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhao ZJ, 2014, J OPT SOC AM A, V31, P1186, DOI 10.1364/JOSAA.31.001186
NR 20
TC 1
Z9 1
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2017
VL 64
BP 23
EP 33
DI 10.1016/j.imavis.2017.05.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FH0ZW
UT WOS:000410870200003
DA 2024-07-18
ER

PT J
AU Xia, BQ
   Ben Amor, B
   Daoudi, M
AF Xia, Baiqiang
   Ben Amor, Boulbaba
   Daoudi, Mohamed
TI = Joint gender, ethnicity and age estimation from 3D faces An
   experimental illustration of their correlations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face; Gender; Ethnicity; Age; Correlation; Random Forest; Feature
   selection
ID MULTIMODAL FACIAL GENDER; SEXUAL-DIMORPHISM; RECOGNITION;
   CLASSIFICATION; TEXTURE; IMAGES
AB Humans present clear demographic traits which allow their peers to recognize their gender and ethnic groups as well as estimate their age. Abundant literature has investigated the problem of automated gender, ethnicity and age recognition from facial images. However, despite the co-existence of these traits, most of the studies have addressed them separately, very little attention has been given to their correlations. In this work, we address the problem of joint demographic estimation and investigate the correlation through the morphological differences in 3D facial shapes. To this end, a set of facial features are extracted to capture the 3D shape differences among the demographic groups. Then, a correlation-based feature selection is applied to highlight salient features and remove redundancy. These features are later fed to Random Forest for gender and ethnicity classification, and age estimation. Extensive experiments conducted on FRGCv2 dataset, under Expression-Dependent and Expression-Independent settings, demonstrate the effectiveness of the proposed approaches for the three traits, and also show the accuracy improvement when considering their correlations. To the best of our knowledge, this is the first study exploring the correlations of these facial soft-biometric traits using 3D faces. This is also the first work which studies the problem of age estimation from 3D Faces.(1) (C) 2017 Elsevier B.V. All rights reserved.
C1 [Xia, Baiqiang; Ben Amor, Boulbaba; Daoudi, Mohamed] Univ Lille, CNRS, IMT Lille Douai, UMR 9189 CRIStAL,Ctr Rech Informat Signal & Autom, F-59000 Lille, France.
C3 Universite de Lille; Centrale Lille; IMT - Institut Mines-Telecom; IMT
   Nord Europe; Centre National de la Recherche Scientifique (CNRS)
RP Xia, BQ (corresponding author), Univ Lille, CNRS, IMT Lille Douai, UMR 9189 CRIStAL,Ctr Rech Informat Signal & Autom, F-59000 Lille, France.
EM xia.baigiang@telecom-lille.fr; boulbaba.benamor@telecom-lille.fr;
   mohamed.daoudi@telecom-lille.fr
RI Ben Amor, Boulbaba/K-7066-2018; Daoudi, Mohammed/H-5935-2013
OI Ben Amor, Boulbaba/0000-0002-4176-9305; Daoudi,
   Mohammed/0000-0003-4219-7860
FU ANR [2010 INTB 0301 01]; CMCU [34882WK]; Chinese Scholarship Council
   (CSC); FUI project MAGNUM 2
FX This work was supported by the ANR project 2010 INTB 0301 01, the CMCU
   project number 34882WK, the Ph.D. scholarship from the Chinese
   Scholarship Council (CSC) to Baiqiang Xia and partially supported by the
   FUI project MAGNUM 2. The authors would like to thank the colleagues at
   the Media Integration and Communication Center (MICC) of the University
   Florence for providing the FU-3D-Faces dataset.
CR Alphonse J, 2013, OBSTET GYNECOL INT, V2013, DOI 10.1155/2013/847293
   [Anonymous], P ACM MULT INT WORKS
   [Anonymous], IEEE EUR C COMP VIS
   [Anonymous], 2005, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2005.268
   [Anonymous], ARXIV12041611
   [Anonymous], RELATIONSHIP AGE FAC
   [Anonymous], 1995, THESIS STANFORD U
   [Anonymous], 2014, IEEE T PATTERN ANAL
   Ballihi L, 2012, IEEE T INF FOREN SEC, V7, P1766, DOI 10.1109/TIFS.2012.2209876
   Baudouin JY, 2006, J EXP PSYCHOL HUMAN, V32, P789, DOI 10.1037/0096-1523.32.4.789
   Ben Amor B, 2014, IEEE T CYBERNETICS, V44, P2443, DOI 10.1109/TCYB.2014.2308091
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   BRUCE V, 1993, PERCEPTION, V22, P131, DOI 10.1068/p220131
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Deffenbacher KA, 1998, PERCEPTION, V27, P1233, DOI 10.1068/p271233
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   ENLOW DH, 1966, AMER J ORTHODONTICS, V52, P283, DOI 10.1016/0002-9416(66)90169-2
   Farinella G, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P383, DOI 10.1109/ICIEV.2012.6317383
   Farkas LG, 2005, J CRANIOFAC SURG, V16, P615, DOI 10.1097/01.scs.0000171847.58031.9e
   Fu SY, 2014, IEEE T PATTERN ANAL, V36, P2483, DOI 10.1109/TPAMI.2014.2321570
   Fu Y, 2010, IEEE T PATTERN ANAL, V32, P1955, DOI 10.1109/TPAMI.2010.36
   Gangestad SW, 2003, EVOL HUM BEHAV, V24, P231, DOI 10.1016/S1090-5138(03)00017-5
   Gao W, 2009, LECT NOTES COMPUT SC, V5558, P169, DOI 10.1007/978-3-642-01793-3_18
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Gilani SZ, 2013, 2013 INTERNATIONAL CONFERENCE ON DIGITAL IMAGE COMPUTING: TECHNIQUES & APPLICATIONS (DICTA), P96
   Guo G., 2010, IEEE COMP SOC C COMP, P71, DOI DOI 10.1109/CVPRW.2010.5543609
   Guo G., 2012, HUMAN AGE ESTIMATION, P101
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Hall M. A., 1999, Proceedings of the Twelfth International Florida AI Research Society Conference, P235
   Han X, 2009, 2009 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P114, DOI 10.1109/CW.2009.41
   Hayashi J, 2002, INT C PATT RECOG, P405, DOI 10.1109/ICPR.2002.1044736
   Hu YX, 2010, LECT NOTES COMPUT SC, V5916, P66
   Huang D, 2014, IMAGE VISION COMPUT, V32, P1181, DOI 10.1016/j.imavis.2014.06.009
   HUNTER WS, 1972, AM J PHYS ANTHROPOL, V36, P133, DOI 10.1002/ajpa.1330360115
   Huynh Tri, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P133, DOI 10.1007/978-3-642-37410-4_12
   Jain AK, 2004, LECT NOTES COMPUT SC, V3072, P731
   Jennifer A., 2013, OBSTET GYNECOLOGY IN
   Kumar Neeraj, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Lakshmiprabha NS, 2011, COMM COM INF SC, V157, P211
   Lanitis A, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1027, DOI 10.1109/ICDSP.2002.1028265
   Little A.C., 2008, Symmetry is related to sexual dimorphism in faces, V3
   Little AC, 2008, BEHAV ECOL, V19, P902, DOI 10.1093/beheco/arn049
   Liu YX, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P222
   Lu XG, 2006, LECT NOTES COMPUT SC, V3832, P554
   OToole AJ, 1997, PERCEPTION, V26, P719, DOI 10.1068/p260719
   Ramanathan N, 2009, J VISUAL LANG COMPUT, V20, P131, DOI 10.1016/j.jvlc.2009.01.011
   Rhodes MG, 2009, APPL COGNITIVE PSYCH, V23, P1, DOI 10.1002/acp.1442
   Samal A, 2007, J VIS COMMUN IMAGE R, V18, P453, DOI 10.1016/j.jvcir.2007.04.010
   Shirakabe Y, 2003, AESTHET PLAST SURG, V27, P397, DOI 10.1007/s00266-003-2099-x
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Suo J., 2010, COMPOSITIONAL DYNAMI
   Toderici G, 2010, INT J COMPUT VISION, V89, P382, DOI 10.1007/s11263-009-0300-7
   Tokola R, 2015, INT CONF BIOMETR, P201, DOI 10.1109/ICB.2015.7139052
   Ueki Kazuya, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3400, DOI 10.1109/ICPR.2010.830
   Vignali G., 2003, AVSP 2003 INT C AUD, P193
   Wang XL, 2013, IEEE GLOB CONF SIG, P1077, DOI 10.1109/GlobalSIP.2013.6737080
   Wu J, 2010, IMAGE VISION COMPUT, V28, P1039, DOI 10.1016/j.imavis.2009.09.003
   Xia B., 2013, IEEE INT C WORKSH AU, P1
   Xia BQ, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P5
   Young J.W., 1993, HEAD FACE ANTHR ADUL
   Zhong C, 2009, LECT NOTES COMPUT SC, V5558, P386, DOI 10.1007/978-3-642-01793-3_40
   Zhuang Z., 2010, ANN OCCUP HYG
   Zhuang ZQ, 2005, J OCCUP ENVIRON HYG, V2, P567, DOI 10.1080/15459620500324727
NR 63
TC 9
Z9 9
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2017
VL 64
BP 90
EP 102
DI 10.1016/j.imavis.2017.06.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA FH0ZW
UT WOS:000410870200008
DA 2024-07-18
ER

PT J
AU Zhou, XZ
   Huo, QR
   Shang, YY
   Xu, M
   Ding, H
AF Zhou, Xiuzhuang
   Huo, Qirun
   Shang, Yuanyuan
   Xu, Min
   Ding, Hui
TI Learning spatially regularized similarity for robust visual tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Part-based representation; Metric learning; Local
   similarity; Spatially regularized
ID FACE RECOGNITION; OBJECT TRACKING
AB Matching visual appearances of the target object over consecutive frames is a critical step in visual tracking. The accuracy performance of a practical tracking system highly depends on the similarity metric used for visual matching. Recent attempts to integrate discriminative metric learned by sequential visual data (instead of a predefined metric) in visual tracking have demonstrated more robust and accurate results. However, a global similarity metric is often suboptimal for visual matching when the target object experiences large appearance variation or occlusion. To address this issue, we propose in this paper a spatially weighted similarity fusion (SWSF) method for robust visual tracking. In our SWSF, a part-based model is employed as the object representation, and the local similarity metric and spatially regularized weights are jointly learned in a coherent process, such that the total matching accuracy between visual target and candidates can be effectively enhanced. Empirically, we evaluate our proposed tracker on various challenging sequences against several state-of-the-art methods, and the results demonstrate that our method can achieve competitive or better tracking performance in various challenging tracking scenarios. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zhou, Xiuzhuang; Shang, Yuanyuan; Xu, Min; Ding, Hui] Capital Normal Univ, Coll Informat Engn, Beijing, Peoples R China.
   [Zhou, Xiuzhuang; Shang, Yuanyuan] Beijing Adv Innovat Ctr Imaging Technol, Beijing, Peoples R China.
   [Huo, Qirun] Beijing Inst Technol, Sch Comp Sci, Beijing, Peoples R China.
C3 Capital Normal University; Beijing Institute of Technology
RP Shang, YY (corresponding author), Capital Normal Univ, Coll Informat Engn, Beijing, Peoples R China.
EM syy@bao.ac.cn
RI Shang, Yuanyuan/ACH-0016-2022
OI Shang, Yuanyuan/0000-0003-4219-2541
FU National Natural Science Foundation of China [61373090]
FX This work is partially supported by the National Natural Science
   Foundation of China under grant no. 61373090.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], P ADV NEURAL INFORM
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   He SF, 2013, PROC CVPR IEEE, P2427, DOI 10.1109/CVPR.2013.314
   Hong ZB, 2012, LECT NOTES COMPUT SC, V7572, P513, DOI 10.1007/978-3-642-33718-5_37
   Hu J, 2015, IEEE INT FUZZY SYST
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jiang N, 2011, IEEE T IMAGE PROCESS, V20, P2288, DOI 10.1109/TIP.2011.2114895
   Kwon J, 2008, LECT NOTES COMPUT SC, V5302, P387, DOI 10.1007/978-3-540-88682-2_30
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Liang FM, 2007, J AM STAT ASSOC, V102, P305, DOI 10.1198/016214506000001202
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Liu Jun S, 2008, MONTE CARLO STRATEGI
   Lu J., 2014, LOCALIZED MULTIFEATU
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu JW, 2015, IEEE T INF FOREN SEC, V10, P79, DOI 10.1109/TIFS.2014.2363792
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   Wang D, 2015, IEEE T CYBERNETICS, V45, P1838, DOI 10.1109/TCYB.2014.2360924
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang Q, 2011, IEEE T SYST MAN CY B, V41, P385, DOI 10.1109/TSMCB.2010.2056366
   Wang X., 2010, Discriminative Tracking by Metric Learning, P200
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhou XZ, 2012, IEEE T IMAGE PROCESS, V21, P789, DOI 10.1109/TIP.2011.2168414
   Zhou XZ, 2010, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR.2010.5539856
   Zhuang BH, 2014, IEEE T IMAGE PROCESS, V23, P1872, DOI 10.1109/TIP.2014.2308414
NR 42
TC 3
Z9 3
U1 0
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 134
EP 141
DI 10.1016/j.imavis.2016.11.016
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800014
DA 2024-07-18
ER

PT J
AU Goodkind, A
   Brizan, DG
   Rosenberg, A
AF Goodkind, Adam
   Brizan, David Guy
   Rosenberg, Andrew
TI Utilizing overt and latent linguistic structure to improve
   keystroke-based authentication
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Keystroke dynamics; Biometrics; Linguistics; User authentication
ID USER AUTHENTICATION; DYNAMICS
AB Keystroke production is influenced by a number of factors including linguistic context and structure. Previous studies in keystroke-based authentication have neglected to take these many of these into account. By incorporating the linguistic context under which keystrokes are produced, we are able to improve the accuracy of authentication experiments. We are able to reduce baseline EER by 36% on a dataset of 486 users, from a baseline of 0.0483 using only unigraph holds and digraph intervals to 0.0309 using linguistic context. Our EER results are further improved to 0.0232 by reducing the size of our feature-set through various methods of feature pruning. These results demonstrate the importance of context when authenticating a typist. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Goodkind, Adam; Brizan, David Guy; Rosenberg, Andrew] CUNY, Grad Ctr, 365 5th Ave, New York, NY 10016 USA.
   [Rosenberg, Andrew] CUNY Queens Coll, 65-30 Kissena Blvd, Queens, NY 11367 USA.
C3 City University of New York (CUNY) System; City University of New York
   (CUNY) System
RP Goodkind, A (corresponding author), CUNY, Grad Ctr, 365 5th Ave, New York, NY 10016 USA.
EM agoodkind@gradcenter.cuny.edu; dbrizan@gradcenter.cuny.edu;
   andrew@cs.qc.cuny.edu
OI Goodkind, Adam/0000-0001-9230-1131
FU DARPA Active Authentication grants [FA8750-12-2-0201, FA8750-13-2-0274]
FX This work was supported in part by DARPA Active Authentication grants
   FA8750-12-2-0201 and FA8750-13-2-0274. The views, findings,
   recommendations, and conclusions contained herein are those of the
   authors and should not be interpreted as necessarily representing the
   official policies or endorsements, either expressed or implied, of the
   sponsoring agencies or the U.S. Government.
CR Ahmed AA, 2014, IEEE T CYBERNETICS, V44, P458, DOI 10.1109/TCYB.2013.2257745
   Alves RA, 2007, STUD WRIT, V20, P55
   [Anonymous], P 2013 EUR INT SEC I
   [Anonymous], 2012, INF SECUR TECH REP, DOI [DOI 10.1016/J.ISTR.2012.02.001, 10.1016/j.istr.2012.02.001]
   [Anonymous], 2012, INTRO PSYCHOLINGUIST
   [Anonymous], KEYSTROKE PATTERNS P
   [Anonymous], P 9 ANN CYB INF SEC
   [Anonymous], NETW DISTR SYST SEC
   [Anonymous], P INT MULT ENG COMP
   Araújo LCF, 2005, IEEE T SIGNAL PROCES, V53, P851, DOI 10.1109/TSP.2004.839903
   Ashbourn J., 2014, Biometrics: Advanced Identity Verification: The Complete Guide
   Banerjee SP, 2012, J PATTERN RECOGNIT R, V7, P116, DOI 10.13176/11.427
   Bartmann D, 2007, INT J INF SECUR PRIV, V1, P1, DOI 10.4018/jisp.2007040101
   Chung C, 2007, FRONT SOC PSYCHOL, P343
   Gunetti D., 2005, ACM Transactions on Information and Systems Security, V8, P312, DOI 10.1145/1085126.1085129
   Jain A K, 2011, Introduction to Biometrics
   JOYCE R, 1990, COMMUN ACM, V33, P168, DOI 10.1145/75577.75582
   Killourhy K, 2010, LECT NOTES COMPUT SC, V6307, P256, DOI 10.1007/978-3-642-15512-3_14
   Killourhy KS, 2009, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN.2009.5270346
   Manning CD, 2014, PROCEEDINGS OF 52ND ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: SYSTEM DEMONSTRATIONS, P55, DOI 10.3115/v1/p14-5010
   Messerman Arik., 2011, BIOMETRICS IJCB 2011, P1, DOI [DOI 10.1109/IJCB.2011.6117552, 10.1109/IJCB.2011.6117552]
   Monrose F., 2002, International Journal of Information Security, V1, P69, DOI 10.1007/s102070100006
   Monrose F, 2000, FUTURE GENER COMP SY, V16, P351, DOI 10.1016/S0167-739X(99)00059-X
   Montalvao J, 2006, PROCEEDINGS OF THE IEEE INTERNATIONAL TELECOMMUNICATIONS SYMPOSIUM, VOLS 1 AND 2, P560
   Roffo G., 2014, Proceedings of the 16th International Conference on Multimodal Interaction - ICMI'14, P224
   Roth J, 2014, IEEE T IMAGE PROCESS, V23, P4611, DOI 10.1109/TIP.2014.2348802
   Roth J, 2013, INT CONF BIOMETR
   RUMELHART DE, 1982, COGNITIVE SCI, V6, P1
   Saevanee H, 2012, IFIP ADV INF COMM TE, V376, P465
   SALTHOUSE TA, 1986, PSYCHOL BULL, V99, P303, DOI 10.1037/0033-2909.99.3.303
   SHAFFER LH, 1978, Q J EXP PSYCHOL, V30, P333, DOI 10.1080/14640747808400680
   Sim T, 2007, COMPUTER VISION PATT, P1
   Stewart J., 2011, BIOMETRICS IJCB 2011, P1, DOI DOI 10.1109/IJCB.2011.6117480
   Teh PS, 2013, SCI WORLD J, DOI 10.1155/2013/408280
   Vizer LM, 2009, INT J HUM-COMPUT ST, V67, P870, DOI 10.1016/j.ijhcs.2009.07.005
   Zheng N, 2011, PROCEEDINGS OF THE 18TH ACM CONFERENCE ON COMPUTER & COMMUNICATIONS SECURITY (CCS 11), P139
   Zhong Yu., 2012, Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on, P117, DOI [10.1109/CVPRW.2012.6239225, DOI 10.1109/CVPRW.2012.6239225]
NR 37
TC 7
Z9 9
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 230
EP 238
DI 10.1016/j.imavis.2016.06.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700022
DA 2024-07-18
ER

PT J
AU Jampour, M
   Lepetit, V
   Mauthner, T
   Bischof, H
AF Jampour, Mahdi
   Lepetit, Vincent
   Mauthner, Thomas
   Bischof, Horst
TI Pose-specific non-linear mapings in feature space towards multiview
   facial expression recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Non-frontal facial expression recognition; Sparse coding; Non-linear
   transformation; Robust arbitrary view facial; expression recognition
ID HEAD POSE
AB We introduce a novel approach to recognizing facial expressions over a large range of head poses. Like previous approaches, we map the features extracted from the input image to the corresponding features of the face with the same facial expression but seen in a frontal view. This allows us to collect all training data into a common referential and therefore benefit from more data to learn to recognize the expressions. However, by contrast with such previous work, our mapping depends on the pose of the input image: We first estimate the pose of the head in the input image, and then apply the mapping specifically learned for this pose. The features after mapping are therefore much more reliable for recognition purposes. In addition, we introduce a non-linear form for the mapping of the features, and we show that it is robust to occasional mistakes made by the pose estimation stage. We evaluate our approach with extensive experiments on two protocols of the BU3DFE and Multi-PIE datasets, and show that it outperforms the state-of-the-art on both datasets. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Jampour, Mahdi; Lepetit, Vincent; Mauthner, Thomas; Bischof, Horst] Graz Univ Technol, Graz, Austria.
C3 Graz University of Technology
RP Jampour, M (corresponding author), Graz Univ Technol, Graz, Austria.
EM jampour@icg.tugraz.at; lepetit@icg.tugraz.at; mauthner@icg.tugraz.at;
   bischof@icg.tugraz.at
RI Jampour/AAT-8828-2020; Jampour, Mahdi/AAA-5129-2022
OI Jampour, Mahdi/0000-0002-1559-1865; Bischof, Horst/0000-0002-9096-6671
FU Austrian Research Promotion Agency [832045, 840824, 836630]
FX This work was supported by following Austrian Research Promotion Agency
   (FFG) projects FACTS (832045), DIANGO (840824) and Vision+ (836630).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Amor B. B., 2014, IEEE T CYBERNETICS, V44, P1
   [Anonymous], 2013, FACIAL EXPRESSION RE
   Asthana S. C. A., 2014, COMP VIS PATT REC CV, P1
   Bristow H., ARXIV14071957
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chu Wen-Sheng, 2013, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, V2013, P3515
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhall A, 2014, IEEE WINT CONF APPL, P1028, DOI 10.1109/WACV.2014.6835991
   Ding XY, 2013, IEEE I CONF COMP VIS, P2400, DOI 10.1109/ICCV.2013.298
   Ekman P., FACIAL ACTION CODING
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Hesse N, 2012, INT C PATT RECOG, P3533
   Hu Y., 2008, P IEEE 8 INT C AUT F, P1
   Hu YX, 2008, INT C PATT RECOG, P460
   Huang XH, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.76
   Huang XH, 2010, LECT NOTES COMPUT SC, V6475, P312, DOI 10.1007/978-3-642-17691-3_29
   Jampour Mahdi, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163101
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Kotsia I, 2008, PATTERN RECOGN, V41, P833, DOI 10.1016/j.patcog.2007.06.026
   Liu JJ, 2014, IMAGE VISION COMPUT, V32, P671, DOI 10.1016/j.imavis.2014.02.009
   Liu WF, 2012, INT C PATT RECOG, P1839
   Moeini A, 2015, IMAGE VISION COMPUT, V36, P9, DOI 10.1016/j.imavis.2015.01.007
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Moore S., 2010, BRIT MACH VIS C BMVC
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Rigamonti R, 2011, PROC CVPR IEEE, P1545, DOI 10.1109/CVPR.2011.5995313
   Rudovic Ognjen, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4121, DOI 10.1109/ICPR.2010.1001
   Rudovic O, 2013, IEEE T PATTERN ANAL, V35, P1357, DOI 10.1109/TPAMI.2012.233
   Rudovic O, 2012, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2012.6247983
   Taheri S., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P306, DOI 10.1109/FG.2011.5771415
   Tang H, 2010, IEEE INT CON MULTI, P1202, DOI 10.1109/ICME.2010.5582576
   Tariq U, 2014, PATTERN RECOGN LETT, V46, P89, DOI 10.1016/j.patrec.2014.05.011
   Tariq U, 2012, LECT NOTES COMPUT SC, V7585, P578, DOI 10.1007/978-3-642-33885-4_58
   Timofte R, 2013, IEEE I CONF COMP VIS, P1920, DOI 10.1109/ICCV.2013.241
   Tropp JA, 2007, IEEE T INFORM THEORY, V53, P4655, DOI 10.1109/TIT.2007.909108
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang LG, 2014, IMAGE VISION COMPUT, V32, P107, DOI 10.1016/j.imavis.2013.12.008
   Zhang Xiao, 2013, 2013 10 IEEE INT C W, P1
   Zheng WM, 2014, IEEE T AFFECT COMPUT, V5, P71, DOI 10.1109/TAFFC.2014.2304712
   Zheng WM, 2010, LECT NOTES COMPUT SC, V6316, P490, DOI 10.1007/978-3-642-15567-3_36
NR 44
TC 21
Z9 23
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 38
EP 46
DI 10.1016/j.imavis.2016.05.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700005
DA 2024-07-18
ER

PT J
AU Rochan, M
   Rahman, S
   Bruce, NDB
   Wang, Y
AF Rochan, Mrigank
   Rahman, Shafin
   Bruce, Neil D. B.
   Wang, Yang
TI Weakly supervised object localization and segmentation in videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Weakly supervised; Object localization
ID TRACKING; EXTRACTION
AB We consider the problem of localizing and segmenting objects in weakly labeled video. A video is weakly labeled if it is associated with a tag (e.g. YouTube videos with tags) describing the main object present in the video. It is weakly labeled because the tag only indicates the presence/absence of the object, but does not give the detailed spatial/temporal location of the object in the video. Given a weakly labeled video, our method can automatically localize the object in each frame and segment it from the background. Our method is fully automatic and does not require any user-input. In principle, it can be applied to a video of any object class. We evaluate our proposed method on a dataset with more than 100 video shots. Our experimental results show that our method outperforms other baseline approaches. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Rochan, Mrigank; Rahman, Shafin; Bruce, Neil D. B.; Wang, Yang] Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada.
C3 University of Manitoba
RP Rochan, M (corresponding author), Univ Manitoba, Dept Comp Sci, Winnipeg, MB R3T 2N2, Canada.
EM mrochan@cs.umanitoba.ca; shafin12@cs.umanitoba.ca;
   bruce@cs.umanitoba.ca; ywang@cs.umanitoba.ca
RI Rahman, Shafin/N-1939-2019; Zhang, Han/JMR-0670-2023; Bruce, Neil
   DB/K-2062-2015
OI Rahman, Shafin/0000-0001-7169-0318; Bruce, Neil/0000-0002-5710-1107
FU NSERC; University of Manitoba Research Grants Program (URGP)
FX This work was supported by NSERC and the University of Manitoba Research
   Grants Program (URGP).
CR [Anonymous], P NIPS VANC BC CAN
   [Anonymous], 2014, PROC COMPUT VIS PATT
   [Anonymous], EUR C COMP VIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], ARXIV14085093
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C MACH LEARN
   [Anonymous], EUR C COMP VIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2006, EUR C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Badrinarayanan V, 2013, IEEE T PATTERN ANAL, V35, P2751, DOI 10.1109/TPAMI.2013.54
   Badrinarayanan V, 2010, PROC CVPR IEEE, P3265, DOI 10.1109/CVPR.2010.5540054
   Berclaz J, 2011, IEEE T PATTERN ANAL, V33, P1806, DOI 10.1109/TPAMI.2011.21
   Brendel W, 2011, IEEE I CONF COMP VIS, P778, DOI 10.1109/ICCV.2011.6126316
   Brendel W, 2009, IEEE I CONF COMP VIS, P833, DOI 10.1109/ICCV.2009.5459242
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Galleguillos C, 2008, LECT NOTES COMPUT SC, V5302, P193, DOI 10.1007/978-3-540-88682-2_16
   Grundmann M, 2010, PROC CVPR IEEE, P2141, DOI 10.1109/CVPR.2010.5539893
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Hartmann G, 2012, LECT NOTES COMPUT SC, V7583, P198, DOI 10.1007/978-3-642-33863-2_20
   Ke Y., 2007, IEEE INT C COMPUTER
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Lezama J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3369, DOI 10.1109/CVPR.2011.6044588
   Pang Y, 2013, IEEE I CONF COMP VIS, P2784, DOI 10.1109/ICCV.2013.346
   Perazzi F, 2015, IEEE I CONF COMP VIS, P3227, DOI 10.1109/ICCV.2015.369
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Prest A, 2012, PROC CVPR IEEE, P3282, DOI 10.1109/CVPR.2012.6248065
   Ramanan D, 2005, PROC CVPR IEEE, P271
   Raza SH, 2013, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2013.396
   Rochan M, 2014, LECT NOTES COMPUT SC, V8887, P172, DOI 10.1007/978-3-319-14249-4_17
   Rochan M, 2014, 2014 CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P119, DOI 10.1109/CRV.2014.24
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Tang K, 2013, PROC CVPR IEEE, P2483, DOI 10.1109/CVPR.2013.321
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Vazquez-Reina A, 2010, LECT NOTES COMPUT SC, V6315, P268, DOI 10.1007/978-3-642-15555-0_20
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang D, 2013, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2013.87
NR 42
TC 9
Z9 9
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2016
VL 56
BP 1
EP 12
DI 10.1016/j.imavis.2016.08.015
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EF1FW
UT WOS:000390071700001
DA 2024-07-18
ER

PT J
AU Chellappa, R
AF Chellappa, Rama
TI The changing fortunes of pattern recognition and computer vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Biometrics Conference
CY OCT, 2015
CL London, ENGLAND
DE Convolutional Neural Networks; Deep Learning; Image Recognition;
   Biometrics
AB As someone who had been attending conferences on pattern recognition and computer vision since 1978, I have watched with interest the ups and downs of pattern recognition and computer vision areas and how they have been presented at various conferences such as PRIP, CVPR, ECCV, ICCV, ACCV, ICPR, IjCAI, AAAI, NIPS, ICASSP and ICIP. Given the recent successes of deep learning networks, it appears that the scale is tilting towards pattern recognition as is commonly understood. A good number of papers in recent vision conferences seem to push data through one or other deep learning networks and report improvements over state of the art. While one cannot argue against the remarkable (magical?) performance improvements obtained by deep learning network based approaches, I worry that five years from now, most students in computer vision will only be aware of software that implements some deep learning network. After all, 2-D based detection and recognition problems for which the deep learning networks have shown their mettle are only a subset of the computer vision field. While enjoying the ride, I would like to caution that understanding of scene and image formation, invariants, interaction between light and matter, human vision, 3D recovery, and emerging concepts like common sense reasoning are too important to ignore for the long-term viability of the computer vision field. It will be a dream come true if we manage to integrate these computer vision concepts into deep learning networks so that more robust performance can be obtained with less data and cheaper computers. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
   [Chellappa, Rama] Univ Maryland, Ctr Automat Res, UMIACS, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park;
   University System of Maryland; University of Maryland College Park
RP Chellappa, R (corresponding author), Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.; Chellappa, R (corresponding author), Univ Maryland, Ctr Automat Res, UMIACS, College Pk, MD 20742 USA.
RI Chellappa, Rama/B-6573-2012; Chellappa, Rama/AAV-8690-2020
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], LEARNING RELEARNING
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Carpenter G.A., 1991, PATTERN RECOGN
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Fu K., 1981, Syntactic Pattern Recognition andApplications"
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Giryes R., ARXIV141258962014
   Grimson W., 1990, OBJECT RECOGNITION C
   Haeffele B. D., ARXIV1506075402015
   Horn B.K.P, 1986, Robot Vision
   Kanade T., 1987, 3 DIMENSIONAL VISION
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2004, PROC CVPR IEEE, P97
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mallat S., 2014, ARXIV1601049202016
   Rosenfeld A, 1982, PATTERN RECOGN LETT, V1, P2, DOI 10.1016/0167-8655(82)90042-3
   Rumelhart D.E., 2013, Learning internal representations by error propagation, P399, DOI [10.1016/b978-1-4832-1446-7.50035-2, 10.1016/B978-1-4832-1446-7.50035-2]
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sun Y, 2015, PROC CVPR IEEE, P2892, DOI 10.1109/CVPR.2015.7298907
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Werbos P.J., 1994, The roots of backpropagation: from ordered derivatives to neural networks and political forecasting, VVolume 1
   Zhou Y., 1991, ARTIFICIAL NEURAL NE
NR 27
TC 7
Z9 10
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
BP 3
EP 5
DI 10.1016/j.imavis.2016.04.005
PN 1
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA ED8BO
UT WOS:000389097100002
DA 2024-07-18
ER

PT J
AU Oh, K
   Lee, M
   Kim, G
   Kim, S
AF Oh, Kanghan
   Lee, Myungeun
   Kim, Gwangbok
   Kim, Soohyung
TI Detection of multiple salient objects through the integration of
   estimated foreground clues
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiple-salient-region detection; Object segmentation; Saliency map
ID VISUAL-ATTENTION
AB In this paper, a novel method for the detection of multiple salient regions that is based on the integration of estimated foreground clues is proposed. Although this subject has been very well studied for the detection of salient objects, many technical challenges still exist regarding the multiple-object-detection task; in particular, unlike a single-object-detection problem, a high inter-object dissimilarity causes new difficulties. By analyzing the limitations of the existing models, the following two main frameworks that are based on a multi-level foreground segmentation strategy are proposed: non-parametric cluster-based saliency (NS) and parametric cluster-based saliency (PS). Each framework consists of a vector classification, a foreground estimation, an energy generation, and an integration process. In contrast to previous models, the proposed method is not dependent upon the contrast features, and is unaffected by the size, thickness, and shape of the objects. In the experiment results, a superior detection accuracy for the SED2 benchmark was achieved with the use of the proposed scheme; furthermore, the corresponding precision and recall are superior to those of the state-of-the-art approaches, and more effective performances were also achieved on the MSRA-ASD, SED2 and CSSD benchmarks. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Oh, Kanghan; Kim, Gwangbok; Kim, Soohyung] Chonnam Natl Univ, Sch Elect & Comp Engn, 77 Yongbong Ro, Gwangju 500757, South Korea.
   [Lee, Myungeun] Seoul Natl Univ, Adv Inst Convergence Technol, 145 Gwanggyo Ro, Suwon 443270, Gyeonggi Do, South Korea.
C3 Chonnam National University; Seoul National University (SNU)
RP Kim, S (corresponding author), Chonnam Natl Univ, Sch Elect & Comp Engn, 77 Yongbong Ro, Gwangju 500757, South Korea.
EM blastps@naver.com; melee@snu.ac.kr; loopaz63@gmail.com; shkim@jnu.ac.kr
OI Lee, Myungeun/0000-0001-5032-0086
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Education [NRF-2015R1D1A3A01018993,
   NRF-2013R1A1A2064317]; Chonnam National University
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Education (NRF-2015R1D1A3A01018993, NRF-2013R1A1A2064317). This study
   was financially supported by Chonnam National University, 2016.
CR Achanta R, ICVS 2008, P66
   Achanta R, 2010, IEEE IMAGE PROC, P2653, DOI 10.1109/ICIP.2010.5652636
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2007, IEEE T PATTERN ANAL
   [Anonymous], 2016, CVPR
   Berengolts A, 2006, IEEE T PATTERN ANAL, V28, P1973, DOI 10.1109/TPAMI.2006.249
   Bernd Jahne, 2005, Digital Image Processing, a Systematic Approach to Digital Image Processing/Uses Examples and Images to Illustrate Basic Concepts
   Bonaiuto J., CVPR 2005, P90
   Borji A, 2015, IEEE T IMAGE PROCESS, V24, P5706, DOI 10.1109/TIP.2015.2487833
   Bruce N., NIPS 2005, P155
   Bruce NDB, 2015, VISION RES, V116, P95, DOI 10.1016/j.visres.2015.01.010
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Frederick L, 2012, STAT GENTLE INTRO
   Harel J., NIPS 2006, P545
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou X., NIPS 2008, P681
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kang-Han O., 2014, ICUIMC
   Khuwuthyakom P., ECCV 2010, P636
   Klein D., ICCV 2011, P2214
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kootstra G, 2011, COGN COMPUT, V3, P223, DOI 10.1007/s12559-010-9089-5
   Li ZC, 2011, IMAGE VISION COMPUT, V29, P1, DOI 10.1016/j.imavis.2010.07.001
   Ma Y.-F., ACM MM 2003, P374
   Martin D., ICCV 2001, P416
   Mathe S., IEEE T PATTERN ANAL, V37
   Ming-Yu L, CVPR 2011, P2097
   Nian L., CVPR 2015, P362
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qiong Y., CVPR 2013, P1155
   Rahtu E., ECCV 2010, P366
   Rosin PL, 2009, PATTERN RECOGN, V42, P2363, DOI 10.1016/j.patcog.2009.04.021
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Ye L., 2013, ACM MM 2013, P509
   Yeh HH, 2014, PATTERN RECOGN, V47, P1740, DOI 10.1016/j.patcog.2013.11.015
   Zhang YD, 2014, INFORM SCIENCES, V281, P586, DOI 10.1016/j.ins.2013.12.043
   ZIMAN JM, 1969, NATURE, V224, P318, DOI 10.1038/224318a0
NR 45
TC 13
Z9 14
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2016
VL 54
BP 31
EP 44
DI 10.1016/j.imavis.2016.07.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EB6UG
UT WOS:000387520500004
DA 2024-07-18
ER

PT J
AU Sigari, MH
   Soltanian-Zadeh, H
   Pourreza, HR
AF Sigari, Mohamad-Hoseyn
   Soltanian-Zadeh, Hamid
   Pourreza, Hamid-Reza
TI A framework for dynamic restructuring of semantic video analysis systems
   based on learning attention control
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Attention control; Broadcast soccer video; Event detection; Q-learning;
   Semantic video analysis
ID SHOT BOUNDARY DETECTION; EVENT DETECTION; QR-DECOMPOSITION; TASK
AB Current semantic video analysis systems are usually hierarchical and consist of some levels to overcome semantic gaps between low-level features and high-level concepts. In these systems, some features, descriptors, objects or concepts are extracted in each level and therefore, total computational complexity of such systems is huge. In this paper, we present a new general framework to impose attention control on a video analysis system using Q-learning. Thus, our proposed framework restructures a given system dynamically to direct attention to the blocks extracting the most informative features/concepts and reduces computational complexity of the system. In other words, the proposed framework directs flow of processing actively using a learning attention control method. The proposed framework is evaluated for event detection in broadcast soccer videos using limited numbers of training samples. Experiments show that the proposed framework is able to learn how to direct attention to informative features/concepts and restructure the initial structure of the system dynamically to reach the final goal with less computational complexity. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Sigari, Mohamad-Hoseyn; Soltanian-Zadeh, Hamid] Univ Tehran, Sch Elect & Comp Engn, CIPCE, Coll Engn, Tehran 14399, Iran.
   [Soltanian-Zadeh, Hamid] Henry Ford Hlth Syst, Dept Radiol, Image Anal Lab, Detroit, MI 48202 USA.
   [Soltanian-Zadeh, Hamid] Inst Res Fundamental Sci IPM, Sch Cognit Sci, Tehran 19395, Iran.
   [Pourreza, Hamid-Reza] Ferdowsi Univ Mashhad, Fac Engn, Dept Comp Engn, Machine Vis Res Lab, Mashhad 91779, Iran.
C3 University of Tehran; Henry Ford Health System; Henry Ford Hospital;
   Ferdowsi University Mashhad
RP Sigari, MH (corresponding author), Univ Tehran, Sch Elect & Comp Engn, CIPCE, Coll Engn, Tehran 14399, Iran.
EM hoseynsigari@ut.ac.ir; hszadeh@ut.ac.ir; hpourreza@um.ac.ir
RI Sigari, Mohamad-Hoseyn/AAV-8499-2020; Soltanian-Zadeh,
   Hamid/AAD-7027-2022; Pourreza, Hamid-Reza/AAP-7735-2021; Pourreza,
   Hamidreza/B-8754-2015
OI Sigari, Mohamad-Hoseyn/0000-0003-4048-2262; Soltanian-Zadeh,
   Hamid/0000-0002-7302-6856; Pourreza, Hamid-Reza/0000-0002-3560-8070;
   Pourreza, Hamidreza/0000-0002-3560-8070
CR Amiri A, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/892124
   Amiri A, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/509438
   [Anonymous], INT J COMPUT GRAPH
   [Anonymous], J VIRTUAL REAL BROAD
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], ADV ARTIF INTELL
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], IEEE T MULTIMED
   [Anonymous], INT J MULTIMED UBIQU
   [Anonymous], INT S ART INT SIGN P
   Boreczky JS, 1996, J ELECTRON IMAGING, V5, P122, DOI 10.1117/12.238675
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Borji A, 2010, IMAGE VISION COMPUT, V28, P1130, DOI 10.1016/j.imavis.2009.10.006
   Breiman L, 1998, BIOMETRICS, DOI [10.1201/9781315139470, DOI 10.2307/2530946]
   Cavallaro A, 2005, IEEE T CIRC SYST VID, V15, P1200, DOI 10.1109/TCSVT.2005.854240
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   D'Orazio T, 2009, COMPUT VIS IMAGE UND, V113, P622, DOI 10.1016/j.cviu.2008.01.010
   D'Orazio T, 2009, IEEE T CIRC SYST VID, V19, P1804, DOI 10.1109/TCSVT.2009.2026817
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Frintrop S, 2010, ACM T APPL PERCEPT, V7, DOI 10.1145/1658349.1658355
   Han YH, 2015, IEEE T NEUR NET LEAR, V26, P252, DOI 10.1109/TNNLS.2014.2314123
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hosseini MS, 2013, APPL SOFT COMPUT, V13, P846, DOI 10.1016/j.asoc.2012.10.007
   Huang CL, 2006, IEEE T MULTIMEDIA, V8, P749, DOI 10.1109/TMM.2006.876289
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Ji P, 2014, NEUROCOMPUTING, V123, P86, DOI 10.1016/j.neucom.2013.06.003
   Khatoonabadi SH, 2009, IMAGE VISION COMPUT, V27, P469, DOI 10.1016/j.imavis.2008.06.015
   Kolekar Maheshkumar H, 2009, J Multimed, V4, P298, DOI 10.4304/jmm.4.5.298-312
   Küçüktunç O, 2010, J VIS COMMUN IMAGE R, V21, P838, DOI 10.1016/j.jvcir.2010.07.001
   Lien CC, 2007, J VIS COMMUN IMAGE R, V18, P1, DOI 10.1016/j.jvcir.2006.09.002
   Liu TM, 2003, IEEE T CIRC SYST VID, V13, P1006, DOI 10.1109/TCSVT.2003.816521
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Mirian MS, 2011, NEURAL COMPUT, V23, P558, DOI 10.1162/NECO_a_00079
   Miriana MS, 2012, J INTELL FUZZY SYST, V23, P111, DOI 10.3233/IFS-2012-0500
   Miura J, 2009, COMPUT VIS IMAGE UND, V113, P653, DOI 10.1016/j.cviu.2008.10.005
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Shen JL, 2008, IEEE T CIRC SYST VID, V18, P1587, DOI 10.1109/TCSVT.2008.2005607
   Shyu ML, 2008, IEEE T MULTIMEDIA, V10, P252, DOI 10.1109/TMM.2007.911830
   Smeaton AF, 2010, COMPUT VIS IMAGE UND, V114, P411, DOI 10.1016/j.cviu.2009.03.011
   Sun K, 2007, LECT NOTES COMPUT SC, V4738, P594
   Sutton R., 1998, Reinforcement Learning: An Introduction
   Tavassolipour M, 2014, IEEE T CIRC SYST VID, V24, P291, DOI 10.1109/TCSVT.2013.2243640
   Tjondronegoro DW, 2010, IEEE T SYST MAN CY A, V40, P1009, DOI 10.1109/TSMCA.2010.2046729
   Tong XF, 2004, 2004 7TH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING PROCEEDINGS, VOLS 1-3, P1364
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wolfe J. M., 2007, INTEGRATED MODELS CO, P99, DOI [10.1093/acprof:oso/9780195189193.003.0008, DOI 10.1093/ACPROF:OSO/9780195189193.003.0008]
   WOLFE JM, 1994, PSYCHON B REV, V1, P202, DOI 10.3758/BF03200774
   Xu M, 2014, MULTIMED TOOLS APPL, V70, P757, DOI 10.1007/s11042-012-1046-8
   Xu M, 2013, SIGNAL PROCESS, V93, P2140, DOI 10.1016/j.sigpro.2012.06.026
NR 50
TC 5
Z9 5
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2016
VL 53
BP 20
EP 34
DI 10.1016/j.imavis.2015.07.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DX4YH
UT WOS:000384386500003
DA 2024-07-18
ER

PT J
AU Dong, Z
   Pei, MT
   Jia, YD
AF Dong, Zhen
   Pei, Mingtao
   Jia, Yunde
TI Orthonormal dictionary learning and its application to face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Orthonormal dictionary learning; Low-rank representation; Face
   recognition
ID RANK MATRIX RECOVERY; DISCRIMINATIVE DICTIONARY; SPARSE REPRESENTATION;
   K-SVD; ALGORITHM
AB This paper presents an orthonormal dictionary learning method for low-rank representation. The orthonormal property encourages the dictionary atoms to be as dissimilar as possible, which is beneficial for reducing the ambiguities of representations and computation cost. To make the dictionary more discriminative, we enhance the ability of the class-specific dictionary to well represent samples from the associated class and suppress the ability of representing samples from other classes, and also enforce the representations that have small within-class scatter and big between-class scatter. The learned orthonormal dictionary is used to obtain low-rank representations with fast computation. The performances of face recognition demonstrate the effectiveness and efficiency of the method. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Dong, Zhen; Pei, Mingtao; Jia, Yunde] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Pei, MT (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM dongzhen@bit.edu.cn; peimt@bit.edu.cn; jiayunde@bit.edu.cn
FU Natural Science Foundation of China (NSFC) [61472038, 61375044];
   Specialized Research Fund for the Doctoral Program of Higher Education
   of China [20121101120029]
FX This work was supported in part by the Natural Science Foundation of
   China (NSFC) under grant no. 61472038 and no. 61375044, and the
   Specialized Research Fund for the Doctoral Program of Higher Education
   of China (20121101120029).
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], BMVC
   [Anonymous], 2002, THESIS STANFORD U
   [Anonymous], IEEE COMP SOC C COMP
   Bao CL, 2014, LECT NOTES COMPUT SC, V8694, P302, DOI 10.1007/978-3-319-10599-4_20
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chen CF, 2012, PROC CVPR IEEE, P2618, DOI 10.1109/CVPR.2012.6247981
   Chen Y. C., 2012, DICT BASED FACE RECO, P766, DOI 10.1007/978-3-642-33783-3_55
   Chen YL, 2013, J MATER CHEM A, V1, P13301, DOI 10.1039/c3ta12911j
   Cui Z, 2012, PROC CVPR IEEE, P2626, DOI 10.1109/CVPR.2012.6247982
   Gao SH, 2015, INT J COMPUT VISION, V111, P365, DOI 10.1007/s11263-014-0750-4
   Gao SH, 2014, IEEE T IMAGE PROCESS, V23, P623, DOI 10.1109/TIP.2013.2290593
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Kim M., 2008, PROC CVPR IEEE, P1
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kong S, 2012, LECT NOTES COMPUT SC, V7572, P186, DOI 10.1007/978-3-642-33718-5_14
   Lee KC, 2003, PROC CVPR IEEE, P313
   Li A, 2015, IEEE I CONF COMP VIS, P3613, DOI 10.1109/ICCV.2015.412
   Li HX, 2015, PROC CVPR IEEE, P4055, DOI 10.1109/CVPR.2015.7299032
   Li Lingjun., 2013, NDSS, V56, P57, DOI DOI 10.1109/NSSMIC.2013.6829098
   Lin Z., 2011, ADV NEURAL INFORM PR, V24, P612, DOI DOI 10.1007/S11263-013-0611-6
   Liu G., 2010, P INT C MACH LEARN, P663
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Lu JW, 2015, IEEE I CONF COMP VIS, P3721, DOI 10.1109/ICCV.2015.424
   Lu JW, 2014, LECT NOTES COMPUT SC, V8689, P265, DOI 10.1007/978-3-319-10590-1_18
   Lu JW, 2013, IEEE I CONF COMP VIS, P329, DOI 10.1109/ICCV.2013.48
   Ma L, 2012, PROC CVPR IEEE, P2586, DOI 10.1109/CVPR.2012.6247977
   Martinez A.M., 1998, AR FACE DATABASE CVC
   PATI YC, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P40, DOI 10.1109/ACSSC.1993.342465
   Ramirez I, 2010, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR.2010.5539964
   Shu XB, 2014, PROC CVPR IEEE, P3874, DOI 10.1109/CVPR.2014.495
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Q, 2015, IEEE T CIRC SYST VID, V25, P638, DOI 10.1109/TCSVT.2014.2339571
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Wang W, 2015, PROC CVPR IEEE, P3395, DOI 10.1109/CVPR.2015.7298816
   Wolf Lior, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P88
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2015, COMPUT VIS IMAGE UND, V136, P59, DOI 10.1016/j.cviu.2015.01.006
   Yang F, 2014, IEEE WINT CONF APPL, P854, DOI 10.1109/WACV.2014.6836014
   Yang M, 2015, NEUROCOMPUTING, V168, P70, DOI 10.1016/j.neucom.2015.06.013
   Yang M, 2014, PROC CVPR IEEE, P4138, DOI 10.1109/CVPR.2014.527
   Yang M, 2014, INT J COMPUT VISION, V109, P209, DOI 10.1007/s11263-014-0722-8
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Zhang GX, 2015, LECT NOTES COMPUT SC, V9005, P97, DOI 10.1007/978-3-319-16811-1_7
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang YMZ, 2013, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2013.93
   Zheng ZL, 2014, PATTERN RECOGN, V47, P3502, DOI 10.1016/j.patcog.2014.05.001
   Zhou N, 2014, IEEE T PATTERN ANAL, V36, P715, DOI 10.1109/TPAMI.2013.189
   Zhou N, 2012, PROC CVPR IEEE, P3490, DOI 10.1109/CVPR.2012.6248091
NR 57
TC 11
Z9 11
U1 2
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2016
VL 51
BP 13
EP 21
DI 10.1016/j.imavis.2016.03.010
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4HB
UT WOS:000378455900002
DA 2024-07-18
ER

PT J
AU Poling, B
   Lerman, G
AF Poling, Bryan
   Lerman, Gilad
TI Enhancing feature tracking with gyro regularization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature tracking; Optical flow; Inertial sensors; Gyroscopes
ID FUSION
AB We present a deeply integrated method of exploiting low-cost gyroscopes to improve general purpose feature tracking. Most previous methods use gyroscopes to initialize and bound the search for features. In contrast, we use them to regularize the tracking energy function so that they can directly assist in the tracking of ambiguous and poor-quality features. We demonstrate that our simple technique offers significant improvements in performance over conventional template-based tracking methods, and is in fact competitive with more complex and computationally expensive state-of-the-art trackers, but at a fraction of the computational cost. Additionally, we show that the practice of initializing template-based feature trackers like KLT (Kanade-Lucas-Tomasi) using gyro-predicted optical flow offers no advantage over using a careful optical-only initialization method, suggesting that some deeper level of integration, like the method we propose, is needed in order to realize a genuine improvement in tracking performance from these inertial sensors. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Poling, Bryan; Lerman, Gilad] Univ Minnesota, Sch Math, 127 Vincent Hall,206 Church St SE, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Lerman, G (corresponding author), Univ Minnesota, Sch Math, 127 Vincent Hall,206 Church St SE, Minneapolis, MN 55455 USA.
EM poli0048@math.umn.edu; lerman@umn.edu
OI Lerman, Gilad/0000-0003-4624-3115
FU NSF [DMS-09-56072, DMS-14-18386]; University of Minnesota Doctoral
   Dissertation Fellowship Program; Feinberg Foundation Visiting Faculty
   Program Fellowship of the Weizmann Institute of Science; Division Of
   Mathematical Sciences; Direct For Mathematical & Physical Scien
   [1418386, 0956072] Funding Source: National Science Foundation
FX We are thankful to the anonymous reviewer and the action editor for
   their very helpful comments that improved the presentation of the paper
   and its supplementary material. This work was supported by NSF awards
   DMS-09-56072 and DMS-14-18386, the University of Minnesota Doctoral
   Dissertation Fellowship Program, and the Feinberg Foundation Visiting
   Faculty Program Fellowship of the Weizmann Institute of Science.
CR [Anonymous], 2011, 201103 CSTR STANF U
   [Anonymous], 2001, Pyramidal implementation of the Lucas Kanade Feature Tracker Description of the Algorithm
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Buchanan A., 2007, CVPR, P1
   Chi V., 1998, QUANTERNIONS ROTATIO
   Diel DavidD., 2005, Proceedings of the IEEE Workshop on Motion and Video Computing, V2, P221
   Gray J.R., 2009, Deeply-integrated Feature Tracking for Embedded Navigation
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hol JD, 2007, J REAL-TIME IMAGE PR, V2, P149, DOI 10.1007/s11554-007-0040-2
   Hwangbo M, 2011, INT J ROBOT RES, V30, P1755, DOI 10.1177/0278364911416391
   Jones ES, 2011, INT J ROBOT RES, V30, P407, DOI 10.1177/0278364910388963
   Joshi N, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778767
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Mourikis AI, 2009, IEEE T ROBOT, V25, P264, DOI 10.1109/TRO.2009.2012342
   Pachter M, 2010, P AMER CONTR CONF, P3975
   Poling B, 2014, PROC CVPR IEEE, P3454, DOI 10.1109/CVPR.2014.441
   Roumeliotis SI, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P4326, DOI 10.1109/ROBOT.2002.1014441
   Sachs David., IMAGE STABILIZATION
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Tomasi C, 1991, DETECTION TRACKING P
   Veth MM, 2006, I NAVIG SAT DIV INT, P1093
   Veth MichaelJ., 2006, Fusion of Imaging and Inertial Sensors for Navigation
   You S, 1999, P IEEE VIRT REAL ANN, P260, DOI 10.1109/VR.1999.756960
NR 23
TC 2
Z9 2
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2016
VL 50
BP 42
EP 58
DI 10.1016/j.imavis.2016.01.004
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4KP
UT WOS:000378465100004
OA Bronze, Green Submitted
DA 2024-07-18
ER

PT J
AU Gao, Y
   Liu, H
   Sun, XH
   Wang, C
   Liu, Y
AF Gao, Yuan
   Liu, Hong
   Sun, Xiaohu
   Wang, Can
   Liu, Yi
TI Violence detection using Oriented VIolent Flows
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Violence detection; Oriented VIolent Flows; AdaBoost; SVM
ID RECOGNITION
AB Nowadays, with so many surveillance cameras having been installed, the market demand for intelligent violence detection is continuously growing, while it is still a challenging topic in research area. Therefore, we attempt to make some improvements of existing violence detectors. The primary contributions of this paper are two-fold. Firstly, a novel feature extraction method named Oriented VIolent Flows (OViF), which takes full advantage of the motion magnitude change information in statistical motion orientations, is proposed for practical violence detection in videos. The comparison of OViF and baseline approaches on two public databases demonstrates the efficiency of the proposed method. Secondly, feature combination and multi classifier combination strategies are adopted and excellent results are obtained. Experimental results show that using combined features with AdaBoost+Linear-SVM achieves improved performance over the state-of-the-art on the Violent-Flows benchmark. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Gao, Yuan; Liu, Hong; Sun, Xiaohu; Wang, Can; Liu, Yi] Peking Univ, Shenzhen Grad Sch, Key Lab Machine Percept, Beijing 100871, Peoples R China.
   [Liu, Yi] PKU HKUST Shenzhen Hong Kong Inst, IMSL Shenzhen Key Lab, Shenzhen 518057, Peoples R China.
C3 Peking University; Peking University; PKU-HKUST Shenzhen HongKong
   Institution; Hong Kong University of Science & Technology
RP Liu, H (corresponding author), Peking Univ, Shenzhen Grad Sch, Key Lab Machine Percept, Beijing 100871, Peoples R China.
EM ygao@sz.pku.edu.cn; hongliu@pku.edu.cn; xiaohusun@pku.edu.cn;
   canwang@pku.edu.cn; yi.liu@imsl.org.cn
OI Gao, Yuan/0000-0003-1406-1843
FU National Natural Science Foundation of China (NSFC) [61340046]; National
   High Technology Research and Development Program of China (863 Program)
   [2006AA04Z247]; Science and Technology Innovation Commission of Shenzhen
   Municipality [JCYJ20120614152234873, JCYJ20130331144716089]; Specialized
   Research Fund for the Doctoral Program of Higher Education
   [20130001110011]; Natural Science Foundation of Guangdong Province
   [2015A030311034]
FX This work is supported by National Natural Science Foundation of China
   (NSFC, No.61340046), National High Technology Research and Development
   Program of China (863 Program, No.2006AA04Z247), Science and Technology
   Innovation Commission of Shenzhen Municipality (No.
   JCYJ20120614152234873, No. JCYJ20130331144716089), Specialized Research
   Fund for the Doctoral Program of Higher Education (No.20130001110011),
   Natural Science Foundation of Guangdong Province (No.2015A030311034).
CR [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Clarin C., 2005, PCSC, V6, P150
   Danafar S, 2007, LECT NOTES COMPUT SC, V4844, P457
   Datta A, 2002, INT C PATT RECOG, P433, DOI 10.1109/ICPR.2002.1044748
   Deniz O, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P478
   Dollar P., PIOTRS COMPUTER VISI
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Liang-Hua Chen, 2011, Proceedings of the 2011 Eighth International Conference on Computer Graphics, Imaging and Visualization (CGIV 2011), P119, DOI 10.1109/CGIV.2011.14
   Lin JA, 2009, LECT NOTES COMPUT SC, V5879, P930
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Nam J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P353, DOI 10.1109/ICIP.1998.723496
   Niebles J. C., 2007, COMPUTER VISION PATT, P1
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rota P, 2015, IEEE IMAGE PROC, P3456, DOI 10.1109/ICIP.2015.7351446
   Sun QR, 2013, IEEE IMAGE PROC, P3220, DOI 10.1109/ICIP.2013.6738663
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Zajdel W, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P200, DOI 10.1109/AVSS.2007.4425310
NR 24
TC 139
Z9 142
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR-MAY
PY 2016
VL 48-49
BP 37
EP 41
DI 10.1016/j.imavis.2016.01.006
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO4GS
UT WOS:000377740400004
DA 2024-07-18
ER

PT J
AU Martinez, B
   Pantic, M
AF Martinez, Brais
   Pantic, Maja
TI Facial landmarking for in-the-wild images with local inference based on
   global appearance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial landmarking; Regression; Part-based models; Gaussian processes
ID MEAN-SHIFT; MODELS
AB We present a novel method that tackles the problem of facial landmarking in unconstrained conditions within the part-based framework. Part-based methods alternate the evaluation of local appearance models to produce a per-point response map and a shape fitting step which finds a valid face shape that maximises the sum of the per-point responses. Our approach focuses on obtaining better appearance models for the creation of the response maps, and it can be used in combination with any shape fitting strategy. Local appearance models need to tackle very heterogeneous data when dealing with in-the-wild imagery due to factors as varying head poses, facial expressions, identity, lighting conditions, or image quality among others. Pose-wise experts are typically used in this scenario so that each expert deals with more homogeneous data. However, the computation cost at test time is significantly increased. Furthermore, choosing the right expert is not straightforward, which can lead to gross errors. We propose to dynamically select at test time the training examples used for inference. We use a global similarity measure to select the most adequate training examples for inference, and create a single test sample-specific expert using a localised inference technique. To illustrate the validity of these ideas, we capitalise on the recently proposed use of regression to generate local appearance models. In particular, we use Gaussian processes, as their non-parametric nature easily allows for localised regression. This novel way of constructing the response maps is combined with two state-of-the-art standard shape fitting algorithms, the popular Constrained Local Models framework and the Consensus of Exemplars method. We validate our method on two publicly available datasets as well as on a cross-dataset experiment showing a considerable performance improvement of the proposed approach. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Martinez, Brais; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
   [Pantic, Maja] Univ Twente, Dept Comp Sci, NL-7500 AE Enschede, Netherlands.
C3 Imperial College London; University of Twente
RP Martinez, B (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, Intelligent Behav Understanding Grp, 180 Queens Gate, London SW7 2AZ, England.
EM brais.martinez@imperial.ac.uk
FU Engineering and Physical Sciences Research Council (EPSRC)
   [EP/J017787/1]; EPSRC [EP/H016988/1]; EPSRC [EP/H016988/1, EP/J017787/1]
   Funding Source: UKRI
FX This work has been funded in part by the Engineering and Physical
   Sciences Research Council (EPSRC) project EP/J017787/1 Analysis of
   Facial Behaviour for Security in 4D (4D-FAB). The work of Brais Martinez
   is also funded in part by the EPSRC grant EP/H016988/1: Pain
   rehabilitation: E/Motion-based automated coaching.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], IEEE C COMP VIS PATT
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Carreira-Perpiñán MA, 2007, IEEE T PATTERN ANAL, V29, P767, DOI 10.1109/TPAMI.2007.1057
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Jiang BH, 2014, IEEE T CYBERNETICS, V44, P161, DOI 10.1109/TCYB.2013.2249063
   Ladicky L., 2011, Proceedings of the 28th International Conference on Machine Learning (ICML-11), P985
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Nguyen-Tuong D., 2009, Advances in neural information processing systems, P1193
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Snelson E., 2005, ADV NEURAL INFORM PR, V18
   Tzimiropoulos Georgios, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P650, DOI 10.1007/978-3-642-37431-9_50
   Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zhang H., 2006, 2006 IEEE COMP SOC C, V2, P2126, DOI DOI 10.1109/CVPR.2006.301
   Zhu X., 2012, BRIT MACH VIS C
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 30
TC 5
Z9 6
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2015
VL 36
BP 40
EP 50
DI 10.1016/j.imavis.2015.01.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CG2GV
UT WOS:000353093800004
OA Green Published
DA 2024-07-18
ER

PT J
AU Elguebaly, T
   Bouguila, N
AF Elguebaly, Tarek
   Bouguila, Nizar
TI Simultaneous high-dimensional clustering and feature selection using
   asymmetric Gaussian mixture models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Asymmetric Gaussian distribution; Mixture modeling;
   Expectation-maximization (EM); Rival penalized EM (RPEM); Feature
   selection; Model selection; Minimum message length (MML); Scene
   categorization; Facial expression recognition
ID FACIAL EXPRESSION RECOGNITION; FACE-RECOGNITION; SCENE CLASSIFICATION;
   IMAGE CLASSIFICATION; ACTION UNITS; SEQUENCES; FRAMEWORK; TRACKING
AB Finite mixture models are broadly applied in a wide range of applications concerning density estimation and clustering due to their sound mathematical basis and to the interpretability of their results. Indeed, they permit the incorporation of domain knowledge which allows the provision of better insight into the nature of the clusters and then uncovers application-specific desirable patterns that the practitioner is looking for. However, most of the works done on mixture models, when applied to computer vision tasks, assume that per-component data follow a mixture of Gaussians which may not hold as data are generally non-Gaussian (for instance, it is well-known that the distribution of natural images is highly non-Gaussian). The effect of the Gaussian mixture is analogous to the deployment of Euclidean or Mahalanobis type distances for discrimination purposes. Thus, this mixture cannot be applied efficiently in several applications involving asymmetric shapes. In this paper, we overcome this problem by using the asymmetric Gaussian mixture (AGM) model. The AGM can change its shape to model non-symmetrical and heavy tailed real world data which make it a good choice for modeling data with outliers. Modern computer vision applications generally generate complex high-dimensional data and usually, some features are noisy, redundant, or uninformative which may affect the speed and also compromise the accuracy of the used learning algorithm. Therefore, this paper addresses also the problem of unsupervised feature selection when considering AGM models. We propose two approaches for learning the resulting statistical framework. The first approach is based on the minimization of a message length objective and the second one considers rival penalized competitive learning. Our extensive simulations and experiments involving two challenging tasks namely visual scene categorization and facial expression recognition indicate that the method developed in this paper is efficient and has merits. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Elguebaly, Tarek] Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1T7, Canada.
   [Bouguila, Nizar] Concordia Univ, CIISE, Montreal, PQ H3G 1T7, Canada.
C3 Concordia University - Canada; Concordia University - Canada
RP Elguebaly, T (corresponding author), Concordia Univ, Dept Elect & Comp Engn, Montreal, PQ H3G 1T7, Canada.
EM t_elgue@encs.concordia.ca; nizar.bouguila@concordia.ca
RI Bouguila, Nizar/AAJ-2518-2020; Bouguila, Nizar/AGN-5929-2022
CR Allili MS, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2898125
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], 2006, P IEEE C COMPUTER VI
   [Anonymous], 2005, Statistical and Inductive Inference by Minimum Message Length
   [Anonymous], 2010, P NIPS
   Bart E, 2005, PROC CVPR IEEE, P672
   Bartlett MS, 1999, PSYCHOPHYSIOLOGY, V36, P253, DOI 10.1017/S0048577299971664
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Batlle J, 2000, IMAGE VISION COMPUT, V18, P515, DOI 10.1016/S0262-8856(99)00040-2
   Bennett PaulN., 2003, SIGIR '03: Proceedings of the 26th annual international ACM SIGIR conference on Research and development in informaion retrieval, P111
   Black MJ, 2000, INT J COMPUT VISION, V38, P231, DOI 10.1023/A:1008195307933
   Blair RJR, 1999, BRAIN, V122, P883, DOI 10.1093/brain/122.5.883
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Bouguila N, 2009, PATTERN RECOGN, V42, P33, DOI 10.1016/j.patcog.2008.06.022
   Bouguila N, 2007, IEEE T PATTERN ANAL, V29, P1716, DOI [10.1109/TPAMI.2007.1095, 10.1109/TPAMl.2007.1095]
   Boutemedjet S, 2007, LECT NOTES ARTIF INT, V4702, P30
   Boutemedjet S, 2009, IEEE T PATTERN ANAL, V31, P1429, DOI 10.1109/TPAMI.2008.155
   Browne RP, 2012, IEEE T PATTERN ANAL, V34, P814, DOI 10.1109/TPAMI.2011.199
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Chen XW, 2003, PATTERN RECOGN LETT, V24, P1295, DOI 10.1016/S0167-8655(02)00371-9
   Cheung HM, 2002, ICONIP'02: PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON NEURAL INFORMATION PROCESSING, P467
   Cheung YM, 2006, 2006 INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY, PTS 1 AND 2, PROCEEDINGS, P633, DOI 10.1109/ICCIAS.2006.294213
   Cheung YM, 2005, IEEE T KNOWL DATA EN, V17, P750, DOI 10.1109/TKDE.2005.97
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   Chuang CF, 2006, PATTERN RECOGN, V39, P1795, DOI 10.1016/j.patcog.2006.03.017
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Edwards GJ, 1998, IMAGE VISION COMPUT, V16, P203, DOI 10.1016/S0262-8856(97)00069-3
   Elguebaly T, 2014, MACH VISION APPL, V25, P1145, DOI 10.1007/s00138-013-0568-z
   Elguebaly T, 2011, SIGNAL PROCESS, V91, P801, DOI 10.1016/j.sigpro.2010.08.014
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fei-Fei L, 2007, J VISION, V7, DOI 10.1167/7.1.10
   Feng X., 2005, Pattern Recognition and Image Analysis, V15, P546
   Galleguillos C, 2008, PROC CVPR IEEE, P3552
   Galleguillos C, 2010, COMPUT VIS IMAGE UND, V114, P712, DOI 10.1016/j.cviu.2010.02.004
   Goldberger J, 2008, IEEE T PATTERN ANAL, V30, P1496, DOI 10.1109/TPAMI.2008.100
   Gupta A, 2008, LECT NOTES COMPUT SC, V5302, P16, DOI 10.1007/978-3-540-88682-2_3
   Hyvärinen A, 2000, NEURAL COMPUT, V12, P1705, DOI 10.1162/089976600300015312
   JAIN AK, 1981, P IEEE, V69, P502, DOI 10.1109/PROC.1981.12021
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kimura S, 1997, PROC CVPR IEEE, P295, DOI 10.1109/CVPR.1997.609338
   Kobayashi H, 1997, IEEE SYS MAN CYBERN, P3732, DOI 10.1109/ICSMC.1997.633250
   Kotch A., 2002, P 8 ACM SIGKDD INT C, P307
   Kumar S, 2005, IEEE I CONF COMP VIS, P1284
   Lam KM, 1996, PATTERN RECOGN, V29, P771, DOI 10.1016/0031-3203(95)00119-0
   Law MHC, 2004, IEEE T PATTERN ANAL, V26, P1154, DOI 10.1109/TPAMI.2004.71
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   LeCun Y, 2004, PROC CVPR IEEE, P97
   LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724
   Li LJ, 2007, LECT NOTES ARTIF INT, V4456, P1
   Li YM, 2004, IMAGE VISION COMPUT, V22, P413, DOI 10.1016/j.imavis.2003.12.005
   Li YH, 2009, IEEE T PATTERN ANAL, V31, P953, DOI 10.1109/TPAMI.2008.261
   Lien JJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P390, DOI 10.1109/AFGR.1998.670980
   Lien JJJ, 2000, ROBOT AUTON SYST, V31, P131, DOI 10.1016/S0921-8890(99)00103-7
   Littlewort G., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P298, DOI 10.1109/FG.2011.5771414
   Lu L, 2005, PROC CVPR IEEE, P688
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Martí J, 2001, IMAGE VISION COMPUT, V19, P1041, DOI 10.1016/S0262-8856(01)00065-8
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   McLachlan G. J., 1997, The EM Algorithm and Extensions, V473, P486
   McLachlan GJ, 1998, INT C PATT RECOG, P553, DOI 10.1109/ICPR.1998.711203
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Pantic M, 2000, IMAGE VISION COMPUT, V18, P881, DOI 10.1016/S0262-8856(00)00034-2
   Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Rocha A, 2010, COMPUT VIS IMAGE UND, V114, P349, DOI 10.1016/j.cviu.2009.10.002
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Serrano N, 2004, PATTERN RECOGN, V37, P1773, DOI 10.1016/j.patcog.2004.03.003
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Singhal A, 2003, PROC CVPR IEEE, P235
   Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254
   TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726
   Terzopoulos D., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P727, DOI 10.1109/ICCV.1990.139628
   Tian Y., 2004, IEEE International Conference on Computer Vision and Pattern Recognition, P82
   Tian Y., 2003, P IEEE WORKSH PERF E
   Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824
   Tsai CY, 2008, COMPUT STAT DATA AN, V52, P4658, DOI 10.1016/j.csda.2008.03.002
   van Gemert JC, 2008, LECT NOTES COMPUT SC, V5304, P696
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Whiteley MR, 1998, J OPT SOC AM A, V15, P802, DOI 10.1364/JOSAA.15.000802
   Wongun Choi, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3273, DOI 10.1109/CVPR.2011.5995707
   Wu HY, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P345, DOI 10.1109/AFGR.1996.557289
   Wu Y, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P529, DOI 10.1109/ICME.2006.262442
   Xie XD, 2006, IEEE T IMAGE PROCESS, V15, P2481, DOI 10.1109/TIP.2006.877435
   XU L, 1993, IEEE T NEURAL NETWOR, V4, P636, DOI 10.1109/72.238318
   Xu L, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P2525, DOI 10.1109/IJCNN.1998.687259
   Yaccob Y., 1994, Proceedings of the 12th IAPR International Conference on Pattern Recognition (Cat. No.94CH3440-5), P747, DOI 10.1109/ICPR.1994.576429
   YACOOB Y, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P70, DOI 10.1109/CVPR.1994.323812
   YAMADA H, 1993, APPL COGNITIVE PSYCH, V7, P257, DOI 10.1002/acp.2350070309
   YongSeog Kim, 2000, Proceedings. KDD-2000. Sixth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, P365
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
   Zhou X, 2010, LECT NOTES COMPUT SC, V6315, P141, DOI 10.1007/978-3-642-15555-0_11
   ZHU J, 2010, ADV NEURAL INFORM PR, P2586
NR 99
TC 27
Z9 27
U1 0
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2015
VL 34
BP 27
EP 41
DI 10.1016/j.imavis.2014.10.011
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA5OB
UT WOS:000348956600003
DA 2024-07-18
ER

PT J
AU Matsui, S
   Nagahara, H
   Taniguchi, R
AF Matsui, Shuhei
   Nagahara, Hajime
   Taniguchi, Rin-ichiro
TI Half-sweep imaging for depth from defocus
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computational photography; Depth from defocus; Image deblurring
AB Depth from defocus (DFD) is a technique that restores scene depth based on the amount of defocus blur in the images. DFD usually captures two differently focused images, one near-focused and the other far-focused, and calculates the size of the defocus blur in these images. However, DFD using a regular circular aperture is not sensitive to depth, since the point spread function (PSF) is symmetric and only the radius changes with the depth. In recent years, the coded aperture technique, which uses a special pattern for the aperture to engineer the PSF, has been used to improve the accuracy of DFD estimation. The technique is often used to restore an all-in-focus image and estimate depth in DFD applications. Use of a coded aperture has a disadvantage in terms of image deblurring, since deblurring requires a higher signal-to-noise ratio (SNR) of the captured images. The aperture attenuates incoming light in controlling the PSF and, as a result decreases the input image SNR. In this paper, we propose a new computational imaging approach for DFD estimation using focus changes during image integration to engineer the PSF. We capture input images with a higher SNR since we can control the PSF with a wide aperture setting unlike with a coded aperture. We confirm the effectiveness of the method through experimental comparisons with conventional DFD and the coded aperture approach. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Matsui, Shuhei; Nagahara, Hajime; Taniguchi, Rin-ichiro] Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Nishi Ku, Fukuoka 8190395, Japan.
C3 Kyushu University
RP Matsui, S (corresponding author), Kyushu Univ, Grad Sch Informat Sci & Elect Engn, Nishi Ku, 744 Motooka, Fukuoka 8190395, Japan.
CR Dowski E.R., 1994, APPL OPT, V33
   Green P, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1276377.1276462
   Hasinoff SW, 2009, IEEE I CONF COMP VIS, P333, DOI 10.1109/ICCV.2009.5459269
   Hiura S, 1998, PROC CVPR IEEE, P953, DOI 10.1109/CVPR.1998.698719
   Kuthirummal S, 2011, IEEE T PATTERN ANAL, V33, P58, DOI 10.1109/TPAMI.2010.66
   Levin A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239521
   Levin A, 2010, LECT NOTES COMPUT SC, V6311, P214, DOI 10.1007/978-3-642-15549-9_16
   Levin A, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531403
   Matsui S, 2011, LECT NOTES COMPUT SC, V7087, P335
   Nagahara H., 2008, P EUR C COMP VIS
   Nagahara H, 2010, LECT NOTES COMPUT SC, V6316, P337, DOI 10.1007/978-3-642-15567-3_25
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Rajagopalan AN, 1997, PROC CVPR IEEE, P219, DOI 10.1109/CVPR.1997.609323
   Subbarao M., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P498, DOI 10.1109/CVPR.1988.196281
   Surya G., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P61, DOI 10.1109/CVPR.1993.340978
   Veeraraghavan A, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239520
   Zhou C., 2009, P IEEE INT C COMP PH
   Zhou CY, 2009, IEEE I CONF COMP VIS, P325, DOI 10.1109/ICCV.2009.5459268
   Zhou CY, 2011, INT J COMPUT VISION, V93, P53, DOI 10.1007/s11263-010-0409-8
NR 19
TC 9
Z9 9
U1 2
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 954
EP 964
DI 10.1016/j.imavis.2014.09.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900012
DA 2024-07-18
ER

PT J
AU Wang, D
   Shan, SG
   Zhang, HM
   Zeng, W
   Chen, XL
AF Wang, Dan
   Shan, Shiguang
   Zhang, Hongming
   Zeng, Wei
   Chen, Xilin
TI Data-driven hair segmentation with isomorphic manifold inference
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hair segmentation; Data driven; Shape model; Isomorphic manifold
   inference
ID TEXTURE; CLASSIFICATION; REGRESSION
AB Hair segmentation is challenging due to the diverse appearance, irregular region boundary and the influence of complex background. To deal with this problem, we propose a novel data-driven method, named Isomorphic Manifold Inference (IMI). The IMI method assumes the coarse probability map and the binary segmentation map as a couple of isomorphic manifolds and tries to learn hair specific priors from manually labeled training images. For an input image, firstly, the method calculates a coarse probability map. Then it exploits regression techniques to obtain the relationship between the coarse probability map of the test image and those of training images. Finally, this relationship, i.e., a coefficient set, is transferred to the binary segmentation maps and a soft segmentation of the test image will be achieved by a linear combination of those binary maps. Further, we employ this soft segmentation as a shape cue and integrate it with color and texture cues into a unified segmentation framework. A better segmentation is achieved by the Graph Cuts optimization. Extensive experiments are conducted to validate effectiveness of the IMI method, compare contributions of different cues and investigate the generalization of IMI method. The results strongly encourage our method. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Wang, Dan] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Wang, Dan; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Key Lab Intelligent Informat Proc, Inst Comp Technol, Beijing, Peoples R China.
   [Zhang, Hongming; Zeng, Wei] NEC Labs China, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Computing Technology, CAS
RP Shan, SG (corresponding author), 6 Kexueyuan South Rd, Beijing 100190, Peoples R China.
EM sgshan@ict.ac.cn
OI Shan, Shiguang/0000-0002-8348-392X
FU Natural Science Foundation of China [61025010, 61222211, 61272321]
FX This paper is partially supported by Natural Science Foundation of China
   under contracts No. 61025010, No. 61222211, and 61272321.
CR Alexe B, 2010, LECT NOTES COMPUT SC, V6315, P380, DOI 10.1007/978-3-642-15555-0_28
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], 2010, P AS C COMP VIS ACCV
   [Anonymous], LEARNED MILLER LABEL
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bertails F., 2005, EUROGRAPHICS SHORT P
   Bertails F, 2006, ACM T GRAPHIC, V25, P1180, DOI 10.1145/1141911.1142012
   Bertelli L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2153, DOI 10.1109/CVPR.2011.5995597
   Borenstein E, 2004, LECT NOTES COMPUT SC, V3023, P315
   Borenstein E., 2002, Computer Vision- ECCV 2002, P639
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen H, 2006, IEEE T PATTERN ANAL, V28, P1025, DOI 10.1109/TPAMI.2006.131
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Felzenszwalb P. F., 2008, P INT C COMPUTER VIS, P1
   Friedman J., 2001, The Elements of Statistical Learning, V10, DOI 10.1007/978-0-387-21606-5
   He XM, 2006, LECT NOTES COMPUT SC, V3951, P338
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Julian P., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4617, DOI 10.1109/ICPR.2010.1134
   Kampmann M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 2, P876, DOI 10.1109/ICIP.1998.723696
   Kumar MP, 2005, PROC CVPR IEEE, P18
   LEE K., 2008, P IEEE VEHICULAR TEC, P1
   Levin A, 2006, LECT NOTES COMPUT SC, V3954, P581
   Liu ZQ, 1996, ISSPA 96 - FOURTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, PROCEEDINGS, VOLS 1 AND 2, P575
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Ning JF, 2010, PATTERN RECOGN, V43, P445, DOI 10.1016/j.patcog.2009.03.004
   Rousset C, 2008, IEEE IMAGE PROC, P2276, DOI 10.1109/ICIP.2008.4712245
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Ueki K, 2004, INT C PATT RECOG, P446, DOI 10.1109/ICPR.2004.1333798
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34
   Wang D, 2009, IEEE IMAGE PROC, P2401, DOI 10.1109/ICIP.2009.5414215
   Wang N, 2012, PROC CVPR IEEE, P662, DOI 10.1109/CVPR.2012.6247734
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Winn J, 2005, IEEE I CONF COMP VIS, P756
   Yacoob Y, 2006, IEEE T PATTERN ANAL, V28, P1164, DOI 10.1109/TPAMI.2006.139
   Zhang Z, 2008, IEEE IMAGE PROC, P1644, DOI 10.1109/ICIP.2008.4712087
NR 42
TC 2
Z9 2
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 739
EP 750
DI 10.1016/j.imavis.2014.02.011
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700011
DA 2024-07-18
ER

PT J
AU Yan, JJ
   Zhang, XZ
   Lei, Z
   Li, SZ
AF Yan, Junjie
   Zhang, Xuzong
   Lei, Zhen
   Li, Stan Z.
TI Face detection by structural models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face detection; Structural model; Face-body co-occurrence
ID OBJECT DETECTION; POSE ESTIMATION; LBP
AB Despite the successes in the last two decades, the state-of-the-art face detectors still have problems in dealing with images in the wild due to large appearance variations. Instead of leaving appearance variations directly to statistical learning algorithms, we propose a hierarchical part based structural model to explicitly capture them. The model enables part subtype option to handle local appearance variations such as closed and open month, and part deformation to capture the global appearance variations such as pose and expression. In detection, candidate window is fitted to the structural model to infer the part location and part subtype, and detection score is then computed based on the fitted configuration. In this way, the influence of appearance variation is reduced. Besides the face model, we exploit the co-occurrence between face and body, which helps to handle large variations, such as heavy occlusions, to further boost the face detection performance. We present a phrase based representation for body detection, and propose a structural context model to jointly encode the outputs of face detector and body detector. Benefit from the rich structural face and body information, as well as the discriminative structural learning algorithm, our method achieves state-of-the-art performance on FDDB, AFW and a self-annotated dataset, under wide comparisons with commercial and academic methods. (C) 2013 Elsevier B.V. All rights reserved.
C1 Chinese Acad Sci, Ctr Biometr & Secur Res, Beijing 100190, Peoples R China.
   Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Chinese Academy of Sciences; Institute of
   Automation, CAS
RP Lei, Z (corresponding author), 1402 Intelligent Bldg, Beijing, Peoples R China.
EM jjyan@nlpr.ia.ac.cn; xucong.zhang1990@gmail.com; zlei@nlpr.ia.ac.cn;
   szli@nlpr.ia.ac.cn
RI Yan, Junjie/C-6064-2016; Lei, Zhen/JOJ-8587-2023; Li, SY/JPK-3839-2023
OI Lei, Zhen/0000-0002-6544-023X; Li, SY/0009-0000-9254-7115
FU Chinese National Natural Science Foundation [61070146, 61105023,
   61103156, 61105037, 61203267, 61375037]; National IoT RD Project
   [2150510]; National Science and Technology Support Program
   [2013BAK02B01]; Chinese Academy of Sciences [KGZD-EW-102-2]; European
   Union FP7 Project [257289]; Authen-Metric RD Funds
FX We thank the reviewers and editors for helpful feedbacks. This work is
   supported by the Chinese National Natural Science Foundation Projects
   #61070146, #61105023, #61103156, #61105037, #61203267, and #61375037,
   the National IoT R&D Project #2150510, the National Science and
   Technology Support Program Project #2013BAK02B01, the Chinese Academy of
   Sciences Project No. KGZD-EW-102-2, the European Union FP7 Project
   #257289 (TABULA RASA), and Authen-Metric R&D Funds.
CR Ali K, 2012, IEEE T PATTERN ANAL, V34, P225, DOI 10.1109/TPAMI.2011.117
   [Anonymous], 2010, UMCS2010009
   [Anonymous], 2008, Proceedings of the Twenty-Fifth International Conference on Machine Learning
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P EEE COMP SOC C COM
   [Anonymous], 2003, TR200396 MITS EL RES
   [Anonymous], 2010, ECCV
   [Anonymous], 2012, PASCAL VISUAL OBJECT
   [Anonymous], 2013, IEEE C COMP VIS PATT
   [Anonymous], COMP VIS PATT REC 20
   Bourdev L, 2005, PROC CVPR IEEE, P236, DOI 10.1109/cvpr.2005.310
   Bourdev L, 2013, TPAMI
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Cevikalp H, 2013, AUT FAC GEST REC FG
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Desai C, 2009, IEEE I CONF COMP VIS, P229, DOI 10.1109/ICCV.2009.5459256
   Felzenszwalb P.F., 2010, Discriminatively trained deformable part models, release 4
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Girshick R. B., 2011, Advances in Neural Information Processing Systems, P442
   Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011
   Jain A. K., 2011, HDB FACE RECOGNITION
   Jain V, 2011, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2011.5995317
   Jianguo Li, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2183, DOI 10.1109/ICCVW.2011.6130518
   Kalal Z., 2008, BMVC, DOI DOI 10.5244/C.22.42
   Kanade Takeo, 1973, Picture processing system by computer complex and recognition of human faces
   Koestinger M., 2011, WORKSH BENCHM FAC IM
   Kokkinos I., 2011, Advances in Neural Information Processing Systems NIPS, P2681
   Kotropoulos C, 1997, INT CONF ACOUST SPEE, P2537, DOI 10.1109/ICASSP.1997.595305
   KRUPPA H, 2003, P BMVC NORW ENGL, P3
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Li SZ, 2002, LECT NOTES COMPUT SC, V2353, P67
   Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sadeghi MA, 2011, PROC CVPR IEEE, P1745, DOI 10.1109/CVPR.2011.5995711
   Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Shen X, 2013, COMP VIS PATT REC CV, P4321
   Subburaman V.B., 2010, ECCV WORKSH FAC DET, V7
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Viola P., 2006, Proceedings of Advances in Neural Information Processing Systems, V18, P1417
   Wu JX, 2008, IEEE T PATTERN ANAL, V30, P369, DOI 10.1109/TPAMI.2007.1181
   Xiao R, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P709
   Yan JJ, 2013, IEEE INT CONF AUTOMA
   Yan JJ, 2013, INT CONF BIOMETR
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Zhang C., 2010, Microsoft Research
   Zhang JE, 2011, PROC CVPR IEEE, P1393, DOI 10.1109/CVPR.2011.5995678
   Zhang L, 2007, LECT NOTES COMPUT SC, V4642, P11
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 54
TC 106
Z9 122
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 790
EP 799
DI 10.1016/j.imavis.2013.12.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700016
DA 2024-07-18
ER

PT J
AU Patterson, T
   McClean, S
   Morrow, P
   Parr, G
   Luo, CB
AF Patterson, Timothy
   McClean, Sally
   Morrow, Philip
   Parr, Gerard
   Luo, Chunbo
TI Timely autonomous identification of UAV safe landing zones
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE UAV safe landing zone detection; Terrain classification; Fuzzy logic;
   UAV safety
ID CLASSIFICATION
AB For many applications such as environmental monitoring in the aftermath of a natural disaster and mountain search-and-rescue, swarms of autonomous Unmanned Aerial Vehicles (UAVs) have the potential to provide a highly versatile and often relatively inexpensive sensing platform. Their ability to operate as an 'eye-in-the-sky', processing and relaying real-time colour imagery and other sensor readings facilitate the removal of humans from situations which may be considered dull, dangerous or dirty. However, as with manned aircraft they are likely to encounter errors, the most serious of which may require the UAV to land as quickly and safely as possible. Within this paper we therefore present novel work on autonomously identifying Safe Landing Zones (SLZs) which can be utilised upon occurrence of a safety critical event. Safe Landing Zones are detected and subsequently assigned a safety score either solely using multichannel aerial imagery or, whenever practicable by fusing knowledge in the form of Ordnance Survey (OS) map data with such imagery. Given the real-time nature of the problem we subsequently model two SLZ detection options one of which utilises knowledge enabling the UAV to choose an optimal, viable solution. Results are presented based on colour aerial imagery captured during manned flight demonstrating practical potential in the methods discussed. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Patterson, Timothy; McClean, Sally; Morrow, Philip; Parr, Gerard] Univ Ulster, Sch Comp & Informat Engn, Coleraine BT52 1SA, Londonderry, North Ireland.
   [Luo, Chunbo] Univ West Scotland, Sch Comp, Paisley PA1 2BE, Renfrew, Scotland.
C3 Ulster University; University of West Scotland
RP Patterson, T (corresponding author), Univ Ulster, Sch Comp & Informat Engn, Cromore Rd, Coleraine BT52 1SA, Londonderry, North Ireland.
EM t.patterson@ulster.ac.uk; si.mcclean@ulster.ac.uk;
   pj.morrow@ulster.ac.uk; gp.parr@ulster.ac.uk; chunbo.luo@uws.ac.uk
OI McClean, Sally/0000-0002-6871-3504; Parr, Gerard/0000-0002-9365-9132
FU Department for Employment and Learning studentship; Engineering and
   Physical Sciences Research Council (EPSRC) [EP/F064217/1, EP/F064179/1,
   EP/F06358X/1]; EPSRC [EP/G051674/1, EP/J016748/1, EP/F064179/1,
   EP/F06358X/1, EP/F064217/1, EP/E017061/1] Funding Source: UKRI
FX This research was supported by a Department for Employment and Learning
   studentship and through the Engineering and Physical Sciences Research
   Council (EPSRC) funded Sensing Unmanned Autonomous Aerial Vehicles
   (SUAAVE) project under grants EP/F064217/1, EP/F064179/1 and
   EP/F06358X/1.
CR Almurib H., 2011, CONTROL PATH PLANNIN, P700
   [Anonymous], 2009, 2009 INT C ADV ROB
   [Anonymous], DIGITAL IMAGE PROCES
   Bryson M, 2010, J FIELD ROBOT, V27, P632, DOI 10.1002/rob.20343
   Cameron S., 2010, SUAAVE COMBINING AER, P7
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cesetti A, 2010, J INTELL ROBOT SYST, V57, P233, DOI 10.1007/s10846-009-9373-3
   Cesetti A., 2010, 2010 IEEE/ASME International Conference on Mechatronic and Embedded Systems and Applications (MESA 2010), P125, DOI 10.1109/MESA.2010.5552081
   Chen LP, 2004, 10TH INTERNATIONAL MULTIMEDIA MODELLING CONFERENCE, PROCEEDINGS, P273
   Cox TimothyH., 2004, Civil UAV Capability Assessment
   Fitzgerald D, 2005, Proceedings of the IASTED International Conference on Computational Intelligence, P187
   Fitzgerald D., 2005, AUSTR INT AER C MELB, P60
   Haddon C., 2004, UK CAA POLICY LIGHT
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   Howard A, 2004, IEEE T AERO ELEC SYS, V40, P1122, DOI 10.1109/TAES.2004.1386868
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Majidi B., 2005, P DIG IM COMP TECHN, V2005, P448, DOI DOI 10.1109/DICTA.2005.68
   Mejias Luis, 2009, Aerial Vehicles, P415
   Mera T., 2004, 9 INT S EXP ROB, P57
   Ochieng WY, 2003, J NAVIGATION, V56, P51, DOI 10.1017/S0373463302002096
   Ordnance Survey Northern Ireland, OSNI LARG SCAL TECHN
   Oruç I, 2003, VISION RES, V43, P2451, DOI 10.1016/S0042-6989(03)00435-8
   Pacheco H, 2011, LECT NOTES COMPUT SC, V7042, P709, DOI 10.1007/978-3-642-25085-9_84
   Patterson T., 2011, 2011 Canadian Conference on Computer and Robot Vision (CRV), P8, DOI 10.1109/CRV.2011.9
   Patterson T., 2010, 2010 IR MACH VIS IM, P291
   Patterson T., 2010, International Conference on Sensor Systems and Software, P36
   Richards J.A., 2006, Remote Sensing Digital Image Analysis: An Introduction, Vfourth
   Saripalli S., 2002, IEEE INT C ROB AUT 2, V3, P371
   Scherer S, 2012, IEEE INT CONF ROBOT, P951, DOI 10.1109/ICRA.2012.6225215
   Sevcik K.W., 2009, J INTELL ROBOT SYST, V57, P281
   Sharp CS, 2001, IEEE INT CONF ROBOT, P1720, DOI 10.1109/ROBOT.2001.932859
   Templeton T, 2007, IEEE INT CONF ROBOT, P1349, DOI 10.1109/ROBOT.2007.363172
   Zhou CH, 2008, J VISION, V8, DOI 10.1167/8.4.4
   Zsedrovits T., 2011, 2011 European Conference on Circuit Theory and Design (ECCTD 2011), P472, DOI 10.1109/ECCTD.2011.6043389
NR 34
TC 27
Z9 37
U1 2
U2 47
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2014
VL 32
IS 9
BP 568
EP 578
DI 10.1016/j.imavis.2014.06.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AO6QY
UT WOS:000341477800002
DA 2024-07-18
ER

PT J
AU Ko, B
   Park, J
   Nam, JY
AF Ko, ByoungChul
   Park, JunOh
   Nam, Jae-Yeal
TI Spatiotemporal bag-of-features for early wildfire smoke detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Wildfire smoke detection; Spatiotemporal feature; Bag-of-features;
   Histogram of oriented gradient; Histogram of oriented optical flow;
   Random forest
ID SEGMENTATION; FLOW
AB Wildfire smoke detection is particularly important for early warning systems, because smoke usually rises before flames arise. Therefore, this paper presents an automatic wildfire smoke detection method using computer vision and pattern recognition techniques. First, candidate blocks are identified using key-frame differences and nonparametric smoke color models to detect smoke-colored moving objects. Subsequently, three-dimensional spatiotemporal volumes are built by combining the candidate blocks in the current key-frame with the corresponding blocks in previous frames. A histogram of oriented gradient (HOG) is extracted, and a histogram of oriented optical flow (HOOF) is extracted as a temporal feature based on the fact that the direction of smoke diffusion is upward owing to thermal convection. From spatiotemporal features of training data, a visual codebook and a bag-of-features (BoF) histogram are generated using our proposed weighting scheme. For smoke verification, a random forest classifier is built during the training phase using the BoF histogram. The random forest with the BoF histogram can increase the detection accuracy performance when compared with related methods and allow smoke detection to be carried out in near real time. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Ko, ByoungChul; Park, JunOh; Nam, Jae-Yeal] Keimyung Univ Sindang Dong, Dept Comp Engn, Taegu 704701, South Korea.
C3 Keimyung University
RP Ko, B (corresponding author), Keimyung Univ Sindang Dong, Dept Comp Engn, Taegu 704701, South Korea.
EM niceko@kmu.ac.kr; jopark@kmu.ac.kr; jynam@kmu.ac.kr
CR [Anonymous], 2007, CIVR '07
   Benazza-Benyahia A, 2012, EUR SIGNAL PR CONF, P2752
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Deok-Yeon Kim, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P362, DOI 10.1109/ICME.2012.124
   Genovese A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR MEASUREMENT SYSTEMS AND APPLICATIONS (CIMSA), P34
   Habiboglu YH, 2011, EUR SIGNAL PR CONF, P894
   Ham S.J., 2011, SPIE ELECT IMAGING M, VIV, P1
   Heidemann G, 2005, IMAGE VISION COMPUT, V23, P861, DOI 10.1016/j.imavis.2005.05.016
   Jakovcevic T, 2011, INT SYMP IMAGE SIG, P480
   Ko B.C., 2012, OPT ENG, V51
   Ko B.C., 2012, OPT ENG, V57
   Ko BC, 2011, J DIGIT IMAGING, V24, P1141, DOI 10.1007/s10278-011-9380-3
   Ko BC, 2011, MICRON, V42, P695, DOI 10.1016/j.micron.2011.03.009
   Krstinic D, 2009, INF TECHNOL CONTROL, V38, P237
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Maree R., 2009, IPSJ T COMPUT VIS AP, V1, P46
   Niebles J.C., 2006, BRIT MACH VIS C, P1
   Norwak E., 2006, EUR C COMP VIS ECCV, P490
   Park J.O., 2013, IEEE C WORKSH APPL C
   Pierce C.C., 2008, LESSONS FOREST DECEN, P101
   Stula M, 2012, INFORM SYST FRONT, V14, P725, DOI 10.1007/s10796-011-9299-8
   Toreyin BU, 2009, INT CONF ACOUST SPEE, P1461, DOI 10.1109/ICASSP.2009.4959870
   Vicente J, 2002, INT J THERM SCI, V41, P1113, DOI 10.1016/S1290-0729(02)01397-2
   Yuan X., 2011, IEEE INT C IMAGE PRO, P1061
   Zhang S., 2009, ACM MULTIMEDIA, P19
   Zhu F, 2013, PATTERN RECOGN LETT, V34, P20, DOI 10.1016/j.patrec.2012.04.016
NR 27
TC 44
Z9 52
U1 1
U2 47
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 786
EP 795
DI 10.1016/j.imavis.2013.08.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900009
DA 2024-07-18
ER

PT J
AU Dupuis, Y
   Savatier, X
   Vasseur, P
AF Dupuis, Y.
   Savatier, X.
   Vasseur, P.
TI Feature subset selection applied to model-free gait recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature selection; Gait recognition; Model-free; Panoramic; Random
   forest
ID IMAGE; SYMMETRY
AB In this paper, we tackle the problem of gait recognition based on the model-free approach. Numerous methods exist; they all lead to high dimensional feature spaces. To address the problem of high dimensional feature space, we propose the use of the Random Forest algorithm to rank features' importance. In order to efficiently search throughout subspaces, we apply a backward feature elimination search strategy. Our first experiments are carried out on unknown covariate conditions. Our first results suggest that the selected features contribute to increase the CCR of different existing classification methods. Secondary experiments are performed on unknown covariate conditions and viewpoints. Inspired by the location of our first experiments' features, we proposed a simple mask. Experimental results demonstrate that the proposed mask gives satisfactory results for all angles of the probe and consequently is not view specific. We also show that our mask performs well when an uncooperative experimental setup is considered as compared to the state-of-the art methods. As a consequence, we propose a panoramic gait recognition framework on unknown covariate conditions. Our results suggest that panoramic gait recognition can be performed under unknown covariate conditions. Our approach can greatly reduce the complexity of the classification problem while achieving fair correct classification rates when gait is captured with unknown conditions. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Dupuis, Y.; Savatier, X.] IRSEEM, F-76801 St Etienne, France.
   [Vasseur, P.] LITIS Lab, F-76801 St Etienne, France.
C3 Universite de Rouen Normandie
RP Dupuis, Y (corresponding author), IRSEEM, Ave Galilee, F-76801 St Etienne, France.
EM yohan.dupuis@esigelec.fr; xavier.savatier@esigelec.fr;
   pascal.vasseur@insa-rouen.fr
RI SAVATIER, Xavier/AAG-6093-2019
OI SAVATIER, Xavier/0000-0003-2494-8595; DUPUIS, Yohan/0000-0002-9725-2049
FU European Regional Development Fund (ERDF) under the Interreg IVA program
   [4051]; University of Kent (UK)
FX This work is part of the NOmad Biometric Authentication (NOBA) project
   sponsored by the European Regional Development Fund (ERDF) under the
   Interreg IVA program (Ref. No. 4051) in collaboration with the
   University of Kent (UK).
CR [Anonymous], 1994, BAGGING PREDICTORS
   [Anonymous], IEEE INT C PATT REC
   [Anonymous], IEEE C AUT FAC GEST
   [Anonymous], 1992, EVALUATION FEATURE S
   [Anonymous], BRIT MACH VIS C
   [Anonymous], INT C MACH LEARN
   Balagani KS, 2010, IEEE T SYST MAN CY A, V40, P651, DOI 10.1109/TSMCA.2009.2036935
   Bankert R. L, 1996, LEARNING DATA ARTIFI, P199, DOI [DOI 10.1007/978-1-4612-2404-4_19, 10.1007/978-1-4612-2404-4_19]
   Bashir K., 2010, the British Machine Vision Conference, P1, DOI DOI 10.1049/IC.2009.0230
   Bashir K, 2008, INT CONF ACOUST SPEE, P985
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   BenAbdelkader C, 2004, EURASIP J APPL SIG P, V2004, P572, DOI 10.1155/S1110865704309236
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Breiman L., 2001, Mach. Learn., V45, P5
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Guo BF, 2009, IEEE T SYST MAN CY A, V39, P36, DOI 10.1109/TSMCA.2008.2007977
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Hayfron-Acquah JB, 2003, PATTERN RECOGN LETT, V24, P2175, DOI 10.1016/S0167-8655(03)00086-2
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang PS, 1999, ARTIF INTELL ENG, V13, P359, DOI 10.1016/S0954-1810(99)00008-4
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kobayashi T, 2004, INT C PATT RECOG, P741, DOI 10.1109/ICPR.2004.1333879
   Kusakunniran W, 2010, PROC CVPR IEEE, P974, DOI 10.1109/CVPR.2010.5540113
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lee JW, 2005, COMPUT STAT DATA AN, V48, P869, DOI 10.1016/j.csda.2004.03.017
   Lee S., 2007, Celebrity Fandom and its Relationship to Tourism and Leisure Behaviors: The Case of Korean Wave, Texas AM Repository, P1
   Liu Y., 2002, Computer Vision - ECCV 2002, V2351, P733
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Mitiche A, 2003, ROBOT AUTON SYST, V43, P39, DOI 10.1016/S0921-8890(03)00002-2
   Phillips PJ, 2002, INT C PATT RECOG, P385, DOI 10.1109/ICPR.2002.1044731
   Polana R, 1997, INT J COMPUT VISION, V23, P261, DOI 10.1023/A:1007975200487
   Qu XD, 2011, J BIOMECH, V44, P1259, DOI 10.1016/j.jbiomech.2011.02.016
   Sanderson C, 2001, VIDTIMIT AUDIO VIDEO
   Shutler JD, 2004, ADV SOFT COMP, P339
   Shutler JD., 2001, P BMVC, P705
   Tao DC, 2007, IEEE T PATTERN ANAL, V29, P1700, DOI 10.1109/TPAMI.2007.1096
   Yu SQ, 2006, INT C PATT RECOG, P441
   Zhao G, 2007, PATTERN ANAL APPL, V10, P235, DOI 10.1007/s10044-007-0064-z
   Zhao GY, 2005, LECT NOTES COMPUT SC, V3781, P205, DOI 10.1007/11569947_26
   Zheng S, 2011, IEEE IMAGE PROC, DOI 10.1109/ICIP.2011.6115889
NR 41
TC 50
Z9 58
U1 0
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2013
VL 31
IS 8
BP 580
EP 591
DI 10.1016/j.imavis.2013.04.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 185TO
UT WOS:000321993400005
DA 2024-07-18
ER

PT J
AU Wöllmer, M
   Kaiser, M
   Eyben, F
   Schuller, B
   Rigoll, G
AF Woellmer, Martin
   Kaiser, Moritz
   Eyben, Florian
   Schuller, Bjoern
   Rigoll, Gerhard
TI LSTM-Modeling of continuous emotions in an audiovisual affect
   recognition framework
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Emotion recognition; Long Short-Term Memory; Facial movement features;
   Context modeling
ID FACIAL EXPRESSION RECOGNITION; BIDIRECTIONAL LSTM; CLASSIFICATION;
   NETWORKS; FEATURES; FACE
AB Automatically recognizing human emotions from spontaneous and non-prototypical real-life data is currently one of the most challenging tasks in the field of affective computing. This article presents our recent advances in assessing dimensional representations of emotion, such as arousal, expectation, power, and valence, in an audiovisual human-computer interaction scenario. Building on previous studies which demonstrate that long-range context modeling tends to increase accuracies of emotion recognition, we propose a fully automatic audiovisual recognition approach based on Long Short-Term Memory (LSTM) modeling of word-level audio and video features. LSTM networks are able to incorporate knowledge about how emotions typically evolve over time so that the inferred emotion estimates are produced under consideration of an optimal amount of context. Extensive evaluations on the Audiovisual Sub-Challenge of the 2011 Audio/Visual Emotion Challenge show how acoustic, linguistic, and visual features contribute to the recognition of different affective dimensions as annotated in the SEMAINE database. We apply the same acoustic features as used in the challenge baseline system whereas visual features are computed via a novel facial movement feature extractor. Comparing our results with the recognition scores of all Audiovisual Sub-Challenge participants, we find that the proposed LSTM-based technique leads to the best average recognition performance that has been reported for this task so far. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Woellmer, Martin; Kaiser, Moritz; Eyben, Florian; Schuller, Bjoern; Rigoll, Gerhard] Tech Univ Munich, Inst Human Machine Commun, D-80333 Munich, Germany.
C3 Technical University of Munich
RP Wöllmer, M (corresponding author), Tech Univ Munich, Inst Human Machine Commun, Theresienstr 90, D-80333 Munich, Germany.
EM woellmer@tum.de
RI Schuller, Björn Wolfgang/D-3241-2011; Kaiser, M. Shamim/F-5750-2012
OI Schuller, Björn Wolfgang/0000-0002-6478-8699; Kaiser, M.
   Shamim/0000-0002-4604-5461
CR [Anonymous], THESIS TU MUNCHEN
   [Anonymous], 1998, Intel Technology Journal, DOI DOI 10.1109/ACV.1998.732882
   [Anonymous], 2009, An introduction to seismology, earthquakes and Earth structure
   [Anonymous], P INT ISCA BRISB AUS
   Arsic D, 2009, 2009 16TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING, VOLS 1 AND 2, P639
   Barrett LF, 2010, PSYCHOL SCI, V21, P595, DOI 10.1177/0956797610363547
   Bengio S., 2003, ADV NIPS, V15, P1
   Cen L, 2011, LECT NOTES COMPUT SC, V6975, P332, DOI 10.1007/978-3-642-24571-8_44
   Collignon O, 2008, BRAIN RES, V1242, P126, DOI 10.1016/j.brainres.2008.04.023
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Cruz A, 2011, LECT NOTES COMPUT SC, V6975, P341, DOI 10.1007/978-3-642-24571-8_45
   Dahmane M, 2011, LECT NOTES COMPUT SC, V6975, P351, DOI 10.1007/978-3-642-24571-8_46
   Devillers L, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2350
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Eyben F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P322, DOI 10.1109/FG.2011.5771417
   Eyben F, 2010, J MULTIMODAL USER IN, V3, P7, DOI 10.1007/s12193-009-0032-6
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Fernández S, 2007, LECT NOTES COMPUT SC, V4669, P220
   Fontaine JRJ, 2007, PSYCHOL SCI, V18, P1050, DOI 10.1111/j.1467-9280.2007.02024.x
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Glodek M, 2011, LECT NOTES COMPUT SC, V6975, P359, DOI 10.1007/978-3-642-24571-8_47
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Greig D., 2009, IEEE WORKSH APPL COM, P23
   Grézl F, 2007, INT CONF ACOUST SPEE, P757
   Grimm M, 2007, INT CONF ACOUST SPEE, P1085
   Gunes Hatice, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P827, DOI 10.1109/FG.2011.5771357
   Hall M., 2009, ACM SIGKDD Explor. Newsl, V11, P18, DOI DOI 10.1145/1656274.1656278
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Kim JC, 2011, LECT NOTES COMPUT SC, V6975, P369, DOI 10.1007/978-3-642-24571-8_48
   Kolen JF, 2009, A Field Guide to Dynamical Recurrent Networks, DOI [DOI 10.1109/9780470544037.CH14, 10.1109/9780470544037]
   Kotsia I, 2008, IMAGE VISION COMPUT, V26, P1052, DOI 10.1016/j.imavis.2007.11.004
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Kumano S, 2009, INT J COMPUT VISION, V83, P178, DOI 10.1007/s11263-008-0185-x
   Lee A., 2009, ASIA PACIFIC SIGNAL, P131
   McKee GJ, 2010, AGR ISSUES POLICIES, P1
   Meng HY, 2011, LECT NOTES COMPUT SC, V6975, P378, DOI 10.1007/978-3-642-24571-8_49
   Metallinou A, 2008, IEEE INT SYM MULTIM, P250, DOI 10.1109/ISM.2008.40
   Narayanan S., 2012, P ICASSP KYOT JAP
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan SF, 2011, LECT NOTES COMPUT SC, V6975, P388, DOI 10.1007/978-3-642-24571-8_50
   Ramirez GA, 2011, LECT NOTES COMPUT SC, V6975, P396, DOI 10.1007/978-3-642-24571-8_51
   Sayedelahl A, 2011, LECT NOTES COMPUT SC, V6975, P407, DOI 10.1007/978-3-642-24571-8_52
   Schröder M, 2012, IEEE T AFFECT COMPUT, V3, P165, DOI 10.1109/T-AFFC.2011.34
   Schuller B, 2003, INT CONF ACOUST SPEE, P1
   Schuller B, 2008, INT CONF ACOUST SPEE, P4501, DOI 10.1109/ICASSP.2008.4518656
   Schuller B, 2011, LECT NOTES COMPUT SC, V6975, P415, DOI 10.1007/978-3-642-24571-8_53
   Schuller B, 2009, 2009 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION & UNDERSTANDING (ASRU 2009), P552, DOI 10.1109/ASRU.2009.5372886
   Schuller B, 2009, IMAGE VISION COMPUT, V27, P1760, DOI 10.1016/j.imavis.2009.02.013
   Schuller Bjorn, 2011, Interspeech
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   SNEDECOR G W, 1980
   Stupakov A, 2012, COMPUT SPEECH LANG, V26, P52, DOI 10.1016/j.csl.2010.12.003
   Tian Y., 2011, HDB FACE RECOGNITION, P487
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Witten I. H., 2005, DATA MINING PRACTICA
   Wöllmer M, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2362
   Wöllmer M, 2011, INT CONF ACOUST SPEE, P4860
   Wöllmer M, 2010, COGN COMPUT, V2, P180, DOI 10.1007/s12559-010-9041-8
   Wöllmer M, 2011, IEEE T INTELL TRANSP, V12, P574, DOI 10.1109/TITS.2011.2119483
   Wöllmer M, 2010, IEEE J-STSP, V4, P867, DOI 10.1109/JSTSP.2010.2057200
   Wöllmer M, 2009, NEUROCOMPUTING, V73, P366, DOI 10.1016/j.neucom.2009.08.005
   Wöllmer M, 2009, INT CONF ACOUST SPEE, P3949, DOI 10.1109/ICASSP.2009.4960492
   Wollmer M., 2011, 2011 IEEE Workshop on Automatic Speech Recognition & Understanding (ASRU), P36, DOI 10.1109/ASRU.2011.6163902
   Wollmer M., 2011, ACM Transactions on Speech and Language Processing (TSLP), V7, P1
   Yang P, 2009, PATTERN RECOGN LETT, V30, P132, DOI 10.1016/j.patrec.2008.03.014
   Zeng ZH, 2008, IEEE T MULTIMEDIA, V10, P570, DOI 10.1109/TMM.2008.921737
   Ziemke T, 2009, COGN COMPUT, V1, P104, DOI 10.1007/s12559-009-9012-0
NR 69
TC 178
Z9 194
U1 1
U2 80
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2013
VL 31
IS 2
BP 153
EP 163
DI 10.1016/j.imavis.2012.03.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 102KN
UT WOS:000315843600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhao, GY
   Huang, XH
   Taini, M
   Li, SZ
   Pietikäinen, M
AF Zhao, Guoying
   Huang, Xiaohua
   Taini, Matti
   Li, Stan Z.
   Pietikainen, Matti
TI Facial expression recognition from near-infrared videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Spatiotemporal descriptors; Near-infrared
   (NIR); Visible light (VIS); Component-based facial features
ID FACE RECOGNITION; CLASSIFICATION
AB Facial expression recognition is to determine the emotional state of the face regardless of its identity. Most of the existing datasets for facial expressions are captured in a visible light spectrum. However, the visible light (VIS) can change with time and location, causing significant variations in appearance and texture. In this paper, we present a novel research on a dynamic facial expression recognition, using near-infrared (NIR) video sequences and LBP-TOP (Local binary patterns from three orthogonal planes) feature descriptors. NIR imaging combined with LBP-TOP features provide an illumination invariant description of face video sequences. Appearance and motion features in slices are used for expression classification, and for this, discriminative weights are learned from training examples. Furthermore, component-based facial features are presented to combine geometric and appearance information, providing an effective way for representing the facial expressions. Experimental results of facial expression recognition using a novel Oulu-CASIA NIR&VIS facial expression database, a support vector machine and sparse representation classifiers show good and robust results against illumination variations. This provides a baseline for future research on NIR-based facial expression recognition. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Zhao, Guoying; Huang, Xiaohua; Taini, Matti; Pietikainen, Matti] Univ Oulu, Machine Vis Grp, Infotech Oulu, FI-90014 Oulu, Finland.
   [Zhao, Guoying; Huang, Xiaohua; Taini, Matti; Pietikainen, Matti] Univ Oulu, Dept Comp Sci & Engn, FI-90014 Oulu, Finland.
   [Li, Stan Z.] Chinese Acad Sci, Inst Automat, Beijing 100080, Peoples R China.
   [Huang, Xiaohua] Southeast Univ, Res Ctr Learning Sci, Nanjing 210096, Peoples R China.
C3 University of Oulu; University of Oulu; Chinese Academy of Sciences;
   Institute of Automation, CAS; Southeast University - China
RP Zhao, GY (corresponding author), Univ Oulu, Machine Vis Grp, Infotech Oulu, POB 4500, FI-90014 Oulu, Finland.
EM gyzhao@ee.oulu.fi; huang.xiaohua@ee.oulu.fi; szli@cbsr.ia.ac.cn;
   mkp@ee.oulu.fi
RI Li, SY/JPK-3839-2023; Huang, Xiaohua/A-4878-2011; Zhao,
   Guoying/ABE-7716-2020; Zhao, Guoying/G-5383-2012
OI Li, SY/0009-0000-9254-7115; Zhao, Guoying/0000-0003-3694-206X; Huang,
   Xiaohua/0000-0001-8897-3517
FU European Regional Development Fund,; Finnish Funding Agency for
   Technology and Innovation; Academy of Finland; European Union (EU)
   [257289]; China Scholarship Council of Chinese government; Chinese
   National Natural Science Foundation [61070146]; National Science and
   Technology Support Program Project [2009BAK43B26]; TABULA RASA project
FX The financial support provided by the European Regional Development
   Fund, the Finnish Funding Agency for Technology and Innovation, the
   Academy of Finland, and the TABULA RASA project
   (http://www.tabularasa-euproject.org) under the Seventh Framework
   Programme for research and technological development (FP7) of the
   European Union (EU), grant agreement #257289 is gratefully acknowledged.
   Xiaohua Huang is funded by China Scholarship Council of Chinese
   government. Stan Z. Li would like to acknowledge the funding support
   from the Chinese National Natural Science Foundation Project #61070146,
   the National Science and Technology Support Program Project
   #2009BAK43B26 and the TABULA RASA project.
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   [Anonymous], BMVC
   [Anonymous], PATTERN RECOG IMAGE
   Chen X, 2005, COMPUT VIS IMAGE UND, V99, P332, DOI 10.1016/j.cviu.2005.03.001
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Feng XY, 2004, LECT NOTES COMPUT SC, V3212, P668
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gross R, 2003, LECT NOTES COMPUT SC, V2688, P10
   Heisele B., 2004, INT C FAC GEST REC
   Holappa J., 2008, IEEE INT C BIOM THEO
   Ivanov Y, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P421, DOI 10.1109/AFGR.2004.1301569
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kim C, 2005, IEEE IJCNN, P2030
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   Kumano S, 2009, INT J COMPUT VISION, V83, P178, DOI 10.1007/s11263-008-0185-x
   Li SZ, 2007, IEEE T PATTERN ANAL, V29, P627, DOI 10.1109/TPAMI.2007.1014
   Li ZS, 2009, IEEE SYS MAN CYBERN, P1353, DOI 10.1109/ICSMC.2009.5346254
   Liao S., 2006, P 2006 IEEE INT C IM, P665
   MEHRABIAN A, 1968, PSYCHOL TODAY, V2, P53
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Mises R.V., 1964, MATH THEORY PROBABIL
   *NAT I STAND TECHN, 2006, FAC REC VEND TESTS F
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Socolinsky DA, 2003, COMPUT VIS IMAGE UND, V91, P72, DOI 10.1016/S1077-3142(03)00075-4
   Socolinsky DA, 2002, INT C PATT RECOG, P217, DOI 10.1109/ICPR.2002.1047436
   Taini M, 2009, LECT NOTES COMPUT SC, V5575, P239, DOI 10.1007/978-3-642-02230-2_25
   Taini M, 2008, INT C PATT RECOG, P1438
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yi Sun, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P13, DOI 10.1109/CVPR.2009.5204305
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
   Zhao SY, 2005, LECT NOTES ARTIF INT, V3587, P437
NR 42
TC 434
Z9 465
U1 3
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2011
VL 29
IS 9
BP 607
EP 619
DI 10.1016/j.imavis.2011.07.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 836PI
UT WOS:000296123200004
DA 2024-07-18
ER

PT J
AU Vogiatzis, G
   Hernández, C
AF Vogiatzis, George
   Hernandez, Carlos
TI Video-based, real-time multi-view stereo
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Real-time; Multi-view stereo; 3d reconstruction; Shape-from-X
ID RECONSTRUCTION
AB We investigate the problem of obtaining a dense reconstruction in real-time, from a live video stream. In recent years, multi-view stereo (MVS) has received considerable attention and a number of methods have been proposed. However, most methods operate under the assumption of a relatively sparse set of still images as input and unlimited computation time. Video based MVS has received less attention despite the fact that video sequences offer significant benefits in terms of usability of MVS systems. In this paper we propose a novel video based MVS algorithm that is suitable for real-time, interactive 3d modeling with a hand-held camera. The key idea is a per-pixel, probabilistic depth estimation scheme that updates posterior depth distributions with every new frame. The current implementation is capable of updating 15 million distributions/s. We evaluate the proposed method against the state-of-the-art real-time MVS method and show improvement in terms of accuracy. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Vogiatzis, George] Aston Univ, Birmingham B4 7ET, W Midlands, England.
   [Hernandez, Carlos] Google, Seattle, WA 98103 USA.
C3 Aston University; Google Incorporated
RP Vogiatzis, G (corresponding author), Aston Univ, Birmingham B4 7ET, W Midlands, England.
EM g.vogiatzis@aston.ac.uk; carloshernandez@google.com
OI Vogiatzis, George/0000-0002-3226-0603
FU Toshiba Research Europe Ltd.
FX This work was carried out while both authors were at the Computer Vision
   Group, Toshiba Cambridge Research Laboratory, Cambridge Science Park, CM
   0GZ, UK. The research was fully funded by Toshiba Research Europe Ltd.
CR Agarwal S., 2009, P 12 INT C COMP VIS
   [Anonymous], P 10 EUR C COMP VIS
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2006, ACM T GRAPHICS
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2006, P CVPR 06 IE COMP SO
   [Anonymous], 2008, P IEEE C COMP VIS PA
   Bhotika R, 2002, LECT NOTES COMPUT SC, V2352, P112
   Broadhurst A., 2001, ICCV, V1, P338
   Cornelis N, 2008, INT J COMPUT VISION, V78, P121, DOI 10.1007/s11263-007-0081-9
   Davison AJ, 2003, P 9 INT C COMP VIS I
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Furukawa Yasutaka, 2007, P IEEE C COMP VIS PA
   Gargallo P, 2005, PROC CVPR IEEE, P885
   GOESELE, 2006, P IEEE COMP SOC C CO, V2, P2402
   Goesele M., 2007, P ICCV 2007 OCT
   Hernandez C., 2007, P IEEE C COMP VIS PA
   Hornung Alexander, 2006, ACM INT C PROCEED IN, P41, DOI DOI 10.2312/SGP/SGP06
   Jaynes E. T., 2003, Probability Theory
   Kleinand G., 2008, P 10 EUR C COMP VIS
   Kolev K., 2008, P 10 EUR C COMP VIS
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   Li XW, 2008, LECT NOTES COMPUT SC, V5302, P427
   Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4
   Richard A., 2010, P IEEE C COMP VIS PA
   Strecha C, 2004, PROC CVPR IEEE, P552
   Vogiatzis G, 2007, IEEE T PATTERN ANAL, V29, P2241, DOI 10.1109/TPAMI.2007.70712
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 29
TC 106
Z9 130
U1 1
U2 40
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2011
VL 29
IS 7
BP 434
EP 441
DI 10.1016/j.imavis.2011.01.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 786YW
UT WOS:000292344800001
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Likforman-Sulem, L
   Darbon, J
   Smith, EHB
AF Likforman-Sulem, Laurence
   Darbon, Jerome
   Smith, Elisa H. Barney
TI Enhancement of historical printed document images by combining Total
   Variation regularization and Non-local Means filtering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Document image enhancement; Image processing; Variational approach;
   Non-local Means; Historical documents; Character recognition
AB This paper proposes a novel method for document enhancement which combines two recent powerful noise-reduction steps. The first step is based on the Total Variation framework. It flattens background grey-levels and produces an intermediate image where background noise is considerably reduced. This image is used as a mask to produce an image with a cleaner background while keeping character details. The second step is applied to the cleaner image and consists of a filter based on Non-local Means: character edges are smoothed by searching for similar patch images in pixel neighborhoods. The document images to be enhanced are real historical printed documents from several periods which include several defects in their background and on character edges. These defects result from scanning, paper aging and bleed-through. The proposed method enhances document images by combining the Total Variation and the Non-local Means techniques in order to improve OCR recognition. The method is shown to be more powerful than when these techniques are used alone and than other enhancement methods. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Likforman-Sulem, Laurence] Telecom ParisTech, Signal & Image Proc Dept, Paris, France.
   [Darbon, Jerome] Univ Calif Los Angeles, Dept Math, Los Angeles, CA 90024 USA.
   [Darbon, Jerome] PRES UniverSud, CNRS, ENS Cachan, CMLA, Paris, France.
   [Smith, Elisa H. Barney] Boise State Univ, Elect & Comp Engn Dept, Boise, ID 83725 USA.
C3 IMT - Institut Mines-Telecom; Institut Polytechnique de Paris; Telecom
   Paris; University of California System; University of California Los
   Angeles; Universite Paris Saclay; Centre National de la Recherche
   Scientifique (CNRS); Idaho; Boise State University
RP Likforman-Sulem, L (corresponding author), Telecom ParisTech, Signal & Image Proc Dept, Paris, France.
EM likforman@telecom-paristech.fr
RI Darbon, Jerome/S-8142-2019; Smith, Elisa H Barney/F-8840-2011
OI Darbon, Jerome/0000-0003-0483-7919
FU Office of Naval Research [N000140710810]
FX The authors wish to thank Marc Sigelle from Telecom ParisTech for
   fruitful discussions. Research of Jerome Darbon has been supported by
   the Office of Naval Research through grant N000140710810.
CR *ABBYY, ABBYY FIN READ
   [Anonymous], MATLAB and Octave functions for computer vision and image processing
   BARYOSEF I, 2008, GLOBAL LOCAL SHAPE P
   Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536
   *BRIT LIB, TREAS FULL
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Chambolle A, 2004, J MATH IMAGING VIS, V20, P89
   Darbon J, 2006, J MATH IMAGING VIS, V26, P261, DOI 10.1007/s10851-006-8803-0
   Darbon J, 2008, I S BIOMED IMAGING, P1331, DOI 10.1109/ISBI.2008.4541250
   Drira F, 2007, PROC INT CONF DOC, P1068
   DROETTBOOM M, GAMERA PROJECT
   DROETTBOOM M, 2003, P JOINT C DIG LIB JC
   FAN KC, 2002, PATTERN RECOGNITION, V35
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   GATOS B, 2009, P IEEE 10 INT C DOC
   IMPACT, IMP IMPR ACC TEXT DE
   Kim IK, 2002, PATTERN RECOGN, V35, P265, DOI 10.1016/S0031-3203(01)00027-9
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   Leung CC, 2005, PATTERN RECOGN LETT, V26, P769, DOI 10.1016/j.patrec.2004.09.032
   Likforman-Sulem Laurence, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P758, DOI 10.1109/ICDAR.2009.210
   Meyer Y, 2001, U LECT SERIES, V22
   MOGHADDAM RF, 2009, P IEEE 10 INT C DOC
   Nomura S, 2009, PATTERN RECOGN LETT, V30, P729, DOI 10.1016/j.patrec.2009.03.008
   Pan XB, 2004, IMAGE VISION COMPUT, V22, P443, DOI 10.1016/j.imavis.2003.11.007
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sattar F, 1999, IEEE SIGNAL PROC LET, V6, P249, DOI 10.1109/97.789601
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Smith EHB, 1998, PATTERN RECOGN LETT, V19, P1191, DOI 10.1016/S0167-8655(98)00107-X
   Smith R, 2007, PROC INT CONF DOC, P629, DOI 10.1109/icdar.2007.4376991
   Sturgill M, 2008, DOCENG'08: PROCEEDINGS OF THE EIGHTH ACM SYMPOSIUM ON DOCUMENT ENGINEERING, P263
   Taghva K, 2000, P SOC PHOTO-OPT INS, V3967, P157
   Tonazzini A., 2004, International Journal on Document Analysis and Recognition, V6, P236, DOI 10.1007/s10032-003-0115-y
   Tonazzini A., 2004, International Journal on Document Analysis and Recognition, V7, P17, DOI 10.1007/s10032-004-0121-8
   Tonazzini Anna, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P546, DOI 10.1109/ICDAR.2009.131
   Winkler G., 2006, IMAGE ANAL RANDOM FI, Vsecond
   Wolf C, 2002, INT C PATT RECOG, P160, DOI 10.1109/ICPR.2002.1047819
   Wolfe Cary., 2008, Philosophy and Animal Life, P1
   YOSEF IB, 2005, PATTERN RECOGN, V26, P1168
NR 39
TC 41
Z9 44
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2011
VL 29
IS 5
BP 351
EP 363
DI 10.1016/j.imavis.2011.01.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 751FT
UT WOS:000289603600006
OA Green Published
DA 2024-07-18
ER

PT J
AU Tung, F
   Zelek, JS
   Clausi, DA
AF Tung, Frederick
   Zelek, John S.
   Clausi, David A.
TI Goal-based trajectory analysis for unusual behaviour detection in
   intelligent surveillance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video surveillance; Behaviour understanding; Trajectory analysis;
   Anomaly detection
ID VISUAL SURVEILLANCE; OBJECT TRAJECTORIES; MOTION; MODELS
AB In a typical surveillance installation, a human operator has to constantly monitor a large array of video feeds for suspicious behaviour. As the number of cameras increases, information overload makes manual surveillance increasingly difficult, adding to other confounding factors such as human fatigue and boredom. The objective of an intelligent vision-based surveillance system is to automate the monitoring and event detection components of surveillance, alerting the operator only when unusual behaviour or other events of interest are detected. While most traditional methods for trajectory-based unusual behaviour detection rely on low-level trajectory features such as flow vectors or control points, this paper builds upon a recently introduced approach that makes use of higher-level features of intentionality. Individuals in the scene are modelled as intentional agents, and unusual behaviour is detected by evaluating the explicability of the agent's trajectory with respect to known spatial goals. The proposed method extends the original goal-based approach in three ways: first, the spatial scene structure is learned in a training phase; second, a region transition model is learned to describe normal movement patterns between spatial regions; and third. classification of trajectories in progress is performed in a probabilistic framework using particle filtering. Experimental validation on three published third-party datasets demonstrates the validity of the proposed approach. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Tung, Frederick; Zelek, John S.; Clausi, David A.] Univ Waterloo, Vis & Image Proc Lab, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Tung, F (corresponding author), Univ Waterloo, Vis & Image Proc Lab, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
EM ftung@uwaterloo.ca; jzelek@uwaterloo.ca; dclausi@uwaterloo.ca
RI Clausi, David A/J-4613-2013
FU Natural Sciences and Engineering Research Council (NSERC) of Canada;
   GEOIDE (Geomatics for Informed Decisions, a Network of Centres of
   Excellence)
FX This work is sponsored by the Natural Sciences and Engineering Research
   Council (NSERC) of Canada and by GEOIDE (Geomatics for Informed
   Decisions, a Network of Centres of Excellence).
CR Ali S, 2008, LECT NOTES COMPUT SC, V5303, P1, DOI 10.1007/978-3-540-88688-4_1
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen SS, 1998, INT CONF ACOUST SPEE, P645, DOI 10.1109/ICASSP.1998.675347
   Dee HM, 2008, MACH VISION APPL, V19, P329, DOI 10.1007/s00138-007-0077-z
   Dee HM, 2009, ARTIF INTELL, V173, P329, DOI 10.1016/j.artint.2008.10.011
   Dee HM, 2005, AVSS 2005: Advanced Video and Signal Based Surveillance, Proceedings, P34
   DEE HM, 2006, P IEEE ITN WORKSH VI, P73
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Fernyhough J, 2000, IMAGE VISION COMPUT, V18, P81, DOI 10.1016/S0262-8856(99)00023-2
   He XC, 2004, INT C PATT RECOG, P791, DOI 10.1109/ICPR.2004.1334377
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Johnson N, 1996, IMAGE VISION COMPUT, V14, P609, DOI 10.1016/0262-8856(96)01101-8
   Junejo IN, 2004, INT C PATT RECOG, P716, DOI 10.1109/ICPR.2004.1334359
   Liao L, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P348
   Liao L, 2007, ARTIF INTELL, V171, P311, DOI 10.1016/j.artint.2007.01.006
   MacCormick J, 2000, INT J COMPUT VISION, V39, P57, DOI 10.1023/A:1008122218374
   Makris D, 2005, IEEE T SYST MAN CY B, V35, P397, DOI 10.1109/TSMCB.2005.846652
   Makris D, 2002, IMAGE VISION COMPUT, V20, P895, DOI 10.1016/S0262-8856(02)00098-7
   McKenna SJ, 2005, PATTERN ANAL APPL, V7, P386, DOI 10.1007/s10044-004-0233-2
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593
   Montemerlo M., 2003, P INT JOINT C ARTIFI, P1151, DOI [10.5555/1630659.1630824, DOI 10.5555/1630659.1630824]
   Naftel A, 2006, MULTIMEDIA SYST, V12, P227, DOI [10.1007/s00530-006-0058-5, 10.1007/S00530-006-0058-5]
   Owens J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P77, DOI 10.1109/VS.2000.856860
   Piciarelli C, 2006, PATTERN RECOGN LETT, V27, P1835, DOI 10.1016/j.patrec.2006.02.004
   Piciarelli C, 2008, IEEE T CIRC SYST VID, V18, P1544, DOI 10.1109/TCSVT.2008.2005599
   RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805
   Russell S., 2016, Artificial intelligence a modern approach
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   SILLITO RR, 2008, P BRIT MACH VIS C, P1035
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Thrun S., 2005, PROBABILISTIC ROBOTI
   Xiang T, 2008, PATTERN RECOGN, V41, P1012, DOI 10.1016/j.patcog.2007.07.023
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   Yan W, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P370
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhong H, 2004, PROC CVPR IEEE, P819
NR 40
TC 82
Z9 91
U1 0
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2011
VL 29
IS 4
BP 230
EP 240
DI 10.1016/j.imavis.2010.11.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 727UR
UT WOS:000287828800003
OA Green Submitted
DA 2024-07-18
ER

EF