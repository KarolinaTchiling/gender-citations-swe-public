FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Thalhammer, S
   Weibel, JB
   Vincze, M
   Garcia-Rodriguez, J
AF Thalhammer, Stefan
   Weibel, Jean-Baptiste
   Vincze, Markus
   Garcia-Rodriguez, Jose
TI Self-supervised Vision Transformers for 3D pose estimation of novel
   objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object pose estimation; Template matching; Vision transformer;
   Self-supervised learning
AB Object pose estimation is important for object manipulation and scene understanding. In order to improve the general applicability of pose estimators, recent research focuses on providing estimates for novel objects, that is, objects unseen during training. Such works use deep template matching strategies to retrieve the closest template connected to a query image, which implicitly provides object class and pose. Despite the recent success and improvements of Vision Transformers over CNNs for many vision tasks, the state of the art uses CNN-based approaches for novel object pose estimation. This work evaluates and demonstrates the differences between self-supervised CNNs and Vision Transformers for deep template matching. In detail, both types of approaches are trained using contrastive learning to match training images against rendered templates of isolated objects. At test time such templates are matched against query images of known and novel objects under challenging settings, such as clutter, occlusion and object symmetries, using masked cosine similarity. The presented results not only demonstrate that Vision Transformers improve matching accuracy over CNNs but also that for some cases pre-trained Vision Transformers do not need fine-tuning to achieve the improvement. Furthermore, we highlight the differences in optimization and network architecture when comparing these two types of networks for deep template matching.
C1 [Thalhammer, Stefan; Weibel, Jean-Baptiste; Vincze, Markus] TU Wien, Automat & Control Inst, Gusshausstr 27-29, A-1040 Vienna, Austria.
   [Garcia-Rodriguez, Jose] Univ Alicante, Dept Comp Technol, Carr San Vicente del Raspeig, Alicante 03690, Spain.
C3 Technische Universitat Wien; Universitat d'Alacant
RP Thalhammer, S (corresponding author), TU Wien, Automat & Control Inst, Gusshausstr 27-29, A-1040 Vienna, Austria.
EM thalhammer@acin.tuwien.ac.at; weibel@acin.tuwien.ac.at;
   vincze@acin.tuwien.ac.at; jgarcia@dtic.ua.es
FU NVIDIA Corporation [101017089]
FX We gratefully acknowledge the support of the EU-program EC Horizon 2020
   for Research and Innovation under grant agreement No. 101017089 ,
   project TraceBot and the NVIDIA Corporation for supporting this research
   by providing hardware resources.r 101017089, project TraceBot and the
   NVIDIA Corporation for support-ing this research by providing hardware
   resources.
CR Aing L, 2023, IMAGE VISION COMPUT, V130, DOI 10.1016/j.imavis.2022.104618
   Balntas V, 2017, IEEE I CONF COMP VIS, P3876, DOI 10.1109/ICCV.2017.416
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9620, DOI 10.1109/ICCV48922.2021.00950
   Dede MA, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104495
   Denninger M., INT C ROB SCI SYST R
   Dosovitskiy Alexey, 2020, ABS201011929 CORR
   Drost B, 2010, PROC CVPR IEEE, P998, DOI 10.1109/CVPR.2010.5540108
   Dwibedi D, 2017, IEEE I CONF COMP VIS, P1310, DOI 10.1109/ICCV.2017.146
   Goyal P, 2018, Arxiv, DOI arXiv:1706.02677
   Grill J.-B., 2020, arXiv, V33, P21271
   Gutmann Michael, 2010, P MACHINE LEARNING R, P297, DOI DOI 10.1145/3292500.3330651
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D, 2020, Arxiv, DOI arXiv:1606.08415
   Hinterstoisser V., 2012, P COMP VIS ACCV 2012, P548
   Hodan T, 2018, LECT NOTES COMPUT SC, V11214, P19, DOI 10.1007/978-3-030-01249-6_2
   Hodan T, 2017, IEEE WINT CONF APPL, P880, DOI 10.1109/WACV.2017.103
   Hodan T, 2015, IEEE INT C INT ROBOT, P4421, DOI 10.1109/IROS.2015.7354005
   Hou T., 2020, PREPRINT
   Hsieh Cho-Jui, 2020, INT C LEARNING REPRE
   Huang L, 2022, LECT NOTES COMPUT SC, V13670, P585, DOI 10.1007/978-3-031-20080-9_34
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiang ZH, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104127
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Labbe Y., 2023, P 6 ANN C ROB LEARN, P715
   Lei Ba J., 2016, arXiv
   Nair Vinod, 2010, INT C INT C MACHINE, P807
   Park Kiru, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P656, DOI 10.1007/978-3-030-58548-8_38
   Park K, 2019, IEEE I CONF COMP VIS, P7667, DOI 10.1109/ICCV.2019.00776
   Parmar N, 2018, PR MACH LEARN RES, V80
   Patten T, 2020, FRONT ROBOT AI, V7, DOI 10.3389/frobt.2020.00120
   Peng SD, 2019, PROC CVPR IEEE, P4556, DOI 10.1109/CVPR.2019.00469
   Remus A, 2023, IEEE ROBOT AUTOM LET, V8, P1515, DOI 10.1109/LRA.2023.3240362
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salimans T, 2016, ADV NEUR IN, V29
   Shugurov I, 2022, PROC CVPR IEEE, P6825, DOI 10.1109/CVPR52688.2022.00671
   Sun HW, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2022.104372
   Sundermeyer Martin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13913, DOI 10.1109/CVPR42600.2020.01393
   Sundermeyer M., 2023, P IEEECVF C COMPUTER, P2784
   Sundermeyer M, 2018, LECT NOTES COMPUT SC, V11210, P712, DOI 10.1007/978-3-030-01231-1_43
   Thalhammer S, 2023, IEEE WINT CONF APPL, P2859, DOI 10.1109/WACV56688.2023.00288
   Thalhammer S, 2021, IEEE INT CONF ROBOT, P13909, DOI 10.1109/ICRA48506.2021.9562108
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Nguyen VN, 2022, PROC CVPR IEEE, P6761, DOI 10.1109/CVPR52688.2022.00665
   Wang G, 2021, PROC CVPR IEEE, P16606, DOI 10.1109/CVPR46437.2021.01634
   Wang H, 2019, PROC CVPR IEEE, P2637, DOI 10.1109/CVPR.2019.00275
   Wohlhart P, 2015, PROC CVPR IEEE, P3109, DOI 10.1109/CVPR.2015.7298930
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Zhang X, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103854
   Zhang X, 2019, IMAGE VISION COMPUT, V89, P1, DOI 10.1016/j.imavis.2019.06.013
NR 55
TC 0
Z9 0
U1 6
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104816
DI 10.1016/j.imavis.2023.104816
EA SEP 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA T9XV6
UT WOS:001081450900001
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Xu, YP
   Li, YY
   Chen, YS
   Bao, HG
   Zheng, YQ
AF Xu, Yaping
   Li, Yanyan
   Chen, Yunshan
   Bao, Haogang
   Zheng, Yaqian
TI Spontaneous visual database for detecting learning-centered emotions
   during online learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Learning-centered emotions; Emotion recognition; Emotional database;
   Machine learning; Deep learning
ID FACIAL EXPRESSIONS; FACES; CLASSIFICATION; ENGAGEMENT
AB Emotions significantly affect learning. The affective states of students can be automatically recognized through behavioral cues using machine learning and deep learning techniques. The accuracy and robustness of the recognition results mainly depend on the quality of the database used. However, no databases developed from actual online learning scenarios currently exist to detect and analyze learning-centered emotions (academic emotions). To address this shortcoming, an emotional database was compiled in this study using the facial expressions and hand gestures of students. The nonverbal emotions and behaviors in this dataset are spontaneous because all images are from videos recorded during actual online learning activities, leading to a robust learner emotion recognition model trained on these images that consider variates such as occlusion, illumination, background clutter, and pose. The database includes 1301 video clips and 21,632 images from 78 college students. The samples were labeled by both novice judges and researchers using six types of academic emotions (engaged, confused, frustrated, happy, sleepy, and neutral). To perform an elementary assessment of the database, an extensive analysis was conducted on it using state-of-the-art machine learning and deep learning algorithms. The experimental results demonstrate that the improved convolutional neural network algorithm provides the best recognition performance, with an average accuracy of 79%. In particular, when recognizing happy expressions, the model achieves the best score, with a recognition rate of 94%. This study provides a foundation for comparative studies of affective analysis approaches in specific online learning scenarios and enables these methods to be generalized in the educational field.
C1 [Xu, Yaping; Li, Yanyan; Chen, Yunshan; Zheng, Yaqian] Beijing Normal Univ, Fac Educ, Sch Educ Technol, Beijing, Peoples R China.
   [Bao, Haogang] China Natl Acad Educ Sci, Beijing, Peoples R China.
C3 Beijing Normal University
RP Li, YY (corresponding author), Beijing Normal Univ, Fac Educ, Sch Educ Technol, Beijing, Peoples R China.
EM liyy@bnu.edu.cn
OI Zheng, Yaqian/0009-0005-9807-3623
FU National Natural Science Foundation of China [62277006]; Beijing Natural
   Science Foundation [9222019]; International Joint Research Project of
   Faculty of Education of Beijing Normal University [ICER201903]
FX This work was supported by the National Natural Science Foundation of
   China (Grant No: 62277006) , the Beijing Natural Science Foundation
   (Grant No: 9222019) , and the International Joint Research Project of
   Faculty of Education of Beijing Normal University (Grant No: ICER201903)
   .
CR Afzal S., 2009, 3 INT C AFF COMP INT, P1, DOI [DOI 10.1109/ACII.2009.5349537, 10.1109/ACII.2009.5349537]
   Arriaga O, 2017, Arxiv, DOI arXiv:1710.07557
   Arroyo I, 2009, FRONT ARTIF INTEL AP, V200, P17, DOI 10.3233/978-1-60750-028-5-17
   Ashwin TS, 2020, FUTURE GENER COMP SY, V108, P334, DOI 10.1016/j.future.2020.02.075
   Baker RSJD, 2010, INT J HUM-COMPUT ST, V68, P223, DOI 10.1016/j.ijhcs.2009.12.003
   Benavente R, 1998, 24 COMP VIS CTR
   Bian CL, 2019, IET COMPUT VIS, V13, P329, DOI 10.1049/iet-cvi.2018.5281
   Boekaerts M., 2007, EMOTION ED, P37, DOI DOI 10.1016/B978-012372545-5/50004-6
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Cen L., 2016, Emotions, Technology, Design, and Learning, P27
   Chickerur S, 2015, BRIT J EDUC TECHNOL, V46, P1028, DOI 10.1111/bjet.12325
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   D'Errico F, 2016, J E-LEARN KNOWL SOC, V12, P9
   D'Mello S., 2010, 3rd International Conference on Educational Data Mining, P31
   D'Mello S, 2007, IEEE INTELL SYST, V22, P53, DOI 10.1109/MIS.2007.79
   D'Mello S, 2013, J EDUC PSYCHOL, V105, P1082, DOI 10.1037/a0032674
   D'Mello SK., 2013, International Handbook of Metacognition and Learning Technologies, P669, DOI [DOI 10.1007/978-1-4419-5546-3_44, 10.1007/978-1-4419-5546-344, DOI 10.1007/978-1-4419-5546-344]
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalrymple KA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079131
   Delgado K, 2021, IEEE INT CONF COMP V, P3621, DOI 10.1109/ICCVW54120.2021.00405
   Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P509, DOI 10.1145/2522848.2531739
   Dweck C.S., 2002, Improving academic achievement: Impact of psychological factors on education, P37, DOI DOI 10.1016/B978-012064455-1/50006-3
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Efklides A, 2005, LEARN INSTR, V15, P377, DOI 10.1016/j.learninstruc.2005.07.006
   Friesen E., 1978, Environmental Psychology & Nonverbal Behavior, V3, P5, DOI 10.1037/t27734-000
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Graesser A.C., 2012, Adaptive technologies for training and education, P117
   Grafsgaard JF, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P145
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Gunes H, 2006, INT C PATT RECOG, P1148
   Gupta A, 2022, Arxiv, DOI arXiv:1609.01885
   Happy SL, 2017, IEEE T AFFECT COMPUT, V8, P131, DOI 10.1109/TAFFC.2015.2498174
   Hara N., 1999, First Monday, V4
   Jack RE, 2012, J EXP PSYCHOL GEN, V141, P19, DOI 10.1037/a0023463
   Karnati M, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3243661
   Karnati M, 2022, IEEE T AFFECT COMPUT, V13, P2058, DOI 10.1109/TAFFC.2022.3208309
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Liang K, 2017, J ELECTR COMPUT ENG, V2017, DOI 10.1155/2017/9720396
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mahmoud M, 2011, LECT NOTES COMPUT SC, V6975, P248, DOI 10.1007/978-3-642-24571-8_27
   McDuff D, 2013, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2013.130
   Mehrabian A., 1974, APPROACH ENV PSYCHOL, P222, DOI DOI 10.1016/J.ELERAP.2013.07.001
   Mohan K, 2021, NEURAL COMPUT APPL, V33, P9125, DOI 10.1007/s00521-020-05676-y
   Mohan K, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3031835
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Qu FL, 2017, PROCEEDINGS OF 2017 INTERNATIONAL SYMPOSIUM - QUALITY EDUCATION FOR TEENAGERS, P280
   Raman S., 2022, Int J Res Appl Sci Eng Technol, V10, P3731, DOI [10.22214/ijraset.2022.43205, DOI 10.22214/IJRASET.2022.43205]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Regan K., 2019, Online Learning, V7, DOI DOI 10.24059/OLJ.V7I3.1847
   Saneiro M, 2014, SCI WORLD J, DOI 10.1155/2014/484873
   Sapinski T, 2019, LECT NOTES COMPUT SC, V11188, P153, DOI 10.1007/978-3-030-05792-3_15
   Schmidt A, 2007, ADV INTEL SOFT COMPU, V45, P816
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tang Wan, 2015, Shanghai Arch Psychiatry, V27, P62, DOI 10.11919/j.issn.1002-0829.215010
   Wei QL, 2017, SIGNAL PROCESS-IMAGE, V59, P168, DOI 10.1016/j.image.2017.08.012
   Weiner B., 1986, An attributional theory of motivation and emotion, DOI [10.1007/978-1-4612-4948-1, DOI 10.1007/978-1-4612-4948-1]
   Whitehill J, 2014, IEEE T AFFECT COMPUT, V5, P86, DOI 10.1109/TAFFC.2014.2316163
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Wu EHK, 2020, IEEE ACCESS, V8, P77788, DOI 10.1109/ACCESS.2020.2988252
   Xie Z., 2020, DATA SCI, P275, DOI [DOI 10.1007/978-981-15-2810-1_27, 10.1007/978-981-15-2810-1_27]
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   You Ji Won, 2012, [The Journal of Yeolin Education, 열린교육연구], V20, P19
   Yun H., 2017, DELFI GMW WORKSH, P1
   Zhao GY, 2011, IMAGE VISION COMPUT, V29, P607, DOI 10.1016/j.imavis.2011.07.002
NR 71
TC 1
Z9 1
U1 8
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104739
DI 10.1016/j.imavis.2023.104739
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FO3S3
UT WOS:001146746000001
DA 2024-07-18
ER

PT J
AU Kumar, A
   Sharma, K
   Sharma, A
AF Kumar, Akshi
   Sharma, Kapil
   Sharma, Aditi
TI MEmoR: A Multimodal Emotion Recognition using affective biomarkers for
   smart prediction of emotional health for people analytics in smart
   industries
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Affective computing; Visual analysis; Multi-model; Emotion recognition;
   E-IoT; Facial expression analysis
ID DEEP; FRAMEWORK; MODEL; NETWORK; STRESS; ISSUES; FUSION
AB The intersection of people, data and intelligent machines has a far-reaching impact on the productivity, efficiency and operations of a smart industry. Internet-of-things (IoT) offers a great potential for workplace gains using the "quantified self" and the computer vision strategies. Their goal is to focus on productivity, fitness, wellness, and improvement of the work environment. Recognizing and regulating human emotion is vital to people analytics as it plays an important role in workplace productivity. Within the smart industry setting, various non-invasive IoT devices can be used to recognize emotions and study the behavioral outcomes in various situations. This research puts forward a deep learning model for detection of human emotional state in real-time using multimodal data from the Emotional Internet-of-things (E-IoT). The proposed multimodal emotion recognition model, MEmoR makes use of two data modalities: visual and psychophysiological. The video signals are sampled to obtain image frames and a ResNet50 model pre-trained for face recognition is fine-tuned for emotion classification. Simultaneously, CNN is trained on the psychophysiological signals and the results of the two modality networks are combined using decision-level weighted fusion. The model is tested on the benchmark Bio Vid Emo DB multi modal dataset and compared to the state-of-the-art. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Kumar, Akshi] Manchester Metropolitan Univ, Dept Comp & Math, Manchester, England.
   [Sharma, Kapil] Delhi Technol Univ, Dept Informat Technol, Delhi, India.
   [Sharma, Aditi] Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
C3 Manchester Metropolitan University; Delhi Technological University;
   Delhi Technological University
RP Sharma, A (corresponding author), Delhi Technol Univ, Dept Comp Sci & Engn, Delhi, India.
EM aditisharma_phdco2k18@dtu.ac.in
RI Sharma, Aditi/AAC-6040-2021
OI Sharma, Aditi/0000-0003-2840-3330; Kumar, Akshi/0000-0003-4263-7168
CR Abbas A, 2020, IEEE ACCESS, V8, P74901, DOI 10.1109/ACCESS.2020.2989273
   Delbrouck J.-B., 2020, ARXIV PREPRINT ARXIV
   Dresvyanskiy D., ARXIV PREPRINT ARXIV
   Gideon J., 2017, ARXIV PREPRINT ARXIV
   Gumaei A, 2019, IEEE ACCESS, V7, P99152, DOI 10.1109/ACCESS.2019.2927134
   Gupta D, 2021, IEEE SENS J, V21, P25421, DOI 10.1109/JSEN.2021.3095853
   Hagar Ahmed F., 2019, 2019 14th International Conference on Computer Engineering and Systems (ICCES). Proceedings, P16, DOI 10.1109/ICCES48960.2019.9068168
   Hassan MM, 2019, INFORM FUSION, V51, P10, DOI 10.1016/j.inffus.2018.10.009
   HODAPP V, 1988, PERS INDIV DIFFER, V9, P851, DOI 10.1016/0191-8869(88)90003-7
   Hossain MS, 2019, INFORM FUSION, V49, P69, DOI 10.1016/j.inffus.2018.09.008
   Huang D.-Y., 2017, P 19 ACM INT C MULT, P577, DOI DOI 10.1145/3136755.3143012
   Iskhakova Anastasia, 2020, Speech and Computer. 22nd International Conference, SPECOM 2020. Proceedings. Lecture Notes in Artificial Intelligence Subseries of Lecture Notes in Computer Science (LNAI 12335), P184, DOI 10.1007/978-3-030-60276-5_19
   Khushaba RN, 2016, PROCEEDINGS OF 2016 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), DOI 10.1109/SSCI.2016.7850064
   Kumar A, 2021, APPL SOFT COMPUT, V109, DOI 10.1016/j.asoc.2021.107525
   Kumar A, 2021, PATTERN RECOGN LETT, V145, P81, DOI 10.1016/j.patrec.2021.01.030
   Kumar A, 2020, COMPUT COMMUN, V152, P272, DOI 10.1016/j.comcom.2020.01.041
   Kumar A, 2019, INT J INF RETR RES, V9, P1, DOI 10.4018/IJIRR.2019010101
   Li W, 2018, MACH VISION APPL, V29, P489, DOI 10.1007/s00138-017-0904-9
   Li W, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P482, DOI 10.1145/2818346.2830583
   Luis-Ferreira F, 2013, AIP CONF PROC, V1558, P1368, DOI 10.1063/1.4825770
   Mittal T, 2020, AAAI CONF ARTIF INTE, V34, P1359
   Nanayakkara S., ARXIV PREPRINT ARXIV
   Kumar AN, 2021, INT J ELEC ENG EDUC, V58, P83, DOI 10.1177/0020720919830905
   Picard RW, 2001, IEEE T PATTERN ANAL, V23, P1175, DOI 10.1109/34.954607
   Poria S, 2017, INFORM FUSION, V37, P98, DOI 10.1016/j.inffus.2017.02.003
   Sharma A., 2022, NEURAL COMPUT APPL, P1, DOI DOI 10.1007/S00521-022-06913-2
   TSANOUSA A, 2019, INT CONF INFORM INTE, P417
   Tzirakis P, 2017, IEEE J-STSP, V11, P1301, DOI 10.1109/JSTSP.2017.2764438
   uregui D.A.G. J, 2017, SMART INTERFACES 201
   Wang ZM, 2020, INT J MACH LEARN CYB, V11, P923, DOI 10.1007/s13042-019-01056-8
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xie J., 2018, 2018 International Workshop on Big Geospatial Data and Data Science (BGDDS), Big Geospatial Data and Data Science (BGDDS), 2018 International Workshop on (p, P1
   Yang J, 2020, FUTURE GENER COMP SY, V102, P701, DOI 10.1016/j.future.2019.09.029
   Zhang SQ, 2018, IEEE T CIRC SYST VID, V28, P3030, DOI 10.1109/TCSVT.2017.2719043
NR 34
TC 12
Z9 13
U1 4
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104483
DI 10.1016/j.imavis.2022.104483
EA MAY 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1W0YE
UT WOS:000806506500006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Liu, BY
   Malon, C
   Xue, LZ
   Kruus, E
AF Liu, Bingyuan
   Malon, Christopher
   Xue, Lingzhou
   Kruus, Erik
TI Improving neural network robustness through neighborhood preserving
   layers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Manifold approximation; Neighborhood preservation;
   Robustness; Adversarial attack; Image classi fication
AB High-dimensional embeddings are often projected via fully connected layers while training neural networks. A major vulnerability that makes neural networks fail to be robust against adversarial attack is their use of overparameterized fully connected layers. We present a dimension reducing layer which preserves high-dimensional neighborhoods across the entire manifold. Atypically, our neighborhood preserving layer operates on non static high dimensional inputs and can be trained efficiently via gradient descent. Our interest is in developing a trainable manifold representation, whose low-dimensional embeddings can be re-used for other purposes, and in investigating its robustness against adversarial attack.Our layer internally uses nearest-neighbor attractive and repulsive forces to create a low dimensional output representation. We demonstrate a novel neural network architecture which can incorporate such a layer, and also can be trained efficiently. Our theoretical results show why linear layers, which have many parameters, are innately less robust. This is corroborated by experiments on MNIST and CIFAR10 replacing the first fully connected layer with a neighborhood preserving layer by our proposed model.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Liu, Bingyuan; Malon, Christopher; Kruus, Erik] NEC Labs America, Princeton, NJ USA.
   [Liu, Bingyuan] Google, Mountain View, CA USA.
   [Xue, Lingzhou] Penn State Univ, State Coll, PA USA.
   [Kruus, Erik] NEC Labs America LLC, 4 Independence Way,Suite 200, Princeton, NJ 08540 USA.
C3 Google Incorporated; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); Pennsylvania State University
RP Kruus, E (corresponding author), NEC Labs America LLC, 4 Independence Way,Suite 200, Princeton, NJ 08540 USA.
EM kruus@nec-labs.com
RI Xue, Lingzhou/AFK-5503-2022
OI Xue, Lingzhou/0000-0002-8252-0637
CR Afsar FA, 2008, INMIC: 2008 INTERNATIONAL MULTITOPIC CONFERENCE, P143, DOI 10.1109/INMIC.2008.4777725
   Agrawal A., ARXIV PREPRINT ARXIV
   [Anonymous], NIPS
   Arif Muhammad, 2010, Journal of Biomedical Science & Engineering, V3, P380, DOI 10.4236/jbise.2010.34053
   Bengio Y, 2004, ADV NEUR IN, V16, P177
   Bhm J.N., ARXIV PREPRINT ARXIV
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chakraborty A., ARXIV PREPRINT ARXIV
   Chen PY, 2018, AAAI CONF ARTIF INTE, P10
   Croce F, 2020, PR MACH LEARN RES, V119
   Dong YP, 2018, PROC CVPR IEEE, P9185, DOI 10.1109/CVPR.2018.00957
   Doshi-Velez F., ARXIV PREPRINT ARXIV
   Ericsson L, 2021, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR46437.2021.00537
   Ghojogh B., ARXIV PREPRINT ARXIV
   Goodfellow I. J., 2015, 3 INT C LEARNING REP
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   Levina Elizaveta, 2004, Advances in neural information processing systems, V17
   Madry A., ARXIV PREPRINT ARXIV
   McInnes L., ARXIV PREPRINT ARXIV
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Musgrave Kevin, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P681, DOI 10.1007/978-3-030-58595-2_41
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C., ARXIV PREPRINT ARXIV
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang YF, 2021, J MACH LEARN RES, V22
   Weng T.-W., ARXIV PREPRINT ARXIV
   Zang Z., CORR
NR 30
TC 4
Z9 4
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104469
DI 10.1016/j.imavis.2022.104469
EA MAY 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L9ND
UT WOS:000799606300007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, YP
   Liang, QK
   Zou, KL
   Li, ZW
   Sun, W
   Wang, YN
AF Zhang, Yanping
   Liang, Qiaokang
   Zou, Kunlin
   Li, Zhengwei
   Sun, Wei
   Wang, Yaonan
TI Self-supervised part segmentation via motion imitation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Motion imitation; Self-supervised; Part segmentation
AB Given two images with the same appearance and different poses, the motion imitation is to warp the source image into the reference pose. Can the network learn the part information of the object in this process? In this paper, we take motion simulation as the pretext task to learn part information. It is based on the assumption that the generated image will be similar to the reference image only if the part information is sufficiently accurate. Different from the existing work, the key idea of this paper is to minimize the "creativity" of the motion imitation network to avoid that the network can generate an image similar to the reference image even if the part information is not learned. In particular, we investigate the complementarity of key point information and part information, and propose a joint learning module to make them benefit from each other. We constructed a multi-source fusion module to fuse missing information from multiple images to reduce the importance of the inpainting network with "creative" capabilities in the entire framework. And warping the image in the image space forces the network to directly use the original information to generate the image. In this way, the network can only move pixels based on the learned part information, not modify pixels. Compared with the existing self supervised methods, the proposed method in this paper can produce more semantically consistent and meaningful parts without the utilization of any pre-computed information or pre-training weights. The effectivity and validity of the proposed method have verified through extensive experiments on Tai-Chi-HD and VoxCeleb datasets.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhang, Yanping; Liang, Qiaokang; Zou, Kunlin; Sun, Wei; Wang, Yaonan] Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
   [Zhang, Yanping; Liang, Qiaokang; Zou, Kunlin; Sun, Wei; Wang, Yaonan] Hunan Univ, Natl Engn Lab Robot Vis Percept & Control, Changsha 410082, Hunan, Peoples R China.
   [Li, Zhengwei] Univ Alberta, Dept Mech Engn, Edmonton, AB T6G 2E1, Canada.
C3 Hunan University; Hunan University; University of Alberta
RP Liang, QK (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha 410082, Hunan, Peoples R China.
EM qiaokang@hnu.edu.cn
RI Zhang, Yanping/HMP-5348-2023; Liang, Qiaokang/D-5406-2012
OI Liang, qiaokang/0000-0002-5504-9966
FU National Natural Science Founda-tion of China [U21A20490, 62073129];
   National Key Research and Development Program [2021YFC1910402]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China (U21A20490 and 62073129) and National Key Research
   and Development Program (2021YFC1910402) .
CR Alldieck T, 2019, PROC CVPR IEEE, P1175, DOI 10.1109/CVPR.2019.00127
   Bachman P, 2019, ADV NEUR IN, V32
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   Chan C, 2019, IEEE I CONF COMP VIS, P5932, DOI 10.1109/ICCV.2019.00603
   Chen T, 2020, PR MACH LEARN RES, V119
   Collins E, 2018, LECT NOTES COMPUT SC, V11218, P352, DOI 10.1007/978-3-030-01264-9_21
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doersch C, 2015, IEEE I CONF COMP VIS, P1422, DOI 10.1109/ICCV.2015.167
   Fernando B, 2017, PROC CVPR IEEE, P5729, DOI 10.1109/CVPR.2017.607
   Gidaris S., 2018, P 6 INT C LEARNING R
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   Huang HJ, 2020, IEEE T IMAGE PROCESS, V29, P7468, DOI 10.1109/TIP.2020.3003442
   Huang Z, P IEEE CVF C COMP VI, P8662
   Hung WC, 2019, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2019.00096
   Jackson AS, 2016, LECT NOTES COMPUT SC, V9915, P143, DOI 10.1007/978-3-319-49409-8_14
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang Y, 2019, IEEE T IMAGE PROCESS, V28, P2465, DOI 10.1109/TIP.2018.2886785
   Lathuiliere S, P IEEE CVF WINT C AP, P439
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li YN, 2019, PROC CVPR IEEE, P3688, DOI 10.1109/CVPR.2019.00381
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma L., ARXIV170509368
   Nagrani A, 2017, INTERSPEECH, P2616, DOI 10.21437/Interspeech.2017-950
   Neverova N, 2018, LECT NOTES COMPUT SC, V11207, P128, DOI 10.1007/978-3-030-01219-9_8
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   PINKER S, 1984, COGNITION, V18, P1, DOI 10.1016/0010-0277(84)90021-0
   Ren Yurui., P IEEE CVF C COMP VI, P7690
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Siarohin A, P IEEE CVF C COMP VI, P13653
   Siarohin A, 2018, PROC CVPR IEEE, P3408, DOI 10.1109/CVPR.2018.00359
   Siarohin Aliaksandr, 2020, ARXIV200403234
   Siarohin Aliaksandr, 2019, Adv.Neural Inf. Process. Syst.
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang HY, 2015, PROC CVPR IEEE, P1788, DOI 10.1109/CVPR.2015.7298788
   Wang JD, 2021, IEEE T PATTERN ANAL, V43, P3349, DOI 10.1109/TPAMI.2020.2983686
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Yang H., P IEEE CVF C COMP VI, P7850
   Zhang P, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104118
   Zhang Q, 2019, I S BIOMED IMAGING, P489, DOI [10.1109/ISBI.2019.8759374, 10.1109/isbi.2019.8759374]
   Zhang R, 2016, LECT NOTES COMPUT SC, V9907, P649, DOI 10.1007/978-3-319-46487-9_40
   Zhang YT, 2018, PROC CVPR IEEE, P2694, DOI 10.1109/CVPR.2018.00285
   Zhu K., 2020, ECCV, P346, DOI [10.1007/978-3-030-58580-8_21, DOI 10.1007/978-3-030-58580-8_21]
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
   Zhu Z, 2019, PROC CVPR IEEE, P2342, DOI 10.1109/CVPR.2019.00245
NR 48
TC 1
Z9 1
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104393
DI 10.1016/j.imavis.2022.104393
EA FEB 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500008
DA 2024-07-18
ER

PT J
AU Hao, LB
   Wang, HM
AF Hao, Linbo
   Wang, Huaming
TI Geometric feature statistics histogram for both real-valued and binary
   feature representations of 3D local shape
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D point cloud; Local feature descriptor; Multiple geometric features;
   Binary extension; Feature matching
ID OBJECT RECOGNITION; PERFORMANCE EVALUATION; REGISTRATION; DESCRIPTOR;
   EFFICIENT
AB 3D local feature description is now at the core of many 3D vision technologies. However, most of the existing 3D feature descriptors can't strike a balance among descriptiveness, robustness, compactness, and efficiency. To overcome the challenges, we propose a real-valued 3D local feature descriptor named Geometric Feature Statistics Histogram (GFSH) and its binary extension descriptor named B-GFSH. A GFSH descriptor first constructs an improved-weighted covariance matrix to solve a stable and reliable Local Reference Frame (LRF), and then achieves a comprehensive description of the 3D local surface by performing statistics on multiple geometric distribution features, namely voxel density, voxel centroid, and projection density. A particular trait of our GFSH descriptor is its seamless extension to the binary representation to reduce storage consumption and accelerate feature matching. For each sub-feature of GFSH, B-GFSH respectively adopts the corresponding binarization strategy, i.e., improved Gray code quantization, thresholding based on coordinates, and neighbor comparison. Extensive experiments on six public datasets prove that both GFSH and B-GFSH have high descriptiveness, strong robustness, and fast real-time performance. In addition, B-GFSH further has the characteristics of fast matching speed, low memory footprint, and high compactness. Finally, we conduct 3D scene registration and 3D object recognition experiments to visually demonstrate the actual effectiveness of GFSH and B-GFSH.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Hao, Linbo; Wang, Huaming] Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Wang, HM (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Mech & Elect Engn, Nanjing 210016, Peoples R China.
EM lb_hao@nuaa.edu.cn; hmwang@nuaa.edu.cn
CR Abbad A, 2018, COMPUT ELECTR ENG, V70, P525, DOI 10.1016/j.compeleceng.2017.08.017
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Davis Jesse, 2006, P 23 INT C MACH LEAR, P233, DOI [DOI 10.1145/1143844.1143874, 10.1145/1143844.1143874]
   Deng HW, 2018, LECT NOTES COMPUT SC, V11209, P620, DOI 10.1007/978-3-030-01228-1_37
   Deng HW, 2018, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2018.00028
   Dong Z, 2017, ISPRS J PHOTOGRAMM, V130, P431, DOI 10.1016/j.isprsjprs.2017.06.012
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Guo YL, 2015, INFORM SCIENCES, V293, P196, DOI 10.1016/j.ins.2014.09.015
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   He Y, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17081862
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Petrelli A, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P403, DOI 10.1109/3DIMPVT.2012.51
   Petrelli A, 2011, IEEE I CONF COMP VIS, P2244, DOI 10.1109/ICCV.2011.6126503
   Prakhya SM, 2017, AUTON ROBOT, V41, P1501, DOI 10.1007/s10514-016-9612-y
   Prakhya SM, 2017, IEEE ROBOT AUTOM LET, V2, P1472, DOI 10.1109/LRA.2017.2667721
   Quan SW, 2018, INFORM SCIENCES, V444, P153, DOI 10.1016/j.ins.2018.02.070
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Shah SAA, 2017, PATTERN RECOGN, V64, P29, DOI 10.1016/j.patcog.2016.10.028
   Shotton J, 2013, PROC CVPR IEEE, P2930, DOI 10.1109/CVPR.2013.377
   Sipiran I, 2011, VISUAL COMPUT, V27, P963, DOI 10.1007/s00371-011-0610-y
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Sun TC, 2020, INFORM SCIENCES, V520, P209, DOI 10.1016/j.ins.2020.02.004
   Tang KK, 2017, IEEE ACCESS, V5, P1833, DOI 10.1109/ACCESS.2017.2658681
   Tateno K, 2016, IEEE INT CONF ROBOT, P2295, DOI 10.1109/ICRA.2016.7487378
   Tombari Federico, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology (PSIVT), P349, DOI 10.1109/PSIVT.2010.65
   Tombari F., P ACM WORKSH 3D OBJ, P57
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Yang JQ, 2017, COMPUT VIS IMAGE UND, V160, P133, DOI 10.1016/j.cviu.2017.02.004
   Yang JQ, 2017, PATTERN RECOGN, V65, P175, DOI 10.1016/j.patcog.2016.11.019
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhang YH, 2021, PATTERN RECOGN, V111, DOI 10.1016/j.patcog.2020.107691
   Zou Y, 2018, PATTERN RECOGN, V76, P522, DOI 10.1016/j.patcog.2017.11.029
NR 41
TC 5
Z9 6
U1 5
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104339
DI 10.1016/j.imavis.2021.104339
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4VF
UT WOS:000772585200001
DA 2024-07-18
ER

PT J
AU Liu, YZ
   Wang, YN
   Kong, AWK
AF Liu, Yanzhu
   Wang, Yanan
   Kong, Adams Wai Kin
TI Pixel-wise ordinal classification for salient object grading
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ordinal classification; Salient object grading; Deep neural networks
AB Driven by business intelligence applications for rating attraction of products in shops, a new problem - salient object grading is studied in this paper. In computer vision, plenty of salient object detection approaches have been proposed, while most existing studies detect objects in a binary manner: salient or not. This paper focuses on a new problem setting that requires detecting all salient objects and categorizing them into different salient levels. Based on that, a pixel-wise ordinal classification method is proposed. It consists of a multi-resolution saliency detector which detects and segments objects, an ordinal classifier which grades pixels into different salient levels, and a binary saliency enhancer which sharpens the difference between non-saliency and all other salient levels. Two new image datasets with salient level labels are constructed. Experimental results demonstrate that, on the one hand, the proposed method provides effective salient level predictions and on the other hand, offers very comparable performance with state-of-the-art salient object detection methods in the traditional problem setting. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Liu, Yanzhu; Kong, Adams Wai Kin] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639978, Singapore.
   [Wang, Yanan] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian 710119, Peoples R China.
C3 Nanyang Technological University; Chinese Academy of Sciences; Xi'an
   Institute of Optics & Precision Mechanics, CAS
RP Liu, YZ (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639978, Singapore.
EM yzliu@ntu.edu.sg
OI , Yanzhu/0000-0002-4570-519X
FU Ministry of Education, Singapore [MOE2016-T2-1-042(S)]
FX This work is supported by Ministry of Education, Singapore
   (MOE2016-T2-1-042(S)).
CR Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   IBM, 2019, ANAL REAL WORLD USE
   Islam MA, 2018, PROC CVPR IEEE, P7142, DOI 10.1109/CVPR.2018.00746
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Li GB, 2017, PROC CVPR IEEE, P247, DOI 10.1109/CVPR.2017.34
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu YZ, 2018, PROC CVPR IEEE, P831, DOI 10.1109/CVPR.2018.00093
   Liu YZ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2372
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
NR 23
TC 4
Z9 4
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104086
DI 10.1016/j.imavis.2020.104086
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700002
DA 2024-07-18
ER

PT J
AU Duan, JH
   Xu, H
   Lin, XZ
   Zhu, SC
   Du, YZ
AF Duan, Jinhao
   Xu, Hua
   Lin, Xiaozhu
   Zhu, Shangchao
   Du, Yuanze
TI Multi-semantic long-range dependencies capturing for efficient video
   representation learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video representation learning; Long-range dependencies capturing; Video
   classification
ID VISUAL-ATTENTION; NEURAL-NETWORKS; RECOGNITION; MODEL
AB Capturing long-range dependencies has proven effective on video understanding tasks. However, previous works address this problem in a pixel pairs manner, which might be inaccurate since pixel pairs contain too limited semantic information. Besides, considerable computations and parameters will be introduced in those methods. Following the pattern of features aggregation in Graph Convolutional Networks (GCNs), we aggregate pixels with their neighbors into semantic units, which contain stronger semantic information than pixel pairs. We designed an efficient, parameter-free, semantic units-based dependencies capturing framework, named as Multi semantic Long-range Dependencies Capturing (MLDC) block. We verified our methods on large-scale challenging video classification benchmark, such as Kinetics. Experiments demonstrate that our method highly outperforms pixel pairs-based methods and achieves the state-of-the-art performance, without introducing any parameters and much computations. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Duan, Jinhao; Xu, Hua; Lin, Xiaozhu; Zhu, Shangchao] Beijing Inst Petrochem Technol, Beijing 102617, Peoples R China.
   [Du, Yuanze] China Univ Min Technol, Beijing 100083, Peoples R China.
C3 Beijing Institute of Petrochemical Technology; China University of
   Mining & Technology
RP Xu, H (corresponding author), Beijing Inst Petrochem Technol, Beijing 102617, Peoples R China.
EM huaxu.bj@gmail.com
OI , Jinhao Duan/0000-0002-6546-8136
FU China National Natural Science Foundation [41877186, 41430318];
   Fundamental Research Funds for the Central Universities [2010YD02]
FX This research was financially supported by China National Natural
   Science Foundation (41877186, 41430318), Fundamental Research Funds for
   the Central Universities (2010YD02).
CR [Anonymous], CoRR abs/1511.07122
   Cao Y, 2019, IEEE ICC
   Cao ZC, 2018, IEEE INT CON AUTO SC, P803, DOI 10.1109/COASE.2018.8560578
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chiang WL, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P257, DOI 10.1145/3292500.3330925
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Gu Y, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.004
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Jiang YG, 2018, IEEE T PATTERN ANAL, V40, P352, DOI 10.1109/TPAMI.2017.2670560
   Kipf TN, 2017, INT C LEARN REPR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Levie R, 2019, IEEE T SIGNAL PROCES, V67, P97, DOI 10.1109/TSP.2018.2879624
   Li J, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107037
   Li RY, 2018, AAAI CONF ARTIF INTE, P3546
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu XY, 2019, PROC CVPR IEEE, P4268, DOI 10.1109/CVPR.2019.00440
   Liu ZQ, 2019, AAAI CONF ARTIF INTE, P4424
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo CX, 2019, IEEE I CONF COMP VIS, P5511, DOI 10.1109/ICCV.2019.00561
   Luo WJ, 2016, ADV NEUR IN, V29
   Moldovan AC, 2019, IEEE INT ULTRA SYM, P2056, DOI [10.1109/ultsym.2019.8925549, 10.1109/ULTSYM.2019.8925549]
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   OLSHAUSEN BA, 1993, J NEUROSCI, V13, P4700
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Tao Y, 2017, CHIN CONTR CONF, P4288, DOI 10.23919/ChiCC.2017.8028032
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Velickovic P., 2019, ARXIV180910341, P1
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2018, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2018.00155
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu K, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350934
   Yi YY, 2020, ADV FUNCT MATER, V30, DOI 10.1002/adfm.201903878
   Ying R, 2018, ADV NEUR IN, V31
   Yuan Y, 2016, IMAGE VISION COMPUT, V55, P77, DOI 10.1016/j.imavis.2016.04.001
   Zhang MH, 2018, AAAI CONF ARTIF INTE, P4430
   Zhuang CY, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P499, DOI 10.1145/3178876.3186116
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 57
TC 0
Z9 0
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 103988
DI 10.1016/j.imavis.2020.103988
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800014
DA 2024-07-18
ER

PT J
AU Lisanti, G
   Martinel, N
   Micheloni, C
   Del Bimbo, A
   Foresti, GL
AF Lisanti, Giuseppe
   Martinel, Niki
   Micheloni, Christian
   Del Bimbo, Alberto
   Foresti, Gian Luca
TI From person to group re-identification via unsupervised transfer of
   sparse features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Group Re-Identification; Dictionary learning; Encoding
AB The visual association of a person appearing in the field of view of different cameras is today well known as Person Re-Identification. Current approaches find a solution to such a problem by considering persons as individuals, hence avoiding the fact that frequently they form groups or move in crowds. In such cases, the information acquired by neighboring individuals can provide relevant visual context to boost the performance in re-identifying persons within the group. In light of enriched information, groups re-identification encompasses additional problems to the common person re-identification ones, such as severe occlusions and changes in the relative position of people within the group. In this paper, the single person re-identification knowledge is transferred by means of a sparse dictionary learning to group re-identification. First, patches extracted from single person images are used to learn a dictionary of sparse atoms. This is used to obtain a sparsity-driven residual group representation that is exploited to perform group re identification. To evaluate the performance of the proposed approach, we considered the i-LIDS groups dataset that is the only group re-identification publicly available dataset. The benchmark datasets for single person re-identification evaluation do not include group information, hence we collected two additional datasets under challenging scenarios and used them to validate our solution. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Lisanti, Giuseppe] Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy.
   [Martinel, Niki; Micheloni, Christian; Foresti, Gian Luca] Univ Udine, Dept Math Comp Sci & Phys, Udine, Italy.
   [Del Bimbo, Alberto] Univ Florence, MICC, Florence, Italy.
C3 University of Bologna; University of Udine; University of Florence
RP Lisanti, G (corresponding author), Univ Bologna, Dept Comp Sci & Engn, Bologna, Italy.
EM giuseppe.lisanti@unibo.it; niki.martinel@uniud.it;
   chrstian.micheloni@uniud.it; alberto.delbimbo@unifi.it;
   gianluca.foresti@uniud.it
RI Micheloni, Christian/E-5427-2012; Lisanti, Giuseppe/AAG-8699-2020
OI Lisanti, Giuseppe/0000-0002-0785-9972; Micheloni,
   Christian/0000-0003-4503-7483
FU Social Museum and Smart Tourism, MIUR project [CTNO1 00034 23154 SMST];
   "PREscriptive Situational awareness for cooperative autoorganizing
   aerial sensor NETworks" MoD project [C1G68827500FB]
FX This research was partially supported by the Social Museum and Smart
   Tourism, MIUR project no. CTNO1 00034 23154 SMST and by the
   "PREscriptive Situational awareness for cooperative autoorganizing
   aerial sensor NETworks" MoD project C1G68827500FB. The Titan Xp used for
   this research was donated by the NVIDIA Corporation.
CR [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], 2016, AAAI NAT C AI
   [Anonymous], 2014, BRIT MACH VIS C
   [Anonymous], 2004, CAVIAR DAT
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], 2014, ECCV
   Assari SM, 2016, LECT NOTES COMPUT SC, V9906, P119, DOI 10.1007/978-3-319-46475-6_8
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   Chen JX, 2015, IEEE T IMAGE PROCESS, V24, P4741, DOI 10.1109/TIP.2015.2466117
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   FELZENSZWALB PF, 2010, PROC CVPR IEEE, P2241, DOI DOI 10.1109/CVPR.2010.5539906
   García J, 2017, IEEE T IMAGE PROCESS, V26, P1650, DOI 10.1109/TIP.2017.2652725
   García J, 2016, J VIS COMMUN IMAGE R, V38, P115, DOI 10.1016/j.jvcir.2016.02.009
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hirzer M, 2012, LECT NOTES COMPUT SC, V7577, P780, DOI 10.1007/978-3-642-33783-3_56
   Insafutdinov  E., 2016, ARTICULATED MULTIPER
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Karaca S, 2017, INT J MENT HEALTH AD, V15, P701, DOI 10.1007/s11469-016-9660-8
   Karaman S, 2014, PATTERN RECOGN, V47, P3767, DOI 10.1016/j.patcog.2014.06.003
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Kodirov E., 2015, BMVC, DOI DOI 10.5244/C.29.44
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Z, 2013, PROC CVPR IEEE, P3610, DOI 10.1109/CVPR.2013.463
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lin  Y., 2017, ARXIV17030722
   Lisanti G, 2017, IEEE I CONF COMP VIS, P2468, DOI 10.1109/ICCV.2017.268
   Lisanti G, 2015, IEEE T PATTERN ANAL, V37, P1629, DOI 10.1109/TPAMI.2014.2369055
   Ma AJ, 2015, IEEE T IMAGE PROCESS, V24, P1599, DOI 10.1109/TIP.2015.2395715
   Ma BP, 2012, LECT NOTES COMPUT SC, V7583, P413, DOI 10.1007/978-3-642-33863-2_41
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Martinel N, 2017, IEEE T CYBERNETICS, V47, P3530, DOI 10.1109/TCYB.2016.2568264
   Matsukawa T, 2016, PROC CVPR IEEE, P1363, DOI 10.1109/CVPR.2016.152
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Tao DP, 2015, IEEE T CYBERNETICS, V45, P242, DOI 10.1109/TCYB.2014.2323992
   Ukita N, 2016, COMPUT VIS IMAGE UND, V144, P228, DOI 10.1016/j.cviu.2015.06.011
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang JW, 2019, AGROFOREST SYST, V93, P395, DOI 10.1007/s10457-017-0129-y
   Wang XJ, 2016, IEEE T CIRC SYST VID, V26, P1447, DOI 10.1109/TCSVT.2015.2450331
   Wang ZJ, 2014, J CHEM-NY, V2014, DOI 10.1155/2014/475389
   Wu  L, 2017, ARXIV170603160
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yao H., 2017, ARXIV170700798
   Yinghao Cai, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2744, DOI 10.1109/ICPR.2010.672
   Zhang H, 2013, IEEE T CYBERNETICS, V43, P1429, DOI 10.1109/TCYB.2013.2275291
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang SS, 2016, PROC CVPR IEEE, P1259, DOI 10.1109/CVPR.2016.141
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P3916, DOI 10.1109/ICCV.2015.446
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2016, IEEE T PATTERN ANAL, V38, P591, DOI 10.1109/TPAMI.2015.2453984
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng Wei-Shi, 2009, P BRIT MACH VIS C, P23, DOI DOI 10.5244/C.23.23
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   2013, IEEE C COMP VIS PATT, P3586, DOI DOI 10.1109/CVPR.2013.460
   2015, IEEE T IMAGE PROCESS, V24, P5645, DOI DOI 10.1109/TIP.2015.2487048
   2016, IEEE T PATTERN ANAL, V38, P1707, DOI DOI 10.1109/TPAMI.2015.2496269
   2014, ASIAN C COMPUTER VIS, P1, DOI DOI 10.1002/9781118468791
   2016, PATTERN RECOGN LETT, V71, P23, DOI DOI 10.1016/J.PATREC.2015.11.022
NR 74
TC 5
Z9 6
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR-APR
PY 2019
VL 83-84
BP 29
EP 38
DI 10.1016/j.imavis.2019.02.009
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HW6TR
UT WOS:000466824000003
DA 2024-07-18
ER

PT J
AU Chen, YQ
   Duffner, S
   Stoian, A
   Dufour, JY
   Baskurt, A
AF Chen, Yiqiang
   Duffner, Stefan
   Stoian, Andrei
   Dufour, Jean-Yves
   Baskurt, Atilla
TI Deep and low-level feature based attribute learning for person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Soft-biometrics; Pedestrian attributes;
   Convolutional neural network
ID CNN
AB In video surveillance, pedestrian attributes are defined as semantic descriptors like gender, clothing or accessories. In this paper, we propose a CNN-based pedestrian attribute-assisted person re-identification framework. First we perform the attribute learning by a part-specific CNN to model attribute patterns related to different body parts and fuse them with low-level robust Local Maximal Occurrence (LOMO) features to address the problem of the large variation of visual appearance and location of attributes due to different body poses and camera views. Our experiments on three public benchmarks show that the proposed method improves the state of the art on attribute recognition. Then we merge the learned attribute CNN embedding with another identification CNN embedding in a triplet structure to perform the person re-identification task. Both CNNs are pre-trained in a supervised way on attributes and person identities respectively, and then continue the training with a combined architecture for re-identification. We experimentally show that this fusion of "identity and attributes features" improves the overall re-identification. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Chen, Yiqiang; Duffner, Stefan; Baskurt, Atilla] Univ Lyon, CNRS, INSA Lyon, LIRIS,UMR5205, Lyon, France.
   [Stoian, Andrei; Dufour, Jean-Yves] ThereSIS, Thales Serv, Palaiseau, France.
C3 Centre National de la Recherche Scientifique (CNRS); Institut National
   des Sciences Appliquees de Lyon - INSA Lyon; Thales Group
RP Chen, YQ (corresponding author), Univ Lyon, CNRS, INSA Lyon, LIRIS,UMR5205, Lyon, France.
EM yiqiang.chen@insa-lyon.fr
OI Stoian, Andrei/0000-0002-3479-9565
FU Group Image Mining (GIM); THALES Group in Computer Vision and Data
   Mining
FX This work was supported by the Group Image Mining (GIM) which joins
   researchers of LIRIS Lab. and THALES Group in Computer Vision and Data
   Mining. We thank NVIDIA Corporation for their generous GPU donation to
   carry out this research.
CR [Anonymous], 2015, PROC CVPR IEEE
   [Anonymous], 2012, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2012.6247939
   [Anonymous], 2016, INT J COMPUT RES
   [Anonymous], 2009, Applications of Computer Vision (WACV), 2009 Workshop on
   Chen Y., 2018, INT C COMP VIS THEOR
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Duan K, 2012, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2012.6248089
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gray D., 2007, P INT WORKSH PERF EV, V3
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Khamis S, 2015, LECT NOTES COMPUT SC, V8927, P134, DOI 10.1007/978-3-319-16199-0_10
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Layne R, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.24
   Layne R, 2014, ADV COMPUT VIS PATT, P93, DOI 10.1007/978-1-4471-6296-4_5
   Lefebvre G, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P238, DOI 10.1109/AVSS.2013.6636646
   Li AN, 2014, ADV COMPUT VIS PATT, P119, DOI 10.1007/978-1-4471-6296-4_6
   Li D., 2015, P AS C PATT REC ACPR
   Li HY, 2017, NEUROCOMPUTING, V226, P212, DOI 10.1016/j.neucom.2016.11.056
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Liao S., 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, P1301, DOI DOI 10.1109/CVPR.2010.5539817
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu H, 2017, IEEE T IMAGE PROCESS, V26, P3492, DOI 10.1109/TIP.2017.2700762
   MA B, 2012, P EUR C COMPUT VIS, P413, DOI DOI 10.1007/978-3-642-33863-241
   Matsukawa T, 2016, INT C PATT RECOG, P2428, DOI 10.1109/ICPR.2016.7900000
   McLaughlin N, 2017, IEEE T CIRC SYST VID, V27, P525, DOI 10.1109/TCSVT.2016.2619498
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Prosser B., 2010, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.24.21
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su C, 2016, LECT NOTES COMPUT SC, V9906, P475, DOI 10.1007/978-3-319-46475-6_30
   Sudowe Patrick, 2015, ICCV, P87
   Tian YL, 2015, PROC CVPR IEEE, P5079, DOI 10.1109/CVPR.2015.7299143
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204
   Xiong F, 2014, LECT NOTES COMPUT SC, V8695, P1, DOI 10.1007/978-3-319-10584-0_1
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zhu J., 2014, P AS C COMP VIS, P545
   Zhu JQ, 2017, IMAGE VISION COMPUT, V58, P224, DOI 10.1016/j.imavis.2016.07.004
   Zhu JQ, 2015, INT CONF BIOMETR, P535, DOI 10.1109/ICB.2015.7139070
   Zhu JQ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P331, DOI 10.1109/ICCVW.2013.51
NR 51
TC 23
Z9 24
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 25
EP 34
DI 10.1016/j.imavis.2018.09.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jiang, HJ
   Wang, RP
   Li, Y
   Liu, HM
   Shan, SG
   Chen, XL
AF Jiang, Huajie
   Wang, Ruiping
   Li, Yan
   Liu, Haomiao
   Shan, Shiguang
   Chen, Xilin
TI Attribute annotation on large-scale image database by active knowledge
   transfer
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Attribute; Annotation; Relationship; Active learning; Transfer learning
ID FACIAL ATTRIBUTES; OBJECT CLASSES; RECOGNITION
AB Attributes are widely used in different vision tasks. However, existing attribute resources are quite limited and most of them are not in large scale. Current attribute annotation process is generally done by human, which is expensive and time-consuming. in this paper, we propose a novel framework to perform effective attribute annotations. Based on the common knowledge that attributes can be shared among different classes, we leverage the benefits of transfer learning and active learning together to transfer knowledge from some existing small attribute databases to large-scale target databases. In order to learn more robust attribute models, attribute relationships are incorporated to assist the learning process. Using the proposed framework, we conduct extensive experiments on two large-scale image databases, i.e. ImageNet and SUN Attribute, where high quality automatic attribute annotations are obtained. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Jiang, Huajie] Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Shanghai 200050, Peoples R China.
   [Jiang, Huajie; Wang, Ruiping; Li, Yan; Liu, Haomiao; Shan, Shiguang; Chen, Xilin] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Jiang, Huajie] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
   [Jiang, Huajie; Wang, Ruiping; Li, Yan; Liu, Haomiao; Shan, Shiguang; Chen, Xilin] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Institute of Microsystem &
   Information Technology, CAS; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS; ShanghaiTech University; Chinese Academy of
   Sciences; University of Chinese Academy of Sciences, CAS
RP Wang, RP (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
EM wangruiping@ict.ac.cn
RI Zhang, yuxuan/JXM-9935-2024; Liu, Haomiao/W-9062-2019
OI Shan, Shiguang/0000-0002-8348-392X
FU 973 Program [201503351802]; Natural Science Foundation of China
   [61390511, 61772500]; Frontier Science Key Research Project CAS
   [QYZDJ-SSW-JSC009]; Youth Innovation Promotion Association CAS [2015085]
FX This work is partially supported by 973 Program under contract No.
   201503351802, Natural Science Foundation of China under contract Nos.
   61390511 and 61772500, Frontier Science Key Research Project CAS No.
   QYZDJ-SSW-JSC009, and Youth Innovation Promotion Association CAS No.
   2015085.
CR Al-Halah Z, 2017, PROC CVPR IEEE, P5112, DOI 10.1109/CVPR.2017.543
   [Anonymous], 2009, COMPUT SCI TECH REP
   [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.559
   [Anonymous], 2015, CVPR
   Aytar Y, 2011, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2011.6126504
   Biswas A, 2013, PROC CVPR IEEE, P644, DOI 10.1109/CVPR.2013.89
   Chen L, 2014, PROC CVPR IEEE, P1027, DOI 10.1109/CVPR.2014.135
   Chen Q, 2015, PROC CVPR IEEE, P5315, DOI 10.1109/CVPR.2015.7299169
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diba A, 2016, PROC CVPR IEEE, P3557, DOI 10.1109/CVPR.2016.387
   Douze M, 2011, PROC CVPR IEEE, P745, DOI 10.1109/CVPR.2011.5995595
   Escorcia V, 2015, PROC CVPR IEEE, P1256, DOI 10.1109/CVPR.2015.7298730
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534
   Fu YW, 2014, LECT NOTES COMPUT SC, V8690, P584, DOI 10.1007/978-3-319-10605-2_38
   Fu YW, 2012, LECT NOTES COMPUT SC, V7575, P530, DOI 10.1007/978-3-642-33765-9_38
   Gan C, 2016, PROC CVPR IEEE, P87, DOI 10.1109/CVPR.2016.17
   Gavves E, 2015, IEEE I CONF COMP VIS, P2731, DOI 10.1109/ICCV.2015.313
   Gong BQ, 2012, PROC CVPR IEEE, P2066, DOI 10.1109/CVPR.2012.6247911
   Gopalan R, 2011, IEEE I CONF COMP VIS, P999, DOI 10.1109/ICCV.2011.6126344
   Han YH, 2014, IEEE T MULTIMEDIA, V16, P1115, DOI 10.1109/TMM.2014.2306092
   Jayaraman D, 2014, PROC CVPR IEEE, P1629, DOI 10.1109/CVPR.2014.211
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Kapoor A, 2010, INT J COMPUT VISION, V88, P169, DOI 10.1007/s11263-009-0268-3
   Kovashka A, 2013, IEEE I CONF COMP VIS, P297, DOI 10.1109/ICCV.2013.44
   Kovashka A, 2013, IEEE I CONF COMP VIS, P3432, DOI 10.1109/ICCV.2013.426
   Kovashka A, 2012, PROC CVPR IEEE, P2973, DOI 10.1109/CVPR.2012.6248026
   Kulkarni G, 2013, IEEE T PATTERN ANAL, V35, P2891, DOI 10.1109/TPAMI.2012.162
   Kusakunniran Worapan, 2014, Image and Vision Computing, V32, P1117, DOI 10.1016/j.imavis.2014.10.004
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Liang L, 2014, PROC CVPR IEEE, P208, DOI 10.1109/CVPR.2014.34
   Liu MX, 2014, NEUROCOMPUTING, V139, P34, DOI 10.1016/j.neucom.2013.09.056
   Luo P, 2013, IEEE I CONF COMP VIS, P2864, DOI 10.1109/ICCV.2013.356
   MACKAY DJC, 1992, NEURAL COMPUT, V4, P590, DOI 10.1162/neco.1992.4.4.590
   Mahajan D, 2011, IEEE I CONF COMP VIS, P1227, DOI 10.1109/ICCV.2011.6126373
   Mensink T, 2011, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2011.5995380
   Ordonez V., 2011, ADV NEURAL INFORM PR, P1143
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Patterson G, 2016, LECT NOTES COMPUT SC, V9910, P85, DOI 10.1007/978-3-319-46466-4_6
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Russakovsky O., 2010, LNCS, P1, DOI DOI 10.1007/978-3-642-35749-7_1
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Samangouei P, 2017, IMAGE VISION COMPUT, V58, P181, DOI 10.1016/j.imavis.2016.05.004
   Siddiquie B, 2011, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.2011.5995329
   Tong S, 2002, J MACH LEARN RES, V2, P45, DOI 10.1162/153244302760185243
   Wang Y, 2010, LECT NOTES COMPUT SC, V6315, P155, DOI 10.1007/978-3-642-15555-0_12
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Yu Zhang, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P697, DOI 10.1007/978-3-642-33460-3_50
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zhu JQ, 2017, IMAGE VISION COMPUT, V58, P224, DOI 10.1016/j.imavis.2016.07.004
NR 52
TC 5
Z9 6
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2018
VL 78
BP 1
EP 13
DI 10.1016/j.imavis.2018.06.012
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV5LO
UT WOS:000446143900001
DA 2024-07-18
ER

PT J
AU McCurrie, M
   Beletti, F
   Parzianello, L
   Westendorp, A
   Anthony, S
   Scheirer, WJ
AF McCurrie, Mel
   Beletti, Fernando
   Parzianello, Lucas
   Westendorp, Allen
   Anthony, Samuel
   Scheirer, Walter J.
TI Convolutional Neural Networks for Subjective Face Attributes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Psychophysics; Face attributes; Convolutional neural networks
ID TRUSTWORTHINESS; PERCEPTION; DOMINANCE
AB Describable visual facial attributes are now commonplace in human biometrics and affective computing, with existing algorithms even reaching a sufficient point of maturity for placement into commercial products. These algorithms model objective facets of facial appearance, such as hair and eye color, expression, and aspects of the geometry of the face. A natural extension, which has not been studied to any great extent thus far, is the ability to model subjective attributes that are assigned to a face based purely on visual judgments. For instance, with just a glance, our first impression of a face may lead us to believe that a person is smart, worthy of our trust, and perhaps even our admiration regardless of the underlying truth behind such attributes. Psychologists believe that these judgments are based on a variety of factors such as emotional states, personality traits, and other physiognomic cues. But work in this direction leads to an interesting question: how do we create models for problems where there is only measurable behavior? In this paper, we introduce a convolutional neural network-based regression framework that allows us to train predictive models of crowd behavior for social attribute assignment. Over images from the AFLW face database, these models demonstrate strong correlations with human crowd ratings. (C) 2018 Elsevier B.V. All rights reserved.
C1 [McCurrie, Mel; Beletti, Fernando; Parzianello, Lucas; Westendorp, Allen; Scheirer, Walter J.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
   [Anthony, Samuel] Harvard Univ, Dept Psychol, Cambridge, MA 02138 USA.
   [Anthony, Samuel] Percept Automata Inc, Somerville, MA 02143 USA.
C3 University of Notre Dame; Harvard University
RP McCurrie, M (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
EM mmccurr1@nd.edu
FU Boeing Company; Brazil Scientific Mobility Program; NSF CNS RET Award
   [1609394]; NSF SBIR Award [IIP-1621689]; NVIDIA Corporation; Direct For
   Computer & Info Scie & Enginr; Division Of Computer and Network Systems
   [1609394] Funding Source: National Science Foundation
FX M. McCurrie was supported by a gift from the Boeing Company. F. Beletti
   and L. Parzianello were supported by the Brazil Scientific Mobility
   Program. A. Westendorp was supported by NSF CNS RET Award #1609394. S.
   Anthony was supported in part by NSF SBIR Award #IIP-1621689. Hardware
   support was generously provided by the NVIDIA Corporation.
CR ALICKE MD, 1986, PERS SOC PSYCHOL B, V12, P381, DOI 10.1177/0146167286124001
   [Anonymous], 2016, ARXIV160406433
   [Anonymous], IEEE ICCV
   [Anonymous], 1 IEEE INT WORKSH BE
   [Anonymous], INT C MULT INT
   [Anonymous], 2016, ARXIV161002391
   [Anonymous], 2008, INT WORKSH COGN TECH
   [Anonymous], 2013, P 12 PYTH SCI C
   [Anonymous], 2015, IEEE CVPR
   [Anonymous], IEEE CVPR
   [Anonymous], IEEE CVPR WORKSH
   [Anonymous], IEEE CVPR WORKSH
   [Anonymous], MEGAFACE 2 672 057 I
   [Anonymous], IEEE ICCV
   [Anonymous], IEEE ICIP
   [Anonymous], 2016, EUR C COMP VIS ECCV
   [Anonymous], IEEE CVPR
   [Anonymous], ARXIV160509062
   [Anonymous], IEEE CVPR
   [Anonymous], 2012, Advances in neural information processing systems
   Berger J., 2010, Proceedings of the Python for Scientific Computing Conference (SciPy), number Scipy, P1
   Bolme DS, 2003, LECT NOTES COMPUT SC, V2626, P304
   Chollet F, 2015, KERAS
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Falvello V, 2015, SOC COGNITION, V33, P368, DOI 10.1521/soco.2015.33.5.368
   Germine L, 2012, PSYCHON B REV, V19, P847, DOI 10.3758/s13423-012-0296-9
   Golomb B.A., 1990, NIPS
   KEATING CF, 1981, J PERS SOC PSYCHOL, V40, P615, DOI 10.1037/0022-3514.40.4.615
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Kwon YH, 1999, COMPUT VIS IMAGE UND, V74, P1, DOI 10.1006/cviu.1997.0549
   Mignault A, 2003, J NONVERBAL BEHAV, V27, P111, DOI 10.1023/A:1023914509763
   Oosterhof NN, 2008, P NATL ACAD SCI USA, V105, P11087, DOI 10.1073/pnas.0805664105
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pinkham AE, 2008, SCHIZOPHRENIA BULL, V34, P688, DOI 10.1093/schbul/sbn031
   Scheirer W.J., 2012, IEEE CVPR
   Senior C, 1999, BEHAV RES METH INS C, V31, P341, DOI 10.3758/BF03207730
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Todorov A, 2008, COGN NEUROPSYCHOL, V25, P395, DOI 10.1080/02643290802044996
   Todorov A, 2008, SOC COGN AFFECT NEUR, V3, P119, DOI 10.1093/scan/nsn009
   Todorov A, 2009, SOC COGNITION, V27, P813, DOI 10.1521/soco.2009.27.6.813
   Winston JS, 2002, NAT NEUROSCI, V5, P277, DOI 10.1038/nn816
   Wolf L, 2011, IEEE IMAGE PROC
   Zhang N, 2014, PROC CVPR IEEE, P1637, DOI 10.1109/CVPR.2014.212
   Zhong Y, 2016, INT CONF BIOMETR
NR 44
TC 4
Z9 6
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2018
VL 78
BP 14
EP 25
DI 10.1016/j.imavis.2018.06.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA GV5LO
UT WOS:000446143900002
DA 2024-07-18
ER

PT J
AU Meng, M
   Drira, H
   Boonaert, J
AF Meng, Meng
   Drira, Hassen
   Boonaert, Jacques
TI Distances evolution analysis for online and off-line human object
   interaction recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human object interaction; Rate invariance; Shape analysis; Temporal
   modeling
ID RATE-INVARIANT ANALYSIS; SEGMENTATION; AFFORDANCES
AB Human action recognition in 3D sequences is one of the most challenging and active areas of research in the computer vision domain. However designing automatic systems that are robust to significant variability due to object combinations and high complexity of human motions is more challenging in addition to the typical requirements such as rotation, translation, and scale invariance is challenging task. In this paper, we propose a spatio-temporal modeling of human-object interaction videos for online and off-line recognition. The inter-joint distances and the object are considered as low-level features for online classification. For off-line recognition, we propose rate-invariant classification of full video and early recognition. A shape analysis of trajectories of the inter-joint and object-joints distances is proposed for this end. The experiments conducted following state-of-the-art settings using MSR Daily Activity 3D Dataset and Online RGBD Action Dataset and on a new multi-view dataset for human object interaction demonstrate that the proposed approach is effective and discriminative for human object interaction classification as demonstrated here. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Meng, Meng; Drira, Hassen] North Carolina Cent Univ, Durham, NC 27707 USA.
   [Boonaert, Jacques] IMT Lille Douai, Villeneuve Dascq, France.
   [Drira, Hassen] Univ Lille 1, CNRS, UMR 9189, CRIStAL Lab, Villeneuve Dascq, France.
C3 University of North Carolina; North Carolina Central University; IMT -
   Institut Mines-Telecom; Universite de Lille; IMT Nord Europe; Universite
   de Lille; Centrale Lille; Centre National de la Recherche Scientifique
   (CNRS)
RP Drira, H (corresponding author), North Carolina Cent Univ, Durham, NC 27707 USA.; Drira, H (corresponding author), Univ Lille 1, CNRS, UMR 9189, CRIStAL Lab, Villeneuve Dascq, France.
EM mmeng@nccu.edu; drira@imt-lille-douai.fr;
   jacques.boonaert@imt-lille-douai.fr
RI Drira, Hassen/AAG-9736-2020
OI Drira, Hassen/0000-0003-1052-4353; BOONAERT, Jacques/0000-0002-8594-6959
CR Abdelkader MF, 2011, COMPUT VIS IMAGE UND, V115, P439, DOI 10.1016/j.cviu.2010.10.006
   Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Aksoy EE, 2011, INT J ROBOT RES, V30, P1229, DOI 10.1177/0278364911410459
   Anguelov D, 2005, PROC CVPR IEEE, P169
   Anirudh R, 2015, PROC CVPR IEEE, P3147, DOI 10.1109/CVPR.2015.7298934
   [Anonymous], 2014, Asian Conference on Computer Vision
   Batista GEAPA, 2003, APPL ARTIF INTELL, V17, P519, DOI [10.1080/713827181, 10.1080/08839510390219309]
   Ben Amor B, 2016, IEEE T PATTERN ANAL, V38, P1, DOI 10.1109/TPAMI.2015.2439257
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chaquet JM, 2013, COMPUT VIS IMAGE UND, V117, P633, DOI 10.1016/j.cviu.2013.01.013
   Chen G, 2015, SIGNAL PROCESS, V110, P67, DOI 10.1016/j.sigpro.2014.08.024
   Delaitre V, 2012, LECT NOTES COMPUT SC, V7577, P284, DOI 10.1007/978-3-642-33783-3_21
   Desai C, 2012, LECT NOTES COMPUT SC, V7575, P158, DOI 10.1007/978-3-642-33765-9_12
   Desai Chaitanya., 2010, Ieee computer society conference on computer vision and pattern recognition workshops, P9
   Devanne M, 2015, FGW, V7, P1
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Gall J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1969, DOI 10.1109/CVPR.2011.5995582
   Gong D, 2011, IEEE I CONF COMP VIS, P571, DOI 10.1109/ICCV.2011.6126290
   Grest D, 2005, LECT NOTES COMPUT SC, V3663, P285
   Gupta A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1961, DOI 10.1109/CVPR.2011.5995448
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Han F, 2017, COMPUT VIS IMAGE UND, V158, P85, DOI 10.1016/j.cviu.2017.01.011
   Jiang M, 2015, SIGNAL PROCESS-IMAGE, V33, P29, DOI 10.1016/j.image.2015.02.004
   KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502
   Ke SR, 2013, COMPUTERS, V2, P88, DOI 10.3390/computers2020088
   Kim VG, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601117
   Kjellström H, 2011, COMPUT VIS IMAGE UND, V115, P81, DOI 10.1016/j.cviu.2010.08.002
   Kleinsmith A, 2013, IEEE T AFFECT COMPUT, V4, P15, DOI 10.1109/T-AFFC.2012.16
   Knoop S, 2006, IEEE INT CONF ROBOT, P1686
   Koppula HS, 2013, INT J ROBOT RES, V32, P951, DOI 10.1177/0278364913478446
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Meng Meng, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166850
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mokni R., 2017, MULTIMEDIA TOOLS APP
   Moore D. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P80, DOI 10.1109/ICCV.1999.791201
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Packer B, 2012, PROC CVPR IEEE, P1378, DOI 10.1109/CVPR.2012.6247824
   Paiement Adeline., 2014, British Machine Vision Conference, P153
   Pazhoumand-Dar H, 2015, J VIS COMMUN IMAGE R, V30, P10, DOI 10.1016/j.jvcir.2015.03.002
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Prest A, 2013, IEEE T PATTERN ANAL, V35, P835, DOI 10.1109/TPAMI.2012.175
   Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158
   Qi J, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0114147
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Srivastava A, 2012, IMAGE VISION COMPUT, V30, P398, DOI 10.1016/j.imavis.2012.03.006
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Su JY, 2014, PROC CVPR IEEE, P620, DOI 10.1109/CVPR.2014.86
   Turaga P, 2011, IEEE T PATTERN ANAL, V33, P2273, DOI 10.1109/TPAMI.2011.52
   Veeraraghavan A, 2009, IEEE T IMAGE PROCESS, V18, P1326, DOI 10.1109/TIP.2009.2017143
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wei P, 2017, IEEE T PATTERN ANAL, V39, P1165, DOI 10.1109/TPAMI.2016.2574712
   Wu J, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, P7, DOI 10.1109/SOLI.2007.4383891
   Xia BG, 2015, PATTERN RECOGN, V48, P746, DOI 10.1016/j.patcog.2014.09.021
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xiang J, 2015, SIGNAL PROCESS, V110, P82, DOI 10.1016/j.sigpro.2014.08.020
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67
   Yao Bangpeng, 2010, CVPR
   Yao B, 2009, IEEE I CONF COMP VIS, P1507, DOI 10.1109/ICCV.2009.5459277
   Yao BZ, 2014, IEEE T PATTERN ANAL, V36, P436, DOI 10.1109/TPAMI.2013.144
   Ye M., 2013, LECT NOTES COMPUTER, P149, DOI [10.1007/978-3-642-44964-2_8, DOI 10.1007/978-3-642-44964-2_8]
   Zhou Y, 2015, PROC CVPR IEEE, P3323, DOI 10.1109/CVPR.2015.7298953
   Zhu YK, 2014, LECT NOTES COMPUT SC, V8690, P408, DOI 10.1007/978-3-319-10605-2_27
   Ziaeefard M, 2015, PATTERN RECOGN, V48, P2329, DOI 10.1016/j.patcog.2015.03.006
NR 68
TC 18
Z9 20
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2018
VL 70
BP 32
EP 45
DI 10.1016/j.imavis.2017.12.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GA7AR
UT WOS:000428487500004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kwon, J
   Lee, H
AF Kwon, Junseok
   Lee, Hansung
TI Visual tracking based on edge field with object proposal association
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Object proposal
AB In this paper, we present a novel tracking system based on edge-based object proposal and data association called object proposal association. Our object proposal method accurately detects and localizes objects in an image by searching for object-like regions, with the assumption that an object is represented by a closed boundary. To search for closed boundaries in an image, we present a new Edge Fields (EFs) technique. Using this technique, our method can extract high-quality edges and can obtain accurate boundaries from the image. The EFs technique consists of blurring and thresholding steps, where the former helps extract high-quality edges and the latter prevents the method from losing image details while blurring. After the method extracts object-like regions, we associate the regions in the previous frame with those in the current frame. For this purpose, using the Markov chain Monte Carlo data association (MCMCDA) algorithm, we can find pairs of similar regions across two frames. Experimental results demonstrate that our object proposal method is competitive with state-of-the-art object proposal methods on the PASCAL VOC 2007 dataset. Our tracking method is also competitive with state-of-the-art tracking methods on Object Tracking Benchmark dataset. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Kwon, Junseok] Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.
   [Lee, Hansung] Samsung Elect Co Ltd, SW R&D Ctr, Seoul, South Korea.
C3 Chung Ang University; Samsung
RP Kwon, J (corresponding author), Chung Ang Univ, Sch Comp Sci & Engn, Seoul, South Korea.; Lee, H (corresponding author), Samsung Elect Co Ltd, SW R&D Ctr, Seoul, South Korea.
EM jskwon@cau.ac.kr; hs7108.lee@samsung.com
RI Lee, Hansung/JBI-8397-2023; Lee, Hansung/R-2247-2019
OI Lee, Hansung/0000-0002-6519-4120; kwon, junseok/0000-0001-9526-7549
FU National Research Foundation of Korea (NRF) grant - Korea government
   (MSIP; Ministry of Science, ICT AMP; Future Planning) [2017R1C1B1003354]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant funded by the Korea government (MSIP; Ministry of Science,
   ICT & Future Planning) (No. 2017R1C1B1003354).
CR Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   Alexe B, 2010, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.2010.5540226
   [Anonymous], 2011, ICCV
   [Anonymous], 2015, CoRR
   [Anonymous], 2004, ICDC
   [Anonymous], 2013, ICCV
   [Anonymous], 2014, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-10599-4_13
   [Anonymous], 2015, ICCV
   Arbeláez P, 2014, PROC CVPR IEEE, P328, DOI 10.1109/CVPR.2014.49
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Cheng MM, 2014, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR.2014.414
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D., 2000, CVPR
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Endres I, 2014, IEEE T PATTERN ANAL, V36, P222, DOI 10.1109/TPAMI.2013.122
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   FORTMANN TE, 1983, IEEE J OCEANIC ENG, V8, P173, DOI 10.1109/JOE.1983.1145560
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques F., 2012, ECCV
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Jia C., 2010, TECHNICAL REPORT
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J., 2015, ISIS
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Li X, 2013, PROC CVPR IEEE, P859, DOI 10.1109/CVPR.2013.116
   Liang PP, 2016, IEEE SIGNAL PROC LET, V23, P949, DOI 10.1109/LSP.2016.2556706
   Liu BY, 2011, PROC CVPR IEEE, P1313, DOI 10.1109/CVPR.2011.5995730
   Perez P., 2002, ECCV
   Rantalankila P, 2014, PROC CVPR IEEE, P2417, DOI 10.1109/CVPR.2014.310
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   Sevilla-Lara L., 2012, CVPR
   Song HH, 2017, ELECTRON LETT, V53, P20, DOI 10.1049/el.2016.3011
   Song HH, 2014, ELECTRON LETT, V50, P1931, DOI 10.1049/el.2014.1911
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang TZ, 2012, LECT NOTES COMPUT SC, V7577, P470, DOI 10.1007/978-3-642-33783-3_34
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zhu G., 2015, ARXIV150708085
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 46
TC 6
Z9 6
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 22
EP 32
DI 10.1016/j.imavis.2017.11.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100003
DA 2024-07-18
ER

PT J
AU Tariq, A
   Foroosh, H
AF Tariq, Amara
   Foroosh, Hassan
TI Designing a symmetric classifier for image annotation using multi-layer
   sparse coding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic image annotation; Sparse coding; Symmetric classifier response
ID MODELS
AB Automatic annotation of images with descriptive words is a challenging problem with vast applications in the areas of image search and retrieval. This problem can be viewed as a label-assignment problem by a classifier dealing with a very large set of labels, i.e., the vocabulary set. We propose a novel annotation method that employs two layers of sparse coding and performs coarse-to-fine labeling. Themes extracted from the training data are treated as coarse labels. Each theme is a set of training images that share a common subject in their visual and textual contents. Our system extracts coarse labels for training and test images without requiring any prior knowledge. Vocabulary words are the fine labels to be associated with images. Most of the annotation methods achieve low recall due to the large number of available fine labels, i.e., vocabulary words. These systems also tend to achieve high precision for highly frequent words only. On the other hand, text mining literature discusses a general trend where relatively rare/moderately frequent words are more important for search retrieval process than the extremely frequent words. Our system not only outperforms various previously proposed annotation systems, but also achieves symmetric response in terms of precision and recall. Our system scores and maintains high precision for words with a wide range of frequencies. Such behavior is achieved by intelligently reducing the number of available fine labels or words for each image based on coarse labels assigned to it. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Tariq, Amara] Forman Christian Coll, Dept Comp Sci, Lahore, Pakistan.
   [Foroosh, Hassan] Univ Cent Florida, Computat Imaging Lab, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Tariq, A (corresponding author), Forman Christian Coll, Dept Comp Sci, Lahore, Pakistan.
EM amara_tariq@knights.uct.edu
RI Tariq, Amara/Z-1211-2019
OI Tariq, Amara/0000-0001-5932-2491
CR [Anonymous], BMVC
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], STAT HIGH DIMENSIONA
   Ballan Lamberto, 2014, P INT C MULT RETR IC, P73
   Cao XC, 2015, IEEE T IMAGE PROCESS, V24, P2746, DOI 10.1109/TIP.2015.2428055
   Chen M., 2013, FAST IMAGE TAGGING
   Cui C., 2013, ACM SIGIR C RES DEV
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fei Wu, 2015, IEEE Transactions on Big Data, V1, P109, DOI 10.1109/TBDATA.2015.2497270
   Feng SL, 2004, PROC CVPR IEEE, P1002
   Fu H, 2012, LECT NOTES COMPUT SC, V7577, P86, DOI 10.1007/978-3-642-33783-3_7
   Gao SH, 2011, PROC CVPR IEEE
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Gong Yunchao., 2013, Deep convolutional ranking for multilabel image annotation
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197
   Han YH, 2012, IEEE T IMAGE PROCESS, V21, P3066, DOI 10.1109/TIP.2012.2183880
   Hebiri M, 2013, IEEE T INFORM THEORY, V59, P1846, DOI 10.1109/TIT.2012.2227680
   Hu H., 2016, ARXIV151105616
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Jeon J., 2003, Proceedings of the 26th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, P119, DOI DOI 10.1145/860435.860459
   Jing XY, 2016, IEEE T IMAGE PROCESS, V25, P2712, DOI 10.1109/TIP.2016.2549459
   Johnson J, 2015, IEEE I CONF COMP VIS, P4624, DOI 10.1109/ICCV.2015.525
   Kalayeh MM, 2014, PROC CVPR IEEE, P184, DOI 10.1109/CVPR.2014.31
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kulkarni G, 2011, PROC CVPR IEEE, P1601, DOI 10.1109/CVPR.2011.5995466
   Kulkarni N, 2011, PROC CVPR IEEE, P1609, DOI 10.1109/CVPR.2011.5995701
   Lavrenko V., 2003, P 17 INT C NEUR INF
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XR, 2009, IEEE T MULTIMEDIA, V11, P1310, DOI 10.1109/TMM.2009.2030598
   Li Z., 2013, ENG APPL ARTIF INTEL, V26
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Liu X., P 17 ACM INT C MULT, P115
   Makadia A., 2008, P 10 EUR C COMP VI 3
   Mitchell M, 2012, P 13 C EUR CHAPT ASS, P747
   Moran S, 2014, INT J MULTIMED INF R, V3, P209, DOI 10.1007/s13735-014-0063-y
   Moran S, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.1
   Murthy V.N., 2014, ICMR 2014 P ACM INT, P369, DOI DOI 10.1145/2578726.2578774
   Murthy VN, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P603, DOI 10.1145/2671188.2749391
   Murthy VN, 2016, ICMR'16: PROCEEDINGS OF THE 2016 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P299, DOI 10.1145/2911996.2912055
   Ordonez V, 2013, IEEE I CONF COMP VIS, P2768, DOI 10.1109/ICCV.2013.344
   Simon N, 2013, J COMPUT GRAPH STAT, V22, P231, DOI 10.1080/10618600.2012.681250
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun FM, 2014, IEEE T IMAGE PROCESS, V23, P1028, DOI 10.1109/TIP.2014.2298978
   Tariq A., 2015, IEEE C COMP VIS PATT
   Tariq A., 2014, P IEEE INT C IM PROC
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Turney PD, 2010, J ARTIF INTELL RES, V37, P141, DOI 10.1613/jair.2934
   Verma Y., 2012, COMPUTER VISION ECCV
   Wang CH, 2009, PROC CVPR IEEE, P1643, DOI 10.1109/CVPRW.2009.5206866
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Zhang CJ, 2011, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2011.5995484
   Zhang ST, 2012, IEEE T SYST MAN CY B, V42, P838, DOI 10.1109/TSMCB.2011.2179533
NR 57
TC 4
Z9 4
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 33
EP 43
DI 10.1016/j.imavis.2017.11.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100004
DA 2024-07-18
ER

PT J
AU Jo, J
   Kim, H
   Kim, J
AF Jo, Jaeik
   Kim, Hyunjun
   Kim, Jaihie
TI 3D facial shape reconstruction using macro- and micro-level features
   from high resolution facial images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D facial reconstruction; Micro-level feature; Macro-level feature;
   Structure from motion; Active appearance model; Stereo matching
ID FACE RECOGNITION; MODEL; FACTORIZATION; MOTION; ROBUST
AB Three-dimensional (3D) facial modeling and stereo matching-based methods are widely used for 3D facial reconstruction from 2D single-view and multiple-view images. However, these methods cannot realistically reconstruct 3D faces because they use insufficient numbers of macro-level Facial Feature Points (FFPs). This paper proposes an accurate and person-specific 3D facial reconstruction method that uses ample numbers of macro and micro-level FFPs to enable coverage of all facial regions of high resolution facial images. Comparisons of 3D facial images reconstructed using the proposed method for ground-truth 3D facial images from the Bosphorus 3D database show that the method is superior to a conventional Active Appearance Model-Structure from Motion (AAM + SfM)-based method in terms of average 3D root mean square error between the reconstructed and ground-truth 3D faces. Further, the proposed method achieved outstanding accuracy in local facial regions such as the cheek areas where extraction of FFPs is difficult for existing methods. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Jo, Jaeik; Kim, Hyunjun; Kim, Jaihie] Yonsei Univ, Sch Elect & Elect Engn, Seoul 120749, South Korea.
C3 Yonsei University
RP Kim, J (corresponding author), Yonsei Univ, B619,2nd Engn Bldg,134 Sinchon Dong, Seoul 120749, South Korea.
EM jaeik@yonsei.ac.kr; kimhj8574@gmail.com; jhkim@yonsei.ac.kr
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT & Future Planning
   [2016R1A2B4006320]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT & Future Planning (No. 2016R1A2B4006320).
CR Ahmed A, 2008, IEEE IMAGE PROC, P201, DOI 10.1109/ICIP.2008.4711726
   Aldrian O., P BRIT MACH VIS C 20
   [Anonymous], 1 COST 2101 WORKSH B
   Ansari AN, 2005, PATTERN RECOGN, V38, P2549, DOI 10.1016/j.patcog.2005.04.016
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Buchanan AM, 2005, PROC CVPR IEEE, P316
   Chowdhury AKR, 2003, COMPUT VIS IMAGE UND, V91, P188, DOI 10.1016/S1077-3142(03)00079-1
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dovgard R, 2004, LECT NOTES COMPUT SC, V3022, P99
   Fidaleo D, 2007, LECT NOTES COMPUT SC, V4778, P124
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Franco A, 2008, PATTERN RECOGN, V41, P3822, DOI 10.1016/j.patcog.2008.05.029
   Gökberk B, 2009, ADV PATTERN RECOGNIT, P217, DOI 10.1007/978-1-84882-385-3_9
   Herold C, 2014, COMPUT VIS IMAGE UND, V122, P182, DOI 10.1016/j.cviu.2014.01.006
   Jiang DL, 2005, PATTERN RECOGN, V38, P787, DOI 10.1016/j.patcog.2004.11.004
   Jo J, 2015, PATTERN RECOGN, V48, P73, DOI 10.1016/j.patcog.2014.07.013
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Klare Brendan., 2010, Fourth IEEE International Conference on Biometrics: Theory Applications and Systems (BTAS). IEEE, P1, DOI DOI 10.1109/BTAS.2010.5634533
   Lee MW, 2003, PATTERN RECOGN, V36, P1835, DOI 10.1016/S0031-3203(03)00008-6
   Lee SJ, 2011, PATTERN RECOGN, V44, P1470, DOI 10.1016/j.patcog.2010.11.012
   Lee YJ, 2012, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2012-176
   Li D, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2412374
   Li D, 2015, PATTERN RECOGN, V48, P732, DOI 10.1016/j.patcog.2014.09.026
   Liao HB, 2012, J VIS COMMUN IMAGE R, V23, P924, DOI 10.1016/j.jvcir.2012.06.005
   Lin YP, 2010, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2010.5539793
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maejima A, 2008, IEICE T INF SYST, VE91D, P1135, DOI 10.1093/ietisy/e91-d.4.1135
   Marques M, 2009, COMPUT VIS IMAGE UND, V113, P261, DOI 10.1016/j.cviu.2008.09.004
   Park U., P IEEE C COMP VIS PA, P1
   Park U., P INT C AUT FAC GEST, P1
   Park U, 2007, LECT NOTES COMPUT SC, V4642, P1085
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Patel A, 2012, PATTERN RECOGN, V45, P1993, DOI 10.1016/j.patcog.2011.11.013
   Pighin F, 2002, INT J COMPUT VISION, V50, P143, DOI 10.1023/A:1020393915769
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Rara H., P INT JOINT C BIOM 2, P1
   Shan Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P644, DOI 10.1109/ICCV.2001.937687
   Smith WAP, 2006, IEEE T PATTERN ANAL, V28, P1914, DOI 10.1109/TPAMI.2006.251
   Tao LL, 2013, COMPUT VIS IMAGE UND, V117, P1287, DOI 10.1016/j.cviu.2013.03.005
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Wang CH, 2004, LECT NOTES COMPUT SC, V3332, P553
   Wang SF, 2006, LECT NOTES COMPUT SC, V3852, P427
   Wiberg T., P S COMP STAT, P229
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
   Zhang ZY, 2004, INT J COMPUT VISION, V58, P93, DOI 10.1023/B:VISI.0000015915.50080.85
   Zollhöfer M, 2011, COMPUT ANIMAT VIRT W, V22, P195, DOI 10.1002/cav.405
NR 51
TC 3
Z9 3
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2017
VL 64
BP 1
EP 9
DI 10.1016/jimavis.2017.05.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FH0ZW
UT WOS:000410870200001
DA 2024-07-18
ER

PT J
AU Le, THN
   Luu, K
   Zhu, CC
   Savvides, M
AF Le, T. Hoang Ngan
   Luu, Khoa
   Zhu, Chenchen
   Savvides, Marios
TI Semi self-training beard/moustache detection and segmentation
   simultaneously
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Beard/moustache; Detection and segmentation; Super pixel; Random Ferns;
   Support Vector Machine; Histogram of Gabor (HoG); Histogram of Oriented
   Gradient of Gabor (HOGG)
AB This paper presents a robust, fully automatic and semi self-training system to detect and segment facial beard/moustache simultaneously in challenging facial images. Based on the observation that some certain facial areas, e.g. cheeks, do not typically contain any facial hair whereas the others, e.g. brows, often contain facial hair, a self-trained model is first built using a testing image itself. To overcome the limitation of that facial hairs in brows regions and beard/moustache regions are different in length, density, color, etc., a pre-trained model is also constructed using training data. The pre-trained model is only pursued when the self-trained model produces low confident classification results. In the proposed system, we employ the superpixel together a combination of two classifiers, i.e. Random Ferns (rFerns) and Support Vector Machines (SVM) to obtain good classification performance as well as improve time efficiency. A feature vector, consisting of Histogram of Gabor (HoG) and Histogram of Oriented Gradient of Gabor (HOGG) at different directions and frequencies, is generated from both the bounding box of the superpixel and the super pixel foreground. The segmentation result is then refined by our proposed aggregately searching strategy in order to deal with inaccurate landmarking points. Experimental results have demonstrated the robustness and effectiveness of the proposed system. It is evaluated in images drawn from three entire databases i.e. the Multiple Biometric Grand Challenge (MBGC) still face database, the NIST color Facial Recognition Technology FERET database and a large subset from Pinellas County database. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Le, T. Hoang Ngan] Carnegie Mellon Univ, CyLab Biometr Ctr, Pittsburgh, PA 15213 USA.
   Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University; Carnegie Mellon University
RP Le, THN (corresponding author), Carnegie Mellon Univ, CyLab Biometr Ctr, Pittsburgh, PA 15213 USA.
RI Luu, Khoa/AAQ-8540-2021
OI Luu, Khoa/0000-0003-2104-0901; Le, T. Hoang Ngan/0000-0003-2571-0511
CR Achanta R., 2010, SLIC SUPERPIXELS EPF
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Le THN, 2015, INT CONF BIOMETR, P507, DOI 10.1109/ICB.2015.7139066
   Le THN, 2013, IEEE T IMAGE PROCESS, V22, P3097, DOI 10.1109/TIP.2013.2259835
   Le THN, 2012, IEEE IMAGE PROC, P165, DOI 10.1109/ICIP.2012.6466821
   Nguyen MH, 2008, COMPUT GRAPH FORUM, V27, P627, DOI 10.1111/j.1467-8659.2008.01160.x
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Ozuysal V. L. M., 2007, FAST KEYPOINT RECOGN, P1
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Pierrard Jean-Sebastien, 2008, THESIS
   Seshadri K, 2009, 2009 IEEE 3RD INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P319
NR 12
TC 15
Z9 16
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 214
EP 223
DI 10.1016/j.imavis.2016.07.009
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700020
DA 2024-07-18
ER

PT J
AU Milani, S
AF Milani, Simone
TI Compression of multiple user photo galleries
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image coding; Photo collections; Geotagging; Synchronization; SIFT;
   Predictive coding
AB The possibility of sharing multimedia contents in easy and ubiquitous way has brought to the creation of multiuser photo albums. Pictures and video sequences taken by different people attending common social events (e.g., concerts and sport competitions) are gathered together into huge sets of heterogeneous multimedia data. These databases require effective compression strategies that exploit the common visual information related to the scene but compensate effectively the differences depending on the acquiring viewpoints, camera models, and acquisition time instants.
   The paper presents a predictive coding strategy for multi-user photo gallery, which initially localizes each picture in terms of viewpoint, orientation, time, and acquired elements. This information permits ordering all the images in a prediction tree and associates to each of them a reference picture. From this structure, it is possible to build a predictive coding strategy that exploits the redundant elements between the image to be coded and its reference. Experimental results show an average bit rate reduction up to 75% with respect to HEVC Intra low complexity coding. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Milani, Simone] Univ Padua, Dept Informat Engn, Via Gradenigo 6-B, I-35131 Padua, Italy.
C3 University of Padua
RP Milani, S (corresponding author), Univ Padua, Dept Informat Engn, Via Gradenigo 6-B, I-35131 Padua, Italy.
EM simone.milani@dei.unipd.it
FU University of Padova, Italy [CPDA142399]
FX The work has been supported by the Robotic 3D and by the CloudVision
   projects (prot. CPDA142399), funded by the University of Padova, Italy.
CR Ait-Aoudia S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/92734
   [Anonymous], P 2 ACM INT C MULT R
   Ballan L., 2010, WEB PAGE UNSTRUCTURE
   Ballan Luca, 2010, ACM SIGGRAPH 2010 papers
   Bjontegaard G., 2001, P ITU T Q 6 SG16 VCE
   Blakowski G, 1996, IEEE J SEL AREA COMM, V14, P5, DOI 10.1109/49.481691
   Boschetti A., 2011, IM PROC ICIP 2011 18, P3665
   Broilo M, 2012, IEEE IMAGE PROC, P1945, DOI 10.1109/ICIP.2012.6467267
   Conci N., MULTIUSER EVENT MEDI
   Conci N., 2014, TASK DESCR DAT EV ME
   Graham A., 2002, P 2 ACM IEEE CS JOIN, P326
   Habrial A, EVOLUTION SOCIAL MED
   Jang C., 2009, P 2009 ACM S APPL CO, P1784
   Kim G, 2013, PROC CVPR IEEE, P620, DOI 10.1109/CVPR.2013.86
   Li L, 2007, MEDIA CONVERGENCE: MOVING TO THE NEXT GENERATION, P59
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinian E, 2006, IEEE IMAGE PROC, P2981, DOI 10.1109/ICIP.2006.312963
   Merkle P, 2010, IEEE T CONSUM ELECTR, V56, P946, DOI 10.1109/TCE.2010.5506024
   Milani S., 2015, P IEEE INT C MULT EX, P1
   Ozbek N., 2006, MULT EXP 2006 IEEE I, P213
   Schmieder A., IPCV 2009, P501
   Shen LQ, 2010, IEEE T CIRC SYST VID, V20, P925, DOI 10.1109/TCSVT.2010.2045910
   Shi ZB, 2014, IEEE J EM SEL TOP C, V4, P17, DOI 10.1109/JETCAS.2014.2298291
   Sinha P., 2009, P 17 ACM INT C MULT, P1131
   Snavely N., 2006, P SIGGRAPH 2006
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Soroushian K., 2014, US Patent App., Patent No. [13/539,337, 13539337]
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   VCEG I. M. I.-T., 2008, TECH REP
   Veenhuizen A., 2012, MED SYNCHR WORKSH
   Wiegand T., 2004, 12 M REDM WA US
   Yang JC, 2012, IEEE T MULTIMEDIA, V14, P1642, DOI 10.1109/TMM.2012.2198458
   Yang WX, 2006, IEEE T CIRC SYST VID, V16, P1385, DOI 10.1109/TCSVT.2006.884571
   Yeung C.-H., 2011, MULTIMEDIA AND EXPO, P1
   Zamarin M, 2010, J VIS COMMUN IMAGE R, V21, P462, DOI 10.1016/j.jvcir.2009.09.008
   Zamarin M, 2010, PROCEEDINGS OF THE 2010 ACM WORKSHOP ON 3D VIDEO PROCESSING (3DVP'10), P7, DOI 10.1145/1877791.1877794
   Zanuttigh P, 2006, SIGNAL PROCESS-IMAGE, V21, P787, DOI 10.1016/j.image.2006.06.003
   Zini L, 2013, IEEE J EM SEL TOP C, V3, P165, DOI 10.1109/JETCAS.2013.2256754
NR 38
TC 6
Z9 6
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2016
VL 53
BP 68
EP 75
DI 10.1016/j.imavis.2015.12.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DX4YH
UT WOS:000384386500007
DA 2024-07-18
ER

PT J
AU Daubney, B
   Xie, XH
   Deng, JJ
   Mac Parthaláin, N
   Zwiggelaar, R
AF Daubney, Ben
   Xie, Xianghua
   Deng, Jingjing
   Mac Parthalain, Neil
   Zwiggelaar, Reyer
TI Fixing the root node: Efficient tracking and detection of 3D human pose
   through local solutions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D pose estimation; Tracking; Local solutions; Root node
ID MODELS
AB 3D human pose estimation is a very difficult task. In this paper we propose that this problem can be more easily solved by first finding the solutions to a set of easier sub-problems. These are to locally estimate pose conditioned on a fixed root node state, which defines the global position and orientation of the person. The global solution can then be found using information extracted during this procedure. This approach has two key benefits: The first is that each local solution can be found by modeling the articulated object as a kinematic chain, which has far less degrees of freedom than alternative models. The second is that by using this approach we can represent, or support, a much larger area of the posterior than is currently possible. This allows far more robust algorithms to be implemented since there is far less pressure to prune the search space to free up computational resources. We apply this approach to two problems: The first is single frame monocular 3D pose estimation, where we propose a method to directly extract 3D pose without first extracting any intermediate 2D representation or being dependent on strong spatial prior models. The second is multi-view 3D tracking where we show that using the above technique results in an approach that is far more robust than current approaches, without relying on strong temporal prior models. In both domains we demonstrate the strength and versatility of the proposed method. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Daubney, Ben; Xie, Xianghua; Deng, Jingjing] Swansea Univ, Dept Comp Sci, Swansea SA2 8PP, W Glam, Wales.
   [Mac Parthalain, Neil; Zwiggelaar, Reyer] Aberystwyth Univ, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
C3 Swansea University; Aberystwyth University
RP Xie, XH (corresponding author), Swansea Univ, Dept Comp Sci, Swansea SA2 8PP, W Glam, Wales.
EM X.Xie@swansea.ac.uk
RI Zwiggelaar, Reyer/HGA-3089-2022; Deng, Jingjing/ABF-3634-2021;
   Parthalain, Neil Mac/T-7096-2019
OI Deng, Jingjing/0000-0001-9274-651X; Mac Parthalain,
   Neil/0000-0003-1935-2914
CR Andriluka M, 2012, INT J COMPUT VISION, V99, P259, DOI 10.1007/s11263-011-0498-z
   Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156
   [Anonymous], 2013, BMVC
   [Anonymous], 2010, P BRIT MACH VIS C
   [Anonymous], 2011, CVPR
   Baak A, 2009, IEEE I CONF COMP VIS, P1428, DOI 10.1109/ICCV.2009.5459291
   Chan KC, 2013, IEEE INT CONF ROBOT, P1623, DOI 10.1109/ICRA.2013.6630787
   Cherian A, 2009, IEEE INT CONF ROBOT, P519
   Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P115
   Conaire Ciaran O., 2007, CVPR '07. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Daubney B., ICPR
   Daubney B, 2012, COMPUT VIS IMAGE UND, V116, P330, DOI 10.1016/j.cviu.2011.08.007
   Daubney B, 2011, PROC CVPR IEEE, P1321, DOI 10.1109/CVPR.2011.5995502
   Daubney B, 2010, LECT NOTES COMPUT SC, V6169, P67, DOI 10.1007/978-3-642-14061-7_7
   Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c
   Deutscher J, 2001, PROC CVPR IEEE, P669
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Fossati A., 2007, Proc. IEEE Conf. Computer Vision and Pattern Recognition, P1
   Hua G, 2005, IEEE T PATTERN ANAL, V27, P1747, DOI 10.1109/TPAMI.2005.229
   Isard M, 2003, PROC CVPR IEEE, P613
   Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318
   JULIER SJ, 1995, PROCEEDINGS OF THE 1995 AMERICAN CONTROL CONFERENCE, VOLS 1-6, P1628
   Kanaujia A, 2013, IEEE COMPUT SOC CONF, P542, DOI 10.1109/CVPRW.2013.154
   Lan XY, 2005, IEEE I CONF COMP VIS, P470
   Lee MW, 2006, IEEE T PATTERN ANAL, V28, P905, DOI 10.1109/TPAMI.2006.110
   Li R, 2010, INT J COMPUT VISION, V87, P170, DOI 10.1007/s11263-009-0283-4
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MacCormick J., 2000, IEEE European Conference on Computer Vision, P3, DOI DOI 10.1007/3-540-45053-X1
   Pishchulin L, 2012, PROC CVPR IEEE, P3178, DOI 10.1109/CVPR.2012.6248052
   Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600
   Sapp B, 2011, PROC CVPR IEEE, P1281, DOI 10.1109/CVPR.2011.5995607
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Sigal L, 2004, PROC CVPR IEEE, P421
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Simo-Serra E, 2012, PROC CVPR IEEE, P2673, DOI 10.1109/CVPR.2012.6247988
   Sminchisescu C, 2001, PROC CVPR IEEE, P447
   Taylor GW, 2010, PROC CVPR IEEE, P631, DOI 10.1109/CVPR.2010.5540157
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Urtasun R., 2006, COMPUTER VISION PATT, DOI DOI 10.1109/CVPR.2006.15
   Wang CY, 2014, PROC CVPR IEEE, P2369, DOI 10.1109/CVPR.2014.303
   Xu XY, 2009, IEEE T IMAGE PROCESS, V18, P1292, DOI 10.1109/TIP.2009.2017131
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Yao A, 2012, INT J COMPUT VISION, V100, P16, DOI 10.1007/s11263-012-0532-9
   Yu TH, 2013, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2013.467
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
NR 49
TC 2
Z9 2
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 73
EP 87
DI 10.1016/j.imavis.2016.05.010
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400006
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Fernandez-Beltran, R
   Pla, F
AF Fernandez-Beltran, Ruben
   Pla, Filiberto
TI Incremental probabilistic Latent Semantic Analysis for video retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Content-based Video Retrieval; Latent topics; probabilistic Latent
   Semantic Analysis (pLSA); Relevance Feedback; Information retrieval
ID OF-THE-ART; IMAGE RETRIEVAL; RECOGNITION
AB Recent research trends in Content-based Video Retrieval have shown topic models as an effective tool to deal with the semantic gap challenge. In this scenario, this paper has a dual target: (1) it is aimed at studying how the use of different topic models (pLSA, LDA and FSTM) affects video retrieval performance; (2) a novel incremental topic model (IpLSA) is presented in order to cope with incremental scenarios in an effective and efficient way. A comprehensive comparison among these four topic models using two different retrieval systems and two reference benchmarking video databases is provided. Experiments revealed that pLSA is the best model in sparse conditions, LDA tend to outperform the rest of the models in a dense space and IpLSA is able to work properly in both cases. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Fernandez-Beltran, Ruben; Pla, Filiberto] Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana, Spain.
C3 Universitat Jaume I
RP Pla, F (corresponding author), Univ Jaume 1, Inst New Imaging Technol, Castellon de La Plana, Spain.
EM rufernan@uji.es; pla@uji.es
RI Fdz, Ruben/ABH-6669-2020; Fernandez-Beltran, Ruben/GLT-5907-2022; Pla,
   Filiberto/AAD-1208-2022
OI Fernandez-Beltran, Ruben/0000-0003-1374-8416; Pla,
   Filiberto/0000-0003-0054-3489
FU Spanish Ministry of Education [FPU-AP-2009-4435]; Generalitat Valenciana
   [PROMETEOII/2014/062]
FX This work was partially supported by FPU-AP-2009-4435 from the Spanish
   Ministry of Education and the PROMETEOII/2014/062 project from
   Generalitat Valenciana.
CR [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   [Anonymous], P TRECVID 2007 WORKS
   [Anonymous], 2004, ADV NEURAL INFORM PR
   Antani S, 2002, PATTERN RECOGN, V35, P945, DOI 10.1016/S0031-3203(01)00086-3
   Arevalillo-Herraez M., 2013, IMAGE VISION COMPUTI
   Arun R., 2010, P 14 PAC AS C ADV 1
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Blei DavidM., 2006, P ICML
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chang J., 2009, Advances in neural information processing systems, P22, DOI DOI 10.5555/2984093.2984126
   Chechik G, 2010, J MACH LEARN RES, V11, P1109
   Chiu CY, 2014, IEEE T MULTIMEDIA, V16, P1952, DOI 10.1109/TMM.2014.2342668
   Chou TC, 2008, IEEE T KNOWL DATA EN, V20, P289, DOI 10.1109/TKDE.2007.190702
   Cord M, 2007, IMAGE VISION COMPUT, V25, P14, DOI 10.1016/j.imavis.2006.01.004
   Cotton CV, 2010, INT CONF ACOUST SPEE, P2386, DOI 10.1109/ICASSP.2010.5496185
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Fernandez-Beltran Ruben, 2013, Pattern Recognition and Image Analysis. 6th Iberian Conference, IbPRIA 2013. Proceedings. LNCS 7887, P648
   Fernández-Beltran R, 2013, LECT NOTES COMPUT SC, V8156, P290
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Jiang Y. G., 2011, CONSUMER VIDEO UNDER
   Kakkonen T, 2008, EDUC TECHNOL SOC, V11, P275
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Liu GH, 2011, PATTERN RECOGN, V44, P2123, DOI 10.1016/j.patcog.2011.02.003
   Liu Y, 2007, PATTERN RECOGN, V40, P262, DOI 10.1016/j.patcog.2006.04.045
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu Y, 2011, INFORM RETRIEVAL, V14, P178, DOI 10.1007/s10791-010-9141-9
   Ren W, 2009, PATTERN RECOGN, V42, P267, DOI 10.1016/j.patcog.2008.08.033
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Teh Y.W., 2004, J. Am. Stat. Ass, V101
   Than K., 2012, LECT NOTES COMPUTER
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Urbano J, 2013, SIGIR'13: THE PROCEEDINGS OF THE 36TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH & DEVELOPMENT IN INFORMATION RETRIEVAL, P925
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wu H, 2008, RECSYS'08: PROCEEDINGS OF THE 2008 ACM CONFERENCE ON RECOMMENDER SYSTEMS, P99
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Yi X., 2009, 31 EUR C IR RES ADV
   Zhang RF, 2007, IEEE T IMAGE PROCESS, V16, P562, DOI 10.1109/TIP.2006.888350
NR 42
TC 21
Z9 21
U1 0
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2015
VL 38
BP 1
EP 12
DI 10.1016/j.imavis.2015.02.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CK4LX
UT WOS:000356196400001
OA Green Published
DA 2024-07-18
ER

PT J
AU Moeini, A
   Moeini, H
   Faez, K
AF Moeini, Ali
   Moeini, Hossein
   Faez, Karim
TI Unrestricted pose-invariant face recognition by sparse dictionary matrix
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Real-world; Facial expression generic elastic models; Face synthesis;
   Pose-invariant face recognition; Sparse representation; Sparse
   dictionary matrix
ID FACIAL EXPRESSION ANALYSIS; FRAMEWORK
AB In this paper, a novel method is proposed for real-world pose-invariant face recognition from only a single image in a gallery. A 3D Facial Expression Generic Elastic Model (3D FE-GEM) is proposed to reconstruct a 3D model of each human face using only a single 2D frontal image. Then, for each person in the database, a Sparse Dictionary Matrix (SDM) is created from all face poses by rotating the 3D reconstructed models and extracting features in the rotated face. Each SDM is subsequently rendered based on triplet angles of face poses. Before matching to SDM, an initial estimate of triplet angles of face poses is obtained in the probe face image using an automatic head pose estimation approach. Then, an array of the SDM is selected based on the estimated triplet angles for each subject Finally, the selected arrays from SDMs are compared with the probe image by sparse representation classification. Convincing results were acquired to handle pose changes on the FERET, CMU PIE, LFW and video face databases based on the proposed method compared to several state-of-the-art in pose-invariant face recognition. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Moeini, Ali; Faez, Karim] Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Moeini, Hossein] Semnan Univ, Dept Elect Engn, Semnan, Iran.
C3 Amirkabir University of Technology; Semnan University
RP Moeini, A (corresponding author), Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
EM ali.moeini1989@gmail.com
RI faez, karim/K-5117-2019
OI faez, karim/0000-0002-1159-4866
CR Aggarwal G., 2012, SPARSE REPRESENTATIO
   [Anonymous], BRIT MACH VIS C
   [Anonymous], P AS C COMP VIS
   Arashloo SR, 2011, COMPUT VIS IMAGE UND, V115, P1073, DOI 10.1016/j.cviu.2010.12.006
   Asthana A, 2011, IEEE I CONF COMP VIS, P937, DOI 10.1109/ICCV.2011.6126336
   Baltrusaitis T., 2013, P COMP VIS PATT REC
   Blanz V, 2005, PROC CVPR IEEE, P454
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Breidt M., 2011, ROBUST SEMANTIC ANAL, P713
   Chen SSB, 2001, SIAM REV, V43, P129, DOI [10.1137/S003614450037906X, 10.1137/S1064827596304010]
   Cox D., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P8, DOI 10.1109/FG.2011.5771385
   Donoho DL, 2006, COMMUN PUR APPL MATH, V59, P797, DOI 10.1002/cpa.20132
   Fanelli G., 2011, Real time head pose estimation with random regression forests
   Fang T., 2011, 3D FACIAL EXPRESSION, P603
   Fang TH, 2012, IMAGE VISION COMPUT, V30, P738, DOI 10.1016/j.imavis.2012.02.004
   González-Jiménez D, 2007, IEEE T INF FOREN SEC, V2, P413, DOI 10.1109/TIFS.2007.903543
   Heo J, 2012, IEEE T PATTERN ANAL, V34, P2341, DOI 10.1109/TPAMI.2011.275
   Heo J, 2012, IEEE T INF FOREN SEC, V7, P563, DOI 10.1109/TIFS.2012.2184755
   Huang G.B., 2008, PROC WORKSHOP FACES
   Ho HT, 2013, IEEE T IMAGE PROCESS, V22, P1571, DOI 10.1109/TIP.2012.2233489
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Lee MW, 2003, PATTERN RECOGN, V36, P1835, DOI 10.1016/S0031-3203(03)00008-6
   Loop C, 1987, THESIS U UTAH
   Moeini A., 2013, INT C ICDSC
   Moeini A, 2014, J ELECTRON IMAGING, V23, DOI 10.1117/1.JEI.23.5.053013
   Niinuma K., 2013, IEEE C BTAS
   Park SW, 2007, IEEE T SYST MAN CY B, V37, P1156, DOI 10.1109/TSMCB.2007.904575
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Prabhu U, 2011, IEEE T PATTERN ANAL, V33, P1952, DOI 10.1109/TPAMI.2011.123
   Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Sharma A, 2012, COMPUT VIS IMAGE UND, V116, P1095, DOI 10.1016/j.cviu.2012.08.001
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   ul Hussain S, 2012, LECT NOTES COMPUT SC, V7573, P716, DOI 10.1007/978-3-642-33709-3_51
   Weise T., 2011, SIGGRAPH, V30
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Yi D., 2013, IEEE C CVPR
   Zhang HC, 2013, PATTERN RECOGN, V46, P1511, DOI 10.1016/j.patcog.2012.10.025
   Zhang HC, 2012, PATTERN RECOGN, V45, P1290, DOI 10.1016/j.patcog.2011.09.009
   Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53
   Zhao X, 2013, IMAGE VISION COMPUT, V31, P231, DOI 10.1016/j.imavis.2012.10.001
NR 43
TC 23
Z9 24
U1 2
U2 25
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2015
VL 36
BP 9
EP 22
DI 10.1016/j.imavis.2015.01.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CG2GV
UT WOS:000353093800002
DA 2024-07-18
ER

PT J
AU Skodras, E
   Fakotakis, N
AF Skodras, Evangelos
   Fakotakis, Nikos
TI Precise localization of eye centers in low resolution color images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Eye localization; Eye detection; Facial feature detection; Radial
   symmetry
ID FEATURE-EXTRACTION; RADIAL SYMMETRY; FACE DETECTION; TRACKING; ROBUST;
   INTENSITY; LOCATION
AB The localization of eye centers and tracking of gaze constitutes an integral component of many human-computer interaction applications. A number of constraints including intrusiveness, mobility, robustness and high-price of eye tracking systems have hindered the way of the integration of eye trackers in everyday applications. Several 'passive' systems based on a single camera have been lately proposed in the literature, exhibiting though subordinate precision compared to the commercial, hardware-based eye tracking devices. In this paper we introduce an automatic, non-intrusive method for precise eye center localization in low resolution images, acquired from single low-cost cameras. To this end, the proposed system uses color information to derive a novel eye map that emphasizes the iris area and a radial symmetry transform which operates both on the original eye images and the eye map. The performance of the proposed method is extensively evaluated on four publicly available databases containing low resolution images and videos. Experimental results demonstrate great accuracy in challenging cases and resilience to pose and illumination variations, achieving significant improvement over existing methods. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Skodras, Evangelos; Fakotakis, Nikos] Univ Patras, Dept Elect & Comp Engn, GR-26504 Patras, Greece.
C3 University of Patras
RP Skodras, E (corresponding author), Univ Patras, Dept Elect & Comp Engn, Wire Commun Lab, GR-26504 Patras, Greece.
EM evskodras@upatras.gr; fakotaki@upatras.gr
CR [Anonymous], THESIS
   [Anonymous], 2003, PROC GRAPHICON
   Asteriadis S, 2006, INT S CONTR COMM SIG
   Bai L, 2006, INT C PATT RECOG, P511
   Campadelli P., 2006, BRIT MACHINE VISION, P187
   Castrillón M, 2007, J VIS COMMUN IMAGE R, V18, P130, DOI 10.1016/j.jvcir.2006.11.004
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Dobes M, 2006, OPTIK, V117, P468, DOI 10.1016/j.ijleo.2005.11.008
   Dongheng L., 2005, 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P79
   Duchowski A.T., 2007, THEORY PRACTICE, V373
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   Everingham M, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P441
   Grauman K, 2001, PROC CVPR IEEE, P1010
   Hansen DW, 2007, IMAGE PROCESS SER, P309
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hansen DW, 2005, COMPUT VIS IMAGE UND, V98, P155, DOI 10.1016/j.cviu.2004.07.013
   Hansen DW, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P132, DOI 10.1109/ACV.2002.1182170
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Kawaguchi T, 2003, PATTERN RECOGN, V36, P549, DOI 10.1016/S0031-3203(02)00066-3
   Kim BS, 2010, IEEE T CONSUM ELECTR, V56, P2498, DOI 10.1109/TCE.2010.5681133
   Kim S, 2007, PROC WRLD ACAD SCI E, V19, P483
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Loy G, 2003, IEEE T PATTERN ANAL, V25, P959, DOI 10.1109/TPAMI.2003.1217601
   Ma L, 2004, PATTERN RECOGN, V37, P1287, DOI 10.1016/j.patcog.2004.02.001
   Milborrow S., The MUCT Landmarked Face Database
   Morimoto CH, 2000, IMAGE VISION COMPUT, V18, P331, DOI 10.1016/S0262-8856(99)00053-0
   Orman Z., 2011, INT J COMPUT SCI ENG, V2, P29, DOI [10.5121/ijcses.2011.2303, DOI 10.5121/IJCSES.2011.2303]
   Peixoto Helton M., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P2475, DOI 10.1109/IJCNN.2009.5178924
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Saber E, 1998, PATTERN RECOGN LETT, V19, P669, DOI 10.1016/S0167-8655(98)00044-0
   SAMARIA F, 1994, IMAGE VISION COMPUT, V12, P537, DOI 10.1016/0262-8856(94)90007-8
   Shamsi M, 2009, 2009 INTERNATIONAL CONFERENCE OF SOFT COMPUTING AND PATTERN RECOGNITION, P393, DOI 10.1109/SoCPaR.2009.83
   Sirohey SA, 2001, PATTERN RECOGN, V34, P1367, DOI 10.1016/S0031-3203(00)00082-0
   Skodras E, 2012, PROC INT C TOOLS ART, P994, DOI 10.1109/ICTAI.2012.141
   Song FY, 2013, PATTERN RECOGN, V46, P3157, DOI 10.1016/j.patcog.2013.05.009
   Tarres F., GTAV face database
   Timm F., 2011, ACCURATE EYE CTR LOC, P125
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Valenti R, 2009, PROC CVPR IEEE, P612, DOI 10.1109/CVPRW.2009.5206640
   Valenti Roberto., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Van Huan N, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P620, DOI 10.1109/CISP.2008.176
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang P., 2005, 2005 IEEE COMP SOC C, P164
   XIE X, 1994, PATTERN RECOGN, V27, P791, DOI 10.1016/0031-3203(94)90164-3
   Yang P, 2004, IEEE IMAGE PROC, P67
   Yang XF, 2013, APPL MECH MATER, V401, P1324, DOI 10.4028/www.scientific.net/AMM.401-403.1324
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhang YF, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON AUTOMATION AND LOGISTICS, VOLS 1-6, P301, DOI [10.1109/EMS.2008.76, 10.1109/ICAL.2008.4636164]
   Zhiwei Zhu, 2002, Proceedings ETRA 2002. Eye Tracking Research and Applications Symposium, P139
   Zhou ZH, 2004, PATTERN RECOGN, V37, P1049, DOI 10.1016/j.patcog.2003.09.006
   Zhu DJ, 1999, COMPUT METH PROG BIO, V59, P145, DOI 10.1016/S0169-2607(98)00105-9
   Zhu J, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P131, DOI 10.1109/AFGR.2002.1004144
   Zhu ZW, 2004, MACH VISION APPL, V15, P139, DOI 10.1007/s00138-004-0139-4
NR 56
TC 34
Z9 35
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2015
VL 36
BP 51
EP 60
DI 10.1016/j.imavis.2015.01.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CG2GV
UT WOS:000353093800005
DA 2024-07-18
ER

PT J
AU Baber, J
   Dailey, MN
   Satoh, S
   Afzulpurkar, N
   Bakhtyar, M
AF Baber, Junaid
   Dailey, Matthew N.
   Satoh, Shin'ichi
   Afzulpurkar, Nitin
   Bakhtyar, Maheen
TI BIG-OH: BInarization of gradient orientation histograms
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gradient orientation histograms; SIFT; Gradient based keypoint
   descriptors; Keypoint descriptor quantization
ID SCALE
AB Extracting local keypoints and keypoint descriptions from images is a primary step for many computer vision and image retrieval applications. In the literature, many researchers have proposed methods for representing local texture around keypoints with varying levels of robustness to photometric and geometric transformations. Gradient-based descriptors such as the Scale Invariant Feature Transform (SIFT) are among the most consistent and robust descriptors. The SIFT descriptor, a 128-element vector consisting of multiple gradient histograms computed from local image patches around a keypoint, is widely considered as the gold standard keypoint descriptor. However, SIFT descriptors require at least 128 bytes of storage per descriptor. Since images are typically described by thousands of keypoints, it may require more space to store the SIFT descriptors for an image than the original image itself. This may be prohibitive in extremely large-scale applications and applications on memory-constrained devices such as tablets and smartphones. In this paper, with the goal of reducing the memory requirements of keypoint descriptors such as SIFT, without affecting their performance, we propose BIG-OH, a simple yet extremely effective method for binary quantization of any descriptor based on gradient orientation histograms. BIG-OH's memory requirements are very small when it uses SIFT's default parameters for the construction of the gradient orientation histograms, it only requires 16 bytes per descriptor. BIG-OH quantizes gradient orientation histograms by computing a bit vector representing the relative magnitudes of local gradients associated with neighboring orientation bins. In a series of experiments on keypoint matching with different types of keypoint detectors under various photometric and geometric transformations, we find that the quantized descriptor has performance comparable to or better than other descriptors, including BRISK, CARD, BRIEF, D-BRIEF, SQ, and PCA-SIFT. Our experiments also show that BIG-OH is extremely effective for image retrieval, with modestly better performance than SIFT. BIG-OH's drastic reduction in memory requirements, obtained while preserving or improving the image matching and image retrieval performance of SIFT, makes it an excellent descriptor for large image databases and applications running on memory-constrained devices. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Baber, Junaid; Bakhtyar, Maheen] Univ Balochistan, Dept Comp Sci & Informat Technol, Quetta, Pakistan.
   [Baber, Junaid; Dailey, Matthew N.; Afzulpurkar, Nitin] Asian Inst Technol, Sch Engn & Technol, Pathum Thani 12120, Thailand.
   [Satoh, Shin'ichi] Natl Inst Informat, Tokyo, Japan.
C3 University of Balochistan; Asian Institute of Technology; Research
   Organization of Information & Systems (ROIS); National Institute of
   Informatics (NII) - Japan
RP Baber, J (corresponding author), Univ Balochistan, Dept Comp Sci & Informat Technol, Quetta, Pakistan.
EM junaidbaber@ieee.org; mdailey@ait.asia; satoh@nii.ac.jp;
   nafzulpurkar@aud.edu
OI baber, junaid/0000-0002-7517-6858
FU University of Balochistan; National Institute of Informatics; Asian
   Institute of Technology; Grants-in-Aid for Scientific Research
   [26240016] Funding Source: KAKEN
FX This research was supported by fellowships to Junaid Baber from the
   University of Balochistan, the National Institute of Informatics, and
   the Asian Institute of Technology. We are thankful to Wengang Zhou for
   providing the IR-II dataset.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ambai M., 2011, INT C COMP VIS ICCV
   [Anonymous], 2012, P 20 ACM MULTIMEDIA
   Baber J., 2011, 2011 7th International Conference on Emerging Technologies, ICET 2011, P1
   Baber J., 2011, INT C DIG SIGN PROC
   Baber J, 2013, INT J PATTERN RECOGN, V27, DOI 10.1142/S0218001413550070
   Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Douze M, 2010, IEEE T MULTIMEDIA, V12, P257, DOI 10.1109/TMM.2010.2046265
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Heinly J, 2012, LECT NOTES COMPUT SC, V7573, P759, DOI 10.1007/978-3-642-33709-3_54
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Ke Y, 2004, PROC CVPR IEEE, P506
   Leutenegger S., 2011, INT C COMP VIS ICCV
   Lindeberg T, 1997, IMAGE VISION COMPUT, V15, P415, DOI 10.1016/S0262-8856(97)01144-X
   Ling HF, 2012, IEEE MULTIMEDIA, V19, P60, DOI 10.1109/MMUL.2011.75
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Liu XL, 2014, PATTERN RECOGN, V47, P748, DOI 10.1016/j.patcog.2013.08.022
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pietikäinen M, 2004, PATTERN RECOGN, V37, P313, DOI 10.1016/S0031-3203(03)00231-0
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   SNAVELY N, 2008, COMPUTER VISION PATT
   Strecha C, 2012, IEEE T PATTERN ANAL, V34, P66, DOI 10.1109/TPAMI.2011.103
   Ta Duy-Nguyen., 2009, Computer Vision and Pattern Recognition
   Tola E, 2010, IEEE T PATTERN ANAL, V32, P815, DOI 10.1109/TPAMI.2009.77
   Trzcinski T., 2012, EUR C COMP VIS ECCV
   Wang J, 2012, IEEE T PATTERN ANAL, V34, P2393, DOI 10.1109/TPAMI.2012.48
   Wang XY, 2009, IEEE I CONF COMP VIS, P32, DOI 10.1109/iccv.2009.5459207
   Weiss Yair., 2008, Spectral Hashing
   Yamazaki M, 2009, IEICE T INF SYST, VE92D, P1745, DOI 10.1587/transinf.E92.D.1745
   Zhou W., 2013, MULTIMEDIA SYST, P1
   Zhou W., 2010, INT C MULT
NR 46
TC 16
Z9 16
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 940
EP 953
DI 10.1016/j.imavis.2014.08.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900011
DA 2024-07-18
ER

PT J
AU Kose, N
   Dugelay, JL
AF Kose, Neslihan
   Dugelay, Jean-Luc
TI Mask spoofing in face recognition and countermeasures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Spoofing; Mask attacks; Countermeasure; Face recognition
AB In this paper, initially, the impact of mask spoofing on face recognition is analyzed. For this purpose, one baseline technique is selected for both 2D and 3D face recognition. Next, novel countermeasures, which are based on the analysis of different shape, texture and reflectance characteristics of real faces and mask faces, are proposed to detect mask spoofing. In this paper, countermeasures are developed using both 2D data (texture images) and 3D data (3D scans) available in the mask database. The results show that each of the proposed countermeasures is successful in detecting mask spoofing, and the fusion of these countermeasures further improves the results compared to using a single countermeasure. Since there is no publicly available mask database, studies on mask spoofing are limited. This paper provides significant results by proposing novel countermeasures to protect face recognition systems against mask spoofing. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Kose, Neslihan; Dugelay, Jean-Luc] EURECOM, Multimedia Dept, Sophia Antipolis, France.
C3 IMT - Institut Mines-Telecom; EURECOM
RP Kose, N (corresponding author), EURECOM, Multimedia Dept, Sophia Antipolis, France.
EM neslihan.kose@eurecom.fr; jean-luc.dugelay@eurecom.fr
RI DUGELAY, Jean-Luc/ABE-7096-2021
OI DUGELAY, jean-luc/0000-0003-3151-4330
FU TABULA RASA project 7th Framework Research Programme of the European
   Union (EU) [257289]; EU
FX This work has been performed by the TABULA RASA project 7th Framework
   Research Programme of the European Union (EU), grant agreement number:
   257289. The authors would like to thank the EU for the financial support
   and the partners within the consortium for a fruitful collaboration. For
   more information about the TABULA RASA consortium please visit
   http://www.tabularasa-euproject.org.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2011, 2011 INT JOINT C BIO
   [Anonymous], 2013, INT CONF DIGIT SIG
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], TECHNICAL REPORT
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Bai JM, 2010, IEEE INT SYMP CIRC S, P3425, DOI 10.1109/ISCAS.2010.5537866
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Chetty G., 2006, BIOMETRICS S SPECIAL, P1
   De Marsico M., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P73, DOI 10.1109/ICB.2012.6199761
   Erdogmus N, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P225, DOI 10.1109/ICIEV.2012.6317338
   Kim YS, 2009, J OPT SOC AM A, V26, P760, DOI 10.1364/JOSAA.26.000760
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   Kollreider K, 2008, IEEE COMPUTER SOC C, P1
   Kose N., 2013, 2013 10 IEEE INT C W, P1, DOI [10.1109/FG.2013.6553761, DOI 10.1109/FG.2013.6553761]
   Kose N, 2013, INT CONF ACOUST SPEE, P2357, DOI 10.1109/ICASSP.2013.6638076
   Kose N, 2013, IEEE COMPUT SOC CONF, P111, DOI 10.1109/CVPRW.2013.24
   Kose N, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P1027, DOI 10.1109/ICIEV.2012.6317336
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Määttä J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
NR 25
TC 15
Z9 17
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 779
EP 789
DI 10.1016/j.imavis.2014.06.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, Z
   Yap, KH
AF Li, Zhen
   Yap, Kim-Hui
TI An efficient approach for scene categorization based on discriminative
   codebook learning in bag-of-words framework
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Scene categorization; Codebook learning; Bag-of-words
ID UNIVERSAL
AB This paper proposes an efficient technique for learning a discriminative codebook for scene categorization. A state-of-the-art approach for scene categorization is the Bag-of-Words (BoW) framework, where codebook generation plays an important role in determining the performance of the system. Traditionally, the codebook generation methods adopted in the BoW techniques are designed to minimize the quantization error, rather than optimize the classification accuracy. In view of this, this paper tries to address the issue by careful design of the codewords such that the resulting image histograms for each category will retain strong discriminating power, while the online categorization of the testing image is as efficient as in the baseline BoW. The codewords are refined iteratively to improve their discriminative power offline. The proposed method is validated on UIUC Scene-15 dataset and NTU Scene-25 dataset and it is shown to outperform other state-of-the-art codebook generation methods in scene categorization. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Li, Zhen; Yap, Kim-Hui] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Li, Z (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM lizh0019@ntu.edu.sg; EKHYap@ntu.edu.sg
OI Yap, Kim-Hui/0000-0003-1933-4986
FU Agency for Science, Technology and Research (A*STAR), Singapore under
   SERC [062 130 0055]
FX We would like to thank Dr. Jan C. van Gemert for kindly providing the
   source code of his algorithm. This work is supported by Agency for
   Science, Technology and Research (A*STAR), Singapore under SERC grant
   062 130 0055.
CR Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Jurie F, 2005, IEEE I CONF COMP VIS, P604
   Kohonen T., 1986, Learning vector quantization for pattern recognition
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755
   Scott D., 1992, MULTIVARIATE DENSITY, V139
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang ZM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P815
NR 12
TC 7
Z9 10
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 748
EP 755
DI 10.1016/j.imavis.2013.07.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900006
DA 2024-07-18
ER

PT J
AU Cuevas, C
   García, N
AF Cuevas, Carlos
   Garcia, Narciso
TI Improved background modeling for real-time spatio-temporal
   non-parametric moving object detection strategies
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dynamic bandwidth estimation; Moving object detection; Non-parametric
   background modeling; Selective update; Spatio-temporal data
ID KERNEL DENSITY-ESTIMATION; SUBTRACTION; SCENES
AB Answering to the growing demand of machine vision applications for the latest generation of electronic devices endowed with camera platforms, several moving object detection strategies have been proposed in recent years. Among them, spatio-temporal based non-parametric methods have recently drawn the attention of many researchers. These methods, by combining a background model and a foreground model, achieve high-quality detections in sequences recorded with non-completely static cameras and in scenarios containing complex backgrounds. However, since they have very high memory and computational associated costs, they apply some simplifications in the background modeling process, therefore decreasing the quality of the modeling. Here, we propose a novel background modeling that is applicable to any spatio-temporal non-parametric moving object detection strategy. Through an efficient and robust method to dynamically estimate the bandwidth of the kernels used in the modeling, both the usability and the quality of previous approaches are improved. Furthermore, by adding a novel mechanism to selectively update the background model, the number of misdetections is significantly reduced, achieving an additional quality improvement. Empirical studies on a wide variety of video sequences demonstrate that the proposed background modeling significantly improves the quality of previous strategies while maintaining the computational requirements of the detection process. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Cuevas, Carlos; Garcia, Narciso] Univ Politecn Madrid, Grp Tratamiento Imagenes, E-28040 Madrid, Spain.
C3 Universidad Politecnica de Madrid
RP Cuevas, C (corresponding author), Univ Politecn Madrid, Grp Tratamiento Imagenes, E-28040 Madrid, Spain.
EM ccr@gti.ssr.upm.es; narciso@gti.ssr.upm.es
RI García, Narciso/E-8603-2011; Cuevas, Carlos/Z-3173-2019
OI García, Narciso/0000-0002-0397-894X; Cuevas, Carlos/0000-0001-9873-8502
FU Ministerio de Economia y Competitividad of the Spanish Government
   [TEC2010-20412]
FX This work was supported in part by the Ministerio de Economia y
   Competitividad of the Spanish Government under project TEC2010-20412
   (Enhanced 3DTV).
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   [Anonymous], P ACM INT WORKSH VID
   [Anonymous], 2011, J SIGNAL INFOR PROCE, DOI DOI 10.4236/JSIP.2011.22010)
   [Anonymous], PETS PERF EV TRACK S
   Benezeth Y, 2008, INT C PATT RECOG, P237, DOI 10.1109/icpr.2008.4760998
   Bicego M, 2006, COMPUT VIS IMAGE UND, V102, P22, DOI 10.1016/j.cviu.2005.09.001
   Bors AG, 2009, IEEE T SYST MAN CY B, V39, P1543, DOI 10.1109/TSMCB.2009.2020688
   Chiranjeevi P, 2012, IMAGE VISION COMPUT, V30, P829, DOI 10.1016/j.imavis.2012.06.015
   Cristani M, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/343057
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Cuevas C, 2013, IEEE T CIRC SYST VID, V23, P1, DOI 10.1109/TCSVT.2012.2202191
   Cuevas C, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.4.040501
   Cuevas C, 2012, IEEE T CONSUM ELECTR, V58, P117, DOI 10.1109/TCE.2012.6170063
   Ding JW, 2011, LECT NOTES COMPUT SC, V6493, P82
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Elhabian Shireen Y, 2008, Recent Patents Comput. Sci, V1, P32, DOI DOI 10.2174/1874479610801010032
   Evangelio R. H., 2011, 2011 Workshop on Person-Oriented Vision (POV), P27, DOI 10.1109/POV.2011.5712365
   Gao Z, 2006, I C DEPEND SYS NETWO, P259
   Han TD, 2011, IEEE T PARALL DISTR, V22, P78, DOI 10.1109/TPDS.2010.62
   Hao JY, 2011, FRONT COMPUT SCI CHI, V5, P290, DOI 10.1007/s11704-011-0377-3
   Hu SW, 2012, COMPUT STAT DATA AN, V56, P732, DOI 10.1016/j.csda.2011.09.022
   Karmann K., 1990, MOVING OBJECT RECOGN, V2, P297
   Kehuang Li, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P381, DOI 10.1109/CISP.2011.6099940
   Ko T, 2008, LECT NOTES COMPUT SC, V5304, P276, DOI 10.1007/978-3-540-88690-7_21
   Lin HH, 2011, IEEE T IMAGE PROCESS, V20, P822, DOI 10.1109/TIP.2010.2075938
   Lu XY, 2011, IMAGE VISION COMPUT, V29, P104, DOI 10.1016/j.imavis.2010.08.001
   Martel-Brison N., 2008, ACM WORKSH VIS NETW, P93
   Martinez-Hinarejos C. D., 2002, Structural, Syntactic, and Statistical Pattern Recognition. Joint IAPR International Workshops SSPR 2002 and SPR 2002 (Lecture Notes in Computer Science Vol. 2396), P47
   McHugh JM, 2009, IEEE SIGNAL PROC LET, V16, P390, DOI 10.1109/LSP.2009.2016447
   Mittal A, 2004, PROC CVPR IEEE, P302
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Pless R, 2003, PROC CVPR IEEE, P73
   Porikli F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/197875
   Sangani Kris, 2010, Engineering & Technology, V5, P28, DOI 10.1049/et.2010.1103
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Sheikh Y, 2009, IEEE I CONF COMP VIS, P1219, DOI 10.1109/ICCV.2009.5459334
   Shoushtarian B, 2005, PATTERN RECOGN LETT, V26, P5, DOI 10.1016/j.patrec.2004.07.013
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tanaka T, 2010, LECT NOTES COMPUT SC, V5994, P201
   Tavakkoli A, 2009, MACH VISION APPL, V20, P395, DOI 10.1007/s00138-008-0134-2
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Vemulapalli R., 2011, IEEE 12 INT COF COMP, P1145
   Wagner D, 2010, IEEE T VIS COMPUT GR, V16, P355, DOI 10.1109/TVCG.2009.99
   Zhang X, 2008, ELECTRON LETT, V44, P851, DOI 10.1049/el:20081420
   Zhang X, 2009, OPT ENG, V48, DOI 10.1117/1.3250188
NR 46
TC 32
Z9 34
U1 0
U2 16
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2013
VL 31
IS 9
BP 616
EP 630
DI 10.1016/j.imavis.2013.06.003
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220EG
UT WOS:000324564300003
DA 2024-07-18
ER

PT J
AU Li, YT
   Wachs, JP
AF Li, Yu-Ting
   Wachs, Juan P.
TI Recognizing hand gestures using the weighted elastic graph matching
   (WEGM) method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Elastic bunch graph; Graph matching; Feature weight; Hand gesture
   recognition
AB This paper proposes a weighted scheme for elastic graph matching hand posture recognition. Visual features scattered on the elastic graph are assigned corresponding weights according to their relative ability to discriminate between gestures. The weights' values are determined using adaptive boosting. A dictionary representing the variability of each gesture class is expressed in the form of a bunch graph. The positions of the nodes in the bunch graph are determined using three techniques: manually, semi-automatically, and automatically. Experimental results also show that the semi-automatic annotation method is efficient and accurate in terms of three performance measures; assignment cost, accuracy, and transformation error. In terms of the recognition accuracy, our results show that the hierarchical weighting on features has more significant discriminative power than the classic method (uniform weighting). The hierarchical elastic graph matching (WEGM) approach was used to classify a lexicon of ten hand postures, and it was found that the poses were recognized with a recognition accuracy of 97.08% on average. Using the weighted scheme, computing cycles can be decreased by only computing the features for those nodes whose weight is relatively high and ignoring the remaining nodes. It was found that only 30% of the nodes need to be computed to obtain a recognition accuracy of over 90%. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Li, Yu-Ting; Wachs, Juan P.] Purdue Univ, W Lafayette, IN 47906 USA.
C3 Purdue University System; Purdue University
RP Wachs, JP (corresponding author), Purdue Univ, Sch Ind Engn, W Lafayette, IN 47907 USA.
EM jpwachs@purdue.edu
RI Li, Yuting/IVH-4108-2023
OI Wachs, Juan/0000-0002-6425-5745
CR [Anonymous], 2011, PROC IEEE INT C HAND
   [Anonymous], 2011, INT C MECHATRONICS I
   Chang YJ, 2011, RES DEV DISABIL, V32, P2064, DOI 10.1016/j.ridd.2011.08.010
   de La Gorce M, 2011, IEEE T PATTERN ANAL, V33, P1793, DOI 10.1109/TPAMI.2011.33
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Friedman Jerome H., 1996, Technical Report
   Harris C., 1988, Proc. of the 4th Alvey Vision Conference, P189
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Kotropoulos C, 2000, IEEE T IMAGE PROCESS, V9, P555, DOI 10.1109/83.841933
   Kumar PP, 2010, I C CONT AUTOMAT ROB, P1151, DOI 10.1109/ICARCV.2010.5707352
   Leyvand T, 2011, COMPUTER, V44, P94, DOI 10.1109/MC.2011.114
   Li Y.-T., 2012, 17 IB C PATT REC CIA
   Poppe R, 2007, LECT NOTES COMPUT SC, V4451, P234
   Rautaray S. S., 2011, 2011 International Conference on Multimedia, Signal Processing and Communication Technologies (IMPACT 2011), P244, DOI 10.1109/MSPCT.2011.6150485
   Roomi S. Mohamed Mansoor, 2010, Journal of Computer Sciences, V6, P1002, DOI 10.3844/jcssp.2010.1002.1007
   Shin H, 2007, PATTERN RECOGN LETT, V28, P1077, DOI 10.1016/j.patrec.2007.01.003
   Sonka M., 2008, IMAGE PROCESSING ANA
   Tefas A, 2002, SIGNAL PROCESS, V82, P833, DOI 10.1016/S0165-1684(02)00157-3
   Torralba A, 2004, PROC CVPR IEEE, P762
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   Tottenham N, 2009, PSYCHIAT RES, V168, P242, DOI 10.1016/j.psychres.2008.05.006
   Triesch J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P170, DOI 10.1109/AFGR.1996.557260
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   Wachs JP, 2008, J AM MED INFORM ASSN, V15, P321, DOI 10.1197/jamia.M241
   Wachs JP, 2011, COMMUN ACM, V54, P60, DOI 10.1145/1897816.1897838
   Wiskott L, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P129, DOI 10.1109/ICIP.1997.647401
   Wood KAC, 2009, IEEE ENG MED BIO, P5973, DOI 10.1109/IEMBS.2009.5333523
   Zhang J, 1997, P IEEE, V85, P1423, DOI 10.1109/5.628712
NR 28
TC 12
Z9 13
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2013
VL 31
IS 9
BP 649
EP 657
DI 10.1016/j.imavis.2013.06.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220EG
UT WOS:000324564300006
DA 2024-07-18
ER

PT J
AU Tian, Y
   Sigal, L
   De la Torre, F
   Jia, YH
AF Tian, Yan
   Sigal, Leonid
   De la Torre, Fernando
   Jia, Yonghua
TI Canonical locality preserving Latent Variable Model for discriminative
   pose inference
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human pose estimation; Gaussian Mixture Regression; Latent Variable
   Model; Discriminative Model
ID 3D HUMAN POSE; BODY POSE; SILHOUETTES
AB Discriminative approaches for human pose estimation model the functional mapping, or conditional distribution, between image features and 3D poses. Learning such multi-modal models in high dimensional spaces, however, is challenging with limited training data; often resulting in over-fitting and poor generalization. To address these issues Latent Variable Models (LVMs) have been introduced. Shared LVMs learn a low dimensional representation of common causes that give rise to both the image features and the 3D pose. Discovering the shared manifold structure can, in itself, however, be challenging. In addition, shared LVM models are often non-parametric, requiring the model representation to be a function of the training set size. We present a parametric framework that addresses these shortcomings. In particular, we jointly learn latent spaces for both image features and 3D poses by maximizing the non-linear dependencies in the projected latent space, while preserving local structure in the original space; we then learn a multi-modal conditional density between these two low-dimensional spaces in the form of Gaussian Mixture Regression. With this model we can address the issue of over-fitting and generalization, since the data is denser in the learned latent space, as well as avoid the need for learning a shared manifold for the data. We quantitatively compare the performance of the proposed method to several state-of-the-art alternatives, and show that our method gives a competitive performance. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Tian, Yan; Jia, Yonghua] Hangzhou Hikvis Digital Technol Co Ltd, Hangzhou, Zhejiang, Peoples R China.
   [Tian, Yan] Zhejiang Univ, Hangzhou 310003, Zhejiang, Peoples R China.
   [De la Torre, Fernando] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
   [Sigal, Leonid] Disney Res, Pittsburgh, PA USA.
C3 Hangzhou Hikvision Digital Technology Co., Ltd.; Zhejiang University;
   Carnegie Mellon University
RP Tian, Y (corresponding author), Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Agarwal A, 2004, PROC CVPR IEEE, P882
   [Anonymous], J GRAPH TOOL
   [Anonymous], IEEE P COMPUT VIS PA
   [Anonymous], COMPUT SOFTW
   [Anonymous], AS C COMP VIS
   [Anonymous], 2007, MACHINE LEARNING MUL, DOI DOI 10.1007/978-3-540-78155-4
   Bissacco A., 2007, CVPR
   De la Torre F, 2012, IEEE T PATTERN ANAL, V34, P1041, DOI 10.1109/TPAMI.2011.184
   Dong Huang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPR.2011.5995683
   Elgammal A, 2004, PROC CVPR IEEE, P681
   Fathi A, 2007, IEEE I CONF COMP VIS, P1917
   Guo F, 2006, INT C PATT RECOG, P43
   Hardoon DR, 2004, NEURAL COMPUT, V16, P2639, DOI 10.1162/0899766042321814
   He XF, 2004, ADV NEUR IN, V16, P153
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jaeggli T, 2009, INT J COMPUT VISION, V83, P121, DOI 10.1007/s11263-008-0158-0
   Kanaujia A., 2007, IEEE PROC INT C COMP, P1
   Kim M, 2011, IEEE T PATTERN ANAL, V33, P657, DOI 10.1109/TPAMI.2010.111
   Lai P L, 2000, Int J Neural Syst, V10, P365, DOI 10.1016/S0129-0657(00)00034-X
   Liefeng Bo, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2403, DOI 10.1109/CVPRW.2009.5206699
   Melzer T, 2003, PATTERN RECOGN, V36, P1961, DOI 10.1016/S0031-3203(03)00058-X
   Nadaraya E.A., 1964, Theory of Probability and Its Applications, V61, P405, DOI [10.1137/1109020, DOI 10.1137/1109020]
   Navaratnam R., 2007, IEEE PROC MT CONE CO, P1
   Nilsson Jens, 2007, Proceedings of the 24th International Conference on Machine Learning (ICML), P697
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Sigal Leonid, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2852, DOI 10.1109/CVPRW.2009.5206576
   Sminchisescu C, 2005, PROC CVPR IEEE, P390
   Sminchisescu C., 2006, COMPUTER VISION PATT, V2, P1743
   Song L., 2008, ADV NEURAL INFORM PR, P1385
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Urtasun R., 2008, IEEE PROC COMPUT VIS, P1
   Weinberger K. Q., 2004, P 21 INT C MACH LEAR, P106
   Yang HY, 2005, IEEE COMP SOC ANN, P71
NR 36
TC 8
Z9 8
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2013
VL 31
IS 3
BP 223
EP 230
DI 10.1016/j.imavis.2012.06.009
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 122NK
UT WOS:000317324600001
DA 2024-07-18
ER

PT J
AU Bousmalis, K
   Mehu, M
   Pantic, M
AF Bousmalis, Konstantinos
   Mehu, Marc
   Pantic, Maja
TI Towards the automatic detection of spontaneous agreement and
   disagreement based on nonverbal behaviour: A survey of related cues,
   databases, and tools
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Agreement; Disagreement; Nonverbal behaviour; Social signal processing
ID FACIAL EXPRESSION ANALYSIS; HEAD POSE; SPEECH RECOGNITION; TEMPORAL
   SEGMENTS; HUMAN MOVEMENT; VISUAL FOCUS; MODEL; DYNAMICS; LAUGHTER;
   CONTEXT
AB While detecting and interpreting temporal patterns of nonverbal behavioural cues in a given context is a natural and often unconscious process for humans, it remains a rather difficult task for computer systems. Nevertheless, it is an important one to achieve if the goal is to realise a naturalistic communication between humans and machines. Machines that are able to sense social attitudes like agreement and disagreement and respond to them in a meaningful way are likely to be welcomed by users due to the more natural, efficient and human-centred interaction they are bound to experience. This paper surveys the nonverbal behavioural cues that could be present during displays of agreement and disagreement; discusses a number of methods that could be used or adapted to detect these suggested cues; lists some publicly available databases these tools could be trained on for the analysis of spontaneous, audiovisual instances of agreement and disagreement, it examines the few existing attempts at agreement and disagreement classification, and finally discusses the challenges in automatically detecting agreement and disagreement. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Bousmalis, Konstantinos; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
   [Mehu, Marc] Univ Geneva, Swiss Ctr Affect Sci, CH-1211 Geneva 4, Switzerland.
   [Pantic, Maja] Univ Twente, EEMCS, NL-7500 AE Enschede, Netherlands.
C3 Imperial College London; University of Geneva; University of Twente
RP Bousmalis, K (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.
EM k.bousmalis@imperial.ac.uk; marc.mehu@unige.ch; m.pantic@imperial.ac.uk
RI Mehu, Marc/M-4124-2015
OI Mehu, Marc/0000-0001-5164-3573
FU European Community [231287]; Google European Doctoral Fellowship in
   Social Computing; European Research Council [ERC-2007-StG-203143];
   National Center of Competence in Research Affective Sciences; Swiss
   National Science Foundation
FX This work has been supported by the European Community's 7th Framework
   Programme [FP7/20072013] under grant agreement no. 231287 (SSPNet). The
   work of Konstantinos Bousmalis is currently funded by Google European
   Doctoral Fellowship in Social Computing. The work by Maja Pantic is also
   funded in part by the European Research Council under the ERC Starting
   Grant agreement no. ERC-2007-StG-203143 (MAHNOB). Part of this research
   was supported by the National Center of Competence in Research Affective
   Sciences and by the Swiss National Science Foundation.
CR Agarwal A, 2006, LECT NOTES COMPUT SC, V3851, P50
   Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], NEUR INF PROC SYST N
   [Anonymous], P INT C AUT FAC GEST
   [Anonymous], IEEE INT C IM PROC
   [Anonymous], 2008 INT S WORLD WIR
   [Anonymous], NTT TECH REV
   [Anonymous], 2004, PHYLOGENY EVOLUTION
   [Anonymous], P INT C LANG RES EV
   [Anonymous], P ACM INT C MULT INT
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2004, HDB FACE RECOGNITION
   [Anonymous], P INT C CYB IEEE
   [Anonymous], ICSI M CORP P IEEE I
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2010, P ACMMM, DOI DOI 10.1145/1873951.1874102
   [Anonymous], U PA WORKING PAP LIN
   [Anonymous], COGN COMPUT
   [Anonymous], P INT C AUGM COGN
   [Anonymous], DECODING INTEREST BO
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], 2002, EXPRESSION EMOTIONS
   [Anonymous], 1991, Research on Language and Social Interaction, DOI DOI 10.1080/08351819109389361
   [Anonymous], P S EYE TRACK RES AP
   [Anonymous], P NIST M REC WORKSH
   [Anonymous], INTERPRETING INTERRU
   [Anonymous], THESIS IMPERIAL COLL
   [Anonymous], ENCODING DISAGREEMEN
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], BODILY COMMUNICATION
   [Anonymous], 2005, P BRIT MACH VIS C
   [Anonymous], PROC BRIT MACH VIS C
   [Anonymous], 2009, P 2009 3 INT C AFFEC
   [Anonymous], 2003, P HLT NAACL 2003
   [Anonymous], 2008, PROC IEEE CONE COMPU, DOI DOI 10.1109/CVPR.2008.4587628
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P EUR C COMP VIS
   [Anonymous], P INT C AFF COMP INT
   [Anonymous], IMAGE VISION COMPUTI
   [Anonymous], IMAGE VISION COMPUT
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], NONVERBAL CONTEXT VE
   [Anonymous], TALK WORK MANAGEMENT
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P INT C COMP VIS
   [Anonymous], MODELING INTEREST FA
   [Anonymous], 2006, COMPUT LINGUIST
   [Anonymous], 2005, P 6 INT 2005 9 EUR C
   [Anonymous], P INT C SPOK LANG PR
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587730
   Asteriadis S, 2009, MULTIMED TOOLS APPL, V41, P469, DOI 10.1007/s11042-008-0240-1
   Ba SO, 2009, IEEE T SYST MAN CY B, V39, P16, DOI 10.1109/TSMCB.2008.927274
   Baron-Cohen S., 2004, MIND READING INTERAC
   Bartlett MS, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P223, DOI 10.1109/fgr.2006.55
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Boersma P., 2018, Praat: doing phonetics by computer, DOI DOI 10.1097/AUD.0B013E31821473F7
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Bousmalis K., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P746, DOI 10.1109/FG.2011.5771341
   BRUNNER LJ, 1979, J PERS SOC PSYCHOL, V37, P728, DOI 10.1037/0022-3514.37.5.728
   Cai R, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P37
   Carletta J, 2007, LANG RESOUR EVAL, V41, P181, DOI 10.1007/s10579-007-9040-x
   Cerrato L, 2005, P 2 NORD C MULT COMM, P137
   Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Cheon YJ, 2009, PATTERN RECOGN, V42, P1340, DOI 10.1016/j.patcog.2008.10.010
   Cowie R., 2000, PROC ISCA WORKSHOP S, P19
   Cunningham D.W., 2004, P 1 S APPL PERCEPTIO, V73, P143
   DITTMANN AT, 1972, J COMMUN, V22, P404, DOI 10.1111/j.1460-2466.1972.tb00165.x
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Douglas-Cowie E., 2003, P 15 INT C PHONETIC, P2877
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   DUNCAN S, 1972, J PERS SOC PSYCHOL, V23, P283, DOI 10.1037/h0033031
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P., 1985, TELLING LIES
   EKMAN P, 1979, HUMAN ETHOLOGY
   El Kaliouby R., 2004, 2004 Conference on Computer Vision and Pattern Recognition Workshop, P154, DOI DOI 10.1109/CVPR.2004.153
   Elgammal A, 2004, PROC CVPR IEEE, P681
   Enzweiler M, 2010, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2010.5540110
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fujie S, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P159, DOI 10.1109/ROMAN.2004.1374748
   Gabrea M., 2000, INTERSPEECH, P678
   Gatica-Perez D, 2005, INT CONF ACOUST SPEE, P489
   Gatica-Perez D, 2009, IMAGE VISION COMPUT, V27, P1775, DOI 10.1016/j.imavis.2009.01.004
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Germesin Sebastian., 2009, ICMI, P7, DOI [10.1145/1647314.1647319, DOI 10.1145/1647314.1647319]
   Gilbert A, 2009, IEEE I CONF COMP VIS, P925, DOI 10.1109/ICCV.2009.5459335
   Givens D.B., 2002, NONVERBAL DICT GESTU
   Gonzalez I, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P463, DOI 10.1109/ICIG.2009.146
   Goto M., 1999, P EUROPEAN C SPEECH, P227
   GOTTMAN J, 1977, J MARRIAGE FAM, V39, P461, DOI 10.2307/350902
   Gunes Hatice, 2010, International Journal of Strategic Synthetic Emotions, V1, P68, DOI 10.4018/jse.2010101605
   Guo GD, 2003, IEEE T NEURAL NETWOR, V14, P209, DOI 10.1109/TNN.2002.806626
   HADAR U, 1985, J NONVERBAL BEHAV, V9, P214, DOI 10.1007/BF00986881
   Han D, 2009, IEEE I CONF COMP VIS, P1933, DOI 10.1109/ICCV.2009.5459427
   Hansen D.W., 2003, Proc. IEEE Workshop Applications on Computer Vision, P132
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Hansen DW, 2005, COMPUT VIS IMAGE UND, V98, P155, DOI 10.1016/j.cviu.2004.07.013
   Haumer F, 2009, J BROADCAST ELECTRON, V53, P262, DOI 10.1080/08838150902907918
   Hirschberg Julia, 2004, P 42 ANN M ASS COMP, P669
   Hu Y., 2009, Proceedings of Int Conf Computer Science Applications, V23, P1, DOI DOI 10.1109/IAS.2009.5324874
   Hu Y.X., 2008, IEEE INT C PATT REC, P1
   Huang Y, 2002, INT C PATT RECOG, P552, DOI 10.1109/ICPR.2002.1044791
   Hung H, 2010, IEEE T MULTIMEDIA, V12, P563, DOI 10.1109/TMM.2010.2055233
   Jayagopi DB, 2009, IEEE T AUDIO SPEECH, V17, P501, DOI 10.1109/TASL.2008.2008238
   Jhuang H., 2007, PROC INT C COMPUTER, P1
   Junejo IN, 2008, LECT NOTES COMPUT SC, V5303, P293, DOI 10.1007/978-3-540-88688-4_22
   Kalimeri Kyriaki, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P124, DOI 10.1007/978-3-642-25446-8_14
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kapoor A., P 13 ANN ACM INT C M, P677
   Kapoor Ashish., 2001, Proceedings of the 2001 workshop on Perceptive user interfaces, P1
   Kawato S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P40, DOI 10.1109/AFGR.2000.840610
   Keller E, 2007, LECT NOTES COMPUT SC, V4775, P85
   Kendon A., 2002, Gesture, V2, P147, DOI 10.1075/gest.2.2.03ken
   Kim M, 2009, IEEE T PATTERN ANAL, V31, P1847, DOI 10.1109/TPAMI.2009.37
   Kim T, 2008, CSCW: 2008 ACM CONFERENCE ON COMPUTER SUPPORTED COOPERATIVE WORK, CONFERENCE PROCEEDINGS, P457
   Knox MT, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P797
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Krüger V, 2007, ADV ROBOTICS, V21, P1473
   Kumano Shiro, 2009, P 2009 INT C MULTIMO, P99, DOI [10.1145/1647314.1647333, DOI 10.1145/1647314.1647333]
   Kyunghee Kim, 2009, 2009 International Conference on Computational Science and Engineering (CSE), P801, DOI 10.1109/CSE.2009.415
   Laptev I., 2007, PROC INT C COMPUTER, P1
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laskowski K, 2008, LECT NOTES COMPUT SC, V5237, P149, DOI 10.1007/978-3-540-85853-9_14
   Lee CC, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P1678
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Liu Y, 2006, IEEE T AUDIO SPEECH, V14, P1526, DOI 10.1109/TASL.2006.878255
   Lockerd A., 2002, CHI '02 extended abstracts on Human factors in computing systems, P574, DOI DOI 10.1145/506443.506490
   Lucey Simon., 2007, Face recognition
   Mahmoud M, 2009, LECT NOTES COMPUT SC, V5627, P481, DOI 10.1007/978-3-642-02611-9_48
   Manusov V, 2002, J COMMUN, V52, P640, DOI 10.1093/joc/52.3.640
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Marzinzik M, 2002, IEEE T SPEECH AUDI P, V10, P109, DOI 10.1109/89.985548
   Matos S, 2006, IEEE T BIO-MED ENG, V53, P1078, DOI 10.1109/TBME.2006.873548
   McKeown G, 2010, IEEE INT CON MULTI, P1079, DOI 10.1109/ICME.2010.5583006
   Mikic I, 2003, INT J COMPUT VISION, V53, P199, DOI 10.1023/A:1023012723347
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Morency L.P., 2005, P 7 INT C MULTIMODAL, P18, DOI DOI 10.1145/1088463.1088470
   Morency L.P., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383299
   Morency L.-P., 2006, Proc. Int'l. Conf. Multimodal Interfaces, P287, DOI DOI 10.1145/1180995.1181051
   Morency LP, 2008, LECT NOTES COMPUT SC, V4892, P11
   Mori G, 2006, IEEE T PATTERN ANAL, V28, P1052, DOI 10.1109/TPAMI.2006.149
   Morris D., 1994, Bodytalk. A World Guide to Gestures
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Murthy G.R.S., 2009, International Journal of Information Technology and Knowledge Management, V2, P405
   Niebles J. C., 2007, PROC IEEE C COMPUTER, P1
   Nowozin S, 2007, IEEE I CONF COMP VIS, P1727
   Ogden R, 2006, J PRAGMATICS, V38, P1752, DOI 10.1016/j.pragma.2005.04.011
   Oikonomopoulos A, 2009, IMAGE VISION COMPUT, V27, P1814, DOI 10.1016/j.imavis.2009.05.010
   Ong EJ, 2006, COMPUT VIS IMAGE UND, V104, P178, DOI 10.1016/j.cviu.2006.08.004
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Pantic M, 2005, IEEE SYS MAN CYBERN, P3358
   Pantic Maja, 2008, International Journal of Automomous and Adaptive Communications Systems, V1, P168, DOI 10.1504/IJAACS.2008.019799
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M., 2011, Social Signal Processing: The Research Agenda, P511
   Pantic M., 2007, FACE RECOGNITION, P377
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   Pentland A, 2005, COMPUTER, V38, P33, DOI 10.1109/MC.2005.104
   Petridis Stavros, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P619, DOI 10.1109/FG.2011.5771468
   Petridis S, 2011, IEEE T MULTIMEDIA, V13, P216, DOI 10.1109/TMM.2010.2101586
   Pianesi F, 2007, LANG RESOUR EVAL, V41, P409, DOI 10.1007/s10579-007-9060-6
   Poggi I, 2010, LREC 2010 - SEVENTH INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P2570
   Pomerantz A., 1975, Second assessments: A study of some features of agreements/ disagreements
   Pomerantz Anita, 1984, STRUCTURES SOCIAL AC
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Rapantzikos K., 2007, Proceedings of the 6th ACM international conference on Image and video retrieval, P294, DOI DOI 10.1145/1282280.1282326
   Rapantzikos K, 2009, PROC CVPR IEEE, P1454, DOI 10.1109/CVPRW.2009.5206525
   Reuderink B, 2008, LECT NOTES COMPUT SC, V5237, P137, DOI 10.1007/978-3-540-85853-9_13
   RINN WE, 1984, PSYCHOL BULL, V95, P52, DOI 10.1037/0033-2909.95.1.52
   Roman Jakobson., 1972, Language in Society, P91, DOI [10.1017/S0047404500006564, DOI 10.1017/S0047404500006564]
   Rosenfeld H.M., 1978, Nonverbalbehavior and communication, P291
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Schuller B, 2008, LECT NOTES ARTIF INT, V5078, P99, DOI 10.1007/978-3-540-69369-7_12
   Schuller B, 2009, IMAGE VISION COMPUT, V27, P1760, DOI 10.1016/j.imavis.2009.02.013
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Seiter JS, 2006, COMMUN REP, V19, P57, DOI 10.1080/08934210600626856
   Seiter JS, 2005, J SOC PSYCHOL, V145, P225, DOI 10.3200/SOCP.145.2.225-236
   Seiter JS, 1999, PSYCHOL REP, V84, P855, DOI 10.2466/PR0.84.3.855-861
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   Shechtman E., 2007, PROC IEEE C COMPUTER
   Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119
   Sheerman-Chase Tim, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1985, DOI 10.1109/ICCVW.2009.5457525
   Stouten F, 2006, SPEECH COMMUN, V48, P1590, DOI 10.1016/j.specom.2006.04.004
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Sung J, 2009, IMAGE VISION COMPUT, V27, P1313, DOI 10.1016/j.imavis.2008.11.010
   Tan WZ, 2003, EXPERT SYST APPL, V25, P461, DOI 10.1016/S0957-4174(03)00088-5
   Taycher Leonid., 2006, IEEE C COMPUTER VISI, P222
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Tong Y, 2010, IEEE T PATTERN ANAL, V32, P258, DOI 10.1109/TPAMI.2008.293
   Tong Y, 2009, AFFECTIVE INFORMATION PROCESSING, P159, DOI 10.1007/978-1-84800-306-4_10
   Truong KP, 2007, SPEECH COMMUN, V49, P144, DOI 10.1016/j.specom.2007.01.001
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Valstar MF, 2007, LECT NOTES COMPUT SC, V4796, P118
   Valstar MF, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P38
   Veenstra Arno, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P838, DOI 10.1109/ICCVW.2011.6130339
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Vinciarelli A, 2009, IEEE SIGNAL PROC MAG, V26, P133, DOI 10.1109/MSP.2009.933382
   Voit M, 2008, LECT NOTES COMPUT SC, V5237, P1, DOI 10.1007/978-3-540-85853-9_1
   Voit Michael., 2008, Proceedings of the 10th international conference on Multimodal interfaces, P173
   Vural E., 2008, P INT C AUT TECHN
   Wang H., 2009, BMVC
   Wang HG, 2005, COMPUT VIS IMAGE UND, V98, P83, DOI 10.1016/j.cviu.2004.07.008
   Wang JJL, 2003, REAL-TIME IMAGING, V9, P321, DOI 10.1016/j.rti.2003.08.001
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang S.B., 2006, P IEEE COMP SOC C CO
   Wang TH, 2009, PATTERN RECOGN, V42, P962, DOI 10.1016/j.patcog.2008.09.035
   Wang W., 2011, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers, V2, P374
   Whitehill J, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P97
   Willems G, 2008, LECT NOTES COMPUT SC, V5303, P650, DOI 10.1007/978-3-540-88688-4_48
   Williams O., 2006, P IEEE C CVPR, V1, P230, DOI DOI 10.1109/CVPR.2006.285
   Wu CH, 2004, J VLSI SIG PROC SYST, V36, P91, DOI 10.1023/B:VLSI.0000015089.17975.f4
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Yang P., 2007, PROC IEEE INT CONE C, P1, DOI [10.1109/CVPR2007.383059, DOI 10.1109/CVPR2007.383059]
   Yang P, 2009, PATTERN RECOGN LETT, V30, P132, DOI 10.1016/j.patrec.2008.03.014
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zelnik-Manor L, 2006, IEEE T PATTERN ANAL, V28, P1530, DOI 10.1109/TPAMI.2006.194
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 222
TC 51
Z9 60
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2013
VL 31
IS 2
BP 203
EP 221
DI 10.1016/j.imavis.2012.07.003
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 102KN
UT WOS:000315843600009
OA Green Published
DA 2024-07-18
ER

PT J
AU Li, Y
   Tax, DMJ
   Loog, M
AF Li, Yan
   Tax, David M. J.
   Loog, Marco
TI Scale selection for supervised image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Scale selection; Image segmentation; Supervised learning; Scale space
   theory; Max rule
ID CHEST RADIOGRAPHS; TEXTURE CLASSIFICATION; VESSEL SEGMENTATION; SPACE;
   REPRESENTATION; RECOGNITION; REGIMES; RIBS
AB Finding the right scales for feature extraction is crucial for supervised image segmentation based on pixel classification. There are many scale selection methods in the literature; among them the one proposed by Lindeberg is widely used for image structures such as blobs, edges and ridges. Those schemes are usually unsupervised, as they do not take into account the actual segmentation problem at hand. In this paper, we consider the problem of selecting scales, which aims at an optimal discrimination between user-defined classes in the segmentation. We show the deficiency of the classical unsupervised scale selection paradigms and present a supervised alternative. In particular, the so-called max rule is proposed, which selects a scale for each pixel to have the largest confidence in the classification across the scales. In interpreting the classifier as a complex image filter, we can relate our approach back to Lindeberg's original proposal. In the experiments, the max rule is applied to artificial and real-world image segmentation tasks, which is shown to choose the right scales for different problems and lead to better segmentation results. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Li, Yan; Tax, David M. J.; Loog, Marco] Delft Univ Technol, Pattern Recognit Lab, Fac Elect Engn Math & Comp Sci, NL-2628 CD Delft, Netherlands.
   [Loog, Marco] Univ Copenhagen, Dept Comp Sci, Image Grp, DK-1168 Copenhagen, Denmark.
C3 Delft University of Technology; University of Copenhagen
RP Li, Y (corresponding author), Delft Univ Technol, Pattern Recognit Lab, Fac Elect Engn Math & Comp Sci, Mekelweg 4, NL-2628 CD Delft, Netherlands.
EM yan.li@tudelft.nl; d.m.j.tax@tudelft.nl; m.loog@tudelft.nl
FU Faculty of Science, University of Copenhagen [10-05087]; Netherlands
   Research Organization (NWO) [639.021.611]
FX The authors would like to thank the reviewers for their constructive
   comments. Ihor Smal, Erik Meijering (both Erasmus Medical Centre) and
   Ilya Grigoriev and Anna Akhmanova (both Utrecht University) are kindly
   acknowledged for the spot detection data set. Marco Loog was partly
   supported by the Research Grant Program of the Faculty of Science,
   University of Copenhagen (research grant 10-05087) and the Innovational
   Research Incentives Scheme of The Netherlands Research Organization
   (NWO, VENI grant 639.021.611).
CR [Anonymous], 2008, Computer Vision and Pattern Recognition
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   BLANZ WE, 1981, PATTERN RECOGN, V13, P293, DOI 10.1016/0031-3203(81)90020-0
   Boltz S, 2010, LECT NOTES COMPUT SC, V6313, P692
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Brox T, 2004, LECT NOTES COMPUT SC, V3022, P578
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chomat O, 2000, LECT NOTES COMPUT SC, V1842, P117
   Collins RT, 2003, PROC CVPR IEEE, P234
   Duda R., 1973, Pattern Classification and Scene Analysis
   Duin R. P. W., 1998, Advances in Pattern Recognition. Joint IAPR International Workshops SSPR'98 and SPR'98. Proceedings, P611, DOI 10.1007/BFb0033285
   Fergus R, 2003, PROC CVPR IEEE, P264
   Florack L., 1993, SYNTACTICAL STRUCTUR
   Florack L. M. J., 1993, Journal of Mathematical Imaging and Vision, V3, P327, DOI 10.1007/BF01664793
   FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W
   Folkesson J, 2007, IEEE T MED IMAGING, V26, P106, DOI 10.1109/TMI.2006.886808
   García MA, 2007, IMAGE VISION COMPUT, V25, P1091, DOI 10.1016/j.imavis.2006.05.023
   GEMAN D, 1990, IEEE T PATTERN ANAL, V12, P609, DOI 10.1109/34.56204
   GREENSPAN H, 1994, IEEE T PATTERN ANAL, V16, P894, DOI 10.1109/34.310685
   Guo CE, 2007, COMPUT VIS IMAGE UND, V106, P5, DOI 10.1016/j.cviu.2005.09.004
   HARING S, 1994, IMAGE VISION COMPUT, V12, P339, DOI 10.1016/0262-8856(94)90058-2
   He XM, 2004, PROC CVPR IEEE, P695
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Kumar S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1150, DOI 10.1109/ICCV.2003.1238478
   Kuncheva LI, 2004, COMBINING PATTERN CL, DOI DOI 10.1002/0471660264
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li Y, 2012, LECT NOTES COMPUT SC, V6667, P350, DOI 10.1007/978-3-642-24785-9_30
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Loog M, 2006, MED IMAGE ANAL, V10, P826, DOI 10.1016/j.media.2006.06.002
   Loog M, 2005, LECT NOTES COMPUT SC, V3753, P146, DOI 10.1007/11577812_13
   Loog M, 2006, IEEE T MED IMAGING, V25, P602, DOI 10.1109/TMI.2006.872747
   Loog M., 2004, THESIS UTRECHT U
   Loog M, 2009, LECT NOTES COMPUT SC, V5519, P468, DOI 10.1007/978-3-642-02326-2_47
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo B, 2009, MULTISCALE MODEL SIM, V8, P1, DOI 10.1137/080730627
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Manmatha R, 2005, IEEE T PATTERN ANAL, V27, P1212, DOI 10.1109/TPAMI.2005.150
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   Maver J, 2010, IEEE T PATTERN ANAL, V32, P1211, DOI 10.1109/TPAMI.2009.105
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Niemeijer M, 2004, PROC SPIE, V5370, P648, DOI 10.1117/12.535349
   Okada K, 2004, PROC CVPR IEEE, P594
   PANDA DP, 1978, IEEE T COMPUT, V27, P875, DOI 10.1109/TC.1978.1675208
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Shotton J, 2009, INT J COMPUT VISION, V81, P2, DOI 10.1007/s11263-007-0109-1
   Smal I, 2010, IEEE T MED IMAGING, V29, P282, DOI 10.1109/TMI.2009.2025127
   Smal I, 2009, I S BIOMED IMAGING, P1178, DOI 10.1109/ISBI.2009.5193268
   Sporring J, 1999, IEEE T INFORM THEORY, V45, P1051, DOI 10.1109/18.761342
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Strong DM, 2006, MULTISCALE MODEL SIM, V5, P273, DOI 10.1137/040621624
   Suzuki K, 2006, IEEE T MED IMAGING, V25, P406, DOI 10.1109/TMI.2006.871549
   Ter Haar Romeny B., 2002, FRONT END VISION MUL
   van Ginneken B, 2006, MED IMAGE ANAL, V10, P19, DOI 10.1016/j.media.2005.02.002
   Vandenbroucke N, 2003, COMPUT VIS IMAGE UND, V90, P190, DOI 10.1016/S1077-3142(03)00025-0
   Witkin A., 1983, INT JOINT C ART INT, V9, P1019
   Wu YN, 2008, Q APPL MATH, V66, P81
   Yu ZW, 2011, IMAGE VISION COMPUT, V29, P29, DOI 10.1016/j.imavis.2010.08.003
NR 70
TC 12
Z9 13
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 991
EP 1003
DI 10.1016/j.imavis.2012.08.010
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800007
DA 2024-07-18
ER

PT J
AU Prasad, DK
   Leung, MKH
   Quek, C
   Cho, SY
AF Prasad, Dilip K.
   Leung, Maylor K. H.
   Quek, Chai
   Cho, Siu-Yeung
TI A novel framework for making dominant point detection methods
   non-parametric
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Non-parametric; Line fitting; Polygonal approximation; Dominant points;
   Digital curves
ID DIGITAL PLANAR CURVES; POLYGONAL-APPROXIMATION; DIGITIZED-CURVES;
   REPRESENTATION; RECOGNITION; ALGORITHM; IMAGES
AB Most dominant point detection methods require heuristically chosen control parameters. One of the commonly used control parameter is maximum deviation. This paper uses a theoretical bound of the maximum deviation of pixels obtained by digitization of a line segment for constructing a general framework to make most dominant point detection methods non-parametric. The derived analytical bound of the maximum deviation can be used as a natural bench mark for the line fitting algorithms and thus dominant point detection methods can be made parameter-independent and non-heuristic. Most methods can easily incorporate the bound. This is demonstrated using three categorically different dominant point detection methods. Such non-parametric approach retains the characteristics of the digital curve while providing good fitting performance and compression ratio for all the three methods using a variety of digital, non-digital, and noisy curves. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Prasad, Dilip K.; Quek, Chai] Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
   [Leung, Maylor K. H.] Univ Tunku Abdul Rahman Kampar, Fac Informat & Commun Technol, Kampar, Malaysia.
   [Cho, Siu-Yeung] Univ Nottingham Ningbo, Ningbo, Zhejiang, Peoples R China.
C3 Nanyang Technological University; University of Nottingham Ningbo China
RP Prasad, DK (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
EM dilipprasad@gmail.com
RI Prasad, Dilip K./B-5838-2009; Quek, Chai/AAF-3038-2020
OI Prasad, Dilip K./0000-0002-3693-6973; Quek, Chai/0000-0002-7313-4339
CR ANSARI N, 1991, PATTERN RECOGN, V24, P849, DOI 10.1016/0031-3203(91)90004-O
   Bhowmick P, 2007, IEEE T PATTERN ANAL, V29, P1590, DOI 10.1109/TPAMI.2007.1082
   Brunner D, 2007, IMAGE VISION COMPUT, V25, P1352, DOI 10.1016/j.imavis.2006.09.002
   Carmona-Poyato A, 2011, PATTERN RECOGN, V44, P45, DOI 10.1016/j.patcog.2010.07.029
   Carmona-Poyato A, 2010, PATTERN RECOGN, V43, P14, DOI 10.1016/j.patcog.2009.06.010
   Cronin TM, 1999, PATTERN RECOGN LETT, V20, P617, DOI 10.1016/S0167-8655(99)00025-2
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Elder JH, 2001, IEEE T PATTERN ANAL, V23, P291, DOI 10.1109/34.910881
   Kanungo T., 1994, IAPR WOLKSH MACH VIS
   Kolesnikov A, 2005, PATTERN RECOGN, V38, P381, DOI 10.1016/j.patcog.2004.07.005
   Kolesnikov A, 2003, PATTERN RECOGN LETT, V24, P2243, DOI 10.1016/S0167-8655(03)00051-5
   Kolesnikov A, 2007, PATTERN RECOGN, V40, P1282, DOI 10.1016/j.patcog.2006.09.002
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   LAVALLEE S, 1995, IEEE T PATTERN ANAL, V17, P378, DOI 10.1109/34.385980
   LOWE DG, 1987, ARTIF INTELL, V31, P355, DOI 10.1016/0004-3702(87)90070-1
   Marji M, 2004, PATTERN RECOGN, V37, P2113, DOI 10.1016/j.patcog.2004.03.004
   Masood A, 2008, IMAGE VISION COMPUT, V26, P702, DOI 10.1016/j.imavis.2007.08.006
   Masood A, 2007, J VIS COMMUN IMAGE R, V18, P264, DOI 10.1016/j.jvcir.2006.12.002
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   Nguyen TP, 2011, PATTERN RECOGN, V44, P32, DOI 10.1016/j.patcog.2010.06.022
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   Prasad D.K., 2011, AS C PATT REC ACPR B, P441
   Prasad D.K., 2012, DIGITAL IMAGE PROCES, P71
   Prasad DK, 2012, PATTERN RECOGN, V45, P3204, DOI 10.1016/j.patcog.2012.02.014
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   RAY BK, 1992, PATTERN RECOGN LETT, V13, P849, DOI 10.1016/0167-8655(92)90084-D
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Salotti M, 2002, PATTERN RECOGN, V35, P435, DOI 10.1016/S0031-3203(01)00051-6
   SANKAR PV, 1978, COMPUT VISION GRAPH, V7, P403, DOI 10.1016/S0146-664X(78)80006-9
   Sarkar B, 2003, PATTERN RECOGN LETT, V24, P2869, DOI 10.1016/S0167-8655(03)00145-4
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Toussaint G.T, 1988, MACHINE INTELLIGENCE, V6, P71
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Yang RG, 2004, IEEE T PATTERN ANAL, V26, P956, DOI 10.1109/TPAMI.2004.27
NR 34
TC 67
Z9 72
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2012
VL 30
IS 11
BP 843
EP 859
DI 10.1016/j.imavis.2012.06.010
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 052CW
UT WOS:000312176300005
DA 2024-07-18
ER

PT J
AU Meer, P
AF Meer, Peter
TI Are we making real progress in computer vision today
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Human vision
AB This paper presents an opinion on research progress in computer vision. (c) 2012 Elsevier B.V. All rights reserved.
C1 Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
C3 Rutgers University System; Rutgers University New Brunswick
RP Meer, P (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
EM meer@cronos.rutgers.edu
NR 0
TC 6
Z9 6
U1 9
U2 57
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 472
EP 473
DI 10.1016/j.imavis.2011.10.004
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100005
OA hybrid
DA 2024-07-18
ER

PT J
AU Prakash, S
   Gupta, P
AF Prakash, Surya
   Gupta, Phalguni
TI An efficient ear localization technique
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Skin segmentation; Biometrics; Ear localization; Ear recognition;
   Connected components
AB This paper proposes an efficient technique for automatic localization of ear from side face images. The technique is rotation, scale and shape invariant and makes use of the connected components in a graph obtained from the edge map of the side face image. It has been evaluated on IIT Kanpur database consisting of 2672 side faces with variable sizes, rotations and shapes and University of Notre Dame database containing 2244 side faces with variable background and poor illumination. Experimental results reveal the efficiency and robustness of the technique. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Prakash, Surya; Gupta, Phalguni] Indian Inst Technol Kanpur, Dept Comp Sci & Engn, Kanpur 208016, Uttar Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur
RP Prakash, S (corresponding author), Indian Inst Technol Kanpur, Dept Comp Sci & Engn, Kanpur 208016, Uttar Pradesh, India.
EM psurya@cse.iitk.ac.in; pg@cse.iitk.ac.in
RI Gupta, Phalguni/C-6439-2012; Prakash, Surya/C-3536-2008; Prakash,
   Surya/S-6308-2019
OI Prakash, Surya/0000-0001-8039-1280
FU Department of Information Technology, Government of India
FX Authors are thankful to the anonymous reviewers and the Editor for their
   valuable suggestions which have helped us to improve the quality of the
   manuscript. Authors also like to acknowledge the support provided by the
   Department of Information Technology, Government of India to carry out
   this work.
CR Alvarez L., 2005, Proceedings of the IEEE 39th International Carnahan Conference on Security Technology (IEEE Cat. No. 05CH37697), P145, DOI 10.1109/CCST.2005.1594829
   [Anonymous], 2008, 2008 IEEE WORKSH APP
   [Anonymous], U NOTR DAM PROF FAC
   Ansari S, 2007, ICCTA 2007: INTERNATIONAL CONFERENCE ON COMPUTING: THEORY AND APPLICATIONS, PROCEEDINGS, P688
   Arbab-Zavar B, 2007, LECT NOTES COMPUT SC, V4842, P549
   Attarchi S, 2008, LECT NOTES COMPUT SC, V5259, P1030, DOI 10.1007/978-3-540-88458-3_93
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Burge M, 2000, INT C PATT RECOG, P822, DOI 10.1109/ICPR.2000.906202
   Bustard J., 2008, PROC INT C BIOMETRIC, P1
   Cai J, 1999, IMAGE VISION COMPUT, V18, P63, DOI 10.1016/S0262-8856(99)00006-2
   Chen H, 2004, INT C PATT RECOG, P574, DOI 10.1109/ICPR.2004.1334594
   Cummings A., 2010, P INT C BIOM THEOR A, P1
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   HOPCROFT J, 1973, COMMUN ACM, V16, P372, DOI 10.1145/362248.362272
   Hurley DJ, 2005, COMPUT VIS IMAGE UND, V98, P491, DOI 10.1016/j.cviu.2004.11.001
   Ibrahim MIS, 2010, LECT NOTES COMPUT SC, V6453, P499
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Poynton CharlesA., 1996, TECHNICAL INTRO DIGI
   Prakash S., 2008, PROC IEEE INT WORKSH, P1
   Prakash S, 2009, IEEE IMAGE PROC, P2741, DOI 10.1109/ICIP.2009.5414150
   Prakash S, 2009, PROC SPIE, V7306, DOI 10.1117/12.818371
   Prakash S, 2009, ICAPR 2009: SEVENTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, PROCEEDINGS, P213, DOI 10.1109/ICAPR.2009.31
   Sana A, 2007, PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION, P46
   Yan P., P 2005 IEEE COMPUTER, DOI [DOI 10.1109/CVPR.2005.450, 10.1109/CVPR.2005.450]
   Yan P, 2007, IEEE T PATTERN ANAL, V29, P1297, DOI 10.1109/TPAMI.2007.1067
   Yuan L, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2213
NR 28
TC 39
Z9 39
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2012
VL 30
IS 1
BP 38
EP 50
DI 10.1016/j.imavis.2011.11.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900WC
UT WOS:000300921400004
DA 2024-07-18
ER

PT J
AU Demonceaux, C
   Vasseur, P
   Fougerolle, Y
AF Demonceaux, Cedric
   Vasseur, Pascal
   Fougerolle, Yohan
TI Central catadioptric image processing with geodesic metric
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Catadioptric image; Image processing; Spherical image
ID OMNIDIRECTIONAL IMAGES
AB Because of the distortions produced by the insertion of a mirror, catadioptric images cannot be processed similarly to classical perspective images. Now, although the equivalence between such images and spherical images is well known, the use of spherical harmonic analysis often leads to image processing methods which are more difficult to implement. In this paper, we propose to define catadioptric image processing from the geodesic metric on the unitary sphere. We show that this definition allows to adapt very simply classical image processing methods. We focus more particularly on image gradient estimation, interest point detection, and matching. More generally, the proposed approach extends traditional image processing techniques based on Euclidean metric to central catadioptric images. We show in this paper the efficiency of the approach through different experimental results and quantitative evaluations. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Demonceaux, Cedric; Fougerolle, Yohan] Univ Bourgogne, UMR LE21 5158, F-71200 Le Creusot, France.
   [Vasseur, Pascal] Univ Rouen, LITIS, F-76800 St Etienne, France.
C3 Universite de Bourgogne; Universite de Rouen Normandie
RP Demonceaux, C (corresponding author), Univ Bourgogne, UMR LE21 5158, 12 Rue Fonderie, F-71200 Le Creusot, France.
EM cedric.demonceaux@u-bourgogne.fr; Pascal.Vasseur@univ-rouen.fr;
   yohan.fougerolle@u-bourgogne.fr
RI Demonceaux, Cédric/JJC-2233-2023
OI Demonceaux, Cédric/0000-0001-6916-1273
CR [Anonymous], P 5 IFAC S INT AUT V
   Barreto JP, 2006, COMPUT VIS IMAGE UND, V103, P208, DOI 10.1016/j.cviu.2006.06.003
   Benosman R., 2001, PANORAMIC VISION SEN
   Bigot S, 2008, LECT NOTES COMPUT SC, V5259, P554, DOI 10.1007/978-3-540-88458-3_50
   Bogdanova I, 2007, IEEE T IMAGE PROCESS, V16, P1888, DOI 10.1109/TIP.2007.899008
   Bulow T., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P609
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Daniilidis K, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P3, DOI 10.1109/OMNVIS.2002.1044483
   Demonceaux C, 2006, PATTERN RECOGN LETT, V27, P1957, DOI 10.1016/j.patrec.2006.05.007
   DRISCOLL JR, 1994, ADV APPL MATH, V15, P202, DOI 10.1006/aama.1994.1008
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jacquey F, 2008, FUZZY SET SYST, V159, P1991, DOI 10.1016/j.fss.2008.02.022
   Lemaire T, 2007, J FIELD ROBOT, V24, P91, DOI 10.1002/rob.20175
   Makadia A, 2007, INT J COMPUT VISION, V75, P311, DOI 10.1007/s11263-007-0035-2
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   YING X, 2004, P EUR C COMP VIS ECC, V1, P442
NR 17
TC 26
Z9 30
U1 6
U2 66
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2011
VL 29
IS 12
BP 840
EP 849
DI 10.1016/j.imavis.2011.09.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 873TJ
UT WOS:000298905600004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mélange, T
   Nachtegael, M
   Schulte, S
   Kerre, EE
AF Melange, Tom
   Nachtegael, Mike
   Schulte, Stefan
   Kerre, Etienne E.
TI A fuzzy filter for the removal of random impulse noise in image
   sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video; Denoising; Impulse noise; Fuzzy sets
ID SEARCH ALGORITHM
AB In this paper a new fuzzy filter for the removal of random impulse noise in digital grayscale image sequences is presented. The filter consists of different noise detection and filtering steps, in which the fuzzy set theory is used. This noise detection is based both on spatial and on temporal information and has the aim to prevent the filtering of noise free image pixels. The filtering of the detected noisy pixels is finally performed in a motion compensated way. Experimental results show that our method outperforms other state-of-the-art filters in terms of the peak-signal-to-noise ratio as well as visual quality. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Melange, Tom; Nachtegael, Mike; Schulte, Stefan; Kerre, Etienne E.] Univ Ghent, Fuzziness & Uncertainty Modelling Res Unit, Dept Appl Math & Comp Sci, B-9000 Ghent, Belgium.
C3 Ghent University
RP Mélange, T (corresponding author), Univ Ghent, Fuzziness & Uncertainty Modelling Res Unit, Dept Appl Math & Comp Sci, Krijgslaan 281,Bldg S9, B-9000 Ghent, Belgium.
EM tom.melange@ugent.be
FU FWO [G.0667.06]; Ghent University [B/04138/01IV]
FX This research was financially supported by the FWO project G.0667.06 and
   the GOA project B/04138/01IV of Ghent University.
CR Balster EJ, 2006, IEEE T CIRC SYST VID, V16, P220, DOI 10.1109/TCSVT.2005.857816
   Buades A, 2008, INT J COMPUT VISION, V76, P123, DOI 10.1007/s11263-007-0052-1
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Cocchia F, 1997, IEEE T CONSUM ELECTR, V43, P1291, DOI 10.1109/30.642398
   Dabov K, 2007, IEEE T IMAGE PROCESS, V16, P2080, DOI 10.1109/TIP.2007.901238
   El Hassouni M, 2006, IEEE T IMAGE PROCESS, V15, P572, DOI 10.1109/TIP.2005.863039
   Guo LW, 2007, IEEE T CIRC SYST VID, V17, P1423, DOI 10.1109/TCSVT.2007.903797
   Guo SM, 2005, EXPERT SYST APPL, V28, P483, DOI 10.1016/j.eswa.2004.12.010
   HARDIE RC, 1993, IEEE T SIGNAL PROCES, V41, P1061, DOI 10.1109/78.205713
   Jovanov L., 2007, P IEEE INT C AC SPEE
   Kim JS, 2001, SIGNAL PROCESS-IMAGE, V16, P657, DOI 10.1016/S0923-5965(00)00043-6
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   Kwan H.K., 2003, FUZZY FILTERS IMAGE, P54
   Liang SF, 2008, IEEE T FUZZY SYST, V16, P863, DOI 10.1109/TFUZZ.2008.917297
   Liu C., 2010, P EUR C COMP VIS
   Lukac R., 2001, EURASIP Journal on Applied Signal Processing, V2001, P110, DOI 10.1155/S1110865701000099
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Rahman SMM, 2007, IEEE T CIRC SYST VID, V17, P187, DOI 10.1109/TCSVT.2006.887079
   Russo F, 1999, PATTERN RECOGN, V32, P1843, DOI 10.1016/S0031-3203(99)00009-6
   Russo F, 1999, FUZZY SET SYST, V103, P265, DOI 10.1016/S0165-0114(98)00226-7
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   Schulte S, 2007, FUZZY SET SYST, V158, P270, DOI 10.1016/j.fss.2006.10.010
   Schulte S, 2007, IEEE T IMAGE PROCESS, V16, P2565, DOI 10.1109/TIP.2007.904960
   Wang JH, 2002, IEEE T SYST MAN CY B, V32, P230, DOI 10.1109/3477.990880
   WEBER S, 1983, FUZZY SET SYST, V11, P115, DOI 10.1016/S0165-0114(83)80073-6
   Windyga PS, 2001, IEEE T IMAGE PROCESS, V10, P173, DOI 10.1109/83.892455
   Xu HX, 2004, PATTERN RECOGN LETT, V25, P1657, DOI 10.1016/j.patrec.2004.05.025
   Yildirim MT, 2008, IEEE T FUZZY SYST, V16, P920, DOI 10.1109/TFUZZ.2008.924358
   Yin HB, 2007, IEEE T CIRC SYST VID, V17, P1714, DOI 10.1109/TCSVT.2007.904590
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   Zhu C, 2002, IEEE T CIRC SYST VID, V12, P349, DOI 10.1109/TCSVT.2002.1003474
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 32
TC 20
Z9 22
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2011
VL 29
IS 6
BP 407
EP 419
DI 10.1016/j.imavis.2011.01.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 761TD
UT WOS:000290423000004
OA Green Published
DA 2024-07-18
ER

PT J
AU Hsiao, JY
   Chang, CT
AF Hsiao, Ju-Yuan
   Chang, Chieh-Tse
TI An adaptive steganographic method based on the measurement of just
   noticeable distortion profile
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Data hiding; Just noticeable distortion; Steganography; Information
   hiding
ID HIDING DATA; IMAGES; INFORMATION; SUBSTITUTION; SCHEME
AB This paper presents an adaptive steganographic method based on just noticeable distortion (JND) profile measurement. According to the input requirements, our method can produce a higher quality or higher embedding capacity stego-image. In the embedding secret data bits into a target pixel process, four different impact factors are utilized to compute how much information can be embedded and what the stego-pixel value will be. These are difference values that represent the correlation between neighboring pixels, the JND value of the target pixel, a predefined embedding capacity control factor, and the contents of various lengths secret data bits. The proposed method embeds more secret data bits within complex areas and less data bits in smooth areas. The difference between the target pixel and the stego-pixel values is controlled, as far as possible, to less than or equal to the JND value of the target pixel. Thus, the stego-image maintains good imperceptible property. In the extraction phase, the embedded secret data can be extracted from the stego-image without referencing the original image and the JND profile. The experimental results show that our method improves stego-image quality and conspicuously increases the embedding capacity at the same time. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Hsiao, Ju-Yuan; Chang, Chieh-Tse] Natl Changhua Univ Educ, Dept Comp Sci & Informat Engn, Changhua 500, Taiwan.
C3 National Changhua University of Education
RP Hsiao, JY (corresponding author), Natl Changhua Univ Educ, Dept Comp Sci & Informat Engn, Changhua 500, Taiwan.
EM hsiaojy@cc.ncue.edu.tw; cjtzer@yahoo.com.tw
CR Anderson RJ, 1998, IEEE J SEL AREA COMM, V16, P474, DOI 10.1109/49.668971
   Bender W, 2000, IBM SYST J, V39, P547, DOI 10.1147/sj.393.0547
   Bender W, 1996, IBM SYST J, V35, P313, DOI 10.1147/sj.353.0313
   Besdok E, 2005, AEU-INT J ELECTRON C, V59, P15, DOI 10.1016/j.aeue.2004.11.040
   Chan CK, 2004, PATTERN RECOGN, V37, P469, DOI 10.1016/j.patcog.2003.08.007
   Chan CK, 2001, ELECTRON LETT, V37, P1017, DOI 10.1049/el:20010714
   Chang CC, 2004, PATTERN RECOGN LETT, V25, P1431, DOI 10.1016/j.patrec.2004.05.006
   Chang CC, 2003, PATTERN RECOGN, V36, P1583, DOI 10.1016/S0031-3203(02)00289-3
   Chou CH, 1995, IEEE T CIRC SYST VID, V5, P467, DOI 10.1109/76.475889
   Hsiao JY, 2008, IMAGING SCI J, V56, P291, DOI 10.1179/174313108X283937
   JAYANT N, 1993, P IEEE, V81, P1385, DOI 10.1109/5.241504
   Kutter M, 2002, IEEE T IMAGE PROCESS, V11, P16, DOI 10.1109/83.977879
   LIE WN, 1999, P IEEE INT C IM PROC, V1, P286
   Lu ZK, 2005, IEEE T IMAGE PROCESS, V14, P1928, DOI 10.1109/TIP.2005.854478
   Marvel LM, 1999, IEEE T IMAGE PROCESS, V8, P1075, DOI 10.1109/83.777088
   Netravali A.N., 1988, DIGITAL PICTURES REP
   NETRAVALI AN, 1977, P IEEE, V65, P536, DOI 10.1109/PROC.1977.10515
   Noda H, 2002, IEEE SIGNAL PROC LET, V9, P410, DOI 10.1109/LSP.2002.806056
   Park YR, 2005, LECT NOTES COMPUT SC, V3612, P962
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Swanson MD, 1996, 1996 IEEE DIGITAL SIGNAL PROCESSING WORKSHOP, PROCEEDINGS, P37, DOI 10.1109/DSPWS.1996.555454
   Thien CC, 2003, PATTERN RECOGN, V36, P2875, DOI 10.1016/S0031-3203(03)00221-8
   Wang RZ, 2001, PATTERN RECOGN, V34, P671, DOI 10.1016/S0031-3203(00)00015-7
   Wang RZ, 2000, ELECTRON LETT, V36, P2069, DOI 10.1049/el:20001429
   Wei ZH, 1998, IEEE T CONSUM ELECTR, V44, P1267, DOI 10.1109/30.735826
   Wong PHW, 2003, IEEE T CIRC SYST VID, V13, P746, DOI 10.1109/TCSVT.2003.815949
   Wu DC, 2003, PATTERN RECOGN LETT, V24, P1613, DOI 10.1016/S0167-8655(02)00402-6
   Zhang XP, 2005, IEEE SIGNAL PROC LET, V12, P67, DOI 10.1109/LSP.2004.838214
NR 28
TC 6
Z9 7
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2011
VL 29
IS 2-3
BP 155
EP 166
DI 10.1016/j.imavis.2010.08.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 707NV
UT WOS:000286294200006
DA 2024-07-18
ER

PT J
AU Yang, ZW
   Fang, T
AF Yang, Zhengwu
   Fang, Tao
TI On the accuracy of image normalization by Zernike moments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image normalization; Zernike moments; Image regularization; Scale space
ID EDGE-DETECTION; REGULARIZATION; APPROXIMATION; COMPUTATION; ALGORITHMS;
   INVARIANTS
AB Zernike Moment (ZM) is an effective region-based shape representation technique. The extracted ZM features should be independent of scale, position and orientation, which can be achieved by ZM-based image normalization. Nevertheless, due to the discretization of digital image and the presence of noise. the normalization is imperfect. Thus, in practice Zernike Moment Invariants (ZMI) cannot perfectly preserve the invariant properties. In this paper, firstly the ZM-based image normalization criteria are derived, and then I theoretically and experimentally evaluate the accuracy of the ZM-based image normalization. Our theoretical and experimental results not only disclose some essential facts, but also have some new findings. The relations between the accuracy of ZM-based image normalization and its influencing factors are established. A creative pseudo-polar coordinate is proposed to cut down the geometrical errors to the greatest extent. Furthermore, I suggest several techniques to improve the accuracy of image normalization. By combining moment-based image normalization with the image regularization theory and the scale-space theory, and several new conclusions are drawn. Our experimental results show that the proposed techniques can preserve the invariance of image normalization and restrain the influence of noise quite effectively. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Yang, Zhengwu; Fang, Tao] Shanghai Jiao Tong Univ, Inst Pattern Recognit & Intelligent Syst, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, ZW (corresponding author), Shanghai Jiao Tong Univ, Inst Pattern Recognit & Intelligent Syst, Shanghai 200030, Peoples R China.
EM zwyaang@hotmail.com
RI wang, Xiaoming/KBB-8854-2024; fang, tao/IQU-3074-2023
CR Abu-Mostafa Y. S., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P114
   ABUMOSTAFA YS, 1985, IEEE T PATTERN ANAL, V7, P46, DOI 10.1109/TPAMI.1985.4767617
   [Anonymous], 1986, COMPUTATIONAL APPROA, DOI DOI 10.1109/TPAMI.1986.4767851
   Chong CW, 2003, PATTERN RECOGN, V36, P731, DOI 10.1016/S0031-3203(02)00091-2
   DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   Liao SX, 1997, IEEE WESCANEX 97 COMMUNICATIONS, POWER AND COMPUTING CONFERENCE PROCEEDINGS, P157, DOI 10.1109/WESCAN.1997.627131
   Nielsen M, 1997, J MATH IMAGING VIS, V7, P291, DOI 10.1023/A:1008282127190
   PAWLAK M, 1998, NONPARAMETRIC ESTIMA
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Strong D, 2003, INVERSE PROBL, V19, pS165, DOI 10.1088/0266-5611/19/6/059
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   TEH CH, 1986, COMPUT VISION GRAPH, V33, P318, DOI 10.1016/0734-189X(86)90180-5
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P247, DOI 10.1109/83.366474
   Unser M, 1997, IEEE T SIGNAL PROCES, V45, P1697, DOI 10.1109/78.599940
   Unser M, 1997, IEEE T SIGNAL PROCES, V45, P2941, DOI 10.1109/78.650255
   WALLIN A, 1995, IEEE T PATTERN ANAL, V17, P1106, DOI 10.1109/34.473239
   XIN Y, 2005, IMPROVEMENT ROTATION
   Xin YQ, 2007, IEEE T IMAGE PROCESS, V16, P581, DOI 10.1109/TIP.2006.888346
NR 24
TC 10
Z9 12
U1 1
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 403
EP 413
DI 10.1016/j.imavis.2009.06.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300011
DA 2024-07-18
ER

PT J
AU Economopoulos, TL
   Asvestas, PA
   Matsopoulos, GK
AF Economopoulos, T. L.
   Asvestas, P. A.
   Matsopoulos, G. K.
TI Contrast enhancement of images using Partitioned Iterated Function
   Systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Contrast enhancement; Iterated Function System; Self-similarity; Linear
   and nonlinear unsharp masking; Contrast Limited Adaptive Histogram
   Equalization; Local Range Modification
AB A new algorithm for the contrast enhancement of images, based on the theory of Partitioned Iterated Function System (PIFS), is presented. A PIFS consists of contractive transformations, such that the original image is the fixed point of the union of these transformations. Each transformation involves the contractive affine spatial transform of a square block, as well as the linear transform of the gray levels of its pixels. The transformation of the gray levels is determined by two parameters which adjust the brightness and the contrast of the transformed block. The PIFS is used in order to create a lowpass version of the original image. The contrast-enhanced image is obtained by adding the difference of the original image with its lowpass version, to the original image itself. The proposed algorithm uses a predefined constant value for the contrast parameter, whereas, the parameters of the affine spatial transform, as well as the parameter adjusting the brightness, are calculated using k-dimensional trees. The lowpass version of the original image is obtained applying the PIFS on the original image repeatedly while using a value for the contrast parameter that is lower than the predefined one. Quantitative and qualitative results stress the superior performance of the proposed contrast enhancement algorithm against four other widely used contrast enhancement methods; namely, linear and nonlinear unsharp masking, Contrast Limited Adaptive Histogram Equalization and Local Range Modification. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Economopoulos, T. L.; Asvestas, P. A.; Matsopoulos, G. K.] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece.
C3 National Technical University of Athens
RP Matsopoulos, GK (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, 9 Iroon Polytechniou Str, Athens 15780, Greece.
EM pasv@esd.ece.ntua.gr; gmatso@esd.ece.ntua.gr
CR [Anonymous], 1992, R. woods digital image processing
   Arici T, 2006, IEEE IMAGE PROC, P2881, DOI 10.1109/ICIP.2006.313031
   Badamchizadeh M. A., 2004, Proceedings. Third International Conference on Image and Graphics, P27
   Barnsley M.F., 1993, Fractal Image Compression
   Barnsley MF., 1993, Fractals Everywhere
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Chang DC, 1998, IEEE T MED IMAGING, V17, P518, DOI 10.1109/42.730397
   CHEN SK, 1995, SWED DENT J, V19, P139
   DEVRIES FPP, 1990, SIGNAL PROCESS, V21, P169, DOI 10.1016/0165-1684(90)90048-4
   FAHNESTOCK JD, 1983, OPT ENG, V22, P378, DOI 10.1117/12.7973124
   FAN KC, 1995, P SOC PHOTO-OPT INS, V2501, P1727, DOI 10.1117/12.206708
   JACQUIN AE, 1993, P IEEE, V81, P1451, DOI 10.1109/5.241507
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Kuan J, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P924, DOI 10.1109/ICICS.1997.652114
   Lewis RA, 2004, PHYS MED BIOL, V49, P3573, DOI 10.1088/0031-9155/49/16/005
   Li H, 1997, IEEE T MED IMAGING, V16, P785, DOI 10.1109/42.650875
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   MARTIN C, 1992, IEEE T SIGNAL PROCES, V40, P1819, DOI 10.1109/78.143454
   Nikiel S, 2006, COMPUT GRAPH-UK, V30, P277, DOI 10.1016/j.cag.2006.01.002
   Polesel A, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P267, DOI 10.1109/ICIP.1997.647756
   Ramponi G, 1998, SIGNAL PROCESS, V67, P211, DOI 10.1016/S0165-1684(98)00038-3
   Suman K Mitra, 1998, FUNDAM INFORM, V34, P1
   Sund T, 2006, DENTOMAXILLOFAC RAD, V35, P133, DOI 10.1259/dmfr/21936923
   THOMAS L, 1995, IEEE T IMAGE PROCESS, V4, P832, DOI 10.1109/83.388086
   Umbaugh S.E., 1997, Computer Vision and Image Processing: A Practical Approach Using Cviptools with Cdrom
   Zuiderverld K., 1994, Contrast Limited Adaptive Histograph Equalisation. Graphic Gems IV
NR 26
TC 58
Z9 62
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 45
EP 54
DI 10.1016/j.imavis.2009.04.011
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000006
DA 2024-07-18
ER

PT J
AU Li, DL
AF Li, Dalong
TI Support vector regression based image denoising
SO IMAGE AND VISION COMPUTING
LA English
DT Article
AB Support vector regression (SVR) has been applied for blind image deconvolution. In this correspondence, it is applied in the problem of image denoising. After training on noisy images with ground-truth, support vectors (SVs) are identified and their weights are computed. Then the SVs and their weights are used in denoising different images corrupted by random noise at different levels on a pixel-by-pixel basis. The proposed SVR based image denoising algorithm is an example-based approach since it uses SVs in denoising. The SVR denoising is compared with a Multiple wavelet domain method (Besov ball projection). Some initial experiments indicate that SVR based image denoising outperforms Besov ball projection method on non-natural images (e.g. document images) in terms of both peak signal-to-noise ratio (PSNR) and visual inspection. (C) 2008 Elsevier B.V. All rights reserved.
C1 Pegasus Imaging Corp, Tampa, FL 33603 USA.
RP Li, DL (corresponding author), Pegasus Imaging Corp, 4001 Riverside Dr, Tampa, FL 33603 USA.
EM dalongli@gmail.com
CR Alexander S. K., 2007, P 2007 EUR SIGN PROC, P975
   Bharath AA, 2005, IEEE T IMAGE PROCESS, V14, P948, DOI 10.1109/TIP.2005.849295
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1522, DOI 10.1109/83.862630
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Choi H, 2004, IEEE SIGNAL PROC LET, V11, P717, DOI 10.1109/LSP.2004.833493
   Farbiz F, 2000, IEEE T SYST MAN CY B, V30, P110, DOI 10.1109/3477.826951
   Ghael S. P., 1997, P SPIE
   Ghazel M, 2003, IEEE T IMAGE PROCESS, V12, P1560, DOI 10.1109/TIP.2003.818038
   Ishwar P, 1998, INT CONF ACOUST SPEE, P1889, DOI 10.1109/ICASSP.1998.681833
   Kuo SS, 2002, IEEE T IMAGE PROCESS, V11, P509, DOI 10.1109/TIP.2002.1006398
   Li DL, 2007, IEEE T NEURAL NETWOR, V18, P931, DOI 10.1109/TNN.2007.891622
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   Munteanu C, 2004, IEEE T SYST MAN CY B, V34, P1292, DOI 10.1109/TSMCB.2003.818533
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   *U SO CAL, USC SIPI IM DAT
   Xie JC, 2004, IEEE T IMAGE PROCESS, V13, P179, DOI 10.1109/tip.2004.823828
   Zhong JM, 2005, IEEE T IMAGE PROCESS, V14, P1435, DOI 10.1109/TIP.2005.849313
NR 20
TC 33
Z9 37
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 623
EP 627
DI 10.1016/j.imavis.2008.06.006
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000002
DA 2024-07-18
ER

PT J
AU Lin, CH
   Chen, RT
   Chan, YK
AF Lin, Chuen-Horng
   Chen, Rong-Tai
   Chan, Yung-Kuan
TI A smart content-based image retrieval system based on color and texture
   feature
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image retrieval; Color; Texture; Co-occurrence; Motif; Feature selection
ID HISTOGRAMS
AB In this paper, three image features are proposed for image retrieval. In addition, a feature selection technique is also brought forward to select optimal features to not only maximize the detection rate but also simplify the computation of image retrieval. The first and second image features are based on color and texture features, respectively called color co-occurrence matrix (CCM) and difference between pixels of scan pattern (DBPSP) in this paper. The third image feature is based on color distribution, called color histogram for K-mean (CHKM).
   CCM is the conventional pattern co-occurrence matrix that calculates the probability of the occurrence of same pixel color between each pixel and its adjacent ones in each image, and this probability is considered as the attribute of the image. According to the sequence of motifs of scan patterns, DBPSP calculates the difference between pixels and converts it into the probability of occurrence on the entire image. Each pixel color in an image is then replaced by one color in the common color palette that is most similar to color so as to classify all pixels in image into k-cluster, called the CHKM feature.
   Difference in image properties and contents indicates that different features are contained. Some images have stronger color and texture features, while others are more sensitive to color and spatial features. Thus, this study integrates CCM, DBPSP, and CHKM to facilitate image retrieval. To enhance image detection rate and simplify computation of image retrieval, sequential forward selection is adopted for feature selection. Besides, based on the image retrieval system (CTCHIRS), a series of analyses and comparisons are performed in our experiment. Three image databases with different properties are used to carry out feature selection. Optimal features are selected from original features to enhance the detection rate. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Lin, Chuen-Horng; Chen, Rong-Tai] Natl Taichung Inst Technol, Dept Informat Sci, Taichung 404, Taiwan.
   [Chan, Yung-Kuan] Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung 40227, Taiwan.
C3 National Chung Hsing University
RP Lin, CH (corresponding author), Natl Taichung Inst Technol, Dept Informat Sci, 129 Sec 3,Sanmin Rd, Taichung 404, Taiwan.
EM linch@ntit.edu.tw; s1493B047@ntit.edu.tw; ykchan@nchu.edu.tw
OI Chan, Yung-Kuan/0000-0002-1556-0567
CR [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   Brunelli R, 2001, PATTERN RECOGN, V34, P1625, DOI 10.1016/S0031-3203(00)00054-6
   Chan YK, 2004, J SYST SOFTWARE, V71, P65, DOI 10.1016/S0164-1212(02)00140-1
   CHANG CC, 2000, FAST FILTER IMAGE RE, P47
   Chun YD, 2003, IEEE T CIRC SYST VID, V13, P951, DOI 10.1109/TCSVT.2003.816507
   DAUBECHIES I, 1998, COMMUNICATIONS PURE, V41, P909
   Fuertes JM, 2001, PATTERN RECOGN LETT, V22, P323, DOI 10.1016/S0167-8655(00)00128-8
   GONG Y, 1994, P IEEE INT C MULT CO, P121
   Gu Y., 2001, P 2001 ACM S APPL CO, P236
   GUDIVADA VN, 1995, ACM T INFORM SYST, V13, P115, DOI 10.1145/201040.201041
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   HARALICK RM, 1992, COMPUTER ROBET VISIO, V1
   Huang PW, 2003, PATTERN RECOGN, V36, P665, DOI 10.1016/S0031-3203(02)00083-3
   Jhanwar N, 2004, IMAGE VISION COMPUT, V22, P1211, DOI 10.1016/j.imavis.2004.03.026
   Ko B, 2005, IEEE T MULTIMEDIA, V7, P105, DOI 10.1109/TMM.2004.840603
   Liapis S, 2004, IEEE T MULTIMEDIA, V6, P676, DOI 10.1109/TMM.2004.834858
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   Moghaddam HA, 2005, PATTERN RECOGN, V38, P2506, DOI 10.1016/j.patcog.2005.05.010
   Nezamabadi-Pour H, 2004, PATTERN RECOGN LETT, V25, P1547, DOI 10.1016/j.patrec.2004.05.019
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Su MS, 2001, IEEE T PATTERN ANAL, V23, P674, DOI 10.1109/34.927466
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Theodoridis S, 2006, PATTERN RECOGNITION, 3RD EDITION, P1
   Wu ST, 2005, PATTERN RECOGN, V38, P707, DOI 10.1016/j.patcog.2004.10.005
NR 25
TC 218
Z9 243
U1 0
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 658
EP 665
DI 10.1016/j.imavis.2008.07.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000006
DA 2024-07-18
ER

PT J
AU Schlei, BR
AF Schlei, B. R.
TI A new computational framework for 2D shape-enclosing contours
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Contour; Isocontour; Edge; Unstructured grid; Delaunay tessellation;
   Skeleton; Shape morphology; Material surface; Bacterial colony;
   Handwritten letter recognition; Constellation; Freeze-out hyper-surface
ID RELATIVISTIC HYDRODYNAMICS; GEOMETRIC MORPHOLOGY; ALGORITHM
AB In this paper, a new framework for one-dimensional contour extraction from discrete two-dimensional data sets is presented. Contour extraction is important in many scientific fields such as digital image processing, computer vision, pattern recognition, etc. This novel framework includes (but is not limited to) algorithms for dilated contour extraction, contour displacement, shape skeleton extraction, contour continuation, shape feature based contour refinement and contour simplification. Many of the new techniques depend strongly on the application of a Delaunay tessellation. In order to demonstrate the versatility of this novel toolbox approach, the contour extraction techniques presented here are applied to scientific problems in material science, biology, handwritten letter recognition, astronomy and heavy ion physics. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Schlei, B. R.] Los Alamos Natl Lab, Div Theoret, Los Alamos, NM 87545 USA.
C3 United States Department of Energy (DOE); Los Alamos National Laboratory
RP Schlei, BR (corresponding author), Bahnhofstr 59, D-34454 Bad Arolsen, Germany.
EM schlei@me.com
FU Department of Energy [W-7405-ENG-36]
FX This work has been supported by the Department of Energy under contract
   W-7405-ENG-36.
CR [Anonymous], 2006, GRAPHENTHEORIE
   [Anonymous], ALGORITHMS GRAPHICS
   Bai YB, 2001, COMPUT IND, V46, P65, DOI 10.1016/S0166-3615(01)00115-4
   BOLZ J, 1993, PHYS REV D, V47, P3860, DOI 10.1103/PhysRevD.47.3860
   BOLZ J, 1992, PHYS REV C, V46, P2047, DOI 10.1103/PhysRevC.46.2047
   Bribiesca E, 1999, PATTERN RECOGN, V32, P235, DOI 10.1016/S0031-3203(98)00132-0
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carpenter DT, 1998, J APPL PHYS, V84, P5843, DOI 10.1063/1.368898
   CLARE RB, 1986, PHYS REP, V141, P177, DOI 10.1016/0370-1573(86)90090-6
   COOPER F, 1975, PHYS REV D, V11, P192, DOI 10.1103/PhysRevD.11.192
   COURTESY B, OSBORNE MEMORIAL LAB
   COURTESY MC, DEP ENG SCI MECH
   Csernai L. P., 1994, Introduction to Relativistic Heavy Ion Collisions
   DA L, 2000, SHAPE ANAL CLASSIFIC
   de Berg M., 2000, COMPUTATIONAL GEOMET
   de Sa J.P. Marques., 2001, PATTERN RECOGN
   Demirel M.C., 2000, ELECT BACKSCATTER DI, P65, DOI DOI 10.1007/978-1-4757-3205-4_6
   DiZenzo S, 1996, IEEE T PATTERN ANAL, V18, P83, DOI 10.1109/34.476016
   Fineman M., 1996, The Nature of Visual Illusion
   GEORGE PL, 1998, TRIANGULATION MESHIN
   Goldstein E.B.:., 2002, Wahrnehmungspsychologie
   Jahne B., 1997, DIGITAL IMAGE PROCES
   Jones NL, 2000, COMPUT GEOSCI, V26, P831, DOI 10.1016/S0098-3004(00)00009-1
   Kaygin S, 2001, PATTERN RECOGN LETT, V22, P1169, DOI 10.1016/S0167-8655(01)00059-9
   Kuprat A, 2003, COMP MATER SCI, V28, P199, DOI 10.1016/S0927-0256(03)00107-1
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   Latecki LJ, 2002, PATTERN RECOGN, V35, P15, DOI 10.1016/S0031-3203(01)00039-5
   LIFSCHITZ EM, 1980, CLASSICAL THEORY FIE, V2
   O'Rourke J., 1993, COMPUTATIONAL GEOMET
   Parker J.R., 1997, Algorithms for Image Processing and Computer Vision
   Prasad L, 2000, P SOC PHOTO-OPT INS, V4117, P202, DOI 10.1117/12.404822
   Prasad L, 2000, P SOC PHOTO-OPT INS, V4117, P234, DOI 10.1117/12.404825
   Prasad L, 2000, PROC SPIE, V4117, P222, DOI 10.1117/12.404824
   PRASAD L, CNLS NEWSLETTER  JUL
   Pratt W.K, 1978, DIGITAL IMAGE PROCES
   Ren MW, 2002, IMAGE VISION COMPUT, V20, P125, DOI 10.1016/S0262-8856(01)00091-9
   Schlei BR, 2002, P SOC PHOTO-OPT INS, V4794, P63, DOI 10.1117/12.452361
   Schlei BR, 2001, P SOC PHOTO-OPT INS, V4476, P73, DOI 10.1117/12.447289
   Schlei BR, 2000, P SOC PHOTO-OPT INS, V4117, P196, DOI 10.1117/12.404821
   SCHLEI BR, 2002, LAUR021409, P113
   SCHLEI BR, 2000, PARALLEL ALGORITHM D
   SCHLEI BR, 2001, LAUR011847, P58
   SCHLEI RR, LACC0030 LOS AL NAT
   WEIGERT A, 1989, ASTRONOMIE ASTROPHYS
   Wilson J., 2002, MOL BIOL CELL PROBLE
   Zou JJ, 2001, PATTERN RECOGN, V34, P1895, DOI 10.1016/S0031-3203(00)00131-X
NR 46
TC 10
Z9 15
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 637
EP 647
DI 10.1016/j.imavis.2008.06.014
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Seise, M
   McKenna, SJ
   Ricketts, IW
   Wigderowitz, CA
AF Seise, Matthias
   McKenna, Stephen J.
   Ricketts, Ian W.
   Wigderowitz, Carlos A.
TI Parts-based segmentation with overlapping part models using Markov chain
   Monte Carlo
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 17th Annual British Machine Vision Conference
CY SEP, 2006
CL British Machine Vis Assoc, Edinburgh, SCOTLAND
HO British Machine Vis Assoc
DE Probabilistic segmentation; Model-based segmentation; Markov chain Monte
   Carlo
ID SHAPE; OBJECTS; ATLAS; IMAGE
AB A probabilistic method is proposed for segmenting multiple objects that overlap or are in close proximity to one another. A likelihood function is formulated that explicitly models overlapping object appearance. Priors on global appearance and geometry (including shape) are learned from example images. Markov chain Monte Carlo methods are used to obtain samples from a posterior distribution over model parameters from which expectations can be estimated. The method is described in detail for the problem of segmenting femur and tibia in X-ray images. The result is a probabilistic segmentation that quantifies uncertainty, conditioned upon the model, so that measurements such as joint space can be made with associated uncertainty. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Seise, Matthias; McKenna, Stephen J.; Ricketts, Ian W.] Univ Dundee, Sch Comp, Dundee DD1 4HN, Scotland.
   [Wigderowitz, Carlos A.] Ninewells Hosp, Dundee DD1 9SY, Scotland.
C3 University of Dundee; University of Dundee
RP McKenna, SJ (corresponding author), Univ Dundee, Sch Comp, Dundee DD1 4HN, Scotland.
EM mseise@computing.dundee.ac.uk; stephen@computing.dundee.ac.uk;
   ricketts@computing.dundee.ac.uk; cawigderowitz@lineone.net
RI McKenna, Stephen/AAL-8335-2020
OI McKenna, Stephen/0000-0003-0530-2035
CR ALTMAN RD, 1995, OSTEOARTHR CARTILAGE, V3, P3
   Andrieu C, 2003, MACH LEARN, V50, P5, DOI 10.1023/A:1020281327116
   [Anonymous], 1991, Hands: A Pattern Theoretic Study of Biological Shapes
   [Anonymous], 2004, Statistical Models of Appearance for Computer Vision
   Brejl M, 2000, IEEE T MED IMAGING, V19, P973, DOI 10.1109/42.887613
   Brooks SP, 1998, STAT COMPUT, V8, P319, DOI 10.1023/A:1008820505350
   BUCKLANDWRIGHT JC, 1995, ANN RHEUM DIS, V54, P872, DOI 10.1136/ard.54.11.872
   Davies RH, 2002, IEEE T MED IMAGING, V21, P525, DOI 10.1109/TMI.2002.1009388
   GEYER CJ, 1995, J AM STAT ASSOC, V90, P909, DOI 10.1080/01621459.1995.10476590
   Glasbey C. A., 1998, Journal of Computing and Information Technology - CIT, V6, P107
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Günther KP, 1999, OSTEOARTHR CARTILAGE, V7, P239, DOI 10.1053/joca.1998.0152
   HOLLOMAN CH, 2002, MULTIRESOLUTION GENE
   Jordan MI, 2004, STAT SCI, V19, P140, DOI 10.1214/088342304000000026
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KELLGREN JH, 1957, ANN RHEUM DIS, V16, P494, DOI 10.1136/ard.16.4.494
   Li SZ, 2000, IEEE T IMAGE PROCESS, V9, P273, DOI 10.1109/83.821741
   LIU C, 2002, EUR C COMP VIS, P687
   MacCormick J., 2000, THESIS U OXFORD
   MacKay D., 2003, INFORM THEORY INFERE
   Mardia KV, 1997, IEEE T PATTERN ANAL, V19, P1035, DOI 10.1109/34.615452
   MCALINDON TE, 1992, BRIT J RHEUMATOL, V31, P189
   MOGHADDAM B, 1996, EARLY VISUAL LEARNIN, P99
   Nagaosa Y, 2000, ANN RHEUM DIS, V59, P587, DOI 10.1136/ard.59.8.587
   Neal RM, 1996, STAT COMPUT, V6, P353, DOI 10.1007/BF00143556
   Neal RM, 2003, ANN STAT, V31, P705, DOI 10.1214/aos/1056562461
   Rue H, 1998, STAT COMPUT, V8, P221, DOI 10.1023/A:1008953210305
   Seise M, 2007, IEEE T MED IMAGING, V26, P666, DOI 10.1109/TMI.2007.895479
   Smyth PP, 1999, RADIOLOGY, V211, P571, DOI 10.1148/radiology.211.2.r99ma40571
   THODBERG HH, 2003, BRIT MACH VIS C, P251
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Ware R., 2003, U CANTERBURY ENGLAND, V15, P2003
NR 32
TC 2
Z9 2
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 2
PY 2009
VL 27
IS 5
SI SI
BP 504
EP 513
DI 10.1016/j.imavis.2008.04.020
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 437WD
UT WOS:000265516700002
DA 2024-07-18
ER

PT J
AU Forssén, PE
   Moe, A
AF Forssen, Per-Erik
   Moe, Anders
TI View matching with blob features
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Wide-baseline matching; Colour; Region feature; Conic; Colour
   correction; Homography
AB This article introduces a new region based feature for object recognition and image matching. In contrast to many other region based features, this one makes use of colour in the feature extraction stage. We perform experiments on the repeatability rate of the features across scale and inclination angle changes, and show that avoiding to merge regions connected by only a few pixels improves the repeatability. We introduce two voting schemes that allow us to find correspondences automatically, and compare them with respect to the number of valid correspondences they give, and their inlier ratios. We also demonstrate how the matching procedure can be applied to colour correction. (C) 2006 Elsevier B.V. All rights reserved.
C1 [Forssen, Per-Erik] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.
   [Moe, Anders] Linkoping Univ, Dept Elect Engn, Comp Vis Lab, SE-58183 Linkoping, Sweden.
C3 University of British Columbia; Linkoping University
RP Forssén, PE (corresponding author), Univ British Columbia, Dept Comp Sci, 2366 Main Mall, Vancouver, BC V6T 1Z4, Canada.
EM perfo@cs.ubc.ca; moe@isy.liu.se
CR [Anonymous], THESIS LINKOPING U
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Basri R, 2001, IEEE T PATTERN ANAL, V23, P519, DOI 10.1109/34.922709
   BROWN M., 2002, BRIT MACHINE VISION, P656, DOI [10.5244/C.16.23, DOI 10.5244/C.16.23]
   CHUN O, 2003, LECT NOTES COMPUTER, V2781, P236
   Drew MS, 1998, PATTERN RECOGN, V31, P1077, DOI 10.1016/S0031-3203(97)00144-1
   FINLAYSON GD, 1994, J OPT SOC AM A, V11, P3011, DOI 10.1364/JOSAA.11.003011
   Forssén PE, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P228, DOI 10.1109/CRV.2005.88
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   KAHL F, 2001, THESIS LUND U
   KUMAR MP, 2004, P ICVGIP KOLK IND
   Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mundy J., 1992, GEOMETRIC INVARIANCE
   OBDRZALEK S, 2002, 13 BMVC, P113
   Quan L, 1996, IEEE T PATTERN ANAL, V18, P151, DOI 10.1109/34.481540
   Schmid C, 2000, INT J COMPUT VISION, V40, P199, DOI 10.1023/A:1008135310502
   SONKA VH, 1999, IMAGE PROCESSING ANA
   TRAN LV, 2003, THESIS LINKOPING U
   Tuytelaars T, 2004, INT J COMPUT VISION, V59, P61, DOI 10.1023/B:VISI.0000020671.28016.e8
NR 21
TC 2
Z9 2
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 99
EP 107
DI 10.1016/j.imavis.2006.10.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700011
DA 2024-07-18
ER

PT J
AU Hassouna, MS
   Abdel-Hakim, AE
   Farag, AA
AF Hassouna, M. Sabry
   Abdel-Hakim, Alaa E.
   Farag, Aly A.
TI PDE-based robust robotic navigation
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Robotic navigation; Level set methods; Fast marching methods; Path
   planning; Optimum path; Skeletonization
ID PROBABILISTIC ROADMAPS; PATH
AB In robotic navigation, path planning is aimed at getting the optimum collision-free path between a starting and target locations. The optimality criterion depends on the surrounding environment and the running conditions. In this paper, we propose a general, robust, and fast path planning framework for robotic navigation using level set methods. A level set speed function is proposed such that the minimum cost path between the starting and target locations in the environment, is the optimum planned path. The speed function is controlled by one parameter, which takes one of three possible values to generate either the safest, the shortest, or the hybrid planned path. The hybrid path is much safer than the shortest path, but less shorter than the safest one. The main idea of the proposed technique is to propagate a monotonic wave front with a particular speed function from a starting location until the target is reached and then extracts the optimum planned path between them by solving an ordinary differential equation (ODE) using an efficient numerical scheme. The framework supports both local and global planning for both 2D and 3D environments. The robustness of the proposed framework is demonstrated by correctly extracting planned paths of complex maps. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Hassouna, M. Sabry; Abdel-Hakim, Alaa E.; Farag, Aly A.] Univ Louisville, Comp Vis & Image Proc Lab, Dept Elect & Comp Engn, Louisville, KY 40292 USA.
C3 University of Louisville
RP Hassouna, MS (corresponding author), Univ Louisville, Comp Vis & Image Proc Lab, Dept Elect & Comp Engn, Louisville, KY 40292 USA.
EM msabry@cvip.uofl.edu; alaa@cvip.uofl.edu; farag@cvip.uofl.edu
RI Abdel-Hakim, Alaa E./P-3695-2014
OI Abdel-Hakim, Alaa E./0000-0002-0003-6914
CR ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098
   Amato NM, 1996, IEEE INT CONF ROBOT, P113, DOI 10.1109/ROBOT.1996.503582
   BARRAQUAND J, 1992, IEEE T SYST MAN CYB, V22, P224, DOI 10.1109/21.148426
   BELLMAN R, Q APPL MATH, V16
   BOHLIN R, 1997, P IEEE INT C ROB AUT, P333
   Branicky MS, 2001, IEEE INT CONF ROBOT, P1481, DOI 10.1109/ROBOT.2001.932820
   Cheng P, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P267, DOI 10.1109/ROBOT.2002.1013372
   Choset H, 1997, 8TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS, 1997 PROCEEDINGS - ICAR'97, P333, DOI 10.1109/ICAR.1997.620203
   CUNHA SR, 1993, P IECON 93 IEE INT C, V3, P1442
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   DIMITROV P, 2003, CVPR, P835
   Godunov S., 1959, Matematieskij sbornik, V47, P271
   Hassouna MS, 2005, 2nd Canadian Conference on Computer and Robot Vision, Proceedings, P176, DOI 10.1109/CRV.2005.59
   Hassouna MS, 2005, PROC CVPR IEEE, P458
   Hoff K.  III, 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P2931, DOI 10.1109/ROBOT.2000.846473
   HWANG YK, 1992, COMPUT SURV, V24, P219, DOI 10.1145/136035.136037
   HWANG YK, 1992, IEEE T ROBOTIC AUTOM, V8, P23, DOI 10.1109/70.127236
   HWANG YK, 1989, IEEE COMP SOC C COMP, P569
   KAVRAKI L, 1994, IEEE INT CONF ROBOT, P2138, DOI 10.1109/ROBOT.1994.350966
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   KIM JH, 2003, P IEEE INT C ROB AUT
   LaValle S.M., 1998, RAPIDLY EXPLORING RA, V129, P98
   LaValle SM, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P473, DOI 10.1109/ROBOT.1999.770022
   MIRTICH B, 1992, P IEEE INT C ROB AUT
   Murphy R.R., 2019, INTRO AI ROBOTICS
   RAO NSV, ORNLTM12410
   Siméon T, 2000, ADV ROBOTICS, V14, P477, DOI 10.1163/156855300741960
   ZHU D, 1991, IEEE T ROBOTIC AUTOM, V7, P9, DOI 10.1109/70.68066
NR 29
TC 14
Z9 14
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 10
EP 18
DI 10.1016/j.imavis.2007.03.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700003
DA 2024-07-18
ER

PT J
AU Hotta, K
AF Hotta, Kazuhiro
TI Robust face recognition under partial occlusion based on support vector
   machine with local Gaussian summation kernel
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE support vector machine; local kernel; occlusion; robust and face
   recognition
ID OBJECTS
AB This paper presents the use of Support Vector Machine (SVM) with local Gaussian summation kernel for robust face recognition under partial occlusion. In recent years, the effectiveness of SVM and local features has been reported. However, because conventional methods apply one kernel to global features and global features are influenced easily by noise or occlusion, the conventional methods are not robust to occlusion. The recognition method based on local features, however, is robust to occlusion because partial occlusion affects only specific local features. In order to utilize this property of local features in SVM local kernels are applied to local features. The use of local kernels in SVM requires local kernel integration. The summation of local kernels is used as the integration method in this study. The effectiveness and robustness of the proposed method are shown by comparison with global kernel based SVM. The recognition rate of the proposed method is high under large occlusion, whereas the recognition rate of the SVM with the global Gaussian kernel decreases drastically. Furthermore, we investigate the robustness to practical occlusion in the real world using the AR face database. Although only face images with non-occlusion are used for training, faces wearing sunglasses or a scarf are classified with high accuracy. (C) 2008 Elsevier B.V. All rights reserved.
C1 Univ Electrocommun, Dept Informat & Commun Engn, Tokyo 1828585, Japan.
C3 University of Electro-Communications - Japan
RP Hotta, K (corresponding author), Univ Electrocommun, Dept Informat & Commun Engn, 1-5-1 Chofugaoka, Tokyo 1828585, Japan.
EM hotta@ice.uec.ac.jp
FU Ministry of Education, Culture, Sports, Science and Technology of Japan
   [15700150]; Grants-in-Aid for Scientific Research [15700150] Funding
   Source: KAKEN
FX I thank Prof. Haruhisa Takahashi for providing the opportunity for this
   work to be undertaken.; This work is supported in part by the
   Grant-in-Aid for Scientific Research (No.15700150) from the Ministry of
   Education, Culture, Sports, Science and Technology of Japan.
CR [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 1998, ADV KERNEL METHODS S
   [Anonymous], 1999, UCSC-CRL-99-10
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   BOUGHORBEL S, 2004, P BRIT MACH VIS C
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Debnath R, 2004, PATTERN ANAL APPL, V7, P164, DOI 10.1007/s10044-004-0213-6
   Duda R., 1973, Pattern Classification and Scene Analysis
   Féraud R, 2001, IEEE T PATTERN ANAL, V23, P42, DOI 10.1109/34.899945
   Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693
   Hotta K, 2004, INT C PATT RECOG, P482, DOI 10.1109/ICPR.2004.1334571
   Hotta K., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P34, DOI 10.1109/AFGR.2000.840609
   HOTTA K, 2004, J ADV COMPUTATIONAL, V8, P130
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kurita T, 2003, NEUROCOMPUTING, V51, P181, DOI 10.1016/S0925-2312(02)00615-X
   KURITA T, 2000, P IAPR WORKSH MACH V, P211
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Martinez A., 1998, AR FACE DATABASE
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Ohba K, 1997, IEEE T PATTERN ANAL, V19, P1043, DOI 10.1109/34.615453
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   PHILLIPS PJ, 2003, FRVT2002 EVALUATION
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   ROWLEY H, 1999, CMUCS99117
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Yang WG, 2002, IEEE PHOTONIC TECH L, V14, P215, DOI 10.1109/68.980526
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 39
TC 55
Z9 61
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1490
EP 1498
DI 10.1016/j.imavis.2008.04.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000004
DA 2024-07-18
ER

PT J
AU Shang, L
AF Shang, Li
TI Non-negative sparse coding shrinkage for image denoising using normal
   inverse Gaussian density model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE normal inverse Gaussian density; image denoising; non-negative sparse
   coding; shrinkage function; maximum a posterior estimator
ID COMPONENTS
AB This paper proposes a novel image denoising technique based on the normal inverse Gaussian (NIG) density model and the extended non-negative sparse coding (NNSC). The NIG density function, which is fully specified by four real-valued parameters, represents a class of flexible closed form distribution and is quite suitable for modeling sparse data. By choosing appropriate parameters, one can describe a variety of data distributions. In this paper, we demonstrate that the NIG density function provides good fit to non-negative sparse data. With the aid of NIG-based maximum a posteriori estimator (MAP), significant denoising can be achieved for non-negatively and sparsely coded images corrupted with additive Gaussian noise. It is also shown that the proposed NNSC shrinkage technique is adaptive to various distribution properties of natural image data. Experimental results confirm the effectiveness of the proposed NIG based NNSC shrinkage method for image denoising. The comparison with other denoising methods are also made and it is shown that the proposed method produces the best denoising effect. (C) 2008 Elsevier B.V. All rights reserved.
C1 Suzhou Vocat Univ, Dept Elect Informat Engn, Suzhou 215104, Jiangsu, Peoples R China.
C3 Suzhou Vocational University
RP Shang, L (corresponding author), Suzhou Vocat Univ, Dept Elect Informat Engn, Suzhou 215104, Jiangsu, Peoples R China.
EM s1093@jssvc.edu.cnv
CR AKKARAKARAN S, 1999, SPIE INT SOC OPTICAL, V3813, P346
   [Anonymous], 2001, ADV NEURAL INFORM PR
   [Anonymous], APPL MATH SCI
   BarndorffNielsen OE, 1997, SCAND J STAT, V24, P1, DOI 10.1111/1467-9469.00045
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   Cottet GH, 1998, IEEE T IMAGE PROCESS, V7, P292, DOI 10.1109/83.661179
   DONOHO DL, 1995, J ROY STAT SOC B MET, V57, P301
   FCAI C, 1998, J CHEM INF COMP SCI, V38, P1161
   Hanssen A., 2001, P IEEE EURASIP WORKS
   HOYER PO, 2003, TRENDS RES 2003
   Hyvärinen A, 1999, NEURAL COMPUT, V11, P1739, DOI 10.1162/089976699300016214
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Hyvarinen A, 1998, IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, P859, DOI 10.1109/IJCNN.1998.685880
   Hyvarinen A, 1998, NEUROCOMPUTING, V22, P49, DOI 10.1016/S0925-2312(98)00049-6
   Hyvärinen A, 1999, IEEE SIGNAL PROC LET, V6, P145, DOI 10.1109/97.763148
   HYVARINEN A, 1999, P INT S CIRC SYST OR
   Mika S, 1999, ADV NEUR IN, V11, P536
   OJA E, 1992, NEURAL NETWORKS, V5, P927, DOI 10.1016/S0893-6080(05)80089-9
   SIMONCELLI EP, 1996, 3 IEEE INT C IM PROC
   WEAVER JB, 1991, MAGNETIC RESONANCE M, V24, P195
NR 20
TC 13
Z9 15
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1137
EP 1147
DI 10.1016/j.imavis.2007.12.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300007
DA 2024-07-18
ER

PT J
AU De Backer, S
   Pizurica, A
   Huysmans, B
   Philips, W
   Scheunders, P
AF De Backer, Steve
   Pizurica, Aleksandra
   Huysmans, Bruno
   Philips, Wilfried
   Scheunders, Paul
TI Denoising of multicomponent images using wavelet least-squares
   estimators
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multicomponent images; denoising; wavelets; Bayesian estimation; least
   squares estimators
ID SHRINKAGE; SIGNAL; SELECTION; SCALE
AB In this paper, we study denoising of multicomponent images. The presented procedures are spatial wavelet-based denoising techniques, based on Bayesian least-squares optimization procedures, using prior models for the wavelet coefficients that account for the correlations between the spectral bands. We analyze three mixture priors: Gaussian scale mixture models, Bernoulli-Gaussian mixture models and Laplacian mixture models. These three prior models are studied within the same framework of least-squares optimization. The presented procedures are compared to Gaussian prior model and single-band denoising procedures. We analyze the suppression of non-correlated as well as correlated white Gaussian noise on multispectral and hyperspectral remote sensing data and Rician distributed noise on multiple images of within-modality magnetic resonance data. It is shown that a superior denoising performance is obtained when (a) the interband covariances are fully accounted for and (b) prior models are used that better approximate the marginal distributions of the wavelet coefficients. (c) 2008 Published by Elsevier B.V.
C1 [De Backer, Steve; Scheunders, Paul] Univ Instelling Antwerp, Visionlab, Dept Phys, B-2610 Antwerp, Belgium.
   [Pizurica, Aleksandra; Huysmans, Bruno; Philips, Wilfried] Univ Ghent, Dept Telecommun & Informat Proc Telin, B-9000 Ghent, Belgium.
C3 University of Antwerp; Ghent University
RP De Backer, S (corresponding author), Univ Instelling Antwerp, Visionlab, Dept Phys, Univ Pl 1, B-2610 Antwerp, Belgium.
EM steve.debacker@ua.ac.be; sanja@telin.ugent.be; bhuysman@telin.ugent.be;
   philips@telin.ugent.be; paul.scheunders@ua.ac.be
RI Pizurica, Aleksandra/ISU-9519-2023; Pizurica, Aleksandra/AAG-4687-2021;
   Scheunders, Paul/I-4764-2013
OI Pizurica, Aleksandra/0000-0002-9322-4999; Pizurica,
   Aleksandra/0000-0002-9322-4999; Scheunders, Paul/0000-0003-2447-4772
CR Abramovich F, 1998, J ROY STAT SOC B, V60, P725, DOI 10.1111/1467-9868.00151
   Achim A, 2003, IEEE T GEOSCI REMOTE, V41, P1773, DOI 10.1109/TGRS.2003.813488
   Benazza-Benyahia A, 2005, IEEE T IMAGE PROCESS, V14, P1814, DOI 10.1109/TIP.2005.857247
   Box G. E. P., 1992, Bayesian inference in statistical analysis, DOI DOI 10.1002/9781118033197.CH4
   Chang SG, 2000, IEEE T IMAGE PROCESS, V9, P1532, DOI 10.1109/83.862633
   Chipman HA, 1997, J AM STAT ASSOC, V92, P1413, DOI 10.2307/2965411
   Clyde M, 1998, BIOMETRIKA, V85, P391, DOI 10.1093/biomet/85.2.391
   Coifman RR., 1995, WAVELETS STAT, P125, DOI DOI 10.1007/978-1-4612-2544-7_9
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   Daubechies I., 1992, Ten lectures on wavelets, DOI [DOI 10.1137/1.9781611970104, 10.1137/1.9781611970104]
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Donoho DL, 1995, J AM STAT ASSOC, V90, P1200, DOI 10.1080/01621459.1995.10476626
   GREEN AA, 1988, IEEE T GEOSCI REMOTE, V26, P65, DOI 10.1109/36.3001
   Hansen M, 2000, IEEE T INFORM THEORY, V46, P1778, DOI 10.1109/18.857790
   Jansen M, 2001, J AM STAT ASSOC, V96, P629, DOI 10.1198/016214501753168307
   Jansen M., 2001, NOISE REDUCTION WAVE
   Johnstone IM, 2005, ANN STAT, V33, P1700, DOI 10.1214/009053605000000345
   Kwan RKS, 1999, IEEE T MED IMAGING, V18, P1085, DOI 10.1109/42.816072
   LEE C, 1993, IEEE T GEOSCI REMOTE, V31, P792, DOI 10.1109/36.239901
   LEE JB, 1990, IEEE T GEOSCI REMOTE, V28, P295, DOI 10.1109/36.54356
   LEPORINI D, 1999, LECT NOTES STAT, P155
   Malfait M, 1997, IEEE T IMAGE PROCESS, V6, P549, DOI 10.1109/83.563320
   Mallat S., 1998, WAVELET TOUR SIGNAL
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Mihçak MK, 1999, IEEE SIGNAL PROC LET, V6, P300, DOI 10.1109/97.803428
   Moulin P, 1999, IEEE T INFORM THEORY, V45, P909, DOI 10.1109/18.761332
   Othman H, 2006, IEEE T GEOSCI REMOTE, V44, P397, DOI 10.1109/TGRS.2005.860982
   Pizurica A, 2006, IEEE T IMAGE PROCESS, V15, P654, DOI 10.1109/TIP.2005.863698
   Pizurica A, 2003, IEEE T MED IMAGING, V22, P323, DOI 10.1109/TMI.2003.809588
   Pizurica A, 2002, IEEE T IMAGE PROCESS, V11, P545, DOI 10.1109/TIP.2002.1006401
   PIZURICA A, 2005, P SPIE C WAV 11, V5914, P508
   PIZURICA A, 2005, P INT GEOSC REM SENS, V6, P4260
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Scheunders P, 2004, IEEE IMAGE PROC, P985
   Scheunders P, 2004, IEEE T IMAGE PROCESS, V13, P475, DOI 10.1109/TIP.2004.823829
   Scheunders P, 2006, INT C PATT RECOG, P754
   Sendur L, 2002, IEEE T SIGNAL PROCES, V50, P2744, DOI 10.1109/TSP.2002.804091
   Simoncelli EP, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P379
   Starck JL, 2001, SIGNAL PROCESS, V81, P2449, DOI 10.1016/S0165-1684(01)00104-9
   Thomas I.L., 1987, CLASSIFICATION REMOT
   Vetterli Martin, 1995, Wavelets and Subband Coding
   Vidakovic B, 1998, J AM STAT ASSOC, V93, P173, DOI 10.2307/2669614
   Vidakovic B., 1998, PRACTICAL NONPARAMET, P133
NR 43
TC 23
Z9 25
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 1038
EP 1051
DI 10.1016/j.imavis.2007.11.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800016
OA Green Published
DA 2024-07-18
ER

PT J
AU Neumann, B
   Möller, R
AF Neumann, Bernd
   Moeller, Ralf
TI On scene interpretation with description logics
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE scene interpretation; description logics; high-level vision
ID KNOWLEDGE REPRESENTATION
AB We examine the possible use of description logics (DLs) as a knowledge representation and reasoning system for high-level scene interpretation. It is shown that so-called aggregates composed of multiple parts and constrained primarily by temporal and spatial relations can be used to represent high-level concepts such as object configurations, occurrences, events, and episodes that are required in an application context. Scene interpretation is modelled as a stepwise process which exploits the taxonornical and compositional relations between aggregate concepts while incorporating visual evidence and contextual information. It is shown that aggregates can be represented by concept expressions of a description logic which provides a concrete-domain extension for quantitative temporal and spatial constraints. The analysis reveals that different kinds of representation constructs have to be carefully selected in order to provide for the required expressivity while retaining decidability in general as well as practical support from description logic system implementations in particular. Reasoning services of the DL system can be used as building blocks for the interpretation process, but additional information is required to generate preferred interpretations. A probabilistic model is sketched which can be integrated with the knowledge-based framework. (c) 2007 Elsevier 13N. All rights reserved.
C1 Univ Hamburg, D-22527 Hamburg, Germany.
   Tech Univ Hamburg, D-21079 Hamburg, Germany.
C3 University of Hamburg; Hamburg University of Technology
RP Neumann, B (corresponding author), Univ Hamburg, Vogt Kolln Str 30, D-22527 Hamburg, Germany.
EM neumann@informatik.uni-hamburg.de; r.f.moeller@tu-harburg.de
OI Moller, Ralf/0000-0002-1174-3323
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], P UAI 1994
   Arens M, 2003, LECT NOTES ARTIF INT, V2821, P149
   Artale A, 2000, ANN MATH ARTIF INTEL, V30, P171, DOI 10.1023/A:1016636131405
   ARTALE A, 1996, DATA KNOWLEDGE ENG D, V20
   Baader F, 2003, DESCRIPTION LOGIC HANDBOOK: THEORY, IMPLEMENTATION AND APPLICATIONS, P43
   BAADER F, 1995, J AUTOM REASONING, V14, P149, DOI 10.1007/BF00883932
   BAADER F, 2000, P 7 INT C PRINC KNOW, P261
   Baader Franz., 1991, Proceedings of the 12th International Joint Conference on Artificial Intelligence. Sydney, Australia, August 24-30, P452
   Barwise J., 1983, SITUATIONS ATTITUDES
   BINFORD TO, 1989, UNCERTAINTY AI
   Blake A., 1992, Active Vision
   Brachman R.J., 1991, Principles of Semantic Networks, P401, DOI DOI 10.1016/B978-1-4832-0771-1.50022-9
   BRACHMAN RJ, 1975, ASS NETWORKS REPRESE, P3
   COHEN WW, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P754
   Cohn AG, 2003, LECT NOTES ARTIF INT, V2685, P232
   Cohn AG, 2001, FUND INFORM, V46, P1
   DISCIASCIO E, 1999, LNCS
   Donini FM, 1998, ARTIF INTELL, V100, P225, DOI 10.1016/S0004-3702(98)00009-5
   Gardenfors P., 2000, Conceptual Spaces: The Geometry of Thought, DOI [10.7551/mitpress/2076.001.0001, DOI 10.7551/MITPRESS/2076.001.0001]
   Gyftodimos E., 2002, P ICML 2002 WORKSHOP, P23
   HAAG M, 1997, LECT NOTES ARTIF INT, V1303, P301
   HAARSLEV V, 2001, LECT NOTES COMPUTER, V2083, P701
   HAARSLEV V, 2001, P INT JOINT C AUT RE, P29
   HAYES P, 1979, FRAME CONCEPTIONS TE, P46
   HONGENG S, 2004, P 15 BRIT MACH VIS C
   HORROCKS I, 2000, LNCS
   HOWARTH R, 1995, ARTIF INTELL REV, V9, P37, DOI 10.1007/BF00857653
   Johnson-Laird PN., 1983, Mental Models: towards a Cognitive Science of Language, Inference, and Consciousness
   Kanade T., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P95
   Koller D, 1997, PROC AAAI IAAI, P390
   LAMBRIX P, 2000, LECT NOTES ARTIFICIA
   Laskey KathrynB., 2001, Proceedings of the 17th Conference in Uncertainty in Artificial Intelligence, Seattle, P301
   MATSUYAMA T, 1990, ADV COMPUTER VISION
   Moller R., 1999, Proceedings Integration of Speech and Image Understanding, P101, DOI 10.1109/ISIU.1999.824868
   Nagel H.-H., 1999, Proceedings Integration of Speech and Image Understanding, P79, DOI 10.1109/ISIU.1999.824862
   NEUMANN B, 2003, P 3 INT C COMP VIS S, P212
   NEUMANN B, 1989, SEMANTIC STRUCTURES, P167
   Nilsson NJ., 1998, ARTIF INTELL
   Pearl J., 1988, PROBABILISTIC REASON
   RANDELL DA, 1992, PRINCIPLES OF KNOWLEDGE REPRESENTATION AND REASONING: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE (KR 92), P165
   REITER R, 1987, 8723 TR U BRIT COL D
   RIMEY RD, 1993, 468 TR U ROCH
   RUSS TA, P IM UND WORKSH IUW
   Russell S., 2016, Artificial intelligence a modern approach
   SATTLER U, 2000, P 14 EUR C ART INT E
   SCHMIDTSCHAUSS M, 1991, ARTIF INTELL, V48, P1, DOI 10.1016/0004-3702(91)90078-X
   SCHMIDTSCHAUSS M, 1989, S REPR REAS, P421
   SCHRODER C, 1999, BILDINTERPRETATION M
   SCHRODER C, 1996, P INT C IM PROC ICIP, V2, P785
   SPEEL PH, 1994, P ECAI WORKSH PARTS, P111
   Stefik M., 1995, INTRO KNOWLEDGE SYST
   Stock O., 1997, Spatial and Temporal Reasoning
   Straccia U, 2001, J ARTIF INTELL RES, V14, P137, DOI 10.1613/jair.813
   VANHARMELEN F, 2003, OWL WEB ONTOLOGY LAN
   VILA L, 1994, AI COMMUN, V7, P4
   WESSEL M, 2005, P INT WORKSH DESCR L
   Woods W.A., 1975, What's in a link: Foundations for semantic networks, P35
   WOODS WA, 1992, SEMANTIC NETWORKS AR, P133
   Yelland P.M., 2000, Proceedings KR-2000, P225
NR 61
TC 70
Z9 71
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 82
EP 101
DI 10.1016/j.imavis.2007.08.013
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100008
DA 2024-07-18
ER

PT J
AU Kleindienst, J
   Macek, T
   Serédi, L
   Sedivy, J
AF Kleindienst, Jan
   Macek, Tomas
   Seredi, Ladislav
   Sedivy, Jan
TI Interaction framework for home environment using speech and vision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multi-modal; computer-vision; context-aware; speech recognition
AB In this article we describe an interaction framework that uses speech recognition and computer-vision to model new generation of interfaces in the residential environment. We outline the blueprints of the architecture and describe the main building blocks. We show a concrete prototype platform where this novel architecture has been deployed and tested at the user field trials. The work is co-funded by EC as part of "HomeTalk" IST-2001-33507 project. (C) 2006 Elsevier B.V. All rights reserved.
C1 IBM Ceska Republika Voice Technol & Syst, V Parku 229414, Czech Republic.
C3 International Business Machines (IBM)
RP Kleindienst, J (corresponding author), IBM Ceska Republika Voice Technol & Syst, Praha 10 CHodov, V Parku 229414, Czech Republic.
EM jankle@cz.ibm.com; tomas_macek@cz.ibm.com; ladislav_seredi@cz.ibm.com;
   jan_sedivy@cz.ibm.com
RI Sedivy, Jan/AAF-2693-2019
CR [Anonymous], OXYGEN PROJECT
   [Anonymous], CONTEXT TOOLKIT
   *AP, AP PROJ
   *AST, AST PROJ
   CALVARY G, 2001, HCT 2001 IHM 2001, P349
   Carroll J., 2002, Human-computer interaction in the new millennium
   COHEN M, 1997, NATURE SCI SOC, V5, P31
   KLEINDIENST J, 2003, SPRINGER INT J
   MCALESTER D, 2002, SKIP INTRO FLASH USA
   OVIATT S, 2000, 10 MYTHS MULTIMODEL
   Pascoe J, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P92, DOI 10.1109/ISWC.1998.729534
   RAMASWAMY G, 1999, PERVASIVE CONVERSATI
   ROSSLER H, 2001, INT WORKSH INF PRES
   ROTH J, 2002, PATTERNS MOBILE INTE, V6
   SCHILIT WN, 1994, IEEE WORKSH MOB COMP, P85
   WANT R, 1992, ACM T INFORM SYST, V10, P91, DOI 10.1145/128756.128759
   Weiss S., 2002, HANDHELD USABILITY
   VOICEXML 2 0
   TINYXML DOCUMENTATIO
   OPENCV PROJECT
   MULTIMODAL REQUIREME
NR 21
TC 1
Z9 1
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 3
PY 2007
VL 25
IS 12
BP 1836
EP 1847
DI 10.1016/j.imavis.2006.04.026
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220BD
UT WOS:000250131000002
DA 2024-07-18
ER

PT J
AU Oliveira, R
   Xavier, J
   Costeira, JP
AF Oliveira, R.
   Xavier, J.
   Costeira, J. P.
TI Multi-view correspondence by enforcement of rigidity constraints
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multi-view correspondence; feature matching; factorization; constrained
   optimization; point correspondence; structure from motion; factorization
   method
AB Establishing the correct correspondence between features in an image set remains a challenging problem amongst computer vision researchers. In fact, the combinatorial nature of feature matching effectively hinders the solution of large scale problems, which have direct applications in important areas such as 3D reconstruction and tracking.
   The solution is obtained by imposing a geometric constraint - rigidity - that selects the matching solution resulting in a rank-4 observation matrix. Since this is a global criterion, issues usually associated to local matching algorithms (such as the aperture problem) do not present an obstacle in this case. The use of a geometric constraint of this type assumes that all feature points are visible in every image, so as to obtain a complete observation matrix.
   The rank of the observation matrix is a function of the matching solutions associated to each image and as such a simultaneous solution for all frames has to be found. For each frame, correspondence is modeled through a permutation matrix, which also allows for the rejection of wrong candidates.
   Although each image is matched individually, an iterative algorithm is used to integrate correspondence information associated to all remaining images. Each individual matching process results in a linear problem: the reduced computational complexity allows the solution of large problems in an acceptable time interval. Although the algorithm has intrinsically been designed for calibrated systems, some instances of the uncalibrated case can also be solved provided a convenient bootstrap is available. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Tecn Lisboa, Inst Sistemas & Robot, Inst Super Tecn, P-1049001 Lisbon, Portugal.
C3 Universidade de Lisboa
RP Oliveira, R (corresponding author), Univ Tecn Lisboa, Inst Sistemas & Robot, Inst Super Tecn, Av Rovisco Pais, P-1049001 Lisbon, Portugal.
EM rco@isr.ist.utl.pt; jxavier@isr.ist.utl.pt; jpc@isr.ist.uti.pt
RI Costeira, Joao P/D-8157-2013; Xavier, Joao/R-4294-2016; Oliveira,
   Ricardo/B-7407-2018
OI Costeira, Joao P/0000-0001-6769-2935; Xavier, Joao/0000-0002-9669-8532;
   Oliveira, Ricardo/0000-0001-7307-560X
CR FAZEL M, 2001, P ACC
   FERRARI V, 2003, P ICCV
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5
   IRANI M, 2000, P ECCV
   IRANI M, 1998, IEEE T PATT AN MACH, V20
   IRANI M, 1999, P ICCV
   Kolmogorov V., 2002, P ECCV
   LUCAS B, 1981, P 7 INT JOINT C AI
   Lutkepohl H., 1996, HDB MATRICES
   Ma Y, 2004, INT J COMPUT VISION, V59, P115, DOI 10.1023/B:VISI.0000022286.53224.3d
   MACIEL J, 2003, IEEE T PATT AN MACH, V25
   MARTINEC D, 2005, P CVPR
   MCREYNOLDS D, 1996, IEEE T PATT AN MACH, V18
   OLIVEIRA R, 2005, P 3DIM
   OLIVEIRA R, 2005, P CVPR
   Poelman C.J., 1994, PROC 3 EUROPEAN C CO, P97
   ROY S, 1998, P ICCV
   SHAFIQUE K, 2003, P ICCV
   Sturm P., 1996, EUROPEAN C COMPUTER, P709, DOI DOI 10.1007/3-540-61123-1
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Wolsey L.A., 1999, WIL INT S D
NR 23
TC 2
Z9 3
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 1008
EP 1020
DI 10.1016/j.imavis.2006.07.013
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600021
DA 2024-07-18
ER

PT J
AU van der Weken, D
   Nachtegael, M
   Kerre, E
AF van der Weken, Dietrich
   Nachtegael, Mike
   Kerre, Etienne
TI Combining neighbourhood-based and histogram similarity measures for the
   design of image quality measures
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE fuzzy similarity measures; image quality evaluation
AB In this paper, we will show how fuzzy similarity measures are used in establishing measures for image quality evaluation. Similarity measures, originally introduced to express the degree of comparison between two fuzzy sets, can be applied to digital images. We will show how neighbourhood-based similarity measures and histogram similarity measures can be combined in order to improve the perceptive behaviour of these similarity measures. In this way, we obtained several new image quality measures, which outperform the Mean Squared Error in the sense of image quality evaluation because the results of the new measures coincide better with human perception. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Ghent, Dept Appl Math & Comp Sci, Fuzziness & Uncertainty Modelling Res Unit, B-9000 Ghent, Belgium.
C3 Ghent University
RP van der Weken, D (corresponding author), Univ Ghent, Dept Appl Math & Comp Sci, Fuzziness & Uncertainty Modelling Res Unit, Krijgslaan 281 Bldg S9, B-9000 Ghent, Belgium.
EM dietrich.vanderweken@ugent.be; mike.nachtegael@ugent.be;
   etienne.kerre@ugent.be
RI cai, bo/G-1491-2010
CR Ahumada Albert J. Jr., 1993, P141
   Avcibas I, 2002, J ELECTRON IMAGING, V11, P206, DOI 10.1117/1.1455011
   BouchonMeunier B, 1996, FUZZY SET SYST, V84, P143, DOI 10.1016/0165-0114(96)00067-X
   CHEN SM, 1995, FUZZY SET SYST, V72, P79, DOI 10.1016/0165-0114(94)00284-E
   CHEN SM, 1995, FUZZY SET SYST, V74, P217, DOI 10.1016/0165-0114(94)00339-9
   Cornelis C, 2003, FUZZY SET SYST, V134, P283, DOI 10.1016/S0165-0114(02)00225-7
   De Cock M, 2003, FUZZY SET SYST, V133, P137, DOI 10.1016/S0165-0114(02)00239-7
   DEBAETS B, P EUSFLAT 2002 2 C E, P249
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Fan JL, 1999, FUZZY SET SYST, V101, P403, DOI 10.1016/S0165-0114(97)00108-5
   Girod Bernd, 1993, P207
   Jou FD, 2004, PATTERN RECOGN LETT, V25, P277, DOI 10.1016/j.patrec.2003.10.005
   Kamarainen JK, 2003, PATTERN RECOGN LETT, V24, P2009, DOI 10.1016/S0167-8655(03)00039-4
   Klein Stanley A., 1993, P73
   Kriete A, 2001, SCANNING, V23, P313, DOI 10.1002/sca.4950230504
   Kullback S., 1959, STAT INFORM THEORY
   LIU XC, 1992, FUZZY SET SYST, V52, P305, DOI 10.1016/0165-0114(92)90239-Z
   NILL NB, 1985, IEEE T COMMUN, V33, P551, DOI 10.1109/TCOM.1985.1096337
   PAL NR, 1993, INFORM SCIENCES, V67, P209, DOI 10.1016/0020-0255(93)90073-U
   PAPPIS CP, 1993, FUZZY SET SYST, V56, P171, DOI 10.1016/0165-0114(93)90141-4
   PAPPIS CP, 1991, FUZZY SET SYST, V39, P111, DOI 10.1016/0165-0114(91)90070-7
   Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Van der Weken D, 2003, FRONT ARTIF INTEL AP, V104, P878
   Van der Weken D, 2003, LECT NOTES ARTIF INT, V2715, P396
   Van der Weken D, 2002, INT CONF ACOUST SPEE, P3317
   VANDERWEKEN D, 2001, INTELLECTUAL SYSTEMS, V5, P231
   WANG XZ, 1995, FUZZY SET SYST, V73, P259, DOI 10.1016/0165-0114(94)00308-T
   Watson A.B., 1993, DIGITAL IMAGES HUMAN, P179
   Watson A. B., 1993, DIGITAL IMAGES HUMAN
   ZADEH LA, 1971, INFORM SCIENCES, V3, P177, DOI 10.1016/S0020-0255(71)80005-1
   Zhou H, 2002, VIS 2002: IEEE VISUALIZATION 2002, PROCEEDINGS, P315, DOI 10.1109/VISUAL.2002.1183790
   Zwick R., 1987, International Journal of Approximate Reasoning, V1, P221, DOI 10.1016/0888-613X(87)90015-6
NR 33
TC 12
Z9 13
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 184
EP 195
DI 10.1016/j.imavis.2006.01.032
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700007
DA 2024-07-18
ER

PT J
AU Wang, HN
   Oliveira, MM
AF Wang, Hanning
   Oliveira, Manuel M.
TI Filling holes on locally smooth surfaces reconstructed from point clouds
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE hole filling; surface reconstruction; moving least squares; 3D scanners
AB Creating models of real scenes is a complex task for which the use of traditional modeling techniques is inappropriate. For this task, laser rangefinders are frequently used to sample the scene from several viewpoints, with the resulting range images integrated into a final model. In practice. due to surface reflectance properties, occlusions and accessibility limitations, certain areas of the scenes are usually not sampled, leading to holes and introducing undesirable artifacts in the resulting models. We present an algorithm for filling holes on surfaces reconstructed from point clouds. The algorithm is based on moving least squares and can interpolate both geometry and shading information. The reconstruction process is mostly automatic and the sampling rate of the given samples is preserved in the reconstructed areas. We demonstrate the use of the algorithm on both real and synthetic datasets to obtain complete geometry and plausible shading. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Fed Rio Grande do Sul, Inst Informat, BR-91501970 Porto Alegre, RS, Brazil.
   SUNY Stony Brook, Ctr Visual Comp, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 Universidade Federal do Rio Grande do Sul; State University of New York
   (SUNY) System; State University of New York (SUNY) Stony Brook
RP Oliveira, MM (corresponding author), Univ Fed Rio Grande do Sul, Inst Informat, Av Bento Goncalves 9500, BR-91501970 Porto Alegre, RS, Brazil.
EM jianning@cs.sunysb.edu; oliveira@inf.ufrgs.br
RI Menezes de Oliveira Neto, Manuel/H-1508-2011
OI Menezes de Oliveira Neto, Manuel/0000-0003-4957-9984
CR Alexander M, 2001, INTERNETWEEK, P21
   Amenta N., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P415, DOI 10.1145/280814.280947
   [Anonymous], 1986, Curve and Surface Fitting: An Introduction
   [Anonymous], INT C VIS IM IM PROC
   Bajaj ChandrajitL., 1995, Proc. Conf. on Computer graphics and interactive techniques, P109
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Besl PJ., 1989, ADV MACHINE VISION, P1
   BOISSONNAT JD, 1984, ACM T GRAPHIC, V3, P266, DOI 10.1145/357346.357349
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Clarenz U, 2004, COMPUT AIDED GEOM D, V21, P427, DOI 10.1016/j.cagd.2004.02.004
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Davis J, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P428, DOI 10.1109/TDPVT.2002.1024098
   Dinh HQ, 2002, IEEE T PATTERN ANAL, V24, P1358, DOI 10.1109/TPAMI.2002.1039207
   EDELSBRUNNER H, 1994, ACM T GRAPHIC, V13, P43, DOI 10.1145/174462.156635
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   GOPI M, 2000, INT J HIGH PERFORM C, V1, P1
   Hoppe Hugues, 1992, P SIGGRAPH 92, P71, DOI DOI 10.1145/133994.134011
   Ju T, 2004, ACM T GRAPHIC, V23, P888, DOI 10.1145/1015706.1015815
   Ju T, 2002, ACM T GRAPHIC, V21, P339
   Liepa P., 2003, Symposium on Geometry Processing, P200
   Lorensen W.E., 1987, P 14 ANN C COMP GRAP, P163
   McAllister DK, 1999, SPRING EUROGRAP, P145
   MENCL R, 1995, P EUR 95 COMP GRAPH, V14, P445
   Morse BS, 2001, INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDING, P89, DOI 10.1109/SMA.2001.923379
   Nyland L, 1999, IEEE WORKSHOP ON MULTI-VIEW MODELING & ANALYSIS OF VISUAL SCENES (MVIEW'99). PROCEEDINGS, P3, DOI 10.1109/MVIEW.1999.781077
   Ohtake Y, 2003, ACM T GRAPHIC, V22, P463, DOI 10.1145/882262.882293
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Savchenko V, 2002, ADVANCES IN MODELLING, ANIMATION AND RENDERING, P139
   SAVCHENKO VV, 1995, COMPUT GRAPH FORUM, V14, P181, DOI 10.1111/1467-8659.1440181
   SCARLOFF S, 1991, P SIGGRAPH 91, P247
   Sharf A, 2004, ACM T GRAPHIC, V23, P878, DOI 10.1145/1015706.1015814
   TERZOPOULOS D, 1991, IEEE T PATTERN ANAL, V13, P703, DOI 10.1109/34.85659
   Turk G., 1999, VARIATIONAL IMPLICIT
   Verdera J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P903
   Wang DN, 2003, XVI BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P11
   WANG J, 2002, P EUROGRAPHICS 2002, P521
   Wei LY, 2001, COMP GRAPH, P355, DOI 10.1145/383259.383298
   Xie H, 2003, IEEE VISUALIZATION 2003, PROCEEDINGS, P91, DOI 10.1109/VISUAL.2003.1250359
   Ying LI, 2001, SPRING EUROGRAP, P301
   Yu YZ, 2001, IEEE T VIS COMPUT GR, V7, P351, DOI 10.1109/2945.965349
NR 41
TC 70
Z9 85
U1 3
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 103
EP 113
DI 10.1016/j.imavis.2005.12.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600012
DA 2024-07-18
ER

PT J
AU Pareek, NK
   Patidar, V
   Sud, KK
AF Pareek, N. K.
   Patidar, Vinod
   Sud, K. K.
TI Image encryption using chaotic logistic map
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image cipher; chaotic cryptography; logistic map
ID SCHEME; ALGORITHM
AB In recent years, the chaos based cryptographic algorithms have suggested some new and efficient ways to develop secure image encryption techniques. In this communication, we propose a new approach for image encryption based on chaotic logistic maps in order to meet the requirements of the secure image transfer. In the proposed image encryption scheme, an external secret key of 80-bit and two chaotic logistic maps are employed. The initial conditions for the both logistic maps are derived using the external secret key by providing different weightage to all its bits. Further, in the proposed encryption process, eight different types of operations are used to encrypt the pixels of an image and which one of them will be used for a particular pixel is decided by the outcome of the logistic map. To make the cipher more robust against any attack, the secret key is modified after encrypting each block of sixteen pixels of the image. The results of several experimental, statistical analysis and key sensitivity tests show that the proposed image encryption scheme provides an efficient and secure way for real-time image encryption and transmission. (c) 2006 Elsevier B.V. All rights reserved.
C1 MLS Univ, Dept Phys, Udaipur 313002, Rajasthan, India.
   MLS Univ, Ctr Comp, Udaipur 313002, Rajasthan, India.
C3 Mohanlal Sukhadia University; Mohanlal Sukhadia University
RP Sud, KK (corresponding author), MLS Univ, Dept Phys, Coll Sci Campus, Udaipur 313002, Rajasthan, India.
EM kksud@yahoo.com
RI Patidar, Vinod/G-5906-2010
OI Patidar, Vinod/0000-0002-1270-3454
CR BOURBAKIS N, 1992, PATTERN RECOGN, V25, P567, DOI 10.1016/0031-3203(92)90074-S
   Chang CC, 2001, J SYST SOFTWARE, V58, P83, DOI 10.1016/S0164-1212(01)00029-2
   Chang HKC, 1997, SIGNAL PROCESS-IMAGE, V10, P279, DOI 10.1016/S0923-5965(96)00025-2
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Cheng H, 2000, IEEE T SIGNAL PROCES, V48, P2439, DOI 10.1109/78.852023
   Fridrich J, 1998, INT J BIFURCAT CHAOS, V8, P1259, DOI 10.1142/S021812749800098X
   Li SJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P708
   Li SJ, 2002, PROC SPIE, V4666, P149, DOI 10.1117/12.458527
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   Pareek NK, 2003, PHYS LETT A, V309, P75, DOI 10.1016/S0375-9601(03)00122-1
   REFREGIER P, 1995, OPT LETT, V20, P767, DOI 10.1364/OL.20.000767
   Scharinger J, 1998, J ELECTRON IMAGING, V7, P318, DOI 10.1117/1.482647
   Yen JC, 2000, IEE P-VIS IMAGE SIGN, V147, P167, DOI 10.1049/ip-vis:20000208
   Yen JC, 2000, ISCAS 2000: IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS - PROCEEDINGS, VOL IV, P49, DOI 10.1109/ISCAS.2000.858685
   YEN JC, 1999, P IEEE WORKSH SIGN P, P430
NR 15
TC 814
Z9 874
U1 7
U2 200
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 926
EP 934
DI 10.1016/j.imavis.2006.02.021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200002
DA 2024-07-18
ER

PT J
AU Toledo, GK
   Kussul, E
   Baidyk, T
AF Toledo, Gengis K.
   Kussul, Ernst
   Baidyk, Tatiana
TI Neural classifier for micro work piece recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE neural network; neural classifier; technical vision; object recognition;
   position recognition; microassembly
ID SYSTEM
AB The aim of this article, is to describe a technical vision system for automation of micromanufacturing and microassembly processes. One of the principal problems is connected with the recognition of work pieces and detection of their positions. For this purpose we use neural classifier named limited receptive area (LIRA) grey scale. This classifier was developed for wide range of image recognition tasks. A special software was designed. We describe some experiments and results of application of LIRA in the recognition of micro work pieces and their positions for automated handling system. The best recognition rate obtained was 94%. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Nacl Autonoma Mexico, Lab Micromech & Mechatron, Ctr Ciencias Aplicadas & Desarrollo Tecnol, Mexico City 04510, DF, Mexico.
C3 Universidad Nacional Autonoma de Mexico
RP Toledo, GK (corresponding author), Univ Nacl Autonoma Mexico, Lab Micromech & Mechatron, Ctr Ciencias Aplicadas & Desarrollo Tecnol, Cd Univ AP 70-186, Mexico City 04510, DF, Mexico.
EM gengiskanhg.geo@yahoo.com; ekussul@servidor.unam.mx;
   tbaidyk@aleph.cinstrum.unam.mx
OI Kussul, Ernst/0000-0002-2849-2532; Baydyk, Tetyana/0000-0002-3095-2032
CR Baidyk T, 2004, PATTERN RECOGN LETT, V25, P107, DOI 10.1016/j.patrec.2003.09.005
   BAIDYK T, 2002, P INT JOINT C NEUR N, V1, P160
   Bennamoun M, 1997, IEEE T SYST MAN CY B, V27, P893, DOI 10.1109/3477.650052
   Bleuler H., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P959, DOI 10.1109/ROBOT.2000.844172
   Detter H., 2000, IEEE INT C MICR NIS, P61
   EHRENMANN M, 2000, IEEE INT C ROB AUT S, P1862
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Friedrich CR, 1996, J MICROELECTROMECH S, V5, P33, DOI 10.1109/84.485213
   Jain R., 1995, MACHINE VISION
   Kussul E, 2004, IMAGE VISION COMPUT, V22, P971, DOI 10.1016/j.imavis.2004.03.008
   Kussul E, 2002, J MICROMECH MICROENG, V12, P795, DOI 10.1088/0960-1317/12/6/311
   KUSSUL E, 2002, INT S MICR HUM SCI N, V20, P125
   Mardanov S, 1999, COMPUT IND, V38, P93, DOI 10.1016/S0166-3615(98)00111-0
   Mitzias DA, 2004, MEASUREMENT, V36, P315, DOI 10.1016/j.measurement.2004.09.008
   OFEIFER T, 2002, IEEE INT S MICR HUM, P117
   OOYAMA N, 2000, P 2 INT WORKSH MICR, P14
   RadjenovicMrcarica J, 1997, J INTELL MANUF, V8, P191, DOI 10.1023/A:1018569123830
   Rossenblatt F., 1962, PRINCIPLES NEURODYNA
   Simard PY, 2003, PROC INT CONF DOC, P958
   STEINHAUS P, 1997, THESIS U KARLSRUHE G
   SUNHO L, 1999, IEEE TENCON, P479
   TOLEDO GK, 2004, 7 ALL UKR INT C SIGN, P17
NR 22
TC 5
Z9 5
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 827
EP 836
DI 10.1016/j.imavis.2006.02.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100004
DA 2024-07-18
ER

PT J
AU Villanueva, A
   Cabeza, R
   Porta, S
AF Villanueva, Arantxa
   Cabeza, Rafael
   Porta, Sonia
TI Eye tracking: Pupil orientation geometrical modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE gaze tracking; eye tracking; eye movement modeling; calibration
ID LAW
AB Lately eye tracking system development and applications are becoming increasingly interesting. Efforts in eye tracking research cover a broad spectrum of fields, being mathematical modeling an important aspect and probably-one of the least explored topics. In order to build up a robust and efficient model a deep mathematical review of the geometry and the intrinsic nature of eye tracking systems is needed. Video-oculography represents one of the most popular eye tracking methods due to its non-intrusive nature. The images acquired from user eye are analyzed in order to identify some selected features, and through a calibration process the parameters of a model are adjusted for each user. This paper tries to accomplish the first step of a more extensive model and presents a simple expression for pupil orientation based on framework physical parameters. The proposed model requires alternative calibration strategies depending on the number of parameters employed to obtain an efficient behavior. It exhibits lower errors than other generic mathematical expressions, which normally need more calibration points to construct a competent model. The paper starts modeling a whole video-oculographic system and once the model is derived, the work addresses different simplification ways in order to obtain a simpler and more efficient form. Lastly an experimental validation is provided. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Publ Navarra, Dept Elect & Elect Engn, E-31006 Pamplona, Spain.
C3 Universidad Publica de Navarra
RP Villanueva, A (corresponding author), Univ Publ Navarra, Dept Elect & Elect Engn, Campus Arrosadia S-N, E-31006 Pamplona, Spain.
EM avilla@unavarra.es
RI Cabeza, Rafael/D-8236-2012; Villanueva, Arantxa/M-1641-2014
OI Cabeza, Rafael/0000-0001-7999-1182; Villanueva,
   Arantxa/0000-0001-9822-2530
CR Beymer D, 2003, PROC CVPR IEEE, P451
   Blanco Y., 1998, P 5 INT C SPOK LANG
   BOEHM W, 1986, GEOMETRIC CONCEPTS G
   Brolly X.L. C., 2004, Proc. of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW'04), V8, P134, DOI DOI 10.1109/CVPR.2004.92
   Carpenter Roger., 1988, Movements of the Eyes, V2
   Duchowski A., 2003, THEORY PRACTICE
   Ebisawa Y., 1993, Proceedings of the 15th Annual Int. Conf. of the IEEE Eng. in Medicine and Biology Society, San Diego, P1268
   FERMAN L, 1987, VISION RES, V27, P929
   FINDLAY J, 2001, P 11 EUR C EY MOV TU
   FRY G, 1947, AM J OPTOMETRY ARCH, P329
   Goñi S, 2004, INT C PATT RECOG, P941, DOI 10.1109/ICPR.2004.1333928
   HANSEN DW, 2004, P ETRA EYE TRACK RES, P58
   Haro A, 2000, PROC CVPR IEEE, P163, DOI 10.1109/CVPR.2000.855815
   JACOB RJK, 1991, ACM T INFORM SYST, V9, P152, DOI 10.1145/123078.128728
   MERCHANT J, 1974, IEEE T BIO-MED ENG, VBM21, P309, DOI 10.1109/TBME.1974.324318
   Morimoto CH, 2000, IMAGE VISION COMPUT, V18, P331, DOI 10.1016/S0262-8856(99)00053-0
   NAKAYAMA K, 1977, VISION RES, V17, P453, DOI 10.1016/0042-6989(77)90038-4
   Ohno T., 2004, Proc. ACM Symp. Eye Tracking Res. Appl, V22, P115, DOI [DOI 10.1145/968363.968387, 10.1145/968363.968387]
   OTT D, 1990, J NEUROSCI METH, V35, P229, DOI 10.1016/0165-0270(90)90128-3
   RABETTS RB, 1998, BENNETT RABBETTS CLI
   Ramloll R., 2004, ACM SIGCHI EYE TRACK, P19, DOI [10.1145/968363, DOI 10.1145/968363]
   Shih SW, 2004, IEEE T SYST MAN CY B, V34, P234, DOI 10.1109/TSMCB.2003.811128
   SKABURSKIS A, 2004, P EY TRACK RES APPL, P101
   TOMONO A, 1989, OPTICS ILLUMINATION, V4, P2
   VILLANUEVA A, 2001, P 11 EUR C EY MOV TU
   Villanueva Arantxa, 2004, Proceedings of the 2004 symposium on Eye tracking research applications, P55
   YOO D, 2001, P IEEE INT C AUT FAC, P785
   YOUNG LR, 1975, BEHAV RES METH INSTR, V7, P397, DOI 10.3758/BF03201553
NR 28
TC 27
Z9 32
U1 1
U2 27
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 663
EP 679
DI 10.1016/j.imavis.2005.06.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400003
DA 2024-07-18
ER

PT J
AU Zhou, FQ
   Zhang, GJ
AF Zhou, FQ
   Zhang, GJ
TI Complete calibration of a structured light stripe vision sensor through
   planar target of unknown orientations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE structured light; calibration; control points; planar target; vision
   inspection
AB Structured light 3D vision inspection is a commonly used method for various 3D surface profiling techniques. In this paper, the mathematical model of the structured light stripe vision sensor is established. We propose a flexible new approach to easily determine all primitive parameters of a structured light stripe vision sensor. It is well suited for use without specialized knowledge of 3D geometry. The technique only requires the sensor to observe a planar target shown at a few (at least two) different orientations. Either the sensor or the planar target can be freely moved. The motion need not be known. A novel approach is proposed to generate sufficient non-collinear control points for structured light stripe vision sensor calibration. Real data has been used to test the proposed technique, and very good result has been obtained. Compared with classical techniques, which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. It advances structured light vision one step from laboratory environments to real engineering 3D metrology applications. (C) 2004 Elsevier B.V. All rights reserved.
C1 Beijing Univ Aeronaut & Astronaut, Sch Instrument Sci & Optoelect Engn, Beijing 100083, Peoples R China.
C3 Beihang University
RP Beijing Univ Aeronaut & Astronaut, Sch Instrument Sci & Optoelect Engn, Beijing 100083, Peoples R China.
EM fuqiang_zhou@yahoo.com
RI cai, bo/G-1491-2010
CR Chang M, 1995, OPT ENG, V34, P3572, DOI 10.1117/12.215483
   CHEN CH, 1987, P IEEE C ROB AUT, V2, P807
   Dear R, 1988, Society of Manufacturing Engineers, P5
   DENG W, 1999, CHINESE J HUAZHONG U, V37, P79
   Duan Fajie, 2000, Chinese Journal of Scientific Instrument, V21, P108
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Heikkila J, 1996, P 13 INT C PATT REC, V1, P166
   Huynh DQ, 1999, INT J COMPUT VISION, V33, P73, DOI 10.1023/A:1008117315311
   JAMES KW, 1988, P AUT 88 C, V12, P9
   JARVIS R, 1993, ADV IMAGE COMMUN, V1, P17
   JARVIS RA, 1983, IEEE T PATTERN ANAL, V5, P122, DOI 10.1109/TPAMI.1983.4767365
   JONES BF, 1995, IEEE T BIO-MED ENG, V42, P464, DOI 10.1109/10.376150
   McIvor AM, 2002, OPT ENG, V41, P205, DOI 10.1117/1.1416694
   Melen T., 1994, THESIS NORWEGIAN U S
   Mouaddib E, 1997, IEEE INT CONF ROBOT, P130, DOI 10.1109/ROBOT.1997.620027
   Reid ID, 1996, IMAGE VISION COMPUT, V14, P659, DOI 10.1016/0262-8856(96)84490-8
   SHIRAI Y, 1971, P 2 INT JOINT C ART, P81
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Xu Guangyou, 1995, Chinese Journal of Computers, V18, P450
   Zhang Guangjun, 2002, Chinese Journal of Scientific Instrument, V23, P31
   Zhang YM, 1997, J MANUF SCI E-T ASME, V119, P151, DOI 10.1115/1.2831090
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 22
TC 159
Z9 216
U1 7
U2 77
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2005
VL 23
IS 1
BP 59
EP 67
DI 10.1016/j.imavis.2004.07.006
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 882BO
UT WOS:000225913700006
DA 2024-07-18
ER

PT J
AU Rieger, B
   vanVliet, LJ
AF Rieger, B
   vanVliet, LJ
TI A systematic approach to <i>n</i>D orientation representation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE gradient structure tenser; Knutsson mapping; continuous orientation
   representation; local structure
ID ORIENTED PATTERNS; CURVATURE; CURVES
AB In this paper, we present new insights in methods to solve the orientation representation problem in arbitrary dimensions. The gradient structure tensor is one of the most used descriptors for local structure in multi-dimensional images. We will relate its properties to the double angle method (2D) and the Knutsson mapping. We present a general scheme to reduce the dimensionality of the Knutsson mapping and derive some properties of these reduced mappings. (C) 2003 Elsevier B.V. All rights reserved.
C1 Delft Univ Technol, Dept Appl Phys, Pattern Recognit Grp, NL-2628 CJ Delft, Netherlands.
C3 Delft University of Technology
RP Delft Univ Technol, Dept Appl Phys, Pattern Recognit Grp, Lorentzweg 1, NL-2628 CJ Delft, Netherlands.
EM bernd@ph.tn.tudelft.nl; lucas@ph.tn.tudelft.nl
RI van Vliet, Lucas/E-1678-2012
OI van Vliet, Lucas/0000-0001-7018-726X
CR [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], 1999, Taschenbuch der Mathematik
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433
   BISHOP CM, 1909, NEURAL NETWORKS PATT
   Jahne B., 1997, DIGITAL IMAGE PROCES
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0
   KNUTSSON H, 1989, 6 SCAND C IM AN OUL, P244
   KNUTSSON H, 1985, IEEE COMP SOC WORKSH, P175
   Larkin KG, 2001, J OPT SOC AM A, V18, P1871, DOI 10.1364/JOSAA.18.001871
   Lee MS, 1999, COMPUT VIS IMAGE UND, V76, P54, DOI 10.1006/cviu.1999.0787
   Rieger B, 2002, IEEE T IMAGE PROCESS, V11, P738, DOI 10.1109/TIR2002.800885
   RIEGER B, 2003, IN PRESS IEEE T PATT
   SCHECK F, 1999, MECH NEWTONS LAW DET
   van de Weijer J, 2001, IEEE T PATTERN ANAL, V23, P1035, DOI 10.1109/34.955116
   van den Doel LR, 2001, APPL OPTICS, V40, P4487, DOI 10.1364/AO.40.004487
   VANKEMPEN GMP, 1999, SCIA 99, P447
   VERBEEK PW, 1993, COMMUNICATION
   VROOMAN HA, 1991, THESIS DELFT U TECHN
   [No title captured]
NR 21
TC 14
Z9 15
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2004
VL 22
IS 6
BP 453
EP 459
DI 10.1016/j.imavis.2003.11.005
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 817HB
UT WOS:000221167500002
DA 2024-07-18
ER

PT J
AU de Trazegnies, C
   Urdiales, C
   Bandera, A
   Sandoval, F
AF de Trazegnies, C
   Urdiales, C
   Bandera, A
   Sandoval, F
TI A Hidden Markov Model object recognition technique for incomplete and
   distorted corner sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Symposium on Probabilistic Models in Computer Vision
CY MAY, 2001
CL ENGLAND
SP British Mach Vis, Royal Stat Sov
DE 2D object recognition; Hidden Markov Models
ID CHARACTER-RECOGNITION; MOMENT INVARIANTS; CLASSIFICATION; ALGORITHM;
   SHAPES; CURVES; SPACE; OCR
AB This paper presents a new technique for planar object recognition based on Hidden Markov Models. First, the contour of the object is processed to extract a sequence of high curvature points. These points are extracted from a new adaptively extracted curvature function which is resistant against noise and transformations. Each corner is characterized by its subtended angle and its distance to the next corner. Then, corner sequences are analyzed by using HMMs. The method has been successfully tested for different databases. Its main advantage is that it can deal with incomplete and distorted corner sequences. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Malaga, ETSI Telecommun, Dpto Tecnol Elect, E-29071 Malaga, Spain.
C3 Universidad de Malaga
RP de Trazegnies, C (corresponding author), Univ Malaga, ETSI Telecommun, Dpto Tecnol Elect, Campus Teatinos S-N, E-29071 Malaga, Spain.
RI Bandera, Antonio/H-2111-2015; Urdiales, Cristina/H-4664-2019; Sandoval,
   Francisco/B-4487-2016
OI Bandera, Antonio/0000-0003-3147-0307; Urdiales,
   Cristina/0000-0002-9251-6447; Trazegnies, Carmen de/0000-0002-6756-5087;
   Sandoval, Francisco/0000-0001-9235-7856
CR AAS K, 1995, LECT NOTES COMPUTER, V970, P503
   Agam G, 1997, IEEE T PATTERN ANAL, V19, P1212, DOI 10.1109/34.632981
   Amit Y, 1997, IEEE T PATTERN ANAL, V19, P1300, DOI 10.1109/34.632990
   ANSARI N, 1991, PATTERN RECOGN, V24, P441, DOI 10.1016/0031-3203(91)90057-C
   Arrebola F, 1999, ELECTRON LETT, V35, P1065, DOI 10.1049/el:19990764
   BAILEY RR, 1996, IEEE T PATTERN ANAL, V18, P369
   Bandera A, 2000, ELECTRON LETT, V36, P124, DOI 10.1049/el:20000177
   BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   BOKSER M, 1992, P IEEE, V80, P1066, DOI 10.1109/5.156470
   Chang FS, 2000, ELECTRON LETT, V36, P126, DOI 10.1049/el:20000149
   CHEIKH FA, 2000, P 7 INT C EL CIRC SY, P461
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   HE Y, 1991, IEEE T PATTERN ANAL, V13, P1172, DOI 10.1109/34.103276
   Hornegger J, 1997, LECT NOTES COMPUT SC, V1223, P311
   Huet B, 1999, PATTERN RECOGN LETT, V20, P1259, DOI 10.1016/S0167-8655(99)00093-8
   KIMURA F, 1991, PATTERN RECOGN, V24, P969, DOI 10.1016/0031-3203(91)90094-L
   LINDEBERG T, 1990, IEEE T PATTERN ANAL, V12, P234, DOI 10.1109/34.49051
   LIU R, 1998, PATTERN RECOGN, V19, P279
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468
   Park J, 2000, IEEE T PATTERN ANAL, V22, P400, DOI 10.1109/34.845383
   PAVLIDIS T, 1986, COMPUT VISION GRAPH, V35, P111, DOI 10.1016/0734-189X(86)90128-3
   PEEREZ JY, 1994, PATTERN RECOGN, V15, P743
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   RAMESH SR, 1989, PATTERN RECOGN, V22, P347, DOI 10.1016/0031-3203(89)90043-5
   REISS TH, 1991, IEEE T PATTERN ANAL, V13, P830, DOI 10.1109/34.85675
   ROCHA J, 1994, IEEE T PATTERN ANAL, V16, P393, DOI 10.1109/34.277592
   Rosin PL, 1996, GRAPH MODEL IM PROC, V58, P286, DOI 10.1006/gmip.1996.0023
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
   SINGH S, 1996, P 13 INT C PATT REC, V3, P145
   TAXT T, 1990, PATTERN RECOGN, V23, P1155, DOI 10.1016/0031-3203(90)90113-Y
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   ZHU PF, 1995, IEEE T PATTERN ANAL, V17, P737, DOI 10.1109/34.400564
NR 33
TC 4
Z9 4
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2003
VL 21
IS 10
BP 879
EP 889
DI 10.1016/S0262-8856(03)00074-X
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 723KU
UT WOS:000185432200005
DA 2024-07-18
ER

PT J
AU Katajamäki, J
AF Katajamäki, J
TI Methods for gamma invariant colour image processing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE gamma; image normalization; colour image enhancement; neural network
ID RETRIEVAL; ENHANCEMENT
AB This article presents methods for normalizing natural RGB images with respect to the group of gamma adjustments. Applications of the normalization include image enhancement and gamma invariant indexing. By utilizing the logarithmic domain it is possible to define both histogram-based and spatially based normalization methods involving operations that commute with gamma, which is an essential benefit in practical algorithms. The normalization can be refined using a neural network or other empirically optimized system in a way consistent with the normalization principle. It is also possible to perform normalization simultaneously with respect to gamma and linear scaling. Four algorithms were tested using a set of over 3600 images. The average ratio between the computed gamma values and subjective optimum gammas was less than 1.3 for the best algorithm, which utilized a neural network. The gamma invariance of the algorithms and their stability under perturbations were good except in the presence of zero values, at which the logarithm is singular. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Aalto Univ, Dept Automat & Syst Technol, FIN-02015 Helsinki, Finland.
C3 Aalto University
RP Aalto Univ, Dept Automat & Syst Technol, POB 6400, FIN-02015 Helsinki, Finland.
EM juha.katajamaki@hut.fi
CR ALKOFER JS, 1988, Patent No. 4731671
   Androutsos D, 1999, COMPUT VIS IMAGE UND, V75, P46, DOI 10.1006/cviu.1999.0767
   [Anonymous], 1999, 6196621 IEC
   BHUKHANWALA SA, 1994, IEEE T CONSUM ELECTR, V40, P1, DOI 10.1109/30.273657
   Boyack JR, 1998, IMAGE PROCESSING IMAGE QUALITY IMAGE CAPTURE SYSTEMS CONFERENCE, P395
   Cardei VC, 2000, J IMAGING SCI TECHN, V44, P288
   CHOCHIA PA, 1994, P SOC PHOTO-OPT INS, V2363, P82
   Demuth H., 2003, NEURAL NETWORK TOOLB
   Eschbach R, 2000, P SOC PHOTO-OPT INS, V3963, P178
   ESCHBACH R, 1995, Patent No. 5450502
   Farid H, 2001, IEEE T IMAGE PROCESS, V10, P1428, DOI 10.1109/83.951529
   Finlayson G., 2001, BRIT MACHINE VISION, P303
   HYODO M, 2000, Patent No. 6018589
   JASPERS C, 1998, Patent No. 5734746
   Katajamäki J, 1999, SEVENTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P301
   Kim IJ, 1997, ICICS - PROCEEDINGS OF 1997 INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATIONS AND SIGNAL PROCESSING, VOLS 1-3, P948, DOI 10.1109/ICICS.1997.652119
   LAU SSY, 1994, ELECTRON LETT, V30, P122, DOI 10.1049/el:19940081
   LEE HC, 1998, Patent No. 5822453
   LEVIEN RL, 1993, Patent No. 5544258
   LIN Q, 1998, Patent No. 5812286
   Mann S, 2000, IEEE T IMAGE PROCESS, V9, P1389, DOI 10.1109/83.855434
   POYNTON CA, 1996, INTRO DIGITAL VIDEO, pCH6
   SCHWARTZ MS, 1995, Patent No. 5426517
   Siebert A, 2001, PATTERN RECOGN LETT, V22, P249, DOI 10.1016/S0167-8655(00)00107-0
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SUKANYA P, 1998, IEEE INT C COMP VIS, V1, P221
   WINKELMAN KH, 1998, Patent No. 5748802
NR 27
TC 3
Z9 3
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2003
VL 21
IS 6
BP 527
EP 542
DI 10.1016/S0262-8856(03)00033-7
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 688BA
UT WOS:000183411300006
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Huang, S
   Yang, WL
   Tang, WH
   Zhang, XH
   Yang, D
AF Zhang, Yi
   Huang, Sheng
   Yang, Wanli
   Tang, Wenhao
   Zhang, Xiaohong
   Yang, Dan
TI Anchor-based discriminative dual distribution calibration for
   transductive zero-shot learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Zero-shot learning; Transductive learning; Generative adversarial
   network; Image recognition
ID NETWORK
AB Zero-shot learning (ZSL) is machine learning task to recognize samples from classes that are not observed during training. Transductive ZSL (TZSL) is a more realistic and effective paradigm that leverages unlabeled unseen data during training to reduce the bias towards seen classes. However, most existing TZSL methods neglect the information gap between visual and semantic spaces, and thus fail to generate distribution-consistent unseen features. To address this issue, we propose a novel TZSL approach named Anchor-based Discriminative Dual Distribution Calibrated Feature Generative Network (AD3C-FGN), which performs anchor-based distribution calibration in both visual and semantic spaces for improving generalization ability of the model. In AD3C-FGN, we adopt conditional generative adversarial network with an unseen discriminator to construct a Y-shape generation model that mitigates the domain shift problem. Moreover, an AD3C module is elaborated for calibrating the distribution of generated and real samples in both visual and semantic spaces with real sample anchors, and also enhance the discriminability of the generated samples. AD3C enforces the generated sample to be closer to its homogenous anchor but farther away from inhomogeneous anchors in both spaces. Extensive experimental results on six popular ZSL benchmarks demonstrate that our method achieves promising performances in different settings. The source codes of our model have been released onhttps://github.com/ZYi-CQU/AD3C-FGN.
C1 [Zhang, Yi; Huang, Sheng; Yang, Wanli; Tang, Wenhao; Zhang, Xiaohong; Yang, Dan] Chongqing Univ, Sch Big Data & Software Engn, 55 Daxuecheng South Rd, Chongqing 401331, Peoples R China.
   [Huang, Sheng; Zhang, Xiaohong] Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, 174 Shazhengjie, Chongqing 400044, Peoples R China.
C3 Chongqing University; Chongqing University
RP Huang, S (corresponding author), Chongqing Univ, Key Lab Dependable Serv Comp Cyber Phys Soc, Minist Educ, 174 Shazhengjie, Chongqing 400044, Peoples R China.
EM huangsheng@cqu.edu.cn
RI YANG, Dan/HHD-2733-2022; Zhang, Xiaohong/A-3060-2015
FU National Natural Science Foundation of China [cstc2021jcyj-msxmX0568];
   Natural Science Foundation of Chongqing;  [62176030]
FX Reported research is partly supported by the National Natural Science
   Foundation of China under Grant 62176030, and the Natural Science
   Foundation of Chongqing under Grant cstc2021jcyj-msxmX0568.
CR Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chen SM, 2022, AAAI CONF ARTIF INTE, P330
   Chen SM, 2022, PROC CVPR IEEE, P7602, DOI 10.1109/CVPR52688.2022.00746
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Feng YG, 2022, PROC CVPR IEEE, P9336, DOI 10.1109/CVPR52688.2022.00913
   Fu YW, 2018, IEEE SIGNAL PROC MAG, V35, P112, DOI 10.1109/MSP.2017.2763441
   Gao R, 2020, IEEE T IMAGE PROCESS, V29, P3665, DOI 10.1109/TIP.2020.2964429
   Goodfellow I., 2014, arXiv, DOI 10.48550/arXiv.1406.2661
   Guo T, 2022, PATTERN RECOGN LETT, V159, P125, DOI 10.1016/j.patrec.2022.05.009
   Han ZY, 2022, INT J COMPUT VISION, V130, P2606, DOI 10.1007/s11263-022-01656-y
   Huang S, 2020, IEEE SIGNAL PROC LET, V27, P301, DOI 10.1109/LSP.2020.2968213
   Huang S, 2015, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2015.7298638
   Gulrajani I, 2017, ADV NEUR IN, V30
   Kong X, 2022, PROC CVPR IEEE, P9296, DOI 10.1109/CVPR52688.2022.00909
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Li XY, 2022, PROC CVPR IEEE, P9316, DOI 10.1109/CVPR52688.2022.00911
   Li X, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104077
   Liu B, 2021, IEEE T IMAGE PROCESS, V30, P6943, DOI 10.1109/TIP.2021.3100552
   Liu Y, 2023, IEEE T CYBERNETICS, V53, P3794, DOI 10.1109/TCYB.2022.3164142
   Liu Y, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108237
   Liu ZZ, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103924
   Lv FM, 2023, PATTERN RECOGN, V141, DOI 10.1016/j.patcog.2023.109591
   Mall U, 2022, IEEE COMPUT SOC CONF, P3930, DOI 10.1109/CVPRW56347.2022.00438
   Marmoreo F, 2021, IEEE WINT CONF APPL, P3108, DOI 10.1109/WACV48630.2021.00315
   Meenakshi, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104506
   Mercea OB, 2022, PROC CVPR IEEE, P10543, DOI 10.1109/CVPR52688.2022.01030
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Pourpanah F, 2023, IEEE T PATTERN ANAL, V45, P4051, DOI 10.1109/TPAMI.2022.3191696
   Radovanovic M, 2010, J MACH LEARN RES, V11, P2487
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Sariyildiz MB, 2019, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2019.00227
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Srivastava A, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104534
   Su HZ, 2022, PROC CVPR IEEE, P7875, DOI 10.1109/CVPR52688.2022.00773
   Touvron H, 2023, IEEE T PATTERN ANAL, V45, P5314, DOI 10.1109/TPAMI.2022.3206148
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang L, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104548
   Xian YQ, 2019, PROC CVPR IEEE, P10267, DOI 10.1109/CVPR.2019.01052
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328
   Xie GS, 2021, IEEE T IMAGE PROCESS, V30, P4316, DOI 10.1109/TIP.2021.3070231
   Xie GS, 2019, PROC CVPR IEEE, P9376, DOI 10.1109/CVPR.2019.00961
   Xing Y, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102961
   Xu BR, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3142181
   Yang ZQ, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104586
   Ye M, 2017, PROC CVPR IEEE, P5103, DOI 10.1109/CVPR.2017.542
   Ye YL, 2023, IEEE T MULTIMEDIA, V25, P2252, DOI 10.1109/TMM.2022.3145237
   Yuan QL, 2022, IMAGE VISION COMPUT, V120, DOI 10.1016/j.imavis.2022.104400
   Yucel MK, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104392
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang Y, 2020, IEEE C COMP VIS PATT, P12767
NR 58
TC 0
Z9 0
U1 3
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104772
DI 10.1016/j.imavis.2023.104772
EA AUG 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P9FR2
UT WOS:001053666100001
DA 2024-07-18
ER

PT J
AU Yang, XM
   Xiong, SX
   Wu, KW
   Shan, DF
   Xie, Z
AF Yang, Xingming
   Xiong, Sixuan
   Wu, Kewei
   Shan, Dongfeng
   Xie, Zhao
TI Attentive spatial-temporal contrastive learning for self-supervised
   video representation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Self-supervised learning; Spatial-temporal feature; Contrastive
   learning; Spatial-temporal self-attention
AB Most existing self-supervised works learn video representation by using a single pretext task. A single pretext task, providing single supervision from unlabeled data, may neglect to describe the difference between spatial features and temporal features. The similar spatial features and temporal features may hinder distinguishing between two similar videos with different class labels. In this paper, we propose an attentive spatial-temporal contrastive learning network (ASTCNet), which learns self-attention spatial-temporal features by contrastive learning between multiple spatial and temporal pretext tasks. The spatial features are learned by multiple spatial pretext tasks, including spatial rotation, and spatial jigsaw. Each spatial feature is enhanced with spatial selfattention by learning the relation between patches. The temporal features are learned by multiple temporal pretext tasks, including temporal order, and temporal pace. Each temporal feature is enhanced with temporal self-attention by learning the relation between frames, and is enhanced by feeding the optical flow features into a motion module. To separate the spatial feature and the temporal feature learned in one video, we represent the video as different features for each pretext task, and design pretext task-based contrastive loss. The pretext taskbased contrastive loss encourages the different pretext tasks to learn dissimilar features, and encourages the same pretext task to learn similar features. The pretext task-based contrastive loss can learn the discriminative features for each pretext task in one video. The experiments show that our method achieves state-of-the-art performance for self-supervised action recognition on the UCF101 dataset and the HMDB51 dataset.
C1 [Yang, Xingming; Wu, Kewei; Xie, Zhao] Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 230601, Peoples R China.
   [Yang, Xingming; Xiong, Sixuan; Wu, Kewei; Shan, Dongfeng; Xie, Zhao] Hefei Univ Technol, Sch Comp Sci & Informat Engn, Hefei 230601, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Xie, Z (corresponding author), Hefei Univ Technol, Key Lab Knowledge Engn Big Data, Minist Educ, Hefei 230601, Peoples R China.
EM xiezhao@hfut.edu.cn
FU Fundamental Research Funds forthe Central Universities of China [PA2021
   GDSK0072, JZ2021HGQA0219]; Anhui Province Key Research and Development
   Program [202004d07020004]; Anhui Natural Science Foundation
   [2108085MF203]
FX Acknowledgement This research was supported by the Fundamental Research
   Funds forthe Central Universities of China (PA2021 GDSK0072,
   JZ2021HGQA0219) , Anhui Province Key Research and Development Program
   (202004d07020004) , Anhui Natural Science Foundation (2108085MF203) .
CR Ahsan U, 2019, IEEE WINT CONF APPL, P179, DOI 10.1109/WACV.2019.00025
   Bai YT, 2020, Arxiv, DOI arXiv:2011.13046
   Behrmann N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9224, DOI 10.1109/ICCV48922.2021.00911
   Benaim S., 2020, CVPR, P9919
   Bertasius G., 2021, P INT C MACH LEARN, P813
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chauhan S, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105803
   Chen XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9620, DOI 10.1109/ICCV48922.2021.00950
   Dave I, 2022, COMPUT VIS IMAGE UND, V219, DOI 10.1016/j.cviu.2022.103406
   Dosovitskiy Alexey, 2021, ICLR
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Fernando B, 2017, PROC CVPR IEEE, P5729, DOI 10.1109/CVPR.2017.607
   Guo AB, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104391
   Han T., 2020, Advances in Neural Information Processing Systems, V33
   Huang LH, 2021, PROC CVPR IEEE, P13881, DOI 10.1109/CVPR46437.2021.01367
   Jing LL, 2019, Arxiv, DOI arXiv:1811.11387
   Kay W, 2017, Arxiv, DOI arXiv:1705.06950
   Kim D, 2019, AAAI CONF ARTIF INTE, P8545
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Li KC, 2022, Arxiv, DOI arXiv:2201.09450
   Liang HW, 2022, AAAI CONF ARTIF INTE, P1564
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P1978, DOI 10.1109/TIP.2022.3147032
   Luo DZ, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3473342
   Piergiovanni AJ, 2020, PROC CVPR IEEE, P130, DOI 10.1109/CVPR42600.2020.00021
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Stergiou A, 2019, IEEE IMAGE PROC, P1830, DOI [10.1109/ICIP.2019.8803153, 10.1109/icip.2019.8803153]
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Jiangliu, 2020, ECCV, P504, DOI DOI 10.1007/978-3-030-58520-430
   Wang JP, 2021, PROC CVPR IEEE, P11799, DOI 10.1109/CVPR46437.2021.01163
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu DJ, 2019, PROC CVPR IEEE, P10326, DOI 10.1109/CVPR.2019.01058
   Yao Y, 2020, PROC CVPR IEEE, P6547, DOI 10.1109/CVPR42600.2020.00658
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zeng W., 2022, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P11101
   Zhang C, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104329
   Zhang ML, 2022, AAAI CONF ARTIF INTE, P3300
   Zhang Y, 2022, AAAI CONF ARTIF INTE, P3380
NR 42
TC 2
Z9 2
U1 5
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104765
DI 10.1016/j.imavis.2023.104765
EA JUL 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA O3SP4
UT WOS:001043051600001
DA 2024-07-18
ER

PT J
AU Yadav, G
   Yadav, DK
AF Yadav, Gaurav
   Yadav, Dilip Kumar
TI Contrast enhancement of region of interest of backlit image for
   surveillance systems based on multi-illumination fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Backlit; Surveillance; Image enhancement; ROI; Contrast measure
ID HISTOGRAM EQUALIZATION
AB The surveillance images under backlit conditions is a potential and challenging research problem in image pro-cessing and computer vision. Low contrast regions of interest of backlit images form an indiscernible part for the real-time surveillance and biometrics applications. However, current state-of-the-art techniques typically offer limited dark-region contrast enhancement, are susceptible to colour distortion. This research work uses re-gion of interest segmentation and a transfer learning-based strategy to improve the contrast of the dark intensity regions in backlit image using multi-illumination mappings, motivated by its usefulness. To generate a diversified collection of illumination-maps and enhance the brightness and contrast of the backlit image, the proposed framework applies the varied set of log and gamma transforms. The experimental findings confirm the assertion that the proposed method provides better performance than state-of-the-art methods both objectively and subjectively.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Yadav, Gaurav; Yadav, Dilip Kumar] Natl Inst Technol, Dept Comp Sci & Engn, Jamshedpur 831014, Jharkhand, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Jamshedpur
RP Yadav, DK (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Jamshedpur 831014, Jharkhand, India.
EM yadgaurav90@gmail.com; dkyadav.cse@nitjsr.ac.in
RI Yadav, Gaurav/AAC-6186-2019; KUMAR, DINESH/JTT-7703-2023
OI Yadav, Gaurav/0000-0002-8233-1991; 
CR Akai M, 2021, IEEE IMAGE PROC, P1659, DOI 10.1109/ICIP42928.2021.9506526
   Akai M, 2022, OPT REV, V29, P69, DOI 10.1007/s10043-022-00725-4
   Alvarez-Meza AM, 2016, IMAGE VISION COMPUT, V45, P22, DOI 10.1016/j.imavis.2015.11.006
   Buades A, 2020, IET IMAGE PROCESS, V14, P211, DOI 10.1049/iet-ipr.2019.0814
   Cai JR, 2018, IEEE T IMAGE PROCESS, V27, P2049, DOI 10.1109/TIP.2018.2794218
   Celik T, 2014, IEEE T IMAGE PROCESS, V23, P5298, DOI 10.1109/TIP.2014.2364537
   CROMARTIE R, 1993, IMAGE VISION COMPUT, V11, P460, DOI 10.1016/0262-8856(93)90066-P
   Dhara SK, 2019, LECT NOTES COMPUT SC, V11854, P170, DOI 10.1007/978-3-030-34879-3_14
   Feng XM, 2021, APPL INTELL, V51, P5111, DOI 10.1007/s10489-020-02119-y
   Gonzalez RC, 2009, DIGITAL IMAGE PROCES, DOI 10.1117/1.3115362
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Hsia SC, 2016, IMAGING SCI J, V64, DOI 10.1080/13682199.2016.1219117
   Hyun DY, 2010, IEEE IMAGE PROC, P3545, DOI 10.1109/ICIP.2010.5651281
   Iqbal K, 2016, NEUROCOMPUTING, V174, P413, DOI 10.1016/j.neucom.2015.03.120
   Kang B, 2011, IMAGE VISION COMPUT, V29, P557, DOI 10.1016/j.imavis.2011.06.001
   LAND EH, 1986, P NATL ACAD SCI USA, V83, P3078, DOI 10.1073/pnas.83.10.3078
   Li CY, 2018, PATTERN RECOGN LETT, V104, P15, DOI 10.1016/j.patrec.2018.01.010
   Li ZH, 2018, IEEE T IMAGE PROCESS, V27, P976, DOI 10.1109/TIP.2017.2771142
   Li ZN, 2015, AER ADV ENG RES, V17, P1, DOI 10.1109/PLASMA.2015.7180009
   Lv XQ, 2022, COMPUT VIS IMAGE UND, V218, DOI 10.1016/j.cviu.2022.103403
   Niu Y, 2016, IEEE T IMAGE PROCESS, V25, P4815, DOI 10.1109/TIP.2016.2598485
   Obayya M, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104584
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Trongtirakul T, 2020, IEEE ACCESS, V8, P71940, DOI 10.1109/ACCESS.2020.2987256
   Ueda Y, 2020, IEEE IMAGE PROC, P958, DOI [10.1109/icip40778.2020.9190929, 10.1109/ICIP40778.2020.9190929]
   Wang QH, 2016, IEEE IMAGE PROC, P4077, DOI 10.1109/ICIP.2016.7533126
   Yadav G, 2021, IMAGING SCI J, V69, P57, DOI 10.1080/13682199.2022.2149056
   Yadav G, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-021-01272-9
   Yaghoubi E, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104288
   Zhang L, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1623, DOI 10.1145/3343031.3351069
   Zhou Z, 2016, IMAGE VISION COMPUT, V46, P29, DOI 10.1016/j.imavis.2015.11.009
NR 33
TC 2
Z9 2
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104693
DI 10.1016/j.imavis.2023.104693
EA MAY 2023
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA J3QW9
UT WOS:001008801900001
DA 2024-07-18
ER

PT J
AU Wang, Y
   Li, SX
AF Wang, Yu
   Li, Shuxiao
TI Hierarchical interaction and pooling network for co-salient object
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Co -salient object detection; Four -branch network; Hierarchical
   architecture; Pyramid pooling interaction
ID DEEP
AB Co-salient object detection (CoSOD) aims to detect common and salient objects across the given image group. Due to the particularity of CoSOD, images in the given group are processed synergistically to excavate the rele-vance between them. Inspired by the tracking methods, previous works tend to utilize pixel-wise correspon-dences to measure the relevance. However, because of the complexity of the image groups, the obtained feature maps could be easily affected by the common interference. Moreover, current works tend to utilize clas-sification labels to ensure intra-group coherence and inter-group separability, which may cause some overfitting problems. In this paper, we propose the hierarchical interaction and pooling network to alleviate the above prob-lems. We first design a pyramid pooling interaction module and perform convolution with dimension permuta-tion, making full use of convolution and multi-receptive field information. We further propose the coherence confirmation module along with the four-branch architecture. Without the classification labels, the module achieves comparable or even better performance. Extensive experiments demonstrate that the proposed method can detect common and salient objects more accurately and achieves the new state-of-the-art.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Wang, Yu; Li, Shuxiao] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Wang, Yu; Li, Shuxiao] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Automation, CAS
RP Li, SX (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing, Peoples R China.
EM shuxiao.li@ia.ac.cn
FU National Natural Science Foundation of China [U19B2033, 62076020]
FX This work is partly supported by the National Natural Science Foundation
   of China (Grant No. U19B2033, Grant No. 62076020) .
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Bouraffa T., 2022, EXP ASTRON, V123
   Cao X., 2013, P IEEE INT C MULT EX, P1, DOI DOI 10.1109/WCSP.2013.6677045
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Fan DP, 2018, Arxiv, DOI arXiv:1805.10421
   Fan DP, 2022, IEEE T PATTERN ANAL, V44, P6024, DOI 10.1109/TPAMI.2021.3085766
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan Q, 2021, PROC CVPR IEEE, P12283, DOI 10.1109/CVPR46437.2021.01211
   Fu HZ, 2013, IEEE T IMAGE PROCESS, V22, P3766, DOI 10.1109/TIP.2013.2260166
   Gupta AK, 2019, ELECTRON LETT, V55, P783, DOI 10.1049/el.2019.1092
   Gupta AK, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3108503
   Gupta AK, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3064423
   Gupta AK, 2021, PATTERN ANAL APPL, V24, P625, DOI 10.1007/s10044-020-00925-1
   Gupta AK, 2020, ENTROPY-SWITZ, V22, DOI 10.3390/e22101174
   Jerripothula KR, 2019, IEEE T CIRC SYST VID, V29, P744, DOI 10.1109/TCSVT.2018.2805811
   Jin W.-D., 2020, P ADV NEUR INF PROC
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Li YJ, 2015, IEEE SIGNAL PROC LET, V22, P588, DOI 10.1109/LSP.2014.2364896
   Li ZW, 2018, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2018.00067
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu JW, 2020, Arxiv, DOI arXiv:2004.04979
   Liu Z, 2014, IEEE SIGNAL PROC LET, V21, P88, DOI 10.1109/LSP.2013.2292873
   Paszke A, 2019, ADV NEUR IN, V32
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Raju PM, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104215
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan ZS, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109356
   Tsai CC, 2017, IEEE INT CON MULTI, P523, DOI 10.1109/ICME.2017.8019413
   Vondrick C, 2018, LECT NOTES COMPUT SC, V11217, P402, DOI 10.1007/978-3-030-01261-8_24
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang WG, 2016, IEEE T MULTIMEDIA, V18, P1011, DOI 10.1109/TMM.2016.2545409
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang ZY, 2021, IMAGE VISION COMPUT, V113, DOI 10.1016/j.imavis.2021.104243
   Wei XS, 2019, PATTERN RECOGN, V88, P113, DOI 10.1016/j.patcog.2018.10.022
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Wu Q, 2022, IMAGE VISION COMPUT, V122, DOI 10.1016/j.imavis.2022.104442
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Yu S., 2022, P IEEECVF C COMPUTER, P979
   Zhang DW, 2016, INT J COMPUT VISION, V120, P215, DOI 10.1007/s11263-016-0907-4
   Zhang J, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104508
   Zhang KH, 2020, AAAI CONF ARTIF INTE, V34, P12813
   Zhang KH, 2019, PROC CVPR IEEE, P3090, DOI 10.1109/CVPR.2019.00321
   Zhang N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4147, DOI 10.1109/ICCV48922.2021.00413
   Zhang QJ, 2020, Arxiv, DOI arXiv:2011.04887
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P455, DOI 10.1007/978-3-030-58610-2_27
NR 52
TC 1
Z9 1
U1 3
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2023
VL 132
AR 104647
DI 10.1016/j.imavis.2023.104647
EA FEB 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 9V8ZZ
UT WOS:000948676000001
DA 2024-07-18
ER

PT J
AU Tianyi, L
   Riaz, S
   Xuande, Z
   Mirza, A
   Afzal, F
   Iqbal, Z
   Khan, MA
   Alhaisoni, M
   Alqahtani, A
AF Tianyi, Lan
   Riaz, Saleem
   Xuande, Zhang
   Mirza, Alina
   Afzal, Farkhanda
   Iqbal, Zeshan
   Khan, Muhammad Attique
   Alhaisoni, Majed
   Alqahtani, Abdullah
TI Federated learning based nonlinear two-stage framework for
   full-reference image quality assessment: An application for biometric
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image quality assessment; Activation function; Nonlinearity; Two -stage
   framework; Deep learning
ID SIMILARITY
AB The non-linearity in medical image processing is a critical issue. Because the privacy of the medical image and loss of data is a major concern in recent years. Federated learning is a most advanced form of machine learning in which, rather than transmitting data to local server, a machine learning (ML) algorithm is installed to various de-vices to train on the information. The parameters from the separate modules will then be transferred to a master ML/ (deep learning) DL model for global training. The research of Image Quality Assessment (IQA) aims to sim-ulate the process of human perception of image quality and construct an objective image quality model as con-sistent as possible with subjective assessment. The existing IQA methods can be roughly divided into traditional methods and deep learning methods. Traditional methods are knowledge-driven, using prior knowledge or as-sumptions about the human visual system (HVS) to heuristically design image quality index. Deep learning methods are data-driven, using a large amount of annotated data to learn the mapping from the image to its vi-sual quality end-to-end. To effectively integrate traditional methods into deep networks and investigate the knowledge (model)-driven deep learning methods are the current mainstream trends in IQA research. In this paper, we take the contrary direction and improve traditional methods guided by the cue from deep learning methods. The main works include: 1. the employment of activation function ensure the nonlinear approximation ability of the neural network, here we first extend the two-stage framework widely used in the field of full -reference image quality assessment and propose a nonlinear two-stage framework. 2. Within this framework, we revisit the Edge Strength SIMlarity (ESSIM) algorithm that we previously published in IEEE Signal Processing Letters, and proposed the Nonlinear Edge Strength SIMlarity (NESSIM) algorithm. Experiments on public data-bases show that NESSIM can obtain good assessment results in traditional methods. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Tianyi, Lan; Xuande, Zhang] Shaanxi Univ Sci & Technol, Coll Elect & Control Engn, Xian 710021, Peoples R China.
   [Riaz, Saleem] Northwestern Polytech Univ, Sch Automat, Xian 710072, Peoples R China.
   [Mirza, Alina; Afzal, Farkhanda] Natl Univ Sci & Technol, Mil Coll Signals, Islamabad 45000, Pakistan.
   [Iqbal, Zeshan] Univ Engn & Technol, Dept Comp Sci, Taxila 47040, Pakistan.
   [Khan, Muhammad Attique] HITEC Univ, Dept Comp Sci, Taxila, Pakistan.
   [Alhaisoni, Majed] Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Comp Sci Dept, Riyadh 11671, Saudi Arabia.
   [Alqahtani, Abdullah] Prince Sattam Bin Abdulaziz Univ, Coll Comp Engn & Sci, Al Kharj, Saudi Arabia.
C3 Shaanxi University of Science & Technology; Northwestern Polytechnical
   University; National University of Sciences & Technology - Pakistan;
   University of Engineering & Technology Taxila; NITEC University;
   Princess Nourah bint Abdulrahman University; Prince Sattam Bin Abdulaziz
   University
RP Khan, MA (corresponding author), HITEC Univ, Dept Comp Sci, Taxila, Pakistan.
EM attique.khan@hitecuni.edu.pk
RI Alqahtani, Abdullah Qunayfith/DWN-4582-2022; RIAZ, SALEEM/AAR-4436-2021;
   Iqbal, Zeshan/A-1166-2010; Khan, Dr. Muhammad Attique/AAX-2644-2021;
   Iqbal, Zeshan/D-8820-2014
OI Alqahtani, Abdullah Qunayfith/0000-0002-2859-1629; RIAZ,
   SALEEM/0000-0001-7818-2578; Khan, Dr. Muhammad
   Attique/0000-0002-6347-4890; Iqbal, Zeshan/0000-0003-4545-4092
CR Alazab M, 2022, IEEE T IND INFORM, V18, P3501, DOI 10.1109/TII.2021.3119038
   Atchison D., 2000, OPTICS HUMAN EYE, DOI DOI 10.1016/B978-0-7506-3775-6.50022-5
   Benmalek M., 2022, EVOL SYST, P1
   Chen ZL, 2022, HUM-CENT COMPUT INFO, V12, DOI 10.22967/HCIS.2022.12.001
   De Mulder W, 2015, COMPUT SPEECH LANG, V30, P61, DOI 10.1016/j.csl.2014.09.005
   Estes W.K., 2019, The first century of experimental psychology, P623
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Hammad M, 2022, HUM-CENT COMPUT INFO, V12, DOI 10.22967/HCIS.2022.12.004
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kalinke Thomas., 1998, IEEE Intelligent Vehicles Symposium, P341
   Kang D., 2022, MOSAIC STYLIZATION U
   Larson EC, 2010, J ELECTRON IMAGING, V19, DOI 10.1117/1.3267105
   Li X, 2019, IET INTELL TRANSP SY, V13, P1401, DOI 10.1049/iet-its.2018.5590
   Li Z, 2016, INT J AGRIC BIOL, V18, P86
   Lin Hanhe, 2019, 2019 11 INT C QUALIT, P1
   Ma KD, 2017, IEEE T IMAGE PROCESS, V26, P3951, DOI 10.1109/TIP.2017.2708503
   Merzougui N, 2021, J IMAGING SCI TECHN, V65, DOI 10.2352/J.ImagingSci.Technol.2021.65.6.060409
   Mohamed A.H., 2022, Computational Intelligence and Neuroscience, V2022, P2247675, DOI 10.1155/2022/2247675
   Netravali A.N., 1988, DIGITAL PICTURES REP
    P, 2021, Arxiv, DOI arXiv:2101.00798
   Patel Y, 2019, Arxiv, DOI arXiv:1908.04187
   Patoliya J, 2022, EARTH SCI INFORM, V15, P2703, DOI 10.1007/s12145-022-00791-x
   Pinkus A., 1999, Acta Numerica, V8, P143, DOI 10.1017/S0962492900002919
   Ponomarenko N., 2009, ADV MODERN RADIOELEC, V10, P30, DOI 10.1109/TIP.2015.2439035
   Ponomarenko N, 2015, SIGNAL PROCESS-IMAGE, V30, P57, DOI 10.1016/j.image.2014.10.009
   Ramachandran P, 2017, Arxiv, DOI arXiv:1710.05941
   Ramu SP, 2022, SUSTAIN CITIES SOC, V79, DOI 10.1016/j.scs.2021.103663
   Riaz S., 2021, COMPLEXITY 2021
   Riaz S, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/5975158
   Riaz S, 2020, INTEGR FERROELECTR, V213, P103, DOI 10.1080/10584587.2020.1859828
   Ryu K, 2022, MAGN RESON MED, V88, P1263, DOI 10.1002/mrm.29261
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Temel D, 2019, SIGNAL PROCESS-IMAGE, V70, P37, DOI 10.1016/j.image.2018.09.005
   Umar R., 2022, J TEKNOL DAN SIST KO
   Venkataramanan AK, 2022, Arxiv, DOI arXiv:2202.11241
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z., 2006, Modern Image Quality Assessment, DOI 10.2200/S00010ED1V01Y200508IVM003
   Wang Z., 2003, P 37 AS C SIGN SYST, P1398, DOI [DOI 10.1109/ACSSC.2003.1292216, 10.1109/ACSSC.2003.1292216]
   Wu JJ, 2020, IEEE T IMAGE PROCESS, V29, P7414, DOI 10.1109/TIP.2020.3002478
   Xue WF, 2014, IEEE T IMAGE PROCESS, V23, P684, DOI 10.1109/TIP.2013.2293423
   Yang GY, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0246-1
   Yousfi S., 2022, J KING SAUD U COMP I
   Zhang L, 2014, IEEE T IMAGE PROCESS, V23, P4270, DOI 10.1109/TIP.2014.2346028
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang XD, 2013, IEEE SIGNAL PROC LET, V20, P319, DOI 10.1109/LSP.2013.2244081
NR 46
TC 3
Z9 3
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104588
DI 10.1016/j.imavis.2022.104588
EA NOV 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500007
DA 2024-07-18
ER

PT J
AU He, S
   Yang, XF
   Lin, GS
AF He, Su
   Yang, Xiaofeng
   Lin, Guosheng
TI Learning language to symbol and language to vision mapping for visual
   grounding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross modality; Visual grounding; Neural symbolic reasoning
AB Visual Grounding (VG) isa task of locating a specific object in an image semantically matching a given linguistic expression. The mapping of the linguistic and visual contents and the understanding of diverse linguistic expressions are the two challenges of this task. The performance of visual grounding is consistently improved by deep visual features in the last few years. While deep visual features contain rich information, they could also be noisy, biased and easily over-fitted. In contrast, symbolic features are discrete, easy to map and usually less noisy. In this work, we propose a novel modular network learning to match both the object's symbolic features and conventional visual features with the linguistic information. Moreover, the Residual Attention Parser is designed to alleviate the difficulty of understanding diverse expressions. Our model achieves competitive performance on three popular datasets of VG. (C) 2022 Elsevier B.V. All rights reserved.
C1 [He, Su; Yang, Xiaofeng; Lin, Guosheng] Nanyang Technol Univ, Sch Comp Sci & Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Lin, GS (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM hesu0002@e.ntu.edu.sg; xiaofeng001@e.ntu.edu.sg; gslin@ntu.edu.sg
FU National Research Foundation, Singapore [AISGRP-2018-003]; MOE AcRF
   Tier-1 [RG28/18, RG22/19, RG95/20]
FX This research is supported by the National Research Foundation,
   Singapore under its AI Singapore Programme (AISG Award No:
   AISGRP-2018-003), and the MOE AcRF Tier-1 research grants: RG28/18 (S),
   RG22/19 (S) and RG95/20.
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Andreas J., P IEEE C COMPUTER VI, P39
   Antol S., P IEEE INT C COMPUTE, P2425
   Deng C., P IEEE C COMPUTER VI, P7746
   Deng J., P IEEE CVF INT C COM, P1769
   Han YZ, 2022, IEEE T PATTERN ANAL, V44, P7436, DOI 10.1109/TPAMI.2021.3117837
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hong R., IEEE T PATTERN ANAL, V44, P684
   Huang J., 2021, ARXIV PREPRINT ARXIV
   Jiang Y., 2018, arXiv
   Jiao Y., 2022, ARXIV PREPRINT ARXIV
   Kazemzadeh S., P 2014 C EMP METH NA, P787
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu D., P IEEECVF INT C COMP, P4673
   Liu X., P IEEE C COMPUTER VI, P1950
   Lyu F, 2020, NEUROCOMPUTING, V413, P51, DOI 10.1016/j.neucom.2020.06.091
   Mao J., P IEEE C COMPUTER VI, P11
   Nagaraja VK, 2016, LECT NOTES COMPUT SC, V9908, P792, DOI 10.1007/978-3-319-46493-0_48
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rohrbach M., P IEEE C COMPUTER VI, P1115
   Socher Richard, 2013, Long Papers, P455
   Wang P., P IEEE C COMPUTER VI, P1960
   Yang S., P IEEE INT C COMPUTE, P4644
   Yang Z., P IEEECVF INT C COMP, P4683
   You Q., P IEEE C COMPUTER VI, P4651
   Yu L., P IEEE C COMPUTER VI, P1307
   Yu L., P IEEE C COMPUTER VI, P7282
   Yu LC, 2016, LECT NOTES COMPUT SC, V9906, P69, DOI 10.1007/978-3-319-46475-6_5
   Zhang H., P IEEE C COMPUTER VI, P4158
   Zhuang B., P IEEE C COMPUTER VI, P4252
NR 32
TC 0
Z9 0
U1 2
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104451
DI 10.1016/j.imavis.2022.104451
EA APR 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1F1NU
UT WOS:000794942300009
DA 2024-07-18
ER

PT J
AU Cheng, DQ
   Liu, RH
   Li, JH
   Liang, S
   Kou, QQ
   Zhao, K
AF Cheng, Deqiang
   Liu, Ruihang
   Li, Jiahan
   Liang, Song
   Kou, Qiqi
   Zhao, Kai
TI Activity guided multi-scales collaboration based on scaled-CNN for
   saliency prediction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Saliency prediction; Convolutional neural networks; Human eye fixations;
   Deep learning
ID VISUAL-ATTENTION; MODEL; QUALITY
AB Visual saliency prediction has achieved significant improvements with the advent of convolutional neural networks, but the breakthrough in saliency prediction accuracy comes at the high computational cost. In this paper, we present a lightweight saliency prediction model based on scaled up convolutional neural networks (CNN), utilizing image activity guided collaboration learning of global and local information at multiple scales. we use a pseudo-siamese network with a scaled up network (EfficientNet) as the backbone, and the two branches of the network respectively capture the global saliency feature and high-level local feature. Concretely, we first utilize the image complexity-related activity features (Image Activity Measure) as our low-level local salience prior, and then feed the input images and the activity maps to scaled up CNN modules to further learn high-level features in a multi-scale collaboration manner. Through extensive evaluation, we show that the proposed method exhibits competitive and consistent results on the challenging benchmark datasets, and our method has better prediction performance, fewer trainable parameters and faster inference speed. Moreover, the proposed model has low requirements for platform computing capabilities, which improves the universality of saliency application scenarios. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Cheng, Deqiang; Liu, Ruihang; Li, Jiahan; Liang, Song; Zhao, Kai] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Jiangsu, Peoples R China.
   [Kou, Qiqi] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology
RP Kou, QQ (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
EM kouqiqi@cumt.edu.cn
RI SUN, YANLING/JTT-9082-2023; Yang, Tian/JFB-1008-2023; Wu,
   Jiale/JQV-3750-2023; wang, jiajun/JRW-6032-2023; Cheng,
   Deqiang/HDO-0132-2022
FU National Natural Science Foundation of China [51774281]
FX This work was supported by the National Natural Science Foundation of
   China under Grants 51774281.
CR [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], 2019, ARXIV190206634
   Borji A., 2015, P CVPR WORKSH FUT DA
   Borji A, 2012, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.2012.6247706
   Bruce N.D.B., P 18 INT C NEUR INF, P155
   Bylinskii Z., 2018, MIT SALIENCY BENCHMA
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Che ZH, 2020, IEEE T IMAGE PROCESS, V29, P2287, DOI 10.1109/TIP.2019.2945857
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Fang S., 2016, IEEE T NEURAL NETWOR
   Gao D., P ADV NIPS 2007, P497
   Gao Y, 2015, IEEE T MULTIMEDIA, V17, P359, DOI 10.1109/TMM.2015.2389616
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gu K, 2016, IEEE T MULTIMEDIA, V18, P1098, DOI 10.1109/TMM.2016.2547343
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Huang YP, 2019, ADV NEUR IN, V32
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jetley S, 2016, PROC CVPR IEEE, P5753, DOI 10.1109/CVPR.2016.620
   Jia S, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103887
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Jiang QP, 2018, IEEE T MULTIMEDIA, V20, P2035, DOI 10.1109/TMM.2017.2763321
   Judd T., 2021, IEEE T PATTERN ANAL
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim H, 2015, IEEE T MULTIMEDIA, V17, P2198, DOI 10.1109/TMM.2015.2493367
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kümmerer M, 2018, LECT NOTES COMPUT SC, V11220, P798, DOI 10.1007/978-3-030-01270-0_47
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Kümmerer M, 2015, P NATL ACAD SCI USA, V112, P16054, DOI 10.1073/pnas.1510393112
   Kummerer M., 2015, INT C LEARN REPR ICL
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Li SX, 2018, IEEE T MULTIMEDIA, V20, P155, DOI 10.1109/TMM.2017.2721544
   Lin SS, 2013, IEEE T MULTIMEDIA, V15, P359, DOI 10.1109/TMM.2012.2228475
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Pan J., 2017, PROC IEEE C COMPUT V
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Saha S, 2000, IEEE SIGNAL PROC LET, V7, P104, DOI 10.1109/97.841153
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang W., IEEE C COMP VIS PATT, P3395
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Ye LW, 2017, IEEE T MULTIMEDIA, V19, P1742, DOI 10.1109/TMM.2017.2693022
   Zagoruyko S., 2016, ARXIV160507146, DOI DOI 10.5244/C.30.87
   Zhang DW, 2017, IEEE T IMAGE PROCESS, V26, P1746, DOI 10.1109/TIP.2017.2658957
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zhao Q, 2011, J VISION, V11, DOI 10.1167/11.3.9
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 61
TC 5
Z9 6
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2021
VL 114
AR 104267
DI 10.1016/j.imavis.2021.104267
EA AUG 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UR9HP
UT WOS:000697051200008
DA 2024-07-18
ER

PT J
AU Yu, L
   Zhang, HL
   Yu, JY
   Qiao, BJ
AF Yu, Lang
   Zhang, Huanlong
   Yu, Junyang
   Qiao, Baojun
TI Online-adaptive classification and regression network with
   sample-efficient meta learning for long-term tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Long-term tracking; Target regression; Online learning; Meta learning
AB Classification and regression-based trackers (CAR) are widely adopted to tackle the short-term visual tracking task. However, the existing CAR tackers either employ offline-trained regression models based on predefined anchor-boxes, or online update their models in a rough and inflexible way, which leads to the lack of longterm adaptability for target deformations and appearance variations. To overcome this limitation, we propose a novel long-term tracking framework LT-CAR utilizing sample-efficient meta learning to online optimize both the classification and regression model. Specifically, we first introduce the ridge regression to a fully convolutional network as our regression branch, and then implement a vertically stacked GRU module termed as Meta-Sample-Filter to keep historical information about the target as well as help our model learn what to learn. Moreover, we extend our framework for long-term tracking by introducing a carefully designed spatial- temporal verification network to identify tracking failures, and a query-guided detector to conduct global re-detection. Experimental results on LaSOT, VOT-LT2018, VOT-LT2019, and TLP benchmarks show that our LT-CAR achieves comparable performance to the state-of-the-art long-term algorithms. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Yu, Lang; Yu, Junyang] Henan Univ, Sch Software, Kaifeng 475000, Peoples R China.
   [Zhang, Huanlong] Zhengzhou Univ Light Ind, Sch Elect & Informat Engn, Zhengzhou 450000, Peoples R China.
   [Qiao, Baojun] Henan Univ, Sch Comp Sci, Kaifeng 475000, Peoples R China.
C3 Henan University; Zhengzhou University of Light Industry; Henan
   University
RP Yu, JY (corresponding author), Henan Univ, Sch Software, Kaifeng 475000, Peoples R China.
EM jyyu@edu.henu.cn
RI Yu, Lang/AAZ-3493-2021
OI Yu, Lang/0000-0002-9083-5313
FU Key Technologies Research and Development Program of Henan
   [212102210078]; Elite Postgraduate Students Program of Henan University
   [SYL20060174]; National Natural Science Foundation [61873246]; Natural
   Science Foundation of Henan [202300410495]
FX This work was supported in part by the Key Technologies Research and
   Development Program of Henan under Grant (212102210078), the Elite
   Postgraduate Students Program of Henan University (SYL20060174), the
   National Natural Science Foundation (61873246), and the Natural Science
   Foundation of Henan (202300410495).
CR Abbass MY, 2021, VISUAL COMPUT, V37, P993, DOI 10.1007/s00371-020-01848-y
   [Anonymous], 2018, P ACCV
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P205, DOI 10.1007/978-3-030-58592-1_13
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Chen BaoXin., 2019, Fast visual object tracking with rotated bounding boxes
   Choi J, 2020, ACCV
   Choi J, 2019, IEEE I CONF COMP VIS, P911, DOI 10.1109/ICCV.2019.00100
   Cui Y., 2020, ARXIV200407109
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai KN, 2020, PROC CVPR IEEE, P6297, DOI 10.1109/CVPR42600.2020.00633
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Huang LH, 2020, AAAI CONF ARTIF INTE, V34, P11037
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M., 2019, P IEEE CVF INT C COM
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Lukezi A., 2018, AS C COMP VIS, P595
   Marvasti-Zadeh SM, 2022, IEEE T INTELL TRANSP, V23, P3943, DOI 10.1109/TITS.2020.3046478
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Park E, 2018, LECT NOTES COMPUT SC, V11207, P587, DOI 10.1007/978-3-030-01219-9_35
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Yan B, 2019, IEEE I CONF COMP VIS, P2385, DOI 10.1109/ICCV.2019.00247
   Yunhua Zhang, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P355, DOI 10.1007/978-3-030-01240-3_22
   Zhu G, 2016, PROC CVPR IEEE, P943, DOI 10.1109/CVPR.2016.108
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 36
TC 7
Z9 7
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104181
DI 10.1016/j.imavis.2021.104181
EA MAY 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100011
DA 2024-07-18
ER

PT J
AU Gao, Q
   Shen, XK
AF Gao, Qian
   Shen, Xukun
TI ThickSeg: Efficient semantic segmentation of large-scale 3D point clouds
   using multi-layer projection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D point cloud; Semantic segmentation; Convolutional neural network;
   Large scale
AB Efficient semantic segmentation of large-scale three-dimensional (3D) point clouds is an essential approach for intelligent robots to perceive the surrounding environment. However, due to the expensive sampling process or time-consuming pre/post-processing steps, most of the current solutions are inefficient or limited in scale. In this paper, we propose a novel framework, ThickSeg, to efficiently assign semantic labels for large-scale point clouds. ThickSeg contains three main steps: Firstly, it projects raw point clouds onto a multi-layer image with a random-hit strategy to efficiently preserve more local geometric features. Secondly, the projected multi-layer image is fed into a Self-Sorting 3D Convolutional Neural Network (SS-3DCNN) to predict grid-wise semantics and subsequently project them back to their corresponding 3D points. Finally, the labels of occluded points are determined by an iterative and accumulative post-processing mechanism, avoiding time-consuming explicit 3D neighborhood searching. We validate our approach on two well-known public benchmarks (SemanticKITTI and KITTI), where ThickSeg gets state-of-the-art results and more efficient than previous methods. Our detailed ablation study shows how each component contributes to the final performance.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Gao, Qian; Shen, Xukun] Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
   [Shen, Xukun] Beihang Univ, Sch New Media Art & Design, Beijing 100191, Peoples R China.
C3 Beihang University; Beihang University
RP Gao, Q (corresponding author), Beihang Univ, State Key Lab Virtual Real Technol & Syst, Beijing 100191, Peoples R China.
EM gaoqian@buaa.edu.cn; xkshen@buaa.edu.cn
CR Alonso I, 2020, IEEE ROBOT AUTOM LET, V5, P5432, DOI 10.1109/LRA.2020.3007440
   [Anonymous], 2016, ARXIV160207360
   [Anonymous], 2017, ISPRS Annals of the Photogrammetry, Remote Sensing and Spatial Information Sciences, DOI [DOI 10.5194/ISPRS-ANNALS-IV-1-W1-3-2017, 10.5194/isprs-annals-IV-1-W1-3-2017]
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Behley J, 2019, IEEE I CONF COMP VIS, P9296, DOI 10.1109/ICCV.2019.00939
   BESL PJ, 1988, IEEE T PATTERN ANAL, V10, P167, DOI 10.1109/34.3881
   Biasutti P, 2019, IEEE INT CONF COMP V, P942, DOI 10.1109/ICCVW.2019.00123
   Boulch A, 2020, COMPUT GRAPH-UK, V88, P24, DOI 10.1016/j.cag.2020.02.005
   Boulch A, 2018, COMPUT GRAPH-UK, V71, P189, DOI 10.1016/j.cag.2017.11.010
   Bronstein MM, 2010, PROC CVPR IEEE, P1704, DOI 10.1109/CVPR.2010.5539838
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chenfeng Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P1, DOI 10.1007/978-3-030-58604-1_1
   Cortinhal Tiago, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12510), P207, DOI 10.1007/978-3-030-64559-5_16
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dewan A, 2020, IEEE INT CONF ROBOT, P2624, DOI [10.1109/icra40945.2020.9197193, 10.1109/ICRA40945.2020.9197193]
   Engelmann F, 2017, IEEE INT CONF COMP V, P716, DOI 10.1109/ICCVW.2017.90
   Geiger A., 2012, CVPR
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hulik R, 2014, J VIS COMMUN IMAGE R, V25, P86, DOI 10.1016/j.jvcir.2013.04.001
   Jiang XY, 1996, THIRD IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV '96, PROCEEDINGS, P83, DOI 10.1109/ACV.1996.572006
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kingma D. P., 2014, arXiv
   Komarichev A, 2019, PROC CVPR IEEE, P7413, DOI 10.1109/CVPR.2019.00760
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Landrieu L, 2018, PROC CVPR IEEE, P4558, DOI 10.1109/CVPR.2018.00479
   Li Y., 2018, ADV NEURAL INFORM PR, P820, DOI DOI 10.48550/ARXIV.1801.07791
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Liu B, 2005, INT J COMPUT VISION, V65, P175, DOI 10.1007/s11263-005-3670-5
   Meng HY, 2019, IEEE I CONF COMP VIS, P8499, DOI 10.1109/ICCV.2019.00859
   Milioto A, 2019, IEEE INT C INT ROBOT, P4213, DOI 10.1109/IROS40897.2019.8967762
   Ozdemir E., 2019, The International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V42, P103, DOI DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W13-103-2019
   Qi C.R., 2017, ABS170602413 CORR, P5099
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Riegler G, 2017, PROC CVPR IEEE, P6620, DOI 10.1109/CVPR.2017.701
   Ronneberger O., 2015, UNET CONVOLUTIONAL N
   Rosa S., 2020, 2020 P IEEECVF C COM, P11108, DOI [DOI 10.1109/CVPR42600.2020.01112, 10.1109/CVPR42600.2020.01112]
   Sakowski BA, 2019, ENVIRON PROG SUSTAIN, V38, DOI 10.1002/ep.13144
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Seitz S.M., 2006, IEEE COMP SOC C COMP, P519
   Su H, 2018, PROC CVPR IEEE, P2530, DOI 10.1109/CVPR.2018.00268
   Su H, 2015, IEEE I CONF COMP VIS, P2686, DOI 10.1109/ICCV.2015.308
   Tatarchenko M, 2018, PROC CVPR IEEE, P3887, DOI 10.1109/CVPR.2018.00409
   Tchapmi LP, 2017, INT CONF 3D VISION, P537, DOI 10.1109/3DV.2017.00067
   Thomas H, 2019, IEEE I CONF COMP VIS, P6420, DOI 10.1109/ICCV.2019.00651
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang RS, 2018, IEEE J-STARS, V11, P606, DOI 10.1109/JSTARS.2017.2781132
   Wang Yuan., 2018, Pointseg: Real-time semantic segmentation based on 3d lidar point cloud
   Wu BC, 2019, IEEE INT CONF ROBOT, P4376, DOI [10.1109/ICRA.2019.8793495, 10.1109/icra.2019.8793495]
   Wu BC, 2018, IEEE INT CONF ROBOT, P1887
   Xie YX, 2020, IEEE GEOSC REM SEN M, V8, P38, DOI 10.1109/MGRS.2019.2937630
   Ye XQ, 2018, LECT NOTES COMPUT SC, V11211, P415, DOI 10.1007/978-3-030-01234-2_25
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 57
TC 6
Z9 6
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104161
DI 10.1016/j.imavis.2021.104161
EA MAR 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600003
DA 2024-07-18
ER

PT J
AU Zhang, ZJ
   Wu, Q
   Wang, Y
   Chen, F
AF Zhang, Zongjian
   Wu, Qiang
   Wang, Yang
   Chen, Fang
TI Exploring region relationships implicitly: Image captioning with visual
   relationship attention
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image captioning; Visual relationship attention; Relationship-level
   attention parallel attention; mechanism; Learned spatial constraint
AB Visual attention mechanism has been widely used by image captioning model in order to dynamically attend to the related visual region based on given language information. Such capability allows a trained model to carry out fine-grained level image understanding and reasoning. However, existing visual attention models only focus on the individual visual region in the image and the alignment between the language representation and related in-dividual visual regions. It does not fully explore the relationships/interactions between visual regions. Further-more, it does not analyze or explore alignment for related words/phrases (e.g. verb or phrasal verb), which may best describe the relationships/interactions between these visual regions. Thus, it causes the inaccurate or impropriate description to the current image captioning model. Instead of visual region attention commonly ad-dressed by existing visual attention mechanism, this paper proposes the novel visual relationship attention via contextualized embedding for individual regions. It can dynamically explore a related visual relationship existing between multiple regions when generating interaction words. Such relationship exploring process is constrained by spatial relationships and driven by the linguistic context of language decoder. In this work, such new visual relationship attention is designed through a parallel attention mechanism under the learned spatial constraint in order to more precisely map visual relationship information to the semantic description of such relationship in language. Different from existing methods for exploring the visual relationship, it is trained implicitly through an unsupervised approach without using any explicit visual relationship annotations. By integrating the newly proposed visual relationship attention with existing visual region attention, our image captioning model can gen-erate high-quality captions. Solid experiments on the MSCOCO dataset demonstrate the proposed visual relation-ship attention can effectively boost the captioning performances by capturing related visual relationships for generating accurate interaction descriptions.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhang, Zongjian; Wu, Qiang; Wang, Yang; Chen, Fang] Univ Technol Sydney, 15 Broadway, Sydney, NSW, Australia.
C3 University of Technology Sydney
RP Zhang, ZJ (corresponding author), Univ Technol Sydney, 15 Broadway, Sydney, NSW, Australia.
EM zongjian.zhang@student.uts.edu.au
OI Wu, Qiang/0000-0001-5641-2483; Wang, Yang/0000-0002-6815-0879
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 2018, ECCV
   [Anonymous], 2015, CVPR
   [Anonymous], 2018, AAAI
   [Anonymous], 2005, ACL
   Bengio S, 2015, ADV NEUR IN, V28
   Chen L, 2017, PROC CVPR IEEE, P6298, DOI 10.1109/CVPR.2017.667
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Gao LL, 2020, IEEE T PATTERN ANAL, V42, P1112, DOI 10.1109/TPAMI.2019.2894139
   Huang L., 2019, INT C COMP VIS
   Kingma D. P., 2015, INT C LEARNING REPRE
   Kipf Thomas N., 2017, PROC INT C LEARN REP
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li XY, 2019, IEEE T MULTIMEDIA, V21, P2117, DOI 10.1109/TMM.2019.2896516
   Lin T.Y., Proceedings of the European Conference on Computer Vision, P740
   Liu CX, 2017, AAAI CONF ARTIF INTE, P4176
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Pedersoli M, 2017, IEEE I CONF COMP VIS, P1251, DOI 10.1109/ICCV.2017.140
   Peng YQ, 2019, IMAGE VISION COMPUT, V86, P38, DOI 10.1016/j.imavis.2019.03.003
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Sabour S, 2017, ADV NEUR IN, V30
   Song JK, 2020, INT J COMPUT VISION, V128, P2243, DOI 10.1007/s11263-020-01305-2
   Song JK, 2019, IEEE T NEUR NET LEAR, V30, P3047, DOI 10.1109/TNNLS.2018.2851077
   Tavakoli HR, 2017, IEEE I CONF COMP VIS, P2506, DOI 10.1109/ICCV.2017.272
   Velickovic Petar, 2018, INT C LEARN REPR
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2019, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2019.00271
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   Zhang Z., 2018, WACV
   Zhang Z, 2019, GENE THER, P1, DOI DOI 10.1109/IJCNN.2019.8851832
   Zhang ZL, 2019, INT J PROD RES, V57, P2327, DOI 10.1080/00207543.2018.1516904
NR 41
TC 26
Z9 28
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104146
DI 10.1016/j.imavis.2021.104146
EA MAR 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600010
DA 2024-07-18
ER

PT J
AU Zhang, L
   Zhang, YS
   Zhao, X
   Zou, ZX
AF Zhang, Le
   Zhang, Yanshuo
   Zhao, Xin
   Zou, Zexiao
TI Image captioning via proximal policy optimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image captioning; Reinforcement learning; Proximal policy optimization
AB Image captioning is the task of generating captions of images in natural language. The training typically consists of two phases, first minimizing the XE (cross-entropy) loss, and then with RL (reinforcement learning) over CIDEr scores. Although there are many innovations in neural architectures, fewer works are proposed for the RL phase. Motivated by one recent state-of-the-art architecture X-Transformer [Pan et al., CVPR 2020], we apply PPO (Proximal Policy Optimization) to it to establish a further improvement. However, trivially applying a vanilla policy gradient objective function with the clipping form of PPO would not improve the result. Therefore, we introduce certain modifications. We show that PPO is capable of enforcing trust-region constraints effectively. Also, experimentally performance decreases when PPO is combined with the regularization technique dropout. We analyze the possible reason in terms of KL-divergence of RL policies. As to the baseline adopted in the policy gradient estimator of RL, it is generally sentence-level. So all words in the same sentence use the same baseline in the gradient estimator. We instead use a word-level baseline via Monte-Carlo estimation. Thus, different words can have different baseline values. With all these, by fine-tuning a pre-trained X-Transformer, we train a single model achieving a competitive result of 133.3% on the MSCOCO Karpathy test set. Source code is available at https://github.com/lezhang-thu/xtransformer-ppo.& nbsp; (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhang, Le; Zhang, Yanshuo; Zhao, Xin; Zou, Zexiao] Beijing Elect Sci & Technol Inst, Beijing 100070, Peoples R China.
   [Zhang, Le; Zhang, Yanshuo] State Key Lab Cryprol, POB 5159, Beijing 100878, Peoples R China.
C3 Beijing Electronic Science & Technology Institute
RP Zhang, L (corresponding author), Beijing Elect Sci & Technol Inst, Beijing 100070, Peoples R China.
EM lezhang.thu@gmail.com
FU Fundamental Research Funds for the Central Universities [328201904];
   National Key Research Program of China [2017YFB0801803]
FX Supported by the Fundamental Research Funds for the Central Universities
   (No.328201904) and the National Key Research Program of China
   (No.2017YFB0801803) .
CR Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   Bellemare MG, 2013, J ARTIF INTELL RES, V47, P253, DOI 10.1613/jair.3912
   Bengio S., 2015, NIPS, DOI DOI 10.5555/2969239.2969370
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Engstrom L., 2020, 8 INT C LEARN REPR I, P2
   Gao J, 2019, SOCIAL MOBILISATION IN POST-INDUSTRIAL CHINA: THE CASE OF RURAL URBANISATION, P30
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Huang YG, 2020, PROC CVPR IEEE, P5900, DOI 10.1109/CVPR42600.2020.00594
   Ji J., 2020, CORR
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu FF, 2020, MYCOKEYS, P33, DOI 10.3897/mycokeys.69.53205
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Pan Y., P IEEE CVF C COMP VI, P10971
   Parikh, 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7299087
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Schulman J., 2017, ARXIV
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
   Tucker G, 2018, PR MACH LEARN RES, V80
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yuan C., 2020, PROC 28 INT C COMPUT, P3157
   Zhu Xizhou, 2020, CORR
   Zoph B., 2017, ICLR, P1, DOI DOI 10.1109/ICAIIC48513.2020.9065031
NR 34
TC 8
Z9 8
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104126
DI 10.1016/j.imavis.2021.104126
EA FEB 2021
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600010
DA 2024-07-18
ER

PT J
AU Solovyev, R
   Wang, WM
   Gabruseva, T
AF Solovyev, Roman
   Wang, Weimin
   Gabruseva, Tatiana
TI Weighted boxes fusion: Ensembling boxes from different object detection
   models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Computer vision; Deep learning
AB Object detection is a crucial task in computer vision systems with a wide range of applications in autonomous driving, medical imaging, retail, security, face recognition, robotics, and others. Nowadays, neural networks based models are used to localize and classify instances of objects of particular classes. When real-time inference is not required, ensembles of models help to achieve better results. In this work, we present a novel method for fusing predictions from different object detection models: weighted boxes fusion. Our algorithm utilizes confidence scores of all proposed bounding boxes to construct averaged boxes. We tested the method on several datasets and evaluated it in the context of Open Images and COCO Object Detection challenges, achieving top results in these challenges. The 3D version of boxes fusion was successfully applied by the winning teams of Waymo Open Dataset and Lyft 3D Object Detection for Autonomous Vehicles challenges. The source code is publicly available at GitHub (Solovyev, 2019 [31]). We present a novel method for combining predictions in ensembles of different object detection models: weighted boxes fusion. This method significantly improves the quality of the fused predicted rectangles for an ensemble. We tested the method on several datasets and evaluated it in the context of the Open Images and COCO Object Detection challenges. It helped to achieve top results in these challenges. The source code is publicly available at GitHub.
   (c) 2021 Published by Elsevier B.V.
C1 [Solovyev, Roman] Russian Acad Sci, Inst Design Problems Microelect, 3 Sovetskaya St, Moscow 124365, Russia.
   [Wang, Weimin] Natl Univ Singapore, 21 Lower Kent Ridge Rd, Singapore 119077, Singapore.
   [Gabruseva, Tatiana] Cork Univ Hosp, Cork, Ireland.
C3 Russian Academy of Sciences; National University of Singapore;
   University College Cork
RP Solovyev, R (corresponding author), Russian Acad Sci, Inst Design Problems Microelect, 3 Sovetskaya St, Moscow 124365, Russia.
EM roman.solovyev.zf@gmail.com
RI Wang, Weimin/L-7870-2018; Solovyev, Roman/I-3618-2014
OI Wang, Weimin/0000-0001-6557-7175; Solovyev, Roman/0000-0003-0312-452X
CR [Anonymous], 2019, Tensorflow Object Detection API
   Atwood J, 2020, SPRING SER CHALLENGE, P155, DOI 10.1007/978-3-030-29135-8_6
   Belousov S, 2020, MAP MEAN AVERAGE PRE
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Cheng SY, 2020, ANN INTERN MED, V173, P638, DOI 10.7326/M20-2927
   Codalab, 2020, CO CODETECTION CHALL
   Dollár P, 2009, PROC CVPR IEEE, P304, DOI 10.1109/CVPRW.2009.5206631
   Gabruseva T, 2020, IEEE COMPUT SOC CONF, P1436, DOI 10.1109/CVPRW50498.2020.00183
   Ge R., 2020, ARXIV200615505V1
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   He K, 2015, DEEP RESIDUAL LEARNI
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Kaggle, 2019, OPEN IMAGES OBJECT D
   Kaggle, 2019, LYFT 3D OBJECT DETEC
   Kuznetsova A., 2018, The open images dataset v4: Unified image classification, object detection, and visual relationship detection at scale
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   MMDetection, 2019, GITHUB MMDETECTION B
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Ng A.Y., 2017, ARXIV2017171105225V1
   Ning CC, 2017, IEEE INT CONF MULTI, DOI 10.1109/ICMEW.2017.8026312
   Okun O., 2011, Ensembles in Machine Learning Applications, V373
   Qiao S., 2020, GITHUB DETECTORS
   Qiao S., ARXIV200602334
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Solovyev R, 2018, PLANET UNDERSTANDING
   Solovyev R, 2019, GITHUB WEIGHTED BOXE
   Solovyev R, 2020, WBF 3D BOXES
   Solovyev R, 2020, CO COWBF BENCHMARK
   Solovyev R, 2018, KERAS RETINANET OPEN
   Solovyev RA, 2020, 2020 IEEE 40TH INTERNATIONAL CONFERENCE ON ELECTRONICS AND NANOTECHNOLOGY (ELNANO), P688, DOI [10.1109/elnano50318.2020.9088863, 10.1109/ELNANO50318.2020.9088863]
   Szeliski R, 2011, TEXTS COMPUT SCI, P181, DOI 10.1007/978-1-84882-935-0_4
   Tan M., 2020, GITHUB EFFICIENTDET
   Tensorflow, 2019, GITHUB TENSORFLOW DE
   Tensorpack, 2019, GITHUB TENSORPACK FA
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   ultralytics, 2020, YOLO V5 GITHUB
   Wang D., ARXIV190202067
   Waymo, 2020, WAYMO OPEN DATASET C
   Zhang W, 2020, LYFT 3D OBJECT DETEC
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhou HJ, 2017, IEEE INT CONF COMP V, P760, DOI 10.1109/ICCVW.2017.95
NR 42
TC 189
Z9 195
U1 10
U2 67
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104117
DI 10.1016/j.imavis.2021.104117
EA FEB 2021
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QZ7RZ
UT WOS:000630921400001
OA Green Submitted
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Lv, ZH
   Chen, DL
AF Lv, Zhihan
   Chen, Dongliang
TI Industrial visual perception technology in Smart City
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Smart city; Industrial visual perception technology; Convolutional
   neural network; Quality evaluation; Image
ID CITIES; INTERNET; THINGS
AB In order to study the application effect and function of industrial visual perception technology in smart city, the image processing and quality evaluation system was constructed by using convolutional neural network (CNN) and Internet of things (IoT) technology. The system was simulated, and then the quality performance of image and video obtained by using industrial visual perception technology was processed and analyzed. The results show that in the analysis of image local optimization effect, it is found that the classification performance of all algorithms decreases with the increase of noise, and the performance of local anisotropic mode (LAP) is superior, which has strong robustness to rotation, illumination, and noise. In the analysis of image feature similarity effect, it is found that the chi square distance between Log Gabor features is positively correlated with the degree of image distortion, and the validity of the measurement method is verified. Further analysis of the video processing effect of industrial visual perception technology shows that the video processing effect of test algorithm is significantly better than that of HM16.8 by comparing the distortion performance of the two algorithms with different sequences, with low distortion and significantly improved performance. Therefore, through the research, it is found that the improved CNN algorithm is superior to other algorithms in image and video processing. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Lv, Zhihan; Chen, Dongliang] Qingdao Univ, Sch Data Sci & Software Engn, Qingdao 266071, Peoples R China.
C3 Qingdao University
RP Lv, ZH (corresponding author), Qingdao Univ, Sch Data Sci & Software Engn, Qingdao 266071, Peoples R China.
EM lvzhihan@gmail.com
RI Lv, Zhihan/GLR-6000-2022; Lyu, Zhihan/I-3187-2014
OI Lv, Zhihan/0000-0003-2525-3074; Lyu, Zhihan/0000-0003-2525-3074;
   Dongliang, Chen/0000-0001-7700-4729
FU National Natural Science Foundation of China [61902203]; Natural Science
   Foundation of Shandong Province [ZR2017QF015]; Key Research and
   Development Plan - Major Scientific and Technological Innovation
   Projects of ShanDong Province [2019JZZY020101]
FX This work was supported by National Natural Science Foundation of China
   (No. 61902203), Natural Science Foundation of Shandong Province
   (ZR2017QF015) and Key Research and Development Plan - Major Scientific
   and Technological Innovation Projects of ShanDong Province
   (2019JZZY020101).
CR Ahmed E, 2016, IEEE WIREL COMMUN, V23, P10, DOI 10.1109/MWC.2016.7721736
   Arshad H, 2017, INT J ADV SCI ENG IN, V7, P496
   Betis G, 2018, P IEEE, V106, P507, DOI 10.1109/JPROC.2018.2814239
   Cao CS, 2019, IEEE T PATTERN ANAL, V41, P1627, DOI 10.1109/TPAMI.2018.2843329
   Chen FC, 2018, IEEE T IND ELECTRON, V65, P4392, DOI 10.1109/TIE.2017.2764844
   Chen JW, 2018, IEEE T INSTRUM MEAS, V67, P257, DOI 10.1109/TIM.2017.2775345
   Choi C.H., 2016, J KOREA I INTELLIG T, V15, P1
   Clement S. J., 2017, 2017 11th IEEE Symposium on Service-Oriented System Engineering (SOSE). Proceedings, P81, DOI 10.1109/SOSE.2017.29
   Crisostomi E, 2016, IEEE TECHNOL SOC MAG, V35, P23, DOI 10.1109/MTS.2016.2592782
   Dameri RP, 2016, P ANN HICSS, P2974, DOI 10.1109/HICSS.2016.372
   Dong YS, 2017, IEEE SIGNAL PROC LET, V24, P614, DOI 10.1109/LSP.2017.2670026
   Faghih-Roohi S, 2016, IEEE IJCNN, P2584, DOI 10.1109/IJCNN.2016.7727522
   He NJ, 2019, IEEE T GEOSCI REMOTE, V57, P755, DOI 10.1109/TGRS.2018.2860464
   Lima S, 2019, INT CONF EDEMOC EGOV, P180, DOI [10.1109/ICEDEG.2019.8734346, 10.1109/icedeg.2019.8734346]
   Lv ZH, 2019, IEEE ACCESS, V7, P65211, DOI 10.1109/ACCESS.2019.2915487
   Mehmood Y, 2017, IEEE COMMUN MAG, V55, P16, DOI 10.1109/MCOM.2017.1600514
   Muhammad K, 2019, IEEE COMMUN MAG, V57, P60, DOI 10.1109/MCOM.2018.1800371
   Paganelli F, 2016, IEEE SYST J, V10, P1412, DOI 10.1109/JSYST.2014.2354835
   Qian Y, 2019, IEEE NETWORK, V33, P4, DOI 10.1109/mnet.2019.8675165
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Nguyen VL, 2016, INT C PATT RECOG, P2006, DOI 10.1109/ICPR.2016.7899931
   Wang LZ, 2016, IEEE T COMPUT, V65, P1337, DOI 10.1109/TC.2016.2538059
   Xin X.I.E., 2018, J CHINA U METROL, V2, P14
   Xu YP, 2018, IEEE T DIELECT EL IN, V25, P533, DOI 10.1109/TDEI.2018.006919
   Yan MX, 2017, INT C WAVEL ANAL PAT, P188, DOI 10.1109/ICWAPR.2017.8076687
   Yonghong Hou, 2018, IEEE Transactions on Circuits and Systems for Video Technology, V28, P807, DOI 10.1109/TCSVT.2016.2628339
   Zhu HX, 2017, IEEE IND ELEC, P6187, DOI 10.1109/IECON.2017.8217074
NR 27
TC 3
Z9 3
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104070
DI 10.1016/j.imavis.2020.104070
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800009
DA 2024-07-18
ER

PT J
AU Gu, Y
   Ye, XF
   Sheng, WH
   Ou, YS
   Li, YQ
AF Gu, Ye
   Ye, Xiaofeng
   Sheng, Weihua
   Ou, Yongsheng
   Li, Yongqiang
TI Multiple stream deep learning model for human action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Information fusion; Action recognition
AB Human action recognition is one of the most important and challenging topic in the fields of image processing. Unlike object recognition, action recognition requires motion feature modeling which contains not only spatial but also temporal information. In this paper, we use multiple models to characterize both global and local motion features. Global motion patterns are represented efficiently by the depth-based 3-channel motion history images (MHIs). Meanwhile, the local spatial and temporal patterns are extracted from the skeleton graph. The decisions of these two streams are fused. At the end, the domain knowledge, which is the object/action dependency is considered. The proposed framework is evaluated on two RGB-D datasets. The experimental results show the effectiveness of our proposed approach. The performance is comparable with the state-of-the-art. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Gu, Ye] Shenzhen Technol Univ, 3002 Lantian St, Shenzhen 518118, Peoples R China.
   [Ye, Xiaofeng] Shenzhen Acad Robot, 6 Yuexing Er St, Shenzhen 518052, Peoples R China.
   [Sheng, Weihua] Oklahoma State Univ, Whitehurst Hall 301, Stillwater, OK 74078 USA.
   [Ou, Yongsheng] Chinese Acad Sci, Shenzhen Inst Adv Technol, 1068 Xueyuan St, Shenzhen 518055, Peoples R China.
   [Li, Yongqiang] Harbin Inst Technol, 92 Xidazhi St, Harbin 150001, Peoples R China.
C3 Shenzhen Technology University; Shenzhen Academy of Robotics; Oklahoma
   State University System; Oklahoma State University - Stillwater; Chinese
   Academy of Sciences; Shenzhen Institute of Advanced Technology, CAS;
   Harbin Institute of Technology
RP Gu, Y (corresponding author), Shenzhen Technol Univ, 3002 Lantian St, Shenzhen 518118, Peoples R China.
EM guye@sztu.edu.cn
FU National Natural Science Foundation of China [61976070, U1713216];
   Shenzhen Overseas High Level Talent (Peacock Plan) Program
   [KQTD20140630154026047]; Shenzhen Basic Research Projects
   [K1120160429161539298]
FX This project is supported by the National Natural Science Foundation of
   China (No. 61906123), Shenzhen Overseas High Level Talent (Peacock Plan)
   Program (No. KQTD20140630154026047), National Natural Science Foundation
   of China (No. 61976070, No. U1713216) and Shenzhen Basic Research
   Projects K1120160429161539298).
CR [Anonymous], ABS160504988 CORR
   [Anonymous], 2016, CORR
   [Anonymous], 2017, CORR
   [Anonymous], CORR
   [Anonymous], 2015, CORR
   [Anonymous], 2014, 2014 INT C LEARNING
   Cai YP, 2016, IEEE GLOBE WORK
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chandraker Manmohan, 2018, CORR
   Chen C, 2015, IEEE WINT CONF APPL, P1092, DOI 10.1109/WACV.2015.150
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duckworth P, 2016, FRONT ARTIF INTEL AP, V285, P1062, DOI 10.3233/978-1-61499-672-9-1062
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jingen Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3337, DOI 10.1109/CVPR.2011.5995353
   Ke Q., 2018, P AS C COMP VIS
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Lei Z, 2012, INT C PATT RECOG, P1136
   Li YH, 2016, LECT NOTES COMPUT SC, V9911, P203, DOI 10.1007/978-3-319-46478-7_13
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Luo JJ, 2013, IEEE I CONF COMP VIS, P1809, DOI 10.1109/ICCV.2013.227
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Ni BB, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shahroudy A, 2018, IEEE T PATTERN ANAL, V40, P1045, DOI 10.1109/TPAMI.2017.2691321
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Simonyan K., 2014, CORR
   Song SB, 2016, IEEE COMPUT SOC CONF, P378, DOI 10.1109/CVPRW.2016.54
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Wang PC, 2016, IEEE T HUM-MACH SYST, V46, P498, DOI 10.1109/THMS.2015.2504550
   Watanabe K, 2008, BLISS 2008: 2008 ECSIS SYMPOSIUM ON BIO-INSPIRED, LEARNING AND INTELLIGENT SYSTEMS FOR SECURITY, PROCEEDINGS, P51, DOI 10.1109/BLISS.2008.15
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhang YP, 2012, IEEE VTS VEH TECHNOL
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao ZC, 2017, IEEE I CONF COMP VIS, P3411, DOI 10.1109/ICCV.2017.367
   Zhu WT, 2016, AAAI CONF ARTIF INTE, P3697
NR 43
TC 20
Z9 21
U1 1
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103818
DI 10.1016/j.imavis.2019.10.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000006
DA 2024-07-18
ER

PT J
AU Galiyawala, H
   Raval, MS
   Dave, S
AF Galiyawala, Hiren
   Raval, Mehul S.
   Dave, Shivansh
TI Visual appearance based person retrieval in unconstrained environment
   videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Linear filtering; Person retrieval; Semantic description; Soft
   biometrics; Video surveillance
ID SURVEILLANCE
AB Visual appearance-based person retrieval is a challenging problem in surveillance. It uses attributes like height, cloth color, cloth type and gender to describe a human. Such attributes are known as soft biometrics. This paper proposes person retrieval from surveillance video using height, torso cloth type, torso cloth color and gender. The approach introduces an adaptive torso patch extraction and bounding box regression to improve the retrieval. The algorithm uses fine-tuned Mask R-CNN and DenseNet-169 for person detection and attribute classification respectively. The performance is analyzed on AVSS 2018 challenge II dataset and it achieves 11.35% improvement over state-of-the-art based on average Intersection over Union measure. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Galiyawala, Hiren; Raval, Mehul S.] Pandit Deendayal Petr Univ, Sch Technol, Dept Informat & Commun Technol, Gandhinagar, India.
   [Dave, Shivansh] Univ Windsor, Dept Comp Sci, Windsor, ON, Canada.
C3 Pandit Deendayal Energy University; University of Windsor
RP Galiyawala, H (corresponding author), Pandit Deendayal Petr Univ, Sch Technol, Dept Informat & Commun Technol, Gandhinagar, India.
EM hiren.gphd19@sot.pdpu.ac.in; mehul.raval@sot.pdpu.ac.in;
   dave11o@uwindsor.ca
OI Raval, Mehul/0000-0002-3895-1448; Galiyawala, Hiren/0000-0002-2973-3844
FU Board of Research in Nuclear Sciences (BRNS) of India
   [36(3)/14/20/2016-BRNS/36020]
FX This work is supported by the Board of Research in Nuclear Sciences
   (BRNS) of India (36(3)/14/20/2016-BRNS/36020). The authors acknowledge
   the support of NVIDIA Corporation for a donation of the Quadro K5200 GPU
   used for this research. We would also like to thank the AVSS 2018
   challenge II organizers for creating the challenging dataset and
   providing the necessary details to compare the performance.
CR [Anonymous], PROC CVPR IEEE
   [Anonymous], INT C NEUR INT PROC
   [Anonymous], DEEP BIOMETRICS
   Dantcheva A, 2016, IEEE T INF FOREN SEC, V11, P441, DOI 10.1109/TIFS.2015.2480381
   Deng YB, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P789, DOI 10.1145/2647868.2654966
   Denman S, 2015, PATTERN RECOGN LETT, V68, P306, DOI 10.1016/j.patrec.2015.06.015
   Galiyawala H., 2018, 2018 15 IEEE INT C A, P1
   Halstead M., 2018, 2018 15 IEEE INT C A, P1
   Halstead M, 2014, INT C PATT RECOG, P4501, DOI 10.1109/ICPR.2014.770
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Li DW, 2018, IEEE INT CON MULTI
   Li DW, 2019, IEEE T IMAGE PROCESS, V28, P1575, DOI 10.1109/TIP.2018.2878349
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Martinho-Corbishley D, 2016, IEEE T CONTROL NETW, P1
   Martinho-Corbishley D, 2019, IEEE T PATTERN ANAL, V41, P1486, DOI 10.1109/TPAMI.2018.2836900
   Martinho-Corbishley D, 2016, INT C PATT RECOG, P3067, DOI 10.1109/ICPR.2016.7900105
   Raval, 2016, CSI COMMUNICATIONS, V39, P9
   Reid DA, 2013, HANDB STAT, V31, P327, DOI 10.1016/B978-0-444-53859-8.00013-8
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schumann A., 2018, 2018 15 IEEE INT C A, P1
   Shah P, 2017, NAT C COMP VIS PATT, P457
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Yaguchi T., 2018, 2018 15 IEEE INT C A, P1
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
NR 28
TC 9
Z9 9
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2019
VL 92
AR 103816
DI 10.1016/j.imavis.2019.10.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JW2JO
UT WOS:000502884200007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, Y
   He, CJ
   Wu, YF
   Ren, ZM
AF Liu, Yang
   He, Chuanjiang
   Wu, Yongfei
   Ren, Zemin
TI The <i>L</i><sub>0</sub>-regularized discrete variational level set
   method for image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Level set; Variational model; L-0-based regularizer
ID SCALABLE FITTING ENERGY; ACTIVE CONTOURS DRIVEN; RE-INITIALIZATION;
   MODEL; MINIMIZATION; EVOLUTION; FORMULATION; ALGORITHMS
AB In this paper, we present a new variant of level set methods and then propose a ternary variational level set model involving L-0 gradient regularizer and L(0 )function regularizer in discrete framework, following the Chan-Vese model for image segmentation. Different from the existing level set methods, we use the 0.5-level set of a ternary function whose values are within {0,0.5,1} to implicitly represent the interfaces between subregions and use L-0 counting operator to discretely measure the length of interfaces and the area of foreground subregions. The proposed model can be regarded as a discrete form of the Chan-Vese model. Based on the half-quadratic splitting method, we design an alternating minimization algorithm to solve our model efficiently. Experimental results show that the proposed method has good performance for segmentation of images with severe noise, outliers or low contrast (C) 2018 Elsevier B.V All rights reserved.
C1 [Liu, Yang; He, Chuanjiang] Chongqing Univ, Coll Math & Stat, Chongqing 401331, Peoples R China.
   [Wu, Yongfei] Taiyuan Univ Technol, Coll Data Sci, Taiyuan 030024, Shanxi, Peoples R China.
   [Ren, Zemin] Chongqing Univ Sci & Technol, Coll Math & Phys, Chongqing 401331, Peoples R China.
C3 Chongqing University; Taiyuan University of Technology; Chongqing
   University of Science & Technology
RP He, CJ (corresponding author), Chongqing Univ, Coll Math & Stat, Chongqing 401331, Peoples R China.
EM cquyangliu@163.com; chuanjianghe@sina.com
RI Wu, Yongfei/AAI-2243-2019
FU Chinese National Science Foundation [61561019, 11371384]; Chongqing
   Graduate Student Research Innovation Project [CYS14020]; Scientific and
   Technological Innovation Programs of Higher Education Institutions in
   Shanxi [2017141]; National Natural Science Foundation of China
   [61601068]; Scientific and Technological Research Program of Chongqing
   Municipal Education Commission [KJ1601317]
FX We would like to thank the reviewers of this manuscript for their
   helpful comments and suggestions. This work was partially supported by
   the Chinese National Science Foundation (61561019, 11371384), Chongqing
   Graduate Student Research Innovation Project (CYS14020), Scientific and
   Technological Innovation Programs of Higher Education Institutions in
   Shanxi (No. 2017141), National Natural Science Foundation of China
   (61601068) and Scientific and Technological Research Program of
   Chongqing Municipal Education Commission (Grant No. KJ1601317).
CR Afonso MV, 2015, IEEE T IMAGE PROCESS, V24, P2239, DOI 10.1109/TIP.2015.2417505
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   Chang HB, 2017, IEEE T MED IMAGING, V36, P721, DOI 10.1109/TMI.2016.2636026
   Dong FF, 2013, IMAGE VISION COMPUT, V31, P809, DOI 10.1016/j.imavis.2013.08.003
   Duan YP, 2014, IEEE IMAGE PROC, P6, DOI 10.1109/ICIP.2014.7025000
   Duan YP, 2015, IEEE T IMAGE PROCESS, V24, P3927, DOI 10.1109/TIP.2015.2451957
   He CJ, 2012, SIGNAL PROCESS, V92, P587, DOI 10.1016/j.sigpro.2011.09.004
   Huang CC, 2016, APPL MATH MODEL, V40, P7739, DOI 10.1016/j.apm.2016.03.039
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2010, IEEE T IMAGE PROCESS, V19, P3243, DOI 10.1109/TIP.2010.2069690
   Li CM, 2005, PROC CVPR IEEE, P430
   Li J, 2016, J VIS COMMUN IMAGE R, V40, P14, DOI 10.1016/j.jvcir.2016.06.003
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   Liu B, 2010, PATTERN RECOGN, V43, P2028, DOI 10.1016/j.patcog.2010.01.002
   Liu C, 2017, SIGNAL PROCESS, V130, P12, DOI 10.1016/j.sigpro.2016.06.013
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Shattuck DW, 2001, NEUROIMAGE, V13, P856, DOI 10.1006/nimg.2000.0730
   Taheri S, 2010, IMAGE VISION COMPUT, V28, P26, DOI 10.1016/j.imavis.2009.04.005
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Wu YF, 2015, SIGNAL PROCESS, V106, P123, DOI 10.1016/j.sigpro.2014.07.013
   Xiao Y, 2011, PATTERN RECOGN, V44, P1708, DOI 10.1016/j.patcog.2011.02.002
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu L, 2011, ACM T GRAPHIC, V30, DOI 10.1145/2024156.2024208
   Zhang KH, 2010, IMAGE VISION COMPUT, V28, P668, DOI 10.1016/j.imavis.2009.10.009
   Zhang KH, 2010, PATTERN RECOGN, V43, P1199, DOI 10.1016/j.patcog.2009.10.010
   Zheng Y, 2009, IMAGE VISION COMPUT, V27, P1411, DOI 10.1016/j.imavis.2009.01.001
NR 29
TC 15
Z9 15
U1 2
U2 20
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2018
VL 75
BP 32
EP 43
DI 10.1016/j.imavis.2018.03.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GM3LM
UT WOS:000438006100004
DA 2024-07-18
ER

PT J
AU Muhammad, UR
   Svanera, M
   Leonardi, R
   Benini, S
AF Muhammad, Umar Riaz
   Svanera, Michele
   Leonardi, Riccardo
   Benini, Sergio
TI Hair detection, segmentation, and hairstyle classification in the wild
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hair detection; Hair segmentation; Hairstyle classification; Texture
   analysis; Hair database
ID FACE RECOGNITION; HEAD DETECTION; APPEARANCE; SCALE
AB Hair highly characterises human appearance. Hair detection in images is useful for many applications, such as face and gender recognition, video surveillance, and hair modelling. We tackle the problem of hair analysis (detection, segmentation, and hairstyle classification) from unconstrained view by relying only on textures, without a-priori information on head shape and location, nor using body-part classifiers. We first build a hair probability map by classifying overlapping patches described by features extracted from a CNN, using Random Forest. Then modelling hair (resp. non-hair) from high (resp. low) probability regions, we segment at pixel level uncertain areas by using LTP features and SVM. For the experiments we extend Figaro, an image database for hair detection to Figaro1k, a new version with more than 1000 manually annotated images. Achieved segmentation accuracy (around 90%) is superior to known state-of-the-art. Images are eventually classified into hairstyle classes: straight, wavy, curly, kinky, braids, dreadlocks, and short. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Muhammad, Umar Riaz; Svanera, Michele; Leonardi, Riccardo; Benini, Sergio] Univ Brescia, Dept Informat Engn, Brescia, Italy.
   [Muhammad, Umar Riaz] Queen Mary Univ London, Sch EECS, London, England.
   [Svanera, Michele] Univ Glasgow, Inst Neurosci & Psychol, Glasgow, Lanark, Scotland.
C3 University of Brescia; University of London; Queen Mary University
   London; University of Glasgow
RP Svanera, M (corresponding author), Univ Brescia, Dept Informat Engn, Brescia, Italy.; Svanera, M (corresponding author), Univ Glasgow, Inst Neurosci & Psychol, Glasgow, Lanark, Scotland.
EM u.muhammad@qmul.ac.uk; Michele.Svanera@glasgow.ac.uk;
   riccardo.leonardi@unibs.it; sergio.benini@ing.unibs.it
RI Svanera, Michele/AAN-7736-2020; Leonardi, Riccardo/F-5666-2010
OI Svanera, Michele/0000-0002-7828-9209; 
CR Aarabi P, 2015, IEEE INT SYM MULTIM, P69, DOI 10.1109/ISM.2015.16
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2003, EXPLORING ARTIFICIAL
   [Anonymous], 1980, TECH REP
   [Anonymous], 2008, FG
   [Anonymous], NATURE
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2016, ACM T GRAPHIC, DOI DOI 10.1145/2897824.2925961
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2015, IEEE IMAGE PROC
   [Anonymous], 2013, 2013 10 IEEE INT C W
   [Anonymous], 1998, CVC TECHNICAL REPORT
   [Anonymous], PASCAL VISUAL OBJECT
   [Anonymous], COMP VIS PATT REC 20
   Bell S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462002
   Benini S., 2016, Multimed. Tools Appl., P1
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Breiman L., 2001, Mach. Learn., V45, P5
   Caputo B, 2005, IEEE I CONF COMP VIS, P1597, DOI 10.1109/iccv.2005.54
   Chai ML, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2816795.2818112
   Chai ML, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461990
   Chai ML, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185612
   Cimpoi M, 2016, INT J COMPUT VISION, V118, P65, DOI 10.1007/s11263-015-0872-3
   Cimpoi M, 2015, PROC CVPR IEEE, P3828, DOI 10.1109/CVPR.2015.7299007
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dan Wang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P233, DOI 10.1109/FG.2011.5771403
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ferrari V., 2007, P 20 INT C NEUR INF, P433
   Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858
   Jackson AS, 2016, LECT NOTES COMPUT SC, V9915, P143, DOI 10.1007/978-3-319-49409-8_14
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnston RA, 2009, MEMORY, V17, P577, DOI 10.1080/09658210902976969
   Julian P., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4617, DOI 10.1109/ICPR.2010.1134
   Kakadiaris IA, 2016, IEEE IMAGE PROC, P3156, DOI 10.1109/ICIP.2016.7532941
   Khan K, 2017, IEEE INT CON MULTI, P175, DOI 10.1109/ICME.2017.8019521
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liu ZQ, 1996, ISSPA 96 - FOURTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, PROCEEDINGS, VOLS 1 AND 2, P575
   Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perronnin Florent, 2007, 2007 IEEE C COMPUTER, P1
   Roth J, 2014, AAAI CONF ARTIF INTE, P2824
   Rousset C, 2010, IEEE IMAGE PROC, P237, DOI 10.1109/ICIP.2010.5651970
   Rousset C, 2008, IEEE IMAGE PROC, P2276, DOI 10.1109/ICIP.2008.4712245
   Schwartz G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P883, DOI 10.1109/ICCVW.2013.121
   Sharan L, 2013, INT J COMPUT VISION, V103, P348, DOI 10.1007/s11263-013-0609-0
   SHEPHERD J., 1981, PERCEIVING REMEMBERI
   Sherrow Victoria., 2006, ENCY HAIR CULTURAL H
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Svanera M., 2015, 2015 13th International Workshop on Content-Based Multimedia Indexing (CBMI), P1, DOI DOI 10.1109/CBMI.2015.7153627
   Svanera M, 2016, IEEE IMAGE PROC, P933, DOI 10.1109/ICIP.2016.7532494
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Toseeb U, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034144
   Ueki K, 2004, INT C PATT RECOG, P446, DOI 10.1109/ICPR.2004.1333798
   Walker A., 1997, Andre Talks Hair!
   Wang D, 2009, IEEE IMAGE PROC, P2401, DOI 10.1109/ICIP.2009.5414215
   Wang Y, 2014, INT C PATT RECOG, P450, DOI 10.1109/ICPR.2014.86
   Wright DB, 2003, ACTA PSYCHOL, V114, P101, DOI 10.1016/S0001-6918(03)00052-0
   Xu RY, 2015, MULTIMED TOOLS APPL, V74, P729, DOI 10.1007/s11042-014-2177-x
   Yacoob Y, 2006, IEEE T PATTERN ANAL, V28, P1164, DOI 10.1109/TPAMI.2006.139
   Zhang Z, 2008, IEEE IMAGE PROC, P1644, DOI 10.1109/ICIP.2008.4712087
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 65
TC 18
Z9 21
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2018
VL 71
BP 25
EP 37
DI 10.1016/j.imavis.2018.02.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GB1QS
UT WOS:000428825900003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Deng, DG
   Wang, RM
   Wu, HF
   He, HY
   Li, Q
   Luo, XN
AF Deng, Daiguo
   Wang, Ruomei
   Wu, Hefeng
   He, Huayong
   Li, Qi
   Luo, Xiaonan
TI Learning deep similarity models with focus ranking for fabric image
   retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional neural network; Fabric image retrieval; Metric embedding;
   Focus ranking
AB Fabric image retrieval is beneficial to many applications including clothing searching, online shopping and cloth modeling. Learning pairwise image similarity is of great importance to an image retrieval task. With the resurgence of Convolutional Neural Networks (CNN5), recent works have achieved significant progresses via deep representation learning with metric embedding, which drives similar examples close to each other in a feature space, and dissimilar ones apart from each other. In this paper, we propose a novel embedding method termed focus ranking that can be easily unified into a CNN for jointly learning image representations and metrics in the context of fine-grained fabric image retrieval. Focus ranking aims to rank similar examples higher than all dissimilar ones by penalizing ranking disorders via the minimization of the overall cost attributed to similar samples being ranked below dissimilar ones. At the training stage, training samples are organized into focus ranking units for efficient optimization. We build a large-scale fabric image retrieval dataset (FIRD) with about 25,000 images of 4300 fabrics, and test the proposed model on the FIRD dataset. Experimental results show the superiority of the proposed model over existing metric embedding models. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Deng, Daiguo; Wang, Ruomei; He, Huayong] Sun Yat Sen Univ, Guangzhou 510006, Guangdong, Peoples R China.
   [Wu, Hefeng] Guangdong Univ Foreign Studies, Guangzhou 510006, Guangdong, Peoples R China.
   [Li, Qi] Western Kentucky Univ, Bowling Green, KY 42101 USA.
   [Luo, Xiaonan] Guilin Univ Elect Technol, Guilin 541004, Peoples R China.
C3 Sun Yat Sen University; Guangdong University of Foreign Studies; Western
   Kentucky University; Guilin University of Electronic Technology
RP Wu, HF (corresponding author), Guangdong Univ Foreign Studies, Guangzhou 510006, Guangdong, Peoples R China.
EM wuhefeng@gmail.com
OI Wu, Hefeng/0000-0002-2132-6515
FU National Natural Science Foundation of China [61379112, 61402120,
   61672547, 61472455, 61370186]
FX This work was supported in part by the National Natural Science
   Foundation of China (61379112, 61402120, 61672547, 61472455, 61370186).
   The authors would like to thank Shenzhen Micro Vision Technology Co.,
   Ltd. for providing the large-scale dataset of 100,000 fabric images for
   evaluation.
CR [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2016, INT C LEARN REPR
   [Anonymous], 2007, P IEEE C COMP VIS PA
   Babenko A., P EUR C COMP VIS ECC
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Bottou L., 2012, Neural networks: Tricks of the trade, P421, DOI DOI 10.1007/978-3-642-35289-8_25
   Chen SZ, 2016, IEEE T IMAGE PROCESS, V25, P2353, DOI 10.1109/TIP.2016.2545929
   Chen TS, 2018, AAAI CONF ARTIF INTE, P6730
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   diaeresis>tze Hinrich Schu<spacing, 2008, INTRO INFORM RETRIEV, V39
   Douze M, 2009, P ACM INT C IM VID R, P1, DOI DOI 10.1145/1646396.1646421
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hu JL, 2014, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2014.242
   Jammalamadaka N, 2017, IMAGE VISION COMPUT, V59, P31, DOI 10.1016/j.imavis.2016.12.002
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jegou H, 2007, PROC CVPR IEEE, P9
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Lin L, 2016, INT J COMPUT VISION, V118, P256, DOI 10.1007/s11263-015-0876-z
   Liu H, 2015, NEUROCOMPUTING, V151, P1283, DOI 10.1016/j.neucom.2014.11.002
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Paulin M, 2015, IEEE I CONF COMP VIS, P91, DOI 10.1109/ICCV.2015.19
   PERRONNIN F, 2010, PROC CVPR IEEE, P3384, DOI DOI 10.1109/CVPR.2010.5540009
   Perronnin F, 2015, PROC CVPR IEEE, P3743, DOI 10.1109/CVPR.2015.7298998
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Perronnin F, 2007, PROC CVPR IEEE, P2272
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang ZD, 2017, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2017.49
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Yandex Artem Babenko, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1269, DOI 10.1109/ICCV.2015.150
   Yun H., P ADV NEUR INF PROC
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang RM, 2015, IEEE T IMAGE PROCESS, V24, P4766, DOI 10.1109/TIP.2015.2467315
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zhu JQ, 2017, IMAGE VISION COMPUT, V58, P224, DOI 10.1016/j.imavis.2016.07.004
NR 51
TC 27
Z9 31
U1 0
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2018
VL 70
BP 11
EP 20
DI 10.1016/j.imavis.2017.12.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GA7AR
UT WOS:000428487500002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Rattani, A
   Derakhshani, R
AF Rattani, Ajita
   Derakhshani, Reza
TI Ocular biometrics in the visible spectrum: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Biometrics; Ocular biometrics; Mobile biometrics; Iris; Conjunctival
   vasculature; Periocular biometrics; Visible spectrum
ID IRIS RECOGNITION; PERIOCULAR RECOGNITION; IMAGE; COLOR; ALGORITHM;
   FEATURES; PATTERN; FUSION
AB Ocular biometrics encompasses the imaging and use of characteristic features extracted from the eyes for personal recognition. Ocular biometric modalities in visible light have mainly focused on iris, blood vessel structures over the white of the eye (mostly due to conjunctival and episcieral layers), and periocular region around eye. Most of the existing studies on iris recognition use the near infrared spectrum. However, conjunctival vasculature and periocular regions are imaged in the visible spectrum. Iris recognition in the visible spectrum is possible for light color irides or by utilizing special illumination. Ocular recognition in the visible spectrum is an important research area due to factors such as recognition at a distance, suitability for recognition with regular RGB cameras, and adaptability to mobile devices. Further these ocular modalities can be obtained from a single RGB eye image, and then fused together for enhanced performance of the system. Despite these advantages, the state-of-the-art related to ocular biometrics in visible spectrum is not well known. This paper surveys this topic in terms of computational image enhancement, feature extraction, classification schemes and designed hardware-based acquisition set-ups. Future research directions are also enumerated to identify the path forward. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Rattani, Ajita; Derakhshani, Reza] Univ Missouri, Kansas City, MO USA.
C3 University of Missouri System; University of Missouri Kansas City
RP Rattani, A (corresponding author), Univ Missouri, Kansas City, MO USA.
EM rattania@umkc.edu; derakhshanir@umkc.edu
CR Abate AF, 2015, PATTERN RECOGN LETT, V57, P43, DOI 10.1016/j.patrec.2014.10.017
   Adams J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P205, DOI 10.1109/ICPR.2010.59
   Agarwal S., 2014, IOSR J COMPUT ENG, V16, P47
   Alonso-Fernandez F., 2015, PATTERN RECOGN LETT
   Alonso-Fernandez F., 2015, BIOM FOR IWBF 2015 I, P1
   Alonso-Fernandez F, 2015, IET BIOMETRICS, V4, P74, DOI 10.1049/iet-bmt.2014.0038
   Alonso-Fernandez F, 2014, IEEE IMAGE PROC, P4987, DOI 10.1109/ICIP.2014.7026010
   [Anonymous], PATTERN ANAL APPL
   [Anonymous], 2011, 2011 INT JOINT C BIO
   [Anonymous], P ANN IEEE IND C IND
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], IEEE INT C BOM THEOR
   [Anonymous], 2016, BIOM FOR IWBF 2016 4
   [Anonymous], 2010, P 2010 ACM S APPL CO, DOI DOI 10.1145/1774088.1774408
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2013, ELECT LETT COMPUT VI
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   [Anonymous], 2006, Handbook of Multibiometrics
   Arora S. S., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P336, DOI 10.1109/ICB.2012.6199829
   Baker SE, 2010, COMPUT VIS IMAGE UND, V114, P1030, DOI 10.1016/j.cviu.2010.06.002
   Bakshi S, 2015, BIOCYBERN BIOMED ENG, V35, P30, DOI 10.1016/j.bbe.2014.05.003
   Barra S, 2015, PATTERN RECOGN LETT, V57, P66, DOI 10.1016/j.patrec.2014.10.011
   Bharadwaj Samarth., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Boddeti N., 2008, 2nd IEEE International Conference on Biometrics: Theory, Applications and Systems, P1
   Boddeti V.N., 2011, BIOMETRICS IJCB 2011, P1, DOI 10.1109/ijcb.2011.6117500
   Bourlai T, 2011, IEEE T INF FOREN SEC, V6, P371, DOI 10.1109/TIFS.2011.2109951
   Bowyer KW, 2012, PATTERN RECOGN LETT, V33, P965, DOI 10.1016/j.patrec.2011.11.024
   Bruni V, 2015, PATTERN RECOGN LETT, V57, P74, DOI 10.1016/j.patrec.2014.09.001
   Busch C, 2013, P 18 INT C DIGITAL S, P1
   Cao Z., 2015, Pattern Recognition Letters
   Chen L, 2015, MED IMAGE ANAL, V23, P1, DOI 10.1016/j.media.2015.03.004
   Chun-Wei Tan, 2014, IEEE Transactions on Information Forensics and Security, V9, P1518, DOI 10.1109/TIFS.2014.2339496
   Crihalmeanu A., 2011, IEEE Workshop on Applications of Computer Vision, P204
   Crihalmeanu S., 2007, TECH REP
   Crihalmeanu S, 2012, PATTERN RECOGN LETT, V33, P1860, DOI 10.1016/j.patrec.2011.11.006
   Crihalmeanu S, 2009, LECT NOTES COMPUT SC, V5558, P1240, DOI 10.1007/978-3-642-01793-3_125
   Das Abhijit, 2014, 2014 IEEE Symposium on Computational Intelligence in Biometrics and Identity Management (CIBIM). Proceedings, P22, DOI 10.1109/CIBIM.2014.7015439
   Das A., 2013, Biometric Recognition, V8232, P370
   Das A, 2013, INT CONF INTELL SYST, P74, DOI 10.1109/ISDA.2013.6920711
   Das A, 2014, IEEE INT FUZZY SYST, P561, DOI 10.1109/FUZZ-IEEE.2014.6891684
   Das A, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P917, DOI 10.1109/ACPR.2013.168
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   De Marsico M, 2015, PATTERN RECOGN LETT, V57, P17, DOI 10.1016/j.patrec.2015.02.009
   De Marsico M, 2014, IMAGE VISION COMPUT, V32, P1161, DOI 10.1016/j.imavis.2013.12.014
   Demirel H., 2008, International Symposium in Computer and Information Sciences, P1
   Derakhshani R., 2006, Artificial Neural Networks in Engineering, P1
   Derakhshani R, 2007, IEEE IJCNN, P2987
   Dobes M, 2004, OPTIK, V115, P399, DOI 10.1078/0030-4026-00388
   Dong YH, 2012, INT J PROD RES, V50, P2681, DOI 10.1080/00207543.2011.579637
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   Du YZ, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/936512
   Farouk RM, 2011, COMPUT VIS IMAGE UND, V115, P1239, DOI 10.1016/j.cviu.2011.04.002
   Farzin H, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/280635
   Fenghua Wang, 2007, WSEAS Transactions on Information Science and Applications, V4, P1415
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   Gottemukkula V, 2016, IET BIOMETRICS, V5, P3, DOI 10.1049/iet-bmt.2014.0059
   Gottemukkula V, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, P150, DOI 10.1109/THS.2012.6459841
   Haindl M, 2015, PATTERN RECOGN LETT, V57, P60, DOI 10.1016/j.patrec.2015.02.012
   Hollingsworth K, 2009, COMPUT VIS IMAGE UND, V113, P150, DOI 10.1016/j.cviu.2008.08.001
   Hollingsworth KP, 2014, J FORENSIC SCI, V59, P648, DOI 10.1111/1556-4029.12357
   Hosseini MS, 2010, IEEE T INSTRUM MEAS, V59, P792, DOI 10.1109/TIM.2009.2037996
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Hu Y, 2015, PATTERN RECOGN LETT, V57, P24, DOI 10.1016/j.patrec.2014.12.012
   Ikin S., EDGE DETECTION REDUC, V9443, P94430
   Jillela R.R., 2014, PATTERN RECOGN LET 1, P4
   Jillela R, 2014, IEEE IMAGE PROC, P4997, DOI 10.1109/ICIP.2014.7026012
   Jobson D. J., 2002, PORC SPIE, V4662
   Joshi A, 2012, 2012 12TH INTERNATIONAL CONFERENCE ON HYBRID INTELLIGENT SYSTEMS (HIS), P57, DOI 10.1109/HIS.2012.6421309
   Juefei-Xu Felix, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P141, DOI 10.1109/CVPRW.2015.7301308
   Kang BJ, 2009, INT J IMAG SYST TECH, V19, P323, DOI 10.1002/ima.20209
   Keshari R, 2016, IEEE IMAGE PROC, P3116, DOI 10.1109/ICIP.2016.7532933
   Kourkoumelis N, 2011, THESCIENTIFICWORLDJO, V11, P520, DOI 10.1100/tsw.2011.52
   Kumar A., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P303, DOI 10.1109/ICB.2012.6199824
   Kumar A., 2012, 2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P59, DOI DOI 10.1109/CVPRW.2012.6239216
   Li PH, 2012, INT C PATT RECOG, P2420
   Li PH, 2012, PATTERN RECOGN LETT, V33, P1000, DOI 10.1016/j.patrec.2011.06.018
   Li YH, 2013, IEEE T PATTERN ANAL, V35, P784, DOI 10.1109/TPAMI.2012.169
   Marsico M.D., 2016, PATTERN RECOGN LETT
   Matey JR, 2006, P IEEE, V94, P1936, DOI 10.1109/JPROC.2006.884091
   Matey JR, 2009, ADV PATTERN RECOGNIT, P23, DOI 10.1007/978-1-84882-385-3_2
   McConnon G., 2011, INT J SIGNAL PROCESS, V4, P165
   Mikaelyan A, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P584, DOI 10.1109/SITIS.2014.105
   Moreno J.C., 2013, Proceedings of the 6th International Conference on Security of Information and Networks, P160
   Moreno JC, 2016, J SIGNAL PROCESS SYS, V82, P403, DOI 10.1007/s11265-015-1023-3
   Narayanswamy R, 2005, P SOC PHOTO-OPT INS, V5779, P41, DOI 10.1117/12.603612
   Nie L, 2014, INT C PATT RECOG, P399, DOI 10.1109/ICPR.2014.77
   Nigam I, 2015, INFORM FUSION, V26, P1, DOI 10.1016/j.inffus.2015.03.005
   Oh K, 2014, NEUROCOMPUTING, V128, P185, DOI 10.1016/j.neucom.2013.01.066
   Padole C. N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P439, DOI 10.1109/ICB.2012.6199790
   Park KR, 2005, IEEE T SYST MAN CY C, V35, P441, DOI 10.1109/TSMCC.2005.848168
   Park M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICUWB 2009), P1, DOI 10.1109/ICUWB.2009.5288737
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Pérez-Palacios T, 2015, INT J ANAL CHEM, V2015, DOI 10.1155/2015/209214
   Phillips P., 2005, Computer Vision and Pattern Recognition (CVPR 2005), P1
   Proena H., COMPUT VIS IMAGE UND, V116, P167
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Proenca H., 2007, First IEEE International Conference on Biometrics: Theory, Applications, and Systems, P1
   Proença H, 2011, EUR SIGNAL PR CONF, P2259
   Proença H, 2014, IEEE T IMAGE PROCESS, V23, P5082, DOI 10.1109/TIP.2014.2361285
   Proença H, 2013, IEEE T INF FOREN SEC, V8, P1975, DOI 10.1109/TIFS.2013.2283458
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Proença H, 2009, CIB: 2009 IEEE WORKSHOP ON COMPUTATIONAL INTELLIGENCE IN BIOMETRICS: THEORY, ALGORITHMS, AND APPLICATIONS, P9
   Radu P, 2012, 2012 THIRD INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P53, DOI 10.1109/EST.2012.33
   Radu P., 2011, International Journal of Hybrid Information Technology, V4, P1
   Raffei AFM, 2015, KNOWL-BASED SYST, V74, P40, DOI 10.1016/j.knosys.2014.11.002
   Raffei AFM, 2014, INFORM SCIENCES, V276, P104, DOI 10.1016/j.ins.2014.02.049
   Raffei AFM, 2013, PATTERN RECOGN, V46, P2622, DOI 10.1016/j.patcog.2013.03.009
   Raghavendra R, 2016, IEEE IMAGE PROC, P325, DOI 10.1109/ICIP.2016.7532372
   Raghavendra R, 2016, IEEE CONF IMAGING SY, P201, DOI 10.1109/IST.2016.7738223
   Raghavendra R, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P155, DOI 10.1109/ACPR.2013.22
   Raja K.B., 2014, Padmashri Amalananda Ghosh Memorial Lecture, P1
   Raja K. B., 2014, P 7 INT C SEC INF NE, DOI [10.1145/2659651.2659704, DOI 10.1145/2659651.2659704]
   Raja KB, 2016, IEEE IMAGE PROC, P330, DOI 10.1109/ICIP.2016.7532373
   Raja KB, 2015, PATTERN RECOGN LETT, V57, P33, DOI 10.1016/j.patrec.2014.09.006
   Raja KB, 2014, 2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS, P15, DOI 10.1109/BIOMS.2014.6951530
   Rattani A, 2016, IEEE IMAGE PROC, P320, DOI 10.1109/ICIP.2016.7532371
   Roy K, 2010, IEEE IMAGE PROC, P1705, DOI 10.1109/ICIP.2010.5653680
   Sankowski W, 2010, IMAGE VISION COMPUT, V28, P231, DOI 10.1016/j.imavis.2009.05.014
   Santos G, 2015, PATTERN RECOGN LETT, V57, P52, DOI 10.1016/j.patrec.2014.09.012
   Santos G, 2012, PATTERN RECOGN LETT, V33, P984, DOI 10.1016/j.patrec.2011.08.017
   Seong-Taek Lee, 2010, Proceedings of the 2010 2nd International Conference on Signal Processing Systems (ICSPS 2010), P285, DOI 10.1109/ICSPS.2010.5555624
   Sequeira AF, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3, P133
   Sharma A, 2014, IEEE IMAGE PROC, P5007, DOI 10.1109/ICIP.2014.7026014
   Shin KY, 2012, PATTERN RECOGN LETT, V33, P991, DOI 10.1016/j.patrec.2011.08.016
   Shukri DSM, 2013, PATTERN RECOGN LETT, V34, P1071, DOI 10.1016/j.patrec.2013.02.017
   SIMON JW, 1980, BRIT J OPHTHALMOL, V64, P793, DOI 10.1136/bjo.64.10.793
   Singh M. R. T., 2014, INT J IND ELECT ELEC
   Smereka JM, 2015, IEEE T INF FOREN SEC, V10, P1875, DOI 10.1109/TIFS.2015.2434271
   Smereka JM, 2013, IEEE COMPUT SOC CONF, P117, DOI 10.1109/CVPRW.2013.25
   Smereka M.Jonathon, 2016, IEEE INT C ID SEC BE, P1, DOI [10.1109/ISBA.2016.7477247, DOI 10.1109/ISBA.2016.7477247]
   Sreelekshmi K.J., 2014, INT J ADV RES COMPUT, V2, P285
   Sunder M. S., 2010, INT C PATT REC ICPR, P1
   Tan C.-W., 2013, P IEEE 6 INT C BIOM, P1
   Tan CW, 2014, IEEE T IMAGE PROCESS, V23, P3962, DOI 10.1109/TIP.2014.2337714
   Tan CW, 2013, IEEE T IMAGE PROCESS, V22, P3751, DOI 10.1109/TIP.2013.2260165
   Tan Chun-Wei., 2011, CVPR_2011_WORKSHOPS, P9
   Tan TN, 2012, PATTERN RECOGN LETT, V33, P970, DOI 10.1016/j.patrec.2011.08.009
   Tankasala, 2011, International Conference on Image Information Processing, P1
   Tankasala S.P., 2012, IEEE S TECHN HOM SEC, P1
   Tankasala SP, 2012, PROC TECH, V1, P564, DOI 10.1016/j.protcy.2012.10.068
   Tsai Y., 2014, INT J COMPUT INF SYS, P30
   Tzaphlidou M, 2011, THESCIENTIFICWORLDJO, V11, P529, DOI 10.1100/tsw.2011.53
   Uhl A, 2012, LECT NOTES COMPUT SC, V7325, P1, DOI 10.1007/978-3-642-31298-4_1
   Wang HT, 2004, IEEE IMAGE PROC, P1397
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Woodard D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on, P162, DOI DOI 10.1109/CVPRW.2010.5544621
   Xiaomin Liu, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P265, DOI 10.1109/ICB.2012.6199818
   Xu JJ, 2011, SEX TRANSM DIS, V38, P89, DOI 10.1097/OLQ.0b013e3181f0bc5e
   Zhang H, 2012, INT C PATT RECOG, P3427
   Zhou Z, 2011, IEEE WORKSH COMP INT, P103, DOI [10.1109/cibim.2011.5949225, DOI 10.1109/CIBIM.2011.5949225]
   Zhou Z, 2012, IEEE T SYST MAN CY A, V42, P571, DOI 10.1109/TSMCA.2011.2170416
   Zhou Z, 2010, I C CONT AUTOMAT ROB, P638, DOI 10.1109/ICARCV.2010.5707959
NR 154
TC 55
Z9 58
U1 1
U2 32
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2017
VL 59
BP 1
EP 16
DI 10.1016/j.imavis.2016.11.019
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EP9IS
UT WOS:000397687900001
DA 2024-07-18
ER

PT J
AU Mai, G
   Lim, MH
   Yuen, PC
AF Mai, Guangcan
   Lim, Meng-Hui
   Yuen, Pong C.
TI Binary feature fusion for discriminative and secure multi-biometric
   cryptosystems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometric; Binary representation; Binary feature; Multi-biometric;
   Feature fusion; Template protection; Cryptosystems
ID FINGERPRINT; RECOGNITION; TEMPLATE; IMAGE
AB Biometric cryptosystem has been proven to be a promising approach for template protection. Cryptosystems such as fuzzy extractor and fuzzy commitment require discriminative and informative binary biometric input to offer accurate and secure recognition. In multi-modal biometric recognition, binary features can be produced via fusing the real-valued unimodal features and binarizing the fused features. However, when the extracted features of certain modality are represented in binary and the extraction parameters are not known, real-valued features of other modalities need to be binarized and the feature fusion needs to be carried out at the binary level. In this paper, we propose a binary feature fusion method that extracts a set of fused binary features with high discriminability (small intra-user and large inter-user variations) and entropy (weak dependency among bits and high bit uniformity) from multiple sets of binary unimodal features. Unlike existing fusion methods that mainly focus on discriminability, the proposed method focuses on both feature discriminability and system security: The proposed method 1) extracts a set of weakly dependent feature groups from the multiple unimodal features; and 2) fuses each group to a bit using a mapping that minimizes the intra-user variations and maximizes the inter-user variations and uniformity of the fused bit. Experimental results on three multi-modal databases show that fused binary feature of the proposed method has both higher discriminability and higher entropy compared to the unimodal features and the fused features generated from the state-of-the-art binary fusion approaches. (C) 2016 Published by Elsevier B.V.
C1 [Mai, Guangcan; Lim, Meng-Hui; Yuen, Pong C.] Hong Kong Baptist Univ, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong Baptist University
RP Yuen, PC (corresponding author), Hong Kong Baptist Univ, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
EM csgcmai@comp.hkbu.edu.hk; menghuilim@comp.hkbu.edu.hk;
   pcyuen@comp.hkbu.edu.hk
RI Mai, Guangcan/AAB-4447-2019
OI Mai, Guangcan/0000-0002-0326-500X
FU Hong Kong RGC grant [HKBU 211612]
FX This project is partially supported by the Hong Kong RGC grant HKBU
   211612 and Mr. Kwok Yat Wai and Madam Kwok Chung Bo Fun Graduate School
   Development Fund.
CR [Anonymous], TECH REP
   [Anonymous], 2010, 2010 IEEE COMPUTER S
   [Anonymous], ADV INFORM SECURITY
   [Anonymous], AC SPEECH SIGN PROC
   [Anonymous], 2009, ND IRIS 0405 IRIS IM
   [Anonymous], BIOM THEOR APPL SYST
   [Anonymous], 1979422011 ISOIEC
   [Anonymous], COMP VIS PATT REC 19
   [Anonymous], IEEE T SYSTEMS MAN C
   Cappelli R, 2007, IEEE T PATTERN ANAL, V29, P1489, DOI 10.1109/TPAMI.2007.1087
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Deb K, 2000, COMPUT METHOD APPL M, V186, P311, DOI 10.1016/S0045-7825(99)00389-8
   Deep K, 2009, APPL MATH COMPUT, V212, P505, DOI 10.1016/j.amc.2009.02.044
   Dodis Y, 2008, SIAM J COMPUT, V38, P97, DOI 10.1137/060651380
   Farooq F., 2007, IEEE C, P1
   Feng YC, 2014, PATTERN RECOGN, V47, P3019, DOI 10.1016/j.patcog.2014.03.003
   Feng YC, 2012, IEEE T INF FOREN SEC, V7, P613, DOI 10.1109/TIFS.2011.2170422
   Feng YC, 2010, IEEE T INF FOREN SEC, V5, P103, DOI 10.1109/TIFS.2009.2038760
   Haiyun Xu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1212, DOI 10.1109/ICPR.2010.302
   Hidano S., 2012, 2012 BIOSIG - Proceedings of the International Conference of Biometrics Special Interest Group (BIOSIG), P1
   Jin Z, 2014, PATTERN RECOGN LETT, V42, P137, DOI 10.1016/j.patrec.2014.02.011
   Juels A, 2006, DESIGN CODE CRYPTOGR, V38, P237, DOI 10.1007/s10623-005-6343-z
   Juels A, 1999, 6TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P28, DOI 10.1145/319709.319714
   Kanade S., 2009, BTAS 09 P 3 IEEE INT, P1
   Kelkboom E.J. C., 2009, IEEE 3rd international conference on biometrics: theory, applications, and systems, 2009 (BTAS '09), P1, DOI 10.1109/BTAS.2009.5339045
   Ko JG, 2007, ETRI J, V29, P399, DOI 10.4218/etrij.07.0206.0141
   Kraskov A., 2009, Information theory and statistical learning, P101, DOI DOI 10.1007/978-0-387-84816-7_5
   Lim MH, 2016, PATTERN RECOGN, V60, P706, DOI 10.1016/j.patcog.2016.06.018
   Lim MH, 2013, IEEE T PATTERN ANAL, V35, P300, DOI 10.1109/TPAMI.2012.122
   Liu SQ, 2016, LECT NOTES COMPUT SC, V9911, P85, DOI 10.1007/978-3-319-46478-7_6
   Maiorana E, 2015, IEEE T INF FOREN SEC, V10, P900, DOI 10.1109/TIFS.2014.2384735
   Nagar A, 2012, IEEE T INF FOREN SEC, V7, P255, DOI 10.1109/TIFS.2011.2166545
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Prasad M. Mahadeva, 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P172, DOI 10.1109/ICFHR.2010.34
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Rodrigues R. N., 2010, BIOMETRICS THEORY AP, P1
   Ross A, 2007, IEEE T PATTERN ANAL, V29, P544, DOI 10.1109/TPAMI.2007.1018
   Ross ArunA., 2006, HDB MULTIBIOMETRICS, V6
   Shrivastava A, 2015, PROC CVPR IEEE, P2282, DOI 10.1109/CVPR.2015.7298841
   Sutcu Yagiz., 2007, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Uhl A., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P283, DOI 10.1109/ICB.2012.6199821
   Vij A, 2014, IEEE COMPUT SOC CONF, P64, DOI 10.1109/CVPRW.2014.15
   Xu R, 2005, IEEE T NEURAL NETWOR, V16, P645, DOI 10.1109/TNN.2005.845141
   Yang JF, 2012, PATTERN RECOGN LETT, V33, P623, DOI 10.1016/j.patrec.2011.11.002
NR 48
TC 16
Z9 16
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 254
EP 265
DI 10.1016/j.imavis.2016.11.011
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700024
DA 2024-07-18
ER

PT J
AU Rigas, I
   Komogortsev, OV
AF Rigas, Ioannis
   Komogortsev, Oleg V.
TI Current research in eye movement biometrics: An analysis based on BioEye
   2015 competition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Eye movement biometrics; Biometric databases; Biometric competition
ID ATTENTION; ALGORITHM; SCANPATHS
AB On the onset of the second decade of research in eye movement biometrics, the already demonstrated results strongly support the promising perspectives of the field. This paper presents a description of the research conducted in eye movement biometrics based on an extended analysis of the characteristics and results of the "BioEye 2015: Competition on Biometrics via Eye Movements." This extended presentation can contribute to the understanding of the current level of research in eye movement biometrics, covering areas such as the previous work in the field, the procedures for the creation of a database of eye movement recordings, and the different approaches that can be used for the analysis of eye movements. Also, the presented results from BioEye 2015 competition can demonstrate the potential identification accuracy that can be achieved under easier and more difficult scenarios. Based on the provided presentation, we discuss topics related to the current status in eye movement biometrics and suggest possible directions for the future research in the field. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Rigas, Ioannis; Komogortsev, Oleg V.] Texas State Univ, Dept Comp Sci, San Marcos, TX 78666 USA.
C3 Texas State University System; Texas State University San Marcos
RP Rigas, I (corresponding author), Texas State Univ, Dept Comp Sci, San Marcos, TX 78666 USA.
EM rigas@txstate.edu; ok11@txstate.edu
RI Rigas, Ioannis/HJG-9954-2022
FU NSF CAREER [CNS-1250718]; NIST [60NANB12D234, 60NANB14D274]; Google
   Research Award [2014_R1_308]; SensoMotoric Instruments (SMI)
FX We would like to express our gratitude to the participants of BioEye
   2015 competition for their submissions, for providing their method
   descriptions, and for their valuable comments. We would like to thank
   SensoMotoric Instruments (SMI) for sponsoring BioEye 2015 competition
   prize in a form of REDn scientific eye tracker given to the winner of
   the competition. The recording of the competition database was supported
   in part by NSF CAREER grant no. CNS-1250718 and NIST grant nos.
   60NANB12D234 and 60NANB14D274. The processing of the results of BioEye
   2015 competition was made possible in part by the Google Research Award
   no. 2014_R1_308. Special gratitude is expressed to Dr. E. Abdulin, T.
   Miller, Ch. Heinich, and N. Myers for proctoring eye movement
   recordings.
CR Andrews TJ, 1999, VISION RES, V39, P2947, DOI 10.1016/S0042-6989(99)00019-X
   [Anonymous], 1935, How people look at pictures: A study of the psychology and perception in art
   [Anonymous], 2012, Technical Report
   BAHILL A T, 1975, Mathematical Biosciences, V24, P191, DOI 10.1016/0025-5564(75)90075-9
   Bednarik R, 2005, LECT NOTES COMPUT SC, V3540, P780
   Bulling A., 2009, Proceedings of the 27th international conference extended abstracts on Human factors in computing systems, P3259
   Cantoni V, 2015, PATTERN RECOGN, V48, P1027, DOI 10.1016/j.patcog.2014.02.017
   Castelhano MS, 2008, CAN J EXP PSYCHOL, V62, P1, DOI 10.1037/1196-1961.62.1.1
   CHILDERS DG, 1977, P IEEE, V65, P1428, DOI 10.1109/PROC.1977.10747
   Choi JES, 2014, J NEUROSCI, V34, P1212, DOI 10.1523/JNEUROSCI.2798-13.2014
   Cifu DX, 2015, J HEAD TRAUMA REHAB, V30, P21, DOI 10.1097/HTR.0000000000000036
   CORNSWEET TN, 1973, J OPT SOC AM, V63, P921, DOI 10.1364/JOSA.63.000921
   Ditchburn R.W., 1973, EYE MOVEMENTS VISUAL
   DITCHBURN RW, 1953, J PHYSIOL-LONDON, V119, P1
   Ganchev T., 2005, 10th International Conference on Speech and Computer (SPECOM 2005), V1, P191
   George A., SCORE LEVEL IN PRESS
   GOLDBERG JH, 1995, BEHAV RES METH INSTR, V27, P338, DOI 10.3758/BF03200428
   GRONER R, 1989, EUR ARCH PSY CLIN N, V239, P9, DOI 10.1007/BF01739737
   Hering Ewald., 1879, SITZBERICHTE KAISERL, V79, P137
   HOLCOMB JH, 1977, PERCEPT MOTOR SKILL, V44, P639, DOI 10.2466/pms.1977.44.2.639
   Holland Corey, 2011, 2011 INT JOINT C BIO, P1, DOI [DOI 10.1109/IJCB.2011.6117536, 10.1109/IJCB.2011.6117536.]
   Holland CD, 2013, IEEE T INF FOREN SEC, V8, P2115, DOI 10.1109/TIFS.2013.2285884
   Holloway CL, 2013, USNC-URSI RADIO SCI, P1, DOI 10.1109/USNC-URSI.2013.6715307
   Huey E., 1908, PSYCHOL PEDAGOGY REA
   HUTCHINSON TE, 1989, IEEE T SYST MAN CYB, V19, P1527, DOI 10.1109/21.44068
   JUST MA, 1980, PSYCHOL REV, V87, P329, DOI 10.1037/0033-295X.87.4.329
   Kasprowski P, 2004, LECT NOTES COMPUT SC, V3087, P248
   Kasprowski P., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P195, DOI 10.1109/BTAS.2012.6374577
   Kasprowski P, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Kaufman A. E., 1993, Proceedings IEEE 1993 Symposium on Research Frontiers in Virtual Reality (Cat. No.93TH0585-0), P120, DOI 10.1109/VRAIS.1993.378254
   Kinnunen T, 2010, P S EYE TRACK RES AP, P187
   Komogortsev O. V., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P413, DOI 10.1109/ICB.2012.6199786
   Komogortsev O. V., 2010, TECHNICAL REPORT
   Komogortsev O. V., 2014, SPIE BIOMETRIC SURVE
   Komogortsev O. V., 2015, IEEE 7 INT C BIOM TH
   Komogortsev Oleg, 2010, P 2010 S EYE TRACK R, P57, DOI [DOI 10.1145/1743666.1743679, 10.1145/1743666.1743679]
   Komogortsev Oleg, 2014, CHI 14 EXTENDED ABST, P1711, DOI [10.1145/2559206.2581150, DOI 10.1145/2559206.2581150]
   Komogortsev OV, 2007, LECT NOTES COMPUT SC, V4552, P679
   Komogortsev OV, 2015, IEEE T INF FOREN SEC, V10, P716, DOI 10.1109/TIFS.2015.2405345
   Komogortsev OV, 2013, BEHAV RES METHODS, V45, P203, DOI 10.3758/s13428-012-0234-9
   Komogortsev OV, 2013, 2013 IEEE Sixth International Conference on Biometrics: Theory, Applications and Systems (BTAS), P1
   KOWLER E, 1995, VISION RES, V35, P1897, DOI 10.1016/0042-6989(94)00279-U
   Kumar M, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P65, DOI 10.1145/1344471.1344488
   Lamare M., 1892, Bulletins et Memoires de La Societe Francaise d'Ophthalmologie, V10, P354
   Leigh RJ., 2006, NEUROLOGY EYE MOVEME, V4th
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Morimoto CH, 2000, IMAGE VISION COMPUT, V18, P331, DOI 10.1016/S0262-8856(99)00053-0
   Cuong NV, 2012, PROC INT C TOOLS ART, P253, DOI 10.1109/ICTAI.2012.42
   Niinuma K, 2010, IEEE T INF FOREN SEC, V5, P771, DOI 10.1109/TIFS.2010.2075927
   NOTON D, 1971, VISION RES, V11, P929, DOI 10.1016/0042-6989(71)90213-6
   NOTON D, 1971, SCIENCE, V171, P308, DOI 10.1126/science.171.3968.308
   Nyström M, 2010, BEHAV RES METHODS, V42, P188, DOI 10.3758/BRM.42.1.188
   Ober J., 1997, SPIE, V3061
   Poynter W, 2013, VISION RES, V89, P32, DOI 10.1016/j.visres.2013.07.002
   Prendinger H, 2009, UNIVERSAL ACCESS INF, V8, P339, DOI 10.1007/s10209-009-0144-5
   RABINER LR, 1975, P IEEE, V63, P595, DOI 10.1109/PROC.1975.9794
   Rayner K, 1998, PSYCHOL BULL, V124, P372, DOI 10.1037/0033-2909.124.3.372
   REULEN JPH, 1988, MED BIOL ENG COMPUT, V26, P20, DOI 10.1007/BF02441823
   Rigas I., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P217, DOI 10.1109/BTAS.2012.6374580
   Rigas I., MULTISOURCE IN PRESS
   Rigas I, 2015, PATTERN RECOGN LETT, V68, P316, DOI 10.1016/j.patrec.2015.06.011
   Rigas I, 2014, IEEE T INF FOREN SEC, V9, P1743, DOI 10.1109/TIFS.2014.2350960
   Rigas I, 2012, PATTERN RECOGN LETT, V33, P786, DOI 10.1016/j.patrec.2012.01.003
   ROBINSON DA, 1963, IEEE T BIO-MED ENG, VBM10, P137, DOI 10.1109/TBMEL.1963.4322822
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Salvucci D. D., 1998, ACM 1998 C HUM FACT, P66
   SAUTER D, 1991, MED BIOL ENG COMPUT, V29, P63, DOI 10.1007/BF02446297
   SAVITZKY A, 1964, ANAL CHEM, V36, P1627, DOI 10.1021/ac60214a047
   Schnitzer BS, 2006, VISION RES, V46, P1611, DOI 10.1016/j.visres.2005.09.023
   Sen T., 1984, Theoretical and applied aspects of eye movement research, P103, DOI [10.1016/S0166-4115(08), DOI 10.1016/S0166-4115(08)]
   Silver D.L., 2006, P IC, P344
   SMI, 2015, RED250RED500 SMI
   SR-Research, 2015, SR RES EYELINK 1000
   STAMPE DM, 1993, BEHAV RES METH INSTR, V25, P137, DOI 10.3758/BF03204486
   Stark L., 1981, SCANPATHS REV COGN M
   Yarbus A. L., 1967, Eye Movements and Vision
   Yoon H.-J., 2014, SPIE
   Zhai S., 1999, SIGCHI C HUM FACT CO
   Zhang Y., 2012, P THE 2 INT C ADV IN, P85
   Zhen Liang, 2012, Proceedings of the 2012 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC), P728, DOI 10.1109/ICSPCC.2012.6335584
NR 80
TC 20
Z9 22
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 129
EP 141
DI 10.1016/j.imavis.2016.03.014
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700013
OA Bronze
DA 2024-07-18
ER

PT J
AU Tzelepis, C
   Ma, ZG
   Mezaris, V
   Ionescu, B
   Kompatsiaris, I
   Boato, G
   Sebe, N
   Yan, SC
AF Tzelepis, Christos
   Ma, Zhigang
   Mezaris, Vasileios
   Ionescu, Bogdan
   Kompatsiaris, Ioannis
   Boato, Giulia
   Sebe, Nicu
   Yan, Shuicheng
TI Event-based media processing and analysis: A survey of the literature
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Event-based media processing and analysis; Event conceptualization;
   Event representation and modeling; Multimedia event detection;
   Event-based applications and benchmarking; Survey of the literature
ID CLASSIFICATION; RECOGNITION; FEATURES; SCALE; VISUALIZATION;
   TRAJECTORIES; DESCRIPTORS; EXTRACTION; ALGORITHM; KNOWLEDGE
AB Research on event-based processing and analysis of media is receiving an increasing attention from the scientific community due to its relevance for an abundance of applications, from consumer video management and video surveillance to lifelogging and social media. Events have the ability to semantically encode relationships of different informational modalities, such as visual-audio-text, time, involved agents and objects, with the spatio-temporal component of events being a key feature for contextual analysis. This unveils an enormous potential for exploiting new information sources and opening new research directions. In this paper, we survey the existing literature in this field. We extensively review the employed conceptualization of the notion of event in multimedia, the techniques for event representation and modeling, the feature representation and event inference approaches for the problems of event detection in audio, visual, and textual content. Furthermore, we review some key event-based multimedia applications, and various benchmarking activities that provide solid frameworks for measuring the performance of different event processing and analysis systems. We provide an in-depth discussion of the insights obtained from reviewing the literature and identify future directions and challenges. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Tzelepis, Christos; Mezaris, Vasileios; Kompatsiaris, Ioannis] CERTH, ITI, Thessaloniki 57001, Greece.
   [Tzelepis, Christos] Queen Mary Univ London, Mile End Campus, London E1 4NS, England.
   [Ma, Zhigang] Carnegie Mellon Univ, Sch Comp Sci, Pittsburgh, PA 15213 USA.
   [Ionescu, Bogdan] Univ Politehn Bucuresti, LAPI, Bucharest 061071, Romania.
   [Boato, Giulia; Sebe, Nicu] Univ Trento, Trento, Italy.
   [Yan, Shuicheng] Natl Univ Singapore, Dept ECE, Singapore, Singapore.
C3 Centre for Research & Technology Hellas; University of London; Queen
   Mary University London; Carnegie Mellon University; National University
   of Science & Technology POLITEHNICA Bucharest; University of Trento;
   National University of Singapore
RP Tzelepis, C (corresponding author), CERTH, ITI, Thessaloniki 57001, Greece.
EM tzelepis@iti.gr; kevinma@cs.cmu.edu; bmezaris@iti.gr;
   bionescu@alpha.imag.pub.ro; ikom@iti.gr; boato@disi.unitn.it;
   sebe@disi.unitn.it; eleyans@nus.edu.sg
RI Kompatsiaris, Ioannis/P-8594-2015; Ionescu, Bogdan/IWU-7778-2023; Yan,
   Shuicheng/HCI-1431-2022; Sebe, Niculae/KEC-2000-2024; Tzelepis,
   Christos/O-6413-2015
OI Kompatsiaris, Ioannis/0000-0001-6447-9020; Sebe,
   Niculae/0000-0002-6597-7248; Tzelepis, Christos/0000-0002-2036-9089
FU European Union's Horizon 2020; FP7 research and innovation programmes
   [H2020-687786 InVID, H2020-693092 MOVING, FP7-611346 xLiMe, FP7-600826
   ForgetIT]
FX This work was supported by the European Union's Horizon 2020 and FP7
   research and innovation programmes under grant agreements H2020-687786
   InVID, H2020-693092 MOVING, FP7-611346 xLiMe and FP7-600826 ForgetIT.
CR ALLEN JF, 1983, COMMUN ACM, V26, P832, DOI 10.1145/182.358434
   Althoff T., 2012, Proceedings of the 20th ACM international conference on Multimedia, P1065
   [Anonymous], INT C MULT RETR ICMR
   [Anonymous], MEDIAEVAL 2014 WORKS
   [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], 2012, TECH REP
   [Anonymous], ICMR 2013 P 3 ACM C
   [Anonymous], NIST TRECVID VID RET
   [Anonymous], P 21 ACM INT C MULT
   [Anonymous], 2009, Proceedings of the 26th Annual International Conference on Machine Learning
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], 2013, P 3 ACM C INT C MULT
   [Anonymous], P 21 ACM INT C MULT
   [Anonymous], 2010, P 3 ACM INT C WEB SE, DOI DOI 10.1145/1718487.1718524
   [Anonymous], P 12 ANN ACM INT C M
   [Anonymous], 2008, Handbook of knowledge representation
   Antoniou G., 2009, Handbook on Ontologies, P91, DOI [DOI 10.1007/978-3-540-92673-3_4, DOI 10.1007/978-3-540-92673-34]
   Apostolidis K., 2014, P MEDIAEVAL WORKSH, P1263
   Arestis-Chartampilas S, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1219, DOI 10.1145/2733373.2806321
   Assari SM, 2014, PROC CVPR IEEE, P2529, DOI 10.1109/CVPR.2014.324
   ATREY P.K., 2006, 2006 IEEE INT C AC S, DOI DOI 10.1109/ICASSP.2006.1661400
   Bach Francis R, 2004, P 21 INT C MACH LEAR, P6, DOI 10.1145/1015330.1015424
   Baillie M, 2003, LECT NOTES COMPUT SC, V2728, P300
   Ballan L, 2011, MULTIMED TOOLS APPL, V51, P279, DOI 10.1007/s11042-010-0643-7
   Baumgartner N, 2006, PROCEEDINGS OF THE FOURTH IASTED INTERNATIONAL CONFERENCE ON KNOWLEDGE SHARING AND COLLABORATIVE ENGINEERING, P1
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Bhattacharya S, 2014, PROC CVPR IEEE, P2243, DOI 10.1109/CVPR.2014.287
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bolles R., 2014, P TRECVID WORKSH
   Brand M, 1999, NEURAL COMPUT, V11, P1155, DOI 10.1162/089976699300016395
   Brezeale D, 2008, IEEE T SYST MAN CY C, V38, P416, DOI 10.1109/TSMCC.2008.919173
   Burghouts GJ, 2009, COMPUT VIS IMAGE UND, V113, P48, DOI 10.1016/j.cviu.2008.07.003
   Cai R, 2006, IEEE T AUDIO SPEECH, V14, P1026, DOI 10.1109/TSA.2005.857575
   Cao L., 2012, COMPUTER VISION ECCV, P688
   SanMiguel JC, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P220, DOI 10.1109/AVSS.2009.28
   Casey M, 2001, IEEE T CIRC SYST VID, V11, P737, DOI 10.1109/76.927433
   Cervesato I, 2000, COMPUT INTELL-US, V16, P307, DOI 10.1111/0824-7935.00115
   Chang S.-F., 2007, P INT WORKSHOP WORKS, P255, DOI DOI 10.1145/1290082.1290118
   Chang XJ, 2016, AAAI CONF ARTIF INTE, P3464
   Chang X, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P581, DOI 10.1145/2733373.2806218
   Chang XJ, 2015, PR MACH LEARN RES, V37, P1348
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen H, 2005, WHITESTEIN SER SOFTW, P233, DOI 10.1007/3-7643-7361-X_10
   Chen H., 2005, USING OWL PERVASIVE
   Chen M-y, 2009, Mosift: Recognizing human actions in surveillance videos, CMU-CS-09-161
   Cheng H, 2014, MULTIMED TOOLS APPL, V70, P177, DOI 10.1007/s11042-012-1162-5
   Cheng W.-H., 2003, P 5 ACM SIGMM INT WO, P109, DOI DOI 10.1145/973264.973282
   Cheng Y, 2014, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2014.286
   Chu WT, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1591, DOI 10.1109/ICME.2004.1394553
   Chung WY, 2005, INT J HUM-COMPUT ST, V62, P127, DOI 10.1016/j.ijhcs.2004.08.005
   Clavel C, 2005, 2005 IEEE International Conference on Multimedia and Expo (ICME), Vols 1 and 2, P1307
   Codella N. C. F., 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P747, DOI 10.1109/ICME.2012.190
   Conci N., 2015, MEDIAEVAL 2015 WORKS
   Cricri F, 2014, MULTIMED TOOLS APPL, V70, P119, DOI 10.1007/s11042-012-1085-1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dao MS, 2014, MULTIMED TOOLS APPL, V70, P25, DOI 10.1007/s11042-012-1153-6
   DAVIS SB, 1980, IEEE T ACOUST SPEECH, V28, P357, DOI 10.1109/TASSP.1980.1163420
   Deligiannidis Leonidas, 2008, 2008 Conference on Human System Interactions, P158, DOI 10.1109/HSI.2008.4581426
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Doerr M., 2007, ER 07, P51, DOI DOI 10.13140/2.1.1420.6400
   Doman K, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P949, DOI 10.1145/2647868.2654973
   Donahue J., 2013, Decaf: A deep convolutional activation feature for generic visual recognition
   Douze M, 2013, IEEE I CONF COMP VIS, P1825, DOI 10.1109/ICCV.2013.229
   Duan LX, 2012, IEEE T PATTERN ANAL, V34, P465, DOI 10.1109/TPAMI.2011.114
   Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189
   Ekin A, 2004, IEEE T MULTIMEDIA, V6, P839, DOI 10.1109/TMM.2004.837238
   Elhoseiny M, 2015, ARXIV151200818
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Elo J.P., 2009, AC SPEECH SIGN PROC, P1973
   Erhan Dumitru, 2009, VISUALIZING HIGHER L, V1341, P1
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578
   François ARJ, 2005, IEEE MULTIMEDIA, V12, P76, DOI 10.1109/MMUL.2005.87
   FRIEDMAN A, 1979, J EXP PSYCHOL GEN, V108, P316, DOI 10.1037/0096-3445.108.3.316
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   Gan C, 2016, AAAI CONF ARTIF INTE, P3487
   Gan C, 2015, AAAI CONF ARTIF INTE, P3769
   Gan C, 2015, PROC CVPR IEEE, P2568, DOI 10.1109/CVPR.2015.7298872
   Gangemi A., 2009, Handbook on ontologies, P221, DOI DOI 10.1007/978-3-540-92673-3
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Gkalelis N., 2011, 2011 9th International Workshop on Content-Based Multimedia Indexing (CBMI), P85, DOI 10.1109/CBMI.2011.5972525
   Gkalelis N., 2014, P TRECVID WORKSH
   Gkalelis N, 2013, IEEE IMAGE PROC, P4372, DOI 10.1109/ICIP.2013.6738901
   Gkalelis N, 2010, IEEE INT C SEMANT CO, P79, DOI 10.1109/ICSC.2010.21
   Gravier G, 2014, MULTIMED TOOLS APPL, V70, P1421, DOI 10.1007/s11042-012-1169-y
   Guo J, 2012, P IEEE MTTS INT MICR, P1
   Gupta A., 2011, Synthesis Lectures on Data Management, V3, P1, DOI DOI 10.2200/S00374ED1V01Y201107DTM019
   Gurrin Cathal, 2014, Foundations and Trends in Information Retrieval, V8, P5, DOI 10.1561/1500000033
   Habibian A, 2013, P 3 ACM C INT C MULT, P89, DOI DOI 10.1145/2461466.2461482
   Habibian A, 2014, ICMR
   Habibian A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P17, DOI 10.1145/2647868.2654913
   Hakeem A, 2004, PROCEEDING OF THE NINETEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE SIXTEENTH CONFERENCE ON INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE, P263
   Harma A., 2005, MULT EXP 2005 ICME 2
   Iliakopoulou K., 2015, CONT BAS MULT IND CB, P1
   Izadinia H, 2012, LECT NOTES COMPUT SC, V7575, P430, DOI 10.1007/978-3-642-33765-9_31
   Jain M, 2015, IEEE I CONF COMP VIS, P4588, DOI 10.1109/ICCV.2015.521
   Jain R, 2008, COMPUTER, V41, P42, DOI 10.1109/MC.2008.49
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Jiang L., 2015, INT C MULT RETR
   Jiang Y.-G., 2009, Proc. ACM MM, P155, DOI DOI 10.1145/1631272.1631296
   Jiang YG, 2015, IEEE T MULTIMEDIA, V17, P1174, DOI 10.1109/TMM.2015.2436813
   Jiang YG, 2013, INT J MULTIMED INF R, V2, P73, DOI 10.1007/s13735-012-0024-2
   Jiang YG, 2010, IEEE T MULTIMEDIA, V12, P42, DOI 10.1109/TMM.2009.2036235
   Joo S.W., 2006, Computer Vision and Pattern Recognition Workshop, P107, DOI [DOI 10.1109/CVPRW.2006.32, 10.1109/CVPRW.2006.32]
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kowalski R., 1989, Foundations of knowledge base management, P23, DOI [10.1007/978-3-642-83397-7_2, DOI 10.1007/978-3-642-83397-72, DOI 10.1007/978-3-642-83397-7_2]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai KT, 2014, PROC CVPR IEEE, P2251, DOI 10.1109/CVPR.2014.288
   Lai KT, 2014, LECT NOTES COMPUT SC, V8691, P675, DOI 10.1007/978-3-319-10578-9_44
   Lan ZZ, 2014, MULTIMED TOOLS APPL, V71, P333, DOI 10.1007/s11042-013-1391-2
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Li BX, 2001, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P132, DOI 10.1109/IVL.2001.990867
   Li L.-j., 2010, NIPS
   Li WX, 2013, IEEE I CONF COMP VIS, P2728, DOI 10.1109/ICCV.2013.339
   Lin FZ, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P670
   Liu J, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P297, DOI 10.1109/ROBIO.2014.7090346
   Liu JE, 2013, IEEE WORK APP COMP, P339, DOI 10.1109/WACV.2013.6475038
   Loui Alexander., 2007, MIR 07, P245
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu L., 2010, EL CONTR ENG ICECE 2, P292
   Ma Z., 2012, MM 2012 - Proceedings of the 20th ACM International Conference on Multimedia, P469, DOI DOI 10.1145/2393347.2393414
   Ma ZG, 2014, IEEE T PATTERN ANAL, V36, P1789, DOI 10.1109/TPAMI.2014.2306419
   Ma ZG, 2013, PROC CVPR IEEE, P2627, DOI 10.1109/CVPR.2013.339
   Ma Z, 2013, IEEE T MULTIMEDIA, V15, P1628, DOI 10.1109/TMM.2013.2264928
   Matheus CJ, 2005, LECT NOTES COMPUT SC, V3729, P944, DOI 10.1007/11574620_67
   Matheus CJ, 2005, PROC SPIE, V5813, P75, DOI 10.1117/12.604120
   Matheus CJ, 2003, FUSION 2003: PROCEEDINGS OF THE SIXTH INTERNATIONAL CONFERENCE OF INFORMATION FUSION, VOLS 1 AND 2, P545
   Mazloom M., 2015, ARXIV151002899
   Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313
   Merler M, 2012, IEEE T MULTIMEDIA, V14, P88, DOI 10.1109/TMM.2011.2168948
   Mettes P, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P427, DOI 10.1145/2671188.2749404
   Miao YJ, 2014, IEEE W SP LANG TECH, P165, DOI 10.1109/SLT.2014.7078568
   Ming Y, 2013, 2013 ASE/IEEE INTERNATIONAL CONFERENCE ON SOCIAL COMPUTING (SOCIALCOM), P959, DOI 10.1109/SocialCom.2013.151
   Moon TK, 1996, IEEE SIGNAL PROC MAG, V13, P47, DOI 10.1109/79.543975
   Mori Shunji, 1999, WILEY MICRO
   Morsillo N, 2010, STUD COMPUT INTELL, V287, P357
   Moumtzidou A., 2010, ITI CERTH PARTICIPAT
   Natarajan P, 2012, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2012.6247814
   Nevatia R., 2004, Computer Vision and Pattern Recognition Workshop, P119
   O. Standard, 2010, COMM AL PROT VERS 1
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Over P., 2014, Proceedings of TRECVID 2014
   Pahal N, 2014, 2014 IEEE/WIC/ACM INTERNATIONAL JOINT CONFERENCES ON WEB INTELLIGENCE (WI) AND INTELLIGENT AGENT TECHNOLOGIES (IAT), VOL 1, P438, DOI 10.1109/WI-IAT.2014.68
   Papadopoulos S, 2011, MEDIAEVAL
   Penet C, 2013, INT WORK CONTENT MUL, P17, DOI 10.1109/CBMI.2013.6576546
   Peng Wang, 2014, Advances in Multimedia Information Processing - PCM 2014. 15th Pacific-Rim Conference on Multimedia. Proceedings: LNCS 8879, P163, DOI 10.1007/978-3-319-13168-9_17
   Petkos G., 2012, P 2 ACM INT C MULT R, P231, DOI 10. 1145/2324796.2324825.
   Petkos G, 2014, P ACM ICMR 2014 WORK
   Piasek P, 2014, IR HUM COMP INT C 20
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Potapov D, 2014, LECT NOTES COMPUT SC, V8694, P540, DOI 10.1007/978-3-319-10599-4_35
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   Rafailidis D., 2013, MEDIAEVAL
   Raimond Yves, 2007, The Event Ontology
   Ramanathan V, 2015, IEEE I CONF COMP VIS, P4471, DOI 10.1109/ICCV.2015.508
   Reinders F, 2001, VISUAL COMPUT, V17, P55, DOI 10.1007/PL00013399
   Reuter Timo., 2013, P MEDIAEVAL 2013 MUL, P1
   Rosani A, 2015, IEEE T MULTIMEDIA, V17, P1359, DOI 10.1109/TMM.2015.2441003
   Rostamzadeh N., 2015, IM PROC ICIP 2015 IE
   Rudin C, 2009, J MACH LEARN RES, V10, P2233
   Ruocco M, 2014, MULTIMED TOOLS APPL, V70, P55, DOI 10.1007/s11042-012-1087-z
   Sadlier DA, 2005, IEEE T CIRC SYST VID, V15, P1225, DOI 10.1109/TCSVT.2005.854237
   Sakaki T., 2010, P 19 INT C WORLD WID, P851
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Sayyadi H, 2009, ICWSM
   Scherp A., 2008, ELECT IMAGING 2008
   Scherp A, 2014, MULTIMED TOOLS APPL, V70, P7, DOI 10.1007/s11042-013-1427-7
   Scherp A, 2009, K-CAP'09: PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON KNOWLEDGE CAPTURE, P137
   Schinas M, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P189, DOI 10.1145/2733373.2809933
   Shaw R, 2009, LECT NOTES COMPUT SC, V5926, P153, DOI 10.1007/978-3-642-10871-6_11
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan Karen, 2014, WORKSH P INT C LEARN
   Sinclair P., 2006, 1 INT WORKSH SEM WEB
   Singh B., 2015, COMP VIS ICCV 2015 I
   Snoek Cees G. M., 2008, Foundations and Trends in Information Retrieval, V2, P215, DOI 10.1561/1500000014
   Snoek C. G. M., 2005, 13th Annual ACM International Conference on Multimedia, P399, DOI 10.1145/1101149.1101236
   Sun C, 2014, PROC CVPR IEEE, P2569, DOI 10.1109/CVPR.2014.329
   Sun C, 2013, IEEE I CONF COMP VIS, P913, DOI 10.1109/ICCV.2013.453
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Tang KV, 2013, IEEE I CONF COMP VIS, P2696, DOI 10.1109/ICCV.2013.335
   Tong W, 2014, MACH VISION APPL, V25, P5, DOI 10.1007/s00138-013-0529-6
   Tsai C. -Y., 2014, P INT C MULT RETR, P419
   Tzelepis Christos, 2016, MultiMedia Modeling. 22nd International Conference, MMM 2016. Proceedings, P3, DOI 10.1007/978-3-319-27671-7_1
   Tzelepis C., 2015, IMAGE VIS COMPUT
   Vahdat A, 2013, IEEE I CONF COMP VIS, P1185, DOI 10.1109/ICCV.2013.463
   van Hage WR, 2012, MULTIMED TOOLS APPL, V57, P175, DOI 10.1007/s11042-010-0680-2
   Vapnik V.N., 1998, COMP VIS PATT REC C, V1, P3169
   VAPNIK VN, 2008, STAT LEARNING THEORY, V1
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang P., 2011, P INT WORKSH SEM WEB, P8
   Wang XH, 2004, SECOND IEEE ANNUAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATIONS WORKSHOPS, PROCEEDINGS, P18
   Wang XJ, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P95, DOI 10.1109/ICSC.2007.70
   Wen HK, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P727, DOI 10.1145/2647868.2654883
   Weng J., 2021, Proc. Int. AAAI Conf. Web Soc. Media, V5, P401, DOI [10.1609/icwsm.v5i1.14102, DOI 10.1609/ICWSM.V5I1.14102]
   Westermann U., 2006, P 22 INT C DAT ENG W, px106
   Westermann U, 2007, IEEE MULTIMEDIA, V14, P19, DOI 10.1109/MMUL.2007.23
   Wu S, 2014, PROC CVPR IEEE, P2665, DOI 10.1109/CVPR.2014.341
   Xiong Z., 2003, AC SPEECH SIGN PROC, V5, pV
   Xu M., 2003, P IEEE INT C MULT EX, V2, pII
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Xu ZW, 2014, PROC CVPR IEEE, P97, DOI 10.1109/CVPR.2014.20
   Xu ZW, 2013, IEEE I CONF COMP VIS, P3440, DOI 10.1109/ICCV.2013.427
   Yan WQ, 2011, MULTIMED TOOLS APPL, V55, P443, DOI 10.1007/s11042-010-0560-9
   Yang Y, 2012, LECT NOTES COMPUT SC, V7574, P722, DOI 10.1007/978-3-642-33712-3_52
   Yang Y, 2013, IEEE I CONF COMP VIS, P2104, DOI 10.1109/ICCV.2013.456
   Yau S. S., 2006, SOFTW TECHN FUT EMB, P6
   Ye G., 2012, COMP VIS PATT REC CV
   Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221
   Ye GN, 2013, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2013.282
   Ye Guangnan., 2012, ACM International Conference on Multimedia Retrieval, P39
   Yin J, 2012, IEEE INTELL SYST, V27, P52, DOI 10.1109/MIS.2012.6
   Yu Q., 2012, P 20 ACM INT C MULT, P1073
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zha S., 2015, 26 BRIT MACH VIS C B, P601
   Zhen-Zhong Lan, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P388, DOI 10.1007/978-3-319-04114-8_33
   Zigkolis C, 2014, MULTIMED TOOLS APPL, V70, P89, DOI 10.1007/s11042-012-1154-5
NR 226
TC 13
Z9 14
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2016
VL 53
BP 3
EP 19
DI 10.1016/j.imavis.2016.05.005
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DX4YH
UT WOS:000384386500002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Sagonas, C
   Antonakos, E
   Tzimiropoulos, G
   Zafeiriou, S
   Pantic, M
AF Sagonas, Christos
   Antonakos, Epameinondas
   Tzimiropoulos, Georgios
   Zafeiriou, Stefanos
   Pantic, Maja
TI 300 Faces In-The-Wild Challenge: database and results
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial landmark localization; Challenge; Semi-automatic annotation tool;
   Facial database
ID PICTORIAL STRUCTURES; ALIGNMENT; MODELS
AB Computer Vision has recently witnessed great research advance towards automatic facial points detection. Numerous methodologies have been proposed during the last few years that achieve accurate and efficient performance. However, fair comparison between these methodologies is infeasible mainly due to two issues. (a) Most existing databases, captured under both constrained and unconstrained (in-the-wild) conditions have been annotated using different mark-ups and, in most cases, the accuracy of the annotations is low. (b) Most published works report experimental results using different training/testing sets, different error metrics and, of course, landmark points with semantically different locations. In this paper, we aim to overcome the aforementioned problems by (a) proposing a semi-automatic annotation technique that was employed to re-annotate most existing facial databases under a unified protocol, and (b) presenting the 300 Faces In The-Wild Challenge (300-W), the first facial landmark localization challenge that was organized twice, in 2013 and 2015. To the best of our knowledge, this is the first effort towards a unified annotation scheme of massive databases and a fair experimental comparison of existing facial landmark localization systems. The images and annotations of the new testing database that was used in the 300-W challenge are available from http://ibug.docic.ac.uk/resources/300-W_IMAVISi. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Sagonas, Christos; Antonakos, Epameinondas; Zafeiriou, Stefanos; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
   [Tzimiropoulos, Georgios] Univ Nottingham, Sch Comp Sci, Nottingham NG7 2RD, England.
   [Pantic, Maja] Univ Twente, Fac Elect Engn Math & Comp Sci, POB 217, NL-7500 AE Enschede, Netherlands.
C3 Imperial College London; University of Nottingham; University of Twente
RP Sagonas, C (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
EM c.sagonas@imperial.ac.uk
OI Tzimiropoulos, Georgios/0000-0002-1803-5338
FU EPSRC [EP/J017787/1 (4D-FAB), EP/L026813/1, EP/M02153X/1]; European
   Community [645094]; EPSRC [EP/H016988/1, EP/L026813/1, EP/J017787/1,
   EP/M02153X/1, EP/N007743/1] Funding Source: UKRI
FX This work is funded by the EPSRC project EP/J017787/1 (4D-FAB). The work
   of S. Zafeiriou is also partially supported by the EPSRC project
   EP/L026813/1 Adaptive Facial Deformable Models for Tracking (ADAManT).
   The work of G. Tzimiropoulos is also partially supported by EPSRC
   project EP/M02153X/1 Facial Deformable Models of Animals. The work of M.
   Pantic is further supported by the European Community Horizon 2020
   [H2020/2014-2020] under grant agreement no. 645094 (SEWA).
CR Alabort-i-Medina J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P679, DOI 10.1145/2647868.2654890
   Alabort-i-Medina J, 2015, PROC CVPR IEEE, P3679, DOI 10.1109/CVPR.2015.7298991
   Alabort-i-Medina J, 2014, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2014.439
   Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2005, P 2 INT C AUDIO VIDE
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2010, Fddb: A benchmark for face detection in unconstrained settings
   [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2012, AS C COMP VIS
   [Anonymous], P IEEE INT C COMP VI
   Antonakos E, 2015, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2015.7299182
   Antonakos E, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431445
   Antonakos E, 2014, IEEE IMAGE PROC, P224, DOI 10.1109/ICIP.2014.7025044
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Baltrusaitis T, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P354, DOI 10.1109/ICCVW.2013.54
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cech J, 2016, IMAGE VISION COMPUT, V47, P60, DOI 10.1016/j.imavis.2015.11.003
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Deng JK, 2016, IMAGE VISION COMPUT, V47, P19, DOI 10.1016/j.imavis.2015.11.005
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Haoqiang Fan, 2016, Image and Vision Computing, V47, P27, DOI 10.1016/j.imavis.2015.11.004
   Jaiswal S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P370, DOI 10.1109/ICCVW.2013.56
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Martinez A., 1998, AR FACE DATABASE
   Martinez B, 2016, IMAGE VISION COMPUT, V47, P36, DOI 10.1016/j.imavis.2015.09.003
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Milborrow S, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P378, DOI 10.1109/ICCVW.2013.57
   Pedersoli M, 2014, PROC CVPR IEEE, P3694, DOI 10.1109/CVPR.2014.472
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Tong Y, 2012, COMPUT VIS IMAGE UND, V116, P922, DOI 10.1016/j.cviu.2012.03.008
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Tzimiropoulos G, 2014, IEEE T INF FOREN SEC, V9, P2024, DOI 10.1109/TIFS.2014.2361018
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79
   Tzimiropoulos G, 2012, IEEE T PATTERN ANAL, V34, P2454, DOI 10.1109/TPAMI.2012.40
   Uricár M, 2016, IMAGE VISION COMPUT, V47, P45, DOI 10.1016/j.imavis.2016.02.004
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu Y, 2014, PROC CVPR IEEE, P1781, DOI 10.1109/CVPR.2014.230
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yan JJ, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P392, DOI 10.1109/ICCVW.2013.126
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 55
TC 408
Z9 448
U1 2
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2016
VL 47
BP 3
EP 18
DI 10.1016/j.imavis.2016.01.002
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO5LL
UT WOS:000377824500002
OA Green Submitted, Green Published
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Zhao, XH
   Jiang, YC
   Stathaki, T
AF Zhao, Xiaohui
   Jiang, Yicheng
   Stathaki, Tania
TI A novel low false alarm rate pedestrian detection framework based on
   single depth images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pedestrian detection; Histogram of Oriented Gradients; Shape context;
   Chamfer matching
ID TRACKING
AB Pedestrian detection is an important image understanding problem with many potential applications. There has been little success in creating an algorithm which exhibits a high detection rate while keeping the false alarm in a relatively low rate. This paper presents a method designed to resolve this problem. The proposed method uses the Kinect or any similar type of sensors which facilitate the extraction of a distinct foreground. Then potential regions, which are candidates for the presence of human(s), are detected by employing the widely used Histogram of Oriented Gradients (HOG) technique, which performs well in terms of good detection rates but suffers from significantly high false alarm rates. Our method applies a sequence of operations to eliminate the false alarms produced by the HOG detector based on investigating the fine details of local shape information. Local shape information can be identified by efficient utilization of the edge points which, in this work, are used to formulate the so called Shape Context (SC) model. The proposed detection framework is divided in four sequential stages, with each stage aiming at refining the detection results of the previous stage. In addition, our approach employs a pre-evaluation stage to pre-screen and restrict further detection results. Extensive experimental results on the dataset created by the authors, involves 673 images collected from 11 different scenes, demonstrate that the proposed method eliminates a large percentage of the false alarms produced by the HOG pedestrian detector. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Zhao, Xiaohui; Jiang, Yicheng] Harbin Inst Technol, Res Inst Elect Engn Technol, Mailbox 338, Harbin 150001, Peoples R China.
   [Zhao, Xiaohui; Stathaki, Tania] Univ London Imperial Coll Sci Technol & Med, Commun & Signal Proc Res Grp, Dept Elect & Elect Engn, Exhibit Rd, London SW7 2AZ, England.
C3 Harbin Institute of Technology; Imperial College London
RP Jiang, YC (corresponding author), Harbin Inst Technol, Res Inst Elect Engn Technol, Mailbox 338, Harbin 150001, Peoples R China.; Stathaki, T (corresponding author), Univ London Imperial Coll Sci Technol & Med, Commun & Signal Proc Res Grp, Dept Elect & Elect Engn, Exhibit Rd, London SW7 2AZ, England.
EM xh.zhao@outlook.com; jiangyc@hit.edu.cn; t.stathaki@imperial.ac.uk
RI Stathaki, Tania/ADC-9453-2022; Zhao, Xiaohui/D-9785-2014
OI Zhao, Xiaohui/0000-0001-5369-1595
FU China Scholarship Council (CSC) [201306120111]
FX This paper was supported by the China Scholarship Council (CSC) for 1
   year study at Imperial College London, File No. 201306120111.
CR [Anonymous], CVPR 2011 WORKSHOPS, DOI DOI 10.1109/CVPRW.2011.5981811
   [Anonymous], CVPR
   Belongie S., 2001, ADV NEURAL INFORM PR, V2, P3
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chiu S, 1996, 1996 BIENNIAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P461, DOI 10.1109/NAFIPS.1996.534778
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Enzweiler M, 2009, IEEE T PATTERN ANAL, V31, P2179, DOI 10.1109/TPAMI.2008.260
   Gavrila DM, 2007, INT J COMPUT VISION, V73, P41, DOI 10.1007/s11263-006-9038-7
   Giannarou S., 2013, NOVEL FRAMEWORK OBJE, P235
   Keller CG, 2011, IEEE INT VEH SYM, P691, DOI 10.1109/IVS.2011.5940480
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Song SR, 2013, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2013.36
   Szarvas M, 2005, 2005 IEEE INTELLIGENT VEHICLES SYMPOSIUM PROCEEDINGS, P224
   Ulusoy I, 2005, PROC CVPR IEEE, P258
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Zhang L, 2007, 2007 IEEE INT PAR DI, P1
   Zhao X., 2015, NEUROCOMPUTING
   Zhao XH, 2015, IEEE GEOSCI REMOTE S, V12, P1828, DOI 10.1109/LGRS.2015.2430366
NR 23
TC 0
Z9 0
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2016
VL 45
BP 11
EP 21
DI 10.1016/j.imavis.2015.11.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DE8PY
UT WOS:000370900000002
DA 2024-07-18
ER

PT J
AU Kim, J
   Kim, D
AF Kim, Jiman
   Kim, Daijin
TI Accurate abandoned and removed object classification using hierarchical
   finite state machine
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Support vector machine; Hierarchical finite state machine; Pixel
   classification; Region classification; Event classification
AB The ability of most existing approaches to classify abandoned and removed objects (AROs) in images is affected by external environmental conditions such as illumination and traffic volume because the approaches use several pre-defined threshold values and generate many falsely-classified static regions. To reduce these effects, we propose an accurate ARO classification method using a hierarchical finite state machine (FSM) that consists of pixel-layer, region-layer, and event-layer FSMs, where the result of the lower-layer FSM is used as the input of the higher-layer FSM. Each FSM is defined by a Mealy state machine with three states and several state transitions, where a support vector machine (SVM) determines the state transition based on the current state and input features such as area, intensity, motion, shape, time duration, color and edge. Because it uses the hierarchical FSM (H-FSM) structure with features that are optimally trained by SVM classifiers, the proposed ARO classification method does not require threshold values and guarantees better classification accuracy under severe environmental changes. In experiments, the proposed ARO classification method provided much higher classification accuracy and lower false alarm rate than the state-of-the-art methods in both public databases and a commercial database. The proposed ARO classification method can be applied to many practical applications such as detection of littering, illegal parking, theft, and camouflaged soldiers. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Kim, Jiman] Software Ctr, Suwon, South Korea.
   [Kim, Daijin] POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Kim, D (corresponding author), POSTECH, Dept Comp Sci & Engn, San 31, Pohang 790784, South Korea.
EM jiman.kim@samsung.com; dkim@postech.ac.kr
FU Institute for Information & Communications Technology Promotion (IITP)
   grant - Korean government (MSIP) [B0101-15-0552]; Implementation of
   Technologies for Identification, Behavior, and Location of Human based
   on Sensor Network Fusion Program through the Ministry of Trade, Industry
   and Energy [10041629]
FX This work was supported by Institute for Information & Communications
   Technology Promotion (IITP) grant funded by the Korean government (MSIP)
   (B0101-15-0552, Development of Predictive Visual Intelligence
   Technology). This work was also supported by the Implementation of
   Technologies for Identification, Behavior, and Location of Human based
   on Sensor Network Fusion Program through the Ministry of Trade, Industry
   and Energy (Grant Number: 10041629).
CR [Anonymous], DIGITAL IMAGE PROCES
   Barnich O., 2009, IEEE INT C AC SPEECH, P945
   Bayona A, 2010, IEEE IMAGE PROC, P4657, DOI 10.1109/ICIP.2010.5650699
   Beynon MD, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P221, DOI 10.1109/AVSS.2003.1217925
   Chang JY, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/675784
   Evangelio R., 2011, IEEE INT C ADV VID S, P71
   Fan Q., 2011, IEEE INT C ADV VID S, P36
   Fan QF, 2012, 2012 IEEE NINTH INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL-BASED SURVEILLANCE (AVSS), P58, DOI 10.1109/AVSS.2012.62
   Fujiyoshi H, 2004, IEICE T INF SYST, VE87D, P2821
   Guler S., 2006, IEEE INT WORKSH PETS, P99
   Hague M., 2012, IEEE INT C ADV VID S, P166
   Han B, 2008, IEEE T PATTERN ANAL, V30, P1186, DOI 10.1109/TPAMI.2007.70771
   Hassan W, 2013, IET COMPUT VIS, V7, P1, DOI 10.1049/iet-cvi.2012.0054
   Kim J, 2014, IEEE SIGNAL PROC LET, V21, P937, DOI 10.1109/LSP.2014.2320676
   Li L., 2003, ACM MULTIMEDIA 2003, P2
   Li QJ, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P156, DOI 10.1109/ICIG.2009.166
   Liao H., IEEE INT C ADV VID S, P132
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Mathew R., 2005, IEEE WORKSH MULT SIG, P1
   Miguel J., IEEE INT C ADV VID S, P18
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Ortego D., 2014, IEEE INT C IM PROC 2, P2403
   Pan J., 2011, IEEE INT C IM PROC 2, P3597
   Porikli F, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/197875
   Szeliski R., 2011, COMPUTER VISION ALGO
   Tian YL, 2011, IEEE T SYST MAN CY C, V41, P565, DOI 10.1109/TSMCC.2010.2065803
   Venetianer PL, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P242, DOI 10.1109/AVSS.2007.4425317
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 28
TC 1
Z9 1
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2015
VL 44
BP 1
EP 14
DI 10.1016/j.imavis.2015.09.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CZ5EK
UT WOS:000367125100001
DA 2024-07-18
ER

PT J
AU Lo Presti, L
   La Cascia, M
   Sclaroff, S
   Camps, O
AF Lo Presti, Liliana
   La Cascia, Marco
   Sclaroff, Stan
   Camps, Octavia
TI Hankelet-based dynamical systems modeling for 3D action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hidden Markov Model; Hankel Matrix; Linear time invariant system;
   Discriminative learning; Action
ID HIDDEN MARKOV-MODELS; IDENTIFICATION; ENSEMBLE
AB This paper proposes to model an action as the output of a sequence of atomic Linear Time Invariant (LTI) systems. The sequence of LTI systems generating the action is modeled as a Markov chain, where a Hidden Markov Model (HMM) is used to model the transition from one atomic LTI system to another. In turn, the LTI systems are represented in terms of their Hankel matrices. For classification purposes, the parameters of a set of HMMs. (one for each action class) are learned via a discriminative approach. This work proposes a novel method to learn the atomic LTI systems from training data, and analyzes in detail the action representation in terms of a sequence of Hankel matrices. Extensive evaluation of the proposed approach on two publicly available datasets demonstrates that the proposed method attains state-of-the-art accuracy in action classification, from the 3D locations of body joints (skeleton). (C) 2015 Elsevier B.V. All rights reserved.
C1 [Lo Presti, Liliana; La Cascia, Marco] Univ Palermo, DICGIM, I-90128 Palermo, Italy.
   [Sclaroff, Stan] Boston Univ, Dept Comp Sci, Boston, MA 02215 USA.
   [Camps, Octavia] Northeastern Univ, Dept Elect & Comp Eng, Boston, MA 02115 USA.
C3 University of Palermo; Boston University; Northeastern University
RP Lo Presti, L (corresponding author), Univ Palermo, DICGIM, Vle Sci, Ed 6, I-90128 Palermo, Italy.
EM liliana.lopresti@unipa.it; marco.lacascia@unipa.it; sclaroff@bu.edu;
   camps@coe.neu.edu
RI La Cascia, Marco/E-9612-2012
OI La Cascia, Marco/0000-0002-8766-6395; Lo Presti,
   Liliana/0000-0003-0833-4403
FU Italian MIUR SINTESYS - Security and Intelligence System grant
   [PON0101687]; US NSF [1029430, IIS-1318145, ECCS-1404163]; AFOSR grant
   [FA9550-12-1-0271]; Alert DHS Center of Excellence [2008-ST-061-ED0001];
   Direct For Computer & Info Scie & Enginr; Div Of Information &
   Intelligent Systems [1029430] Funding Source: National Science
   Foundation; Direct For Computer & Info Scie & Enginr; Div Of Information
   & Intelligent Systems [0910908] Funding Source: National Science
   Foundation
FX This work was partially supported by Italian MIUR SINTESYS - Security
   and Intelligence System grant PON0101687, US NSF grant 1029430, US NSF
   grants IIS-1318145 and ECCS-1404163; AFOSR grant FA9550-12-1-0271, and
   the Alert DHS Center of Excellence under Award Number
   2008-ST-061-ED0001.
CR Altun Y., 2003, P INT C MACHINE LEAR, P3
   [Anonymous], J VIS COMMUN IMAGE R
   [Anonymous], NIPS
   [Anonymous], 2008, BMVC
   Bahl L. R., 1986, ICASSP 86 Proceedings. IEEE-IECEJ-ASJ International Conference on Acoustics, Speech and Signal Processing (Cat. No.86CH2243-4), P49
   Bamieh B, 2002, INT J ROBUST NONLIN, V12, P841, DOI 10.1002/rnc.706
   BAUM LE, 1970, ANN MATH STAT, V41, P164, DOI 10.1214/aoms/1177697196
   Binlong Li, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3193, DOI 10.1109/CVPR.2011.5995672
   Chang YJ, 2011, RES DEV DISABIL, V32, P2566, DOI 10.1016/j.ridd.2011.07.002
   Collins M, 2002, PROCEEDINGS OF THE 2002 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING, P1
   Cooper H, 2007, LECT NOTES COMPUT SC, V4796, P88
   Cuzzolin F, 2014, IEEE T PATTERN ANAL, V36, P1483, DOI 10.1109/TPAMI.2013.181
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Devanne M, 2013, LECT NOTES COMPUT SC, V8158, P456, DOI 10.1007/978-3-642-41190-8_49
   Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Duric Z, 2002, P IEEE, V90, P1272, DOI 10.1109/JPROC.2002.801449
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Felzenszwalb P, 2008, PROC CVPR IEEE, P1984
   Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548
   Gupta V., 2009, Networked sensing, estimation and control systems
   Hussein, 2013, INT JOINT C ART INT
   Ikizler N., 2007, IEEE Conf. on Computer Vision and Pattern Recognition, P1, DOI 10.1109/cvpr.2007.383168
   Jebara T., 1998, Advances in neural information processing systems, P494
   Jiang H, 2010, COMPUT SPEECH LANG, V24, P589, DOI 10.1016/j.csl.2009.08.002
   Junejo IN, 2011, IEEE T PATTERN ANAL, V33, P172, DOI 10.1109/TPAMI.2010.68
   Jung N., 2012, US Patent, Patent No. [8,219,438, 8219438]
   Klamka J, 2013, B POL ACAD SCI-TECH, V61, P335, DOI 10.2478/bpasts-2013-0031
   Lafferty John, 2001, INT C MACH LEARN ICM
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822
   Li R, 2007, IEEE I CONF COMP VIS, P1687
   Li R, 2010, INT J COMPUT VISION, V87, P170, DOI 10.1007/s11263-009-0283-4
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Lo Presti L., 2015, P COMP VIS PATT REC, P36
   Lo Presti L, 2015, LECT NOTES COMPUT SC, V9280, P586, DOI 10.1007/978-3-319-23234-8_54
   Lo Presti L, 2015, LECT NOTES COMPUT SC, V9005, P529, DOI 10.1007/978-3-319-16811-1_35
   Lo Presti L, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P730, DOI 10.1109/ICCVW.2013.100
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   MARTENS J, 2011, P 28 INT C MACH LEAR, P1033
   Martínez-Contreras F, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P43, DOI 10.1109/AVSS.2009.46
   MEIR R, 1995, NEURAL COMPUT, V7, P144, DOI 10.1162/neco.1995.7.1.144
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Padilla-Lopez J.R., 2015, ABS14077390 CORR
   Paoletti S, 2007, EUR J CONTROL, V13, P242, DOI 10.3166/EJC.13.242-260
   Park S., 2003, First ACM SIGMM International Workshop on Video surveillance, P65
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Raman N., 2015, NEUROCOMPUT IN PRESS
   Rehg JM, 2013, PROC CVPR IEEE, P3414, DOI 10.1109/CVPR.2013.438
   Sankaranarayanan AC, 2010, LECT NOTES COMPUT SC, V6311, P129, DOI 10.1007/978-3-642-15549-9_10
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Sha Fei, 2007, in Advances in Neural Information Processing Systems, V19, P1249
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Smola Alexander J, 2000, ADV LARGE MARGIN CLA
   SONTAG ED, 1981, IEEE T AUTOMAT CONTR, V26, P346, DOI 10.1109/TAC.1981.1102596
   Suha Kwak, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3345, DOI 10.1109/CVPR.2011.5995435
   Sung JY, 2012, IEEE INT CONF ROBOT, P842, DOI 10.1109/ICRA.2012.6224591
   Taskar B, 2004, ADV NEUR IN, V16, P25
   Thangali A, 2011, PROC CVPR IEEE, P521, DOI 10.1109/CVPR.2011.5995718
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Varadaraju A. Thangali, 2013, THESIS BOSTON U MA
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Wang CY, 2013, PROC CVPR IEEE, P915, DOI 10.1109/CVPR.2013.123
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wang Y, 2009, PROC CVPR IEEE, P872, DOI 10.1109/CVPRW.2009.5206709
   Weinland D, 2007, IEEE I CONF COMP VIS, P170
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yao A., 2011, P BRIT MACH VIS C BM, V3, P671
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 86
TC 23
Z9 24
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2015
VL 44
BP 29
EP 43
DI 10.1016/j.imavis.2015.09.007
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CZ5EK
UT WOS:000367125100003
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Shi, CJ
   Ruan, QQ
   An, GY
   Ge, C
AF Shi, Caijuan
   Ruan, Qiuqi
   An, Gaoyun
   Ge, Chao
TI Semi-supervised sparse feature selection based on multi-view Laplacian
   regularization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-view learning; Laplacian regularization; Semi-supervised learning;
   Sparse feature selection
AB Semi-supervised sparse feature selection, which can exploit the large number unlabeled data and small number labeled data simultaneously, has placed an important role in web image annotation. However, most of the semi-supervised sparse feature selection methods are developed for single-view data and these methods cannot naturally deal with the multi-view data, though it has shown that leveraging information contained in multiple views can dramatically improve the feature selection performance. Recently, multi-view learning has obtained much research attention because it can reveal and leverage the correlated and complementary information between different views. So in this paper, we apply multi-view learning into semi-supervised sparse feature selection and propose a semi-supervised sparse feature selection method based on multi-view Laplacian regularization, namely, multi-view Laplacian sparse feature selection (MLSFS).(1) MLSFS utilizes multi-view Laplacian regularization to boost semi-supervised sparse feature selection performance. A simple iterative method is proposed to solve the objective function of MLSFS. We apply MLSFS algorithm into image annotation task and conduct experiments on two web image datasets. The experimental results show that the proposed MLSFS outperforms the state-of-art single-view sparse feature selection methods. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Shi, Caijuan; Ge, Chao] North China Univ Sci & Technol, Coll Informat Engn, Tangshan 063009, Peoples R China.
   [Shi, Caijuan; Ruan, Qiuqi; An, Gaoyun] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   [Shi, Caijuan; Ruan, Qiuqi; An, Gaoyun] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 North China University of Science & Technology; Beijing Jiaotong
   University; Beijing Jiaotong University
RP Shi, CJ (corresponding author), North China Univ Sci & Technol, Coll Informat Engn, Tangshan 063009, Peoples R China.
EM shicaijuan2011@gmail.com; qqruan@center.njtu.edu.cn; gyan@bjtu.edu.cn;
   chaoge@ncst.edu.cn
FU National Key Basic Research Program of China [2012CB316304]; National
   Natural Science Foundation of China [61471032, 61472030]; New Century
   Excellent Talents in University [NCET-12-0768]; Program for Innovative
   Research Team in University of Ministry of Education of China
   [IRT201206]; Hebei Colleges and University Scientific and Technology
   Research [QN2014026]
FX This work was supported by the Youth Foundation Project of Hebei
   Colleges and University Scientific and Technology Research (QN2014026),
   National Key Basic Research Program of China (2012CB316304), National
   Natural Science Foundation of China (61471032, 61472030), New Century
   Excellent Talents in University (NCET-12-0768), Program for Innovative
   Research Team in University of Ministry of Education of China
   (IRT201206).
CR [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], SURVEY MULTIVIEW LEA
   [Anonymous], 2006, CS0609071 ARXIV
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Blum A., P 11 ANN C COMP LEAR, P92
   Brefeld U., P 23 INT C MACH LEAR, P145
   Cao L., P IEEE C COMP VIS PA, P1998
   Cawley G.C., 2006, Advances in Neural Information Processing Systems, P209
   Chapelle O., P INT C ART INT STAT, P57
   Chaudhuri K., P 26 INT C MACH LEAR, P129
   Chua T., P CIVR 2009, P1
   Collobert R, 2006, J MACH LEARN RES, V7, P1687
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Feng Y.F., 2012, P ACCV 2012, P343
   Francis R.B., 2004, P 21 INT C MACH LEAR, P41
   Geng B, 2012, IEEE T PATTERN ANAL, V34, P1227, DOI 10.1109/TPAMI.2012.57
   Guan N., ARXIV12073438V1STATM
   Guan NY, 2012, IEEE T NEUR NET LEAR, V23, P1087, DOI 10.1109/TNNLS.2012.2197827
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P309, DOI 10.1109/ICCV.2009.5459266
   He J.R., 2011, P ICML
   Hotelling H, 1936, BIOMETRIKA, V28, P321, DOI 10.1093/biomet/28.3-4.321
   Jones Rosie., 2005, Learning to extract entities from labeled and unlabeled text
   Kakade SM, 2007, LECT NOTES COMPUT SC, V4539, P82, DOI 10.1007/978-3-540-72927-3_8
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Li H., P ICDMW 2009, P164
   Liu WF, 2014, COMPUT VIS IMAGE UND, V118, P50, DOI 10.1016/j.cviu.2013.03.007
   Liu WF, 2013, IEEE T IMAGE PROCESS, V22, P2676, DOI 10.1109/TIP.2013.2255302
   Liu Y., P ICCIA 2010, P293
   Luo Y., P AAAI 2013, P647
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   MILLER DJ, 1996, ADV NEURAL INFORM PR, V9, P571
   Nguyen C.T., P IJCAI 2013, P1558
   Nie F.P., P NIPS 2010, P1813
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Nigam K, 2000, MACH LEARN, V39, P103, DOI 10.1023/A:1007692713085
   Nigam K., P 9 INT C INF KNOWL, P86
   Shi CJ, 2014, IMAGE VISION COMPUT, V32, P189, DOI 10.1016/j.imavis.2013.12.013
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Wang L.P., L2 P MATRIX NORM ITS
   Xia TA, 2010, IEEE T SYST MAN CY B, V40, P1438, DOI 10.1109/TSMCB.2009.2039566
   Xie B, 2011, IEEE T SYST MAN CY B, V41, P1088, DOI 10.1109/TSMCB.2011.2106208
   Xu C., P ICIMCS 2013, P7
   Xu ZL, 2010, IEEE T NEURAL NETWOR, V21, P1033, DOI 10.1109/TNN.2010.2047114
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P4636, DOI 10.1109/TIP.2012.2207395
   Zhu X., 2007, SEMISUPERVISED LEARN, P1530
   Zhu X, 2003, ICML
NR 46
TC 29
Z9 30
U1 0
U2 51
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2015
VL 41
BP 1
EP 10
DI 10.1016/j.imavis.2015.06.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CQ4ST
UT WOS:000360595600001
DA 2024-07-18
ER

PT J
AU Yi, KM
   Jeong, H
   Kim, SW
   Yin, S
   Oh, S
   Choi, JY
AF Yi, Kwang Moo
   Jeong, Hawook
   Kim, Soo Wan
   Yin, Shimin
   Oh, Songhwai
   Choi, Jin Young
TI Visual tracking of non-rigid objects with partial occlusion through
   elastic structure of local patches and hierarchical diffusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Local patches; Markov random field; Particle filtering;
   Hierarchical diffusion
AB In this paper, a tracking method based on sequential Bayesian inference is proposed. The proposed method focuses on solving both the problem of tracking under partial occlusions and the problem of non-rigid object tracking in real-time on a desktop personal computer (PC). The proposed method is mainly composed of two parts: (1) modeling the target object using elastic structure of local patches for robust performance; and (2) efficient hierarchical diffusion method to perform the tracking procedure in real-time. The elastic structure of local patches allows the proposed method to handle partial occlusions and non-rigid deformations through the relationship among neighboring patches. The proposed hierarchical diffusion method generates samples from the region where the posterior is concentrated to reduce computation time. The method is extensively tested on a number of challenging image sequences with occlusion and non-rigid deformation. The experimental results show the real-time capability and the robustness of the proposed method under various situations. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Yi, Kwang Moo] Ecole Polytech Fed Lausanne, Comp Vis Lab, CH-1015 Lausanne, Switzerland.
   [Jeong, Hawook; Kim, Soo Wan; Oh, Songhwai; Choi, Jin Young] Seoul Natl Univ, ASRI, Dept Elect & Comp Engn, Seoul 151744, South Korea.
   [Yin, Shimin] Samsung Techwin, Gyeonggi Do, South Korea.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Seoul National University (SNU); Samsung
RP Oh, S (corresponding author), Seoul Natl Univ, Coll Engn, Dept Elect & Comp Engn, 014,1 Gwanangno, Seoul 151744, South Korea.
EM kwang.yi@epfl.ch; hwjeong@snu.ac.kr; soowankim@snu.ac.kr;
   simcom79@gmail.com; songhwai@snu.ac.kr; jychoi@snu.ac.kr
RI Yi, Kwang Moo/C-2612-2016
OI Yi, Kwang Moo/0000-0001-9036-3822
FU SNU Brain Korea 21 Plus Information Technology program [21A20131612805];
   IT R&D program of MOTIE/KEIT [10041610]
FX This research was partially sponsored by the SNU Brain Korea 21 Plus
   Information Technology program [21A20131612805] and the IT R&D program
   of MOTIE/KEIT [10041610].
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 1995, Markov random field modeling in computer vision
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Godec M, 2011, IEEE I CONF COMP VIS, P81, DOI 10.1109/ICCV.2011.6126228
   Grabner H., 2006, BMVC, P47
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Kim IS, 2010, INT J CONTROL AUTOM, V8, P926, DOI 10.1007/s12555-010-0501-4
   Kwon J, 2009, PROC CVPR IEEE, P991, DOI 10.1109/CVPRW.2009.5206501
   Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502
   Mel X., 2009, COMP VIS IEEE INT C, P1436
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Platt JC, 2000, ADV NEUR IN, P61
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Salzmann M, 2008, PROC CVPR IEEE, P1213
   Stalder Severin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1409, DOI 10.1109/ICCVW.2009.5457445
   Varol A, 2012, PROC CVPR IEEE, P2248, DOI 10.1109/CVPR.2012.6247934
   Yi K.M., 2010, P IM VIS COMP NZ 25, P1
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin S, 2011, COMPUT VIS IMAGE UND, V115, P885, DOI 10.1016/j.cviu.2011.02.010
NR 31
TC 3
Z9 3
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2015
VL 39
BP 23
EP 37
DI 10.1016/j.imavis.2015.04.007
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CM2WQ
UT WOS:000357543400003
DA 2024-07-18
ER

PT J
AU Chen, SZ
   Tian, YL
   Liu, QS
   Metaxas, DN
AF Chen, Shizhi
   Tian, YingLi
   Liu, Qingshan
   Metaxas, Dimitris N.
TI Recognizing expressions from face and body gesture by temporal
   normalized motion and appearance features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Affect recognition; Facial feature; Body gesture; MHI-HOG; Image-HOG
ID FACIAL EXPRESSION; RECOGNITION; SEGMENTATION
AB Recently, recognizing affects from both face and body gestures attracts more attentions. However, it still lacks of efficient and effective features to describe the dynamics of face and gestures for real-time automatic affect recognition. In this paper, we combine both local motion and appearance feature in a novel framework to model the temporal dynamics of face and body gesture. The proposed framework employs MHI-HOG and Image-HOG features through temporal normalization or bag of words to capture motion and appearance information. The MHI-HOG stands for Histogram of Oriented Gradients (HOG) on the Motion History Image (MHI). It captures motion direction and speed of a region of interest as an expression evolves over the time. The Image-HOG captures the appearance information of the corresponding region of interest. The temporal normalization method explicitly solves the time resolution issue in the video-based affect recognition. To implicitly model local temporal dynamics of an expression, we further propose a bag of words (BOW) based representation for both MHI-HOG and Image-HOG features. Experimental results demonstrate promising performance as compared with the state-of-the-art. Significant improvement of recognition accuracy is achieved as compared with the frame-based approach that does not consider the underlying temporal dynamics. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Chen, Shizhi; Tian, YingLi] CUNY, Dept Elect Engn, New York, NY 10021 USA.
   [Liu, Qingshan] Nanjing Univ Informat Sci & Technol, Sch Informat & Control, Nanjing, Peoples R China.
   [Metaxas, Dimitris N.] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08855 USA.
C3 City University of New York (CUNY) System; Nanjing University of
   Information Science & Technology; Rutgers University System; Rutgers
   University New Brunswick
RP Tian, YL (corresponding author), CUNY, Dept Elect Engn, New York, NY 10021 USA.
EM schen21@ccny.cuny.edu; ytian@ccny.cuny.edu; qsliu@nuist.edu.cn;
   dnm@cs.rutgers.edu
RI Liu, Qing/GWC-9222-2022; Liu, Qingqing/HMV-4816-2023; Chen,
   Rainie/ISS-6016-2023; liu, qingqing/HHD-0360-2022
OI Tian, Yingli/0000-0003-4458-360X
FU DOE [DE-AC05-060R23100]; NOAA Cooperative Remote Sensing Science and
   Technology (CREST) Fellowship; Div Of Information & Intelligent Systems;
   Direct For Computer & Info Scie & Enginr [0964597] Funding Source:
   National Science Foundation
FX The authors thank Dr. H. Gunes for providing the FABO Database. This
   article was partially developed under an appointment to the DHS Summer
   Research Team Program for Minority Serving Institutions, administered by
   the Oak Ridge Institute for Science and Education (ORISE) through an
   interagency agreement between the U.S. Department of Energy (DOE) and
   U.S. Department of Homeland Security (DHS). ORISE is managed by Oak
   Ridge Associated Universities (ORAU) under DOE contract number
   DE-AC05-060R23100. It has not been formally reviewed by DHS. The views
   and conclusions contained in this document are those of the authors and
   should not be interpreted as necessarily representing the official
   policies, either expressed or implied, of DHS, DOE, or ORAU/ORISE. DHS,
   DOE and ORAU/ORISE do not endorse any products or commercial services
   mentioned in this article.; Shizhi Chen is supported by NOAA Cooperative
   Remote Sensing Science and Technology (CREST) Fellowship.
CR Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203
   AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   [Anonymous], THESIS
   Bernhardt D, 2007, LECT NOTES COMPUT SC, V4738, P59
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bradski GR, 2002, MACH VISION APPL, V13, P174, DOI 10.1007/s001380100064
   Chang C.C., LIBSVM: a library for support vector machines
   Chen S., 2011, IEEE WIR OPT COMM C
   Chen S., 2011, IEEE INT C AUT FAC G
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dalai N., 2005, IEEE INT C COMP VIS
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Ekman P., 1978, FACIAL ACTIONCODING
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fei-Fei L., 2009, IEEE INT C COMP VIS
   Glowinski D, 2011, IEEE T AFFECT COMPUT, V2, P106, DOI 10.1109/T-AFFC.2011.7
   Gunes H, 2006, INT C PATT RECOG, P1148
   Gunes H, 2009, IEEE T SYST MAN CY B, V39, P64, DOI 10.1109/TSMCB.2008.927269
   Guo GD, 2005, IEEE T SYST MAN CY B, V35, P477, DOI 10.1109/TSMCB.2005.846658
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Joachims Thorsten, 1998, EUROPEAN C MACHINE L, P137, DOI 10.1007/
   Kim D, 2007, PATTERN RECOGN, V40, P3012, DOI 10.1016/j.patcog.2007.02.010
   Kovac J., 2003, EUROCON COMP TOOL
   Lanitis A, 1997, IEEE T PATTERN ANAL, V19, P743, DOI 10.1109/34.598231
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Littlewort G., 2003, IEEE INT C COMP VIS
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lyons M. J., 1998, IEEE INT C AUT FAC G
   Meeren HKM, 2005, P NATL ACAD SCI USA, V102, P16518, DOI 10.1073/pnas.0507650102
   Ohya J., 1998, IEEE INT C AUT FAC G
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Patras I., 2006, IEEE T SYST MAN CY B
   Patras I., 2004, IEEE INT C MULT EXP
   Picard R., 2005, ACM MULTIMEDIA
   Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179
   Saragih J., 2011, IEEE INT C AUT FAC G
   Scherer KR, 2007, EMOTION, V7, P158, DOI 10.1037/1528-3542.7.1.158
   Schmidt K., 2001, Yearbook of Physical Anthropology
   Shan C., 2007, BRIT MACH VIS C, P1
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Tong S., 2000, INT C MACH LEARN ICM
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Wang Y, 2011, IEEE T PATTERN ANAL, V33, P1310, DOI 10.1109/TPAMI.2010.214
   Yang P., 2008, EUR C COMP VIS EECV
   Yang Peng, 2007, IEEE INT C COMP VIS
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang JK, 2011, IEEE ICC
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 51
TC 47
Z9 55
U1 0
U2 39
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2013
VL 31
IS 2
BP 175
EP 185
DI 10.1016/j.imavis.2012.06.014
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 102KN
UT WOS:000315843600007
DA 2024-07-18
ER

PT J
AU Metallinou, A
   Katsamanis, A
   Narayanan, S
AF Metallinou, Angeliki
   Katsamanis, Athanasios
   Narayanan, Shrikanth
TI Tracking continuous emotional trends of participants during affective
   dyadic interactions using body language and speech information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Continuous emotion tracking; Dimensional emotional descriptions;
   Gaussian Mixture Model mapping; Body language; Improvised dyadic
   interactions
ID AFFECT RECOGNITION; FACE
AB We address the problem of tracking continuous levels of a participant's activation, valence and dominance during the course of affective dyadic interactions, where participants may be speaking, listening or doing neither. To this end, we extract detailed and intuitive descriptions of each participant's body movements, posture and behavior towards his interlocutor, and speech information. We apply a Gaussian Mixture Model-based approach which computes a mapping from a set of observed audio-visual cues to an underlying emotional state. We obtain promising results for tracking trends of participants' activation and dominance values, which outperform other regression-based approaches used in the literature. Additionally, we shed light into the way expressive body language is modulated by underlying emotional states in the context of dyadic interactions. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Metallinou, Angeliki; Katsamanis, Athanasios; Narayanan, Shrikanth] Univ So Calif, SAIL, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Metallinou, A (corresponding author), Univ So Calif, SAIL, Los Angeles, CA 90089 USA.
EM metallin@usc.edu; nkatsam@sipi.usc.edu; shri@sipi.usc.edu
RI Katsamanis, Nassos/AAK-8217-2020; Narayanan, Shrikanth S/D-5676-2012
OI Katsamanis, Athanasios/0000-0002-2642-2354
FU Division of Computing and Communication Foundations; Direct For Computer
   & Info Scie & Enginr [1029373] Funding Source: National Science
   Foundation; Division Of Research On Learning; Direct For Education and
   Human Resources [1008372] Funding Source: National Science Foundation
CR [Anonymous], P LREC WORKSH MULT C
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], 2006, The HTK book (for HTK version 3.4) [Computer software manual]
   [Anonymous], 2007, Pattern Classification
   [Anonymous], 2005, NEW HDB METHODS NONV
   [Anonymous], IEEE T AFFECTIVE COM
   [Anonymous], P EUR SIGN PROC C
   Baucom B., 2011, P ICASSP
   Busso C, 2008, LANG RESOUR EVAL, V42, P335, DOI 10.1007/s10579-008-9076-6
   Camurri A, 2003, INT J HUM-COMPUT ST, V59, P213, DOI 10.1016/S1071-5819(03)00050-8
   Camurri A., 2007, P ACII
   Cowie R., GTRACE GEN TRACE PRO
   Cowie R., 2000, PROC ISCA WORKSHOP S, P19
   Eyben F., 2010, P INT JAP
   Eyben F, 2010, J MULTIMODAL USER IN, V3, P7, DOI 10.1007/s12193-009-0032-6
   Glowinski D, 2011, IEEE T AFFECT COMPUT, V2, P106, DOI 10.1109/T-AFFC.2011.7
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A., RNNLIB TOOLBOX
   Greenwald M. K., 1989, Journal of Psychophysiology, V3, P51
   Grimm M, 2007, SPEECH COMMUN, V49, P787, DOI 10.1016/j.specom.2007.01.010
   Gunes H, 2007, J NETW COMPUT APPL, V30, P1334, DOI 10.1016/j.jnca.2006.09.007
   Gunes H, 2009, IEEE T SYST MAN CY B, V39, P64, DOI 10.1109/TSMCB.2008.927269
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Hasegawa-Johnson M., 2010, P INT
   HENLEY NM, 1995, GENDER POWER COMMUNI
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Juslin P.N., 2005, NEW HDB METHODS NONV, P65, DOI [DOI 10.1093/ACPROF:OSO/9780198529620.003.0003, 10.1093/acprof:oso/9780198529620.003.0003]
   Kleinsmith A., 2007, P 2 INT C AFF COMP I
   Kleinsmith A, 2011, IEEE T SYST MAN CY B, V41, P1027, DOI 10.1109/TSMCB.2010.2103557
   Meng HY, 2011, LECT NOTES COMPUT SC, V6974, P225, DOI 10.1007/978-3-642-24600-5_26
   Metallinou A., 2010, P ICASSP
   Metallinou A., 2012, IEEE T AFFE IN PRESS
   Minami Y., 2004, P INT
   Narayanan S., IEEE T PATT IN PRESS
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Robinson P., 2007, P ACII
   RUSSELL JA, 1977, J RES PERS, V11, P273, DOI 10.1016/0092-6566(77)90037-X
   Sanghvi J, 2011, ACMIEEE INT CONF HUM, P305, DOI 10.1145/1957656.1957781
   SCHLOSBERG H, 1954, PSYCHOL REV, V61, P81, DOI 10.1037/h0054570
   Sebe N., 2005, Handbook of Pattern Recognition and Computer Vision
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Toda T, 2008, SPEECH COMMUN, V50, P215, DOI 10.1016/j.specom.2007.09.001
   Toda T, 2007, IEEE T AUDIO SPEECH, V15, P2222, DOI 10.1109/TASL.2007.907344
   Varni G, 2010, IEEE T MULTIMEDIA, V12, P576, DOI 10.1109/TMM.2010.2052592
   Ververidis D, 2006, SPEECH COMMUN, V48, P1162, DOI 10.1016/j.specom.2006.04.003
   Woellmer M., 2008, P INT
   Wöllmer M, 2010, IEEE J-STSP, V4, P867, DOI 10.1109/JSTSP.2010.2057200
   Wu DR, 2010, IEEE INT CON MULTI, P737, DOI 10.1109/ICME.2010.5583101
   Yang YH, 2011, IEEE T AUDIO SPEECH, V19, P762, DOI 10.1109/TASL.2010.2064164
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zlatintsi A., 2011, P ICASSP
NR 52
TC 74
Z9 78
U1 1
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2013
VL 31
IS 2
BP 137
EP 152
DI 10.1016/j.imavis.2012.08.018
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 102KN
UT WOS:000315843600004
DA 2024-07-18
ER

PT J
AU Ni, WY
   Vu, NS
   Caplier, A
AF Ni, Weiyuan
   Ngoc-Son Vu
   Caplier, Alice
TI Lucas-Kanade based entropy congealing for joint face alignment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Entropy Congealing; Lucas-Kanade method; Face alignment; POEM descriptor
ID RECOGNITION; MODELS
AB Entropy Congealing is an unsupervised joint image alignment method, in which the transformation parameters are obtained by minimizing a sum-of-entropy function. Our previous work presented a forward formulation of entropy Congealing to estimate all the transformation parameters at the same time. In this paper, we propose an inverse compositional Lucas-Kanade formulation of entropy Congealing. This yields constant parts in Jacobion and Hessian which can be precomputed to decrease the computational complexity. Moreover, we combine Congealing with POEM descriptor to catch more information about face. Experimental results indicate that the proposed algorithm performs better than other alignment methods, regarding several evaluation criteria on different databases. Concerning the complexity, the proposed algorithm is more efficient than other considered approaches. Also, compared to the forward formulation, the inverse method produces a speed improvement of 20%. 2012 Elsevier B.V. All rights reserved.
C1 [Ni, Weiyuan] Grenoble Univ, ICA Lab, Grenoble, France.
   [Ngoc-Son Vu; Caplier, Alice] Grenoble Univ, Gipsa Lab, Grenoble, France.
C3 Communaute Universite Grenoble Alpes; Universite Grenoble Alpes (UGA);
   Communaute Universite Grenoble Alpes; Institut National Polytechnique de
   Grenoble; Universite Grenoble Alpes (UGA); Centre National de la
   Recherche Scientifique (CNRS)
RP Ni, WY (corresponding author), Grenoble Univ, ICA Lab, Grenoble, France.
EM ni.weiyuan@imag.fr; Ngoc-Son.Vu@gipsa-lab.grenoble-inp.fr;
   alice.caplier@gipsa-lab.inpg.fr
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], EUR C COMP VIS
   Ashraf A., 2010, IEEE C COMP VIS PATT
   Asthana A, 2011, PATTERN RECOGN, V44, P2598, DOI 10.1016/j.patcog.2011.03.014
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cox M., 2008, IEEE C COMP VIS PATT
   Cox M, 2009, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2009.5459430
   Dowson N, 2008, IEEE T PATTERN ANAL, V30, P180, DOI 10.1109/TPAMI.2007.70757
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Huang G., 2007, 11 IEEE INT C COMP V
   Jiao F., 2003, P IEEE C COMP VIS PA
   Jones M., 2003, Mitsubishi Electric Research Lab TR-20003-96, V3, P2
   Learned-Miller EG, 2006, IEEE T PATTERN ANAL, V28, P236, DOI 10.1109/TPAMI.2006.34
   Lemieux A., 2002, P 16 INT C PATT REC
   Levi K, 2004, PROC CVPR IEEE, P53
   Liu X., 2009, 12 IEEE INT C COMP V
   Liu X., 2010, EUR C COMP VIS
   Liu X., 2007, IEEE C COMP VIS PATT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Markus Storer H.B., 2010, INT C PATT REC
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Miller Erik G, 2000, P IEEE C COMP VIS PA
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ni W., 2011, INT C IM PROC
   Ni WY, 2011, LECT NOTES COMPUT SC, V6855, P57, DOI 10.1007/978-3-642-23678-5_5
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rentzeperis E., 2006, P 3 IFIP C ART INT A
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Shan S., 2004, P 6 IEEE INT C AUT F
   Tong Y., 2009, IEEE C COMP VIS PATT
   Tzimiropoulos G., 2011, INT C COMP VIS BARC
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Wang P., 2005, COMP VIS PATT REC WO
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhang C., 2010, Microsoft Research
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zhao C., 2011, IEEE C COMP VIS PATT
NR 44
TC 5
Z9 5
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 954
EP 965
DI 10.1016/j.imavis.2012.08.016
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800004
DA 2024-07-18
ER

PT J
AU Bastanlar, Y
   Temizel, A
   Yardimci, Y
   Sturm, P
AF Bastanlar, Y.
   Temizel, A.
   Yardimci, Y.
   Sturm, P.
TI Multi-view structure-from-motion for hybrid camera scenarios
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Omnidirectional cameras; Hybrid camera systems; Feature matching;
   Epipolar geometry; Multi-view; Structure-from-motion
AB We describe a pipeline for structure-from-motion (SfM) with mixed camera types, namely omnidirectional and perspective cameras. For the steps of this pipeline, we propose new approaches or adapt the existing perspective camera methods to make the pipeline effective and automatic. We model our cameras of different types with the sphere camera model. To match feature points, we describe a preprocessing algorithm which significantly increases scale invariant feature transform (SIFT) matching performance for hybrid image pairs. With this approach, automatic point matching between omnidirectional and perspective images is achieved. We robustly estimate the hybrid fundamental matrix with the obtained point correspondences. We introduce the normalization matrices for lifted coordinates so that normalization and denormalization can be performed linearly for omnidirectional images. We evaluate the alternatives of estimating camera poses in hybrid pairs. A weighting strategy is proposed for iterative linear triangulation which improves the structure estimation accuracy. Following the addition of multiple perspective and omnidirectional images to the structure, we perform sparse bundle adjustment on the estimated structure by adapting it to use the sphere camera model. Demonstrations of the end-to-end multi-view SfM pipeline with the real images of mixed camera types are presented. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Bastanlar, Y.; Temizel, A.; Yardimci, Y.] Middle E Tech Univ, Inst Informat, TR-06531 Ankara, Turkey.
   [Sturm, P.] INRIA Rhone Alpes, Grenoble, France.
   [Sturm, P.] Lab Jean Kuntzmann, Grenoble, France.
C3 Middle East Technical University; Communaute Universite Grenoble Alpes;
   Institut National Polytechnique de Grenoble; Universite Grenoble Alpes
   (UGA); Centre National de la Recherche Scientifique (CNRS); Inria
RP Bastanlar, Y (corresponding author), Izmir Inst Technol, Comp Eng Dept, Izmir, Turkey.
EM yalinbastanlar@iyte.edu.tr; atemizel@ii.metu.edu.tr;
   yardimy@ii.metu.edu.tr; peter.sturm@inrialpes.fr
RI Temizel, Alptekin/D-1315-2010; Bastanlar, Yalin/AAA-7114-2022
OI Temizel, Alptekin/0000-0001-6082-2573; Bastanlar,
   Yalin/0000-0002-3774-6872
CR Adorni G., 2003, P WORKSH OMN VIS OMN
   Alhwarin F., 2008, VISIONS COMPUTER SCI
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], P INT C PATT REC ICP
   Barreto J., 2004, P WORKSH OMN VIS
   Barreto J.P., 2006, IEEE C COMPUTER VISI, P1258
   Bartoli A, 2004, IEEE T PATTERN ANAL, V26, P426, DOI 10.1109/TPAMI.2004.1262342
   Bastanlar Y, 2010, ELECTRON LETT, V46, P346, DOI 10.1049/el.2010.2548
   Bastanlar Y., 2010, P INT C PATT REC ICP
   Bastanlar Y., 2008, P WORKSH OMN VIS
   Bastanlar Y., 2009, THESIS
   Beardsley PA, 1997, INT J COMPUT VISION, V23, P235, DOI 10.1023/A:1007923216416
   Cauchois C., 1999, P INT C ROB AUT ICRA
   Chang P., 2000, P IEEE WORKSH OMN VI
   Chen D., 2005, WORKSH APPL COMP VIS
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fleck S., 2005, P INT C ROB AUT ICRA
   Geyer C, 2002, IEEE T PATTERN ANAL, V24, P687, DOI 10.1109/34.1000241
   Geyer C, 2000, Proc. European Conf. Computer Vision, P445, DOI [10.1007/3-540-45053-X_29, DOI 10.1007/3-540-45053-X_29]
   Goedemé T, 2007, INT J COMPUT VISION, V74, P219, DOI 10.1007/s11263-006-0025-9
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820
   Lhuillier M., 2007, IEEE C COMP VIS PATT
   Lourakis M., 2004, TR340 4 ICS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mei C, 2007, IEEE INT CONF ROBOT, P3945, DOI 10.1109/ROBOT.2007.364084
   Orghidan R., 2003, P WORKSH OMN VIS OMN
   PERI VN, 1997, P DARPA IM UND WORKS
   Puig L, 2008, P WORKSH OMN VIS OMN
   Ramalingam S., 2004, P IEEE WORKSH OMN VI
   Scaramuzza D, 2006, P INT C INT ROB SYST
   Scotti G, 2005, IEE P-VIS IMAGE SIGN, V152, P250, DOI 10.1049/ip-vis:20041302
   Sturm P, 2002, THIRD WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P37, DOI 10.1109/OMNVIS.2002.1044489
   Sturm P., 2008, P EUR C COMP VIS ECC
   Tardif J., 2006, P EUR C COMP VIS ECC
   Yamazawa K., 2003, LECT NOTES COMPUT SC, V2749, P159
   Yi Z, 2008, ELECTRON LETT, V44, P107, DOI 10.1049/el:20082477
   Ying XG, 2004, LECT NOTES COMPUT SC, V3021, P442
NR 40
TC 15
Z9 19
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 557
EP 572
DI 10.1016/j.imavis.2012.06.001
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100016
DA 2024-07-18
ER

PT J
AU Mittal, S
   Meer, P
AF Mittal, Sushil
   Meer, Peter
TI Conjugate gradient on Grassmann manifolds for robust subspace estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Grassmann manifolds; Conjugate gradient algorithm; Generalized
   projection based M-estimator
ID MOTION ESTIMATION; VISUAL TRACKING; MEAN SHIFT; ALGORITHMS; FRAMEWORK
AB Most geometric computer vision problems involve orthogonality constraints. An important subclass of these problems is subspace estimation, which can be equivalently formulated into an optimization problem on Grassmann manifolds. In this paper, we propose to use the conjugate gradient algorithm on Grassmann manifolds for robust subspace estimation in conjunction with the recently introduced generalized projection based M-Estimator (gpbM). The gpbM method is an elemental subset-based robust estimation algorithm that can process heteroscedastic data without any user intervention. We show that by optimizing the orthogonal parameter matrix on Grassmann manifolds, the performance of the gpbM algorithm improves significantly. Results on synthetic and real data are presented. (c) 2011 Elsevier B.V. All rights reserved.
C1 [Mittal, Sushil; Meer, Peter] Rutgers State Univ, ECE Dept, Piscataway, NJ 08854 USA.
C3 Rutgers University System; Rutgers University New Brunswick
RP Mittal, S (corresponding author), Rutgers State Univ, ECE Dept, Piscataway, NJ 08854 USA.
EM smittal@caip.rutgers.edu; meer@jove.rutgers.edu
CR [Anonymous], 1992, SMR
   [Anonymous], 1994, INTRO CONJUGATE GRAD
   [Anonymous], 2003, Statistics on Special Manifolds
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Çetingül HE, 2009, PROC CVPR IEEE, P1896, DOI 10.1109/CVPRW.2009.5206806
   Chaudhry R, 2010, LECT NOTES COMPUT SC, V6312, P735, DOI 10.1007/978-3-642-15552-9_53
   Edelman A, 1998, SIAM J MATRIX ANAL A, V20, P303, DOI 10.1137/S0895479895290954
   Fan ZM, 2006, IEEE T PATTERN ANAL, V28, P91, DOI 10.1109/TPAMI.2006.16
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fletcher PT, 2003, PROC CVPR IEEE, P95
   Gallivan KA, 2003, PROCEEDINGS OF THE 2003 IEEE WORKSHOP ON STATISTICAL SIGNAL PROCESSING, P315
   Govindu VM, 2004, PROC CVPR IEEE, P684
   Hartley R, 2009, INT J COMPUT VISION, V83, P274, DOI 10.1007/s11263-009-0225-1
   Helmke U, 2007, INT J COMPUT VISION, V74, P117, DOI 10.1007/s11263-006-0005-0
   KARCHER H, 1977, COMMUN PUR APPL MATH, V30, P509, DOI 10.1002/cpa.3160300502
   Li M, 2010, PROC CVPR IEEE, P1315, DOI 10.1109/CVPR.2010.5539815
   Li X, 2008, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2008.4587516
   Lin D., 2006, P C COMPUTER VISION, P1727
   Lin DH, 2009, PROC CVPR IEEE, P747, DOI 10.1109/CVPRW.2009.5206660
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Ma Y, 2001, INT J COMPUT VISION, V44, P219, DOI 10.1023/A:1012276232049
   Matei BC, 2006, IEEE T PATTERN ANAL, V28, P1537, DOI 10.1109/TPAMI.2006.205
   Mittal S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2689, DOI 10.1109/CVPR.2011.5995514
   Moakher M, 2002, SIAM J MATRIX ANAL A, V24, P1, DOI 10.1137/S0895479801383877
   ONeill B., 1983, Semi-Riemannian Geometry Geometry, With Applications to Relativity
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Ruszczynski A., 2006, Nonlinear optimization
   Soatto S, 1996, IEEE T AUTOMAT CONTR, V41, P393, DOI 10.1109/9.486640
   Soatto S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P428, DOI 10.1109/CVPR.1993.341095
   Srivastava A, 2004, ADV APPL PROBAB, V36, P43, DOI 10.1239/aap/1077134463
   Subbarao R., 2008, P IEEE C COMP VIS PA
   Subbarao R, 2006, LECT NOTES COMPUT SC, V3951, P301
   Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8
   Tosato D, 2010, LECT NOTES COMPUT SC, V6312, P378, DOI 10.1007/978-3-642-15552-9_28
   Turaga P., 2011, IEEE T PATT IN PRESS
   Tuzel O, 2005, IEEE I CONF COMP VIS, P18
   Tuzel O., 2008, P IEEE C COMP VIS PA
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94
NR 41
TC 17
Z9 17
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2012
VL 30
IS 6-7
SI SI
BP 417
EP 427
DI 10.1016/j.imavis.2011.09.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 977BA
UT WOS:000306630100005
DA 2024-07-18
ER

PT J
AU Younes, L
AF Younes, Laurent
TI Spaces and manifolds of shapes in computer vision: An overview
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape spaces; Shape manifolds; Shape metrics
ID GEOMETRIC ACTIVE CONTOURS; SKELETAL STRUCTURES; BOUNDARIES; METRICS;
   SEGMENTATION; RECOGNITION; GEODESICS; DISTANCE; MODELS; IMAGES
AB We provide an overview of several shape space models that have been proposed in the past few years, focusing, in particular on models involving Riemannian manifolds of shapes. The discussion is organized in three stages, starting with a review of some shape representation methods, followed by shape space structures, from metric spaces to manifolds, and concluding with a short description of some of the applications that resulted from such models. (c) 2011 Elsevier B.V. All rights reserved.
C1 [Younes, Laurent] Johns Hopkins Univ, Dept Appl Math & Stat, Baltimore, MD 21218 USA.
C3 Johns Hopkins University
RP Younes, L (corresponding author), 3400 N Charles St, Baltimore, MD 21218 USA.
EM Laurent.younes@jhu.edu
RI Younes, E. Laurent/A-3349-2010
OI Younes, Laurent/0000-0003-2017-9565
FU NSF; ONR
FX Partially supported by NSF and ONR.
CR [Anonymous], J GEOM MECH IN PRESS
   [Anonymous], 2007, Pattern theory: from representation to inference
   [Anonymous], ICIP 2005
   [Anonymous], ECCV 2002
   [Anonymous], 1991, Hands: A Pattern Theoretic Study of Biological Shapes
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2007, EUR S POINT BAS GRAP
   [Anonymous], THESIS BROWN U
   [Anonymous], THESIS BROWN U
   [Anonymous], 1998, STAT SHAPE ANAL
   [Anonymous], MATH0510192 ARXIV
   [Anonymous], LEVEL SET BASED SEGM
   [Anonymous], CVPR 2003
   [Anonymous], CVPR 2004
   [Anonymous], 2010, Shapes and diffeomorphisms
   [Anonymous], MATH METH BIOM IM AN
   [Anonymous], ICCV 2009 WORKSH
   [Anonymous], CVPR 2003
   [Anonymous], INT J COMPUT VIS
   [Anonymous], AC SPEECH SIGN PROC
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], 1996, Elements of pattern theory
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IMAGE VIS COMPUT
   [Anonymous], 2010, PATTERN THEORY STOCH
   [Anonymous], INT J COMPUT VIS
   [Anonymous], ECCV 2004
   [Anonymous], ARXIV100338952010
   [Anonymous], GROWTH FORM
   [Anonymous], SPIE
   [Anonymous], SHAPE SHAPE THEORY
   [Anonymous], CVPR 2004
   [Anonymous], COMP VISIONECCV 2002
   [Anonymous], ISBI 2002
   [Anonymous], 1993, General pattern theory
   Arrate F, 2010, SIAM J IMAGING SCI, V3, P176, DOI 10.1137/090766401
   Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1
   Beg MF, 2005, INT J COMPUT VISION, V61, P139, DOI 10.1023/B:VISI.0000043755.93987.aa
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Ben Hamza A, 2006, IEEE T IMAGE PROCESS, V15, P2249, DOI 10.1109/TIP.2006.875250
   Ben Hamza A, 2003, LECT NOTES COMPUT SC, V2886, P378
   Bookstein F L, 1997, Med Image Anal, V1, P225
   Bookstein F.L, 1991, MORPHOMETRIC TOOLS L, DOI [10.1017/CBO9780511573064, DOI 10.1017/CBO9780511573064]
   Bookstein F.L., 1978, MEASUREMENT BIOL SHA
   Bookstein FL, 1997, COMPUT VIS IMAGE UND, V66, P97, DOI 10.1006/cviu.1997.0607
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Bronstein AM, 2008, MONOGR COMPUT SCI, P1, DOI 10.1007/978-0-387-73301-2_1
   Bronstein AM, 2010, INT J COMPUT VISION, V89, P266, DOI 10.1007/s11263-009-0301-6
   Bruckstein AM, 1997, IMAGE VISION COMPUT, V15, P335, DOI 10.1016/S0262-8856(96)01140-7
   Camion V, 2001, LECT NOTES COMPUT SC, V2134, P513
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Charpiat G, 2005, FOUND COMPUT MATH, V5, P1, DOI 10.1007/s10208-003-0094-x
   Chazal F, 2009, COMPUT GRAPH FORUM, V28, P1393, DOI 10.1111/j.1467-8659.2009.01516.x
   Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985
   Chen YM, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P145, DOI 10.1109/VLSM.2001.938893
   Chung MK, 2009, LECT NOTES COMPUT SC, V5636, P386, DOI 10.1007/978-3-642-02498-6_32
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Cootes T. F., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P173
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5
   Damon J, 2005, INT J COMPUT VISION, V63, P45, DOI 10.1007/s11263-005-4946-5
   Damon J, 2004, COMPOS MATH, V140, P1657, DOI 10.1112/S0010437X04000570
   Damon J, 2003, ANN I FOURIER, V53, P1941, DOI 10.5802/aif.1997
   Davis B., 2007, ICCV 2007, P1
   Dupuis P, 1998, Q APPL MATH, V56, P587, DOI 10.1090/qam/1632326
   Duta N, 1998, IEEE T MED IMAGING, V17, P1049, DOI 10.1109/42.746716
   Edelsbrunner H, 2008, CONTEMP MATH, V453, P257
   Elad A, 2003, IEEE T PATTERN ANAL, V25, P1285, DOI 10.1109/TPAMI.2003.1233902
   Fletcher PT, 2008, PROC CVPR IEEE, P3153
   Fletcher PT, 2003, LECT NOTES COMPUT SC, V2732, P450
   Fletcher PT, 2004, IEEE T MED IMAGING, V23, P995, DOI 10.1109/TMI.2004.831793
   Garcin L, 2006, J MATH IMAGING VIS, V25, P329, DOI 10.1007/s10851-006-6729-1
   Giblin PJ, 2003, INT J COMPUT VISION, V54, P143, DOI 10.1023/A:1023761518825
   Glaunes J, 2004, PROC CVPR IEEE, P712
   GRENANDER U, 1993, SIAM J APPL MATH, V53, P1072, DOI 10.1137/0153054
   Holm DD, 2009, Q APPL MATH, V67, P661, DOI 10.1090/S0033-569X-09-01134-2
   Huang H, 2005, PROC SPIE, V5747, P1384, DOI 10.1117/12.595954
   Joshi S, 2002, IEEE T MED IMAGING, V21, P538, DOI 10.1109/TMI.2002.1009389
   Joshi SC, 2000, IEEE T IMAGE PROCESS, V9, P1357, DOI 10.1109/83.855431
   Joshi SH, 2007, LECT NOTES COMPUT SC, V4679, P387
   Joshi SH, 2009, INT J COMPUT VISION, V81, P331, DOI 10.1007/s11263-008-0179-8
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kazhdan M., 2003, Symposium on Geometry Processing, P156
   Kendall D. G., 1989, STAT SCI, V4, P87, DOI DOI 10.1214/SS/1177012582
   KENDALL DG, 1984, B LOND MATH SOC, V16, P81, DOI 10.1112/blms/16.2.81
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   Klassen E, 2004, IEEE T PATTERN ANAL, V26, P372, DOI 10.1109/TPAMI.2004.1262333
   Kume A, 2007, BIOMETRIKA, V94, P513, DOI 10.1093/biomet/asm047
   Kurtek S, 2011, IEEE T MED IMAGING, V30, P849, DOI 10.1109/TMI.2010.2099130
   Kushnarev S, 2009, EXP MATH, V18, P325, DOI 10.1080/10586458.2009.10129054
   Le H, 2004, LMS J COMPUT MATH, V7, P193, DOI DOI 10.1112/S1461157000001091
   Le HL, 2001, ADV APPL PROBAB, V33, P324, DOI 10.1017/S0001867800010818
   LE HL, 1995, ADV APPL PROBAB, V27, P44, DOI 10.2307/1428094
   LE HL, 1993, ANN STAT, V21, P1225, DOI 10.1214/aos/1176349259
   Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Ling HB, 2005, PROC CVPR IEEE, P719
   Liu XW, 2010, INT J COMPUT VISION, V89, P69, DOI 10.1007/s11263-010-0323-0
   Ma J, 2008, NEUROIMAGE, V42, P252, DOI 10.1016/j.neuroimage.2008.03.056
   Ma J, 2010, INT J BIOMED IMAGING, V2010, DOI 10.1155/2010/974957
   Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208
   Marsland S., 2002, Statistics of Large Datasets, Proceedings of Leeds Annual Statistical Research Workshop, P91
   Marsland S, 2008, IMAGE VISION COMPUT, V26, P333, DOI 10.1016/j.imavis.2006.12.009
   Mémoli F, 2005, FOUND COMPUT MATH, V5, P313, DOI 10.1007/s10208-004-0145-y
   Mémoli F, 2001, J COMPUT PHYS, V173, P730, DOI 10.1006/jcph.2001.6910
   Michor PW, 2007, APPL COMPUT HARMON A, V23, P74, DOI 10.1016/j.acha.2006.07.004
   Michor PW, 2006, J EUR MATH SOC, V8, P1, DOI 10.4171/JEMS/37
   Michor PW, 2005, DOC MATH, V10, P217
   Miller MI, 2006, J MATH IMAGING VIS, V24, P209, DOI 10.1007/s10851-005-3624-0
   Miller MI, 2002, ANNU REV BIOMED ENG, V4, P375, DOI 10.1146/annurev.bioeng.4.092101.125733
   Miller MI, 2001, INT J COMPUT VISION, V41, P61, DOI 10.1023/A:1011161132514
   Mio W, 2007, INT J COMPUT VISION, V73, P307, DOI [10.1007/s11263-006-9968-0, 10.1007/s11263-006-996S-0]
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384
   Moghaddam B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1131, DOI 10.1109/ICCV.1999.790407
   Olver PJ, 2001, FOUND COMPUT MATH, V1, P3, DOI 10.1007/s102080010001
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Rathi Y, 2005, PROC CVPR IEEE, P2
   Rathi Y, 2007, IEEE T PATTERN ANAL, V29, P1470, DOI 10.1109/TPAMI.2007.1081
   Rivlin E., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P697, DOI 10.1109/CVPR.1993.341022
   Rousson M, 2004, LECT NOTES COMPUT SC, V3216, P209
   Sato J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P915, DOI 10.1109/ICPR.1996.546157
   Schmidt FR, 2006, LECT NOTES COMPUT SC, V4174, P142
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sharon E, 2006, INT J COMPUT VISION, V70, P55, DOI 10.1007/s11263-006-6121-z
   Shen L, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P81, DOI 10.1109/CRV.2007.26
   Shen L, 2009, EVOLUTION, V63, P1003, DOI 10.1111/j.1558-5646.2008.00557.x
   SHINAGAWA Y, 1991, IEEE COMPUT GRAPH, V11, P66, DOI 10.1109/38.90568
   Siddiqi K, 2008, COMPUT IMAGING VIS, V37, P1, DOI 10.1007/978-1-4020-8658-8
   Srivastava A., 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   Styner M, 2003, LECT NOTES COMPUT SC, V2879, P464
   Styner M, 2003, MED IMAGE ANAL, V7, P207, DOI 10.1016/S1361-8415(02)00110-X
   Sundaramoorthi G, 2007, INT J COMPUT VISION, V73, P345, DOI 10.1007/s11263-006-0635-2
   Sundaramoorthi G, 2009, IEEE DECIS CONTR P, P2395, DOI 10.1109/CDC.2009.5400786
   Sundaramoorthi Ganesh., 2006, COMPUTER VISION PATT, V1, P674
   Trouvé A, 2005, SIAM J MATH ANAL, V37, P17, DOI 10.1137/S0036141002404838
   Trouvé A, 2005, FOUND COMPUT MATH, V5, P173, DOI 10.1007/s10208-004-0128-z
   Trouvé A, 2000, LECT NOTES COMPUT SC, V1842, P573
   Vaillant M, 2004, NEUROIMAGE, V23, pS161, DOI 10.1016/j.neuroimage.2004.07.023
   van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121
   Veeraraghavan A, 2005, IEEE T PATTERN ANAL, V27, P1896, DOI 10.1109/TPAMI.2005.246
   Wang L, 2007, IEEE T IMAGE PROCESS, V16, P1646, DOI 10.1109/TIP.2007.896661
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Younes L, 1999, IMAGE VISION COMPUT, V17, P381, DOI 10.1016/S0262-8856(98)00125-5
   Younes L, 1998, SIAM J APPL MATH, V58, P565, DOI 10.1137/S0036139995287685
   Younes L, 2008, REND LINCEI-MAT APPL, V19, P25
   Younes L, 2008, J MATH IMAGING VIS, V32, P41, DOI 10.1007/s10851-008-0074-5
   Younes L, 2009, NEUROIMAGE, V45, pS40, DOI 10.1016/j.neuroimage.2008.10.050
   Zhang J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P581, DOI 10.1109/ICIP.1998.999044
   Zhang Q., 2006, Computer Vision and Pattern Recognition, 2006 IEEE Computer Society Conference on, V1, P1092, DOI [10.1109/CVPR.2006.214, DOI 10.1109/CVPR.2006.214]
   Zhang SR, 2008, SIAM J APPL MATH, V68, P806, DOI 10.1137/060664707
   Zomorodian A.J., 2005, Topology for Computing, V1st edn
NR 154
TC 39
Z9 45
U1 1
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2012
VL 30
IS 6-7
SI SI
BP 389
EP 397
DI 10.1016/j.imavis.2011.09.009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 977BA
UT WOS:000306630100003
DA 2024-07-18
ER

PT J
AU Chin, TJ
   Suter, D
   Wang, HZ
AF Chin, Tat-Jun
   Suter, David
   Wang, Hanzi
TI Boosting histograms of descriptor distances for scalable multiclass
   specific scene recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Keypoints; Descriptors; Distance histograms; Specific scene recognition
AB We present an unconventional way of using keypoints in the form of histograms of keypoint descriptor distances. Descriptor distances are often exhaustively computed between sets of keypoints, but besides finding the k-smallest distances the structure of the distribution of these distances has been largely overlooked. We highlight the potential of such information in the task of specific scene recognition. Discriminative scene signatures in the form of histograms of keypoint descriptor distances are constructed in a supervised manner. The distances are computed between properly selected reference keypoints and the keypoints detected in the input image. The signature is low dimensional, computationally cheap to obtain, and can distinguish a large number of scenes. We introduce a scheme based on Multiclass AdaBoost to select the appropriate reference key points. The result is a scalable multiclass specific scene classifier capable of processing a large number of scene classes at a fraction of the time required for methods based on exhaustive keypoint matching. We test the idea on 3 datasets for specific scene recognition and report the obtained results. Crown Copyright (C) 2010 Published by Elsevier BM. All rights reserved.
C1 [Chin, Tat-Jun; Suter, David; Wang, Hanzi] Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
C3 University of Adelaide
RP Chin, TJ (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA 5005, Australia.
EM tjchin@cs.adelaide.edu.au; dsuter@cs.adelaide.edu.au;
   hanzi.wang@ieee.org
RI Wang, Hanzi/F-8796-2012
OI Suter, David/0000-0001-6306-3023
CR Ali H, 2007, 5 INT S MOB MAPP TEC
   AMLACHER K, 2008, GEOINDEXED OBJECT RE
   [Anonymous], BAGS FEATURES SPATIA
   [Anonymous], VISION BASED MOBILE
   Bay H, 2006, SURF SPEEDED ROBUST
   Beis JS, 1997, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.1997.609451
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Boiman Oren., 2008, In defense of nearest-neighbor based image classification. 0:1-8
   CALONDER M, 2008, KEYPOINT SIGNATURES
   CHIN TJ, 2009, KEYPOINT INDUCED DIS
   CHIN TJ, 2008, USING DENSELY RECORD
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   FRITZ G, 2005, URBAN OBJECT RECOGNI
   FRITZ G, 2006, MOBILE VISION SYSTEM
   Grauman K., 2005, The pyramid match kernel: Discriminative classification with sets of image features
   KE Y, 2000, PCA SIFT MORE DISTIN
   KHAN S, 2006, WAS PICTURE TAKEN IM
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   LI T, 2003, USING DISCRIMINANT A
   Ling H., 2007, PROXIMITY DISTRIBUTI
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MAREE R, 2005, RANDOM SUBWINDOWS RO
   NI K, 2008, EPITOMIC LOCATION RE
   Opelt A, 2006, IEEE T PATTERN ANAL, V28, P416, DOI 10.1109/TPAMI.2006.54
   OZUYSAL M, 2007, FAST KEYPOINT RECOGN
   Philbin J., 2008, Lost in quantization: Improving particular object retrieval in large scale image databases
   Philbin J., 2007, OBJECT RETRIEVAL LAR
   Pronobis A., 2006, DISCRIMINATIVE APPRO
   Quelhas P, 2007, IEEE T PATTERN ANAL, V29, P1575, DOI 10.1109/TPAMI.2007.1155
   Russell B., 2007, OBJECT RECOGNITION S
   SCHINDLER G, 2008, DETECTING MATCHING R
   SHAKHNAROVOCH G, 2006, NEAREST NEIGHBOR MET
   SHAO H, 2003, FAST INDEXING IMAGE
   SILPAANAN C, 2008, OPTIMISED KD TREES F
   Sivic J., 2003, Video google: a text retrieval approach to object matching in videos
   Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951
   Wu J, 2008, AM I PLACE INSTANCE
   XIAO J, 2003, 2 FRAME WIDE BASELIN
   YANG L, 2008, UNIFYING DISCRIMINAT
   Zhu Ji., 2005, MULTICLASS ADABOOST
   Zivkovic Z, 2007, ROBOT AUTON SYST, V55, P411, DOI 10.1016/j.robot.2006.12.005
NR 42
TC 6
Z9 6
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2011
VL 29
IS 4
BP 241
EP 250
DI 10.1016/j.imavis.2010.11.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 727UR
UT WOS:000287828800004
DA 2024-07-18
ER

PT J
AU Wang, JZ
   Zhang, BX
   Qi, MA
   Kong, J
AF Wang, Jianzhong
   Zhang, Baoxue
   Qi, Miao
   Kong, Jun
TI Linear discriminant projection embedding based on patches alignment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dimensionality reduction; Manifold learning; Patches alignment; Face
   recognition; Maximum margin criterion
ID NONLINEAR DIMENSIONALITY REDUCTION; FACE; VISUALIZATION; RECOGNITION;
   EFFICIENT
AB Dimensionality reduction is often required as a preliminary stage in many data analysis applications. In this paper, we propose a novel supervised dimensionality reduction method, called linear discriminant projection embedding (LOPE), for pattern recognition. LOPE first chooses a set of overlapping patches which cover all data points using a minimum set cover algorithm with geodesic distance constraint. Then, principal component analysis (PCA) is applied on each patch to obtain the data's local representations. Finally, patches alignment technique combined with modified maximum margin criterion (MMC) is used to yield the discriminant global embedding. LOPE takes both label information and structure of manifold into account, thus it can maximize the dissimilarities between different classes and preserve data's intrinsic structures simultaneously. The efficiency of the proposed algorithm is demonstrated by extensive experiments using three standard face databases (ORL, YALE and CMU PIE). Experimental results show that LOPE outperforms other classical and state of art algorithms. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Zhang, Baoxue; Qi, Miao; Kong, Jun] NE Normal Univ, Key Lab Appl Stat, MOE, Changchun, Peoples R China.
   [Wang, Jianzhong; Qi, Miao; Kong, Jun] NE Normal Univ, Sch Comp Sci & Informat Technol, Changchun, Peoples R China.
   [Wang, Jianzhong; Zhang, Baoxue] NE Normal Univ, Sch Math & Stat, Changchun, Peoples R China.
C3 Northeast Normal University - China; Northeast Normal University -
   China; Northeast Normal University - China
RP Zhang, BX (corresponding author), NE Normal Univ, Key Lab Appl Stat, MOE, Changchun, Peoples R China.
EM bxzhang@nenu.edu.cn; kongjun@nenu.edu.cn
RI Zhang, Bao/B-3926-2012
FU NENU [NENU-STC07018]; Jilin Provincial Science & Technology Department
   [20070322]; MOE [109052]; National Natural Science Foundation of China
   [10871037]; Program for New Century Excellent Talents in University
   [NCET-09-0284]
FX The authors would like to thank the Associate Editor and anonymous
   reviewers for their valuable advices. This work was supported by the
   Training Fund of NENU'S Scientific Innovation Project (No.
   NENU-STC07018), the Fund of Jilin Provincial Science & Technology
   Department (No. 20070322), Key Project of MOE (No. 109052), the National
   Natural Science Foundation of China (No. 10871037) and Program for New
   Century Excellent Talents in University (NCET-09-0284).
CR [Anonymous], 2008, P IEEE INT C COMPUTE, DOI DOI 10.1109/CVPR.2008.4587719
   [Anonymous], OL OR RES LAB FAC DA
   [Anonymous], YAL U FAC DAT
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bengio Y, 2004, ADV NEUR IN, V16, P177
   Chin TJ, 2008, IEEE T PATTERN ANAL, V30, P1547, DOI 10.1109/TPAMI.2007.70813
   DERIDDER D, 2004, LOCAL FISHER EMBEDDI
   Geng X, 2005, IEEE T SYST MAN CY B, V35, P1098, DOI 10.1109/TSMCB.2005.850151
   Hamsici OC, 2008, IEEE T PATTERN ANAL, V30, P647, DOI 10.1109/TPAMI.2007.70717
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Kokiopoulou E., 2005, IEEE Int. Conf. on Data Mining, P1
   Li B, 2008, PATTERN RECOGN, V41, P3813, DOI 10.1016/j.patcog.2008.05.027
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Lin T, 2008, IEEE T PATTERN ANAL, V30, P796, DOI 10.1109/TPAMI.2007.70735
   Liu J, 2008, PATTERN RECOGN, V41, P102, DOI 10.1016/j.patcog.2007.06.001
   Meng DY, 2008, PATTERN RECOGN LETT, V29, P862, DOI 10.1016/j.patrec.2008.01.005
   Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sim T., 2002, P IEEE INT C AUT FAC
   Sun TK, 2007, IMAGE VISION COMPUT, V25, P531, DOI 10.1016/j.imavis.2006.04.014
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Xu D, 2009, IEEE T PATTERN ANAL, V31, P1913, DOI 10.1109/TPAMI.2009.51
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2007, IEEE T PATTERN ANAL, V29, P650, DOI 10.1109/TPAMI.2007.1008
   Yang L, 2006, IEEE T PATTERN ANAL, V28, P827, DOI 10.1109/TPAMI.2006.89
   Yang L, 2008, IEEE T PATTERN ANAL, V30, P438, DOI 10.1109/TPAMI.2007.70706
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172
NR 29
TC 9
Z9 11
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1624
EP 1636
DI 10.1016/j.imavis.2010.05.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300005
DA 2024-07-18
ER

PT J
AU Kiranyaz, S
   Birinci, M
   Gabbouj, M
AF Kiranyaz, Serkan
   Birinci, Murat
   Gabbouj, Moncef
TI Perceptual color descriptor based on spatial distribution: A top-down
   approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Perceptual color descriptor; Human visual system; Content-based image
   indexing and retrieval; Spatial color distribution
ID IMAGE RETRIEVAL
AB Color features are the key-elements widely used in content-analysis and retrieval. However, most of them show severe limitations and drawbacks due to their inefficiency of modeling the human visual system with respect to color perception. Moreover, they cannot characterize all the properties of the color composition in a visual scenery. In this paper we present a perceptual color feature, which describes all major properties of prominent colors both in spatial and color domains. In accordance with the well-known Gestalt law, we adopt a global, top-down approach in order to model (see) the whole color composition before its parts and in this way we can avoid the problems of pixel-based approaches. In color domain the dominant colors are extracted along with their global properties and quad-tree decomposition partitions the image so as to characterize the spatial color distribution (SCD). We propose two efficient SCD descriptors; the proximity histograms, which distill the histogram of inter-color distances and the proximity grids, which cumulate the spatial co-occurrence of colors in a 2D grid. Both approaches are configurable and provide means of modeling SCD in a scalar and directional way. Combination of the extracted global and spatial properties forms the final descriptor, which is unbiased and robust to non-perceivable color elements in both spatial and color domains. Finally a penalty-trio model fuses all color properties in a similarity distance computation during retrieval. Experimental results approve the superiority of the proposed technique against powerful global and spatial color descriptors. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Kiranyaz, Serkan; Birinci, Murat; Gabbouj, Moncef] Tampere Univ Technol, Dept Signal Proc, FIN-33101 Tampere, Finland.
C3 Tampere University
RP Kiranyaz, S (corresponding author), Tampere Univ Technol, Dept Signal Proc, POB 553, FIN-33101 Tampere, Finland.
EM serkan.kiranyaz@tut.fi
RI Gabbouj, Moncef/G-4293-2014; Kiranyaz, Serkan/AAK-1416-2021
OI Gabbouj, Moncef/0000-0002-9788-2323; kiranyaz,
   serkan/0000-0003-1551-3397
FU Academy of Finland [213462]
FX This work was supported by the Academy of Finland, Project No. 213462
   (Finnish Centre of Excellence Program (2006-2011).
CR [Anonymous], MULTIMED TOOLS APPL
   BRANDENBURG KH, 1999, AES 17 INT C FLOR IT, P17
   CHANG SF, 1997, P ACM MULT SEATTL
   Chun YD, 2008, IEEE T MULTIMEDIA, V10, P1073, DOI 10.1109/TMM.2008.2001357
   Cox I. J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P361, DOI 10.1109/ICPR.1996.546971
   Deng Y., 1999, P IEEE INT S CIRC SY, V4, P21, DOI DOI 10.1109/ISCAS.1999.779933
   FAUQUEUR J, 2002, P IEEE INT C IM PROC
   Gong YH, 1996, MULTIMED TOOLS APPL, V2, P133, DOI 10.1007/BF00672252
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Kato T., 1991, Journal of Information Processing, V14, P134
   Kunttu I, 2003, Digital Media: Processing Multimedia Interactive Services, P88, DOI 10.1142/9789812704337_0016
   Lee HY, 2003, IEEE T MULTIMEDIA, V5, P358, DOI 10.1109/TMM.2003.814792
   LEE SJ, 2008, 23 INT TECHN C CIRC, P1613
   Li JG, 2008, PROC CVPR IEEE, P3863, DOI 10.1109/CVPR.2008.4587839
   Luo JB, 2006, IEEE T IMAGE PROCESS, V15, P1443, DOI 10.1109/TIP.2006.871081
   Ma WY, 1998, CONF REC ASILOMAR C, P253, DOI 10.1109/ACSSC.1998.750865
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Moghaddam HA, 2006, INT C PATT RECOG, P925
   Mojsilovic A, 2000, IEEE T IMAGE PROCESS, V9, P38, DOI 10.1109/83.817597
   Mojsilovic A, 2002, IEEE T IMAGE PROCESS, V11, P1238, DOI 10.1109/TIP.2002.804260
   NAGASAKA A, 1992, IFIP TRANS A, V7, P113
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Ojala T., 2001, Proceedings of 12th Scandinavian Conference on Image Analysis, P621
   Ooi BC, 1998, VLDB J, V7, P115, DOI 10.1007/s007780050057
   Partio M., 2002, P 5 NORD SIGN PROC S, P1
   PARTIO M, 2007, P EURASIP J IMAGE VI, P15
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   PENTLAND A, 1994, P SOC PHOTO-OPT INS, V2185, P34, DOI 10.1117/12.171786
   Po LM, 2004, IEEE IMAGE PROC, P1533
   ROGOWITZ B, 1997, P SOC PHOTO-OPT INS, V3299, P576
   Sclaroff S, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P2
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Smith J. R., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P528, DOI 10.1109/ICIP.1995.537688
   STRICKER M, 1995, P SOC PHOTO-OPT INS, V2410, P381, DOI 10.1117/12.205308
   SUDHAMANI MV, 2007, INT J APPL MATH COMP, V4, P150
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tran LV, 2005, SIGNAL PROCESS, V85, P233, DOI 10.1016/j.sigpro.2004.10.001
   Utenpattanant A, 2007, 9TH INTERNATIONAL CONFERENCE ON ADVANCED COMMUNICATION TECHNOLOGY: TOWARD NETWORK INNOVATION BEYOND EVOLUTION, VOLS 1-3, P1123, DOI 10.1109/ICACT.2007.358555
   VALOVA I, 2004, EUR C ADV DAT INF SY
   van den Broek EL, 2004, PROC SPIE, V5292, P351, DOI 10.1117/12.526927
   VANDESANDE K, 2008, IEEE C COMP VIS PATT, P1
   Wang SR, 2003, CISST'03: PROCEEDING OF THE INTERNATIONAL CONFERENCE ON IMAGING SCIENCE, SYSTEMS AND TECHNOLOGY, VOLS 1 AND 2, P107
   Wertheimer M., 1938, SOURCE BOOK GESTALT, DOI [10.1037/11496-0053, DOI 10.1037/11496-0053, DOI 10.1037/11496-005]
   Wong KM, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P611
NR 47
TC 19
Z9 19
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1309
EP 1326
DI 10.1016/j.imavis.2010.01.012
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400013
DA 2024-07-18
ER

PT J
AU Binczak, S
   Sliwa, T
   Jacquir, S
   Bilbault, JM
AF Binczak, S.
   Sliwa, T.
   Jacquir, S.
   Bilbault, J. M.
TI Reaction-diffusion network for geometric multiscale high speed image
   processing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image analysis; Multiscale geometry; Nonlinear signal processing
ID NONLINEAR ELECTRICAL LATTICE; GEODESIC ACTIVE CONTOURS; PROPAGATION;
   IMPLEMENTATION; FAILURE; SYSTEMS; RETINA
AB In the framework of heavy mid-level processing for high speed imaging, a nonlinear bi-dimensional network is proposed, allowing the implementation of active curve algorithms. Usually this efficient type of algorithm is prohibitive for real-time image processing due to its calculus charge and the inadequate structure for the use of serial or parallel architectures. Another kind of implementation philosophy is proposed here, by considering the active curve generated by a propagation phenomenon inspired from biological modeling. A programmable nonlinear reaction-diffusion system is proposed under front control and technological constraints. Geometric multiscale processing is presented and this opens a discussion about electronic implementation. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Binczak, S.; Jacquir, S.; Bilbault, J. M.] Univ Bourgogne, LE2I, CNRS, UMR 5158, F-21078 Dijon, France.
   [Sliwa, T.] Univ Bourgogne, LE2I, CNRS, UMR 5158, F-89010 Auxerre, France.
C3 Universite de Bourgogne; Centre National de la Recherche Scientifique
   (CNRS); Centre National de la Recherche Scientifique (CNRS); Universite
   de Bourgogne
RP Binczak, S (corresponding author), Univ Bourgogne, LE2I, CNRS, UMR 5158, BP 47870, F-21078 Dijon, France.
EM stbinc@u-bourgogne.fr
RI BILBAULT, Jean-Marie/R-1304-2017; Bilbault, Jean-Marie/KFS-1462-2024
OI Jacquir, Sabir/0000-0002-6296-7888
CR [Anonymous], 2005, Encyclopedia of Nonlinear Science
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   Aubreton O, 2004, J ELECTRON IMAGING, V13, P559, DOI 10.1117/1.1762886
   Barbaro M, 2002, IEEE J SOLID-ST CIRC, V37, P160, DOI 10.1109/4.982422
   Binczak S, 2004, INT J BIFURCAT CHAOS, V14, P1819, DOI 10.1142/S0218127404010187
   Binczak S, 2003, INT J BIFURCAT CHAOS, V13, P483, DOI 10.1142/S0218127403006686
   CHUA LO, 1988, IEEE T CIRCUITS SYST, V35, P1257, DOI 10.1109/31.7600
   Cosp J, 2006, ELECTRON LETT, V42, P1221, DOI 10.1049/el:20062110
   ERNEUX T, 1993, PHYSICA D, V67, P237, DOI 10.1016/0167-2789(93)90208-I
   Fast VG, 1997, CARDIOVASC RES, V33, P258, DOI 10.1016/S0008-6363(96)00216-7
   GILBERT B, 1968, IEEE J SOLID-ST CIRC, VSC 3, P365, DOI 10.1109/JSSC.1968.1049925
   Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533
   JACQUIR S, 2007, INT J BIFURCAT CHAOS, V17, P1
   Keener J.P., 1998, Mathematical Physiology, Interdisciplinary Applied Mathematics
   KEENER JP, 1987, SIAM J APPL MATH, V47, P556, DOI 10.1137/0147038
   KYUMA K, 1994, NATURE, V372, P197, DOI 10.1038/372197a0
   Neu JC, 1997, PHYSICA D, V102, P285, DOI 10.1016/S0167-2789(96)00203-5
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Sánchez-Sinencio E, 2000, IEE P-CIRC DEV SYST, V147, P3, DOI 10.1049/ip-cds:20000055
   Scott A., 1970, Active and nonlinear wave propagation in electronics
   Scott A., 2002, NEUROSCIENCE MATH PR
   Serra J., 1988, IMAGE ANAL MATH MORP
   Zarandy A, 1998, IEEE T CIRCUITS-I, V45, P163, DOI 10.1109/81.661683
NR 23
TC 4
Z9 4
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 914
EP 926
DI 10.1016/j.imavis.2009.11.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gholipour, A
   Kehtarnavaz, N
   Yousefi, S
   Gopinath, K
   Briggs, R
AF Gholipour, Ali
   Kehtarnavaz, Nasser
   Yousefi, Siamak
   Gopinath, Kaundinya
   Briggs, Richard
TI Symmetric deformable image registration via optimization of information
   theoretic measures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Information theoretic measures; Deformable image registration; Mutual
   information
ID MUTUAL-INFORMATION; NONRIGID REGISTRATION; DISTORTION CORRECTION;
   GEOMETRIC DISTORTION; SIMILARITY MEASURES; ENTROPY; MAXIMIZATION;
   ALGORITHM; ALIGNMENT; PROTOCOL
AB The use of information theoretic measures (ITMs) has been steadily growing in image processing, bioinformatics, and pattern classification. Although the ITMs have been extensively used in rigid and affine registration of multi-modal images, their computation and accuracy are critical issues in deformable image registration. Three important aspects of using ITMs in multi-modal deformable image registration are considered in this paper: computation, inverse consistency, and accuracy; a symmetric formulation of the deformable image registration problem through the computation of derivatives and resampling on both source and target images, and sufficient criteria for inverse consistency are presented for the purpose of achieving more accurate registration. The techniques of estimating ITMs are examined and analytical derivatives are derived for carrying out the optimization in a computationally efficient manner. ITMs based on Shannon's and Renyi's definitions are considered and compared. The obtained evaluation results via registration functions, and controlled deformable registration of multi-modal digital brain phantom and in vivo magnetic resonance brain images show the improved accuracy and efficiency of the developed formulation. The results also indicate that despite the recent favorable studies towards the use of ITMs based on Renyi's definitions, these measures are seen not to provide improvements in this type of deformable registration as compared to ITMs based on Shannon's definitions. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Gholipour, Ali; Kehtarnavaz, Nasser; Yousefi, Siamak] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75080 USA.
   [Gholipour, Ali] Harvard Univ, Sch Med, Childrens Hosp Boston, Dept Radiol, Boston, MA 02115 USA.
   [Gopinath, Kaundinya; Briggs, Richard] Univ Texas SW Med Ctr Dallas, Dept Radiol, Dallas, TX 75390 USA.
C3 University of Texas System; University of Texas Dallas; Harvard
   University; Boston Children's Hospital; Harvard Medical School;
   University of Texas System; University of Texas Southwestern Medical
   Center Dallas
RP Gholipour, A (corresponding author), 300 Longwood Ave, Boston, MA 02115 USA.
EM ali.gholipour@childrens.harvard.edu; kehtar@utdallas.edu;
   Kaundinya.Gopinath@utsouthwestern.edu; Richard.Briggs@utsouthwestern.edu
FU UTD Erik Jonsson School of Engineering and Computer Science; Department
   of Veterans Affairs through VA IDIQ [VA549-P-0027]
FX This study was jointly supported by the UTD Erik Jonsson School of
   Engineering and Computer Science, and a subcontract from UT Southwestern
   Medical Center at Dallas, funded by the Department of Veterans Affairs
   through VA IDIQ Contract No. VA549-P-0027 awarded and administered by
   the VA Medical Center, Dallas, TX. The content of this paper does not
   necessarily reflect the position or the policy of the Veterans
   Administration or the Federal government, and no official endorsement
   should be inferred.
CR [Anonymous], 2006, Elements of Information Theory
   [Anonymous], 2001, Medical image registration
   [Anonymous], P IEEE EMBS DALL WOR
   Ardekani S, 2005, MAGN RESON MED, V54, P1163, DOI 10.1002/mrm.20651
   Ashburner J, 1997, NEUROIMAGE, V6, P209, DOI 10.1006/nimg.1997.0290
   Ashburner J, 1999, HUM BRAIN MAPP, V7, P254, DOI 10.1002/(SICI)1097-0193(1999)7:4<254::AID-HBM4>3.0.CO;2-G
   BYRD RH, 1995, SIAM J SCI COMPUT, V16, P1190, DOI 10.1137/0916069
   Chen HM, 2003, IEEE T MED IMAGING, V22, P1111, DOI 10.1109/TMI.2003.816949
   Christensen GE, 2001, IEEE T MED IMAGING, V20, P568, DOI 10.1109/42.932742
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   Cusack R, 2003, NEUROIMAGE, V18, P127, DOI 10.1006/nimg.2002.1281
   Daub CO, 2004, BMC BIOINFORMATICS, V5, DOI 10.1186/1471-2105-5-118
   Erdogmus D, 2005, SIGNAL PROCESS, V85, P927, DOI 10.1016/j.sigpro.2004.11.018
   Erdogmus D, 2003, IEEE SIGNAL PROC LET, V10, P242, DOI 10.1109/LSP.2003.814400
   Erdogmus D, 2006, IEEE SIGNAL PROC MAG, V23, P14, DOI 10.1109/SP-M.2006.248709
   Gholipour A., 2007, PROC IEEE DALLAS ENG, P5
   GHOLIPOUR A, 2008, P ICIP2008 IEEE INT
   Gholipour A, 2008, IEEE T BIO-MED ENG, V55, P563, DOI 10.1109/TBME.2007.912641
   Gholipour A, 2007, PROC SPIE, V6512, DOI 10.1117/12.710129
   Gholipour A, 2007, IEEE T MED IMAGING, V26, P427, DOI 10.1109/TMI.2007.892508
   GREENGARD L, 1991, SIAM J SCI STAT COMP, V12, P79, DOI 10.1137/0912004
   Hermosillo G, 2002, INT J COMPUT VISION, V50, P329, DOI 10.1023/A:1020830525823
   Hutton C, 2002, NEUROIMAGE, V16, P217, DOI 10.1006/nimg.2001.1054
   JEZZARD P, 1995, MAGNET RESON MED, V34, P65, DOI 10.1002/mrm.1910340111
   Kybic J, 2000, IEEE T MED IMAGING, V19, P80, DOI 10.1109/42.836368
   Lee S, 1996, IEEE T VIS COMPUT GR, V2, P337, DOI 10.1109/2945.556502
   LI Y, 2006, SPIE P MED IMAG, V6144, P808
   Loeckx D, 2006, LECT NOTES COMPUT SC, V4057, P206
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Maes F, 2003, P IEEE, V91, P1699, DOI 10.1109/JPROC.2003.817864
   Maes F, 1999, Med Image Anal, V3, P373, DOI 10.1016/S1361-8415(99)80030-9
   Mattes D, 2003, IEEE T MED IMAGING, V22, P120, DOI 10.1109/TMI.2003.809072
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Pluim JPW, 2004, IEEE T MED IMAGING, V23, P1508, DOI 10.1109/TMI.2004.836872
   Principe J., 2000, Unsupervised Adaptive Filtering, P265
   Rao M, 2004, IEEE T INFORM THEORY, V50, P1220, DOI 10.1109/TIT.2004.828057
   Rogelj P, 2006, MED IMAGE ANAL, V10, P484, DOI 10.1016/j.media.2005.03.003
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Skerl D, 2008, MED IMAGE ANAL, V12, P42, DOI 10.1016/j.media.2007.06.001
   Skerl D, 2006, IEEE T MED IMAGING, V25, P779, DOI 10.1109/TMI.2006.874963
   Steuer R, 2002, BIOINFORMATICS, V18, pS231, DOI 10.1093/bioinformatics/18.suppl_2.S231
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Studholme C, 2000, IEEE T MED IMAGING, V19, P1115, DOI 10.1109/42.896788
   Thévenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Wang F, 2007, INT J COMPUT VISION, V74, P201, DOI 10.1007/s11263-006-0011-2
   West J, 1997, J COMPUT ASSIST TOMO, V21, P554, DOI 10.1097/00004728-199707000-00007
   YANG C, 2003, P ICCV2003 9 IEEE IN
   Zhu CY, 1997, ACM T MATH SOFTWARE, V23, P550, DOI 10.1145/279232.279236
NR 49
TC 9
Z9 12
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 965
EP 975
DI 10.1016/j.imavis.2009.11.012
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200011
DA 2024-07-18
ER

PT J
AU Reid, I
   Connor, K
AF Reid, Ian
   Connor, Keith
TI Multiview segmentation and tracking of dynamic occluding layers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiple views; Segmentation; Novel view synthesis
AB We present an algorithm for the layered segmentation of video data in multiple views. The approach is based on computing the parameters of a layered representation of the scene in which each layer is modelled by its motion, appearance and occupancy, where occupancy describes, probabilistically, the layer's spatial extent and not simply its segmentation in a particular view. The problem is formulated as the MAP estimation of all layer parameters conditioned on those at the previous time step; i.e., a sequential estimation problem that is equivalent to tracking multiple objects in a given number views. Expectation-Maximisation is used to establish layer posterior probabilities for both occupancy and visibility, which are represented distinctly. Evidence from areas in each view which are described poorly under the model is used to propose new layers automatically. Since these potential new layers often occur at the fringes of images, the algorithm is able to segment and track these in a single view until such time as a suitable candidate match is discovered in the other views. The algorithm is shown to be very effective at segmenting and tracking non-rigid objects and can cope with extreme occlusion. We demonstrate an application of this representation to dynamic novel view synthesis. Crown Copyright (C) 2009 Published by Elsevier B.V. All rights reserved.
C1 [Reid, Ian; Connor, Keith] Univ Oxford, Dept Engn Sci, Oxford OX1 3PJ, England.
C3 University of Oxford
RP Reid, I (corresponding author), Univ Oxford, Dept Engn Sci, Parks Rd, Oxford OX1 3PJ, England.
EM ian@robots.ox.ac.uk
OI Reid, Ian/0000-0001-7790-6423
FU European Framework 5 [IST-1999-21125]
FX This work was supported by the European Framework 5 grant EVENTS
   [IST-1999-21125].
CR [Anonymous], P SIGGRAPH 2002
   APOSTOLOFF NE, 2004, P IEEE C COMP VIS PA
   AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859
   BAKER S, 2001, P IEEE C COMP VIS PA
   BAKER S, 1998, P IEEE C COMP VIS PA
   CONNOR K, 2003, P BRIT MACH VIS C
   DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Goldlücke B, 2003, PROC CVPR IEEE, P683
   GUILLEMAUT JY, 2007, P 3DIM, P167
   Jepson AD, 2002, LECT NOTES COMPUT SC, V2350, P692
   JOJIC N, 2001, P IEEE C COMP VIS PA
   Kohli P, 2008, INT J COMPUT VISION, V79, P285, DOI 10.1007/s11263-007-0120-6
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1480, DOI 10.1109/TPAMI.2006.193
   LHUILLIER M, 1999, P IEEE C COMP VIS PA
   Pereira F., 2002, IMSC Press multimedia series
   SINGARAJU D, 2008, P IEEE COMP VIS PATT
   Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885
   Torr PHS, 2001, IEEE T PATTERN ANAL, V23, P297, DOI 10.1109/34.910882
   WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981
   Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092
   Wexler Y, 2002, LECT NOTES COMPUT SC, V2352, P487
   XIAO J, 2005, P IEEE COMP VIS PATT
   YIN P, 2007, P IEEE COMP VIS PATT
   ZHOU Y, 2003, P INT C COMP VIS
NR 25
TC 3
Z9 7
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 1022
EP 1030
DI 10.1016/j.imavis.2009.09.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200015
DA 2024-07-18
ER

PT J
AU Kanan, HR
   Faez, K
AF Kanan, Hamidreza Rashidy
   Faez, Karim
TI Recognizing faces using Adaptively Weighted Sub-Gabor Array from a
   single sample image per enrolled subject
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Gabor Wavelet; Adaptively Weighted Sub-Gabor Array;
   Partial occlusion; Single model database
ID RECOGNITION; EIGENFACES; FEATURES; SPACE; MODEL; PCA
AB In this paper, we propose a new approach for face representation and recognition based on Adaptively Weighted Sub-Gabor Array (AWSGA) when only one sample image per enrolled subject is available. instead of using holistic representation of face images which is not effective under different facial expressions and partial occlusions, the proposed algorithm utilizes a local Gabor array to represent faces partitioned into sub-patterns. Especially, in order to perform matching in the sense of the richness of identity information rather than the size of a local area and to handle the partial occlusion problem, the proposed method employs an adaptively weighting scheme to weight the Sub-Gabor features extracted from local areas based on the importance of the information they contain and their similarities to the corresponding local areas in the general face image. An extensive experimental investigation is conducted using AR and Yale face databases covering face recognition under controlled/ideal condition, different illumination condition, different facial expression and partial occlusion. The system performance is compared with the performance of four benchmark approaches. The promising experimental results indicate that the proposed method can greatly improve the recognition rates under different conditions. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Faez, Karim] Amirkabir Univ Technol, Tehran Polytech, Dept Elect Engn, Image Proc & Pattern Recognit Lab, Tehran 15914, Iran.
   [Kanan, Hamidreza Rashidy] Islamic Azad Univ, Qazvin Branch, Dept Elect & Comp Engn, Qazvin, Iran.
C3 Amirkabir University of Technology; Islamic Azad University
RP Faez, K (corresponding author), Amirkabir Univ Technol, Tehran Polytech, Dept Elect Engn, Image Proc & Pattern Recognit Lab, Hafez Ave, Tehran 15914, Iran.
EM rashidykanan@aut.ac.ir; kfaez@aut.ac.ir
RI faez, karim/K-5117-2019; Rashidy Kanan, Hamidreza/AAI-7928-2020
OI faez, karim/0000-0002-1159-4866; Rashidy Kanan,
   Hamidreza/0000-0001-8789-8658
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 1965, The expression of emotions in man and animal
   Ayinde O, 2002, PATTERN RECOGN, V35, P1275, DOI 10.1016/S0031-3203(01)00120-0
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bruce V., 1988, RECOGNIZING FACES
   Chen SC, 2004, PATTERN RECOGN LETT, V25, P1173, DOI 10.1016/j.patrec.2004.03.012
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Ekman P, 1978, FACIAL ACTION CODING
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Gao YS, 2005, PATTERN RECOGN, V38, P1009, DOI 10.1016/j.patcog.2004.12.006
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   Gottumukkal R, 2004, PATTERN RECOGN LETT, V25, P429, DOI 10.1016/j.patrec.2003.11.005
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174
   Kyrki V, 2004, PATTERN RECOGN LETT, V25, P311, DOI 10.1016/j.patrec.2003.10.008
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu DH, 2004, PATTERN RECOGN LETT, V25, P267, DOI 10.1016/j.patrec.2003.10.007
   LUCEY S, 2006, CVPR, V1, P909
   Martinez A., 1998, AR FACE DATABASE
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Martínez AM, 2000, PROC CVPR IEEE, P712, DOI 10.1109/CVPR.2000.855890
   Nanni L, 2007, PATTERN RECOGN LETT, V28, P487, DOI 10.1016/j.patrec.2006.09.002
   Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   PHILLIPS PJ, 1997, P 1 INT C AUD VID BA
   Price JR, 2005, PATTERN RECOGN, V38, P209, DOI 10.1016/j.patcog.2004.07.001
   Shan S., 2005, PROC IEEE INT WORKSH, P278
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   SHEN L, P IM VIS COMP NZ, P77
   SHEN LL, 2006, IMAGE VIS COMPUT
   SHEPHERD J., 1981, PERCEIVING REMEMBERI
   SU Y, 2006, ICPR, V2, P528
   Tan KR, 2005, NEUROCOMPUTING, V64, P505, DOI 10.1016/j.neucom.2004.10.113
   Tan X., 2005, IEEE T NEURAL NETWOR, V16
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   *YAL U, 2002, YAL U FAC DAT
   YANG P, 2004, 6 IEEE INT C AUT FAC
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 42
TC 24
Z9 30
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 438
EP 448
DI 10.1016/j.imavis.2009.06.013
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300014
DA 2024-07-18
ER

PT J
AU Sizintsev, M
   Wildes, RP
AF Sizintsev, Mikhail
   Wildes, Richard P.
TI Coarse-to-fine stereo vision with accurate 3D boundaries
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Stereo; Coarse-to-fine; Occlusions; Real-time
   algorithms
ID ENERGY MINIMIZATION; ALGORITHM; PROPAGATION
AB This paper presents methods for efficient recovery of accurate binocular disparity estimates in the vicinity of 3D surface discontinuities. Of particular concern are methods that impact coarse-to-fine, local block-based matching as it forms the basis of the fastest and the most resource efficient stereo computation procedures. A novel coarse-to-fine refinement procedure that adapts match window support across scale to ameliorate corruption of disparity estimates near boundaries is presented. Extensions are included to account for half-occlusions and colour uniformity. Empirical results show that incorporation of these advances in the standard coarse-to-fine, block matching framework reduces disparity errors by more than a factor of two, while performing little extra computation, preserving low complexity and the parallel/pipeline nature of the framework. Moreover, the proposed advances prove to be beneficial for CTF global matchers as well. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Sizintsev, Mikhail] York Univ, Dept Comp Sci & Engn, Toronto, ON M3J 1P3, Canada.
   York Univ, Ctr Vis Res, Toronto, ON M3J 1P3, Canada.
C3 York University - Canada; York University - Canada
RP Sizintsev, M (corresponding author), York Univ, Dept Comp Sci & Engn, 4700 Keele St,CSE 3023, Toronto, ON M3J 1P3, Canada.
EM sizints@cse.yorku.ca; wildes@cse.yorku.ca
RI cai, bo/G-1491-2010
CR AGARWAL A, 2006, P IEEE C COMP VIS PA, P2339
   ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   [Anonymous], 2006, P BMVC CIT
   Birchfield S, 1998, IEEE T PATTERN ANAL, V20, P401, DOI 10.1109/34.677269
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 1997, PROC CVPR IEEE, P470, DOI 10.1109/CVPR.1997.609367
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   *BROWN U, 2006, BROWN U IM SEQ
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   CECH J, 2007, P BENCOS WORKSH CVPR
   COCHRAN SD, 1992, IEEE T PATTERN ANAL, V14, P981, DOI 10.1109/34.159902
   Cornelis N, 2005, PROC CVPR IEEE, P1099
   Darabiha A, 2006, MACH VISION APPL, V17, P116, DOI 10.1007/s00138-006-0018-2
   Deng Y, 2005, IEEE I CONF COMP VIS, P1316
   Drumheller M., 1986, Proceedings 1986 IEEE International Conference on Robotics and Automation (Cat. No.86CH2282-2), P1439
   Egnal G, 2002, IEEE T PATTERN ANAL, V24, P1127, DOI 10.1109/TPAMI.2002.1023808
   Felzenszwalb PR, 2004, PROC CVPR IEEE, P261
   Forstmann S., 2004, IEEE CVPR WORKSHOP R, P29
   Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428
   Goldberg SB, 2002, AEROSP CONF PROC, P2025
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hirschmüller H, 2002, INT J COMPUT VISION, V47, P229, DOI 10.1023/A:1014554110407
   Hirschmuller H., 2006, P 2006 IEEE COMPUTER, P2386, DOI DOI 10.1109/CVPR.2006.294
   Jahne B., 1993, Digital Image Processing: Concepts, Algorithms, and Scientific Applications
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   KOLMOGOROV V, 2006, P EUR C COMP VIS, V2, P1
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Kostkova J., 2003, BMVC Proc, P339
   LEUNG C, 2004, P BRIT MACH VIS C, P97
   Lhuillier M, 2002, IEEE T PATTERN ANAL, V24, P1140, DOI 10.1109/TPAMI.2002.1023810
   Lindeberg T., 1994, SCALE SPACE THEORY C
   MEERBERGEN GV, 2002, INT J COMPUT VISION, V47, P275
   Ogale AS, 2004, PROC CVPR IEEE, P568
   Okutomi M, 2002, INT J COMPUT VISION, V47, P261, DOI 10.1023/A:1014510328154
   Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763
   Sara R, 1997, PROC CVPR IEEE, P852, DOI 10.1109/CVPR.1997.609427
   SARA R, 2002, P EUR C COMP VIS, V3, P900
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shimizu M., 2002, Syst. Comput. Jpn, V33, P1409
   Sizintsev M., 2006, CS200607 YORK U
   Sizintsev M, 2008, PROCEEDINGS OF THE FIFTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, P97, DOI 10.1109/CRV.2008.8
   Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703
   Sun J, 2005, PROC CVPR IEEE, P399
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Szeliski R, 2004, IEEE T PATTERN ANAL, V26, P419, DOI 10.1109/TPAMI.2004.1262341
   Szeliski R, 1999, INT J COMPUT VISION, V32, P45, DOI 10.1023/A:1008192912624
   Szeliski R, 2006, LECT NOTES COMPUT SC, V3952, P16
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   van der Wal G, 2000, 5TH INTERNATIONAL WORKSHOP ON COMPUTER ARCHITECTURES FOR MACHINE PERCEPTION, PROCEEDINGS, P31, DOI 10.1109/CAMP.2000.875956
   Veksler O, 2003, PROC CVPR IEEE, P556
   Wang JB, 2006, J COMPUT THEOR NANOS, V3, P798, DOI 10.1166/jctn.2006.018
   XIONG W, 2007, P IEEE C COMP VIS PA
   Yang Q., 2006, P 17 BRIT MACHINE VI, P989
   Yang RG, 2003, PROC CVPR IEEE, P211, DOI 10.1109/ISCS.2003.1239980
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
NR 57
TC 33
Z9 39
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 352
EP 366
DI 10.1016/j.imavis.2009.06.008
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300007
DA 2024-07-18
ER

PT J
AU Wan, DR
   Zhou, J
AF Wan, Dingrui
   Zhou, Jie
TI Self-calibration of spherical rectification for a PTZ-stereo system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE PTZ-stereo system; Spherical rectification; Self-calibration
AB Since PTZ (pan-tilt-zoom) camera is able to obtain multi-view-angle and multi-resolution information, PTZ-stereo system using two PTZ cameras has much higher capability and flexibility compared with traditional stereo system. In this paper, we propose a self-calibration framework to deal with the calibration of spherical rectification, which can be deemed as a kind of relative pose estimation, for a M-stereo system. The goal of this calibration is to guarantee high performance of stereo rectification, so that stereo matching can be achieved more efficiently and accurately. In this framework, we assume two PTZ cameras are fully calibrated, i.e., the focal length and the local camera orientation can be computed by given pan-tilt-zoom values. This approach, which is based on point matches, aims at finding uniformly distributed point matches in an iterative way. At each iteration, according to the distribution of previously used point matches, the system could automatically guide two cameras to move to collect a new match. Point matching is firstly performed for the lowest zoom setting (widest field of view). Once a candidate match is chosen, each camera is then controlled to zoom in on corresponding point to get a refined match with high spatial resolution. The final match will be added into the estimation to update the calibration parameters. Compared with previous researches, the proposed framework has the following advantages: (1) Neither manual interaction nor calibration object is needed. Calibration samples (point matches) will be added and removed in each stage automatically. (2) The distribution of calibration samples is as uniform as possible so that biased estimation could be avoided to some extent. (3) The accuracy of calibration can be controlled and improved when iteration goes on. These advantages make the proposed framework more practicable in applications. Experimental results illustrate its accuracy. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Wan, Dingrui; Zhou, Jie] Tsinghua Univ, Dept Automat, TNList, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Zhou, J (corresponding author), Tsinghua Univ, Dept Automat, TNList, Qinhuayuan 1, Beijing 100084, Peoples R China.
EM wandingrui00@mails.tsinghua.edu.cn; jzhou@tsinghua.edu.cn
RI cai, bo/G-1491-2010
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fujiki J., 2007, MIRAGE, P461
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   LOOP CT, 1999, CVPR, P1125
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Papadimitriou DV, 1996, IEEE T IMAGE PROCESS, V5, P672, DOI 10.1109/83.491345
   Pollefeys M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P496, DOI 10.1109/ICCV.1999.791262
   Pollefeys M, 2004, LECT NOTES COMPUT SC, V3023, P509
   ROY S, 1997, CVPR, P393
   Senior AW, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P433
   SINHA S, 2004, OMNIVIS 2004
   WAN D, 2007, P ICASSP, V1, P777
   Wan DR, 2008, COMPUT VIS IMAGE UND, V112, P184, DOI 10.1016/j.cviu.2008.02.005
   Wan DR, 2009, IEEE T IMAGE PROCESS, V18, P677, DOI 10.1109/TIP.2008.2011178
NR 18
TC 8
Z9 10
U1 1
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 367
EP 375
DI 10.1016/j.imavis.2009.06.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300008
DA 2024-07-18
ER

PT J
AU Jonsson, E
   Felsberg, M
AF Jonsson, Erik
   Felsberg, Michael
TI Efficient computation of channel-coded feature maps through piecewise
   polynomials
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Channel-coded feature maps; Feature histograms; Soft histograms;
   Splines; Piecewise polynomials
AB Channel-coded feature maps (CCFMs) represent arbitrary image features using multi-dimensional histograms with soft and overlapping bins. This representation can be seen as a generalization of the SIFT descriptor. where one advantage is that it is better suited for computing derivatives with respect to image transformations. Using these derivatives, a local optimization of image scale, rotation and position relative to a reference view can be computed. If piecewise polynomial bin functions are used, e.g. B-splines, these histograms can be computed by first encoding the data set into a histogram-like representation with non-overlapping multi-dimensional monomials as bin functions. This representation can then be processed using multi-dimensional convolutions to obtain the desired representation. This allows to reuse much of the computations for the derivatives. By comparing the complexity of this method to direct encoding, it is found that the piecewise method is preferable for large images and smaller patches with few channels, which makes it useful, e.g. in early steps of coarse-to-fine approaches. (C) 2009 Published by Elsevier B.V.
C1 [Jonsson, Erik; Felsberg, Michael] Comp Vis Lab, Dept Elect Engn, Linkoping, Sweden.
RP Felsberg, M (corresponding author), Comp Vis Lab, Dept Elect Engn, Linkoping, Sweden.
EM mfe@isy.liu.se
OI Felsberg, Michael/0000-0002-6096-3648; Landolsi,
   Erik/0000-0002-6639-1257
FU European Community [FP7/2007-2013, FP6/2003-2007]
FX We thank David Lowe for providing the original source code of SIFF. The
   research leading to these results has received funding from the European
   Community's Seventh Framework Programme (FP7/2007-2013) under grant
   agreement no 215078 DIPLECS and from the European Community's Sixth
   Framework Programme (FP6/2003-2007) under grant agreement no 004176
   COSPAL.
CR [Anonymous], 2001, 2017 INT C ENERGY CO
   [Anonymous], 1994, COMPUTER VISION PATT
   [Anonymous], 1999, IEEE INT C COMP VIS
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   FELSBERG M, 2006, INT C PATT REC HONG
   GRANLUND GH, 2000, P ALG FRAM PERC ACT
   JONSSON E, 2007, P 15 SCAND C IM AN
   MICHAEL F, 2007, J REAL TIME IMAGE PR, V2, P103
   SE S, 2001, P INT C ROB AUT
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   YANG C, 2005, P IEEE INT C COMP VI, V1, P212
NR 12
TC 5
Z9 5
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 2
PY 2009
VL 27
IS 11
SI SI
BP 1688
EP 1694
DI 10.1016/j.imavis.2008.11.002
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 498HJ
UT WOS:000270127800005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hu, ZH
   Fan, X
   Song, YL
   Liang, DQ
AF Hu, Zhaohua
   Fan, Xin
   Song, Yaoliang
   Liang, Dequn
TI Joint trajectory tracking and recognition based on bi-directional
   nonlinear learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Trajectory generative model; Autoencoder network;
   Nonlinear dimensionality reduction; Particle filter; Improved Hausdorff
   distance
ID VISUAL TRACKING; DIMENSIONALITY; CLASSIFICATION; RETRIEVAL; PATTERNS;
   MODELS
AB Motion trajectory is one of the most important cues for tracking and behavior recognition and can be widely applied to numerous fields. However, it is a difficult problem to directly model the spatio-temporal variations of trajectories due to their high dimensionality and nonlinearity. In this paper, we propose a joint trajectory tracking and recognition algorithm by combining a generative model derived from a bi-directional deep. neural network (called "autoencoder") into a Bayesian estimation framework. The "autoencoder" network embeds high-dimensional trajectories into a two-dimensional plane based on a peculiar training rule and learns a trajectory generative model by its inverse mapping. A set of plausible trajectories can be generated by the trajectory generative model. In the tracking process, the samples from the plausible trajectory set are weighted by a mixed likelihood and are resampled to obtain the target state estimation at each time step in spirit of the particle filtering. The trajectory identity is inferred by evaluating the improved Hausdorff distance between the estimated trajectory up to now and the truncated reference trajectories. Moreover, the trajectory recognition results are also used to guide the trajectory tracking for the next time. The experiments on tracking and recognizing handwritten digits show that the proposed approach can achieve both robust tracking and exact recognition in background clutter and partial occlusion. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Hu, Zhaohua] Nanjing Univ Informat Sci & Technol, Sch Elect & Informat Engn, Nanjing 210044, Peoples R China.
   [Hu, Zhaohua; Fan, Xin; Liang, Dequn] Dalian Maritime Univ, Sch Informat Engn, Dalian 116026, Peoples R China.
   [Song, Yaoliang] Nanjing Univ Sci & Technol, Sch Elect Engn & Optoelect Technol, Nanjing 210094, Peoples R China.
C3 Nanjing University of Information Science & Technology; Dalian Maritime
   University; Nanjing University of Science & Technology
RP Hu, ZH (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Elect & Informat Engn, Nanjing 210044, Peoples R China.
EM zhaohua_hu@163.com
FU National Key Technologies R&D Program of China [2004BA111B01]
FX This work is supported by the Sub-Project of the National Key
   Technologies R&D Program of China on Image-based Intelligent Traffic
   Management under Grant No. 2004BA111B01. We thank the reviewers for
   valuable comments and suggestions that have greatly improved our paper.
CR [Anonymous], IEEE EUR C COMP VIS
   Bashir FI, 2007, IEEE T MULTIMEDIA, V9, P58, DOI 10.1109/TMM.2006.886346
   Bashir FI, 2007, IEEE T IMAGE PROCESS, V16, P1912, DOI 10.1109/TIP.2007.898960
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Chen H, 2002, LECT NOTES COMPUT SC, V2415, P358
   Chen H, 2003, IEE P-VIS IMAGE SIGN, V150, P153, DOI 10.1049/ip-vis:20030362
   CHEN W, 2000, SPIE C SAN JOS CA JA
   CHEUNG S, 2003, IEEE INT C IM PROC
   Elgammal A, 2004, PROC CVPR IEEE, P478
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Fu ZY, 2005, IEEE IMAGE PROC, P2029
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hu WM, 2004, IEEE T NEURAL NETWOR, V15, P135, DOI 10.1109/TNN.2003.820668
   Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896
   Kumar P, 2005, IEEE T INTELL TRANSP, V6, P43, DOI 10.1109/TITS.2004.838219
   Lee KC, 2005, COMPUT VIS IMAGE UND, V99, P303, DOI 10.1016/j.cviu.2005.02.002
   Murray AF, 2001, NEURAL NETWORKS, V14, P1257, DOI 10.1016/S0893-6080(01)00097-1
   North B, 2000, IEEE T PATTERN ANAL, V22, P1016, DOI 10.1109/34.877523
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Perez P., 2002, COLOR BASED PROBABIL
   Porikli F., 2004, P 2004 C COMPUTER VI, V7, P114
   REA N, 2004, P C IM VID RETR DUBL
   Roweis SamT., 2003, J MACHINE LEARNING R, V4, P119
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   SAHOURIA E, 1999, IEEE INT C IM PROC
   Schonfeld D, 2000, J VIS COMMUN IMAGE R, V11, P154, DOI 10.1006/jvci.1999.0432
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   SUN J, 2005, INT C COMP VIS, V1, P717
   TAY T, 2001, P IEEE ICCV, V51, P648
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   VENKATARAMAN V, P IEEE INT WORKSH OB
   Vlachos M, 2002, 13TH INTERNATIONAL WORKSHOP ON DATABASE AND EXPERT SYSTEMS APPLICATIONS, PROCEEDINGS, P721
   VLACHOS M, 2002, P 18 INT C DAT ENG I, P285
   Wada Y, 2004, NEURAL NETWORKS, V17, P353, DOI 10.1016/j.neunet.2003.11.009
   Wang Q, 2003, PROC CVPR IEEE, P227
   Yanagisawa Y, 2003, LECT NOTES COMPUT SC, V2574, P63
   Zhang Z, 2007, PROC CVPR IEEE, P813
   Zhou SHK, 2004, IEEE T IMAGE PROCESS, V13, P1491, DOI 10.1109/TIP.2004.836152
NR 39
TC 3
Z9 5
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1302
EP 1312
DI 10.1016/j.imavis.2008.11.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200007
DA 2024-07-18
ER

PT J
AU Fussenegger, M
   Roth, P
   Bischof, H
   Deriche, R
   Pinz, A
AF Fussenegger, Michael
   Roth, Peter
   Bischof, Horst
   Deriche, Rachid
   Pinz, Axel
TI A level set framework using a new incremental, robust Active Shape Model
   for object segmentation and tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Level set; Segmentation; Tracking; Active Shape Model; Incremental
   robust PCA
ID CONTOURS; MOTION; REGIONS
AB Level set based approaches are widely used for image segmentation and object tracking. As these methods are usually driven by low level cues such as intensity, colour, texture, and motion they are not sufficient for many problems. To improve the segmentation and tracking results, shape priors were introduced into level set based approaches. Shape priors are generated by presenting many views a priori, but in many applications this a priori information is not available. In this paper, we present a level set based segmentation and tracking method that builds the shape model incrementally from new aspects obtained by segmentation or tracking. In addition, in order to tolerate errors during the segmentation process, we present a robust Active Shape Model, which provides a robust shape prior in each level set iteration step. For the tracking, we use a simple decision function to maintain the desired topology for multiple regions. We can even handle full occlusions and objects, which are temporarily hidden in containers by combining the decision function and our shape model. Our experiments demonstrate the improvement of the level set based segmentation and tracking using an Active Shape Model and the advantages of our incremental, robust method over standard approaches. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Fussenegger, Michael; Pinz, Axel] Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, A-8010 Graz, Austria.
   [Roth, Peter; Bischof, Horst] Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria.
   [Deriche, Rachid] Odyssee Project Team INRIA Sophia Antipolis Medit, Sophia Antipolis, France.
C3 Graz University of Technology; Graz University of Technology
RP Pinz, A (corresponding author), Graz Univ Technol, Inst Elect Measurement & Measurement Signal Proc, Kopernikusgasse 24, A-8010 Graz, Austria.
EM mfussenegger@iconmobile.com; pmroth@icg.tugraz.at;
   bischof@icg.tugraz.at; Rachid.Deriche@-sophia.inria.fr;
   axel.pinz@tugraz.at
RI Roth, Peter M./JJD-5492-2023; Deriche, Rachid/AAM-9869-2021
OI Deriche, Rachid/0000-0002-4643-8417; Bischof, Horst/0000-0002-9096-6671
FU Austrian Science Foundation [S9103, S9104]; IMAVIS [HPMT-CF-2000-00040];
   Marie Curie Fellowship; FFG [813395]
FX This research has been partly funded by the Austrian Science Foundation
   (FWF, projects S9103 and S9104), the European project IMAVIS
   HPMT-CF-2000-00040 within the framework of the Marie Curie Fellowships
   Training Sites Programme, and the FFG project AUTOVISTA (813395) under
   the FIT-IT programme.
CR [Anonymous], LECT NOTES MATH
   Bertalmio M, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P318, DOI 10.1109/ICIP.1998.999021
   Besson SJ, 2000, INT C PATT RECOG, P1100, DOI 10.1109/ICPR.2000.903738
   Brox T, 2004, LECT NOTES COMPUT SC, V3175, P415
   CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cohen I, 1998, PROC CVPR IEEE, P741, DOI 10.1109/CVPR.1998.698686
   Cootes T., 1992, PROC BR MACHINE VISI, P266
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   CREMERS D, 2004, P EUR C COMP VIS ECC, V4, P74
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161
   DERVIEUX A, 1981, LECT NOTE PHYS, V141, P158
   Freedman D, 2004, IEEE T IMAGE PROCESS, V13, P518, DOI 10.1109/TIP.2003.821445
   FUSSENEGGER M, 2006, P AS C COMP VIS, V1, P674
   FUSSENEGGER M, 2006, P AS C COMP VIS, V2, P395
   Fussenegger M, 2006, LECT NOTES COMPUT SC, V4174, P122
   Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   JAMES A, 1995, IEEE T PATTERN ANAL, V17, P158
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   LAVALLEE S, 1995, IEEE T PATTERN ANAL, V17, P378, DOI 10.1109/34.385980
   Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830
   Leventon M., 2000, P IEEE C COMPUTER VI, P316, DOI DOI 10.1109/CVPR.2000.855835
   Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2005, COMPUT VIS IMAGE UND, V97, P259, DOI 10.1016/j.cviu.2003.04.001
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475
   Paragios N., 2000, Proceedings ECCV, VII, P224
   PARAGIOS N, 2002, P EUR C COMP VIS, V2, P813
   RIKLINRAVIV T, 2004, P EUR C COMP VIS, V4, P50
   ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7
   ROUSSON M, 2002, P EUR C COMP VIS, V2, P78
   Shi YG, 2005, PROC CVPR IEEE, P34
   Skocaj D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1494
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   VELTKAMP RC, 1999, UUCS199927
   Vemuri BC, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P86, DOI 10.1109/MMBIA.2000.852364
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
NR 41
TC 11
Z9 13
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1157
EP 1168
DI 10.1016/j.imavis.2008.10.014
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000016
DA 2024-07-18
ER

PT J
AU Robinson, JA
AF Robinson, John A.
TI Covariance estimation in full- and reduced-dimensionality image
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gaussian models; Face analysis; Regularization
ID BAYESIAN-ESTIMATION; MATRIX
AB This paper introduces an estimation technique for covariance matrices. The method differs from previous estimators in specifying an application-dependent cost function, regularizing all classes in the same way then compensating for volume distortions via scale parameters, and allowing m-fold rather than leave-one-out cross-validation. It provides a systematic basis for parameter estimation in high-dimensional spaces, where there are inevitably far too few training samples for reliable parameter estimates from sample statistics only. This is demonstrated with standard classifiers using normal models in the high dimensional space of appearance-based image processing. When the models are trained with the new technique, face classification performance is significantly better than with unregularized covariances and with earlier regularized estimators. Dimensionality reduction is also improved when it uses a covariance structure estimated with the method. (C) 2008 Elsevier B.V. All rights reserved.
C1 Univ York, Dept Elect, York YO10 5DD, N Yorkshire, England.
C3 University of York - UK
RP Robinson, JA (corresponding author), Univ York, Dept Elect, York YO10 5DD, N Yorkshire, England.
EM jar11@ohm.york.ac.uk
CR Anderson T.W., 1962, Tech. rep.
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   Champion CJ, 2003, J MULTIVARIATE ANAL, V87, P60, DOI 10.1016/S0047-259X(02)00076-3
   Daniels MJ, 2001, BIOMETRICS, V57, P1173, DOI 10.1111/j.0006-341X.2001.01173.x
   DICKEY JM, 1985, COMMUN STAT-THEOR M, V14, P1019, DOI 10.1080/03610928508828960
   Duda R. O., 2000, PATTERN CLASSIFICATI
   EFRON B, 1976, ANN STAT, V4, P22, DOI 10.1214/aos/1176343345
   ENIS P, 1974, ANN STAT, V2, P403, DOI 10.1214/aos/1176342677
   FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860
   Hoffbeck JP, 1996, IEEE T PATTERN ANAL, V18, P763, DOI 10.1109/34.506799
   Iwamura M., 2004, Systems and Computers in Japan, V35, P30, DOI 10.1002/scj.10519
   James M., 1985, CLASSIFICATION ALGOR
   JAMES W, P 4 BERK S MATH STAT, V1, P361
   Jimenez LO, 1998, IEEE T SYST MAN CY C, V28, P39, DOI 10.1109/5326.661089
   Kuo BC, 2002, IEEE T GEOSCI REMOTE, V40, P814, DOI 10.1109/TGRS.2002.1006358
   Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90
   Livingstone MS, 2000, SCIENCE, V290, P1299, DOI 10.1126/science.290.5495.1299b
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384
   OSullivan F., 1986, STAT SCI, V1, P502
   PENEV PS, 2000, 4 IEEE INT C AUT FAC
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Robinson J., 2005, P BRIT MACH VIS C 20, P389
   ROBINSON JA, 2005, BRIT MACH VIS C 2005, P609
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sakai M., 2000, Systems and Computers in Japan, V31, P28, DOI 10.1002/1520-684X(200008)31:9<28::AID-SCJ4>3.0.CO;2-V
   Samaria F. S., 1994, P 2 IEEE WORKSH APPL
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Shakhnarovich G., 2004, Handbook of Face Recognition
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   TADJUDIN S, 1999, IEEE T GEOSCIENCE RE, V37
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   TITTERINGTON DM, 1985, INT STAT REV, V53, P141, DOI 10.2307/1402932
   VIOLA P, 2001, P IEEE CVPR HAW DEC
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   YANG RY, 1994, ANN STAT, V22, P1195, DOI 10.1214/aos/1176325625
NR 36
TC 1
Z9 2
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1062
EP 1071
DI 10.1016/j.imavis.2008.09.010
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000008
DA 2024-07-18
ER

PT J
AU Laptev, I
AF Laptev, Ivan
TI Improving object detection with boosted histograms
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 17th Annual British Machine Vision Conference
CY SEP, 2006
CL British Machine Vis Assoc, Edinburgh, SCOTLAND
HO British Machine Vis Assoc
DE Object recognition; Machine learning; Histogram image features
ID RECOGNITION
AB We address the problem of visual object class recognition and localization in natural images. Building upon recent progress in the field we show bow histogram-based image descriptors can be combined with a boosting classifier to provide a state of the art object detector. Among the improvements we introduce a weak learner for multi-valued histogram features and show how to overcome problems of limited training sets. We also analyze different choices of image features and address computational aspects of the method. Validation of the method on recent benchmarks for object recognition shows its superior performance. In particular, using a single set of parameters our approach outperforms all the methods reported in VOC05 Challenge for seven out of eight detection tasks and four object classes while providing close to real-time performance. (C) 2008 Elsevier B.V. All rights reserved.
C1 INRIA Rennes Bretagne Atlantique, F-35042 Rennes, France.
C3 Universite de Rennes
RP Laptev, I (corresponding author), INRIA Rennes Bretagne Atlantique, Campus Univ Beaulieu, F-35042 Rennes, France.
EM ivan.laptev@inria.fr
CR [Anonymous], 1988, ALVEY VISION C
   [Anonymous], P COMP VIS PATT REC
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   DORKO D, 2003, P 9 INT C COMP VIS N
   Duda R. O., 2000, PATTERN CLASSIFICATI
   EPSHTEIN B, 2007, P COMP VIS PATT REC
   Everingham M., 2006, SEL P 1 PASCAL CHALL
   Everingham M., 2006, PASCAL VISUAL OBJECT
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   FRITZ M, 2005, P 10 INT C COMP VIS
   KOENDERINK JJ, 1987, BIOL CYBERN, V55, P367, DOI 10.1007/BF00318371
   LAPTEV I, 2006, P BRIT MACH VIS C ED
   Lazebnik S., 2006, P COMP VIS PATT REC
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Levi K., 2004, P COMP VIS PATT REC
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lindeberg T., 1994, SCALE SPACE THEORY C
   LOWE D, 1999, P 7 INT C COMP VIS C
   MIKOLAJCZYK K, 2002, LECT NOTES COMPUTER, V2350
   MIKOLAJCZYK K, 2005, P 10 INT C COMP VIS
   MIKOLAJCZYK K, 2003, P COMP VIS PATT REC
   PORIKLI F, 2005, P COMP VIS PATT REC
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   SCHNEIDERMAN H, 2000, P COMP VIS PATT REC, V1
   Sivic J., 2005, P 10 INT C COMP VIS
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   VARMA M, 2002, LECT NOTES COMPUTER
   VIITANIEMI V, 2006, 16 INT C ART NEUR NE
   Viola P., 2001, P 2001 IEEE COMPUTER
   Wang H., 2006, P AS C COMP VIS
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   ZHU Q, 2006, P COMP VIS PATT REC
NR 32
TC 65
Z9 79
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 2
PY 2009
VL 27
IS 5
SI SI
BP 535
EP 544
DI 10.1016/j.imavis.2008.08.010
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 437WD
UT WOS:000265516700005
DA 2024-07-18
ER

PT J
AU Gheissari, N
   Bab-Hadiashar, A
AF Gheissari, Niloofar
   Bab-Hadiashar, Alireza
TI A comparative study of model selection criteria for computer vision
   applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Model selection; Model-based computer vision; Motion segmentation; Range
   segmentation
ID SEGMENTATION; INFORMATION
AB During last three decades many model selection techniques have been developed, many of those have also been employed in computer vision applications. Interestingly, most of those criteria are based upon assumptions that are rarely realised in practical applications. As a result, the question of which model selection criterion works best for a particular application is of interest to many computer vision researcher and practitioners alike. This paper is an attempt to provide a satisfactory answer to this question for some well-known computer vision applications. Here, we present a comparative study of a large number of the existing model selection criteria for three computer vision tasks including: range modelling, motion modelling and merging of 3D surfaces in range data. Compared with other criteria, the results show that the surface selection criterion (SSC) appears to perform generally better for the above applications. (C) 2008 Elsevier B.V. All rights reserved
C1 [Gheissari, Niloofar; Bab-Hadiashar, Alireza] Swinburne Univ Technol, Fac Engn & Ind Sci, Hawthorn, Vic 3122, Australia.
C3 Swinburne University of Technology
RP Gheissari, N (corresponding author), Swinburne Univ Technol, Fac Engn & Ind Sci, Hawthorn, Vic 3122, Australia.
EM ngheissari@swin.edu.au; abab-hadiashar@swin.edu.au
RI Bab-Hadiashar, Alireza/A-9157-2010
OI Bab-Hadiashar, Alireza/0000-0002-6192-2303
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Bab-Hadiashar A, 1998, INT J COMPUT VISION, V29, P59, DOI 10.1023/A:1008090730467
   Bab-Hadiashar A, 2006, IEEE T IMAGE PROCESS, V15, P2006, DOI 10.1109/TIP.2006.877064
   BABHADIASHAR A, 2002, ROBUST MODEL BASED M, P753
   Barron J. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P236, DOI 10.1109/CVPR.1992.223269
   BOYER KL, 1994, IEEE T PATTERN ANAL, V16, P987, DOI 10.1109/34.329010
   BOZDOGAN H, 1987, PSYCHOMETRIKA, V52, P345, DOI 10.1007/BF02294361
   Brownlee K.A., 1960, STAT THEORY METHODOL
   Bubna K, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P895, DOI 10.1109/ICCV.1998.710823
   Bubna K, 2000, COMPUT VIS IMAGE UND, V80, P215, DOI 10.1006/cviu.2000.0871
   Chickering DM, 1997, MACH LEARN, V29, P181, DOI 10.1023/A:1007469629108
   Efron B, 1997, J AM STAT ASSOC, V92, P548, DOI 10.2307/2965703
   FITZGIBBON AWJ, 1977, THESIS
   Gheissari N, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P442, DOI 10.1109/ICIAP.2003.1234090
   GHEISSARI N, 2003, P DIG IM COMP TECHN, P185
   GU H, 1995, J PATTERN RECOGNITIO, V28, P781
   Kanatani K, 2000, DATA SEGMENTATION AND MODEL SELECTION FOR COMPUTER VISION, P91
   Kanatani K, 2004, IEEE T PATTERN ANAL, V26, P1307, DOI 10.1109/TPAMI.2004.93
   Kanatani K, 2002, LECT NOTES COMPUT SC, V2352, P335
   KANATANI K, 2002, P 5 AS C COMP VIS ME, pR11
   KANATANI K, 2003, P 3 INT WORKSH STAT
   MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   RISSANEN J, 1984, IEEE T INFORM THEORY, V30, P629, DOI 10.1109/TIT.1984.1056936
   RONCHETTI E, 1994, J AM STAT ASSOC, V89, P550, DOI 10.2307/2290858
   SUBBARAO JM, 1988, INTERPRETATION VISUA
   TORR P, 1998, MODEL SELECTION 2 VI
   Torr PHS, 2000, DATA SEGMENTATION AND MODEL SELECTION FOR COMPUTER VISION, P143
   Torr PHS, 1998, PHILOS T R SOC A, V356, P1321, DOI 10.1098/rsta.1998.0224
   Torr PHS, 1997, PROC CVPR IEEE, P47, DOI 10.1109/CVPR.1997.609296
   TORR PHS, 2000, P IEEE EUR C COMP VI, P273
   WERGHI N, 1998, P 5 EUR C COMP VIS, P185
   Whaite P., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P41, DOI 10.1109/ICCV.1993.378237
NR 33
TC 7
Z9 8
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1636
EP 1649
DI 10.1016/j.imavis.2008.04.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500007
DA 2024-07-18
ER

PT J
AU Abadpour, A
   Kasaei, S
AF Abadpour, Arash
   Kasaei, Shohreh
TI Color PCA eigenimages and their application to compression and
   watermarking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
ID IMAGE WATERMARKING; DIGITAL WATERMARKING; SEGMENTATION; TRANSFORM;
   SCHEME; ROBUST; QUANTIZATION
AB From the birth of multi-spectral imaging techniques, there has been a tendency to consider and process this new type of data as a set of parallel gray-scale images, instead of an ensemble of an n-D realization. However, it has been proved that using vector-based tools leads to a more appropriate understanding of color images and thus more efficient algorithms for processing them. Such tools are able to take into consideration the high correlation of the color components and thus to successfully carry out energy compaction. In this paper, a novel method is proposed to utilize the principal component analysis in the neighborhoods of an image in order to extract the corresponding eigenimages. These eigenimages exhibit high levels of energy compaction and thus are appropriate for such operations as compression and water-marking. Subsequently, two such methods are proposed in this paper and their comparison with available approaches is presented. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Kasaei, Shohreh] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
   [Abadpour, Arash] Sharif Univ Technol, Dept Math Sci, Tehran, Iran.
C3 Sharif University of Technology; Sharif University of Technology
RP Kasaei, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
EM skasaei@sharif.edu
RI Kasaei, Shohreh/AAD-5618-2019
OI Kasaei, Shohreh/0000-0002-3831-0878
CR Abadpour A, 2005, IEE P-COMMUN, V152, P605, DOI 10.1049/ip-com:20050028
   ABADPOUR A, 2004, 9 ANN CSI COMP C CSI, P125
   ABADPOUR A, 2005, 10 ANN CSI COMP C CS
   ABADPOUR A, 2004, 2 IEEE C ADV TECHN G
   ABADPOUR A, 2004, P 12 IR C EL ENG ICE
   ABADPOUR A, 2004, IPM WORKSH COMP VIS
   ABADPOUR A, 2005, THESIS SHARIF U TECH
   ABADPOUR A, 2007, VISUAL COMMUNICATION, V18, P15
   [Anonymous], 2000, Digital Watermarking
   Barni M, 2002, IEEE T CIRC SYST VID, V12, P142, DOI 10.1109/76.993436
   Benson K.B., 1992, Television engineering handbook
   Carevic D, 1997, GRAPH MODEL IM PROC, V59, P27, DOI 10.1006/gmip.1996.0402
   Chaira T, 2003, PATTERN RECOGN LETT, V24, P1943, DOI 10.1016/S0167-8655(03)00033-3
   Chen TQ, 2002, PATTERN RECOGN, V35, P395, DOI 10.1016/S0031-3203(01)00050-4
   Cheng HD, 2003, PATTERN RECOGN, V36, P1545, DOI 10.1016/S0031-3203(02)00293-5
   Cheng SC, 2003, J VIS COMMUN IMAGE R, V14, P184, DOI 10.1016/S1047-3203(03)00024-5
   CHOU CH, 2001, EURASIP J APPL SIG P, V1, P327
   Clausen C, 2000, PATTERN RECOGN, V33, P1555, DOI 10.1016/S0031-3203(99)00126-0
   DAI X, 2002, IEEE ICSP02, P969
   Dhara BC, 2007, PATTERN RECOGN, V40, P2408, DOI 10.1016/j.patcog.2006.12.022
   Faloutsos C, 1997, IEEE T KNOWL DATA EN, V9, P373, DOI 10.1109/69.599927
   FUKUMA S, 1998, LOSSLESS COLOR COORD, P595
   HOTTELING H, 1933, J EDUC PSYCHOL, V24, P417
   Hsieh MS, 2001, IEEE T IND ELECTRON, V48, P875, DOI 10.1109/41.954550
   Huang PS, 2005, IEE P-VIS IMAGE SIGN, V152, P561, DOI 10.1049/ip-vis:20041081
   Kang XG, 2003, IEEE T CIRC SYST VID, V13, P776, DOI 10.1109/TCSVT.2003.815957
   Kasaei S, 2002, IEEE T IMAGE PROCESS, V11, P1365, DOI 10.1109/TIP.2002.802534
   KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441
   KLINKER GJ, 1988, INT J COMPUT VISION, V2, P7, DOI 10.1007/BF00836279
   Kutter M, 1998, J ELECTRON IMAGING, V7, P326, DOI 10.1117/1.482648
   Kutter M, 2002, IEEE T IMAGE PROCESS, V11, P16, DOI 10.1109/83.977879
   Leung SH, 2004, IEEE T IMAGE PROCESS, V13, P51, DOI 10.1109/TIP.2003.818116
   LIMB JO, 1977, IEEE T COMMUN, V25, P1349, DOI 10.1109/TCOM.1977.1093774
   LIMB JO, 1971, IEEE T COMMUN, V20, P890
   Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207
   Lucchese L, 2001, IEE P-VIS IMAGE SIGN, V148, P141, DOI 10.1049/ip-vis:20010229
   MA KK, 2002, 7 INT C CONTR AUT RO, P1228
   MASULLI F, 2000, SERIES STUIDES FUZZI, P335
   Nikolaev DP, 2004, COMPUT VIS IMAGE UND, V94, P115, DOI 10.1016/j.cviu.2003.10.012
   Nikolaidis A, 2000, IEEE T MULTIMEDIA, V2, P172, DOI 10.1109/6046.865482
   Papamarkos N, 2000, IMAGE VISION COMPUT, V18, P213, DOI 10.1016/S0262-8856(99)00015-3
   PRATT WK, 1971, IEEE T COMMUN TECHN, VCO19, P980, DOI 10.1109/TCOM.1971.1090769
   Ruanaidch J. J. K. O., 1996, IEE P-VIS IMAGE SIGN, V143, P250
   SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836
   SHAHINFARD E, 2003, IR C MECH ENG ICME Q, P363
   SHIHHAO, 2004, IEEE T IMAGE PROCESS, V13, P154
   Slater J., 1991, MODERN TELEVISION SY
   Swanson MD, 1998, P IEEE, V86, P1064, DOI 10.1109/5.687830
   Tang CW, 2003, IEEE T SIGNAL PROCES, V51, P950, DOI 10.1109/TSP.2003.809367
   Tsai P, 2004, SIGNAL PROCESS, V84, P95, DOI 10.1016/j.sigpro.2003.07.012
   Tschumperle D, 2002, THESIS U NICE SOPHIA
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yazdi M, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P456, DOI 10.1109/ICIP.1997.647805
   YE Q, 2003, P 2003 IEEE INT C AC, P401
   Yu PT, 2001, SIGNAL PROCESS, V81, P663, DOI 10.1016/S0165-1684(00)00239-5
   YU YD, 1999, IEEE IENCON 99, P1259
NR 56
TC 17
Z9 19
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 878
EP 890
DI 10.1016/j.imavis.2007.10.013
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800002
DA 2024-07-18
ER

PT J
AU He, L
   Peng, ZG
   Everding, B
   Wang, X
   Han, CY
   Weiss, KL
   Wee, WG
AF He, Lei
   Peng, Zhigang
   Everding, Bryan
   Wang, Xun
   Han, Chia Y.
   Weiss, Kenneth L.
   Wee, William G.
TI A comparative study of deformable contour methods on medical image
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE medical image segmentation; deformable contour method; snake; level set;
   comparative study
ID LEVEL SET METHOD; T-SNAKES; MODELS; SHAPE; GRADIENT
AB A comparative study to review eight different deformable contour methods (DCMs) of snakes and level set methods applied to the medical image segmentation is presented. These DCMs are now applied extensively in industrial and medical image applications. The segmentation task that is required for biomedical applications is usually not simple. Critical issues for any practical application of DCMs include complex procedures, multiple parameter selection, and sensitive initial contour location. Guidance on the usage of these methods will be helpful for users, especially those unfamiliar with DCMs, to select suitable approaches in different conditions. This study is to provide such guidance by addressing the critical considerations on a common image test set. The test set of selected images offers different and typical difficult problems encountered in biomedical image segmentation. The studied DCMs are compared using both qualitative and quantitative measures and the comparative results highlight both the strengths and limitations of these methods. The lessons learned from this medical segmentation comparison can also be translated to other image segmentation domains. (c) 2007 Elsevier B.V. All rights reserved.
C1 [He, Lei] Armstrong Atlantic State Univ, Dept Informat Technol, Savannah, GA 31419 USA.
   [Peng, Zhigang; Everding, Bryan; Wang, Xun; Han, Chia Y.; Wee, William G.] Univ Cincinnati, Dept Elect & Comp Engn, Cincinnati, OH 45221 USA.
   [Peng, Zhigang; Everding, Bryan; Wang, Xun; Han, Chia Y.; Wee, William G.] Univ Cincinnati, Dept Comp Sci, Cincinnati, OH 45221 USA.
   [Weiss, Kenneth L.] Univ Cincinnati, Dept Psychiat, Cincinnati, OH 45267 USA.
C3 University System of Georgia; Armstrong Atlantic State University;
   University System of Ohio; University of Cincinnati; University System
   of Ohio; University of Cincinnati; University System of Ohio; University
   of Cincinnati
RP He, L (corresponding author), Armstrong Atlantic State Univ, Dept Informat Technol, 11935 Abercorn St, Savannah, GA 31419 USA.
EM helei@mail.armstrong.edu
RI Peng, Zhigang/HPF-2037-2023; cai, bo/G-1491-2010
CR ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098
   AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chakraborty A, 1996, IEEE T MED IMAGING, V15, P859, DOI 10.1109/42.544503
   Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen YM, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P145, DOI 10.1109/VLSM.2001.938893
   COHEN JS, 1991, PHARMACOL THERAPEUT, V52, P211, DOI 10.1016/0163-7258(91)90009-B
   Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4
   Delingette H, 2001, COMPUT VIS IMAGE UND, V83, P140, DOI 10.1006/cviu.2001.0920
   Falcao AX, 2000, IEEE T MED IMAGING, V19, P55, DOI 10.1109/42.832960
   Fenster SD, 2001, IEEE T PATTERN ANAL, V23, P1028, DOI 10.1109/34.955115
   FLECKENSTEIN P, 2001, ANATOMY DIAGNOSTICS
   Frangi AF, 2001, IEEE T MED IMAGING, V20, P2, DOI 10.1109/42.906421
   Giraldi GA, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.855797
   Grzeszczuk RP, 1997, IEEE T PATTERN ANAL, V19, P1100, DOI 10.1109/34.625111
   Haaga J., 2003, CT and MR imaging of the whole body, V5th
   HOFFBRAND AV, 2000, COLOR ATLAS CLIN HAE
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555
   Jain AK, 1998, SIGNAL PROCESS, V71, P109, DOI 10.1016/S0165-1684(98)00139-X
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Leventon M., 2000, P IEEE C COMPUTER VI, P316, DOI DOI 10.1109/CVPR.2000.855835
   LUNDERVOLD A, 1995, IEEE T MED IMAGING, V14, P339, DOI 10.1109/42.387715
   MAI JK, 1997, ATLAS HUMAN BRAIN
   Malladi R, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P304, DOI 10.1109/ICCV.1998.710735
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   McInerney T, 2000, MED IMAGE ANAL, V4, P73, DOI 10.1016/S1361-8415(00)00008-6
   Niessen WJ, 1998, IEEE T MED IMAGING, V17, P634, DOI 10.1109/42.730407
   ODONNELL L, 2001, P MED IM COMP ASS IN, P1022
   Olstad B, 1996, IEEE T PATTERN ANAL, V18, P863, DOI 10.1109/34.537341
   OTTO CM, 2002, PRACTICE CLIN ECHOCA
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   ROUSSON M, 2002, P EUR C COMP VIS, P78
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Siddiqi K, 1998, IEEE T IMAGE PROCESS, V7, P433, DOI 10.1109/83.661193
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   STOVIK G, 1994, IEEE T PAMI, V16, P976
   TOHKA J, 2002, P 7 EUR C COMP VIS E, P350
   Wang X, 2004, INT J COMPUT VISION, V59, P87, DOI 10.1023/B:VISI.0000020672.14006.ad
   Williams L, 2001, FILM QUART, V55, P14, DOI 10.1525/fq.2001.55.2.14
   XU C, 2000, SPIE HDB MED IMAGING, V3, P129
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 49
TC 185
Z9 214
U1 0
U2 62
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 141
EP 163
DI 10.1016/j.imavis.2007.07.010
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500001
DA 2024-07-18
ER

PT J
AU Money, JH
   Kang, SH
AF Money, James H.
   Kang, Sung Ha
TI Total variation minimizing blind deconvolution with shock filter
   reference
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image deblurring; blind deconvolution; total variation; variational
   method; L-1 norm; L-2 norm
ID IMAGE-RESTORATION; ENHANCEMENT
AB We present a preconditioned method for blind image deconvolution. This method uses a pre-processed reference image (via the shock filter) as an initial condition for total variation minimizing blind deconvolution. Using the shock filter gives good information on location of the edges, while using the variational functionals such as Chan and Wong's [T.F. Chan, C.K. Wong, Total variation blind deconvolution, IEEE Transactions on Image Processing 7 (1998), 370-375] allows robust reconstruction of the image and the blur kernel. Comparison between using the L-1 and L-2 norms for the fidelity term is presented, as well as an analysis on the choice of the parameter for the kernel functional. Numerical results indicate the method is robust for both black and non-black background images while reducing the overall computational cost. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Money, James H.] N Carolina Cent Univ, Dept Math & Comp Sci, Durham, NC 27707 USA.
   [Kang, Sung Ha] Univ Kentucky, Dept Math, Lexington, KY 40506 USA.
C3 University of North Carolina; North Carolina Central University;
   University of Kentucky
RP Money, JH (corresponding author), N Carolina Cent Univ, Dept Math & Comp Sci, Durham, NC 27707 USA.
EM jmoney@nccu.edu; skang@ms.uky.edu
RI Money, James/AAB-2257-2021; Money, James/B-8085-2017
OI Money, James/0000-0001-9174-706X; Money, James/0000-0001-9174-706X
CR ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   [Anonymous], SIAM MMS
   [Anonymous], 2002, COMPUTATIONAL METHOD
   Bar L, 2006, IEEE T IMAGE PROCESS, V15, P483, DOI 10.1109/TIP.2005.863120
   Bar L, 2005, LECT NOTES COMPUT SC, V3752, P49
   Bar L, 2005, LECT NOTES COMPUT SC, V3459, P107
   Bar L, 2004, LECT NOTES COMPUT SC, V3022, P166
   Chan T, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P17, DOI 10.1007/0-387-28831-7_2
   Chan TF, 2005, INT J IMAG SYST TECH, V15, P92, DOI 10.1002/ima.20041
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   CHAN TF, 2005, IMS LECT NOTES
   Chan TF, 2005, IMAGE PROCESSING AND ANALYSIS, P207
   FISH DA, 1995, J OPT SOC AM A, V12, P58, DOI 10.1364/JOSAA.12.000058
   Fu HY, 2006, SIAM J SCI COMPUT, V27, P1881, DOI 10.1137/040615079
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Gilboa G, 2002, LECT NOTES COMPUT SC, V2350, P399
   He L, 2005, INT J IMAG SYST TECH, V15, P74, DOI 10.1002/ima.20040
   Kärkkäinen T, 2005, COMPUTING, V74, P353, DOI 10.1007/s00607-004-0097-8
   Nagy JG, 1998, SIAM J SCI COMPUT, V19, P1063, DOI 10.1137/S106482759528507X
   Nikolova M, 2005, MULTISCALE MODEL SIM, V4, P960, DOI 10.1137/040619582
   Nikolova M, 2004, J MATH IMAGING VIS, V20, P99, DOI 10.1023/B:JMIV.0000011920.58935.9c
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   STRONG D, 1997, P SPIE ANN M, V3137, P222
   STRONG D, CAM9607 UCLA
   Vogel CR, 1996, SIAM J SCI COMPUT, V17, P227, DOI 10.1137/0917016
   Welk M, 2005, LECT NOTES COMPUT SC, V3663, P485
   Yin WT, 2005, LECT NOTES COMPUT SC, V3752, P73
   You YL, 1999, IEEE T IMAGE PROCESS, V8, P396, DOI 10.1109/83.748894
   [No title captured]
NR 30
TC 63
Z9 77
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 302
EP 314
DI 10.1016/j.imavis.2007.06.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500013
DA 2024-07-18
ER

PT J
AU El-Bakry, HM
   Mastorakis, N
AF El-Bakry, Hazem M.
   Mastorakis, Nikos
TI New fast normalized neural networks for pattern detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fast pattern detection; neural networks; cross correlation; image
   normalization; parallel processing
AB Neural networks have shown good results for detecting a certain pattern in a given image. In this paper, fast neural networks for pattern detection are presented. Such processors are designed based on cross correlation in the frequency domain between the input image and the input weights of neural networks. This approach is developed to reduce the computation steps required by these fast neural networks for the searching process. The principle of divide and conquer strategy is applied through image decomposition. Each image is divided into small in size sub-images and then each one is tested separately by using a single fast neural processor. Furthermore, faster pattern detection is obtained by using parallel processing techniques to test the resulting sub-images at the same time using the same number of fast neural networks. In contrast to fast neural networks, the speed up ratio is increased with the size of the input image when using fast neural networks and image decomposition. Moreover, the problem of local sub-image normalization in the frequency domain is solved. The effect of image normalization on the speed up ratio of pattern detection is discussed. Simulation results show that local sub-image normalization through weight normalization is faster than sub-image normalization in the spatial domain. The overall speed up ratio of the detection process is increased as the normalization of weights is done offline. (c) 2007 Elsevier B.V. All rights reserved.
C1 Mansoura Univ, Fac Comp Sci & Informat Syst, Mansoura, Egypt.
C3 Egyptian Knowledge Bank (EKB); Mansoura University
RP El-Bakry, HM (corresponding author), Mansoura Univ, Fac Comp Sci & Informat Syst, Mansoura, Egypt.
EM helbakry20@yahoo.com
RI El-Bakry, Hazem/GOK-0336-2022
OI El Bakry, Hazem/0000-0002-4798-0427
CR Ben-Yacoub S., 1997, Fast object detection using MLP and FFT
   Ben-Yacoub S., 1999, P 2 INT C AUD VID BA
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   El-Bakry H, 2001, METMBS'01: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON MATHEMATICS AND ENGINEERING TECHNIQUES IN MEDICINE AND BIOLOGICAL SCIENCES, P112
   El-Bakry H, 2001, CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING 2001, VOLS I AND II, CONFERENCE PROCEEDINGS, P1409, DOI 10.1109/CCECE.2001.933664
   El-Bakry H., 2001, P 7 FUZZ DAYS INT C, P269
   El-Bakry H. M., 2005, Machine Graphics & Vision, V14, P29
   El-Bakry H. M., 2004, INT J SIGNAL PROCESS, V1, P182
   El-Bakry HM, 2006, J RES PRACT INF TECH, V38, P151
   El-Bakry HM, 2005, EURASIP J APPL SIG P, V2005, P2054, DOI 10.1155/ASP.2005.2054
   El-Bakry HM, 2003, IEEE IJCNN, P1284
   El-Bakry HM, 2001, IEEE IJCNN, P577, DOI 10.1109/IJCNN.2001.939086
   El-Bakry HM, 2002, NEUROCOMPUTING, V48, P1039, DOI 10.1016/S0925-2312(02)00608-2
   El-Bakry HM, 2001, FRONT ARTIF INTEL AP, V69, P1330
   El-Bakry HM, 2001, SPRING COMP SCI, P201
   ELBAKRY H, 2002, P INNS IEEE INT JOIN
   ELBAKRY HM, 2000, P IJCNN INT JOINT C, V3, P320
   ELBAKRY HM, 2000, P 6 INT C SOFT COMP
   ELBAKRY HM, 2004, P CIC 2004 INT C COM
   ELBAKRY HM, 2001, P 6 INT COMP SCI C A, P205
   ELBAKRY HM, 2004, P IEEE INT S CIRC SY
   ELBAKRY HM, 2005, INT J INFORM TECHNOL, V2, P71
   ELBAKRY HM, 2004, P 30 ANN SOFSEM C CU
   ELBAKRY HM, 2004, P 8 WORLD MULT C SYS
   ELBAKRY HM, 2001, INT J MACHINE GRAPHI, V10, P47
   ELBAKRY HM, 2004, INT J SIGNAL PROCESS, V1, P188
   ELBAKRY HM, 2004, P 5 INT S SOFT COMP
   ELBAKRY HM, 2004, P 1 INT C CYB INF TE, V4, P150
   ELBAKRY HM, 2002, MACHINE GRAPHICS VIS, V11, P498
   ELBAKRY HM, 2001, P 5 WORLD MULT C SYS
   ELBAKRY HM, 2004, P IS 2004 14 ANN CAN
   ELBAKRY HM, 2005, INT J SIGNAL PROCESS, V2, P183
   ELBAKRY HM, 2004, INT J COMPUTATIONAL, V1, P313
   ELBAKRY HM, 2001, P IEEE INT C IM PROC
   FASEL B, 1998, 9804 IDIAPCOM
   FERAUD R, 2000, P 4 IEEE INT C AUT F
   ISHAK KA, 2004, P INT S INF COMM TEC, V2, P5
   Klette R., 1996, HDB IMAGE PROCESSING
   Lewis J P., FAST NORMALIZED CROS
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586
   Srisuk S, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P306, DOI 10.1109/AFGR.2002.1004171
   ZHU Y, 2000, P IEEE COMP SOC INT, V1, P1636
NR 43
TC 19
Z9 19
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1767
EP 1784
DI 10.1016/j.imavis.2007.02.001
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shi, XJ
   Manduchi, R
AF Shi, Xiaojin
   Manduchi, Roberto
TI On the Bayes fusion of visual features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image classification; Bayes fusion; color; texture
ID BIAS; VARIANCE
AB We consider the problem of image classification when more than one visual feature is available. In such cases, Bayes fusion offers an attractive solution by combining the results of different classifiers (one classifier per feature). This is the general form of the so-called "naive Bayes" approach. This paper compares the performance of Bayes fusion with respect to Bayesian classification, which is based the joint feature distribution. It is well-known that the latter has lower bias than the former, unless the features are conditionally independent, in which case the two coincide. However, as originally noted by Friedman, the low variance associated with naive Bayes estimation may mitigate the effect of its inherent bias. Indeed, in the case of small training samples, naive Bayes may outperform Bayes classification in terms of error rate. The contribution of this paper is threefold. First, we present a detailed analysis of the error rate of Bayes fusion assuming that the statistical description of the data is known. Second, we provide a qualitative justification of the small sample effect on the classifier's performance based on the bias/variance theory. Third, we present experimental results on three image data sets using color and texture features. Our experiments highlight the relationship between the error rate of the Bayes and the Bayes fusion classifiers as a function of the training sample size. (c) 2007 Elsevier B.V. All rights reserved.
C1 Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA.
C3 University of California System; University of California Santa Cruz
RP Manduchi, R (corresponding author), Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA.
EM manduchi@cse.ucsc.edu
CR Alkoot FM, 1999, PATTERN RECOGN LETT, V20, P1361, DOI 10.1016/S0167-8655(99)00107-5
   [Anonymous], P ECML 98 10 EUR C M
   Breiman L, 1998, BIOMETRICS, DOI [10.1201/9781315139470, DOI 10.2307/2530946]
   Breiman L., 1996, 460 STAT DEP
   Castano R., 2001, CLASSIFICATION EXPT
   COOPER WS, 1995, ACM T INFORM SYST, V13, P100, DOI 10.1145/195705.195735
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Domingos P, 1997, MACH LEARN, V29, P103, DOI 10.1023/A:1007413511361
   Domingos P, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P564
   Eun Bae Kong, 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P313
   Friedman JH, 1997, DATA MIN KNOWL DISC, V1, P55, DOI 10.1023/A:1009778005914
   Friedman N, 1997, MACH LEARN, V29, P131, DOI 10.1023/A:1007465528199
   GEMAN S, 1992, NEURAL COMPUT, V4, P1, DOI 10.1162/neco.1992.4.1.1
   JONES MJ, 9811 CRL
   Kittler J, 1998, PROC CVPR IEEE, P924, DOI 10.1109/CVPR.1998.698715
   Kittler J., 1998, IEEE T PAMI, V20
   LANGLEY P, 1994, P 10 C UNC ART INT S
   Manduchi R, 2005, AUTON ROBOT, V18, P81, DOI 10.1023/B:AURO.0000047286.62481.1d
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MARTIN JK, 1996, 9621 DEPT INF COMP S
   Moore Andrew W, 1994, P 11 INT C MACH LEAR, P190, DOI DOI 10.1016/B978-1-55860-335-6.50031-3
   RAUDYS S, 1997, IEEE T PAMI, V19, P337
   RAUDYS SJ, 1991, IEEE T PATTERN ANAL, V13, P252, DOI 10.1109/34.75512
   Ripley BD, 1996, PATTERN RECOGNITION
   SHI X, 2003, IEEE WORKSH STAT AN
   SHI X, 2004, P IEEE CVPR WASH DC
   Smyth P., 1996, P 2 INT C KNOWL DISC, P126
   Tax DavidM. J., 1997, Proc. Workshop on Statistical Pattern Recognition, P165
   Tibshirani R., 1996, Bias, Variance, and Prediction Error for Classification Rules
   TSUYUGUCHI M, 2002, P AMAI 2002
   Wolpert DH, 1997, NEURAL COMPUT, V9, P1211, DOI 10.1162/neco.1997.9.6.1211
   INT WORKSH MULT CLAS
NR 32
TC 5
Z9 10
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1748
EP 1758
DI 10.1016/j.imavis.2007.01.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900005
DA 2024-07-18
ER

PT J
AU Couprie, M
   Coeurjolly, D
   Zrour, R
AF Couprie, Michel
   Coeurjolly, David
   Zrour, Rita
TI Discrete bisector function and Euclidean skeleton in 2D and 3D
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE bisector function; skeleton; euclidean distance transform; voronoi
   diagram; digital topology
ID LINEAR-TIME ALGORITHM
AB We propose a new definition and an algorithm for the discrete bisector function, which is an important tool for analyzing and filtering Euclidean skeletons. We also introduce a new thinning algorithm which produces homotopic discrete Euclidean skeletons. These algorithms, which are valid both in 2D and 313, are integrated in a skeletonization method which is based on exact transformations, allows the filtering of skeletons, and is computationally efficient. (c) 2006 Elsevier B.V. All rights reserved.
C1 Grp ESIEE, Lab A2SI, Inst Gaspard Monge, F-93162 Noisy Le Grand, France.
   CNRS, LIRIS, F-69622 Villeurbanne, France.
   LLAIC, F-63172 Aubiere, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon; Centre
   National de la Recherche Scientifique (CNRS)
RP Couprie, M (corresponding author), Grp ESIEE, Lab A2SI, Inst Gaspard Monge, BP 99, F-93162 Noisy Le Grand, France.
EM m.couprie@esiee.fr; david.coeurjolly@liris.enrs.fr;
   zrour@llaic3.u-clermon1.fr
OI Coeurjolly, David/0000-0003-3164-8697
CR Attali D, 2001, COMP GEOM-THEOR APPL, V19, P175, DOI 10.1016/S0925-7721(01)00019-0
   BERTRAND G, 1994, PATTERN RECOGN LETT, V15, P1003, DOI 10.1016/0167-8655(94)90032-9
   Blum H., 1967, Models for the Perception of Speech and Visual Form, P380
   Borgefors G., 1991, P 7 SCAND C IM AN, V2, P974
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Daragon X, 2003, LECT NOTES COMPUT SC, V2886, P236
   DAVIES ER, 1981, PATTERN RECOGN, V14, P53, DOI 10.1016/0031-3203(81)90045-5
   Ge YR, 1996, IEEE T PATTERN ANAL, V18, P1055, DOI 10.1109/34.544075
   Hesselink WH, 2005, COMPUT IMAGING VIS, V30, P259
   Hirata T, 1996, INFORM PROCESS LETT, V58, P129, DOI 10.1016/0020-0190(96)00049-X
   KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   Malandain G, 1998, IMAGE VISION COMPUT, V16, P317, DOI 10.1016/S0262-8856(97)00074-7
   Maurer CR, 2003, IEEE T PATTERN ANAL, V25, P265, DOI 10.1109/TPAMI.2003.1177156
   Meijster A, 2000, COMP IMAG VIS, V18, P331
   Remy E, 2005, IMAGE VISION COMPUT, V23, P167, DOI 10.1016/j.imavis.2004.06.007
   ROSENFELD A, 1970, J ACM, V17, P146, DOI 10.1145/321556.321570
   SAITO T, 1994, PATTERN RECOGN, V27, P1551, DOI 10.1016/0031-3203(94)90133-3
   TALBOT H, 1992, SPIE, V1818, P862
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 24
TC 57
Z9 67
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1543
EP 1556
DI 10.1016/j.imavis.2006.06.020
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Brunner, D
   Soille, P
AF Brunner, Dorninik
   Soille, Pierre
TI Iterative area filtering of multichannel images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE partition; image simplification; quasi-flat zone; seeded region growing;
   mathematical morphology; area filter; connected operator; multispectral
ID CONNECTED OPERATORS; SEGMENTATION; MORPHOLOGY
AB Owing to the absence of total ordering between vectors of more than one dimension, most morphological transformations are not directly applicable to multichannel images. In this paper, we show that area based operators can be extended to the processing of multichannel images by using the quasi-flat zones and seeded region growing paradigms. The method is iterative in the sense that it starts with the smallest non-unitary quasi-flat zones until an automatically derived contrast threshold value is reached. Pseudo-code is given for all algorithms. We illustrate their usefulness for the simplification of complex natural images such as those occurring in satellite images of the earth. (c) 2006 Elsevier B.V. All rights reserved.
C1 Commiss European Communities, DG Joint Res Ctr, Inst Environm & Sustainabil, I-21020 Ispra, Italy.
   Commiss European Communities, DG Joint Res Ctr, Inst Protect & Secur Citizens, I-21020 Ispra, Italy.
C3 European Commission Joint Research Centre; EC JRC ISPRA Site; European
   Commission Joint Research Centre; EC JRC ISPRA Site
RP Soille, P (corresponding author), Commiss European Communities, DG Joint Res Ctr, Inst Environm & Sustainabil, Via Fermi 1, I-21020 Ispra, Italy.
EM Pierre.Soille@jrc.it
OI Soille, Pierre/0000-0002-8479-9205
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   ADAMS R, 1991, P DICTA 91, P459
   Baraldi A, 1996, IEEE T GEOSCI REMOTE, V34, P137, DOI 10.1109/36.481899
   BEAULIEU JM, 1989, IEEE T PATTERN ANAL, V11, P150, DOI 10.1109/34.16711
   Breen EJ, 1994, COMP IMAG VIS, V2, P249
   BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1
   BRUNNER D, 2005, P 7 INT S MATH MORPH, P397
   Crespo J, 1997, SIGNAL PROCESS, V62, P37, DOI 10.1016/S0165-1684(97)00114-X
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   Iwanowski M, 2005, LECT NOTES COMPUT SC, V3691, P538
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Meyer F, 2004, J MATH IMAGING VIS, V20, P59, DOI 10.1023/B:JMIV.0000011319.21884.39
   MEYER F, 1992, IEE CONF PUBL, V354, P303
   Meyer F, 1998, COMP IMAG VIS, V12, P199
   Meyer F, 2000, J VIS COMMUN IMAGE R, V11, P245, DOI 10.1006/jvci.1999.0447
   Ronse C, 2005, J MATH IMAGING VIS, V22, P283, DOI 10.1007/s10851-005-4895-1
   ROSENFELD A, 1983, PATTERN RECOGN, V16, P47, DOI 10.1016/0031-3203(83)90007-9
   SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422
   Salembier P, 1998, COMP IMAG VIS, V12, P183
   SALEMBIER P, 1994, IEEE T IMAGE PROCESS, V3, P639, DOI 10.1109/83.334980
   Salembier P, 1996, IEEE T IMAGE PROCESS, V5, P881, DOI 10.1109/83.503906
   Soille P, 2005, IMAGE VISION COMPUT, V23, P249, DOI 10.1016/j.imavis.2004.06.002
   Soille P, 2002, IEEE T GEOSCI REMOTE, V40, P2042, DOI 10.1109/TGRS.2002.804618
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Zanoguera F, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P369
NR 26
TC 22
Z9 22
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1352
EP 1364
DI 10.1016/j.imavis.2006.09.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000015
DA 2024-07-18
ER

PT J
AU García, MA
   Puig, D
AF Garcia, Miguel Angel
   Puig, Domenec
TI Supervised texture classification by integration of multiple texture
   methods and evaluation windows
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE supervised texture classification; multiple texture methods; multiple
   evaluation windows; Kullback J-divergence; MeasTex; LBP; edge flow;
   JSEG; fabric defect detection
ID SEGMENTATION; REGIONS; COLOR
AB Pixel-based texture classifiers and segmenters typically combine texture feature extraction methods belonging to a same family. Each method is evaluated over square windows of the same size, which is chosen experimentally. This paper proposes a pixel-based texture classifier that integrates multiple texture feature extraction methods from different families, with each method being evaluated over multiple windows of different size. Experimental results show that this integration scheme leads to significantly better results than well-known supervised and unsupervised texture classifiers based on specific families of texture methods. A practical application to fabric defect detection is also presented. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Rovira & Virgili, Dept Math & Comp Sci, Intelligent Robot & Comp Vis Grp, Tarragona 43007, Spain.
C3 Universitat Rovira i Virgili
RP Puig, D (corresponding author), Univ Rovira & Virgili, Dept Math & Comp Sci, Intelligent Robot & Comp Vis Grp, Avda Paisos Catalans 26, Tarragona 43007, Spain.
EM magarcia@etse.urv.es; dpuig@etse.urv.es
RI Garcia, Miguel Angel/C-4304-2014
OI Garcia, Miguel Angel/0000-0003-2611-6821
CR Berger J. O., 1985, STAT DECISION THEORY, DOI DOI 10.1007/978-1-4757-4286-2
   Berthod M, 1996, IMAGE VISION COMPUT, V14, P285, DOI 10.1016/0262-8856(95)01072-6
   BLOSTEIN D, 1989, IEEE T PATTERN ANAL, V11, P1233, DOI 10.1109/34.41363
   Brodatz P., 1999, Textures: a photographic album for artists and designers
   CAELLI T, 1993, PATTERN RECOGN, V26, P461, DOI 10.1016/0031-3203(93)90102-3
   CHANG KI, 1999, IEEE INT C COMP VIS
   CHAUDHURI BB, 1995, IEEE T PATTERN ANAL, V17, P72, DOI 10.1109/34.368149
   Cohen H. A., 1992, ICIP 92. Proceedings of the 2nd Singapore International Conference on Image Processing, P726
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   García MA, 2002, INT C PATT RECOG, P7, DOI 10.1109/ICPR.2002.1047782
   García-Sevilla P, 2000, INT C PATT RECOG, P1068, DOI 10.1109/ICPR.2000.903730
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593
   Kittler J., 1986, HDB PATTERN RECOGNIT, P60
   LAWS KI, 1980, ISGTRIPI940 USC
   Loog M, 2002, INT C PATT RECOG, P925, DOI 10.1109/ICPR.2002.1048456
   Lu CS, 1997, PATTERN RECOGN, V30, P729, DOI 10.1016/S0031-3203(96)00116-1
   Ma WY, 1997, PROC CVPR IEEE, P744, DOI 10.1109/CVPR.1997.609409
   Malik J., 2000, Perceptual organization for Artificial Vision Systems
   Mathiassen JR, 2002, LECT NOTES COMPUT SC, V2352, P133
   NOVIANTO S, 1999, IEEE INT C IM PROC J
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   OJALA T, 2001, CVONLINE COMPENDIUM
   Pichler O, 1996, PATTERN RECOGN, V29, P733, DOI 10.1016/0031-3203(95)00127-1
   Puig D, 2002, IEEE IMAGE PROC, P125
   Puzicha J, 1997, PROC CVPR IEEE, P267, DOI 10.1109/CVPR.1997.609331
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Rao AR, 1996, VISION RES, V36, P1649, DOI 10.1016/0042-6989(95)00202-2
   REED TR, 1993, CVGIP-IMAG UNDERSTAN, V57, P359, DOI 10.1006/ciun.1993.1024
   Sharon E, 2001, PROC CVPR IEEE, P469
   Smith G, 1997, PATTERN RECOGN LETT, V18, P1495, DOI 10.1016/S0167-8655(97)00132-3
   WESZKA JS, 1976, IEEE T SYST MAN CYB, V6, P269, DOI 10.1109/TSMC.1976.5408777
   Zöller T, 2002, INT C PATT RECOG, P627, DOI 10.1109/ICPR.2002.1048380
NR 34
TC 31
Z9 33
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1091
EP 1106
DI 10.1016/j.imavis.2006.05.023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300007
DA 2024-07-18
ER

PT J
AU Kuo, CM
   Hsieh, CH
   Huang, YR
AF Kuo, Chung-Ming
   Hsieh, Chaur-Heh
   Huang, Yong-Ren
TI A new adaptive vertex-based binary shape coding technique
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE shape coding; vertex-based coding; modified object-adaptive vertex
   encoding
ID PERFORMANCE; EFFICIENCY; SEGMENTS; CURVES
AB This paper presents a new adaptive vertex-based coding scheme to improve the coding efficiency of the object shapes of a video sequence. We first smooth out the original contour using the property of perfect 8-connectivity, which reduces the number of vertexes without loss of quality. Then we propose top-down and bottom-up algorithms to select the vertex points. In the top-down scheme, we develop a new adjusting technique to measure the distortion. It is simple for both calculation and implementation, and the reconstructed shape has better quality. In the bottom-up scheme, we develop a new area-based measure that makes the insertion of a new vertex easy. Finally, we propose a scheme that employs multiple dynamic ranges to modify the object-adaptive vertex coding method. It improves the coding performance significantly. (C) 2006 Elsevier B.V. All rights reserved.
C1 I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
   Shu Te Univ, Dept Informat Engn, Kaohsiung 824, Taiwan.
C3 I Shou University; Shu-Te University
RP Kuo, CM (corresponding author), I Shou Univ, Dept Informat Engn, Kaohsiung 840, Taiwan.
EM kuocm@isu.edu.tw
CR [Anonymous], 1997, J PHARM SCI-US
   Chiariglione L, 1997, IEEE T CIRC SYST VID, V7, P5, DOI 10.1109/76.554414
   Cho SH, 1999, IEEE T CIRC SYST VID, V9, P59, DOI 10.1109/76.744275
   Chung JW, 2000, SIGNAL PROCESS-IMAGE, V15, P665, DOI 10.1016/S0923-5965(99)00046-6
   EDEN M, 1985, SIGNAL PROCESS, V8, P381, DOI 10.1016/0165-1684(85)90001-5
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   *ISO IEC, 1998, 144962 ISO IEC
   KANEKO T, 1985, IEEE T COMMUN, V33, P697, DOI 10.1109/TCOM.1985.1096361
   KOPLOWITZ J, 1981, IEEE T PATTERN ANAL, V3, P180, DOI 10.1109/TPAMI.1981.4767075
   LEE S, 1997, P ICIP97, P508
   MARCHANDMAILLET S, 1997, THESIS U LONDON
   *MPEG VID GROUP, 2001, MPEG 4 VID VER MOD V
   OCONNELL KJ, 1997, IEEE T CIRC SYST VID, V7, P252
   PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   ROSENFELD A, 1974, IEEE T COMPUT, VC 23, P1264, DOI 10.1109/T-C.1974.223845
   SHARAIHA YM, 1993, PATTERN RECOGN, V26, P799, DOI 10.1016/0031-3203(93)90132-G
   SIKORA T, 1995, IEEE T CIRC SYST VID, V5, P254, DOI 10.1109/76.401104
NR 18
TC 7
Z9 8
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 863
EP 872
DI 10.1016/j.imavis.2006.06.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600008
DA 2024-07-18
ER

PT J
AU Ranade, A
   Mahabalarao, SS
   Kale, S
AF Ranade, Abhiram
   Mahabalarao, Srikanth S.
   Kale, Satyen
TI A variation on SVD based image compression
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE image compression; singular value decomposition; Karhunen-Loeve
   transform; matrix rank; low resolution sample
ID SINGULAR-VALUE DECOMPOSITION
AB We present a variation to the well studied SVD based image compression technique. Our variation can be viewed as a preprocessing step in which the input image is permuted as per a fixed, data independent permutation, after which it is fed to the standard SVD algorithm. Likewise, our decompression algorithm can be viewed as the standard SVD algorithm followed by a postprocessing step which applies the inverse permutation.
   On experimenting with standard images we show that our method performs substantially better than the standard method. Typically, for any given compression quality, our method needs about 30% fewer singular values and vectors to be retained. We also present a bit allocation scheme and show that our method also performs better than the more familiar discrete cosine transform (DCT).
   We show that the original SVD algorithm as well as our variation, can be viewed as instances of the Karhunen-Loeve transform (KLT). In fact, we observe that there is a whole family of variations possible by choosing different parameter values while applying the KLT. We present heuristic arguments to show that our variation is likely to yield the best compression of all these. We also present experimental evidence, which appears to justify our analysis. (C) 2006 Elsevier B.V. All rights reserved.
C1 Indian Inst Technol, Dept Comp Sci & Engn, Bombay 400076, Maharashtra, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bombay
RP Mahabalarao, SS (corresponding author), Symantec Corp, Pune, Maharashtra, India.
EM ranade@cse.iitb.ac.in; srikanth.sm@gmail.com; satyen@cs.princeton.edu
CR ANDREWS HC, 1976, IEEE T COMMUN, V24, P425, DOI 10.1109/TCOM.1976.1093309
   GERBRANDS JJ, 1981, PATTERN RECOGN, V14, P375, DOI 10.1016/0031-3203(81)90082-0
   GOLDRICK CM, 1995, IMAGE PROCESSING ITS, P296
   Golub G. H., 1983, MATRIX COMPUTATIONS
   Jain A.K., 2000, FUNDAMENTALS DIGITAL, VV
   KALMAN D, 1996, COLL MATH J, V27
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   SAITO T, 1990, IMPROVEMENT SINGUL 1, V73, P11
   WALDEMAR P, 1996, P NORSIG C, P83
   YANG JF, 1995, IEEE T IMAGE PROCESS, V4, P1141, DOI 10.1109/83.403419
NR 10
TC 34
Z9 41
U1 1
U2 19
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 771
EP 777
DI 10.1016/j.imavis.2006.07.004
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, W
   Kosecká, J
AF Zhang, Wei
   Kosecka, Jana
TI Hierarchical building recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE building recognition; man-made structures retrieval; localization;
   visual landmark recognition
AB in urban areas, buildings are often used as landmarks for localization. Reliable and efficient recognition of buildings is crucial for enabling this functionality. Motivated by the applications which would enhance visual localization and navigation capabilities, we propose in this paper a hierarchical approach for building recognition. In the first recognition stage the model views are indexed by localized color histograms computed from dominant orientation structures in the image. This novel representation enables quick retrieval of a small number of candidate buildings from the database. In the second stage the recognition results are refined by matching previously proposed SIFT descriptors associated with local image regions. For this stage, we propose a method for selecting discriminative SIFT features and a simple probabilistic model for integration of the evidence from individual matches based on the match quality. This enables us to eliminate the sensitive choice of threshold for match selection as well as the sensitivity to the number of features characterizing different models. The proposed approach is validated by extensive experiments, with images taken in different weather conditions, seasons and with different cameras. We report superior recognition results on a publicly available database and one additional database of buildings we collected. (c) 2006 Elsevier B.V. All rights reserved.
C1 George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
C3 George Mason University
RP Zhang, W (corresponding author), George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
EM wzhang2@cs.gmu.edu
CR [Anonymous], P ECCV
   [Anonymous], INT C COMP VIS
   [Anonymous], 260 SWISS FED I TECH
   [Anonymous], 2005, PAMI
   AOKI H, 1998, RECOGNIZING PERSONAL
   Coughlan J. M., 1999, P IEEE INT C COMPUTE, DOI DOI 10.1109/ICCV.1999.790349
   FRITZ G, 2005, SCIA, P629
   Goedemé T, 2004, PROC CVPR IEEE, P24
   Ke Y., 2004, P IEEE COMP VIS PATT
   Koseck Jana, 2002, European Conference on Computer Vision, P476
   Kumar S, 2003, PROC CVPR IEEE, P119
   Li Y, 2002, INT C PATT RECOG, P952, DOI 10.1109/ICPR.2002.1048195
   Lindeberg T, 1994, J APPL STAT, V21
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   LOWE D, 2004, INT J COMP VIS
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Mikolajczyk K., 2003, CVPR
   MOHR R, 1997, P COMP AN IM PATT
   NAYAR S, 1995, IEEE T ROBOTIC AUTOM, V6, P750
   Pass G, 1999, MULTIMEDIA SYST, V7, P234, DOI 10.1007/s005300050125
   Pope AR, 2000, INT J COMPUT VISION, V40, P149, DOI 10.1023/A:1026502202780
   Robertson D., 2004, BMVC
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   SCHIELE B, 2000, INT J COMPUTER VISIO
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Schmid C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P485, DOI 10.1109/CVPR.1999.784725
   Shao H, 2003, LECT NOTES COMPUT SC, V2728, P71
   Stassopoulou A., 2000, INT J PATTERN RECOGN, V83, P705
   Stricker M, 1997, MACH VISION APPL, V10, P66, DOI 10.1007/s001380050060
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TORRALBA A, 2001, RECOGNIZING INDOOR S
   TUYTELAARS T, 2004, IJCV, V59
   Yeh T., 2004, CVPR
   ZHANG W, 2004, GMUCSTR20043
   ZHANG W, 2005, WORKSH COMP VIS APPL
NR 35
TC 46
Z9 50
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 704
EP 716
DI 10.1016/j.imavis.2006.05.016
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200016
DA 2024-07-18
ER

PT J
AU Bray, M
   Koller-Meier, E
   Schraudolph, NN
   Van Gool, L
AF Bray, M.
   Koller-Meier, E.
   Schraudolph, N. N.
   Van Gool, L.
TI Fast stochastic optimization for articulated structure tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stochastic meta-descent; hand tracking; deformable hand model
AB Recently, an optimization approach for fast visual tracking of articulated structures based on stochastic meta-descent (SMD) [7] has been presented. SMD is a gradient descent with local step size adaptation that combines rapid convergence with excellent scalability. Stochastic sampling helps to avoid local minima in the optimization process. We have extended the SMD algorithm with new features for fast and accurate tracking by adapting the different step sizes between as well as within video frames and by introducing a robust cost function, which incorporates both depths and surface orientations. The advantages of the resulting tracker over state-of-the-art methods are supported through 3D hand tracking experiments. A realistic deformable hand model reinforces the accuracy of our tracker. (c) 2006 Elsevier B.V. All rights reserved.
C1 ETH, Comp Vis Lab, Swiss Fed Inst Technol, CH-8092 Zurich, Switzerland.
   Natl ICT Australia, Canberra, NSW 2000, Australia.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; NICTA
RP Bray, M (corresponding author), ETH, Comp Vis Lab, Swiss Fed Inst Technol, Sternwartstr 7, CH-8092 Zurich, Switzerland.
EM bray@vision.ee.ethz.ch; ebmeier@vision.ee.ethz.ch;
   vangool@vision.ee.ethz.ch
CR ALMEIDA LB, 1999, PARAMETER ADAPTATION
   Athitsos V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P45, DOI 10.1109/AFGR.2002.1004129
   Bertsekas D.P., 2000, Nonlinear Programming, VSecond
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Black M.J., 1996, Fourth European Conference on Computer 650 Vision (ECCV), P329
   Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422
   Bray M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P675, DOI 10.1109/AFGR.2004.1301612
   BRAY M, 2004, 1 EUR C VIS MED PROD, P59
   CATMULL E, 1972, ACM ANN C, P422
   Cham T.J., 1999, IEEE COMPUTER SOC C, P239
   Delamarre Q, 2001, COMPUT VIS IMAGE UND, V81, P328, DOI 10.1006/cviu.2000.0892
   DEUTSCHER J, 2000, INT C COMP VIS PATT, P26
   Gourret J., 1989, ACM SIGGRAPH COMPUTE, V23, P21, DOI DOI 10.1145/74333.74335
   HEAP AJ, 1996, INT C AUT FAC GEST R, P140
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2
   Kivinen J., 1995, Proceedings of the Twenty-Seventh Annual ACM Symposium on the Theory of Computing, P209, DOI 10.1145/225058.225121
   Komatsu K., 1988, Visual Computer, V3, P265, DOI 10.1007/BF01914861
   Koninckx TP, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P293, DOI 10.1109/IM.2003.1240262
   KUCH JJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P666, DOI 10.1109/ICCV.1995.466875
   Levenberg K., 1944, Quarterly of Applied Mathematics, V2, P164, DOI [10.1090/QAM/10666, DOI 10.1090/QAM/10666]
   LIN J, 2001, ARL FED LAB 5 ANN S, P105
   Lin M. H., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P648, DOI 10.1109/ICCV.1999.791286
   MAGNENATTHALMAN.N, 1988, GRAPHICS INTERFACE, P26
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147
   PLAENKERS R, 2001, INT C COMP VIS, P394
   Press W. H., 1988, Numerical Recipes
   PROESMANS M, 1996, INT C PATT REC, P336
   REHG JM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P612, DOI 10.1109/ICCV.1995.466882
   REHG JM, 1994, EUR C COMP VIS, P35
   Rosales R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P378, DOI 10.1109/ICCV.2001.937543
   Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600
   SHIMADA N, 2001, WORKSH REC AN TRACK, P23
   Sidenbladh H., 2000, Lecture Notes in Computer Science, P702
   Sminchisescu C, 2001, PROC CVPR IEEE, P447
   SUTTON RS, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P171
   Tomasi C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1441
   Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P426, DOI 10.1109/ICCV.2001.937656
NR 39
TC 27
Z9 29
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 352
EP 364
DI 10.1016/j.imavis.2005.10.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100011
DA 2024-07-18
ER

PT J
AU Yip, RKK
AF Yip, Raymond K. K.
TI Genetic Fourier descriptor for the detection of rotational symmetry
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE genetic algorithm; Fourier descriptors; rotational symmetry detection
ID ALGORITHM
AB In this paper, a genetic Fourier descriptors is proposed to detect rotational symmetry. Rotational symmetry is one of the important features for image decoding and object recognition in computer vision systems. In the genetic Fourier algorithm, the Fourier descriptors are chromosomes and fitting function of the GA. The genetic Fourier method has the following advantages. (1) It can handle partially occurred contour and opened contour, (2) it can handle complex point pattern and (3) it can obtain multiple perceptions. Experimental results show that it can handle complex symmetry figures, these symmetry figures may be formed by separated curves, points or partially occurred or partially missed (opened contour). (c) 2006 Elsevier B.V. All rights reserved.
C1 City Univ Hong Kong, Dept Informat Syst, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Yip, RKK (corresponding author), City Univ Hong Kong, Dept Informat Syst, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
EM hkrayyip@cityu.edu.hk
CR [Anonymous], 1996, GENETIC ALGORITHMS D, DOI DOI 10.1007/978-3-662-03315-9_4
   GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926
   Han KP, 2001, PATTERN RECOGN, V34, P1729, DOI 10.1016/S0031-3203(00)00114-X
   KUHL FP, 1982, COMPUT VISION GRAPH, V18, P236, DOI 10.1016/0146-664X(82)90034-X
   LIN CS, 1987, PATTERN RECOGN, V20, P535, DOI 10.1016/0031-3203(87)90080-X
   PINKOWSKI B, 1996, INT C DSP APPL TECHN, P1007
   Rohlf F.J., 1990, Proceedings of the Michigan morphometrics workshop, P167
   YIP RKK, 1994, IEEE T PATTERN ANAL, V16, P277, DOI 10.1109/34.276127
   Yip RKK, 1999, PATTERN RECOGN LETT, V20, P991, DOI 10.1016/S0167-8655(99)00066-5
   Yuen SY, 2000, PATTERN RECOGN, V33, P1949, DOI 10.1016/S0031-3203(99)00189-2
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhang LH, 2003, PATTERN RECOGN LETT, V24, P9, DOI 10.1016/S0167-8655(02)00160-5
NR 12
TC 13
Z9 15
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 148
EP 154
DI 10.1016/j.imavis.2006.01.024
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700003
DA 2024-07-18
ER

PT J
AU Ortiz, A
   Oliver, G
AF Ortiz, Alberto
   Oliver, Gabriel
TI Radiometric calibration of vision cameras and intensity uncertainty
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CCD sensors; camera calibration; intensity uncertainty
AB The irradiance measurement performed by vision cameras is not noise-free due to both processing errors during CCD fabrication and the behaviour of the electronic device itself. A proper characterization of sensor performance, however, allows either removing the resulting noise from the image or accounting for it within image processing algorithms. This paper proposes a robust algorithm named (RCIU)-C-2 for characterizing the noise sources affecting CCD performance with the aim of estimating the uncertainty of the intensity values yielded by vision cameras. (RCIU)-C-2 makes use of sets of images of plane calibration cards such that, for every set, the average intensity changes. As it is shown in the paper, the (spatial) average and variance of (temporal) average images of every set lie in a parabola, while the (spatial) averages of the (temporal) average and variance images of every set lie in a straight line. (RCIU)-C-2 exploits these two facts to compute the noise source distribution parameters by least-squares fitting. Intensity uncertainties are estimated next by a sum in quadrature of the variances of the different noise sources involved in the process of image formation. Experimental results and application examples can be found at the end of the paper. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Balearic Isl, Dept Math & Comp Sci, Palma de Mallorca 07071, Spain.
C3 Universitat de les Illes Balears
RP Ortiz, A (corresponding author), Univ Balearic Isl, Dept Math & Comp Sci, Edificio Amselm Turmeda,Campus UIB,Cra Valldemoss, Palma de Mallorca 07071, Spain.
EM alberto.ortiz@uib.es; goliver@uib.es
RI Ortiz, Alberto/K-5624-2014; Oliver-Codina, Gabriel/J-7749-2013
OI Ortiz, Alberto/0000-0002-8253-7455; Oliver-Codina,
   Gabriel/0000-0001-6910-1940
CR [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], 1997, PHYS CHEMESTRY EMGIN, DOI DOI 10.1121/1.418074
   [Anonymous], 1992, ROBUST COMPUTER VISI
   [Anonymous], 1993, Statistical Theory
   Fernández-García NL, 2004, PATTERN RECOGN LETT, V25, P35, DOI 10.1016/j.patrec.2003.08.011
   Gevers T, 2003, INT J COMPUT VISION, V53, P135, DOI 10.1023/A:1023095923133
   HEALEY GE, 1994, IEEE T PATTERN ANAL, V16, P267, DOI 10.1109/34.276126
   HOLST G, 1995, CCD ARRAYS CAMERAS D
   Horn B.K.P, 1986, Robot Vision
   Janesick J. R., 2001, SCI CHARGE COUPLED D
   Manders C, 2004, IEEE IMAGE PROC, P2965
   Ortiz A, 2004, FRONT ARTIF INTEL AP, V113, P201
   Ortiz A, 2004, IEEE INT CONF ROBOT, P4730, DOI 10.1109/ROBOT.2004.1302465
   Ortiz A, 2003, FR ART INT, V100, P199
   ORTIZ A, 2005, THESIS U BALEARIC IS
   ORTIZ A, 2005, A12005 U BAL ISL DEP
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Román-Roldán R, 2001, PATTERN RECOGN, V34, P969, DOI 10.1016/S0031-3203(00)00052-2
   Shafique K, 2004, IEEE IMAGE PROC, P2339
   TAREL JP, 1996, P 10 C AFCET REC FOR
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
NR 21
TC 8
Z9 8
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1137
EP 1145
DI 10.1016/j.imavis.2006.04.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300009
DA 2024-07-18
ER

PT J
AU Shimshoni, I
   Sasporta, A
AF Shimshoni, I
   Sasporta, A
TI Object recognition using point uncertainty regions as pose uncertainty
   regions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object recognition; uncertainty regions; pose estimation
ID IMAGE; LOCALIZATION; LOCATION; MODEL
AB In this paper, a recognition algorithm based on point features is presented. In this algorithm sets of hypothesized matches between model and image points are generated. From them the pose of the object is estimated and stored in a lookup table. When two similar poses are found the pose is assumed to be correct and the hypothesis is verified. The main contribution of this paper is that poses and their uncertainties are represented by the uncertainty regions of the projections of several 3D points, which are circles in the image. These uncertainty regions are due to the measurement uncertainty of the image features, which result in uncertainty in the recovered pose. When two poses are consistent, the pairs of uncertainty regions of the same 3D point will have a non-empty intersection. The algorithm exploits the fact that these uncertainty regions can be computed easily and accurately. The algorithm has been implemented and tested on real images. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Haifa, Dept Management Informat Syst, IL-31905 Haifa, Israel.
   Technion, Dept Ind Engn & Management, IL-32000 Haifa, Israel.
C3 University of Haifa; Technion Israel Institute of Technology
RP Univ Haifa, Dept Management Informat Syst, IL-31905 Haifa, Israel.
EM ishimshoni@mis.haifa.ac.il
OI Shimshoni, Ilan/0000-0002-5276-0242
CR ALTER TD, 1994, IEEE T PATTERN ANAL, V16, P802, DOI 10.1109/34.308475
   ALTER TD, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P892, DOI 10.1109/CVPR.1994.323920
   Austin WJ, 1998, COMPUT VIS IMAGE UND, V72, P304, DOI 10.1006/cviu.1997.0672
   BENARIE J, 1990, IEEE T PATTERN ANAL, V12, P760, DOI 10.1109/34.57667
   BINFORD TO, 1987, WORKSH UNC ART INT
   Breuel T. M., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P445, DOI 10.1109/CVPR.1992.223152
   BURNS JB, 1993, IEEE T PATTERN ANAL, V15, P51, DOI 10.1109/34.184774
   Cass T. A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P360, DOI 10.1109/ICCV.1990.139551
   David P, 2004, INT J COMPUT VISION, V59, P259, DOI 10.1023/B:VISI.0000025800.10423.1f
   Dellaert F, 2000, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2000.854916
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gold S, 1998, PATTERN RECOGN, V31, P1019, DOI 10.1016/S0031-3203(98)80010-1
   Häusler G, 1999, COMPUT VIS IMAGE UND, V73, P64, DOI 10.1006/cviu.1998.0704
   HORNEGGER J, 1995, ICCV, P914
   HUTTENLOCHER DP, 1990, INT J COMPUT VISION, V5, P195, DOI 10.1007/BF00054921
   Jurie F, 1999, COMPUT VIS IMAGE UND, V73, P357, DOI 10.1006/cviu.1998.0735
   Kyrki V, 2004, IEEE INT CONF ROBOT, P1861, DOI 10.1109/ROBOT.2004.1308095
   Lepetit V, 2004, PROC CVPR IEEE, P244
   OLSON CF, 1995, IEEE T PATTERN ANAL, V17, P518, DOI 10.1109/34.391391
   Shimshoni I, 1999, COMPUT VIS IMAGE UND, V74, P163, DOI 10.1006/cviu.1999.0755
   Shimshoni I, 2000, INT J COMPUT VISION, V36, P51, DOI 10.1023/A:1008172423811
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   STOCKMAN G, 1987, COMPUT VISION GRAPH, V40, P361, DOI 10.1016/S0734-189X(87)80147-0
   THOMPSON DW, 1987, IEEE J ROBOTIC AUTOM, P208
NR 24
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 192
EP 201
DI 10.1016/j.imavis.2005.11.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900009
DA 2024-07-18
ER

PT J
AU Long, X
   Cleveland, WL
   Yao, YL
AF Long, X
   Cleveland, WL
   Yao, YL
TI Effective automatic recognition of cultured cells in bright field images
   using fisher's linear discriminant preprocessing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE cell recognition; Fisher's linear discriminant; principal component
   analysis; neural networks
ID FLUORESCENCE MICROGRAPHS; SEGMENTATION; EIGENFACES; SYSTEM
AB Automatic cell recognition in bright field microscopy is an inherently difficult task due to the immense variability of cell appearance. Yet, it is essential for a high-throughput robotic system. In this paper, we employed a pixel patch decomposition method to detect cultured cells in bright field images. To increase the classification accuracy, we proposed a novel Fisher's Linear Discriminant (FLD) preprocessing approach. This technique was applied to various experimental scenarios utilizing different imaging environments and the results were compared with those for the traditional Principal Component Analysis (PCA) preprocessing. Our FLD preprocessing was shown to be more effective than PCA primarily owing to its ability to maximize the ratio of between-class scatter to within-class scatter. The optimized algorithm has sufficient accuracy and speed for practical use in robotic systems capable of automatic micromanipulation of single cells. (C) 2005 Elsevier Ltd All rights reserved.
C1 St Lukes Roosevelt Hosp, Dept Med, New York, NY 10019 USA.
   Columbia Univ, New York, NY 10019 USA.
   Columbia Univ, Dept Mech Engn, New York, NY 10027 USA.
C3 Mount Sinai St. Luke's; Mount Sinai West; Columbia University; Columbia
   University
RP St Lukes Roosevelt Hosp, Dept Med, New York, NY 10019 USA.
EM wlcl@columbia.edu
CR Baker S, 1996, PROC CVPR IEEE, P544, DOI 10.1109/CVPR.1996.517125
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213
   CLEVELAND WL, 1983, J IMMUNOL METHODS, V56, P221
   CONSTANTINOS G, 2003, CYTOM PART A, V55, P30
   CUI Y, 1995, INT C COMP VIS, P631
   Fok YL, 1996, IEEE T MED IMAGING, V15, P353, DOI 10.1109/42.500144
   KAMPFE T, 2001, LECT NOTES COMPUTER, V2191, P262
   Kelz M., 2002, Sci Aging Knowledge Environ
   Kovalev VA, 1996, PROC SPIE, V2710, P805, DOI 10.1117/12.237986
   Mitchell T. M., 1997, MACHINE LEARNING
   Moler C., 1973, SIAM J. Numer. Anal, V10, P99
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Nattkemper TW, 2003, COMPUT BIOL MED, V33, P31, DOI 10.1016/S0010-4825(02)00060-4
   Nattkemper TW, 2002, NEUROCOMPUTING, V48, P357, DOI 10.1016/S0925-2312(01)00642-7
   Nattkemper TW, 2001, IEEE T INF TECHNOL B, V5, P138, DOI 10.1109/4233.924804
   Pandya A.S., 1996, PATTERN RECOGNITION
   Sajda P, 2003, MED IMAGE ANAL, V7, P187, DOI 10.1016/S1361-8415(03)00003-3
   SHIGETOSHI S, 1994, JSME INT J C-DYN CON, V37, P202
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Sjöström PJ, 1999, CYTOMETRY, V36, P18
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Turk M., 1990, Proc. IAPR Workshop on Machine Vision Appkications, P267
NR 23
TC 16
Z9 20
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1203
EP 1213
DI 10.1016/j.imavis.2005.07.019
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500009
DA 2024-07-18
ER

PT J
AU Ghent, J
   McDonald, J
AF Ghent, J
   McDonald, J
TI Photo-realistic facial expression synthesis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image synthesis; facial expression shape model (FESM); facial expression
   texture model (FETM); radial basis function network (RBFN)
AB This paper details a procedure for generating a function which maps an image of a neutral face to one depicting a desired expression independent of age, sex, or skin colour. Facial expression synthesis is a growing and relatively new domain within computer vision. One of the fundamental problems when trying to produce accurate expression synthesis in previous approaches is the lack of a consistent method for measuring expression. This inhibits the generation of a universal mapping function. This paper advances this domain by the introduction of the Facial Expression Shape Model (FESM) and the Facial Expression Texture Model (FETM). These are statistical models of facial expression based on anatomical analysis of expression called the Facial Action Coding System (FACS). The FESM and the FETM allow for the generation of a universal mapping function. These models provide a robust means for upholding the rules of the FACS and are flexible enough to describe subjects that are not present during the training phase. We use these models in conjunction with several Artificial Neural Networks (ANN) to generate photo-realistic images of facial expressions. (c) 2005 Elsevier Ltd. All rights reserved.
C1 Natl Univ Ireland Maynooth, Dept Comp Sci, Maynooth, Kildare, Ireland.
C3 Maynooth University
RP Natl Univ Ireland Maynooth, Dept Comp Sci, Maynooth, Kildare, Ireland.
EM jghent@cs.may.ie
OI McDonald, John/0000-0001-9225-673X
CR ABBOUD B, 2004, IMAGE COMMUNICATION
   [Anonymous], STAT MODELS APPEARAN
   ARAD N, 1994, CVGIP-GRAPH MODEL IM, V56, P161, DOI 10.1006/cgip.1994.1015
   BALKE A, 1998, ACTIVE CONTOURS APPL
   Beinglass A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P461, DOI 10.1109/CVPR.1991.139736
   Birdwhistell R.L., 1970, Kinesics and Context
   BOZMA HI, 1991, P 12 INT C INF PROC, P358
   BRUCE V, 1986, BRIT J PSYCHOL, V77, P305, DOI 10.1111/j.2044-8295.1986.tb02199.x
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Choe B, 2001, COMP ANIM CONF PROC, P12, DOI 10.1109/CA.2001.982372
   COHN J, 1999, C KANADE AU CODED FA
   Du YZ, 2003, PATTERN RECOGN LETT, V24, P2923, DOI 10.1016/S0167-8655(03)00153-3
   Faigan G., 1990, ARTISTS GUIDE FACIAL
   GHENT J, 2003, P IR MACH VIS IM PRC
   GHENT J, 2004, NUIMCSTR200401
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   GRALEWSKI L, 2004, INT C COMP SCI, P190
   Grimson W., 1990, OBJECT RECOGNITION C
   HIETANEN JK, 1992, EXP BRAIN RES, V89, P157
   HILL A, 1992, IMAGE VISION COMPUT, V10, P295, DOI 10.1016/0262-8856(92)90045-5
   HINTON GE, 1992, ADV NEURAL INFORAMTI, P4
   KING I, 1996, ICONIP 96
   KOBAYASHI H, 1992, IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN COMMUNICATION : PROCEEDINGS, P381
   KRINDIS S, 2003, P 10 INT C HUM COMP, P1432
   Landis C, 1924, J COMP PSYCHOL, V4, P447, DOI 10.1037/h0073039
   LISPON P, 1990, LECT NOTES COMPUTER, P413
   Moody J, 1989, NEURAL COMPUT, V1, P281, DOI 10.1162/neco.1989.1.2.281
   POWELL JD, 1986, RADIAL BASIS FUNCTIO
   Principe J. C., 1999, Neural and adaptive systems
   Raouzaiou A, 2002, EURASIP J APPL SIG P, V2002, P1021, DOI 10.1155/S1110865702206149
   RHODES G, 1993, COGNITION, V47, P25, DOI 10.1016/0010-0277(93)90061-Y
   Staib L.H., 1989, IEEE Computer Society Conference on Computer Vision and Pattern Recognition, San Diego, P427
   Vernon D., 1991, Machine vision-Automated visual inspection and robot vision
   WANG H, 2004, FACE EXPRESSION DECO
   YOUNG G, 1941, ARCH PSYCHOL, V37
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   ZHANG Q, 2003, SIGGRAPH S COMP AN
NR 37
TC 10
Z9 20
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2005
VL 23
IS 12
BP 1041
EP 1050
DI 10.1016/j.imavis.2005.06.011
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 971ZK
UT WOS:000232423400002
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sengel, M
   Bischof, H
AF Sengel, M
   Bischof, H
TI Efficient representation of in-plane rotation within a PCA framework
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE appearance based recognition; principle component analysis; pose
   estimation
ID RECOGNITION
AB In this paper, we derive an analytic representation of the eigenvectors and coefficients for in-plane rotated images. This, on the one hand, allows an efficient PCA-basis calculation in the learning stage and on the other hand a direct computation of the rotation angle in the recognition stage. In the experimental section, we demonstrate that the new method is feasible and the recognition and out-of-plane results are comparable to the standard method. (c) 2005 Elsevier Ltd. All rights reserved.
C1 Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria.
C3 Graz University of Technology
RP Graz Univ Technol, Inst Comp Graph & Vis, Inffeldgasse 16 2OG, A-8010 Graz, Austria.
EM sengel@icg.tu-graz.ac.at; xbischof@icg.tu-graz.ac.at
OI Bischof, Horst/0000-0002-9096-6671
CR Bischof H, 1998, PROC CVPR IEEE, P664, DOI 10.1109/CVPR.1998.698675
   DEVERDIERE VC, 1998, EUR C COMP VIS ECCV, P640
   JOGAN M, 2001, ICAR 2001 OMN VIS AP, P31
   Kreyszig E., 1993, ADV ENG MATH
   Krumm J, 1996, PROC CVPR IEEE, P55, DOI 10.1109/CVPR.1996.517053
   Leonardis A, 2000, COMPUT VIS IMAGE UND, V78, P99, DOI 10.1006/cviu.1999.0830
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   MURASE H, 1995, P 9 SCAND C IM AN, P323
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Uenohara M, 1998, IEEE T IMAGE PROCESS, V7, P116, DOI 10.1109/83.650856
NR 11
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2005
VL 23
IS 12
BP 1051
EP 1059
DI 10.1016/j.imavis.2005.07.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 971ZK
UT WOS:000232423400003
DA 2024-07-18
ER

PT J
AU Chung, AJ
   Deligianni, F
   Hu, XP
   Yang, GZ
AF Chung, AJ
   Deligianni, F
   Hu, XP
   Yang, GZ
TI Extraction of visual features with eye tracking for saliency driven
   2D/3D registration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 2D/3D registration; saliency; image correlation; eye tracking
ID IMAGE REGISTRATION; SIMILARITY; ATTENTION; MODELS
AB This paper presents a new technique for deriving information on visual saliency with experimental eye-tracking data. The strength and potential pitfalls of the method are demonstrated with feature correspondence for 2D to 3D image registration. With this application, an eye-tracking system is employed to determine which features in endoscopy video images are considered to be salient from a group of human observers. By using this information, a biologically inspired saliency map is derived by transforming each observed video image into a feature space representation. Features related to visual attention are determined by using a feature normalisation process based on the relative abundance of image features within the background image and those dwelled on visual search scan paths. These features are then back-projected to the image domain to determine spatial area of interest for each unseen endoscopy video image. The derived saliency map is employed to provide an image similarity measure that forms the heart of a new 2D/3D registration method with much reduced rendering overhead by only processing-selective regions of interest as determined by the saliency map. Significant improvements in pose estimation efficiency are achieved without apparent reduction in registration accuracy when compared to that of using an intensity-based similarity measure. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ London Imperial Coll Sci & Technol, Dept Commun, Royal Soc, Wolfson Fdn Med Image Comp Lab, London SW7 2BZ, England.
C3 Imperial College London
RP Univ London Imperial Coll Sci & Technol, Dept Commun, Royal Soc, Wolfson Fdn Med Image Comp Lab, 180 Queens Gate, London SW7 2BZ, England.
EM a.chung@imperial.ac.uk
RI Deligianni, Fani/M-9116-2018
OI Deligianni, Fani/0000-0003-1306-5017
CR [Anonymous], INT J COMPUTER VISIO
   Ayoub AF, 1998, BRIT J ORAL MAX SURG, V36, P353, DOI 10.1016/S0266-4356(98)90646-5
   Clarkson MJ, 2001, IEEE T PATTERN ANAL, V23, P1266, DOI 10.1109/34.969117
   Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191
   Deguchi D, 2003, INT CONGR SER, V1256, P460, DOI 10.1016/S0531-5131(03)00331-5
   Dey D, 2002, IEEE T MED IMAGING, V21, P23, DOI 10.1109/42.981231
   Dey D, 2000, LECT NOTES COMPUT SC, V1935, P796
   Einhäuser W, 2003, EUR J NEUROSCI, V17, P1089, DOI 10.1046/j.1460-9568.2003.02508.x
   FAISAL AA, 1998, OBSERVATION HUMAN EY
   Frantz DD, 2003, PHYS MED BIOL, V48, P2241, DOI 10.1088/0031-9155/48/14/314
   GIELES P, MED MUNDI, V40
   HELFERTY JP, 2001, IEEE INT C IM PROC
   Hill DLG, 2001, PHYS MED BIOL, V46, pR1, DOI 10.1088/0031-9155/46/3/201
   HU XP, IN PRESS IEEE T MED
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   ITTI L, 1999, SPIE HUMAN VISION 4, V3644, P373
   JAGERSAND M, 1993, SALIENCY MAPS ATTENT
   JOSKOWICZ L, J COMPUTER AIDED SUR, V3
   JOSKOWICZ L, 2000, P IFAC C MECH SYST D
   Leventon ME, 1998, LECT NOTES COMPUT SC, V1496, P1057, DOI 10.1007/BFb0056295
   Mack MJ, 2001, JAMA-J AM MED ASSOC, V285, P568, DOI 10.1001/jama.285.5.568
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   Mori K, 2002, MED IMAGE ANAL, V6, P321, DOI 10.1016/S1361-8415(02)00089-0
   Mori K, 2000, PROC SPIE, V3978, P134, DOI 10.1117/12.383392
   Penney GP, 1998, LECT NOTES COMPUT SC, V1496, P1153, DOI 10.1007/BFb0056305
   Petkov N, 1997, BIOL CYBERN, V76, P83, DOI 10.1007/s004220050323
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Roche A, 1998, LECT NOTES COMPUT SC, V1496, P1115, DOI 10.1007/BFb0056301
   Shokoufandeh A, 1999, IMAGE VISION COMPUT, V17, P445, DOI 10.1016/S0262-8856(98)00124-3
   TENDICK F, 1999, FINAL REPORT TECHNIC, pCH3
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   TSOTSOS JK, 1995, ARTIF INTELL, V78, P507, DOI 10.1016/0004-3702(95)00025-9
   Wagner D, 2002, WSCG'2002, VOLS I AND II, CONFERENCE PROCEEDINGS, P493
   WHITTED T, 1979, COMPUTER GRAPHICS SP, V13, P1
   Yang GZ, 2002, IMAGE VISION COMPUT, V20, P291, DOI 10.1016/S0262-8856(02)00022-7
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 36
TC 8
Z9 12
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2005
VL 23
IS 11
BP 999
EP 1008
DI 10.1016/j.imavis.2005.07.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 973KF
UT WOS:000232520600006
DA 2024-07-18
ER

PT J
AU Zhang, DS
   Lu, GJ
AF Zhang, DS
   Lu, GJ
TI Study and evaluation of different Fourier methods for image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CBIR; shape; Fourier descriptor; retrieval
ID DESCRIPTORS; RECOGNITION; OBJECTS; REPRESENTATION; CONTOURS; MOMENTS
AB Shape is one of the primary low-level image features exploited in the newly emerged content-based image retrieval (CBIR). Many shape methods exist. Among these shape methods, Fourier descriptor (FD) is one of the most widely used shape descriptors due to its simple computation, clarity and coarse to fine description capability. FD has been applied to a variety of applications, including image retrieval application. Generally, FD can be acquired in a number of ways, however, FD acquired from different ways can have different retrieval performance. In this paper, we study shape retrieval using FD. Specifically, we study different ways of acquiring FD, the number of FD features needed for general shape description and the retrieval performance of different FD. A Java client-server retrieval framework has been developed to facilitate the study. The retrieval performance of the different FD is tested using a standard shape database and a commonly used performance measurement. (C) 2004 Elsevier B.V. All rights reserved.
C1 Monash Univ, Gippsland Sch Comp & Informat Technol, Churchill, Vic 3842, Australia.
C3 Federation University Australia; Monash University
RP Monash Univ, Gippsland Sch Comp & Informat Technol, Churchill, Vic 3842, Australia.
EM dengsheng.zhang@infotech.monash.edu.au; guojun.lu@infotech.monash.edu.au
RI Rohlf, F J/A-8710-2008; Zhang, Dengsheng/W-8467-2019
OI Zhang, Dengsheng/0000-0001-8728-1746; Lu, Guojun/0000-0003-2523-7576
CR Abbasi S, 1999, MULTIMEDIA SYST, V7, P467, DOI 10.1007/s005300050147
   Abbasi S, 2000, IMAGE VISION COMPUT, V18, P199, DOI 10.1016/S0262-8856(99)00019-0
   [Anonymous], GEOMETRIC METHODS CO
   Arbter K., 1989, From Pixels to Features. Proceedings of a Workshop, P153
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   Berretti S, 2000, IEEE T MULTIMEDIA, V2, P225, DOI 10.1109/6046.890058
   Beyer K., 1999, Proceedings of the 7th International Conference on Database Theory, ICDT'99, DOI [10.1007/3-540-49257-7_15, DOI 10.1007/3-540-49257-7_15]
   CHAKRABARTI K, 2000, P IEEE INT C MULT EX
   CHELLAPPA R, 1984, IEEE T PATTERN ANAL, V6, P102, DOI 10.1109/TPAMI.1984.4767482
   Davies E.R., 1997, MACHINE VISION THEOR, P171
   DELBIMBO A, 1999, VISUAL INFORMATION R, P566
   EICHMANN G, 1990, SPIE HYBRID IMAGE 2, V1297, P86
   Glassner A. S., 1995, Principles of Digital Image Synthesis
   GRANLUND GH, 1972, IEEE T COMPUT, VC 21, P195, DOI 10.1109/TC.1972.5008926
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huang CL, 1998, IMAGE VISION COMPUT, V16, P149, DOI 10.1016/S0262-8856(97)00062-0
   KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390
   KAUPPINEN H, 1995, IEEE T PATTERN ANAL, V17, P201, DOI 10.1109/34.368168
   Kim WY, 2000, SIGNAL PROCESS-IMAGE, V16, P95, DOI 10.1016/S0923-5965(00)00019-9
   LI SZ, 1999, SHAPE ANAL PROGR NEU, V6, P203
   Lu GJ, 1999, MULTIMEDIA SYST, V7, P165, DOI 10.1007/s005300050119
   MARIN FJS, 2000, ARTIF INTELL MED, V18, P173
   MEHROTRA R, 1995, IEEE COMPUTER    SEP, P57
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   Mokhtarian F., 1996, BRIT MACHINE VISION, P53
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029
   Pavlidis T., 1982, Algorithms for Graphics and Image Processing, P143
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   Rauber T.W., 1994, UNINOVART1094 GR U N
   RICHARD CW, 1974, IEEE T SYST MAN CYB, VSMC4, P371, DOI 10.1109/TSMC.1974.5408458
   SAFAR M, 2000, P IEEE INT C MULT EX
   SAJJANHAR A, 1997, THESIS MONACH U AUST
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   TIENG QM, 1997, IEEE T PAMI      AUG, P19
   Van Otterloo P.J., 1991, A contour-oriented approach to shape analysis, P90
   Weber R., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P194
   Yang HS, 1998, J VIS COMMUN IMAGE R, V9, P171, DOI 10.1006/jvci.1998.0384
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   ZHANG DS, 2001, P 2 IEEE PAC RIM C M, P855
NR 40
TC 159
Z9 195
U1 0
U2 17
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2005
VL 23
IS 1
BP 33
EP 49
DI 10.1016/j.imavis.2004.09.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 882BO
UT WOS:000225913700004
DA 2024-07-18
ER

PT J
AU Ringer, M
   Lasenby, J
AF Ringer, M
   Lasenby, J
TI A procedure for automatically estimating model parameters in optical
   motion capture
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE optical motion capture; training sequence; computed tomography
ID MARKOV-CHAINS; ASSIGNMENT
AB Model-based optical motion capture systems require knowledge of the position of the markers relative to the underlying skeleton, the lengths of the skeleton's limbs, and which limb each marker is attached to. These model parameters are typically assumed and entered into the system manually, although techniques exist for calculating some of them, such as the position of the markers relative to the skeleton's joints.
   We present a fully automatic procedure for determining these model parameters. It tracks the 2D positions of the markers on the cameras' image planes and determines which markers lie on each limb before calculating the position of the underlying skeleton. The only assumption is that the skeleton consists of rigid limbs connected with ball joints. The proposed system is demonstrated on a number of real data examples and is shown to calculate good estimates of the model parameters in each. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
C3 University of Cambridge
RP Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
EM mar39@eng.cam.ac.uk; jl@eng.cam.ac.uk
OI Lasenby, Joan/0000-0002-0571-0218
CR [Anonymous], FITTING CIRCLES ELLI
   BERTSEKAS DP, 1990, INTERFACES, V20, P133, DOI 10.1287/inte.20.4.133
   Blackman S., 1999, Design and analysis of modern tracking systems
   DAVIS RB, 1991, HUM MOVEMENT SCI, V10, P575, DOI 10.1016/0167-9457(91)90046-Z
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   GAMAGE S, 2001, CUEDFINFENGTR408 CAM
   GAVRILA DM, 1996, P C COMP VIS PATT RE
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97
   HERDA L, 2000, P COMP AN IEEE
   Lasenby J, 1998, INT J COMPUT VISION, V26, P191, DOI 10.1023/A:1007901028047
   Menache Alberto, 2000, Understanding motion capture for computer animation and video games
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   O'Brien JF, 2000, PROC GRAPH INTERF, P53
   POORE AB, 1994, DIMACS SERIES DISCRE, V16, P317
   Ringer M., 2000, BMV2000. Proceedings of the 11th British Machine Vision Conference, P172
   RINGER M, 2002, P EUR C COMP VIS ECC
   Silaghi MC, 1998, LECT NOTES ARTIF INT, V1537, P26
   Stoddart A.J., 1999, P 10 BRIT MACH VIS C
   TIERNEY L, 1994, ANN STAT, V22, P1701, DOI 10.1214/aos/1176325750
NR 19
TC 10
Z9 14
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 843
EP 850
DI 10.1016/j.imavis.2004.02.011
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300012
DA 2024-07-18
ER

PT J
AU Mitchell, PE
   Yan, H
AF Mitchell, PE
   Yan, H
TI Newspaper layout analysis incorporating connected component separation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE document analysis; image segmentation; newspaper segmentation
ID DOCUMENT IMAGE-ANALYSIS; PAGE SEGMENTATION
AB This paper presents an algorithm that performs automated segmentation and classification of newspaper images. A notable feature of the algorithm is a technique for segmenting components that are connected to other components. In particular, horizontal lines and vertical lines, which can be vital in determining the page layout, can be segmented from other lines and other components. The algorithm uses a bottom-up approach to initially segment the image, classify patterns and extract text lines. The classified patterns are then merged into complete regions. The algorithm is tested on a set of complex English and Greek newspaper images dating back to 1900. (C) 2003 Published by Elsevier B.V.
C1 Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
   City Univ Hong Kong, Dept Comp Engn & Informat Technol, Kowloon, Hong Kong, Peoples R China.
C3 University of Sydney; City University of Hong Kong
RP Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
EM mitchell@ee.usyd.edu.au
OI YAN, Hong/0000-0001-9661-3095
CR Antonacopoulos A, 1998, COMPUT VIS IMAGE UND, V70, P350, DOI 10.1006/cviu.1998.0691
   Fei Liu, 2001, Proceedings of Sixth International Conference on Document Analysis and Recognition, P1176, DOI 10.1109/ICDAR.2001.953970
   Gatos B, 2001, PROC INT CONF DOC, P1147, DOI 10.1109/ICDAR.2001.953965
   Hadjar K, 2001, PROC INT CONF DOC, P1186, DOI 10.1109/ICDAR.2001.953972
   Kavallieratou E, 2002, IMAGE VISION COMPUT, V20, P813, DOI 10.1016/S0262-8856(02)00091-4
   Kise K., 1998, Systems and Computers in Japan, V29, P59, DOI 10.1002/(SICI)1520-684X(199803)29:3<59::AID-SCJ6>3.0.CO;2-O
   Kwag HK, 2002, IMAGE VISION COMPUT, V20, P25, DOI 10.1016/S0262-8856(01)00071-3
   Liu JM, 1997, PATTERN RECOGN, V30, P1265, DOI 10.1016/S0031-3203(96)00165-3
   Mitchell PE, 2001, PROC INT CONF DOC, P1181, DOI 10.1109/ICDAR.2001.953971
   Mitchell PE, 2000, OPT ENG, V39, P724, DOI 10.1117/1.602419
   Mitchell PE, 2000, INT C PATT RECOG, P458, DOI 10.1109/ICPR.2000.905375
   Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820
   Phillips IT, 1999, IEEE T PATTERN ANAL, V21, P849, DOI 10.1109/34.790427
   Strouthopoulos C, 1998, IMAGE VISION COMPUT, V16, P879, DOI 10.1016/S0262-8856(98)00055-9
   Tang YY, 1996, PATTERN RECOGN, V29, P1931, DOI 10.1016/S0031-3203(96)00044-1
   Tseng YH, 1999, PATTERN RECOGN LETT, V20, P791, DOI 10.1016/S0167-8655(99)00043-4
   Xi J, 2002, PATTERN RECOGN, V35, P2695, DOI 10.1016/S0031-3203(01)00248-5
   Xiao Y, 2003, PATTERN RECOGN, V36, P799, DOI 10.1016/S0031-3203(02)00082-1
   YAN H, 1993, CVGIP-GRAPH MODEL IM, V55, P538, DOI 10.1006/cgip.1993.1041
   Yin PY, 2001, IMAGE VISION COMPUT, V19, P567, DOI 10.1016/S0262-8856(00)00098-6
NR 20
TC 7
Z9 8
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2004
VL 22
IS 4
BP 307
EP 317
DI 10.1016/j.imavis.2003.11.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 778FW
UT WOS:000189229700004
DA 2024-07-18
ER

PT J
AU Laptev, I
   Lindeberg, T
AF Laptev, I
   Lindeberg, T
TI Velocity adaptation of spatio-temporal receptive fields for direct
   recognition of activities: an experimental study
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Statistical Methods in Video Processing
CY JUN 01-02, 2002
CL COPENHAGEN, DENMARK
DE motion; spatio-temporal filtering; scale-space; recognition
ID SCALE-SPACE; AFFINE; SHAPE
AB This article presents an experimental study of the influence of velocity adaptation when recognizing spatio-temporal patterns using a histogram-based statistical framework. The basic idea consists of adapting the shapes of the filter kernels to the local direction of motion, so as to allow the computation of image descriptors that are invariant to the relative motion in the image plane between the camera and the objects or events that are studied. Based on a framework of recursive spatio-temporal scale-space, we first outline how a straightforward mechanism for local velocity adaptation can be expressed. Then, for a test problem of recognizing activities, we present an experimental evaluation, which shows the advantages of using velocity-adapted spatio-temporal receptive fields, compared to directional derivatives or regular partial derivatives for which the filter kernels have not been adapted to the local image motion. (C) 2003 Elsevier B.V. All rights reserved.
C1 KTH, Dept Numer Anal & Comp Sci, Computat Vis & Act Percept Lab, SE-10044 Stockholm, Sweden.
C3 Royal Institute of Technology
RP KTH, Dept Numer Anal & Comp Sci, Computat Vis & Act Percept Lab, SE-10044 Stockholm, Sweden.
EM laptev@nada.kth.se; tony@nada.kth.se
RI Lindeberg, Tony/G-3580-2011
OI Lindeberg, Tony/0000-0002-9081-2170
CR ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   Almansa A, 2000, IEEE T IMAGE PROCESS, V9, P2027, DOI 10.1109/83.887971
   [Anonymous], 1996, SPRINGER LNCS, DOI DOI 10.1007/BFB0015539
   [Anonymous], 1964, APPL MATH SERIES
   Ballester C, 1998, J MATH IMAGING VIS, V9, P141, DOI 10.1023/A:1008337710072
   BLACK M, 2004, LECT NOTES COMPUTER, V801, P138
   Chomat O, 2000, LECT NOTES COMPUT SC, V1842, P117
   CHOMAT O, 2000, P 6 EUR C COMP VIS D, pI487
   DEANGELIS GC, 1995, TRENDS NEUROSCI, V18, P451, DOI 10.1016/0166-2236(95)94496-R
   Florack L, 1998, INT J COMPUT VISION, V27, P263, DOI 10.1023/A:1007922215235
   Florack LMJ., 1997, SERIES MATH IMAGING, DOI DOI 10.1007/978-94-015-8845-4
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Guichard F, 1998, IEEE T IMAGE PROCESS, V7, P444, DOI 10.1109/83.661194
   Hall D, 2000, LECT NOTES COMPUT SC, V1842, P164
   HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568
   IRANI M, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P605, DOI 10.1109/ICCV.1995.466883
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   KOENDERINK JJ, 1988, BIOL CYBERN, V58, P159, DOI 10.1007/BF00364135
   Lindeberg T, 2002, LECT NOTES COMPUT SC, V2350, P52
   Lindeberg T, 1997, LECT NOTES COMPUT SC, V1252, P113
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lindeberg T., 1994, The Kluwer International Series in Engineering and Computer Science
   Lindeberg T., 1997, LECT NOTES COMPUTER, V1315, P94
   LINDEBERG T, 1994, P 3 EUR C C VIS STOC, pA389
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   NAGEL H, 1998, P 5 EUR C COMP VIS F, pII86
   Schaffalitzky F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P636, DOI 10.1109/ICCV.2001.937686
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   ZELNIKMANOR L, 2001, P COMP VIS PATT REC, pII123
NR 33
TC 20
Z9 21
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2004
VL 22
IS 2
BP 105
EP 116
DI 10.1016/j.imavis.2003.07.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 769DW
UT WOS:000188612000004
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Cibelli, M
   Nappi, M
   Tucci, M
AF Cibelli, M
   Nappi, M
   Tucci, M
TI ABI: analogy-based indexing for content image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE content image retrieval; visual analogy
ID OBJECT RECOGNITION; REPRESENTATION
AB Morphogeometric-based metrics are not always appropriate to describe high-level contents of images as well as to formulate complex queries. People often find that two pictures as similar because they share relational predicates rather than objects attributes. In particular, images can be related because they are analogous. Scientists, for example, use analogies to trace art influences across different paints. In this paper, we focus on analogous relationships between groups of objects. The model we propose combines primitive properties by mean of a logical reasoning engine to produce a hierarchical image description. Each picture is decomposed into its spatial relations (physical layer), cognitive relations between objects within a group (group layer), and relations between groups (meta-group layer). This new Analogy Based Indexing (ABI for short) for Content Image Retrieval, allows users to express complex queries such as search for functional associations or group membership relations. A proof-of-concept prototype is also discussed to verify the precision and the efficiency of the proposed system. Furthermore, an embedded visual language enables pictorial queries composition and simplifies image annotation. The experimental results show the effectiveness of ABI in terms of precision vs. recall curve diagrams. (C) 2003 Elsevier B.V. All rights reserved.
C1 Microsoft Corp, MDD USA, Redmond, WA 98052 USA.
   Univ Salerno, Dipartimento Matemat & Informat, I-84081 Baronissi, Salerno, Italy.
C3 Microsoft; University of Salerno
RP Microsoft Corp, MDD USA, 1 Microsoft Way, Redmond, WA 98052 USA.
EM mcibelli@microsoft.com; mnappi@unisa.it; mtucci@microsoft.com
RI Nappi, Michele/X-3089-2019
OI Nappi, Michele/0000-0002-2517-2867
CR Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   Cibelli M, 2000, J VISUAL LANG COMPUT, V11, P573, DOI 10.1006/jvlc.2000.0171
   Eakins J.P., 1996, Proceedings of Third International Conference on Electronic Library and Visual Information Research e, V3, P123
   Eakins JohnP., 1998, Techniques for Image Retrieval (Library and Information Briefings 85)
   Edelman S, 1997, PHILOS T R SOC B, V352, P1191, DOI 10.1098/rstb.1997.0102
   Edelman S, 1997, NEURAL COMPUT, V9, P701, DOI 10.1162/neco.1997.9.4.701
   ENSER PGB, 1995, J DOC, V51, P126, DOI 10.1108/eb026946
   Faloutsos C., 1994, Journal of Intelligent Information Systems: Integrating Artificial Intelligence and Database Technologies, V3, P231, DOI 10.1007/BF00962238
   Feder J., 1996, Advanced Imaging, V11, P26
   Feldman J, 1997, COMPUT INTELL, V13, P582, DOI 10.1111/0824-7935.00052
   Feldman J, 1999, ACTA PSYCHOL, V102, P137, DOI 10.1016/S0001-6918(98)00054-7
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Gentner D, 1997, AM PSYCHOL, V52, P45, DOI 10.1037/0003-066X.52.1.45
   GEVERS T, 1997, IMAGE DATABASES MULT, P25
   Goldstone RL, 1998, SCI PSYCH S, P283
   GRIMSON WEL, 1990, ARTIF INTELL, V44, P121, DOI 10.1016/0004-3702(90)90100-E
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   Hermes T., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P394, DOI 10.1117/12.205310
   HOFSTADTER DR, 1996, FLUID CONCEPT CREATI
   HUANG T, 1997, DIGITAL IMAGE ACCESS, P101
   JACOBS D, 1987, IEEE WORKSH COMP VIS, P164
   KATO T, 1990, P INT C DAT EXP SYST, P234
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   MINKA T, 1996, 365 MIT
   NASTAR C, 1998, ACM MULTIMEDIA 98
   OGLE VE, 1995, COMPUTER, V28, P40, DOI 10.1109/2.410150
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Ravela S, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P82, DOI 10.1109/ACV.1998.732862
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   ROSH E, 1998, READING COGNITIVE SC, P312
   SALTON G, 1983, INTRO MODERN INFORMA
   SCHLUTER D, 1998, P DAGM S SPRING BERL, P393
   SCLAROFF S, IMAGE DATABASE USED
   SCLAROFF S, 1997, PATTERN RECOGNITION, V30
   Smith J., 1997, International Food Ingredients, P23
   Wactlar HD, 1996, COMPUTER, V29, P46, DOI 10.1109/2.493456
NR 37
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2004
VL 22
IS 1
BP 23
EP 34
DI 10.1016/j.imavis.2003.07.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 763BB
UT WOS:000188048400004
DA 2024-07-18
ER

PT J
AU Paclík, P
   Duin, RPW
   van Kempen, GMP
   Kohlus, R
AF Paclík, P
   Duin, RPW
   van Kempen, GMP
   Kohlus, R
TI Segmentation of multi-spectral images using the combined classifier
   approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multi-spectral imaging; image segmentation; classifier combination
ID PROBABILISTIC RELAXATION
AB Segmentation methods, combining spectral and spatial information, are essential for analysis of multi-spectral images. In this article, we propose such a method based on statistical pattern recognition algorithms and a combined classifier approach. A set of experiments is presented with multi-spectral images of detergent laundry powders acquired by imaging cross-sections with scanning electron microscopy using energy-dispersive X-ray microanalysis (SEM/EDX). The algorithm stability and the segmentation quality are investigated. The use of a priori information for the segmentation of images with similar spectral properties is studied as well. Finally, a comparison with probabilistic relaxation method for multi-spectral image segmentation is made. (C) 2003 Published by Elsevier Science B.V.
C1 Delft Univ Technol, Pattern Recognit Grp, Fac Sci Appl, NL-2628 CJ Delft, Netherlands.
   Unilever Res Vlaardingen, NL-3130 AC Vlaardingen, Netherlands.
C3 Delft University of Technology; Unilever
RP Paclík, P (corresponding author), Delft Univ Technol, Pattern Recognit Grp, POB 5046, NL-2600 GA Delft, Netherlands.
CR CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565
   DUIN RPW, 1998, LECT NOTES COMPUTER, V1451, P611
   EKLUNDH JO, 1980, IEEE T PATTERN ANAL, V2, P72, DOI 10.1109/TPAMI.1980.4766973
   FU KS, 1981, PATTERN RECOGN, V13, P3, DOI 10.1016/0031-3203(81)90028-5
   GOLDSTEIN J, 1992, SCANNING ELECT ICROS
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   Hauta-Kasari M, 1999, PATTERN ANAL APPL, V2, P275, DOI 10.1007/s100440050036
   HSIAO JY, 1989, IEEE T PATTERN ANAL, V11, P1279, DOI 10.1109/34.41366
   HUNTSBERGER TL, 1985, PATTERN RECOGN, V18, P131, DOI 10.1016/0031-3203(85)90036-6
   ISMAIL MA, 1989, PATTERN RECOGN, V22, P75, DOI 10.1016/0031-3203(89)90040-X
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   LAMBERT P, 2000, INT C COL GRAPH IM P
   MATAS J, 1995, P 6 INT C COMP AN IM, P162
   Paclik P., 2001, Proceedings of 12th Scandinavian Conference on Image Analysis, P230
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Skarbek W., 1994, Colour image segmentation - A survey
   SPANN M, 1985, PATTERN RECOGN, V18, P257, DOI 10.1016/0031-3203(85)90051-2
   Stoddart AJ, 1998, J MATH IMAGING VIS, V9, P29, DOI 10.1023/A:1008218126123
NR 18
TC 33
Z9 37
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2003
VL 21
IS 6
BP 473
EP 482
DI 10.1016/S0262-8856(03)00013-1
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 688BA
UT WOS:000183411300001
DA 2024-07-18
ER

PT J
AU Das, SK
   Namasudra, S
   Kumar, A
   Moparthi, NR
AF Das, Sujit Kumar
   Namasudra, Suyel
   Kumar, Awnish
   Moparthi, Nageswara Rao
TI AESPNet: Attention Enhanced Stacked Parallel Network to improve
   automatic Diabetic Foot Ulcer identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image Classification; Convolutional Neural Network; Attention Module;
   Medical Image
AB Diabetic Foot Ulcer (DFU) is a severe complication of diabetes, and it may cause lower limb amputation. However, the manual diagnosis of DFU is a complicated and expensive process. The primary objective of this work is to design an efficient Convolutional Neural Network (CNN) approach to identify DFU. Therefore, a novel CNN-based approach (AESPNet) is proposed in this paper, where convolution layers are stacked together in a parallel fashion and with an intermediate attention module to perform DFU vs -normal skin classification. The AESPNet consists of 2 blocks, where varying-sized kernel convolution layers are connected in a parallel fashion for better local and global feature abstraction. A bottleneck attention module is associated after every concatenation operation in the network. The Stochastic Gradient Descent (SGD) (with momentum) optimizer with 1e -2 learning rate is used to train the proposed network on a privately accessed DFU dataset. The results of the proposed approach are compared with other standard CNN-based schemes, namely AlexNet, VGG16, DenseNet121, and InceptionV3. It has been found that the proposed AESPNet outperforms state-of-the-art schemes with a sensitivity score of 98.44% and 0.98 F1-Scores.
C1 [Das, Sujit Kumar] Siksha O Anusandhan Univ, Dept Comp Sci & Engn, ITER, Bhubaneswar, Odisha, India.
   [Namasudra, Suyel; Kumar, Awnish] Natl Inst Technol Agartala, Dept Comp Sci & Engn, Agartala, Tripura, India.
   [Moparthi, Nageswara Rao] Koneru Lashmaiah Educ Fdn, Dept CSE, Vaddeswaram, Andra Pradesh, India.
C3 Siksha 'O' Anusandhan University; National Institute of Technology (NIT
   System); National Institute of Technology Agartala; Koneru Lakshmaiah
   Education Foundation (K L Deemed to be University)
RP Namasudra, S (corresponding author), Natl Inst Technol Agartala, Dept Comp Sci & Engn, Agartala, Tripura, India.; Moparthi, NR (corresponding author), Koneru Lashmaiah Educ Fdn, Dept CSE, Vaddeswaram, Andra Pradesh, India.
EM suyelnamasudra@gmail.com; mnrphd@gmail.com
RI Moparthi, Nageswara Rao/V-8130-2017
OI Moparthi, Nageswara Rao/0000-0001-6406-4554; Das, Dr. Sujit
   Kumar/0000-0002-7807-1461
CR Abadi M., 2016, arXiv, DOI DOI 10.48550/ARXIV.1603.04467
   Ahsan M, 2023, INFORMATION, V14, DOI 10.3390/info14010036
   Ai LM, 2022, PHYS ENG SCI MED, V45, P1175, DOI 10.1007/s13246-022-01185-5
   Al-Khateeb Belal, 2023, EXPERT SYST, DOI DOI 10.1111/exsy.13327
   Hernandez-Contreras DA, 2019, IEEE ACCESS, V7, P161296, DOI 10.1109/ACCESS.2019.2951356
   Alshayeji MH, 2023, BIOMED SIGNAL PROCES, V79, DOI 10.1016/j.bspc.2022.104143
   Alzubaidi L, 2021, J ENG SCI TECHNOL, V16, P2001
   Alzubaidi L, 2020, MULTIMED TOOLS APPL, V79, P15655, DOI 10.1007/s11042-019-07820-w
   Bhatia Surbhi, 2023, Innovations in Artificial Intelligence and Human-Computer Interaction in the Digital Era
   Cassidy B, 2021, Arxiv, DOI arXiv:2004.11853
   Cassidy Bill, 2021, arXiv
   Chen CM, 2023, CMES-COMP MODEL ENG, V137, P733, DOI 10.32604/cmes.2023.027463
   Chen SY, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104571
   Cruz-Vega I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20061762
   Das SK, 2022, CONCURR COMP-PRACT E, V34, DOI 10.1002/cpe.6741
   Das SK, 2022, INT J IMAG SYST TECH, V32, P192, DOI 10.1002/ima.22598
   Das Sujit Kumar, 2021, ICT Express
   Dhilsath Fathima M., 2023, Int. J. Interact. Multimed. Artif. Intell., V527
   Glaudemans AWJM, 2015, DIABETIC MED, V32, P748, DOI 10.1111/dme.12750
   Goyal M, 2020, IEEE TETCI, V4, P728, DOI 10.1109/TETCI.2018.2866254
   Jain Aarushi, 2022, 2022 2 INT C INT TEC, P1
   Jan Atif, 2023, Real world anomalous scene detection and classification using multilayer deep neural networks
   Jiang Song, 2023, Cloud Computing and Data Science, P122
   Liu X., 2022, J Artif Intell Technol, V2, P42, DOI 10.37965/jait.2022.0091
   Manjari K, 2023, ACM T ASIAN LOW-RESO, V22, DOI 10.1145/3526217
   MCNEELY MJ, 1995, DIABETES CARE, V18, P216, DOI 10.2337/diacare.18.2.216
   Meng J., 2022, Journal of Artificial Intelligence and Technology, V2, P100, DOI [DOI 10.37965/JAIT.2022.0110, 10.37965/jait.2022.0110]
   Mishra RK, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104573
   Namasudra S, 2023, MOBILE NETW APPL, V28, P764, DOI 10.1007/s11036-023-02114-w
   Park J, 2018, Arxiv, DOI [arXiv:1807.06514, 10.48550/arXiv.1807.06514, DOI 10.48550/ARXIV.1807.06514]
   Rajinikanth Venkatesan, 2023, Resnet18 supported inspection of tuberculosis in chest radiographs with integrated deep, lbp, and dwt features
   Rayyan A., 2023, Cloud Comput. Data Sci., P17
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Salman Akbal Omran, 2022, Int. J. Math. Stat. Comput. Sci., V1
   Saminathan J, 2020, INFRARED PHYS TECHN, V105, DOI 10.1016/j.infrared.2020.103219
   Schrepp Martin, 2023, On the Importance of UX Quality Aspects for Different Product Categories
   Singh V, 2023, INT J INTERACT MULTI, V8, P14, DOI 10.9781/ijimai.2021.10.008
   Taherdoost Hamed, 2023, Cloud Comput. Data Sci, P1
   Thotad Puneeth N., 2023, Sensors Int., V4
   Wang Ke, 2023, Pattern Recogn
   Wang X, 2022, CAAI T INTELL TECHNO, V7, P492, DOI 10.1049/cit2.12082
   Wang Y, 2022, CAAI T INTELL TECHNO, V7, P512, DOI 10.1049/cit2.12079
   Yi T, 2022, CAAI T INTELL TECHNO, V7, P381, DOI 10.1049/cit2.12094
   Zhang Cheng, 2023, Deep learning assisted medical insurance data analytics with multimedia system
   Zhang J, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104337
   Zheng M., 2022, Journal of Artificial Intelligence and Technology, V2, P93
NR 46
TC 3
Z9 3
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104809
DI 10.1016/j.imavis.2023.104809
EA SEP 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA S8LN4
UT WOS:001073629200001
DA 2024-07-18
ER

PT J
AU Zhang, YZ
   Zhang, T
   Wu, CY
   Zheng, YX
AF Zhang, Yunzuo
   Zhang, Tian
   Wu, Cunyu
   Zheng, Yuxin
TI Accurate video saliency prediction via hierarchical fusion and temporal
   recurrence
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video saliency prediction; Hierarchical spatiotemporal feature; Temporal
   recurrence; 3D convolutional network; Attention mechanism
ID CONVOLUTIONAL NETWORKS; NEURAL-NETWORK; MODEL; EYE
AB With the ability to extract spatiotemporal features, 3D convolutional networks have become the mainstream method for Video Saliency Prediction (VSP). However, these methods cannot make full use of hierarchical spatio-temporal features and also lack focus on past salient features, which hinders further improvements in accuracy. To address these issues, we propose a 3D convolutional Network based on Hierarchical Fusion and Temporal Re-currence (HFTR-Net) for VSP. Specifically, we propose a Bi-directional Temporal-Spatial Feature Pyramid (BiTSFP), which adds the flow of shallow location information based on the previous flow of deep semantic infor-mation. Then, different from simple addition and concatenation, we design a Hierarchical Adaptive Fusion (HAF) mechanism that can adaptively learn the fusion weights of adjacent features to integrate them appropriately. Moreover, to utilize previous salient information, a Recall 3D convGRU (R3D GRU) module is integrated into the 3D convolution-based method for the first time. It subtly combines the local feature extraction of the 3D back-bone with the long-term relationship modeling of the temporal recurrence mechanism. Experimental results on the three common datasets demonstrate that the HFTR-Net outperforms existing state-of-the-art methods in accuracy.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Zhang, Yunzuo; Zhang, Tian; Wu, Cunyu; Zheng, Yuxin] Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang 050043, Hebei, Peoples R China.
C3 Shijiazhuang Tiedao University
RP Zhang, YZ (corresponding author), Shijiazhuang Tiedao Univ, Sch Informat Sci & Technol, Shijiazhuang 050043, Hebei, Peoples R China.
EM zhangyunzuo888@sina.com
RI zheng, yuxin/IUP-3624-2023
OI zheng, yuxin/0000-0002-2336-2560
FU National Natural Science Foundation of China [61702347, 62027801];
   Natural Science Foundation of Hebei Province [F2022210007, F2017210161];
   Science and Tecnology Project of Hebei Education Department [ZD2022100,
   ZD2020174, QN2017132]; Central Guidance on Local Science and Technology
   Development Fund [226Z0501G]
FX This work is jointly supported by the National Natural Science
   Foundation of China (No. 61702347, No. 62027801) , the Natural Science
   Foundation of Hebei Province (No. F2022210007, No. F2017210161) , the
   Science and Tecnology Project of Hebei Education Department (No.
   ZD2022100, No. ZD2020174, No. QN2017132) , the Central Guidance on Local
   Science and Technology Development Fund (No. 226Z0501G) .
CR Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665
   Bellitto G, 2021, INT J COMPUT VISION, V129, P3216, DOI 10.1007/s11263-021-01519-y
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chang QY, 2023, COGN COMPUT, V15, P856, DOI 10.1007/s12559-023-10114-x
   Chen J, 2021, PATTERN RECOGN, V109, DOI 10.1016/j.patcog.2020.107615
   Fang YM, 2014, IEEE T IMAGE PROCESS, V23, P3910, DOI 10.1109/TIP.2014.2336549
   Gorji S, 2018, PROC CVPR IEEE, P7501, DOI 10.1109/CVPR.2018.00783
   Guraya FFE, 2010, PROCEEDINGS OF THE NINTH INTERNATIONAL SYMPOSIUM ON DISTRIBUTED COMPUTING AND APPLICATIONS TO BUSINESS, ENGINEERING AND SCIENCE (DCABES 2010), P508, DOI 10.1109/DCABES.2010.160
   Hadizadeh H, 2014, IEEE T IMAGE PROCESS, V23, P19, DOI 10.1109/TIP.2013.2282897
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2019, IEEE T IMAGE PROCESS, V28, P1923, DOI 10.1109/TIP.2018.2878958
   Itti L, 2003, PROC SPIE, V5200, P64, DOI 10.1117/12.512618
   Jain S, 2021, IEEE INT C INT ROBOT, P3520, DOI 10.1109/IROS51168.2021.9635989
   Jiang L, 2018, LECT NOTES COMPUT SC, V11218, P625, DOI 10.1007/978-3-030-01264-9_37
   Kalchbrenner Nal, 2017, INT C MACHINE LEARNI, P1771
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Lai QX, 2020, IEEE T IMAGE PROCESS, V29, P1113, DOI 10.1109/TIP.2019.2936112
   Leifman G, 2017, IEEE I CONF COMP VIS, P1707, DOI 10.1109/ICCV.2017.188
   Li GY, 2021, IEEE T IMAGE PROCESS, V30, P1461, DOI 10.1109/TIP.2020.3044440
   Li GY, 2019, NEUROCOMPUTING, V368, P180, DOI 10.1016/j.neucom.2019.08.051
   Liang YH, 2021, NEUROCOMPUTING, V462, P478, DOI 10.1016/j.neucom.2021.08.037
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Linardos P, 2019, Arxiv, DOI arXiv:1907.01869
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu Y, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104536
   Luo XH, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104491
   Ma C, 2022, IEEE T CIRC SYST VID, V32, P6850, DOI 10.1109/TCSVT.2022.3172971
   Mahdi A, 2019, J VIS COMMUN IMAGE R, V65, DOI 10.1016/j.jvcir.2019.102662
   Mathe S, 2015, IEEE T PATTERN ANAL, V37, P1408, DOI 10.1109/TPAMI.2014.2366154
   Min K, 2019, IEEE I CONF COMP VIS, P2394, DOI 10.1109/ICCV.2019.00248
   Riche N, 2013, IEEE I CONF COMP VIS, P1153, DOI 10.1109/ICCV.2013.147
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi XJ, 2015, ADV NEUR IN, V28
   Souza LS, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107028
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Sun MJ, 2019, IEEE T CYBERNETICS, V49, P2900, DOI 10.1109/TCYB.2018.2832053
   Sun ZH, 2019, IEEE ACCESS, V7, P147743, DOI 10.1109/ACCESS.2019.2946479
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tong YB, 2011, COGN COMPUT, V3, P241, DOI 10.1007/s12559-010-9094-8
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P38, DOI 10.1109/TIP.2017.2754941
   Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang WG, 2018, IEEE T PATTERN ANAL, V40, P20, DOI 10.1109/TPAMI.2017.2662005
   Wang Y., 2019, 7 INT C LEARNING REP
   Wang YH, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104216
   Wang YB, 2017, ADV NEUR IN, V30
   Wang ZQ, 2023, IEEE T MULTIMEDIA, V25, P1161, DOI 10.1109/TMM.2021.3139743
   Wang ZQ, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104149
   Wenguan Wang, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3395, DOI 10.1109/CVPR.2015.7298961
   Wu X, 2023, IEEE T IMAGE PROCESS, V32, P364, DOI 10.1109/TIP.2022.3228497
   Wu X, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3124913
   Wu XY, 2020, AAAI CONF ARTIF INTE, V34, P12410
   Wu Z, 2019, IEEE T CIRC SYST VID, V29, P2960, DOI 10.1109/TCSVT.2018.2870954
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xue H, 2022, NEUROCOMPUTING, V468, P233, DOI 10.1016/j.neucom.2021.10.024
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang J, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104508
   Zhang J, 2022, IMAGE VISION COMPUT, V120, DOI 10.1016/j.imavis.2022.104423
   Zhang K, 2021, IEEE T IMAGE PROCESS, V30, P572, DOI 10.1109/TIP.2020.3036749
   Zhang K, 2019, IEEE T CIRC SYST VID, V29, P3544, DOI 10.1109/TCSVT.2018.2883305
   Zhang Q, 2022, NEUROCOMPUTING, V501, P741, DOI 10.1016/j.neucom.2022.06.052
   Zhang Yunzuo, 2023, ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P1, DOI 10.1109/ICASSP49357.2023.10096685
   Zhang YZ, 2023, SIGNAL PROCESS-IMAGE, V113, DOI 10.1016/j.image.2023.116943
   Zhang YZ, 2023, IEEE GEOSCI REMOTE S, V20, DOI 10.1109/LGRS.2023.3265995
   Zheng QP, 2022, NEUROCOMPUTING, V467, P465, DOI 10.1016/j.neucom.2021.10.007
   Zhou L, 2020, IEEE T IMAGE PROCESS, V29, P694, DOI 10.1109/TIP.2019.2928144
   Zou WB, 2021, PATTERN RECOGN LETT, V147, P78, DOI 10.1016/j.patrec.2021.04.010
NR 71
TC 2
Z9 2
U1 7
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104744
DI 10.1016/j.imavis.2023.104744
EA JUL 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N9CL0
UT WOS:001039905500001
DA 2024-07-18
ER

PT J
AU Meden, B
   -Hernandez, MG
   Peer, P
   Struc, V
AF Meden, Blaz
   Gonzalez -Hernandez, Manfred
   Peer, Peter
   Struc, Vitomir
TI Face deidentification with controllable privacy protection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face deidentification; Privacy protection; Data utility; Privacy
   -enhancing technologies; Face biometrics; Deep learning
ID VERIFICATION
AB Privacy protection has become a crucial concern in today's digital age. Particularly sensitive here are facial images, which typically not only reveal a person's identity, but also other sensitive personal information. To address this problem, various face deidentification techniques have been presented in the literature. These techniques try to remove or obscure personal information from facial images while still preserving their usefulness for further analysis. While a considerable amount of work has been proposed on face deidentification, most state-of-theart solutions still suffer from various drawbacks, and (a) deidentify only a narrow facial area, leaving potentially important contextual information unprotected, (b) modify facial images to such degrees, that image naturalness and facial diversity is suffering in the deidentify images, (c) offer no flexibility in the level of privacy protection ensured, leading to suboptimal deployment in various applications, and (d) often offer an unsatisfactory tradeoff between the ability to obscure identity information, quality and naturalness of the deidentified images, and sufficient utility preservation. In this paper, we address these shortcomings with a novel controllable face deidentification technique that balances image quality, identity protection, and data utility for further analysis. The proposed approach utilizes a powerful generative model (StyleGAN2), multiple auxiliary classification models, and carefully designed constraints to guide the deidentification process. The approach is validated across four diverse datasets (CelebA-HQ, RaFD, XM2VTS, AffectNet) and in comparison to 7 state-of-the-art competitors. The results of the experiments demonstrate that the proposed solution leads to: (a) a considerable level of identity protection, (b) valuable preservation of data utility, (c) sufficient diversity among the deidentified faces, and (d) encouraging overall performance. (c) 2023 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Meden, Blaz; Peer, Peter] Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana 1000, Slovenia.
   [Gonzalez -Hernandez, Manfred] Univ Costa Rica, Atlantic Campus, Turrialba, Cartago, Costa Rica.
   [Struc, Vitomir] Univ Ljubljana, Fac Elect Engn, Trzaska 25, Ljubljana 1000, Slovenia.
C3 University of Ljubljana; Universidad Costa Rica; University of Ljubljana
RP Meden, B (corresponding author), Univ Ljubljana, Fac Comp & Informat Sci, Vecna Pot 113, Ljubljana 1000, Slovenia.
EM blaz.meden@fri.uni-lj.si
OI Gonzalez-Hernandez, Manfred/0000-0002-5408-7901
FU ARRS [P2-0250, P2-0214, J2-1734]
FX The research presented in this paper was supported in parts by the ARRS
   Research Program P2-0250 (B) "Metrology and Biometric Systems", the ARRS
   Research Program P2-0214 (A) "Computer Vision", and primarily by the
   ARRS research project J2-1734 "FaceGEN". We also gratefully acknowledge
   the "NVIDIA's Academic Hardware Grants" Programme, which provided a
   Titan Xp graphics card used in our research.
CR Abdal R, 2019, IEEE I CONF COMP VIS, P4431, DOI 10.1109/ICCV.2019.00453
   Agrawal P, 2011, IEEE T CIRC SYST VID, V21, P299, DOI 10.1109/TCSVT.2011.2105551
   Ahmed A, 2018, 2018 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND BIG DATA (ICAIBD), P144, DOI 10.1109/ICAIBD.2018.8396183
   Alaluf Yuval, 2022, P IEEE CVF C COMP VI, P18511
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Cho D, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10031120
   Croft WL, 2019, LECT NOTES COMPUT SC, V11713, P229, DOI 10.1007/978-3-030-29726-8_15
   Crosswhite N, 2018, IMAGE VISION COMPUT, V79, P35, DOI 10.1016/j.imavis.2018.09.002
   Das A, 2017, IEEE COMPUT SOC CONF, P1387, DOI 10.1109/CVPRW.2017.181
   Deeba F, 2019, INT J ADV COMPUT SC, V10, P274
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Eyiokur FI, 2023, IMAGE VISION COMPUT, V130, DOI 10.1016/j.imavis.2022.104610
   Gafni O, 2019, IEEE I CONF COMP VIS, P9377, DOI 10.1109/ICCV.2019.00947
   GAN C., EXPERT SYST APPL, V210
   Gross R., 2009, Protecting privacy in video surveillance, P129
   Gross R, 2006, LECT NOTES COMPUT SC, V3856, P227
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hu S., 2022, P IEEE CVF C COMP VI, P15014
   Hukkelas Hakon, 2023, 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), P1329, DOI 10.1109/WACV56688.2023.00138
   Hukkel†s H, 2019, Arxiv, DOI arXiv:1909.04538
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Khorzooghi SMSM, 2023, Arxiv, DOI [arXiv:2212.02611, DOI 10.56553/POPETS-2023-0114]
   Kim M., 2022, P IEEECVF C COMPUTER, P18750
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kobayashi K, 2014, 2014 TENTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING (IIH-MSP 2014), P463, DOI 10.1109/IIH-MSP.2014.122
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Li T, 2019, IEEE COMPUT SOC CONF, P56, DOI 10.1109/CVPRW.2019.00013
   Li T, 2021, Arxiv, DOI arXiv:2103.05472
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Maximov M, 2020, PROC CVPR IEEE, P5446, DOI 10.1109/CVPR42600.2020.00549
   Meden B., 2017, International Conference and Workshop on Bioinspired Intelligence, IWOBI 2017, Funchal, Portugal, July 10-12
   Meden B, 2021, IEEE T INF FOREN SEC, V16, P4147, DOI 10.1109/TIFS.2021.3096024
   Meden B, 2018, ENTROPY-SWITZ, V20, DOI 10.3390/e20010060
   Messer K, 2003, LECT NOTES COMPUT SC, V2688, P964
   Minh-Ha Le, 2020, WPES'20: Proceedings of the 19th Workshop on Privacy in the Electronic Society, P87, DOI 10.1145/3411497.3420220
   Mirjalili V, 2018, INT CONF BIOMETR THE
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Newton EM, 2005, IEEE T KNOWL DATA EN, V17, P232, DOI 10.1109/TKDE.2005.32
   Nousi P, 2020, SIGNAL PROCESS-IMAGE, V81, DOI 10.1016/j.image.2019.115699
   Pan Y., 2019, 16th IEEE International Conference on Advanced Video and Signal Based Surveillance, AVSS 2019, Taipei, Taiwan, September 18-21, P1
   Parkhi O.M, Deep face recognition
   Pernus M., 2023, IEEE T IMAGE PROCESS
   Qiu YY, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12146962
   Ren ZZ, 2018, LECT NOTES COMPUT SC, V11205, P639, DOI 10.1007/978-3-030-01246-5_38
   Sammut C., 2010, Mean Squared Error, V653, DOI 10.1007/978- 0- 387- 30164- 8 _ 528
   Savchenko AV, 2022, IEEE T AFFECT COMPUT, V13, P2132, DOI 10.1109/TAFFC.2022.3188390
   Serengil SI, 2021, 2021 7TH INTERNATIONAL CONFERENCE ON ENGINEERING AND EMERGING TECHNOLOGIES (ICEET 2021), P863, DOI 10.1109/ICEET53442.2021.9659697
   Srivastava A, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104534
   The Human Rights Act, 2022, RESP YOUR PRIV FAM L
   The International Association of Privacy Professionals (IAPP), 2000, WHAT IS PRIV
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Wang M, 2021, NEUROCOMPUTING, V429, P215, DOI 10.1016/j.neucom.2020.10.081
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wen YQ, 2021, Arxiv, DOI arXiv:2103.01745
   Wen ZY, 2022, Arxiv, DOI [arXiv:2109.07270, 10.48550/arXiv.2109.07270]
   Xia W., 2022, IEEE T PATTERN ANAL, DOI 10.1109/TPAMI.2022.3181070
   Xu CG, 2019, IEEE T INF FOREN SEC, V14, P2358, DOI 10.1109/TIFS.2019.2897874
   Yang X, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3877, DOI 10.1109/ICCV48922.2021.00387
   Yuan L, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P1661, DOI 10.1145/3503161.3548202
   Zhai LM, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P5303, DOI 10.1145/3503161.3547757
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zheng J, 2010, LECT NOTES COMPUT SC, V6111, P454, DOI 10.1007/978-3-642-13772-3_46
   Zhou YQ, 2018, IEEE INT CONF AUTOMA, P769, DOI 10.1109/FG.2018.00121
NR 67
TC 2
Z9 2
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2023
VL 134
AR 104678
DI 10.1016/j.imavis.2023.104678
EA MAY 2023
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA H8ZE0
UT WOS:000998768600001
OA hybrid, Green Published
DA 2024-07-18
ER

PT J
AU Chen, ZS
   Feng, XN
   Zhang, SW
AF Chen, Zhongshan
   Feng, Xinning
   Zhang, Shengwei
TI Emotion detection and face recognition of drivers in autonomous vehicles
   in IoT platform
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE IoT; Machine learning; FR; ED
ID CLASSIFICATION; INTERNET; FUSION
AB The Internet of Things (IoT) has been used in many fields, such as medical treatment, video monitoring, and transport. In these regions, the rapid adoption and development of IoT produce a large amount of evidence. For instance, IoT devices such as cameras capture the different facial emotions of drivers in Autonomous driving systems. In completely autonomous vehicles, drivers have trouble in takeover transfers as they become discon-nected from the actual aspect of driving. Factors affecting takeover effectiveness, such as lead time and the par-ticipation of non-driving-related tasks, have been concentrated. Nevertheless, considering the vital role of emotions, human communication and manual driving affect drivers' takeover efficiency. Face identity is essential for emotional sensitivity detection for drivers in autonomous vehicles. Automated and intelligent face recogni-tion (FR) devices are highly accurate in a comfortable condition and unregulated, with poor reliability in auton-omous vehicles. Artificial Intelligence (AI) can significantly perceive and express feelings in well-being and similar fields. This study suggests an optimized IoT architecture that facilitates the physiological signal with wire-less transmission to the database management center. Face Recognition and Emotion Detection based on IoT (FRED-IoT) has been proposed to track drivers' emotional and face recognition in autonomous vehicles. A low delay of 2 milliseconds is achieved in the proposed IoT Protocols. In contrast with cutting-edge technology, FRED-IoT improves reliability and achieves a high rating (F-score) of 96%.(c) 2022 Published by Elsevier B.V.
C1 [Chen, Zhongshan; Zhang, Shengwei] Nanjing Normal Univ Special Educ, Sch Math & Informat Sci, 1 Shennong Rd, Nanjing, Peoples R China.
   [Feng, Xinning] Nanjing Univ Posts &Telecommun, Coll Commun Engn, Tongda Coll, 33 Runyang South Rd, Yangzhou, Peoples R China.
C3 Nanjing Normal University of Special Education; Nanjing University of
   Posts & Telecommunications
RP Zhang, SW (corresponding author), Nanjing Normal Univ Special Educ, Sch Math & Informat Sci, 1 Shennong Rd, Nanjing, Peoples R China.
EM ycddczs@163.com
RI Chen, Zhongshan/JMQ-9642-2023
CR Amin SU, 2019, FUTURE GENER COMP SY, V101, P542, DOI 10.1016/j.future.2019.06.027
   Awais M., 2020, IEEE INTERNET THINGS
   Brown CL, 2020, SOC COGN AFFECT NEUR, V15, P511, DOI 10.1093/scan/nsaa060
   Fridman L, 2019, IEEE ACCESS, V7, P102021, DOI 10.1109/ACCESS.2019.2926040
   Gyrard Amelie, 2020, Smart Health, V15, P26, DOI 10.1016/j.smhl.2019.100083
   Halfon S, 2021, PSYCHOTHER RES, V31, P402, DOI 10.1080/10503307.2020.1839141
   Hossain MS, 2019, IEEE WIREL COMMUN, V26, P62, DOI 10.1109/MWC.2019.1800419
   Hossain MS, 2018, FUTURE GENER COMP SY, V83, P596, DOI 10.1016/j.future.2017.03.029
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jiang YY, 2020, INFORM FUSION, V53, P209, DOI 10.1016/j.inffus.2019.06.019
   Kanjo E, 2019, INFORM FUSION, V49, P46, DOI 10.1016/j.inffus.2018.09.001
   Kumar S, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0268-2
   Liu WJ, 2020, BIG DATA MIN ANAL, V3, P300, DOI 10.26599/BDMA.2020.9020021
   Lu HM, 2019, IEEE NETWORK, V33, P65, DOI 10.1109/MNET.2019.1800339
   Masud M, 2020, WIREL COMMUN MOB COM, V2020, DOI 10.1155/2020/8893494
   Masud M, 2020, COMPUT COMMUN, V152, P215, DOI 10.1016/j.comcom.2020.01.050
   Min WQ, 2020, IEEE T IMAGE PROCESS, V29, P657, DOI 10.1109/TIP.2019.2932502
   Mustaqeem, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010183
   Ninaus M, 2019, COMPUT EDUC, V142, DOI 10.1016/j.compedu.2019.103641
   Osman NA., 2019, International Journal of Machine Learning and Computing, V9, P425, DOI DOI 10.18178/IJMLC.2019.9.4.821
   Qian YF, 2018, IEEE INTERNET THINGS, V5, P1242, DOI 10.1109/JIOT.2018.2800035
   Qiu T, 2019, IEEE ACCESS, V7, P146342, DOI 10.1109/ACCESS.2019.2915488
   Rodrigues JJPC, 2019, IEEE WIREL COMMUN, V26, P6, DOI 10.1109/mwc.2019.8938176
   Shakeel PM, 2020, INT J TECHNOL HUM IN, V16, P94, DOI 10.4018/IJTHI.2020010107
   Xiao Zhang, 2017, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, V1, DOI 10.1145/3161414
   Zhan HW, 2021, J AMB INTEL HUM COMP, DOI 10.1007/s12652-021-03007-0
NR 26
TC 8
Z9 8
U1 8
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104569
DI 10.1016/j.imavis.2022.104569
EA NOV 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500001
DA 2024-07-18
ER

PT J
AU Hu, JT
   Yang, Y
   Yao, L
   An, YZ
   Pan, LY
AF Hu, Juntao
   Yang, You
   Yao, Lu
   An, Yongzhi
   Pan, Longyue
TI Position-guided transformer for image captioning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image captioning; Bi-positional attention; Position encoding; Group
   normalization; Transformer; Self-attention
AB Transformer-based frameworks have shown superiorities in image captioning. However, such frameworks are strenuous to consider geometric interrelations among visual contents in an image, as well as fail to prevent changes in the distribution of each layer's input in self-attention. In this work, we first propose a Bi-Positional At-tention (BPA) module, which incorporates absolute and relative position encoding to precisely explore internal relations between objects and their geometric information in an image. Additionally, we use a Group Normaliza-tion (GN) method inside BPA to relieve shifts of the distribution and better exploit the channel dependence of visual features. To validate our proposals, we apply BPA and GN into the original Transformer to constitute our Position-Guided Transformer (PGT) network, which learns a more comprehensive positional representations to augment spatial interactions among objects for image captioning. We conduct extensive experiments to verify the effectiveness of our model. Compared with non-pretraining state-of-the-art methods, experimental results on the MSCOCO benchmark dataset demonstrate that our PGT achieves competitive performance, reaching 134.2% CIDEr score on the Karpathy split with a single model, and 136.2% CIDEr score on the official testing server with an ensemble configuration.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Hu, Juntao; Yao, Lu; An, Yongzhi; Pan, Longyue] Chongqing Normal Univ, Sch Comp & Informat Sci, Chongqing 401331, Peoples R China.
   [Yang, You] Chongqing Normal Univ, Natl Ctr Appl Math Chongqing, Chongqing 401331, Peoples R China.
C3 Chongqing Normal University; Chongqing Normal University
RP Yang, Y (corresponding author), Chongqing Normal Univ, Natl Ctr Appl Math Chongqing, Chongqing 401331, Peoples R China.
EM hjt65190411@gmail.com; 20130958@cqnu.edu.cn;
   2020110516074@stu.cqnu.edu.cn; 2020110516064@stu.cqnu.edu.cn;
   2020110516011@stu.cqnu.edu.cn
FU Science and Technology Re- search Project of Chongqing Municipal
   Education Commission; Youth Project of Science and Technology Research
   Program of Chongqing Municipal Education Commission;  [KJZD-K202200504];
    [KJQN202200564]
FX This work is supported partially by the Science and Technology Re-
   search Project of Chongqing Municipal Education Commission (Grant No.
   KJZD-K202200504) and Youth Project of Science and Technology Research
   Program of Chongqing Municipal Education Commission (Grant No.
   KJQN202200564) .
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   Huang CZA, 2018, Arxiv, DOI [arXiv:1809.04281, 10.48550/arXiv.1809.04281, DOI 10.48550/ARXIV.1809.04281]
   Banerjee S., 2005, P ACL WORKSH INTR EX, P65
   Chen TY, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104340
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Dai ZH, 2019, Arxiv, DOI [arXiv:1901.02860, DOI 10.48550/ARXIV.1901.02860]
   Fan ZH, 2021, Arxiv, DOI arXiv:2106.10936
   Gehring J, 2017, PR MACH LEARN RES, V70
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He S, 2020, P ASIAN C COMPUTER V
   Herdade S, 2019, ADV NEUR IN, V32
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Huiyu Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P108, DOI 10.1007/978-3-030-58548-8_7
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji JY, 2021, AAAI CONF ARTIF INTE, V35, P1655
   Jiang H., 2020, IEEE CVF C COMP VIS, DOI 10.1109/CVPR42600.2020.01028
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Ke L, 2019, IEEE I CONF COMP VIS, P8887, DOI 10.1109/ICCV.2019.00898
   Kingma D. P., 2014, arXiv
   Lei Ba J., 2016, arXiv
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li Y., 2018, EUR C COMP VIS ECCV, P684
   Li YH, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P3799, DOI 10.1145/3474085.3478331
   Lin Chin-Yew, 2004, Text summarization branches out, P74, DOI DOI 10.2307/3105454
   Lin T.-Y., 2014, CoRR, P740
   Liu Z, 2022, Arxiv, DOI [arXiv:2111.09883, 10.48550/arXiv.2111.09883]
   Longteng Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10324, DOI 10.1109/CVPR42600.2020.01034
   Lu JS, 2017, PROC CVPR IEEE, P3242, DOI 10.1109/CVPR.2017.345
   Luo YP, 2021, Arxiv, DOI arXiv:2101.06462
   Papineni K., 2002, P ACL, P311
   Qin Y, 2019, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2019.00856
   Ramachandran P, 2019, ADV NEUR IN, V32
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Shaw P, 2018, Arxiv, DOI arXiv:1803.02155
   Song ZL, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P5056, DOI 10.1145/3474085.3475607
   Sutskever I, 2014, ADV NEUR IN, V27
   Ulyanov D, 2017, Arxiv, DOI arXiv:1607.08022
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang T.J.J., 2019, 1 INT WORKSHOP MULTI, P3
   Wang Y, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4190, DOI 10.1145/3394171.3413877
   Wu YX, 2018, LECT NOTES COMPUT SC, V11217, P3, DOI 10.1007/978-3-030-01261-8_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2019, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2019.00271
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu J, 2020, IEEE T CIRC SYST VID, V30, P4467, DOI 10.1109/TCSVT.2019.2947482
   Zhang L, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104126
   Zhang XY, 2021, PROC CVPR IEEE, P15460, DOI 10.1109/CVPR46437.2021.01521
   Zhang ZJ, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104146
   Zhao XY, 2020, WEB CONFERENCE 2020: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2020), P2377, DOI 10.1145/3366423.3380301
NR 60
TC 5
Z9 5
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104575
DI 10.1016/j.imavis.2022.104575
EA NOV 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500009
DA 2024-07-18
ER

PT J
AU Yu, MX
   Wang, CL
   Zhang, YH
   Lin, ZL
AF Yu, Mingxin
   Wang, Changlong
   Zhang, Yuhua
   Lin, Zhilong
TI Rotation-aware dynamic temporal consistency with spatial sparsity
   correlation tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dynamic temporal consistency; Spatial sparsity; Correlation tracking;
   Rotation invariance; Connected hyper ellipse fitting
ID CORRELATION FILTER; REPRESENTATION; SCALE
AB Recently, discriminative correlation filter (DCF)-based trackers have been widely applied to visual tracking. How-ever, a significant problem of DCF-based trackers is that the model uses the fixed patterns of temporal modeling and fails to suppress the distractive features. To obviate the issue, we propose the dynamic temporal consistency with spatial sparsity correlation filter. The dynamics refers to the adaptive temporal consistency hidden in the re-sponse maps and dynamic lasso constraint moderated by the prior knowledge. Unlike the classical temporal modeling method applied to filter model, we exploit the consistency of the response maps to perceive adaptive temporal continuity modeling to enable the filter to have self-regularized ability. Temporal modeling and spatial sparsity are incorporated in a unified optimization learning model and optimized together with ADMM algorithm and Sherman-Morrison formula. In particular, the tracking performance is hindered by the weak capacity to ro-tation variation. For the sake of estimating the rotation angle accurately to maintain rotation invariance, we ex-plore the coarse-to-fine rotation estimation module. The coarse rotation is supported by the angle pool and the part-based tracker. By introducing the connected hyper ellipse fitting strategy to eliminate fake distractors to en-sure a pure target region, the fine level attempts to achieve the optimal rotation angle with the minimum second order statistical bias. The design enables the filter to train with the recovered rotated image instead of axis -aligned bounding box, which attributes to alleviating the impact of ambiguous region and concentrating on the interested target. Extensive experimental results validate the superiority of the proposed method against other state-of-the art trackers and exhibit a remarkable generality in the rotated challenging scenarios.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yu, Mingxin; Wang, Changlong; Zhang, Yuhua; Lin, Zhilong] Army Engn Univ, Shijiazhuang, Peoples R China.
C3 Army Engineering University of PLA
RP Lin, ZL (corresponding author), Army Engn Univ, Shijiazhuang, Peoples R China.
EM tiantianwish@126.com
FU National Natural Science Foundation of China;  [61801507]
FX This work was supported by National Natural Science Foundation of China
   under Grant 61801507.
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   [毕笃彦 Bi Duyan], 2016, [电子与信息学报, Journal of Electronics & Information Technology], V38, P1099
   Cao ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15437, DOI 10.1109/ICCV48922.2021.01517
   Chen BX, 2019, IEEE INT CONF COMP V, P2281, DOI 10.1109/ICCVW.2019.00281
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Du QY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING (DSP), P1035, DOI 10.1109/ICDSP.2015.7252035
   Fu CH, 2020, IEEE INT C INT ROBOT, P8293, DOI 10.1109/IROS45743.2020.9340954
   Fu C, 2021, IEEE T GEOSCI REMOTE, V59, P6301, DOI 10.1109/TGRS.2020.3030265
   Fu HC, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2020.103869
   Fu Z., 2021, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P13774
   Guo DQ, 2022, J VIS COMMUN IMAGE R, V84, DOI 10.1016/j.jvcir.2022.103484
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   He A., 2018, P EUR C COMP VIS ECC
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Jiang B, 2021, IEEE T MULTIMEDIA, V23, P2162, DOI 10.1109/TMM.2020.3008035
   Kanatani K, 2011, COMPUT STAT DATA AN, V55, P2197, DOI 10.1016/j.csda.2010.12.012
   Lee DH, 2019, IEEE ACCESS, V7, P55477, DOI 10.1109/ACCESS.2019.2913390
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li Y, 2016, IEEE IMAGE PROC, P454, DOI 10.1109/ICIP.2016.7532398
   Liang W, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109435
   Lin FL, 2022, IEEE T INTELL TRANSP, V23, P10469, DOI 10.1109/TITS.2021.3094654
   Liu B, 2022, KNOWL-BASED SYST, V238, DOI 10.1016/j.knosys.2021.107913
   Lu Allen, 2017, Medical Image Computing and Computer-Assisted Intervention, MICCAI 2017. 20th International Conference. Proceedings: LNCS 10434, P323, DOI 10.1007/978-3-319-66185-8_37
   Lu XK, 2018, LECT NOTES COMPUT SC, V11218, P369, DOI 10.1007/978-3-030-01264-9_22
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Marvasti-Zadeh SM, 2019, IRAN CONF ELECTR ENG, P1272, DOI [10.1109/IranianCEE.2019.8786548, 10.1109/iraniancee.2019.8786548]
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Song WJ, 2018, NEUROCOMPUTING, V286, P121, DOI 10.1016/j.neucom.2018.01.067
   Wang KZ, 2015, IEEE T IMAGE PROCESS, V24, P3019, DOI 10.1109/TIP.2015.2432712
   Wang N, 2021, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR46437.2021.00162
   Wen LY, 2014, IEEE T IMAGE PROCESS, V23, P785, DOI 10.1109/TIP.2013.2293430
   Xu TY, 2020, IEEE T CIRC SYST VID, V30, P3727, DOI 10.1109/TCSVT.2019.2945068
   Xu TY, 2019, IEEE I CONF COMP VIS, P7949, DOI 10.1109/ICCV.2019.00804
   Xu TY, 2019, IEEE T IMAGE PROCESS, V28, DOI 10.1109/TIP.2019.2919201
   Yan B, 2021, PROC CVPR IEEE, P15175, DOI 10.1109/CVPR46437.2021.01493
   Yan YM, 2021, NEUROCOMPUTING, V436, P273, DOI 10.1016/j.neucom.2021.01.057
   Yang TY, 2020, PROC CVPR IEEE, P6717, DOI 10.1109/CVPR42600.2020.00675
   Yang YX, 2017, SCI CHINA INFORM SCI, V60, DOI 10.1007/s11432-016-0037-0
   Yang YX, 2016, ELECTRON LETT, V52, P511, DOI 10.1049/el.2015.3071
   Ye JJ, 2022, IEEE T IND ELECTRON, V69, P6004, DOI 10.1109/TIE.2021.3088366
   Yiming Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11920, DOI 10.1109/CVPR42600.2020.01194
   Yuan D, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102882
   Zhang LC, 2019, IEEE I CONF COMP VIS, P4009, DOI 10.1109/ICCV.2019.00411
   Zhang MD, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P595, DOI 10.1109/ICCVW.2015.81
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zheng GZ, 2021, IEEE INT CONF ROBOT, P503, DOI 10.1109/ICRA48506.2021.9561931
   Zheng YH, 2020, IEEE T NEUR NET LEAR, V31, P2336, DOI 10.1109/TNNLS.2019.2929407
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhou XZ, 2017, IMAGE VISION COMPUT, V60, P134, DOI 10.1016/j.imavis.2016.11.016
   Zhu XF, 2021, IEEE T CIRC SYST VID, V31, P557, DOI 10.1109/TCSVT.2020.2979480
   Zhu ZY, 2019, IEEE ACCESS, V7, P30142, DOI 10.1109/ACCESS.2019.2903161
NR 58
TC 2
Z9 2
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104546
DI 10.1016/j.imavis.2022.104546
EA SEP 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5Q3YO
UT WOS:000873771400003
DA 2024-07-18
ER

PT J
AU Meenakshi
   Srirangarajan, S
AF Meenakshi
   Srirangarajan, Seshan
TI Twin relaxed least squares regression with classwise mean constraint for
   image classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Regression; Relaxed target; Image classification; Dimensionality
   reduction
ID ROBUST FACE RECOGNITION; K-SVD; DICTIONARY; ALGORITHM; ILLUMINATION;
   PROJECTION; MODELS; SCENE
AB This paper presents a twin relaxed least squares regression (TRLSR) framework with classwise mean constraint for image classification. The primary objective of TRLSR is to learn discriminative projections with enhanced interclass margins while preserving the intrinsic structure of the data. To this end, we introduce a relaxed regression target matrix together with a twin matrix to allow greater flexibility in learning the projections compared to using the conventional strict binary label matrix. In addition, a classwise mean constraint is introduced to retain the intraclass similarity of the data, which is beneficial in learning more discriminative projections. An l(2,1)-norm based regularization on the optimized projections is incorporated to extract more significant features while limiting the impact of noise and overfitting. The performance of the proposed technique on several public data sets for face recognition, object classification, action recognition and scene classification applications is demonstrated. The proposed method is shown to outperform the state-of-the-art approaches. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Meenakshi; Srirangarajan, Seshan] Indian Inst Technol Delhi, Dept Elect Engn, New Delhi 110016, India.
   [Srirangarajan, Seshan] Indian Inst Technol Delhi, Bharti Sch Telecommun Technol & Management, New Delhi 110016, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Delhi
RP Srirangarajan, S (corresponding author), Indian Inst Technol Delhi, Dept Elect Engn, New Delhi 110016, India.; Srirangarajan, S (corresponding author), Indian Inst Technol Delhi, Bharti Sch Telecommun Technol & Management, New Delhi 110016, India.
EM meenakshi319@gmail.com; seshan@ee.iitd.ac.in
OI Meenakshi, Ph.D., Meenakshi/0000-0003-1848-1896
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   Akhtar N, 2017, PATTERN RECOGN, V65, P136, DOI 10.1016/j.patcog.2016.12.017
   [Anonymous], 2015, 3 INT C LEARN REPR
   [Anonymous], 2007, CALTECH 256 OBJECT C
   [Anonymous], 2010, CALTECH UCSD BIRDS 2
   Becker BC, 2013, IEEE COMPUT SOC CONF, P904, DOI 10.1109/CVPRW.2013.133
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Cai SJ, 2016, PROC CVPR IEEE, P2950, DOI 10.1109/CVPR.2016.322
   Cai X, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P1124
   Deng J., 2009, IEEE C COMP VIS PATT
   Dicker LH, 2017, ELECTRON J STAT, V11, P1022, DOI 10.1214/17-EJS1258
   Fang XZ, 2018, IEEE T NEUR NET LEAR, V29, P5228, DOI 10.1109/TNNLS.2018.2796133
   Fang XZ, 2018, IEEE T NEUR NET LEAR, V29, P2502, DOI 10.1109/TNNLS.2017.2693221
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Foroughi H, 2018, IEEE T IMAGE PROCESS, V27, P806, DOI 10.1109/TIP.2017.2766446
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Han N, 2020, IEEE T CIRC SYST VID, V30, P307, DOI 10.1109/TCSVT.2018.2890511
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HOERL AE, 1970, TECHNOMETRICS, V12, P55, DOI 10.1080/00401706.1970.10488634
   Holkar A, 2022, IMAGE VISION COMPUT, V120, DOI 10.1016/j.imavis.2022.104420
   Jiang ZL, 2013, IEEE T PATTERN ANAL, V35, P2651, DOI 10.1109/TPAMI.2013.88
   Koringa PA, 2018, IMAGE VISION COMPUT, V76, P64, DOI 10.1016/j.imavis.2018.06.002
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lai ZH, 2018, IEEE T CYBERNETICS, V48, P2472, DOI 10.1109/TCYB.2017.2740949
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li ZM, 2020, IEEE T NEUR NET LEAR, V31, P786, DOI 10.1109/TNNLS.2019.2910146
   Li ZM, 2017, IEEE T NEUR NET LEAR, V28, P278, DOI 10.1109/TNNLS.2015.2508025
   Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422
   Maji S, 2013, IEEE T PATTERN ANAL, V35, P66, DOI 10.1109/TPAMI.2012.62
   Martinez A., 1998, AR FACE DATABASE
   McIntosh AR, 2004, NEUROIMAGE, V23, pS250, DOI 10.1016/j.neuroimage.2004.07.020
   Naseem I, 2010, IEEE T PATTERN ANAL, V32, P2106, DOI 10.1109/TPAMI.2010.128
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Sanodiya RK, 2019, IMAGE VISION COMPUT, V90, DOI 10.1016/j.imavis.2019.08.006
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tommasi T, 2015, LECT NOTES COMPUT SC, V8927, P18, DOI 10.1007/978-3-319-16199-0_2
   Vu TH, 2017, IEEE T IMAGE PROCESS, V26, P5160, DOI 10.1109/TIP.2017.2729885
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang LF, 2018, IEEE T NEUR NET LEAR, V29, P1352, DOI 10.1109/TNNLS.2017.2651169
   Wei CP, 2014, IEEE T IMAGE PROCESS, V23, P3294, DOI 10.1109/TIP.2014.2329451
   Wen J, 2019, IEEE T CIRC SYST VID, V29, P390, DOI 10.1109/TCSVT.2018.2799214
   Wen J, 2018, NEURAL NETWORKS, V102, P36, DOI 10.1016/j.neunet.2018.02.002
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xiang SM, 2012, IEEE T NEUR NET LEAR, V23, P1738, DOI 10.1109/TNNLS.2012.2212721
   Xu Y, 2014, NEUROCOMPUTING, V135, P253, DOI 10.1016/j.neucom.2013.11.025
   Xu YL, 2013, IEEE T NEUR NET LEAR, V24, P635, DOI 10.1109/TNNLS.2013.2242091
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang QA, 2010, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2010.5539989
   Zhang XY, 2015, IEEE T NEUR NET LEAR, V26, P2206, DOI 10.1109/TNNLS.2014.2371492
NR 52
TC 2
Z9 2
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104506
DI 10.1016/j.imavis.2022.104506
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800001
DA 2024-07-18
ER

PT J
AU Shenaj, D
   Barbato, F
   Michieli, U
   Zanuttigh, P
AF Shenaj, Donald
   Barbato, Francesco
   Michieli, Umberto
   Zanuttigh, Pietro
TI Continual coarse-to-fine domain adaptation in semantic segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Coarse-to-fine learning; Unsupervised domain adaptation; Semantic
   segmentation; Continual learning; Deep learning
AB Deep neural networks are typically trained in a single shot for a specific task and data distribution, but in real world settings both the task and the domain of application can change. The problem becomes even more challenging in dense predictive tasks, such as semantic segmentation, and furthermore most approaches tackle the two problems separately. In this paper we introduce the novel task of coarse-to-fine learning of semantic segmentation architectures in presence of domain shift. We consider subsequent learning stages progressively refining the task at the semantic level; i.e., the finer set of semantic labels at each learning step is hierarchically derived from the coarser set of the previous step. We propose a new approach (CCDA) to tackle this scenario. First, we employ the maximum squares loss to align source and target domains and, at the same time, to balance the gradients between well-classified and harder samples. Second, we introduce a novel coarse-to-fine knowledge distillation constraint to transfer network capabilities acquired on a coarser set of labels to a set of finer labels. Finally, we design a coarse-to-fine weight initialization rule to spread the importance from each coarse class to the respective finer classes. To evaluate our approach, we design two benchmarks where source knowledge is extracted from the GTA5 dataset and it is transferred to either the Cityscapes or the IDD datasets, and we show how it outperforms the main competitors.
C1 [Shenaj, Donald; Barbato, Francesco; Michieli, Umberto; Zanuttigh, Pietro] Univ Padua, Dept Informat Engn, Padua, Italy.
C3 University of Padua
RP Shenaj, D (corresponding author), Univ Padua, Dept Informat Engn, Padua, Italy.
EM donald.shenaj@dei.unipd.it; francesco.barbato@dei.unipd.it;
   umberto.michieli@dei.unipd.it; zanuttigh@dei.unipd.it
RI Zanuttigh, Pietro/AAB-9555-2019; Barbato, Francesco/AAD-1361-2022;
   Michieli, Umberto/KLC-7487-2024
OI Zanuttigh, Pietro/0000-0002-9502-2389; Barbato,
   Francesco/0000-0001-9893-5813; Michieli, Umberto/0000-0003-2666-4342;
   Shenaj, Donald/0000-0002-6501-9437
FU University of Padova Grant: "CAPRI: Calcolo ad Alte Prestazioni per la
   Ricerca e l'Innovazione"; SID project "Semantic Segmentation in the
   Wild"
FX This work was partially supported by the University of Padova Grant:
   "CAPRI: Calcolo ad Alte Prestazioni per la Ricerca e l'Innovazione" and
   by the SID project "Semantic Segmentation in the Wild".
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Barbato F., 2021, ARXIV 2021 PREPRINT
   Barbato F., P IEEE C COMPUTER VI, P2835
   Cardace A., P WINT C APPL COMP V, P1160
   Cermelli F., P IEEE C COMP VIS PA, P9233
   Chen L. C., P EUROPEAN C COMPUTE, P833
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen M., P INT C COMPUTER VIS, P2090
   Chen Y.-C., P IEEE C COMPUTER VI, P1791
   Cordts M., P IEEE C COMPUTER VI, P3213
   Csurka G, 2017, PREPRINT ARXIV170205
   Douillard A, 2021, PROC CVPR IEEE, P4039, DOI 10.1109/CVPR46437.2021.00403
   Hoffman J., P INT C MACH LEARN 2, P1994
   Klingner M, 2020, IEEE INT C INTELL TR, DOI 10.1109/itsc45102.2020.9294483
   Lesort T, 2020, INFORM FUSION, V58, P52, DOI 10.1016/j.inffus.2019.12.004
   Li J, 2020, ARXIV
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Maracani A., P INT C COMP VIS 202, P7026
   Mel M, 2020, TECHNOLOGIES, V8, DOI 10.3390/technologies8010001
   Michieli Umberto, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P397, DOI 10.1007/978-3-030-58598-3_24
   Michieli U., 2021, UNSUPERVISED DOMAIN
   Michieli U., 2019, P INT C COMPUTER VIS
   Michieli U, 2021, PROC CVPR IEEE, P1114, DOI 10.1109/CVPR46437.2021.00117
   Murez Z., P IEEE C COMPUTER VI, P4500
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Pizzati F, 2020, IEEE WINT CONF APPL, P2979, DOI 10.1109/WACV45572.2020.9093540
   Richter S.R., P EUROPEAN C COMPUTE, P102
   Stretcu O., 2020, P INT C LEARN REPR W
   Stretcu O., 2021, ARXIV 2021 PREPRINT
   Toldo M., P WINT C APPL COMP V, P1358
   Toldo M, 2020, TECHNOLOGIES, V8, DOI 10.3390/technologies8020035
   Toldo M, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103889
   Tranheden W, 2021, IEEE WINT CONF APPL, P1378, DOI 10.1109/WACV48630.2021.00142
   Tsai Y.-H., P IEEE C COMPUTER VI, P7472
   Varma G., P WINTER C APPL COMP, P1743
   Wang D., 2016, PREPRINT ARXIV161202
   Yang B., 2021, IEEE T NEURAL NETWOR
   Zhang Y., P INT C COMPUTER VIS, P2020
   Zhang Y., 2019, TPAMI, V42, P1823
   Zhao H., P IEEE C COMPUTER VI, P2881
   Zou Y., P INT C COMPUTER VIS, P5982
   Zou Yang., Proceedings of the European Conference on Computer Vision ECCV, P289
NR 43
TC 5
Z9 5
U1 2
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104426
DI 10.1016/j.imavis.2022.104426
EA MAR 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0Z8MP
UT WOS:000791325900005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gan, CQ
   Xiao, JH
   Wang, ZY
   Zhang, ZF
   Zhu, QY
AF Gan, Chenquan
   Xiao, Junhao
   Wang, Zhangyi
   Zhang, Zufan
   Zhu, Qingyi
TI Facial expression recognition using densely connected convolutional
   neural network and hierarchical spatial attention
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial image; Facial expression recognition; Densely connected
   convolutional neural; network; Spatial attention
ID HISTOGRAM; FEATURES
AB This paper is dedicated to eliminating the impact of redundant information from emotional-unrelated regions on facial expression recognition (FER). To this end, a densely connected convolutional neural network with hierarchical spatial attention is proposed. Specifically, it can adaptively locate salient regions and focus on the emotional related features so that the facial expressions can be represented more efficiently. This superior performance is also verified by some experiments. Experimental results reveal that the proposed method can distinguish facial expression more accurately than existing state-of-the-art methods.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Gan, Chenquan; Xiao, Junhao; Wang, Zhangyi; Zhang, Zufan] Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Chongqing 400065, Peoples R China.
   [Gan, Chenquan; Zhang, Zufan] Chongqing Key Lab Mobile Commun Technol, Chongqing 400065, Peoples R China.
   [Gan, Chenquan; Zhang, Zufan] Minist Educ, Engn Res Ctr Mobile Commun, Chongqing 400065, Peoples R China.
   [Zhu, Qingyi] Chongqing Univ Posts & Telecommun, Sch Cyber Secur & Informat Law, Chongqing 400065, Peoples R China.
C3 Chongqing University of Posts & Telecommunications; Chongqing University
   of Posts & Telecommunications
RP Gan, CQ (corresponding author), Chongqing Univ Posts & Telecommun, Sch Commun & Informat Engn, Chongqing 400065, Peoples R China.
EM gancq@cqupt.edu.cn; 402332840@qq.com; wangzy0523@cqupt.edu.cn;
   zhangzf@cqupt.edu.cn; zhuqy@cqupt.edu.cn
RI Zhu, Qingyi/A-6494-2018
OI Zhu, Qingyi/0000-0002-1168-1599; Xiao, Junhao/0000-0003-1129-8036; Gan,
   Chenquan/0000-0002-0453-5630
FU Natural Science Foundation of China [61903056]; Major Pro-ject of
   Science and Technology Research Program of Chongqing Educa-tion
   Commission of China [KJZDM201900601]; Chongqing Research Program of
   Basic Research and Frontier Technology [cstc2019jcyj-msxm1262,
   cstc2021jcyj-msxmX0761]; Chongqing Municipal Key Laboratory of
   Institutions of Higher Education [cqupt-mct202006]; Chongqing Key
   Laboratory of Mobile Communications Technology; Engineering Re-search
   Center of Mobile Communications, Ministry of Education
FX Acknowledgments The authors are grateful to the anonymous reviewers and
   the editor for their valuable comments and suggestions. This work is
   supported by Natural Science Foundation of China (Grant No. 61903056) ,
   Major Pro-ject of Science and Technology Research Program of Chongqing
   Educa-tion Commission of China (Grant No. KJZDM201900601) , Chongqing
   Research Program of Basic Research and Frontier Technology (Grant Nos.
   cstc2019jcyj-msxm1262 and cstc2021jcyj-msxmX0761) , Project Supported by
   Chongqing Municipal Key Laboratory of Institutions of Higher Education
   (Grant No. cqupt-mct-201901) , Project Supported by Chongqing Key
   Laboratory of Mobile Communications Technology (Grant No.
   cqupt-mct-202002) , Project Supported by Engineering Re-search Center of
   Mobile Communications, Ministry of Education (Grant No. cqupt-mct202006)
   .
CR Deng J, 2019, IEEE ACCESS, V7, P9848, DOI 10.1109/ACCESS.2019.2891668
   Gan CQ, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.06.035
   Gan YL, 2020, IEEE ACCESS, V8, P7383, DOI 10.1109/ACCESS.2020.2963913
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hua CH, 2020, INT CONF UBIQUIT INF, DOI 10.1109/imcom48794.2020.9001686
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ilyas CMA, 2018, VISAPP: PROCEEDINGS OF THE 13TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL 4: VISAPP, P522, DOI 10.5220/0006721305220530
   Ji YL, 2019, NEUROCOMPUTING, V333, P231, DOI 10.1016/j.neucom.2018.12.037
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kumar Y, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC), P1074, DOI 10.1109/ICCMC.2017.8282636
   Kuo CM, 2018, IEEE COMPUT SOC CONF, P2202, DOI 10.1109/CVPRW.2018.00286
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Li W., 2019, P IEEE INT C AUT FAC, P1
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Majumder A, 2018, IEEE T CYBERNETICS, V48, P103, DOI 10.1109/TCYB.2016.2625419
   Fernandez PDM, 2019, IEEE COMPUT SOC CONF, P837, DOI 10.1109/CVPRW.2019.00112
   MEHRABIAN A, 1967, J CONSULT PSYCHOL, V31, P248, DOI 10.1037/h0024648
   Nigam S, 2018, MULTIMED TOOLS APPL, V77, P28725, DOI 10.1007/s11042-018-6040-3
   Rabhi Y., 2018, P INT C ADV TECHN SI, P1
   Sun A, 2018, HUM-CENT COMPUT INFO, V8, DOI 10.1186/s13673-018-0156-3
   Sun WY, 2018, NEUROCOMPUTING, V296, P12, DOI 10.1016/j.neucom.2018.03.034
   Turan C, 2018, J VIS COMMUN IMAGE R, V55, P331, DOI 10.1016/j.jvcir.2018.05.024
   Vyas AS, 2019, INT CONF ADVAN COMPU, P102, DOI [10.1109/ICACCS.2019.8728330, 10.1109/icaccs.2019.8728330]
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang JZ, 2018, PEER PEER NETW APPL, V11, P679, DOI 10.1007/s12083-017-0556-6
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Xie SY, 2019, PATTERN RECOGN, V92, P177, DOI 10.1016/j.patcog.2019.03.019
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Ye YS, 2019, J VIS COMMUN IMAGE R, V62, P1, DOI 10.1016/j.jvcir.2019.04.009
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang KH, 2017, IEEE T IMAGE PROCESS, V26, P4193, DOI 10.1109/TIP.2017.2689999
NR 33
TC 17
Z9 17
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104342
DI 10.1016/j.imavis.2021.104342
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4VF
UT WOS:000772585200006
DA 2024-07-18
ER

PT J
AU Mishra, NK
   Dutta, M
   Singh, SK
AF Mishra, Nayaneesh Kumar
   Dutta, Mainak
   Singh, Satish Kumar
TI Multiscale parallel deep CNN<i> (mpdCNN)</i> architecture for the real
   low-resolution face recognition for surveillance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Low-resolution images; Surveillance; Multiscale
   parallel architecture; Convolution neural network
ID ROBUST RECOGNITION; SUPERRESOLUTION
AB Images from the surveillance networks are being extensively used for the purpose of monitoring and criminal in-vestigations. However, it is often difficult to recognize faces using the data from the surveillance networks be-cause the resolution of the face in the images captured is too low. Further, the low-resolution images have varying magnitude of facial feature content because of wide variations in illumination, pose, resolution and the distance from which the image is captured. Also, a single face recognition solution is not able to recognize faces efficiently in both high and low-resolution images. Wide variations in facial feature content in high and low-resolution images causes difficulty in classification of the features by a single model for the purpose of face recognition. We present a Deep-CNN based architecture called mpdCNN to solve the problem of face recog-nition in low as well as high-resolution images with high accuracy and robustness. Our proposed architecture mpdCNN gives 88.6% accuracy on the SCface database which is an impressive improvement over the state-of -the-art algorithms. We also achieved an accuracy of above 99% on normal to high-resolution databases for face recognition. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Mishra, Nayaneesh Kumar; Dutta, Mainak; Singh, Satish Kumar] Indian Inst Informat Technol, Jhalwa 211012, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Mishra, NK (corresponding author), Indian Inst Informat Technol, Jhalwa 211012, Prayagraj, India.
EM nayaneesh@gmail.com
RI Dutta, Mainak/H-3354-2019; Singh, Dr Satish Kumar/JMP-6186-2023
OI Dutta, Mainak/0000-0003-3977-3230; Singh, Dr Satish
   Kumar/0000-0003-1991-7727; Mishra, Nayaneesh Kumar/0000-0002-2164-9541;
   Dutta, Mainak/0000-0003-4881-8445
FU Indian Institute of Information Technology, Al-lahabad, India
FX I would like to thank Indian Institute of Information Technology,
   Al-lahabad, India for supporting the work on recognition of faces in
   real low resolution images.
CR Ahmed Wafaa Shihab, 2020, 2020 International Conference on Computer Science and Software Engineering (CSASE). Proceedings, P88, DOI 10.1109/CSASE48920.2020.9142089
   Alshamaa D, 2018, SIGNAL PROCESS, V148, P68, DOI 10.1016/j.sigpro.2018.02.021
   [Anonymous], 2001, IEEE COMP SOC C COMP
   [Anonymous], 2012, ARXIV PREPRINT ARXIV
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Biswas S, 2013, IEEE T PATTERN ANAL, V35, P3037, DOI 10.1109/TPAMI.2013.68
   Cheng Z., 2018, ASIAN C COMPUTER VIS, P605
   Cheng Z., 2018, ARXIV180409691
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Gao G., 2018, ARTIF INTELL ROBOT, P17, DOI DOI 10.1007/978-3-319-69877-9_3
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Ge SM, 2019, IEEE T IMAGE PROCESS, V28, P2051, DOI 10.1109/TIP.2018.2883743
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang H, 2011, IEEE T NEURAL NETWOR, V22, P121, DOI 10.1109/TNN.2010.2089470
   Iranmanesh SM, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103861
   Jiang JJ, 2017, IEEE T MULTIMEDIA, V19, P27, DOI 10.1109/TMM.2016.2601020
   Khalid Syed Safwan, 2020, IEEE Transactions on Biometrics, Behavior, and Identity Science, V2, P410, DOI 10.1109/TBIOM.2020.3007356
   King DB, 2015, ACS SYM SER, V1214, P1
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Lei Z, 2012, IEEE T INF FOREN SEC, V7, P1707, DOI 10.1109/TIFS.2012.2210041
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Li P., 2016, IEEE Int. Conference on Biometrics: Theory Applications and Systems (BTAS), P1
   Li P, 2019, IEEE T INF FOREN SEC, V14, P2000, DOI 10.1109/TIFS.2018.2890812
   Li P, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P243, DOI 10.1109/BTAS.2017.8272704
   Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429
   Lu ZJ, 2018, IEEE ACCESS, V6, DOI [10.1109/ACCESS.2018.2864189, 10.1109/LSP.2018.2810121]
   Makrem B., 2016, INT REV COMPUT SOFTW, V11
   Massoli FV, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103927
   Min J, 2005, LECT NOTES COMPUT SC, V3546, P41
   Mishra N.K., DATA SCI THEORY ALGO, V2021, P279
   Moutafis P, 2014, 2014 IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2014)
   Mudunuri S. Prasad, P IEEE C COMP VIS PA, P489
   Obara K, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P478, DOI 10.23919/MVA.2017.7986904
   Peixoto SA, 2020, IMAGE VISION COMPUT, V96, DOI 10.1016/j.imavis.2020.103899
   Peng YX, 2017, IET BIOMETRICS, V6, P418, DOI 10.1049/iet-bmt.2016.0026
   Peng Yuxi, 2016, BIOMETRICS SPECIAL I, P1
   Ren CX, 2012, IEEE T IMAGE PROCESS, V21, P3770, DOI 10.1109/TIP.2012.2192285
   Ruder S., 2016, ARXIV
   Sanderson C., 2004, VIDTIMIT DATABASE
   Shekhar S., 2011, P INT JOINT C BIOMET P 2011 INT JOINT C B, P1
   Srivastava Y., 2020, INT C COMP VIS IM PR, P70
   Srivastava Y., 2020, Revised Selected Papers, V7, P322
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang ZY, 2016, PROC CVPR IEEE, P4792, DOI 10.1109/CVPR.2016.518
   Wen-Ming Cao, 2010, Natural Science, V2, P49, DOI 10.4236/ns.2010.21007
   Yang FW, 2018, IEEE SIGNAL PROC LET, V25, P388, DOI 10.1109/LSP.2017.2746658
   Yong Xu, 2008, 2008 3rd International Conference on Innovative Computing Information and Control (ICICIC), DOI 10.1109/ICICIC.2008.234
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 50
TC 12
Z9 13
U1 3
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104290
DI 10.1016/j.imavis.2021.104290
EA SEP 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WB1NI
UT WOS:000703345700002
DA 2024-07-18
ER

PT J
AU Wang, YH
   Liu, ZR
   Xia, YB
   Zhu, CB
   Zhao, DP
AF Wang, Yuhao
   Liu, Zhuoran
   Xia, Yibo
   Zhu, Chunbo
   Zhao, Danpei
TI Spatiotemporal module for video saliency prediction based on
   self-attention
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video saliency prediction; Spatio-temporal; Self-attention;
   Convolutional LSTM
ID VISUAL-ATTENTION; MODEL; EYE; FIXATIONS; NETWORK; IMAGE
AB Considering that the existing video saliency prediction methods still have limitations in spatiotemporal correla-tion learning between features and saliency regions, this paper proposes a spatiotemporal module for video sa-liency prediction based on self-attention. The proposed model emphasizes three essential problems as follows. First, we raise a multi-scale feature-fusion network (MFN) for effective feature integration. The framework can extract and fuse features from four scales at low memory cost. Second, we view the task as a global evaluation of the correlation on pixel level to predict human visual attention in task-driven scenes more accurately. An adapted transformer encoder is designed for spatiotemporal correlation learning. Finally, we introduce DConvLSTM to learn the context in videos. Experimental results show that the proposed model achieves state -of-the-art performance on both driving scenes and natural scenes with multi-motion information. And our model also achieves very comparable performance especially in natural scenes with multi-category objects. It proves our method is practicable in both data-driven and task-driven conditions. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wang, Yuhao; Liu, Zhuoran; Xia, Yibo; Zhu, Chunbo; Zhao, Danpei] Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
   [Zhu, Chunbo; Zhao, Danpei] Beihang Univ, Beijing Key Lab Digital Media, Beijing 100191, Peoples R China.
   [Zhu, Chunbo; Zhao, Danpei] Minist Educ, Key Lab Spacecraft Design Optimizat & Dynam Simul, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Zhao, DP (corresponding author), Beihang Univ, Image Proc Ctr, Sch Astronaut, Beijing 100191, Peoples R China.
EM zhaodanpei@buaa.edu.cn
RI Liu, Zhuoran/IUO-1250-2023
OI Zhao, Danpei/0000-0001-6701-0471
FU National Key Research and Development Program of China [2019YFC1510905]
FX This work was supported in part by the National Key Research and
   Development Program of China under Grant No. 2019YFC1510905.
CR [Anonymous], MIT Saliency Benchmark
   Bak C, 2018, IEEE T MULTIMEDIA, V20, P1688, DOI 10.1109/TMM.2017.2777665
   Bellitto Giovanni, 2020, ARXIV201001220
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Carion Nicolas, 2020, EUR C COMP VIS ECCV, DOI DOI 10.1007/978-3-030-58452-8_13
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Deng T, 2020, IEEE T INTELL TRANSP, V21, P2146, DOI 10.1109/TITS.2019.2915540
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Droste R., 2020, P 16 EUR C COMP VIS, DOI [10.1007/978-3-030-58558-7_25, DOI 10.1007/978-3-030-58558-7_25]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Evangelopoulos G, 2013, IEEE T MULTIMEDIA, V15, P1553, DOI 10.1109/TMM.2013.2267205
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Gandhi V., 2020, ARXIV201206170
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2003, PROC SPIE, V5200, P64, DOI 10.1117/12.512618
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang L, 2018, LECT NOTES COMPUT SC, V11218, P625, DOI 10.1007/978-3-030-01264-9_37
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Keren G, 2016, IEEE IJCNN, P3412, DOI 10.1109/IJCNN.2016.7727636
   Khatoonabadi SH, 2015, PROC CVPR IEEE, P5501, DOI 10.1109/CVPR.2015.7299189
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Le Meur O, 2007, VISION RES, V47, P2483, DOI 10.1016/j.visres.2007.06.015
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Linardos P., 2019, P BRIT MACHINE VISIO
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Liu NA, 2018, IEEE T NEUR NET LEAR, V29, P392, DOI 10.1109/TNNLS.2016.2628878
   Liu N, 2015, PROC CVPR IEEE, P362, DOI 10.1109/CVPR.2015.7298633
   Liu Z, 2017, IEEE T CIRC SYST VID, V27, P2527, DOI 10.1109/TCSVT.2016.2595324
   Min K, 2019, IEEE I CONF COMP VIS, P2394, DOI 10.1109/ICCV.2019.00248
   Nothdurft HC, 2002, VISION RES, V42, P1287, DOI 10.1016/S0042-6989(02)00016-0
   Pan J., 2020, SALGAN VISUAL SALIEN
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ren ZX, 2013, IEEE T IMAGE PROCESS, V22, P3120, DOI 10.1109/TIP.2013.2259837
   Rudoy D, 2013, PROC CVPR IEEE, P1147, DOI 10.1109/CVPR.2013.152
   Shen JB, 2017, IEEE T IMAGE PROCESS, V26, P4911, DOI 10.1109/TIP.2017.2722691
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K, 2014, ADV NEUR IN, V27
   Tawari A, 2018, IEEE INT C INTELL TR, P3225, DOI 10.1109/ITSC.2018.8569438
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang WG, 2021, IEEE T PATTERN ANAL, V43, P220, DOI 10.1109/TPAMI.2019.2924417
   Wang WG, 2018, PROC CVPR IEEE, P4894, DOI 10.1109/CVPR.2018.00514
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Wang WG, 2016, IEEE T IMAGE PROCESS, V25, P5025, DOI 10.1109/TIP.2016.2601784
   Wu XY, 2020, AAAI CONF ARTIF INTE, V34, P12410
   Xu M, 2017, IEEE T IMAGE PROCESS, V26, P369, DOI 10.1109/TIP.2016.2628583
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang K, 2019, IEEE T CIRC SYST VID, V29, P3544, DOI 10.1109/TCSVT.2018.2883305
   Zhang L., 2009, SUNDAY SALIENCY USIN
   Zhou XF, 2018, IEEE T MULTIMEDIA, V20, P2993, DOI 10.1109/TMM.2018.2829605
NR 60
TC 12
Z9 12
U1 3
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104216
DI 10.1016/j.imavis.2021.104216
EA MAY 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100013
DA 2024-07-18
ER

PT J
AU Lin, YM
   Shen, J
   Wang, YJ
   Pantic, M
AF Lin, Yiming
   Shen, Jie
   Wang, Yujiang
   Pantic, Maja
TI RoI Tanh-polar transformer network for face parsing in the wild
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face parsing; In-the-wild dataset; Head pose augmentation; Tanh-polar
   representation
AB Face parsing aims to predict pixel-wise labels for facial components of a target face in an image. Existing approaches usually crop the target face from the input image with respect to a bounding box calculated during pre-processing, and thus can only parse inner facial Regions of Interest (RoIs). Peripheral regions like hair are ignored and nearby faces that are partially included in the bounding box can cause distractions. Moreover, these methods are only trained and evaluated on near-frontal portrait images and thus their performance for in-the wild cases has been unexplored. To address these issues, this paper makes three contributions. First, we introduce iBugMask dataset for face parsing in the wild, which consists of 21,866 training images and 1000 testing images. The training images are obtained by augmenting an existing dataset with large face poses. The testing images are manually annotated with 11 facial regions and there are large variations in sizes, poses, expressions and background. Second, we propose RoI Tanh-polar transform that warps the whole image to a Tanh-polar representation with a fixed ratio between the face area and the context, guided by the target bounding box. The new representation contains all information in the original image, and allows for rotation equivariance in the convolutional neural networks (CNNs). Third, we propose a hybrid residual representation learning block, coined HybridBlock, that contains convolutional layers in both the Tanh-polar space and the Tanh-Cartesian space, allowing for receptive fields of different shapes in CNNs. Through extensive experiments, we show that the proposed method improves the state-of-the-art for face parsing in the wild and does not require facial landmarks for alignment. 0 2021 Elsevier B.V. All rights reserved.
C1 [Lin, Yiming; Shen, Jie; Wang, Yujiang; Pantic, Maja] Imperial Coll London, Dept Comp, London, England.
C3 Imperial College London
RP Shen, J (corresponding author), Imperial Coll London, Dept Comp, London, England.
EM yiming.lin15@imperial.ac.uk; jie.shen07@imperial.ac.uk;
   yujiang.wang14@imperial.ac.uk; maja.pantic@imperial.ac.uk
OI Wang, Yujiang/0000-0002-6220-029X
CR [Anonymous], 2015, NEURAL INFORM PROCES
   [Anonymous], 2008, FG
   [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587673
   [Anonymous], 2018, 2018 IEEE C COMP VIS
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Banerjee S., 2020 IEEE WINT C APP, P289
   Bao Y., 2011 IEEE SICE INT S, P74
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Chen C., 2019, 2019 14 IEEE INT C A, P1
   Chen L.-C., 2018, NEURAL INFORM PROCES
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P4545, DOI 10.1109/CVPR.2016.492
   Chen Z., 2020, 2020 IEEE C COMP VIS
   Cohen TS, 2016, PR MACH LEARN RES, V48
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Deng JK, 2019, INT J COMPUT VISION, V127, P599, DOI 10.1007/s11263-018-1134-y
   Ebel P, 2019, IEEE I CONF COMP VIS, P253, DOI 10.1109/ICCV.2019.00034
   Esteves X.Z. Carlos, 2018, INT C LEARN REPR
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Guclu U., 2017, ARXIV170303305
   Guo TC, 2018, AAAI CONF ARTIF INTE, P6861
   Gusi Te, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P258, DOI 10.1007/978-3-030-58610-2_16
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hotta K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P70, DOI 10.1109/AFGR.1998.670927
   Hou Q., 2020, 2020 IEEE C COMP VIS
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jackson AS, 2016, LECT NOTES COMPUT SC, V9915, P143, DOI 10.1007/978-3-319-49409-8_14
   Jurie F, 1999, PATTERN RECOGN, V32, P865, DOI 10.1016/S0031-3203(98)00096-X
   Kae A, 2013, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2013.263
   Kalayeh MM, 2021, IEEE T PATTERN ANAL, V43, P1620, DOI 10.1109/TPAMI.2019.2956039
   Kalayeh MM, 2017, PROC CVPR IEEE, P4227, DOI 10.1109/CVPR.2017.450
   Karras T., 2018, INT C LEARN REPR, P1, Patent No. 171010196
   Khan K, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020328
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Lee C.-H., 2020, 2020 IEEE C COMP VIS
   Li XL, 2020, IEEE ACCESS, V8, P93069, DOI 10.1109/ACCESS.2020.2995202
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin J., 2019, 2019 IEEE C COMP VIS
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu L.J. Sifei, 2017, P BRIT MACH VIS C BM
   Liu SF, 2015, PROC CVPR IEEE, P3451, DOI 10.1109/CVPR.2015.7298967
   Liu Y., AAAI C ART INT, P11637
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo B., 2020 IEEE WINT C APP, P1952
   Luo P, 2012, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2012.6247963
   Masi I., 2020, 2020 IEEE C COMP VIS
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Minaee S., 2021, IEEE T PATTERN ANAL
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Nirkin Y, 2018, IEEE INT CONF AUTOMA, P98, DOI 10.1109/FG.2018.00024
   Ou XY, 2016, MM'16: PROCEEDINGS OF THE 2016 ACM MULTIMEDIA CONFERENCE, P701, DOI 10.1145/2964284.2973812
   Paszke A, 2019, ADV NEUR IN, V32
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Scheffler C, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.53
   SEGMAN J, 1992, IEEE T PATTERN ANAL, V14, P1171, DOI 10.1109/34.177382
   Shen J., 2020, ARXIV200603708
   Shi XJ, 2015, ADV NEUR IN, V28
   Simonyan K., 2014, CORR
   Smith BM, 2013, PROC CVPR IEEE, P3484, DOI 10.1109/CVPR.2013.447
   Tai K.S., 2019, INT C MACH LEARN
   Wang J., 2020, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.20202983686, DOI 10.1109/TPAMI.20202983686]
   Wang K., 2020, 2020 IEEE C COMP VIS
   Wang YJ, 2019, INT J COMPUT VISION, V127, P625, DOI 10.1007/s11263-018-1130-2
   Warrell J, 2009, IEEE IMAGE PROC, P2481, DOI 10.1109/ICIP.2009.5413918
   Wei Z, 2019, IEEE T IMAGE PROCESS, V28, P4659, DOI 10.1109/TIP.2019.2909652
   Wei Z, 2017, PROC CVPR IEEE, P3947, DOI 10.1109/CVPR.2017.420
   Wu Y., 2020, 2020 IEEE C COMP VIS
   Xiaojuan Cheng, 2019, IEEE Transactions on Biometrics, Behavior, and Identity Science, V1, P223, DOI 10.1109/TBIOM.2019.2936624
   Yacoob Y, 2006, IEEE T PATTERN ANAL, V28, P1164, DOI 10.1109/TPAMI.2006.139
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Yu F., P INT C LEARN REPR, P1
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zhang H, 2019, INT J COMPUT VISION, V127, P845, DOI 10.1007/s11263-019-01175-3
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou L., 2017, ARXIV170803736
   Zhou YS, 2015, LECT NOTES COMPUT SC, V9377, P222, DOI 10.1007/978-3-319-25393-0_25
   Zhu P., 2020, 2020 IEEE C COMP VIS
   Zhu XY, 2019, IEEE T PATTERN ANAL, V41, P78, DOI 10.1109/TPAMI.2017.2778152
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 88
TC 19
Z9 19
U1 3
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104190
DI 10.1016/j.imavis.2021.104190
EA MAY 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, Q
   Zhou, WA
   Wang, SR
AF Zhou, Qiang
   Zhou, Wen'an
   Wang, Shirui
TI Cluster adaptation networks for unsupervised domain adaptation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Domain adaptation; Deep networks; Image classification
AB Domain adaptation is an important technology for transferring source domain knowledge to new, unseen target domains. Recently, domain adaptation models are applied to learn domain invariant representations by minimizing distribution distance or adversarial training in the feature space. However, existing adversarial domain adaptation methods fail to preserve the data structure in the feature space. In this paper, we propose a novel domain adaptation method called Cluster adaptation Networks (CAN). CAN decreases the domain shift by aligning the category centers of source representations and the cluster centers of target representations in the feature space, which preserves the class-level structure and facilitates the classification of the target domain. Experiments on Digits, Office-Home and ImageCLEF-DA datasets validate the effectiveness of the structure preservation in our model.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhou, Qiang; Zhou, Wen'an; Wang, Shirui] Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Zhou, WA (corresponding author), Beijing Univ Posts & Telecommun, Sch Comp Sci, Beijing 100876, Peoples R China.
EM zhouwa@bupt.edu.cu
CR [Anonymous], MNIST DATABASE HANDW
   [Anonymous], 2016, IJCAI
   [Anonymous], 2011, P IEEECVF C COMPUTER
   Ben-David S., 2007, ADV NEURAL INFORM PR, V19
   Bousmalis G., 2016, Advances in Neural Information Processing Systems, V29, P1
   Chang JL, 2017, IEEE I CONF COMP VIS, P5880, DOI [10.1109/ICCV.2017.626, 10.1109/ICCV.2017.627]
   Chapelle O., 2005, Proceedings of the tenth international workshop on artificial intelligence and statistics, P57
   Chen-Yu Lee, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10277, DOI 10.1109/CVPR.2019.01053
   Denker J.S., 1989, Advances in Neural Information Processing Systems, P323
   Donahue J, 2014, PR MACH LEARN RES, V32
   Ganin Yaroslav, 2016, JMLR, V17, P2096, DOI DOI 10.1007/978-3-319-58347-1_10
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo XF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1753
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hu LQ, 2018, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2018.00162
   Karlekar A, 2019, IEEE ACCESS, V7, P55121, DOI 10.1109/ACCESS.2019.2910195
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu M.-Y., 2016, P ADV NEUR INF PROC, P469
   Long MS, 2013, IEEE I CONF COMP VIS, P2200, DOI 10.1109/ICCV.2013.274
   Netzer Yuval, 2011, ADV NEUR INF PROC SY
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pei Zhongyi, 2018, AAAI CONF ARTIF INTE
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Seal A, 2020, APPL SOFT COMPUT, V88, DOI 10.1016/j.asoc.2019.106016
   Sharma K.K., 2020, EXPERT SYST APPL
   Sharma KK, 2021, KNOWL-BASED SYST, V211, DOI 10.1016/j.knosys.2020.106567
   Sharma KK, 2021, INFORM SCIENCES, V547, P723, DOI 10.1016/j.ins.2020.08.080
   Sharma KK, 2020, ENG APPL ARTIF INTEL, V96, DOI 10.1016/j.engappai.2020.103928
   Sharma KK, 2019, EXPERT SYST APPL, V137, P100, DOI 10.1016/j.eswa.2019.06.050
   Sun BC, 2017, ADV COMPUT VIS PATT, P153, DOI 10.1007/978-3-319-58347-1_8
   Sun MX, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUIT TECHNOLOGY (ICSICT), P478, DOI 10.1109/ICSICT.2016.7998956
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Venkateswara H, 2017, PROC CVPR IEEE, P5385, DOI 10.1109/CVPR.2017.572
   Yosinski J, 2014, ADV NEUR IN, V27
   Yu CH, 2019, IEEE DATA MINING, P778, DOI 10.1109/ICDM.2019.00088
   Zeng KW, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103913
   Zhang LH, 2015, INT CONF SOFTW ENG, P931, DOI 10.1109/ICSESS.2015.7339207
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhuang FZ, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4119
NR 42
TC 19
Z9 19
U1 14
U2 101
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104137
DI 10.1016/j.imavis.2021.104137
EA FEB 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600002
DA 2024-07-18
ER

PT J
AU Liu, YF
   Chen, JH
AF Liu, Yanfei
   Chen, Junhua
TI Unsupervised face Frontalization for pose-invariant face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face frontalization generative adversarial network pose-invariant face
   recognition
ID CNN
AB Face frontalization aims to normalize profile faces to frontal ones for pose-invariant face recognition. Current works have achieved promising results in face frontalization by using deep learning techniques. However, training deep models of face frontalization usually needs paired training data which is undoubtedly costly and time-consuming to acquire. To address this issue, we propose a Pose Conditional CycleGAN (PCCycleGAN) to generate authentic and identity-preserving frontal face images for pose-invariant face recognition. First, through coupling with a pair of inverse mappings, constraining with cycle consistent loss and using conditional pose label to control specific face pose generation, PCCycleGAN can be trained with unpaired samples. Second, pixel-level loss, feature space perception loss, and identity preserving loss are introduced in PCCycleGAN to help synthesize realistic and identity-preserving frontal face images. Extensive experiments on both constrained Multi-PIE dataset and unconstrained LFW and IJB-A datasets are conducted on face synthesis and pose-invariant face recognition. Results demonstrate that the proposed face frontalization model can synthesize frontal faces with high image quality as well as maintaining the identity information in both the constrained and unconstrained environments. In addition, our method enhances the performance of face recognition on the Multi-PIE, LFW and IJB-A datasets and achieves competitive face recognition performance on LFW and IJB-A datasets. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Liu, Yanfei] Chongqing Univ Technol, Sch Artificial Intelligence, 69 Hongguang Ave, Chongqing, Peoples R China.
   [Chen, Junhua] Chongqing Univ Posts & Telecommun, Key Lab Ind Internet Things & Networked Control, Chongqing, Peoples R China.
C3 Chongqing University of Technology; Chongqing University of Posts &
   Telecommunications
RP Chen, JH (corresponding author), Chongqing Univ Posts & Telecommun, Key Lab Ind Internet Things & Networked Control, Chongqing, Peoples R China.
EM chenjh@cqupt.edu.cn
FU National Natural Science Foundation of China [61502444]; youth project
   of science and technology research program of Chongqing Education
   Commission of China [KJQN201801119]; Scientific Research Foundation of
   Chongqing University of Technology [2017ZD58]
FX This research is supported by the National Natural Science Foundation of
   China (Grant No. 61502444), the youth project of science and technology
   research program of Chongqing Education Commission of China (Grant No.
   KJQN201801119), and the Scientific Research Foundation of Chongqing
   University of Technology (Grant No. 2017ZD58).
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2014, LEARNING FACE REPRES
   [Anonymous], 2008, LABELED FACES WILD D
   Bao JM, 2018, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2018.00702
   Cohn J., 2008, IEEE INT CONF AUTOMA, P1
   Ding CX, 2017, PATTERN RECOGN, V66, P144, DOI 10.1016/j.patcog.2016.11.024
   Dou H, 2019, INT CONF ACOUST SPEE, P1757, DOI [10.1109/icassp.2019.8682600, 10.1109/ICASSP.2019.8682600]
   Fang Y., 2020, PATTERN RECOGN, V102, P1
   Ge Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, P12
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Hassner T, 2015, PROC CVPR IEEE, P4295, DOI 10.1109/CVPR.2015.7299058
   Hu YB, 2018, PROC CVPR IEEE, P8398, DOI 10.1109/CVPR.2018.00876
   Huang R, 2017, IEEE I CONF COMP VIS, P2458, DOI 10.1109/ICCV.2017.267
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jourabloo A, 2017, INT J COMPUT VISION, V124, P187, DOI 10.1007/s11263-017-1012-z
   Khan A, 2016, CVPR
   Kingma D. P., 2014, arXiv
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Li C, 2016, PROC CVPR IEEE, P2479, DOI 10.1109/CVPR.2016.272
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P5881, DOI 10.1109/TIP.2019.2922854
   Maas Andrew L, 2013, P INT C MACH LEARN A, V30, P3
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Masi I, 2016, PROC CVPR IEEE, P4838, DOI 10.1109/CVPR.2016.523
   Mirza S. O. Mehdi, 2014, ARCXIV14111784
   Parkhi A. V. O. M, 2015, BRIT MACH VIS C
   Qi GJ, 2020, INT J COMPUT VISION, V128, P1118, DOI 10.1007/s11263-019-01265-2
   Rong C., 2020, IEEE Access, V4, P1
   Sagonas C, 2015, IEEE I CONF COMP VIS, P3871, DOI 10.1109/ICCV.2015.441
   Shen YJ, 2018, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2018.00092
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Xiong C, 2015, IEEE I CONF COMP VIS, P3667, DOI 10.1109/ICCV.2015.418
   Yim J, 2015, PROC CVPR IEEE, P676, DOI 10.1109/CVPR.2015.7298667
   Yin X, 2017, IEEE I CONF COMP VIS, P4010, DOI 10.1109/ICCV.2017.430
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhao J, 2017, Neural information processing systems (NIPS)
   Zhao J, 2018, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2018.00235
   Zhao J, 2019, IEEE T PATTERN ANAL, V41, P2380, DOI 10.1109/TPAMI.2018.2858819
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XY, 2015, PROC CVPR IEEE, P787, DOI 10.1109/CVPR.2015.7298679
NR 43
TC 11
Z9 11
U1 1
U2 49
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104093
DI 10.1016/j.imavis.2020.104093
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700010
DA 2024-07-18
ER

PT J
AU Farazi, MR
   Khan, SH
   Barnes, N
AF Farazi, Moshiur R.
   Khan, Salman H.
   Barnes, Nick
TI From known to the unknown: Transferring knowledge to answer questions
   about novel visual and semantic concepts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual Question Answering; Computer vision; Deep learning; Natural
   language processing; Dataset bias
AB Current Visual Question Answering (VQA) systems can answer intelligent questions about 'known' visual content. However, their performance drops significantly when questions about visually and linguistically 'unknown' concepts are presented during inference ('Open-world' scenario). A practical VQA systemshould be able to dealwith novel concepts in real world settings. To address this problem, we propose an exemplar-based approach that transfers learning (i.e., knowledge) from previously 'known' concepts to answer questions about the 'unknown'. We learn a highly discriminative joint embedding (JE) space, where visual and semantic features are fused to give a unified representation. Once novel concepts are presented to the model, it looks for the closest match from an exemplar set in the JE space. This auxiliary information is used alongside the given Image-Question pair to refine visual attention in a hierarchical fashion. Our novel attention model is based on a dual-attention mechanismthat combines the complementary effect of spatial and channel attention. Since handling the high dimensional exemplars on large datasets can be a significant challenge, we introduce an efficientmatching scheme that uses a compact feature description for search and retrieval. To evaluate ourmodel, we propose a newdataset for VQA, separating unknown visual and semantic concepts fromthe training set. Our approach shows significant improvements over state-of-the-art VQA models on the proposed Open-World VQA dataset and other standard VQA datasets. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Farazi, Moshiur R.; Khan, Salman H.; Barnes, Nick] Australian Natl Univ ANU, Coll Engn & Comp Sci, Canberra, ACT 0200, Australia.
   [Farazi, Moshiur R.] CSIRO, Data61, Canberra, ACT 2601, Australia.
   [Khan, Salman H.] Mohamed Bin Zayed Univ Artificial Intelligence MB, Abu Dhabi 0000, U Arab Emirates.
C3 Australian National University; Commonwealth Scientific & Industrial
   Research Organisation (CSIRO); Mohamed Bin Zayed University of
   Artificial Intelligence
RP Farazi, MR (corresponding author), Australian Natl Univ ANU, Coll Engn & Comp Sci, Canberra, ACT 0200, Australia.; Farazi, MR (corresponding author), CSIRO, Data61, Canberra, ACT 2601, Australia.
EM moshiur.farazi@anu.edu.au
RI Barnes, Nick/Y-2744-2018; Khan, Salman Hameed/M-4834-2016
OI Barnes, Nick/0000-0002-9343-9535; Khan, Salman
   Hameed/0000-0002-9502-1749
CR Agrawal A., ARXIV170408243
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], ARXIV14091259
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Ben-Younes H, 2019, AAAI CONF ARTIF INTE, P8102
   Ben-Younes Hedi., ICCV
   Cadene R., 2019, P INT C NEUR INF PRO, P839
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farazi M. R., 2018, BRIT MACH VIS C BMVC
   Fukui A., ARXIV160601847
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kim J.-H., ARXIV161004325
   Kiros Ryan., 2015, Advances in Neural Information Processing Systems 28: Annual Conference on Neural Information Processing Systems, P3294
   Krishna R., ARXIV160207332
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lu JS, 2016, ADV NEUR IN, V29
   Manjunatha V, 2019, PROC CVPR IEEE, P9554, DOI 10.1109/CVPR.2019.00979
   Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331
   McCloskey M., 1989, PSYCHOL LEARN MOTIV, V24, P109, DOI [10.1016/S0079-7421(08)60536-8, DOI 10.1016/S0079-7421(08)60536-8]
   Patro B., 2018, IEEE C COMP VIS PATT
   Ramakrishnan SK, 2017, PROC CVPR IEEE, P7312, DOI 10.1109/CVPR.2017.773
   Teney D., 2018, EUR C COMP VIS ECCV
   Teney D., ARXIV161105546
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Wang P, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1290
   Wang PC, 2017, PROC CVPR IEEE, P416, DOI 10.1109/CVPR.2017.52
   Wu CF, 2018, ADV NEUR IN, V31
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Zhang Y., 2018, LEARNING COUNT OBJEC
NR 35
TC 8
Z9 10
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 103985
DI 10.1016/j.imavis.2020.103985
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Massoli, FV
   Amato, G
   Falchi, F
AF Massoli, Fabio Valerio
   Amato, Giuseppe
   Falchi, Fabrizio
TI Cross-resolution learning for Face Recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Low resolution Face Recognition; Cross resolution Face
   Recognition
AB Convolutional Neural Network models have reached extremely high performance on the Face Recognition task. Mostly used datasets, such as VGGFace2, focus on gender, pose, and age variations, in the attempt of balancing them to empower models to better generalize to unseen data. Nevertheless, image resolution variability is not usually discussed, which may lead to a resizing of 256 pixels. While specific datasets for very low-resolution faces have been proposed, less attention has been paid on the task of cross-resolution matching. Hence, the discrimination power of a neural network might seriously degrade in such a scenario. Surveillance systems and forensic applications are particularly susceptible to this problem since, in these cases, it is common that a low-resolution query has to be matched against higher-resolution galleries. Although it is always possible to either increase the resolution of the query image or to reduce the size of the gallery (less frequently), to the best of our knowledge, extensive experimentation of cross-resolution matching was missing in the recent deep learning-based literature. In the context of low- and cross-resolution Face Recognition, the contribution of our work is fourfold: i) we proposed a training procedure to fine-tune a state-of-the-art model to empower it to extract resolution-robust deep features; ii) we conducted an extensive test campaign by using high-resolution datasets (IJB-B and IJB-C) and surveillance-camera-quality datasets (QMUL-SurvFace, TinyFace, and SCface) showing the effectiveness of our algorithm to train a resolution-robust model; iii) even though our main focus was the cross-resolution Face Recognition, by using our training algorithm we also improved upon state-of-the-art model performances considering low-resolution matches; iv) we showed that our approach could be more effective concerning preprocessing faces with super-resolution techniques.
   The python code of the proposed method will be available at https://github.com/fvmassoli/cross-resolution-face-recognition. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Massoli, Fabio Valerio; Amato, Giuseppe; Falchi, Fabrizio] CNR, ISTI, Via G Moruzzi 1, I-56124 Pisa, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Scienza e
   Tecnologie dell'Informazione "Alessandro Faedo" (ISTI-CNR)
RP Massoli, FV (corresponding author), CNR, ISTI, Via G Moruzzi 1, I-56124 Pisa, Italy.
EM fabio.massoli@isti.cnr.it
RI Massoli, Fabio Valerio/AAV-3705-2020; Amato, Giuseppe/F-2227-2013;
   Falchi, Fabrizio/J-2920-2012
OI Massoli, Fabio Valerio/0000-0001-6447-1301; Amato,
   Giuseppe/0000-0003-0171-4315; Falchi, Fabrizio/0000-0001-6258-5313
FU AI4EU project - EC (H2020) [825619]; NVIDIA Corporation
FX This work was partially supported by the AI4EU project, funded by the EC
   (H2020 -Contract n. 825619). We gratefully acknowledge the support of
   NVIDIA Corporation with the donation of the Titan V GPU used for this
   research.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], ARXIV170702733
   [Anonymous], 2018, ABS180406655 CORR
   Bengio Y., 2009, P 26 ANN INT C MACH, V60, P6, DOI [DOI 10.1145/1553374.1553380, 10.1145/1553374.1553380]
   Biswas S, 2012, IEEE T PATTERN ANAL, V34, P2019, DOI 10.1109/TPAMI.2011.278
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Cheng Z., 2018, ASIAN C COMPUTER VIS, P605
   Cheng Z., 2018, ARXIV80409691
   Dean J., 2015, NIPS DEEP LEARNING R
   Ekenel HK, 2005, IMAGE VISION COMPUT, V23, P469, DOI 10.1016/j.imavis.2004.09.002
   Ge SM, 2019, IEEE T IMAGE PROCESS, V28, P2051, DOI 10.1109/TIP.2018.2883743
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Grother P. J., 2018, TECHNICAL REPORT
   Günther M, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P697, DOI 10.1109/BTAS.2017.8272759
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Herrmann C, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P221, DOI 10.1109/AVSS.2016.7738017
   Jian M, 2015, IEEE T CIRC SYST VID, V25, P1761, DOI 10.1109/TCSVT.2015.2400772
   Kim Jun-Hyuk, 2018, P IEEE C COMP VIS PA
   Kolouri S, 2015, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR.2015.7299121
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Li P, 2019, IEEE T INF FOREN SEC, V14, P2000, DOI 10.1109/TIFS.2018.2890812
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Lu ZJ, 2018, IEEE ACCESS, V6, DOI [10.1109/ACCESS.2018.2864189, 10.1109/LSP.2018.2810121]
   Luo XL, 2019, PATTERN RECOGN, V93, P283, DOI 10.1016/j.patcog.2019.04.027
   Maze B, 2018, INT CONF BIOMETR, P158, DOI 10.1109/ICB2018.2018.00033
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Radford A., 2015, ARXIV
   Shekhar S., 2011, P INT JOINT C BIOMET P 2011 INT JOINT C B, P1
   Singh M, 2018, INT CONF CYBER DIST, P479, DOI 10.1109/CyberC.2018.00093
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Whitelam C., P IEEE C COMP VIS PA, P90
   Yang JC, 2010, IEEE T IMAGE PROCESS, V19, P2861, DOI 10.1109/TIP.2010.2050625
   Yang MC, 2015, INT CONF BIOMETR, P237, DOI 10.1109/ICB.2015.7139090
   Yu X., 2018, P EUR C COMP VIS ECC, P217
   Zangeneh E., 2017, ARXIV170606247
   Zhang K., 2018, P EUR C COMP VIS ECC, P183
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 41
TC 38
Z9 40
U1 1
U2 40
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2020
VL 99
AR 103927
DI 10.1016/j.imavis.2020.103927
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LZ3LW
UT WOS:000541130800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xu, BL
   Liu, JX
   Hou, XX
   Liu, BZ
   Qiu, GP
AF Xu, Bolei
   Liu, Jingxin
   Hou, Xianxu
   Liu, Bozhi
   Qiu, Guoping
TI Deep reinforcement learning-based patch selection for illuminant
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Color constancy; Reinforcement learning; Patch selection
ID COLOR CONSTANCY
AB Previous deep learning based approaches to illuminant estimation either resized the raw image to lows resolution or randomly cropped image patches for the deep learning model. However, such practices would inevitably lead to information loss or the selection of noisy patches that would affect estimation accuracy In this paper, we regard patch selection in neural network based illuminant estimation as a controlling problem of selecting image patches that could help remove noisy patches and improve estimation accuracy To achieve this, we construct a selection network (SeNet) to learn a patch selection policy. Based on data statistics and the learning progression state of the deep illuminant estimation network (DeNet), the SeNs decides which training patches should be input to the DeNet, which in turn gives feedback to the SeNet fc it to update its selection policy. To achieve such interactive and intelligent learning, we utilize a reinforcement learning approach termed policy gradient to optimize the SeNet. We show that the proposed learning strategy can enhance the illuminant estimation accuracy, speed up the convergence and improve the stability of the training process of DeNet. We evaluate our method on two public datasets and demonstrate of method outperforms state-of-the-art approaches. (C) 2019 Elsevier B.V. All rights reservesed
C1 [Xu, Bolei; Liu, Jingxin; Hou, Xianxu; Liu, Bozhi; Qiu, Guoping] Shenzhen Univ, Coll Informat Engn, Shenzhen, Guangdong, Peoples R China.
   [Qiu, Guoping] Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Guangdong, Peoples R China.
   [Qiu, Guoping] Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen, Guangdong, Peoples R China.
   [Qiu, Guoping] Univ Nottingham, Nottingham, England.
C3 Shenzhen University; Shenzhen Institute of Artificial Intelligence &
   Robotics for Society; University of Nottingham
RP Qiu, GP (corresponding author), Shenzhen Univ, Coll Informat Engn, Shenzhen, Guangdong, Peoples R China.
EM guoping.qiu@nottingham.ac.uk
RI Xu, Bolei/GRO-1172-2022
OI Qiu, Guoping/0000-0002-5877-5648; Liu, Jingxin/0000-0001-6071-9197
CR [Anonymous], ARXIV150404548
   [Anonymous], ARXIV180106302
   [Anonymous], PROC CVPR IEEE
   [Anonymous], COL IM C 2004 SOC IM
   [Anonymous], 2012, BRIT MACH VIS C
   [Anonymous], 2000, Re-processed version of the gehler color constancy dataset of 568 images
   [Anonymous], 2013, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2013.239
   [Anonymous], ARXIV180503643
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Barnard K, 2000, LECT NOTES COMPUT SC, V1842, P390
   Barron Jonathan, 2017, IEEE C COMP VIS PATT
   Barron JT, 2015, IEEE I CONF COMP VIS, P379, DOI 10.1109/ICCV.2015.51
   Bianco S, 2017, IEEE T IMAGE PROCESS, V26, P4347, DOI 10.1109/TIP.2017.2713044
   BRAINARD DH, 1986, J OPT SOC AM A, V3, P1651, DOI 10.1364/JOSAA.3.001651
   BUCHSBAUM G, 1980, J FRANKLIN I, V310, P1, DOI 10.1016/0016-0032(80)90058-7
   Chakrabarti A, 2012, IEEE T PATTERN ANAL, V34, P1509, DOI 10.1109/TPAMI.2011.252
   Cheng DL, 2015, PROC CVPR IEEE, P1000, DOI 10.1109/CVPR.2015.7298702
   Cheng DL, 2014, J OPT SOC AM A, V31, P1049, DOI 10.1364/JOSAA.31.001049
   FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770
   Funt B, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P47
   Funt B, 1996, FOURTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS AND APPLICATIONS, P58
   Funt B, 2010, COLOR IMAG CONF, P256
   Gehler PV, 2008, PROC CVPR IEEE, P3291
   Gijsenij A, 2011, IEEE T IMAGE PROCESS, V20, P2475, DOI 10.1109/TIP.2011.2118224
   Gijsenij A, 2011, IEEE T PATTERN ANAL, V33, P687, DOI 10.1109/TPAMI.2010.93
   Gijsenij A, 2010, INT J COMPUT VISION, V86, P127, DOI 10.1007/s11263-008-0171-3
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   Lou Z., 2015, BMVC, P76
   Oh SW, 2017, PATTERN RECOGN, V61, P405, DOI 10.1016/j.patcog.2016.08.013
   Qian Y., 2019, P IEEECVF C COMPUTER, P8062
   Rosenberg C, 2004, ADV NEUR IN, V16, P1595
   Shi W, 2016, LECT NOTES COMPUT SC, V9908, P371, DOI 10.1007/978-3-319-46493-0_23
   Stanikunas R, 2004, NEURAL NETWORKS, V17, P327, DOI 10.1016/j.neunet.2003.12.002
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Van de Weijer J, 2007, IEEE T IMAGE PROCESS, V16, P2207, DOI 10.1109/TIP.2007.901808
   Wang F, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043010
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
NR 40
TC 0
Z9 0
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2019
VL 91
AR 103798
DI 10.1016/j.imavis.2019.08.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU3YI
UT WOS:000501614200006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Adeli, V
   Fazl-Ersi, E
   Harati, A
AF Adeli, Vida
   Fazl-Ersi, Ehsan
   Harati, Ahad
TI A component-based video content representation for action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Actionness likelihood; Action recognition; Action components; LSTM;
   Three-stream convolutional neural network
ID MOTION REPRESENTATION
AB This paper investigates the challenging problem of action recognition in videos and proposes a new component-based approach for video content representation. Although satisfactory performance for action recognition has already been obtained for certain scenarios, many of the existing solutions require fully-annotated video datasets in which region of the activity in each frame is specified by a bounding box. Another group of methods require auxiliary techniques to extract human-related areas in the video frames before being able to accurately recognize actions. In this paper, a Weakly-Supervised Learning (WSL) framework is introduced that eliminates the need for per-frame annotations and learns video representations that improve recognition accuracy and also highlights the activity related regions within each frame. To this end, two new representation ideas are proposed, one focus on representing the main components of an action, i.e. actionness regions, and the other focus on encoding the background context to represent general and holistic cues. A three-stream CNN is developed, which takes the two proposed representations and combines them with a motion-encoding stream. Temporal cues in each of the three different streams are modeled through LSTM, and finally fully-connected neural network layers are used to fuse various streams and produce the final video representation. Experimental results on four challenging datasets, demonstrate that the proposed Component-based Multi-stream CNN model (CM-CNN), trained on a WSL setting, outperforms the state-of-the-art in action recognition, even the fully-supervised approaches. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Adeli, Vida; Fazl-Ersi, Ehsan; Harati, Ahad] Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad 9177948944, Razavi Khorasan, Iran.
C3 Ferdowsi University Mashhad
RP Fazl-Ersi, E (corresponding author), Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad 9177948944, Razavi Khorasan, Iran.
EM fazlersi@um.ac.ir
RI Harati, Ahad/P-4468-2015
OI Harati, Ahad/0000-0001-7263-0309; Fazl-Ersi, Ehsan/0000-0001-7384-1618
CR [Anonymous], 2016, P 33 INT C MACHINE L
   Blank M, 2005, IEEE I CONF COMP VIS, P1395
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carreira J, ARXIV170506950
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen M, 2011, INT CONF CLOUD COMPU, P316, DOI 10.1109/CCIS.2011.6045082
   Cherian A, 2017, PROC CVPR IEEE, P1581, DOI 10.1109/CVPR.2017.172
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2018, IEEE T IMAGE PROCESS, V27, P1347, DOI 10.1109/TIP.2017.2778563
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Fan LJ, 2018, PROC CVPR IEEE, P6016, DOI 10.1109/CVPR.2018.00630
   Feichtenhofer C., ARXIV181203982
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Feichtenhofer Christoph, 2018, CONNECTIONS, V19, P29
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Hou R, 2017, IEEE I CONF COMP VIS, P5823, DOI 10.1109/ICCV.2017.620
   Huang DA, 2018, PROC CVPR IEEE, P7366, DOI 10.1109/CVPR.2018.00769
   Jain M, 2014, PROC CVPR IEEE, P740, DOI 10.1109/CVPR.2014.100
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kalogeiton V, 2017, IEEE I CONF COMP VIS, P4415, DOI 10.1109/ICCV.2017.472
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Liu K, 2018, AAAI CONF ARTIF INTE, P7138
   Lu JS, 2015, PROC CVPR IEEE, P3762, DOI 10.1109/CVPR.2015.7299000
   Marszalek M, 2009, PROC CVPR IEEE, P2921, DOI 10.1109/CVPRW.2009.5206557
   Ng JYH, 2018, IEEE WINT CONF APPL, P1606, DOI 10.1109/WACV.2018.00179
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Piergiovanni AJ, 2019, PROC CVPR IEEE, P9937, DOI 10.1109/CVPR.2019.01018
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodriguez MD, 2008, PROC CVPR IEEE, P3001, DOI 10.1109/cvpr.2008.4587727
   Saha S, 2017, IEEE I CONF COMP VIS, P4424, DOI 10.1109/ICCV.2017.473
   Simonyan K., 2014, P 27 INT C NEUR INF, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Singh G, 2017, IEEE I CONF COMP VIS, P3657, DOI 10.1109/ICCV.2017.393
   Singh Gurkirt, 2018, P EUR C COMP VIS ECC
   Sipiran I, 2011, VISUAL COMPUT, V27, P963, DOI 10.1007/s00371-011-0610-y
   Soomro K, 2017, IEEE I CONF COMP VIS, P696, DOI 10.1109/ICCV.2017.82
   Srivastava N, 2015, PR MACH LEARN RES, V37, P843
   Stroud J.C., ARXIV181208249
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Tian YC, 2013, PROC CVPR IEEE, P2642, DOI 10.1109/CVPR.2013.341
   Tran D., 1708, 1708 ARXIV
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Tu ZG, 2018, PATTERN RECOGN, V79, P32, DOI 10.1016/j.patcog.2018.01.020
   Uddin MDA, 2017, IEEE ACCESS, V5, P21157, DOI 10.1109/ACCESS.2017.2759225
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang LM, 2016, PROC CVPR IEEE, P2708, DOI 10.1109/CVPR.2016.296
   Wu CY, 2018, PROC CVPR IEEE, P6026, DOI 10.1109/CVPR.2018.00631
   Xie Saining, 2017, ARXIV171204851, V1, P5
   Ye YC, 2019, J VIS COMMUN IMAGE R, V58, P515, DOI 10.1016/j.jvcir.2018.12.019
   Zhang MW, 2018, MULTIMED TOOLS APPL, V77, P3303, DOI 10.1007/s11042-017-5116-9
   Zolfaghari M, 2017, IEEE I CONF COMP VIS, P2923, DOI 10.1109/ICCV.2017.316
NR 64
TC 9
Z9 10
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2019
VL 90
AR 103805
DI 10.1016/j.imavis.2019.08.009
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU0WT
UT WOS:000501400600004
DA 2024-07-18
ER

PT J
AU Sharma, RP
   Dey, S
AF Sharma, Ram Prakash
   Dey, Somnath
TI Two-stage quality adaptive fingerprint image enhancement using Fuzzy
   C-means clustering based fingerprint quality analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Fingerprint image quality; Fuzzy C-means clustering;
   Fingerprint image enhancement; Fingerprint matching
ID FILTER; SYSTEM; DIFFUSION; ALGORITHM; FEATURES; NETWORK; WAVELET
AB Fingerprint recognition techniques are dependent on the quality of fingerprint images. An efficient enhancement algorithm improves the performance of recognition algorithms for poor quality images. Performance improvement of the recognition algorithms will be more if the enhancement process is adaptive to the fingerprint qualities (wet, dry or normal). In this paper, a quality adaptive fingerprint enhancement algorithm is proposed. The proposed fingerprint quality assessment (FQA) algorithm assigns the appropriate quality class of dry, wet, normal dry, normal wet, and good quality using Fuzzy C-means clustering technique to each fingerprint image. It considers seven features namely, mean, moisture, variance, uniformity, contrast, ridge valley area uniformity (RVAU), and ridge valley uniformity (RVU) to cluster the fingerprint images into suitable quality class. Fingerprint images of each quality class undergo through a two-stage fingerprint quality enhancement (FQE) process. In the first stage, a quality adaptive preprocessing (QAP) method is used to preprocess the fingerprint images. Next, fingerprint images are enhanced with Gabor, short-term Fourier transform (SIFT), and oriented diffusion filtering (ODF) based enhancement techniques in the second stage. Experimental evaluations are performed on a quality driven database of FVC 2004. Results show that the performance improvement of 1.54% to 50.62% for NBIS matcher and 1.66% to 8.95% for VeriFinger matcher are achieved while the QAP based approaches are used in comparison to the current state-of-the-art enhancement techniques. In addition, the experimentation is also performed on FVC 2002 database to validate the robustness and efficacy of the proposed method. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Sharma, Ram Prakash; Dey, Somnath] Indian Inst Technol Indore, Discipline Comp Sci & Engn, Simrol, Madhya Pradesh, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Indore
RP Sharma, RP (corresponding author), Indian Inst Technol Indore, Discipline Comp Sci & Engn, Simrol, Madhya Pradesh, India.
EM phd1501201003@iiti.ac.in; somnathd@iiti.ac.in
RI Sharma, Ram Prakash/IAN-9085-2023
OI Sharma, Ram Prakash/0000-0002-1851-2325
FU SERB, Department of Science and Technology, Government of India
   [ECR/2017/000027]
FX The authors are thankful to SERB (ECR/2017/000027), Department of
   Science and Technology, Government of India for providing financial
   support. Also, We would like to acknowledge Indian Institute of
   Technology Indore for providing the laboratory support and research
   facilities to carry out this research work.
CR Alonso-Fernandez F, 2007, IEEE T INF FOREN SEC, V2, P734, DOI 10.1109/TIFS.2007.908228
   [Anonymous], 2005, P INT C IM PROC
   [Anonymous], 2011, P 2011 INT JOINT C B
   Bartunek JS, 2013, IEEE T IMAGE PROCESS, V22, P644, DOI 10.1109/TIP.2012.2220373
   Bharadwaj S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-34
   Cao K, 2015, INT CONF BIOMETR, P349, DOI 10.1109/ICB.2015.7139060
   Cappelli R, 2006, IEEE T PATTERN ANAL, V28, P3, DOI 10.1109/TPAMI.2006.20
   Chikkerur S, 2007, PATTERN RECOGN, V40, P198, DOI 10.1016/j.patcog.2006.05.036
   Ding SF, 2017, IET BIOMETRICS, V6, P438, DOI 10.1049/iet-bmt.2016.0161
   Ding SF, 2017, INFORM SCIENCES, V415, P233, DOI 10.1016/j.ins.2017.06.028
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Fahmy MF, 2013, IEEE INT SYMP SIGNAL, P215, DOI 10.1109/ISSPIT.2013.6781882
   Fronthaler H, 2008, IEEE T IMAGE PROCESS, V17, P354, DOI 10.1109/TIP.2007.916155
   Ghafoor M, 2014, IET IMAGE PROCESS, V8, P417, DOI 10.1049/iet-ipr.2013.0528
   Ghiani L, 2017, IMAGE VISION COMPUT, V58, P110, DOI 10.1016/j.imavis.2016.07.002
   Gottschlich C, 2012, IET BIOMETRICS, V1, P105, DOI 10.1049/iet-bmt.2012.0003
   Gottschlich C, 2012, IEEE T IMAGE PROCESS, V21, P2220, DOI 10.1109/TIP.2011.2170696
   Greenberg S, 2002, REAL-TIME IMAGING, V8, P227, DOI 10.1006/rtim.2001.0283
   Hasan H, 2013, NEURAL COMPUT APPL, V23, P1605, DOI 10.1007/s00521-012-1113-0
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Hsieh CT, 2003, PATTERN RECOGN, V36, P303, DOI 10.1016/S0031-3203(02)00032-8
   Hu Y, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 2, P195, DOI 10.1109/ICACC.2010.5487213
   Jin ATB, 2004, IMAGE VISION COMPUT, V22, P503, DOI 10.1016/j.imavis.2003.12.002
   Jirachaweng S, 2007, LECT NOTES COMPUT SC, V4642, P96
   Li J, 2018, SIGNAL PROCESS-IMAGE, V60, P52, DOI 10.1016/j.image.2017.08.010
   Lim E., 2004, 2004 International Conference on Image Processing (ICIP) (IEEE Cat. No.04CH37580), P1241
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Maio D, 2002, INT C PATT RECOG, P811, DOI 10.1109/ICPR.2002.1048144
   Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140
   Maltoni D., 2009, HDB FINGERPRINT RECO
   Mehtre B. M., 1993, Machine Vision and Applications, V6, P124, DOI 10.1007/BF01211936
   Munir MU, 2012, NEUROCOMPUTING, V85, P62, DOI 10.1016/j.neucom.2012.01.002
   Nagaty KA, 2005, IMAGE VISION COMPUT, V23, P491, DOI 10.1016/j.imavis.2004.12.001
   OGORMAN L, 1989, PATTERN RECOGN, V22, P29, DOI 10.1016/0031-3203(89)90035-6
   Olsen M., 2015, P 3 INT WORKSHOP BIO, P1
   Olsen MA, 2016, IET BIOMETRICS, V5, P47, DOI 10.1049/iet-bmt.2014.0055
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Patil A, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPUTATION SYSTEM AND INFORMATION TECHNOLOGY FOR SUSTAINABLE SOLUTIONS (CSITSS), P188, DOI 10.1109/CSITSS.2016.7779420
   Ratha NK, 1996, IEEE T PATTERN ANAL, V18, P799, DOI 10.1109/34.531800
   Schouten B, 2009, IMAGE VISION COMPUT, V27, P305, DOI 10.1016/j.imavis.2008.05.008
   Schuch P, 2018, IET BIOMETRICS, V7, P102, DOI 10.1049/iet-bmt.2016.0088
   Seghetti L. M., 2004, CRS REP C, P1
   Sharma T, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL CONFERENCE ON INVENTIVE COMMUNICATION AND COMPUTATIONAL TECHNOLOGIES (ICICCT), P1, DOI 10.1109/ICICCT.2017.7975155
   SHERLOCK BG, 1994, IEE P-VIS IMAGE SIGN, V141, P87, DOI 10.1049/ip-vis:19949924
   Sutthiwichaiporn Prawit, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1257, DOI 10.1109/ICPR.2010.313
   Tabassi  E., 2016, DEV NFIQ 2 0 NIST
   Turroni F., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P152, DOI 10.1109/ICB.2012.6199773
   Wang W, 2008, PATTERN RECOGN LETT, V29, P301, DOI 10.1016/j.patrec.2007.10.004
   Watson C.I., 2007, USERS GUIDE NIST BIO
   Willis AJ, 2001, PATTERN RECOGN, V34, P255, DOI 10.1016/S0031-3203(00)00003-0
   Yang JC, 2013, IEEE T HUM-MACH SYST, V43, P235, DOI 10.1109/TSMCC.2011.2174049
   Yun EK, 2006, IMAGE VISION COMPUT, V24, P101, DOI 10.1016/j.imavis.2005.09.017
   Zhu GC, 2004, LECT NOTES COMPUT SC, V3338, P439
   2015, 2015 IEEE SYMPOSIUM, P354
   2012, SOFT COMPUTING, V16, P1555
NR 55
TC 22
Z9 24
U1 3
U2 22
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR-APR
PY 2019
VL 83-84
BP 1
EP 16
DI 10.1016/j.imavis.2019.02.006
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HW6TR
UT WOS:000466824000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zheng, DC
   Liu, WS
   Han, M
AF Zheng, Danchen
   Liu, Wangshu
   Han, Min
TI Learning contextual dissimilarity on tensor product graph for visual
   re-ranking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Diffusion process; Contextual dissimilarity; Tensor product graph; Mean
   first-passage time; Hybrid fitting constraint
ID DIFFUSION
AB As the object retrieval problem cannot be well solved by pairwise distances, many algorithms have been developed for visual re-ranking as the post-processing step. As discussed in recent studies, the contextual similarity/dissimilarity based on diffusion process can be obtained by solving an optimization problem that contains a smoothness constraint and a fitting constraint. In this paper, we introduce the mean first-passage time (MFPT) as the contextual dissimilarity. By analysis of the principle behind MFPT, one can find that the corresponding cost function is generated with a hybrid fitting constraint, and the predefined values of contextual dissimilarities are limited within proper ranges. With the hybrid fitting constraint and the smoothness constraint based on a tensor product graph, we construct the objective function associated with a novel contextual dissimilarity. On that basis, we obtain the contextual dissimilarities as an iterative solution by solving the optimization problem, and the manifold structure can be effectively captured by using the proposed method. Our method is evaluated on retrieval tasks for different databases, and the re-ranking result with the proposed contextual dissimilarity outperforms other state-of-the-art algorithms. (C) 2018 Published by Elsevier B.V.
C1 [Zheng, Danchen; Liu, Wangshu; Han, Min] Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116023, Peoples R China.
C3 Dalian University of Technology
RP Han, M (corresponding author), Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116023, Peoples R China.
EM minhan@dlut.edu.cn
FU National Natural Science Foundation of China [61773087]; Fundamental
   Research Funds for the Central Universities [DUT17ZD216]
FX This research is supported by the project (61773087) of the National
   Natural Science Foundation of China and the project (DUT17ZD216) of the
   Fundamental Research Funds for the Central Universities.
CR Almeida J, 2016, IEEE J-STARS, V9, P5325, DOI 10.1109/JSTARS.2016.2608358
   [Anonymous], 1998, TECH REP
   [Anonymous], 2013, ACTA PRESS
   [Anonymous], ADV NEURAL INFORM PR
   Bai S, 2017, IEEE I CONF COMP VIS, P774, DOI 10.1109/ICCV.2017.90
   Bai S, 2017, AAAI CONF ARTIF INTE, P3967
   Bai S, 2017, PROC CVPR IEEE, P3356, DOI 10.1109/CVPR.2017.358
   Bai S, 2016, PROC CVPR IEEE, P5023, DOI 10.1109/CVPR.2016.543
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Bai X, 2014, IEEE T IMAGE PROCESS, V23, P3935, DOI 10.1109/TIP.2014.2336542
   Bai X, 2012, IEEE T IMAGE PROCESS, V21, P2747, DOI 10.1109/TIP.2011.2170082
   Bai X, 2009, IEEE I CONF COMP VIS, P575, DOI 10.1109/ICCV.2009.5459188
   Bai X, 2010, IEEE T PATTERN ANAL, V32, P861, DOI 10.1109/TPAMI.2009.85
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Condamin S, 2007, NATURE, V450, P77, DOI 10.1038/nature06201
   Donoser M, 2013, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2013.174
   Fauchald P, 2003, ECOLOGY, V84, P282, DOI 10.1890/0012-9658(2003)084[0282:UFPTIT]2.0.CO;2
   Jiang JY, 2011, IEEE I CONF COMP VIS, P794, DOI 10.1109/ICCV.2011.6126318
   Kontschieder Peter, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P655
   Li HY, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2440174
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Redner S., 2001, A Guide to First-Passage Processes
   Soderkvist Oskar., 2001, COMPUTER VISION CLAS, P74
   Soltani AA, 2017, PROC CVPR IEEE, P2511, DOI 10.1109/CVPR.2017.269
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tong Tong, 2015, Machine Learning in Medical Imaging. 6th International Workshop, MLMI 2015, held in conjunction with MICCAI 2015. Proceedings: LNCS 9352, P77, DOI 10.1007/978-3-319-24888-2_10
   Wang Chu, 2017, P BRIT MACH VIS C
   Wang JY, 2011, PATTERN RECOGN, V44, P2367, DOI 10.1016/j.patcog.2011.02.007
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xingwei Yang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2369, DOI 10.1109/CVPR.2011.5995325
   Yang XW, 2008, LECT NOTES COMPUT SC, V5305, P788, DOI 10.1007/978-3-540-88693-8_58
   Yang XW, 2013, IEEE T PATTERN ANAL, V35, P28, DOI 10.1109/TPAMI.2012.60
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Zhou DY, 2004, ADV NEUR IN, V16, P169
   Zhou Y, 2016, INT J COMPUT VISION, V118, P337, DOI 10.1007/s11263-015-0879-9
NR 35
TC 2
Z9 2
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 1
EP 10
DI 10.1016/j.imavis.2018.06.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800001
DA 2024-07-18
ER

PT J
AU Boulkenafet, Z
   Komulainen, J
   Hadid, A
AF Boulkenafet, Zinelabidine
   Komulainen, Jukka
   Hadid, Abdenour
TI On the generalization of color texture-based face anti-spoofing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Presentation attack detection; Spoofing; Color texture
   analysis; Cross-database; Generalization
ID LIVENESS DETECTION; IMAGE QUALITY; CLASSIFICATION; SYSTEMS; ATTACK
AB Despite the significant attention given to the problem of face spoofing, we still lack generalized presentation attack detection (PAD) methods performing robustly in practical face recognition systems. The existing face anti-spoofing techniques have indeed achieved impressive results when trained and evaluated on the same database (i.e. intra-test protocols). Cross-database experiments have, however, revealed that the performance of the state-of-the-art methods drops drastically as they fail to cope with new attacks scenarios and other operating conditions that have not been seen during training and development phases. So far, even the popular convolutional neural networks (CNN) have failed to derive well-generalizing features for face anti-spoofing. In this work, we explore the effect of different factors, such as acquisition conditions and presentation attack instrument (PAI) variation, on the generalization of color texture-based face anti spoofing. Our extensive cross-database evaluation of seven color texture-based methods demonstrates that most of the methods are unable to generalize to unseen spoofing attack scenarios. More importantly, the experiments show that some facial color texture representations are more robust to particular PAls than others. From this observation, we propose a face PAD solution of attack-specific countermeasures based solely on color texture analysis and investigate how well it generalizes under display and print attacks in different conditions. The evaluation of the method combining attack-specific detectors on three benchmark face anti-spoofing databases showed remarkable generalization ability against display attacks while print attacks require still further attention. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Boulkenafet, Zinelabidine; Komulainen, Jukka; Hadid, Abdenour] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
   [Hadid, Abdenour] Northwestern Polytech Univ, Sch Elect & Informat, Xian, Shaanxi, Peoples R China.
C3 University of Oulu; Northwestern Polytechnical University
RP Boulkenafet, Z (corresponding author), Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
EM zinelabidine.boulkenafet@oulu.fi
RI Komulainen, Jukka/O-6240-2017
OI Komulainen, Jukka/0000-0002-0102-7868
FU Finnish Foundation for Technology Promotion; Academy of Finland
FX The financial support from the Finnish Foundation for Technology
   Promotion and the Academy of Finland is acknowledged.
CR Anjos A, 2014, ADV COMPUT VIS PATT, P65, DOI 10.1007/978-1-4471-6524-8_4
   [Anonymous], 2004, PROC 10 ASSTA C
   [Anonymous], 2017, IEEE T INF FORENSICS
   [Anonymous], 2016, INFORM TECHNOLOGY BI
   [Anonymous], 2008, J. Recent Adv. in Face Recogn
   [Anonymous], 2014, CoRR
   Bai JM, 2010, IEEE INT SYMP CIRC S, P3425, DOI 10.1109/ISCAS.2010.5537866
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bharadwaj S, 2013, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2013.23
   Biggio B, 2012, IET BIOMETRICS, V1, P11, DOI 10.1049/iet-bmt.2011.0012
   Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Chingovska I, 2013, INT CONF BIOMETR
   Chingovska I., 2016, Face Recognition Across the Imaging Spectrum, P165, DOI 10.1007/978-3-319-28501-68
   Chingovska Ivana, 2012, IEEE INT C BIOM SPEC
   De Marsico M., 2012, INT C BIOM ICB
   Erdogmus N., 2013, BIOM THEOR APPL SYST
   Erdogmus N, 2013, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG 2013)
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Frischholz RW, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P234
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, INT C PATT RECOG, P1173, DOI 10.1109/ICPR.2014.211
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Hadid A, 2015, IEEE SIGNAL PROC MAG, V32, P20, DOI 10.1109/MSP.2015.2437652
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Komulainen J, 2013, INT CONF BIOMETR
   Kose N, 2013, IEEE INT CONF AUTOMA
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   Li X., 2016, INT C PATT REC ICPR
   Li Y., 2016, IEEE T DEPENDABLE SE, VPP
   Maatta J, 2011, INT JOINT C BIOM IJC, P1, DOI DOI 10.1109/IJCB.2011.6117510
   Marcel S, 2014, ADV COMPUT VIS PATT, P1, DOI 10.1007/978-1-4471-6524-8
   Ng ES, 2012, INT C PATT RECOG, P1249
   Nosaka R., 2012, ROTATION INVARIANT C, P15
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Patel K, 2016, LECT NOTES COMPUT SC, V9967, P611, DOI 10.1007/978-3-319-46654-5_67
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Pavlidis I, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P15, DOI 10.1109/CVBVS.2000.855246
   Pereira TD, 2013, INT CONF BIOMETR
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Pinto A, 2015, IEEE T IMAGE PROCESS, V24, P4726, DOI 10.1109/TIP.2015.2466088
   Raghavendra R, 2015, IEEE T IMAGE PROCESS, V24, P1060, DOI 10.1109/TIP.2015.2395951
   Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924
   Rastislav Lukac K. N. P., 2007, COLOR IMAGE PROCESSI, V8
   Rudd EM, 2016, IEEE COMPUT SOC CONF, P171, DOI 10.1109/CVPRW.2016.28
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Siddiqui T., 2016, INT C PATT REC ICPR
   Tan XY, 2010, LECT NOTES COMPUT SC, V6316, P504, DOI 10.1007/978-3-642-15567-3_37
   Tirunagari S, 2015, IEEE T INF FOREN SEC, V10, P762, DOI 10.1109/TIFS.2015.2406533
   Wang T, 2013, INT CONF BIOMETR
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Yang Jianwei, 2013, INT C BIOM ICB
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zhiwei Zhang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P436, DOI 10.1109/FG.2011.5771438
NR 58
TC 41
Z9 46
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2018
VL 77
BP 1
EP 9
DI 10.1016/j.imavis.2018.04.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV7DT
UT WOS:000446282900001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Alexiadis, DS
   Mitianoudis, N
   Stathaki, T
AF Alexiadis, Dimitrios S.
   Mitianoudis, Nikolaos
   Stathaki, Tania
TI Multidimensional directional steerable filters - Theory and application
   to 3D flow estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Steerable filters; Multi-dimensional signal processing; Frequency
   domain; 3D flow estimation
ID MOTION; DESIGN
AB In this paper, a thorough theoretical analysis on the construction of multi-dimensional directional steerable filters is given. Steerable filters have been constructed for up to three dimensions. We extend the relevant theory to multiple dimensions and construct multi-dimensional steerable filters, as well as quadrature pairs of such filters. Formulating the multi-dimensional motion estimation problem in the spatiotemporal frequency domain, it is shown that motion manifests itself as energy concentration along "motion hyper planes" in that domain. Subsequently, using the constructed multi-dimensional filters, we formulate the "hyper-donut" mechanism, i.e. a mechanism to efficiently "measure" the "motion energy" on a "motion hyper-plane". On top of that, rigorous mathematical analysis on the use of the constructed filters in the dense flow estimation task is given. Based on the theoretical developments, a steerable filter-based algorithm is formulated, in its simplest possible form, for estimating 3D flow in sequences of volumetric or point-cloud data. Experimental results on simulated and real-world data verify the validity of our arguments and the effectiveness of the proposed method. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Alexiadis, Dimitrios S.; Mitianoudis, Nikolaos] Democritus Univ Thrace, Dept Elect & Comp Engn, Univ Campus Xanthi, Xanthi 67100, Greece.
   [Stathaki, Tania] Imperial Coll London, Dept Elect & Elect Engn, Exhibit Rd, London SW7 2AZ, England.
C3 Democritus University of Thrace; Imperial College London
RP Alexiadis, DS (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Univ Campus Xanthi, Xanthi 67100, Greece.
EM dalexiad@iti.gr
RI Mitianoudis, Nikolaos/E-8184-2012; Stathaki, Tania/ADC-9453-2022
OI Mitianoudis, Nikolaos/0000-0003-0898-6102; 
FU F3SME research project [PE6 3210]; European Social Fund (ESF)
FX This work was supported by the F3SME research project (PE6 3210),
   implemented within the framework of the Action "Supporting Postdoctoral
   Researchers" of the Operational Program "Education and Lifelong
   Learning", and co-financed by the European Social Fund (ESF) and the
   Greek State.
CR Abràmoff MD, 2002, IEEE T MED IMAGING, V21, P296, DOI 10.1109/TMI.2002.1000254
   ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   Alexiadis D., 2013, 11 IEEE IVMSP WORKSH
   Alexiadis D, 2014, IEEE IMAGE PROC, P2012, DOI 10.1109/ICIP.2014.7025403
   Alexiadis DS, 2008, COMPUT VIS IMAGE UND, V110, P192, DOI 10.1016/j.cviu.2007.07.002
   Alexiadis DS, 2013, IEEE T MULTIMEDIA, V15, P339, DOI 10.1109/TMM.2012.2229264
   Alvarez L, 2007, LECT NOTES COMPUT SC, V4739, P612
   Andersson M.T., 1992, THESIS
   [Anonymous], 1992, THESIS MIT CAMBRIDGE
   Barron J., 2005, Tutorial: Computing 2D and 3D optical flow
   Barron JL, 2005, INT J IMAG SYST TECH, V15, P189, DOI 10.1002/ima.20048
   Barron JL, 2004, 1ST CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P370
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Cappé O, 2007, P IEEE, V95, P899, DOI 10.1109/JPROC.2007.893250
   Chen X, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P664, DOI 10.1109/ICIP.2001.958206
   Derpanis K., 2005, IEEE INT C IM PROC I
   Doumanoglou A., 2014, IEEE T CIRCUITS SYST
   DRIVER B., 2003, Analysis Tools with Applications
   Flannery B. P., 1992, NUMERICAL RECIPES C, DOI DOI 10.2277/052143064X
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301
   Gall J, 2007, J MATH IMAGING VIS, V28, P1, DOI 10.1007/s10851-007-0007-8
   Hazewinkel M., 2001, MULTINOMIAL COEFFICI
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Holte MB, 2012, IEEE J-STSP, V6, P553, DOI 10.1109/JSTSP.2012.2193556
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   HUANG CL, 1995, IMAGE VISION COMPUT, V13, P21, DOI 10.1016/0262-8856(95)91465-P
   Jaehne B., 2005, DIGITAL IMAGE PROCES
   Johnson SG, 2007, IEEE T SIGNAL PROCES, V55, P111, DOI 10.1109/TSP.2006.882087
   Kassim AA, 2005, IEEE T INF TECHNOL B, V9, P132, DOI 10.1109/TITB.2004.838376
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Li H., 2009, ACM T GRAPH
   Li H., 2008, P 6 EUR S GEOM PROC, V27
   Lipman Y., 2004, DIFFERENTIAL COORDIN
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Papadopoulos G.T., 2016, IEEE T CIRCUITS SYST
   Saff EB, 1997, MATH INTELL, V19, P5, DOI 10.1007/BF03024331
   Simoncelli E.P., 1993, THESIS
   SIMONCELLI EP, 1994, IEEE IMAGE PROC, P790, DOI 10.1109/ICIP.1994.413423
   Spies H, 2002, COMPUT VIS IMAGE UND, V85, P209, DOI 10.1006/cviu.2002.0970
   Spivak M., 1971, CALCULUS MANIFOLDS M
   Vedula S, 2005, IEEE T PATTERN ANAL, V27, P475, DOI 10.1109/TPAMI.2005.63
   von Siebenthal M, 2007, PHYS MED BIOL, V52, P1547, DOI 10.1088/0031-9155/52/6/001
NR 44
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2018
VL 71
BP 38
EP 67
DI 10.1016/j.imavis.2018.01.002
PG 30
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GB1QS
UT WOS:000428825900004
DA 2024-07-18
ER

PT J
AU Heimberger, M
   Horgan, J
   Hughes, C
   McDonald, J
   Yogamani, S
AF Heimberger, Markus
   Horgan, Jonathan
   Hughes, Ciaran
   McDonald, John
   Yogamani, Senthil
TI Computer vision in automated parking systems: Design, implementation and
   challenges
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automated parking; Automotive vision; Autonomous driving; ADAS; Machine
   learning; Computer vision; Embedded vision; Safety critical systems
AB Automated driving is an active area of research in both industry and academia. Automated parking, which is automated driving in a restricted scenario of parking with low speed manoeuvring, is a key enabling product for fully autonomous driving systems. It is also an important milestone from the perspective of a higher end system built from the previous generation driver assistance systems comprising of collision warning, pedestrian detection, etc. In this paper, we discuss the design and implementation of an automated parking system from the perspective of computer vision algorithms. Designing a low-cost system with functional safety is challenging and leads to a large gap between the prototype and the end product, in order to handle all the corner cases. We demonstrate how camera systems are crucial for addressing a range of automated parking use cases and also, to add robustness to systems based on active distance measuring sensors, such as ultrasonics and radar. The key vision modules which realize the parking use cases are 3D reconstruction, parking slot marking recognition, freespace and vehicle/pedestrian detection. We detail the important parking use cases and demonstrate how to combine the vision modules to form a robust parking system. To the best of the authors' knowledge, this is the first detailed discussion of a systemic view of a commercial automated parking system. (C) 2017 Published by Elsevier B.V.
C1 [Heimberger, Markus] Valeo Schalter & Sensoren, Automated Parking Prod Segment, Bietigheim, Germany.
   [Horgan, Jonathan; Hughes, Ciaran; McDonald, John; Yogamani, Senthil] Valeo Vis Syst, Automated Parking Prod Segment, Tuam, Ireland.
C3 Valeo SA
RP Yogamani, S (corresponding author), Valeo Vis Syst, Automated Parking Prod Segment, Tuam, Ireland.
EM senthil.yogamani@valeo.com
RI Eising, Ciarán/GON-7585-2022
OI Eising, Ciarán/0000-0001-8383-2635
CR [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, AUTONOMOUS DRIVING L
   [Anonymous], 2016, ARXIV
   [Anonymous], 2015, VELODYNE HDL 64E DAT
   [Anonymous], 2013, VALET PARK4U AUTOMAT
   Badino H., 2007, WORKSH DYN VIS ICCV, V20
   Boreman G.D., 2001, Modulation transfer function in optical and electro-optical systems, V21
   Broggi A, 2014, IEEE INT VEH SYM, P918
   Buch N, 2011, IEEE T INTELL TRANSP, V12, P920, DOI 10.1109/TITS.2011.2119372
   Cerri P, 2005, IEEE INT CONF ROBOT, P2223
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Faheem, 2013, J APPL RES TECHNOL, V11, P714, DOI 10.1016/S1665-6423(13)71580-3
   Farrell J., 2006, ELECT IMAGING 2006
   Fuentes-Pacheco J, 2015, ARTIF INTELL REV, V43, P55, DOI 10.1007/s10462-012-9365-8
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hata A, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P584, DOI 10.1109/ITSC.2014.6957753
   Horgan J, 2015, IEEE INT C INTELL TR, P2032, DOI 10.1109/ITSC.2015.329
   Hughes C, 2009, IET INTELL TRANSP SY, V3, P19, DOI 10.1049/iet-its:20080017
   Jung HG, 2006, LECT NOTES COMPUT SC, V4109, P384
   Jung HG, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P109
   Liu YC, 2008, LECT NOTES COMPUT SC, V4931, P207
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Naseer Tayyab, 2017, IEEE INT C ROB AUT
   S.O.-R.A.V.S. Committee, 2014, TAX DEF TERMS REL ON
   Savage D., 2013, ERTICO 9 ITS EUR C
   Scaramuzza D, 2008, IEEE T ROBOT, V24, P1015, DOI 10.1109/TRO.2008.2004490
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P906, DOI 10.1109/TITS.2013.2246835
   Su B., 2014, SYSTEM PARKING LOT M, P268
   Vacek S., 2007, ROAD MARKING ANAL AU
   Wang CX, 2014, ADV MECH ENG, DOI 10.1155/2014/847406
   Xu J, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P725, DOI 10.1109/IVS.2000.898435
NR 34
TC 64
Z9 69
U1 8
U2 86
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2017
VL 68
SI SI
BP 88
EP 101
DI 10.1016/j.imavis.2017.07.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FR9UP
UT WOS:000419418900009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU He, T
   Mao, H
   Guo, JX
   Yi, Z
AF He, Tao
   Mao, Hua
   Guo, Jixiang
   Yi, Zhang
TI Cell tracking using deep neural networks with multi-task learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cell tracking; Deep learning; Convolutional Neural Networks; Multi-task
   learning
ID SEGMENTATION; NUCLEI
AB Cell tracking plays crucial role in biomedical and computer vision areas. As cells generally have frequent deformation activities and small sizes in microscope image, tracking the non-rigid and non-significant cells is quite difficult in practice. Traditional visual tracking methods have good performances on tracking rigid and significant visual objects, however, they are not suitable for cell tracking problem. In this paper, a novel cell tracking method is proposed by using Convolutional Neural Networks (CNNs) as well as multi-task learning (MTL) techniques. The CNNs learn robust cell features and MTL improves the generalization performance of the tracking. The proposed cell tracking method consists of a particle filter motion model, a multi-task learning observation model, and an optimized model update strategy. In the training procedure, the cell tracking is divided into an online tracking task and an accompanying classification task using the MTL technique. The observation model is trained by building a CNN to learn robust cell features. The tracking procedure is started by assigning the cell position in the first frame of a microscope image sequence. Then, the particle filter model is applied to produce a set of candidate bounding boxes in the subsequent frames. The trained observation model provides the confidence probabilities corresponding to all of the candidates and selects the candidate with the highest probability as the final prediction. Finally, an optimized model update strategy is proposed to enable the multi-task observation model for the variation of the tracked cell over the entire tracking procedure. The performance and robustness of the proposed method are analyzed by comparing with other commonly-used methods. Experimental results demonstrate that the proposed method has good performance to the cell tracking problem. (C) 2016 Elsevier B.V. All rights reserved.
C1 [He, Tao; Mao, Hua; Guo, Jixiang; Yi, Zhang] Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP Mao, H (corresponding author), Sichuan Univ, Coll Comp Sci, Machine Intelligence Lab, Chengdu 610065, Peoples R China.
EM taohe@stu.scu.edu.cn; huamao@scu.edu.cn; guojixiang@scu.edu.cn;
   zhangyi@scu.edu.cn
RI He, Tao/AAG-2492-2019
OI He, Tao/0000-0001-9405-3979; Mao, Hua/0000-0003-3198-6282; Guo,
   Jixiang/0000-0002-1678-8205
FU National Science Foundation of China [61432012, 61402306]; Science 87
   Technology Department of Science Province [2015GZ01191]
FX This work was supported by the National Science Foundation of China
   [grant numbers 61432012, 61402306]; Science 87 Technology Department of
   Science Province [grant number 2015GZ01191.
CR Abu-Mostafa Y. S., 1990, Journal of Complexity, V6, P192, DOI 10.1016/0885-064X(90)90006-Y
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2011, 22 INT JT C ART INT, DOI 10.5555/2283516.2283603
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bise R, 2011, I S BIOMED IMAGING, P1004, DOI 10.1109/ISBI.2011.5872571
   Chen XW, 2006, IEEE T BIO-MED ENG, V53, P762, DOI 10.1109/TBME.2006.870201
   Dong DX, 2015, PROCEEDINGS OF THE 53RD ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS AND THE 7TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING, VOL 1, P1723
   Dzyubachyk O, 2010, IEEE T MED IMAGING, V29, P852, DOI 10.1109/TMI.2009.2038693
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Gong Pinghua, 2012, KDD, V2012, P895
   Heigold G, 2013, INT CONF ACOUST SPEE, P8619, DOI 10.1109/ICASSP.2013.6639348
   Hu J, 2015, IEEE INT FUZZY SYST
   Huang C, 2008, LECT NOTES COMPUT SC, V5303, P788, DOI 10.1007/978-3-540-88688-4_58
   Huh S, 2011, I S BIOMED IMAGING, P2121, DOI 10.1109/ISBI.2011.5872832
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li K, 2008, MED IMAGE ANAL, V12, P546, DOI 10.1016/j.media.2008.06.001
   Lou X., 2011, Advances in neural information processing systems, P1296
   Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717
   Magnusson KEG, 2012, 2012 9TH IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING (ISBI), P382, DOI 10.1109/ISBI.2012.6235564
   Meijering E, 2012, METHOD ENZYMOL, V504, P183, DOI 10.1016/B978-0-12-391857-4.00009-4
   Mukherjee DP, 2004, IEEE T IMAGE PROCESS, V13, P562, DOI 10.1109/TIP.2003.819858
   Ren YY, 2015, INT CONF CONTR AUTO, P502, DOI 10.1109/ICCAIS.2015.7338721
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wan L, 2013, P 30 INT C MACH LEAR, P1058, DOI DOI 10.5555/3042817.3043055
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang FX, 2005, LECT NOTES COMPUT SC, V3749, P302
   Yang XD, 2006, IEEE T CIRCUITS-I, V53, P2405, DOI 10.1109/TCSI.2006.884469
   Yi Z., 2004, Convergence Analysis of Recurrent Neural Networks, V13
   Yi Z, 2010, IEEE T NEURAL NETWOR, V21, P494, DOI 10.1109/TNN.2009.2039758
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang L, 2008, P 18 IEEE C COMPUTER, P1
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
NR 35
TC 56
Z9 68
U1 1
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 142
EP 153
DI 10.1016/j.imavis.2016.11.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800015
OA Bronze, Green Accepted
DA 2024-07-18
ER

PT J
AU Bergmüller, T
   Christopoulos, E
   Fehrenbach, K
   Schnöll, M
   Uhl, A
AF Bergmueller, Thomas
   Christopoulos, Eleftherios
   Fehrenbach, Kevin
   Schnoell, Martin
   Uhl, Andreas
TI Recompression effects in iris recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris recognition; Iris segmentation; Image quality; Image compression;
   Recompression; ISO standards
ID IMAGE QUALITY ASSESSMENT; COMPRESSION
AB Rating a compression algorithms' performance is usually done in experimental studies, where researchers have frequently used JPEG pre-compressed data. It is not clear yet, if results of such compression experiments are reliable when conducted on pre-compressed data. To investigate this issue, we first study the impact of using pre-compressed data in iris segmentation and evaluate the relation between iris segmentation performance and general image quality metrics. In this context we propose a method to overcome potential problems in case using pre-compressed data sets cannot be avoided. As the second step, we conduct experimentation on the entire iris recognition pipeline. We find that overall, recognition accuracy results might not be entirely reliable in case of applying JPEG XR or JPEG2000 to JPEG pre-compressed data. (C) 2016 Published by Elsevier B.V.
C1 [Bergmueller, Thomas] Authent Vis GmbH, Salzburg, Austria.
   [Bergmueller, Thomas; Christopoulos, Eleftherios; Fehrenbach, Kevin; Schnoell, Martin; Uhl, Andreas] Salzburg Univ, Dept Comp Sci, Salzburg, Austria.
C3 Salzburg University
RP Uhl, A (corresponding author), Salzburg Univ, Dept Comp Sci, Salzburg, Austria.
EM tb@authenticvision.com; uhl@cosy.sbg.ac.at
CR [Anonymous], 2013, ADV INFORM SECURITY
   [Anonymous], P 22 INT C PATT REC
   [Anonymous], 2013, Handbook of iris recognition
   Bauschke HH, 2003, IEEE T IMAGE PROCESS, V12, P843, DOI 10.1109/TIP.2003.812375
   Bergmueller T, 2015, INT CONF BIOMETR, P1, DOI 10.1109/ICB.2015.7139040
   Bharadwaj S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-34
   Bowyer K. W., TECH REP
   Burge M., 2010, SPIE P, V7667
   Carneiro Milena Bueno Pereira, 2011, Biometric Systems, Design and Applications, P111
   Chan S., 1992, 21068 U KENT COMP LA
   Chandler DM, 2007, IEEE T IMAGE PROCESS, V16, P2284, DOI 10.1109/TIP.2007.901820
   Damera-Venkata N, 2000, IEEE T IMAGE PROCESS, V9, P636, DOI 10.1109/83.841940
   Daugman J., 2008, IEEE T INF FORENSICS, V3
   Gabarda S, 2007, J OPT SOC AM A, V24, pB42, DOI 10.1364/JOSAA.24.000B42
   Hämmerle-Uhl J, 2009, LECT NOTES COMPUT SC, V5558, P1102, DOI 10.1007/978-3-642-01793-3_111
   Hammerle-Uhl J., 2014, P IEEE INT C IM PROC
   Hofbauer H., 2016, International Conference of the Biometrics Special Interest Group (BIOSIG), P1
   Horvath K, 2011, LECT NOTES COMPUT SC, V6855, P73, DOI 10.1007/978-3-642-23678-5_7
   Ives RW, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/680845
   Ives RW, 2008, J ELECTRON IMAGING, V17, DOI 10.1117/1.2891313
   Konrad M, 2009, LECT NOTES COMPUT SC, V5558, P1091, DOI 10.1007/978-3-642-01793-3_110
   Kumar B., 2011, INT J ENG SCI TECHNO, V3, P8519
   Kumar P., 2013, INT J COMPUT APPL, V74, P10
   Maio D, 2004, LECT NOTES COMPUT SC, V3072, P1
   Matschitsch S, 2007, LECT NOTES COMPUT SC, V4642, P232
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Pardamean B., 2012, INT J MATH MODELS ME, V6, P332
   Pennebaker W.B., 1993, JPEG: Still Image Compression Standard
   Phillips PJ, 2007, IEEE T PATTERN ANAL, V29, P1869, DOI [10.1109/TPAMI.2007.1137, 10.1109/TPAMI.2007.1137.]
   Rakshit S, 2007, IEEE T INF FOREN SEC, V2, P605, DOI 10.1109/TIFS.2007.902401
   Rathgeb C., 2014, P IAPR IEEE INT JOIN
   Rathgeb C., 2014, P IEEE IAPR INT JOIN
   Sencar HusrevTaha., 2012, Digital Image Forensics - There is More to a Picture than Meets the Eye, DOI DOI 10.1007/978-1-4614-0757-7
   Tuba A., 2012, APPL MATH ELECT COMP, P417
   Wang Z, 2002, IEEE IMAGE PROC, P477
   Wang Z., IEEE AS C SIGN SYST
   Zhang L, 2010, IEEE IMAGE PROC, P321, DOI 10.1109/ICIP.2010.5649275
NR 38
TC 5
Z9 7
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 142
EP 157
DI 10.1016/j.imavis.2016.08.003
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700014
DA 2024-07-18
ER

PT J
AU Jacobs, N
   Workman, S
   Souvenir, R
AF Jacobs, Nathan
   Workman, Scott
   Souvenir, Richard
TI Cloudmaps from static ground-view video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image formation; Time-lapse; Clouds; Lighting estimation; Solar
   forecasting; Scene factorization
AB Cloud shadows dramatically affect the appearance of outdoor scenes. We describe three approaches that use video of cloud shadows to estimate a cloudmap, a spatio-temporal function that represents the clouds passing over the scene. Two of the methods make assumptions about the camera and/or scene geometry. The third method uses techniques from manifold learning and does not require such assumptions. None of the methods require directly viewing the clouds, but instead use the pattern of intensity changes caused by the cloud shadows. An accurate estimate of the cloudmap has potential applications in solar power estimation and forecasting, surveillance, and graphics. We present a quantitative evaluation of our methods on synthetic scenes and show qualitative results on real scenes. We also demonstrate the use of a cloudmap for foreground object detection and video editing. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Jacobs, Nathan; Workman, Scott] Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA.
   [Souvenir, Richard] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 University of Kentucky; University of North Carolina; University of
   North Carolina Charlotte
RP Jacobs, N (corresponding author), Univ Kentucky, Dept Comp Sci, Lexington, KY 40506 USA.
EM jacobs@cs.uky.edu; scott@cs.uky.edu; souvenir@uncc.edu
RI Jacobs, Nathan/AAC-3392-2019
OI Jacobs, Nathan/0000-0002-4242-8967; Workman, Scott/0000-0002-7145-7484
FU Defense Advanced Research Projects Agency [DARPA CSSG D11AP00255];
   National Science Foundation [EPSCoR 0918856]
FX We gratefully acknowledge the support of the Defense Advanced Research
   Projects Agency (DARPA CSSG D11AP00255) and the National Science
   Foundation (EPSCoR 0918856). The views and conclusions contained in this
   document are those of the authors and should not be interpreted as
   necessarily representing the official policies or endorsement, either
   expressed or implied, of the Department of Defense or the U.S.
   Government.
CR Abrams A., 2012, EUR C COMP VIS
   ACKERMAN SA, 1981, J APPL METEOROL, V20, P581, DOI 10.1175/1520-0450(1981)020<0581:COSAAS>2.0.CO;2
   Ackermann J., 2012, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   Baraniuk RG, 2008, IEEE SIGNAL PROC MAG, V25, P12, DOI 10.1109/MSP.2008.915557
   Björklund S, 2003, 42ND IEEE CONFERENCE ON DECISION AND CONTROL, VOLS 1-6, PROCEEDINGS, P2502
   Chu YH, 2013, SOL ENERGY, V98, P592, DOI 10.1016/j.solener.2013.10.020
   Eastman R, 2013, J CLIMATE, V26, P1286, DOI 10.1175/JCLI-D-12-00280.1
   ELGAMMAL A, 2004, IEEE C COMP VIS PATT
   Fergus R., 2006, Random lens imaging
   Hein M., 2006, ADV NEURAL INFORM PR
   Horprasert T., 1999, ICCV FRAME RATE WORK
   Igawa N, 2004, SOL ENERGY, V77, P137, DOI 10.1016/j.solener.2004.04.016
   Islam M., 2013, CVPR WORKSH GROUND T
   Jacobs N., 2014, IEEE WINT C APPL COM
   Jacobs N, 2013, IEEE T PATTERN ANAL, V35, P2526, DOI 10.1109/TPAMI.2013.55
   Kazantzidis A, 2012, ATMOS RES, V113, P80, DOI 10.1016/j.atmosres.2012.05.005
   Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24
   Lalonde JF, 2009, IEEE I CONF COMP VIS, P183, DOI 10.1109/ICCV.2009.5459163
   Langguth F., 2012, IEEE C COMP VIS PATT
   Li QY, 2012, IEEE GEOSCI REMOTE S, V9, P417, DOI 10.1109/LGRS.2011.2170953
   Liutkus A, 2014, SCI REP-UK, V4, DOI 10.1038/srep05552
   Long C.N., 2006, J ATMOSPHERIC OCEANI, V23
   Marquez R, 2013, SOL ENERGY, V91, P327, DOI 10.1016/j.solener.2012.09.018
   Murdock C., 2013, IEEE WORKSH APPL COM
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Silva AA, 2013, METEOROL ATMOS PHYS, V120, P201, DOI 10.1007/s00703-013-0245-9
   Souvenir R., 2005, IEEE WORKSH APPL COM
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Sunkavalli K, 2008, PROC CVPR IEEE, P541
   Sunkavalli K, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276504, 10.1145/1239451.1239552]
   SZEICZ G, 1974, J APPL ECOL, V11, P617, DOI 10.2307/2402214
   Tao LT, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531374
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Veikherman D., 2014, CLOUDS IN THE CLOUD, P659
   Workman S, 2015, COMPUT VIS IMAGE UND, V134, P116, DOI 10.1016/j.cviu.2014.10.002
NR 40
TC 1
Z9 1
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 154
EP 166
DI 10.1016/j.imavis.2016.05.013
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400012
OA hybrid
DA 2024-07-18
ER

PT J
AU Takahashi, K
   Murakami, T
AF Takahashi, Kenta
   Murakami, Takao
TI A measure of information gained through biometric systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Entropy; Mutual information; Relative entropy; Divergence
AB We propose a measure of information gained through biometric matching systems. Firstly, we discuss how the information about the identity of a person is derived from biometric samples through a biometric system, and define the "biometric system entropy" or BSE based on mutual information. We present several theoretical properties and interpretations of the BSE, and show how to design a biometric system which maximizes the BSE. Then we prove that the BSE can be approximated asymptotically by the relative entropy D(f(G)(x)parallel to f(I)(x)) where f(G)(x) and f(I)(x) are probability mass functions of matching scores between samples from individuals and among population. We also discuss how to evaluate the BSE of a biometric system and show experimental evaluation of the BSE of face, fingerprint and multimodal biometric systems. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Takahashi, Kenta; Murakami, Takao] Hitachi Ltd, Yokohama Res Lab, Yokohama, Kanagawa 2440817, Japan.
   [Murakami, Takao] Univ Tokyo, Inst Ind Sci, Tokyo 1538505, Japan.
C3 Hitachi Limited; University of Tokyo
RP Takahashi, K (corresponding author), Hitachi Ltd, Yokohama Res Lab, Yokohama, Kanagawa 2440817, Japan.
EM kenta.takahashi.bw@hitachi.com; takao.murakami.nr@hitachi.com
RI Murakami, Takao/M-6399-2016
OI Murakami, Takao/0000-0002-5110-1261
CR Adler  A., 2006, P CAN C COMP EL ENG
   [Anonymous], 2003, Handbook of fingerprint recognition
   [Anonymous], 2002, Best practices in testing and reporting performance of biometric devices
   Bartle RG, 1995, ELEMENTS INTEGRATION
   Beirlant J, 1997, INT J MATH STAT SCI, V6, P17
   Bhatnagar J, 2009, PATTERN RECOGN, V42, P1803, DOI 10.1016/j.patcog.2008.10.004
   Billingsley P., 2013, CONVERGE PROBAB MEAS
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Burr W.E., 2006, NIST SPECIAL PUBLICA
   Darbellay GA, 1999, IEEE T INFORM THEORY, V45, P1315, DOI 10.1109/18.761290
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   Faivishevsky L., 2009, NEURAL INFORM PROCES
   Goriaa M.N., 2005, J NONPARAMETRIC STAT, V17
   HAN TS, 1994, IEEE T INFORM THEORY, V40, P1247, DOI 10.1109/18.335943
   Hidano S., 2010, P 11 INT C CONTR AUT
   Kozachenko L. F., 1987, Problems of Information Transmission, V23, P95
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lehmann E., 2005, TESTING STAT HYPOTHE, V3rd
   Leonenko N, 2008, TATRA MT MATH PUBL, V39, P265
   Murakami T., 2009, P INT WORKSH INF FOR
   Nandakumar K., 2009, P INT C BIOM ICB 09
   Pérez-Cruz F, 2008, IEEE INT SYMP INFO, P1666, DOI 10.1109/ISIT.2008.4595271
   Renyi A., 1961, P 4 BERK S MATH STAT, V1, P547
   Shay R., 2010, P 6 S US PRIV SEC SO, P2
   Sutcu Y., 2010, P ICPR
   Takahashi K., 2010, P ICPR
   Thomas T. M.CoverandJ. A., 1991, ELEMENTS INFORM THEO, DOI 10.1002/0471200611
   Wang A., 2009, IEEE INT S INF THEOR, V55
   Wang Q., 2006, IEEE INT S INF THEOR
   Wang Q., 2005, IEEE T INF THEORY, V51
NR 30
TC 22
Z9 25
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1194
EP 1203
DI 10.1016/j.imavis.2013.12.010
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600020
DA 2024-07-18
ER

PT J
AU Hochreiter, J
   Han, ZK
   Masood, SZ
   Fonte, S
   Tappen, M
AF Hochreiter, Jason
   Han, Zhongkai
   Masood, Syed Zain
   Fonte, Spencer
   Tappen, Marshall
TI Exploring album structure for face recognition in online social networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Online social networks; Structural SVM
AB In this paper, we propose an album-oriented face-recognition model that exploits the album structure for face recognition in online social networks. Albums, usually associated with pictures of a small group of people at a certain event or occasion, provide vital information that can be used to effectively reduce the possible list of candidate labels. We show how this intuition can be formalized into a model that expresses a prior on how albums tend to have many pictures of a small number of people. We also show how it can be extended to include other information available in a social network. Using two real-world datasets independently drawn from Facebook, we show that this model is broadly applicable and can significantly improve recognition rates. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Hochreiter, Jason; Han, Zhongkai; Masood, Syed Zain; Fonte, Spencer; Tappen, Marshall] Univ Cent Florida, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Hochreiter, J (corresponding author), Univ Cent Florida, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.
EM jasonhochreiter@gmail.com
FU NSF [IIS-0905387, IIS-0916868]
FX This work was funded by NSF grants IIS-0905387 and IIS-0916868.
CR [Anonymous], P CVPR WORKSH INT VI
   [Anonymous], 2006, P BRIT MACHINE VISIO
   [Anonymous], 2003, ACM Multimedia Conference
   [Anonymous], 2008, Proceedings of the Twenty-Fifth International Conference on Machine Learning
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], ANN STAT
   Berg T., 2006, NEURAL INFORM PROCES, P264
   Berg TL, 2004, PROC CVPR IEEE, P848
   Bradski G., 2000, OPENCV LIB DDJ SOFTW
   Delong A, 2010, PROC CVPR IEEE, P2173, DOI 10.1109/CVPR.2010.5539897
   Gallagher A., 2007, USING GROUP PRIOR ID, P1
   HOCHBAUM DS, 1982, MATH PROGRAM, V22, P148, DOI 10.1007/BF01581035
   Joachims T, 2009, MACH LEARN, V77, P27, DOI [10.1007/S10994-009-5108-8, 10.1007/s10994-009-5108-8]
   KUEHN AA, 1963, MANAGE SCI, V9, P643, DOI 10.1287/mnsc.9.4.643
   Naaman M., 2005, 20052 STANF INFOLAB
   Parry M., 2011, Chronicle of Higher Education
   Pinto Nicolas, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2591, DOI 10.1109/CVPRW.2009.5206605
   Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579
   Pinto Nicolas, 2008, WORKSH FAC REAL LIF, P3
   Scharstein D., 2002, TAXONOMY EVALUATION
   Williams C.K.I., PASCAL VISUAL OBJECT
   Zhao M, 2006, LECT NOTES COMPUT SC, V4071, P163
NR 22
TC 2
Z9 2
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 751
EP 760
DI 10.1016/j.imavis.2014.01.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700012
DA 2024-07-18
ER

PT J
AU Firouzi, H
   Najjaran, H
AF Firouzi, Hadi
   Najjaran, Homayoun
TI Adaptive on-line similarity measure for direct visual tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Adaptive metric; Similarity measure; Visual tracking; Template matching
ID MODELS
AB This paper presents an on-line adaptive metric to estimate the similarity between the target representation model and new image received at every time instant. The similarity measure, also known as observation likelihood, plays a crucial role in the accuracy and robustness of visual tracking. In this work, an L2-norm is adaptively weighted at every matching step to calculate the similarity between the target model and image descriptors. A histogram-based classifier is learned on-line to categorize the matching errors into three classes namely i) image noise, ii) significant appearance changes, and iii) outliers. A robust weight is assigned to each matching error based on the class label. Therefore, the proposed similarity measure is able to reject outliers and adapt to the target model by discriminating the appearance changes from the undesired outliers. The experimental results show the superiority of the proposed method with respect to accuracy and robustness in the presence of severe and long-term occlusion and image noise in comparison with commonly used robust regressors. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Firouzi, Hadi; Najjaran, Homayoun] Univ British Columbia, Okanagan Sch Engn, Kelowna, BC, Canada.
C3 University of British Columbia
RP Firouzi, H (corresponding author), Univ British Columbia, Okanagan Sch Engn, Kelowna, BC, Canada.
EM hadi.firouzi@ubc.ca; h.najjaran@ubc.ca
OI Najjaran, Homayoun/0000-0002-3550-225X
CR Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Coifman B, 1998, TRANSPORT RES C-EMER, V6, P271, DOI 10.1016/S0968-090X(98)00019-9
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dame A, 2011, IEEE IMAGE PROC, P1493, DOI 10.1109/ICIP.2011.6115726
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Hampapur A, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P128, DOI 10.1109/AVSS.2009.100
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Jiang N, 2011, IEEE T IMAGE PROCESS, V20, P2288, DOI 10.1109/TIP.2011.2114895
   Karavasilis V, 2011, IMAGE VISION COMPUT, V29, P295, DOI 10.1016/j.imavis.2010.12.002
   Li SX, 2010, IMAGE VISION COMPUT, V28, P424, DOI 10.1016/j.imavis.2009.06.012
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Meer P., EMERGING TOPICS COMP, P555
   Richa R, 2011, IEEE INT C INT ROBOT, P2953, DOI 10.1109/IROS.2011.6048295
   Rius I, 2009, PATTERN RECOGN, V42, P2907, DOI 10.1016/j.patcog.2009.02.012
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Wang F, 2007, INT J COMPUT VISION, V74, P201, DOI 10.1007/s11263-006-0011-2
   Yang C, 2005, PROC CVPR IEEE, P176
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 24
TC 1
Z9 2
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2014
VL 32
IS 4
BP 227
EP 236
DI 10.1016/j.imavis.2014.01.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AG0MN
UT WOS:000335109700001
DA 2024-07-18
ER

PT J
AU Zhang, LG
   Tjondronegoro, D
   Chandran, V
AF Zhang, Ligang
   Tjondronegoro, Dian
   Chandran, Vinod
TI Facial expression recognition experiments with data from television
   broadcasts and the World Wide Web
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Realistic; Texture; Geometry; Experiment
ID FEATURES; FACE
AB Facial expression recognition (FER) systems must ultimately work on real data in uncontrolled environments although most research studies have been conducted on lab-based data with posed or evoked facial expressions obtained in pre-set laboratory environments. It is very difficult to obtain data in real-world situations because privacy laws prevent unauthorized capture and use of video from events such as funerals, birthday parties, marriages etc. It is a challenge to acquire such data on a scale large enough for benchmarking algorithms. Although video obtained from TV or movies or postings on the World Wide Web may also contain 'acted' emotions and facial expressions, they may be more 'realistic' than lab-based data currently used by most researchers. Or is it? One way of testing this is to compare feature distributions and FER performance. This paper describes a database that has been collected from television broadcasts and the World Wide Web containing a range of environmental and facial variations expected in real conditions and uses it to answer this question. A fully automatic system that uses a fusion based approach for FER on such data is introduced for performance evaluation. Performance improvements arising from the fusion of point-based texture and geometry features, and the robustness to image scale variations are experimentally evaluated on this image and video dataset. Differences in FER performance between lab-based and realistic data, between different feature sets, and between different train-test data splits are investigated. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Zhang, Ligang] Xian Univ Technol, Fac Comp Sci & Engn, Xian 710048, Peoples R China.
   [Zhang, Ligang; Tjondronegoro, Dian; Chandran, Vinod] Queensland Univ Technol, Fac Sci & Engn, Brisbane, Qld 4000, Australia.
C3 Xi'an University of Technology; Queensland University of Technology
   (QUT)
RP Zhang, LG (corresponding author), Xian Univ Technol, Fac Comp Sci & Engn, 5 South Jinhua Rd, Xian 710048, Peoples R China.
EM ligzhang@gmail.com; dian@qut.edu.au; v.chandran@qut.edu.au
RI Tjondronegoro, Dian/AAE-4685-2022; Chandran, Vinod/N-3053-2019
OI Tjondronegoro, Dian/0000-0001-7446-2839; Chandran,
   Vinod/0000-0003-3185-0852
FU Smart Services CRC in Australia
FX We would like to thank the emotion annotators of the QUT FER dataset.
   This work was supported in part by the Smart Services CRC in Australia.
CR [Anonymous], P BRIT MACH VIS C BM
   Berretti S., 2010, P INT C PATTERN RECO, P4125
   Beszedes M., 2007, BRIT MACH VIS C
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen SZ, 2013, IMAGE VISION COMPUT, V31, P175, DOI 10.1016/j.imavis.2012.06.014
   Chew SW, 2012, IEEE T SYST MAN CY B, V42, P1006, DOI 10.1109/TSMCB.2012.2194485
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dhall Abhinav, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P613, DOI 10.1007/978-3-642-37444-9_48
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Douglas-Cowie E., 2003, P 15 INT C PHONETIC, P2877
   Douglas-Cowie E, 2011, COGN TECHNOL, P243, DOI 10.1007/978-3-642-15184-2_14
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Grites T., 2008, Academic advising: a comprehensive handbook, P1, DOI [10.1109/AFGR.2008.4813379, DOI 10.1109/AFGR.2008.4813379]
   Hamm J, 2011, J NEUROSCI METH, V200, P237, DOI 10.1016/j.jneumeth.2011.06.023
   Hampapur A., 2003, P IEEE WORKSH
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Kotsia I, 2008, PATTERN RECOGN, V41, P833, DOI 10.1016/j.patcog.2007.06.026
   Lajevardi SM, 2012, SIGNAL IMAGE VIDEO P, V6, P159, DOI 10.1007/s11760-010-0177-5
   Ligang Zhang, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P1027, DOI 10.1109/ICME.2012.97
   Liu M., 2013, ENHANCING EXPRESSION, V7725, P577
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Pandzic I., 2002, MPEG-4 Facial Animation: The Standard, Implementation and Applications
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Scherer KR, 1997, MOTIV EMOTION, V21, P211, DOI 10.1023/A:1024498629430
   Shan He, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P760, DOI 10.1109/ICIG.2011.91
   Sharma A., 2009, ADV ROB ITS SOC IMP, P36
   Tariq U., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P872, DOI 10.1109/FG.2011.5771365
   Tariq U., 2012, IEEE COMPUTER SOC C, P146
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wallhoff F., 2006, Facial Expressions and Emotion Database
   Wallhoff F, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P493, DOI 10.1109/ICME.2006.262433
   Wang P, 2007, PROC CVPR IEEE, P701
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   Wei Y., 2009, THESIS NANJING U
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Xiao R, 2011, PATTERN RECOGN, V44, P107, DOI 10.1016/j.patcog.2010.07.017
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Yu KM, 2013, PATTERN RECOGN, V46, P2144, DOI 10.1016/j.patcog.2013.01.032
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhaoyu W., MACH LEARN SIGN PROC, P1
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 44
TC 25
Z9 25
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2014
VL 32
IS 2
BP 107
EP 119
DI 10.1016/j.imavis.2013.12.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AD0DS
UT WOS:000332905300002
DA 2024-07-18
ER

PT J
AU Lin, PY
   Chen, YH
   Chang, CC
   Lee, JS
AF Lin, Pei-Yu
   Chen, Yi-Hui
   Chang, Chin-Chen
   Lee, Jung-San
TI Contrast-Adaptive Removable Visible Watermarking (CARVW) mechanism
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Restoration; Transparency; Visible watermark; Contrast-adaptive;
   Copyright protection
ID REVERSIBLE WATERMARKING
AB Engineers have proposed many watermark mechanisms for protecting the content of digital media from unauthorized use. The visible watermark scheme indicates the copyright of digital media posted over the Internet by embedding an inconspicuous but recognizable pattern into media. However, the embedding process often results in serious distortion of the protected image. Since the strength of the watermark in conventional methods mainly depends on the feature of protected media, this may lead to unsatisfactory transparency of watermarked images. This paper proposes a removable solution for visible watermark mechanism. By adopting the subsampling technique, the method proposes a contrast-adaptive strategy to solve this problem. This method can also guarantee the essentials of general visible watermark schemes. Experimental results show that the proposed method outperforms related works in terms of preserving the quality of the restored image. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Lin, Pei-Yu] Yuan Ze Univ, Dept Informat Commun, Chungli 32003, Taiwan.
   [Chen, Yi-Hui] Asia Univ, Dept Appl Informat & Multimedia, Taichung 41354, Taiwan.
   [Chang, Chin-Chen] Asia Univ, Dept Comp Sci & Informat Engn, Taichung 41354, Taiwan.
   [Chang, Chin-Chen; Lee, Jung-San] Feng Chia Univ, Dept Informat Engn & Comp Sci, Taichung 40724, Taiwan.
C3 Yuan Ze University; Asia University Taiwan; Asia University Taiwan; Feng
   Chia University
RP Chang, CC (corresponding author), Asia Univ, Feng Chia Univ, Dept Comp Sci & Informat Engn, Dept Informat Engn & Comp Sci, Taichung, Taiwan.
EM pagelin3@gmail.com; chenyh@asia.edu.tw; alan3c@gmail.com;
   leejs@fcu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
OI Lin, Pei-Yu/0000-0001-8809-1063
CR An LL, 2012, IEEE T IMAGE PROCESS, V21, P3598, DOI 10.1109/TIP.2012.2191564
   Barni M, 2001, IEEE T IMAGE PROCESS, V10, P783, DOI 10.1109/83.918570
   Coatrieux G, 2009, IEEE T INF TECHNOL B, V13, P158, DOI 10.1109/TITB.2008.2007199
   Cox IJ, 1997, IEEE T IMAGE PROCESS, V6, P1673, DOI 10.1109/83.650120
   Hu YJ, 2006, IEEE T CIRC SYST VID, V16, P129, DOI 10.1109/TCSVT.2005.858742
   Hu YJ, 2001, ELECTRON LETT, V37, P1219, DOI 10.1049/el:20010838
   Hu Y, 2006, IEEE T CIRC SYST VID, V16, P1423, DOI 10.1109/TCSVT.2006.884011
   Huang BB, 2006, IEEE MULTIMEDIA, V13, P60, DOI 10.1109/MMUL.2006.23
   Kim DW, 2010, IMAGE VISION COMPUT, V28, P1220, DOI 10.1016/j.imavis.2009.12.006
   Kyriakopoulos K, 2007, LECT NOTES COMPUT SC, V4427, P241
   Lin PY, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2000486.2000489
   Lu W, 2006, APPL MATH COMPUT, V181, P886, DOI 10.1016/j.amc.2006.02.012
   Luo LX, 2010, IEEE T INF FOREN SEC, V5, P187, DOI 10.1109/TIFS.2009.2035975
   Miyahara M, 1998, IEEE T COMMUN, V46, P1215, DOI 10.1109/26.718563
   Mohanty S. P., 1999, P 7 ACM INT C MUL OC, P49
   Tsai HM, 2010, SIGNAL PROCESS-IMAGE, V25, P10, DOI 10.1016/j.image.2009.11.002
   Tsai MJ, 2009, J VIS COMMUN IMAGE R, V20, P323, DOI 10.1016/j.jvcir.2009.03.011
   Wang X, 2010, IEEE SIGNAL PROC LET, V17, P567, DOI 10.1109/LSP.2010.2046930
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yeung MM, 1997, 1997 IEEE FIRST WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P357, DOI 10.1109/MMSP.1997.602661
NR 20
TC 23
Z9 24
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2013
VL 31
IS 4
BP 311
EP 321
DI 10.1016/j.imavis.2013.02.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 136QV
UT WOS:000318379400002
DA 2024-07-18
ER

PT J
AU Zhang, L
   Li, HY
AF Zhang, Lin
   Li, Hongyu
TI Encoding local image patterns using Riesz transforms: With applications
   to palmprint and finger-knuckle-print recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Riesz transforms; Palmprint recognition;
   Finger-knuckle-print recognition
ID VERIFICATION; ALGORITHM
AB Biometrics authentication is an effective method for automatically recognizing a person's identity with high confidence. It is well recognized that in biometric systems feature extraction and representation are key considerations. Among various feature extraction and representation schemes, coding-based methods are most attractive because they have the merits of high accuracy, robustness, compactness and high matching speed, and thus they have been adopted in many different kinds of biometric systems, such as iris, palmprint, and finger-knuckle-print based ones. However, how to devise a good coding scheme is still an open issue. Recent studies in image processing and applied mathematics have shown that local image features can be well extracted with Riesz transforms in a unified framework. Thus, in this paper we propose to utilize Riesz transforms to encode the local patterns of biometric images. Specifically, two Riesz transforms based coding schemes, namely RCode1 and RCode2, are proposed. They both use 3-bits to represent each code and employ the normalized Hamming distance for matching. RCode1 and RCode2 are thoroughly evaluated and compared with the other 3-bit coding methods on a palmprint database and a finger-knuckle-print database. Experiments show that the proposed methods, especially RCode2, could achieve quite similar verification accuracies with the state-of-the-art method (CompCode) while they need much less time at the feature extraction stage, which renders them better candidates for time critical applications. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Zhang, Lin; Li, Hongyu] Tongji Univ, Sch Software Engn, Shanghai 200092, Peoples R China.
C3 Tongji University
RP Li, HY (corresponding author), Tongji Univ, Sch Software Engn, Shanghai 200092, Peoples R China.
EM hyli@tongji.edu.cn
OI Zhang, Lin/0000-0002-4360-5523
FU Fundamental Research Funds for the Central Universities [2100219033];
   Natural Science Foundation of China [60903120, 61201394]; Shanghai
   Natural Science Foundation [09ZR1434400]; Shanghai Municipal Education
   Commission [12ZZ029]
FX This work is supported by the Fundamental Research Funds for the Central
   Universities under grant no. 2100219033, the Natural Science Foundation
   of China under grant no. 60903120 and no. 61201394, the Shanghai Natural
   Science Foundation under grant no. 09ZR1434400, and the Innovation
   Program of Shanghai Municipal Education Commission under grant no.
   12ZZ029.
CR [Anonymous], 2003, Handbook of fingerprint recognition
   [Anonymous], 2010, POLYU FING KNUCKL PR
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   Connie T, 2005, IMAGE VISION COMPUT, V23, P501, DOI 10.1016/j.imavis.2005.01.002
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Duta N, 2009, PATTERN RECOGN, V42, P2797, DOI 10.1016/j.patcog.2009.02.007
   Felsberg M, 2004, J MATH IMAGING VIS, V21, P5, DOI 10.1023/B:JMIV.0000026554.79537.35
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Guo ZH, 2009, PATTERN RECOGN LETT, V30, P1219, DOI 10.1016/j.patrec.2009.05.010
   Hahn SL, 1996, HILBERT TRANSFORMS S, V2
   Held S, 2010, IEEE T IMAGE PROCESS, V19, P653, DOI 10.1109/TIP.2009.2036713
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P777, DOI 10.1109/34.709565
   Huang DS, 2008, PATTERN RECOGN, V41, P1316, DOI 10.1016/j.patcog.2007.08.016
   Jain AK, 2009, IEEE T PATTERN ANAL, V31, P1032, DOI 10.1109/TPAMI.2008.242
   Jia W, 2008, PATTERN RECOGN, V41, P1504, DOI 10.1016/j.patcog.2007.10.011
   Kong A, 2009, PATTERN RECOGN, V42, P1408, DOI 10.1016/j.patcog.2009.01.018
   Kong AWK, 2004, INT C PATT RECOG, P520, DOI 10.1109/ICPR.2004.1334184
   Kumar A, 2009, ELECTRON LETT, V45, P1023, DOI 10.1049/el.2009.1435
   Kumar A, 2009, IEEE T INF FOREN SEC, V4, P98, DOI 10.1109/TIFS.2008.2011089
   Lee TS, 1996, IEEE T PATTERN ANAL, V18, P959, DOI 10.1109/34.541406
   Leung MKH, 2007, IEEE PERVAS COMPUT, V6, P40, DOI 10.1109/MPRV.2007.78
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mellor M, 2005, MED IMAGE ANAL, V9, P330, DOI 10.1016/j.media.2005.01.002
   Morales A, 2011, ELECTRON LETT, V47, P380, DOI 10.1049/el.2011.0156
   Moura L, 2002, ELECTRON LETT, V38, P605, DOI 10.1049/el:20020370
   *POLYU, POLYU PALMPR DAT
   Shang L, 2006, NEUROCOMPUTING, V69, P1782, DOI 10.1016/j.neucom.2005.11.004
   Stein E M., 1971, PRINCETON MATH SERIE
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   Sun ZN, 2005, PROC CVPR IEEE, P279
   Takaya K, 2007, IEEE PACIF, P268
   Unser M, 2010, IEEE T IMAGE PROCESS, V19, P636, DOI 10.1109/TIP.2009.2038832
   Unser M, 2009, IEEE T IMAGE PROCESS, V18, P2402, DOI 10.1109/TIP.2009.2027628
   Wang HG, 2008, PATTERN RECOGN, V41, P1514, DOI 10.1016/j.patcog.2007.10.021
   Wietzke L., 2008, TECHNICAL REPORT
   Wietzke L, 2010, J MATH IMAGING VIS, V37, P132, DOI 10.1007/s10851-010-0197-3
   Woodard DL, 2005, COMPUT VIS IMAGE UND, V100, P357, DOI 10.1016/j.cviu.2005.06.003
   Wu XQ, 2003, PATTERN RECOGN LETT, V24, P2829, DOI 10.1016/S0167-8655(03)00141-7
   Yang WK, 2011, PATTERN RECOGN, V44, P1649, DOI 10.1016/j.patcog.2011.01.019
   Zang D, 2007, J VIS COMMUN IMAGE R, V18, P81, DOI 10.1016/j.jvcir.2006.10.002
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang L, 2011, PATTERN RECOGN, V44, P1990, DOI 10.1016/j.patcog.2010.06.007
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
   Zhang L, 2009, IEEE IMAGE PROC, P1981, DOI 10.1109/ICIP.2009.5413734
   Zhang L, 2010, PATTERN RECOGN, V43, P2560, DOI 10.1016/j.patcog.2010.01.020
NR 46
TC 57
Z9 61
U1 0
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 1043
EP 1051
DI 10.1016/j.imavis.2012.09.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800011
DA 2024-07-18
ER

PT J
AU Carrasco, M
   Clady, X
AF Carrasco, Miguel
   Clady, Xavier
TI Exploiting eye-hand coordination to detect grasping movements
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual system; Grasping movements; Motion analysis; Hand posture; Hand
   gesture; Object recognition
ID VISION; TRANSFORMATIONS; RECOGNITION; CAMERA; MEMORY
AB Human beings are very skillful at reaching for and grasping objects under multiple conditions, even when faced with an object's wide variety of positions, locations, structures and orientations. This natural ability, controlled by the human brain, is called eye-hand coordination. To understand this behavior it is necessary to study both eye and hand movements simultaneously. This paper proposes a novel approach to detect grasping movements by means of computer vision techniques. This solution fuses two viewpoints, one viewpoint which is obtained from an eye-tracker capturing the user's perspective and a second viewpoint which is captured by a wearable camera attached to a user's wrist. Utilizing information from these two viewpoints it is possible to characterize multiple hand movements in conjunction with eye-gaze movements through a Hidden-Markov Model framework. This paper shows that combining these two sources makes it possible to detect hand gestures using only the objects contained in the scene even without markers on the surface of the objects. In addition, it is possible to detect which is the desired object before the user can actually grasp said object. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Carrasco, Miguel] Univ Diego Portales, Escuela Informat & Telecomunicac, Fac Ingn, Santiago, Chile.
   [Clady, Xavier] Univ Paris 06, CNRS, INSERM, Vis Inst,UMR S968,UMR7222, Paris, France.
C3 University Diego Portales; Centre National de la Recherche Scientifique
   (CNRS); Institut National de la Sante et de la Recherche Medicale
   (Inserm); Sorbonne Universite
RP Carrasco, M (corresponding author), Univ Diego Portales, Escuela Informat & Telecomunicac, Fac Ingn, Vergara 432, Santiago, Chile.
EM miguel.carrasco@udp.cl; xavier.clady@upmc.fr
RI Carrasco, Miguel/T-7272-2019; Carrasco, Miguel/GRS-5323-2022
OI Carrasco, Miguel/0000-0002-5389-7590; Carrasco,
   Miguel/0000-0002-5389-7590
CR ADAMS JA, 1981, J MOTOR BEHAV, V13, P262
   Aggarwal JK, 1997, IEEE NONRIGID AND ARTICULATED MOTION WORKSHOP, PROCEEDINGS, P90, DOI 10.1109/NAMW.1997.609859
   [Anonymous], C ADV CONC INT VIS S
   [Anonymous], IEEE ICCV
   [Anonymous], EYE HAND PLAN GOAL D
   [Anonymous], INT C ADV ROB JUN
   [Anonymous], 1996, Accuracy and Stability of Numerical Algorithms
   [Anonymous], INT C MULT INT
   [Anonymous], P 9 EUR C CONP VIS M
   [Anonymous], IEEE INT C ROB AUT I
   [Anonymous], 2 INT C COMP VIS THE
   [Anonymous], P INT C PERV COMP PE
   BALLARD DH, 1995, J COGNITIVE NEUROSCI, V7, P66, DOI 10.1162/jocn.1995.7.1.66
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Brouwer AM, 2007, J VISION, V7, DOI 10.1167/7.5.6
   Buneo CA, 2002, NATURE, V416, P632, DOI 10.1038/416632a
   Crawford JD, 2004, J NEUROPHYSIOL, V92, P10, DOI 10.1152/jn.00117.2004
   de Campos TE, 2006, SIBGRAPI, P179
   DeVaul R, 2003, SEVENTH IEEE INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P4, DOI 10.1109/ISWC.2003.1241386
   Dockstader SL, 2001, P IEEE, V89, P1441, DOI 10.1109/5.959340
   Engel KC, 2002, ARCH ITAL BIOL, V140, P211
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Flanagan JR, 2001, NATURE, V412, P389, DOI 10.1038/35086674
   Gersho A., 2003, Vector Quantization and Signal Compression
   Hamer H, 2009, IEEE I CONF COMP VIS, P1475, DOI 10.1109/ICCV.2009.5459282
   Hayhoe MM, 2003, J VISION, V3, P49, DOI 10.1167/3.1.6
   Hayhoe MM, 1998, VISION RES, V38, P125, DOI 10.1016/S0042-6989(97)00116-8
   Hodges S, 2006, LECT NOTES COMPUT SC, V4206, P177
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Johansson RS, 2001, J NEUROSCI, V21, P6917, DOI 10.1523/JNEUROSCI.21-17-06917.2001
   Land M, 1999, PERCEPTION, V28, P1311, DOI 10.1068/p2935
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   McConkie GW, 1996, J EXP PSYCHOL HUMAN, V22, P563, DOI 10.1037/0096-1523.22.3.563
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Mrotek LA, 2007, J NEUROSCI, V27, P7297, DOI 10.1523/JNEUROSCI.2046-07.2007
   Perini E, 2006, LECT NOTES COMPUT SC, V3979, P99
   Polana R., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P77, DOI 10.1109/MNRAO.1994.346251
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prendinger H, 2009, UNIVERSAL ACCESS INF, V8, P339, DOI 10.1007/s10209-009-0144-5
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rizzolatti G, 1997, CURR OPIN NEUROBIOL, V7, P562, DOI 10.1016/S0959-4388(97)80037-2
   Sakita K., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P846
   Sasaki D, 2004, RO-MAN 2004: 13TH IEEE INTERNATIONAL WORKSHOP ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, PROCEEDINGS, P655, DOI 10.1109/ROMAN.2004.1374840
   Shafique K, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P110
   Shechtman E, 2005, PROC CVPR IEEE, P405
   Sigal L, 2010, INT J COMPUT VISION, V87, P1, DOI 10.1007/s11263-009-0293-2
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Starner T., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P265, DOI 10.1109/ISCV.1995.477012
   Tamura M., 2006, ROMAN 15 IEEE INT S, P189
   Tamura Yusuke, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P3709, DOI 10.1109/IROS.2007.4399618
   Thielman GT, 2004, ARCH PHYS MED REHAB, V85, P1613, DOI 10.1016/j.apmr.2004.01.028
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   van Donkelaar P, 2000, J NEUROPHYSIOL, V84, P1677, DOI 10.1152/jn.2000.84.3.1677
   Zhou HY, 2008, BIOMED SIGNAL PROCES, V3, P1, DOI 10.1016/j.bspc.2007.09.001
NR 54
TC 8
Z9 8
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2012
VL 30
IS 11
BP 860
EP 874
DI 10.1016/j.imavis.2012.07.001
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 052CW
UT WOS:000312176300006
DA 2024-07-18
ER

PT J
AU Aggarwal, JK
   Ryoo, MS
AF Aggarwal, J. K.
   Ryoo, M. S.
TI Toward a unified framework of motion understanding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Opinion paper; Motion understanding; Human activity recognition
C1 [Aggarwal, J. K.] Univ Texas Austin, Comp & Vis Res Ctr, Austin, TX 78712 USA.
   [Ryoo, M. S.] CALTECH, Jet Prop Lab, Pasadena, CA 91109 USA.
C3 University of Texas System; University of Texas Austin; National
   Aeronautics & Space Administration (NASA); NASA Jet Propulsion
   Laboratory (JPL); California Institute of Technology
RP Aggarwal, JK (corresponding author), Univ Texas Austin, Comp & Vis Res Ctr, Austin, TX 78712 USA.
EM aggarwaljk@mail.utexas.edu; mryoo@jpl.nasa.jov
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Gupta A., IEEE COMPUT SOC C CO, DOI [10.1109/CVPR.2007.383331, DOI 10.1109/CVPR.2007.383331]
   Jain S., 2011, IEEE WORKSH DYN SHAP
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Kim K., 2011, INT C COMP VIS ICCV
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Liu J., 2009, IEEE C COMP VIS PATT
   Oh SM, 2011, PROC CVPR IEEE
   Ryoo MS, 2009, INT C COMP VIS ICCV
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   WEBB JA, 1982, ARTIF INTELL, V19, P107, DOI 10.1016/0004-3702(82)90023-6
NR 12
TC 0
Z9 0
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 465
EP 466
DI 10.1016/j.imavis.2011.12.012
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100002
OA hybrid
DA 2024-07-18
ER

PT J
AU Pinto, N
   Cox, DD
AF Pinto, Nicolas
   Cox, David D.
TI High-throughput-derived biologically-inspired features for unconstrained
   face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Face recognition; Biologically-inspired
AB Many modern computer vision algorithms are built atop of a set of low-level feature operators (such as SIFT [23,24]; HOG [8,3]; or LBP [1,2]) that transform raw pixel values into a representation better suited to subsequent processing and classification. While the choice of feature representation is often not central to the logic of a given algorithm, the quality of the feature representation can have critically important implications for performance. Here, we demonstrate a large-scale feature search approach to generating new, more powerful feature representations in which a multitude of complex, nonlinear, multilayer neuromorphic feature representations are randomly generated and screened to find those best suited for the task at hand. In particular, we show that a brute-force search can generate representations that, in combination with standard machine learning blending techniques, achieve state-of-the-art performance on the Labeled Faces in the Wild (LFW) [19] unconstrained face recognition challenge set. These representations outperform previous state-of-the-art approaches, in spite of requiring less training data and using a conceptually simpler machine learning backend. We argue that such large-scale-search-derived feature sets can play a synergistic role with other computer vision approaches by providing a richer base of features with which to work. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Pinto, Nicolas; Cox, David D.] Harvard Univ, Rowland Inst Harvard, Cambridge, MA 02142 USA.
   [Pinto, Nicolas] MIT, McGovern Inst Brain Res, Cambridge, MA 02139 USA.
C3 Harvard University; Massachusetts Institute of Technology (MIT)
RP Cox, DD (corresponding author), Harvard Univ, Rowland Inst Harvard, Cambridge, MA 02142 USA.
EM pinto@rowland.harvard.edu; cox@rowland.harvard.edu
RI Cox, David/C-4888-2008
OI Cox, David/0000-0002-2189-9743
FU Div Of Information & Intelligent Systems; Direct For Computer & Info
   Scie & Enginr [0964269] Funding Source: National Science Foundation; Div
   Of Information & Intelligent Systems; Direct For Computer & Info Scie &
   Enginr [0963668] Funding Source: National Science Foundation
CR Ahonen T., 2004, IEEE EUR C COMP VIS
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Albiol A, 2008, PATTERN RECOGN LETT, V29, P1537, DOI 10.1016/j.patrec.2008.03.017
   [Anonymous], 2002, Computational Neuroscience of Vision
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C AC SPEECH SIGN
   [Anonymous], INT C COMP VIS
   [Anonymous], 2009, INT C COMP VIS
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Dalal N., 2005, IEEE C COMP VIS PATT
   FUKUSHIMA K, 1980, BIOL CYBERN, V36, P193, DOI 10.1007/BF00344251
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   GEISLER WS, 1992, VISION RES, V32, P1409, DOI 10.1016/0042-6989(92)90196-P
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   HUA G, 2007, IEEE C COMP VIS PATT
   Hua G., 2009, INT C COMP VIS
   Huang G.B., 2007, Labeled faces in the wild
   Lazebnik S., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.68
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mutch J, 2008, INT J COMPUT VISION, V80, P45, DOI 10.1007/s11263-007-0118-0
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Pinto N., 2008, IEEE EUR C COMP VIS
   Pinto N, 2008, PLOS COMPUT BIOL, V4, DOI 10.1371/journal.pcbi.0040027
   Pinto N, 2009, PLOS COMPUT BIOL, V5, DOI 10.1371/journal.pcbi.1000579
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Sonnenburg S, 2006, J MACH LEARN RES, V7, P1531
   Taigman Yaniv, 2009, BMVC
   Vasilescu M.A.O., 2002, INT C PATT REC
   WOLF L., 2009, ACCV
   Wright J., 2009, IEEE C COMP VIS PATT
   YANG MH, 2002, IEEE C AUT FAC GEST
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zou J, 2007, IEEE T IMAGE PROCESS, V16, P2617, DOI 10.1109/TIP.2007.904421
NR 38
TC 4
Z9 7
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 159
EP 168
DI 10.1016/j.imavis.2011.12.009
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000004
DA 2024-07-18
ER

PT J
AU Lee, T
   Soatto, S
AF Lee, Taehee
   Soatto, Stefano
TI Video-based descriptors for object recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature tracking; Video-based descriptors; Object recognition;
   Multi-view recognition; Mobile devices; Visual recognition; Active
   vision
ID SHAPE; PERSISTENCE
AB We describe a visual recognition system operating on a hand-held device, based on a video-based feature descriptor, and characterize its invariance and discriminative properties. Feature selection and tracking are performed in real-time, and used to train a template-based classifier during a capture phase prompted by the user. During normal operation, the system recognizes objects in the field of view based on their ranking. Severe resource constraints have prompted a re-evaluation of existing algorithms improving their performance (accuracy and robustness) as well as computational efficiency. We motivate the design choices in the implementation with a characterization of the stability properties of local invariant detectors, and of the conditions under which a template-based descriptor is optimal. The analysis also highlights the role of time as "weak supervisor" during training, which we exploit in our implementation. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Lee, Taehee; Soatto, Stefano] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.
C3 University of California System; University of California Los Angeles
RP Lee, T (corresponding author), Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90095 USA.
FU ARO [56765-CI]; ONR [N00014-08-1-0414]; AFOSR [FA9550-09-1-0427]
FX This project was supported in part by ARO 56765-CI, ONR
   N00014-08-1-0414, AFOSR FA9550-09-1-0427. A video demonstration of the
   system can be seen at http://www.youtube.com/watch? v=cMv-McHw660.
CR ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333
   [Anonymous], P NEUROINFORMATION P
   [Anonymous], P DAT COMPR C
   [Anonymous], IEEE CVPR
   [Anonymous], PASCAL VIS OBJ CLASS
   [Anonymous], IEEE CVPR
   [Anonymous], 2001, P 2 INT WORKSH STAT
   [Anonymous], COMPUTER GRAPHICS AP
   [Anonymous], RR6968 INRIA
   [Anonymous], P INT C COMP VIS
   [Anonymous], ANN MATH STUDIES
   [Anonymous], 1983, INTRO MODERN INFORM
   [Anonymous], OPENCV OP SOURC COMP
   [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587673
   [Anonymous], BMVC
   [Anonymous], 2009, P INT C COMP VIS
   [Anonymous], 2006, NIPS
   BAJCSY R, 1988, P IEEE, V76, P996, DOI 10.1109/5.5968
   Baker S, 2001, PROC CVPR IEEE, P1090
   Berg AC, 2001, PROC CVPR IEEE, P607
   Cohen-Steiner D, 2007, DISCRETE COMPUT GEOM, V37, P103, DOI 10.1007/s00454-006-1276-5
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Duci A, 2006, IMAGE VISION COMPUT, V24, P271, DOI 10.1016/j.imavis.2005.07.021
   Edelsbrunner H, 2002, DISCRETE COMPUT GEOM, V28, P511, DOI 10.1007/s00454-002-2885-2
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Guillemin V, 1974, DIFFERENTIAL TOPOLOG
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Jackson JD, 2008, INT J COMPUT VISION, V79, P71, DOI 10.1007/s11263-007-0097-1
   Jin HL, 2005, INT J COMPUT VISION, V63, P175, DOI 10.1007/s11263-005-6876-7
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Lindeberg T., 1998, Principles for Automatic Scale Selection
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B., 1981, Proc. DARPA Image Understanding Workshop, P121
   Matas J., 2002, BMVC
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Mumford D, 2001, Q APPL MATH, V59, P85, DOI 10.1090/qam/1811096
   Nister David, 2006, CVPR
   Poston T., 1978, CATASTROPHE THEORY I
   Robert C. P., 2001, The Bayesian choice
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Soatto S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P974
   Vedaldi A., VLFEAT OPEN PORTABLE
   Wiener N., 1988, FOURIER INTEGRAL CER
   Yezzi AJ, 2003, INT J COMPUT VISION, V53, P153, DOI 10.1023/A:1023048024042
NR 45
TC 14
Z9 17
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2011
VL 29
IS 10
BP 639
EP 652
DI 10.1016/j.imavis.2011.08.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 848YP
UT WOS:000297091300001
DA 2024-07-18
ER

PT J
AU Da, FP
   Zhang, H
AF Da, Feipeng
   Zhang, Hu
TI Sub-pixel edge detection based on an improved moment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Edge detection; Sub-pixel edge location; Vision measuring
ID IMAGE INTERPOLATION; LOCATION; OPERATOR
AB A novel moment-based method for sub-pixel edge location is proposed. Based on coarse edge-location by SOBEL operator, the geometric information of the target is used to reduce the number of moment-template to only one, which can largely save the time. Experimental results demonstrate that the proposed method is effective with more robustness, higher precision and speed. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Da, Feipeng; Zhang, Hu] Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
C3 Southeast University - China
RP Da, FP (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Peoples R China.
EM dafp@seu.edu.cn
RI cai, bo/G-1491-2010
FU National Natural Science Foundation of China [60775025]; Natural Science
   Foundation of Jiangsu Province [BK2007116]
FX This work was supported by the National Natural Science Foundation of
   China under Grant 60775025 and the Natural Science Foundation of Jiangsu
   Province BK2007116.
CR Ahn SJ, 2001, PATTERN RECOGN, V34, P2283, DOI 10.1016/S0031-3203(00)00152-7
   Bin TJ, 2008, IMAGE VISION COMPUT, V26, P563, DOI 10.1016/j.imavis.2007.07.003
   Bouchara F, 2009, J OPT SOC AM A, V26, P820, DOI 10.1364/JOSAA.26.000820
   Cheng SC, 2005, PATTERN RECOGN, V38, P527, DOI 10.1016/j.patcog.2004.08.016
   GHOSAL S, 1993, PATTERN RECOGN, V26, P295, DOI 10.1016/0031-3203(93)90038-X
   GONZALEZ RC, 2002, DIGITAL IMAGE PROCES, P121
   Hermosilla T, 2008, IMAGE VISION COMPUT, V26, P1240, DOI 10.1016/j.imavis.2008.02.012
   Hu Z. F., 2008, P IEEE INT C AUT LOG, P828
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   LEE CK, 1992, PROCEEDINGS OF THE 1992 INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, INSTRUMENTATION, AND AUTOMATION, VOLS 1-3, P710, DOI 10.1109/IECON.1992.254545
   [李金泉 Li Jinquan], 2003, [光学技术, Optical Technology], V29, P500
   LYVERS EP, 1988, IEEE T PATTERN ANAL, V10, P927, DOI 10.1109/34.9114
   LYVERS EP, 1989, IEEE T PATTERN ANAL, V11, P1293, DOI 10.1109/34.41367
   NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852
   Qu YD, 2005, IMAGE VISION COMPUT, V23, P11, DOI 10.1016/j.imavis.2004.07.003
   Shan Y, 2000, IMAGE VISION COMPUT, V18, P1015, DOI 10.1016/S0262-8856(00)00040-8
   TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502
   XIA LZ, 2005, DIGITAL IMAGE PROCES, P234
   Ye J, 2005, IMAGE VISION COMPUT, V23, P453, DOI 10.1016/j.imavis.2004.07.007
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 20
TC 70
Z9 86
U1 2
U2 54
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1645
EP 1658
DI 10.1016/j.imavis.2010.05.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300007
DA 2024-07-18
ER

PT J
AU Lan, YX
   Harvey, R
   Torres, JRP
AF Lan, Yuxuan
   Harvey, Richard
   Torres, Jose Roberto Perez
TI Finding stable salient contours
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stable salient contours; Maximally stable extremal regions (MSER);
   Distinguished regions; Sieve
ID STEREO
AB Methods for generating maximally stable extremal regions are generalized to make intensity trees. Such trees may be computed quickly, but they are large so there is a need to select useful nodes within the tree. Methods for simplifying the tree are developed and it is shown that standard confidence tests may be applied to regions identified as parent and child nodes in the tree. These tests provide a principled way to edit the tree and hence control its size. One of the algorithms for simplifying trees is able to reduce the tree size by at least 90% while retaining important nodes. Furthermore the tree can be parsed to identify salient contours which are presented as generalisations of maximally stable extremal regions. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Lan, Yuxuan; Harvey, Richard; Torres, Jose Roberto Perez] Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.
C3 University of East Anglia
RP Harvey, R (corresponding author), Univ E Anglia, Sch Comp Sci, Norwich NR4 7TJ, Norfolk, England.
EM y.lan@uea.ac.uk; r.w.harvey@uea.ac.uk
RI Harvey, Richard/AAA-7738-2020
OI Harvey, Richard/0000-0001-9925-8316
CR [Anonymous], THESIS U OXFORD
   [Anonymous], P 28 WORKSH AAPR
   Bangham JA, 1996, J ELECTRON IMAGING, V5, P283, DOI 10.1117/12.243349
   BANGHAM JA, 1998, P BRIT MACH VIS C BM, V1, P33
   BANGHAM JA, 1995, Patent No. 9512459
   BANGHAM JA, 1994, SIGNAL PROCESS, V7, P1621
   GIBSON S, 2003, P BRIT MACH VIS C, P799
   KADIR T, 2004, EUR C COMP VIS, P257
   LAN Y, 2007, THESIS U E ANGLIA NO
   LIFSHITZ LM, 1990, IEEE T PATTERN ANAL, V12, P529, DOI 10.1109/34.56189
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K., 2007, Affine Covariant Features
   Moravec K, 2000, IEE P-VIS IMAGE SIGN, V147, P363, DOI 10.1049/ip-vis:20000583
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   SCOTT DW, 1979, BIOMETRIKA, V66, P605, DOI 10.1093/biomet/66.3.605
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Torres JRP, 2007, LECT NOTES COMPUT SC, V4485, P350
   VINCENT L, 1994, P SOC PHOTO-OPT INS, V2300, P253, DOI 10.1117/12.179208
   VINCENT L, 1989, SIGNAL PROCESS, V16, P365, DOI 10.1016/0165-1684(89)90031-5
NR 20
TC 2
Z9 2
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1244
EP 1254
DI 10.1016/j.imavis.2010.01.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400007
DA 2024-07-18
ER

PT J
AU Sarfraz, MS
   Hellwich, O
AF Sarfraz, M. Saquib
   Hellwich, Olaf
TI Probabilistic learning for fully automatic face recognition across pose
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Recognition across pose; Bayesian face modeling;
   Face-GLOH-Signature
AB Recent pose invariant methods try to model the subject specific appearance change across pose. For this, however, almost all of the existing methods require a perfect alignment between a gallery and a probe image. In this paper we present a pose invariant face recognition method that does not require the facial landmarks to be detected as such and is able to work with only single training image of the subject. We propose novel extensions by introducing to use a more robust feature description as opposed to pixel-based appearances. Using such features we put forward to synthesize the non-frontal views to frontal. Furthermore, using local kernel density estimation, instead of commonly used normal density assumption, is suggested to derive the prior models. Our method does not require any strict alignment between gallery and probe images which makes it particularly attractive as compared to the existing state of the art methods. Improved recognition across a wide range of poses has been achieved using these extensions. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Sarfraz, M. Saquib; Hellwich, Olaf] Berlin Univ Technol, D-10587 Berlin, Germany.
C3 Technical University of Berlin
RP Sarfraz, MS (corresponding author), Berlin Univ Technol, Sekr FR 3-1,Franklinstr 28-29, D-10587 Berlin, Germany.
EM saquib@fpk.tu-berlin.de; hellwich@fpk.tu-berlin.de
CR [Anonymous], FACE RECOGNITION BAS
   [Anonymous], IEEE COMP SOC C COMP
   [Anonymous], 2003, TR200396 MERL
   [Anonymous], LNCS, DOI DOI 10.1007/3-540-47969-4_30
   BEYMER D, 1995, INT C COMP VIS
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Chai XJ, 2007, IEEE T IMAGE PROCESS, V16, P1716, DOI 10.1109/TIP.2007.899195
   Gross R, 2004, IEEE T PATTERN ANAL, V26, P449, DOI 10.1109/TPAMI.2004.1265861
   Kanade T, 2003, 2003 IEEE INTERNATIONAL SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN ROBOTICS AND AUTOMATION, VOLS I-III, PROCEEDINGS, P954
   Kim TK, 2005, IEEE T PATTERN ANAL, V27, P318, DOI 10.1109/TPAMI.2005.58
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Liu XM, 2005, PROC CVPR IEEE, P502
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LUCEY S, 2008, VIEWPOINT INVARIANT
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   MIKOLAJCZYK CS, 2005, PAMI, V27, P31
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Phillips P., 2003, FRVT 2002: Overview and summary
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Prince SJD, 2008, IEEE T PATTERN ANAL, V30, P970, DOI 10.1109/TPAMI.2008.48
   Sarfraz AS, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P235
   Sarfraz M., 2008, Pattern Recognition and Image Analysis, V18, P434, DOI 10.1134/S1054661808030115
   Sarfraz M. S., 2008, P 8 IEEE INT C FAC G
   Sarfraz M. S., 2008, THESIS TU BERLIN
   SARFRAZ MS, 2006, PERFORMANCE ANAL CLA, P255
   Silverman B. W, 1992, DENSITY ESTIMATION S
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Wen Yi Zhao, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P285, DOI 10.1109/AFGR.2000.840648
NR 28
TC 34
Z9 37
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 744
EP 753
DI 10.1016/j.imavis.2009.07.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900003
DA 2024-07-18
ER

PT J
AU Chen, Q
   Montesinos, P
   Sen Sun, Q
   Heng, PA
   Xia, DS
AF Chen, Qiang
   Montesinos, Philippe
   Sen Sun, Quan
   Heng, Peng Ann
   Xia, De Shen
TI Adaptive total variation denoising based on difference curvature
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image denoise; Total variation; Difference curvature; Staircase effect;
   Loss of details
ID TOTAL VARIATION MINIMIZATION; NOISE REMOVAL; EDGE-DETECTION; DIFFUSION;
   DECOMPOSITION; IMAGES; SPACE
AB Image denoising methods based on gradient dependent regularizers such as Rudin et al.'s total variation (TV) model often suffer the staircase effect and the loss of fine details. In order to overcome such drawbacks, this paper presents an adaptive total variation method based on a new edge indicator, named difference curvature, which can effectively distinguish between edges and ramps. With adaptive regularization and fidelity terms, the new model has the following properties: at object edges, the regularization term is approximate to the TV norm in order to preserve the edges, and the weight of the fidelity term is large in order to preserve details; in flat and ramp regions, the regularization term is approximate to the L2 norm in order to avoid the staircase effect, and the weight of the fidelity term is small in order to strongly remove the noise. Comparative results on both synthetic and natural images demonstrate that the new method can avoid the staircase effect and better preserve fine details. (C) 2009 Elsevier B. V. All rights reserved.
C1 [Chen, Qiang; Sen Sun, Quan; Xia, De Shen] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiangsu, Peoples R China.
   [Montesinos, Philippe] LGI2P, EMA, EERIE, Nimes, France.
   [Heng, Peng Ann] Chinese Acad Sci, Chinese Univ Hong Kong, Shenzhen Inst Adv Integrat Technol, Shenzhen, Peoples R China.
   [Heng, Peng Ann] Chinese Univ Hong Kong, Dept Comp Sci & Engn, Hong Kong, Hong Kong, Peoples R China.
C3 Nanjing University of Science & Technology; IMT - Institut
   Mines-Telecom; IMT Mines Ales; The Chinese University of Hong Kong,
   Shenzhen; Chinese Academy of Sciences; Shenzhen Institute of Advanced
   Technology, CAS; Chinese University of Hong Kong
RP Chen, Q (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Xiao Lingwei 200, Nanjing 210094, Jiangsu, Peoples R China.
EM chen2qiang@163.com
RI chen, qiang/GWZ-7308-2022; chen, qiang/HGU-5418-2022; Montesinos,
   Philippe/G-2262-2013
OI Heng, Pheng Ann/0000-0003-3055-5034
FU National Science Foundation of China [60805003, 60773172]; Postdoctoral
   Science Foundation of Jiangsu Province [AD41158]; Hong Kong Special
   Administrative Region [CUHK4121/08E]
FX Work was supported by the National Science Foundation of China under
   grant Nos. 60805003/60773172, and the Postdoctoral Science Foundation of
   Jiangsu Province under Grant No. AD41158. This research was also
   supported by a grant from the Research Grants Council of the Hong Kong
   Special Administrative Region, (Project No. CUHK4121/08E). This work is
   affiliated with the Virtual Reality, Visualization and Imaging Research
   Centre at the Chinese University of Hong Kong as well as the CUHK
   MoE-Microsoft Key Laboratory of Human-Centric Computing and Interface
   Technologies.
CR ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   [Anonymous], 2003, P VLSM
   Black MJ, 1998, IEEE T IMAGE PROCESS, V7, P421, DOI 10.1109/83.661192
   Blomgren P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P384, DOI 10.1109/ICIP.1997.632128
   BLOMGREN P, 1997, P SPIE, V3162
   Bournan C, 1993, IEEE T IMAGE PROCESS, V2, P296, DOI 10.1109/83.236536
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Buades A, 2006, IEEE T IMAGE PROCESS, V15, P1499, DOI 10.1109/TIP.2006.871137
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   Chan T., 2004, HDB MATH MODELS COMP
   Chan TF, 2005, SIAM J APPL MATH, V65, P1817, DOI 10.1137/040604297
   Chen K, 2005, IEEE T PATTERN ANAL, V27, P1552, DOI 10.1109/TPAMI.2005.190
   Esedoglu S, 2004, COMMUN PUR APPL MATH, V57, P1609, DOI 10.1002/cpa.20045
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Ito K, 2000, INVERSE PROBL, V16, P909, DOI 10.1088/0266-5611/16/4/303
   Lee SH, 2005, IEEE T IMAGE PROCESS, V14, P904, DOI 10.1109/TIP.2005.849294
   Li F, 2007, J VIS COMMUN IMAGE R, V18, P322, DOI 10.1016/j.jvcir.2007.04.005
   Luo HG, 2006, SIGNAL PROCESS, V86, P1728, DOI 10.1016/j.sigpro.2005.09.019
   Lysaker M, 2006, INT J COMPUT VISION, V66, P5, DOI 10.1007/s11263-005-3219-7
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   Nikolova M, 2002, SIAM J NUMER ANAL, V40, P965, DOI 10.1137/S0036142901389165
   Osher S, 2005, MULTISCALE MODEL SIM, V4, P460, DOI 10.1137/040605412
   Osher S, 2003, MULTISCALE MODEL SIM, V1, P349, DOI 10.1137/S1540345902416247
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Schnorr C., 1994, Journal of Mathematical Imaging and Vision, V4, P189, DOI 10.1007/BF01249896
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang J, 2006, IEEE IMAGE PROC, P1429, DOI 10.1109/ICIP.2006.312698
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   YOU YL, 1996, IEEE T IMAGE PROCESS, V5
NR 33
TC 145
Z9 181
U1 1
U2 45
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 298
EP 306
DI 10.1016/j.imavis.2009.04.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300002
DA 2024-07-18
ER

PT J
AU Vinciarelli, A
   Pantic, M
   Bourlard, H
AF Vinciarelli, Alessandro
   Pantic, Maja
   Bourlard, Herve
TI Social signal processing: Survey of an emerging domain
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Social signals; Computer vision; Speech processing; Human behaviour
   analysis'; Social interactions
ID EMOTION RECOGNITION; FACE DETECTION; AUTOMATIC-ANALYSIS; GAIT
   RECOGNITION; THIN SLICES; SELF; COMMUNICATION; EXPRESSIONS; BEHAVIOR;
   SPEECH
AB The ability to understand and manage social signals of a person we are communicating with is the core of social intelligence. Social intelligence is a facet of human intelligence that has been argued to be indispensable and perhaps the most important for success in life. This paper argues that next-generation computing needs to include the essence of social intelligence - the ability to recognize human social signals and social behaviours like turn taking, politeness, and disagreement - in order to become more effective and more efficient. Although each one of us understands the importance of social signals in everyday life situations, and in spite of recent advances in machine analysis of relevant behavioural cues like blinks, smiles, crossed arms, laughter, and similar, design and development of automated systems for social signal processing (SSP) are rather difficult. This paper surveys the past efforts in solving these problems by a computer, it summarizes the relevant findings in social psychology, and it proposes a set of recommendations for enabling the development of the next generation of socially aware computing. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Vinciarelli, Alessandro; Bourlard, Herve] IDIAP Res Inst, CH-1920 Martigny, Switzerland.
   [Vinciarelli, Alessandro; Bourlard, Herve] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.
   [Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, London SW7 2AZ, England.
   [Pantic, Maja] Univ Twente, NL-7522 NB Enschede, Netherlands.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Imperial College London; University of Twente
RP Vinciarelli, A (corresponding author), IDIAP Res Inst, CP592, CH-1920 Martigny, Switzerland.
EM vincia@idiap.ch; m.pantic@imperial.ac.uk; bourlard@idiap.ch
RI Vinciarelli, Alessandro/HZI-8274-2023; Vinciarelli,
   Alessandro/C-1651-2012
OI Vinciarelli, Alessandro/0000-0002-9048-0524
FU Swiss National Science Foundation; EC [FP7/2007-2013, 211486, 231287];
   European Research Council [ERC-2007-StG-203143]
FX The work of Dr. Vinciarelli is supported by the Swiss National Science
   Foundation through the National Center of Competence in Research on
   Interactive Multimodal Information Management (IM2). The work of Dr.
   Pantic is supported in part by the EC's 7th Framework Programme
   (FP7/2007-2013) under Grant Agreement No. 211486 (SEMAINE), and the
   European Research Council under the ERC Starting Grant Agreement No.
   ERC-2007-StG-203143 (MAHNOB). The research that has led to this work has
   been supported in part by the European Community's Seventh Framework
   Programme (FP7/2007-2013), under Grant Agreement No. 231287 (SSPNet).
CR Adolphs R, 2003, NAT REV NEUROSCI, V4, P165, DOI 10.1038/nrn1056
   Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   Ajmera J, 2003, SPEECH COMMUN, V40, P351, DOI 10.1016/S0167-6393(02)00087-0
   AJMERA J, 2004, THESIS ECOLE POLYTEC
   ALBRECHT K, 2005, INTELLIGENCE NEW SCI
   AMBADY N, 1992, PSYCHOL BULL, V111, P256, DOI 10.1037/0033-2909.111.2.256
   Ambady N, 2000, ADV EXP SOC PSYCHOL, V32, P201, DOI 10.1016/S0065-2601(00)80006-4
   [Anonymous], 1997, EUROSPEECH
   [Anonymous], P ICMI
   [Anonymous], 2006, P 8 ACM INT WORKSHOP
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], 2001, P SIGCHI C HUMAN FAC, DOI DOI 10.1145/365024.365119
   [Anonymous], 1965, The expression of emotions in man and animal
   [Anonymous], P NIST M REC WORKSH
   [Anonymous], 2005, Handbook of nonverbal behavior research methods in the affective sciences
   [Anonymous], P INT C SPOK LANG PR
   [Anonymous], C P IEEE INT C SYST
   [Anonymous], 2008, P IEEE INT C COMP VI
   [Anonymous], 1950, AM SOCIOL REV
   [Anonymous], NSF PLANN WORKSH FAC
   Argyle Michael., 1967, The psychology of interpersonal behavior
   ARIKAN D, 2006, FDN TRENDS COMPUTER, V1, P77
   Bailenson JN, 2007, J NONVERBAL BEHAV, V31, P225, DOI 10.1007/s10919-007-0034-6
   Bailenson JN, 2008, COMPUT HUM BEHAV, V24, P66, DOI 10.1016/j.chb.2007.01.015
   Banerjee S., 2004, Proc. Int. Conf. Spoken Language Processing, P2189
   BARRAS C, 2004, P RICH TRANSCR WORKS
   Barzilay R, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P679
   BENABDELKADER C, 2009, COMPUTATIONAL FORENS
   BESKOW KJ, 2000, P INT C SPOK LANG PR, P464
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Boersma P., 2018, Praat: doing phonetics by computer, DOI DOI 10.1097/AUD.0B013E31821473F7
   BUCHANAN M, 1968, STRATEGY BUSINESS, V48, P68
   BURGOON JK, 1995, DILLMANINTERPERSONAL
   Campbell N, 2006, IEEE T AUDIO SPEECH, V14, P1171, DOI 10.1109/TASL.2006.876131
   Chartrand TL, 1999, J PERS SOC PSYCHOL, V76, P893, DOI 10.1037/0022-3514.76.6.893
   Cohn J.F., 2006, Proceedings of the 8th international conference on Multimodal interfaces-ICMI'06, P233, DOI DOI 10.1145/1180995.1181043
   COLEMAN D, 2006, SOCIAL INTELLIGENCE
   CORTES JB, 1965, J CONSULT PSYCHOL, V29, P432, DOI 10.1037/h0022504
   Costa M, 2001, J NONVERBAL BEHAV, V25, P225, DOI 10.1023/A:1012544204986
   Coulson M, 2004, J NONVERBAL BEHAV, V28, P117, DOI 10.1023/B:JONB.0000023655.25550.be
   Coulston R., 2002, ICSLP2002, V4, P2689
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   COWIE R, 2008, P IEEE INT C AUT FAC
   Cunningham D.W., 2004, P 1 S APPL PERCEPTIO, V73, P143
   Curhan JR, 2007, J APPL PSYCHOL, V92, P802, DOI 10.1037/0021-9010.92.3.802
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Darrell T, 2000, INT J COMPUT VISION, V37, P175, DOI 10.1023/A:1008103604354
   De Silva PR, 2004, COMPUT ANIMAT VIRT W, V15, P269, DOI 10.1002/cav.29
   Dielmann A, 2007, IEEE T MULTIMEDIA, V9, P25, DOI 10.1109/TMM.2006.886337
   Ding L, 2007, 2007 IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P447, DOI 10.1109/AVSS.2007.4425352
   DION K, 1972, J PERS SOC PSYCHOL, V24, P285, DOI 10.1037/h0033731
   Dong W, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P271
   Eagle N, 2006, PERS UBIQUIT COMPUT, V10, P255, DOI 10.1007/s00779-005-0046-3
   Eisenthal Y, 2006, NEURAL COMPUT, V18, P119, DOI 10.1162/089976606774841602
   Ekman P, 2003, ANN NY ACAD SCI, V1000, P205, DOI 10.1196/annals.1280.010
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P., 2005, WHAT FACE REVEALS BA
   Ekman P., 1969, Semiotica, V1, P49, DOI [10.1515/semi.1969.1.1.49, DOI 10.1515/SEMI.1969.1.1.49]
   Ekman Paul., 1982, Emotion in the Human Face - 1st Edition
   FADEN RR, 1986, HIST THEORY INFORMED
   Fasel I, 2005, COMPUT VIS IMAGE UND, V98, P182, DOI 10.1016/j.cviu.2004.07.014
   Favre S., 2008, Proc. ACM International Conference on Multimodal Interfaces, P29
   Fragopanagos N, 2005, NEURAL NETWORKS, V18, P389, DOI 10.1016/j.neunet.2005.03.006
   Frank MG, 2004, J PERS SOC PSYCHOL, V86, P486, DOI 10.1037/0022-3514.86.3.486
   Gandhi T, 2007, IEEE T INTELL TRANSP, V8, P413, DOI 10.1109/TITS.2007.903444
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Garg N. P., 2008, P ACM INT C MULT, P693
   Gatica-Perez D, 2005, INT CONF ACOUST SPEE, P489
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Gladwell M., 2005, The power of thinking without thinking
   GLASS CR, 1982, COGNITIVE THER RES, V6, P37, DOI 10.1007/BF01185725
   Gold JM, 2008, PERCEPT PSYCHOPHYS, V70, P88, DOI 10.3758/PP.70.1.88
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Grahe JE, 1999, J NONVERBAL BEHAV, V23, P253, DOI 10.1023/A:1021698725361
   GREENE K, 2008, 10 EMERGING TECHNOLO
   GREENWALD AG, 1995, PSYCHOL REV, V102, P4, DOI 10.1037/0033-295X.102.1.4
   Gregory SW, 1997, J NONVERBAL BEHAV, V21, P23
   GROSS MM, 2007, P INT C EXPR EM HLTH
   Gunes H, 2004, IEEE SYS MAN CYBERN, P2168
   Gunes Hatice, 2008, Affective Computing. Focus on Emotion Expression, Synthesis and Recognition, P185
   Gunes H, 2007, J NETW COMPUT APPL, V30, P1334, DOI 10.1016/j.jnca.2006.09.007
   Gunes H, 2006, INT J HUM-COMPUT ST, V64, P1184, DOI 10.1016/j.ijhcs.2006.07.004
   Hall E. T., 1959, SILENT LANGUAGE
   Hayfron-Acquah JB, 2003, PATTERN RECOGN LETT, V24, P2175, DOI 10.1016/S0167-8655(03)00086-2
   HIRSCHBERG J, 1993, ARTIF INTELL, V63, P305, DOI 10.1016/0004-3702(93)90020-C
   HIRSCHBERG J, 1992, SPEECH AND NATURAL LANGUAGE, P441
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Huang KS, 2004, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2004.1334689
   HUNG H, 2007, P ACM INT C MULT, P835
   Ito A, 2005, 2005 INTERNATIONAL CONFERENCE ON CYBERWORLDS, PROCEEDINGS, P437, DOI 10.1109/CW.2005.82
   IVANOV Y, 1999, P WORKSH VIS SURV CO
   Jaimes A., 2004, 1st ACM workshop on Continuous archival and retrieval of personal experiences (CARPE 2004), P74, DOI DOI 10.1145/1026653.1026665
   Keltner D, 1999, COGNITION EMOTION, V13, P505, DOI 10.1080/026999399379168
   Keltner D., 2000, Handbook of emotions, Vsecond, P236
   Keltner D., 1998, REV GEN PSYCHOL, V2, P320, DOI DOI 10.1037/1089-2680.2.3.320
   Kimura M, 2006, J NONVERBAL BEHAV, V30, P115, DOI 10.1007/s10919-006-0011-5
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kleinsmith A, 2006, INTERACT COMPUT, V18, P1371, DOI 10.1016/j.intcom.2006.04.003
   Knapp M., 1972, Nonverbal Communication in Human Interaction
   KONG WW, 2008, P IEEE INT C AUT FAC
   Lakin JL, 2003, J NONVERBAL BEHAV, V27, P145, DOI 10.1023/A:1025389814290
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   LEUNG TK, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P637, DOI 10.1109/ICCV.1995.466878
   Li XL, 2008, IEEE T SYST MAN CY C, V38, P145, DOI 10.1109/TSMCC.2007.913886
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Littlewort GC, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P15
   LIU Y, 2007, P EUR C SPEECH COMM
   LOTT DF, 1967, J PERS SOC PSYCHOL, V7, P90, DOI 10.1037/h0024925
   Lu L, 2002, IEEE T SPEECH AUDI P, V10, P504, DOI 10.1109/TSA.2002.804546
   Lucey Simon., 2007, FACE RECOGNITION DEL, P275
   MCARTHUR LZ, 1983, PSYCHOL REV, V90, P215, DOI 10.1037/0033-295X.90.3.215
   McCowan I, 2005, IEEE T PATTERN ANAL, V27, P305, DOI 10.1109/TPAMI.2005.49
   McCowan I, 2003, INT CONF ACOUST SPEE, P748
   McNeill D., 1996, HAND MIND WHAT GESTU
   MEHRABIAN A, 1967, J CONSULT PSYCHOL, V31, P248, DOI 10.1037/h0024648
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   MOB Y, 2003, P IEEE INT C AC SPEE, P85
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Möller S, 1999, SPEECH COMMUN, V28, P175, DOI 10.1016/S0167-6393(99)00016-3
   Montague PR, 2002, NEUROIMAGE, V16, P1159, DOI 10.1006/nimg.2002.1150
   Moore BrianC. J., 1982, An Introduction to the Psychology of Hearing
   Morgan N, 1998, INT CONF ACOUST SPEE, P729, DOI 10.1109/ICASSP.1998.675368
   MORGAN N, 1997, P EUR, P2079
   MORRIS D, 2007, PEOPLEWATCHING2007
   Mota Selene, 2003, P COMP VIS PATT REC, V5, P1, DOI [10.1109/CVPRW.2003.10047, DOI 10.1109/CVPRW.2003.10047]
   Mukhopadhyay S, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P477, DOI 10.1145/319463.319690
   Murphy Kevin Patrick, 2002, Dynamic bayesian networks: representation, inference and learning
   NASS C, 1993, HUM COMMUN RES, V19, P504, DOI 10.1111/j.1468-2958.1993.tb00311.x
   Nass C, 2001, J EXP PSYCHOL-APPL, V7, P171, DOI 10.1037//1076-898X.7.3.171
   O'Toole AJ, 1999, IMAGE VISION COMPUT, V18, P9, DOI 10.1016/S0262-8856(99)00012-8
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Oliver N, 2004, COMPUT VIS IMAGE UND, V96, P163, DOI 10.1016/j.cviu.2004.02.004
   Oviatt S., 2004, ACM Transactions on Computer-Human Interaction, V11, P300, DOI 10.1145/1017494.1017498
   Oviatt S, 2003, P IEEE, V91, P1457, DOI 10.1109/JPROC.2003.817127
   Pal P., 2006, P IEEE INT C AC SPEE, V2, P721
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Pantic Maja, 2008, International Journal of Automomous and Adaptive Communications Systems, V1, P168, DOI 10.1504/IJAACS.2008.019799
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   PANTIC M, 2007, HDB FACE RECOGNITION, P377
   Pantic M, 2007, LECT NOTES COMPUT SC, V4451, P47
   Pelachaud C., 2002, Proceedings of the First International Joint Conference on Autonomous Agents and Multiagent Systems, P758
   Pentland A, 2005, COMPUTER, V38, P33, DOI 10.1109/MC.2005.104
   PENTLAND A, 2008, SIGNALS THEYR SHAPE
   Pentland A., 2004, SOCIAL DYNAMICS SIGN
   Pentland A, 2007, PHYSICA A, V378, P59, DOI 10.1016/j.physa.2006.11.046
   Pentland A, 2007, IEEE SIGNAL PROC MAG, V24, P108, DOI 10.1109/MSP.2007.4286569
   Petridis S, 2008, INT CONF ACOUST SPEE, P5117, DOI 10.1109/ICASSP.2008.4518810
   Pfau T, 1998, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.1998.675422
   Pickles J. O., 1982, INTRO PHYSL HEARING
   Pollick FE, 2002, VISION RES, V42, P2345, DOI 10.1016/S0042-6989(02)00196-7
   Pollick FE, 2001, COGNITION, V82, pB51, DOI 10.1016/S0010-0277(01)00147-0
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Psathas G., 1995, CONVERSATION ANAL ST, DOI https://doi.org/10.4135/9781412983792
   Rabiner L., 1977, INT C ACOUSTICS SPEE, V2, P323
   Rabiner Lawrence, 2010, Digital Processing of Speech Signals
   REYNOLDS D, 2004, P IEEE INT C AC SPEE, P177
   Richmond V., 1995, Nonverbal behaviors in interpersonal relations
   Rienks R, 2005, LECT NOTES COMPUT SC, V3869, P76
   Rienks R., 2006, P 8 INT C MULTIMODAL, P257
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   Russell JamesA., 1997, The Psychology of Facial Expression
   Russo N.F., 1967, Cornell Journal of Social Relations, V2, P37
   SAYETTE MA, 1992, J STUD ALCOHOL, V53, P541, DOI 10.15288/jsa.1992.53.541
   SCHEFLEN AE, 1964, PSYCHIATR, V27, P316
   Scherer K. R., 1979, Personality markers in speech
   Scherer KR, 2003, SPEECH COMMUN, V40, P227, DOI 10.1016/S0167-6393(02)00084-5
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Schuller B, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P30
   Segerstrale U.C., 1997, NONVERBAL COMMUNICAT
   SEPHERI A, 2006, J MULTIMEDIA, V1, P18
   Shriberg A., 2001, EUROSPEECH 2001, P1359
   SHRIBERG E, 1999, P INT C PHON SCI, V11, P619
   SHROUT PE, 1981, J PERS, V49, P115, DOI 10.1111/j.1467-6494.1981.tb00732.x
   Sminchisescu C, 2006, COMPUT VIS IMAGE UND, V104, P210, DOI 10.1016/j.cviu.2006.07.014
   SMITHLOVIN L, 1989, AM SOCIOL REV, V54, P424, DOI 10.2307/2095614
   StanleyWasserman Katherine, 1994, SOCIAL NETWORK ANAL, DOI 10.1017/CBO9780511815478
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Thorndike EL, 1920, Harper's Magazine, V140, P227
   Thurau C, 2007, LECT NOTES COMPUT SC, V4814, P299
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Tischler H.L., 1990, Introduction to Sociology, V3rd
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   TRAN D, 2008, P EUR C COMP VIS
   Tranter SE, 2006, IEEE T AUDIO SPEECH, V14, P1557, DOI 10.1109/TASL.2006.878256
   Triandis H., 1994, CULTURE SOCIAL BEHAV
   Truong KP, 2007, SPEECH COMMUN, V49, P144, DOI 10.1016/j.specom.2007.01.001
   TRUONG KP, 1994, P EUR C SPEECH COMM, P485
   Uddin LQ, 2007, TRENDS COGN SCI, V11, P153, DOI 10.1016/j.tics.2007.01.001
   Utsumi A, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P39, DOI 10.1109/AFGR.2002.1004128
   Valstar M., 2006, COMP VIS PATT REC WO, P149
   Valstar M.F., 2006, International Conference on Multimodal Interfaces, P162, DOI DOI 10.1145/1180995.1181031
   Valstar MF, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P38
   Van den Stock J, 2007, EMOTION, V7, P487, DOI 10.1037/1528-3542.7.3.487
   Vinciarelli A., 2008, P 10 INT C MULTIMODA, P61, DOI DOI 10.1145/1452392.1452405
   Vinciarelli A., 2008, P 16 ACM INT C MULT, P1061, DOI DOI 10.1145/1459359.1459573
   Vinciarelli A, 2007, IEEE T MULTIMEDIA, V9, P1215, DOI 10.1109/TMM.2007.902882
   Vinciarelli A, 2006, IEEE T MULTIMEDIA, V8, P981, DOI 10.1109/TMM.2006.879870
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Waibel A, 2003, INT CONF ACOUST SPEE, P752
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang P, 2004, INT C PATT RECOG, P179, DOI 10.1109/ICPR.2004.1333733
   WARNER RM, 1986, J PERS SOC PSYCHOL, V50, P792, DOI 10.1037/0022-3514.50.4.792
   Weng CY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1403
   Williams ACD, 2002, BEHAV BRAIN SCI, V25, P439, DOI 10.1017/S0140525X02000080
   Wu Y, 1999, LECT NOTES ARTIF INT, V1739, P103
   Xuan Huang, 2021, 2021 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech), P867, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech52372.2021.00144
   Yacoob Y, 2006, IEEE T PATTERN ANAL, V28, P1164, DOI 10.1109/TPAMI.2006.139
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   YAO J, 2008, P EUR C COMP VIS VIS
   YULE G, 1996, PRAGMATICS 1996
   Zancanaro M., 2006, Proceedings of the 8th international conference on Multimodal interfaces, P28
   Zellner B., 1994, FUNDAMENTALS SPEECH, P41
   Zeng Z., 2006, J MULTIMED, V1, P1, DOI DOI 10.4304/jmm.1.5.1-8
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   Zhu Q, 2006, 2006 IEEE COMP SOC C, P1491, DOI [10.1109/CVPR.2006.119, DOI 10.1109/CVPR.2006.119]
   1969, D CRYSTAL PROSODIC S
NR 221
TC 555
Z9 616
U1 3
U2 59
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2009
VL 27
IS 12
SI SI
BP 1743
EP 1759
DI 10.1016/j.imavis.2008.11.007
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 513PL
UT WOS:000271335000002
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Kelly, P
   O'Connor, NE
   Smeaton, AF
AF Kelly, Philip
   O'Connor, Noel E.
   Smeaton, Alan F.
TI Robust pedestrian detection and tracking in crowded scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pedestrian detection; Pedestrian tracking; Stereo; Crowds
ID PERSON TRACKING; STEREO
AB in this paper, a robust computer vision approach to detecting and tracking pedestrians in unconstrained crowded scenes is presented. Pedestrian detection is performed via a 3D clustering process within a region-growing framework. The clustering process avoids using hard thresholds by using bio-metrically inspired constraints and a number of plan-view statistics. Pedestrian tracking is achieved by formulating the track matching process as a weighted bipartite graph and using a Weighted Maximum Cardinality Matching scheme. The approach is evaluated using both indoor and outdoor sequences, captured using a variety of different camera placements and orientations, that feature significant challenges in terms of the number of pedestrians present, their interactions and scene lighting conditions. The evaluation is performed against a manually generated groundtruth for all sequences. Results point to the extremely accurate performance of the proposed approach in all cases. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Kelly, Philip; O'Connor, Noel E.; Smeaton, Alan F.] Dublin City Univ, Adapt Informat Cluster, Ctr Digital Video Proc Elect Engn, Dublin 9, Ireland.
C3 Dublin City University
RP Kelly, P (corresponding author), Dublin City Univ, Adapt Informat Cluster, Ctr Digital Video Proc Elect Engn, Dublin 9, Ireland.
EM kellyp@eeng.dcu.ie
OI Smeaton, Alan F./0000-0003-1028-8389; O'Connor, Noel/0000-0002-4033-9135
FU Science Foundation Ireland [03/IN.3/1361]
FX This material is based on works supported by Science Foundation Ireland
   under Grant No. 03/IN.3/1361.
CR [Anonymous], IEEE WORKSH HUM MOD
   BERGE C, 1957, P NATL ACAD SCI USA, V43, P842, DOI 10.1073/pnas.43.9.842
   Beymer D, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P127, DOI 10.1109/HUMO.2000.897382
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Darrell T, 2000, INT J COMPUT VISION, V37, P175, DOI 10.1023/A:1008103604354
   Elgammal AM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P145, DOI 10.1109/ICCV.2001.937617
   GALIL Z, 1986, COMPUT SURV, V18, P23, DOI 10.1145/6462.6502
   Haritaoglu I., 1998, EUR C COMPUTER VISIO, P877
   Harville M, 2004, IMAGE VISION COMPUT, V22, P127, DOI 10.1016/j.imavis.2003.07.009
   Harville M., 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P67
   HARVILLE M, 2002, IEEE COMP SOC C COMP, P398
   Hayashi K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P681, DOI 10.1109/AFGR.2004.1301613
   Heisele B, 1998, INT C PATT RECOG, P1325, DOI 10.1109/ICPR.1998.711946
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   KELLY P, 2006, ACM INT WORKSH VID S, P161
   Kelly P, 2006, LECT NOTES COMPUT SC, V4142, P802
   Krumm J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P3, DOI 10.1109/VS.2000.856852
   Leibe B, 2005, PROC CVPR IEEE, P878
   Liu X, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P306
   Muñoz-Salinas R, 2005, LECT NOTES ARTIF INT, V3789, P337
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   Pai CJ, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P101
   Remagnino P, 2005, IEEE T SYST MAN CY A, V35, P1, DOI 10.1109/TSMCA.2004.838456
   Rittscher J, 2005, PROC CVPR IEEE, P486
   Senior A., 2002, PROC IEEE INT WORKSH, P48
   SOBOTTKA K, 1996, INT C PATT REC ICPR, V3, P421
   VALEE M, 2005, INT C PERV COMP, P157
   Zhao L, 2000, IEEE T INTELL TRANSP, V1, P148, DOI 10.1109/6979.892151
   Zhao T, 2003, PROC CVPR IEEE, P459, DOI 10.1109/NSSMIC.2003.1352083
NR 30
TC 18
Z9 22
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1445
EP 1458
DI 10.1016/j.imavis.2008.04.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800004
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Hotta, K
AF Hotta, Kazuhiro
TI Pose independent object classification from small number of training
   samples based on kernel principal component analysis of local parts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pose independence; Local features; Kernel principal component analysis;
   Face recognition; 3D object recognition
ID FACE RECOGNITION; FEATURES; MACHINE; MODELS
AB This paper presents a pose independent classification method from a small number of training samples based on kernel principal component analysis (KPCA) of local parts. Pose changes induce large non-linear variation in feature space of global features. Therefore, conventional methods require multiple poses in training. However, the influence of pose changes in local features is less than that in global features because the global configuration is much influenced. The difference of distributions of local parts cropped from different poses is not so large. If the distribution of local parts cropped from typical poses is modeled, it is robust to unknown poses. Since the distribution of local parts is non-linear, KPCA is used to model the feature space specialized of each class. Class-featuring information compression (CLAFIC) is used to compute the similarity with subspace. In CLAFIC of KPCA, the similarity with certain class is computed by the weighted sum of the similarities with training local parts. Since many local parts are cropped from the input, voting, summation, and median rules are used to combine the similarities of all local parts. Robustness to pose variation is evaluated using the face images of five poses of 300 subjects. Although only frontal and profile views are used in training, the recognition rates to unknown poses are more than 90%. Effectiveness is shown by the comparison with linear PCA of local parts and global features based methods. In addition, the proposed method can be applied easily to the recognition problem of various kinds of 3D objects because it does not require many poses in training or preprocessing such as accurate correspondence between images. The robustness to pose variation and ease of applications are demonstrated using COIL 100 database. (C) 2008 Elsevier B.V. All rights reserved.
C1 Univ Electrocommun, Dept Informat & Commun Engn, Tokyo 1828585, Japan.
C3 University of Electro-Communications - Japan
RP Hotta, K (corresponding author), Univ Electrocommun, Dept Informat & Commun Engn, 1-5-1 Chofugaoka, Tokyo 1828585, Japan.
EM hotta@ice.uec.ac.jp
FU Ministry of Education, Culture, Sports, Science and Technology of Japan
   [18700170]; Grants-in-Aid for Scientific Research [18700170] Funding
   Source: KAKEN
FX This work was partially supported by the Grant-in-Aid for Scientific
   Research (No. 18700170) from the Ministry of Education, Culture, Sports,
   Science and Technology of Japan.
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Ali S, 2005, IEEE I CONF COMP VIS, P1347
   [Anonymous], 1996, COLUMBIA OBJECT IMAG
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], 2006, 10 INT WORKSH FRONT
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], 1998, ADV KERNEL METHODS S
   [Anonymous], 1983, SUBSPACE METHODS PAT
   [Anonymous], P INT JOINT C PATT R
   BALACHANDER T, 1999, P INT JOINT C NEUR N, V5, P3119
   BART E, 2004, P ECCV, V2, P152
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   BEYMER D, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P500, DOI 10.1109/ICCV.1995.466898
   Blanz V, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P202, DOI 10.1109/AFGR.2002.1004155
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Debnath R, 2004, IEICE T INF SYST, VE87D, P2903
   Féraud R, 2001, IEEE T PATTERN ANAL, V23, P42, DOI 10.1109/34.899945
   Ferrari V, 2004, LECT NOTES COMPUT SC, V3021, P40
   FUKUI K, 2006, P AS C COMP VIS, V1, P315
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Goudail F, 1996, IEEE T PATTERN ANAL, V18, P1024, DOI 10.1109/34.541411
   Gross R., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P481
   Gross R, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P3, DOI 10.1109/AFGR.2002.1004122
   Gupta H, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P13, DOI 10.1109/ACV.2002.1182137
   Heisele B, 2003, COMPUT VIS IMAGE UND, V91, P6, DOI 10.1016/S1077-3142(03)00073-0
   Hotta K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P70, DOI 10.1109/AFGR.1998.670927
   Hotta K, 2001, IEICE T INF SYST, VE84D, P867
   HOTTA K, 2004, J ADV COMPUTATIONAL, V8, P130
   HOTTA K, 2005, P IEEE INT C IM PROC, V3, P760
   Hotta K, 2008, IMAGE VISION COMPUT, V26, P1490, DOI 10.1016/j.imavis.2008.04.008
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Huber P., 1981, Robust Statistics
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kurita T, 2003, NEUROCOMPUTING, V51, P181, DOI 10.1016/S0925-2312(02)00615-X
   KURITA T, 2000, P IAPR WORKSH MACH V, P211
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   LI Y, 2000, P IEEE INT C AUT FAC, P300
   Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moghaddam B, 2002, IEEE T PATTERN ANAL, V24, P780, DOI 10.1109/TPAMI.2002.1008384
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   OBDRZALEK S., 2002, BRIT MACHINE VISION, P113
   Ohba K, 1997, IEEE T PATTERN ANAL, V19, P1043, DOI 10.1109/34.615453
   Okada K, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P71, DOI 10.1109/AFGR.2002.1004134
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   PHILLIPS PJ, 2003, NISTIR6965
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   Rothganger F, 2003, PROC CVPR IEEE, P272
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   ROWLEY H, 1999, CMUCS99117
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   SCHOLKOPF B, 1995, P 1 INT C KNOWL DISC, P252
   Shawe-Taylor J., 2004, KERNEL METHODS PATTE
   SMOLA AJ, 1999, 9904 U WISC
   Suzuki H, 2005, IEICE T INF SYST, VE88D, P410, DOI 10.1093/ietisy/e88-d.3.410
   Tipping ME, 2001, ADV NEUR IN, V13, P633
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Watanabe S., 1969, Knowing and Guessing: A Quantitative Study of Inference and Information
   Yang WG, 2002, IEEE PHOTONIC TECH L, V14, P215, DOI 10.1109/68.980526
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhou SK, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P229, DOI 10.1109/AFGR.2004.1301536
   HOIP FACE DATABASE
NR 73
TC 6
Z9 6
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1240
EP 1251
DI 10.1016/j.imavis.2008.11.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200002
DA 2024-07-18
ER

PT J
AU Bodor, R
   Drenner, A
   Fehr, D
   Malsoud, O
   Papanikolopoulos, N
AF Bodor, R.
   Drenner, A.
   Fehr, D.
   Malsoud, O.
   Papanikolopoulos, N.
TI View-independent human motion classification using image-based
   reconstruction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image-based rendering; Human motion recognition; Computer vision; Visual
   tracking; Shape reconstruction
ID RECOGNITION
AB We introduce in this paper a novel method for employing image-based rendering to extend the range of applicability of human motion and gait recognition systems. Much work has been done in the field of human motion and gait recognition, and many interesting methods for detecting and classifying motion have been developed. However, systems that can robustly recognize human behavior in real-world contexts have yet to be developed. A significant reason for this is that the activities of humans in typical settings are unconstrained in terms of the motion path. People are free to move throughout the area of interest in any direction they like. While there have been many good classification systems developed in this domain, the majority of these systems have used a single camera providing input to a training-based learning method. Methods that rely on a single camera are implicitly view-dependent. In practice, the classification accuracy of these systems often becomes increasingly poor as the angle between the camera and the direction of motion varies away from the training view angle. As a result, these methods have limited real-world applications, since it is often impossible to limit the direction of motion of people so rigidly. We demonstrate the use of image-based rendering to adapt the input to meet the needs of the classifier by automatically constructing the proper view (image), that matches the training view, from a combination of arbitrary views taken from several cameras. We tested the method on 162 sequences of video data of human motions taken indoors and outdoors, and promising results were obtained. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Bodor, R.; Drenner, A.; Fehr, D.; Malsoud, O.; Papanikolopoulos, N.] Univ Minnesota, Artificial Intelligence Robot & Vis Lab, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Papanikolopoulos, N (corresponding author), Univ Minnesota, Artificial Intelligence Robot & Vis Lab, Dept Comp Sci & Engn, 4-192 EE CS Bldg,200 Union St SE, Minneapolis, MN 55455 USA.
EM rbodor@cs.umn.edu; drenner@cs.umn.edu; fehr@cs.umn.edu;
   masoud@cs.umn.edu; npapas@cs.umn.edu
RI Papanikolopoulos, Nikos/ITW-0029-2023
OI Papanikolopoulos, Nikos/0000-0002-2177-1870
FU USDOD ARMY [W911NF-08-1-0463]; National Science Foundation [IIS-0219863,
   IIP-0443945]; Minnesota Department of Transportation; ITS Institute at
   the University of Minnesota
FX This work was Supported by the USDOD ARMY through contract
   #W911NF-08-1-0463 (Proposal 55111-CI), the National Science Foundation
   through Grants #IIS-0219863 and #IIP-0443945, the Minnesota Department
   of Transportation, and the ITS Institute at the University of Minnesota.
CR [Anonymous], P 3 IEEE INT C AUT F
   [Anonymous], P 23 ANN C COMP GRAP
   Ben-Arie J, 2002, IEEE T PATTERN ANAL, V24, P1091, DOI 10.1109/TPAMI.2002.1023805
   Bradski GR, 2002, MACH VISION APPL, V13, P174, DOI 10.1007/s001380100064
   Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382
   CAO D, 2004, IEEE INT C ROB AUT I
   CARRANZA J, 2003, P SIGGRAPH 03, P569
   Cheung KM, 2005, INT J COMPUT VISION, V62, P221, DOI 10.1007/s11263-005-4881-5
   CUTLER R, 1998, P 3 IEEE C FAC GEST
   Davis JW, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P169, DOI 10.1109/AVSS.2003.1217918
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   DiFranco DE, 2001, PROC CVPR IEEE, P307
   Elgammal A, 2004, PROC CVPR IEEE, P478
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   FABLET R, 2002, EUR C COMP VIS ECCV0
   GAVRILA D, 1999, COMPUTER VISION IMAG, V73
   GAVRILA DM, 1996, P IEEE C COMP VIS PA, V1
   Grauman K, 2003, PROC CVPR IEEE, P187
   Kale A, 2003, P IEEE C ADV VID SIG
   LUCK J, 2001, INT WORKSH ROB VIS 2, P19
   MARTIN R, 2000, P IEEE 5 INT C INT T, P152
   Masoud O, 2003, IMAGE VISION COMPUT, V21, P729, DOI 10.1016/S0262-8856(03)00068-4
   MASOUD O, 2004, P IEEE RSJ INT C INT
   Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951
   Mizoguchi M, 2002, INT C PATT RECOG, P56, DOI 10.1109/ICPR.2002.1047399
   Ojanen Harri., 1999, Automatic Correction of Lens Distortion by Using Digital Image Processing
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   POLANA R, 1994, NONPARAMETRIC RECOGN
   ROSALES R, 1999, P IEEE C COMP VIS PA
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   VEERARAGHAVANM H, 2004, P 2004 IEEE C ROB AU, V3, P2303
   WEIK S, 2001, INT WORKSH ROB VIS 2, P27
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   ZHAO L, 2001, CMURITR0119
NR 34
TC 100
Z9 112
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1194
EP 1206
DI 10.1016/j.imavis.2008.11.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000019
DA 2024-07-18
ER

PT J
AU Carneiro, G
   Jepson, AD
AF Carneiro, Gustavo
   Jepson, Allan D.
TI The quantitative characterization of the distinctiveness and robustness
   of local image descriptors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual object recognition; Local image descriptors; Discriminant
   classifier; Regression models
AB We introduce a new method that characterizes quantitatively local image descriptors in terms of their distinctiveness and robustness to geometric transformations and brightness deformations. The quantitative characterization of these properties is important for recognition systems based on local descriptors because it allows for the implementation of a classifier that selects descriptors based on their distinctiveness and robustness properties. This classification results in: (a) recognition time reduction due to a smaller number of descriptors present in the test image and in the database of model descriptors; (b) improvement of the recognition accuracy since only the most reliable descriptors for the recognition task are kept in the model and test images; and (c) better scalability given the smaller number of descriptors per model. Moreover, the quantitative characterization of distinctiveness and robustness of local descriptors provides a more accurate formulation of the recognition process, which has the potential to improve the recognition accuracy. We show how to train a multi-layer perceptron that quickly classifies robust and distinctive local image descriptors. A regressor is also trained to provide quantitative models for each descriptor. Experimental results show that the use of these trained models not only improves the performance of our recognition system, but it also reduces significantly the computation time for the recognition process. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Carneiro, Gustavo] Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ USA.
   [Jepson, Allan D.] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
C3 Siemens AG; University of Toronto
RP Carneiro, G (corresponding author), Siemens Corp Res, Integrated Data Syst Dept, 755 Coll Rd E, Princeton, NJ USA.
EM carneiro@cs.toronto.edu; jepson@cs.utoronto.ca
OI Carneiro, Gustavo/0000-0002-5571-6220
CR Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113
   Amit Y, 1999, NEURAL COMPUT, V11, P1691, DOI 10.1162/089976699300016197
   BOSCH A, 2007, P INT C COMP VIS RIO
   CARNEIRO G, 2006, ECCV, V3, P29
   CARNEIRO G, 2003, IEEE C COMP VIS PATT
   CARNEIRO G, 2002, ECCV, P282
   CARNEIRO G, 2007, IEEE T PATTERN ANAL, V29, P12
   CARNEIRO G, 2005, IEEE C COMP VIS PATT
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   DAVISON AJ, 2003, INT C COMP VIS NIC F
   Ding LY, 2008, PROC CVPR IEEE, P3653
   DORKO G, 2003, INT C COMP VIS NIC F
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   Fergus R, 2003, PROC CVPR IEEE, P264
   Fleet DavidJ., 1992, MEASUREMENT IMAGE VE
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HE X, 2005, WORKSH MACH LEARN BA
   KE Y, 2004, IEEE CVPR
   LAPTEV I, 2006, P BRIT MACH VIS C ED
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Nabney I., 2003, NETLAB NEURAL NETWOR
   Nelson RC, 1996, IMAGE UNDERSTANDING WORKSHOP, 1996 PROCEEDINGS, VOLS I AND II, P1305
   Ohba K, 1997, IEEE T PATTERN ANAL, V19, P1043, DOI 10.1109/34.615453
   Pope AR, 2000, INT J COMPUT VISION, V40, P149, DOI 10.1023/A:1026502202780
   Sala P, 2006, IEEE T ROBOT, V22, P334, DOI 10.1109/TRO.2005.861480
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2383, P186
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   SE S, 2002, INT J ROBOTICS RES, V21
   Sim R, 2001, PROC CVPR IEEE, P406
   SIVIC J, 2004, EUR C COMP VIS PRAG
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Weber M, 2000, LECT NOTES COMPUT SC, V1842, P18
   WU J, 2000, THESIS QUEENS U KING
   YUILLE A, 1999, IEEE C COMP VIS PATT
   Zhang W, 2007, IMAGE VISION COMPUT, V25, P704, DOI 10.1016/j.imavis.2006.05.016
NR 40
TC 10
Z9 10
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1143
EP 1156
DI 10.1016/j.imavis.2008.10.015
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000015
DA 2024-07-18
ER

PT J
AU Lillholm, M
   Griffin, LD
AF Lillholm, Martin
   Griffin, Lewis D.
TI Statistics and category systems for the shape index descriptor of local
   2nd order natural image structure
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Local image structure; Image features; Natural image statistics
ID RECEPTIVE-FIELDS; MODEL
AB The shape index offers a natural and invariant description of pure 2nd order image structure. We discuss its properties and report novel natural image statistics for the shape index and the additional two parameters of curvedness and principal direction that form a complete and decoupled re-parameterisation of 2nd order structure. In a second main theme, we address three separate avenues to a categorisation of the shape index for natural images and Suggest five feature categories as a natural 2nd order image structure 'alphabet'. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Lillholm, Martin; Griffin, Lewis D.] UCL, Dept Comp Sci, London WC1E 6BT, England.
C3 University of London; University College London
RP Lillholm, M (corresponding author), UCL, Dept Comp Sci, Malet Pl, London WC1E 6BT, England.
EM m.lillholm@cs.ucl.ac.uk
RI Griffin, Lewis/C-2118-2008
FU EPSRC [EP/D030978/1]; EPSRC [EP/D030978/1] Funding Source: UKRI
FX EPSRC-funded project 'Basic Image Features' EP/D030978/1
CR AGHAJANIAN J, 2007, IN BMVA STUD PAP M
   [Anonymous], 1985, GM RES LABS TECHN PU
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871
   CASORATI F, 1867, REND MAEM ACCD LOMB
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   de Bruijne M, 2004, LECT NOTES COMPUT SC, V3216, P168
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Florack L. M. J., 1993, Journal of Mathematical Imaging and Vision, V3, P327, DOI 10.1007/BF01664793
   Folkesson J, 2005, PROC SPIE, V5747, P1484, DOI 10.1117/12.595665
   G?rdenfors P., 2004, CONCEPTUAL SPACES GE
   Griffin LD, 2005, SPATIAL VISION, V18, P484
   Griffin LD, 2004, VISION RES, V44, P407, DOI 10.1016/j.visres.2003.09.025
   GRIFFIN LD, 2007, P SPIE
   GRIFFIN LD, 2005, P SCAL SPAC 2005, P26
   GRIFFIN LD, ANALOGY COLOUR UNPUB
   Griffin LD, 2007, IEEE T PATTERN ANAL, V29, P1355, DOI 10.1109/TPAMI.2007.1066
   Griffin LD, 2006, INT J COMPUT VISION, V70, P213, DOI 10.1007/s11263-006-6355-9
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HUANG J, 1999, CVPR99
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   Hyvärinen A, 2001, VISION RES, V41, P2413, DOI 10.1016/S0042-6989(01)00114-6
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Koenderink J. J., 1992, Journal of Visual Communication and Image Representation, V3, P1, DOI 10.1016/1047-3203(92)90026-P
   Koenderink J. J., 1993, Journal of Intelligent Systems, V3, P49, DOI [10.1515/JISYS.1993.3.1.49, DOI 10.1515/JISYS.1993.3.1.49]
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   KOENDERINK JJ, 1984, BIOL CYBERN, V50, P363, DOI 10.1007/BF00336961
   KOENDERINK JJ, 1992, IEEE T PATTERN ANAL, V14, P597, DOI 10.1109/34.141551
   Koenderink JJ, 2002, LECT NOTES COMPUT SC, V2350, P158
   Koenderink JJ, 2003, IEICE T INF SYST, VE86D, P1165
   Koenderink JJ, 2000, LECT NOTES COMPUT SC, V1888, P69
   KOENDERINK JJ, 1990, BIOL CYBERN, V63, P291, DOI 10.1007/BF00203452
   KOENDERINK JJ, 1996, ADV IMAGE UNDERSTAND, P113
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Lillholm M, 2003, INT J COMPUT VISION, V52, P73, DOI 10.1023/A:1022995822531
   LILLHOLM M, 2008, LNSC, V4485, P394
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Nasrallah AJ, 2007, SPATIAL VISION, V20, P277, DOI 10.1163/156856807780421183
   Olmos AdrianaA., MCGILL CALIBRATED CO
   Olshausen BA, 1996, NETWORK-COMP NEURAL, V7, P333, DOI 10.1088/0954-898X/7/2/014
   PEDERSEN KS, 2004, P ECCV 04 WORKSH STA
   PEDERSEN KS, 2003, STAT NATURAL IMAGE G
   REISFELD D, 1992, P INT C PATT REC HAG, V1, P117
   Rhodes G, 2005, P ROY SOC B-BIOL SCI, V272, P1379, DOI 10.1098/rspb.2005.3093
   RUDERMAN DL, 1994, PHYS REV LETT, V73, P814, DOI 10.1103/PhysRevLett.73.814
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Sayood K, 2017, Introduction to data compression
   Schaffalitzky F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P636, DOI 10.1109/ICCV.2001.937686
   van Hateren JH, 1998, P ROY SOC B-BIOL SCI, V265, P359, DOI 10.1098/rspb.1998.0303
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Wagemans J, 1997, TRENDS COGN SCI, V1, P346, DOI 10.1016/S1364-6613(97)01105-4
   Witkin A.P., 1983, P INT JOINT C ART IN, P1019, DOI DOI 10.1007/978-3-8348-9190-729
   Wolf L, 2006, LECT NOTES COMPUT SC, V3952, P481
   Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1
   Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627
NR 60
TC 8
Z9 8
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 771
EP 781
DI 10.1016/j.imavis.2008.08.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000016
DA 2024-07-18
ER

PT J
AU de Croon, GCHE
   Sprinkhuizen-Kuyper, IG
   Postma, EO
AF de Croon, G. C. H. E.
   Sprinkhuizen-Kuyper, I. G.
   Postma, E. O.
TI Comparing active vision models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active vision; Probabilistic approach; Behavioural approach
ID OBJECT RECOGNITION
AB Active vision models can simplify visual tasks, provided that they can select sensible actions given incoming sensory inputs. Many active vision models have been proposed, but a comparative evaluation of these models is lacking. We present a comparison of active vision models from two different approaches. The "probabilistic approach" is an approach in which state estimation is the central goal. The "behavioural approach" is an approach that does not divide the vision process in a state estimation and an acting phase. We identify different types of models of the probabilistic approach, and introduce a model inspired on the behavioural approach. We describe these types of models in a common framework and evaluate their performances on a task of viewpoint selection for the classification of three-dimensional objects. The experimental results reveal how the performances of the active vision models relate to each other. For example, the behavioural model performs as good as the best model from the probabilistic approach. Overall, the experimental results reveal relations between the usefulness of active vision, the number of objects involved in the classification task, and the richness of the visual observations of the models. We conclude that research on active vision should aim at reaching a deeper understanding of these relations by applying active vision models to more complex and real-world tasks. (C) 2008 Elsevier B.V. All rights reserved.
C1 [de Croon, G. C. H. E.] Delft Univ Technol, Aerosp Engn Aerosp Software & Technol Inst, NL-2600 GB Delft, Netherlands.
   [Sprinkhuizen-Kuyper, I. G.] Radboud Univ Nijmegen, Nijmegen Inst Cognit & Informat, NL-6500 HE Nijmegen, Netherlands.
   [Postma, E. O.] Maastricht Univ, Fac Gen Sci, Dept Comp Sci, NL-6200 MD Maastricht, Netherlands.
C3 Delft University of Technology; Radboud University Nijmegen; Maastricht
   University
RP de Croon, GCHE (corresponding author), Delft Univ Technol, Aerosp Engn Aerosp Software & Technol Inst, POB 5058, NL-2600 GB Delft, Netherlands.
EM g.c.h.e.decroon@tudelft.nl; i.kuyper@nici.ru.nl; postma@micc.unimaas.nl
RI Sprinkhuizen-Kuyper, Ida/E-2829-2010; de Croon, Guido/AAG-5098-2020
OI Sprinkhuizen-Kuyper, Ida/0000-0003-0273-9354; de Croon,
   Guido/0000-0001-8265-1496
CR Aloimonos J., 1987, International Journal of Computer Vision, V1, P333, DOI 10.1007/BF00133571
   [Anonymous], 1995, Empirical methods for artificial intelligence
   Arbel T, 2001, IMAGE VISION COMPUT, V19, P779, DOI 10.1016/S0262-8856(00)00103-7
   Back T., 1996, EVOLUTIONARY ALGORIT
   BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4
   Beer RD, 2003, ADAPT BEHAV, V11, P209, DOI 10.1177/1059712303114001
   Borotschnig H, 1999, COMPUTING, V62, P293, DOI 10.1007/s006070050026
   Borotschnig H, 2000, IMAGE VISION COMPUT, V18, P715, DOI 10.1016/S0262-8856(99)00075-X
   Cover T., 1991, Wiley series in telecommunications, V1st
   de Croon G, 2006, PATTERN RECOGN LETT, V27, P1181, DOI 10.1016/j.patrec.2005.07.016
   Deinzer F, 2003, LECT NOTES COMPUT SC, V2756, P65
   Denzler J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P400
   Denzler J, 2002, IEEE T PATTERN ANAL, V24, P145, DOI 10.1109/34.982896
   DENZLER J, 2000, OPTIMAL SELECTION CA
   Deutsch B, 2004, LECT NOTES COMPUT SC, V3175, P359
   Floreano D, 2004, BIOL CYBERN, V90, P218, DOI 10.1007/s00422-004-0467-5
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Hornby GS, 2000, LECT NOTES COMPUT SC, V1801, P80
   Kröse BJA, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P2255, DOI 10.1109/ROBOT.1999.770441
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Nolfi S., 2002, International Journal of Robotics & Automation, V17, P163
   PALETTA L, 1998, P 6 S INT ROB SYST E
   Partridge M., 1998, Intelligent Data Analysis, V2
   Scheier C, 1998, NEURAL NETWORKS, V11, P1551, DOI 10.1016/S0893-6080(98)00084-7
   Schiele B, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P249, DOI 10.1109/ICCV.1998.710726
   Schiele B, 1997, ROBOT AUTON SYST, V21, P95, DOI 10.1016/S0921-8890(97)00009-2
   Spier E, 2004, Artificial Life IX, P133
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Suzuki M, 2006, INTELLIGENT AUTONOMOUS SYSTEMS 9, P153
   van Dartel M, 2005, ADAPT BEHAV, V13, P227, DOI 10.1177/105971230501300304
NR 30
TC 11
Z9 14
U1 5
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 374
EP 384
DI 10.1016/j.imavis.2008.06.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600007
DA 2024-07-18
ER

PT J
AU He, Y
   Yap, KH
   Chen, L
   Chau, LP
AF He, Yu
   Yap, Kim-Hui
   Chen, Li
   Chau, Lap-Pui
TI A soft MAP framework for blind super-resolution image reconstruction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Super-resolution; Blur identification; Maximum a posteriori estimation;
   Conjugate gradient optimization
ID HIGH-RESOLUTION IMAGE; RESTORATION; ALGORITHM; NOISY
AB This paper proposes a new algorithm to address blind image super-resolution (SR) by fusing multiple low-resolution (LR) blurred images to render a high-resolution (HR) image. Conventional SR image reconstruction algorithms assume the blurring occurred during the image formation process to be either negligible or can be characterized fully a priori. This assumption, however, is impractical as it is often difficult to eliminate the blurring completely in some applications or to know the blurring function completely a priori. In view of this, we present a new soft maximum a posteriori (MAP) estimation framework to perform joint blur identification and HR image reconstruction. The proposed method incorporates a soft blur prior that estimates the relevance of the best-fit parametric blur model, and induces reinforcement learning towards it. An iterative scheme based on alternating minimization is developed to estimate the blur and the HR image progressively. Experimental results show that the new method is effective in performing blind SIR image reconstruction where there is limited information about the blurring function. (C) 2008 Elsevier B.V. All rights reserved.
C1 [He, Yu; Yap, Kim-Hui; Chau, Lap-Pui] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   [Chen, Li] Wuhan Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430081, Peoples R China.
C3 Nanyang Technological University; Wuhan University of Science &
   Technology
RP Yap, KH (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Nanyang Ave, Singapore 639798, Singapore.
EM yuhechina@pmail.ntu.edu.sg; ekhyap@ntu.edu.sg; chenli@ieee.org;
   elpchau@ntu.eclu.sg
RI Yap, Kim-Hui/A-5157-2011; Chau, Lap-Pui/A-5149-2011; xuan,
   bo/H-4351-2011
OI Yap, Kim-Hui/0000-0003-1933-4986; Chau, Lap-Pui/0000-0003-4932-0593; 
CR Andrews H.C., 1977, DIGITAL IMAGE RESTOR
   [Anonymous], LAB IMAGE SIGNAL ANA
   Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   BARRETT E, 2007, P SPIE C UNCONVENTIO, V3
   Bégin I, 2004, INT C PATT RECOG, P85, DOI 10.1109/ICPR.2004.1334046
   Chan TF, 1998, IEEE T IMAGE PROCESS, V7, P370, DOI 10.1109/83.661187
   El-Khamy SE, 2005, OPT ENG, V44, DOI 10.1117/1.2042947
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953
   Forsythe G.E., 1976, COMPUTER METHODS MAT
   He H, 2006, IEEE T IMAGE PROCESS, V15, P592, DOI 10.1109/TIP.2005.860599
   He H, 2004, J ELECTRON IMAGING, V13, P586, DOI 10.1117/1.1762889
   HE H, 2005, P IEEE INT C IM PROC, P329
   Huang H, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5071
   Huang T.S., 1984, ADV COMPUTER VISION, V1, P317
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   KIM SP, 1990, IEEE T ACOUST SPEECH, V38, P1013, DOI 10.1109/29.56062
   Lee ES, 2003, IEEE T IMAGE PROCESS, V12, P826, DOI 10.1109/TIP.2003.811488
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P1299, DOI 10.1109/83.941854
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   Nguyen N, 2000, CIRC SYST SIGNAL PR, V19, P321, DOI 10.1007/BF01200891
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Rajan D, 2002, J MATH IMAGING VIS, V16, P5, DOI 10.1023/A:1013961817285
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   Sroubek F, 2005, IEEE T IMAGE PROCESS, V14, P874, DOI 10.1109/TIP.2005.849322
   Sroubek F, 2003, IEEE T IMAGE PROCESS, V12, P1094, DOI 10.1109/TIP.2003.815260
   TOM BC, 1994, IEEE IMAGE PROC, P553, DOI 10.1109/ICIP.1994.413745
   TOM BC, 1994, P SPIE C VIS COMM IM
   TOM BC, 1994, P SPIE C APPL DIGITA, V17, P316
   Vandewalle P, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/71459
   Wang Y., 2002, VIDEO PROCESSING COM
   Zalevsky Z., 2004, OPTICAL SUPERRESOLUT
NR 34
TC 65
Z9 73
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 364
EP 373
DI 10.1016/j.imavis.2008.05.010
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600006
DA 2024-07-18
ER

PT J
AU Lévesque, D
   Deschênes, F
AF Levesque, D.
   Deschenes, F.
TI Novel depth cues from light scattering
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Light scattering; 3D structure; Occlusion; Weather degraded image
ID ATMOSPHERE; VISION
AB The scattering of light by particles present in the medium through which it is travelling gives clues allowing us to infer structural information about the observed scene. Based on a single-scattering model of light, we review related work and propose a novel method for computing the 3D structure of a scene from two images captured in different conditions of visibility. We also present two new methods for identifying occlusion edges from the same images. The originality of the proposed methods is based on the study of spatial variations of intensity, particularly how they are affected by a change in visibility conditions, while existing methods rely on intensities. We validate our work with experimental results produced from both synthetic and real scenes. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Levesque, D.; Deschenes, F.] Univ Sherbrooke, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada.
C3 University of Sherbrooke
RP Deschênes, F (corresponding author), Univ Sherbrooke, Dept Informat, Sherbrooke, PQ J1K 2R1, Canada.
EM daniel.p.levesque@usherbrooke.ca; francois.deschenes@usherbrooke.ca
CR [Anonymous], 1952, VISION ATMOSPHERE
   [Anonymous], 1729, Essai d'optique sur la gradation de la lumiere. chez Claude Jombert, rue S. Jacques
   [Anonymous], 1976, OPTICS ATMOSPHERE
   [Anonymous], 1999, P 7 IEEE INT C COMP
   Auclair Fortier M.-F., 1999, Proceedings Vision Interface '99, P1
   Cozman F, 1997, PROC CVPR IEEE, P801, DOI 10.1109/CVPR.1997.609419
   DREWNIOK C, 1994, INT J REMOTE SENS, V15, P3743, DOI 10.1080/01431169408954356
   DUNTLEY SQ, 1948, J OPT SOC AM, V38, P179, DOI 10.1364/JOSA.38.000179
   ELMEJDANI S, 2005, P CIRO 05 14 C INT R, P133
   KLASSEN RV, 1987, ACM T GRAPHIC, V6, P215, DOI 10.1145/35068.35071
   LEVESQUE D, 2005, THESIS U SHERBROOKE
   MIDDLETON WEK, 1960, J OPT SOC AM, V50, P97, DOI 10.1364/JOSA.50.000097
   Narasimhan SG, 2003, IEEE T PATTERN ANAL, V25, P713, DOI 10.1109/TPAMI.2003.1201821
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   NARASIMHAN SG, 2000, P IEEE INT C COMP VI
   NARASIMHAN SG, 2001, P IEEE INT C COMP VI
   Nishita T., 1998, Rendering Techniques '98. Proceedings of the Eurographics Workshop, P1
   PEREZ F, 1997, P 8 EUR WORKSH REND, P309
   Preetham AJ, 1999, COMP GRAPH, P91, DOI 10.1145/311535.311545
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Schechner Y., 2001, P IEEE INT C COMP VI
   Schechner YY, 2003, APPL OPTICS, V42, P511, DOI 10.1364/AO.42.000511
   SHAFER SA, 1985, COLOR RES APPL, V10, P210, DOI 10.1002/col.5080100409
   SHI H, 1994, COMPUT IND, V25, P15, DOI 10.1016/0166-3615(94)90029-9
   STOCKHAM TG, 1972, PR INST ELECTR ELECT, V60, P828, DOI 10.1109/PROC.1972.8782
NR 25
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 19
EP 36
DI 10.1016/j.imavis.2006.10.012
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700004
DA 2024-07-18
ER

PT J
AU Ge, SS
   Yang, Y
   Lee, TH
AF Ge, S. S.
   Yang, Y.
   Lee, T. H.
TI Hand gesture recognition and tracking based on distributed locally
   linear embedding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gesture recognition and tracking; Distributed locally linear embedding
   (DLLE); Probabilistic neural network (PNN); Hand recognition; Gesture
   tracking
AB In this paper, we present a computer vision system for human gesture recognition and tracking based on a new nonlinear dimensionality reduction method. Due to the variation of posture appearance, the recognition and tracking of human hand gestures from one single camera remain a difficult problem. We present an unsupervised learning algorithm, distributed locally linear embedding (DLLE), to discover the intrinsic structure of the data, such as neighborhood relationships information. After the embedding of input images are represented in a lower dimensional space, probabilistic neural network (PNN) is employed and a database is set up for static gesture classification. For dynamic gesture tracking, the similarity among the images sequence are utilized. Hand gesture motion can be tracked and dynamically reconstructed according to the image's relative position in the corresponding motion database. The method is robust against the input sequence frames and bad image qualities. Experimental results show that our approach is able to successfully separate different hand postures and track the dynamic gesture. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Ge, S. S.] Natl Univ Singapore, Social Robot Lab, Interact Digital Media Inst, Singapore 117576, Singapore.
   Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
C3 National University of Singapore; National University of Singapore
RP Ge, SS (corresponding author), Natl Univ Singapore, Social Robot Lab, Interact Digital Media Inst, Singapore 117576, Singapore.
EM samge@nus.edu.sg
OI Ge, Shuzhi Sam/0000-0001-5549-312X
CR [Anonymous], 1995, ACM T COMPUT-HUM INT, DOI DOI 10.1145/212430.212431
   ATHITSOS V, 2004, P IEEE C COMP VIS PA
   Bengio Y, 2003, J MACH LEARN RES, V3, P1137, DOI 10.1162/153244303322533223
   BLACK MJ, 1996, P EUR C COMP VIS, V1, P329
   CACOULLOS T, 1966, ANN I STAT MATH TOKY, P18
   Chua CS, 2002, IMAGE VISION COMPUT, V20, P191, DOI 10.1016/S0262-8856(01)00094-4
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Darrell TJ, 1996, IEEE T PATTERN ANAL, V18, P1236, DOI 10.1109/34.546259
   Fels S., 1995, P 1995 P SIGCHI C HU, P456
   Ge SS, 2006, IEEE INT CONF ROBOT, P3399
   GUPTA N, 2002, IEEE J RES, P237
   KUCH JJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P666, DOI 10.1109/ICCV.1995.466875
   LEE J, 1994, MODELS TECHNIQUES CO, P110
   LEE JT, 1995, IEEE COMPUT GRAPH, V15, P77, DOI 10.1109/38.403831
   Lin J, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P121, DOI 10.1109/HUMO.2000.897381
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Raghu PP, 1998, IEEE T NEURAL NETWOR, V9, P516, DOI 10.1109/72.668893
   Ramamoorthy A, 2003, PATTERN RECOGN, V36, P2069, DOI 10.1016/S0031-3203(03)00042-6
   REHG JM, 1994, P EUR C COMP VIS, V2, P35
   RIJPKEMA H, 1991, COMP GRAPH, V25, P339, DOI 10.1145/127719.122754
   Roweis SamT., 2003, J MACHINE LEARNING R, V4, P119
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   SPECHT DF, 1990, NEURAL NETWORKS, V3, P109, DOI 10.1016/0893-6080(90)90049-Q
   STURMAN DJ, 1994, IEEE COMPUT GRAPH, V14, P30, DOI 10.1109/38.250916
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wu Y, 1999, LECT NOTES ARTIF INT, V1739, P103
   Zhang BL, 2004, IEEE T NEURAL NETWOR, V15, P166, DOI 10.1109/TNN.2003.820673
NR 30
TC 57
Z9 67
U1 1
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1607
EP 1620
DI 10.1016/j.imavis.2008.03.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500005
DA 2024-07-18
ER

PT J
AU Zhong, H
   Hung, YS
AF Zhong, H.
   Hung, Y. S.
TI Multi-stage 3D reconstruction under circular motion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multi-stage reconstruction; circular motion; circular projective
   reconstruction
ID GEOMETRY
AB In this paper, we propose a new method for 3D reconstruction from an image sequence captured by a camera with constant intrinsic parameters undergoing circular motion. We introduce a method, called circular projective reconstruction, for enforcing the circular constraint in a factorization-based projective reconstruction. To deal with the missing data problem, our method uses a multi-stage approach to reconstructing the objects and cameras, which first computes a circular projective reconstruction of a sub-sequence and then extends the reconstruction to the complete sequence. Camera matrix, rotation angles, and 3D structure are computed iteratively in a way that the 2D reprojection error is minimized. The algorithm is evaluated using real image sequences. (c) 2007 Elsevier B.V. All rights reserved.
C1 Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Zhong, H (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
EM hzhong@eee.hku.hk; yshung@eee.hku.hk
RI Hung, Yeung Sam/C-1852-2009
CR [Anonymous], EUR C COMP VIS
   ARMSTRONG M, 1996, SELF CALIBRATION IMA, P3
   Boyer E., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P109
   Fitzgibbon A., 1998, LECT NOTES COMPUTER, V1506, P155
   Han M, 2003, IEEE T PATTERN ANAL, V25, P884, DOI 10.1109/TPAMI.2003.1206517
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Jiang G, 2004, IEEE T PATTERN ANAL, V26, P721, DOI 10.1109/TPAMI.2004.4
   Jiang G, 2002, LECT NOTES COMPUT SC, V2350, P537
   JIANG G, 2001, CVPR, V1, P293
   Liu Y, 2000, INT C PATT RECOG, P865, DOI 10.1109/ICPR.2000.903680
   Mendonça PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461
   MENDONCA PRS, 1999, CVPR, P9
   NIEM W, 1994, WORKSH COMP SER
   SLLIVAN S, 1998, PAMI, V20, P1091
   TANG WK, 2002, DAGM, P387
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   TRIGGS B, 1995, P IEEE C COMP VIS PA, P845
   Wong KYK, 2002, IMAGE VISION COMPUT, V20, P441, DOI 10.1016/S0262-8856(02)00015-X
   ZHONG H, 2003, M2VIP, P239
NR 19
TC 2
Z9 2
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1814
EP 1823
DI 10.1016/j.imavis.2007.04.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900010
DA 2024-07-18
ER

PT J
AU Han, J
   Ma, KK
AF Han, Ju
   Ma, Kai-Kuang
TI Rotation-invariant and scale-invariant Gabor features for texture image
   retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE content-based image retrieval; texture analysis; Gabor filter;
   rotation-invariant; scale-invariant; Brodatz; MPEG-7; metadata; data
   mining
ID SPATIAL-FREQUENCY; CLASSIFICATION
AB Conventional Gabor representation and its extracted features often yield a fairly poor performance in retrieving the rotated and scaled versions of the texture image under query. To address this issue, existing methods exploit multiple stages of transformations for making rotation and/or scaling being invariant at the expense of high computational complexity and degraded retrieval performance. The latter is mainly due to the lost of image details after multiple transformations. In this paper, a rotation-invariant and a scale-invariant Gabor representations are proposed, where each representation only requires few summations on the conventional Gabor filter impulse responses. The optimum setting of the orientation parameter and scale parameter is experimentally determined over the Brodatz and MPEG-7 texture databases. Features are then extracted from these new representations for conducting rotation-invariant or scale-invariant texture image retrieval. Since the dimension of the new feature space is much reduced, this leads to a much smaller metadata storage space and faster on-line computation on the similarity measurement. Simulation results clearly show that our proposed invariant Gabor representations and their extracted invariant features significantly outperform the conventional Gabor representation approach for rotation-invariant and scale-invariant texture image retrieval. (C) 2007 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Ma, KK (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM ekkma@ntu.edu.sg
RI Ma, Kai-Kuang/A-5148-2011; Ma, Kai-Kuang/KBA-9411-2024
CR [Anonymous], 1999, Visual Information Retrieval
   BECK J, 1987, COMPUT VISION GRAPH, V37, P299, DOI 10.1016/S0734-189X(87)80006-3
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   CLARK M, 1987, PATTERN RECOGN LETT, V6, P261, DOI 10.1016/0167-8655(87)90086-9
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   FOGEL I, 1989, BIOL CYBERN, V61, P103, DOI 10.1007/BF00204594
   Gravano L., 1994, Proceedings of the Third International Conference on Parallel and Distributed Information Systems (Cat. No.94TH0668-4), P103, DOI 10.1109/PDIS.1994.331726
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kruizinga P, 1999, IEEE T IMAGE PROCESS, V8, P1395, DOI 10.1109/83.791965
   Liu F, 1996, IEEE T PATTERN ANAL, V18, P722, DOI 10.1109/34.506794
   LOURENS T, 1994, FUTURE GENER COMP SY, V10, P351, DOI 10.1016/0167-739X(94)90042-6
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   NYSTUEN JA, 1992, IEEE T GEOSCI REMOTE, V30, P502, DOI 10.1109/36.142928
   SMITH JR, 1994, IEEE IMAGE PROC, P407, DOI 10.1109/ICIP.1994.413817
   TAN TN, 1995, PATTERN RECOGN, V28, P1283, DOI 10.1016/0031-3203(94)00017-G
   TURNER MR, 1986, BIOL CYBERN, V55, P71
   Van de Wouwer G, 1999, IEEE T IMAGE PROCESS, V8, P592, DOI 10.1109/83.753747
   Weldon TP, 1996, OPT ENG, V35, P2852, DOI 10.1117/1.600971
NR 23
TC 208
Z9 224
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1474
EP 1481
DI 10.1016/j.imavis.2006.12.015
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000008
DA 2024-07-18
ER

PT J
AU Oral, M
   Deniz, U
AF Oral, Mustafa
   Deniz, Umut
TI Centre of mass model - A novel approach to background modelling for
   segmentation of moving objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE centre of mass; image modelling; motion segmentation; background
   subtracting
ID TRACKING
AB This paper describes a novel method, centre of mass model, to detect moving objects in a dynamic scene based on background subtraction. Any displacement of the position of centre of mass (CoMs) in two consecutive frames is the indicator of a moving object in a scene. Dividing a scene into subregions and modelling them as individual masses allow segmentation of the moving object(s). In the proposed scheme, an image is divided into blocks that are called super-pixels and each super-pixel is represented with the x and y components of CoM of a block. The segmentation is achieved by taking the absolute difference between CoM of current super-pixel and the mean of CoMs of previous corresponding super-pixels, and thresholding the difference with a dynamically updated value. A comparative work has been carried out to evaluate the performance of the proposed model and the previously reported seven different methods. The model produced consistent outputs for the images taken in different environmental conditions. The moving objects were successfully segmented with no post-processing operations. Centre of mass model demonstrated better overall performance than the methods previously reported. Its output was superior for auto-focused video images. (c) 2007 Published by Elsevier B.V.
C1 Mustafa Kemal Univ, Fac Engn & Architecture, Dept Elect & Elect, TR-31024 Antakya, Hatay, Turkey.
C3 Mustafa Kemal University
RP Oral, M (corresponding author), Mustafa Kemal Univ, Fac Engn & Architecture, Dept Elect & Elect, Tayfur Sokmen Campus, TR-31024 Antakya, Hatay, Turkey.
EM mustafaoral@yahoo.com
RI Oral, Mustafa/J-1165-2018
OI Oral, Mustafa/0000-0001-9127-8857
CR Boult TE, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P48
   Cutler R, 1998, INT C PATT RECOG, P495, DOI 10.1109/ICPR.1998.711189
   Farid Hany., 2011, FUNDAMENTALS IMAGE P
   Gonzales R., 1992, DIGITAL IMAGE PROCES
   HARITAOGLU I, 2000, INT C AUT FAC GEST R, P222
   Heikkilä J, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P74, DOI 10.1109/VS.1999.780271
   Herrero-Jaraba E, 2003, PATTERN RECOGN LETT, V24, P2079, DOI 10.1016/S0167-8655(03)00045-X
   JAIN RC, 1995, INTRO MACHINE VISION
   KALVIAINEN H, 1991, P 7 SCAND C IM AN, P72
   Li XB, 2002, PATTERN RECOGN, V35, P967, DOI 10.1016/S0031-3203(01)00079-6
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   MERKLINGER HM, 2002, INS OUT FOCUS ALTERN
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Toyama K., 1999, The Proceedings of the Seventh IEEE International Conference on Computer Vision, V1, P255
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   YANG YH, 1992, MACH VISION APPL, V5, P17
NR 18
TC 29
Z9 35
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1365
EP 1376
DI 10.1016/j.imavis.2006.10.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000016
DA 2024-07-18
ER

PT J
AU Geys, I
   Van Gool, L
AF Geys, Indra
   Van Gool, Luc
TI View synthesis by the parallel use of GPU and CPU
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE view synthesis; multi-camera; graphical board; depth map; graph-cut
AB We present an algorithm for efficient depth calculations and view synthesis. The main goal is the on-line generation of realistic interpolated views of a dynamic scene. The inputs are video-streams originating from two or more calibrated, static cameras.
   Efficiency is accomplished by the parallel use of the CPU and the GPU in a multi-threaded implementation. The input images are projected on a plane sweeping through 3D space, using the hardware accelerated transformations available on the GPU. A correlation measure is calculated simultaneously for all pixels on the plane and is compared at the different plane positions. A noisy 'virtual' view and a crude depth map result in very limited time. We apply a min-cut/max-flow algorithm on a graph, implemented on the CPU, to ameliorate this result by a global optimisation. (C) 2007 Published by Elsevier B.V.
C1 Katholieke Univ Leuven, ESAT, EPSI, VISICS, B-3001 Heverlee, Belgium.
   ETH, Swiss Fed Inst Technol, BIWI, CH-8092 Zurich, Switzerland.
C3 KU Leuven; Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Geys, I (corresponding author), Katholieke Univ Leuven, ESAT, EPSI, VISICS, Kasteelpk Arenberg 10, B-3001 Heverlee, Belgium.
EM igeys@esat.kuleuven.be
CR [Anonymous], EUR REND WORKSH
   Ansar A, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P455, DOI 10.1109/TDPVT.2004.1335273
   Baker S, 1998, PROC CVPR IEEE, P434, DOI 10.1109/CVPR.1998.698642
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   CHEN SE, 1993, SIGGRAPH 93, P279
   Criminisi A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P191
   Di Stefano L, 2002, REAL-TIME IMAGING, V8, P439, DOI 10.1006/rtim.2002.0299
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   LHUILLIER M, 1999, CVPR 99, P2139
   Matusik W, 2001, SPRING EUROGRAP, P115
   Matusik W, 2000, COMP GRAPH, P369, DOI 10.1145/344779.344951
   MESTER R, 2001, DAGM, P170
   SCHIRMACHER H, 2001, P EUR 2001, V20, pC165
   Schmidt J, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P225, DOI 10.1109/ACV.2002.1182186
   SEITZ SM, 1996, SIGGRAPH, P21
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   WERNER T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P957, DOI 10.1109/ICCV.1995.466831
   Yang RG, 2003, PROC CVPR IEEE, P211, DOI 10.1109/ISCS.2003.1239980
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 21
TC 5
Z9 8
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1154
EP 1164
DI 10.1016/j.imavis.2006.07.023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300012
DA 2024-07-18
ER

PT J
AU Chang, H
   Yeung, DY
AF Chang, Hong
   Yeung, Dit-Yan
TI Kernel-based distance metric learning for content-based image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE metric learning; kernel method; content-based image retrieval; relevance
   feedback
ID RELEVANCE FEEDBACK
AB For a specific set of features chosen for representing images, the performance of a content-based image retrieval (CBIR) system depends critically on the similarity or dissimilarity measure used. Instead of manually choosing a distance function in advance, a more promising approach is to learn a good distance function from data automatically. In this paper, we propose a kernel approach to improve the retrieval performance of CBIR systems by learning a distance metric based on pairwise constraints between images as supervisory information. Unlike most existing metric learning methods which learn a Mahalanobis metric corresponding to performing linear transformation in the original image space, we define the transformation in the kernel-induced feature space which is nonlinearly related to the image space. Experiments performed on two real-world image databases show that our method not only improves the retrieval performance of Euclidean distance without distance learning, but it also outperforms other distance learning methods significantly due to its higher flexibility in metric learning. (c) 2006 Elsevier B.V. All rights reserved.
C1 Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Yeung, DY (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Clear Water Bay, Kowloon, Hong Kong, Peoples R China.
EM hongch@cs.ust.hk; dyyeung@cs.ust.hk
CR [Anonymous], 2002, ADV NEURAL INF PROCE
   [Anonymous], 2001, P 18 INT C MACH LEAR
   [Anonymous], 1995, STORAGE RETRIEVAL IM, DOI DOI 10.1117/12.205308
   DONG A, 2003, P CVPR, V2, P662
   Doulamis A., 2003, INT J IMAGE GRAPHICS, V3, P171
   Guo GD, 2002, IEEE T NEURAL NETWOR, V13, P811, DOI 10.1109/TNN.2002.1021882
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   He X., 2004, MULTIMEDIA '04, P2
   He XF, 2003, IEEE T CIRC SYST VID, V13, P39, DOI 10.1109/TCSVT.2002.808087
   He Xiaofei., 2004, ACM MULTIMEDIA, P17
   Heisterkamp DR, 2001, PROC CVPR IEEE, P388
   Hertz T, 2004, PROC CVPR IEEE, P570
   HERTZ T, 2003, P IEEE COMP SOC C CO, V2, P668
   Hertz Tomer., 2004, International Conference on Machine Learning (ICML), P393
   HERTZ Uri, 2003, Fragmentos, V25, P11
   Hoi C.-H., 2004, PROC 12 ANN ACM INT, P24
   Ishikawa Y., 1998, P 24 VLDB C
   Pass G., 1996, P 4 ACM INT C MULT, V96, P65, DOI DOI 10.1145/244130.244148
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TAO D, 2004, P IEEE INT C COMP VI, V2, P647
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Yang J, 2004, INT J COMPUT VISION, V56, P47, DOI 10.1023/B:VISI.0000004836.59343.e9
   Zhou XS, 2001, PROC CVPR IEEE, P11
NR 27
TC 35
Z9 40
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 695
EP 703
DI 10.1016/j.imavis.2006.05.013
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Heric, D
   Zazula, D
AF Heric, Dusan
   Zazula, Damjan
TI Combined edge detection using wavelet transform and signal registration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE edge model; edge detection; wavelet transform; signal registration
AB This paper presents a novel edge detection algorithm, using Haar wavelet transform and signal registration. The proposed algorithm has two stages: (a) adaptive edge detection with the maximum entropy thresholding technique on time-scale plane and (b) edge linkage into a contour line with signal registration in order to close edge discontinuities and calculate a confidence index for contour linkages. This index measures the level of confidence in the linkage of two adjacent points in the contour structure. Experimenting with synthetic images, we found out the lower level of confidence can be set to approximately e(-2). The method was tested on 200 synthetic images at different signal-to-noise ratios (SNRs) and 11 clinical images. We assessed its reliability, accuracy and robustness using the mean absolute distance (MAD) metric and our confidence index. The results for MAD on synthetic images yield the mean of 0.7 points and standard deviation (std) of 0.14, while the mean confidence level is 0.48 with std of 0.19 (the values are averaged over SNRs from 3 to 50 dB each in 20 Monte-Carlo runs). Our assessment on clinical images, where the references were expert's annotations, give MAD equal 1.36 +/- 0.36 (mean std) and confidence level equal 0.67 +/- 0.25 (mean std). (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Maribor, Fac Elect Engn & Comp Sci, SLO-2000 Maribor, Slovenia.
C3 University of Maribor
RP Heric, D (corresponding author), Univ Maribor, Fac Elect Engn & Comp Sci, Smetanova 17, SLO-2000 Maribor, Slovenia.
EM dusan.heric@uni-mb.si; damjan.zazula@uni-mb.si
RI Zazula, Damjan/A-5154-2008
CR [Anonymous], 2001, Medical image registration
   Bankman I., 2000, Handbook of medical imaging: processing and analysis
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Castleman K. R., 1996, Digital Image Processing
   DAGRAAF CN, 1988, INFORM PROCESSING ME
   HERIC D, 2005, VIIP2005
   Heric D, 2004, P 6 NORD SIGN PROC S
   HERIC D, 2004, ERK2004
   Horn B.K.P, 1986, Robot Vision
   Laptev I, 2000, MACH VISION APPL, V12, P23, DOI 10.1007/s001380050121
   Li J., 2003, THESIS S HOUSTON STA
   Liang Z. P., 1999, PRINCIPLES MAGNETIC
   LU J, 1994, P SOC PHOTO-OPT INS, P711
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   Mikic I, 1998, IEEE T MED IMAGING, V17, P274, DOI 10.1109/42.700739
   Modersitzki J., 2004, NUMER MATH SCI COMP
   Niblack W., 1986, An Introduction to Digital Image Processing
   O'Callaghan RJ, 2005, IEEE T IMAGE PROCESS, V14, P49, DOI 10.1109/TIP.2004.838695
   Periaswamy S, 2003, IEEE T MED IMAGING, V22, P865, DOI 10.1109/TMI.2003.815069
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Perona P, 1989, IEEE T PATTERN ANAL, P629
   ROSENFELD A, 1994, DIGITAL PICTURE PROC
   Russ J.C., 1994, IMAGE PROCESSING HDB, V2nd
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Sonka M., 1993, IMAGE PROCESSING ANA
   VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938
NR 31
TC 32
Z9 37
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 652
EP 662
DI 10.1016/j.imavis.2006.05.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200011
DA 2024-07-18
ER

PT J
AU Shen, L
   Bai, L
   Fairhurst, M
AF Shen, LinLin
   Bai, Li
   Fairhurst, Michael
TI Gabor wavelets and General Discriminant Analysis for face identification
   and verification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face identification; face verification; Gabor wavelets; General
   Discriminant Analysis
ID SUPPORT VECTOR MACHINES; RECOGNITION; PCA; EIGENFACES
AB A novel and uniform framework for both face identification and verification is presented in this paper. The framework is based on a combination of Gabor wavelets and General Discriminant Analysis, and can be considered appearance based in that features are extracted from the whole face image. The feature vectors are then subjected to subspace projection. The design of Gabor filters for facial feature extraction is also discussed, which is seldom reported in the literature. The method has been tested extensively for both identification and verification applications. The FERET and BANCA face databases were used to generate the results. Experiments show that Gabor wavelets can significantly improve system performance whilst General Discriminant Analysis outperforms other subspace projection methods such as Principal Component Analysis, Linear Discriminant Analysis, and Kernel Principal Component Analysis. Our method has achieved 97.5% recognition rate on the FERET database, and 5.96% verification error rate on the BANCA database. This is a significantly better performance than that attainable with other popular approaches reported in the literature. In particular, our verification system performed better than most of the systems in the 2004 International Face Verification Competition, using the BANCA face database and specially designed test protocols. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Nottingham, Sch Comp Sci & IT, Nottingham NG7 2RD, England.
   Univ Kent, Dept Elect, Canterbury CT2 7NZ, Kent, England.
C3 University of Nottingham; University of Kent
RP Shen, L (corresponding author), Univ Nottingham, Sch Comp Sci & IT, Nottingham NG7 2RD, England.
EM lls@cs.nott.ac.uk; bai@cs.nott.ac.uk; m.c.fairhurst@kent.ac.uk
RI Shen, Linlin/B-1968-2009; Shen, Linlin/AEX-9392-2022
OI Shen, Linlin/0000-0003-1420-0815
CR [Anonymous], 2000, GEN THEORY
   Bai L., 2003, Proc. Of the 23rd Artificial Intelligence Conference, P227
   Bailly-Bailliére E, 2003, LECT NOTES COMPUT SC, V2688, P625
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BEVERIDGE JR, 2001, P IEEE INT C COMP VI
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Er MJ, 2002, IEEE T NEURAL NETWOR, V13, P697, DOI 10.1109/TNN.2002.1000134
   Fukunnaga K., 1991, INTRO STAT PATTERN R, Vsecond
   Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Jonsson K, 2002, IMAGE VISION COMPUT, V20, P369, DOI 10.1016/S0262-8856(02)00009-4
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Lee CJ, 1999, ELECTRON LETT, V35, P288, DOI 10.1049/el:19990213
   Liu CJ, 1998, INT C PATT RECOG, P1368, DOI 10.1109/ICPR.1998.711956
   Liu CJ, 2004, IEEE T PATTERN ANAL, V26, P572, DOI 10.1109/TPAMI.2004.1273927
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu QS, 2003, J COMPUT SCI TECH-CH, V18, P788, DOI 10.1007/BF02945468
   Lu JW, 2003, PATTERN RECOGN LETT, V24, P3079, DOI 10.1016/S0167-8655(03)00167-3
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Messer K, 2004, INT C PATT RECOG, P523, DOI 10.1109/ICPR.2004.1333826
   Nefian AV, 1999, INT CONF ACOUST SPEE, P3553, DOI 10.1109/ICASSP.1999.757610
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1999, ADV NEUR IN, V11, P803
   Schölkopf B, 1999, IEEE T NEURAL NETWOR, V10, P1000, DOI 10.1109/72.788641
   Shen LL, 2006, PATTERN RECOGN LETT, V27, P1758, DOI 10.1016/j.patrec.2006.02.005
   Shen LL, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/30274
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Weldon TP, 1996, PATTERN RECOGN, V29, P2005, DOI 10.1016/S0031-3203(96)00047-7
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   Yang P, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P356
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
NR 36
TC 172
Z9 201
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 553
EP 563
DI 10.1016/j.imavis.2006.05.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200004
DA 2024-07-18
ER

PT J
AU Moreno-Noguer, F
   Sanfeliu, A
   Samaras, D
AF Moreno-Noguer, Francesc
   Sanfeliu, Alberto
   Samaras, Dimitris
TI Integration of deformable contours and a multiple hypotheses Fisher
   color model for robust tracking in varying illuminant environments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE tracking; deformable contours; color adaption; particle filters
ID SNAKES
AB In this paper, we propose a new technique to perform figure-ground segmentation in image sequences of moving objects under varying illumination conditions. Unlike most of the algorithms that adapt color, there is not the assumption of smooth change of the viewing conditions. To cope with this, we propose the use of a new colorspace that maximizes the foreground/background class separability based on the 'Linear Discriminant Analysis' method. Moreover, we introduce a technique that formulates multiple hypotheses about the next state of the color distribution (some of these hypotheses take into account small and gradual changes in the color model and others consider more abrupt and unexpected variations) and the hypothesis that generates the best object segmentation is used to remove noisy edges from the image. This simplifies considerably the final step of fitting a deformable contour to the object boundary, thus allowing a standard snake formulation to successfully. track non-rigid contours. In the same manner, the contour estimate is used to correct the color model. The integration of color and shape is done in a stage called 'sample concentration', introduced as a final step to the well-known CONDENSATION algorithm (c) 2006 Elsevier B.V. All rights reserved.
C1 CSIC, Inst Robot & Informat Ind, UPC, E-08028 Barcelona, Spain.
   SUNY Stony Brook, Dept Comp Sci, Stony Brook, NY 11794 USA.
C3 Universitat Politecnica de Catalunya; Consejo Superior de
   Investigaciones Cientificas (CSIC); CSIC - Institut de Robotica i
   Informatica Industrial (IRII); State University of New York (SUNY)
   System; State University of New York (SUNY) Stony Brook
RP Moreno-Noguer, F (corresponding author), CSIC, Inst Robot & Informat Ind, UPC, Llorens & Artigas 4-6, E-08028 Barcelona, Spain.
EM fmoreno@iri.upc.edu; asanfeliu@iri.upc.es; samaras@cs.sunysb.edu
RI ; Moreno-Noguer, Francesc/G-3915-2014
OI Sanfeliu, Alberto/0000-0003-3868-9678; Moreno-Noguer,
   Francesc/0000-0002-8640-684X
CR Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Blake A., 1998, ACTIVE CONTOURS
   DADA RO, 1973, PATTERN RECOGNITION
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   FINLAYSON GD, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P720, DOI 10.1109/ICCV.1995.466867
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   ISARD M, 1996, P ECCV, P893
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   Moreno-Noguer F, 2003, LECT NOTES COMPUT SC, V2652, P580
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   RAJA Y, 2000, P ECCV, V1, P460
   Sigal L, 2000, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2000.854764
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yang J., 1998, Proc. ACCV'98, VII, P687
NR 15
TC 13
Z9 13
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 285
EP 296
DI 10.1016/j.imavis.2005.10.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Antoniol, G
   Ceccarelli, M
AF Antoniol, Giuliano
   Ceccarelli, Michele
TI Microarray image gridding with stochastic search based approaches
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE Markov random fields; gridding; genetic algorithm; microarray
AB The paper reports a novel approach for the problem of automatic gridding in Microarray images. Such problem often requires human intervention; therefore. the development of automated procedures is a fundamental issue for large-scale functional genomic experiments involving many microarray images. Our method uses a two-step process. First a regular rectangular grid is superimposed on the image by interpolating a set of guide spots, this is done by solving a non-linear optimization process with a stochastic search producing the best interpolating grid parameterized by a six values vector. Second, the interpolating grid is adapted, with a Markov Chain Monte Carlo method, to local deformations. This is done by modeling the solution a Markov random field with a Gibbs prior possibly containing first order cliques (1-clique). The algorithm is completely automatic and no human intervention is required, it efficiently accounts arbitrary grid rotations, irregularities and various spot sizes. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Sannio, RCOST, I-82100 Benevento, Italy.
C3 University of Sannio
RP Ceccarelli, M (corresponding author), Univ Sannio, RCOST, Via Traiano, I-82100 Benevento, Italy.
EM antoniol@ieee.org; ceccarelli@unisannio.it
RI Ceccarelli, Michele/AGP-1739-2022
OI Ceccarelli, Michele/0000-0002-4702-6617
CR Ahmed AA, 2004, NUCLEIC ACIDS RES, V32, DOI 10.1093/nar/gnh047
   Angulo J, 2003, BIOINFORMATICS, V19, P553, DOI 10.1093/bioinformatics/btg057
   [Anonymous], 2001, COMP SCI W
   [Anonymous], 1986, Bayesian methods: General background
   Bozinov D, 2002, BIOINFORMATICS, V18, P747, DOI 10.1093/bioinformatics/18.5.747
   Ceccarelli M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P712, DOI 10.1109/ICIP.2001.958218
   EISEN M, 1999, METHOD ENZYMOL, V303, P1999
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GOLDBERG J, 1989, GENETIC ALGORITHMS S
   Hartvigsen J, 2002, J MANIP PHYSIOL THER, V25, P162, DOI 10.1067/mmt.2002.122325
   Jain AN, 2002, GENOME RES, V12, P325, DOI 10.1101/gr.210902
   KATZER M, 2003, P SAC NEW YORK
   Lawrence ND, 2004, BIOINFORMATICS, V20, P518, DOI 10.1093/bioinformatics/btg438
   Liew AWC, 2003, PATTERN RECOGN, V36, P1251, DOI 10.1016/S0031-3203(02)00170-X
   SPALL JC, 2001, INTRO STOCHASTIC SEA
   Steinfath M, 2001, BIOINFORMATICS, V17, P634, DOI 10.1093/bioinformatics/17.7.634
   Yang YH, 2002, J COMPUT GRAPH STAT, V11, P108, DOI 10.1198/106186002317375640
NR 17
TC 11
Z9 13
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 155
EP 163
DI 10.1016/j.imavis.2006.01.023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700004
DA 2024-07-18
ER

PT J
AU Kapp, MN
   Freitas, COD
   Sabourin, R
AF Kapp, Marcelo N.
   Freitas, Cinthia O. de A.
   Sabourin, Robert
TI Methodology for the design of NN-based month-word recognizers written on
   Brazilian bank checks
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE neural networks; rejection; feature selection; handwritten word
   recognition
ID RECOGNITION
AB The study of handwritten words is tied to the development of recognition methods to be used in real-world applications involving handwritten words, such as bank checks, postal envelopes, and handwritten texts, among others. In this work, the focus is handwritten words in the context of Brazilian bank checks, specifically the months of the year, and no restrictions are placed on the types or styles of writing or the number of writers. A global feature set and two architectures of artificial neural networks (ANN) are evaluated for classification of the words. The objectives are to evaluate the performance of conventional and class-modular multiple-layer perceptron (MLP) architectures, to develop a rejection mechanism based on multiple thresholds, and to analyze the behavior of the feature set proposed in the two architectures. The experimental results demonstrate the superiority of the class-modular architecture over the conventional MLP architecture. A rejection mechanism with multiple thresholds demonstrates favorable performance in both architectures. The feature set analysis shows the importance of the structural primitives such as concavities and convexities, and perceptual primitives such as ascenders and descenders. The experimental results reveal a recognition rate of 81.75% without the rejection mechanism, and a reliability rate 91.52% with a rejection rate of 25.33%. (c) 2006 Elsevier B.V. All rights reserved.
C1 Ecole Technol Super, Montreal, PQ H3C 1K3, Canada.
   Pontificia Univ Catolica Parana, Curitiba, Parana, Brazil.
C3 University of Quebec; Ecole de Technologie Superieure - Canada;
   Pontificia Universidade Catolica do Parana
RP Kapp, MN (corresponding author), Ecole Technol Super, 1100 Rue Notre Dame Ouest, Montreal, PQ H3C 1K3, Canada.
EM kapp@livia.etsmtl.ca; cinthia.freitas@pucpr.br;
   robert.sabourin@etsmtl.ca
RI Sabourin, Robert/J-7642-2012
OI Kapp, Marcelo/0000-0002-0743-8641
CR CHOW CK, 1970, IEEE T INFORM THEORY, V16, P41, DOI 10.1109/TIT.1970.1054406
   COTE M, 1997, THESIS ECOLE NATL SU
   Freitas COA, 2001, PROC INT CONF DOC, P665, DOI 10.1109/ICDAR.2001.953873
   Fumera G, 2000, PATTERN RECOGN, V33, P2099, DOI 10.1016/S0031-3203(00)00059-5
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   JUNIOR JJO, 2002, P 15 BRAZ S COMP GRA, P210
   KOHAVI R, 1997, AIJ SPECIAL ISSUE RE, P1
   Kohavi R., 1994, PROC AAAIFALL S RELE, P122
   Madhvanath S, 2001, IEEE T PATTERN ANAL, V23, P149, DOI 10.1109/34.908966
   Molina LC, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P306, DOI 10.1109/ICDM.2002.1183917
   MOODY J, 1992, ADV NEUR IN, V4, P683
   Morita M, 2002, EIGHTH INTERNATIONAL WORKSHOP ON FRONTIERS IN HANDWRITING RECOGNITION: PROCEEDINGS, P105, DOI 10.1109/IWFHR.2002.1030894
   Oh IS, 2002, PATTERN RECOGN, V35, P229, DOI 10.1016/S0031-3203(00)00181-3
   Oliveira LS, 2003, INT J PATTERN RECOGN, V17, P903, DOI 10.1142/S021800140300271X
   OLLIVIER D, 1999, THESIS U PARIS 12 OR
   Principe J. C., 1999, Neural and adaptive systems
   RAMAN B, 2003, THESIS TEXAS A M U C
   SCHOMAKER L, 1998, 6 INT WORKSH FRONT H, P157
   Skalak D., 1994, Proceedings of the Eleventh International Conference on Machine Learning, P293, DOI [https://doi.org/10.1016/B978-1-55860-335-6.50043-X, DOI 10.1016/B978-1-55860-335-6.50043-X, 10.1016/B978-1-55860-335-6.50043-X]
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
NR 20
TC 11
Z9 13
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 40
EP 49
DI 10.1016/j.imavis.2006.01.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600006
DA 2024-07-18
ER

PT J
AU Mayoral, R
   Lera, G
   Pérez-Ilzarbe, MJ
AF Mayoral, Rafael
   Lera, Gabriel
   Perez-Ilzarbe, Maria Jose
TI Evaluation of correspondence errors for stereo
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereo; correspondence problem; evaluation
ID DISCONTINUITIES; RECTIFICATION; ALGORITHM; DEPTH
AB The computation of a scalar correspondence error is the fundamental step in most stereo correspondence algorithms. The quality of the results obtained by the reconstruction algorithm directly depends on the characteristics of such error. We have developed a procedure to evaluate different methods proposed for the computation of the correspondence error. The evaluation is based on exploring the shape of the error surface generated and testing it for uniqueness, isolation and compatibility. The scheme presented makes it possible to recognise the known characteristics of the tested methods for the computation of a correspondence error from the results of the evaluations. Our results show that, for the tested scenes, the evaluation scheme allows us to identify the most appropriate method to compute the correspondence error. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Publ Navarra, Pamplona 31006, Spain.
C3 Universidad Publica de Navarra
RP Mayoral, R (corresponding author), Univ Publ Navarra, Pamplona 31006, Spain.
EM rafael.mayoral@ieee.org; galera@una-varra.es; mjperez@unavarra.es
OI Perez-Ilzarbe, Maria Jose/0000-0001-7348-1018
CR ANDERSON BL, 1994, PSYCHOL REV, V101, P414, DOI 10.1037/0033-295X.101.3.414
   [Anonymous], ROBUST COMPUTER VISI
   Ballard D.H., 1982, Computer Vision
   Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146
   Bhat DN, 1998, IEEE T PATTERN ANAL, V20, P415, DOI 10.1109/34.677275
   Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296
   Bobick AF, 1999, INT J COMPUT VISION, V33, P181, DOI 10.1023/A:1008150329890
   Chen ZZ, 2003, PATTERN RECOGN LETT, V24, P251, DOI 10.1016/S0167-8655(02)00239-8
   Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040
   Eklund MP, 2003, INT J PATTERN RECOGN, V17, P1059, DOI 10.1142/S0218001403002861
   FROHLINGHAUS T, 1996, 13 INT C PATT REC, VA, P451
   Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683
   GENNERT MA, 1988, P INT C COMP VIS, P139
   GIDEON RA, 1987, J AM STAT ASSOC, V82, P656
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   JENKIN MRM, 1991, CVGIP-IMAG UNDERSTAN, V53, P14, DOI 10.1016/1049-9660(91)90002-7
   JONES DG, 1992, IMAGE VISION COMPUT, V10, P699, DOI 10.1016/0262-8856(92)90015-U
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   KANADE T, 1996, CVPR, P103
   Kang SB, 2001, PROC CVPR IEEE, P103
   KASS M, 1987, INT J COMPUT VISION, V1, P357, DOI 10.1007/BF00133572
   Kendall M. G., 1948, Rank correlation methods.
   Klette R., 1998, COMPUTER VISION 3 DI, V1st
   Kolmogorov V, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P508, DOI 10.1109/ICCV.2001.937668
   LUO A, 1995, INT J COMPUT VISION, V15, P171, DOI 10.1007/BF01451740
   MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482
   MATTHIES L, 1989, INT J COMPUT VISION, V3, P209, DOI 10.1007/BF00133032
   Mayoral R., 2001, Proceedings of the IASTED International Conference Intelligent Systems and Control, P497
   Nakamura Y, 1996, PROC CVPR IEEE, P371, DOI 10.1109/CVPR.1996.517099
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   Roy S, 1999, INT J COMPUT VISION, V34, P147, DOI 10.1023/A:1008192004934
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   SCHERER S, 1999, IEEE COMP SOC C COMP, V1, P76
   Sobel I., 1990, An Isotropic 3x3 Image Gradient Operator, P376, DOI [10.13140/RG.2.1.1912.4965, DOI 10.13140/RG.2.1.1912.4965]
   SZELISKI R, 2002, 7 EUR C COMP VIS, V2, P525
   Woodfill J., 1994, ECCV, VII, P151
   Yang Y., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P274, DOI 10.1109/CVPR.1993.340969
NR 39
TC 8
Z9 8
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2006
VL 24
IS 12
BP 1288
EP 1300
DI 10.1016/j.imavis.2006.04.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 107AH
UT WOS:000242142600003
DA 2024-07-18
ER

PT J
AU Wu, YH
   Hu, ZY
AF Wu, Yihong
   Hu, Zhanyi
TI A robust method to recognize critical configuration for camera
   calibration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE camera calibration; invariant; critical configuration
ID PROJECTIVE RECONSTRUCTION; INVARIANTS
AB When space points and camera optical center lie on a twisted cubic, no matter how many pairs there are used from the space points to their image points, camera parameters cannot be determined uniquely. This configuration is critical for camera calibration. We set up invariant relationship between six space points and their image points for the critical configuration. Then based on the relationship, an algorithm to recognize the critical configuration of at least six pairs of space and image points is proposed by using a constructed criterion function, where no any explicit computation on camera projective matrix or optical center is needed. Experiments show the efficiency of the proposed method. (c) 2006 Elsevier B.V. All rights reserved.
C1 Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Wu, YH (corresponding author), Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, POB 2728,95 E Rd Zhongguancun, Beijing 100080, Peoples R China.
EM yhwu@nlpr.ia.ac.cn; huzy@nlpr.ia.ac.cn
CR [Anonymous], 1971, American Society of Photogrammetry Symposium on Close-Range Photogrammetry
   Bayro-Corrochano E, 2002, J MATH IMAGING VIS, V16, P131, DOI 10.1023/A:1013947415006
   BUCHANAN T, 1988, COMPUT VISION GRAPH, V42, P130, DOI 10.1016/0734-189X(88)90146-6
   Carlsson S., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P249, DOI 10.1007/BFb0055671
   CARLSSON S, 1995, KTHNAP9522SE ISRN
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   HARTLEY RI, 1994, IEEE T PATTERN ANAL, V16, P1036, DOI 10.1109/34.329005
   QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34
   QUAN L, 1994, ECCV, P459
   Roh KS, 2000, PATTERN RECOGN, V33, P741, DOI 10.1016/S0031-3203(99)00092-8
   Schaffalitzky F, 2000, LECT NOTES COMPUT SC, V1842, P632
   SEMPLE JG, 1952, ALGEBRAIC PROJECTIVE
   WU Y, 2004, LNCS, V3519, P403
   Wu YH, 2003, IEEE T PATTERN ANAL, V25, P1329, DOI 10.1109/TPAMI.2003.1233907
NR 14
TC 2
Z9 4
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2006
VL 24
IS 12
BP 1313
EP 1318
DI 10.1016/j.imavis.2006.04.010
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 107AH
UT WOS:000242142600005
DA 2024-07-18
ER

PT J
AU Fraundorfer, F
   Schindler, K
   Bischof, H
AF Fraundorfer, Friedrich
   Schindler, Konrad
   Bischof, Horst
TI Piecewise planar scene reconstruction from sparse correspondences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE planar homography; 3D scene reconstruction; affine invariant regions
ID WINDOW; VIEWS
AB A novel method able to recover scene planes of arbitrary position and orientation from oriented images using homographies is presented. Planar regions are reconstructed using only sparse, affine-invariant sets of corresponding seed regions. These regions are iteratively expanded and refined using plane-induced homographies. Experiments on synthetic data show the high accuracy of the reconstruction and demonstrate that the reconstruction method can cope with large baseline changes. Experiments on real images show the performance of the method on practically relevant scenes. (c) 2006 Elsevier B.V. All rights reserved.
C1 Graz Univ Technol, Inst Comp Graph & Vis, A-8010 Graz, Austria.
C3 Graz University of Technology
RP Fraundorfer, F (corresponding author), Graz Univ Technol, Inst Comp Graph & Vis, Inffeldgasse 16-2, A-8010 Graz, Austria.
EM konrad.schindler@eng.monash.edu.au; schindler@eng.monash.edu.au;
   bischof@icg.tu-graz.ac.at
RI Pollefeys, Marc/I-7607-2013
OI Pauldurai, Jona/0000-0002-7217-0872; Fraundorfer,
   Friedrich/0000-0002-5805-8892; Bischof, Horst/0000-0002-9096-6671
CR [Anonymous], P 8 INT C COMP VIS V
   [Anonymous], THESIS U OXFORD
   BAILLARD C, 2000, INT ARCH PHOTOGRA B2, V33, P56
   Baillard C., 1999, Conference on Automatic Extraction of GIS Objects from Digital Imagery, IAPRS, V32, P69
   BAUER J, 2002, P 26 WORKSH AUSTR AS, P29
   BESL P, 1988, MACHINE VISION ALGOR, P221
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Criminisi A, 1999, IMAGE VISION COMPUT, V17, P625, DOI 10.1016/S0262-8856(98)00183-8
   Ferrari V, 2004, LECT NOTES COMPUT SC, V3021, P40
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fraundorfer F., 2003, P 27 WORKSH AUSTR AS, P57
   FRAUNDORFER F, 2003, P 13 SCAND C IM AN G, P208
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hoover A, 1998, COMPUT VIS IMAGE UND, V69, P310, DOI 10.1006/cviu.1998.0666
   IRANI M, 1998, P EUR C COMP VIS, P829
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   KUMAR R, 1994, P DARPA IM UND WORKS
   Lan ZD, 1998, MACH VISION APPL, V10, P256, DOI 10.1007/s001380050077
   Lourakis MIA, 2003, IEEE T PATTERN ANAL, V25, P271, DOI 10.1109/TPAMI.2003.1177157
   Lourakis MIA, 2000, IMAGE VISION COMPUT, V18, P673, DOI 10.1016/S0262-8856(99)00071-2
   Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055
   MA Y, 2003, INVITATION 3D
   Matas J., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P384
   Park TJ, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P290, DOI 10.1109/PCCGA.2000.883952
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705
   Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802
   Rother C, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P42, DOI 10.1109/ICCV.2001.937497
   Schindler K, 2003, LECT NOTES COMPUT SC, V2749, P470
   Szeliski R., 1998, 3D Structure from Multiple Images of Large-Scale Environments. European Workshop, SMILE'98. Proceedings, P171
   WERNER AZ, 2002, P 7 EUR C COMP VIS C, P541
   ZISSERMAN A, 2001, P 2K WORKSH AUSTR AS, P9
NR 32
TC 25
Z9 42
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2006
VL 24
IS 4
BP 395
EP 406
DI 10.1016/j.imavis.2006.01.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 049US
UT WOS:000238043500008
DA 2024-07-18
ER

PT J
AU Duh, DJ
   Jeng, JH
   Chen, SY
AF Duh, DJ
   Jeng, JH
   Chen, SY
TI DCT based simple classification scheme for fractal image compression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fractal image compression; self-similarity; classification; DCT
AB In this paper, a fast fractal encoding algorithm using simple classification scheme is proposed. During the encoding process, the range blocks and domain blocks are classified first. Then, each range block is limited to search in the corresponding domain class to find the best match. Since the searching space is reduced, the encoding speed is improved. Three classes of image blocks are defined, which are smooth class, diagonal/sub-diagonal edge class and horizontal/vertical edge class. The classification operation is performed using only the lowest horizontal and vertical DCT coefficients of the given block. Thus the classification scheme is simple and computationally efficient. Moreover, since the classification mechanism is designed according to the edge properties and the intrinsic idea of fractal coding, the quality of the decoded image can be preserved. The thresholds for the classifier are also adaptively determined from the range pool so as to reduce the overhead and to guarantee a stable speedup ratio of 3. Simulation results show that the stable speedup ratio of the proposed algorithm can be achieved and is independent of images while the quality of the decoded image is almost the same as that of the full search method. (C) 2005 Elsevier Ltd All rights reserved.
C1 I Shou Univ, Dept Informat Engn, Kaohsiung Cty 840, Taiwan.
   Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan 820, Taiwan.
C3 I Shou University; Yuan Ze University
RP I Shou Univ, Dept Informat Engn, Kaohsiung Cty 840, Taiwan.
EM jjeng@isu.edu.tw
CR [Anonymous], 1991, FRACTALS FUNDAMENTAL
   Barnsley M. F., 1990, US Patent, Patent No. [4,941,193, 4941193]
   BARNSLEY MF, 1985, P ROY SOC LOND A MAT, V399, P243, DOI 10.1098/rspa.1985.0057
   BARNSLEY MF, 1988, BYTE             JAN, P215
   Crilly A.J., 1991, FRACTALS CHAOS
   Fisher Y., 1994, Fractal Image Compression
   Graf S., 1992, Journal of Complexity, V8, P72, DOI 10.1016/0885-064X(92)90035-A
   JACOBS EW, 1992, SIGNAL PROCESS, V29, P251, DOI 10.1016/0165-1684(92)90085-B
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Lai CM, 2003, IEEE T IMAGE PROCESS, V12, P1398, DOI 10.1109/TIP.2003.817246
   Lee CK, 1998, IEEE T IMAGE PROCESS, V7, P888, DOI 10.1109/83.679437
   Truong TK, 2000, IEEE T IMAGE PROCESS, V9, P529, DOI 10.1109/83.841930
   Wang Z, 2000, SIGNAL PROCESS-IMAGE, V15, P767, DOI 10.1016/S0923-5965(99)00018-1
   Wohlberg B, 1999, IEEE T IMAGE PROCESS, V8, P1716, DOI 10.1109/83.806618
NR 14
TC 36
Z9 37
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1115
EP 1121
DI 10.1016/j.imavis.2005.05.013
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500001
DA 2024-07-18
ER

PT J
AU Xiang, T
   Cheong, LF
AF Xiang, T
   Cheong, LF
TI On the distortion of shape recovery from motion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE shape recovery; structure from motion; error analysis; iso-distortion
   framework
ID INHERENT AMBIGUITIES; 3-D MOTION; ALGORITHM; TEXTURE; INTEGRATION;
   AFFINE; STEREO
AB Given that most current structure from motion (SFM) algorithms cannot recover true motion estimates reliably, it is important to understand the impact such motion errors have on the shape reconstruction. In this paper, various robustness issues surrounding different types of second order shape estimates recovered from motion cue are addressed. We present a theoretical model to understand the impact that errors in the motion estimates have on shape recovery. Using this model, we focus on the recovery of second order shape under different generic motions, each of these motions presenting different degrees of error sensitivity. We also show that different shapes exhibit different degrees of robustness with respect to its recovery. Understanding such different distortion behavior is important if we want to design better fusion strategy with other shape cues. (C) 2004 Elsevier B.V. All rights reserved.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
   Univ London, Dept Comp Sci, London E1 4NS, England.
C3 National University of Singapore; University of London
RP Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
EM txiang@dcs.qmul.ac.uk; eleclf@nus.edu.sg
CR ADIV G, 1989, IEEE T PATTERN ANAL, V11, P477, DOI 10.1109/34.24780
   ALOIMONOS J, 1987, INT J COMPUT VISION, V1, P333
   BULTHOFF HH, 1988, J OPT SOC AM A, V5, P1749, DOI 10.1364/JOSAA.5.001749
   CAVANAGH P, 1987, COMPUT VISION GRAPH, V37, P171, DOI 10.1016/S0734-189X(87)80001-4
   Cheong LF, 1999, INT J COMPUT VISION, V32, P195, DOI 10.1023/A:1008105012585
   Cheong LF, 2001, INT J COMPUT VISION, V44, P199, DOI 10.1023/A:1012224215211
   Cutting JamesE., 1995, PERCEPTION SPACE MOT, V2nd
   Davies A., 1996, An introduction to computational geometry for curves and surfaces
   FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465
   FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192
   HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130
   Jacobs RA, 1999, VISION RES, V39, P3621, DOI 10.1016/S0042-6989(99)00088-7
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Lucas B.D., 1984, THESIS CARNEGIE MELL
   Ma Y, 2000, INT J COMPUT VISION, V36, P71, DOI 10.1023/A:1008124507881
   Oliensis J, 2000, COMPUT VIS IMAGE UND, V80, P172, DOI 10.1006/cviu.2000.0869
   Schrater PR, 2000, INT J COMPUT VISION, V40, P73, DOI 10.1023/A:1026557704054
   THOMAS JI, 1993, P DARPA IM UND WORKS, P691
   Tittle JS, 1998, PERCEPTION, V27, P147, DOI 10.1068/p270147
   Weng J., 1991, MOTION STRUCTURE IMA
   Xiang T, 2003, INT J COMPUT VISION, V51, P111, DOI 10.1023/A:1021627622971
   YOUNG GSJ, 1992, IEEE T PATTERN ANAL, V14, P995, DOI 10.1109/34.159903
   YOUNG MJ, 1993, VISION RES, V33, P2685, DOI 10.1016/0042-6989(93)90228-O
NR 25
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 807
EP 817
DI 10.1016/j.imavis.2004.02.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300008
DA 2024-07-18
ER

PT J
AU Chan, YK
   Chang, CC
AF Chan, YK
   Chang, CC
TI Block image retrieval based on a compressed linear quadtree
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE quadtree; linear quadtree; image compression; image retrieval
AB Based on a compressed linear quadtree, a data structure is proposed which is more than a structure to compress a gray-level or color image, but a structure, which can be applied to retrieve a block image. This compressed linear quadtree may directly extract a detailed block image without decompressing the compressed data of the original image. (C) 2004 Elsevier B.V. All rights reserved.
C1 Natl Chung Hsing Univ, Management Informat Syst Dept, Taichung, Taiwan.
   Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi, Taiwan.
C3 National Chung Hsing University; National Chung Cheng University
RP Chan, YK (corresponding author), Natl Chung Hsing Univ, Management Informat Syst Dept, 250,Kuokuang Rd, Taichung, Taiwan.
EM ykchan@nchu.edu.tw; ccc@cs.ccu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
OI Chan, Yung-Kuan/0000-0002-1556-0567
CR CHAN YK, 1998, P 5 INT C FDN DAT OR, P268
   CHANG HKC, 1995, P 8 IPPR C COMP VIS, P122
   DYER CR, 1982, COMPUT VISION GRAPH, V19, P335, DOI 10.1016/0146-664X(82)90020-X
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Lin TW, 1997, IMAGE VISION COMPUT, V15, P833, DOI 10.1016/S0262-8856(97)00031-0
   Lin TW, 1997, PATTERN RECOGN, V30, P1239, DOI 10.1016/S0031-3203(97)83108-1
   Morton G. M., 1966, COMPUTER ORIENTED GE
   SAMET H, 1984, ACM COMPUT SURV, V16, P187, DOI DOI 10.1145/356924.356930
   STEWART IP, 1986, COMPUT J, V29, P60, DOI 10.1093/comjnl/29.1.60
   Vassilakopoulos M., 1995, Nordic Journal of Computing, V2, P70
   VASSILAKOPOULOS M, 1993, IMAGE VISION COMPUT, V11, P257, DOI 10.1016/0262-8856(93)90002-X
NR 11
TC 14
Z9 20
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2004
VL 22
IS 5
BP 391
EP 397
DI 10.1016/j.imavis.2003.12.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 806GN
UT WOS:000220422500004
DA 2024-07-18
ER

PT J
AU Nascimento, JC
   Marques, JS
AF Nascimento, JC
   Marques, JS
TI An adaptive potential for robust shape estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE snakes; adaptive potential; EM; strokes; deformable model
ID ACTIVE CONTOUR MODELS; TRACKING; SNAKES
AB This paper describes an algorithm for shape estimation in cluttered scenes. A new image potential is defined based on strokes detected in the image. The motivation is simple. Feature detectors (e.g. edge points detectors) produce many outliers, which hamper the performance of boundary extraction algorithms. To overcome this difficulty we organize edges in strokes and assign a confidence degree (weight) to each stroke. The confidence degrees depend on the distance of the stroke points to the boundary estimates and they are updated during the estimation process. A deformable model is used to estimate the object boundary, based on the minimization of an adaptive potential function which depends on the confidence degree assigned to each stroke. Therefore, the image potential changes during the estimation process. Both steps (weight update, energy minimization) are derived as the solution of a maximum likelihood estimation problem using the EM algorithm.
   Experimental tests are provided to illustrate the performance of the proposed algorithm. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Tecn Lisboa, IST, P-1049001 Lisbon, Portugal.
C3 Universidade de Lisboa
RP Univ Tecn Lisboa, IST, Av Rovisco Pais,Torre Norte,6 Piso, P-1049001 Lisbon, Portugal.
EM jan@isr.ist.utl.pt; jsm@isr.ist.utl.pt
RI Nascimento, Jacinto/B-6128-2009; Marques, Jorge/C-1427-2010
OI Nascimento, Jacinto/0000-0001-7468-5127; Marques,
   Jorge/0000-0002-3800-7756
CR Abrantes AJ, 1996, IEEE T IMAGE PROCESS, V5, P1507, DOI 10.1109/83.541421
   BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225
   Blake A., 1998, ACTIVE CONTOURS
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   FIGUEIREDO M, 1992, IEEE T MED IMAGING, V11, P416
   GEVERS T, 1998, P 9 BRIT MACH VIS C, V2, P578
   Gu HS, 1996, IEEE T PATTERN ANAL, V18, P58, DOI 10.1109/34.476012
   Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707
   KALITZIN S, 2000, IEEE INT C IM PROC, V3, P580
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733
   Marques JS, 2000, INT C PATT RECOG, P916, DOI 10.1109/ICPR.2000.905586
   Nascimento J, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P82, DOI 10.1109/ICIP.2000.899300
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   ZHANG X, 2000, ICPR, V3, P676
NR 18
TC 2
Z9 2
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1107
EP 1116
DI 10.1016/S0262-8856(03)00179-3
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100005
DA 2024-07-18
ER

PT J
AU Sakarya, U
   Erkmen, I
AF Sakarya, U
   Erkmen, I
TI An improved method of photometric stereo using local shape from shading
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Lambert surface model; albedo; photometric stereo; shape from shading
ID MULTIPLE IMAGES; INTEGRATION; RECOVERY
AB This paper presents an improved photometric stereo (PS) method by integrating it with a local shape from shading (SFS) algorithm. PS produces the initial estimate of image for the global accuracy and also provides the recovery of albedo, SFS supplies the more detailed information within each homogeneous area. The quality of depth obtained by integrating PS and SFS is compared with the real depth using absolute dept error function, and the improvement ranging from 2.3 to 14% over PS is obtained. (C) 2003 Elsevier B.V. All rights reserved.
C1 Middle E Tech Univ, Dept Elect Engn & Elect, TR-06531 Ankara, Turkey.
C3 Middle East Technical University
RP Erkmen, I (corresponding author), Middle E Tech Univ, Dept Elect Engn & Elect, TR-06531 Ankara, Turkey.
RI Sakarya, Ufuk/AAZ-4401-2020; Erkmen, Ismet/AAZ-9237-2020
CR [Anonymous], P 2 INT C COMP VIS
   BUTHOFF H, 1998, J OPT SOC AM, V5, P1749
   CRYER JE, 1995, PATTERN RECOGN, V28, P1033, DOI 10.1016/0031-3203(94)00183-M
   FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909
   HEALEY G, 1984, CICPR 84, P894
   Kim BH, 1998, PATTERN RECOGN, V31, P1033, DOI 10.1016/S0031-3203(97)00082-4
   LEE CH, 1985, ARTIF INTELL, V26, P125, DOI 10.1016/0004-3702(85)90026-8
   LEE KM, 1993, J OPT SOC AM A, V10, P855, DOI 10.1364/JOSAA.10.000855
   PANKANTI S, 1995, IEEE T PATTERN ANAL, V17, P831, DOI 10.1109/34.406649
   PENTLAND AP, 1984, IEEE T PATTERN ANAL, V6, P170, DOI 10.1109/TPAMI.1984.4767501
   Torreao JRA, 2001, PATTERN RECOGN, V34, P2367, DOI 10.1016/S0031-3203(00)00168-0
   Tsai P.-S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P734, DOI 10.1109/CVPR.1992.223187
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   WU ZQ, 1988, COMPUT VISION GRAPH, V43, P53, DOI 10.1016/0734-189X(88)90042-4
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang R, 1997, IMAGE VISION COMPUT, V15, P801, DOI 10.1016/S0262-8856(97)00029-2
   ZHANG R, 1994, IEEE C COMP VIS PATT, P377
NR 17
TC 11
Z9 12
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2003
VL 21
IS 11
BP 941
EP 954
DI 10.1016/S0262-8856(03)00096-9
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 731CP
UT WOS:000185867200001
DA 2024-07-18
ER

PT J
AU Drew, MS
   Au, J
AF Drew, MS
   Au, J
TI Clustering of compressed illumination-invariant chromaticity signatures
   for efficient video summarization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE colour; chromaticity; video summarization; clustering; illumination
   invariance
AB Motivated by colour constancy work in physics-based vision, we develop a new low-dimensional video frame feature that is effectively insensitive to lighting change and apply the feature to keyframe production using hierarchical clustering. The new image feature results from normalising colour channels for frames and then treating 2D histograms of chromaticity as images and compressing these. Because we effectively reduce any video to the same lighting conditions, we can precompute a universal basis on which to project video frame feature vectors. The new feature thus has the advantage of more expressively capturing essential colour information, and is useful for video indexing because it is very low-dimension-the feature vector is only of length 8. We carry out clustering efficiently by adapting the hierarchical clustering data structure to temporally-ordered clusters. Using a new multi-stage hierarchical clustering method, we merge clusters based on the ratio of cluster variance to variance of the parent node, merging only adjacent clusters, and then follow with a second round of clustering. The second stage merges clusters incorrectly split in the first round by the greedy hierarchical algorithm, and as well merges non-adjacent clusters to fuse near-repeat shots. The new summarization method produces a very succinct set of keyframes for videos and, compared to a previous well-known technique, results are excellent. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Simon Fraser Univ, Sch Comp Sci, Vancouver, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Simon Fraser Univ, Sch Comp Sci, Vancouver, BC V5A 1S6, Canada.
EM mark@cs.sfu.ca; ksau@cs.sfu.ca
CR [Anonymous], 1995, PROC ICJAI, DOI DOI 10.1145/217279.215068
   [Anonymous], 1993, Cluster Analysis
   BERENS J, 2000, IN PRESS ICPR 00
   BORGES CF, 1991, J OPT SOC AM A, V8, P1319, DOI 10.1364/JOSAA.8.001319
   DEMENTHON D, 1998, ACM MM98
   Drew MS, 1999, PATTERN RECOGN, V32, P1369, DOI 10.1016/S0031-3203(98)00168-X
   Drew MS, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P929, DOI 10.1109/ICIP.2000.899609
   DREW MS, 1998, ICCV 98, P533
   DREW MS, 2000, 1 IEEE PAC RIM C MUL
   DREW MS, ACM MULTIMEDIA 00, P365
   Ferman AM, 1998, J VIS COMMUN IMAGE R, V9, P336, DOI 10.1006/jvci.1998.0402
   FERMAN AM, 1997, SPIE MULT STOR ARCH
   Finlayson GD, 1997, FIFTH COLOR IMAGING CONFERENCE: COLOR SCIENCE, SYSTEMS, AND APPLICATIONS, P6
   FINLAYSON GD, 1998, ECCV 98
   Girgensohn A, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P756, DOI 10.1109/MMCS.1999.779294
   Hanjalic A, 1997, P SOC PHOTO-OPT INS, V3022, P427, DOI 10.1117/12.263432
   KENDER JR, 1998, CVPR 98, P367
   PAULUS D, 2000, INT C IM PROC ICIP 0, V3, P492
   Sahouria E, 1999, IEEE T CIRC SYST VID, V9, P1290, DOI 10.1109/76.809163
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   WEI J, 1998, ELECT IMAGING 98 STO, V3312, P188
   YEO BL, 1998, SPIE STOR RETR IM VI
   Yeung MM, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pA338
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
   Zhong D, 1996, PROC SPIE, V2670, P239, DOI 10.1117/12.234800
NR 25
TC 12
Z9 13
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2003
VL 21
IS 8
BP 705
EP 716
DI 10.1016/S0262-8856(03)00065-9
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 706VM
UT WOS:000184475800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU de la Escalera, A
   Armingol, JM
   Mata, M
AF de la Escalera, A
   Armingol, JM
   Mata, M
TI Traffic sign recognition and analysis for intelligent vehicles
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object recognition; genetic algorithms; neural networks; traffic sign
   recognition; driver support systems; intelligent vehicles; intelligent
   transportation systems
ID SYSTEM
AB This paper deals with object recognition in outdoor environments. In this type of environments, lighting conditions cannot be controlled and predicted, objects can be partially occluded, and their position and orientation is not known a priori. The chosen type of objects is traffic or road signs, due to their usefulness for sign maintenance, inventory in highways and cities, Driver Support Systems and Intelligent Autonomous Vehicles. A genetic algorithm is used for the detection step, allowing an invariance localisation to changes in position, scale, rotation, weather conditions, partial occlusion, and the presence of other objects of the same colour. A neural network achieves the classification. The global system not only recognises the traffic sign but also provides information about its condition or state. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Univ Carlos III Madrid, Div Syst Engn & Automat, Madrid 28911, Spain.
C3 Universidad Carlos III de Madrid
RP de la Escalera, A (corresponding author), Univ Carlos III Madrid, Div Syst Engn & Automat, C Butarque 15, Madrid 28911, Spain.
RI de la Escalera, Arturo/K-1251-2014; Mata, Mario/K-6680-2014; de la
   Escalera, Arturo/P-1799-2019; Armingol, Jose Maria/K-6816-2014
OI de la Escalera, Arturo/0000-0002-2618-857X; Mata,
   Mario/0000-0002-8693-2698; Armingol, Jose Maria/0000-0002-3353-9956
CR ADORNI G, 1997, C INT TRANSP SYST IE
   ADORNI G, 1996, 4 WORKSH CELL NEUR N
   AOYAGI Y, 1996, 22 INT C IND EL CONT
   ARNOUL P, 1996, INT VEH S IEEE SEPT
   AUSTERIRMEIER H, 1992, INT WORKSH STRUCT SY
   BARTNECK N, 1992, 11 INT C PATT REC IA
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   BESSERER B, 1993, 1 INT WORKSH INT AUT
   BETKE M, 1995, INT C COMP VIS IEEE
   Buker U, 1995, J PARALLEL DISTR COM, V31, P141, DOI 10.1006/jpdc.1995.1152
   BULUSWAR S, 1998, 6 INT C COMP VIS IEE
   CARPENTER GA, 1987, COMPUT VISION GRAPH, V37, P54, DOI 10.1016/S0734-189X(87)80014-2
   delaEscalera A, 1997, IEEE T IND ELECTRON, V44, P848, DOI 10.1109/41.649946
   DICKMANNS ED, 1986, SPIE             OCT
   ESTABLE S, 1994, INT VEH S AUG
   Franke U, 1998, IEEE INTELL SYST APP, V13, P40, DOI 10.1109/5254.736001
   GAVRILA DM, 1999, INT C COMP VIS IEEE
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   Handmann U, 2000, IMAGE VISION COMPUT, V18, P367, DOI 10.1016/S0262-8856(99)00032-3
   HIBI T, 1996, 29 INT S AUT TECHN A
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   JANSSEN R, 1993, INT VEH S IEEE JUL
   JIANG GY, 1998, 4 INT C SIGN PROC IE
   KANG DS, 1994, SW S IM AN INT IEEE
   Kehtarnavaz N., 1993, Machine Vision and Applications, V6, P206, DOI 10.1007/BF01212298
   KELLMEYER DL, 1994, INT C NEUR NETW IEEE
   KIM SK, 1997, 30 INT S AUT TECHN A
   LUO RC, 1993, INT JOINT C NEUR NET
   LUO RC, 1992, INT C IND EL CONTR I
   LUO RC, 1992, IEEE RSJ INT C INT R, P527
   LUO RC, 1994, INT C NEUR NETW IEEE
   PANDYA AS, 1996, PATTERN RECOGNITIONN
   Piccioli G, 1996, IMAGE VISION COMPUT, V14, P209, DOI 10.1016/0262-8856(95)01057-2
   POMMERLEAU D, 1996, IEEE EXPERT, V11, P19
   PRIESE L, 1995, INT VEH S IEEE SEPT
   PRIESE L, 1994, INT VEH S IEEE OCT
   Salichs MA, 1999, INTEGR COMPUT-AID E, V6, P303
   YUILLE AL, 1998, 6 INT C COMP VIS IEE
   ZADEH MM, 1998, INTELLIGENT TRANSPOR
NR 39
TC 259
Z9 288
U1 0
U2 96
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2003
VL 21
IS 3
BP 247
EP 258
AR PII S0262-856(02)00156-7
DI 10.1016/S0262-8856(02)00156-7
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657GN
UT WOS:000181658100002
DA 2024-07-18
ER

PT J
AU Kwan, PWH
   Kameyama, K
   Toraichi, K
AF Kwan, PWH
   Kameyama, K
   Toraichi, K
TI On a relaxation-labeling algorithm for real-time contour-based image
   similarity retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE relaxation labeling; real-time; contour; image retrieval; trademark
ID HANDWRITTEN CHARACTER-RECOGNITION; PARALLEL ARCHITECTURE; OPERATIONS
AB In this paper, we propose a relaxation-labeling algorithm for real-time contour-based image similarity retrieval that treats the matching between two images as a consistent labeling problem. To satisfy real-time response, our algorithm works by reducing the size of the labeling problem, thus decreasing the processing required. This is accomplished by adding compatibility constraints on contour segments between the images to reduce the size of the relational network and the order of the compatibility coefficient matrix. Particularly, a relatively strong type constraint based on approximating contour segments by straight line, arc, and smooth curve is introduced. A distance metric, defined using the negative of an objective function maximized by the relaxation labeling processes, is used in computing the similarity ranking. Experiments are conducted on 700 trademark images from the Japan Patent Office for evaluation. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Tsukuba, Inst Informat Sci & Elect, Tsukuba, Ibaraki 3058573, Japan.
C3 University of Tsukuba
RP Kwan, PWH (corresponding author), Univ Tsukuba, Inst Informat Sci & Elect, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan.
RI Kwan, Wing Hing Paul/JQV-6054-2023
OI Kwan, Wing Hing Paul/0000-0002-4959-5274
CR Aigrain P, 1996, MULTIMED TOOLS APPL, V3, P179, DOI 10.1007/BF00393937
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   BEIGI M, 1998, P SOC PHOTO-OPT INS, V3312, P118
   BLUM H, 1973, J THEOR BIOL, V38, P205, DOI 10.1016/0022-5193(73)90175-6
   CHEN LH, 1990, PATTERN RECOGN, V23, P1189, DOI 10.1016/0031-3203(90)90115-2
   CHEN Z, 1990, PATTERN RECOGN, V23, P637, DOI 10.1016/0031-3203(90)90039-N
   DeMarsicoi M, 1997, IMAGE VISION COMPUT, V15, P119, DOI 10.1016/S0262-8856(96)01114-6
   ENSER PGB, 1995, J DOC, V51, P126, DOI 10.1108/eb026946
   FLICKNER M, 1995, IEEE COMPUT, V9, P23
   Haruki R., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P31, DOI 10.1109/ICDAR.1993.395788
   HUANG T, 1997, MULTIMEDIA ANAL RETR, P101
   HUMMEL RA, 1983, IEEE T PATTERN ANAL, V5, P267, DOI 10.1109/TPAMI.1983.4767390
   Idris F, 1997, J VIS COMMUN IMAGE R, V8, P146, DOI 10.1006/jvci.1997.0355
   KAMADA M, 1988, PATTERN RECOGN, V21, P175, DOI 10.1016/0031-3203(88)90025-8
   KITTLER J, 1985, IMAGE VISION COMPUT, V3, P206, DOI 10.1016/0262-8856(85)90009-5
   Kwan P. W. H., 2002, P IASTED INT C NETW, P211
   KWAN PWH, 2001, P 10 IEEE INT C FUZZ, P334
   LAM L, 1988, PATTERN RECOGN, V21, P19, DOI 10.1016/0031-3203(88)90068-4
   LIN SY, 1992, IEEE T SIGNAL PROCES, V40, P1231, DOI 10.1109/78.134485
   MANTAS J, 1986, PATTERN RECOGN, V19, P425, DOI 10.1016/0031-3203(86)90040-3
   NIBLACK W, 1993, RJ9203 IBM
   Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105
   PELILLO M, 1994, IEEE T PATTERN ANAL, V16, P933, DOI 10.1109/34.310691
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   ROSENFELD A, 1976, IEEE T SYST MAN CYB, V6, P420, DOI 10.1109/TSMC.1976.4309519
   ROSENFELD A, 1978, PATTERN RECOGN, V10, P181, DOI 10.1016/0031-3203(78)90026-2
   SMITH JR, 1997, INTELLIGENT MULTIMED, P32
   Toraichi K., 1990, Transactions of the Institute of Electronics, Information and Communication Engineers D-II, VJ73D-II, P1448
   Wada K, 1998, PATTERN RECOGN LETT, V19, P475, DOI 10.1016/S0167-8655(98)00021-X
   Yamamoto K., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P395
   YAMAMOTO K, 1984, P 7 ICPR MONTR, P385
NR 31
TC 9
Z9 12
U1 1
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2003
VL 21
IS 3
BP 285
EP 294
AR PII S0262-8856(02)00159-2
DI 10.1016/S0262-8856(02)00159-2
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657GN
UT WOS:000181658100005
DA 2024-07-18
ER

PT J
AU Sun, CM
AF Sun, CM
TI Uncalibrated three-view image rectification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE rectification; uncalibrated images; trilinear tensor; fundamental
   matrix; epipolar lines; epipoles; vanishing points; vanishing line;
   projection matrix
ID PAIRS; ALGORITHM
AB Image rectification is a process of transforming a set of images into a new set such that the epipolar lines in the transformed images have the same direction as the image rows or columns to enable an efficient and reliable stereo matching. Previous algorithms for stereo image rectification either work for two view uncalibrated or two/three view calibrated situations. In this paper we propose several novel techniques to rectify uncalibrated trinocular images using the trilinear tensor or projective invariants or fundamental matrices obtained from a triplet of images. Our new methods include: a rotation and skew method, an affine transformation method, and a vanishing points method. Real images have been used for testing purposes, and accurate results have been obtained. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 CSIRO Math & Informat Sci, N Ryde, NSW 1670, Australia.
C3 Commonwealth Scientific & Industrial Research Organisation (CSIRO)
RP Sun, CM (corresponding author), CSIRO Math & Informat Sci, Locked Bag 17, N Ryde, NSW 1670, Australia.
RI Sun, Changming/A-3276-2008
OI Sun, Changming/0000-0001-5943-1989
CR Al-Shalfan KA, 2000, ELECTRON LETT, V36, P419, DOI 10.1049/el:20000362
   AYACHE N, 1988, P INT C PATT REC ERG, V1
   COLLINS RT, 1994, TR9406 CMPSCI U MASS
   Criminisi A., 2000, P 11 BRIT MACHINE VI, P82
   Fusiello A, 2000, MACH VISION APPL, V12, P16, DOI 10.1007/s001380050120
   HARTLEY A, 2000, MULTIPLE VIEW GEOMET
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   HARTLEY RI, 1995, P INT C COMP VIS MIT, V20, P1064
   IM JH, 2001, FCV 7 KOR JAP JOINT, P19
   ISGRO F, 1999, INT C IM AN PROC VEN, P297
   Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649
   LOOP C, 1999, MICROSOFT RES, V8
   Papadimitriou DV, 1996, IEEE T IMAGE PROCESS, V5, P672, DOI 10.1109/83.491345
   POLEFEYS M, 1999, P INT C COMP VIS COR, P496
   QUAN L, 1995, IEEE T PATTERN ANAL, V17, P34
   Shao J., 1999, GEOMAT RES AUSTRALAS, V71, P73
   SHASHUA A, 1995, IEEE T PATTERN ANAL, V17, P779, DOI 10.1109/34.400567
   Shashua A., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P920, DOI 10.1109/ICCV.1995.466837
   Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703
   Torr PHS, 1997, IMAGE VISION COMPUT, V15, P591, DOI 10.1016/S0262-8856(97)00010-3
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 21
TC 16
Z9 19
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2003
VL 21
IS 3
BP 259
EP 269
AR PII S0262-8856(02)00157-9
DI 10.1016/S0262-8856(02)00157-9
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657GN
UT WOS:000181658100003
DA 2024-07-18
ER

PT J
AU Zhu, JL
   Li, QL
   Gao, CB
   Ge, Y
   Xu, K
AF Zhu, Jinlong
   Li, Qingliang
   Gao, Changbo
   Ge, Yu
   Xu, Ke
TI Camera-aware re-identification feature for multi-target multi-camera
   tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camera-aware re-identification; Camera position embedding; Camera
   equalization sampling
AB Multi-target multi-camera tracking is an important research topic in intelligent surveillance to achieve re identification (Re-ID) of moving targets across different cameras. However, Re-ID faces significant challenges owing to variations in cameras/viewpoints, making it difficult to learn discriminative feature representations for targets captured from different cameras/viewpoints. A new pipeline is introduced by balancing the across cameras sample feature space in camera-aware Re-ID framework. Specifically, different sampling strategies play a crucial role on the performance under the same baseline and identify the feature discrepancy between cameras/viewpoints as a crucial factor. This proposed sampling strategy is called camera equalization sampling to learn enhanced feature disparities, which balances cameras under identity rather than randomly sampling in a batch. The sampled images are combined with non visual cues(cameras position encoding) to reduce intra class variance. For the mechanism of camera equalization sampling, the improved camera centric loss function can better reduce the negative impact of individual samples and provide stable learnable features.Our proposed method consists of three modules. (i) Camera equalization (CE) ensures that each batch collects at least one image from each camera for every identity, thereby enabling robust features. (ii) Camera position embedding (CPE) mitigates the scene bias caused by different cameras/viewpoints by encoding camera indices. (iii) Camera Center triplet loss(CCL) based on CE improves higher robustness to outliers and noisy labels. We demonstrated the proposed method's effectiveness on popular datasets such as DukeMTMC-reID, Market-1501, and MSMT17, achieving state-of-the-art performance.
C1 [Zhu, Jinlong; Li, Qingliang; Gao, Changbo; Ge, Yu; Xu, Ke] Changchun Normal Univ, Changhun 130032, Peoples R China.
C3 Changchun Normal University
RP Li, QL (corresponding author), Changchun Normal Univ, Changhun 130032, Peoples R China.
EM zhujinlong@ccsfu.edu.cn; liqingliang@ccsfu.edu.cn;
   QX202200148@stu.ccsfu.edu.cn
RI Zhu, Jinlong/ABA-2824-2020
OI Zhu, Jinlong/0000-0002-5723-2879
FU Jilin Province Science and Technology Development Plan
   [YDZJ202301ZYTS529]
FX This document is the results of the research project funded by the Jilin
   Province Science and Technology Development Plan. No. YDZJ202301ZYTS529
CR Bellet A., 2013, arXiv
   Benzine Abdallah, 2021, CVPR, P1
   Chen Guangyi, 2021, Computer Vision and Pattern Recognition, P1
   Chen H, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14940, DOI 10.1109/ICCV48922.2021.01469
   Chen H, 2021, PROC CVPR IEEE, P2004, DOI 10.1109/CVPR46437.2021.00204
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Chen YP, 2017, ADV NEUR IN, V30
   Cheng Mengyao., 2021, China Population and Development Studies, V5, P275, DOI [https://doi.org/10.1007/s42379-021-00093-7, DOI 10.1007/S42379-021-00093-7, 10.1007/s42379-021-00093-7]
   Chu RH, 2019, IEEE I CONF COMP VIS, P8281, DOI 10.1109/ICCV.2019.00837
   Fufu Yu, 2020, CVPR, P1
   Ge Y., 2020, P NIPS, V33, P11309
   Guo YL, 2018, PROC CVPR IEEE, P2335, DOI 10.1109/CVPR.2018.00248
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Hermans Alexander, 2017, ARXIV170307737
   Hou Yunzhong, 2019, CVPR
   Ji HXY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3641, DOI 10.1109/ICCV48922.2021.00364
   Jianing Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P483, DOI 10.1007/978-3-030-58586-0_29
   Jin X, 2020, AAAI CONF ARTIF INTE, V34, P11173
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Li Guorong, 2023, IEEE Trans. Image Process., P32
   Li P, 2019, IEEE COMPUT SOC CONF, P1506, DOI 10.1109/CVPRW.2019.00192
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2194
   Liang Y., 2022, PROC IEEECVF C COMPU, P9559
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Rao YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1005, DOI 10.1109/ICCV48922.2021.00106
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Somers V, 2023, IEEE WINT CONF APPL, P1613, DOI 10.1109/WACV56688.2023.00166
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang ML, 2021, AAAI CONF ARTIF INTE, V35, P2764
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xiang Jun, 2018, P BRIT MACH VIS C
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P924, DOI 10.1109/TPAMI.2020.3013379
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2018, LECT NOTES COMPUT SC, V11211, P176, DOI 10.1007/978-3-030-01234-2_11
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8351, DOI 10.1109/ICCV48922.2021.00826
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhongdao Wang, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P72, DOI 10.1007/978-3-030-58621-8_5
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhu ZH, 2020, AAAI CONF ARTIF INTE, V34, P13114
   Zijie Zhuang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P140, DOI 10.1007/978-3-030-58610-2_9
NR 52
TC 0
Z9 0
U1 2
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2024
VL 142
AR 104889
DI 10.1016/j.imavis.2023.104889
EA DEC 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IJ5M9
UT WOS:001165971300001
DA 2024-07-18
ER

PT J
AU Thanh, PTH
   Bui, MQV
   Nguyen, DD
   Pham, TV
   Duy, TVT
   Naotake, N
AF Thanh, Phan Thi Huyen
   Bui, Minh Quan Viet
   Nguyen, Duc Dung
   Pham, Tran Vu
   Duy, Truong Vinh Truong
   Naotake, Natori
TI Transfer multi-source knowledge via scale-aware online domain adaptation
   in depth estimation for autonomous driving
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Monocular depth estimation; Multi-source domain adaptation;
   Meta-learning; Online domain adaptation; Virtual-to-real; Autonomous
   driving
AB This paper deals with the challenging online monocular depth adaptation task that aims to train an initial depth estimation model in a source domain and continuously adapt the model against a constantly changing target domain. Due to the high cost of real-world data collection and the camera-dependent nature of the depth estimation, previous works tend to simulate the environment using a virtual-world dataset for training (e.g. Virtual KITTI), and employ a real-world dataset for testing (e.g. KITTI, which shares the same camera settings) and are therefore vulnerable to novel domains with unknown statistics. We propose a meta-learning-based online domain adaptation framework that can leverage multi-source domain to transfer the learned knowledge from the virtual world to the real world better with the metrically accurate scale. Our learn-to-adapt algorithm mimics domain shifts during training by creating fictitious testing domains and incorporating a meta-optimization objective for optimizing the performance of the testing domains after updating the training domains in each mini-batch step. The algorithm is augmented with gradient surgery to alleviate unreliable optimization of inconsistent regions. To facilitate multi-source domain training and testing, we introduce a camera conversion technique for transforming images and depth cues from different camera settings to a unified one. During online adaptation, we also apply the exact statistics of the test-time input to the network's normalization layers to ensure a more robust adaptation. Extensive experiments demonstrate that our method can robustly adapt and outperform the virtual-to-real state-of-the-art methods on the standard KITTI Eigen benchmark of both full-length videos and isolated frames, a feat never attempted before, as well as generalizing to other real-world datasets without retraining.
C1 [Thanh, Phan Thi Huyen; Duy, Truong Vinh Truong; Naotake, Natori] Aisin Corp, Tokyo Res Ctr, Akihabara Daibiru 7F,1-18-13 Sotokanda, Tokyo, Tokyo 1010021, Japan.
   [Bui, Minh Quan Viet; Nguyen, Duc Dung; Pham, Tran Vu] VNU HCM, HoChiMinh City Univ Technol HCMUT, 268 Ly Thuong Kiet St,Dist 10, HoChiMinh City 695014, Vietnam.
RP Duy, TVT (corresponding author), Aisin Corp, Tokyo Res Ctr, Akihabara Daibiru 7F,1-18-13 Sotokanda, Tokyo, Tokyo 1010021, Japan.
EM duy.truong@aisin.co.jp
OI Bui, Minh-Quan/0000-0001-8511-7731
CR Akada H, 2022, IEEE WINT CONF APPL, P997, DOI 10.1109/WACV51458.2022.00107
   Atapour-Abarghouei A, 2018, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2018.00296
   Bengar JZ, 2019, IEEE INT CONF COMP V, P914, DOI 10.1109/ICCVW.2019.00120
   Bhat SF, 2021, PROC CVPR IEEE, P4008, DOI 10.1109/CVPR46437.2021.00400
   Bin Cheng, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P52, DOI 10.1007/978-3-030-58577-8_4
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Caesar Holger, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11618, DOI 10.1109/CVPR42600.2020.01164
   Chen X., 2021, IEEE C COMP VIS PATT, P3034
   Chen YC, 2019, PROC CVPR IEEE, P1791, DOI 10.1109/CVPR.2019.00189
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Deschaud J.-E., 2021, arXiv
   Eigen D, 2014, ADV NEUR IN, V27
   Finn C, 2017, PR MACH LEARN RES, V70
   Gaidon A, 2016, PROC CVPR IEEE, P4340, DOI 10.1109/CVPR.2016.470
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godard C, 2019, IEEE I CONF COMP VIS, P3827, DOI 10.1109/ICCV.2019.00393
   Guizilini V, 2020, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR42600.2020.00256
   Gurram A., 2021, arXiv
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 2001, LECT NOTES COMPUT SC, V2130, P87
   Hospedales T, 2022, IEEE T PATTERN ANAL, V44, P5149, DOI 10.1109/TPAMI.2021.3079209
   Jonschkowski Rico, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P557, DOI 10.1007/978-3-030-58536-5_33
   Kundu JN, 2018, PROC CVPR IEEE, P2656, DOI 10.1109/CVPR.2018.00281
   Kuznietsov Y, 2021, IEEE WINT CONF APPL, P2906, DOI 10.1109/WACV48630.2021.00295
   Lee Jin Han, 2019, arXiv
   Li D, 2018, AAAI CONF ARTIF INTE, P3490
   Lu XK, 2019, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2019.00374
   Mou Y., 2019, Learning depth from monocular videos using synthetic data: A temporally-consistent domain adaptation approach
   Nado Z, 2021, Arxiv, DOI arXiv:2006.10963
   Nie XS, 2023, IEEE T BIG DATA, V9, P312, DOI 10.1109/TBDATA.2022.3161905
   Qin ZY, 2023, IEEE-CAA J AUTOMATIC, V10, P1192, DOI 10.1109/JAS.2023.123456
   Saxena A, 2009, IEEE T PATTERN ANAL, V31, P824, DOI 10.1109/TPAMI.2008.132
   Schneider Steffen, 2020, Advances in Neural Information Processing Systems, V33
   Teed Zachary, 2020, EUR C COMP VIS, P402, DOI [DOI 10.1007/978-3-030-58536-524, DOI 10.1007/978-3-030-58536-5_24]
   Tonioni A, 2019, PROC CVPR IEEE, P9653, DOI 10.1109/CVPR.2019.00989
   Yang GR, 2019, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2019.00099
   Yu Tang, 2020, arXiv
   Zhang ZY, 2019, Arxiv, DOI arXiv:1904.08462
   Zhang ZY, 2020, PROC CVPR IEEE, P4493, DOI 10.1109/CVPR42600.2020.00455
   Zhao SS, 2019, PROC CVPR IEEE, P9780, DOI 10.1109/CVPR.2019.01002
   Zheng CX, 2018, LECT NOTES COMPUT SC, V11211, P798, DOI 10.1007/978-3-030-01234-2_47
   Zhou TH, 2017, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2017.700
NR 42
TC 3
Z9 3
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104871
DI 10.1016/j.imavis.2023.104871
EA DEC 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DU0O1
UT WOS:001134475400001
DA 2024-07-18
ER

PT J
AU Xu, R
   Huang, AB
   Hu, YJ
   Feng, XB
AF Xu, Rui
   Huang, Aibin
   Hu, Yuanjing
   Feng, Xibo
TI GFFT: Global-local feature fusion transformers for facial expression
   recognition in the wild
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Cross-patch communication; Self-attention
   mechanism; Transformers
AB Facial expression recognition in the wild has become more challenging owing to various unconstrained conditions, such as facial occlusion and pose variation. Previous methods usually recognize expressions by holistic or relatively coarse local methods, but only capture limited features and are susceptible to be influenced. In this paper, we propose the Global-local Feature Fusion Transformers (GFFT) that is centered on cross-patch communication between features by self-attentive fusion. This method solves the problems of facial occlusion and pose variation effectively. Firstly, the Global Contextual Information Perception (GCIP) is designed to fuse global and local features, learning the relationship between them. Subsequently, the Facial Salient Feature Perception (FSFP) module is proposed to guide the fusion features to understand the key regions of facial features using facial landmark features to further capture face-related salient features. In addition, the Multi-scale Feature Fusion (MFF) is constructed to combine different stages of fusion features to reduce the sensitivity of the deep network to facial occlusion. Extensive experiments show that our GFFT outperforms existing state-of-the-art methods with 92.05% on RAF-DB, 67.46% on AffectNet-7, 63.62% on AffectNet-8, and 91.04% on FERPlus, demonstrating its effectiveness and robustness.
C1 [Xu, Rui; Huang, Aibin; Hu, Yuanjing] Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou 310018, Peoples R China.
   [Xu, Rui; Huang, Aibin; Hu, Yuanjing] Hangzhou Dianzi Univ, Wenzhou Inst, Wenzhou 325038, Peoples R China.
   [Feng, Xibo] China Univ Geosci, Sch Comp Sci, Wuhan 430074, Hubei, Peoples R China.
C3 Hangzhou Dianzi University; Hangzhou Dianzi University; China University
   of Geosciences
RP Huang, AB (corresponding author), Hangzhou Dianzi Univ, Sch Media & Design, Hangzhou 310018, Peoples R China.
EM 211330017@hdu.edu.cn; huangaibin@hdu.edu.cn; 221330024@hdu.edu.cn;
   fengxb@cug.edu.cn
RI Huang, Aibin/S-5634-2019
OI Huang, Aibin/0000-0002-6126-0207
FU Natural Science Foundation of Zhejiang Province [Y4090224]
FX <B>Acknowledgements</B> This work was supported in part by the Natural
   Science Foundation of Zhejiang Province (No. Y4090224) .
CR Barsoum E, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P279, DOI 10.1145/2993148.2993165
   Cai J, 2018, IEEE INT CONF AUTOMA, P302, DOI 10.1109/FG.2018.00051
   Cao KD, 2019, ADV NEUR IN, V32
   Chen C., 2021, PyTorch face landmark: Fast and accurate facial landmark detector
   Chen DL, 2023, IEEE T CIRC SYST VID, V33, P3848, DOI 10.1109/TCSVT.2023.3234312
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Sang DV, 2018, 2018 1ST INTERNATIONAL CONFERENCE ON MULTIMEDIA ANALYSIS AND PATTERN RECOGNITION (MAPR)
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fan YR, 2018, LECT NOTES COMPUT SC, V11139, P84, DOI 10.1007/978-3-030-01418-6_9
   Farzaneh AH, 2021, IEEE WINT CONF APPL, P2401, DOI 10.1109/WACV48630.2021.00245
   Feng HQ, 2023, IEEE ACCESS, V11, P9995, DOI 10.1109/ACCESS.2023.3237817
   Foret P, 2021, Arxiv, DOI arXiv:2010.01412
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Happy SL, 2021, IMAGE VISION COMPUT, V105, DOI 10.1016/j.imavis.2020.104038
   Hasani B, 2017, IEEE COMPUT SOC CONF, P2278, DOI 10.1109/CVPRW.2017.282
   Hayale W, 2023, IEEE T AFFECT COMPUT, V14, P1148, DOI 10.1109/TAFFC.2021.3077248
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jeong M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124270
   Le N, 2022, NEURAL COMPUT APPL, V34, P21625, DOI 10.1007/s00521-021-06778-x
   Lee J, 2019, IEEE I CONF COMP VIS, P10142, DOI 10.1109/ICCV.2019.01024
   Li BB, 2019, IEEE IMAGE PROC, P4549, DOI [10.1109/ICIP.2019.8803604, 10.1109/icip.2019.8803604]
   Li CL, 2024, IEEE T CIRC SYST VID, V34, P882, DOI 10.1109/TCSVT.2023.3237006
   Li H., 2021, MVT: mask vision transformer for facial expression recognition in the wild
   Li HY, 2021, IEEE T IMAGE PROCESS, V30, P2016, DOI 10.1109/TIP.2021.3049955
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li Y., 2020, IEEE Trans. Affect. Comput.
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liu C, 2023, INFORM SCIENCES, V619, P781, DOI 10.1016/j.ins.2022.11.068
   Liu HW, 2022, IEEE T CIRC SYST VID, V32, P6253, DOI 10.1109/TCSVT.2022.3165321
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Ma F., 2021, arXiv
   Ma FY, 2023, IEEE T AFFECT COMPUT, V14, P1236, DOI 10.1109/TAFFC.2021.3122146
   Ma X, 2022, IMAGE VISION COMPUT, V127, DOI 10.1016/j.imavis.2022.104556
   Matsumoto D., 2008, Scholarpedia, V3, P4237, DOI DOI 10.4249/SCHOLARPEDIA.4237
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Pan XZ, 2020, IET IMAGE PROCESS, V14, P176, DOI 10.1049/iet-ipr.2019.0293
   Paszke A, 2019, ADV NEUR IN, V32
   Rosenberg Erika L., 2020, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Ruan DL, 2021, PROC CVPR IEEE, P7656, DOI 10.1109/CVPR46437.2021.00757
   Savchenko AV, 2022, IEEE T AFFECT COMPUT, V13, P2132, DOI 10.1109/TAFFC.2022.3188390
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Sharifnejad M, 2021, IET IMAGE PROCESS, V15, P468, DOI 10.1049/ipr2.12037
   She JH, 2021, PROC CVPR IEEE, P6244, DOI 10.1109/CVPR46437.2021.00618
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tong XY, 2022, IMAGE VISION COMPUT, V120, DOI 10.1016/j.imavis.2022.104399
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wen ZY, 2023, BIOMIMETICS-BASEL, V8, DOI 10.3390/biomimetics8020199
   Xue FL, 2023, IEEE T AFFECT COMPUT, V14, P3244, DOI 10.1109/TAFFC.2022.3226473
   Xue FL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3581, DOI 10.1109/ICCV48922.2021.00358
   Zeng D, 2022, PROC CVPR IEEE, P20259, DOI 10.1109/CVPR52688.2022.01965
   Zeng NY, 2018, NEUROCOMPUTING, V273, P643, DOI 10.1016/j.neucom.2017.08.043
   Zhao S., 2018, BMVC, V12
   Zhao ZQ, 2021, AAAI CONF ARTIF INTE, V35, P3510
   Zhao ZQ, 2021, IEEE T IMAGE PROCESS, V30, P6544, DOI 10.1109/TIP.2021.3093397
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Ziyang Zhang, 2011, 2011 4th International Congress on Image and Signal Processing (CISP 2011), P1544, DOI 10.1109/CISP.2011.6100452
NR 62
TC 3
Z9 3
U1 4
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104824
DI 10.1016/j.imavis.2023.104824
EA SEP 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA W0PR7
UT WOS:001088742600001
DA 2024-07-18
ER

PT J
AU Shah, RA
   Urmonov, O
   Kim, H
AF Shah, Rizwan Ali
   Urmonov, Odilbek
   Kim, Hyungwon
TI Two-stage coarse-to-fine image anomaly segmentation and detection model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Anomaly detection and segmentation; Convolutional neural network; Pseudo
   anomaly insertion; Superpixel segmentation
AB Existing Convolutional Neural Network (CNN) based anomaly detection and segmentation approaches are overly sensitive or not sensitive enough to noise, resulting in anomaly patterns, partially detected in the testing stage. The previous methods may also differentiate normal and abnormal images, but they cannot identify the location of anomaly presented in test images with high accuracy. To address this issue, we propose a two-stage CNN model for coarse-to-fine anomaly segmentation and detection called (TASAD). In both stages of TASAD, we train our model on a mixture of normal and abnormal training samples. The abnormal images are obtained by inserting pseudo-anomaly patterns that are automatically generated from anomaly source images. We use a novel and sophisticated anomaly insertion technique to generate various anomalous samples. In the first stage, we design a coarse anomaly segmentation (CAS) model that takes a whole image as an input, while in the second stage, we train a fine anomaly segmentation (FAS) model on image patches. FAS model improves detection and segmentation performance by refining anomaly patterns partially detected by CAS model. We train our framework on MVTec dataset and compare it with state-of-the-art (SOTA) methods. The proposed architecture leads to a compact model size - four times smaller than the SOTA method, while exhibiting better pixel-level accuracy. TASAD can also be applied to SOTAs to further improve their anomaly detection performance. Our experiments demonstrate that when applied to the latest SOTAs, TASAD improves the average precision (AP) performance of previous methods by 6.2%. For reproducibility of the results, code is provided at https://github.com/Riz wanAliQau/tasad.git.
C1 [Shah, Rizwan Ali; Kim, Hyungwon] Chungbuk Natl Univ, Dept Elect, Cheongju, South Korea.
   [Urmonov, Odilbek] MSISLAB Inc, Image Recognit Div, Cheongju, South Korea.
C3 Chungbuk National University
RP Kim, H (corresponding author), Chungbuk Natl Univ, Dept Elect, Cheongju, South Korea.
EM hwkim@chungbuk.ac.kr
FU National Research Foundation of Korea (NRF) - Korea government (MSIT)
   [2022R1A5A8026986]; Institute of Information & communications Technology
   Planning & Evaluation (IITP) - Korea government (MSIT) [2020-0-01304];
   MSIT (Ministry of Science and ICT) , Korea [IITP-2023-2020-0-01462]
FX This work was supported by the National Research Foundation of Korea
   (NRF) grant for RLRC funded by the Korea government (MSIT) (No.
   2022R1A5A8026986, RLRC) , and was also supported by Institute of
   Information & communications Technology Planning & Evaluation (IITP)
   grant funded by the Korea government (MSIT) (No.2020-0-01304,
   Development of Self-learnable Mobile Recursive Neural Network Processor
   Technology) . It was supported by the MSIT (Ministry of Science and ICT)
   , Korea, under the Grand Information Technology Research Center support
   program (IITP-2023-2020-0-01462, Grand-ICT) supervised by the IITP
   (Institute for Information & communications Technology Planning &
   Evaluation) .
CR Achanta R., 2010, SLIC Superpixels
   Akçay S, 2019, IEEE IJCNN, DOI 10.1109/ijcnn.2019.8851808
   Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   Alharbi A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11050756
   Bank D., 2020, AutoencodersMachine Learning for Data Science Handbook: Data Mining and Knowledge Discovery Handbook, P353
   Bergmann P, 2019, Arxiv, DOI arXiv:1807.02011
   Bergmann P, 2019, PROC CVPR IEEE, P9584, DOI 10.1109/CVPR.2019.00982
   Bozic J, 2021, COMPUT IND, V129, DOI 10.1016/j.compind.2021.103459
   Chandan G., 2018, 2018 INT C INVENTIVE, P1305
   Chen LY, 2022, NEURAL NETWORKS, V147, P53, DOI 10.1016/j.neunet.2021.12.008
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Defard Thomas, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12664), P475, DOI 10.1007/978-3-030-68799-1_35
   Guo JH, 2022, FUTURE INTERNET, V14, DOI 10.3390/fi14030086
   Han CHE, 2021, BMC BIOINFORMATICS, V22, DOI 10.1186/s12859-020-03936-1
   He KM, 2022, PROC CVPR IEEE, P15979, DOI 10.1109/CVPR52688.2022.01553
   Jung A., 2019, Readthedocs
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lagae A, 2010, COMPUT GRAPH FORUM, V29, P2579, DOI 10.1111/j.1467-8659.2010.01827.x
   Lee Y, 2022, IEEE ACCESS, V10, P46717, DOI 10.1109/ACCESS.2022.3171559
   Liang Y., 2023, IEEE Trans. Image Process.
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Kamoona AM, 2021, Arxiv, DOI arXiv:2108.12159
   Pang GS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439950
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Ristea NC, 2022, PROC CVPR IEEE, P13566, DOI 10.1109/CVPR52688.2022.01321
   Roth K, 2022, PROC CVPR IEEE, P14298, DOI 10.1109/CVPR52688.2022.01392
   Salehi M, 2021, PROC CVPR IEEE, P14897, DOI 10.1109/CVPR46437.2021.01466
   Sodemann AA, 2012, IEEE T SYST MAN CY C, V42, P1257, DOI 10.1109/TSMCC.2012.2215319
   Tsai C.-C., 2022, IEEE WINTER C APPL C, P3992
   Wang RY, 2020, PROCEEDINGS OF THE 13TH INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING (WSDM '20), P894, DOI 10.1145/3336191.3371876
   Xia X, 2022, NEUROCOMPUTING, V493, P497, DOI 10.1016/j.neucom.2021.12.093
   Yao W., 2022, arXiv
   Zavrtanik V, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8310, DOI 10.1109/ICCV48922.2021.00822
   Zavrtanik V, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107706
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
NR 35
TC 1
Z9 1
U1 2
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104817
DI 10.1016/j.imavis.2023.104817
EA SEP 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA T8VR8
UT WOS:001080712900001
DA 2024-07-18
ER

PT J
AU Krishnan, A
   Rattani, A
AF Krishnan, Anoop
   Rattani, Ajita
TI A novel approach for bias mitigation of gender classification algorithms
   using consistency regularization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fairness in AI; Facial analytics; Consistency regularization; Gender
   classification; Deep learning
AB Published research has confirmed the bias of automated face-based gender classification algorithms across gender-racial groups. Specifically, unequal accuracy rates were obtained for women and dark-skinned people for face-based automated gender classification algorithms. To mitigate the bias of gender classification and other facial-analysis-based algorithms in general, the vision community has proposed several techniques. However, most of the existing bias mitigation techniques suffer from a lack of generalizability, need a demographicallyannotated training set, are application-specific, and often offer a trade-off between fairness and classification accuracy. This means that fairness is often obtained at the cost of a reduction in the classification accuracy of the best-performing demographic sub-group. In this paper, we propose a novel bias mitigation technique that leverages the power of semantic preserving augmentations at the image- and feature-level in a self-consistency setting for the downstream gender classification task. Thorough experimental validation on gender-annotated facial image datasets confirms the efficacy of our bias mitigation technique in improving overall gender classification accuracy as well as reducing bias across all gender-racial groups over state-of-the-art bias mitigation techniques. Specifically, our proposed technique obtained a reduction in the bias by an average of 30% over existing bias mitigation techniques as well as an improvement in the overall classification accuracy of about 5% over the baseline gender classifier. Therefore, resulting in state-of-the-art generalization performance in the intra- and cross-dataset evaluations. Additionally, our proposed technique operates in the absence of demographic labels and is application agnostic, compared to most of the existing bias mitigation techniques.
C1 [Krishnan, Anoop; Rattani, Ajita] Wichita State Univ, Sch Comp, Wichita, KS USA.
   [Rattani, Ajita] Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76205 USA.
C3 Wichita State University; University of North Texas System; University
   of North Texas Denton
RP Rattani, A (corresponding author), Univ North Texas, Dept Comp Sci & Engn, Denton, TX 76205 USA.
EM axupendrannair@shockers.wichita.edu; ajita.rattani@unt.edu
FU National Science Foundation (NSF);  [2129173]
FX This work is supported in part by National Science Foundation (NSF)
   award No. 2129173.
CR Abdurrahim SH, 2018, VISUAL COMPUT, V34, P1617, DOI 10.1007/s00371-017-1428-z
   Albiero V, 2020, IEEE WINT CONF APPL, P81, DOI [10.1109/WACVW50321.2020.9096947, 10.1109/wacvw50321.2020.9096947]
   Almadan Ali, 2020, 2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA), P1036, DOI 10.1109/ICMLA51294.2020.00168
   Arjovsky, 2017, ARXIV170104862
   Assran Mahmoud, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P15619, DOI 10.1109/CVPR52729.2023.01499
   Balakrishnan Guha, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12363), P547, DOI 10.1007/978-3-030-58523-5_32
   Best-Rowden L, 2018, IEEE T PATTERN ANAL, V40, P148, DOI 10.1109/TPAMI.2017.2652466
   Buolamwini J., 2018, P 1 C FAIRNESS ACCOU, P77
   Chuang C., 2021, 9 INT C LEARNING REP, P15
   Cubuk E.D., 2020, ADV NEURAL INFORM PR, V33, P13
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Das A, 2019, LECT NOTES COMPUT SC, V11129, P573, DOI 10.1007/978-3-030-11009-3_35
   Dosovitskiy A., 2021, P INT C LEARNING REP, P22
   Englesson E., 2021, arXiv
   FaceX, 2022, FACEX FAC API
   Fuglede B, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, PROCEEDINGS, P31
   Girden E.R., 1992, ANOVA: Repeated Measures, V84
   Grill J., 2020, ADV NEURAL INFORM PR, V33, P35
   Grother P., 2010, Report on the evaluation of 2d still-image face recognition algorithms
   Gu J., 2022, 10 INT C LEARNING RE, P24
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang C., 2023, ICLR, P1
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang WR, 2022, Arxiv, DOI arXiv:2111.00743
   Izmailov P, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P876
   Jeong J, 2019, ADV NEUR IN, V32
   Kamishima Toshihiro, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P35, DOI 10.1007/978-3-642-33486-3_3
   K„rkk„inen K, 2019, Arxiv, DOI arXiv:1908.04913
   Kärkkäinen K, 2021, IEEE WINT CONF APPL, P1547, DOI 10.1109/WACV48630.2021.00159
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kaur R, 2023, INFORM FUSION, V97, DOI 10.1016/j.inffus.2023.101804
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kiruthika S., 2022, Computer Vision and Image Processing: 6th International Conference, CVIP 2021, Revised Selected Papers. Communications in Computer and Information Science (1568), P181, DOI 10.1007/978-3-031-11349-9_16
   Klare BF, 2012, IEEE T INF FOREN SEC, V7, P1789, DOI 10.1109/TIFS.2012.2214212
   Krishnan Anoop, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12668), P229, DOI 10.1007/978-3-030-68793-9_16
   Krishnan Anoop, 2020, 2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA), P1028, DOI 10.1109/ICMLA51294.2020.00167
   Krishnan A., 2022, ARXIV
   Krishnan A, 2021, INT CARN CONF SECU, DOI 10.1109/ICCST49569.2021.9717383
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li Y, 2019, PROC CVPR IEEE, P9564, DOI 10.1109/CVPR.2019.00980
   Lin XF, 2022, LECT NOTES COMPUT SC, V13673, P414, DOI 10.1007/978-3-031-19778-9_24
   M.A.C. Services, 2022, MICR AZ COGN SERV FA
   Majumdar P, 2021, IEEE INT CONF COMP V, P4116, DOI 10.1109/ICCVW54120.2021.00459
   Masood Sarfaraz, 2018, ADV INTELL SYST COMP, P217
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Miyato T., 2018, 6 INT C LEARNING REP
   Morales A, 2021, IEEE T PATTERN ANAL, V43, P2158, DOI 10.1109/TPAMI.2020.3015420
   Muthukumar V, 2019, IEEE COMPUT SOC CONF, P2286, DOI 10.1109/CVPRW.2019.00282
   Nadimpalli AV, 2022, Arxiv, DOI [arXiv:2207.10246, 10.48550/ARXIV.2207.10246]
   Nadimpalli AV, 2021, 2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2021), DOI 10.1109/SSCI50451.2021.9660182
   Ozcelik Y., 2023, CANKAYA INT C SCI, P1
   Park S, 2022, PROC CVPR IEEE, P10379, DOI 10.1109/CVPR52688.2022.01014
   Raji ID, 2019, AIES '19: PROCEEDINGS OF THE 2019 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY, P429, DOI 10.1145/3306618.3314244
   Ramachandran S, 2022, Arxiv, DOI [arXiv:2208.08382, 10.48550/arXiv.2208.08382]
   Ramaswamy VV, 2021, PROC CVPR IEEE, P9297, DOI 10.1109/CVPR46437.2021.00918
   Rekognition A., 2022, AM REK FAC API
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Salim N.R., 2021, 2021 IEEE MADRAS SEC, P1, DOI [10.1109/MASCON51689.2021.9563425, DOI 10.1109/MASCON51689.2021.9563425]
   Saunshi N, 2022, PR MACH LEARN RES, P19250
   Sensoy M, 2018, ADV NEUR IN, V31
   Siddiqui H, 2022, IEEE COMPUT SOC CONF, P2925, DOI 10.1109/CVPRW56347.2022.00330
   Singh R, 2022, AAAI CONF ARTIF INTE, P12351
   Tan C, 2022, PROC CVPR IEEE, P7234, DOI 10.1109/CVPR52688.2022.00710
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Teru K.K., 2019, ARXIV
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vera-Rodriguez R, 2019, IEEE COMPUT SOC CONF, P2254, DOI 10.1109/CVPRW.2019.00278
   Vision D., 2022, DEEP VIS FAC API
   Wightman Ross, 2023, Zenodo
   Yag I, 2022, BIOLOGY-BASEL, V11, DOI 10.3390/biology11121732
   Zhang BH, 2018, PROCEEDINGS OF THE 2018 AAAI/ACM CONFERENCE ON AI, ETHICS, AND SOCIETY (AIES'18), P335, DOI 10.1145/3278721.3278779
   Zhang K, 2017, IEEE ACCESS, V5, P22492, DOI 10.1109/ACCESS.2017.2761849
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zietlow D, 2022, PROC CVPR IEEE, P10400, DOI 10.1109/CVPR52688.2022.01016
NR 76
TC 1
Z9 1
U1 2
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104793
DI 10.1016/j.imavis.2023.104793
EA AUG 2023
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Q0SP1
UT WOS:001054703300001
DA 2024-07-18
ER

PT J
AU Boutros, F
   Struc, V
   Fierrez, J
   Damer, N
AF Boutros, Fadi
   Struc, Vitomir
   Fierrez, Julian
   Damer, Naser
TI Synthetic data for face recognition: Current state and future prospects
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Synthetic data; Biometrics
AB Over the past years, deep learning capabilities and the availability of large-scale training datasets advanced rapidly, leading to breakthroughs in face recognition accuracy. However, these technologies are foreseen to face a major challenge in the next years due to the legal and ethical concerns about using authentic biometric data in AI model training and evaluation along with increasingly utilizing data-hungry state-of-the-art deep learning models. With the recent advances in deep generative models and their success in generating realistic and high-resolution synthetic image data, privacy-friendly synthetic data has been recently proposed as an alternative to privacy-sensitive authentic data to overcome the challenges of using authentic data in face recognition development. This work aims at providing a clear and structured picture of the use-cases taxonomy of synthetic face data in face recognition along with the recent emerging advances of face recognition models developed on the bases of synthetic data. We also discuss the challenges facing the use of synthetic data in face recognition development and several future prospects of synthetic data in the domain of face recognition.(C) 2023 Elsevier B.V. All rights reserved.
C1 [Boutros, Fadi; Damer, Naser] Fraunhofer IGD, Fraunhoferstr 5, D-64283 Darmstadt, Hessia, Germany.
   [Damer, Naser] Tech Univ Darmstadt, Karolinenpl 5, D-64289 Darmstadt, Hessia, Germany.
   [Struc, Vitomir] Univ Ljubljana, Fac Elect Engn, Trzaska Cesta 25, Ljubljana 1000, Slovenia.
   [Fierrez, Julian] Univ Autonoma Madrid, Sch Engn, Madrid 28049, Spain.
C3 Technical University of Darmstadt; University of Ljubljana; Autonomous
   University of Madrid
RP Boutros, F (corresponding author), Fraunhofer IGD, Fraunhoferstr 5, D-64283 Darmstadt, Hessia, Germany.
EM fadi.boutros@igd.fraunhofer.de
FU German Federal Ministry of Education and Research; Hessian Ministry of
   Higher Education, Research, Science and the Arts within ARRS research
   program (B) Metrology and Biometrics Systems [P2-0250]; German Federal
   Ministry of Education and Research (BMBF) through the Software Campus
   Project; Hessian Ministry of Higher Education, Research, Science and the
   Arts within National Research Center for Applied Cybersecurity ATHENE
FX This research work has been funded by the German Federal Ministry of
   Education and Research and the Hessian Ministry of Higher Education,
   Research, Science and the Arts within their joint support of the
   National Research Center for Applied Cybersecurity ATHENE and the ARRS
   research program P2-0250 (B) Metrology and Biometrics Systems. This work
   has been partially funded by the German Federal Ministry of Education
   and Research (BMBF) through the Software Campus Project.
CR [Anonymous], 2021, ISO/IEC JTC1 SC37 Biometrics
   [Anonymous], 2016, Regulation (EU) 2016/679 of the European Parliament and of the Council of 27 April 2016 on the protection of natural persons with regard to the processing of personal data and on the free movement of such data, and repealing Directive 95/46/EC (General Data Protection Regulation) OJ L 119, DOI DOI 10.3390/BATTERIES5040068
   [Anonymous], 2018, 208892018 ISOIEC JTC
   Antoniadis I, 2020, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2020/04/033
   Bae Gwangbin, 2023, 2023 IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), P3515, DOI 10.1109/WACV56688.2023.00352
   Bansal Ankan, 2017, 2017 IEEE International Joint Conference on Biometrics (IJCB), P464, DOI 10.1109/BTAS.2017.8272731
   Bond-Taylor S, 2022, IEEE T PATTERN ANAL, V44, P7327, DOI 10.1109/TPAMI.2021.3116668
   Boutros Fadi, 2023, 2023 IEEE 17th International Conference on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG57933.2023.10042627
   Boutros F, 2022, 2022 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), DOI 10.1109/IJCB54206.2022.10007961
   Boutros F, 2022, INT C PATT RECOG, P855, DOI 10.1109/ICPR56361.2022.9955645
   Boutros F, 2022, IEEE COMPUT SOC CONF, P1577, DOI 10.1109/CVPRW56347.2022.00164
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Damer Naser, 2023, 2023 11th International Workshop on Biometrics and Forensics (IWBF), P1, DOI 10.1109/IWBF57495.2023.10157869
   Damer N, 2022, IEEE COMPUT SOC CONF, P1605, DOI 10.1109/CVPRW56347.2022.00167
   Damer N, 2018, INT CONF BIOMETR THE
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng Y, 2020, PROC CVPR IEEE, P5153, DOI 10.1109/CVPR42600.2020.00520
   Fang M., 2023, IEEECVF C COMPUTER V
   GDPR (General Data Protection Regulation), 2016, General Data Protection Regulation (GDPR)-Final Text Neatly Arranged
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   Haoyu Zhang, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P365, DOI 10.1109/TBIOM.2021.3072349
   Huber M, 2022, 2022 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), DOI 10.1109/IJCB54206.2022.10007950
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kobyzev I, 2021, IEEE T PATTERN ANAL, V43, P3964, DOI 10.1109/TPAMI.2020.2992934
   Kolf J.N., 2023, IEEECVF C COMPUTER V
   Kowalski Marek, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P299, DOI 10.1007/978-3-030-58621-8_18
   Mallat K, 2019, INT CONF BIOMETR, DOI 10.1109/icb45273.2019.8987347
   Meden B, 2021, IEEE T INF FOREN SEC, V16, P4147, DOI 10.1109/TIFS.2021.3096024
   Mirjalili V, 2019, IEEE ACCESS, V7, P99735, DOI 10.1109/ACCESS.2019.2924619
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Nech A, 2017, PROC CVPR IEEE, P3406, DOI 10.1109/CVPR.2017.363
   Nguyen HH, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), DOI 10.1109/ijcb48548.2020.9304893
   Kingma DP, 2014, Arxiv, DOI arXiv:1312.6114
   Parkhi O. M., 2015, P BRIT MACH VIS C, P41, DOI [10.5244/C.29.41, DOI 10.5244/C.29.41]
   Qiu HB, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10860, DOI 10.1109/ICCV48922.2021.01070
   Scherhag U., LNI
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sengupta S., 2016, 2016 IEEE WINT C APP, P1, DOI [DOI 10.1109/WACV.2016.7477558, 10.1109/WACV.2016.7477558]
   Shen YJ, 2022, IEEE T PATTERN ANAL, V44, P2004, DOI 10.1109/TPAMI.2020.3034267
   Shen YJ, 2018, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2018.00092
   Shoshan A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14063, DOI 10.1109/ICCV48922.2021.01382
   Sun Y, 2016, IEEE T PATTERN ANAL, V38, P1997, DOI 10.1109/TPAMI.2015.2505293
   Taigman Y, 2015, PROC CVPR IEEE, P2746, DOI 10.1109/CVPR.2015.7298891
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Terhorst P., LNI
   Terhorst P, 2022, 2022 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), DOI 10.1109/IJCB54206.2022.10007976
   The European Parliament and the Council of the European Union, 2016, EUROPEAN PARLIAMENT
   Tinsley P, 2021, IEEE WINT CONF APPL, P1319, DOI 10.1109/WACV48630.2021.00136
   Tolosana R, 2020, INFORM FUSION, V64, P131, DOI 10.1016/j.inffus.2020.06.014
   van den Oord A, 2016, PR MACH LEARN RES, V48
   Wang F, 2018, LECT NOTES COMPUT SC, V11213, P780, DOI 10.1007/978-3-030-01240-3_47
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Yaobin Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7728, DOI 10.1109/CVPR42600.2020.00775
   Yi D, 2014, Arxiv, DOI arXiv:1411.7923
   Zhang N., 2007, Tech. Rep. 07-49, P7
   Zheng T., 2017, ABS170808197 CORR, P97
   Zheng T., 2018, Tech. Rep., V5
   Zhu Z, 2021, PROC CVPR IEEE, P10487, DOI 10.1109/CVPR46437.2021.01035
NR 59
TC 21
Z9 21
U1 3
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104688
DI 10.1016/j.imavis.2023.104688
EA MAY 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA J9ZC9
UT WOS:001013125300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, J
   Wei, GY
   Sun, F
AF Zhang, Jing
   Wei, Guiyan
   Sun, Fang
TI Synthetic multi-view clustering with missing relationships and instances
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Synthetic multi-view data; Multi-view clustering; Auto-encoder;
   Knowledge distillation
AB Multi-view learning not only excavates the supplement information thoroughly, but also avoids noisy features and redundancies to improve down-stream tasks, e.g. Cluster, by constructing the fusing model. However, in practices, it is difficult to obtain complete multi-view data, which is summarized as both of Partially Sample -Missing Problem (PSP) originating from any view and Partially View-unaligned Problem (PVP). SURE (robust multi-view clustering with incomplete information) builds up the novel loss function to remove the noisy sam-ples in the embedding space and presents the aligning method to solve both of PVP and PSP. However, generated instances and relationships contain relatively little discriminate information and semantic consistency, more-over, it needs a large size of complete samples to pre-train. Aiming to above problems, we propose the novel framework (termed Synthetic Multi-view Data Clustering, SMDC). For PSP problem, we induce feature -distillation in each feature-map level to generate features containing more semantic information helping with the guidance of complete feature-maps, furthermore, exploits self-distillation to strengthen the discriminability information of deeper levels supervised from the contrastive constraint in the embedding space. Moreover, for PVP problem, we leverage attention mechanism to adaptively fuse multi-view features and auto-align instances located in different views. The proposed model is verified in images and video clustering tasks, respectively. Comparing with popular methods achieve satisfactory performances. The code of model is published in: https://github.com/LNNU-computer-research-526/SMDC.(c) 2023 Published by Elsevier B.V.
C1 [Zhang, Jing; Wei, Guiyan; Sun, Fang] Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Liaoning, Peoples R China.
C3 Liaoning Normal University
RP Sun, F (corresponding author), Liaoning Normal Univ, Sch Comp & Informat Technol, Dalian, Liaoning, Peoples R China.
EM zhangjing_0412@lnnu.edu.cn; sunfang@lnnu.edu.cn
FU National Science Foundation of China [61902165, 61976109]; Liaoning
   Provincial Department of Education fund [LJKMZ20221425]
FX This document is the results of the research project funded by National
   Science Foundation of China (No.61902165, No.61976109) ; Liaoning
   Provincial Department of Education fund (No. LJKMZ20221425) .
CR Acharya P, 2021, IEEE INT CONF COMP V, P1583, DOI 10.1109/ICCVW54120.2021.00183
   Bagherinezhad H, 2018, Arxiv, DOI arXiv:1805.02641
   Chao GQ, 2016, INFORM SCIENCES, V367, P296, DOI 10.1016/j.ins.2016.06.004
   Fang GF, 2022, AAAI CONF ARTIF INTE, P6597
   Fang ZY, 2021, Arxiv, DOI arXiv:2101.04731
   Guo J, 2019, AAAI CONF ARTIF INTE, P118
   Heo B, 2019, IEEE I CONF COMP VIS, P1921, DOI 10.1109/ICCV.2019.00201
   Hinton G., 2015, COMPUT SCI, V2
   Hu ML, 2019, AAAI CONF ARTIF INTE, P3838
   Huang Z., 2020, P ADV NEUR INF PROC, P2892
   Khan GA, 2022, INT J MACH LEARN CYB, V13, P233, DOI 10.1007/s13042-021-01394-6
   Li LS, 2023, IEEE T KNOWL DATA EN, V35, P589, DOI 10.1109/TKDE.2021.3082470
   Lin YJ, 2021, PROC CVPR IEEE, P11169, DOI 10.1109/CVPR46437.2021.01102
   Liu HW, 2017, IEEE T MULTIMEDIA, V19, P1848, DOI 10.1109/TMM.2017.2683258
   Liu HW, 2017, IEEE T CYBERNETICS, V47, P499, DOI 10.1109/TCYB.2016.2519683
   Liu YF, 2019, PROC CVPR IEEE, P2599, DOI 10.1109/CVPR.2019.00271
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   Qian B, 2022, LECT NOTES COMPUT SC, V13671, P449, DOI 10.1007/978-3-031-20083-0_27
   Ren PZ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2644
   Ren YZ, 2020, KNOWL-BASED SYST, V197, DOI 10.1016/j.knosys.2020.105841
   Romero Adriana, 2014, NEURAL EVOLUTIONARY
   Satyanarayana KV, 2022, MULTIDIM SYST SIGN P, V33, P301, DOI 10.1007/s11045-021-00800-0
   Singh S, 2021, EXPERT SYST APPL, V168, DOI 10.1016/j.eswa.2020.114264
   Suin M, 2021, IEEE J-STSP, V15, P162, DOI 10.1109/JSTSP.2020.3043622
   Tripathi AM, 2022, NEUROCOMPUTING, V489, P59, DOI 10.1016/j.neucom.2022.03.025
   Wang L, 2022, IEEE T PATTERN ANAL, V44, P3048, DOI 10.1109/TPAMI.2021.3055564
   Wang QQ, 2018, IEEE DATA MINING, P1290, DOI 10.1109/ICDM.2018.00174
   Wang Y, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3383-y
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408317
   Wang YH, 2016, IEEE INT SYM MULTIM, P14, DOI [10.1109/ISM.2016.0013, 10.1109/ISM.2016.64]
   Wei JW, 2022, IEEE T PATTERN ANAL, V44, P6534, DOI 10.1109/TPAMI.2021.3088863
   Wen J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3753, DOI 10.1145/3394171.3413807
   Xie XJ, 2020, IEEE T KNOWL DATA EN, V32, P2401, DOI 10.1109/TKDE.2019.2933511
   Xu C, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3933
   Xu J, 2022, P IEEECVF C COMPUTER, P16051
   Yang MX, 2023, IEEE T PATTERN ANAL, V45, P1055, DOI 10.1109/TPAMI.2022.3155499
   Yang MX, 2021, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR46437.2021.00119
   Yang X, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1, DOI 10.1145/3404835.3462823
   Yang X, 2018, IEEE T IMAGE PROCESS, V27, P791, DOI 10.1109/TIP.2017.2765836
   Yang X, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3089249
   Ye YK, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/6148456
   Yeung M, 1998, COMPUT VIS IMAGE UND, V71, P94, DOI 10.1006/cviu.1997.0628
   Zhang Z, 2019, IEEE T PATTERN ANAL, V41, P1774, DOI 10.1109/TPAMI.2018.2847335
   Zhou S., 2021, P IEEECVF INT C COMP, P10387
NR 44
TC 1
Z9 1
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2023
VL 134
AR 104669
DI 10.1016/j.imavis.2023.104669
EA APR 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA G4PO2
UT WOS:000988995400001
DA 2024-07-18
ER

PT J
AU Cascone, L
   Pero, C
   Proença, H
AF Cascone, Lucia
   Pero, Chiara
   Proenca, Hugo
TI Visual and textual explainability for a biometric verification system
   based on piecewise facial attribute analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Interpretable representation; Explainability; Feature extraction;
   Semantics; Facial attribute analysis
AB The decisions behind the mechanics of a biometric verification system based on Machine Learning (ML) are difficult to comprehend. Although there is now well-established research in various fields of application, such as health or justice, the use of ML-based methods is accompanied by a lack of confidence that results in their limited use. The explainability of a ML system and the comprehension of what lies behind its prediction is one of the numerous characteristics that define "trust" in these systems. Over the years, face-based biometric authen-tication has been the subject of extensive research in both academia and industry. However, existing biometric authentication systems still have problems regarding accuracy, robustness and, explainability. Still lacking in the literature is a comprehensive examination of the use of post-hoc explainability techniques for such systems. Cognitive neuroscience has always been interested in the method by which people perceive faces; local elements such as the nose, eyes, and mouth are critical to the perception and recognition of a face. In this work, starting from this assumption, we propose a framework of visual and textual explainability based on the parts of a face by analyzing them with respect to the facial attributes reported in the CelebA dataset. The primary objective is to be able to explain why two pictures of different subjects are distinct. This is done by sinthesizing pairs of images that illustrate how dissimilar the various parts of the face under investigation are and incisive and direct textual explanations of the distinguishing features are generated. A further study analyzes an interpretable mapping between the semantic space of the text and the space of the image. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Cascone, Lucia; Pero, Chiara] Univ Salerno, Dept Comp Sci, Fisciano, Italy.
   [Proenca, Hugo] Univ Beira Interior, Dept Comp Sci, IT Inst Telecomunicacoes, Covilha, Portugal.
C3 University of Salerno; Universidade da Beira Interior
RP Cascone, L (corresponding author), Univ Salerno, Dept Comp Sci, Fisciano, Italy.
EM lcascone@unisa.it; cpero@unisa.it
RI Cascone, Lucia/ABV-5620-2022; Proença, Hugo/F-9499-2010
OI Cascone, Lucia/0000-0002-9333-5699; Proença, Hugo/0000-0003-2551-8570
FU FCT/MCTES; EU [UIDB/EEA/50008/2020]
FX The contributions due to Hugo Proenca in this work were funded by
   FCT/MCTES through national funds and co-funded EU funds under the
   project UIDB/EEA/50008/2020.
CR Abate AF, 2020, 2020 IEEE INTL CONF ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, INTL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING, INTL CONF ON CLOUD AND BIG DATA COMPUTING, INTL CONF ON CYBER SCIENCE AND TECHNOLOGY CONGRESS (DASC/PICOM/CBDCOM/CYBERSCITECH), P601, DOI 10.1109/DASC-PICom-CBDCom-CyberSciTech49142.2020.00105
   Abate AF, 2020, IEEE ACCESS, V8, P9037, DOI 10.1109/ACCESS.2019.2962010
   Apley DW, 2020, J ROY STAT SOC B, V82, P1059, DOI 10.1111/rssb.12377
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Berrahal M., 2021, INDONES J ELECT ENG, V23
   Brito J, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10151861
   Carvalho DV, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080832
   Chung J., 2012, DEEP LEARNING UNSUPE, V3, P1
   da Cruz Brito J.P., 2021, THESIS U BEIRA INTER
   Duan MX, 2021, ACM T INTEL SYST TEC, V12, DOI 10.1145/3418285
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Lipton ZC., 2018, QUEUE, V16, P31, DOI 10.1145/3236386.3241340
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Lundberg SM, 2017, ADV NEUR IN, V30
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Molnar C., 2020, Interpretable machine learning.
   Molnar C, 2020, COMM COM INF SC, V1323, P417, DOI 10.1007/978-3-030-65965-3_28
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Rozsa A, 2016, IEEE COMPUT SOC CONF, P410, DOI 10.1109/CVPRW.2016.58
   Rudd EM, 2016, LECT NOTES COMPUT SC, V9909, P19, DOI 10.1007/978-3-319-46454-1_2
   Sethi A, 2019, PATTERN RECOGN LETT, V119, P157, DOI 10.1016/j.patrec.2018.03.010
   Wang J, 2016, PROC CVPR IEEE, P2295, DOI 10.1109/CVPR.2016.252
   Zheng X, 2020, INT J COMPUT VISION, V128, P2002, DOI 10.1007/s11263-020-01308-z
   Zhong Y, 2016, IEEE IMAGE PROC, P3239, DOI 10.1109/ICIP.2016.7532958
   Zhuang N, 2018, PATTERN RECOGN, V80, P225, DOI 10.1016/j.patcog.2018.03.018
NR 29
TC 0
Z9 0
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2023
VL 132
AR 104645
DI 10.1016/j.imavis.2023.104645
EA FEB 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA C9VZ6
UT WOS:000965324100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhu, F
   Xu, JY
   Yao, CM
AF Zhu, Feng
   Xu, Junyu
   Yao, Chuanming
TI Local information fusion network for 3D shape classification and
   retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D shape recognition; Attention mechanism; Local information
AB Due to the wide applications of 3D shapes, exploring effective 3D shape recognition algorithms has attracted much research attention. Various approaches have been proposed in recent years, within which the multi view based methods show their promising performances. Previous multi-view based methods mainly extract global features of views by employing the well-established CNN and then explore the correlations between the view-level descriptors for 3D shape representation. However, these approaches ignore the local characteristics extraction of view images. Besides, they also lack the consideration for the relationships between image regions and feature map channels, which could provide more detailed and descriptive information to improve the discrimination of shape descriptors. To address these issues, we propose a novel Local Information Fusion Network (LIFN) for local characteristics extraction and relationships exploration based on the feature maps during the convolution process. Concretely, the Region Organization Module (ROM) is introduced for feature map reorganization and region-wise feature extraction. Besides, the Region-wise Attention (RWA) and Channel-wise Attention (CWA) are designed for region-wise and channel-wise interaction exploration, respectively. Extensive experiments on the ModelNet40 database demonstrate the superiority of our proposed network against the state-of-the-art approaches. (c) 2022 Published by Elsevier B.V.
C1 [Zhu, Feng; Xu, Junyu; Yao, Chuanming] Nanjing Res Inst Elect Engn, Nanjing, Peoples R China.
RP Xu, JY (corresponding author), Nanjing Res Inst Elect Engn, Nanjing, Peoples R China.
EM xujunyu@cetc.com.cn
RI xu, junyu/AAR-6286-2021
CR Chen SL, 2019, IEEE T VIS COMPUT GR, V25, P3244, DOI 10.1109/TVCG.2018.2866793
   Feng Y., P IEEE C COMPUTER VI, P264
   Feng YT, 2019, AAAI CONF ARTIF INTE, P8279
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P3986, DOI 10.1109/TIP.2019.2904460
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P658, DOI 10.1109/TIP.2018.2868426
   He X., P IEEE INT C COMPUTE, P7515
   Jiang JW, 2019, AAAI CONF ARTIF INTE, P8513
   Klokov R., P IEEE INT C COMPUTE, P863
   Li J., P IEEE C COMPUTER VI, P9397
   Liu ZJ, 2019, ADV NEUR IN, V32
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Naffouti SE, 2017, SIGNAL PROCESS-IMAGE, V58, P228, DOI 10.1016/j.image.2017.07.005
   Nie W., IEEE T IMAGE PROCESS, V30, P4371
   Nie W., 2021, IEEE T CIRC SYST VID
   Papadimitriou G, 2022, CLUSTER COMPUT, V25, P2873, DOI 10.1007/s10586-021-03457-3
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Shen Y., P IEEE C COMPUTER VI, P4548
   Shi W., P IEEE C COMPUTER VI, P1874
   Su H., Proceedings of the IEEE International Conference on Computer Vision, 2015, P945
   Su Jong-Chyi, 2018, P EUR C COMP VIS ECC, P1
   Wang C, 2019, NEUROCOMPUTING, V323, P139, DOI 10.1016/j.neucom.2018.09.075
   Wu Z., P IEEE C COMPUTER VI, P1912
   Yu T., P IEEE C COMPUTER VI, P186
   Zhang Zhizheng., Proceedings of the ieee/cvf conference on computer vision and pattern recognition, P3186
NR 24
TC 6
Z9 7
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104405
DI 10.1016/j.imavis.2022.104405
EA MAR 2022
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0Z8MP
UT WOS:000791325900002
DA 2024-07-18
ER

PT J
AU Yang, XF
   Wang, QS
   Li, WK
   Zhou, ZH
   Li, HF
AF Yang, Xiaofeng
   Wang, Qianshan
   Li, Wenkuan
   Zhou, Zihao
   Li, Haifang
TI Unsupervised domain adaptation pedestrian re-identification based on an
   improved dissimilarity space
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Transfer learning; Cross-domain; Pedestrian re-identification; Maximum
   mean discrepancy; Dissimilarity space
ID PERSON REIDENTIFICATION
AB Pedestrian re-identification is a key and challenging research topic in intelligent security applications. Because of the need for large-scale manual labeling, pedestrian re-identification methods based on supervised learning can -not be widely used in practical applications. Research on unsupervised pedestrian re-identification has therefore become a hot topic. The DMMD model published in ECCV2020 successfully applied the dissimilarity space to un-supervised pedestrian re-identification. Based on the analysis of the deficiencies of DMMD, a new strong baseline model is composed, an improved dissimilarity space is constructed, a new transfer learning optimization method is proposed, and a time-space-appearance constraint is proposed. The test results show that the R1 accuracy of our model is improved by 21.4% compared with DMMD in the experiment from Market1501 to DukeMTMC.(c) 2021 Published by Elsevier B.V.
C1 [Yang, Xiaofeng; Wang, Qianshan; Li, Wenkuan; Li, Haifang] Taiyuan Univ Technol, Coll Informat & Comp, Yuci 030600, Peoples R China.
   [Yang, Xiaofeng] Shanxi Vocat Univ Engn Sci & Technol, Coll Comp Engn, Yuci 030600, Peoples R China.
   [Zhou, Zihao] Taiyuan Univ Technol, Coll Math, Yuci 030600, Peoples R China.
C3 Taiyuan University of Technology; Shanxi Vocational University of
   Engineering Science & Technology; Taiyuan University of Technology
RP Li, HF (corresponding author), Taiyuan Univ Technol, Coll Informat & Comp, Yuci 030600, Peoples R China.
EM 18817710@qq.com; lihaifang@tyut.edu.cn
RI zhou, zihao/IZD-6452-2023
FU National Natural Science Foundation of China [61873178, 61976150];
   Natural Science Foundation of Shanxi Province [201801D121135]; Key
   Research and Development Projects of Shanxi Province [201803D31038]; Key
   Research and Development Projects of Jinzhong City [Y192006]; CERNET
   Next Generation Internet Technology Innovation Project [NGII20181206];
   Domestic and Foreign Crop Yield Meteorology Forecast Special Project
   [RH19100004]
FX This work is partially supported by research grants from the National
   Natural Science Foundation of China (61873178, 61976150), Natural
   Science Foundation of Shanxi Province (201801D121135), Key Research and
   Development Projects of Shanxi Province (201803D31038), Key Research and
   Development Projects of Jinzhong City (Y192006), CERNET Next Generation
   Internet Technology Innovation Project (NGII20181206), and Domestic and
   Foreign Crop Yield Meteorology Forecast Special Project (RH19100004).
CR Chang XB, 2019, AAAI CONF ARTIF INTE, P3288
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ekladious G., IJCNN2020, P1
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Ge Yixiao, 2020, ARXIV200101526
   Guangyi Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P643, DOI 10.1007/978-3-030-58598-3_38
   Huang Y, 2021, INT J COMPUT VISION, V129, P2244, DOI 10.1007/s11263-021-01474-8
   Huang Y, 2019, IEEE I CONF COMP VIS, P9526, DOI 10.1109/ICCV.2019.00962
   Jianing Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P483, DOI 10.1007/978-3-030-58586-0_29
   Li HF, 2022, IEEE T CIRC SYST VID, V32, P2814, DOI 10.1109/TCSVT.2021.3099943
   Li HF, 2021, IEEE T INF FOREN SEC, V16, P1480, DOI 10.1109/TIFS.2020.3036800
   Li MX, 2020, IEEE T PATTERN ANAL, V42, P1770, DOI 10.1109/TPAMI.2019.2903058
   Li YJ, 2019, IEEE I CONF COMP VIS, P7918, DOI 10.1109/ICCV.2019.00801
   Li ZH, 2019, PATTERN RECOGN, V88, P595, DOI 10.1016/j.patcog.2018.12.010
   Li ZH, 2018, IEEE T NEUR NET LEAR, V29, P6073, DOI 10.1109/TNNLS.2018.2817538
   Li ZH, 2018, IEEE T NEUR NET LEAR, V29, P6323, DOI 10.1109/TNNLS.2018.2829867
   Lin S, 2021, IEEE T IMAGE PROCESS, V30, P1596, DOI 10.1109/TIP.2020.3046864
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Long M.S., 2014, TRANSFER LEARNINGPRO
   Luo C., ECCV2020, P224
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Mekhazni Djebril, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P159, DOI 10.1007/978-3-030-58583-9_10
   Ni TG, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.4.043026
   Qi L, 2019, IEEE I CONF COMP VIS, P8079, DOI 10.1109/ICCV.2019.00817
   Ren CX, 2020, IEEE T INF FOREN SEC, V15, P1290, DOI 10.1109/TIFS.2019.2939750
   Sch&rdquo B., NIPS2006, P512
   Snell J., 2017, ADV NEURAL INFORM PR, V30, P4077
   Song LC, 2020, PATTERN RECOGN, V102, DOI 10.1016/j.patcog.2019.107173
   Sun J, 2021, NEUROCOMPUTING, V440, P1, DOI 10.1016/j.neucom.2021.01.073
   Sun Q., NIPS2011, P505
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Tang YZ, 2020, IEEE T IMAGE PROCESS, V29, P5641, DOI 10.1109/TIP.2020.2985545
   Wang G., CVPR2020, P10568
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu AC, 2019, IEEE I CONF COMP VIS, P6921, DOI 10.1109/ICCV.2019.00702
   Yang Zou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P87, DOI 10.1007/978-3-030-58536-5_6
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yunpeng Zhai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9018, DOI 10.1109/CVPR42600.2020.00904
   Zhai Y., ECCV2020, P594
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhou SR, 2021, NEURAL COMPUT APPL, V33, P4001, DOI 10.1007/s00521-020-05566-3
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu ZQ, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103303
NR 52
TC 1
Z9 1
U1 1
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2022
VL 118
AR 104354
DI 10.1016/j.imavis.2021.104354
EA JAN 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0F3OZ
UT WOS:000777273700010
DA 2024-07-18
ER

PT J
AU Ali, U
   Bayramli, B
   Alsarhan, T
   Lu, HT
AF Ali, Usman
   Bayramli, Bayram
   Alsarhan, Tamam
   Lu, Hongtao
TI A lightweight network for monocular depth estimation with decoupled body
   and edge supervision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Monocular depth estimation; Deep learning; Lightweight network
AB Learning depth from a single image is a challenging task in computer vision. Many recent works on monocular depth estimation explore increasingly large convolutional neural networks to learn monocular cues implicitly. Such methods may fail to generalize well around object boundaries as large networks tend to distort the fine de-tails (such as edges and corners) in low-resolution layers, leading to a poor depth prediction near object edges. To reduce depth loss near object boundaries, this paper proposes to explicitly decouple depth features for the body and edges of objects corresponding to low and high-frequency regions of an image, respectively. To this end, we learn a flow field to warp depth features into consistent body features and residual edge features. Afterward, decoupled supervision is employed on both sets of features to learn body and edge depth maps explicitly. More -over, we also propose a lightweight encoder-decoder network that efficiently combines features at multiple scales to alleviate the loss of fine details in the final feature map. Extensive experiments on NYUD-v2 and KITTI datasets demonstrate that our proposed lightweight network with depth decoupling performs comparably to state-of-the-art methods while drastically reducing the number of parameters. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Ali, Usman; Bayramli, Bayram; Alsarhan, Tamam; Lu, Hongtao] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Lu, HT (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, Shanghai 200240, Peoples R China.
EM htlu@sjtu.edu.cn
FU NSFC [61772330, 61876109]; Shanghai Municipal Science and Technology
   Major Project [2021SHZDZX0102]; Shanghai Key Laboratory of Crime Scene
   Evi-dence [2017XCWZK01]; Interdisciplinary Program of Shanghai Jiao Tong
   University [YG2019QNA09]
FX This paper is supported by NSFC (No. 61772330, 61876109) , Shanghai
   Municipal Science and Technology Major Project (2021SHZDZX0102) , the
   Shanghai Key Laboratory of Crime Scene Evi-dence (no. 2017XCWZK01) , and
   the Interdisciplinary Program of Shanghai Jiao Tong University (no.
   YG2019QNA09) .
CR BERZINS V, 1984, COMPUT VISION GRAPH, V27, P195, DOI 10.1016/S0734-189X(84)80043-2
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen XT, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P694
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Eigen D, 2014, ADV NEUR IN, V27
   Fu H, 2018, PROC CVPR IEEE, P2002, DOI 10.1109/CVPR.2018.00214
   Gan YK, 2018, LECT NOTES COMPUT SC, V11207, P232, DOI 10.1007/978-3-030-01219-9_14
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Guizilini V, 2020, PROC CVPR IEEE, P2482, DOI 10.1109/CVPR42600.2020.00256
   Guizilini Vitor, 2020, 8 INT C LEARN REPR I
   Hao ZX, 2018, INT CONF 3D VISION, P304, DOI 10.1109/3DV.2018.00043
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu JJ, 2019, IEEE WINT CONF APPL, P1043, DOI 10.1109/WACV.2019.00116
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jiao JB, 2018, LECT NOTES COMPUT SC, V11219, P55, DOI 10.1007/978-3-030-01267-0_4
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuznietsov Y, 2017, PROC CVPR IEEE, P2215, DOI 10.1109/CVPR.2017.238
   Laina I, 2016, INT CONF 3D VISION, P239, DOI 10.1109/3DV.2016.32
   Lee JH, 2019, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR.2019.00996
   Levin A, 2004, ACM T GRAPHIC, V23, P689, DOI 10.1145/1015706.1015780
   Li J, 2017, IEEE I CONF COMP VIS, P3392, DOI 10.1109/ICCV.2017.365
   Li X., 2020, ECCV, P4
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu C, 2018, PROC CVPR IEEE, P2579, DOI 10.1109/CVPR.2018.00273
   Mendes RD, 2021, ROBOT AUTON SYST, V136, DOI 10.1016/j.robot.2020.103701
   Mousavian A, 2016, INT CONF 3D VISION, P611, DOI 10.1109/3DV.2016.69
   Paszke A, 2019, ADV NEUR IN, V32
   Qi XJ, 2018, PROC CVPR IEEE, P283, DOI 10.1109/CVPR.2018.00037
   Qi XJ, 2017, IEEE I CONF COMP VIS, P5209, DOI 10.1109/ICCV.2017.556
   Ramamonjisoa M, 2019, IEEE INT CONF COMP V, P2109, DOI 10.1109/ICCVW.2019.00266
   Ren H., P IEEE CVF C COMP VI, P37
   Saxena A., P 18 INT C NEUR INF, P1161
   Saxena A, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2197
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tan MX, 2019, PR MACH LEARN RES, V97
   ULLMAN S, 1979, PROC R SOC SER B-BIO, V203, P405, DOI 10.1098/rspb.1979.0006
   Wolk D, 2019, IEEE INT CONF ROBOT, P6101, DOI [10.1109/icra.2019.8794182, 10.1109/ICRA.2019.8794182]
   Yin W, 2019, IEEE I CONF COMP VIS, P5683, DOI 10.1109/ICCV.2019.00578
   Zhang ZY, 2019, PROC CVPR IEEE, P4101, DOI 10.1109/CVPR.2019.00423
   Zhu XZ, 2017, PROC CVPR IEEE, P4141, DOI 10.1109/CVPR.2017.441
NR 44
TC 1
Z9 3
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104261
DI 10.1016/j.imavis.2021.104261
EA AUG 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900004
DA 2024-07-18
ER

PT J
AU Garcia-Salguero, M
   Briales, J
   Gonzalez-Jimenez, J
AF Garcia-Salguero, Mercedes
   Briales, Jesus
   Gonzalez-Jimenez, Javier
TI Certifiable relative pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Relative pose; Essential matrix; Epipolar constraint; Convex
   programming; Certifiable algorithm; Linear Independence constraint
   qualification
ID ESSENTIAL MATRIX ESTIMATION; MATLAB TOOLBOX; OPTIMIZATION; ALGORITHM;
   MOTION; SPACE; SYNC
AB In this paper we present the first fast optimality certifier for the non-minimal version of the Relative Pose prob-lem for calibrated cameras from epipolar constraints. The proposed certifier is based on Lagrangian duality and relies on a novel closed-form expression for dual points. We also leverage an efficient solver that performs local optimization on the manifold of the original problem's non-convex domain. The optimality of the solution is then checked via our novel fast certifier. The extensive conducted experiments demonstrate that, despite its simplicity, this certifiable solver performs excellently on synthetic data, repeatedly attaining the (certified a posteriori) optimal solution and shows a satisfactory performance on real data.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Garcia-Salguero, Mercedes; Briales, Jesus; Gonzalez-Jimenez, Javier] Univ Malaga, Syst Engn & Automat Dept, Machine Percept & Intelligent Robot MAPIR Grp, Campus Teatinos, Malaga 29071, Spain.
C3 Universidad de Malaga
RP Garcia-Salguero, M (corresponding author), Univ Malaga, Syst Engn & Automat Dept, Machine Percept & Intelligent Robot MAPIR Grp, Campus Teatinos, Malaga 29071, Spain.
EM mercedesgarsal@uma.es; jesusbriales@uma.es; javiergonzalez@uma.es
RI Gonzalez-Jimenez, Javier/D-5774-2011
OI Garcia-Salguero, Mercedes/0000-0002-3382-5872
FU research projects WISER [DPI2017-84827-R]; University of Malaga; 
   [FPU18/01526]
FX This work was supported by the research projects WISER (DPI2017-84827-R)
   , as well as by the Spanish grant program FPU18/01526. The publication
   of this paper has been funded by the University of Malaga.
CR Absil PA, 2008, OPTIMIZATION ALGORITHMS ON MATRIX MANIFOLDS, P1
   Bandeira AS, 2016, CR MATH, V354, P329, DOI 10.1016/j.crma.2015.11.009
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Botterill T., 2011, Proceedings Image and Vision Computing New Zealand, P1
   Boumal N, 2014, J MACH LEARN RES, V15, P1455
   Boyd S., 2004, CONVEX OPTIMIZATION
   Briales J, 2018, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2018.00023
   Briales J, 2017, IEEE ROBOT AUTOM LET, V2, P2127, DOI 10.1109/LRA.2017.2718661
   Briales J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P4630, DOI 10.1109/IROS.2016.7759681
   Carlone L, 2015, IEEE INT C INT ROBOT, P125, DOI 10.1109/IROS.2015.7353364
   Carlone L, 2015, IEEE INT CONF ROBOT, P4589, DOI 10.1109/ICRA.2015.7139835
   Ding Y., 2007, THESIS
   FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gomez-Ojeda R, 2019, IEEE T ROBOT, V35, P734, DOI 10.1109/TRO.2019.2899783
   Grant MC, 2008, LECT NOTES CONTR INF, V371, P95, DOI 10.1007/978-1-84800-155-8_7
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Hartley RI, 2007, IEEE I CONF COMP VIS, P534
   Helmke U, 2007, INT J COMPUT VISION, V74, P117, DOI 10.1007/s11263-006-0005-0
   Kneip L, 2013, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2013.292
   Kukelova Z., 2008, BMVC, V2, P2008
   Kukelova Z, 2007, IEEE I CONF COMP VIS, P2816
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Lui V., 2013, BMVC
   Ma Y, 2001, INT J COMPUT VISION, V44, P219, DOI 10.1023/A:1012276232049
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Özyesil O, 2017, ACTA NUMER, V26, P305, DOI 10.1017/S096249291700006X
   Rosen DM, 2019, INT J ROBOT RES, V38, P95, DOI 10.1177/0278364918784361
   Schöps T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272
   Song SY, 2013, IEEE INT CONF ROBOT, P4698, DOI 10.1109/ICRA.2013.6631246
   Stewénius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005
   Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766
   Toh KC, 1999, OPTIM METHOD SOFTW, V11-2, P545, DOI 10.1080/10556789908805762
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Tron R, 2017, SIAM J IMAGING SCI, V10, P1416, DOI 10.1137/16M1091332
   Wachsmuth G, 2013, OPER RES LETT, V41, P78, DOI 10.1016/j.orl.2012.11.009
   Yamashita M, 2003, OPTIM METHOD SOFTW, V18, P491, DOI 10.1080/1055678031000118482
   Yang H., 2021, ARXIV200107715
   Yang JL, 2014, LECT NOTES COMPUT SC, V8689, P111, DOI 10.1007/978-3-319-10590-1_8
   Zhao J, 2020, IEEE T FUZZY SYST, V28, P2287, DOI 10.1109/TFUZZ.2019.2930492
NR 43
TC 12
Z9 12
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104142
DI 10.1016/j.imavis.2021.104142
EA MAR 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, P
   Wu, Q
   Yao, XX
   Xu, JS
AF Zhang, Peng
   Wu, Qiang
   Yao, Xunxiang
   Xu, Jingsong
TI Beyond modality alignment: Learning part-level representation for
   visible-infrared person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visible-infrared person re-identification; Modality alignment;
   Part-aware feature learning; Hierarchical modality discriminator
AB Visible-Infrared person re-IDentification (VI-reID) aims to automatically retrieve the pedestrian of interest exposed to sensors in different modalities, such as visible camera v.s. infrared sensor. It struggles to learn both modality-invariant and discriminant representations. Unfortunately, existing VI-reID work mainly focuses on tackling the modality difference, which fine-grained level discriminant information has not been well investigated. This causes inferior identification performance. To address the problem, we propose a Dual-Alignment Part-aware Representation (DAPR) framework to simultaneously alleviate the modality bias and mine different level of discriminant representations. Particularly, our DAPR reduces modality discrepancy of high-level features hierarchically by back-propagating reversal gradients from a modality classifier, in order to learn a modality invariant feature space. And meanwhile, multiple heads of classifiers with the improved part-aware BNNeck are integrated to supervise the network producing identity-discriminant representations w.r.t. both local details and global structures in the learned modality-invariant space. By training in an end-to-end manner, the proposed DAPR produces camera-modality-invariant yet discriminant features1 for the purpose of person matching across modalities. Extensive experiments are conducted on two benchmarks, i.e., SYSU MM01 and RegDB, and the results demonstrate the effectiveness of our proposed method. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Zhang, Peng] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
   [Zhang, Peng; Wu, Qiang; Yao, Xunxiang; Xu, Jingsong] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW, Australia.
C3 Shandong University of Science & Technology; University of Technology
   Sydney
RP Zhang, P (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao, Peoples R China.
EM pengzhang_skd@sdust.edu.cn
OI Wu, Qiang/0000-0001-5641-2483
CR [Anonymous], 2017, P ASM 36 INT C OC
   Chen WH, 2019, IEEE INT CONF BIG DA, P3623, DOI 10.1109/BigData47090.2019.9006513
   Cheng D, 2016, PROC CVPR IEEE, P1335, DOI 10.1109/CVPR.2016.149
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hao Y, 2019, AAAI CONF ARTIF INTE, P8385
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   Isola Phillip, 2016, ARXIV161107004, DOI [DOI 10.1109/CVPR.2017.632, 10.1109/CVPR.2017.632]
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Kansal K, 2020, IEEE T CIRC SYST VID, V30, P3422, DOI 10.1109/TCSVT.2019.2963721
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu K, 2015, IEEE I CONF COMP VIS, P3810, DOI 10.1109/ICCV.2015.434
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo H., 2019, P IEEE CVF C COMP VI
   Mang Ye, 2019, MM '19: Proceedings of the 27th ACM International Conference on Multimedia, P347, DOI 10.1145/3343031.3351043
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tian MQ, 2018, PROC CVPR IEEE, P5794, DOI 10.1109/CVPR.2018.00607
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Xiong K, 2014, NETW TELECOMMUN SER, P1, DOI 10.1002/9781118898598
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H., 2019, INT C MACHINE LEARNI, P12744, DOI DOI 10.48550/ARXIV.1805.08318
   Zhang P, 2020, IEEE T CIRC SYST VID, V30, P4554, DOI 10.1109/TCSVT.2019.2939564
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao R, 2017, IEEE T PATTERN ANAL, V39, P356, DOI 10.1109/TPAMI.2016.2544310
   Zheng Liang, 2016, ARXIV
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 49
TC 14
Z9 14
U1 3
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2021
VL 108
AR 104118
DI 10.1016/j.imavis.2021.104118
EA FEB 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RM7QN
UT WOS:000639853600001
DA 2024-07-18
ER

PT J
AU Chen, YF
   Wu, C
   Wang, YM
AF Chen, Yifeng
   Wu, Cheng
   Wang, Yiming
TI Whether normalized or not? Towards more robust iris recognition using
   dynamic programming
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris recognition; Dynamic programming; Partial convolution;
   Normalization
AB Iris recognition is one of the most promising fields in biometrics due to more accurate, convenient and low-cost. However, it is still a challenging task for application in practical complex scenarios. More attention have been paid on non-ideal iris segmentation and cross-system feature extraction in recent years. In order to solve the issues, this paper investigates a novel non-normalized preprocessing method based on dynamic path search for iris segmentation. Meanwhile, we employ a deep convolution network (DCNN) based on partial convolution operators to extract iris features. Through benchmark experiments on two public iris datasets CASIA-Iris-Thousand (CASIA) and IIT Delhi Iris Dataset (IITD), we achieve the significant and encouraging results, which demonstrate the effectiveness of the proposed methods. More importantly, we prove that using iris segmentation images without normalization may be a better choice when exploring iris recognition solutions based on deep learning. ? 2021 Elsevier B.V. All rights reserved.
C1 [Chen, Yifeng; Wu, Cheng; Wang, Yiming] Soochow Univ, Sch Rail Transportat, Suzhou 215137, Jiangsu, Peoples R China.
C3 Soochow University - China
RP Wu, C (corresponding author), Soochow Univ, Sch Rail Transportat, Suzhou 215137, Jiangsu, Peoples R China.
EM yfchen@stu.suda.edu.cn; cwu@suda.edu.cn; ymwang@suda.edu.cn
RI wang, yi/HOF-6668-2023; Wu, Cheng/AFP-6799-2022; Chen, yf/JMR-4435-2023
OI Wu, Cheng/0000-0001-5451-3045; yifeng, Chen/0000-0002-8161-0235
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   Chen R, 2011, IET IMAGE PROCESS, V5, P448, DOI 10.1049/iet-ipr.2009.0234
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Du YZ, 2011, IEEE T SYST MAN CY B, V41, P64, DOI 10.1109/TSMCB.2010.2045371
   Gangwar A, 2016, IEEE IMAGE PROC, P2301, DOI 10.1109/ICIP.2016.7532769
   Gangwar Abhishek, 2019, ARXIV PREPRINT ARXIV
   He ZF, 2009, IEEE T PATTERN ANAL, V31, P1670, DOI 10.1109/TPAMI.2008.183
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Liu GL, 2018, LECT NOTES COMPUT SC, V11215, P89, DOI 10.1007/978-3-030-01252-6_6
   Monro DM, 2007, IEEE T PATTERN ANAL, V29, P586, DOI 10.1109/TPAMI.2007.1002
   Nguyen K, 2018, IEEE ACCESS, V6, P18848, DOI 10.1109/ACCESS.2017.2784352
   Oprea S, 2017, ARXIV PREPRINT ARXIV
   Othman N, 2016, PATTERN RECOGN LETT, V82, P124, DOI 10.1016/j.patrec.2015.09.002
   Saminathan K., 2015, ICTACT Journal on Soft Computing, V5, P889
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Sutra G., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P310, DOI 10.1109/ICB.2012.6199825
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang K, 2019, IEEE T INF FOREN SEC, V14, P3233, DOI 10.1109/TIFS.2019.2913234
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001
   Zhao TM, 2019, IEEE ACCESS, V7, P49691, DOI 10.1109/ACCESS.2019.2911056
   Zhao Z, 2017, IEEE I CONF COMP VIS, P3829, DOI 10.1109/ICCV.2017.411
NR 25
TC 7
Z9 8
U1 2
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104112
DI 10.1016/j.imavis.2021.104112
EA FEB 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RD1DC
UT WOS:000633227000003
DA 2024-07-18
ER

PT J
AU Liu, LL
   Zhang, HJ
   Zhou, DL
AF Liu, Linlin
   Zhang, Haijun
   Zhou, Dongliang
TI Clothing generation by multi-modal embedding: A compatibility
   matrix-regularized GAN model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-modal embedding; Compatibility learning; Generative adversarial
   network; Image translation; Fashion data
ID IMAGE SYNTHESIS
AB Clothing compatibility learning has gained increasing research attention due to the fact that a properly coordinated outfit can represent personality and improve an individual's appearance greatly. In this paper, we propose a Compatibility Matrix-Regularized Generative Adversarial Network (CMRGAN) for compatible item generation. In particular, we utilize a multi-modal embedding to transform the image and text information of an input clothing item into a latent feature code. Sequentially, compatibility learning among latent features is performed to obtain a compatibility style space. The feature of the input image is then regularized by the style space. Finally, a compatible clothing image is generated by a decoder which is fed by the regularized features. To verify the proposed model, we train an Inception-v3 classification model to evaluate the authenticity of synthesized images, a regression scoring VGG model to measure the compatibility degree of the generated image pairs and a deep attentional multimodal similarity model to evaluate the semantic similarity between generated images and ground truth text descriptions. In order to give an objective evaluation, these models are trained based on datasets consisting of fashion data only. The results demonstrate the effectiveness of the proposed method on image to-image translation based on compatibility space.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Linlin; Zhang, Haijun; Zhou, Dongliang] Harbin Inst Technol, Dept Comp Sci, Shenzhen 518055, Peoples R China.
C3 Harbin Institute of Technology
RP Zhang, HJ (corresponding author), Harbin Inst Technol, Dept Comp Sci, Shenzhen 518055, Peoples R China.
EM hjzhang@hit.edu.cn
RI Zhang, Haijun/N-8470-2015; Zhou, Dongliang/AAY-4577-2021
OI Zhou, Dongliang/0000-0003-0361-8597
FU National Key R&D Program of China [2018YFB1003800, 2018YFB1003805];
   National Natural Science Foundation of China [61972112, 61832004];
   Shenzhen Science and Technology Program [JCYJ2010413105929681, JCYJ2017
   0811161545863]
FX This work was supported in part by the National Key R&D Program of China
   under Grant no. 2018YFB1003800, 2018YFB1003805, the National Natural
   Science Foundation of China under Grant no. 61972112 and no. 61832004,
   and the Shenzhen Science and Technology Program under Grant no.
   JCYJ2010413105929681 and no. JCYJ2017 0811161545863.
CR Ak KE, 2019, IEEE I CONF COMP VIS, P10540, DOI 10.1109/ICCV.2019.01064
   AlBahar B, 2019, IEEE I CONF COMP VIS, P9015, DOI 10.1109/ICCV.2019.00911
   [Anonymous], 2017, Advances in neural information processing systems
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Balakrishnan G, 2018, PROC CVPR IEEE, P8340, DOI 10.1109/CVPR.2018.00870
   Che T., 2017, ARXIV PREPRINT
   Chen W, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2662, DOI 10.1145/3292500.3330652
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chou C. T., 2018, AS C COMP VIS, P654
   Gao GY, 2019, MULTIMEDIA SYST, V25, P593, DOI 10.1007/s00530-019-00617-9
   Han XT, 2018, PROC CVPR IEEE, P7543, DOI 10.1109/CVPR.2018.00787
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hsiao WL, 2019, IEEE I CONF COMP VIS, P5046, DOI 10.1109/ICCV.2019.00515
   Hu D, 2016, PROC CVPR IEEE, P3574, DOI 10.1109/CVPR.2016.389
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Gulrajani I, 2017, ADV NEUR IN, V30
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiang SH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3721
   Kim T, 2017, PR MACH LEARN RES, V70
   Lassner C, 2017, IEEE I CONF COMP VIS, P853, DOI 10.1109/ICCV.2017.98
   Lee H, 2019, IEEE WINT CONF APPL, P462, DOI 10.1109/WACV.2019.00055
   Lee HY, 2018, LECT NOTES COMPUT SC, V11205, P36, DOI 10.1007/978-3-030-01246-5_3
   Li YC, 2017, IEEE T MULTIMEDIA, V19, P1946, DOI 10.1109/TMM.2017.2690144
   Lin JX, 2018, PROC CVPR IEEE, P5524, DOI 10.1109/CVPR.2018.00579
   Liu LL, 2020, IEEE T NEUR NET LEAR, V31, P3540, DOI 10.1109/TNNLS.2019.2944979
   Liu ZW, 2016, PROC CVPR IEEE, P1096, DOI 10.1109/CVPR.2016.124
   Ma LQ, 2017, ADV NEUR IN, V30
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Ngiam J., 2011, IEEE INT C MACH LEAR, P689, DOI DOI 10.5555/3104482.3104569
   Odena A, 2017, PR MACH LEARN RES, V70
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Pumarola A, 2018, PROC CVPR IEEE, P8620, DOI 10.1109/CVPR.2018.00899
   Raj A, 2018, LECT NOTES COMPUT SC, V11216, P679, DOI 10.1007/978-3-030-01258-8_41
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salimans T, 2016, ADV NEUR IN, V29
   Tomei M, 2019, PROC CVPR IEEE, P5842, DOI 10.1109/CVPR.2019.00600
   Wang BC, 2018, LECT NOTES COMPUT SC, V11217, P607, DOI 10.1007/978-3-030-01261-8_36
   Wang M, 2019, PROC CVPR IEEE, P1495, DOI 10.1109/CVPR.2019.00159
   Wang T., 2018, ARXIV
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wu MK, 2018, ADV NEUR IN, V31
   Wu PW, 2019, IEEE I CONF COMP VIS, P5913, DOI 10.1109/ICCV.2019.00601
   Xian WQ, 2018, PROC CVPR IEEE, P8456, DOI 10.1109/CVPR.2018.00882
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yang S., 2016, Detailed garment recovery from a single-view image
   Yi ZL, 2017, IEEE I CONF COMP VIS, P2868, DOI 10.1109/ICCV.2017.310
   Zanfir M, 2018, PROC CVPR IEEE, P5391, DOI 10.1109/CVPR.2018.00565
   Zhang B, 2019, PROC CVPR IEEE, P8044, DOI 10.1109/CVPR.2019.00824
   Zhang HJ, 2020, IEEE T IND INFORM, V16, P6750, DOI 10.1109/TII.2019.2924725
   Zhang P, 2020, PROC CVPR IEEE, P5142, DOI 10.1109/CVPR42600.2020.00519
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu SZ, 2017, IEEE I CONF COMP VIS, P1689, DOI 10.1109/ICCV.2017.186
   Zhu YC, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P130, DOI 10.1145/3343031.3350997
NR 54
TC 4
Z9 5
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104097
DI 10.1016/j.imavis.2021.104097
EA JAN 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RD1DC
UT WOS:000633227000005
DA 2024-07-18
ER

PT J
AU Fang, ML
   Damer, N
   Boutros, F
   Kirchbuchner, F
   Kuijper, A
AF Fang, Meiling
   Damer, Naser
   Boutros, Fadi
   Kirchbuchner, Florian
   Kuijper, Arjan
TI Cross-database and cross-attack Iris presentation attack detection using
   micro stripes analyses
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Iris presentation attack detection; Cross-domain; Deep learning
AB With the widespread use of mobile devices, iris recognition systems encounter more challenges, such as the vulnerability of Presentation Attack Detection (PAD). Recent works pointed out the contact lens attacks, especially images captured under the uncontrolled environment, as a hard task for iris PAD. In this paper, we propose a novel framework for detecting iris presentation attacks that especially for detecting contact lenses based on the normalized multiple micro stripes. The classification decision is made by the majority vote of those microstripes. An in-depth experimental evaluation of this framework reveals a superior performance in three databases compared with state-of-the-art (SoTA) algorithms and baselines. Moreover, our solution minimizes the confusion between textured (attack) and transparent (bona fide) presentations in comparison to SoTA methods. We support the rationalization of our proposed method by studying the significance of different pupil-centered eye areas in iris PAD decisions under different experimental settings. In addition, extensive cross-database and cross-attack (unknown attack) detection evaluation experiments are demonstrated to explore the generalizability of our proposed method, texture-based method, and neural network based methods in three different databases. The results indicate that our Micro Stripes Analyses (MSA) method has, in most experiments, better generalizability compared to other baselines. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Fang, Meiling; Damer, Naser; Boutros, Fadi; Kirchbuchner, Florian; Kuijper, Arjan] Fraunhofer Inst Comp Graph Res IGD, Darmstadt, Germany.
   [Fang, Meiling; Damer, Naser; Boutros, Fadi; Kirchbuchner, Florian; Kuijper, Arjan] Tech Univ Darmstadt, Math & Appl Visual Comp, Darmstadt, Germany.
C3 Fraunhofer Gesellschaft; Technical University of Darmstadt
RP Damer, N (corresponding author), Fraunhofer Inst Comp Graph Res IGD, Darmstadt, Germany.
EM naser.damer@igd.fraunhofer.de
RI Fang, Meiling/IQS-5428-2023; Kirchbuchner, Florian/B-8982-2017
OI Kirchbuchner, Florian/0000-0003-3790-3732
FU German Federal Ministry of Education and Research of the National
   Research Center for Applied Cybersecurity ATHENE; Hessen StateMinistry
   for Higher Education, Research and the Arts within the National Research
   Center for Applied Cybersecurity ATHENE
FX This research work has been funded by the German Federal Ministry of
   Education and Research and the Hessen StateMinistry for Higher
   Education, Research and the Artswithin their joint support of the
   National Research Center for Applied Cybersecurity ATHENE.
CR [Anonymous], IEEE Int. Conf. on Biometrics, DOI [DOI 10.1109/ICB.2013.6613021, 10.1109/ICB]
   [Anonymous], 2017, ISO/IEC DIS 30107-3:2016
   Baker SE, 2010, COMPUT VIS IMAGE UND, V114, P1030, DOI 10.1016/j.cviu.2010.06.002
   Boutros Fadi, 2019, IEEE INT C COMP VIS
   Chen CJ, 2018, IEEE WINT CONF APPL, P44, DOI 10.1109/WACVW.2018.00011
   Czajka A, 2019, IEEE WINT CONF APPL, P877, DOI 10.1109/WACV.2019.00098
   Czajka A, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3232849
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Doyle JS, 2015, IEEE ACCESS, V3, P1672, DOI 10.1109/ACCESS.2015.2477470
   Ferrer-Cid P, 2019, IEEE INTERNET THINGS, V6, P9563, DOI 10.1109/JIOT.2019.2929594
   Gragnaniello D, 2015, PATTERN RECOGN LETT, V57, P81, DOI 10.1016/j.patrec.2014.10.018
   Gupta P, 2014, INT C PATT RECOG, P1681, DOI 10.1109/ICPR.2014.296
   Hoffman S, 2019, INT CONF BIOMETR
   Hoffman S, 2018, IEEE COMPUT SOC CONF, P1701, DOI 10.1109/CVPRW.2018.00213
   Holst A., 2019, SMARTPHONE USERS WOR
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Hsieh SH, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030795
   Hui Zhang, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4279, DOI 10.1109/ICPR.2010.1040
   Kimura GY, 2020, PROCEEDINGS OF THE 15TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS, VOL 5: VISAPP, P428, DOI 10.5220/0008983904280434
   Kohli N., 2016, IEEE Int. Conf. on Biometrics: Theory Applications and Systems (BTAS), P1, DOI DOI 10.1109/BTAS.2016.7791168
   Kuehlkamp A, 2019, IEEE T INF FOREN SEC, V14, P1419, DOI 10.1109/TIFS.2018.2878542
   Lee EC, 2006, LECT NOTES COMPUT SC, V3832, P397
   Lee SJ, 2007, OPT ENG, V46, DOI 10.1117/1.2815719
   Mandalapu Hareesh., 2019, ACM Int. Conf. Proceeding Series, P7, DOI DOI 10.1145/3345336.3345341
   McGrath J., 2018, CORR
   Raghavendra R, 2017, IEEE WINT CONF APPL, P1160, DOI 10.1109/WACV.2017.134
   Raghavendra R, 2015, IEEE T INF FOREN SEC, V10, P703, DOI 10.1109/TIFS.2015.2400393
   Rathgeb C, 2016, EURASIP J INF SECUR, DOI 10.1186/s13635-016-0049-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Yadav D, 2019, IEEE COMPUT SOC CONF, P2336, DOI 10.1109/CVPRW.2019.00287
   Yadav D, 2018, IEEE COMPUT SOC CONF, P685, DOI 10.1109/CVPRW.2018.00099
   Yadav D, 2018, IEEE WINT CONF APPL, P503, DOI 10.1109/WACV.2018.00061
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
   Yambay D, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P733, DOI 10.1109/BTAS.2017.8272763
   Yambay D, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY AND BEHAVIOR ANALYSIS (ISBA)
NR 35
TC 12
Z9 12
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104057
DI 10.1016/j.imavis.2020.104057
EA JAN 2021
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800006
DA 2024-07-18
ER

PT J
AU Jain, DK
   Lan, XY
   Manikandan, R
AF Jain, Deepak Kumar
   Lan, Xiangyuan
   Manikandan, Ramachandran
TI Fusion of iris and sclera using phase intensive rubbersheet mutual
   exclusion for periocular recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Phase intensive; Rubbersheeting; Local pattern extraction; Mutual
   exclusive; Bayesian; Distributed hamming distance template matching
   (DHDTM)
ID EYE-MOVEMENT; BIOMETRICS
AB In biometrics, periocular recognition analysis is an essential constituent for identifying the human being. Among prevailing the modalities, ocular biometric traits such as iris, sclera and periocular eye movement have experienced noteworthy consciousness in the recent past. In this paper, we are presenting new multi-biometric fusion method called Phase Intensive Mutual Exclusive Distribution (PI-MED) method by combining periocular features (i.e. iris and sclera) for identity verification. The main objective of the proposed PI-MED method is to reduce the matching fusion time and overhead during human recognition in biometrics. Initially, iris modality and sclera modality is pre-processed using Phase Intensive Rubber Sheeting Local Pattern Extraction to generate the vector of score. After that, the extracted iris and sclera features are given to theMutual Exclusive Bayesian fusionmodel. The fusion model is applied at the score level for reducing fusion overhead. In this model, feature fusion is generated based on the log likelihood ratio by using covariance matrix measurement. Finally with fusion features, Distributed Hamming Distance Template Matching (DHDTM) algorithm is designed to evaluate the recognition rate of test data with available training data. The results show that the DHDTMsignificantly improves the recognition rate of human biometric sampleswhen compared to the conventional person identification methods. Several testswere conducted to evaluate the performance of the proposedmethods of standard biometric databases using three metrics, namely, matching fusion time, overhead and true positive rate. From the experimental results, the proposed PI-MEDmethod reduces thematching fusion time and overhead by 47% and 45% when compared to existingmethods. Similarly, the proposed PI-MED method increases the true positive rate by 33% when compared to existing methods. (c) 2020 Published by Elsevier B.V.
C1 [Jain, Deepak Kumar] Chongqing Univ Posts & Telecommun, Key Lab Intelligent Air Ground Cooperat Control U, Coll Automat, Chongqing, Peoples R China.
   [Lan, Xiangyuan] HongKong Bapist Univ, Dept Comp Sci, Hong Kong, Peoples R China.
   [Manikandan, Ramachandran] SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
C3 Chongqing University of Posts & Telecommunications; Shanmugha Arts,
   Science, Technology & Research Academy (SASTRA)
RP Jain, DK (corresponding author), Chongqing Univ Posts & Telecommun, Key Lab Intelligent Air Ground Cooperat Control U, Coll Automat, Chongqing, Peoples R China.
EM deepak@cqupt.edu.cn; lanxiangyuan@comp.hkbu.edu.hk; srmanimt75@gmail.com
RI Ramachandran, Manikandan/B-2783-2014; Lan, Xiangyuan/F-8034-2018
OI Ramachandran, Manikandan/0000-0001-6116-2132; 
CR Akdogan D, 2019, COMPUT NETW, V163, DOI 10.1016/j.comnet.2019.106885
   Al-Waisy AS, 2018, PATTERN ANAL APPL, V21, P783, DOI 10.1007/s10044-017-0656-1
   Alemu LT, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103862
   Cardoso L, 2013, IEEE T INF FOREN SEC, V8, P1115, DOI 10.1109/TIFS.2013.2262942
   Crihalmeanu S, 2012, PATTERN RECOGN LETT, V33, P1860, DOI 10.1016/j.patrec.2011.11.006
   Goel A., 2019, IJITEE, V8, P912, DOI [10.35940/ijitee.I1147.0789S19, DOI 10.35940/IJITEE.I1147.0789S19]
   James AP, 2014, INFORM FUSION, V19, P4, DOI 10.1016/j.inffus.2013.12.002
   Juefei-Xu F, 2015, IEEE T IMAGE PROCESS, V24, P4780, DOI 10.1109/TIP.2015.2468173
   Kasprowski P, 2018, PATTERN ANAL APPL, V21, P91, DOI 10.1007/s10044-016-0568-5
   Khan Z, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2020.103871
   Lv JY, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103875
   Mukhopadhyay S, 2018, MACH LEARN, V107, P313, DOI 10.1007/s10994-017-5649-1
   Murakami T, 2019, PATTERN RECOGN LETT, V126, P11, DOI 10.1016/j.patrec.2018.04.005
   Nigam I, 2015, INFORM FUSION, V26, P1, DOI 10.1016/j.inffus.2015.03.005
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Peixoto SA, 2020, IMAGE VISION COMPUT, V96, DOI 10.1016/j.imavis.2020.103899
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Selwal A., 2016, PERSPECT SCI, V8, P705, DOI DOI 10.1016/j.pisc.2016.06.065
   Tapia JE, 2019, FUTURE GENER COMP SY, V97, P503, DOI 10.1016/j.future.2019.03.023
   Trokielewicz M, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103866
   Umer S, 2020, NEURAL NETWORKS, V122, P407, DOI 10.1016/j.neunet.2019.11.009
   Wang Z, 2018, IEEE ACCESS, V6, P17905, DOI 10.1109/ACCESS.2018.2812208
   Wild P, 2016, PATTERN RECOGN, V50, P17, DOI 10.1016/j.patcog.2015.08.007
   Zhao ZJ, 2018, IEEE T INF FOREN SEC, V13, P2937, DOI 10.1109/TIFS.2018.2833018
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
NR 25
TC 11
Z9 11
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104024
DI 10.1016/j.imavis.2020.104024
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000013
DA 2024-07-18
ER

PT J
AU Sharma, A
   Anand, S
   Kaul, SK
AF Sharma, Anil
   Anand, Saket
   Kaul, Sanjit K.
TI Intelligent querying for target tracking in camera networks using deep
   Q-learning with n-step bootstrapping
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camera networks; Deep reinforcement learning; Target tracking;
   Multi-camera tracking
ID MULTITARGET
AB Surveillance camera networks are a useful infrastructure for various visual analytics applications, where highlevel inferences and predictions could be made based on target tracking across the network. Most multicamera tracking works focus on target re-identification and trajectory association problems to track the target. However, since camera networks can generate enormous amount of video data, inefficient schemes for making re-identification or trajectory association queries can incur prohibitively large computational requirements. In this paper, we address the problemof intelligent scheduling of re-identification queries in a multi-camera tracking setting. To this end, we formulate the target tracking problem in a camera network as anMDP and learn a reinforcement learning based policy that selects a camera for making a re-identification query. The proposed approach to camera selection does not assume the knowledge of the camera network topology but the resulting policy implicitly learns it. We have also shown that such a policy can be learnt directly from data. Using the NLPR MCT and the Duke MTMC multi-camera multi-target tracking benchmarks, we empirically show that the proposed approach substantially reduces the number of frames queried. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Sharma, Anil; Anand, Saket; Kaul, Sanjit K.] Indraprastha Inst Informat Technol IIIT Delhi, Delhi, India.
C3 Indraprastha Institute of Information Technology Delhi
RP Sharma, A (corresponding author), Indraprastha Inst Informat Technol IIIT Delhi, Delhi, India.
EM anils@iiitd.ac.in
OI Kaul, Sanjit Krishnan/0000-0001-5867-8584
FU Infosys Center for Artificial Intelligence (CAI) at IIIT-Delhi
FX We acknowledge Infosys Center for Artificial Intelligence (CAI) at
   IIIT-Delhi for its partial support for conducting this research work.
CR [Anonymous], MULTICAMERA OBJECT T
   [Anonymous], 2005, International Conference on Machine Learning ICML, DOI DOI 10.1145/1102351.1102433
   BELLMAN R, 1957, J MATH MECH, V6, P679, DOI 10.1512/iumj.1957.6.56038
   Cai YH, 2014, IEEE WINT CONF APPL, P761, DOI 10.1109/WACV.2014.6836026
   Chari V, 2015, PROC CVPR IEEE, P5537, DOI 10.1109/CVPR.2015.7299193
   Chen KW, 2011, IEEE T MULTIMEDIA, V13, P625, DOI 10.1109/TMM.2011.2131639
   Chen WH, 2017, IEEE T CIRC SYST VID, V27, P2367, DOI 10.1109/TCSVT.2016.2589619
   Chen WH, 2014, IEEE IMAGE PROC, P2329, DOI 10.1109/ICIP.2014.7025472
   Chen XJ, 2017, IEEE T CIRC SYST VID, V27, P2382, DOI 10.1109/TCSVT.2016.2565978
   Chen XJ, 2015, IEEE SENS J, V15, P2692, DOI 10.1109/JSEN.2015.2392781
   Collins RT, 2012, PROC CVPR IEEE, P1744, DOI 10.1109/CVPR.2012.6247870
   Daliyot Shahar, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P372, DOI 10.1007/978-3-642-37484-5_31
   Dimitrievski M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19020391
   Ge HL, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12030434
   Ge HL, 2019, INF TECHNOL CONTROL, V48, P538, DOI 10.5755/j01.itc.48.4.23939
   Hamid R, 2010, PROC CVPR IEEE, P731, DOI 10.1109/CVPR.2010.5540142
   Hausknecht M.J., 2017, ABS150706527 CORR
   Huang T, 1997, INT JOINT CONF ARTIF, P1276
   Javed O, 2008, COMPUT VIS IMAGE UND, V109, P146, DOI 10.1016/j.cviu.2007.01.003
   Karayev S, 2014, PROC CVPR IEEE, P572, DOI 10.1109/CVPR.2014.80
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   King DB, 2015, ACS SYM SER, V1214, P1
   Kuo CH, 2010, LECT NOTES COMPUT SC, V6311, P383
   Lavi B., 2018, ARXIV180705284 CORR
   Lee YG, 2018, IEEE T CIRC SYST VID, V28, P2870, DOI 10.1109/TCSVT.2017.2707399
   Luo W., 2018, ARXIV170510561 CORR
   Makris D, 2004, PROC CVPR IEEE, P205
   Matei B. C., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3465, DOI 10.1109/CVPR.2011.5995575
   Mathe S, 2016, PROC CVPR IEEE, P2894, DOI 10.1109/CVPR.2016.316
   Mnih V., 2013, P ADV C NEUR INF PRO, P1
   Pardo F., 2018, Proceedings of the 35th International Conference on Machine Learning, V80, P4045
   Pasula H, 1999, IJCAI-99: PROCEEDINGS OF THE SIXTEENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 & 2, P1160
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Ristani E, 2015, LECT NOTES COMPUT SC, V9007, P444, DOI 10.1007/978-3-319-16814-2_29
   Sharma A, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6458
   Sharma A, 2018, PROCEEDINGS OF THE 17TH INTERNATIONAL CONFERENCE ON AUTONOMOUS AGENTS AND MULTIAGENT SYSTEMS (AAMAS' 18), P2073
   Sharma Anil, 2019, P INT C AUT PLANN SC
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sunderrajan S., 2013, ICDSC, P1
   Supancic J, 2017, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2017.43
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tesfaye YT, 2019, INT J COMPUT VISION, V127, P1303, DOI 10.1007/s11263-019-01180-6
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang S, 2015, IEEE WINT CONF APPL, P365, DOI 10.1109/WACV.2015.55
   Zhang S, 2015, COMPUT VIS IMAGE UND, V134, P64, DOI 10.1016/j.cviu.2015.01.002
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
NR 48
TC 3
Z9 3
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104022
DI 10.1016/j.imavis.2020.104022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bu, FJ
   Gharajeh, MS
AF Bu, Fengju
   Gharajeh, Mohammad Samadi
TI Intelligent and vision-based fire detection systems: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fire detection system; Computer vision; Artificial intelligence;
   Intelligent system; Vision-based system
ID CONVOLUTIONAL NEURAL-NETWORKS; FLAME DETECTION; SMOKE DETECTION; VIDEO;
   COLOR; SURVEILLANCE; COMBINATION; ALGORITHM; MODEL
AB Fire is one of the main disasters in the world. A fire detection system should detect fires in various environments (e.g., buildings, forests, and rural areas) in the shortest time in order to reduce financial losses and humanistic disasters. Fire sensors are, in fact, complemental)/ to conventional point sensors (e.g., smoke and heat detectors), which provide people the early warnings of fire occurrences. Cameras combined with image processing techniques detect fire occurrences more quickly than point sensors. Moreover, they provide the size, growth, and direction of fires more easily than their conventional detectors. This paper, initially, presents a glance view on the main features of various environments including buildings, forests, and mines that should be considered in the design of fire detection systems. Afterwards, it describes some of the intelligent and vision-based fire detection systems that have been presented by researchers in the last decade. These systems are categorized, in this paper, into two groups: intelligent detection systems for forest fires and intelligent fire detection systems for all of the environments. They use various intelligent techniques (e.g., convolutional neural networks, color models, and fuzzy logic) to detect fire occurrences with a high accuracy in various environments. Performances of the fire detection systems are compared to each other in terms of detection rate, precision, true-positive rate, false-positive rate, etc. under different evaluation scenarios. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Bu, Fengju] Shandong Agr & Engn Univ, Jinan, Shandong, Peoples R China.
   [Gharajeh, Mohammad Samadi] Islamic Azad Univ, Young Researchers & Elite Club, Tabriz Branch, Tabriz, Iran.
C3 Shandong Agriculture & Engineering University; Islamic Azad University
RP Gharajeh, MS (corresponding author), Islamic Azad Univ, Young Researchers & Elite Club, Tabriz Branch, Tabriz, Iran.
EM m.samadi@iaut.ac.ir
CR Alcalá-Fdez J, 2016, IEEE T FUZZY SYST, V24, P40, DOI 10.1109/TFUZZ.2015.2426212
   Alkhatib AAA, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/597368
   Babrauskas V., 2003, Ignition Handbook: Principles and Applications to Fire Safety Engineering, Fire Investigation, Risk Management and Forensic Science
   Borges PVK, 2010, IEEE T CIRC SYST VID, V20, P721, DOI 10.1109/TCSVT.2010.2045813
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Caton SE, 2017, FIRE TECHNOL, V53, P429, DOI 10.1007/s10694-016-0589-z
   Celik T., 2007, P IEEE INT C AC SPEE, V1
   Celik T., 2006, 2006 14 EUROPEAN SIG, P1
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Chen TH, 2004, IEEE IMAGE PROC, P1707
   Chen TH, 2006, IIH-MSP: 2006 INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P427
   Collotta M, 2015, J NETW COMPUT APPL, V53, P183, DOI 10.1016/j.jnca.2015.04.005
   Cruz H, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16060893
   Cui Y, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 3, PROCEEDINGS, P95, DOI 10.1109/CISP.2008.397
   Di Lascio R, 2014, LECT NOTES COMPUT SC, V8814, P477, DOI 10.1007/978-3-319-11758-4_52
   Dimitropoulos K, 2015, IEEE T CIRC SYST VID, V25, P339, DOI 10.1109/TCSVT.2014.2339592
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Foggia P, 2015, IEEE T CIRC SYST VID, V25, P1545, DOI 10.1109/TCSVT.2015.2392531
   Gomes P, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/58821
   Gómez-Ríos A, 2019, EXPERT SYST APPL, V118, P315, DOI 10.1016/j.eswa.2018.10.010
   Gong YJ, 2016, IEEE T CYBERNETICS, V46, P2277, DOI 10.1109/TCYB.2015.2475174
   Guggenheim Davis., INCONVENIENT TRUTH
   Habiboglu YH, 2012, MACH VISION APPL, V23, P1103, DOI 10.1007/s00138-011-0369-1
   Hakes RSP, 2017, FIRE TECHNOL, V53, P475, DOI 10.1007/s10694-016-0601-7
   Ho CC, 2009, MEAS SCI TECHNOL, V20, DOI 10.1088/0957-0233/20/4/045502
   Hongda Tian, 2012, 2012 IEEE International Conference on Multimedia and Expo (ICME), P532, DOI 10.1109/ICME.2012.72
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jin X, 2018, MULTIMED TOOLS APPL, V77, P15851, DOI 10.1007/s11042-017-5159-y
   Jo BW, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7090925
   Joy GJ, 2012, J OCCUP ENVIRON HYG, V9, P65, DOI 10.1080/15459624.2011.639232
   Khatami A, 2017, EXPERT SYST APPL, V68, P69, DOI 10.1016/j.eswa.2016.09.021
   Kim YH, 2014, INT J DISTRIB SENS N, DOI 10.1155/2014/923609
   Ko BC, 2011, IEEE T CIRC SYST VID, V21, P1903, DOI 10.1109/TCSVT.2011.2157190
   Ko B, 2014, FIRE SAFETY J, V68, P61, DOI 10.1016/j.firesaf.2014.05.015
   Borges PVK, 2008, IEEE IMAGE PROC, P13, DOI 10.1109/ICIP.2008.4711679
   Kopilovic I, 2000, INT C PATT RECOG, P714, DOI 10.1109/ICPR.2000.903017
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li ZL, 2018, IEEE T IND INFORM, V14, P1146, DOI 10.1109/TII.2017.2768530
   Liu CB, 2004, INT C PATT RECOG, P134, DOI 10.1109/HPD.2004.1346686
   Mahdipour E, 2014, ARTIF INTELL REV, V42, P895, DOI 10.1007/s10462-012-9345-z
   Mahmoud MAI, 2018, MATH PROBL ENG, V2018, DOI 10.1155/2018/7612487
   Manzello S.L, 2014, FIRE SAF SCI, V11, P83, DOI DOI 10.3801/IAFSS.FSS.11-83
   Manzello SL, 2012, FIRE SAFETY J, V54, P181, DOI 10.1016/j.firesaf.2012.06.012
   Maranghides A, 2011, FIRE TECHNOL, V47, P379, DOI 10.1007/s10694-010-0164-y
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Osunmakinde IO, 2013, INT J DISTRIB SENS N, DOI 10.1155/2013/159273
   Phillips W, 2002, PATTERN RECOGN LETT, V23, P319, DOI 10.1016/S0167-8655(01)00135-0
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   Qi-xing Zhang, 2018, Procedia Engineering, V211, P441, DOI 10.1016/j.proeng.2017.12.034
   Quarles S., 2012, LESSONS LEARNED WALD
   Qureshi WS, 2016, FIRE TECHNOL, V52, P1293, DOI 10.1007/s10694-015-0489-7
   Rafiee A., 2011, 2011 3rd International Conference on Computer Research and Development (ICCRD 2011), P262, DOI 10.1109/ICCRD.2011.5764295
   Sahin YG, 2007, SENSORS-BASEL, V7, P3084, DOI 10.3390/s7123084
   Saripalli S, 2003, IEEE T ROBOTIC AUTOM, V19, P371, DOI 10.1109/TRA.2003.810239
   Sun ZW, 2018, J NETW COMPUT APPL, V112, P29, DOI 10.1016/j.jnca.2018.03.023
   Nguyen-Ti T, 2013, PROC INT CONF ADV, P106, DOI 10.1109/ATC.2013.6698087
   Tian HD, 2014, INT J COMPUT VISION, V106, P192, DOI 10.1007/s11263-013-0656-6
   Toreyin B. U., FIRE DETECTION DATAS
   Töreyin BU, 2006, PATTERN RECOGN LETT, V27, P49, DOI 10.1016/j.patrec.2005.06.015
   Trevits M.A., 2008, Proc. 21st World Mining Congress, September 7-11, 2008, Krakow, P303
   Wang HF, 2013, NAT HAZARDS, V67, P763, DOI 10.1007/s11069-013-0602-5
   Wang YL, 2012, ADV MATER RES-SWITZ, V518-523, P5257, DOI 10.4028/www.scientific.net/AMR.518-523.5257
   Warnell School of Forestry and Natural Resources The University of Georgia; College of Agricultural and Environmental Sciences; Center for Invasive Species and Ecosystem Health; US Forest Service; International Society of Arboriculture, USDA ID TECHN PROGR
   Yu CY, 2013, PROCEDIA ENGINEER, V62, P891, DOI 10.1016/j.proeng.2013.08.140
   Yuan C, 2016, INT CONF UNMAN AIRCR, P1200, DOI 10.1109/ICUAS.2016.7502546
   Zhang QJ, 2016, ADV SOC SCI EDUC HUM, V47, P568
   Zhao Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030712
NR 69
TC 68
Z9 71
U1 12
U2 123
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2019
VL 91
AR 103803
DI 10.1016/j.imavis.2019.08.007
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU3YI
UT WOS:000501614200004
DA 2024-07-18
ER

PT J
AU Zhang, BB
   Shao, XY
   Chen, W
   Bi, FM
   Fang, WD
   Sun, TF
   Tang, CG
AF Zhang, Bobin
   Shao, Xiuyan
   Chen, Wei
   Bi, Fangming
   Fang, Weidong
   Sun, Tongfeng
   Tang, Chaogang
TI Visual tracking based on robust appearance model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Semi-supervised linear kernel classifier; Fisher
   vectors; Similarity; Pollution handle
AB This paper aims at solving the problem of target drifting or losing due to the dramatic changes in the appearance of the target caused by the presence of severe target occlusion, background clutter, and illumination variations in video sequence. Firstly, we obtain a discriminative appearance description of the target by calculating the global and local Fisher vectors of the target area, and subsequently we utilize a semi-supervised linear kernel classifier to calculate the confidence of each candidate for well distinguish the foreground target from the background region. Meanwhile, as the change in the appearance of the object has caused serious pollution and interfered with the original information of the target area, we obtain the similarity between the sub-patches of the target template set and all the candidates, according to the pollution degree of patches of each candidate. Finally, we retrieve the best candidate according to the production of the weight, confidence and the similarity. The extensive experiment results show that our algorithm can effectively cope with the pollution of the target area and the drastic change of the target appearance caused by the severe occlusion and illumination changes in complex scenes. This also demonstrates that our algorithm has considerably accuracy and robustness in visual tracking. (C) 2019 Published by Elsevier B.V.
C1 [Zhang, Bobin; Chen, Wei; Bi, Fangming; Sun, Tongfeng; Tang, Chaogang] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
   [Zhang, Bobin; Chen, Wei; Bi, Fangming; Sun, Tongfeng; Tang, Chaogang] China Univ Min & Technol, Mine Digitizat Engn Res Ctr, Minist Educ, Xuzhou 221116, Jiangsu, Peoples R China.
   [Chen, Wei; Fang, Weidong] Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Key Lab Wireless Sensor Network & Commun, Shanghai 201899, Peoples R China.
   [Shao, Xiuyan] Southeast Univ, Sch Econ & Management, Nanjing 211189, Jiangsu, Peoples R China.
C3 China University of Mining & Technology; China University of Mining &
   Technology; Chinese Academy of Sciences; Shanghai Institute of
   Microsystem & Information Technology, CAS; Southeast University - China
RP Chen, W (corresponding author), China Univ Min & Technol, Mine Digitizat Engn Res Ctr, Sch Comp Sci & Technol, Minist Educ, Xuzhou 221116, Jiangsu, Peoples R China.
EM chenw@cumt.edu.cn
RI Fang, Weidong/IVV-4133-2023
FU National Natural Science Foundation of China [51874300, U1510115];
   Shanxi Provincial People's Government Jointly Funded Project of China
   for Coal Base and Low Carbon [U1510115]; Qing Lan Project; China
   Postdoctoral Science Foundation [2013T60574, 20100481181]; southeast
   university; Jorma Ollila Grant of Nokia Foundation; Central Fund of
   Finnish Cultural Foundation; Nvidia Corporation; Ph.D. Programs
   Foundation of Ministry of Education of China [20110095120008]
FX The research is supported by National Natural Science Foundation of
   China (Grant No.51874300), the National Natural Science Foundation of
   China and Shanxi Provincial People's Government Jointly Funded Project
   of China for Coal Base and Low Carbon (Grant No.U1510115), the Qing Lan
   Project, the China Postdoctoral Science Foundation (Grant
   No.2013T60574), and startup funding of southeast university. We
   gratefully acknowledge Academy of Finland, the Jorma Ollila Grant of
   Nokia Foundation, Central Fund of Finnish Cultural Foundation, the
   support of Nvidia Corporation with the donation of the Titan X Pascal
   GPU used for this research, the Ph.D. Programs Foundation of Ministry of
   Education of China (Grant No. 20110095120008) and the China Postdoctoral
   Science Foundation (Grant No., 20100481181).
CR [Anonymous], 2015, PROC CVPR IEEE
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Cannons K., 2008, DEP COMPUT SCI ENG, V08, P35
   Chi ZZ, 2017, IEEE T IMAGE PROCESS, V26, P2005, DOI 10.1109/TIP.2017.2669880
   Dong XP, 2017, IEEE T MULTIMEDIA, V19, P763, DOI 10.1109/TMM.2016.2631884
   Feng QX, 2016, INT CONF ACOUST SPEE, P1566, DOI 10.1109/ICASSP.2016.7471940
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2017, IEEE T IMAGE PROCESS, V26, P5800, DOI 10.1109/TIP.2017.2745204
   Jen-Chao T., 2003, IMAGE VISION COMPUT, V22, P485
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Lu GY, 2017, IEEE T MULTIMEDIA, V19, P2117, DOI 10.1109/TMM.2017.2731044
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P5867, DOI 10.1109/TIP.2016.2615812
   Ma B, 2016, IEEE T CYBERNETICS, V46, P2411, DOI 10.1109/TCYB.2015.2477879
   Ma B, 2016, IEEE T IMAGE PROCESS, V25, P4199, DOI 10.1109/TIP.2016.2588329
   Ma B, 2015, IEEE T MULTIMEDIA, V17, P1818, DOI 10.1109/TMM.2015.2463221
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Paschalakis S, 2004, REAL-TIME IMAGING, V10, P81, DOI 10.1016/j.rti.2004.02.004
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Shen JB, 2018, IEEE T INTELL TRANSP, V19, P162, DOI 10.1109/TITS.2017.2750082
   Song HH, 2014, ELECTRON LETT, V50, P1931, DOI 10.1049/el.2014.1911
   Sun C, 2017, IEEE T CIRC SYST VID, V27, P2567, DOI 10.1109/TCSVT.2016.2595265
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang F, 2014, IEEE WINT CONF APPL, P854, DOI 10.1109/WACV.2014.6836014
   Yang F, 2014, IEEE T IMAGE PROCESS, V23, P1639, DOI 10.1109/TIP.2014.2300823
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yu K., INT C INT C MACH LEA, P1215
   Yu K., INT C NEUR INF PROC, P2223
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang L, 2017, PROC CVPR IEEE, P5825, DOI 10.1109/CVPR.2017.617
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
NR 33
TC 4
Z9 4
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 211
EP 221
DI 10.1016/j.imavis.2019.07.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900018
DA 2024-07-18
ER

PT J
AU Xu, QZ
   Wang, FY
   Gong, YY
   Wang, ZT
   Zeng, K
   Li, Q
   Luo, XN
AF Xu, Qingzhen
   Wang, Fengyun
   Gong, Yongyi
   Wang, Zhoutao
   Zeng, Kun
   Li, Qi
   Luo, Xiaonan
TI A novel edge-oriented framework for saliency detection enhancement
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Saliency detection enhancements; Visual attention; Edge probability map;
   Edge-region
ID OBJECT DETECTION; IMAGE
AB Mixed visual scenes and cluttered background commonly exist in natural images, which forms a challenge for saliency detection. In dealing with complex images, there are two kinds of deficiencies in the existing saliency detection methods: ambiguous object boundaries and fragmented salient regions. To address these two limitations, we propose a novel edge-oriented framework to improve the performance of existing salient detection methods. Our framework is based on two interesting insights: 1) human eyes are sensitive to the edges between foreground and background even there is hardly any difference in terms of saliency, 2) Guided by semantic integrity, human eyes tend to view a visual scene as several objects, rather than pixels or super pixels. The proposed framework consists of the following three parts. First, an edge probability map is extracted from an input image. Second, the edge-based over-segmentation is obtained by sharpening the edge probability map, which is ultilized to generate edge-regions using an edge-strength based hierarchical merge model. Finally, based on the prior saliency map generated by existing methods, the framework assigns each edge-region with a saliency value. Based on four publically available datasets, the experiments demonstrate that the proposed framework can significantly improve the detection results of existing saliency detection models, which is also superior to other state-of-the-art methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Xu, Qingzhen; Wang, Fengyun; Wang, Zhoutao] South China Normal Univ, Sch Comp, Guangzhou 510631, Guangdong, Peoples R China.
   [Wang, Fengyun; Gong, Yongyi] Guangdong Univ Foreign Studies, Intelligent Hlth & Visual Comp Lab, Guangzhou 510006, Guangdong, Peoples R China.
   [Gong, Yongyi] Guangdong Univ Foreign Studies, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
   [Zeng, Kun] Sun Yat Sen Univ, Sch Data & Comp Sci, Guangzhou 510006, Guangdong, Peoples R China.
   [Li, Qi] Western Kentucky Univ, Dept Comp Sci, Bowling Green, KY 42101 USA.
   [Luo, Xiaonan] Guilin Univ Elect Technol, Sch Comp Sci & Informat Secur, Guilin 541004, Peoples R China.
C3 South China Normal University; Guangdong University of Foreign Studies;
   Guangdong University of Foreign Studies; Sun Yat Sen University; Western
   Kentucky University; Guilin University of Electronic Technology
RP Gong, YY (corresponding author), Guangdong Univ Foreign Studies, Intelligent Hlth & Visual Comp Lab, Guangzhou 510006, Guangdong, Peoples R China.; Gong, YY (corresponding author), Guangdong Univ Foreign Studies, Sch Informat Sci & Technol, Guangzhou 510006, Guangdong, Peoples R China.
EM gongyongyi@gdufs.edu.cn; qi.li@wku.edu; luoxn@guet.edu.cn
RI wong, fereen/ABH-9852-2022
FU National Science Foundation of China [61370160, 601772149]; Guangdong
   Provincial Natural Science Foundation [2015A030313578, 2014A030310348];
   Guangdong Scientific and Technological Plan Project [20158010106005]
FX This work was supported by National Science Foundation of China (Project
   Nos. 61370160, 601772149), Guangdong Provincial Natural Science
   Foundation Project 2015A030313578, 2014A030310348, Guangdong Scientific
   and Technological Plan Project 20158010106005.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Alexe B, 2012, IEEE T PATTERN ANAL, V34, P2189, DOI 10.1109/TPAMI.2012.28
   [Anonymous], 1998, MODEL SALIENCY BASED
   [Anonymous], 2017, ARXIV170804366
   [Anonymous], 2018, CONTEXT ENCODING SEM
   Chang K.Y, 2011, FUSING GENERIC OBJEC
   Chang YC, 2016, 2016 INTERNATIONAL SYMPOSIUM ON ANTENNAS AND PROPAGATION (ISAP), P938
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen TS, 2016, IEEE T NEUR NET LEAR, V27, P1135, DOI 10.1109/TNNLS.2015.2506664
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778820
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Christopoulos C., 2000, JPEG2000 STILL IMAGE
   Dollár P, 2015, IEEE T PATTERN ANAL, V37, P1558, DOI 10.1109/TPAMI.2014.2377715
   Dou H., 2018, SOC PHOTOOPTICAL INS, P106
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2016, IEEE T IMAGE PROCESS, V25, P5012, DOI 10.1109/TIP.2016.2602079
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu Tie, 2007, P IEEE C COMP VIS PA, P1, DOI DOI 10.1109/CVPR.2007.383047
   Liu Y., 2016, RICHER CONVOLUTIONAL, P5872
   Liu Y, 2019, IEEE T PATTERN ANAL, V41, P1939, DOI 10.1109/TPAMI.2018.2878849
   Lu HC, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2524198
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Pohlen T, 2017, PROC CVPR IEEE, P3309, DOI 10.1109/CVPR.2017.353
   Reinagel P, 1999, NETWORK-COMP NEURAL, V10, P341, DOI 10.1088/0954-898X/10/4/304
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1330511.1330512
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wei YC, 2016, IEEE T PATTERN ANAL, V38, P1901, DOI 10.1109/TPAMI.2015.2491929
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zhai J., 2018, COMPUT ENG APPL
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhang LH, 2017, IEEE T PATTERN ANAL, V39, P1892, DOI 10.1109/TPAMI.2016.2609426
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Ziou D., 1998, Pattern Recognition and Image Analysis, V8, P537
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 56
TC 21
Z9 21
U1 1
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2019
VL 87
BP 1
EP 12
DI 10.1016/j.imavis.2019.04.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IF3NV
UT WOS:000472988400001
DA 2024-07-18
ER

PT J
AU He, FX
   Liu, FY
   Yao, R
   Lin, GS
AF He, Feixiang
   Liu, Fayao
   Yao, Rui
   Lin, Guosheng
TI Local fusion networks with chained residual pooling for video action
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Residual connection; Local fusion; Deep
   convolutional network
AB Action recognition is an important yet challenging problem. We here present a novel method, multistage local fusion networks with residual connections, to boost the performance of video action recognition. In realistic videos, an action instance may have a long time span and some frames may suffer from deteriorated object appearance due to motion blur or video defocus. Our method enhances the per-frame representation by capturing information from neighboring frames. We propose a local fusion block which considers neighboring frames to capture appearance and local motion information for generating per-frame representation. Our local fusion is performed in a multistage manner allowing feature fusion from varying neighborhood sizes in the temporal dimension. We employ residual connections in the fusion blocks to enable effective gradient propagation through the whole network allowing effective end-to-end training. We achieve competitive results on two challenging and public available datasets, namely HMDB51 and UCF 101, which shows the effectiveness of the proposed method. (C) 2019 Elsevier B.V. All rights reserved.
C1 [He, Feixiang; Lin, Guosheng] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore, Singapore.
   [Liu, Fayao] Univ Adelaide, Sch Comp Sci, Adelaide, SA, Australia.
   [Yao, Rui] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou, Jiangsu, Peoples R China.
C3 Nanyang Technological University; University of Adelaide; China
   University of Mining & Technology
RP Liu, FY (corresponding author), Univ Adelaide, Sch Comp Sci, Adelaide, SA, Australia.
EM fxhe@ntu.edu.sg; fayaoliu@gmail.com; ruiyao@cumt.edu.cn;
   gslin@ntu.edu.sg
RI ; Lin, Guosheng/Q-4024-2017
OI Yao, Rui/0000-0003-2734-915X; Lin, Guosheng/0000-0002-0329-7458; LIU,
   Fayao/0000-0001-6649-7660
FU NTU Start-up Grant; MOE Tier-1 grant [M4011896]
FX This work is partly supported by a NTU Start-up Grant and a MOE Tier-1
   grant (M4011896).
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], 2015, ARXIV PREPRINT ARXIV
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2712608
   [Anonymous], ARXIV12120402
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], ARXIV151106432
   [Anonymous], ARXIV150702159
   [Anonymous], ARXIV170402895
   [Anonymous], ARXIV151104119
   [Anonymous], 2017, P IEEE C COMP VIS PA
   [Anonymous], ARXIV161108240
   [Anonymous], ARXIV160309025
   [Anonymous], 2014, ARXIV PREPRINT ARXIV
   Bilen H, 2016, PROC CVPR IEEE, P3034, DOI 10.1109/CVPR.2016.331
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C., 2016, P INT C NEUR INF PRO, P3468
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Feichtenhofer Christoph, 2017, P IEEE C COMP VIS PA, P4768
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lev G, 2016, LECT NOTES COMPUT SC, V9910, P833, DOI 10.1007/978-3-319-46466-4_50
   Li ZY, 2018, COMPUT VIS IMAGE UND, V166, P41, DOI 10.1016/j.cviu.2017.10.011
   Lin G., 2017, P IEEE C COMP VIS PA
   Liu J, 2017, PROC CVPR IEEE, P3671, DOI 10.1109/CVPR.2017.391
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Sun L, 2015, IEEE I CONF COMP VIS, P4597, DOI 10.1109/ICCV.2015.522
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang L., 2016, P ECCV
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
   Wang LM, 2013, PROC CVPR IEEE, P2674, DOI 10.1109/CVPR.2013.345
   Yao L, 2015, IEEE I CONF COMP VIS, P4507, DOI 10.1109/ICCV.2015.512
   Zhu WJ, 2016, PROC CVPR IEEE, P1991, DOI 10.1109/CVPR.2016.219
NR 40
TC 5
Z9 6
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2019
VL 81
BP 34
EP 41
DI 10.1016/j.imavis.2018.12.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HO1ZJ
UT WOS:000460710900004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Romero-Ramirez, FJ
   Muñoz-Salinas, R
   Medina-Carnicer, R
AF Romero-Ramirez, Francisco J.
   Munoz-Salinas, Rafael
   Medina-Carnicer, Rafael
TI Speeded up detection of squared fiducial markers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fiducial markers; Marker mapping; SLAM
ID AUGMENTED REALITY; TRACKING SYSTEM; GENERATION; IDENTIFICATION;
   VEHICLES; VISION
AB Squared planar markers have become a popular method for pose estimation in applications such as autonomous robots, unmanned vehicles and virtual trainers. The markers allow estimating the position of a monocular camera with minimal cost, high robustness, and speed. One only needs to create markers with a regular printer, place them in the desired environment so as to cover the working area, and then registering their location from a set of images.
   Nevertheless, marker detection is a time-consuming process, especially as the image dimensions grows. Modern cameras are able to acquire high resolutions images, but fiducial marker systems are not adapted in terms of computing speed. This paper proposes a multi-scale strategy for speeding up marker detection in video sequences by wisely selecting the most appropriate scale for detection, identification and corner estimation. The experiments conducted show that the proposed approach outperforms the state-of-the-art methods without sacrificing accuracy or robustness. Our method is up to 40 times faster than the state-of-the-art method, achieving over 1000 fps in 4 K images without any parallelization. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Romero-Ramirez, Francisco J.; Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Univ Cordoba, Dept Informat & Anal Numer, Edificio Einstein,Campus Rabanales, E-14071 Cordoba, Spain.
   [Munoz-Salinas, Rafael; Medina-Carnicer, Rafael] Inst Maimonides Invest Biomed IMIBIC, Ave Menendez Pidal S-N, Cordoba 14004, Spain.
C3 Universidad de Cordoba
RP Muñoz-Salinas, R (corresponding author), Univ Cordoba, Dept Informat & Anal Numer, Edificio Einstein,Campus Rabanales, E-14071 Cordoba, Spain.; Muñoz-Salinas, R (corresponding author), Inst Maimonides Invest Biomed IMIBIC, Ave Menendez Pidal S-N, Cordoba 14004, Spain.
EM fj.romero@uco.es; in1musar@uco.es; rmedina@uco.es
RI Romero-Ramirez, Francisco J./JVE-2018-2024; Medina-Carnicer,
   Rafael/G-3401-2015; Munoz-Salinas, Rafael/K-5999-2014
OI Romero-Ramirez, Francisco J./0000-0002-9572-0128; Medina-Carnicer,
   Rafael/0000-0003-4481-0614; Munoz-Salinas, Rafael/0000-0002-8773-8571
FU Spain Ministry of Economy, Industry and Competitiveness
   [TIN2016-75279-P, IFI16/00033]; FEDER
FX This project has been funded under projects TIN2016-75279-P and
   IFI16/00033 (ISCIII) of Spain Ministry of Economy, Industry and
   Competitiveness, and FEDER.
CR [Anonymous], 2000, Dare 2000, DOI DOI 10.1145/354666.354667
   [Anonymous], 2004, P 2004 ACM SIGGRAPH
   [Anonymous], COMP VIS WINT WORKSH
   Bonnard Q., 2013, Chilitags 2: Robust fiducial markers for augmented reality and robotics
   Bradski G., 2013, LEARNING OPENCV COMP, V2nd
   Broggi A, 2000, IMAGE VISION COMPUT, V18, P365, DOI 10.1016/S0262-8856(00)00032-9
   Chen P, 2016, J VIS COMMUN IMAGE R, V37, P63, DOI 10.1016/j.jvcir.2015.06.016
   Cortés X, 2016, EXPERT SYST APPL, V45, P150, DOI 10.1016/j.eswa.2015.09.049
   Dorfmüller K, 1998, LECT NOTES ARTIF INT, V1537, P113
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Engel J., 2014, LSD SLAM LARGE SCALE
   Fiala M, 2010, IEEE T PATTERN ANAL, V32, P1317, DOI 10.1109/TPAMI.2009.146
   Flohr D., 2007, Eurographics Symposium on Virtual Environments (EGVE) Short Paper Proceedings, P59, DOI DOI 10.2312/PE/VE2007SHORT/059-064
   Garrido-Jurado S, 2016, PATTERN RECOGN, V51, P481, DOI 10.1016/j.patcog.2015.09.023
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   González D, 2017, EXPERT SYST APPL, V71, P332, DOI 10.1016/j.eswa.2016.11.023
   Johnston DJ, 2005, IMAGE VISION COMPUT, V23, P271, DOI 10.1016/j.imavis.2003.08.002
   Kaltenbrunner M., 2007, TEI'07 Proceedings, P69
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   Khattak S., 2014, Proc. GEM, P1
   Knyaz V.A., 1998, 3D Surface Measurements, International Archives of Photogrammetry and Remote Sensing., VXXXII, P80
   Lima JP, 2017, EXPERT SYST APPL, V82, P100, DOI 10.1016/j.eswa.2017.03.060
   Lin S., 2004, Error Control Coding, Vsecond
   Mondéjar-Guerra V, 2018, EXPERT SYST APPL, V93, P336, DOI 10.1016/j.eswa.2017.10.032
   Muñoz-Salinas R, 2018, PATTERN RECOGN, V73, P158, DOI 10.1016/j.patcog.2017.08.010
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Naimark L, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P27, DOI 10.1109/ISMAR.2002.1115065
   Olivares-Mendez MA, 2015, MED C CONTR AUTOMAT, P14, DOI 10.1109/MED.2015.7158723
   Olson E, 2011, IEEE INT CONF ROBOT
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Patterson T, 2014, IMAGE VISION COMPUT, V32, P568, DOI 10.1016/j.imavis.2014.06.006
   Pflugi S, 2017, IEEE ENG MED BIO, P937, DOI 10.1109/EMBC.2017.8036979
   Pichler A, 2017, PROCEDIA MANUF, V11, P72, DOI 10.1016/j.promfg.2017.07.139
   Ribo M, 2001, IEEE IMTC P, P1932, DOI 10.1109/IMTC.2001.929537
   Rohs M, 2004, ADV PERVASIVE COMPUT, P265
   Sanchez -Lopez J. L., 2015, Journal of Intelligent & Robotic Systems, P1
   Schmalstieg D, 2002, PRESENCE-VIRTUAL AUG, V11, P33, DOI 10.1162/105474602317343640
   Sim R, 2009, IMAGE VISION COMPUT, V27, P167, DOI 10.1016/j.imavis.2008.04.003
   SUZUKI S, 1985, COMPUT VISION GRAPH, V30, P32, DOI 10.1016/0734-189X(85)90016-7
   Valencia-Garcia R, 2005, EXPERT SYST APPL, V28, P425, DOI 10.1016/j.eswa.2004.12.003
   Zhong SH, 2015, EXPERT SYST APPL, V42, P5658, DOI 10.1016/j.eswa.2015.01.012
NR 41
TC 394
Z9 425
U1 6
U2 68
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2018
VL 76
BP 38
EP 47
DI 10.1016/j.imavis.2018.05.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GR1TB
UT WOS:000442333500004
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Lee, PY
   Loh, WP
   Chin, JF
AF Lee, Pui Yi
   Loh, Wei Ping
   Chin, Jeng Feng
TI Feature selection in multimedia: The state-of-the-art review
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Feature selection; Multimedia; Data mining; Search strategies
ID FEATURE SUBSET-SELECTION; SPARSE FEATURE-SELECTION; TEXT DETECTION;
   INSTANCE SELECTION; MUTUAL INFORMATION; IMAGE ANNOTATION; ATTENTION
   MODEL; VIDEO; CLASSIFICATION; RECOGNITION
AB Multimedia data mining, particularly feature selection (FS), has been successfully applied in recent classification and recognition works. However, only a few studies in the contemporary literature have reviewed FS (e.g., analyses of data pre-processing prior to classification and clustering). This study aimed to fill this research gap by presenting an extensive survey on the current development of FS in multimedia. A total of 70 related papers published from 2001 to 2017 were collected from multiple databases. Breakdowns and analyses were performed on data types, methods, search strategies, performance measures, and challenges. The development trend of FS presages the increased prominence of heuristic search strategies and hybrid FS in the latest multimedia data mining. (C) 2017 Published by Elsevier B.V.
C1 [Lee, Pui Yi; Loh, Wei Ping; Chin, Jeng Feng] Univ Sains Malaysia, Sch Mech Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
C3 Universiti Sains Malaysia
RP Loh, WP (corresponding author), Univ Sains Malaysia, Sch Mech Engn, Engn Campus, Nibong Tebal 14300, Penang, Malaysia.
EM melissa_lee_88@hotmail.com; meloh@usm.my; chinjengfeng@usm.my
RI Loh, Wei Ping/AAB-1266-2020; Lee, Pui Yi/B-6986-2019
OI Loh, Wei Ping/0000-0002-9633-3410; Chin, Jeng Feng/0000-0002-9547-3673;
   Lee, Pui Yi/0000-0002-7942-1662
FU Universiti Sains Malaysia under USM; Research University (RUI) Scheme
   [1001/PMEKANIK/814188, 1001/PMEKANIK/814271]
FX This work was supported by Universiti Sains Malaysia under USM
   Fellowship and the Research University (RUI) Scheme
   (1001/PMEKANIK/814188) and (1001/PMEKANIK/814271).
CR Agrawal V, 2015, INT CONF CONTEMP, P171, DOI 10.1109/IC3.2015.7346674
   Ahmad A, 2005, PATTERN RECOGN LETT, V26, P43, DOI 10.1016/j.patrec.2004.08.015
   Akiyama J., 2010, SELECTED PAPERS
   Al Mashrgy M, 2014, KNOWL-BASED SYST, V59, P182, DOI 10.1016/j.knosys.2014.01.007
   Alok Abhay Kumar, 2014, International Journal of Computer Information Systems and Industrial Management Applications, V6, P494
   [Anonymous], 247652010E2010E ISOI
   [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], 1994, D57251 ISO
   [Anonymous], 2007, MIR
   [Anonymous], 2010, U WISCONSIN MADISON, V52, P11, DOI DOI 10.1016/J.MATLET.2010.11.072
   [Anonymous], 2000, INT C MACH LEARN ICM
   [Anonymous], 2014, JCGM, V200, P2008
   Ansari E., 2013, SCI IRANICA
   Armingol JM, 2007, ROBOT AUTON SYST, V55, P904, DOI 10.1016/j.robot.2007.09.004
   Bellman R. E., 1961, ADAPTIVE CONTROL PRO
   Bermejo P, 2012, KNOWL-BASED SYST, V25, P35, DOI 10.1016/j.knosys.2011.01.015
   Bestgen Yves, 2015, Prague Bulletin of Mathematical Linguistics, P131, DOI 10.1515/pralin-2015-0007
   Bhanu B, 2003, IMAGE VISION COMPUT, V21, P591, DOI 10.1016/S0262-8856(03)00057-X
   Bilal D, 2012, J AM SOC INF SCI TEC, V63, P1879, DOI 10.1002/asi.22675
   Biland C, 2008, EUR REV APPL PSYCHOL, V58, P65, DOI 10.1016/j.erap.2008.04.001
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Bolón-Canedo V, 2015, KNOWL-BASED SYST, V86, P33, DOI 10.1016/j.knosys.2015.05.014
   Bouma H., 2015, SPIE
   Briassouli A., 2015, HLTH MONITORING PERS
   Buttcher S., 2010, Information Retrieval-Implementing and Evaluating Search Engines
   Cantu-Paz E., 2004, Proceedings of the ACM SIGKDD Internations Conference on Knowledge Discover and Data Mining, P788
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chang CC, 2008, INFORM SCIENCES, V178, P3543, DOI 10.1016/j.ins.2008.05.003
   Chang X., 2014, SEMI SUPERVISED FEAT, P74
   Chang XJ, 2016, ACM T KNOWL DISCOV D, V11, DOI 10.1145/2910585
   Chang XJ, 2014, AAAI CONF ARTIF INTE, P1171
   Chawla N, 2005, J ARTIF INTELL RES, V23, P331, DOI 10.1613/jair.1509
   Chen BL, 2013, SIGNAL PROCESS, V93, P1566, DOI 10.1016/j.sigpro.2012.10.022
   Chen C, 2011, COMPUT VIS IMAGE UND, V115, P290, DOI 10.1016/j.cviu.2010.11.007
   Chen DT, 2004, PATTERN RECOGN, V37, P595, DOI 10.1016/j.patcog.2003.06.001
   Chen HS, 2014, J VIS COMMUN IMAGE R, V25, P285, DOI 10.1016/j.jvcir.2013.12.001
   Chen WY, 2011, IEEE T PATTERN ANAL, V33, P568, DOI 10.1109/TPAMI.2010.88
   Chen ZY, 2015, COMPUT IND, V74, P201, DOI 10.1016/j.compind.2015.08.007
   COHN D, 1994, MACH LEARN, V15, P201, DOI 10.1023/A:1022673506211
   Cong Y, 2015, PATTERN RECOGN, V48, P907, DOI 10.1016/j.patcog.2014.09.010
   Cooperation I., 2004, MICROPROCESSOR QUICK
   Cui Y., 2009, PROQUEST
   Daimi SN, 2014, EXPERT SYST APPL, V41, P6057, DOI 10.1016/j.eswa.2014.03.050
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   De Wang, 2014, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2014. Proceedings: LNCS 8726, P306, DOI 10.1007/978-3-662-44845-8_20
   Nga DH, 2014, COMPUT VIS IMAGE UND, V118, P2, DOI 10.1016/j.cviu.2013.03.009
   Dornaika F, 2011, PATTERN RECOGN LETT, V32, P740, DOI 10.1016/j.patrec.2010.12.010
   Dupuis Y, 2013, IMAGE VISION COMPUT, V31, P580, DOI 10.1016/j.imavis.2013.04.001
   Dy JG, 2004, J MACH LEARN RES, V5, P845
   Ejaz N, 2014, COMPUT ELECTR ENG, V40, P993, DOI 10.1016/j.compeleceng.2013.10.005
   Elguebaly T, 2013, SIGNAL PROCESS, V93, P1531, DOI 10.1016/j.sigpro.2012.07.037
   Elguebaly T, 2012, J VIS COMMUN IMAGE R, V23, P1199, DOI 10.1016/j.jvcir.2012.08.003
   Faria FA, 2014, PATTERN RECOGN LETT, V39, P52, DOI 10.1016/j.patrec.2013.07.014
   Fayyad U, 1996, AI MAG, V17, P37
   Feng YQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2085, DOI 10.1109/ICMLC.2003.1259848
   Ferreira AJ, 2012, PATTERN RECOGN LETT, V33, P1794, DOI 10.1016/j.patrec.2012.05.019
   Foody GM, 2002, REMOTE SENS ENVIRON, V80, P185, DOI 10.1016/S0034-4257(01)00295-4
   Forman G., 2003, Journal of Machine Learning Research, V3, P1289, DOI 10.1162/153244303322753670
   Frénay B, 2014, COMPUT STAT DATA AN, V71, P832, DOI 10.1016/j.csda.2013.05.001
   Freund Y, 1997, MACH LEARN, V28, P133, DOI 10.1023/A:1007330508534
   García S, 2016, KNOWL-BASED SYST, V98, P1, DOI 10.1016/j.knosys.2015.12.006
   Ghasemzadeh H, 2016, DIGIT SIGNAL PROCESS, V51, P133, DOI 10.1016/j.dsp.2015.12.015
   Girvan M, 2002, P NATL ACAD SCI USA, V99, P7821, DOI 10.1073/pnas.122653799
   Gomes RB, 2013, NEUROCOMPUTING, V120, P34, DOI 10.1016/j.neucom.2012.10.033
   Gurwicz Y, 2011, PATTERN RECOGN LETT, V32, P805, DOI 10.1016/j.patrec.2011.01.005
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Ha HY, 2015, IEEE INT C SEMANT CO, P276, DOI 10.1109/ICOSC.2015.7050820
   Hamidi F, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.025
   Han J, 2012, MOR KAUF D, P1
   Han JW, 2014, NEUROCOMPUTING, V144, P128, DOI 10.1016/j.neucom.2013.11.052
   Han YH, 2014, INFORM SCIENCES, V281, P523, DOI 10.1016/j.ins.2014.03.093
   Hansen C.H., 2001, Occupational Exposure to Noise: Evaluation, Prevention and Control
   Hernández-Orallo J, 2013, MACH LEARN, V93, P71, DOI 10.1007/s10994-013-5328-9
   Hernández-Orallo J, 2012, J MACH LEARN RES, V13, P2813
   Homeyer A., 2011, J PATHOL INFORM, V2
   Houben C, 2015, ANNU REV CONTROL, V39, P58, DOI 10.1016/j.arcontrol.2015.03.005
   Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299, DOI 10.1109/TKDE.2005.50
   Huang YP, 2015, APPL SOFT COMPUT, V33, P197, DOI 10.1016/j.asoc.2015.04.011
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jain V., 2011, International Conference on World Wide Web, P277, DOI DOI 10.1145/1963405.1963447
   Jin C, 2015, SIGNAL PROCESS, V109, P172, DOI 10.1016/j.sigpro.2014.10.031
   Kovács L, 2014, DIGIT SIGNAL PROCESS, V31, P1, DOI 10.1016/j.dsp.2014.04.013
   Labatut V., 2015, Int. J. Social Netw. Mining, V2, P44, DOI [10.1504/IJSNM.2015.069776, DOI 10.1504/IJSNM.2015.069776]
   Lee DJ, 2009, DATA KNOWL ENG, V68, P1359, DOI 10.1016/j.datak.2009.07.008
   Lee S, 2013, IMAGE VISION COMPUT, V31, P823, DOI 10.1016/j.imavis.2013.08.007
   Lee T, 2011, IMAGE VISION COMPUT, V29, P639, DOI 10.1016/j.imavis.2011.08.003
   Lee TJ, 2012, NEUROCOMPUTING, V92, P61, DOI 10.1016/j.neucom.2011.09.034
   Leone A, 2006, PATTERN RECOGN LETT, V27, P345, DOI 10.1016/j.patrec.2005.08.020
   Lewis D. D., 1994, SIGIR '94. Proceedings of the Seventeenth Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, P3
   Lin CH, 2014, EXPERT SYST APPL, V41, P6611, DOI 10.1016/j.eswa.2014.04.033
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Liu H, 2005, IEEE T KNOWL DATA EN, V17, P491, DOI 10.1109/TKDE.2005.66
   Liu H., 2016, 13 AAAI C ART INT
   Liu L, 2013, PATTERN RECOGN, V46, P1810, DOI 10.1016/j.patcog.2012.10.004
   Liu L, 2013, SIGNAL PROCESS, V93, P1521, DOI 10.1016/j.sigpro.2012.07.017
   Liu Rui., 2017, Proceedings of the 2017 Workshop on Wearable Systems and Applications, P41
   Liu TL, 2016, IEEE T PATTERN ANAL, V38, P447, DOI 10.1109/TPAMI.2015.2456899
   Liu Y, 2003, COMPUT VIS IMAGE UND, V92, P147, DOI 10.1016/j.cviu.2003.06.003
   Lohr S., 2006, THE NEW YORK TIMES, V27
   Lopez-de-Ipiña K, 2015, COMPUT SPEECH LANG, V30, P43, DOI 10.1016/j.csl.2014.08.002
   Lu G., 2016, Multimedia Tools and Applications, P1
   Lu YY, 2014, NEUROCOMPUTING, V126, P132, DOI 10.1016/j.neucom.2012.08.071
   Ma Z., 2011, Proc. 19th ACM Int'l Conf. Multimedia, P283, DOI DOI 10.1145/2072298.2072336
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1662, DOI 10.1109/TMM.2012.2199293
   Ma ZG, 2012, IEEE T MULTIMEDIA, V14, P1021, DOI 10.1109/TMM.2012.2187179
   Malekesmaeili M, 2014, SIGNAL PROCESS, V98, P308, DOI 10.1016/j.sigpro.2013.11.023
   Manjunath R., 2014, INT J INNOV RES COMP, V2
   Manjunath TN, 2010, INT J COMPUT SCI NET, V10, P165
   Martí R, 2011, APPL MATH SCI, V175, P1, DOI 10.1007/978-3-642-16729-4_1
   Mencattini A, 2014, KNOWL-BASED SYST, V63, P68, DOI 10.1016/j.knosys.2014.03.019
   Mohammadi FG, 2014, ENG APPL ARTIF INTEL, V31, P35, DOI 10.1016/j.engappai.2013.09.016
   Momtazpour M., 2010, EL ENG ICEE 2010 18, P506
   Moradkhani M, 2015, APPL SOFT COMPUT, V35, P123, DOI 10.1016/j.asoc.2015.03.049
   Mueller Scott., 2006, Upgrading and repairing PCs, V17th
   Muhammad G, 2014, BIOMED SIGNAL PROCES, V11, P1, DOI 10.1016/j.bspc.2014.02.001
   Özer H, 2006, DIGIT SIGNAL PROCESS, V16, P389, DOI 10.1016/j.dsp.2005.12.001
   Pang-Ning Tan., 2006, Introduction to Data Mining
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Petrushin V., 2007, Multimedia data mining and knowledge discovery, P3, DOI DOI 10.1007/978-1-84628-799-2_1
   Pohjalainen J, 2015, COMPUT SPEECH LANG, V29, P145, DOI 10.1016/j.csl.2013.11.004
   Provost F., 1998, Machine Learning. Proceedings of the Fifteenth International Conference (ICML'98), P445
   Pudlo F., 2011, MULTIMEDIA DATA MINI, P78
   Qiao MY, 2013, INFORM SCIENCES, V231, P123, DOI 10.1016/j.ins.2012.10.013
   Raghavan H, 2006, J MACH LEARN RES, V7, P1655
   Rashedi E, 2013, KNOWL-BASED SYST, V39, P85, DOI 10.1016/j.knosys.2012.10.011
   Robertson S, 2008, P 31 ANN INT ACM SIG, P689, DOI DOI 10.1145/1390334.1390453
   Rockwell G., 2007, MULTIMEDIA COMPANION, P108
   Roy Nicholas, 2001, Toward optimal active learning through monte carlo estimation of error reduction, P441
   Ruta A, 2010, PATTERN RECOGN, V43, P416, DOI 10.1016/j.patcog.2009.05.018
   Santos Araken M., 2011, International Journal of Computer Information Systems and Industrial Management Applications, V3, P218
   Schaffernicht E, 2007, LECT NOTES COMPUT SC, V4669, P190
   See J, 2013, PATTERN RECOGN LETT, V34, P2057, DOI 10.1016/j.patrec.2013.07.004
   Seok JH, 2015, PATTERN RECOGN, V48, P3584, DOI 10.1016/j.patcog.2015.05.004
   Shi CJ, 2014, IMAGE VISION COMPUT, V32, P189, DOI 10.1016/j.imavis.2013.12.013
   Shivakumara P., 2009, ROBUST WAVELET TRANS, P1285
   Shrivastava N, 2015, COMPUT ELECTR ENG, V46, P314, DOI 10.1016/j.compeleceng.2014.11.009
   Singh A., 2006, MAC OS X INTERNALS S, P146
   Sivagaminathan RK, 2007, EXPERT SYST APPL, V33, P49, DOI 10.1016/j.eswa.2006.04.010
   Spolaór N, 2013, ELECTRON NOTES THEOR, V292, P135, DOI 10.1016/j.entcs.2013.02.010
   Spolaôr N, 2013, 2013 BRAZILIAN CONFERENCE ON INTELLIGENT SYSTEMS (BRACIS), P6, DOI 10.1109/BRACIS.2013.10
   Strehl A, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P93, DOI 10.1162/153244303321897735
   Sun ZH, 2004, PATTERN RECOGN, V37, P2165, DOI 10.1016/j.patcog.2004.03.013
   Szczypinski P, 2014, COMPUT METH PROG BIO, V113, P396, DOI [10.1016/j.cmpb.7017.09.004, 10.1016/j.cmpb.2012.09.004]
   Talavera L, 2005, LECT NOTES COMPUT SC, V3646, P440
   Tian YJ, 2011, PROCEDIA COMPUT SCI, V4, P1691, DOI 10.1016/j.procs.2011.04.183
   Tirunagari S., 2012, J GLOBAL RES COMPUTE, V3, P46
   Tolias G, 2014, COMPUT VIS IMAGE UND, V120, P31, DOI 10.1016/j.cviu.2013.12.002
   Tseng V. S., 2014, ADV KNOWLEDGE DISCOV
   Tsoumakas G., 2006, Multi-label classification: An overview
   Uzun E, 2014, SPEECH COMMUN, V61-62, P1, DOI 10.1016/j.specom.2014.03.003
   Verleysen M, 2005, LECT NOTES COMPUT SC, V3512, P758
   Wang M, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1899412.1899414
   Wang R, 2012, PATTERN RECOGN, V45, P3751, DOI 10.1016/j.patcog.2012.03.022
   Wang S, 2015, LECT NOTES ARTIF INT, V9284, P383, DOI 10.1007/978-3-319-23528-8_24
   Wang XD, 2016, J VIS COMMUN IMAGE R, V41, P272, DOI 10.1016/j.jvcir.2016.10.007
   Wei H, 2014, INT CONF FRONT HAND, P87, DOI [10.1109/ICFHR.2014.22, 10.1109/ISTC.2014.6955091]
   Wei XK, 2016, JMLR WORKSH CONF PRO, V51, P995
   Wei YC, 2012, EXPERT SYST APPL, V39, P10832, DOI 10.1016/j.eswa.2012.03.010
   Witten I. H., 2005, DATA MINING PRACTICA
   Wu QX, 2013, J VIS COMMUN IMAGE R, V24, P1064, DOI 10.1016/j.jvcir.2013.07.001
   Xie LX, 2009, SIGNALS COMMUN TECHN, P35, DOI 10.1007/978-0-387-76569-3_2
   Xu F, 2007, PATTERN RECOGN LETT, V28, P1581, DOI 10.1016/j.patrec.2007.03.016
   Xu Q, 2014, INFORM SCIENCES, V278, P736, DOI 10.1016/j.ins.2014.03.088
   Yan Y, 2014, COMPUT VIS IMAGE UND, V124, P99, DOI 10.1016/j.cviu.2014.02.006
   Yang Y, 2015, INT J COMPUT VISION, V113, P113, DOI 10.1007/s11263-014-0781-x
   Yang Y, 2013, IEEE T MULTIMEDIA, V15, P661, DOI 10.1109/TMM.2012.2237023
   Yao ZJ, 2013, NEUROCOMPUTING, V101, P258, DOI 10.1016/j.neucom.2012.08.023
   Ye QX, 2005, IMAGE VISION COMPUT, V23, P565, DOI 10.1016/j.imavis.2005.01.004
   Yoon H, 2013, EXPERT SYST APPL, V40, P231, DOI 10.1016/j.eswa.2012.07.018
   Yu J, 2001, PATTERN RECOGN LETT, V22, P1379, DOI 10.1016/S0167-8655(01)00085-X
   Yu J, 2013, SIGNAL PROCESS, V93, P1510, DOI 10.1016/j.sigpro.2012.06.011
   Yu SX, 2002, PATTERN RECOGN LETT, V23, P183, DOI 10.1016/S0167-8655(01)00118-0
   Yurtkan K, 2014, PATTERN RECOGN LETT, V38, P26, DOI 10.1016/j.patrec.2013.10.026
   Zeng ZQ, 2017, J VIS COMMUN IMAGE R, V48, P386, DOI 10.1016/j.jvcir.2017.01.030
   Zhang KH, 2013, IEEE T CIRC SYST VID, V23, P1957, DOI 10.1109/TCSVT.2013.2269772
   Zhang LJ, 2012, IEEE T IMAGE PROCESS, V21, P2379, DOI 10.1109/TIP.2012.2183879
   Zhang LF, 2013, NEUROCOMPUTING, V105, P51, DOI 10.1016/j.neucom.2012.06.040
   Zhang YS, 2014, KNOWL-BASED SYST, V64, P70, DOI 10.1016/j.knosys.2014.03.022
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151, DOI DOI 10.1145/1273496.1273641
   Zhou HY, 2010, NEUROCOMPUTING, V73, P1718, DOI 10.1016/j.neucom.2009.09.022
   Zhou X, 2008, PATTERN RECOGN, V41, P778, DOI 10.1016/j.patcog.2007.06.019
   Zhou Z, 2012, COMM COM INF SC, V321, P638
   Zipern A., 2001, NY TIMES
NR 183
TC 23
Z9 25
U1 0
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2017
VL 67
BP 29
EP 42
DI 10.1016/j.imavis.2017.09.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FM3DF
UT WOS:000414883800003
DA 2024-07-18
ER

PT J
AU Terzic, K
   Krishna, S
   du Buf, JMH
AF Terzic, Kasim
   Krishna, Sai
   du Buf, J. M. H.
TI Texture features for object salience
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Texture; Colour; Salience; Attention; Benchmark
ID VISUAL-ATTENTION; OVERT; MODEL
AB Although texture is important for many vision-related tasks, it is not used in most salience models. As a consequence, there are images where all existing salience algorithms fail. We introduce a novel set of texture features built on top of a fast model of complex cells in striate cortex, i.e., visual area V1. The texture at each position is characterised by the two-dimensional local power spectrum obtained from Gabor filters which are tuned to many scales and orientations. We then apply a parametric model and describe the local spectrum by the combination of two one-dimensional Gaussian approximations: the scale and orientation distributions. The scale distribution indicates whether the texture has a dominant frequency and what frequency it is. Likewise, the orientation distribution attests the degree of anisotropy. We evaluate the features in combination with the state-of-the-art VOCUS2 salience algorithm. We found that using our novel texture features in addition to colour improves AUC by 3.8% on the PASCAL-S dataset when compared to the colour-only baseline, and by 62% on a novel texture-based dataset. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Terzic, Kasim] Univ St Andrews, Sch Comp Sci, St Andrews, Fife, Scotland.
   [Krishna, Sai] Orebro Univ, Ctr Appl Autonomous Sensor Syst, Dept Sci & Technol, Orebro, Sweden.
   [Terzic, Kasim; Krishna, Sai; du Buf, J. M. H.] Univ Algarve, Dept Elect Engn & Comp Sci, Faro, Portugal.
C3 University of St Andrews; Orebro University; Universidade do Algarve
RP Terzic, K (corresponding author), Univ St Andrews, Sch Comp Sci, St Andrews, Fife, Scotland.
EM kt54@st-andrews.ac.uk; sai.krishna@oru.se; dubuf@ualg.pt
RI KRISHNA, Dr. S A MOHAN/AAT-9601-2020; du Buf, Hans/M-5125-2013
OI KRISHNA, Dr. S A MOHAN/0000-0002-9877-7189; du Buf,
   Hans/0000-0002-4345-1237
FU EU [ICT-2009.2.1-270247]; FCT [LarSYS UlD/EEA/50009/2013,
   EXPL/EEI-SII/1982/2013]; Fundação para a Ciência e a Tecnologia
   [EXPL/EEI-SII/1982/2013] Funding Source: FCT
FX This work was supported by the EU under the FP-7 grant
   ICT-2009.2.1-270247 NeuralDynamics and by the FCT under the grants
   LarSYS UlD/EEA/50009/2013 and SparseCoding EXPL/EEI-SII/1982/2013.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ahmadvand A, 2016, KNOWL-BASED SYST, V97, P75, DOI 10.1016/j.knosys.2016.01.015
   Ahmadvand A, 2016, IMAGE VISION COMPUT, V45, P1, DOI 10.1016/j.imavis.2015.10.002
   [Anonymous], SPATIOTEMPORAL SALIE
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Chen HY, 2008, 8TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY WORKSHOPS: CIT WORKSHOPS 2008, PROCEEDINGS, P374, DOI 10.1109/CIT.2008.Workshops.8
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Doretto G., 2003, INT J COMPUT VIS, V51
   du Buf JMH, 2007, IMAGE VISION COMPUT, V25, P873, DOI 10.1016/j.imavis.2006.06.005
   Du Buf J. M. H., 1992, Spatial Vision, V6, P221, DOI 10.1163/156856892X00109
   Duan LJ, 2011, PROC CVPR IEEE, P473, DOI 10.1109/CVPR.2011.5995676
   Frintrop S., 2015, TRADITIONAL SALIENCY
   Gao D., 2007, BOTTOM UP SALIENCY I, P1
   Gao D., 2008, DISCRIMINANT CTR SUR, P497
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Grigorescu SE, 2002, IEEE T IMAGE PROCESS, V11, P1160, DOI 10.1109/TIP.2002.804262
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J., 2006, GRAPH BASED VISUAL S, P545
   HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L
   Hou X., 2007, Saliency Detection: A spectral Residual Approach
   Hu Y., 2004, SALIENT REGION DETEC, P993
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Itti L., 2005, BAYESIAN SURPRISE AT, P547
   Jiang H., 2013, SALIENT OBJECT DETEC
   Kalinke Thomas., 1998, IEEE Intelligent Vehicles Symposium, P341
   Klein D. A., 2011, CTR SURROUND DIVERGE
   Klein D. A., 2012, EUR C VIS PERC ECVP
   Kreutzmann A., 2009, WORKSH US CONT VIS P
   LANDY MS, 1991, VISION RES, V31, P679, DOI 10.1016/0042-6989(91)90009-T
   Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9
   Liu T., 2007, LEARNING DETECT SALI
   MALIK J, 1990, J OPT SOC AM A, V7, P923, DOI 10.1364/JOSAA.7.000923
   Martins JA, 2015, BIOSYSTEMS, V135, P35, DOI 10.1016/j.biosystems.2015.07.001
   Momtaz HZ, 2016, COGN NEURODYNAMICS, V10, P31, DOI 10.1007/s11571-015-9357-x
   MUMFORD D, 1991, BIOL CYBERN, V65, P135, DOI 10.1007/BF00202389
   Neumann B., 2010, CONTEXT BASED PROBAB, P155
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   Pan J., 2017, CVPR SCEN U IN PRESS
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Qi XB, 2015, IMAGE VISION COMPUT, V43, P16, DOI 10.1016/j.imavis.2015.07.005
   Schauerte B, 2012, LECT NOTES COMPUT SC, V7573, P116, DOI 10.1007/978-3-642-33709-3_9
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Syeda-Mahmood TF, 1999, COMPUT VIS IMAGE UND, V76, P93, DOI 10.1006/cviu.1999.0784
   TERZIC K, 2015, PAR SPECTR MOD TEXT, V9358, P331
   Terzic K., 2010, INT C AG ART INT VAL
   Terzic K, 2015, NEUROCOMPUTING, V150, P227, DOI 10.1016/j.neucom.2014.09.054
   Terzic K, 2013, IEEE IMAGE PROC, P3372, DOI 10.1109/ICIP.2013.6738695
   Terzie Kasim, 2013, Computer Vision Systems. 9th International Conference, ICVS 2013. Proceedings: LNCS 7963, P113, DOI 10.1007/978-3-642-39402-7_12
   Wang Q, 2013, PATTERN RECOGN LETT, V34, P34, DOI 10.1016/j.patrec.2012.06.002
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Xie J, 2016, IMAGE VISION COMPUT, V55, P86, DOI 10.1016/j.imavis.2016.03.006
   Yan Q., 2013, HIERARCHICAL SALIENC
NR 58
TC 3
Z9 4
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2017
VL 67
BP 43
EP 51
DI 10.1016/j.imavis.2017.09.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FM3DF
UT WOS:000414883800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kossaifi, J
   Tzirniropoulos, G
   Todorovic, S
   Pantic, M
AF Kossaifi, Jean
   Tzirniropoulos, Georgios
   Todorovic, Sinisa
   Pantic, Maja
TI AFEW-VA database for valence and arousal estimation in-the-wild
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Continuous affect estimation in-the-wild; Dimensional affect recognition
   in-the-wild; Valence; Arousal; Facial expressions; Dimensional emotion
   modelling
ID FEATURES; BEHAVIOR; SCALE
AB Continuous dimensional models of human affect, such as those based on valence and arousal, have been shown to be more accurate in describing a broad range of spontaneous, everyday emotions than the more traditional models of discrete stereotypical emotion categories (e.g. happiness, surprise). However, most prior work on estimating valence and arousal considered only laboratory settings and acted data. It is unclear whether the findings of these studies also hold when the methodologies proposed in these works are tested on data collected in-the-wild. In this paper we investigate this. We propose a new dataset of highly accurate per-frame annotations of valence and arousal for 600 challenging video clips extracted from feature films (also used in part for the AFEW dataset). For each video clip, we further provide per-frame annotations of 68 facial landmarks. We subsequently evaluate a number of common baseline and state-of-the-art methods on both a commonly used laboratory recording dataset (Semaine database) and the newly proposed recording set (AFEW-VA). Our results show that geometric features perform well independently of the settings. However, as expected, methods that perform well on constrained data do not necessarily generalise to uncontrolled data and vice-versa. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Kossaifi, Jean; Pantic, Maja] Imperial Coll London, Dept Comp, London SW7 2AZ, England.
   [Tzirniropoulos, Georgios] Univ Nottingham, Sch Comp Sci, Nottingham NG8 1BB, England.
   [Todorovic, Sinisa] Oregon State Univ, Sch EECS, Corvallis, OR 97331 USA.
   [Pantic, Maja] Univ Twente, EEMCS, Enschede, Netherlands.
C3 Imperial College London; University of Nottingham; Oregon State
   University; University of Twente
RP Kossaifi, J (corresponding author), Imperial Coll London, Dept Comp, London SW7 2AZ, England.
EM jean.kossaifi@gmail.com
RI Kossaifi, Jean/AAW-8519-2021
OI Kossaifi, Jean/0000-0002-4445-3429
FU European Community Horizon [645094]; NSF [RI 1302700]
FX The work of Jean Kossaifi and Maja Pantic has been funded by the
   European Community Horizon 2020 [H2020/2014-2020] under grant agreement
   no. 645094 (SEWA). For this work, Sinisa Todorovic has been supported in
   part by grant NSF RI 1302700.
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Amirian M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P67, DOI 10.1145/2988257.2988260
   [Anonymous], P 4 INT WORKSH AUD V
   [Anonymous], 2013, P 3 ACM INT WORKSHOP
   [Anonymous], P 4 INT WORKSH AUD V
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2008, PROC 25 INT C MACH L
   [Anonymous], 16 ACM INT C MULT IN
   [Anonymous], 2015, P 5 INT WORK AUD VIS
   [Anonymous], 2014, P 4 INT WORKSH AUD V
   [Anonymous], 2010, BLUEPRINT AFFECTIVE
   [Anonymous], 2011, IEEE T AFFECTIVE COM
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P 5 INT WORKSH AUD V
   [Anonymous], AUT FAC GEST REC FG
   [Anonymous], 2015, P P ACM MULT WORKSH
   [Anonymous], 2013, 10 IEEE INT C WORKSH
   [Anonymous], P 4 INT WORKSH AUD V
   Bilakhia S, 2015, PATTERN RECOGN LETT, V66, P52, DOI 10.1016/j.patrec.2015.03.005
   Brady K, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P97, DOI 10.1145/2988257.2988264
   Cardinal P., 2015, ACM MULTIMEDIA C, P17
   Chao L, 2015, P 5 INT WORKSH AUD V, P65, DOI [DOI 10.1145/2808196.2811634, 10.1145/2808196.2811634]
   Chen H, 2015, PROC CVPR IEEE, P1836, DOI 10.1109/CVPR.2015.7298793
   Cowie R., 2000, PROC ISCA WORKSHOP S, P19
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Douglas-Cowie E, 2007, LECT NOTES COMPUT SC, V4738, P488
   Ekman P., 2002, FACIAL ACTION CODING
   Grimm M, 2005, 2005 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P381
   Grimm M, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P865, DOI 10.1109/ICME.2008.4607572
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   He Lang, 2015, P 5 INT WORKSH AUD V
   Huang Z, 2015, P 5 INT WORKSH AUD V, P41, DOI 10.1145/2808196.2811640
   K_achele M., 2015, AVEC 2015-Proceedings of the 5th International Workshop on Audio/Visual Emotion Challenge, co-Located with MM 2015, P9, DOI [DOI 10.1145/2808196.2811637, 10.1145/2808196.2811637]
   Kaltwang S, 2016, IEEE T PATTERN ANAL, V38, P1748, DOI 10.1109/TPAMI.2015.2501824
   Kaltwang S, 2015, PROC CVPR IEEE, P296, DOI 10.1109/CVPR.2015.7298626
   Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kossaifi J, 2017, IEEE T IMAGE PROCESS, V26, P1040, DOI 10.1109/TIP.2016.2642828
   Kossaifi J, 2014, IEEE IMAGE PROC, P1420, DOI 10.1109/ICIP.2014.7025284
   Kossatfi J, 2015, IEEE IMAGE PROC, P1135, DOI 10.1109/ICIP.2015.7350977
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   McDuff D, 2013, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2013.130
   McKeown G, 2012, IEEE T AFFECT COMPUT, V3, P5, DOI 10.1109/T-AFFC.2011.20
   Meng H., 2013, P 3 ACM INT WORKSH A, P21, DOI [10.1145/2512530.2512532., DOI 10.1145/2512530.2512532]
   Meng HY, 2016, IEEE T CYBERNETICS, V46, P916, DOI 10.1109/TCYB.2015.2418092
   Müller AC, 2014, J MACH LEARN RES, V15, P2055
   Nicolaou Mihalis A., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P16, DOI 10.1109/FG.2011.5771396
   Nicolaou MA, 2014, IEEE T PATTERN ANAL, V36, P1299, DOI 10.1109/TPAMI.2014.16
   Nicolaou MA, 2012, IMAGE VISION COMPUT, V30, P186, DOI 10.1016/j.imavis.2011.12.005
   Nicolaou MihalisA., 2013, Proceedings of the 21st ACM international conference on Multimedia, P773
   Nicolle J, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P501
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Panagakis Y, 2016, IEEE T PATTERN ANAL, V38, P1665, DOI 10.1109/TPAMI.2015.2497700
   Pantic M, 2003, P IEEE, V91, P1370, DOI 10.1109/JPROC.2003.817122
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Petridis S, 2013, IMAGE VISION COMPUT, V31, P186, DOI 10.1016/j.imavis.2012.08.014
   Povolny F, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P75, DOI 10.1145/2988257.2988268
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Ringeval F, 2015, PATTERN RECOGN LETT, V66, P22, DOI 10.1016/j.patrec.2014.11.007
   Rudovic O, 2012, PROC CVPR IEEE, P2634, DOI 10.1109/CVPR.2012.6247983
   Russakovsky J., 2015, INT COMPUT VIS IJCV, P1
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Schroder Marc, 2009, 3 INT C AFF COMP INT, P1
   Schuller B, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P449
   Schuller B, 2011, LECT NOTES COMPUT SC, V6975, P415, DOI 10.1007/978-3-642-24571-8_53
   Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Sneddon I, 2012, IEEE T AFFECT COMPUT, V3, P32, DOI 10.1109/T-AFFC.2011.26
   Soladié C, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P493
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Somandepalli K, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P59, DOI 10.1145/2988257.2988259
   Sun B, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P83, DOI 10.1145/2988257.2988270
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Valstar M., 2014, P 4 INT WORKSH AUD V, P3, DOI 10.1109/FG.2015.7284874
   Valstar M., 2013, P 3 ACM INT WORKSHOP, DOI [10.1145/2512530.2512533, DOI 10.1145/2512530.2512533]
   Valstar Michel F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P921, DOI 10.1109/FG.2011.5771374
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P966, DOI 10.1109/TSMCB.2012.2200675
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wöllmer M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P597
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 87
TC 128
Z9 134
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2017
VL 65
SI SI
BP 23
EP 36
DI 10.1016/j.imavis.2017.02.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FJ3GM
UT WOS:000412618500004
OA Green Published
DA 2024-07-18
ER

PT J
AU Gong, H
   Cosker, D
AF Gong, Han
   Cosker, Darren
TI User-assisted image shadow removal
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image shadow removal; User-assisted computer vision; Colour correction;
   Curve fitting; Smoothing
AB This paper presents a novel user-aided method for texture-preserving shadow removal from single images requiring simple user input. Compared with the state-of-the-art, our algorithm offers the most flexible user interaction to date and produces more accurate and robust shadow removal under thorough quantitative evaluation. Shadow masks are first detected by analysing user specified shadow feature strokes. Sample intensity profiles with variable interval and length around the shadow boundary are detected next, which avoids artefacts raised from uneven boundaries. Texture noise in samples is then removed by applying local group bilateral filtering, and initial sparse shadow scales are estimated by fitting a piecewise curve to intensity samples. The remaining errors in estimated sparse scales are removed by local group smoothing. To relight the image, a dense scale field is produced by in-painting the sparse scales. Finally, a gradual colour correction is applied to remove artefacts due to image post-processing. Using state-of-the-art evaluation data, we quantitatively and qualitatively demonstrate our method to outperform current leading shadow removal methods. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Gong, Han] Univ East Anglia, Sch Comp Sci, Norwich, Norfolk, England.
   [Cosker, Darren] Univ Bath, Dept Comp Sci, Bath, Avon, England.
C3 University of East Anglia; University of Bath
RP Gong, H (corresponding author), Univ East Anglia, Sch Comp Sci, Norwich, Norfolk, England.
EM h.gong@uea.ac.uk; dpc@cs.bath.ac.uk
RI Li, Mengqi/AAG-6804-2021
OI Cosker, Darren/0000-0001-5177-4741
FU Engineering and Physical Sciences Research Council (EPSRC)
   [EP/M023281/1, EP/M001768/1]; EPSRC [EP/M001768/1, EP/M023281/1] Funding
   Source: UKRI
FX This work was supported by Engineering and Physical Sciences Research
   Council (EPSRC) (EP/M023281/1, EP/M001768/1).
CR [Anonymous], BRIT MACH VIS C
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2 DIMENSIONAL SIGNAL
   [Anonymous], IM PROC 1995 P INT C
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2004, COMPUT VIS IMAGE UND, DOI DOI 10.1016/j.cviu.2004.03.008
   Arbel E, 2011, IEEE T PATTERN ANAL, V33, P1202, DOI 10.1109/TPAMI.2010.157
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Drew MS, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P257, DOI 10.1109/ICME.2006.262431
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Finlayson G., 2007, INT C COMPUTER VISIO, P1
   Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   Garcia D, 2010, COMPUT STAT DATA AN, V54, P1167, DOI 10.1016/j.csda.2009.09.020
   Huang JB, 2009, PROC CVPR IEEE, P2310, DOI 10.1109/CVPRW.2009.5206629
   Lalonde JF, 2010, LECT NOTES COMPUT SC, V6312, P322, DOI 10.1007/978-3-642-15552-9_24
   Liu F, 2008, LECT NOTES COMPUT SC, V5305, P437
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Salamati N, 2011, IEEE IMAGE PROC, P1713, DOI 10.1109/ICIP.2011.6115788
   SEBER G. A., 2009, Multivariate observations, V252
   Shor Y, 2008, COMPUT GRAPH FORUM, V27, P577, DOI 10.1111/j.1467-8659.2008.01155.x
   Su YF, 2010, IEEE T IMAGE PROCESS, V19, P2749, DOI 10.1109/TIP.2010.2050626
   Wu TP, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1243980.1243982
   Yang QX, 2012, IEEE T IMAGE PROCESS, V21, P4361, DOI 10.1109/TIP.2012.2208976
   Yao J, 2006, COMPUT VIS IMAGE UND, V102, P60, DOI 10.1016/j.cviu.2005.09.003
   Zhang L, 2015, IEEE T IMAGE PROCESS, V24, P4623, DOI 10.1109/TIP.2015.2465159
   Zhu JJ, 2010, PROC CVPR IEEE, P223, DOI 10.1109/CVPR.2010.5540209
NR 29
TC 14
Z9 16
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2017
VL 62
BP 19
EP 27
DI 10.1016/j.imavis.2017.04.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EX3GV
UT WOS:000403121500003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Zhu, PF
   Zhu, WC
   Wang, WZ
   Zuo, WM
   Hu, QH
AF Zhu, Pengfei
   Zhu, Wencheng
   Wang, Weizhi
   Zuo, Wangmeng
   Hu, Qinghua
TI Non-convex regularized self-representation for unsupervised feature
   selection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Self-representation; Unsupervised feature selection; Sparse
   representation; Group sparsity
ID CLASSIFICATION; CARCINOMAS
AB Feature selection aims to select a subset of features to decrease time complexity, reduce storage burden and improve the generalization ability of classification or clustering. For the countless unlabeled high dimensional data, unsupervised feature selection is effective in alleviating the curse of dimensionality and can find applications in various fields. In this paper, we propose a non-convex regularized self-representation (RSR) model where features can be represented by a linear combination of other features, and propose to impose L-2.p-norm (0 <= p < 1) regularization on self-representation coefficients for unsupervised feature selection. Compared with the conventional L-2.(1)-norm regularization, when p < 1, much sparser solution is obtained on the self-representation coefficients, and it is also more effective in selecting salient features. To solve the non-convex (0 < p < 1) RSR model, we further propose an efficient iterative reweighted least square (IRLS) algorithm with guaranteed convergence to a stationary point. When p = 0, we exploit the augmented Lagrangian method (ALM) to solve the RSR model. Extensive experimental results on nine datasets show that our feature selection method with small p is more effective. It mostly outperforms RSR with p = 1 and other state-of-the-art unsupervised feature selection methods in terms of classification accuracy and clustering performance. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Wang, Weizhi; Zuo, Wangmeng] Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
   [Zhu, Pengfei; Zhu, Wencheng; Hu, Qinghua] Tianjin Univ, Sch Comp Sci & Technol, Tianjin 300072, Peoples R China.
C3 Harbin Institute of Technology; Tianjin University
RP Zuo, WM (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Harbin 150001, Peoples R China.
RI Hu, Qinghua/B-8857-2008; zhou, xian/JYQ-9844-2024; Zuo,
   Wangmeng/B-3701-2008
CR [Anonymous], 2005, ADV NEURAL INF PROCE
   [Anonymous], 2011, IJCAI INT JOINT C AR
   Bertsekas D. P., 2014, CONSTRAINED OPTIMIZA
   Bhattacharjee A, 2001, P NATL ACAD SCI USA, V98, P13790, DOI 10.1073/pnas.191502998
   Cai D., 2010, KDD, P333
   Cai X., 2013, P 23 INT JOINT C ART
   Cong Y, 2016, NEUROCOMPUTING, V196, P150, DOI 10.1016/j.neucom.2015.10.130
   Dy JG, 2004, J MACH LEARN RES, V5, P845
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   He R, 2012, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2012.6247966
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Li Z., 2012, UNSUPERVISED FEATURE, P1026
   Lin, 2010, ARXIV10095055
   Luo DJ, 2013, KNOWL INF SYST, V36, P411, DOI 10.1007/s10115-012-0545-2
   Mitra P, 2002, IEEE T PATTERN ANAL, V24, P301, DOI 10.1109/34.990133
   Nie F., 2008, P 23 NATL C ARTIFICI, V2, P671
   Nie F., 2010, ADV NEURAL INFORM PR, P1813
   Nutt CL, 2003, CANCER RES, V63, P1602
   Su AI, 2001, CANCER RES, V61, P7388
   Tang J., 2012, P 18 ACM SIGKDD INT, P904, DOI DOI 10.1145/2339530.2339673
   Wang WZ, 2015, LECT NOTES COMPUT SC, V9243, P55, DOI 10.1007/978-3-319-23862-3_6
   Wang YL, 2008, SIAM J IMAGING SCI, V1, P248, DOI 10.1137/080724265
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yao J, 2015, PATTERN RECOGN LETT, V53, P100, DOI 10.1016/j.patrec.2014.11.006
   Zhao Z., 2007, P 24 INT C MACHINE L, P1151
   Zhao Z, 2010, AAAI CONF ARTIF INTE, P673
   Zhou N, 2016, PATTERN RECOGN, V53, P87, DOI 10.1016/j.patcog.2015.12.008
   Zhu J, 2004, ADV NEUR IN, V16, P49
   Zhu PF, 2015, PATTERN RECOGN, V48, P438, DOI 10.1016/j.patcog.2014.08.006
NR 30
TC 29
Z9 31
U1 1
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 22
EP 29
DI 10.1016/j.imavis.2016.11.014
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800003
DA 2024-07-18
ER

PT J
AU Castrillón-Santana, M
   Lorenzo-Navarro, J
   Ramón-Balmaseda, E
AF Castrillon-Santana, M.
   Lorenzo-Navarro, J.
   Ramon-Balmaseda, E.
TI Descriptors and regions of interest fusion for in- and cross-database
   gender classification in the wild
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gender classification; Local descriptors; HOG; LBP; LSP; LOSIB;
   Information fusion; Face local context; Cross-database; CNN
ID LOCAL BINARY PATTERNS; RECOGNITION; SCALE
AB Gender classification (GC) has achieved high accuracy in different experimental evaluations based mostly on inner facial details. However, these results do not generalize well in unrestricted datasets and particularly in cross-database experiments, where the performance drops drastically. In this paper, we analyze the state-of-the-art GC accuracy on three large datasets: MORPH, LFW and GROUPS. We discuss their respective difficulties and bias, concluding that the most challenging and wildest complexity is present in GROUPS. This dataset covers hard conditions such as low resolution imagery and cluttered background. Firstly, we analyze in depth the performance of different descriptors extracted from the face and its local context on this dataset. Selecting the bests and studying their most suitable combination allows us to design a solution that beats any previously published results for GROUPS with the Dago's protocol, reaching an accuracy over 94.22% reducing the gap with other simpler datasets. The chosen solution based on local descriptors is later evaluated in a cross-database scenario with the three mentioned datasets, and full dataset 5-fold cross validation. The achieved results are compared with a Convolutional Neural Network approach, achieving rather similar marks. Finally, a solution is proposed combining both focuses, exhibiting great complementarity, boosting GC performance to beat previously published results in GC both cross-database, and full in-database evaluations. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Castrillon-Santana, M.; Lorenzo-Navarro, J.; Ramon-Balmaseda, E.] ULPGC, SIANI, Las Palmas Gran Canaria, Spain.
C3 Universidad de Las Palmas de Gran Canaria
RP Castrillón-Santana, M (corresponding author), ULPGC, SIANI, Las Palmas Gran Canaria, Spain.
EM modesto.castrillon@ulpgc.es
RI Castrillón-Santana, Modesto/C-6662-2008; Navarro, Javier
   Lorenzo/L-1972-2014
OI Castrillón-Santana, Modesto/0000-0002-8673-2725; Navarro, Javier
   Lorenzo/0000-0002-2834-2067
FU Spanish Ministry of Economy and Competitivity [TIN2015 64395-R]
FX Work partially funded by the project TIN2015 64395-R from the Spanish
   Ministry of Economy and Competitivity.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alexandre LA, 2010, PATTERN RECOGN LETT, V31, P1422, DOI 10.1016/j.patrec.2010.02.010
   Andreu Y, 2014, IMAGE VISION COMPUT, V32, P27, DOI 10.1016/j.imavis.2013.11.001
   [Anonymous], INT C BIOM ICB
   [Anonymous], IEEE S SER COMP INT
   [Anonymous], NATURE
   [Anonymous], 2007, TECH REP
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], TECH REP
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], 22 IEEE INT C PATT R
   [Anonymous], 18 INT C IM AN PROC
   [Anonymous], 2014, LEARNING FACE REPRES
   Antipov G, 2016, PATTERN RECOGN LETT, V70, P59, DOI 10.1016/j.patrec.2015.11.011
   Baluja S, 2007, INT J COMPUT VISION, V71, P111, DOI 10.1007/s11263-006-8910-9
   Bekios-Calfa J, 2014, PATTERN RECOGN LETT, V36, P228, DOI 10.1016/j.patrec.2013.04.028
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Bourdev L, 2011, IEEE I CONF COMP VIS, P1543, DOI 10.1109/ICCV.2011.6126413
   Castrilln-Santana M., 2013, 18 IB C PATT REC CIA, V8259, P270, DOI DOI 10.1007/978-3-642-41827-3_34
   Castrillon-Santana M, 2016, PATTERN RECOGN LETT, V82, P181, DOI 10.1016/j.patrec.2015.09.014
   Chen HZ, 2012, LECT NOTES COMPUT SC, V7574, P609, DOI 10.1007/978-3-642-33712-3_44
   Chen HZ, 2014, IEEE T PATTERN ANAL, V36, P1860, DOI 10.1109/TPAMI.2014.2302443
   Collins Matthew, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1235, DOI 10.1109/ICCVW.2009.5457467
   Dago-Casas P., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2152, DOI 10.1109/ICCVW.2011.6130514
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danisman T, 2015, EXPERT SYST APPL, V42, P2772, DOI 10.1016/j.eswa.2014.11.023
   Danisman T, 2014, INT C PATT RECOG, P3144, DOI 10.1109/ICPR.2014.542
   Déniz O, 2011, PATTERN RECOGN LETT, V32, P1598, DOI 10.1016/j.patrec.2011.01.004
   El-Din Yomna Safaa, 2013, Multiple Classifier Systems. 11th International Workshop, MCS 2013. Proceedings, P49, DOI 10.1007/978-3-642-38067-9_5
   Erdogmus N, 2014, 2014 IEEE 16 INT WOR, P1
   Freire-Obregón D, 2014, IEEE IMAGE PROC, P4972, DOI 10.1109/ICIP.2014.7026007
   Gallagher AC, 2009, PROC CVPR IEEE, P256, DOI 10.1109/CVPRW.2009.5206828
   Guo GD, 2014, IMAGE VISION COMPUT, V32, P761, DOI 10.1016/j.imavis.2014.04.011
   Guo GD, 2010, LECT NOTES COMPUT SC, V5996, P236
   Hadid A, 2009, PATTERN RECOGN, V42, P2818, DOI 10.1016/j.patcog.2009.02.011
   Jia S, 2015, PATTERN RECOGN LETT, V58, P35, DOI 10.1016/j.patrec.2015.02.006
   Klare Brendan., 2010, Fourth IEEE International Conference on Biometrics: Theory Applications and Systems (BTAS). IEEE, P1, DOI DOI 10.1109/BTAS.2010.5634533
   Kumar N., IEEE T PATTERN ANAL
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Levi Gil, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P34, DOI 10.1109/CVPRW.2015.7301352
   Li B, 2012, NEUROCOMPUTING, V76, P18, DOI 10.1016/j.neucom.2011.01.028
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Ludwig D., 2009, 12 INT IEEE C INTELL, P1
   Mäkinen E, 2008, IEEE T PATTERN ANAL, V30, P541, DOI 10.1109/TPAMI.2007.70800
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Ng CB, 2015, PATTERN ANAL APPL, V18, P739, DOI 10.1007/s10044-015-0499-6
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Ramon-Balmaseda Enrique, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P74, DOI 10.1007/978-3-642-33275-3_9
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Russell R, 2009, PERCEPTION, V38, P1211, DOI 10.1068/p6331
   Shan CF, 2012, PATTERN RECOGN LETT, V33, P431, DOI 10.1016/j.patrec.2011.05.016
   Tapia JE, 2013, IEEE T INF FOREN SEC, V8, P488, DOI 10.1109/TIFS.2013.2242063
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Toseeb U, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034144
   Vapnik V., 1999, NATURE STAT LEARNING
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
NR 58
TC 19
Z9 21
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 15
EP 24
DI 10.1016/j.imavis.2016.10.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wang, SP
   Huang, AP
AF Wang, Shiping
   Huang, Aiping
TI Salient object detection with low-rank approximation and
   <i>l</i><sub>2,1</sub>-norm minimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Compute vision; Image processing; Saliency detection; Sparse coding;
   Low-rank approximation; l(2,1)-norm minimization
ID LEARNING SALIENCY; ATTENTION; IMAGE; MODEL
AB Salient object detection is an important issue in computer vision and image procession in that it can facilitate humans to locate conspicuous visual regions in complex scenes rapidly and improve the performance of object detection and video tracking. In recent years, low-rank matrix approximation has been proved to be favorable in image saliency detection and gained a great deal of attention. An underlying assumption of low rank recovery is that an image is a combination of background regions being low-rank and salient objects being sparse, which corresponds to tough non-smooth optimization problems. In this paper, by incorporating 2,1-norm minimization, we obtain the corresponding smooth optimization problems and propose two effective algorithms with proved convergence. To guarantee the robustness of the proposed methods, the input image is divided into patches and each patch is approximately represented by its mean Value. Besides, multi-scale visual features of each patch of the given image are extracted to capture common low-level features such as color, edge, shape and texture. The salient objects of a given image are indicated with sparse coefficients solved by the low-rank matrix approximation problem. Saliency maps are further produced with integration of the high-level prior knowledge. Finally, extensive experiments in four real world datasets demonstrate that the proposed methods come with competitive performance over the eight compared state-of-the-arts. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Wang, Shiping] Fuzhou Univ, Coll Math & Comp Sci, Fuzhou 350116, Peoples R China.
   [Wang, Shiping] Fuzhou Univ, Fujian Prov Key Lab Network Comp & Intelligent In, Fuzhou 350116, Peoples R China.
   [Huang, Aiping] Xiamen Univ, Tan Kah Kee Coll, Zhangzhou 363105, Peoples R China.
C3 Fuzhou University; Fuzhou University; Xiamen University
RP Huang, AP (corresponding author), Xiamen Univ, Tan Kah Kee Coll, Zhangzhou 363105, Peoples R China.
EM sxxhap@163.com
RI Huang, Aiping/GQY-9395-2022
FU National Natural Science Foundation of China [61502104]
FX This work is partly supported by the National Natural Science Foundation
   of China under Grant No. 61502104.
CR Agrawal P, 2014, SIGNAL PROCESS, V99, P29, DOI 10.1016/j.sigpro.2013.12.010
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C IM PROC
   [Anonymous], IEEE 12 INT C COMP V
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 2010, EUR C COMP VIS
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], IEEE 12 INT C COMP V
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 2008, ADV NEURAL INFORM PR
   [Anonymous], AUGMENTED LAGRANGE M
   [Anonymous], 24 BRIT MACH VIS C
   [Anonymous], 2015, IEEE T IMAGE PROCESS, DOI DOI 10.1109/TIP.2015.2487833
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], 2012, EUR C COMP VIS
   [Anonymous], COMPUTER VISION SYST
   [Anonymous], 2013, IEEE C COMP VIS PATT
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], 2010, ADV NEURAL INFORM PR
   [Anonymous], IEEE INT C AC SPEECH
   [Anonymous], PROC
   [Anonymous], 1998, Gabor Analysis and Algorithms
   Bruce N, 2005, ADV NEURAL INF PROCE, V18
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   FAN K, 1949, P NATL ACAD SCI USA, V35, P652, DOI 10.1073/pnas.35.11.652
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Gao DS, 2009, IEEE T PATTERN ANAL, V31, P989, DOI 10.1109/TPAMI.2009.27
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Liang Z, 2014, IEEE T CYBERNETICS, V44, P1249, DOI 10.1109/TCYB.2013.2281618
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Marchesotti L, 2009, IEEE I CONF COMP VIS, P2232, DOI 10.1109/ICCV.2009.5459467
   Peng H, 2013, P 27 AAAI C ART INT
   Perazzi F., 2012, IEEE C COMP VIS PATT
   Rubinstein M, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360615
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Wang Q, 2013, IEEE T CYBERNETICS, V43, P660, DOI 10.1109/TSMCB.2012.2214210
   Wright J., 2009, ADV NEURAL INFORM PR, V22
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yan Q., 2013, IEEE C COMP VIS PATT
   Yu JG, 2014, IEEE T CYBERNETICS, V44, P1661, DOI 10.1109/TCYB.2013.2292054
   Yücel Z, 2013, IEEE T CYBERNETICS, V43, P829, DOI 10.1109/TSMCB.2012.2216979
   Zhang Q, 2013, SIGNAL PROCESS, V93, P2485, DOI 10.1016/j.sigpro.2013.03.018
   Zhang TZ, 2015, INT J COMPUT VISION, V111, P171, DOI 10.1007/s11263-014-0738-0
   Zhang TZ, 2013, INT J COMPUT VISION, V101, P367, DOI 10.1007/s11263-012-0582-z
   Zhao Q, 2013, SIGNAL PROCESS, V93, P1401, DOI 10.1016/j.sigpro.2012.06.014
   Zhu GK, 2014, IEEE T CYBERNETICS, V44, P1014, DOI 10.1109/TCYB.2013.2279002
   Zhu GK, 2013, IEEE T CYBERNETICS, V43, P2032, DOI 10.1109/TSMCB.2013.2238927
NR 51
TC 3
Z9 3
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 67
EP 77
DI 10.1016/j.imavis.2016.10.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800006
DA 2024-07-18
ER

PT J
AU Romero-Manchado, A
   Rojas-Sola, JI
AF Romero-Manchado, Antonio
   Rojas-Sola, Jose Ignacio
TI Application of gradient-based edge detectors to determine vanishing
   points in monoscopic images: Comparative study
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vanishing point; Thales' theorem; Monoscopic image; Discrete gradient
   operators; Edge detector
AB The detection of vanishing points in a monoscopic image is a first step to the extraction of 3D data. This article shows a partition of the image space in order to determine the type of perspective which is present, thereby allowing the determination of the vanishing point associated with each of the axes of the special reference system (X, Y, Z). Additionally, the Thales' second theorem allows us to determine the position of the vanishing points of the image and to automatize the process. An algorithm has been used with the data provided by the selected edge detector (Prewitt, Roberts, Sobel, Frei-Chen, Kirsch, Robinson 3 levels, Robinson 5 levels and Frei-Chen directional), which provides the location of the vanishing points contained on the image plane. The comparative study includes two variables: the number of vanishing points and the image resolution. The results show that in general the Prewitt's edge detector provides the best results, both positional and statistical. Increasing the image resolution improves the results, although the results obtained for a resolution of 640 x 480 pixels and another of 1024 x 768 pixels are very similar. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Romero-Manchado, Antonio] Univ Jaen, Dept Cartog Engn Geodesy & Photogrammetry, Jaen 23071, Spain.
   [Rojas-Sola, Jose Ignacio] Univ Jaen, Dept Engn Graph Design & Projects, Jaen 23071, Spain.
C3 Universidad de Jaen; Universidad de Jaen
RP Rojas-Sola, JI (corresponding author), Univ Jaen, Campus Lagunillas S-N, Jaen 23071, Spain.
EM aromero@ujaen.es; jirojas@ujaen.es
RI Rojas-Sola, José Ignacio/C-9784-2011; Romero-Manchado,
   Antonio/I-2129-2015
OI Rojas-Sola, José Ignacio/0000-0001-9001-1050; Romero-Manchado,
   Antonio/0000-0002-3555-544X
CR Aguilera D.G., 2005, ISPRS ARCH, VXXXVI
   Almansa A, 2003, IEEE T PATTERN ANAL, V25, P502, DOI 10.1109/TPAMI.2003.1190575
   BARNARD ST, 1983, ARTIF INTELL, V21, P435, DOI 10.1016/S0004-3702(83)80021-6
   Bazin JC, 2012, IEEE INT C INT ROBOT, P4282, DOI 10.1109/IROS.2012.6385802
   Bovik A, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P1
   Bräuer-Burchardt C, 2000, INT C PATT RECOG, P559, DOI 10.1109/ICPR.2000.905399
   BRILLAULTOMAHONY B, 1991, CVGIP-IMAG UNDERSTAN, V54, P289, DOI 10.1016/1049-9660(91)90069-2
   BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cantoni V, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P90, DOI 10.1109/ICIAP.2001.956990
   Collins R. T., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P400, DOI 10.1109/ICCV.1990.139560
   Gamba P, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P301, DOI 10.1109/ICIP.1996.560815
   GANDER W, 1994, BIT, V34, P558, DOI 10.1007/BF01934268
   Kalantari M., 2008, INT ARCH PHOTOGRAMME, V37, P203
   Kalantari M, 2009, PHOTOGRAMM REC, V24, P246, DOI 10.1111/j.1477-9730.2009.00542.x
   Kang DJ, 2003, PATTERN RECOGN LETT, V24, P3177, DOI 10.1016/j.patrec.2003.08.003
   LUTTON E, 1994, IEEE T PATTERN ANAL, V16, P430, DOI 10.1109/34.277598
   MAGEE MJ, 1984, COMPUT VISION GRAPH, V26, P256, DOI 10.1016/0734-189X(84)90188-9
   Maini R., 2009, Int J Image Process, V3, P1
   MCLEAN GF, 1995, IEEE T PATTERN ANAL, V17, P1090, DOI 10.1109/34.473236
   Minagawa A, 2000, IEICE T INF SYST, VE83D, P1574
   Mirzaei FM, 2011, IEEE I CONF COMP VIS, P2454, DOI 10.1109/ICCV.2011.6126530
   PALMER PL, 1993, FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION : PROCEEDINGS, P529
   Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009
   Rojas-Sola JI, 2012, EXPERT SYST APPL, V39, P11183, DOI 10.1016/j.eswa.2012.03.059
   Rother C, 2002, IMAGE VISION COMPUT, V20, P647, DOI 10.1016/S0262-8856(02)00054-9
   Schaffalitzky F, 2000, IMAGE VISION COMPUT, V18, P647, DOI 10.1016/S0262-8856(99)00069-4
   Shufelt JA, 1999, IEEE T PATTERN ANAL, V21, P282, DOI 10.1109/34.754631
   STRAFORINI M, 1993, IMAGE VISION COMPUT, V11, P91, DOI 10.1016/0262-8856(93)90075-R
   TAI A, 1993, IMAGE VISION COMPUT, V11, P240, DOI 10.1016/0262-8856(93)90042-F
   Tardif Jean-Philippe, 2009, 2009 IEEE 12th International Conference on Computer Vision (ICCV), P1250, DOI 10.1109/ICCV.2009.5459328
   Van Den Heuvel F.A., 1998, INT ARCH PHOTOGRAMME, V32, P652
   Wang JG, 2010, EXPERT SYST APPL, V37, P113, DOI 10.1016/j.eswa.2009.05.026
   Wildenauer H, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P615, DOI 10.1109/ICIAP.2007.4362845
   Yin XC, 2011, PROC INT CONF DOC, P136, DOI 10.1109/ICDAR.2011.36
NR 35
TC 5
Z9 5
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2015
VL 43
BP 1
EP 15
DI 10.1016/j.imavis.2015.07.003
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CY0AU
UT WOS:000366069200001
DA 2024-07-18
ER

PT J
AU Huerta, I
   Holte, MB
   Moeslund, TB
   González, J
AF Huerta, Ivan
   Holte, Michael B.
   Moeslund, Thomas B.
   Gonzalez, Jordi
TI Chromatic shadow detection and tracking for moving foreground
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Detecting moving objects; Chromatic shadow detection; Temporal local
   gradient; Spatial and temporal brightness and angle distortions; Shadow
   tracking
ID CAST SHADOWS; OBJECT DETECTION; REMOVAL; MODELS
AB Advanced segmentation techniques in the surveillance domain deal with shadows to avoid distortions when detecting moving objects. Most approaches for shadow detection are still typically restricted to penumbra shadows and cannot cope well with umbra shadows. Consequently, umbra shadow regions are usually detected as part of moving objects, thus affecting the performance of the final detection. In this paper we address the detection of both penumbra and umbra shadow regions. First, a novel bottom-up approach is presented based on gradient and colour models, which successfully discriminates between chromatic moving cast shadow regions and those regions detected as moving objects. In essence, those regions corresponding to potential shadows are detected based on edge partitioning and colour statistics. Subsequently (i) temporal similarities between textures and (ii) spatial similarities between chrominance angle and brightness distortions are analysed for each potential shadow region for detecting the umbra shadow regions. Our second contribution refines even further the segmentation results: a tracking-based top-down approach increases the performance of our bottom-up chromatic shadow detection algorithm by properly correcting non-detected shadows. To do so, a combination of motion filters in a data association framework exploits the temporal consistency between objects and shadows to increase the shadow detection rate. Experimental results exceed current state-of-the-art in shadow accuracy for multiple well-known surveillance image databases which contain different shadowed materials and illumination conditions. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Huerta, Ivan] UPC, CSIC, Inst Robot & Informat Ind, Barcelona 08028, Spain.
   [Holte, Michael B.; Moeslund, Thomas B.] Aalborg Univ, Dept Architecture Design & Media Technol, DK-9220 Aalborg, Denmark.
   [Gonzalez, Jordi] UAB, Comp Vis Ctr, Bellaterra 08193, Spain.
   [Gonzalez, Jordi] UAB, Dept Comp Sci, Bellaterra 08193, Spain.
   [Huerta, Ivan] Univ IUAV, DPDCE, I-30135 Venice, Italy.
C3 Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Institut
   de Robotica i Informatica Industrial (IRII); Universitat Politecnica de
   Catalunya; Aalborg University; Autonomous University of Barcelona;
   Centre de Visio per Computador (CVC); Autonomous University of
   Barcelona; IUAV University Venice
RP Huerta, I (corresponding author), UPC, CSIC, Inst Robot & Informat Ind, Parc Tecnol Barcelona,Llorens & Artigas 4-6, Barcelona 08028, Spain.
EM ihuerta@iri.upc.edu; mbh@create.aau.dk; tbm@create.aau.dk;
   jordi.gonzalez@cvc.uab.cat
RI Gonzàlez, Jordi/I-1812-2015; Holte, Michael/AHC-9113-2022
OI Gonzàlez, Jordi/0000-0001-8033-0306; Holte, Michael
   Boelstoft/0000-0002-0538-2779; Huerta, Ivan/0000-0002-4189-4034;
   Moeslund, Thomas B./0000-0001-7584-5209
FU European project CargoANTs [FP7-SST-2013-605598]; CICYT
   [DPI2013-42458-P, TIN2012-39051]
FX This work has been partially funded by the European project CargoANTs
   (FP7-SST-2013-605598), by the Spanish CICYT project DPI2013-42458-P and
   by the CICYT TIN2012-39051.
CR Amato A., 2013, AUGMENTED VISION REA, P1
   Amato A, 2011, IEEE T IMAGE PROCESS, V20, P2954, DOI 10.1109/TIP.2011.2132728
   [Anonymous], 2006, OBJECT TRACKING SURV
   Arbel E, 2011, IEEE T PATTERN ANAL, V33, P1202, DOI 10.1109/TPAMI.2010.157
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Chen C.-C., 2010, ICPR
   Cucchiara R, 2003, IEEE T PATTERN ANAL, V25, P1337, DOI 10.1109/TPAMI.2003.1233909
   Cucchiara R., 2001, IMPROVING SHADOW SUP
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Finlayson GD, 2009, INT J COMPUT VISION, V85, P35, DOI 10.1007/s11263-009-0243-z
   Guo Ruiqi, 2011, CVPR 2011, DOI DOI 10.1109/CVPR.2011.5995725
   Gusfield D., 1989, STABLE MARRIAGE PROB
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Horprasert T., 1999, FRAM RAT APPL WORKSH
   Hsieh JW, 2003, IMAGE VISION COMPUT, V21, P505, DOI 10.1016/S0262-8856(03)00030-1
   Huang J.-B., 2009, CVPR
   Huang Xiang, 2011, ICCV
   Huerta I., 2009, ICCV
   Huerta I, 2015, PATTERN RECOGN, V48, P709, DOI 10.1016/j.patcog.2014.09.023
   Huerta I, 2013, NEUROCOMPUTING, V100, P183, DOI 10.1016/j.neucom.2011.10.036
   Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Lalonde JF, 2012, INT J COMPUT VISION, V98, P123, DOI 10.1007/s11263-011-0501-8
   Leone A, 2007, PATTERN RECOGN, V40, P1222, DOI 10.1016/j.patcog.2006.09.017
   Liao S., 2010, MODELING PIXEL PROCE
   Liu Z., 2007, CVPR
   Maddalena L, 2008, IEEE T IMAGE PROCESS, V17, P1168, DOI 10.1109/TIP.2008.924285
   Martel-Brisson N., 2005, CVPR
   Martel-Brisson N., 2008, CVPR
   Martel-Brisson N, 2007, IEEE T PATTERN ANAL, V29, P1133, DOI 10.1109/TPAMI.2007.1039
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Moeslund ThomasB., 2011, Visual Analysis of Humans - Looking at People
   Nadimi S, 2004, IEEE T PATTERN ANAL, V26, P1079, DOI 10.1109/TPAMI.2004.51
   Onoguchi K., 1998, ICPR
   Pilet J., 2008, ECCV08
   Porikli F., 2005, ICCV
   Prati A, 2003, IEEE T PATTERN ANAL, V25, P918, DOI 10.1109/TPAMI.2003.1206520
   Qin R., 2010, ICPR
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   Sanin A., 2012, PR, V45, P1648
   Sanin A., 2010, ICPR
   Schreer O., 2002, FAST ROBUST SHADOW D
   Senior A, 2006, IMAGE VISION COMPUT, V24, P1233, DOI 10.1016/j.imavis.2005.06.007
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Stauder J, 1999, IEEE T MULTIMEDIA, V1, P65, DOI 10.1109/6046.748172
   Tian JD, 2009, IEEE T IMAGE PROCESS, V18, P2355, DOI 10.1109/TIP.2009.2026682
   Toyama K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P255, DOI 10.1109/ICCV.1999.791228
   Weiss Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P68, DOI 10.1109/ICCV.2001.937606
   Zhang W., 2007, VSSPR
   Zhang W, 2007, IEEE T MULTIMEDIA, V9, P1202, DOI 10.1109/TMM.2007.902842
   Zhu Jiejie, 2010, CVPR
   Zivkovic Z, 2006, PATTERN RECOGN LETT, V27, P773, DOI 10.1016/j.patrec.2005.11.005
NR 52
TC 18
Z9 21
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2015
VL 41
BP 42
EP 53
DI 10.1016/j.imavis.2015.06.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CQ4ST
UT WOS:000360595600004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Buyssens, P
   Gardin, I
   Ruan, S
   Elmoataz, A
AF Buyssens, Pierre
   Gardin, Isabelle
   Ruan, Su
   Elmoataz, Abderrahim
TI Eikonal-based region growing for efficient clustering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Superpixels; Segmentation; Clustering; Eikonal equation
ID SEGMENTATION
AB We describe an Eikonal-based algorithm for computing dense oversegmentation of an image, often called supeipixels. This oversegmentation respects local image boundaries while limiting undersegmentation. The proposed algorithm relies on a region growing scheme, where the potential map used is not fixed and evolves during the diffusion. Refinement steps are also proposed to enhance at low cost the first oversegmentation. Quantitative comparisons on the Berkeley dataset show good performance on traditional metrics over current state-of-the art superpixel methods. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Buyssens, Pierre; Gardin, Isabelle; Ruan, Su] Univ Rouen, LITIS EA QuantIF 4108, F-76183 Rouen, France.
   [Gardin, Isabelle] Ctr Henri Becquerel, Dept Nucl Med, F-76038 Rouen, France.
   [Elmoataz, Abderrahim] Univ Caen Basse Normandie, GREYC UMR CNRS 6072, ENSICAEN Image Team, F-14000 Caen, France.
C3 Universite de Rouen Normandie; UNICANCER; Centre Henri Becquerel;
   Universite de Caen Normandie; Centre National de la Recherche
   Scientifique (CNRS)
RP Buyssens, P (corresponding author), Univ Rouen, LITIS EA QuantIF 4108, 22 Blvd Gambetta, F-76183 Rouen, France.
OI Ruan, Su/0000-0001-8785-6917
FU french SIRTDose project - "Physique Cancer" (INSERM-Plan Cancer)
FX This work is part of the french SIRTDose project funded by the grant
   "Physique Cancer" 2012 (INSERM-Plan Cancer). The authors wants to thank
   the authors of [1] and [18] for the fruitful discussions about
   superpixels and their evaluation. The authors also would like to thank
   the anonymous reviewers for their valuable comments and suggestions to
   improve the quality of the paper.
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], 2009, IEEE I CONF COMP VIS, DOI 10.1109/ICCV.2009.5459175
   [Anonymous], 1999, LEVEL SET METHODS FA
   [Anonymous], 2008, 2008 IEEE C COMP VIS
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Desquesnes Xavier, 2013, J MATH IMAGING VIS, P1
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x
   Kim S, 2001, SIAM J SCI COMPUT, V22, P2178, DOI 10.1137/S1064827500367130
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Lezoray O., 2012, Image Processing and Analysis with Graphs
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Moore AP, 2010, PROC CVPR IEEE, P2117, DOI 10.1109/CVPR.2010.5539890
   Peyre G., 2010, Geodesic methods in computer vision and graphics
   Piotr Dollar, 2013, INT C COMP VIS IEEE
   Schaeffer SE, 2007, COMPUT SCI REV, V1, P27, DOI 10.1016/j.cosrev.2007.05.001
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Vedaldi A, 2008, LECT NOTES COMPUT SC, V5305, P705, DOI 10.1007/978-3-540-88693-8_52
   Veksler O, 2010, LECT NOTES COMPUT SC, V6315, P211, DOI 10.1007/978-3-642-15555-0_16
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Yang Y, 2010, PROC CVPR IEEE, P3113, DOI 10.1109/CVPR.2010.5540070
   Yatziv L, 2006, J COMPUT PHYS, V212, P393, DOI 10.1016/j.jcp.2005.08.005
   Zitnick CL, 2007, INT J COMPUT VISION, V75, P49, DOI 10.1007/s11263-006-0018-8
   Zitnick CL, 2005, IEEE I CONF COMP VIS, P1308
NR 25
TC 16
Z9 22
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1045
EP 1054
DI 10.1016/j.imavis.2014.10.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Theodorakis, S
   Pitsikalis, V
   Maragos, P
AF Theodorakis, Stavros
   Pitsikalis, Vassilis
   Maragos, Petros
TI Dynamic-static unsupervised sequentiality, statistical subunits and
   lexicon for sign language recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic sign language recognition; Data-driven subunits; Sub-sign
   phonetic modeling; Unsupervised; Segmentation; HMM
ID HIDDEN MARKOV-MODELS; ASL RECOGNITION; BASIC UNITS; FEATURES
AB We introduce a new computational phonetic modeling framework for sign language (SL) recognition. This is based on dynamic-static statistical subunits and provides sequentiality in an unsupervised manner, without prior linguistic information. Subunit "sequentiality" refers to the decomposition of signs into two types of parts, varying and non-varying, that are sequentially stacked across time. Our approach is inspired by the Movement-Hold SL linguistic model that refers to such sequences. First, we segment signs into intra-sign primitives, and classify each segment as dynamic or static, i.e., movements and non-movements. These segments are then clustered appropriately to construct a set of dynamic and static subunits. The dynamic/static discrimination allows us employing different visual features for clustering the dynamic or static segments. Sequences of the generated subunits are used as sign pronunciations in a data-driven lexicon. Based on this lexicon and the corresponding segmentation, each subunit is statistically represented and trained on multimodal sign data as a hidden Markov model. In the proposed approach, dynamic/static sequentiality is incorporated in an unsupervised manner. Further, handshape information is integrated in a parallel hidden Markov modeling scheme. The novel sign language modeling scheme is evaluated in recognition experiments on data from three corpora and two sign languages: Boston University American SL which is employed pre-segmented at the sign-level, Greek SL Lemmas, and American SL Large Vocabulary Dictionary, including both signer dependent and unseen signers' testing. Results show consistent improvements when compared with other approaches, demonstrating the importance of dynamic/static structure in sub-sign phonetic modeling. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Theodorakis, Stavros; Pitsikalis, Vassilis; Maragos, Petros] Natl Tech Univ Athens, Sch Elect & Comp Engn, GR-10682 Athens, Greece.
C3 National Technical University of Athens
RP Theodorakis, S (corresponding author), Zografou Campus, Athens 15773, Greece.
EM sth@cs.ntua.gr; vpitsik@cs.ntua.gr; maragos@cs.ntua.gr
FU EU research program Dicta-Sign [FP7-ICT-3-231135]
FX This work was supported by the EU research program Dicta-Sign with grant
   FP7-ICT-3-231135.
CR Ajmera J, 2003, ASRU'03: 2003 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING ASRU '03, P411, DOI 10.1109/ASRU.2003.1318476
   [Anonymous], 2012, IEEE COMP SOC C COMP, DOI DOI 10.1109/CVPRW.2012.6239187
   [Anonymous], P WKSP REPR PROC SL
   [Anonymous], 2004, P BRIT MACH VIS C
   [Anonymous], PHONOLOGY
   [Anonymous], NIPS
   [Anonymous], 1982, ANN M LING SOC AM SA
   [Anonymous], 2011, Visual Analysis of Humans: Looking at People, DOI DOI 10.1007/978-0-85729-997-027
   [Anonymous], IEEE CVPR WKSP GEST
   [Anonymous], 2004, P EUR C COMP VIS
   [Anonymous], 2000, SIGN WRITING
   [Anonymous], P WKSP REPR PROC SL
   [Anonymous], INT STUDIES SL COMMU
   [Anonymous], P ECCV WKSP SIGN GES
   [Anonymous], P INT C IM PROC
   [Anonymous], 2005, PATTERN RECOGNITION, DOI DOI 10.1007/11492429_63
   [Anonymous], P GEST SIGN LANG HCI
   [Anonymous], P ECCV WKSP SIGN GES
   [Anonymous], P INT C MULT EXP
   [Anonymous], 1987, THESIS U TEXAS AUSTI
   [Anonymous], P 5 WKSP REPR PROC S
   [Anonymous], INT C AC SPEECH SIGN
   Aran O, 2010, PATTERN RECOGN, V43, P1776, DOI 10.1016/j.patcog.2009.12.002
   Athitsos Vassilis, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563181
   Awad G, 2009, IEEE IMAGE PROC, P2729, DOI 10.1109/ICIP.2009.5414159
   Bauer B., 2001, INT GESTURE WORKSHOP, P64
   Brentari D., 2002, Modality and Structure in Signed and Spoken Languages, P35, DOI [10.1017/CBO9780511486777.003, DOI 10.1017/CBO9780511486777.003]
   Buehler P, 2009, PROC CVPR IEEE, P2953, DOI 10.1109/CVPRW.2009.5206523
   Cooper H, 2012, J MACH LEARN RES, V13, P2205
   Derpanis KG, 2008, IMAGE VISION COMPUT, V26, P1650, DOI 10.1016/j.imavis.2008.04.007
   Ding LY, 2009, IMAGE VISION COMPUT, V27, P1826, DOI 10.1016/j.imavis.2009.02.005
   Fang GL, 2007, IEEE T SYST MAN CY A, V37, P1, DOI 10.1109/TSMCA.2006.886347
   Fang GL, 2004, INT C PATT RECOG, P454, DOI 10.1109/ICPR.2004.1333800
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Han JW, 2009, PATTERN RECOGN LETT, V30, P623, DOI 10.1016/j.patrec.2008.12.010
   Klima E.S., 1979, SIGNS LANGUAGE
   Koller O, 2013, IEEE INT CONF AUTOMA
   Kong WW, 2010, J SIGNAL PROCESS SYS, V59, P211, DOI 10.1007/s11265-008-0292-5
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Liddell Scott K., 1989, SIGN LANGUAGE STUDIE, V1, P195, DOI [10.1353/sls.1989.0027, DOI 10.1353/SLS.1989.0027]
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Myers EW, 1986, ALGORITHMICA, V1, P251, DOI 10.1007/BF01840446
   Nayak S, 2012, J MACH LEARN RES, V13, P2589
   Ng CW, 2002, IMAGE VISION COMPUT, V20, P993, DOI 10.1016/S0262-8856(02)00113-0
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Ong SCW, 2007, LECT NOTES COMPUT SC, V4778, P16
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Starner T., 1997, Motion-Based Recognit, P227
   STOKOE WC, 1980, ANNU REV ANTHROPOL, V9, P365, DOI 10.1146/annurev.an.09.100180.002053
   Vedaldi A, 2012, IEEE T PATTERN ANAL, V34, P480, DOI 10.1109/TPAMI.2011.153
   Vogler C, 1997, IEEE SYS MAN CYBERN, P156, DOI 10.1109/ICSMC.1997.625741
   Vogler C, 2001, COMPUT VIS IMAGE UND, V81, P358, DOI 10.1006/cviu.2000.0895
   Vogler C, 1999, LECT NOTES ARTIF INT, V1739, P211
   von Agris Ulrich, 2008, Universal Access in the Information Society, V6, P323, DOI 10.1007/s10209-007-0104-x
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Yang HD, 2009, IEEE T PATTERN ANAL, V31, P1264, DOI 10.1109/TPAMI.2008.172
   Yang RD, 2006, INT C PATT RECOG, P108
   Yin P, 2009, INT CONF ACOUST SPEE, P4757, DOI 10.1109/ICASSP.2009.4960694
   Zhang D, 2006, IEEE T MULTIMEDIA, V8, P509, DOI 10.1109/TMM.2006.870735
NR 62
TC 24
Z9 24
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 533
EP 549
DI 10.1016/j.imavis.2014.04.012
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600008
DA 2024-07-18
ER

PT J
AU Arevalillo-Herráez, M
   Ferri, FJ
AF Arevalillo-Herraez, Miguel
   Ferri, Francesc J.
TI An improved distance-based relevance feedback strategy for image
   retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CBIR; Image retrieval; Relevance feedback; Nearest neighbor
ID BAYESIAN FRAMEWORK; CLASSIFICATION; SUBSPACE
AB Most CBIR (content based image retrieval) systems use relevance feedback as a mechanism to improve retrieval results. NN (nearest neighbor) approaches provide an efficient method to compute relevance scores, by using estimated densities of relevant and non-relevant samples in a particular feature space. In this paper, particularities of the CBIR problem are exploited to propose an improved relevance feedback algorithm based on the NN approach. The resulting method has been tested in a number of different situations and compared to the standard NN approach and other existing relevance feedback mechanisms. Experimental results evidence significant improvements in most cases. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Arevalillo-Herraez, Miguel; Ferri, Francesc J.] Univ Valencia, Dept Comp Sci, E-46100 Burjassot, Spain.
C3 University of Valencia
RP Arevalillo-Herráez, M (corresponding author), Univ Valencia, Dept Comp Sci, Avda Univ S-N, E-46100 Burjassot, Spain.
EM miguel.arevalillo@uv.es; francesc.ferri@uv.es
RI Ferri, Francesc Josep/L-7216-2014; Arevalillo-Herraez,
   Miguel/C-1412-2012
OI Ferri, Francesc Josep/0000-0002-1543-3568; Arevalillo-Herraez,
   Miguel/0000-0002-0350-2079
FU FEDER; Spanish Government [TIN2011-29221-C03-02, TIN2009-14205-C04-03];
   Consolider Ingenio [CSD07-00018]
FX We would like to thank Dr. G. Giacinto for his help on the evaluation of
   this paper, facilitating the manually performed classification of the
   30000 images repository. We would also like to thank Dr. M. Ortega for
   providing the thumbnails of these images. This work has been partially
   funded by FEDER and the Spanish Government through projects
   TIN2011-29221-C03-02 and TIN2009-14205-C04-03, and Consolider Ingenio
   2010 CSD07-00018.
CR Amin T, 2007, IEEE T MULTIMEDIA, V9, P1416, DOI 10.1109/TMM.2007.906587
   [Anonymous], 2006, P 2006 IEEE COMPUTER, DOI DOI 10.1109/CVPR.2006.167
   Arevalillo-Herráez M, 2008, SIGNAL PROCESS-IMAGE, V23, P490, DOI 10.1016/j.image.2008.04.016
   Arevalillo-Herráez M, 2010, LECT NOTES COMPUT SC, V6218, P708, DOI 10.1007/978-3-642-14980-1_70
   Arevalillo-Herráez M, 2010, PATTERN RECOGN, V43, P619, DOI 10.1016/j.patcog.2009.08.010
   Ayala G, 2001, IEEE T PATTERN ANAL, V23, P1430, DOI 10.1109/34.977566
   Chang H, 2007, IMAGE VISION COMPUT, V25, P695, DOI 10.1016/j.imavis.2006.05.013
   CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641
   CHEN YD, 1994, OPT ENG, V33, P2713, DOI 10.1117/12.173552
   Chen YQ, 2001, IEEE IMAGE PROC, P34, DOI 10.1109/ICIP.2001.958946
   Ciocca G, 2001, PATTERN RECOGN, V34, P1639, DOI 10.1016/S0031-3203(00)00055-8
   Ciocca G, 1999, INFORM PROCESS MANAG, V35, P605, DOI 10.1016/S0306-4573(99)00021-7
   CONNERS RW, 1984, COMPUT VISION GRAPH, V25, P273, DOI 10.1016/0734-189X(84)90197-X
   Dasarathy B. V., 1991, Nearest neighbor (NN) norms, V317
   Datta R, 2008, ACM COMPUT SURV, V40, DOI 10.1145/1348246.1348248
   de Ves E, 2006, PATTERN RECOGN, V39, P1622, DOI 10.1016/j.patcog.2006.01.006
   Duda R., 1973, Pattern Classification and Scene Analysis
   García S, 2008, J MACH LEARN RES, V9, P2677
   Giacinto G, 2004, INT C PATT RECOG, P989, DOI 10.1109/ICPR.2004.1334425
   Giacinto G, 2004, PATTERN RECOGN, V37, P1499, DOI 10.1016/j.patcog.2004.01.005
   Giacinto G., 2007, CIVR, P456, DOI [10.1145/1282280.1282347, DOI 10.1145/1282280.1282347]
   Giacinto Giorgio., 2005, Advances in Neural Information Processing Systems, V17, P489
   Gondra I, 2004, NEURAL COMPUT APPL, V13, P130, DOI 10.1007/s00521-004-0415-2
   He X, 2008, IEEE T KNOWL DATA EN, V20, P189, DOI 10.1109/TKDE.2007.190692
   Iqbal Q, 2002, INT C PATT RECOG, P438, DOI 10.1109/ICPR.2002.1048333
   Ishikawa Y., 1998, P 24 INT C VER LARG, P433
   Laaksonen J, 2002, IEEE T NEURAL NETWOR, V13, P841, DOI 10.1109/TNN.2002.1021885
   León T, 2007, PATTERN RECOGN, V40, P2621, DOI 10.1016/j.patcog.2007.02.002
   Lew MS, 2006, ACM T MULTIM COMPUT, V2, P1, DOI 10.1145/1126004.1126005
   Muneesawang P, 2004, IEEE T MULTIMEDIA, V6, P703, DOI 10.1109/TMM.2004.834866
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Shakhnarovich G., 2006, NEAREST NEIGHBOR MET
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith G, 1997, PATTERN RECOGN LETT, V18, P1495, DOI 10.1016/S0167-8655(97)00132-3
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Su Z, 2003, IEEE T IMAGE PROCESS, V12, P924, DOI 10.1109/TIP.2003.815254
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tao DC, 2006, IEEE T PATTERN ANAL, V28, P1088, DOI 10.1109/TPAMI.2006.134
   Thomee B, 2012, INT J MULTIMED INF R, V1, P71, DOI 10.1007/s13735-012-0014-4
   Tong S, 2001, P 9 ACM INT C MULT, P107, DOI DOI 10.1145/500141.500159
   Urban J., 2004, Proceedings. IEEE Sixth International Symposium on Multimedia Software, P583
   Zhou XS, 2001, PROC CVPR IEEE, P11
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 43
TC 9
Z9 9
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 704
EP 713
DI 10.1016/j.imavis.2013.07.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900002
DA 2024-07-18
ER

PT J
AU Trujillo-Pino, A
   Krissian, K
   Alemán-Flores, M
   Santana-Cedrés, D
AF Trujillo-Pino, Agustin
   Krissian, Karl
   Aleman-Flores, Miguel
   Santana-Cedres, Daniel
TI Accurate subpixel edge location based on partial area effect
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Edge detection; Subpixel accuracy; Denoising
ID IMAGE INTERPOLATION; COLOR; 2-D
AB The estimation of edge features, such as subpixel position, orientation, curvature and change in intensity at both sides of the edge, from the computation of the gradient vector in each pixel is usually inexact, even in ideal images. In this paper, we present a new edge detector based on an edge and acquisition model derived from the partial area effect, which does not assume continuity in the image values. The main goal of this method consists in achieving a highly accurate extraction of the position, orientation, curvature and contrast of the edges, even in difficult conditions, such as noisy images, blurred edges, low contrast areas or very close contours. For this purpose, we first analyze the influence of perfectly straight or circular edges in the surrounding region, in such a way that, when these conditions are fulfilled, the features can exactly be determined. Afterward, we extend it to more realistic situations considering how adverse conditions can be tackled and presenting an iterative scheme for improving the results. We have tested this method in real as well as in sets of synthetic images with extremely difficult edges, and in both cases a highly accurate characterization has been achieved. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Trujillo-Pino, Agustin; Krissian, Karl; Aleman-Flores, Miguel; Santana-Cedres, Daniel] Univ Las Palmas Gran Canaria, Dept Informat & Sistemas, Las Palmas Gran Canaria 35017, Spain.
C3 Universidad de Las Palmas de Gran Canaria
RP Trujillo-Pino, A (corresponding author), Univ Las Palmas Gran Canaria, Dept Informat & Sistemas, Campus Tafira, Las Palmas Gran Canaria 35017, Spain.
EM agustin@dis.ulpgc.es
RI Santana-Cedrés, Daniel/J-5868-2019; Trujillo-Pino, Agustín/K-5825-2014;
   Aleman-Flores, Miguel/K-6659-2014
OI Santana-Cedrés, Daniel/0000-0003-2032-5649; Trujillo-Pino,
   Agustín/0000-0001-6212-5317; Aleman-Flores, Miguel/0000-0002-9258-0086
FU SIMVA; Spanish Ministry of Science and Innovation [TIN2009-10770]
FX This work has been supported by the project SIMVA, TIN2009-10770 from
   the Spanish Ministry of Science and Innovation.
CR Al-Diri B, 2009, IEEE T MED IMAGING, V28, P1488, DOI 10.1109/TMI.2009.2017941
   Al-Diri B, 2008, IEEE ENG MED BIO, P2262, DOI 10.1109/IEMBS.2008.4649647
   Bankhead P, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0032435
   Bin TJ, 2008, IMAGE VISION COMPUT, V26, P563, DOI 10.1016/j.imavis.2007.07.003
   Bouchara F, 2009, J OPT SOC AM A, V26, P820, DOI 10.1364/JOSAA.26.000820
   Bouma H, 2005, IEEE T PATTERN ANAL, V27, P1501, DOI 10.1109/TPAMI.2005.174
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cheng SC, 2005, PATTERN RECOGN, V38, P527, DOI 10.1016/j.patcog.2004.08.016
   [崔继文 CUI Jiwen], 2005, [光学技术, Optical Technology], V31, P779
   Da FP, 2010, IMAGE VISION COMPUT, V28, P1645, DOI 10.1016/j.imavis.2010.05.003
   Devernay F., 1995, 2724 INRIA
   GHOSAL S, 1993, PATTERN RECOGN, V26, P295, DOI 10.1016/0031-3203(93)90038-X
   GREGSON PH, 1995, COMPUT BIOMED RES, V28, P291, DOI 10.1006/cbmr.1995.1020
   HARTEN A, 1987, J COMPUT PHYS, V71, P231, DOI [10.1016/0021-9991(87)90031-3, 10.1006/jcph.1996.5632]
   Hermosilla T, 2008, IMAGE VISION COMPUT, V26, P1240, DOI 10.1016/j.imavis.2008.02.012
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   KISWORO M, 1994, IEEE T PATTERN ANAL, V16, P405, DOI 10.1109/34.277593
   Lee C.-K., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P536, DOI 10.1109/CVPR.1993.341078
   Lowell J, 2004, IEEE T MED IMAGING, V23, P1196, DOI 10.1109/TMI.2004.830524
   LYVERS EP, 1989, IEEE T PATTERN ANAL, V11, P1293, DOI 10.1109/34.41367
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mendonça PRS, 2004, LECT NOTES COMPUT SC, V3022, P554
   NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852
   OVERINGTON I, 1987, IMAGE VISION COMPUT, V5, P217, DOI 10.1016/0262-8856(87)90052-7
   Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Qu YD, 2005, IMAGE VISION COMPUT, V23, P11, DOI 10.1016/j.imavis.2004.07.003
   Rockett P., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P392
   Shan Y, 2000, IMAGE VISION COMPUT, V18, P1015, DOI 10.1016/S0262-8856(00)00040-8
   Steger C., 2000, International Archives of Photogrammetry and Remote Sensing, VXXXIII, P141
   Steger C., 1998, Ph.D. Thesis
   TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502
   Tabbone S., 1992, Proceedings. 11th IAPR International Conference on Pattern Recognition. Vol.III. Conference C: Image, Speech and Signal Analysis, P655, DOI 10.1109/ICPR.1992.202071
   TSAI DM, 1994, PATTERN RECOGN, V27, P699, DOI 10.1016/0031-3203(94)90048-5
   VERBEEK PW, 1994, IEEE T PATTERN ANAL, V16, P726, DOI 10.1109/34.297954
   Xie SH, 2005, KEY ENG MAT, V295-296, P711, DOI 10.4028/www.scientific.net/KEM.295-296.711
   Xu XY, 2011, IEEE T MED IMAGING, V30, P1184, DOI 10.1109/TMI.2010.2103566
   Ye J, 2005, IMAGE VISION COMPUT, V23, P453, DOI 10.1016/j.imavis.2004.07.007
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
   ZHOU LA, 1994, IEEE T MED IMAGING, V13, P619, DOI 10.1109/42.363106
NR 40
TC 183
Z9 215
U1 10
U2 111
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2013
VL 31
IS 1
BP 72
EP 90
DI 10.1016/j.imavis.2012.10.005
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 084RP
UT WOS:000314557100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chen, SQ
   Cremers, D
   Radke, RJ
AF Chen, Siqi
   Cremers, Daniel
   Radke, Richard J.
TI Image segmentation with one shape prior - A template-based formulation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Shape prior
ID FREE-FORM DEFORMATIONS; ACTIVE CONTOURS; GRAPH CUTS; REGISTRATION; SETS
AB Image segmentation with one shape prior is an important problem in computer vision. Most algorithms not only share a similar energy definition, but also follow a similar optimization strategy. Therefore, they all suffer from the same drawbacks in practice such as slow convergence and difficult-to-tune parameters. In this paper, by reformulating the energy cost function, we establish an important connection between shape-prior based image segmentation with intensity-based image registration. This connection enables us to combine advanced shape and intensity modeling techniques from segmentation society with efficient optimization techniques from registration society. Compared with the traditional regularization-based approach, our framework is more systematic and more efficient, able to converge in a matter of seconds. We also show that user interaction (such as strokes and bounding boxes) can easily be incorporated into our algorithm if desired. Through challenging image segmentation experiments, we demonstrate the improved performance of our algorithm compared to other proposed approaches. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Chen, Siqi; Radke, Richard J.] Rensselaer Polytech Inst, Dept ECSE, Troy, NY USA.
   [Cremers, Daniel] Tech Univ Munich, Dept Comp Sci, D-8000 Munich, Germany.
C3 Rensselaer Polytechnic Institute; Technical University of Munich
RP Chen, SQ (corresponding author), Netflix Inc, Los Gatos, CA USA.
EM siqichensc@gmail.com; daniel.cremers@in.tum.de; rjradke@ecse.rpi.edu
RI Chen, Siqi/IZE-8631-2023; Radke, Richard/I-3289-2013
OI Cremers, Daniel/0000-0002-3079-7984; Radke, Richard/0000-0001-5064-7775
CR [Anonymous], 1999, ICCV
   [Anonymous], 2001, ICCV
   Bay H., 2006, P EUROPEAN C COMPUTE
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan T., 2005, CVPR
   Chen S., 2010, ECCV
   Chen YM, 2002, INT J COMPUT VISION, V50, P315, DOI 10.1023/A:1020878408985
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Cremers D., 2003, VLSM
   Cremers D., 2008, CVPR
   Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5
   Freedman Daniel., 2005, CVPR
   Gorski J, 2007, MATH METHOD OPER RES, V66, P373, DOI 10.1007/s00186-007-0161-1
   Kumar M.P., 2005, CVPR
   Lewis J., 1995, VISION INTERFACE, V95, P120
   Manay S., 2005, EMMCVPR
   Mattes D, 2003, IEEE T MED IMAGING, V22, P120, DOI 10.1109/TMI.2003.809072
   ORCHARD MT, 1991, IEEE T SIGNAL PROCES, V39, P2677, DOI 10.1109/78.107417
   Overgaard N., 2009, SSVM
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   Riklin-Raviv T, 2007, INT J COMPUT VISION, V72, P309, DOI 10.1007/s11263-006-9042-y
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Rousson M., 2002, ECCV
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Ruzon M., 2000, CVPR
   Schoenemann T., 2007, ICCV
   Tsai A, 2003, IEEE T MED IMAGING, V22, P137, DOI 10.1109/TMI.2002.808355
   WENDELL RE, 1976, OPER RES, V24, P643, DOI 10.1287/opre.24.4.643
   Werlberger M., 2009, SSVM
   Wolberg G., 2000, ICIP
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 33
TC 17
Z9 20
U1 0
U2 16
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 1032
EP 1042
DI 10.1016/j.imavis.2012.09.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Carmona-Poyato, A
   Medina-Carnicer, R
   Muñoz-Salinas, R
   Yeguas-Bolivar, E
AF Carmona-Poyato, A.
   Medina-Carnicer, R.
   Munoz-Salinas, R.
   Yeguas-Bolivar, E.
TI On stop conditions about methods to obtain polygonal approximations
   relied on break point suppression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Digital planar curves; Polygonal approximation; Dominant points
ID DIGITAL PLANAR CURVES; ALGORITHM
AB In this work, we propose a new unsupervised stop condition for heuristic methods that employ break point suppression to obtain polygonal approximations. Using a stop condition, these heuristic methods delete redundant break points until a required level of approximation is satisfied. The new stop condition is based on the optimisation of the F-2 measure. Comparisons with original stop conditions of several methods show that the new stop condition yields a measurable improvement in the approximation. The polygonal approximations obtained with the new stop condition are more efficient and better adjusted to the original contours. The new stop condition can be combined with supervised optimal methods to obtain a reference approximation of the original contour with a minimum number of points. In this case, the resulting methods are unsupervised methods. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Carmona-Poyato, A.; Medina-Carnicer, R.; Munoz-Salinas, R.; Yeguas-Bolivar, E.] Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba
RP Carmona-Poyato, A (corresponding author), Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
EM malcapoa@uco.es
RI Muñoz-Salinas, Rafael/K-5999-2014; Yeguas, Enrique/J-4184-2012;
   Medina-Carnicer, Rafael/G-3401-2015; Carmona-Poyato, Angel/G-1593-2015
OI Muñoz-Salinas, Rafael/0000-0002-8773-8571; Yeguas,
   Enrique/0000-0002-8153-5052; Medina-Carnicer,
   Rafael/0000-0003-4481-0614; Carmona-Poyato, Angel/0000-0002-8820-8396
FU Science and Technology Ministry of Spain [TIN2010-18119]
FX This work has been developed with the support of the Research Project
   called "TIN2010-18119" financed by Science and Technology Ministry of
   Spain.
CR Carmona-Poyato A, 2005, IMAGE VISION COMPUT, V23, P1226, DOI 10.1016/j.imavis.2005.07.025
   Carmona-Poyato A, 2010, PATTERN RECOGN, V43, P14, DOI 10.1016/j.patcog.2009.06.010
   Marji M, 2004, PATTERN RECOGN, V37, P2113, DOI 10.1016/j.patcog.2004.03.004
   Masood A, 2008, IMAGE VISION COMPUT, V26, P702, DOI 10.1016/j.imavis.2007.08.006
   Masood A, 2008, PATTERN RECOGN, V41, P227, DOI 10.1016/j.patcog.2007.05.021
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   PIKAZ A, 1995, PATTERN RECOGN LETT, V16, P557, DOI 10.1016/0167-8655(95)80001-A
   Rosin PL, 2001, PATTERN RECOGN, V34, P2083, DOI 10.1016/S0031-3203(00)00136-9
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   SARKAR D, 1993, PATTERN RECOGN LETT, V14, P959, DOI 10.1016/0167-8655(93)90004-W
NR 10
TC 4
Z9 4
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 513
EP 523
DI 10.1016/j.imavis.2012.05.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100012
DA 2024-07-18
ER

PT J
AU Oka, Y
   Shakunaga, T
AF Oka, Yuki
   Shakunaga, Takeshi
TI Real-time face tracking and recognition by sparse eigentracker with
   associative mapping to 3D shape
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Face tracking and recognition; Augmented eigenface; 3D eigentemplate;
   Photometric adjustment; Shape inference from image
ID ACTIVE APPEARANCE MODELS; REPRESENTATION; EIGENFACES
AB This paper proposes a novel framework of real-time face tracking and recognition by combining two eigen-based methods. The first method is a novel extension of eigenface called augmented eigenface and the second method is a sparse 3D eigentemplate tracker controlled by a particle filter. The augmented eigenface is an eigenface augmented by an associative mapping to 3D shape that is specified by a set of volumetric face models. This paper discusses how to make up the augmented eigenface and how it can be used for inference of 3D shape from partial images. The associative mapping is also generalized to subspace-to-one mappings to cover photometric image changes for a fixed shape. A novel technique, called photometric adjustment, is introduced for simple implementation of associative mapping when an image subspace should be combined to a shape. The sparse 3D eigentemplate tracker is an extension of the 3D template tracker proposed by Oka et al. In combination with the augmented eigenface, the sparse 3D eigentemplate tracker facilitates real-time 3D tracking and recognition when a monocular image sequence is provided. In the tracking, sparse 3D eigentemplate is updated by the augmented eigenface while face pose is estimated by the sparse eigentracker. Since the augmented eigenface is constructed on the conventional eigenfaces, face identification and expression recognition are also accomplished efficiently during the tracking. In the experiment, an augmented eigenface was constructed from 25 faces where 24 images were taken in different lighting conditions for each face. Experimental results show that the augmented eigenface works with the 3D eigentemplate tracker for real-time tracking and recognition. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Oka, Yuki; Shakunaga, Takeshi] Okayama Univ, Dept Comp Sci, Okayama 7008530, Japan.
C3 Okayama University
RP Oka, Y (corresponding author), Okayama Univ, Dept Comp Sci, Okayama 7008530, Japan.
EM shaku@cs.okayama-u.ac.jp
CR Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Castelan M, 2007, IEEE T IMAGE PROCESS, V16, P1139, DOI 10.1109/TIP.2006.891351
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kohonen, 1989, SELF ORG ASS MEMORY
   Matsubara Yasuharu, 2005, IPSJ Transactions on Computer Vision and Image Media, V46, P60
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   Oka Y., P INT C IM GRAPH ICI, P390
   Sakabe K., P 3 PAC RIM S IM VID, P714
   Sakaue F., 2004, IEICE T INFOR SYST D
   Sakaue F., P AS C COMP VIS ACCV, V1, P1440
   Satake J., P INT C PATT REC ICP, V3, P294
   Shakunaga T., P INT C AUT FAC GEST, P241
   Shakunaga T., P INT C MACH VIS APP, P13
   Shakunaga T., P INT C IM GRAPH ICI, P398
   Shakunaga T., P IASTED INT C SIGN, P85
   Shakunaga T., P IEEE C COMP VIS PA, V1, P864
   Shakunaga T., P INT C PATT REC ICP, V1, P648
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vasilescu M. A. O., P IEEE C COMP VIS PA, V1, P547
   Vlasic D, 2005, ACM T GRAPHIC, V24, P426, DOI 10.1145/1073204.1073209
   Wu H., P IEEE C COMP VIS PA
   Xu YL, 2011, IEEE T PATTERN ANAL, V33, P1681, DOI 10.1109/TPAMI.2010.216
NR 27
TC 7
Z9 7
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 147
EP 158
DI 10.1016/j.imavis.2011.12.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000003
DA 2024-07-18
ER

PT J
AU Muñoz-Salinas, R
   Yeguas-Bolivar, E
   Díaz-Más, L
   Medina-Carnicer, R
AF Munoz-Salinas, Rafael
   Yeguas-Bolivar, E.
   Diaz-Mas, L.
   Medina-Carnicer, Rafael
TI Shape from pairwise silhouettes for plan-view map generation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Plan-view maps; Shape from silhouettes; Person tracking; Particle
   filtering; Color processing; Condensation algorithm
ID INTEGRATED PERSON TRACKING; STEREO; PEOPLE; RECOGNITION; COLOR
AB A plan-view map is a representation mechanism especially appropriated for people detection and tracking. It allows to represent volumetric information in a very compact and efficient way so that very effective detection and tracking algorithms can be applied using it. In spite of their advantages, plan-view maps have mainly been used with stereo cameras but not with monocular ones. The reason why is that many of the three-dimensional reconstruction algorithms using monocular vision impose strong conditions (such as controlled lightning, lack of occlusion, etc.) thus impeding their applicability in realistic environments.
   This paper presents two main novelties. First, a three-dimensional reconstruction algorithm that is especially appropriate for people detection and tracking because of its robustness to errors in the background subtraction. Second, a new technique for creating plan-view maps from volumetric reconstructions that reduces the amount of false positives in the occluded regions. We show experimentally that these techniques produce plan-view maps that can be reliably employed for tracking purposes. The proposed methods are compared with the traditional SfS obtaining relevant improvements. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Munoz-Salinas, Rafael; Yeguas-Bolivar, E.; Diaz-Mas, L.; Medina-Carnicer, Rafael] Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba
RP Muñoz-Salinas, R (corresponding author), Univ Cordoba, Dept Comp & Numer Anal, E-14071 Cordoba, Spain.
EM rmsalinas@uco.es; eyeguas@uco.es; i22dimal@uco.es; rmedina@uco.es
RI Muñoz-Salinas, Rafael/K-5999-2014; Yeguas, Enrique/J-4184-2012;
   Medina-Carnicer, Rafael/G-3401-2015
OI Muñoz-Salinas, Rafael/0000-0002-8773-8571; Yeguas,
   Enrique/0000-0002-8153-5052; Medina-Carnicer, Rafael/0000-0003-4481-0614
CR Aherne F., 1997, KYBERNETIKA, V32, P1
   [Anonymous], 2000, P EUR C COMP VIS, DOI DOI 10.1007/3-540-45053-X_48
   Bemardin K., 2008, EVALUATING MULTIPLE, DOI [10.1155/2008/246309, DOI 10.1155/2008/246309]
   Beymer D, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P127, DOI 10.1109/HUMO.2000.897382
   Black J, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P169, DOI 10.1109/MOTION.2002.1182230
   Böhme HJ, 2003, ROBOT AUTON SYST, V44, P83, DOI 10.1016/S0921-8890(03)00012-5
   Caillette F, 2008, COMPUT VIS IMAGE UND, V109, P112, DOI 10.1016/j.cviu.2007.05.005
   Cheung KM, 2005, INT J COMPUT VISION, V63, P225, DOI 10.1007/s11263-005-6879-4
   Colombo C, 2003, IEEE T SYST MAN CY B, V33, P677, DOI 10.1109/TSMCB.2003.814281
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Darrell T, 2000, INT J COMPUT VISION, V37, P175, DOI 10.1023/A:1008103604354
   Diaz-Más L, 2010, PATTERN RECOGN, V43, P2119, DOI 10.1016/j.patcog.2010.01.001
   Du W, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P165
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   Focken D, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P400, DOI 10.1109/ICMI.2002.1167028
   Grest D, 2004, 2004 IEEE 6TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P387
   Harville M, 2004, PROC CVPR IEEE, P398
   Harville M, 2004, IMAGE VISION COMPUT, V22, P127, DOI 10.1016/j.imavis.2003.07.009
   Hayashi K, 2006, LECT NOTES COMPUT SC, V3851, P359
   Hayashi K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P681, DOI 10.1109/AFGR.2004.1301613
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kang H, 2004, PATTERN RECOGN LETT, V25, P1701, DOI 10.1016/j.patrec.2004.06.016
   Khan SM, 2006, LECT NOTES COMPUT SC, V3954, P133
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Kim K, 2006, LECT NOTES COMPUT SC, V3953, P98
   Krumm J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P3, DOI 10.1109/VS.2000.856852
   Landabaso JL, 2008, COMPUT VIS IMAGE UND, V112, P210, DOI 10.1016/j.cviu.2008.02.006
   Maes P., 1995, IEEE PRESS COMPUTER, P11
   MITTAL A, 2001, INT J COMPUT VISION, V53, P189
   Muñoz-Salinas R, 2008, PATTERN RECOGN, V41, P3665, DOI 10.1016/j.patcog.2008.06.013
   Muñoz-Salinas R, 2008, PATTERN RECOGN LETT, V29, P319, DOI 10.1016/j.patrec.2007.10.011
   Muñoz-Salinas R, 2007, IMAGE VISION COMPUT, V25, P995, DOI 10.1016/j.imavis.2006.07.012
   Muñoz-Salinas R, 2009, J VIS COMMUN IMAGE R, V20, P339, DOI 10.1016/j.jvcir.2009.03.005
   Muñoz-Salinas R, 2009, INT J APPROX REASON, V50, P732, DOI 10.1016/j.ijar.2009.02.001
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pribanic T, 2000, P ANN INT IEEE EMBS, V22, P163, DOI 10.1109/IEMBS.2000.900694
   Saffiotti A, 2005, P INT C SMART OBJ AM, P275
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110
   Yang DB, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P122
   Zhao T, 2005, PROC CVPR IEEE, P976
NR 42
TC 1
Z9 3
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2012
VL 30
IS 2
BP 122
EP 133
DI 10.1016/j.imavis.2012.02.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 934ZJ
UT WOS:000303486200006
DA 2024-07-18
ER

PT J
AU Lichtenauer, J
   Shen, J
   Valstar, M
   Pantic, M
AF Lichtenauer, Jeroen
   Shen, Jie
   Valstar, Michel
   Pantic, Maja
TI Cost-effective solution to synchronised audio-visual data capture using
   multiple sensors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video recording; Audio recording; Multisensor systems; Synchronisation
AB Applications such as surveillance and human behaviour analysis require high-bandwidth recording from multiple cameras, as well as from other sensors. In turn, sensor fusion has increased the required accuracy of synchronisation between sensors. Using commercial off-the-shelf components may compromise quality and accuracy due to several challenges, such as dealing with the combined data rate from multiple sensors; unknown offset and rate discrepancies between independent hardware clocks; the absence of trigger inputs or -outputs in the hardware; as well as the different methods for time-stamping the recorded data. To achieve accurate synchronisation, we centralise the synchronisation task by recording all trigger- or timestamp signals with a multi-channel audio interface. For sensors that don't have an external trigger signal, we let the computer that captures the sensor data periodically generate timestamp signals from its serial port output. These signals can also be used as a common time base to synchronise multiple asynchronous audio interfaces. Furthermore, we show that a consumer PC can currently capture 8-bit video data with 1024x1024 spatial- and 59.1 Hz temporal resolution, from at least 14 cameras, together with 8 channels of 24-bit audio at 96 kHz. We thus improve the quality/cost ratio of multi-sensor systems data capture systems. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Lichtenauer, Jeroen; Shen, Jie; Valstar, Michel; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
   [Pantic, Maja] Univ Twente, Fac Elect Engn Math & Comp Sci, Enschede, Netherlands.
C3 Imperial College London; University of Twente
RP Lichtenauer, J (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, 180 Queens Gate, London SW7 2AZ, England.
EM j.lichtenauer@imperial.ac.uk
OI Valstar, Michel/0000-0003-2414-161X
FU European Community [211486 (SEMAINE)]; European Research Council
   [ERC-2007-StG-203143 (MAHNOB)]
FX The research of M. Valstar leading to these results is funded in part by
   the European Community's 7th Framework Programme [FP7/2007-2013] under
   the grant agreement no 211486 (SEMAINE). The research of the other
   authors is funded by the European Research Council under the ERC
   Starting Grant agreement no. ERC-2007-StG-203143 (MAHNOB).
CR Allied Vision Technologies GmbH, 2009, AVT STINGR TECHN MAN
   [Anonymous], 2007, NORP STREAMP 4 PROD
   [Anonymous], GIGABYTE BOARDS DPC
   [Anonymous], 2008, MOTU 8PRE PROD DESCR
   Bashkatov AN, 2005, J PHYS D APPL PHYS, V38, P2543, DOI 10.1088/0022-3727/38/15/004
   Cao X, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/351452
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman P, 1978, FACIAL ACTION CODING
   El Gamal A, 2002, INTERNATIONAL ELECTRON DEVICES 2002 MEETING, TECHNICAL DIGEST, P805, DOI 10.1109/IEDM.2002.1175960
   FREUND HJ, 1978, EXP BRAIN RES, V31, P1
   Fujii T, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P437, DOI 10.1109/ICME.2006.262566
   Grant K. W., 2003, INT C AUD VIS SPEECH, P31
   Gunes Hatice, 2010, International Journal of Strategic Synthetic Emotions, V1, P68, DOI 10.4018/jse.2010101605
   Hoshuyama O, 1997, INT CONF ACOUST SPEE, P367, DOI 10.1109/ICASSP.1997.599649
   Hutchinson TC, 2006, IEEE T INSTRUM MEAS, V55, P164, DOI 10.1109/TIM.2005.860872
   Intel, 2008, 316972004 INT
   Lienhart R., 2003, 11 ACM INT C MULT BE, P263
   Sargin ME, 2007, IEEE T MULTIMEDIA, V9, P1396, DOI 10.1109/TMM.2007.906583
   Shu-Ren T, 2007, SECOND WORKSHOP ON DIGITAL MEDIA AND ITS APPLICATION IN MUSEUM & HERITAGE, PROCEEDINGS, P319, DOI 10.1109/DMAMH.2007.76
   Soleymani M., 2010, IEEE T AF UNPUB 1108
   Sookman S., 2007, ADV IMAGING, V2, P20
   Svoboda T., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P515
   Tajbakhsh T, 2007, PROC SPIE, V6502, DOI 10.1117/12.709555
   Tobii Technology AB, 2008, TOB TECHN AB US MAN
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Wilburn B, 2005, ACM T GRAPHIC, V24, P765, DOI 10.1145/1073204.1073259
   Zhou H., 2008, Technical Report SCE-08-12
   Zitnick CL, 2004, ACM T GRAPHIC, V23, P600, DOI 10.1145/1015706.1015766
NR 28
TC 9
Z9 10
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2011
VL 29
IS 10
BP 666
EP 680
DI 10.1016/j.imavis.2011.07.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 848YP
UT WOS:000297091300003
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Samavi, S
   Habibi, M
   Shirani, S
   Rowshanbin, N
AF Samavi, S.
   Habibi, M.
   Shirani, S.
   Rowshanbin, N.
TI Real time fractal image coder based on characteristic vector matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fractal image compression; Classification; Low power
ID COMPRESSION; ARCHITECTURE
AB Fractal coding algorithm has many applications including image compression. In this paper a classification scheme is presented which allows the hardware implementation of the fractal coder. High speed and low power consumption are the goal of the suggested design. The introduced method is based on binary classification of domain and range blocks. The proposed technique increases the processing speed and reduces the power consumption while the qualities of the reconstructed images are comparable with those of the available software techniques. In order to show the functionality of the proposed algorithm, the architecture was implemented on a FPGA chip. The application of the proposed hardware is shown in image compression. The resulted compression ratios, PSNR error, gate count, compression speed and power consumption are compared with the existing designs. Other applications of the proposed design are feasible in certain fields such as mass-volume database coding and also in video coder's block matching schemes. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Samavi, S.; Rowshanbin, N.] Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
   [Samavi, S.; Shirani, S.] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
   [Habibi, M.] Univ Isfahan, Dept Elect Engn, Esfahan, Iran.
C3 Isfahan University of Technology; McMaster University; University of
   Isfahan
RP Samavi, S (corresponding author), Isfahan Univ Technol, Dept Elect & Comp Engn, Esfahan, Iran.
EM samavi@mcmaster.ca
RI cai, bo/G-1491-2010
OI Habibi, Mehdi/0000-0002-4039-5030
CR Acken KP, 1998, J VLSI SIG PROC SYST, V19, P97, DOI 10.1023/A:1008005616596
   Bocchi L, 2004, MED ENG PHYS, V26, P303, DOI 10.1016/j.medengphy.2003.11.009
   Cochran WO, 1996, IEEE T VIS COMPUT GR, V2, P313, DOI 10.1109/2945.556500
   Duh DJ, 2005, IMAGE VISION COMPUT, V23, P1115, DOI 10.1016/j.imavis.2005.05.013
   EBRAHIMPOURKOML.H, 2001, P INT C IM PROC, V3, P58
   GHOSH SK, 2002, P 3 IND C COMP VIS G
   Jackson DJ, 2007, J REAL-TIME IMAGE PR, V1, P225, DOI 10.1007/s11554-007-0024-2
   Jacquin AE, 1992, IEEE T IMAGE PROCESS, V1, P18, DOI 10.1109/83.128028
   Kovács T, 2008, IMAGE VISION COMPUT, V26, P1129, DOI 10.1016/j.imavis.2007.12.008
   Li J, 1999, IEEE T IMAGE PROCESS, V8, P868, DOI 10.1109/83.766863
   Li J, 2008, IEEE T DIELECT EL IN, V15, P496, DOI 10.1109/TDEI.2008.4483470
   Mozaffari S, 2004, INT C PATT RECOG, P331, DOI 10.1109/ICPR.2004.1334199
   Ni RR, 2005, PATTERN RECOGN, V38, P357, DOI 10.1016/j.patcog.2004.08.006
   Puate J, 1996, P SPIE PHOT E S
   RAMIREZ AM, 2003, P 3 INT S IM SIGN PR, P112
   ROWSHANBIN N, 2006, P IEEE CCECE MAY, P2026
   Tseng CC, 2008, IMAGE VISION COMPUT, V26, P1154, DOI 10.1016/j.imavis.2008.01.003
   Vidya D, 2000, J SYST ARCHITECT, V46, P1275, DOI 10.1016/S1383-7621(00)00018-7
   Wu MS, 2007, ENG APPL ARTIF INTEL, V20, P531, DOI 10.1016/j.engappai.2006.08.005
   WU Y, 2003, P IEEE MULT EXP ICME, V1, P353
   Yokoyama T, 2007, LECT NOTES COMPUT SC, V4351, P428
   Zheng Y, 2006, COMPUT MATH APPL, V51, P1727, DOI 10.1016/j.camwa.2006.05.010
   ZHOU YM, 2006, FAST HYBRID FRACTAL
NR 23
TC 10
Z9 11
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2010
VL 28
IS 11
BP 1557
EP 1568
DI 10.1016/j.imavis.2010.03.011
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 639KD
UT WOS:000280972800006
DA 2024-07-18
ER

PT J
AU Gross, R
   Matthews, I
   Cohn, J
   Kanade, T
   Baker, S
AF Gross, Ralph
   Matthews, Iain
   Cohn, Jeffrey
   Kanade, Takeo
   Baker, Simon
TI Multi-PIE
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face database; Face recognition across pose; Face recognition across
   illumination; Face recognition across expression
ID FACE-RECOGNITION; ILLUMINATION; EIGENFACES; MODELS
AB A close relationship exists between the advancement of face recognition algorithms and the availability of face databases varying factors that affect facial appearance in a controlled manner. The CMU PIE database has been very influential in advancing research in face recognition across pose and illumination. Despite its success the PIE database has several shortcomings: a limited number of subjects, a single recording session and only few expressions captured. To address these issues we collected the CMU Multi-PIE database. It contains 337 subjects, imaged under 15 view points and 19 illumination conditions in up to four recording sessions. In this paper we introduce the database and describe the recording procedure. We furthermore present results from baseline experiments using PCA and LDA classifiers to highlight similarities and differences between PIE and Multi-PIE. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Gross, Ralph; Matthews, Iain; Kanade, Takeo] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   [Cohn, Jeffrey] Univ Pittsburgh, Dept Psychol, Pittsburgh, PA 15260 USA.
   [Baker, Simon] Microsoft Corp, Microsoft Res, Redmond, WA 98052 USA.
C3 Carnegie Mellon University; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); University of Pittsburgh; Microsoft
RP Gross, R (corresponding author), Carnegie Mellon Univ, Inst Robot, 5000 Forbes Ave, Pittsburgh, PA 15213 USA.
EM rgross@cs.cmu.edu
FU United States Government's Technology Support Working Group (TSWG)
   [N41756-03-C-402]; Sandia National Laboratories
FX We would like to thank Jonathon Phillips, James Wayman, and David
   Herrington for discussions and support and the anonymous reviewers for
   comments. We furthermore would like to thank Athinodoros Georghiades and
   Peter Belhumeur for providing us with the setup details of the Yale
   "flash system". Collection of the Multi-PIE database was supported by
   United States Government's Technology Support Working Group (TSWG)
   through award N41756-03-C-402 and by Sandia National Laboratories.
CR [Anonymous], 2 INT C AUD VID BIOM
   [Anonymous], CMURITR9834
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Beveridge JR, 2005, MACH VISION APPL, V16, P128, DOI 10.1007/s00138-004-0144-7
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Delaporte V, 2005, PROG UROL, V15, P260
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gross Ralph., 2005, HDB FACE RECOGNITION
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Martinez A., 1998, AR FACE DATABASE
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
NR 15
TC 1248
Z9 1408
U1 2
U2 72
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 807
EP 813
DI 10.1016/j.imavis.2009.08.002
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900009
PM 20490373
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Mayer, C
   Wimmer, M
   Radig, B
AF Mayer, Christoph
   Wimmer, Matthias
   Radig, Bernd
TI Adjusted pixel features for robust facial component classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Facial components; Feature extraction
ID FACE; SEGMENTATION
AB Within the last decade increasing computing power and the scientific advancement of algorithms allowed the analysis of various aspects of human faces such as facial expression estimation [20], head pose estimation [17], person identification [2] or face model fitting [31]. Today, computer scientists can use a bunch of different techniques to approach this challenge [4,29,3,17,9,21]. However, each of them still has to deal with non-perfect accuracy or high execution times.
   This is mainly because the extraction of descriptive features is challenging in real-world scenarios to any image understanding application. In this paper, we consider the extraction of more descriptive information from the image for face analysis tasks. Our approach automatically determines a set of characteristics that describe the conditions of the entire image. They are based on semantic information that describes the location of facial components, such as skin, lips, eyes, and brows. From these image characteristics, pixel features are determined that are highly tuned to the task of interpreting images of human faces. The extracted features are applied to train pixel-based classifiers, which is the straightforward approach because this task suffers from high intra-class and small inter-class color variations due to changing context conditions such as the person's ethnic group or lighting condition. In contrast, more elaborate classifiers that additionally consider shape or region features are not real-time capable.
   The success of this approach relies on the fact that we do not manually select the calculation rules but we provide a multitude of features of various kinds, both color-related and space-related. A Machine Learning algorithm then decides which of them are important and which are not rendering the approach fast due to its pixel-based nature and accurate due to the highly descriptive features the same time. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Mayer, Christoph; Wimmer, Matthias; Radig, Bernd] Tech Univ Munich, D-85748 Garching, Germany.
C3 Technical University of Munich
RP Mayer, C (corresponding author), Tech Univ Munich, Informatix 9,Boltzmannstr 1, D-85748 Garching, Germany.
EM mayerc@in.tum.de
CR BEIGZAHED M, 2008, P 2008 IEEE CAIR INT
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P617
   Cootes T., 1998, Proc. ECCV, V2, P484
   Cootes TF, 2001, PROC CVPR IEEE, P1114
   CRISTINACCE D, 2006, P 7 INT C AUT FAC GE
   Cristinacce D., 2007, Boosted regression active shape models, V2, P880
   EVENO N, 2003, P INT C IM PROC
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Lam KM, 1996, PATTERN RECOGN, V29, P771, DOI 10.1016/0031-3203(95)00119-0
   Leung SH, 2004, IEEE T IMAGE PROCESS, V13, P51, DOI 10.1109/TIP.2003.818116
   LIEW AWC, 2003, IEEE T FUZZY SYSTEMS
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   ORAZIO TD, 2004, P 17 INT C PATT REC
   Ozuysal M., 2006, P EUR C COMP VIS
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Phung SL, 2005, IEEE T PATTERN ANAL, V27, P148, DOI 10.1109/TPAMI.2005.17
   REVERET L, 1997, P 5 BIENN EUR C SPEE, P2011
   Sadeghi M, 2002, IEE P-VIS IMAGE SIGN, V149, P179, DOI 10.1049/ip-vis:20020378
   Sadeghi V. S., 2006, INT J COMPUTER SCI N
   Soriano M, 2000, INT C PATT RECOG, P839, DOI 10.1109/ICPR.2000.905542
   Stegmann MB, 2003, IMAGE VISION COMPUT, V21, P61, DOI 10.1016/S0262-8856(02)00126-9
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Vezhnevets V., 2003, SURVEY PIXEL BASED S
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wimmer M, 2008, IEEE T PATTERN ANAL, V30, P1357, DOI 10.1109/TPAMI.2007.70793
NR 31
TC 9
Z9 10
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 762
EP 771
DI 10.1016/j.imavis.2009.07.012
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900005
DA 2024-07-18
ER

PT J
AU Clark, JJ
AF Clark, James J.
TI Photometric stereo using LCD displays
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape-from-shading; Photometric stereo; Distributed illuminant
AB This paper considers the problem of shape-from-shading using nearby extended light Sources. The paper reviews a number of methods that employ nearby illuminants, and describes a new technique that assumes a rectangular planar nearby distributed uniform isotropic illuminant. It is shown that such a light Source illuminating a small Lambertian Surface patch is equivalent to a single isotropic point light source at infinity, in the absence of shadowing. A closed-form solution is given for the equivalent point light source direction in terms of the illuminant corner locations. Equivalent point light sources can be obtained for distinct illuminant patterns allowing standard photometric stereo algorithms to be used. An extension is given to the case of a rectangular planar illuminant with arbitrary radiance distribution. Experimental results are shown demonstrating the application of the theory to photometric stereo using illumination from a LCD Computer monitor. Details on the photometric calibration of the illumination source and image acquisition device are provided. (C) 2008 Elsevier B.V. All rights reserved.
C1 McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.
C3 McGill University
RP Clark, JJ (corresponding author), McGill Univ, Ctr Intelligent Machines, 3480 Univ St, Montreal, PQ H3A 2A7, Canada.
EM clark@cim.mcgill.ca
OI Clark, James/0000-0002-4512-6171
CR AGRAWAL A, 2006, EUR C COMP VIS ECCV
   [Anonymous], 1999, 145241999E ISO
   [Anonymous], 1980, THESIS MIT CAMBRIDGE
   Clark J, 2006, P CRV, P16
   Clark J. J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P119, DOI 10.1109/CVPR.1999.786927
   CLARK JJ, 1992, P COMP VIS PATT REC
   FUNK N, 2005, THESIS U ALBERTA
   FUNK N, 2006, TR0613 U ALB COMP SC
   HORN BKP, 1975, PSYCHOL COMPUTER VIS, pCH4
   IKEUCHI K, 1981, IEEE T PATTERN ANAL, V3, P661, DOI 10.1109/TPAMI.1981.4767167
   Iwahori Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P83, DOI 10.1109/ICPR.1990.118069
   IWAHORI Y, 1994, IEICE T INF SYST, VE77D, P925
   IWAHORI Y, 1992, P 2 INT C AUT ROB CO
   KIM B, 1991, CVGIP-IMAG UNDERSTAN, V54, P416, DOI 10.1016/1049-9660(91)90040-V
   Magda S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P391, DOI 10.1109/ICCV.2001.937652
   Schechner YY, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P808
   Wolff L. B., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P46, DOI 10.1109/CVPR.1989.37827
   WOODHAM RJ, 1994, J OPT SOC AM A, V11, P3050, DOI 10.1364/JOSAA.11.003050
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   WULLER D, P SPIE IS T ELECT IM, P6502
   Wyszecki G., 1982, Color science: Concepts and methods, quantitative data and formulae
NR 21
TC 14
Z9 16
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 704
EP 714
DI 10.1016/j.imavis.2008.10.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600015
DA 2024-07-18
ER

PT J
AU Hsieh, PF
   Chou, PW
   Chung, HY
AF Hsieh, Pi-Fuei
   Chou, Po-Wen
   Chung, Hsueh-Yi
TI An MRF-based kernel method for nonlinear feature extraction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature extraction; Dimensionality reduction; Kernel trick;
   Classification
ID PRINCIPAL COMPONENT ANALYSIS; DISCRIMINANT-ANALYSIS; FACE RECOGNITION;
   CLASSIFICATION; LIKELIHOOD; FRAMEWORK; LDA
AB Nonlinear kernel-based feature extraction algorithms have recently been proposed to alleviate the loss of class discrimination after feature extraction. When considering image classification, a kernel function may not be sufficiently effective if it depends only on an information resource from the Euclidean distance in the original feature space. This study presents an extended radial basis kernel function that integrates multiple discriminative information resources, including the Euclidean distance, spatial context, and class membership. The concepts related to Markov random fields (MRFs) are exploited to model the spatial context information existing in the image. Mutual closeness in class membership is defined as a similarity measure with respect to classification. Any dissimilarity from the additional information resources will improve the discrimination between two samples that are only a short Euclidean distance apart in the feature space. The proposed kernel function is used for feature extraction through linear discriminant analysis (LDA) and principal component analysis (PCA). Experiments with synthetic and natural images show the effectiveness of the proposed kernel function with application to image classification. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Hsieh, Pi-Fuei; Chou, Po-Wen; Chung, Hsueh-Yi] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan 701, Taiwan.
C3 National Cheng Kung University
RP Hsieh, PF (corresponding author), Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, 1 Univ Rd, Tainan 701, Taiwan.
EM pfhsieh@mail.ncku.edu.tw; sheep174812@yahoo.com;
   p7697138@mail.ncku.edu.tw
CR [Anonymous], MARKOV FIELDS UNPUB
   [Anonymous], 1995, Markov random field modeling in computer vision
   ARONSZAJN N, 1950, T AM MATH SOC, V68, P337, DOI 10.1090/s0002-9947-1950-0051437-7
   Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Camastra F, 2005, IEEE T PATTERN ANAL, V27, P801, DOI 10.1109/TPAMI.2005.88
   Camps-Valls G, 2006, IEEE GEOSCI REMOTE S, V3, P93, DOI 10.1109/LGRS.2005.857031
   Camps-Valls G, 2005, IEEE T GEOSCI REMOTE, V43, P1351, DOI 10.1109/TGRS.2005.846154
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Donoghue W. F., 1974, MONOTONE MATRIX FUNC
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Hotta K, 2008, IMAGE VISION COMPUT, V26, P1490, DOI 10.1016/j.imavis.2008.04.008
   Jebara T, 2003, LECT NOTES ARTIF INT, V2777, P57, DOI 10.1007/978-3-540-45167-9_6
   Ji SW, 2008, IEEE T NEURAL NETWOR, V19, P1768, DOI 10.1109/TNN.2008.2002078
   Kim KI, 2005, IEEE T PATTERN ANAL, V27, P1351, DOI 10.1109/TPAMI.2005.181
   Kim KI, 2002, IEEE SIGNAL PROC LET, V9, P40, DOI 10.1109/97.991133
   Kim KI, 2001, IEEE SIGNAL PROC LET, V8, P39, DOI 10.1109/97.895369
   Kocsor A, 2004, IEEE T SIGNAL PROCES, V52, P2250, DOI 10.1109/TSP.2004.830995
   Kwon H, 2006, IEEE T PATTERN ANAL, V28, P178, DOI 10.1109/TPAMI.2006.39
   Kwon H, 2005, IEEE T GEOSCI REMOTE, V43, P2952, DOI 10.1109/TGRS.2005.857904
   Ma JS, 2003, IEEE SIGNAL PROC LET, V10, P196, DOI 10.1109/LSP.2003.813680
   Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016
   MICCHELLI CA, 1986, INTERPOLATION SCATTE
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Minh HQ, 2006, LECT NOTES ARTIF INT, V4005, P154, DOI 10.1007/11776420_14
   PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559
   Peng J, 2004, IEEE T PATTERN ANAL, V26, P656, DOI 10.1109/TPAMI.2004.1273978
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Rellier G, 2004, IEEE T GEOSCI REMOTE, V42, P1543, DOI 10.1109/TGRS.2004.830170
   Roth V, 2000, ADV NEUR IN, V12, P568
   Ruiz A, 2001, IEEE T NEURAL NETWOR, V12, P16, DOI 10.1109/72.896793
   Saitoh S., 1988, Theory of Reproducing Kernels and its Applications
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Wang L, 2005, IEEE T SYST MAN CY B, V35, P556, DOI 10.1109/TSMCB.2005.846660
   Wang YJ, 2008, CEMENT CONCRETE COMP, V30, P353, DOI 10.1016/j.cemconcomp.2007.03.003
   WOODS JW, 1978, IEEE T AUTOMAT CONTR, V23, P846, DOI 10.1109/TAC.1978.1101866
   YAMAZAKI T, 1995, IEEE T IMAGE PROCESS, V4, P1333, DOI 10.1109/83.413180
   Yang J, 2005, IEEE T PATTERN ANAL, V27, P230, DOI 10.1109/TPAMI.2005.33
   Ye JP, 2008, J MACH LEARN RES, V9, P719
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
   Zheng WM, 2005, IEEE T NEURAL NETWOR, V16, P1, DOI 10.1109/TNN.2004.836239
   Zhou SK, 2006, IEEE T PATTERN ANAL, V28, P917, DOI 10.1109/TPAMI.2006.120
   Zhu ML, 2008, IEEE T NEURAL NETWOR, V19, P148, DOI 10.1109/TNN.2007.904040
   Zhu ML, 2006, IEEE T PATTERN ANAL, V28, P1274, DOI 10.1109/TPAMI.2006.172
NR 46
TC 0
Z9 0
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 502
EP 517
DI 10.1016/j.imavis.2009.08.006
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300020
DA 2024-07-18
ER

PT J
AU Jeong, DS
   Hwang, JW
   Kang, BJ
   Park, KR
   Won, CS
   Park, DK
   Kim, J
AF Jeong, Dae Sik
   Hwang, Jae Won
   Kang, Byung Jun
   Park, Kang Ryoung
   Won, Chee Sun
   Park, Dong-Kwon
   Kim, Jaihie
TI A new iris segmentation method for non-ideal iris images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Non-ideal iris images; AdaBoost eye detection; Color segmentation
ID RECOGNITION; EYELASH; FOCUS
AB Many researchers have studied iris recognition techniques in unconstrained environments, where the probability of acquiring non-ideal iris images is very high due to off-angles, noise, blurring and occlusion by eyelashes, eyelids, glasses, and hair. Although there have been many iris segmentation methods, most focus primarily on the accurate detection with iris images which are captured in a closely controlled environment. This paper proposes a new iris segmentation method that can be used to accurately extract iris regions from non-ideal quality iris images. This research has following three novelties compared to previous works; firstly, the proposed method uses AdaBoost eye detection in order to compensate for the iris detection error caused by the two circular edge detection operations; secondly, it uses a color segmentation technique for detecting obstructions by the ghosting effects of visible light; and thirdly, if there is no extracted corneal specular reflection in the detected pupil and iris regions, the captured iris image is determined as a "closed eye" image. The proposed method has been tested using the UBIRIS.v2 database via NICE.I (Noisy Iris Challenge Evaluation - Part I) contest.
   The results show that FP (False Positive) error rate and FN (False Negative) error rate are 1.2% and 27.6%, respectively, from NICE.I report (the 5th highest rank). (C) 2009 Elsevier B.V. All rights reserved.
C1 [Jeong, Dae Sik; Hwang, Jae Won; Park, Kang Ryoung] Dongguk Univ, Dept Elect Engn, BERC, Seoul 100715, South Korea.
   [Kang, Byung Jun] Hanyang Univ, BERC, Inst Biomed Engn, Seoul 133791, South Korea.
   [Park, Dong-Kwon] ImageproTech Inc, Janghang Dong, Goyang Si 410380, Gyeonggi Do, South Korea.
   [Kim, Jaihie] Yonsei Univ, Sch Elect & Elect Engn, BERC, Seoul 120749, South Korea.
C3 Dongguk University; Hanyang University; Yonsei University
RP Park, KR (corresponding author), Dongguk Univ, Dept Elect Engn, BERC, 26 Pil Dong,3 Ga, Seoul 100715, South Korea.
EM parkgr@dgu.edu
OI Won, Chee Sun/0000-0002-3400-0792
FU Korea Science and Engineering Foundation (KOSEF) [RI 12002105070020]
FX This work was supported by the Korea Science and Engineering Foundation
   (KOSEF) through the Biometrics Engineering Research Center (BERC) at
   Yonsei University [RI 12002105070020(2008)].
CR [Anonymous], P IEEE 1 INT C BIOM
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2003, PATTERN RECOGN, V36, P279, DOI 10.1016/S0031-3203(02)00030-4
   Daugman J., 2003, INT J WAVELETS MULTI, V1, P1, DOI DOI 10.1142/S0219691303000025
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Jang YK, 2008, PATTERN RECOGN LETT, V29, P1698, DOI 10.1016/j.patrec.2008.05.001
   Kang BJ, 2007, PATTERN RECOGN LETT, V28, P1630, DOI 10.1016/j.patrec.2007.04.004
   Kong WK, 2003, INT J PATTERN RECOGN, V17, P1025, DOI 10.1142/S0218001403002733
   Kong WK, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P263, DOI 10.1109/ISIMP.2001.925384
   Park KS, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/438051
   Qian G., 2004, P 2004 ACM S APPL CO, P1232
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   2009, CASIA IRIS DATABASE
NR 14
TC 79
Z9 86
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2010
VL 28
IS 2
SI SI
BP 254
EP 260
DI 10.1016/j.imavis.2009.04.001
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 538GR
UT WOS:000273173100007
DA 2024-07-18
ER

PT J
AU Caputo, B
   Hayman, E
   Fritz, M
   Eklundh, JO
AF Caputo, Barbara
   Hayman, Eric
   Fritz, Mario
   Eklundh, Jan-Olof
TI Classifying materials in the real world
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Material classification; Support vector machines; Experimental
   evaluation
ID SUPPORT VECTOR MACHINES; TEXTURE; CLASSIFICATION; FEATURES; RECOGNITION;
   IMAGES
AB Classifying materials from their appearance is challenging. Impressive results have been obtained under varying illumination and pose conditions. Still, the effect of scale variations and the possibility to generalise across different material samples are still largely unexplored. This paper (A preliminary version of this work was presented in Hayman et al. [E. Hayman, B. Caputo, M.J. Fritz, J.-O. Eklundh, On the significance of real world conditions for material classification, in: Proceedings of the ECCV, Lecture Notes in Computer Science, vol. 4, Springer, Prague, 2004, pp. 253-266].) addresses these issues, proposing a pure learning approach based on support vector machines. We study the effect of scale variations first on the artificially scaled CUReT database, showing how performance depends on the amount of scale information available during training. Since the CUReT database contains little scale variation and only one sample per material, we introduce a new database containing 10 CUReT materials at different distances, pose and illumination. This database provides scale variations, while allowing to evaluate generalisation capabilities: does training on the CUReT database enable recognition of another piece of sandpaper? Our results demonstrate that this is not yet possible, and that material classification is far from being solved in scenarios of practical interest. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Caputo, Barbara] IDIAP Res Inst, Martigny, Switzerland.
   [Caputo, Barbara] Ecole Polytech Fed Lausanne, CH-1015 Lausanne, Switzerland.
   [Hayman, Eric] Tracab, Stockholm, Sweden.
   [Fritz, Mario] Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany.
   [Eklundh, Jan-Olof] KTH, CVAP, Dept Numer Anal & Comp Sci, Stockholm, Sweden.
C3 Swiss Federal Institutes of Technology Domain; Ecole Polytechnique
   Federale de Lausanne; Technical University of Darmstadt; Royal Institute
   of Technology
RP Caputo, B (corresponding author), IDIAP Res Inst, Rue Marconi 19, Martigny, Switzerland.
EM bcaputo@idiap.ch; eric.hayman@tracab.com; fritz@mis.tu-darmstadt.de;
   joe@nada.kth.se
RI Caputo, Barbara/F-3928-2011; Caputo, Barbara/J-8976-2015
OI Caputo, Barbara/0000-0001-7169-0158
FU EU-IST [IST-2000-29688 Insight2+, IST-2000-29375 CogVis, IST-FP6-0027787
   DIRAC, IST-FP6-004250-IP CoSy]; Swedish Foundation for Strategic
   Research
FX This work was funded by the EU-IST projects IST-2000-29688 Insight2+
   (E.H., M.F.), IST-2000-29375 CogVis and IST-FP6-0027787 DIRAC (B.C.),
   IST-FP6-004250-IP CoSy (M.F.) and the VIS-COS project funded by the
   Swedish Foundation for Strategic Research (E.H.).
CR Avidan S, 2001, PROC CVPR IEEE, P184
   BARLA A, 2002, P ECCV COP, V4, P20
   BELONGIE S, 2002, P ECCV COP, V3, P531
   BROADHURST RE, 2005, TEXTURE 2005, P25
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Burges C.J. C., 1998, Advances in Kernel Methods - Support VectorLearning
   CAPUTO B, 2002, P NIPS VANC
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chapelle O, 1999, IEEE T NEURAL NETWOR, V10, P1055, DOI 10.1109/72.788646
   Cristianini N., 2000, INTRO SUPPORT VECTOR
   Cula OG, 2001, PROC CVPR IEEE, P1041
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Fritz M., KTH TIPS DATABASE
   Ganster H, 2001, IEEE T MED IMAGING, V20, P233, DOI 10.1109/42.918473
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   Kim KI, 2002, IEEE T PATTERN ANAL, V24, P1542, DOI 10.1109/TPAMI.2002.1046177
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lazebnik S, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P649
   LAZEBNIK S, 2006, P CVPR NEW YORK
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Li ST, 2003, PATTERN RECOGN, V36, P2883, DOI 10.1016/S0031-3203(03)00219-X
   Li SZ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P674, DOI 10.1109/ICCV.2001.937691
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mäenpää T, 2003, LECT NOTES COMPUT SC, V2749, P885
   Malik J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P918, DOI 10.1109/ICCV.1999.790346
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MANTHALKAR R, 2002, TEXTURE WORKSH, P87
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Penirschke A., 2002, TEXTURE 2002 2 INT W, P103
   PLATT JC, 2000, P NIPS 2000 DENV COL
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   Roobaert D, 2001, PROC CVPR IEEE, P351
   Ruiz L, 2004, 20 ISPRS C
   Shi MH, 2003, IEEE T GEOSCI REMOTE, V41, P1090, DOI 10.1109/TGRS.2003.811076
   Singh S, 2001, PATTERN RECOGN, V34, P1601, DOI 10.1016/S0031-3203(00)00099-6
   Vapnik V., 1998, STAT LEARNING THEORY, V3
   Varma M, 2003, PROC CVPR IEEE, P691
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   VARMA M, 2003, COMMUNICATION
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 47
TC 81
Z9 84
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 150
EP 163
DI 10.1016/j.imavis.2009.05.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000015
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ng, J
   Clay, ST
   Barman, SA
   Fielder, AR
   Moseley, MJ
   Parker, KH
   Paterson, C
AF Ng, J.
   Clay, S. T.
   Barman, S. A.
   Fielder, A. R.
   Moseley, M. J.
   Parker, K. H.
   Paterson, C.
TI Maximum likelihood estimation of vessel parameters from scale space
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Scale space; Maximum likelihood; Retinal blood vessels; Automatic
   segmentation
ID BLOOD-VESSELS; RETINAL IMAGES; SEGMENTATION; MORPHOLOGY
AB We describe a method of detecting features in retinal images using a model-based approach. The image is processed using a bank of filters in a scale space. A parametric model of the target feature is then proposed and the filter responses to the model calculated. A noise model is proposed, and incorporated into a maximum likelihood estimator to estimate model parameters. The estimator uses the generative parametric model to explore smoothly the scale space. This method is applied to the detection of retinal blood vessels, using a Gaussian-profiled valley as a model. A simple thresholding method is proposed as an example of using the rich estimated parameter maps to detect vessels and the results are compared against two existing vessel detectors. Our system is compared against ground truth and the output of existing systems. It is found to be comparable and, in addition, produces direct estimates of vessel calibres and contrasts. It does not use any form of region growing or vessel tracking, but thresholds a function of the estimated vessel parameters to determine vessel regions. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Ng, J.; Clay, S. T.; Paterson, C.] Univ London Imperial Coll Sci Technol & Med, Blackett Lab, Dept Phys, London SW7 2BW, England.
   [Parker, K. H.] Univ London Imperial Coll Sci Technol & Med, Dept Bioengn, London SW7 2AZ, England.
   [Fielder, A. R.; Moseley, M. J.] City Univ London, Dept Optometry & Visual Sci, London EC1V 0HB, England.
   [Barman, S. A.] Kingston Univ, Digital Imaging Res Ctr, Sch Comp Informat Syst & Math, Kingston upon Thames KT1 2EE, Surrey, England.
C3 Imperial College London; Imperial College London; City University
   London; Kingston University
RP Ng, J (corresponding author), Univ London Imperial Coll Sci Technol & Med, Blackett Lab, Dept Phys, London SW7 2BW, England.
EM jeffrey.ng@imperial.ac.uk
RI Paterson, Carl/C-8387-2011
OI Barman, Sarah/0000-0001-5302-0169; Paterson, Carl/0000-0003-3584-1662
FU PPARC PIPSS
FX This research was supported by a PPARC PIPSS grant. Carl Paterson is a
   Royal Society University Research Fellow.
CR Can A, 1999, IEEE Trans Inf Technol Biomed, V3, P125, DOI 10.1109/4233.767088
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Chutatape O, 1998, P ANN INT IEEE EMBS, V20, P3144, DOI 10.1109/IEMBS.1998.746160
   FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W
   FRIEDENWALD JS, 1950, AM J OPHTHALMOL, V33, P1187, DOI 10.1016/0002-9394(50)90988-3
   GRISAN E, P 26 ANN INT C IEEE, P1620
   Hart WE, 1999, INT J MED INFORM, V53, P239, DOI 10.1016/S1386-5056(98)00163-4
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Jiang XY, 2003, IEEE T PATTERN ANAL, V25, P131, DOI 10.1109/TPAMI.2003.1159954
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Martinez-Perez ME, 2002, IEEE T BIO-MED ENG, V49, P912, DOI 10.1109/TBME.2002.800789
   MILES FP, 1993, IEEE T MED IMAGING, V12, P147, DOI 10.1109/42.232243
   Sinthanayothin C, 1999, BRIT J OPHTHALMOL, V83, P902, DOI 10.1136/bjo.83.8.902
   Staal J, 2004, IEEE T MED IMAGING, V23, P501, DOI 10.1109/TMI.2004.825627
   Steger C, 1998, IEEE T PATTERN ANAL, V20, P113, DOI 10.1109/34.659930
   UNSWORTH AC, 1949, T AM OPHTHAL SOC, V47, P738
   Walter T., 2001, ISMDA, P282, DOI DOI 10.1007/3-540-45497-7_43
   Wang L, 2004, INT C PATT RECOG, P534, DOI 10.1109/ICPR.2004.1334584
   Wilson CM, 2008, INVEST OPHTH VIS SCI, V49, P3577, DOI 10.1167/iovs.07-1353
   WILSON CM, 2008, VESSEL PARAMETERS DE
   Zana F, 2001, IEEE T IMAGE PROCESS, V10, P1010, DOI 10.1109/83.931095
NR 22
TC 43
Z9 43
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 55
EP 63
DI 10.1016/j.imavis.2009.04.019
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000007
DA 2024-07-18
ER

PT J
AU Ziegel, J
   Kiderlen, M
AF Ziegel, Johanna
   Kiderlen, Markus
TI Estimation of surface area and surface area measure of three-dimensional
   sets from digitizations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Surface area; Surface area measure; Anisotropy; 3D binary image;
   Configuration; Gauss digitization; Local method; Rose of normal
   directions
ID CONFIGURATION COUNTS; DIRECTIONAL ANALYSIS
AB A local method for estimating surface area and surface area measure of three-dimensional objects from discrete binary images is presented. A weight is assigned to each 2 x 2 x 2 configuration of voxels and the total surface area of an object is given by summation of the local area contributions. The method is based on an exact asymptotic result that holds for increasing resolution of the digitization. It states that the number of occurrences of a 2 x 2 x 2 configuration is asymptotically proportional to an integral of its "h-function" with respect to the surface area measure of the object. We find explicit representations for these h-functions. Analyzing them in detail, we determine weights that lead to an asymptotic worst case error for surface area estimation of less than 4%. We show that this worst case error is the best possible. Exploiting the local nature of the asymptotic result, we also establish two parametric estimators for the surface area measure. The latter allow to quantify anisotropy of the object under consideration. Simulation studies illustrate the validity of the estimation procedure also for finite, but sufficiently high resolution. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Kiderlen, Markus] Univ Aarhus, Dept Math Sci, DK-8000 Aarhus C, Denmark.
   [Ziegel, Johanna] ETH, Dept Math, CH-8092 Zurich, Switzerland.
C3 Aarhus University; Swiss Federal Institutes of Technology Domain; ETH
   Zurich
RP Kiderlen, M (corresponding author), Univ Aarhus, Dept Math Sci, Ny Munkegade Build 1530, DK-8000 Aarhus C, Denmark.
EM johanna.ziegel@math.ethz.ch; kiderlen@imf.au.dk
RI Kiderlen, Markus/ITW-0301-2023; Ziegel, Johanna/HOC-7467-2023
OI Kiderlen, Markus/0000-0003-2858-6659; Ziegel,
   Johanna/0000-0002-5916-9746
CR [Anonymous], 2020, The Algorithm Design Manual
   AVIS D, 1992, DISCRETE COMPUT GEOM, V8, P295, DOI 10.1007/BF02293050
   COEURJOLLY D, 2003, LNCS, V2616
   Gutkowski P, 2004, J MICROSC-OXFORD, V216, P175, DOI 10.1111/j.0022-2720.2004.01405.x
   Jensen EBV, 2003, J MICROSC-OXFORD, V212, P158, DOI 10.1046/j.1365-2818.2003.01149.x
   Kiderlen M, 2005, J MICROSC-OXFORD, V219, P50, DOI 10.1111/j.1365-2818.2005.01493.x
   Kiderlen M, 2003, ADV APPL PROBAB, V35, P583, DOI 10.1239/aap/1059486819
   KIDERLEN M, MATHEMATIKA, V53
   KLETTE R, 2001, LNCS, V2059, P2001
   Klette R., 2004, DIGITAL GEOMETRY GEO
   Liese F., 1987, Convex statistical distances
   Lindblad J, 2005, IMAGE VISION COMPUT, V23, P111, DOI 10.1016/j.imavis.2004.06.012
   LINDBLAD J, 2002, DISCRETE GEOMETRY CO
   Lofberg J., 2004, P IEEE INT S COMPUTE
   Ohser J., 2000, Statistical Analysis of Microstructures in Materials Science
   Schladitz K, 2006, LECT NOTES COMPUT SC, V4245, P247
NR 16
TC 18
Z9 20
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 64
EP 77
DI 10.1016/j.imavis.2009.04.013
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Aja-Fernández, S
   Vegas-Sánchez-Ferrero, G
   Martín-Fernández, M
   Alberola-López, C
AF Aja-Fernandez, Santiago
   Vegas-Sanchez-Ferrero, Gonzalo
   Martin-Fernandez, Marcos
   Alberola-Lopez, Carlos
TI Automatic noise estimation in images using local statistics. Additive
   and multiplicative cases
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Noise estimation; Mode; Restoration; Gaussian noise; Local statistics
ID COEFFICIENT; REGULARIZATION; VARIANCE
AB In this paper, we focus on the problem of automatic noise parameter estimation for additive and multiplicative models and propose a simple and novel method to this end. Specifically we show that if the image to work with has a sufficiently great amount of low-variability areas (which turns out to be a typical feature in most images), the variance of noise (if additive) can be estimated as the mode of the distribution of local variances in the image and the coefficient of variation of noise (if multiplicative) can be estimated as the mode of the distribution of local estimates of the coefficient of variation. Additionally, a model for the sample variance distribution for an image plus noise is proposed and studied. Experiments show the goodness of the proposed method, specially in recursive or iterative filtering methods. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Aja-Fernandez, Santiago; Vegas-Sanchez-Ferrero, Gonzalo; Martin-Fernandez, Marcos; Alberola-Lopez, Carlos] Univ Valladolid, LPI, ETS Ingenieros Telecomunicac, E-47011 Valladolid, Spain.
C3 Universidad de Valladolid
RP Aja-Fernández, S (corresponding author), Univ Valladolid, LPI, ETS Ingenieros Telecomunicac, E-47011 Valladolid, Spain.
EM sanaja@tel.uva.es; gvegsan@lpi.tel.uva.es; marcma@tel.uva.es;
   caralb@tel.uva.es
RI Aja-Fernández, Santiago/L-2490-2017; Sanchez-Ferrero, Gonzalo
   Vegas/K-7556-2017; Aja-Fernandez, Santiago/HMP-5196-2023;
   Martin-Fernandez, Marcos/L-8366-2014; Vegas-Sanchez-Ferrero,
   Gonzalo/AAD-6387-2019; Alberola-Lopez, Carlos/M-1582-2014
OI Aja-Fernández, Santiago/0000-0002-5337-5071; Aja-Fernandez,
   Santiago/0000-0002-5337-5071; Martin-Fernandez,
   Marcos/0000-0001-9342-9989; Vegas-Sanchez-Ferrero,
   Gonzalo/0000-0002-3803-4324; Alberola-Lopez, Carlos/0000-0003-3684-0055
FU Comision Interministerial de Ciencia y Tecnologia [TEC2007-67073]; Fondo
   de Investigaciones Sanitarias [PI-041483]; Juna de Castilla y Leon
   [VA026A07, VA027A07, GRS 292/A/08]; European Commission [FP6-507609];
   MEC/Fulbright Commission [FU2005-0716]
FX The authors acknowledge the Comision Interministerial de Ciencia y
   Tecnologia for research Grant TEC2007-67073, the Fondo de
   Investigaciones Sanitarias for Grant PI-041483, Juna de Castilla y Leon
   for grants VA026A07, VA027A07, GRS 292/A/08 and the European Commission
   for the funds associated to the Network of Excellence SIMILAR
   (FP6-507609). The first author also acknowledges the MEC/Fulbright
   Commission for Grant FU2005-0716.
CR Abramowitz M., 1964, HDB MATH FUNCTIONS F
   Aja-Fernández S, 2006, IEEE T IMAGE PROCESS, V15, P2694, DOI 10.1109/TIP.2006.877360
   [Anonymous], 1991, SIMULATION MODELING
   [Anonymous], Probability, Random Variables and Stochastic Processes
   DONOHO DL, 1994, BIOMETRIKA, V81, P425, DOI 10.1093/biomet/81.3.425
   EVANS NWD, 2001, P EUR, P893
   Galatsanos NP, 1992, IEEE T IMAGE PROCESS, V1, P322, DOI 10.1109/83.148606
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   HIRSCH HG, 1995, P ICASSP, P153
   HURLIMANN W, 1995, STAT PROBABIL LETT, V24, P263, DOI 10.1016/0167-7152(94)00182-8
   KAUSMANN L, 1989, RADIOLOGY, V173, P265
   Kay S. M., 1993, FUNDAMENTALS STAT SI
   Konstantinides K, 1997, IEEE T IMAGE PROCESS, V6, P479, DOI 10.1109/83.557359
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   LEE JS, 1980, IEEE T PATTERN ANAL, V2, P165, DOI 10.1109/TPAMI.1980.4766994
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Martín-Fernández M, 2003, LECT NOTES COMPUT SC, V2809, P506
   *MCGILL U MONTR NE, BRAINWEB
   MEER P, 1990, IEEE T PATTERN ANAL, V12, P216, DOI 10.1109/34.44408
   Nowak RD, 1999, IEEE T IMAGE PROCESS, V8, P1408, DOI 10.1109/83.791966
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Salmeri M, 2001, IEEE IMAGE PROC, P517, DOI 10.1109/ICIP.2001.959067
   Shin DH, 2005, IEEE T CONSUM ELECTR, V51, P218, DOI 10.1109/TCE.2005.1405723
   Starck JL, 1998, PUBL ASTRON SOC PAC, V110, P193, DOI 10.1086/316124
   *U TEX, LIV DAT LAB IM VID E
   VENTER JH, 1967, ANN MATH STAT, V38, P1446, DOI 10.1214/aoms/1177698699
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yu YJ, 2004, IEEE T IMAGE PROCESS, V13, P1640, DOI 10.1109/TIP.2004.836166
NR 28
TC 75
Z9 89
U1 0
U2 24
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 756
EP 770
DI 10.1016/j.imavis.2008.08.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000015
DA 2024-07-18
ER

PT J
AU Singh, R
   Vatsa, M
   Noore, A
AF Singh, Richa
   Vatsa, Mayank
   Noore, Afzel
TI Face recognition with disguise and single gallery images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Face disguise; Log polar Gabor transform; Phase
   features
ID SPATIAL-FREQUENCY; PATTERNS; FEATURES; SPACE
AB This paper presents a face recognition algorithm that addresses two major challenges. The first is when an individual intentionally alters the appearance and features using disguises, and the second is when limited gallery images are available for recognition. The algorithm uses a dynamic neural network architecture to extract the phase features of the face texture using 2D log polar Gabor transform. The phase features are divided into frames which are matched using the Hamming distance. The performance of the proposed algorithm is evaluated using three databases that comprise of real and synthetic face images with different disguise artifacts. The performance of the algorithm is evaluated for decreasing number of gallery images and various types of disguises. In all cases the proposed algorithm shows a better performance compared to other existing algorithms. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Singh, Richa; Vatsa, Mayank; Noore, Afzel] W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
C3 West Virginia University
RP Noore, A (corresponding author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
EM richas@csee.wvu.edu; mayankv@csee.wvu.edu; noore@csee.wvu.edu
RI Vatsa, Mayank/AAR-7199-2020; Singh, Richa/M-9961-2017
OI Vatsa, Mayank/0000-0001-5952-2274; Singh, Richa/0000-0003-4060-4573
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 1973, THESIS KYOTO U
   Ayinde O, 2002, PATTERN RECOGN, V35, P1275, DOI 10.1016/S0031-3203(01)00120-0
   BIGUN J, 1994, IEEE T PATTERN ANAL, V16, P80, DOI 10.1109/34.273714
   Chen SC, 2004, PATTERN RECOGN LETT, V25, P1173, DOI 10.1016/j.patrec.2004.03.012
   Chen SC, 2004, PATTERN RECOGN, V37, P1553, DOI 10.1016/j.patcog.2003.12.010
   Cox IJ, 1996, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.1996.517076
   Daugman J.G., 1988, COMPUTATIONAL NEUROS, P403
   Daugman J.G., 1985, MODELS VISUAL CORTEX, P96
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAUGMAN JG, 1988, IEEE T ACOUST SPEECH, V36, P1169, DOI 10.1109/29.1644
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   HIROSE Y, 1991, NEURAL NETWORKS, V4, P61, DOI 10.1016/0893-6080(91)90032-Z
   *IEEE OTCBVS WS, DOEDEFG0286NE37968 I
   Kalocsai P, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P360, DOI 10.1109/AFGR.1998.670975
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Liu CJ, 2001, LECT NOTES COMPUT SC, V2091, P20
   Liu CJ, 2003, IEEE T NEURAL NETWOR, V14, P919, DOI 10.1109/TNN.2003.813829
   MacLennan B, 1994, CS91144 U TENN
   Martinez A., 1998, AR FACE DATABASE
   Palm C., 2002, Machine Graphics & Vision, V11, P195
   Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002
   Pun CM, 2003, COMPUT VIS IMAGE UND, V89, P24, DOI 10.1016/S1077-3142(03)00012-2
   Quintiliano P., 2003, Pattern Recognition and Image Analysis, V13, P335
   Ramanathan N, 2004, IEEE IMAGE PROC, P1999
   Rios A., 1992, P ARTIFICIAL NEURAL, P503
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Shen LL, 2006, PATTERN ANAL APPL, V9, P273, DOI 10.1007/s10044-006-0033-y
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Singh S.K., 2003, TAMKANG J SCI ENG, V6, P227
   Smeraldi F, 2002, PATTERN RECOGN LETT, V23, P463, DOI 10.1016/S0167-8655(01)00178-7
   TISTARELLI M, 1998, NATO ASI ADV STUDY F, V163, P262
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   VATSA M, 2003, P INT C COMP VIS PAT, P704
   Venkatesh S., 1989, P INT C IMAGE PROCES, P553
   WEBSTER MA, 1985, J OPT SOC AM A, V2, P1124, DOI 10.1364/JOSAA.2.001124
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Yu Y., 1990, P INT JOINT C NEURAL, V3, P167
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
NR 42
TC 56
Z9 60
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 2
PY 2009
VL 27
IS 3
SI SI
BP 245
EP 257
DI 10.1016/j.imavis.2007.06.010
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 393QA
UT WOS:000262386600004
DA 2024-07-18
ER

PT J
AU Adel, M
   Zuwala, D
   Rasigni, M
   Bourennane, S
AF Adel, Mouloud
   Zuwala, Daniel
   Rasigni, Monique
   Bourennane, Salah
TI Filtering noise on mammographic phantom images using local contrast
   modification functions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE contrast modification; noise reduction; mammography; breast phantom;
   quality control
ID HISTOGRAM EQUALIZATION; FEATURE ENHANCEMENT; DIGITAL MAMMOGRAPHY
AB This paper deals with filtering signal-dependent noise on digitized mammographic phantom images using a direct contrast modification method. First, a local contrast is computed for each pixel depending on the statistical properties of its neighbourhood. An optimal modification contrast function is then applied. This function is found by solving an optimisation problem using the mean squared error as a criterion. At last the enhanced pixel value is calculated using an inverse local contrast method. Simulated images containing objects similar to those observed in the phantom are built with different contrast and Signal to Noise Ratio (SNR) levels. Noise reduction results obtained are then compared to those of classical noise filtering methods. This comparison shows that the developed method gives better results. Evaluation was also done on real phantom images with the help of radiologists. Good results obtained lead us to consider the developed method as a good preprocessing step for quality control in mammographic facilities using image processing techniques. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Adel, Mouloud; Bourennane, Salah] Domaine Univ St Jerome, Equipe GSM, CNRS, Inst FRESNEL,UMR 6133, F-13397 Marseille 20, France.
   [Zuwala, Daniel; Rasigni, Monique] Domaine Univ St Jerome, Case ECI, F-13397 Marseille, France.
C3 Aix-Marseille Universite; Centre National de la Recherche Scientifique
   (CNRS); Aix-Marseille Universite
RP Adel, M (corresponding author), Domaine Univ St Jerome, Equipe GSM, CNRS, Inst FRESNEL,UMR 6133, F-13397 Marseille 20, France.
EM mouloud.adel@univ-cezanne.fr
RI ADEL, Mouloud/HTS-8390-2023; Bourennane, Salah/F-2928-2010
CR AGHADASI F, 1992, P 14 ANN INT C IEEE, P1877
   BARNES GT, 1982, RADIOLOGY, V145, P815, DOI 10.1148/radiology.145.3.7146416
   BEGHDADI A, 1989, COMPUT VISION GRAPH, V46, P162, DOI 10.1016/0734-189X(89)90166-7
   Chang DC, 1998, IEEE T MED IMAGING, V17, P518, DOI 10.1109/42.730397
   CHEN HG, 1994, IEEE T MED IMAGING, V13, P557, DOI 10.1109/42.310887
   Cheng HD, 2003, PATTERN RECOGN, V36, P2687, DOI 10.1016/S0031-3203(03)00054-2
   Cheng HD, 2002, INFORM SCIENCES, V148, P167, DOI 10.1016/S0020-0255(02)00293-1
   DASH L, 1991, PATTERN RECOGN, V24, P289, DOI 10.1016/0031-3203(91)90072-D
   DHAWAN AP, 1986, IEEE T MED IMAGING, V5, P8, DOI 10.1109/TMI.1986.4307733
   DHAWAN AP, 1988, COMPUT METH PROG BIO, V27, P23, DOI 10.1016/0169-2607(88)90100-9
   GORDON R, 1984, APPL OPTICS, V23, P560, DOI 10.1364/AO.23.000560
   Guis VH, 2003, OPT ENG, V42, P357, DOI 10.1117/1.1534846
   Jannetta A, 2004, PHYS MED BIOL, V49, P4997, DOI 10.1088/0031-9155/49/21/011
   Jung CR, 2004, J ELECTRON IMAGING, V13, P278, DOI 10.1117/1.1683247
   Kim JK, 1997, IEEE T MED IMAGING, V16, P495, DOI 10.1109/42.640739
   KUAN DT, 1985, IEEE T PATTERN ANAL, V7, P165, DOI 10.1109/TPAMI.1985.4767641
   LAI SM, 1989, IEEE T MED IMAGING, V8, P377, DOI 10.1109/42.41491
   LAINE A, 1995, IEEE ENG MED BIOL, V14, P536, DOI 10.1109/51.464770
   LAINE AF, 1994, IEEE T MED IMAGING, V13, P725, DOI 10.1109/42.363095
   Lure FYM, 1996, P SOC PHOTO-OPT INS, V2710, P830, DOI 10.1117/12.237989
   MARTENS JB, 1995, SIGNAL PROCESS, V44, P1, DOI 10.1016/0165-1684(95)00011-2
   Mayo P, 2004, P ANN INT IEEE EMBS, V26, P247
   MENCATTINI A, 2005, P IEEE INT C IM PROC, P1141
   MORROW WM, 1992, IEEE T MED IMAGING, V11, P392, DOI 10.1109/42.158944
   MUKHERJEE D, 1995, GRAPH MODEL IM PROC, V57, P254, DOI 10.1006/gmip.1995.1024
   PARANJAPE RB, 1992, CVGIP-GRAPH MODEL IM, V54, P259, DOI 10.1016/1049-9652(92)90056-4
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   QIAN W, 1994, IEEE T MED IMAGING, V13, P25, DOI 10.1109/42.276142
   Rangayyan R M, 1997, IEEE Trans Inf Technol Biomed, V1, P161, DOI 10.1109/4233.654859
   SIVARAMAKRISHNA R, 2000, AM J RADIOL, V175
   Sutton MA, 1998, P SOC PHOTO-OPT INS, V3240, P179, DOI 10.1117/12.300055
   TAHOCES PG, 1991, IEEE T MED IMAGING, V10, P330, DOI 10.1109/42.97582
   Webb Steve., 1988, The Physics of Medical Imaging
   Yezzi A, 1998, IEEE T IMAGE PROCESS, V7, P345, DOI 10.1109/83.661184
   Zhu H, 1999, COMPUT VIS IMAGE UND, V73, P281, DOI 10.1006/cviu.1998.0723
   ZUWALA D, 2004, P 7 INT WORKSH DIG M
NR 36
TC 5
Z9 5
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1219
EP 1229
DI 10.1016/j.imavis.2008.02.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300004
DA 2024-07-18
ER

PT J
AU Hermosilla, T
   Bermejo, E
   Balaguer, A
   Ruiz, LA
AF Hermosilla, T.
   Bermejo, E.
   Balaguer, A.
   Ruiz, L. A.
TI Non-linear fourth-order image interpolation for subpixel edge detection
   and localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image processing; subpixel edge detection; non-linear interpolation
ID SCHEMES
AB A fourth-order non-linear interpolation procedure based on the ENO (Essentially Non-Oscillatory) methodology is presented and evaluated, with the purpose of increasing the geometric accuracy of edge detection in digital images. Two possible cases are considered one that considers that each pixel of the image represents a point value, the other that the pixel is an average value of a function. After image interpolation to obtain a finer grid of pixels, the Canny edge detection algorithm is applied, with the objective of improving the localization and geometry of the edges at a subpixel level. The results are compared with other schemes based on fourth order two-dimensional interpolation methods, such as a centered scheme based on a cubic convolution, a fourth order non-centered lineal scheme and a centered cubic convolution based on local gradient features. The evaluation is performed using visual and analytical techniques applied over aerial and satellite images, analyzing the positional errors of the detected edges, as well as the errors due to changes in scale and orientation. In addition to the subpixel edge detection, the quality of the interpolated images is tested. We conclude that the proposed methodology based on ENO interpolation improves the detection of edges in images as compared to other fourth-order methods. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Hermosilla, T.; Bermejo, E.; Ruiz, L. A.] Univ Politecn Valencia, Dept Cartog Engn Geodesy & Photogrammetry, Valencia 46022, Spain.
   [Balaguer, A.] Univ Politecn Valencia, Dept Appl Math, Valencia 46022, Spain.
C3 Universitat Politecnica de Valencia; Universitat Politecnica de Valencia
RP Hermosilla, T (corresponding author), Univ Politecn Valencia, Dept Cartog Engn Geodesy & Photogrammetry, Camino Vera S-N, Valencia 46022, Spain.
EM txohergo@topo.upv.es
RI Ruiz, Luis A./E-8162-2016; Balaguer-Beser, Angel/L-9208-2014;
   Hermosilla, Txomin/K-6206-2014
OI Ruiz, Luis A./0000-0003-0073-7259; Balaguer-Beser,
   Angel/0000-0003-0039-2641; Hermosilla, Txomin/0000-0002-5445-0360
CR Aràndiga F, 2003, SIGNAL PROCESS, V83, P459, DOI 10.1016/S0165-1684(02)00445-0
   Balaguer A, 2005, SIAM J NUMER ANAL, V43, P455, DOI 10.1137/S0036142903437106
   Balaguer A, 2001, INT J NUMER METH ENG, V50, P2339, DOI 10.1002/nme.123
   BINFORD TO, 1981, P SOC PHOTOOPTICAL I, V281, P211
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carey WK, 1999, IEEE T IMAGE PROCESS, V8, P1293, DOI 10.1109/83.784441
   Cha YJ, 2006, IEEE T IMAGE PROCESS, V15, P2315, DOI 10.1109/TIP.2006.875182
   Chan TF, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P391, DOI 10.1109/ICIP.2000.899404
   Devernay F., 1995, A Non-Maxima Suppression Method for Edge Detection with Sub-Pixel Accuracy, P1
   GHOSAL S, 1993, PATTERN RECOGN, V26, P295, DOI 10.1016/0031-3203(93)90038-X
   HARTEN A, 1987, J COMPUT PHYS, V71, P231, DOI [10.1016/0021-9991(87)90031-3, 10.1006/jcph.1996.5632]
   HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838
   Hwang JW, 2004, IEEE SIGNAL PROC LET, V11, P359, DOI 10.1109/LSP.2003.821718
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   JI Q, 2000, J PATTERN RECOGNITIO, V35, P689
   Kubota T, 2001, LECT NOTES COMPUT SC, V2134, P328
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   LYVERS EP, 1989, IEEE T PATTERN ANAL, V11, P1293, DOI 10.1109/34.41367
   MOIK JG, 1980, 432 NASA, P330
   OVERINGTON I, 1987, IMAGE VISION COMPUT, V5, P217, DOI 10.1016/0262-8856(87)90052-7
   Qu YD, 2005, IMAGE VISION COMPUT, V23, P11, DOI 10.1016/j.imavis.2004.07.003
   Rocket P., 1999, P BRIT MACH VIS C, P392
   SHU CW, 1988, J COMPUT PHYS, V77, P439, DOI 10.1016/0021-9991(88)90177-5
   Siddiqi K, 1997, GRAPH MODEL IM PROC, V59, P278, DOI 10.1006/gmip.1997.0438
   Staunton RC, 2005, PATTERN RECOGN LETT, V26, P1609, DOI 10.1016/j.patrec.2005.01.007
   Su D, 2004, COMPUT GRAPH FORUM, V23, P189, DOI 10.1111/j.1467-8659.2004.00752.x
   TABATABAI AJ, 1984, IEEE T PATTERN ANAL, V6, P188, DOI 10.1109/TPAMI.1984.4767502
   Xie SH, 2005, KEY ENG MAT, V295-296, P711, DOI 10.4028/www.scientific.net/KEM.295-296.711
   Ye J, 2005, IMAGE VISION COMPUT, V23, P453, DOI 10.1016/j.imavis.2004.07.007
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 30
TC 60
Z9 82
U1 3
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1240
EP 1248
DI 10.1016/j.imavis.2008.02.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300006
DA 2024-07-18
ER

PT J
AU Zhang, XL
   Lam, KM
   Shen, L
AF Zhang, Xiaoling
   Lam, Kin-Man
   Shen, Lansun
TI Image magnification based on a blockwise adaptive Markov random field
   model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image magnification; MAP estimation; Markov random field; iterated
   function systems
ID MRF PARAMETER-ESTIMATION; SUPERRESOLUTION; INTERPOLATION
AB In this paper, an effective image magnification algorithm based on an adaptive Markov random field (MRF) model with a Bayesian framework is proposed. A low-resolution (LR) image is first magnified to form a high-resolution (HR) image using a fractal-based method, namely the multiple partitioned iterated function system (MPIFS). The quality of this magnified HR image is then improved by means of a block-wise adaptive MRF model using the Bayesian 'maximum a posteriori' (MAP) approach. We propose an efficient parameter estimation method for the MRF model such that the staircase artifact will be reduced in the HR image. Experimental results show that, when compared to the conventional MRF model, which uses a fixed set of parameters for a whole image, our algorithm can provide a magnified image with the well-preserved edges and texture, and can achieve a better PSNR and visual quality. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Zhang, Xiaoling; Lam, Kin-Man] Hong Kong Polytech Univ, Elect & Informat Engn Dept, Ctr Signal Proc, Hong Kong, Hong Kong, Peoples R China.
   [Zhang, Xiaoling; Shen, Lansun] Beijing Univ Technol, Signal & Informat Proc Lab, Beijing, Peoples R China.
   [Zhang, Xiaoling] Xiamen Univ, Dept Commun Engn, Xiamen, Fujian, Peoples R China.
C3 Hong Kong Polytechnic University; Beijing University of Technology;
   Xiamen University
RP Lam, KM (corresponding author), Hong Kong Polytech Univ, Elect & Informat Engn Dept, Ctr Signal Proc, Hong Kong, Hong Kong, Peoples R China.
EM zxl1@xmu.edu.cn; enkmlam@eie.polyu.edu.hk
RI Kan, Kin-Man/A-9352-2014; cai, bo/G-1491-2010; Zhang,
   Xiaoling/J-1666-2016
OI Kan, Kin-Man/0000-0002-0422-8454; 
CR BARSLEY M, 1988, FRACTAL EVERYWHERE
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   Borman S., 1998, P 1998 MIDW S CIRC S, P5
   Carey WK, 1999, IEEE T IMAGE PROCESS, V8, P1293, DOI 10.1109/83.784441
   Chaudhuri S., 2001, SUPER RESOLUTION IMA
   Chung KH, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL VI, PROCEEDINGS, P273
   Fisher Y., 1995, Fractal Image Compression: Theory and Application
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Joshi MV, 2005, IEEE T SYST MAN CY B, V35, P527, DOI 10.1109/TSMCB.2005.846647
   Kato Z., 1994, THESIS
   Lai CM, 2004, PROCEEDINGS OF THE 2004 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P571, DOI 10.1109/ISIMP.2004.1434128
   Li S.Z., 1995, MRF MODELING COMPUTE
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Mitra SK, 2000, PATTERN RECOGN, V33, P1119, DOI 10.1016/S0031-3203(99)00108-9
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Pratt W.K., 1977, DIGITAL IMAGE PROCES
   REUSENS E, 1994, P IEEE INT C AC SPEE, P357
   Saquib SS, 1998, IEEE T IMAGE PROCESS, V7, P1029, DOI 10.1109/83.701163
   SAUPE D, 1995, P DAT COMPR C MARCH
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   Wang L, 2000, PATTERN RECOGN, V33, P1919, DOI 10.1016/S0031-3203(99)00178-8
   Yu YH, 2003, PATTERN RECOGN LETT, V24, P1251, DOI 10.1016/S0167-8655(02)00319-7
   Zhang L, 2006, IEEE T IMAGE PROCESS, V15, P2226, DOI 10.1109/TIP.2006.877407
NR 26
TC 13
Z9 17
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1277
EP 1284
DI 10.1016/j.imavis.2008.03.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300010
DA 2024-07-18
ER

PT J
AU Prakoonwit, S
   Benjamin, R
AF Prakoonwit, Simant
   Benjamin, Ralph
TI 3D surface point and wireframe reconstruction from multiview
   photographic images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D reconstruction; apparent contour; contour generator; epipolar;
   multiview; space curve; surface point; wireframe
ID PROFILES; OBJECTS
AB This paper describes a new method for reconstructing 3D surface points and a wireframe on the surface of a freeform object using a small number, e.g. 10, of 2D photographic images. The images are taken at different viewing directions by a perspective camera with full prior knowledge of the camera configurations. The reconstructed surface points are frontier points and the wireframe is a network of contour generators. Both of them are reconstructed by pairing apparent contours in the 2D images. Unlike previous works, we empirically demonstrate that if the viewing directions are uniformly distributed around the object's viewing sphere, then the reconstructed 3D points automatically cluster closely on a highly curved part of the surface and are widely spread on smooth or flat parts. The advantage of this property is that the reconstructed points along a surface or a contour generator are not under-sampled or under-represented because surfaces or contours should be sampled or represented with more densely points where their curvatures are high. The more complex the contour's shape, the greater is the number of points required, but the greater the number of points is automatically generated by the proposed method. Given that the viewing directions are uniformly distributed, the number and distribution of the reconstructed points depend on the shape or the curvature of the surface regardless of the size of the surface or the size of the object. The unique pattern of the reconstructed points and contours may be used in 31) object recognition and measurement without computationally intensive full surface reconstruction. The results are obtained from both computer-generated and real objects. (C) 2007 Elsevier B.V. All rights reserved.
C1 Univ Reading, Sch Syst Engn, Reading RG6 6AY, Berks, England.
C3 University of Reading
RP Prakoonwit, S (corresponding author), Univ Reading, Sch Syst Engn, Reading RG6 6AY, Berks, England.
EM S.Prakoonwit@reading.ac.uk
CR BEARDSLEY P, 1996, EUR C COMP VIS, P683
   Benjamin R, 1996, MED BIOL ENG COMPUT, V34, P423, DOI 10.1007/BF02523845
   BENNAMOUN M, 2002, OBJECT RECOGNITION F, P261
   Bhattacharya P, 2003, PATTERN RECOGN LETT, V24, P2509, DOI 10.1016/S0167-8655(03)00096-5
   Boyer E., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P109
   BRAND M, 2004, CVPR, P30
   CIPOLLA R, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P269, DOI 10.1109/ICCV.1995.466775
   CIPOLLA R, 1992, INT J COMPUT VISION, V9, P83, DOI 10.1007/BF00129682
   CIPOLLA R, 2000, VISUAL MOTION CURVES, P79
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Eisert P, 2000, IEEE T CIRC SYST VID, V10, P261, DOI 10.1109/76.825726
   FITZGIBBON AW, 1998, ECCV 98 WORKSH 3D ST, P154
   Franco J.S., 2003, P 14 BRIT MACHINE VI, P329, DOI [10.5244/C.17.32, DOI 10.5244/C.17.32]
   FURUKAWA Y, 2004, ROBUST STRUCTURE MOT, P1
   Giblin P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P136
   GIBLIN P, 1994, 3RD P EUR C COMP VIS, P14
   Joshi T, 1997, IMAGE VISION COMPUT, V15, P479, DOI 10.1016/S0262-8856(97)00001-2
   KOCH R, 1998, EUR C COMP VIS, P55
   KUTULAKOS KN, 1995, ARTIF INTELL, V78, P147, DOI 10.1016/0004-3702(95)00027-5
   LEE ETY, 1989, COMPUT AIDED DESIGN, V21, P363, DOI 10.1016/0010-4485(89)90003-1
   Marte M, 1998, OPT EXPRESS, V3, P71, DOI 10.1364/OE.3.000071
   MARTIN WN, 1983, IEEE T PATTERN ANAL, V5, P150, DOI 10.1109/TPAMI.1983.4767367
   MATALAS I, 1996, SEGMENTATION TECHNIQ, P321
   MELNYK TW, 1977, CAN J CHEM, V55, P1745, DOI 10.1139/v77-246
   Mendonça PRS, 2001, IEEE T PATTERN ANAL, V23, P604, DOI 10.1109/34.927461
   Niem W, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P173, DOI 10.1109/IM.1997.603863
   POLLEFEYS M, 1998, 10 IMDSP WORKSH 1998, P195
   PRAKOONWIT S, 1996, RECONSTRUCTION MANIP, P301
   PRESS WH, 1989, NUMERICAL RECIPES AR, P1020
   RIEGER JH, 1986, OPT LETT, V11, P123, DOI 10.1364/OL.11.000123
   Saff EB, 1997, MATH INTELL, V19, P5, DOI 10.1007/BF03024331
   Sato J, 1999, IEEE T PATTERN ANAL, V21, P1188, DOI 10.1109/34.809111
   Sethi A, 2004, INT J COMPUT VISION, V58, P73, DOI 10.1023/B:VISI.0000016148.08046.fc
   SHU C, 2003, NRCERB1101, P1
   SULLIVAN S, 1998, ICCV JAN, P90
   SZELISKI R, 1993, CVGIP-IMAG UNDERSTAN, V58, P23, DOI 10.1006/ciun.1993.1029
   VAILLANT R, 1992, IEEE T PATTERN ANAL, V14, P157, DOI 10.1109/34.121787
   VEMURI BC, 1986, C COMP VIS PATT REC, P435
   Wong KYK, 2004, IEEE T IMAGE PROCESS, V13, P379, DOI 10.1109/TIP.2003.821113
   Zhao CS, 1996, COMPUT VIS IMAGE UND, V64, P62, DOI 10.1006/cviu.1996.0046
NR 40
TC 18
Z9 19
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1509
EP 1518
DI 10.1016/j.imavis.2006.12.019
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000011
OA Bronze
DA 2024-07-18
ER

PT J
AU Liu, ZY
   Sarkar, S
AF Liu, Zongyi
   Sarkar, Sudeep
TI Outdoor recognition at a distance by fusing gait and face
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE gait recognition; face recognition; biometrics fusion
AB We explore the possibility of using both face and gait in enhancing human recognition at a distance performance in outdoor conditions. Although the individual performance of gait and face based biometrics at a distance under outdoor illumination conditions, walking surface changes, and time variations are poor, we show that recognition performance is significantly enhanced by combination of face and gait. For gait, we present a new recognition scheme that relies on computing distances based on selected, discriminatory, gait stances. Given a gait sequence, covering multiple gait cycles, it identifies the salient stances using a population hidden Markov model (HMM). An averaged representation of the detected silhouettes for these stances are then built using eigenstance shape models. Similarity between two gait sequences is based on the similarities of these averaged representations of the salient stances. This gait recognition strategy, which essentially emphasizes shape over dynamics, significantly outperforms the HumanID Gait Challenge baseline algorithm. For face, which is a mature biometric for which many recognition algorithms exists, we chose the elastic bunch graph matching based face recognition method. This method was found to be the best in the FERET 2000 studies. On a gallery database of 70 individuals and two probe sets: one with 39 individuals taken on the same day and the other with 21 individuals taken at least 3 months apart, results indicate that although the verification rate at 1%, false alarm rate of individual biometrics are low, their combination performs better. Specifically, for data taken on the same day, individual verification rates are 42% and 40% for face and gait, respectively, but is 73% for their combination. Similarly, for the data taken with at least 3 months apart, the verification rates are 48% and 25% for face and gait, respectively, but is 60% for their combination. We also find that the combination of outdoor gait and one outdoor face per person is superior to using two outdoor face probes per person or using two gait probes per person, which can considered to be statistical controls for showing improvement by biometric fusion. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ S Florida, Tampa, FL 33647 USA.
C3 State University System of Florida; University of South Florida
RP Liu, ZY (corresponding author), Univ S Florida, Tampa, FL 33647 USA.
EM zliu4@csee.usf.edu; sarkar@csee.usf.edu
RI Sarkar, Sudeep/A-8213-2009; Sarkar, Sudeep/ABD-7629-2021
OI Sarkar, Sudeep/0000-0001-7332-4207; Sarkar, Sudeep/0000-0001-7332-4207
CR ACHERMANN B, 1996, INT C PATT REC
   [Anonymous], 1993, FUNDAMENTAL SPEECH R
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P267, DOI 10.1109/AFGR.2002.1004165
   BOBICK A, 2001, COMPUTER VISION PATT, P1
   BOLME DS, 2003, THESIS COLORADO STAT
   Chang K, 2003, IEEE T PATTERN ANAL, V25, P1160, DOI 10.1109/TPAMI.2003.1227990
   Chang K., 2003, IEEE INT WORKSH AN M
   CHANG KI, 2003, WORKSH MULT US AUTH, P25
   CHANG KI, 2004, 6 IEEE INT C AUT FAC
   Chen X., 2003, P ACM WORKSHOP MULTI, P48
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   CUNTOOR N, 2003, IEEE INT C AC SPEECH
   Dieckmann U, 1997, PATTERN RECOGN LETT, V18, P827, DOI 10.1016/S0167-8655(97)00063-9
   HAYFRONACQUAH J, 2001, 3 INT C AUD VID BAS, P272
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295, DOI 10.1109/34.735803
   HONG L, 1999, IEEE WORKSH AUT ID A, P59
   Jain A.K., 1999, 2 INT C AUDIO VISUAL, P182
   Jain AK, 1999, PATTERN RECOGN LETT, V20, P1371, DOI 10.1016/S0167-8655(99)00108-7
   Kale A, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P336, DOI 10.1109/AFGR.2002.1004176
   KALE A, 2002, INT C AC SPEECH SIGN
   KALE A, 2004, INT C AC SPEECH SIGN
   Kittler Josef., 1998, IEEE Transactions on Pattern Analysis and Machine Intelligence, V20
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   LEE L, 2003, INT C COMP VIS
   LITTLE J, 1998, RECOGNIZING PEOPLE T, V1, P1
   LIU Z, 2004, COMPUTER VISION PATT, V2, P704
   LIU Z, 2004, SPIE PROC DEF SEC S
   Liu ZY, 2005, IEEE T SYST MAN CY B, V35, P170, DOI 10.1109/TSMCB.2004.842251
   Lu XG, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P13
   MELNIK O, 2003, MIXED GROUP RANKS PR
   NIYOGI S, 1994, ANAL GAIT SPATIOTEMP
   Phillips P. J., 2002, FACE RECOGNITION VEN
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 2002, INT C PATT RECOG, P385, DOI 10.1109/ICPR.2002.1044731
   Phillips PJ, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P137, DOI 10.1109/AFGR.2002.1004145
   Prabhakar S, 2002, PATTERN RECOGN, V35, P861, DOI 10.1016/S0031-3203(01)00103-0
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   SCHIELE B, 2002, INT C PATT REC, P2
   SHAKHNAROVICH G, 2002, P 5 IEEE INT C AUT F
   SHAKHNAROVICH G, 2001, COMPUTER VISION PATT
   Shutler J. D., 2000, 4th IEEE Southwest Symposium on Image Analysis and Interpretation, P291, DOI 10.1109/IAI.2000.839618
   Sundaresan A., 2003, IEEE INT C IM PROC
   TANAWONGSUWAN R, 2001, COMPUTER VISION PATT, P11
   Tax DMJ, 2000, PATTERN RECOGN, V33, P1475, DOI 10.1016/S0031-3203(99)00138-7
   TOLLIVER D, 2003, 3 INT C AUD VID BAS
   VEERARAGHAVAN A, 2004, COMPUTER VISION PATT
   VEGA IR, IN PRESS IEEE T PATT
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang L, 2002, INT C PATT RECOG, P115, DOI 10.1109/ICPR.2002.1044626
   Wang YH, 2003, LECT NOTES COMPUT SC, V2688, P805
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Woods K, 1997, IEEE T PATTERN ANAL, V19, P405, DOI 10.1109/34.588027
   Zhou J, 2002, INT C PATT RECOG, P497, DOI 10.1109/ICPR.2002.1047985
   ZUEV YA, 1996, P FDN INF DEC FUS AP, P206
NR 54
TC 40
Z9 50
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 817
EP 832
DI 10.1016/j.imavis.2006.05.022
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600005
OA Green Published
DA 2024-07-18
ER

PT J
AU Dupuis, A
   Vasseur, P
AF Dupuis, Arnaud
   Vasseur, Pascal
TI Image segmentation by cue selection and integration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image partitioning; affinity matrices; cue selection; integration; PCA
ID ORGANIZATION
AB In many recent works, image segmentation has been cast to a graph partitioning problem in which an affinity matrix represents the pairwise similarity of the nodes (pixels). In this paper, we develop an approach for the computation of the affinity matrix based on the combination of affinity matrices from various cues and its integration in the segmentation process. A principal components analysis (PCA) applied to the whole set of the normalized affinity matrices provides the uncorrelated relevant cues and their respective weights for the final combination. We then propose to integrate the evaluation of the affinity matrix at each iteration of an agglomerative algorithm in order to take into account the dynamics of the segmentation process. We finally define a criterion of satisfaction based on the variance-covariance matrix of the affinity matrices, which determines the end of the iterations. Experiments on a range of various images provide significant results. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Picardie, UPJV, CREA, F-80000 Amiens, France.
C3 Universite de Picardie Jules Verne (UPJV)
RP Vasseur, P (corresponding author), Univ Picardie, UPJV, CREA, EA3299,7 Rue Moulin Neuf, F-80000 Amiens, France.
EM pascal.vasseur@sc.u-picardie.fr
CR [Anonymous], 1998, MED IMAGE ANAL
   Batlle J, 2000, IMAGE VISION COMPUT, V18, P515, DOI 10.1016/S0262-8856(99)00040-2
   Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Borra S, 1997, IEEE T PATTERN ANAL, V19, P1306, DOI 10.1109/34.632991
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   CATTELL R, 1966, MULTIVARIATE BEHAV R, P1
   DELBIMBO A, 1999, VISUAL INFORMATION R
   Gdalyahu Y, 2001, IEEE T PATTERN ANAL, V23, P1053, DOI 10.1109/34.954598
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin D., 2002, THESIS UC BERKELEY
   MEILA M, 2001, NEURAL INFORMATION P
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Sarkar S, 2000, IEEE T PATTERN ANAL, V22, P504, DOI 10.1109/34.857006
   Sarkar S, 1998, COMPUT VIS IMAGE UND, V71, P110, DOI 10.1006/cviu.1997.0637
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Soundararajan P, 2003, IEEE T PATTERN ANAL, V25, P642, DOI 10.1109/TPAMI.2003.1201817
   SUN Z, 2003, CVPR03, P1
   Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239
   VEKSLER O, 2000, CVPR00, P1
   Wolf L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P378
   WU Z, 1993, IEEE T PATTERN ANAL, V15, P1101, DOI 10.1109/34.244673
NR 25
TC 9
Z9 10
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1053
EP 1064
DI 10.1016/j.imavis.2006.02.027
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300002
DA 2024-07-18
ER

PT J
AU Gökberk, B
   Irfanoglu, MO
   Akarun, L
AF Gokberk, Berk
   Irfanoglu, M. Okan
   Akarun, Lale
TI 3D shape-based face representation and feature extraction for face
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face recognition; face registration; 3D surface descriptors
AB In this paper, we review and compare 3D face registration and recognition algorithms, which are based solely on 31) shape information and analyze methods based on the fusion of shape features. We have analyzed two different registration algorithms, which produce a dense correspondence between faces. The first algorithm non-linearly warps faces to obtain registration, while the second algorithm allows only rigid transformations. Registration is handled with the use of an average face model, which significantly fastens the registration process. As 3D facial features, we compare the use of 31) point coordinates, surface normals, curvature-based descriptors, 2D depth images, and facial profile curves. Except for surface normals, these feature descriptors are frequently used in state-of-the-art 3D face recognizers. We also perform an in-depth analysis of decision-level fusion techniques such as fixed-rules, voting schemes, rank-based combination rules, and novel serial fusion architectures. The results of the recognition and authentication experiments conducted on the 3D_RMA database indicate that: (i) in terms of face registration method, registration of faces without warping preserves more discriminatory information, (ii) in terms of 31) facial features, surface normals attain the best recognition performance, and (iii) fusion schemes such as product rules, improved consensus voting and proposed serial fusion schemes improve the classification accuracy. Experimental results on the 3D_RMA confirm these findings by obtaining %0.1 misclassification rate in recognition experiments, and %8.06 equal error rate in authentication experiments using surface normal-based features. It is also possible to improve the classification accuracy by %2.38 using fixed fusion rules when moderate-level classifiers are used. (c) 2006 Elsevier B.V. All rights reserved.
C1 Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.
C3 Bogazici University
RP Gökberk, B (corresponding author), Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.
EM gokberk@boun.edu.tr; irfanogl@boun.edu.tr; akarun@boun.edu.tr
RI Gokberk, Berk/G-4017-2012; Akarun, Lale/AAR-7734-2020
OI Akarun, Lale/0000-0002-8813-8084; Gokberk, Berk/0000-0001-6299-1610
CR BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9
   Beumier C, 2001, PATTERN RECOGN LETT, V22, P1321, DOI 10.1016/S0167-8655(01)00077-0
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Bronstein AM, 2005, INT J COMPUT VISION, V64, P5, DOI 10.1007/s11263-005-1085-y
   Bronstein AM, 2004, LECT NOTES COMPUT SC, V3022, P225
   Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62
   Chang KI, 2005, IEEE T PATTERN ANAL, V27, P619, DOI 10.1109/TPAMI.2005.70
   Chin-Seng Chua, 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P233, DOI 10.1109/AFGR.2000.840640
   GOKBERK B, 2005, LNCS, V3456, P1019
   GORDON G, 1992, P IEEE COMP SOC C CO, P108
   Hesher C, 2003, SEVENTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOL 2, PROCEEDINGS, P201, DOI 10.1109/ISSPA.2003.1224850
   Irfanoglu MO, 2004, INT C PATT RECOG, P183, DOI 10.1109/ICPR.2004.1333734
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   Kuncheva L. I., 2004, COMBINING PATTERN CL, V390, P413
   LEE Y, 2003, P 16 INT C VIS INT
   Lu X, 2005, 5th International Workshop on Microprocessor Test and Verification: Common Challenges and Solutions, Proceedings, P97
   Lu XG, 2004, INT C PATT RECOG, P362, DOI 10.1109/ICPR.2004.1334127
   Malassiotis S, 2004, IEEE IMAGE PROC, P91
   Medioni G, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P232
   MORENO AB, 2003, P IR MACH VIS IM PRO
   Pan G, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P193
   Pan G, 2005, INT J IMAGE GRAPH, V5, P573, DOI 10.1142/S0219467805001884
   Papatheodorou T, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P321, DOI 10.1109/AFGR.2004.1301551
   SRIVASTAVA A, UNPUB J IMAGE VISION
   Tanaka HT, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P372, DOI 10.1109/AFGR.1998.670977
   Tsalakanidou F, 2003, PATTERN RECOGN LETT, V24, P1427, DOI 10.1016/S0167-8655(02)00383-5
   Tsutsumi S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P306, DOI 10.1109/AFGR.1998.670966
   Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1
   Wu ZH, 2004, IEEE IMAGE PROC, P2003
   XU C, 2004, P AS C COMP VIS, V2, P884
   Xu CH, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P308
NR 35
TC 63
Z9 67
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 857
EP 869
DI 10.1016/j.imavis.2006.02.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100007
DA 2024-07-18
ER

PT J
AU Lu, SJ
   Chen, BM
   Ko, CC
AF Lu, Shijian
   Chen, Ben M.
   Ko, C. C.
TI A partition approach for the restoration of camera images of planar and
   curled document
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE document image analysis; document image rectification; optical character
   recognition; morphological image processing; fuzzy sets
ID SKEW DETECTION; ALGORITHM
AB As camera resolution increases, high-speed non-contact text capture through a digital camera is opening up a new channel for text capture and understanding. Unfortunately, the captured document images are normally coupled with the perspective and geometric distortions that cannot be handled by the existing optical character recognition (OCR) systems. In this paper, we propose a new technique, which is capable of removing the perspective and geometric distortions, and reconstructing the fronto-parallel view of text with a single document image. Different from reported approaches in the literature, the restoration of the distorted camera documents is carried out through the image partition, which divides the documents into multiple small image patches where text can be approximated to lie on a planar surface. The global distortion is thus corrected through the local rectification of the partitioned image patches one by one. Experimental results show that the proposed method is fast and easy for implementation. (c) 2006 Elsevier B.V. All rights reserved.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
C3 National University of Singapore
RP Chen, BM (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
EM bmchen@nus.edu.sg
RI Lu, Shijian/AAU-4831-2021; Chen, Ben M./L-8791-2019
OI Lu, Shijian/0000-0002-6766-2506; Chen, Ben M./0000-0002-3839-5787
CR Ali MBH, 1997, PROC INT CONF DOC, P671, DOI 10.1109/ICDAR.1997.620591
   Brown M.S., 2001, IEEE C COMP VIS VANC, P117
   Cao HG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P228, DOI 10.1109/ICCV.2003.1238346
   Clark P, 2003, PATTERN RECOGN, V36, P2673, DOI 10.1016/S0031-3203(03)00132-8
   Dance C. R., 2001, Proceedings of the SPIE - The International Society for Optical Engineering, V4670, P244, DOI 10.1117/12.450733
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hearn D., 1994, Computer Graphics
   Kavallieratou E, 2002, IMAGE VISION COMPUT, V20, P813, DOI 10.1016/S0262-8856(02)00091-4
   Kawarago Y.A., 2004, IEEE C PATT REC, P23
   Kwag HK, 2002, IMAGE VISION COMPUT, V20, P25, DOI 10.1016/S0262-8856(01)00071-3
   Liang J, 2005, PROC CVPR IEEE, P338
   Lu SJ, 2005, IMAGE VISION COMPUT, V23, P541, DOI 10.1016/j.imavis.2005.01.003
   MYERS G, 2001, 4 S DOC IM UND TECHN, P85
   Niblack W., 1986, INTRO DIGITAL IMAGE, P115
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   Okun O., 1999, International Journal on Document Analysis and Recognition, V2, P132, DOI 10.1007/s100320050043
   Pal U., 2002, 3 IND C COMP VIS GRA, P270
   Pilu M, 2001, PROC CVPR IEEE, P67
   Pilu M, 2001, PROC CVPR IEEE, P363
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P312, DOI 10.1109/34.368197
   Tsoi YC, 2004, PROC CVPR IEEE, P240
   Yin PY, 2001, IMAGE VISION COMPUT, V19, P567, DOI 10.1016/S0262-8856(00)00098-6
   Yu B, 1996, PATTERN RECOGN, V29, P1599, DOI 10.1016/0031-3203(96)00020-9
   Zadeh L.A., 1975, CALCULUS FUZZY RESTR
   ZHANG Z, 2003, IEEE C DOC AN REC ED, P3
   ZIMMERMANN HJ, 1980, FUZZY SET SYST, V4, P37, DOI 10.1016/0165-0114(80)90062-7
NR 27
TC 20
Z9 22
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 837
EP 848
DI 10.1016/j.imavis.2006.02.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100005
DA 2024-07-18
ER

PT J
AU Tan, HC
   Zhang, YJ
AF Tan, Huachun
   Zhang, Yu-Jin
TI A novel weighted Hausdorff distance for face localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hausdorff distance; face localization; weighting function
ID RECOGNITION
AB In this paper, a new weighted Hausdorff distance measure is proposed for face localization. The weighting function in the new Hausdorff distance measure has large values at important locations, in which the values are proportional to the frequency of edge points appearing. Thus, the weighting function can reflect the common properties of face edge maps effectively. When comparing the edge maps of the face model and that of a candidate face region in face localization, the weighted Hausdorff distance incorporates information about the location of important edge points so that the face can be localized more accurately. Experimental results show the new weighted Hausdorff distance measure achieves accurate face localization. (c) 2005 Elsevier B.V. All rights reserved.
C1 Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
C3 Tsinghua University
RP Tan, HC (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
EM tanhc00@mails.tsinghua.edu.cn; zhang-yj@mail.tsinghua.edu.cn
CR BIEDERMAN I, 1988, COGNITIVE PSYCHOL, V20, P38, DOI 10.1016/0010-0285(88)90024-2
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Gao Y, 2003, IEE P-VIS IMAGE SIGN, V150, P346, DOI 10.1049/ip-vis:20030805
   Gao YS, 2002, PATTERN RECOGN, V35, P361, DOI 10.1016/S0031-3203(01)00049-8
   Han I, 2004, J VIS COMMUN IMAGE R, V15, P27, DOI 10.1016/j.jvcir.2003.06.003
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   KIREBHERG KJ, 2002, P INT ECCV 2002 WORK, P103
   Lin KH, 2003, PATTERN RECOGN, V36, P1827, DOI 10.1016/S0031-3203(03)00011-6
   Lin KH, 2001, PROCEEDINGS OF 2001 INTERNATIONAL SYMPOSIUM ON INTELLIGENT MULTIMEDIA, VIDEO AND SPEECH PROCESSING, P477, DOI 10.1109/ISIMP.2001.925437
   Rucklidge W., 1996, Lecture Notes in Computer Science, V1173
   Sim DG, 1999, IEEE T IMAGE PROCESS, V8, P425, DOI 10.1109/83.748897
   Takacs B, 1998, PATTERN RECOGN, V31, P1873, DOI 10.1016/S0031-3203(98)00076-4
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhao CJ, 2005, PATTERN RECOGN LETT, V26, P581, DOI 10.1016/j.patrec.2004.09.022
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhu ZF, 2004, PATTERN RECOGN LETT, V25, P515, DOI 10.1016/j.patrec.2003.12.014
NR 17
TC 9
Z9 9
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 656
EP 662
DI 10.1016/j.imavis.2005.05.011
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400002
DA 2024-07-18
ER

PT J
AU Zhang, RF
   Zhang, ZF
AF Zhang, RF
   Zhang, ZF
TI BALAS: Empirical Bayesian learning in the relevance feedback for image
   retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CBIR; relevance feedback; Bayesian learning; relevancy confidence;
   session semantic distance
AB This paper is on user relevance for image retrieval. We take this problem as a standard two-class pattern classification problem aiming at refining the retrieval precision by learning through the user relevance feedback data. However, we have investigated the problem by noting two important unique characteristics of the problem: small sample collection and asymmetric sample distributions between positive and negative samples. We have developed a novel approach to empirical Bayesian learning to solve for this problem by explicitly exploiting the two unique characteristics, which is the methodology of Bayesian Learning in Asymmetric and Small sample collections. thus called BALAS. In BALAS different learning strategies are used for positive and negative sample collections, respectively, based on the two unique characteristics. By defining the relevancy confidence as the relevant posterior probability, we have developed an integrated ranking scheme in BALAS, which complernentarily combines the subjective relevancy confidence and the objective similarity measure to capture the overall retrieval semantics. The experimental evaluations have confirmed the rationale of the proposed ranking scheme, and have also demonstrated that BALAS is superior to an existing relevance feedback method in the current literature in capturing the overall retrieval semantics. (c) 2005 Elsevier B.V. All rights reserved.
C1 SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13902 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Binghamton
RP SUNY Binghamton, Dept Comp Sci, Binghamton, NY 13902 USA.
EM rzhang@cs.binghamton.edu; zhongfei@cs.binghamton.edu
OI Zhang, Ruofei/0000-0002-4063-0109
CR [Anonymous], P INT C COMP VIS OCT
   BIMBO AD, 1999, VISUAL INFORMATION R
   BLOM G., 1989, Probability and Statistics: Theory and Applications
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   CHANG CC, LIBSVM LIBR SUPPORT
   CHEN Y, 2001, P IEEE INT C IM PROC
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Chiu ST, 1996, STAT SINICA, V6, P129
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   DeMarsicoi M, 1997, IMAGE VISION COMPUT, V15, P119, DOI 10.1016/S0262-8856(96)01114-6
   Dillon W.R., 1984, MULTIVARIATE ANAL ME
   Duda R., 1973, Pattern Classification and Scene Analysis
   GEMAN D, 2000, P RFIA 2000 PAR FRAN
   HUANG J, 1997, IEEE INT C COMP VIS
   ISHIKAWA Y, 1998, 24 VLDB C P NEW YORK
   JING F, 2003, P IEEE INT C MULT EX
   LAAKDONEN J, 1999, IJCNN 99 P WASH DC
   LIU Y, 1998, IEEE INT WORKSH CONT, P91
   MACCARTHUR SD, 2000, IEEE WORKSH CBAIVL P
   NASTAR C, 1998, IEEE C COMP VIS PATT
   Peng J, 1999, COMPUT VIS IMAGE UND, V75, P150, DOI 10.1006/cviu.1999.0770
   PICARD RW, IEEE INT C IM PROC P
   PORKAEW K, 1999, IEEE INT C MUL COMP
   Ratan AL, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P90, DOI 10.1109/IVL.1997.629725
   Rocchio J. J., 1971, SMART RETRIEVAL SYST, P313
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   RUI Y, 2000, IEEE C COMP VIS PATT
   Santini S, 2000, IEEE MULTIMEDIA, V7, P26, DOI 10.1109/93.879766
   Silverman, 2018, DENSITY ESTIMATION S, DOI 10.1201/9781315140919
   STRICKER MA, 1996, SPIE STORAGE RETRIEV, V2420, P381
   SZUMMER M, 2002, P NEUR INF PROC SYST
   SZUMMER M, 2000, P NEUR INF PROC SYST
   TAO D, 2004, P IEEE C COMP VIS PA
   Tax D. M. J., 2001, Multiple Classifier Systems. Second International Workshop, MCS 2001. Proceedings (Lecture Notes in Computer Science Vol.2096), P299
   TERRELL GR, 1992, ANN STAT, V20, P1236, DOI 10.1214/aos/1176348768
   TIEU K, 2000, IEEE C COMP VIS PATT
   TONG S, 2001, ACM MULT 2001 P OTT
   VASCONCELOS N, 2000, ADV NEURAL INFORMATI, V12
   Venables W. N., 2002, Modern Applied Statistics with S, P271, DOI [10.1007/978-0-387-21706-2, DOI 10.1007/978-0-387-21706-2]
   WANG L, 2003, P IEEE INT C COMP VI
   WOOD MEJ, 1998, ACM MULT 98 P BRIST
   WU Y, 2000, IEEE C COMP VIS PATT
   YAN R, 2003, P ACM MULT 2003 BERK
   Zhang R, 2003, 5 ACM INT WORKSH MUL
   Zhang R, 2004, IEEE INT C COMP VIS
   ZHOU XS, 2001, IEEE C COMP VIS PATT
NR 46
TC 22
Z9 26
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2006
VL 24
IS 3
BP 211
EP 223
DI 10.1016/j.imavis.2005.11.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 031PI
UT WOS:000236716100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Frantz, S
   Rohr, K
   Stiehl, HS
AF Frantz, S
   Rohr, K
   Stiehl, HS
TI Development and validation of a multi-step approach to improved
   detection of 3D point landmarks in tomographic images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE anatomical point landmarks; differential approaches; landmark detection;
   validation
ID THIN-PLATE SPLINES; CT IMAGES; REGISTRATION; LOCALIZATION; EXTRACTION;
   SURGERY; MR
AB We introduce a novel multi-step approach to improved detection of 3D anatomical point landmarks in tomographic images. Such landmarks serve as important image features for a variety of 3D medical image analysis tasks (e.g. image registration). Existing approaches to landmark detection, however, often suffer from a rather large number of false detections. Our multi-step approach combines an existing robust 3D detection operator with two different novel approaches to the reduction of false detections, and is applied within a semi-automatic procedure allowing for interactive control by the user. Experimental results obtained for a number of different anatomical landmarks of the human head in 3D CT and MR images demonstrate that both automatic ROI size selection and incorporation of a priori knowledge of the intensity structure at a landmark significantly improve the detection performance. The applicability of semi-automatic landmark extraction is thus considerably improved. We also summarize the results of a validation study in which we compare the performance of semi-automatic landmark extraction with that of a (standard) manual procedure for landmark extraction. As an exemplary application, we consider rigid MR/CT registration. The main result of our study is that compared to a purely manual procedure, semi-automatic landmark extraction (a) significantly reduces the elapsed time for landmark extraction, (b) generally yields registration results of comparable quality, and (c) increases the reproducibility of the results. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Hamburg, Dept Comp Sci, D-22527 Hamburg, Germany.
   Heidelberg Univ, IPMB, DKFZ Heidelberg, Dept Intelligent Bioinformat Syst, D-69120 Heidelberg, Germany.
C3 University of Hamburg; Ruprecht Karls University Heidelberg; Helmholtz
   Association; German Cancer Research Center (DKFZ)
RP YXLON Int Xray GmbH, Essener Bogen 15, D-22419 Hamburg, Germany.
EM frantz@informatik.uni-hamburg.de; k.rohr@dkfz.de;
   stiehl@informatik.uni-hamburg.de
CR ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   BEIL W, 1997, P COMP ASS RAD SURG, P265
   BERTOLINI R, 1982, ATLAS ANATOMIE MENSC, V3
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   EVANS AC, 1991, WARPING COMPUTERIZED, V1445, P236
   Fitzpatrick JM, 1998, IEEE T MED IMAGING, V17, P694, DOI 10.1109/42.736021
   Florack L. M. J., 1994, Journal of Mathematical Imaging and Vision, V4, P171, DOI 10.1007/BF01249895
   Frantz S, 2000, LECT NOTES COMPUT SC, V1935, P492
   Frantz S, 1998, P SOC PHOTO-OPT INS, V3338, P28, DOI 10.1117/12.310892
   Frantz S, 1999, LECT NOTES COMPUT SC, V1679, P253
   FRANTZ S, 2001, THESIS U HAMBURG GER, V253
   FRANTZ S, 1999, VALIDATING POINT BAS, P233
   GERRITSEN FA, 1994, MED IMAGING ANAL MUL, P4
   Hartkens T, 1999, P SOC PHOTO-OPT INS, V3661, P32, DOI 10.1117/12.348583
   HILL DLG, 1994, RADIOLOGY, V191, P447, DOI 10.1148/radiology.191.2.8153319
   HILL DLG, 1991, BRIT J RADIOL, V64, P1030, DOI 10.1259/0007-1285-64-767-1030
   Johnson A.R., 1998, Applied multivariate statistical analysis
   Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4
   LINDEBERG T, 1994, IEEE IMAGE PROC, P924, DOI 10.1109/ICIP.1994.413244
   Niessen WJ, 1997, COMPUT VIS IMAGE UND, V65, P259, DOI 10.1006/cviu.1996.0582
   OKUTOMI M, 1992, INT J COMPUT VISION, V7, P143, DOI 10.1007/BF00128133
   Rohr K, 1997, IMAGE VISION COMPUT, V15, P219, DOI 10.1016/S0262-8856(96)01127-4
   Rohr K, 1999, PATTERN RECOGN, V32, P3, DOI 10.1016/S0031-3203(98)00088-0
   Rohr K, 2001, IEEE T MED IMAGING, V20, P526, DOI 10.1109/42.929618
   Rohr K, 1998, LECT NOTES COMPUT SC, V1496, P1174, DOI 10.1007/BFb0056307
   SOBOTTA J, 1988, ATLAS ANATOMIE MENSC, V1
   STRASTERS KC, 1997, FRANCE LECT NOTES CO, V1205, P161
   Thirion JP, 1996, INT J COMPUT VISION, V18, P121, DOI 10.1007/BF00054999
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   West J, 1997, J COMPUT ASSIST TOMO, V21, P554, DOI 10.1097/00004728-199707000-00007
NR 31
TC 11
Z9 14
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2005
VL 23
IS 11
BP 956
EP 971
DI 10.1016/j.imavis.2005.05.019
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 973KF
UT WOS:000232520600003
DA 2024-07-18
ER

PT J
AU Chang, CC
   Chuang, JC
   Hu, YS
AF Chang, CC
   Chuang, JC
   Hu, YS
TI Retrieving digital images from a JPEG compressed image database
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE quadtree; image databases; image retrieval; Joint Photographic Experts
   Group; discrete cosine transformation
ID INDEXING TECHNIQUES; INFORMATION
AB In this paper, we propose a new method of feature extraction in order to improve the efficiency of retrieving Joint Photographic Experts Group (JPEG) compressed images. Our feature extraction can be done directly to JPEG compressed images. We extract two features, DC feature and AC feature. from a JPEG compressed image. Then we measure the distances between the query image and the images in a database in terms of these two features. Our image retrieval system will give each retrieved image a rank to define its similarity to the query image. Furthermore, instead of fully decompressing JPEG images, our system only needs to do partial entropy decoding. Therefore, our proposed scheme can accelerate the work of retrieving images. According to our experimental results, our system is not only highly efficient but is also capable of performing satisfactorily. (C) 2003 Elsevier B.V. All rights reserved.
C1 Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, Chiayi 621, Taiwan.
C3 National Chung Cheng University
RP Natl Chung Cheng Univ, Dept Comp Sci & Informat Engn, 160 San Hsing, Chiayi 621, Taiwan.
EM ccc@cs.ccu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR [Anonymous], 2 INT WORKSH CONT BA
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   Chan YK, 2001, PATTERN RECOGN LETT, V22, P447, DOI 10.1016/S0167-8655(00)00114-8
   CHAN YK, 2000, INT J APPL MATH, V4, P157
   Climer S, 2002, PATTERN RECOGN, V35, P2479, DOI 10.1016/S0031-3203(01)00182-0
   Feng GC, 2003, PATTERN RECOGN, V36, P977, DOI 10.1016/S0031-3203(02)00114-0
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   Jia Li, 2000, Proceedings ACM Multimedia 2000, P147
   Jiang J, 2002, PATTERN RECOGN, V35, P2511, DOI 10.1016/S0031-3203(01)00217-5
   Lee DH, 2001, J SYST SOFTWARE, V56, P165, DOI 10.1016/S0164-1212(00)00095-9
   Mandal MK, 1999, IMAGE VISION COMPUT, V17, P513, DOI 10.1016/S0262-8856(98)00143-7
   Ngo CW, 2001, PATTERN RECOGN, V34, P1841, DOI 10.1016/S0031-3203(00)00111-4
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Shneier M, 1996, IEEE T PATTERN ANAL, V18, P849, DOI 10.1109/34.531805
   SLATON G, 1983, INTRO MODERN INFORMA
   Theo G, 2000, IEEE T IMAGE PROCESS, V9, P102
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   WU JK, 1995, MULTIMEDIA SYST, V3, P25, DOI 10.1007/BF01236577
NR 20
TC 30
Z9 34
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2004
VL 22
IS 6
BP 471
EP 484
DI 10.1016/j.imavis.2003.11.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 817HB
UT WOS:000221167500004
DA 2024-07-18
ER

PT J
AU Harville, M
AF Harville, M
TI Stereo person tracking with adaptive plan-view templates of height and
   occupancy statistics
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Statistical Methods in Video Processing
CY JUN 01-02, 2002
CL COPENHAGEN, DENMARK
DE person tracking; plan-view statistics; stereo depth images; adaptive
   template; Kalman filter
AB As the cost of computing per-pixel depth imagery from stereo cameras in real time has fallen rapidly in recent years, interest in using stereo vision for person tracking has greatly increased. Methods that attempt to track people directly in these 'camera-view' depth images are confronted by their substantial amounts of noise and unreliable data. Some recent methods have therefore found it useful to first compute overhead, 'plan-view' statistics of the depth data, and then track people in images of these statistics. We describe a new combination of plan-view statistics that better represents the shape of tracked objects and provides a more robust substrate for person detection and tracking than prior plan-view algorithms. We also introduce a new method of plan-view person tracking, using adaptive statistical templates and Kalman prediction. Adaptive templates provide more detailed models of tracked objects than prior choices such as Gaussians, and we illustrate that the typical problems with template-based tracking in camera-view images are easily avoided in a plan-view framework. We compare results of our method with those for techniques using different plan-view statistics or person models, and find our method to exhibit superior tracking through challenging phenomena such as complex inter-person occlusions and close interactions. Reasonable values for most system parameters may be derived from physically measurable quantities such as average person dimensions. (C) 2003 Elsevier B.V. All rights reserved.
C1 Hewlett Packard Labs, Palo Alto, CA 94304 USA.
C3 Hewlett-Packard
RP Hewlett Packard Labs, 1501 Page Mill Rd,MS 1181, Palo Alto, CA 94304 USA.
EM harville@hpl.hp.com
CR ALLEN T, 1999, UNPUB
   Bar-Shalom Y., 1995, MULTITARGET MULTISEN
   Beymer D, 2000, WORKSHOP ON HUMAN MOTION, PROCEEDINGS, P127, DOI 10.1109/HUMO.2000.897382
   BEYMER D, 1999, P ICCV FRAM RAT WORK
   Cohen I., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P319, DOI 10.1109/CVPR.1999.784651
   Darrell T, 1998, PROC CVPR IEEE, P601, DOI 10.1109/CVPR.1998.698667
   Darrell T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P628, DOI 10.1109/ICCV.2001.937685
   Eveland C, 1998, PROC CVPR IEEE, P266, DOI 10.1109/CVPR.1998.698619
   FOCKEN D, 2002, P INT C MULT INT ICM
   Greiffenhagen M, 2000, PROC CVPR IEEE, P335, DOI 10.1109/CVPR.2000.854840
   Gvili R, 2003, PROC SPIE, V5006, P564, DOI 10.1117/12.474052
   HARITAOGLU I, 1998, P 5 EUR C COMP VIS F, V1, P877
   Harville M, 2002, LECT NOTES COMPUT SC, V2352, P543
   Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3, DOI 10.1109/EVENT.2001.938860
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   Ivanov Y, 2000, INT J COMPUT VISION, V37, P199, DOI 10.1023/A:1008107805263
   Konolige Kurt., 1997, Eighth International Symposium on Robotics Research, P111
   Krumm J, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P3, DOI 10.1109/VS.2000.856852
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275
   MENGEL P, 2002, P INT C IM PROC ICIP, V2, P169
   Schulz D, 2001, PROC CVPR IEEE, P371
   SCHULZ D, 2003, P INT JOINT C ART IN
   Snorrason M, 1999, P SOC PHOTO-OPT INS, V3693, P44, DOI 10.1117/12.354460
   VERLY JG, 1994, P IM UND WORKSH MONT, V1, P559
   WOODFILL J, 1997, IEEE WORKSH FPGAS CU, P242
   2002, PETS PERFORMANCE EVA
NR 27
TC 66
Z9 98
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2004
VL 22
IS 2
BP 127
EP 142
DI 10.1016/j.imavis.2003.07.009
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 769DW
UT WOS:000188612000006
DA 2024-07-18
ER

PT J
AU Cinque, L
   De Rosa, F
   Lecca, F
   Levialdi, S
AF Cinque, L
   De Rosa, F
   Lecca, F
   Levialdi, S
TI Image retrieval using resegmentation driven by query rectangles
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image retrieval; resegmentation; query-rectangle
AB Image retrieval using pictorial attributes such as color, position, and shape is a topic of vigorous research. We address two key issues in image retrieval: the use of rectangles in queries to express properties of regions in the desired target images, and the use of oversegmentation to build the index of images in the database. In our method, the rectangles in the user's query are used to control a partial resegmentation of each candidate image. These query-driven, partial resegmentations provide the features needed for determining the distance between the query and each candidate, so that the closest candidates can be determined and retrieved. This method enables the construction of image retrieval systems with completely automatic indexing and relatively fast querying time. We show results of both qualitative and performance tests. (C) 2003 Published by Elsevier B.V.
C1 Univ Roma La Sapienza, Dipartimento Informat & Sistemist, I-00198 Rome, Italy.
C3 Sapienza University Rome
RP Cinque, L (corresponding author), Univ Roma La Sapienza, Dipartimento Informat & Sistemist, Via Salaria 113, I-00198 Rome, Italy.
EM cinque@dsi.uniroma1.it
CR CARSON C, 1997, P CVPR 97 WORKSH CON
   CINQUE L, 2000, RETRIEVAL IMAGES USI
   Del Bimbo A., 1994, Proceedings. IEEE Symposium on Visual Languages (Cat. No.94TH8010), P216, DOI 10.1109/VL.1994.363615
   DeMarsicoi M, 1997, IMAGE VISION COMPUT, V15, P119, DOI 10.1016/S0262-8856(96)01114-6
   DIMAI A, 1996, BIWITR173 ETH
   FLICKNER M, 1995, IEEE COMPUT, V9, P23
   GUDIVADA VN, 1995, COMPUTER, V28
   HARALIK RM, 1992, COMPUTER ROBOT VISIO
   JING F, 2001, P 3 ACM INT WORKSH M
   NATSEV A, 1999, P ACM SIGMOD INT C M
   NIBLACK W, 1993, P SOC PHOTO-OPT INS, V1908, P173
   ROSENFELD A, 1992, DIGITAL PICTURE PROC
   SANTINI S, 1996, IEEE T PATTERN ANAL
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SMITH JR, 1997, THESIS COLUMBIA U
   Tanimoto S.L, 1976, PATTERN RECOGN, P452
   WANG JZ, 2001, IEEE T PATTERN ANAL, P23
NR 17
TC 4
Z9 4
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2004
VL 22
IS 1
BP 15
EP 22
DI 10.1016/j.imavis.2003.07.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 763BB
UT WOS:000188048400003
DA 2024-07-18
ER

PT J
AU Zribi, M
AF Zribi, M
TI Non-parametric and unsupervised Bayesian classification with Bootstrap
   sampling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE non-parametric and unsupervised Bayesian classification; bootstrap
   sampling; non-parametric expectation-maximization; orthogonal
   probability density functions
ID MARKOV RANDOM-FIELDS; IMAGE SEGMENTATION; MAXIMUM-LIKELIHOOD; SERIES
   METHODS; EM ALGORITHM; JACKKNIFE; DENSITIES; MIXTURE; MODEL; NOISY
AB In this paper, we propose a non-parametric and unsupervised Bayesian classification based on the principle of Bootstrap sampling (BS) which reduces the dependence effect of pixels in real images, and reduces the classification time. Given an original image, we randomly select a small representative set of pixels. Then, a Non-parametric Expectation-Maximization (NEM) algorithm is used for image segmentation. The non-parametric aspect comes from the use of the orthogonal probability density function (pdf) estimation, which is reduced to the estimation of the first Fourier coefficients (FC's) of the pdf with respect to a given orthogonal basis. The results we obtain show that the BS method gives better results than the classical one, both in the quality of the segmented image and the computing time. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Littoral Cote Opale, Maison Rech Blaise Pascal, LASL, UPRES 2600, F-62228 Calais, France.
C3 Universite du Littoral-Cote-d'Opale
RP Zribi, M (corresponding author), Univ Littoral Cote Opale, Maison Rech Blaise Pascal, LASL, UPRES 2600, 50 Rue Ferdinand Buisson,BP 699, F-62228 Calais, France.
EM mourad.zribi@lasl-gw.univ-littoral.fr
CR Ambroise C, 1998, PATTERN RECOGN LETT, V19, P919, DOI 10.1016/S0167-8655(98)00076-2
   [Anonymous], GENETIC LEARNING ADA
   [Anonymous], 1982, Digital Picture Processing
   BANGA C, 1995, THESIS U RENNES FRAN, P44
   BICKEL PJ, 1981, ANN STAT, V9, P1196, DOI 10.1214/aos/1176345637
   BRAATHEN B, 1993, MACHINE GRAPHICS VIS, V2, P39
   Caillol H, 1997, IEEE T IMAGE PROCESS, V6, P425, DOI 10.1109/83.557353
   CHALMOND B, 1989, PATTERN RECOGN, V22, P747, DOI 10.1016/0031-3203(89)90011-3
   Chang E.I., 1991, Advances in neural information processing systems, V3, P797
   DAVIS L, 1975, SURVEY EDGE DETECTIO, P248
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871
   EFRON B, 1979, ANN STAT, V7, P1, DOI 10.1214/aos/1176344552
   Efron B., 1993, INTRO BOOTSTRAP, VVolume 914, DOI DOI 10.1007/978-1-4899-4541-9
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   HALL P, 1982, J MULTIVARIATE ANAL, V12, P432, DOI 10.1016/0047-259X(82)90076-8
   HALL P, 1981, ANN STAT, V9, P683, DOI 10.1214/aos/1176345474
   Hall P., 2013, BOOTSTRAP EDGEWORTH
   HART PE, 1968, IEEE T INFORM THEORY, V14, P515, DOI 10.1109/TIT.1968.1054155
   JAIN AK, 1987, IEEE T PATTERN ANAL, V9, P628, DOI 10.1109/TPAMI.1987.4767957
   JENG FC, 1991, IEEE T SIGNAL PROCES, V39, P683, DOI 10.1109/78.80887
   Kehtarnavaz N, 1998, PATTERN RECOGN LETT, V19, P133, DOI 10.1016/S0167-8655(97)00173-6
   KELLY PA, 1988, IEEE T ACOUST SPEECH, V36, P1628, DOI 10.1109/29.7551
   KENDALL MG, 1967, ADV THEORY STAT, V2, P149
   Koch I., 1996, IEEE ICPR, P447
   KRONMAL R, 1968, J AM STAT ASSOC, V63, P925, DOI 10.2307/2283885
   MASSON P, 1993, IEEE T GEOSCI REMOTE, V31, P618, DOI 10.1109/36.225529
   MILLER RG, 1974, BIOMETRIKA, V61, P1
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Pieczynski W, 1989, J APPL STAT, V16, P283
   SINGH K, 1981, ANN STAT, V9, P1187, DOI 10.1214/aos/1176345636
   Vijaya S.V., 2001, PATTERN RECOGN, V34, P1047
   WON CS, 1992, CVGIP-GRAPH MODEL IM, V54, P308, DOI 10.1016/1049-9652(92)90078-C
   ZHANG J, 1994, IEEE T IMAGE PROCESS, V3, P404, DOI 10.1109/83.298395
   Zhang J, 1993, IEEE T IMAGE PROCESS, V2, P27, DOI 10.1109/83.210863
   Zhang YJ, 1997, PATTERN RECOGN LETT, V18, P963, DOI 10.1016/S0167-8655(97)00083-4
   Zribi M., 1995, Image Analysis and Processing. 8th International Conference, ICIAP '95. Proceedings, P423
   Zribi M, 2003, PATTERN RECOGN LETT, V24, P97, DOI 10.1016/S0167-8655(02)00193-9
NR 38
TC 11
Z9 11
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2004
VL 22
IS 1
BP 1
EP 8
DI 10.1016/S0262-8856(03)00136-7
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 763BB
UT WOS:000188048400001
DA 2024-07-18
ER

PT J
AU Srivastava, A
   Liu, XW
AF Srivastava, A
   Liu, XW
TI Statistical hypothesis pruning for identifying faces from infrared
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT IEEE Workshop in Computer Vision Beyond the Visible Spectrum
CY DEC 14, 2001
CL KAUAI, HI
SP IEEE
DE infrared image analysis; nighttime face identification; bessel K forms;
   linage statistics; hypothesis selection
ID NATURAL IMAGES; TARGET RECOGNITION; SCENES
AB A Bayesian approach to identify faces from their IR facial images amounts to testing of discrete hypotheses in presence of nuisance variables such as pose, facial expression, and thermal state. We propose an efficient, low-level technique for hypothesis pruning, i.e. shortlisting high probability subjects from given observed image(s). (This subset can be further tested using some high-level model for eventual identification.) Hypothesis pruning is accomplished using wavelet decompositions (of the observed images) followed by analysis of lower-order statistics of the coefficients. Specifically, we filter infrared (IR) images using bandpass filters and model the marginal densities of the outputs via a parametric family that was introduced by Grenader and Srivastava [IEEE Trans. Pattern Anal. Mach. Intell. 23 (2001) 424]. IR images are compared using an L-2-metric between the Marginals computed directly from the parameters. Results from experiments on IR face identification and statistical pruning are presented. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Florida State Univ, Dept Stat, Ctr Stat Consulting, Tallahassee, FL 32306 USA.
   Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA.
C3 State University System of Florida; Florida State University; State
   University System of Florida; Florida State University
RP Florida State Univ, Dept Stat, Ctr Stat Consulting, Tallahassee, FL 32306 USA.
EM anuj@stat.fsu.edu
RI Srivastava, Anuj/L-4705-2019; Srivastava, Anuj/F-7417-2011
CR [Anonymous], P SIGGRAPHS, DOI DOI 10.1145/218380.218446
   [Anonymous], 1999, HDB COMPUTER VISION
   [Anonymous], 1993, General pattern theory
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   Comon P., 1994, SIGNAL PROCESSING, V36
   COOPER ML, 1997, P SPIE ALGORITHMS SY, V3070
   Cutler Ross., 1996, FACE RECOGNITION USI
   DONOHO DL, 2001, NETWORK COMPUTATION, V12, P317
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   Grenander U, 1998, IEEE T PATTERN ANAL, V20, P790, DOI 10.1109/34.709572
   Grenander U, 2000, IEEE T INFORM THEORY, V46, P1658, DOI 10.1109/18.850712
   Grenander U, 2001, IEEE T PATTERN ANAL, V23, P424, DOI 10.1109/34.917579
   Hallinan P., 1999, Two and Three-dimensional Patterns of the Face
   HESHER C, 2002, P 2002 INT C IM SCI
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Lanterman AD, 1997, OPT ENG, V36, P1123, DOI 10.1117/1.601302
   LIU X, 2003, IN PRESS IEEE T IMAG
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Pavlidis I, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P104, DOI 10.1109/CVBVS.2000.855255
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   Prokoski F, 2000, P IEEE WORKSH COMP V
   Selinger A., 2001, Appearance-based facial recognition using visible and thermal imagery: a comparative study
   Srivastava A, 2003, J MATH IMAGING VIS, V18, P17, DOI 10.1023/A:1021889010444
   Srivastava A, 2001, PROC SPIE, V4379, P176, DOI 10.1117/12.445364
   Srivastava A, 2002, IEEE T PATTERN ANAL, V24, P1200, DOI 10.1109/TPAMI.2002.1033212
   Wolff L. B., 2001, CVPR WORKSH COMP VIS
   Zhu SC, 1997, NEURAL COMPUT, V9, P1627, DOI 10.1162/neco.1997.9.8.1627
NR 30
TC 19
Z9 24
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2003
VL 21
IS 7
BP 651
EP 661
DI 10.1016/S0262-8856(03)00061-1
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 706FR
UT WOS:000184443400008
DA 2024-07-18
ER

PT J
AU Yan, SC
   Liu, C
   Li, SZ
   Zhang, HJ
   Shum, HY
   Cheng, QS
AF Yan, SC
   Liu, C
   Li, SZ
   Zhang, HJ
   Shum, HY
   Cheng, QS
TI Face alignment using texture-constrained active shape models
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE shape localization; statistical shape model; statistical texture model;
   texture-constrained shape model
AB In this paper, we propose a texture-constrained active shape model (TC-ASM) to localize a face in an image. TC-ASM effectively incorporates not only the shape prior and local appearance around each landmark, but also the global texture constraint over the shape. Therefore, it performs stable to initialization, accurate in shape localization and robust to illumination variation, with low computational cost. Extensive experiments are provided to demonstrate our algorithm. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Peking Univ, Sch Math Sci, Dept Info Sci, Beijing 100871, Peoples R China.
   Beijing Sigma Ctr, Microsoft Res Asia, Beijing 100080, Peoples R China.
C3 Peking University; Microsoft Research Asia; Microsoft
RP Peking Univ, Sch Math Sci, Dept Info Sci, Beijing 100871, Peoples R China.
EM scyan@msrchina.research.microsoft.com
RI Yan, Shuicheng/HCI-1431-2022
CR [Anonymous], P MATH METH BIOM IM
   [Anonymous], STAT MODELS APPEARAN
   [Anonymous], THESIS TU DENMARK LY
   Cootes T., 1998, Proc. ECCV, V2, P484
   Cootes TF, 2001, PROC CVPR IEEE, P1114
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   HOW XW, 2001, P IEEE COMP SOC C CO, P828
   Li YM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P554, DOI 10.1109/ICCV.2001.937565
   Martinez A., 1998, AR FACE DATABASE
   MITCHELL S, 2000, SPIE MED IMAGING FEB
NR 10
TC 38
Z9 52
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 69
EP 75
AR PII S0262-8856(02)00136-1
DI 10.1016/S0262-8856(02)00136-1
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800008
DA 2024-07-18
ER

PT J
AU Lu, L
   Chen, SH
   Tang, HN
   Zhang, XF
   Hu, XL
AF Lu, Lu
   Chen, Shuhan
   Tang, Haonan
   Zhang, Xinfeng
   Hu, Xuelong
TI A multi-scale perceptual polyp segmentation network based on boundary
   guidance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Polyp segmentation; Boundary guidance; Multi-scale global perception;
   Complementary fusion; Detail refinement
ID IMAGE SEGMENTATION
AB Image segmentation of polyps can provide an important basis for the diagnosis of colorectal cancer and has a high clinical application value. Segmentation of polyp regions is very challenging due to the high similarity between polyps and background mucosal tissue, many existing methods have failed to produce satisfactory polyp segmentation results. Therefore, scholars have recently used transformer backbone networks to extract features, which captures global information better than CNNs, resulting in more accurate detection results, but their boundary results are still not accurate enough due to the lack of processing for the boundary. In this paper, we propose a multi-scale perceptual polyp segmentation network based on boundary guidance, to obtain higher segmentation accuracy in both regions and boundary. To increase the feature response region, we first propose a multi-scale global perception module to expand the receptive field and aggregate multi-scale contextual information to capture the primary location of polyps at local and global levels. Then, we design a boundary-guided feature enhancement module that utilizes contextual features to mine hidden polyp boundary and employs the boundary to guide region learning to improve segmentation boundary accuracy. Finally, we propose a complementary fusion module that uses higher-level features to filter out the background noise of lower-level features and fuses the features layer by layer. In particular, to refine the extracted features, a detail refinement module is designed to complement the spatial details to improve the segmentation performance. Extensive experiments using seven evaluation metrics on five publicly available polyp datasets have shown that the proposed a multi-scale perceptual polyp segmentation network based on boundary guidance outperforms most state-of-theart models.
C1 [Lu, Lu; Chen, Shuhan; Tang, Haonan; Zhang, Xinfeng; Hu, Xuelong] Yangzhou Univ, Sch Informat Engn, Yangzhou, Peoples R China.
C3 Yangzhou University
RP Chen, SH (corresponding author), Yangzhou Univ, Sch Informat Engn, Yangzhou, Peoples R China.
EM shchen@yzu.edu.cn; zhangxf@yzu.edu.cn; xlhu@yzu.edu.cn
RI Zhang, Xinfeng/X-8148-2019
FU Natural Science Foundation of China [61802336, 61801417]; Yangzhou
   University "Qinglan Project"
FX This work is partially supported by the Natural Science Foundation of
   China (No. 61802336, No. 61801417) , and Yangzhou University "Qinglan
   Project ".
CR A.C. Society, 2020, COLORECTAL CANC FACT, P48
   Badrinarayanan V, 2016, Arxiv, DOI [arXiv:1511.00561, DOI 10.48550/ARXIV.1511.00561]
   Bernal J, 2015, COMPUT MED IMAG GRAP, V43, P99, DOI 10.1016/j.compmedimag.2015.02.007
   Bi L, 2017, IEEE T BIO-MED ENG, V64, P2065, DOI 10.1109/TBME.2017.2712771
   Chen ZX, 2021, IEEE T IMAGE PROCESS, V30, P431, DOI 10.1109/TIP.2020.3037536
   Codella NCF, 2018, I S BIOMED IMAGING, P168, DOI 10.1109/ISBI.2018.8363547
   De Boer PT, 2005, ANN OPER RES, V134, P19, DOI 10.1007/s10479-005-5724-z
   Deng-Ping Fan, 2020, Medical Image Computing and Computer Assisted Intervention - MICCAI 2020. 23rd International Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12266), P263, DOI 10.1007/978-3-030-59725-2_26
   Dong B, 2024, Arxiv, DOI [arXiv:2108.06932, DOI 10.48550/ARXIV.2108.06932]
   Fan D.-P., 2021, Scientia Sinica Informationis, V6, P6
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fang YQ, 2019, LECT NOTES COMPUT SC, V11764, P302, DOI 10.1007/978-3-030-32239-7_34
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Huang C.-H., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2101.07172
   Jemal A, 2011, CA-CANCER J CLIN, V61, P134, DOI [10.3322/caac.21492, 10.3322/caac.20107, 10.3322/caac.20115]
   Jha D, 2020, LECT NOTES COMPUT SC, V11962, P451, DOI 10.1007/978-3-030-37734-2_37
   Jha D, 2019, IEEE INT SYM MULTIM, P225, DOI 10.1109/ISM46123.2019.00049
   Kim T, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P2167, DOI 10.1145/3474085.3475375
   Leufkens AM, 2012, ENDOSCOPY, V44, P470, DOI 10.1055/s-0031-1291666
   Liu Q, 2017, IEEE T IMAGE PROCESS, V26, P4537, DOI 10.1109/TIP.2017.2703081
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Máttyus G, 2017, IEEE I CONF COMP VIS, P3458, DOI 10.1109/ICCV.2017.372
   Mendonca Teresa, 2013, 2013 35th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), P5437, DOI 10.1109/EMBC.2013.6610779
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Patel K, 2021, 2021 18TH CONFERENCE ON ROBOTS AND VISION (CRV 2021), P181, DOI [10.1109/CRV52889.2021.00032, 10.1109/crv52889.2021.00032]
   Qadir HA, 2019, INT SYM MED INFORM, P181, DOI 10.1109/ismict.2019.8743694
   Qiu Z., 2022, Medical Imaging 2022: Image Processing, V12032, P792
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Saha A, 2020, I S BIOMED IMAGING, P2014, DOI [10.1109/ISBI45749.2020.9098344, 10.1109/isbi45749.2020.9098344]
   Silva J, 2014, INT J COMPUT ASS RAD, V9, P283, DOI 10.1007/s11548-013-0926-3
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P630, DOI 10.1109/TMI.2015.2487997
   Vázquez D, 2017, J HEALTHC ENG, V2017, DOI 10.1155/2017/4037190
   Wang J., 2022, arXiv
   Wang Ruxin, 2022, Med Image Anal, V78, P102395, DOI 10.1016/j.media.2022.102395
   Wang WH, 2022, COMPUT VIS MEDIA, V8, P415, DOI 10.1007/s41095-022-0274-8
   Wei J, 2021, LECT NOTES COMPUT SC, V12901, P699, DOI 10.1007/978-3-030-87193-2_66
   Xinzi Sun, 2019, 2019 18th IEEE International Conference On Machine Learning And Applications (ICMLA), P851, DOI 10.1109/ICMLA.2019.00148
   Yang HK, 2022, COMPUT MED IMAG GRAP, V101, DOI 10.1016/j.compmedimag.2022.102110
   Yu Q., 2021, arXiv
   Yue GH, 2023, IEEE T INSTRUM MEAS, V72, DOI 10.1109/TIM.2023.3264047
   Zhang RF, 2022, LECT NOTES COMPUT SC, V13433, P99, DOI 10.1007/978-3-031-16437-8_10
   Zhang YD, 2021, LECT NOTES COMPUT SC, V12901, P14, DOI 10.1007/978-3-030-87193-2_2
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao XQ, 2021, LECT NOTES COMPUT SC, V12901, P120, DOI 10.1007/978-3-030-87193-2_12
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 45
TC 1
Z9 1
U1 13
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104811
DI 10.1016/j.imavis.2023.104811
EA SEP 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA T9YH0
UT WOS:001081462300001
DA 2024-07-18
ER

PT J
AU Guo, HJ
   Shi, L
AF Guo, Huijie
   Shi, Lei
TI Contrastive learning with semantic consistency constraint
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Representation learning; Contrastive learning; Semantic consistency
AB Contrastive representation learning (CL) can be viewed as an anchor-based learning paradigm that learns rep-resentations by maximizing the similarity between an anchor and positive samples while reducing the similarity with negative samples. A randomly adopted data augmentation strategy generates positive and negative samples, resulting in semantic inconsistency in the learning process. The randomness may introduce additional distur-bances to the original sample, thereby reversing the sample identity. Also, the negative sample demarcation strategy makes the negative samples containing semantically similar samples to the anchors, called false negative samples. Therefore, CL's maximization and reduction process cause distractors to be incorporated into the learned feature representation. In this paper, we propose a novel Semantic Consistency Regularization (SCR) method to alleviate this problem. Specifically, we introduce a new regularization item, pairwise subspace dis-tance, to constrain the consistency of distributions across different views. Furthermore, we propose a divide-and-conquer strategy to ensure that the proposed SCR is well-suited for large mini-batch cases. Empirically, results across multiple benchmark mini and large datasets demonstrate that SCR outperforms state-of-the-art methods. Codes are available at https://github.com/PaulGHJ/SCR.git.
C1 [Guo, Huijie; Shi, Lei] Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing, Peoples R China.
C3 Beihang University
RP Shi, L (corresponding author), Beihang Univ, Beijing Adv Innovat Ctr Big Data & Brain Comp, Beijing, Peoples R China.
EM guo_hj@buaa.edu.cn; leishi@buaa.edu.cn
FU National Key R\ amp; D Program of China [2021YFB3500700]; NSFC
   [62172026]; National Social Science Fund of China [ZD153]; SKLSDE
FX This work was supported by National Key R\ & D Program of China
   (2021YFB3500700) , NSFC Grant 62172026, National Social Science Fund of
   China 22\&ZD153, and SKLSDE.
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   [Anonymous], 2006, PROC IEEE COMPUT SOC
   Arora S., 2019, 36th International Conference on Machine Learning, P9904
   Bao H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2106.08254
   Caron M., 2020, Advances in neural information processing systems, V33, P9912
   Chen D., 2022, ARXIV
   Chen S., 2021, INT C MACH LEARN ICM, P1673
   Chen T, 2020, PR MACH LEARN RES, V119
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Chen XY, 2021, INT C MACHINE LEARNI, V139
   Chuang C.-Y., 2022, P IEEECVF C COMPUTER, P16670
   Chuang Ching-Yao, 2020, ADV NEURAL INFORM PR, V33, P8765, DOI DOI 10.48550/ARXIV.2007.00224
   Coates A., 2011, P 14 INT C ART INT S, V15, P215
   Deshpande I, 2019, PROC CVPR IEEE, P10640, DOI 10.1109/CVPR.2019.01090
   Dosovitskiy A, 2014, ADV NEUR IN, V27
   Dumais ST, 2004, ANNU REV INFORM SCI, V38, P189
   Ermolov A, 2021, PR MACH LEARN RES, V139
   Ge S., 2021, Neural Inf. Process. Syst., V34, P27356
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Grill Jean-Bastien, 2020, ADV NEURAL INFORM PR
   Guo XF, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14114, DOI 10.1109/ICCV48922.2021.01387
   Hjelm R.D., 2018, INT C LEARNING REPRE
   Gulrajani I, 2017, ADV NEUR IN, V30
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kingma D. P., 2014, arXiv
   Kolouri S, 2019, ADV NEUR IN, V32
   Kolouri S, 2018, PROC CVPR IEEE, P3427, DOI 10.1109/CVPR.2018.00361
   Krizhevsky A., 2009, Tech. Rep.
   Larsson G, 2016, LECT NOTES COMPUT SC, V9908, P577, DOI 10.1007/978-3-319-46493-0_35
   Le Ya, 2015, CS 231N, P3
   Li J, 2020, INT C LEARNING REPRE
   Li JM, 2022, Arxiv, DOI arXiv:2203.05119
   Li Yunfan, 2021, 2021 AAAI C ARTIFICI
   Martin D.I., 2007, Handbook of Latent Semantic Analysis, P35, DOI DOI 10.4324/9780203936399.CH2
   Patacchiola M., 2020, Advances in Neural Information Processing Systems, P4003
   Purohit K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2289, DOI 10.1109/ICCV48922.2021.00231
   Qiang WW, 2023, IEEE T KNOWL DATA EN, V35, P3014, DOI 10.1109/TKDE.2021.3112815
   Qiang WW, 2023, INT J COMPUT VISION, V131, P1211, DOI 10.1007/s11263-023-01760-7
   Qiang WW, 2022, APPL SOFT COMPUT, V128, DOI 10.1016/j.asoc.2022.109506
   Qiang WW, 2021, KNOWL-BASED SYST, V223, DOI 10.1016/j.knosys.2021.107066
   Qiang WW, 2020, SIGNAL PROCESS, V170, DOI 10.1016/j.sigpro.2019.107449
   Qiang Wenwen, 2022, INT C MACH LEARN PML, V162, P18018
   Robinson Joshua, 2020, INT C LEARN REPR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Su XZ, 2024, Arxiv, DOI arXiv:2303.05240
   Tsai Yao-Hung Hubert, 2020, Advances in Neural Information Processing Systems, V33, P62
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   Wang T., 2020, INT C MACHINE LEARNI, P9929
   Wang Y., 2021, NEURIPS, P27617
   Wen Z., 2021, P MACHINE LEARNING R, P11112
   Wu M., 2020, INT C LEARNING REPRE
   Wu ZR, 2018, PROC CVPR IEEE, P3733, DOI 10.1109/CVPR.2018.00393
   Xiao T., 2020, INT C LEARNING REPRE
   Yonglong Tian, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P776, DOI 10.1007/978-3-030-58621-8_45
   You Y, 2017, Arxiv, DOI arXiv:1708.03888
   Zbontar J, 2021, PR MACH LEARN RES, V139
   Zhan XH, 2020, PROC CVPR IEEE, P3783, DOI 10.1109/CVPR42600.2020.00384
   Zhang Junbo, 2022, CVPR, P16650
NR 58
TC 0
Z9 0
U1 5
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104754
DI 10.1016/j.imavis.2023.104754
EA JUL 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA O0KM6
UT WOS:001040796500001
DA 2024-07-18
ER

PT J
AU Antoun, M
   Asmar, D
AF Antoun, Maya
   Asmar, Daniel
TI Human object interaction detection: Design and survey
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Human object interaction; Scene understanding; Deep learning
AB Human-Object Interaction (HOI) detection is the process of estimating the interaction between a human and an object in an image. The first attempts at HOI involved two-stage detection methods, then improved to one-stage, and finally end-to-end methods in the last year with the development of transformers. The objective of this paper is to first provide a guideline to researchers seeking to design a human object interaction detection model in addition to describing the benchmark datasets and evaluation metrics used in this task. Second, it presents a survey about the different existing methods for HOI detection and critically analyzes their design decisions through every step. Finally, we report the characteristics of future research directions and present some open issues on human-object interaction detection by presenting the limitations facing HOI detection.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Antoun, Maya; Asmar, Daniel] Amer Univ Beirut, Bliss St, Beirut, Lebanon.
C3 American University of Beirut
RP Asmar, D (corresponding author), Amer Univ Beirut, Bliss St, Beirut, Lebanon.
EM mja27@mail.aub.edu; da20@aub.edu.lb
FU University Research Board (URB); American University of Beirut (AUB);
   National Council for Scientific Research of Lebanon (CNRS-L)
FX The authors would like to acknowledge the University Research Board
   (URB) and the American University of Beirut (AUB) and the National
   Council for Scientific Research of Lebanon (CNRS-L) for granting a
   doctoral fellowship to Maya Antoun.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   [Anonymous], 2018, P EUR C COMP VIS
   [Anonymous], 2016, SINGLE SHOT MULTIBOX
   Bansal A, 2020, Arxiv, DOI arXiv:2004.04851
   Bansal A, 2020, AAAI CONF ARTIF INTE, V34, P10460
   Bergstrom Trevor, 2020, HuMA'20: Proceedings of the 1st International Workshop on Human-centric Multimedia Analysis, P63, DOI 10.1145/3422852.3423481
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chao YW, 2015, IEEE I CONF COMP VIS, P1017, DOI 10.1109/ICCV.2015.122
   Chen Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P696, DOI 10.1007/978-3-030-58610-2_41
   Chen JW, 2021, Arxiv, DOI arXiv:2112.08647
   Chen MF, 2021, Arxiv, DOI arXiv:2103.05983
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Devlin J, 2019, Arxiv, DOI arXiv:1810.04805
   Dong L, 2022, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P19538
   Peters ME, 2018, Arxiv, DOI [arXiv:1802.05365, 10.48550/arXiv.1802.05365]
   Fang HS, 2021, Arxiv, DOI arXiv:2010.01005
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Gao C., 2018, ARXIV
   Girshick Ross, 2018, Detectron
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Gupta S, 2015, Arxiv, DOI arXiv:1505.04474
   Hai Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P248, DOI 10.1007/978-3-030-58520-4_15
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hou Z, 2021, Arxiv, DOI arXiv:2103.08214
   Hou Z, 2020, Arxiv, DOI arXiv:2007.12407
   Joulin A, 2016, Arxiv, DOI [arXiv:1607.01759, DOI 10.48550/ARXIV.1607.01759]
   Kato K, 2018, LECT NOTES COMPUT SC, V11218, P247, DOI 10.1007/978-3-030-01264-9_15
   Kim B., 2020, ECCV, P498, DOI DOI 10.1007/978-3-030
   Kim B, 2021, Arxiv, DOI arXiv:2104.13682
   Kim DJ, 2020, Arxiv, DOI arXiv:2007.08728
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Li Y.-L., ADV NEURAL INF PROCE, V33
   Li YL, 2020, PROC CVPR IEEE, P379, DOI [10.1109/CVPR42600.2020.00046, 10.1109/ICEMME51517.2020.00080]
   Li YL, 2019, PROC CVPR IEEE, P3580, DOI 10.1109/CVPR.2019.00370
   Li YK, 2020, CONSTRUCTION RESEARCH CONGRESS 2020: INFRASTRUCTURE SYSTEMS AND SUSTAINABILITY, P166, DOI [10.1109/CVPR42600.2020.01018, 10.1061/9780784482858.019]
   Liang ZJ, 2021, Arxiv, DOI arXiv:2001.02302
   Liao Y, 2020, PROC CVPR IEEE, P479, DOI 10.1109/CVPR42600.2020.00056
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Lin T.Y., 2017, P IEEE C COMP VIS PA, P2117
   Liu Y, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4235, DOI 10.1145/3394171.3413600
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Pavlakos G, 2019, PROC CVPR IEEE, P10967, DOI 10.1109/CVPR.2019.01123
   Pennington J., 2014, P 2014 C EMP METH NA, P1532, DOI [DOI 10.3115/V1/D14-1162, 10.3115/v1/D14-1162]
   Peyre J, 2019, IEEE I CONF COMP VIS, P1981, DOI 10.1109/ICCV.2019.00207
   Sarullo A, 2020, Arxiv, DOI arXiv:2009.01039
   Shen LY, 2018, IEEE WINT CONF APPL, P1568, DOI 10.1109/WACV.2018.00181
   Tamura M, 2021, Arxiv, DOI [arXiv:2103.05399, DOI 10.48550/ARXIV.2103.05399]
   Ulutan Oytun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13614, DOI 10.1109/CVPR42600.2020.01363
   Wan B, 2019, IEEE I CONF COMP VIS, P9468, DOI 10.1109/ICCV.2019.00956
   Wang TC, 2020, PROC CVPR IEEE, P4115, DOI 10.1109/CVPR42600.2020.00417
   Wang TC, 2019, IEEE I CONF COMP VIS, P5693, DOI 10.1109/ICCV.2019.00579
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Xu BJ, 2019, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2019.00212
   Yuan H., 2022, arXiv
   Zhang A., ADV NEURAL INF PROCE, V34
   Zhang FZ, 2021, Arxiv, DOI arXiv:2012.06060
   Zhang Frederic Z., 2021, arXiv
   Zhang Y., 2022, P IEEECVF C COMPUTER, P19548
   Zhong XB, 2021, Arxiv, DOI arXiv:2104.05269
   Zhong XB, 2021, INT J COMPUT VISION, V129, P1910, DOI 10.1007/s11263-021-01458-8
   Zhou D, 2022, P IEEE CVF C COMP VI, P19568
   Zhou PH, 2019, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2019.00093
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhuang BH, 2017, IEEE I CONF COMP VIS, P589, DOI 10.1109/ICCV.2017.71
   Zou C, 2021, PROC CVPR IEEE, P11820, DOI 10.1109/CVPR46437.2021.01165
NR 72
TC 5
Z9 5
U1 12
U2 44
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2023
VL 130
AR 104617
DI 10.1016/j.imavis.2022.104617
EA JAN 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 8K9KW
UT WOS:000923412800001
DA 2024-07-18
ER

PT J
AU Yang, ZQ
   Zhang, YQ
   Du, YX
   Tong, C
AF Yang, Zaiquan
   Zhang, Yuqi
   Du, Yuxin
   Tong, Chao
TI Semantic-aligned reinforced attention model for zero-shot learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Zero -shot learning; Semantic alignment; Attributes location; Attention
AB Zero-shot learning (ZSL) aims to recognize unseen images from invisible classes, by transferring semantic knowl-edge from visible classes to invisible classes. Such as, although humans have never seen a zebra, if we know that "a horse with stripes is a zebra", then we can easily recognize it when we see a zebra. Given semantic descrip-tions, the human can capture intrinsic visual clues from different channels or appearance factors (e.g., color, tex-ture) on salient parts. But computers are not smart enough to recognize it with high accuracy, they still need to make progress in the learning of semantic-aligned visual representations. Therefore, we propose a semantic -aligned reinforced attention (SRA) model to improve the attributes localization ability. We aim to discover invari-able features related to class-level semantic attributes from variable intra-class vision information, and thereby avoid misalignment between much visual information and simple semantic representations. Specially, during the localization of spatial attention, we develop an efficient constraint directly on feature map to ensure the intra-attention compactness and inter-attention dispersion characteristics like human gaze. While for the chan-nel, we proposed a novel attributes attention cross entropy loss to exploit the supervision effect of each semantic attribute subset. Experiments on three ZSL benchmarks, i.e., CUB, SUN and AWA2, indicate the competitiveness of our proposed method against the state-of-the-art ZSL methods. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Yang, Zaiquan; Zhang, Yuqi; Du, Yuxin; Tong, Chao] Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.
   [Yang, Zaiquan; Zhang, Yuqi; Du, Yuxin; Tong, Chao] Beihang Univ, Chinas State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.
   [Tong, Chao] Yunnan Key Lab Blockchain Applicat Technol, Kunming, Peoples R China.
C3 Beihang University; Beihang University
RP Tong, C (corresponding author), Beihang Univ, Sch Comp Sci & Engn, Beijing, Peoples R China.; Tong, C (corresponding author), Beihang Univ, Chinas State Key Lab Virtual Real Technol & Syst, Beijing, Peoples R China.; Tong, C (corresponding author), Yunnan Key Lab Blockchain Applicat Technol, Kunming, Peoples R China.
EM tongchao@buaa.edu.cn
RI du, yuxin/IAP-7044-2023
FU National Natural Science Foundation of China [62176016]; National Key
   R&D Program of China [2021YFB2104]; Guizhou Province Science and
   Technology Project: Research and Demonstration of Sci. amp; Tech Big
   Data Mining Technology Based on Knowledge Graph (Qiankehe [2021]
   General) [382]; Yunnan Key Laboratory of Blockchain Application
   Technology [202105AG070005 (YNB202106)]; Teaching Reform Project of
   Beihang University in 2020: Standardized Teaching and Intelligent
   Analysis System Construction for Production Practice
FX This study is partially supported by National Natural Science Foundation
   of China (62176016) , National Key R&D Program of China (No.
   2021YFB2104) , Guizhou Province Science and Technology Project: Research
   and Demonstration of Sci. & Tech Big Data Mining Technology Based on
   Knowledge Graph (supported by Qiankehe [2021] General 382) , Research
   Fund of Yunnan Key Laboratory of Blockchain Application Technology under
   Grant No. 202105AG070005 (YNB202106) , Teaching Reform Project of
   Beihang University in 2020: Standardized Teaching and Intelligent
   Analysis System Construction for Production Practice.
CR Akata Z, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2487986
   Akata Z, 2013, PROC CVPR IEEE, P819, DOI 10.1109/CVPR.2013.111
   [Anonymous], 2013, P NIPS
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chao WL, 2016, LECT NOTES COMPUT SC, V9906, P52, DOI 10.1007/978-3-319-46475-6_4
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen S., 2021, arXiv
   Chen S., 2022, PROC IEEE C COMPUT V, P7612
   Chen S., 2019, IEEE T NEUR NET LEAR
   Chen SM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P122, DOI 10.1109/ICCV48922.2021.00019
   Huynh D, 2020, PROC CVPR IEEE, P4482, DOI 10.1109/CVPR42600.2020.00454
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Ge JN, 2021, AAAI CONF ARTIF INTE, V35, P1406
   Guo-Sen Xie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P562, DOI 10.1007/978-3-030-58548-8_33
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang HJ, 2019, IEEE I CONF COMP VIS, P9764, DOI 10.1109/ICCV.2019.00986
   Karessli N, 2017, PROC CVPR IEEE, P6412, DOI 10.1109/CVPR.2017.679
   Keshari Rohit, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13297, DOI 10.1109/CVPR42600.2020.01331
   Kodirov E., 2017, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P3174
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lin M, 2014, Arxiv, DOI [arXiv:1312.4400, DOI 10.48550/ARXIV.1312.4400]
   Liu Y, P IEEECVF INT C COMP, P6698
   Liu Y, 2021, PROC CVPR IEEE, P3793, DOI 10.1109/CVPR46437.2021.00379
   Shojaee SM, 2016, Arxiv, DOI arXiv:1605.09016
   Morgado P, 2017, PROC CVPR IEEE, P2037, DOI 10.1109/CVPR.2017.220
   Palatucci M. M., 2009, Zero-shot learning with semantic output codes"
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Schonfeld E, P IEEECVF C COMPUTER, P8247
   Shaobo Min, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12661, DOI 10.1109/CVPR42600.2020.01268
   Shigeto Y, 2015, LECT NOTES ARTIF INT, V9284, P135, DOI 10.1007/978-3-319-23528-8_9
   Socher R, 2013, Arxiv, DOI arXiv:1301.3666
   Song J, 2018, PROC CVPR IEEE, P1024, DOI 10.1109/CVPR.2018.00113
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Sylvain T, 2019, INT C LEARNING REPRE
   Vyas Maunil R., 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P70, DOI 10.1007/978-3-030-58577-8_5
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2017, PROC CVPR IEEE, P3077, DOI 10.1109/CVPR.2017.328
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Xie G.-S, P IEEECVF C COMPUTER, P9384
   Xingyu Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P572, DOI 10.1007/978-3-030-58586-0_34
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Xu WJ, 2021, Arxiv, DOI arXiv:2008.08290
   Yang Z., 2022, arXiv
   Ye SQ, 2017, IEEE INT WORKS MACH, DOI 10.1109/TPAMI.2017.2762295
   Yu YL, 2018, ADV NEUR IN, V31
   Yu YL, 2018, IEEE T CYBERNETICS, V48, P2908, DOI 10.1109/TCYB.2017.2751741
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhu YZ, 2019, Arxiv, DOI arXiv:1903.00502
   Zongyan Han, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12862, DOI 10.1109/CVPR42600.2020.01288
NR 54
TC 2
Z9 2
U1 5
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104586
DI 10.1016/j.imavis.2022.104586
EA NOV 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500010
DA 2024-07-18
ER

PT J
AU Cui, ZY
   Lu, N
   Wang, WF
   Guo, GS
AF Cui, Zhiyan
   Lu, Na
   Wang, Weifeng
   Guo, Guangshuai
TI Dual global-aware propagation for few-shot learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Few-shot learning; Label propagation; Global-aware features; Feature
   fusion
AB Few-shot learning remains a challenging problem because it needs to classify unseen categories with only a few samples as limited supervision. The tasks and samples can be extremely different in various few-shot problems, which makes it even more difficult. Due to the local connectivity in CNN, it can not capture the global description of the samples and the features are not discriminative enough from a global viewpoint. Meanwhile, a sample usu-ally reveals similar features in different tasks, which does not consider the global information of the task and weakens the discrimination of features. To address the above issue, we proposed a Dual Global-Aware method for label Propagation (DGAP) to encode two kinds of global description to enhance the discriminative power of the learned features. On the sample level, the global-aware sample module (GSM) is employed to get the contex-tual description and enhance the feature representation capability of each sample. On the task level, the global -aware task module (GTM) is used to embed the features in the current task to a more appropriate and discrim-inative position in the feature space which is task-oriented. In the end, a feature fusion module is adopted to com-bine the features obtained from both global sample and global task respects. Based on the label propagation method, the proposed DGAP improves the performance approximately 2-5% over the baseline on different benchmarks (mini-Imagenet and tiered-Imagenet) across different structures (Conv4 structure and ResNet12 structure), which reaches the state-of-the-art.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Cui, Zhiyan; Lu, Na; Wang, Weifeng; Guo, Guangshuai] Xi An Jiao Tong Univ, Syst Engn Inst, Sch Automat Sci & Engn, Xian, Shaanxi, Peoples R China.
C3 Xi'an Jiaotong University
RP Lu, N (corresponding author), Xi An Jiao Tong Univ, Syst Engn Inst, Sch Automat Sci & Engn, Xian, Shaanxi, Peoples R China.
EM lvna2009@mail.xjtu.edu.cn
RI Lu, Na/KMA-3229-2024
FU National Key R&D Program of China; Science and Technology Project of
   SGCC (State Grid Corporation of China) [2018AAA0101501]
FX This work is supported by National Key R&D Program of China
   2018AAA0101501, Science and Technology Project of SGCC (State Grid
   Corporation of China) : Fundamental Theory of Human-in-the-loop
   Hybrid-Augmented Intelligence for Power Grid Dispatch and Control.
CR Afrasiyabi Arman, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P18, DOI 10.1007/978-3-030-58558-7_2
   Cai Q, 2018, PROC CVPR IEEE, P4080, DOI 10.1109/CVPR.2018.00429
   Chen W.-Y., 2018, INT C LEARNING REPRE
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Cui Z., 2021, APPL INTELL, P1
   Finn C, 2017, PR MACH LEARN RES, V70
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YQ, 2022, ALGORITHMS, V15, DOI 10.3390/a15050147
   Jamal MA, 2019, PROC CVPR IEEE, P11711, DOI 10.1109/CVPR.2019.01199
   Laenen S, EPISODES PROTOTYPICA
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li HY, 2019, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2019.00009
   Liu G, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104164
   Liu Yanbin, 2018, INT C LEARNING REPRE
   Mazumder P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104006
   Ravi S., Optimization as a model for few-shot learning
   Rodriguez Pau, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12371), P121, DOI 10.1007/978-3-030-58574-7_8
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Satorras V.G., 2018, ICLR
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shen Xi, 2021, C NEURAL INFORM PROC
   Simon C, 2020, PROC CVPR IEEE, P4135, DOI 10.1109/CVPR42600.2020.00419
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu ZY, 2019, IEEE I CONF COMP VIS, P6658, DOI 10.1109/ICCV.2019.00676
   Xu C., 2021, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P5182, DOI 10.1109/CVPR46437.2021.00514
   Yaoyao Liu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P404, DOI 10.1007/978-3-030-58517-4_24
   Zhang RX, 2018, ADV NEUR IN, V31
   Zhou DY, 2004, ADV NEUR IN, V16, P321
NR 36
TC 5
Z9 5
U1 4
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104574
DI 10.1016/j.imavis.2022.104574
EA NOV 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500004
DA 2024-07-18
ER

PT J
AU Ma, X
   Ma, YD
AF Ma, Xin
   Ma, Yingdong
TI Relation and context augmentation network for facial expression
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Attention mechanism; Cascaded context
   extraction; Spatial and channel relations
ID FEATURES
AB Facial Expression Recognition (FER) is a challenging task due to the complex properties of human facial expression. Recently, convolutional neural networks (CNNs) have been widely adopted by most FER approaches. However, CNN-models extract features by using convolutional and pooling operations which ignore the relations between pixels and channels. The relations among spatial positions and channels provide crucial information which can be leveraged for facial expression classification. Another important aspect of FER is utilization of global and local contextual information to improve recognition performance. In this work, we present a deep network, the Relation and Context Augmentation Network (RCANet), for facial expression classification. RCANet consists of two relation modules and a context module. The relation modules compute global relations in spatial and channel dimensions. The context module is composed of cascaded context units to capture multi-scale contextual information. Extensive experiments are conducted on two popular in-the-wild FER datasets, including RAF-DB and AffectNet. Experimental results demonstrate that our proposed method achieves 90.15% and 65.65% accuracy rate on the RAF-DB and AffectNet datasets respectively.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Ma, Xin; Ma, Yingdong] Inner Mongolia Univ, Comp Sci Coll, Coll Rd 235, Hohhot 010021, Inner Mongolia, Peoples R China.
C3 Inner Mongolia University
RP Ma, YD (corresponding author), Inner Mongolia Univ, Comp Sci Coll, Coll Rd 235, Hohhot 010021, Inner Mongolia, Peoples R China.
EM csmyd@imu.edu.cn
RI 马, 马颖东/ISA-2042-2023
CR Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Chen YL, 2019, 2019 INTERNATIONAL CONFERENCE ON MICROWAVE AND MILLIMETER WAVE TECHNOLOGY (ICMMT 2019), DOI 10.1109/icmmt45702.2019.8992327
   Deng JK, 2019, Arxiv, DOI [arXiv:1905.00641, DOI 10.48550/ARXIV.1905.00641, 10.48550/ARXIV.1905.00641]
   Ding H, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), DOI 10.1109/ijcb48548.2020.9304923
   EKMAN P, 1994, PSYCHOL BULL, V115, P268, DOI 10.1037/0033-2909.115.2.268
   Farzaneh AH, 2021, IEEE WINT CONF APPL, P2401, DOI 10.1109/WACV48630.2021.00245
   Farzaneh AH, 2020, IEEE COMPUT SOC CONF, P1631, DOI 10.1109/CVPRW50498.2020.00211
   Fu J, 2021, IEEE T NEUR NET LEAR, V32, P2547, DOI 10.1109/TNNLS.2020.3006524
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Fu YJ, 2020, IEEE T IMAGE PROCESS, V29, P6535, DOI 10.1109/TIP.2020.2991510
   He K., 2016, P IEEE C COMP VIS PA, P770, DOI DOI 10.48550/ARXIV.1512.03385
   Hewitt C, 2018, Arxiv, DOI arXiv:1807.08775
   Jeong M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124270
   Killeen T., arXiv
   Kollias D, 2020, INT J COMPUT VISION, V128, P1455, DOI 10.1007/s11263-020-01304-3
   Kuo CM, 2018, IEEE COMPUT SOC CONF, P2202, DOI 10.1109/CVPRW.2018.00286
   Lee J, 2019, IEEE I CONF COMP VIS, P10142, DOI 10.1109/ICCV.2019.01024
   Li H., 2021, MVT: mask vision transformer for facial expression recognition in the wild
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Li Y, 2019, PR MACH LEARN RES, P897
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li Y, 2019, IEEE T IMAGE PROCESS, V28, P2439, DOI 10.1109/TIP.2018.2886767
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu YY, 2021, INFORM SCIENCES, V578, P195, DOI 10.1016/j.ins.2021.07.034
   Ma H, 2019, ELECTRON LETT, V55, P184, DOI 10.1049/el.2018.7871
   Ma YD, 2021, APPL INTELL, V51, P8565, DOI 10.1007/s10489-021-02254-0
   Fernandez PDM, 2019, IEEE COMPUT SOC CONF, P837, DOI 10.1109/CVPRW.2019.00112
   MATSUMOTO D, 1992, MOTIV EMOTION, V16, P363, DOI 10.1007/BF00992972
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Ng PC, 2003, NUCLEIC ACIDS RES, V31, P3812, DOI 10.1093/nar/gkg509
   Ruiz-Garcia A, 2016, LECT NOTES COMPUT SC, V9887, P38, DOI 10.1007/978-3-319-44781-0_5
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shikai Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13981, DOI 10.1109/CVPR42600.2020.01400
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siqueira H, 2020, AAAI CONF ARTIF INTE, V34, P5800
   Verma M, 2020, IEEE T IMAGE PROCESS, V29, P1618, DOI 10.1109/TIP.2019.2912358
   Wang C, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P238, DOI 10.1145/3343031.3350872
   Wang K, 2020, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR42600.2020.00693
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang SC, 2021, NEUROCOMPUTING, V453, P742, DOI 10.1016/j.neucom.2020.07.120
   Wang ZN, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107694
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Zeng JB, 2018, LECT NOTES COMPUT SC, V11217, P227, DOI 10.1007/978-3-030-01261-8_14
   Zhang FF, 2020, IEEE T IMAGE PROCESS, V29, P6574, DOI 10.1109/TIP.2020.2991549
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao ZQ, 2021, AAAI CONF ARTIF INTE, V35, P3510
   Zhao ZQ, 2021, IEEE T IMAGE PROCESS, V30, P6544, DOI 10.1109/TIP.2021.3093397
   Zhi RC, 2011, IEEE T SYST MAN CY B, V41, P38, DOI 10.1109/TSMCB.2010.2044788
NR 51
TC 3
Z9 3
U1 1
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104556
DI 10.1016/j.imavis.2022.104556
EA SEP 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300006
DA 2024-07-18
ER

PT J
AU Fahim, G
   Amin, K
   Zarif, S
AF Fahim, George
   Amin, Khalid
   Zarif, Sameh
TI Enhancing single-view 3D mesh reconstruction with the aid of implicit
   surface learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Geometric deep learning; Single-view reconstruction; Mesh
   reconstruction; Implicit surface reconstruction; Hybrid approach
AB The open and ill-posed problem of single-view 3D object reconstruction has been tackled using different approaches with varying degrees of success. Previous approaches are constrained in the quality of their outputs to the in-network shape representation used. This work proposes to enhance the output of a mesh-based single-view object reconstruction model with the aid of additional implicit surface learning. Specifically, it proposes a two-branch network that learns both explicit and implicit representations in an end-to-end fashion. The explicit branch learns to deform a template spherical mesh and the implicit branch learns to regress to the real signed distance values of an implicit surface function. Practically, the mesh output of the proposed hybrid method is enhanced through a surface matching loss by which it is ensured that the mesh output aligns with the zero-isosurface of the learned implicit function. Experiments show that this hybrid approach results in meshes with a lower surface-to-surface error when compared to meshes produced from the explicit branch alone. The proposed hybrid method also outperforms the state-of-the-art mesh reconstruction methods using different evaluation metrics and compares favorably to prior work incorporating a hybrid approach. It also generalizes well to real-world images despite being trained with synthetic images.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Fahim, George; Amin, Khalid; Zarif, Sameh] Menoufia Univ, Dept Informat Technol, Fac Comp & Informat, Menoufia, Egypt.
   [Fahim, George] Int Acad Engn & Media Sci, Multimedia & Internet Dept, Giza, Egypt.
C3 Egyptian Knowledge Bank (EKB); Menofia University
RP Fahim, G (corresponding author), Int Acad Engn & Media Sci, Multimedia & Internet Dept, Giza, Egypt.
EM george.fahim@iams.edu.eg; k.amin@ci.menofia.edu.eg;
   sameh.shenoda@ci.menofia.edu.eg
RI Fahim, George/AAJ-2350-2021
OI Fahim, George/0000-0002-0426-3532
CR Afifi AJ, 2021, IEEE ACCESS, V9, P110, DOI 10.1109/ACCESS.2020.3046951
   Agarwal N, 2019, 30 BRIT MACH VIS C 2, P164
   Bane C, 2017, INT CONF 3D VISION, P412, DOI 10.1109/3DV.2017.00054
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   Chang A. X., 2015, ARXIV
   Chen W., 2019, P INT C NEUR INF PRO, P9605
   Chen ZQ, 2019, PROC CVPR IEEE, P5932, DOI 10.1109/CVPR.2019.00609
   Chen Z, 2020, PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON GEOGRAPHICAL INFORMATION SYSTEMS THEORY, APPLICATIONS AND MANAGEMENT (GISTAM), P45, DOI 10.5220/0009338800450050
   Choy CB, 2016, LECT NOTES COMPUT SC, V9912, P628, DOI 10.1007/978-3-319-46484-8_38
   Deng BY, 2020, PROC CVPR IEEE, P31, DOI 10.1109/CVPR42600.2020.00011
   Fahim George, 2021, Proceedings of the International Conference on Artificial Intelligence and Computer Vision (AICV2021). Advances in Intelligent Systems and Computing (AISC 1377), P473, DOI 10.1007/978-3-030-76346-6_43
   Fahim G, 2021, COMPUT GRAPH-UK, V94, P164, DOI 10.1016/j.cag.2020.12.004
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Girdhar R, 2016, LECT NOTES COMPUT SC, V9910, P484, DOI 10.1007/978-3-319-46466-4_29
   Gkioxari G, 2019, IEEE I CONF COMP VIS, P9784, DOI 10.1109/ICCV.2019.00988
   Groueix T, 2018, PROC CVPR IEEE, P216, DOI 10.1109/CVPR.2018.00030
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   Kazhdan M., 2006, P 4 EUR S GEOM PROC, P61, DOI DOI 10.2312/SGP/SGP06/061-070
   Kipf Thomas N., 2017, 5 INT C LEARN REPRES
   Liao YY, 2018, PROC CVPR IEEE, P2916, DOI 10.1109/CVPR.2018.00308
   Liu SC, 2019, IEEE I CONF COMP VIS, P7707, DOI 10.1109/ICCV.2019.00780
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Lu Q, 2019, IEEE ACCESS, V7, P137420, DOI 10.1109/ACCESS.2019.2943235
   MANDIKAL P, 2018, ARXIV180707796
   Mescheder L, 2019, PROC CVPR IEEE, P4455, DOI 10.1109/CVPR.2019.00459
   Michalkiewicz M, 2019, IEEE I CONF COMP VIS, P4742, DOI 10.1109/ICCV.2019.00484
   Poursaeed O., 2020, COMPUTER VISION ECCV, V12355, P667, DOI 10.1007/978-3-030- 58607-2 39
   Remelli Edoardo, 2020, ADV NEURAL INFORM PR, V33, P22468
   Smith E., 2019, ARXIV191105063
   Smith EJ, 2019, PR MACH LEARN RES, V97
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Sun R, 2019, IEEE ACCESS, V7, P82206, DOI 10.1109/ACCESS.2019.2923842
   Tatarchenko M, 2017, IEEE I CONF COMP VIS, P2107, DOI 10.1109/ICCV.2017.230
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wu JJ, 2016, ADV NEUR IN, V29
   Xie HZ, 2019, IEEE I CONF COMP VIS, P2690, DOI 10.1109/ICCV.2019.00278
   Xu Q., 2019, Advances in Neural Information Processing Systems (NeurIPS)
   Zubic Nikola, 2021, IFIP ADV INFORM COMM, P309
NR 39
TC 7
Z9 8
U1 2
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104377
DI 10.1016/j.imavis.2022.104377
EA JAN 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400006
DA 2024-07-18
ER

PT J
AU Yao, CL
   Feng, L
   Kong, YQ
   Li, SM
   Li, H
AF Yao, Cuili
   Feng, Lin
   Kong, Yuqiu
   Li, Shengming
   Li, Hang
TI Double cross-modality progressively guided network for RGB-D salient
   object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RGB-D; Salient object detection; Cross-modality; Attention mechanism;
   Integration
ID FUSION
AB With the advent of depth sensors, the use of RGB and depth(D) information for salient object detection (SOD) has been explored extensively in recent years. However, the depth quality from the different scenes usually varies, leading to fusing and achieving complementary between RGB and low-quality depth is stilla challenging prob-lem. In this paper, we first design a Double Dilated Merge Module (DDMM) to extract comprehensive and ben-eficial high-level cross-modality features and explore further global context information at multi-scales to obtain a coarse saliency map. Then, we propose a Cross-Modality Enhance Module (CMEM) to enhance cross-modality features compatibility and fuse them with the previous predicted coarse saliency map to generate a more accu-rate saliency map. Furthermore, we introduce a Distribution-Region Combination Loss (DRcom Loss) to optimize our proposed Double Cross-Modality Progressively Guided Network (DCPGNet) in a coarse-to-fine manner. DCPGNet achieves satisfactory performance on five public benchmarks compared with recent state-of-the-art algorithms. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Yao, Cuili; Feng, Lin; Li, Shengming; Li, Hang] Dalian Univ Technol, Sch Comp Sci & Technol, Dalian 116024, Peoples R China.
   [Yao, Cuili; Kong, Yuqiu; Li, Shengming] Dalian Univ Technol, Minist Educ, Key Lab Intelligent Control & Optimizat Ind Equip, Dalian 116024, Peoples R China.
   [Yao, Cuili; Feng, Lin; Kong, Yuqiu; Li, Shengming; Li, Hang] Dalian Univ Technol, Sch Innovat & Entrepreneurship, Dalian 116024, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology; Dalian
   University of Technology
RP Feng, L (corresponding author), Dalian Univ Technol, Sch Innovat & Entrepreneurship, Dalian 116024, Peoples R China.
EM yaocuili1984@dlut.edu.cn; fenglin@dlut.edu.cn; yqkong@dlut.edu.cn;
   lishengming@dlut.edu.cn; lihang@dlut.edu.cn
OI Yao, Cuili/0000-0002-6998-842X
FU Fundamental Research Funds for the Central Universities [DUT20LAB115,
   DUT19RC (3) 040]; LiaoNing Revi-talization Talents Program
   [XLYC1806006]; National Natural Science Foundation of China [61672130,
   61972064]
FX Acknowledgments This work is supported by the Fundamental Research Funds
   for the Central Universities (DUT20LAB115, DUT19RC (3) 040) , LiaoNing
   Revi-talization Talents Program (XLYC1806006) , and the National Natural
   Science Foundation of China (61672130, 61972064) .
CR Chen CLZ, 2021, IEEE T IMAGE PROCESS, V30, P2350, DOI 10.1109/TIP.2021.3052069
   Chen CLZ, 2020, IEEE T IMAGE PROCESS, V29, P4296, DOI 10.1109/TIP.2020.2968250
   Chen H, 2019, IEEE T IMAGE PROCESS, V28, P2825, DOI 10.1109/TIP.2019.2891104
   Chen H, 2020, IEEE T IMAGE PROCESS, V29, P8407, DOI 10.1109/TIP.2020.3014734
   Chen H, 2018, IEEE INT C INT ROBOT, P6821, DOI 10.1109/IROS.2018.8594373
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen H, 2019, PATTERN RECOGN, V86, P376, DOI 10.1016/j.patcog.2018.08.007
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cong RM, 2020, IEEE T CYBERNETICS, V50, P3627, DOI 10.1109/TCYB.2019.2932005
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2021, IEEE T NEUR NET LEAR, V32, P2075, DOI 10.1109/TNNLS.2020.2996406
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fu KR, 2020, PROC CVPR IEEE, P3049, DOI 10.1109/CVPR42600.2020.00312
   Han JW, 2018, IEEE T CYBERNETICS, V48, P3171, DOI 10.1109/TCYB.2017.2761775
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Jiang B, 2021, IEEE T MULTIMEDIA, V23, P1343, DOI 10.1109/TMM.2020.2997184
   Ju R, 2014, IEEE IMAGE PROC, P1115, DOI 10.1109/ICIP.2014.7025222
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Nian Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13753, DOI 10.1109/CVPR42600.2020.01377
   Niu YZ, 2012, PROC CVPR IEEE, P454, DOI 10.1109/CVPR.2012.6247708
   Pan L, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103964
   Paszke A., 2017, arXiv
   Peng HW, 2014, LECT NOTES COMPUT SC, V8691, P92, DOI 10.1007/978-3-319-10578-9_7
   Piao YR, 2019, IEEE I CONF COMP VIS, P7253, DOI 10.1109/ICCV.2019.00735
   Qin XB, 2018, IEEE WINT CONF APPL, P1804, DOI 10.1109/WACV.2018.00200
   Qu LQ, 2017, IEEE T IMAGE PROCESS, V26, P2274, DOI 10.1109/TIP.2017.2682981
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wang NN, 2019, IEEE ACCESS, V7, P55277, DOI 10.1109/ACCESS.2019.2913107
   Wang XH, 2021, IEEE T IMAGE PROCESS, V30, P458, DOI 10.1109/TIP.2020.3037470
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908
   Youwei Pang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P235, DOI 10.1007/978-3-030-58595-2_15
   Yu Y., 2014, J. Image Graph., V2, P151, DOI DOI 10.12720/JOIG.2.2.151-157
   Zhang J., 2021, IEEE T PATT ANAL MAC, P1
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhang Z, 2021, IEEE T IMAGE PROCESS, V30, P1949, DOI 10.1109/TIP.2021.3049959
   Zhao JX, 2019, PROC CVPR IEEE, P3922, DOI 10.1109/CVPR.2019.00405
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhou T, 2021, COMPUT VIS MEDIA, V7, P37, DOI 10.1007/s41095-020-0199-z
   Zhou XF, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103888
   Zhu C., 2021, IEEE T PATT ANAL MAC, P1
   Zhu CB, 2019, IEEE INT CON MULTI, P199, DOI 10.1109/ICME.2019.00042
   Zhu CB, 2017, IEEE INT CONF COMP V, P3008, DOI 10.1109/ICCVW.2017.355
NR 50
TC 6
Z9 6
U1 2
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104351
DI 10.1016/j.imavis.2021.104351
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4VF
UT WOS:000772585200005
DA 2024-07-18
ER

PT J
AU Sundaresan, V
   Shanthi, SA
AF Sundaresan, Vinusha
   Shanthi, S. Amala
TI Monozygotic twin face recognition: An in-depth analysis and plausible
   improvements
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Monozygotic twins; Face recognition systems; Biometrics
ID ACTIVE SHAPE MODELS; IDENTICAL-TWINS
AB Monozygotic twins, commonly known as identical twins, share extreme facial resemblance that they deceive the majority of the prevailing face recognition systems. Hence, the facial recognition systems, which are turning out to be exploited in almost all real-life biometric authentication-needing applications, require significant upgradation to cope with this great challenge. This paper pays special attention towards categorizing and investigating the existing research on the facial recognition of monozygotic twins in an exhaustive sense. Subsequently, the research gap is analyzed. It is then followed by the description of the possible refinements, like the choice of feature and other methodological advancements, which may aid in augmenting the twin recognition accuracy of the face recognition systems. It is believed that the outcomes of the review can well-support and pave the way for further research in the future. Consequently, the "Double Trouble" posed on the commercial face recognition systems can be effectively evaded. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Sundaresan, Vinusha; Shanthi, S. Amala] Noorul Islam Ctr Higher Educ, Elect & Commun Engn, Thuckalay 629180, Tamil Nadu, India.
RP Sundaresan, V (corresponding author), Noorul Islam Ctr Higher Educ, Elect & Commun Engn, Thuckalay 629180, Tamil Nadu, India.
EM s.vinu89@gmail.com
RI Shanthi, Amala/AAT-1271-2020
OI Shanthi, Amala/0000-0001-8619-2792
CR Afaneh A, 2017, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-017-0231-0
   Ahmad B, 2019, IEEE GLOBE WORK, DOI 10.1109/gcwkshps45667.2019.9024704
   Akhtar Z, 2017, COMPUTER, V50, P80, DOI 10.1109/MC.2017.119
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2737538
   Behaine CAR, 2012, IEEE T INSTRUM MEAS, V61, P2330, DOI 10.1109/TIM.2012.2188174
   Biswas S., 2011, Proc. IEEE International Workshop on Information Forensics and Security (WIFS), P1, DOI DOI 10.1109/WIFS.2011.6123126
   Bowyer KW, 2011, COMPUTER, V44, P100, DOI 10.1109/MC.2011.221
   Chakraborty S, 2018, IEEE T CIRC SYST VID, V28, P171, DOI 10.1109/TCSVT.2016.2603535
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Devi CN, 2017, 2017 FOURTH INTERNATIONAL CONFERENCE ON SIGNAL PROCESSING, COMMUNICATION AND NETWORKING (ICSCN)
   Gautam G, 2021, APPL INTELL, V51, P1, DOI 10.1007/s10489-019-01562-w
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Hermosilla G, 2018, IEEE ACCESS, V6, P42800, DOI 10.1109/ACCESS.2018.2850281
   Jain AK, 2002, PATTERN RECOGN, V35, P2653, DOI 10.1016/S0031-3203(01)00218-7
   Juefei-Xu F, 2013, IEEE COMPUT SOC CONF, P56, DOI 10.1109/CVPRW.2013.16
   Kar A, 2021, IEEE T INF FOREN SEC, V16, P495, DOI 10.1109/TIFS.2020.3015552
   Khalid F, 2020, IEEE ACCESS, V8, P129774, DOI 10.1109/ACCESS.2020.3008952
   Klare B., 2011, 2011 INT JOINT C BIO, P1, DOI DOI 10.1109/IJCB.2011.6117548
   Kong AWK, 2006, PATTERN RECOGN, V39, P2149, DOI 10.1016/j.patcog.2006.04.035
   Kumar A, 2019, ARTIF INTELL REV, V52, P927, DOI 10.1007/s10462-018-9650-2
   Le THN, 2015, PATTERN RECOGN, V48, P3843, DOI 10.1016/j.patcog.2015.05.021
   Li P, 2019, IEEE T INF FOREN SEC, V14, P2000, DOI 10.1109/TIFS.2018.2890812
   Li S.Z., 2021, HDB FACE RECOGNITION, V2005
   Liu X., 2020, IEEE SENSORS J
   Mahmood A, 2018, IEEE ACCESS, V6, P12993, DOI 10.1109/ACCESS.2018.2794357
   Nejati H, 2012, INT C PATT RECOG, P1201
   Oloyede MO, 2018, IEEE ACCESS, V6, P75181, DOI 10.1109/ACCESS.2018.2883748
   Paone JR, 2014, IEEE T INF FOREN SEC, V9, P285, DOI 10.1109/TIFS.2013.2296373
   Park U, 2010, IEEE T INF FOREN SEC, V5, P406, DOI 10.1109/TIFS.2010.2049842
   Phillips P. J., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P185, DOI 10.1109/FG.2011.5771395
   Prema R., 2017 INT C EN COMM D, P5093
   Pruitt M.T., 2011, IJCB, P1, DOI [DOI 10.1109/IJCB.2011.6117476, 10.1109/IJCB.2011.6117476]
   Ricanek K, 2013, COMPUTER, V46, P94, DOI 10.1109/MC.2013.82
   Sabatier SB, 2019, MEASUREMENT, V134, P385, DOI 10.1016/j.measurement.2018.10.057
   Seshadri K, 2012, IEEE T INF FOREN SEC, V7, P1255, DOI 10.1109/TIFS.2012.2195175
   Sreedharan NPN, 2018, IET BIOMETRICS, V7, P490, DOI 10.1049/iet-bmt.2017.0160
   Srinivas N, 2012, IEEE T INF FOREN SEC, V7, P1536, DOI 10.1109/TIFS.2012.2206027
   Sun JD, 2020, IEEE ACCESS, V8, P35777, DOI 10.1109/ACCESS.2020.2975312
   Sun ZN, 2010, PROC SPIE, V7667, DOI 10.1117/12.851369
   Toygar O, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12389
   Toygar Ö, 2018, SIGNAL IMAGE VIDEO P, V12, P1157, DOI 10.1007/s11760-018-1263-3
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang HT, 2004, IEEE IMAGE PROC, P1397
   Zeng X, 2018, IEEE T CYBERNETICS, V48, P716, DOI 10.1109/TCYB.2017.2655027
   Zhang ML, 2021, IEEE T MULTIMEDIA, V23, P1938, DOI 10.1109/TMM.2020.3006414
   Zhang WM, 2019, IEEE T PATTERN ANAL, V41, P611, DOI 10.1109/TPAMI.2018.2803179
   Zulfiqar M, 2019, 2019 International Conference on Electrical, Communication, and Computer Engineering (ICECCE), P1
NR 48
TC 1
Z9 1
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104331
DI 10.1016/j.imavis.2021.104331
EA NOV 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WZ2LF
UT WOS:000719802700006
DA 2024-07-18
ER

PT J
AU Baleghi, Y
   Rousseau, D
AF Baleghi, Yasser
   Rousseau, David
TI An analytical proof on suitability of Cauchy-Schwarz Divergence as the
   aggregation criterion in Region Growing Algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Region Growing Algorithm; Image segmentation; Cauchy-Schwarz divergence;
   Aggregation criterion
ID IMAGE SEGMENTATION
AB Region Growing Algorithm (RGA) isa popular, fast and strongly formed object segmentation method. In RGA, the region is grown from the seed points to adjacent points depending on an aggregation criterion. Despite the huge literature on RGA, none of the proposed aggregation criteria have been analytically proved to be suitable for an ideal segmentation. In this paper, Cauchy-Schwarz Divergence (CSD) is proved to be suitable as an aggregation criterion in RGA for object segmentation. First, RGA is formulated in this context. The Cauchy-Schwarz-based cri-terion is proposed here in the continuous case for a bimodal image that contains one object in the background while both regions are normally distributed with different parameters (while the assumption of normal distribu-tion of object and background has been used by many researchers in minimum error thresholding method). Then, a proof is given that in the mentioned formulated case, the proposed RGA will lead to an ideal segmenta-tion. The case is also investigated while object and background have heavy-tail distributions like generalized Gaussian function when beta < 2. While all formulations and proofs are given in the continuous case, the segmen-tation results in the discrete case are shown to be good. Comparison of these results with the outcomes of RGA with traditional aggregation criteria, shows how analytical justifications can suggest a better criterion. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Baleghi, Yasser] Babol Noshirvani Univ Technol, Dept Elect & Comp Engn, Shariati St, Babol, Iran.
   [Rousseau, David] Univ Angers, UMR INRAE IRHS, LARIS, 62 Ave Notre Dame Lac, F-49000 Angers, France.
C3 Babol Noshirvani University of Technology; Universite d'Angers; INRAE
RP Baleghi, Y (corresponding author), Babol Noshirvani Univ Technol, Dept Elect & Comp Engn, Shariati St, Babol, Iran.
EM y.baleghi@nit.ac.ir
OI baleghi, yasser/0000-0002-2882-4613
FU Babol Noshirvani University of Technology [BNUT/370123/99]; French
   embassy in Iran; Campus France [959918E]
FX This work was conducted during a sabbatical supported by Babol
   Noshirvani University of Technology under Grant No. BNUT/370123/99 and a
   simultaneous post-doctoral Grant by French embassy in Iran that was paid
   by Campus France under file No. 959918E. The authors would also like to
   thank Dr. Pejamn Rasti for his support.
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   Adler RJ, 1998, PRACTICAL GUIDE TO HEAVY TAILS, P133
   Ahn S, 2015, IEEE SIGNAL PROC LET, V22, P275, DOI 10.1109/LSP.2014.2357792
   Bama S, 2021, MATER TODAY-PROC, V45, P1726, DOI 10.1016/j.matpr.2020.08.618
   Bannari A., 1995, Remote Sens. Rev., V13, P95, DOI [DOI 10.1080/02757259509532298, 10.1080/02757259509532298]
   Bhattacharyya Anil, 1943, B CALCUTTA MATH SOC, V35, P99
   Bouhlel N, 2019, IEEE SIGNAL PROC LET, V26, P1021, DOI 10.1109/LSP.2019.2915000
   Cheng Z, 2020, POWDER TECHNOL, V368, P80, DOI 10.1016/j.powtec.2020.04.032
   COLEMAN GB, 1979, P IEEE, V67, P773, DOI 10.1109/PROC.1979.11327
   Gonzales R.C., 2002, Digital image processing
   Gostar AK, 2017, IEEE SIGNAL PROC LET, V24, P1313, DOI 10.1109/LSP.2017.2723924
   Goudail F, 2004, J OPT SOC AM A, V21, P1231, DOI 10.1364/JOSAA.21.001231
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   Jenssen R, 2006, J FRANKLIN I, V343, P614, DOI 10.1016/j.jfranklin.2006.03.018
   Jothiaruna N, 2019, COMPUT ELECTRON AGR, V165, DOI 10.1016/j.compag.2019.104934
   Kampa K, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2578, DOI 10.1109/IJCNN.2011.6033555
   Katatbeh QD, 2015, ENTROPY-SWITZ, V17, P7996, DOI 10.3390/e17127858
   Li Y, 2012, APPL MATH COMPUT, V219, P3083, DOI 10.1016/j.amc.2012.09.038
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Mohammed MA, 2017, J COMPUT SCI-NETH, V20, P61, DOI 10.1016/j.jocs.2017.03.009
   Nielsen F, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21050485
   Nikbakhsh N, 2019, COMPUT ELECTRON AGR, V162, P440, DOI 10.1016/j.compag.2019.04.038
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Paiva PVV, 2020, PATTERN RECOGN LETT, V135, P114, DOI 10.1016/j.patrec.2020.04.010
   Rami H, 2016, SIGNAL PROCESS-IMAGE, V42, P45, DOI 10.1016/j.image.2016.01.005
   Refregier P., 2013, STAT IMAGE PROCESSIN
   Refregier P, 2004, NOISE THEORY APPL PH
   Rosea JL, 2010, EUR SIGNAL PR CONF, P1781
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   Shrivastava N, 2020, INT J IMAGE GRAPH, V20, DOI 10.1142/S0219467820500187
   Soltani-Nabipour J, 2020, NUCL ENG TECHNOL, V52, P2313, DOI 10.1016/j.net.2020.03.011
   Sun G, 2020, COMPUT METH PROG BIO, V190, DOI 10.1016/j.cmpb.2020.105340
   Tamal M, 2019, HELIYON, V5, DOI 10.1016/j.heliyon.2019.e02993
   Tiwari A, 2020, PATTERN RECOGN LETT, V131, P244, DOI 10.1016/j.patrec.2019.11.020
   Wang P, 2021, PATTERN RECOGN LETT, V141, P61, DOI 10.1016/j.patrec.2020.07.042
   Wang Y, 2017, PATTERN RECOGN LETT, V96, P66, DOI 10.1016/j.patrec.2016.09.014
   Xin Q, 2011, MATH COMPUT SIMULAT, V81, P2608, DOI 10.1016/j.matcom.2011.04.005
   Yao GL, 2019, PATTERN RECOGN LETT, V118, P14, DOI 10.1016/j.patrec.2018.05.018
   Zhang SQ, 2015, J INF SCI ENG, V31, P1185
   Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7
NR 40
TC 1
Z9 1
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104312
DI 10.1016/j.imavis.2021.104312
EA SEP 2021
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WB1NI
UT WOS:000703345700006
DA 2024-07-18
ER

PT J
AU Mansour, RF
   Escorcia-Gutierrez, J
   Gamarra, M
   Villanueva, JA
   Leal, N
AF Mansour, Romany F.
   Escorcia-Gutierrez, Jose
   Gamarra, Margarita
   Villanueva, Jair A.
   Leal, Nallig
TI Intelligent video anomaly detection and classification using faster RCNN
   with deep reinforcement learning model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video surveillance; Intelligent systems; Anomaly detection; Deep
   reinforcement learning; UCSD dataset
AB Recently, intelligent video surveillance applications have become essential in public security by the use of com-puter vision technologies to investigate and understand long video streams. Anomaly detection and classification are considered a major element of intelligent video surveillance. The aim of anomaly detection is to automatically determine the existence of abnormalities in a short time period. Deep reinforcement learning (DRL) techniques can be employed for anomaly detection, which integrates the concepts of reinforcement learning and deep learn-ing enabling the artificial agents in learning the knowledge and experience from actual data directly. With this motivation, this paper presents an Intelligent Video Anomaly Detection and Classification using Faster RCNN with Deep Reinforcement Learning Model, called IVADC-FDRL model. The presented IVADC-FDRL model operates on two major stages namely anomaly detection and classification. Firstly, Faster RCNN model is applied as an ob-ject detector with Residual Network as a baseline model, which detects the anomalies as objects. Besides, deep Q-learning (DQL) based DRL model is employed for the classification of detected anomalies. In order to validate the effective anomaly detection and classification performance of the IVADC-FDRL model, an extensive set of exper-imentations were carried out on the benchmark UCSD anomaly dataset. The experimental results showcased the better performance of the IVADC-FDRL model over the other compared methods with the maximum accuracy of 98.50% and 94.80% on the applied Test004 and Test007 dataset respectively. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Mansour, Romany F.] New Valley Univ, Fac Sci, Dept Math, El Kharga 72511, Egypt.
   [Escorcia-Gutierrez, Jose] Univ Autonoma Caribe, Elect & Telecommun Engn Program, Barranquilla 08001, Colombia.
   [Gamarra, Margarita] Univ Costa, Dept Computat Sci & Elect, CUC, Barranquilla 08001, Colombia.
   [Villanueva, Jair A.] Univ Autonoma Caribe, Mechatron Engn Program, Barranquilla 08001, Colombia.
   [Leal, Nallig] Univ Autonoma Caribe, Comp Sci Dept, Barranquilla 08001, Colombia.
C3 Universidad de la Costa
RP Mansour, RF (corresponding author), New Valley Univ, Fac Sci, Dept Math, El Kharga 72511, Egypt.
EM romanyf@sci.nvu.edu.eg; jose.escorcia47@uac.edu.co;
   mgamarra3@cuc.edu.co; jair.villanueva94@uac.edu.co; nleal@uac.edu.co
RI Escorcia-Gutierrez, José/AEU-3814-2022; Escorcia-Gutierrez,
   Jose/AAU-4212-2021; Mansour, Romany F./AAB-6085-2021; Gamarra,
   Margarita/AAZ-8674-2021; Gamarra, Margarita/AAW-3533-2021
OI Escorcia-Gutierrez, José/0000-0003-0518-3187; Escorcia-Gutierrez,
   Jose/0000-0003-0518-3187; Mansour, Romany F./0000-0001-5857-8495;
   Gamarra, Margarita/0000-0003-1834-2984; Gamarra,
   Margarita/0000-0003-1834-2984
CR Alam A, 2020, INT CONF BIG DATA, P28, DOI 10.1109/BigComp48618.2020.0-103
   [Anonymous], 2015, BMVC
   [Anonymous], 2017, WACV
   Bellver M., 2016, P C NEUR INF PROC SY, P5
   Ding Y, 2019, ADV ENG INFORM, V42, DOI 10.1016/j.aei.2019.100977
   Fan YX, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102920
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hinami R, 2017, IEEE I CONF COMP VIS, P3639, DOI 10.1109/ICCV.2017.391
   Ionescu RT, 2019, PROC CVPR IEEE, P7834, DOI 10.1109/CVPR.2019.00803
   Kong XY, 2017, PROC CVPR IEEE, P7072, DOI 10.1109/CVPR.2017.748
   Lakshmanaprabu SK, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105487
   Lei XS, 2019, MEASUREMENT, V138, P379, DOI 10.1016/j.measurement.2019.01.072
   Liu S., ISPRS INT J GEO-INF, V10, P170
   Liu ST, 2020, IEEE T NEUR NET LEAR, V31, P2544, DOI 10.1109/TNNLS.2019.2933451
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Micheal AA, 2019, J SUPERCOMPUT, V75, P4986, DOI 10.1007/s11227-019-02782-0
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Murugan BS, 2019, COMPUT ELECTR ENG, V75, P146, DOI 10.1016/j.compeleceng.2019.02.017
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sabokrou M, 2016, ELECTRON LETT, V52, P1122, DOI 10.1049/el.2016.0440
   Sabokrou M, 2018, COMPUT VIS IMAGE UND, V172, P88, DOI 10.1016/j.cviu.2018.02.006
   Uthayakumar J., 2020, Information Systems and e-Business Management, V18, P617, DOI 10.1007/s10257-018-0388-9
   Uzkent B, 2020, IEEE WINT CONF APPL, P1813, DOI 10.1109/WACV45572.2020.9093447
   Veluchamy S, 2021, COMPUT J, V64, P1886, DOI 10.1093/comjnl/bxab002
   Zhang XF, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107394
NR 25
TC 69
Z9 76
U1 5
U2 58
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104229
DI 10.1016/j.imavis.2021.104229
EA JUN 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100009
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Jia, FW
   Wang, X
   Guan, J
   Li, HL
   Qiu, C
   Qi, SH
AF Jia, Fengwei
   Wang, Xuan
   Guan, Jian
   Li, Huale
   Qiu, Chen
   Qi, Shuhan
TI ARank: Toward specific model pruning via advantage rank for multiple
   salient objects detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Model compression; Model pruning; Salient object detection; Multiple
   salient object detection; Computer vision
AB Pruning unnecessary regions from weight kernels and filters used in convolutional nerual networks has proven to be effective for model compression. However, prior studies have often over-optimized for generic application areas, which are not ideal for specific problems in salient object detection. In this study, a novel pruning strategy denoted advantage rank (ARank) is developed for multiple salient object detection (Mul-SOD), in which salient priority criterion (SPC) is used to evaluate parameter contributions. The proposed SPC is a measurable standard for object priority that can be quantified and calculated using ARank. Simulation experiments demonstrate that Mul-SOD can be optimized by removing interference from low-SPC parameters. ARank effectively decreased interference and distinguished high-priority salient objects from multiple background objects.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Jia, Fengwei; Wang, Xuan; Li, Huale; Qiu, Chen; Qi, Shuhan] Harbin Inst Technol, Comp Applicat Res Ctr, Shenzhen 518055, Peoples R China.
   [Guan, Jian] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin 155100, Peoples R China.
C3 Harbin Institute of Technology; Harbin Engineering University
RP Qi, SH (corresponding author), Harbin Inst Technol, Comp Applicat Res Ctr, Shenzhen 518055, Peoples R China.
EM qishuhanhit@foxmail.com
FU National Key-Research and Development Program of China [2020YFB2104003];
   National Natural Science Foundation of China [61902093]; Natural Science
   Foundation of Guangdong [2020A1515010652]; Shenzhen Foundational
   Research Fund [JCYJ20180306171938767]; PINGAN-HITsz Intelligence Finance
   Research Center [YH-OAS-TICS2020-00101]; Ricoh-HITsz Joint Research
   Center [HX20190061]
FX This research was funded by National Key-Research and Development
   Program of China (No.2020YFB2104003), National Natural Science
   Foundation of China (No.61902093), Natural Science Foundation of
   Guangdong (No.2020A1515010652), Shenzhen Foundational Research Funding
   Under Grant (No.JCYJ20180306171938767), PINGAN-HITsz Intelligence
   Finance Research Center (YH-OAS-TICS2020-00101), Ricoh-HITsz Joint
   Research Center (No.HX20190061).
CR [Anonymous], 2016, INT C LEARNING REPRE
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Chen TY, 2004, LECT NOTES COMPUT SC, V3321, P320
   Cheng J, 2018, FRONT INFORM TECH EL, V19, P64, DOI 10.1631/FITEE.1700789
   Einhäuser W, 2003, EUR J NEUROSCI, V17, P1089, DOI 10.1046/j.1460-9568.2003.02508.x
   Erhan Dumitru, 2009, 01 U MONTRAAL
   Fan D.P., 2018, IJCAI
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Gao Zhiyong, 2019, IEEE INT S BROADBAND, P1
   Ghosh S, 2019, IEEE IMAGE PROC, P3915, DOI [10.1109/icip.2019.8803505, 10.1109/ICIP.2019.8803505]
   Gong XP, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103973
   He J, 2020, NEUROCOMPUTING, V390, P248, DOI 10.1016/j.neucom.2019.07.103
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Huang Q, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.11.006
   Ignatov A, 2020, IEEE COMPUT SOC CONF, P1676, DOI 10.1109/CVPRW50498.2020.00217
   Islam MA, 2018, PROC CVPR IEEE, P7142, DOI 10.1109/CVPR.2018.00746
   Islam Md Amirul, 2020, ARXIV200108248
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kalash Mahmoud, 2018, ARXIV181002426
   Kaveti Pushyami, 2020, ARXIV2003
   Kingma D. P., 2014, arXiv
   Kotseruba Iuliia, 2020, ARXIV200506583
   Lee N., 2019, ARXIV190606307
   Li DW, 2018, AAAI CONF ARTIF INTE, P2322
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liebenwein L., 2019, ARXIV191107412
   Lin MB, 2020, PROC CVPR IEEE, P1526, DOI 10.1109/CVPR42600.2020.00160
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mo Sangwoo, 2020, ARXIV200204809
   Molchanov Pavlo, 2019, P IEEE C COMP VIS PA
   Parra-Arnau J, 2017, INFORM SCIENCES, V385, P96, DOI 10.1016/j.ins.2016.12.036
   Paszke A, 2019, ADV NEUR IN, V32
   Pavlo M., 2016, ARXIV161106440
   Rao YT, 2020, INT J PATTERN RECOGN, V34, DOI 10.1142/S0218001420540130
   Rueda FM, 2017, LECT NOTES COMPUT SC, V10496, P177, DOI 10.1007/978-3-319-66709-6_15
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shih KH, 2019, INT CONF ACOUST SPEE, P1398, DOI [10.1109/ICASSP.2019.8683842, 10.1109/icassp.2019.8683842]
   Shu H, 2019, IEEE I CONF COMP VIS, P3234, DOI 10.1109/ICCV.2019.00333
   Simonyan K., 2014, 14091556 ARXIV
   Singh P, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.103857
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Ting-Wu Chin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P1515, DOI 10.1109/CVPR42600.2020.00159
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Wang W., 2019, ARXIV190409146
   Xie Zihao, 2020, NEUROCOMPUTING
   Xu QZ, 2019, IMAGE VISION COMPUT, V87, P1, DOI 10.1016/j.imavis.2019.04.002
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001
   Yildirim Gokhan, 2020, ARXIV200308514
   Zeiler M.D., European conference on computer vision, P818
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
NR 58
TC 3
Z9 3
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104192
DI 10.1016/j.imavis.2021.104192
EA MAY 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700006
DA 2024-07-18
ER

PT J
AU Shen, ZW
   Wu, XJ
   Kittler, J
AF Shen, Zhongwei
   Wu, Xiao-Jun
   Kittler, Josef
TI 2D progressive fusion module for action recognition*
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convergence; spatiotemporal modeling; 2D CNN; action recognition
AB Network convergence as well as recognition accuracy are essential issues when applying Convolutional Neural Networks (CNN) to human action recognition. Most deep learning methods neglect model convergence when striving to improve the abstraction capability, thus degrading the performances sharply when computing resources are limited. To mitigate this problem, we propose a structure named 2D Progressive Fusion (2DPF) Module which is inserted after the 2D backbone CNN layers. 2DPF fuses features through a novel 2D convolution on the spatial and temporal dimensions called variation attenuating convolution and applies fusion techniques to improve the recognition accuracy and the convergency. Our experiments performed on several benchmarks (e.g., Something-Something V1&V2, Kinetics400 & 600, AViD, UCF101) demonstrate the effectiveness of the proposed method. ARTICLE INFO.
   (c) 2021 Published by Elsevier B.V.
C1 [Shen, Zhongwei; Wu, Xiao-Jun] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
   [Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
C3 Jiangnan University; University of Surrey
RP Wu, XJ (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
EM shenzw_cv@163.com; wu_xiaojun@jiangnan.edu.cn; j.kittler@surrey.ac.uk
RI Shen, Zhongwei/KDP-0210-2024
FU National Natural Science Foundation of China [U1836218, 61672265,
   61902153]; 111 Project of Ministry of Education of China [B12018]; EPSRC
   Programme Grant (FACER2VM) [EP/N007743/1]; EPSRC/MURI/Dstl project
   [EP/R013616/1]
FX This work was supported in part by the National Natural Science
   Foundation of China (U1836218, 61672265, 61902153) , the 111 Project of
   Ministry of Education of China (B12018) , the EPSRC Programme Grant
   (FACER2VM) EP/N007743/1 and the EPSRC/MURI/Dstl project under Grant
   EP/R013616/1.
CR [Anonymous], 2017, ABS170805038 CORR
   [Anonymous], 2019, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2019.00369
   [Anonymous], 2019, IEEE INT C COMP VIS
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Du WB, 2017, IEEE I CONF COMP VIS, P3745, DOI 10.1109/ICCV.2017.402
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Gammulle H., 2019, ARXIV191207148
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   He DL, 2019, AAAI CONF ARTIF INTE, P8401
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GL, 2017, IEEE ICC
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., 2017, CORR ABS170506950
   Kim TS, 2017, IEEE COMPUT SOC CONF, P1623, DOI 10.1109/CVPRW.2017.207
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lea C, 2017, PROC CVPR IEEE, P1003, DOI 10.1109/CVPR.2017.113
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H, 2020, IEEE T IMAGE PROCESS, V29, P4733, DOI 10.1109/TIP.2020.2975984
   Liu ZY, 2020, AAAI CONF ARTIF INTE, V34, P11669
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Piergiovanni AJ, 2020, ADV NEURAL INFORM PR
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Simonyan K, 2014, ADV NEUR IN, V27
   Soomro K., 2012, ARXIV12120402CS
   Sun SY, 2018, PROC CVPR IEEE, P1390, DOI 10.1109/CVPR.2018.00151
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang H, 2020, PROC CVPR IEEE, P349, DOI 10.1109/CVPR42600.2020.00043
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Weinzaepfel P, 2013, IEEE I CONF COMP VIS, P1385, DOI 10.1109/ICCV.2013.175
   Wu JC, 2019, PROC CVPR IEEE, P9956, DOI 10.1109/CVPR.2019.01020
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Xu TY, 2020, IEEE T CIRC SYST VID, V30, P3727, DOI 10.1109/TCSVT.2019.2945068
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
NR 45
TC 5
Z9 5
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104122
DI 10.1016/j.imavis.2021.104122
EA MAR 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600006
DA 2024-07-18
ER

PT J
AU Al-Makhadmeh, Z
   Tolba, A
AF Al-Makhadmeh, Zafer
   Tolba, Amr
TI Dependable information processing method for reliable human-robot
   interactions in smart city applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Attribute categorization; Human-robot interaction; Information
   processing; K-means clustering; Smart city
ID COLLABORATION
AB Human-robot interaction (HRI) is a multidisciplinary area that consists of several technologies that are used to create various smart city applications. The knowledge gain and analysis of the smart city environment improves response time. This paper introduces the dependable information processing (DIP) method for handling multi attribute environmental information in a smart city application. Information sensed from the environment is categorized in the initial stage regarding how it meets application requirements. It helps to identify the need and response of the application through different interacting spans and previous trials. For attribute categorization and span validation, learning via K-means clustering is exploited to identify similar and dissimilar information attributes. This identification speeds up the process of successive responses with improved interaction sessions. The accuracy of user responses and latency-free assessment improves the reliability of DIP in smart city applications. The efficiency of the system is then evaluated using detection accuracy (97.34%), the response time (4.3 s), and interaction time (12.3 s), which is compared with other methods. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Al-Makhadmeh, Zafer; Tolba, Amr] King Saud Univ, Dept Comp Sci, Community Coll, Riyadh 11437, Saudi Arabia.
   [Tolba, Amr] Menoufia Univ, Math & Comp Sci Dept, Fac Sci, Shibin Al Kawm 32511, Egypt.
C3 King Saud University; Egyptian Knowledge Bank (EKB); Menofia University
RP Al-Makhadmeh, Z (corresponding author), King Saud Univ, Dept Comp Sci, Community Coll, Riyadh 11437, Saudi Arabia.
EM zalmakhadmee@ksu.edu.sa
RI Tolba, Amr/O-8464-2016
OI Tolba, Amr/0000-0003-3439-6413
FU Deanship of Scientific Research at King Saud University [RG-1439-088]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Saud University for funding this work through Research
   Group No. RG-1439-088.
CR Arun KK, 2022, INTEL SERV ROBOT, V15, P427, DOI 10.1007/s11370-020-00320-z
   Berg J, 2019, PROC CIRP, V79, P614, DOI 10.1016/j.procir.2019.02.080
   Deng YD, 2018, COMPUT ELECTR ENG, V72, P443, DOI 10.1016/j.compeleceng.2018.09.014
   Dong J., 2020, J FRANKLIN I
   Dziergwa M, 2018, INT J SOC ROBOT, V10, P163, DOI 10.1007/s12369-017-0439-2
   Erol BA, 2020, IEEE T COMPUT SOC SY, V7, P234, DOI 10.1109/TCSS.2019.2922593
   Garcia CA, 2020, PROCEDIA MANUF, V42, P315, DOI 10.1016/j.promfg.2020.02.088
   Gomathi P, 2021, COMPLEX INTELL SYST, V7, P1723, DOI 10.1007/s40747-020-00160-5
   Gustaysson P, 2018, PROC CIRP, V72, P123, DOI 10.1016/j.procir.2018.03.156
   Haring KS, 2018, IEEE T COGN DEV SYST, V10, P843, DOI 10.1109/TCDS.2018.2851569
   Hietanen A, 2020, ROBOT CIM-INT MANUF, V63, DOI 10.1016/j.rcim.2019.101891
   Jiang C, 2019, IEEE T SYST MAN CY-S, V49, P797, DOI 10.1109/TSMC.2017.2725300
   Lin YH, 2018, IEEE T COGN DEV SYST, V10, P611, DOI 10.1109/TCDS.2017.2706975
   Liu YY, 2020, ROBOT AUTON SYST, V128, DOI 10.1016/j.robot.2020.103515
   Mi JP, 2019, COGN SYST RES, V54, P128, DOI 10.1016/j.cogsys.2018.12.010
   Neto P, 2019, INT J ADV MANUF TECH, V101, P119, DOI 10.1007/s00170-018-2788-x
   Nyholm S, 2018, SCI ENG ETHICS, V24, P1201, DOI 10.1007/s11948-017-9943-x
   Oliff H, 2020, J MANUF SYST, V56, P326, DOI 10.1016/j.jmsy.2020.06.018
   Onnasch L, 2021, INT J SOC ROBOT, V13, P833, DOI 10.1007/s12369-020-00666-5
   Papanastasiou S., INT J ADV MANUF TECH, V105, P3881
   Quintas J, 2019, IEEE T SYST MAN CY-S, V49, P227, DOI 10.1109/TSMC.2018.2833384
   Rückert P, 2020, PROCEDIA MANUF, V49, P217, DOI 10.1016/j.promfg.2020.07.022
   Savic SZ, 2020, INTEL SERV ROBOT, V13, P99, DOI 10.1007/s11370-019-00303-9
   Tiddi I, 2020, INT J SOC ROBOT, V12, P299, DOI 10.1007/s12369-019-00534-x
   Tse R, 2018, IEEE T ROBOT, V34, P1280, DOI 10.1109/TRO.2018.2830360
   Zarkowski M, 2019, INT J SOC ROBOT, V11, P693, DOI 10.1007/s12369-019-00603-1
   Zhu TH, 2019, INT J CONTROL AUTOM, V17, P474
NR 27
TC 2
Z9 2
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104045
DI 10.1016/j.imavis.2020.104045
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800012
DA 2024-07-18
ER

PT J
AU Ohashi, T
   Ikegami, Y
   Nakamura, Y
AF Ohashi, Takuya
   Ikegami, Yosuke
   Nakamura, Yoshihiko
TI Synergetic reconstruction from 2D pose and 3D motion for wide-space
   multi-person video motion capture in the wild
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Markerless motion capture; Pose estimation; Multi-person; Kinematics
AB Although many studies have investigated markerless motion capture, the technology has not been applied to real sports or concerts. In this paper, we propose a markerless motion capture method with spatiotemporal accuracy and smoothness from multiple cameras in wide-space and multi-person environments. The proposed method predicts each person's 3D pose and determines the bounding box of multi-camera images small enough. This prediction and spatiotemporal filtering based on human skeletal model enables 3D reconstruction of the person and demonstrates high-accuracy. The accurate 3D reconstruction is then used to predict the bounding box of each camera image in the next frame. This is feedback from the 3D motion to 2D pose, and provides a synergetic effect on the overall performance of video motion capture. We evaluated the proposed method using various datasets and a real sports field. The experimental results demonstrate that the mean per joint position error (MPJPE) is 31.5 mm and the percentage of correct parts (PCP) is 99.5% for five people dynamically moving while satisfying the range of motion (RoM). Video demonstration, datasets, and additional materials are posted on our project page(1). (c) 2020 Elsevier B.V. All rights reserved.
C1 [Ohashi, Takuya] NTT DOCOMO, Chiyoda Ku, 2-11-1 Nagata Cho, Tokyo 1006150, Japan.
   [Ohashi, Takuya; Ikegami, Yosuke; Nakamura, Yoshihiko] Univ Tokyo, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
C3 NTT Docomo; University of Tokyo
RP Ohashi, T (corresponding author), NTT DOCOMO, Chiyoda Ku, 2-11-1 Nagata Cho, Tokyo 1006150, Japan.; Ohashi, T (corresponding author), Univ Tokyo, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
EM takuya.ohashi.ht@nttdocomo.com; ikegami@ynl.t.u-tokyo.ac.jp;
   nakamura@race.t.u-tokyo.ac.jp
FU JSPS [JP17H00766]; NTT DOCOMO, Inc.; Grants-in-Aid for Scientific
   Research [20H00599] Funding Source: KAKEN
FX This work was made using sDIMS, a programming library for multibody
   kinematics and dynamicswith the humanmusculo-skeletalmodel developed in
   theUniversity of Tokyo. The authors acknowledge the supports by Ayaka
   Yamada, Hiroki Obara, Tomoyuki Horikawa and the other students in the
   futsal motion capture experiment. We also thank the anonymous
   participants in the studio motion capture experiment. This work was
   conducted in the research funded by JSPS Grants-in-Aid for Scientific
   Research (A) JP17H00766 (2017-2019) and by NTT DOCOMO, Inc.
CR Akhter I., 2015, IEEE CVF C COMP VIS
   Ayusawa K., 2012, IEEE RSJ INT C INT R
   Belagiannis V., 2014, IEEE CVF C COMP VIS
   BELAGIANNIS V, 2016, IEEE T PATTERN ANAL, V38, P1929, DOI DOI 10.1109/TPAMI.2015.2509986
   Bogo F, 2016, LECT NOTES COMPUT SC, V9909, P561, DOI 10.1007/978-3-319-46454-1_34
   Bowen Cheng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12472, DOI 10.1109/CVPR42600.2020.01249
   Bridgeman L., 2019, IEE ECVF C COMP VIS
   Cao Z, 2017, DESTECH TRANS SOC, P25
   Chen YF, 2018, IEEE CONF COMPUT
   de Aguiar E, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360697
   Ershadi-Nasab S, 2018, MULTIMED TOOLS APPL, V77, P15573, DOI 10.1007/s11042-017-5133-8
   Habermann M, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3311970
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   He K., 2017, IEEE CVF INT C COMP
   Joo H., 2018, IEEE CVF C COMP VIS
   Kanazawa Angjoo, 2017, CORR
   Kreiss S., 2019, IEEE CVF C COMP VIS
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Martínez-Ariño J, 2019, COMP EUR POLIT, V17, P651, DOI 10.1057/s41295-018-0119-0
   Mehta D, 2018, INT CONF 3D VISION, P120, DOI 10.1109/3DV.2018.00024
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Mitchelson Joel., 2003, WAND BASED MULTIPLE
   Moreno-Noguer F., 2017, IEEE CVF C COMP VIS
   Murai A, 2010, PROG BIOPHYS MOL BIO, V103, P310, DOI 10.1016/j.pbiomolbio.2010.09.006
   Ohashi T, 2018, IEEE INT C INT ROBOT, P4226, DOI 10.1109/IROS.2018.8593867
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Stoll C, 2011, IEEE I CONF COMP VIS, P951, DOI 10.1109/ICCV.2011.6126338
   Sun K., 2019, IEEE CVF C COMP VIS
   Takano W, 2019, AUTON ROBOT, V43, P1881, DOI 10.1007/s10514-019-09837-4
   Tong J, 2012, IEEE T VIS COMPUT GR, V18, P643, DOI 10.1109/TVCG.2012.56
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   Wei S.E., 2016, IEEE CVF C COMP VIS
   Wong H, 2019, INT CONF MICROELECTR, P3, DOI [10.1109/MIEL.2019.8889652, 10.1109/miel.2019.8889652]
   Xiang D., 2019, IEEE CVF C COMP VIS
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Yamane K., 2005, IEEE INT C ROB AUT I
   Yonemoto K., 1995, JAPANESE J REHABILIT, V32, P207, DOI DOI 10.2490/JJRM1963.32.207
   Zeng WX, 2019, IEEE INT CONF SERV, P9, DOI 10.1109/SOCA.2019.00010
   Zhang YH, 2020, PROC CVPR IEEE, P250, DOI 10.1109/CVPR42600.2020.00033
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou X., 2017, IEEE CVF INT C COMP
NR 41
TC 14
Z9 15
U1 2
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104028
DI 10.1016/j.imavis.2020.104028
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, YL
AF Li, Youling
TI A calibration method of computer vision system based on dual attention
   mechanism
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dual attention mechanism; ResNet; Feature extraction; Zhang Zhengyou
   system calibration
AB Nowadays, the technology of using computer vision to calibrate objects iswidely used, which has a hugemarket demand in many fields. This paper provides a calibration method of computer vision systembased on dual attention neural network. This paper uses the camera to simulate human eyes to obtain three-dimensional images. After obtaining the three-dimensional images, the images are input into the Residual Network (ResNet) model, and the weight of ResNet is repeatedly updated so as to accurately identify the images. On this basis, introduces dual attention mechanism that an algorithm is used in natural language to the visual image processing, using multistage feature extraction method to extract the three-dimensional image for each characteristic of regional. After extracting the feature area, the accuracy of the feature area is constantly updated to theminimum. Besides, the feature areas are brought into the calibration algorithm of Zhang Zhengyou system to obtain the spatial coordinates of the objects in the attention area. This method can realize the space position calibration of specific objects under various complex backgrounds and calculate the distance from the calibrated objects, which can not only calibrate the system but also identify it, and greatly improve the reliability and accuracy of the calibration process. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Li, Youling] Chengdu Normal Univ, Sch Comp Sci, Chengdu 611130, Peoples R China.
C3 Chengdu Normal University
RP Li, YL (corresponding author), Chengdu Normal Univ, Sch Comp Sci, Chengdu 611130, Peoples R China.
EM liyouling321@163.com
FU Science and Technology Project of Sichuan Provincial Department of
   Education, China - Design and Implementation of MOOC-oriented Large Data
   Real-time Stream Recommendation System Based on Storm [18ZB0099]
FX The study was supported by "Science and Technology Project of Sichuan
   Provincial Department of Education, China - Design and Implementation of
   MOOC-oriented Large Data Real-time Stream Recommendation System Based on
   Storm (No. 18ZB0099).
CR Abu A, 2019, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2548-9
   Bai DD, 2018, COMPUT GRAPH-UK, V70, P270, DOI 10.1016/j.cag.2017.07.019
   Chai XH, 2019, MEASUREMENT, V131, P261, DOI 10.1016/j.measurement.2018.08.079
   Chen LX, 2017, RECENT ADV ELECTR EL, V10, P179, DOI 10.2174/2352096509999160819163958
   Huang ZH, 2018, LASER OPTOELECTRON P, V55, DOI 10.3788/LOP55.110401
   Li C, 2017, OPT ENG, V56, DOI 10.1117/1.OE.56.1.013105
   Qin T., 2018, ONLINE TEMPORAL CALI, V1, P386
   Shan BH, 2019, MEASUREMENT, V132, P213, DOI 10.1016/j.measurement.2018.09.048
   Xiao SZ, 2017, PROC SPIE, V10250, DOI 10.1117/12.2267037
   Yang AM, 2019, FUTURE GENER COMP SY, V101, P635, DOI 10.1016/j.future.2019.07.008
   Yang AM, 2019, IEEE ACCESS, V7, P106043, DOI 10.1109/ACCESS.2019.2929919
   Yang TL, 2019, OPT LASER TECHNOL, V110, P78, DOI 10.1016/j.optlastec.2018.07.054
   Ying L., 2014, J XIAN U ARCHITECT T, V46, P860
   Zhang BZ, 2019, IEEE ACCESS, V7, P3826, DOI 10.1109/ACCESS.2018.2887100
   Zhang C, 2018, NUCL SCI TECH, V29, DOI 10.1007/s41365-018-0403-3
   [张国福 Zhang Guofu], 2018, [光学技术, Optical Technology], V44, P75
NR 16
TC 8
Z9 8
U1 5
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104039
DI 10.1016/j.imavis.2020.104039
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000016
DA 2024-07-18
ER

PT J
AU Liu, ZZ
   Zhang, XX
   Zhu, ZF
   Zheng, S
   Zhao, Y
   Cheng, J
AF Liu, Zhizhe
   Zhang, Xingxing
   Zhu, Zhenfeng
   Zheng, Shuai
   Zhao, Yao
   Cheng, Jian
TI Convolutional prototype learning for zero-shot recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Zero-shot recognition; Prototype learning; Image recognition; Deep
   learning
AB Zero-shot learning (ZSL) has received increasing attention in recent years especially in areas of fine-grained object recognition, retrieval, and image captioning. The key to ZSL is to transfer knowledge from the seen to the unseen classes via auxiliary class attribute vectors. However, the popularly learned projection functions in previous works cannot generalize well since they assume the distribution consistency between seen and unseen domains at sample-level. Besides, the provided non-visual and unique class attributes can significantly degrade the recognition performance in semantic space. In this paper, we propose a simple yet effective convolutional prototype learning (CPL) framework for zero-shot recognition. By assuming distribution consistency at task-level, our CPL is capable of transferring knowledge smoothly to recognize unseen samples. Furthermore, inside each task, discriminative visual prototypes are learned via a distance based training mechanism. Consequently, we can perform recognition in visual space, instead of semantic space. An extensive group of experiments are then carefully designed and presented, demonstrating that CPL obtains more favorable effectiveness, over currently available alternatives under various settings. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Liu, Zhizhe; Zhang, Xingxing; Zhu, Zhenfeng; Zheng, Shuai; Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, Beijing, Peoples R China.
   [Liu, Zhizhe; Zhang, Xingxing; Zhu, Zhenfeng; Zheng, Shuai; Zhao, Yao] Beijing Key Lab Adv Informat Sci & Network Techno, Beijing, Peoples R China.
   [Cheng, Jian] Chinese Acad Sci, Inst Automat, NLPR, Beijing, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University; Chinese
   Academy of Sciences; Institute of Automation, CAS
RP Zhu, ZF (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing, Peoples R China.
EM zhzliu@bjtu.edu.cn; zhangxing@bjtu.edu.cn; zhfzhu@bjtu.edu.cn;
   yzhao@bjtu.edu.cn; jcheng@nlpr.ia.ac.cn
RI Zheng, Shuai/JAN-8439-2023; Gu, Bingxin/JNS-4761-2023; ,
   chengjian/KGL-5551-2024; Zhang, Xingxing/HGE-4445-2022
OI Zheng, Shuai/0000-0001-8560-8135; Gu, Bingxin/0009-0005-5667-1430; ,
   chengjian/0000-0003-1289-2758; Zhang, Xingxing/0000-0002-9838-6962
FU Science and Technology Innovation 2030 -"New Generation Artificial
   Intelligence" Major Project [2018AAA0102101]; National Natural Science
   Foundation of China [61976018, 61532005]; Fundamental Research Funds for
   the Central Universities of China [2018JBZ001, 2019YJS048]
FX Thisworkwas supported in part by Science and Technology Innovation 2030
   -"New Generation Artificial Intelligence" Major Project (No.
   2018AAA0102101), in part by the National Natural Science Foundation of
   China (No. 61976018 and No. 61532005), and in part by the Fundamental
   Research Funds for the Central Universities of China (No. 2018JBZ001,
   No. 2019YJS048).
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   Annadani Y, 2018, PROC CVPR IEEE, P7603, DOI 10.1109/CVPR.2018.00793
   [Anonymous], ARXIV200107626
   [Anonymous], ARXIV150302531
   [Anonymous], P EUR C COMP VIS
   [Anonymous], 2016, AAAI
   [Anonymous], ARXIV200211841
   [Anonymous], ARXIV13045634
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], CALTECH UCSD BIRDS 2
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], ARXIV191011671
   [Anonymous], ARXIV181206423
   [Anonymous], 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00749
   Bansal A, 2018, LECT NOTES COMPUT SC, V11205, P397, DOI 10.1007/978-3-030-01246-5_24
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Changpinyo S, 2017, IEEE I CONF COMP VIS, P3496, DOI 10.1109/ICCV.2017.376
   Changpinyo S, 2016, PROC CVPR IEEE, P5327, DOI 10.1109/CVPR.2016.575
   Chen L, 2018, PROC CVPR IEEE, P1043, DOI 10.1109/CVPR.2018.00115
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Frome Andrea, 2013, DEVISE DEEP VISUAL S, P1, DOI DOI 10.5555/2999792.2999849
   Fu YW, 2015, IEEE T PATTERN ANAL, V37, P2332, DOI 10.1109/TPAMI.2015.2408354
   Fu ZY, 2018, IEEE T PATTERN ANAL, V40, P2009, DOI 10.1109/TPAMI.2017.2737007
   Guo YC, 2017, IEEE T IMAGE PROCESS, V26, P3277, DOI 10.1109/TIP.2017.2696747
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kampffmeyer M, 2019, PROC CVPR IEEE, P11479, DOI 10.1109/CVPR.2019.01175
   Kankuekul P, 2012, PROC CVPR IEEE, P3657, DOI 10.1109/CVPR.2012.6248112
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Kodirov E, 2015, IEEE I CONF COMP VIS, P2452, DOI 10.1109/ICCV.2015.282
   Lampert CH, 2014, IEEE T PATTERN ANAL, V36, P453, DOI 10.1109/TPAMI.2013.140
   Lampert CH, 2009, PROC CVPR IEEE, P951, DOI 10.1109/CVPRW.2009.5206594
   Lee H, 2018, IEEE INT CONF COMM
   Li Y, 2018, PROC CVPR IEEE, P7463, DOI 10.1109/CVPR.2018.00779
   Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313
   Morgado P, 2017, PROC CVPR IEEE, P2037, DOI 10.1109/CVPR.2017.220
   Norouzi M., ARXIV13125650
   Patterson G, 2012, PROC CVPR IEEE, P2751, DOI 10.1109/CVPR.2012.6247998
   Radovanovic M, 2010, J MACH LEARN RES, V11, P2487
   Romera-Paredes B, 2015, PR MACH LEARN RES, V37, P2152
   Schönfeld E, 2019, PROC CVPR IEEE, P8239, DOI 10.1109/CVPR.2019.00844
   Snell J, 2017, ADV NEUR IN, V30
   Socher R., 2013, ADV NEURAL INFORM PR, V26, P935, DOI DOI 10.1007/978-3-319-46478-7
   Tsai YHH, 2017, IEEE I CONF COMP VIS, P3591, DOI 10.1109/ICCV.2017.386
   Wang XL, 2018, PROC CVPR IEEE, P6857, DOI 10.1109/CVPR.2018.00717
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xian YQ, 2019, IEEE T PATTERN ANAL, V41, P2251, DOI 10.1109/TPAMI.2018.2857768
   Xian YQ, 2016, PROC CVPR IEEE, P69, DOI 10.1109/CVPR.2016.15
   Yang HM, 2018, PROC CVPR IEEE, P3474, DOI 10.1109/CVPR.2018.00366
   Yu YL, 2018, ADV NEUR IN, V31
   Zhang L, 2017, PROC CVPR IEEE, P3010, DOI 10.1109/CVPR.2017.321
   Zhang XX, 2020, NEUROCOMPUTING, V381, P336, DOI 10.1016/j.neucom.2019.11.073
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
NR 53
TC 12
Z9 13
U1 8
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2020
VL 98
AR 103924
DI 10.1016/j.imavis.2020.103924
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR9US
UT WOS:000536040700006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pandey, A
   Pati, UC
AF Pandey, Achala
   Pati, Umesh C.
TI Image mosaicing: A deeper insight
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Geometric transformation; Registration; Blending; Mosaicing;
   Compositing; Panorama
ID COLOR; ADJUSTMENT; FRAMEWORK; FEATURES; FIELDS; SCENES; SEAMS
AB Image mosaicing is an effective means of constructing a single seamless image by aligning multiple partially overlapped images. Over the years, the research attention on mosaicing has increased a lot due to the growing applications and subsequently, many algorithms related to mosaicing and its contributing steps have come into existence. Though, the varied approaches for mosaic generation are effective, several difficulties arise in each step of mosaicing which need to be addressed specifically. The aim of this review is to provide an insight into the existing mosaicing algorithms, along with their merits and shortcomings. Additionally, the manuscript provides a classification of these algorithms based on their domain of processing, application, image type, and visual attributes. Furthermore, a comparison among various mosaicing methods is presented to find out which algorithm works best for a particular application and image type. Finally, the paper is concluded with a highlight on future research directions. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Pandey, Achala; Pati, Umesh C.] Natl Inst Technol Rourkela, Rourkela 769008, Odisha, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Rourkela
RP Pandey, A (corresponding author), Natl Inst Technol Rourkela, Rourkela 769008, Odisha, India.
EM achala.pandey13@gmail.com; ucpati@nitrkl.ac.in
RI Pati, Umesh C./O-6771-2017
OI Pati, Umesh C./0000-0001-9805-2543
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   Agarwala A, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239545, 10.1145/1276377.1276495]
   Agarwala A, 2006, ACM T GRAPHIC, V25, P853, DOI 10.1145/1141911.1141966
   Ait-Aoudia S., 2012, Proceedings of the 2012 16th International Conference on Information Visualisation (IV), P652, DOI 10.1109/IV.2012.113
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2004, DISTINGUISHED DISSER
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Barrett WA, 2002, ACM T GRAPHIC, V21, P777, DOI 10.1145/566570.566651
   Bartoli A, 2008, IEEE T PATTERN ANAL, V30, P2098, DOI 10.1109/TPAMI.2008.22
   Batool N, 2014, IEEE T IMAGE PROCESS, V23, P3773, DOI 10.1109/TIP.2014.2332401
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bekir Dizdaroglu A., 2009, Proceedings of the 2009 International Conference on Image Processing, Computer Vision, & Pattern Recognition. IPCV 2009, P216
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Bie XH, 2011, J COMPUT SCI TECH-CH, V26, P1011, DOI 10.1007/s11390-011-1197-5
   Bie XH, 2013, VISUAL COMPUT, V29, P599, DOI 10.1007/s00371-013-0826-0
   Bornard R., 2002, P ACM INT C MULTIMED, P355
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Bugeau A, 2010, IEEE T IMAGE PROCESS, V19, P2634, DOI 10.1109/TIP.2010.2049240
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   Chakrasali A., 2013, P INT C VLSI COMM AD, P283
   Chen T, 2013, IEEE T IMAGE PROCESS, V22, P2532, DOI 10.1109/TIP.2013.2251642
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Chen X, 2016, J COMPUT SCI TECH-CH, V31, P463, DOI 10.1007/s11390-016-1640-8
   Choi H, 2010, IEEE T INF FOREN SEC, V5, P52, DOI 10.1109/TIFS.2009.2038758
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Chuang YY, 2002, ACM T GRAPHIC, V21, P243, DOI 10.1145/566570.566572
   Dame A, 2011, IEEE IMAGE PROC, P1493, DOI 10.1109/ICIP.2011.6115726
   Das T, 2014, 2014 INTERNATIONAL CONFERENCE ON ROBOTICS AND EMERGING ALLIED TECHNOLOGIES IN ENGINEERING (ICREATE), P1, DOI 10.1109/iCREATE.2014.6828328
   Davis J, 1998, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.1998.698630
   De Benet J. S., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P361, DOI 10.1145/258734.258882
   Diakopoulos N, 2004, LECT NOTES COMPUT SC, V3115, P299
   DiVerdi S, 2009, COMPUT GRAPH-UK, V33, P73, DOI 10.1016/j.cag.2008.11.002
   Dizdaroglu Bekir, 2011, EURASIP Journal on Advances in Signal Processing, DOI 10.1186/1687-6180-2011-98
   Dizdaroglu B, 2007, LECT NOTES COMPUT SC, V4678, P509
   Eden A., 2006, P 2006 IEEE COMP SOC, VVolume 2, P2498
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Eitz Mathias., 2009, proceedings of SIGGRAPH, P1
   Elder JH, 2001, IEEE T PATTERN ANAL, V23, P291, DOI 10.1109/34.910881
   Farbman Z, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1866158.1866171
   Farbman Z, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531373
   Fattal R., 2002, ACM Transactions on Graphics, V21, P249, DOI 10.1145/566570.566573
   Finlayson GD, 2002, LECT NOTES COMPUT SC, V2353, P823
   Foroosh H, 2002, IEEE T IMAGE PROCESS, V11, P188, DOI 10.1109/83.988953
   Georgiev T., 2004, Workshop on Applications of Computer Vision (ECCV 2004), P1, DOI DOI 10.1145/1050330.1050437
   Georgiev T, 2006, LECT NOTES COMPUT SC, V3954, P56
   Ghosh D, 2016, J VIS COMMUN IMAGE R, V34, P1, DOI 10.1016/j.jvcir.2015.10.014
   Gledhill D, 2003, COMPUT GRAPH-UK, V27, P435, DOI 10.1016/S0097-8493(03)00038-4
   Gracias N, 2009, IMAGE VISION COMPUT, V27, P597, DOI 10.1016/j.imavis.2008.04.014
   GU F, 2006, P OCEANS 06 MTS IEEE, P1
   Guestrin C, 1998, 1998 SECOND INTERNATIONAL CONFERENCE ON KNOWLEDGE-BASED INTELLIGENT ELECTRONIC SYSTEMS, KES '98, PROCEEDINGS, VOL 2, P174, DOI 10.1109/KES.1998.725908
   Ha S. J., IEEE T CONSUM ELECT, V54
   Haenselmann T, 2009, IMAGE VISION COMPUT, V27, P391, DOI 10.1016/j.imavis.2008.06.008
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hasler D, 2004, J VIS COMMUN IMAGE R, V15, P65, DOI 10.1016/j.jvcir.2003.06.001
   Hays J, 2007, ACM T GRAPHIC, V26, DOI 10.1145/1239451.1239455
   Henz B, 2016, COMPUT GRAPH-UK, V57, P46, DOI 10.1016/j.cag.2016.03.004
   Hernández-Mier Y, 2010, COMPUT MED IMAG GRAP, V34, P579, DOI 10.1016/j.compmedimag.2010.02.002
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   Hillman P, 2001, PROC CVPR IEEE, P1063
   Hsu CT, 1996, IEEE T CONSUM ELECTR, V42, P981, DOI 10.1109/30.555800
   Hu J, 2014, IEEE IMAGE PROC, P4632, DOI 10.1109/ICIP.2014.7025939
   Hurtos N., 2013, NOVEL BLENDING TECHN, P1
   Iketani A, 2006, INT C PATT RECOG, P391
   Irani M., 2000, DIRECT METHODS VISIO, P267
   Jeschke S, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1618452.1618462
   Jia JY, 2006, ACM T GRAPHIC, V25, P631, DOI 10.1145/1141911.1141934
   Johnson M, 2006, COMPUT GRAPH FORUM, V25, P407, DOI 10.1111/j.1467-8659.2006.00960.x
   Kekec T, 2014, ROBOT AUTON SYST, V62, P1755, DOI 10.1016/j.robot.2014.07.010
   Kise M, 2008, COMPUT ELECTRON AGR, V60, P67, DOI 10.1016/j.compag.2007.07.002
   Kopf J, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778833
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1239451.1239544, 10.1145/1276377.1276494]
   Kuglin C. D., 1975, Proceedings of the 1975 International Conference on Cybernetics and Society, P163
   Kwatra V, 2003, ACM T GRAPHIC, V22, P277, DOI 10.1145/882262.882264
   Lalonde JF, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276381, 10.1145/1239451.1239454]
   Leventhal D., 2006, SIGGRAPH 06 ACM SIGG, P78
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Lewis J., SIGGRAPH 2001 SKETCH
   Liang J, 2009, COMPUT VIS IMAGE UND, V113, P572, DOI 10.1016/j.cviu.2008.12.004
   Lin CC, 2015, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2015.7298719
   Lin WY, 2011, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2011.5995314
   Lischinski D, 2006, ACM T GRAPHIC, V25, P646, DOI 10.1145/1141911.1141936
   Liu ZH, 2012, ROCK MECHANICS: ACHIEVEMENTS AND AMBITIONS, P31
   Loewke KE, 2011, IEEE T BIO-MED ENG, V58, P159, DOI 10.1109/TBME.2010.2085082
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma XM, 2015, NEUROCOMPUTING, V151, P1430, DOI 10.1016/j.neucom.2014.10.045
   McGuire M, 2005, ACM T GRAPHIC, V24, P567, DOI 10.1145/1073204.1073231
   MILGRAM DL, 1975, IEEE T COMPUT, V24, P1113, DOI 10.1109/T-C.1975.224142
   MILGRAM DL, 1977, IEEE T COMPUT, V26, P1175, DOI 10.1109/TC.1977.1674772
   Mills A, 2009, IMAGE VISION COMPUT, V27, P1593, DOI 10.1016/j.imavis.2009.03.004
   Miranda-Luna R, 2008, IEEE T BIO-MED ENG, V55, P541, DOI 10.1109/TBME.2007.903520
   Pandey A., 2013, India Conference (INDICON), 2013 Annual IEEE, P1
   Pandey A, 2016, COMPUT GRAPH-UK, V59, P93, DOI 10.1016/j.cag.2016.06.003
   Pandey A, 2015, 2015 THIRD INTERNATIONAL CONFERENCE ON IMAGE INFORMATION PROCESSING (ICIIP), P265, DOI 10.1109/ICIIP.2015.7414778
   Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346
   PELEG S, 1981, COMPUT VISION GRAPH, V16, P90, DOI 10.1016/0146-664X(81)90094-0
   Peleg S, 2000, IEEE T PATTERN ANAL, V22, P1144, DOI 10.1109/34.879794
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Philip S, 2015, IEEE T VIS COMPUT GR, V21, P350, DOI 10.1109/TVCG.2014.2366128
   Pizarro O, 2003, IEEE J OCEANIC ENG, V28, P651, DOI 10.1109/JOE.2003.819154
   Pizarro O, 2009, IEEE J OCEANIC ENG, V34, P150, DOI 10.1109/JOE.2009.2016071
   Poleg Y., 2012, IEEE INT C COMP PHOT, P1
   Porter T., 1984, Proceedings of the 11th annual conference on Computer graphics and interactive techniques, P253, DOI 10.1145/800031.808606
   Prados R, 2014, SPRINGERBRIEF COMPUT, P1, DOI 10.1007/978-3-319-05558-9
   Prados R, 2012, IEEE J OCEANIC ENG, V37, P626, DOI 10.1109/JOE.2012.2204152
   Qian R. J., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P143, DOI 10.1109/ICIP.1999.819566
   Rav-Acha A., IEEE T PATTERN ANAL, V29
   Rav-Acha A, 2008, INT J COMPUT VISION, V78, P187, DOI 10.1007/s11263-007-0101-9
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793
   Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589
   Shao HC, 2012, IEEE T BIO-MED ENG, V59, P531, DOI 10.1109/TBME.2011.2175446
   Shen JB, 2007, COMPUT GRAPH-UK, V31, P119, DOI 10.1016/j.cag.2006.10.004
   Shen JB, 2014, IEEE T CYBERNETICS, V44, P1579, DOI 10.1109/TCYB.2013.2290435
   Singh R, 2007, IEEE T SYST MAN CY B, V37, P1212, DOI 10.1109/TSMCB.2007.903537
   Smith A. R., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P259, DOI 10.1145/237170.237263
   Su MS, 2004, IEEE T IMAGE PROCESS, V13, P952, DOI 10.1109/TIP.2004.828416
   Summa B, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185579
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Sunkavalli K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778862
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Szeliski R., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P44, DOI 10.1109/ACV.1994.341287
   Szeliski R., 2011, 2011 IEEE INT C COMP, P1
   Szeliski R, 1997, P 24 ANN C COMP GRAP, P251
   Tao MW, 2013, INT J COMPUT VISION, V103, P178, DOI 10.1007/s11263-012-0579-7
   Torr P H S, 1999, Vision Algorithms: Theory and Practice, P278, DOI DOI 10.1007/3-540-44480-7_19
   Traka M, 2003, SIGNAL PROCESS-IMAGE, V18, P465, DOI 10.1016/S0923-5965(03)00032-8
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Uyttendaele M, 2001, PROC CVPR IEEE, P509
   Wang L, 2007, 2007 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE IN SECURITY AND DEFENSE APPLICATIONS, P1
   Wang W, 2012, IEEE T IMAGE PROCESS, V21, P1809, DOI 10.1109/TIP.2011.2176952
   Wright Steve., 2011, Compositing Visual Effects: Essentials For The Aspiring Artist
   Wright Steve, 2013, DIGITAL COMPOSITING
   Wu H, 2016, J VIS COMMUN IMAGE R, V38, P100, DOI 10.1016/j.jvcir.2016.02.011
   Wu H, 2014, COMPUT GRAPH-UK, V38, P277, DOI 10.1016/j.cag.2013.10.016
   XIONG Y, 2009, P SPIE 6 INT S MULT
   Xiong Y., IEEE T CONSUM ELECT, V56
   Xu ZZ, 2013, SIGNAL IMAGE VIDEO P, V7, P129, DOI 10.1007/s11760-011-0212-1
   Yang WX, 2009, IEEE T IMAGE PROCESS, V18, P2584, DOI 10.1109/TIP.2009.2027365
   Yao W, 2015, IEEE SIGNAL PROC LET, V22, P6, DOI 10.1109/LSP.2014.2345773
   Zappalá A, 1999, IMAGE VISION COMPUT, V17, P589, DOI 10.1016/S0262-8856(98)00178-4
   Zhang Y, 2014, VISUAL COMPUT, V30, P1169, DOI 10.1007/s00371-013-0897-y
   Zomet A, 2006, IEEE T IMAGE PROCESS, V15, P969, DOI 10.1109/TIP.2005.863958
NR 150
TC 29
Z9 34
U1 5
U2 60
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 236
EP 257
DI 10.1016/j.imavis.2019.07.002
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900020
DA 2024-07-18
ER

PT J
AU Yu, J
   Wu, XJ
   Kittler, J
AF Yu, Jun
   Wu, Xiao-Jun
   Kittler, Josef
TI Discriminative Supervised Hashing for Cross-Modal Similarity Search
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross-modal retrieval; Supervised hashing; Unified binary codes; Matrix
   factorization; Discriminative
ID BINARY-CODES
AB With the advantages of low storage cost and high retrieval efficiency, hashing techniques have recently been an emerging topic in cross-modal similarity search. As multiple modal data reflect similar semantic content, many works aim at learning unified binary codes. However, discriminative hashing features learned by these methods are not adequate. This results in lower accuracy and robustness. We propose a novel hashing learning framework which jointly performs classifier learning, subspace learning, and matrix factorization to preserve class-specific semantic content, termed Discriminative Supervised Hashing (DSH), to learn the discriminative unified binary codes for multi-modal data. Besides, reducing the loss of information and preserving the non-linear structure of data, DSH non-linearly projects different modalities into the common space in which the similarity among heterogeneous data points can be measured. Extensive experiments conducted on the three publicly available datasets demonstrate that the framework proposed in this paper outperforms several state-of-the-art methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Yu, Jun; Wu, Xiao-Jun] Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
   [Yu, Jun; Wu, Xiao-Jun] Jiangnan Univ, Jiangsu Prov Engn Lab Pattern Recognit & Computat, Wuxi 214122, Jiangsu, Peoples R China.
   [Kittler, Josef] Univ Surrey, CVSSP, Guildford GU2 7XH, Surrey, England.
C3 Jiangnan University; Jiangnan University; University of Surrey
RP Wu, XJ (corresponding author), Jiangnan Univ, Sch Internet Things Engn, Wuxi 214122, Jiangsu, Peoples R China.
EM yujunjason@aliyun.com; wtudaojun@jiangnan.edu.cn; J.kittler@surrey.ac.uk
FU National Natural Science Foundation of China [61373055, 61672265]; UK
   EPSRC [EP/N007743/1]; Ministry of Education of China [B12018]; MURI /
   EPSRC / DSTL [EP/R018456/1]; EPSRC [EP/N007743/1, EP/R018456/1] Funding
   Source: UKRI
FX The paper is supported by theNational Natural Science Foundation of
   China (Grant Nos.61373055,61672265), UK EPSRC GrantEP/N007743/1, MURI /
   EPSRC / DSTL GrantEP/R018456/1, and the111 Project of Ministry of
   Education of China (Grant No.B12018).
CR Gong YC, 2013, IEEE T PATTERN ANAL, V35, P2916, DOI 10.1109/TPAMI.2012.193
   Hwang SJ, 2012, IEEE T PATTERN ANAL, V34, P1145, DOI 10.1109/TPAMI.2011.190
   Ji RR, 2017, IEEE T IMAGE PROCESS, V26, P5411, DOI 10.1109/TIP.2017.2735184
   Kang WC, 2016, AAAI CONF ARTIF INTE, P1230
   Kulis B, 2009, IEEE I CONF COMP VIS, P2130, DOI 10.1109/ICCV.2009.5459466
   Kumar Shaishav, 2011, 22 INT JOINT C ART I
   Lin ZJ, 2015, PROC CVPR IEEE, P3864, DOI 10.1109/CVPR.2015.7299011
   Liu H., 2016, INT JOINT C ART INT
   Liu H, 2017, P INT COMP SOFTW APP, P738, DOI 10.1109/COMPSAC.2017.131
   Liu H, 2016, AAAI CONF ARTIF INTE, P1258
   Liu H, 2017, AAAI CONF ARTIF INTE, P2238
   Liu W., 2014, P NEURAL INF PROCESS, P3419
   Liu W, 2012, PROC CVPR IEEE, P2074, DOI 10.1109/CVPR.2012.6247912
   Norouzi M.E., 2011, ICML
   Rasiwasia N., 2010, P 18 INT C MULT FIR, P251, DOI 10.1145/1873951.1873987
   Shen FM, 2015, PROC CVPR IEEE, P37, DOI 10.1109/CVPR.2015.7298598
   Shen XB, 2017, IEEE T CYBERNETICS, V47, P4275, DOI 10.1109/TCYB.2016.2606441
   Song J., 2013, P ACM SIGMOD INT C M, P785, DOI DOI 10.1145/2463676.2465274
   Wang D, 2018, IEEE T CIRC SYST VID, V28, P2703, DOI 10.1109/TCSVT.2017.2723302
   Xu X, 2017, IEEE T IMAGE PROCESS, V26, P2494, DOI 10.1109/TIP.2017.2676345
   Yu J., 2018, ARXIV180804152
   Yu J, 2018, INT C PATT RECOG, P958, DOI 10.1109/ICPR.2018.8546254
   Yuan Y., 2016, IEEE SIGNAL PROC LET, V23, P893, DOI DOI 10.1109/LSP.2016.2517093
   Zhang D., 2014, 28 AAAI C ART INT
   Zhou J, 2014, DISCRETE DYN NAT SOC, V2014, P1, DOI 10.1155/2014/761507
NR 25
TC 7
Z9 8
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 50
EP 56
DI 10.1016/j.imavis.2019.06.004
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Derkach, D
   Sukno, FM
AF Derkach, Dmytro
   Sukno, Federico M.
TI Automatic local shape spectrum analysis for 3D facial expression
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Facial expression recognition; 3D face; Spectral shape analysis; Laplace
   operators
AB We investigate the problem of Facial Expression Recognition (FER) using 3D data. Building from one of the most successful frameworks for facial analysis using exclusively 3D geometry, we extend the analysis from a curve-based representation into a spectral representation, which allows a complete description of the underlying surface that can be further tuned to the desired level of detail. Spectral representations are based on the decomposition of the geometry in its spatial frequency components, much like a Fourier transform, which are related to intrinsic characteristics of the surface. In this work, we propose the use of Graph Laplacian Features (GLFs), which result from the projection of local surface patches into a common basis obtained from the Graph Laplacian eigenspace. We extract patches around facial landmarks and include a state-of-the-art localization algorithm to allow for fully-automatic operation. The proposed approach is tested on the three most popular databases for 3D FER (BU-3DFE, Bosphorus and BU-4DFE) in terms of expression and AU recognition. Our results show that the proposed GLFs consistently outperform the curves-based approach as well as the most popular alternative for spectral representation, Shape-DNA, which is based on the Laplace Beltrami Operator and cannot provide a stable basis that guarantee that the extracted signatures for the different patches are directly comparable. Interestingly, the accuracy improvement brought by GLFs is obtained also at a lower computational cost. Considering the extraction of patches as a common step between the three compared approaches, the curves-based framework requires a costly elastic deformation between corresponding curves (e.g. based on splines) and Shape-DNA requires computing an eigen-decomposition of every new patch to be analyzed. In contrast, GLFs only require the projection of the patch geometry into the Graph Laplacian eigenspace, which is common to all patches and can therefore be pre-computed off-line. We also show that 14 automatically detected landmarks are enough to achieve high FER and AU detection rates, only slightly below those obtained when using sets of manually annotated landmarks. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Derkach, Dmytro; Sukno, Federico M.] Pompeu Fabra Univ, Dept Informat & Commun Technol, Barcelona, Spain.
C3 Pompeu Fabra University
RP Sukno, FM (corresponding author), Pompeu Fabra Univ, Dept Informat & Commun Technol, Barcelona, Spain.
EM federico.sukno@upf.edu
RI Sukno, Federico/AAM-4440-2021
OI Sukno, Federico/0000-0002-2029-1576
FU Spanish Ministry of Economy and Competitiveness [TIN2017-90124-P]; Ramon
   y Cajal programme; Maria de Maeztu Units of Excellence Programme
   [MDM-2015-0502]
FX This work is partly supported by the Spanish Ministry of Economy and
   Competitiveness under project grant TIN2017-90124-P, the Ramon y Cajal
   programme, and the Maria de Maeztu Units of Excellence Programme
   (MDM-2015-0502).
CR Corneanu CA, 2016, IEEE T PATTERN ANAL, V38, P1548, DOI 10.1109/TPAMI.2016.2515606
   [Anonymous], COMMUNICATIONS COMPU
   [Anonymous], 2012, Computer Vision and Pattern Recognition Workshops CVPRW
   [Anonymous], 1994, Strong evidence for universals in facial expressions: a reply to Russell's mistaken critique
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 2015, P 11 IEEE INT C WORK
   [Anonymous], 2013, MATRIX ANAL
   [Anonymous], 1997, LAPLACIAN RIEMANNIAN
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], VIRTUAL REALITY
   [Anonymous], AM MATH SOC
   [Anonymous], 5 INT C INT HUM MACH
   [Anonymous], P 2008 8 IEEE INT C, DOI DOI 10.1109/AFGR.2008.4813324
   [Anonymous], 2014, SIXTH INTERNATIONAL
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], 2015, ARXIV151103015
   Arapakis I, 2009, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2009.5202773
   Azazi A, 2015, EXPERT SYST APPL, V42, P3056, DOI 10.1016/j.eswa.2014.10.042
   Ben Amor B, 2014, IEEE T CYBERNETICS, V44, P2443, DOI 10.1109/TCYB.2014.2308091
   Berretti S., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4125, DOI 10.1109/ICPR.2010.1002
   Berretti S, 2013, VISUAL COMPUT, V29, P1333, DOI 10.1007/s00371-013-0869-2
   Bronstein Michael M, 2011, IEEE Trans Pattern Anal Mach Intell, V33, P1065, DOI 10.1109/TPAMI.2010.210
   Chavel I, 1984, PURE APPL MATH, V115
   Courant R., 1965, Methods of mathematical physics, V1
   D'Hose J., 2007, IEEE Conference on Biometrics: Theory, Applications and Systems, BTAS'07, P1
   Derkach D, 2017, IEEE INT CONF AUTOMA, P41, DOI 10.1109/FG.2017.143
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Drira H, 2013, IEEE T PATTERN ANAL, V35, P2270, DOI 10.1109/TPAMI.2013.48
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Eisert P, 1998, IEEE COMPUT GRAPH, V18, P70, DOI 10.1109/38.708562
   Fang T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P603, DOI 10.1109/FG.2011.5771466
   Flach P., 2011, P 28 INT C MACH LEAR, P657
   Girard Jeffrey M, 2013, AUTOMATIC FACE GESTU, P1
   Guo Z, 2009, PROCEEDINGS OF THE FIFTH INTERNATIONAL CONFERENCE ON IMAGE AND GRAPHICS (ICIG 2009), P902, DOI 10.1109/ICIG.2009.12
   Isenburg M, 2001, IEEE VISUAL, P135, DOI 10.1109/VISUAL.2001.964504
   Jain Varun., 2007, INT J SHAPE MODELING, V13, P101, DOI DOI 10.1142/S0218654307000968
   Karni Z, 2000, COMP GRAPH, P279, DOI 10.1145/344779.344924
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kim B, 2005, COMPUT GRAPH FORUM, V24, P295, DOI 10.1111/j.1467-8659.2005.00854.x
   Klassen E, 2006, LECT NOTES COMPUT SC, V3951, P95
   Levy B, 2006, IEEE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS 2006, PROCEEDINGS, P66
   Li HB, 2015, COMPUT VIS IMAGE UND, V140, P83, DOI 10.1016/j.cviu.2015.07.005
   Li HB, 2012, INT C PATT RECOG, P2577
   Maalej A, 2011, PATTERN RECOGN, V44, P1581, DOI 10.1016/j.patcog.2011.02.012
   McDuff D., 2013, AUTOMATIC FACE GESTU, P1
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Nealen A., 2006, P 4 INT C COMP GRAPH, P381, DOI DOI 10.1145/1174429.1174494
   Niethammer M, 2007, LECT NOTES COMPUT SC, V4791, P850
   Ovsjanikov M, 2008, COMPUT GRAPH FORUM, V27, P1341, DOI 10.1111/j.1467-8659.2008.01273.x
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   Qiu A, 2008, NEUROIMAGE, V39, P1803, DOI 10.1016/j.neuroimage.2007.08.043
   Qiu AQ, 2006, IEEE T MED IMAGING, V25, P1296, DOI 10.1109/TMI.2006.882143
   Reale M., 2013, AUTOMATIC FACE GESTU, P1
   Reuter M, 2006, COMPUT AIDED DESIGN, V38, P342, DOI 10.1016/j.cad.2005.10.011
   Reuter M., 2005, P 2005 ACM S SOLID P, P101, DOI DOI 10.1145/1060244.1060256
   Reuter M, 2010, INT J COMPUT VISION, V89, P287, DOI 10.1007/s11263-009-0278-1
   Reuter M, 2009, COMPUT AIDED DESIGN, V41, P739, DOI 10.1016/j.cad.2009.02.007
   Samir C, 2009, INT J COMPUT VISION, V82, P80, DOI 10.1007/s11263-008-0187-8
   Sandbach G, 2012, IEEE IMAGE PROC, P1813, DOI 10.1109/ICIP.2012.6467234
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P683, DOI 10.1016/j.imavis.2012.06.005
   Sandbach G, 2012, IMAGE VISION COMPUT, V30, P762, DOI 10.1016/j.imavis.2012.01.006
   Savran Arman, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1993, DOI 10.1109/ICCVW.2009.5457526
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Srivastava A, 2011, IEEE T PATTERN ANAL, V33, P1415, DOI 10.1109/TPAMI.2010.184
   Sukno FM, 2015, IEEE T CYBERNETICS, V45, P1717, DOI 10.1109/TCYB.2014.2359056
   Taubin G., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P351, DOI 10.1145/218380.218473
   Tie Yun, 2010, 2010 IEEE 12th International Workshop on Multimedia Signal Processing (MMSP), P505, DOI 10.1109/MMSP.2010.5662073
   Vretos N, 2011, IEEE IMAGE PROC, P773, DOI 10.1109/ICIP.2011.6116669
   Wang H, 2012, GRAPH MODELS, V74, P173, DOI 10.1016/j.gmod.2012.04.005
   Wang Jiheng, 2014, MICROCHIM ACTA, P1
   Wang YJ, 2013, IEEE INT SYMP INFO, P529, DOI 10.1109/ISIT.2013.6620282
   Wei J, 2013, IEEE ICCE, P1, DOI 10.1109/ICCE.2013.6486769
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Xudong Yang, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163090
   Xue ML, 2015, IEEE WINT CONF APPL, P199, DOI 10.1109/WACV.2015.34
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang H, 2010, COMPUT GRAPH FORUM, V29, P1865, DOI 10.1111/j.1467-8659.2010.01655.x
   Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833
   Zhen QK, 2016, IEEE T MULTIMEDIA, V18, P1438, DOI 10.1109/TMM.2016.2557063
NR 82
TC 3
Z9 4
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2018
VL 79
BP 86
EP 98
DI 10.1016/j.imavis.2018.09.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA HA0JH
UT WOS:000449893800008
DA 2024-07-18
ER

PT J
AU Magri, L
   Fusiello, A
AF Magri, Luca
   Fusiello, Andrea
TI Multiple structure recovery via robust preference analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-model fitting; Model estimation; Spectral clustering; Matrix
   factorization
ID CONSENSUS
AB This paper address the extraction of multiple models from outlier-contaminated data by exploiting preference analysis and low rank approximation. First points are represented in the preference space, then Robust PCA (Principal Component Analysis) and Symmetric NMF (Non negative Matrix Factorization) are used to break the multi-model fitting problem into many single-model problems, which in turn are tackled with an approach inspired to MSAC (M-estimator SAmple Consensus) coupled with a model-specific scale estimate. Experimental validation on public, real data-sets demonstrates that our method compares favorably with the state of the art. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Magri, Luca] Univ Verona, Dipartimento Informat, Str Grazie 15, I-37134 Verona, Italy.
   [Fusiello, Andrea] Univ Udine, DPIA, Via Sci 208, I-33100 Udine, Italy.
C3 University of Verona; University of Udine
RP Magri, L (corresponding author), Univ Verona, Dipartimento Informat, Str Grazie 15, I-37134 Verona, Italy.; Fusiello, A (corresponding author), Univ Udine, DPIA, Via Sci 208, I-33100 Udine, Italy.
EM magri.luca.l@gmail.com; andrea.fusiello@uniud.it
RI Fusiello, Andrea/GOJ-9893-2022; Magri, Luca/AAU-2569-2021
OI Fusiello, Andrea/0000-0003-2963-0316; 
CR Agarwal S, 2005, PROC CVPR IEEE, P838
   [Anonymous], LECT NOTES COMPUT 1
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], PAMI
   [Anonymous], 2014, J GLOBAL OPTIMIZATIO
   [Anonymous], LNCS
   [Anonymous], CVPR
   [Anonymous], CVPR
   [Anonymous], 2014, CVPR
   [Anonymous], P 48 ANN ALL C COMM
   [Anonymous], 2007, C-J CARBON RES
   [Anonymous], ICCV
   Bruckstein AM, 2009, SIAM REV, V51, P34, DOI 10.1137/060657704
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Choi S., 2009, BMVC
   Chum O, 2005, PROC CVPR IEEE, P772
   Chum O, 2005, PROC CVPR IEEE, P220, DOI 10.1109/cvpr.2005.221
   Delong A, 2012, LECT NOTES COMPUT SC, V7572, P370, DOI 10.1007/978-3-642-33718-5_27
   Denis P, 2008, LECT NOTES COMPUT SC, V5303, P197, DOI 10.1007/978-3-540-88688-4_15
   Fragoso V, 2013, IEEE I CONF COMP VIS, P2472, DOI 10.1109/ICCV.2013.307
   Gallo O, 2011, PATTERN RECOGN LETT, V32, P403, DOI 10.1016/j.patrec.2010.10.009
   Govindu VM, 2005, PROC CVPR IEEE, P1150
   Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7
   Jaccard P., 1901, B SOCIT VAUDOISE SCI, V37, P547, DOI [10.5169/seals-266440, DOI 10.5169/SEALS-266440]
   Jain S, 2013, IEEE I CONF COMP VIS, P3511, DOI 10.1109/ICCV.2013.436
   Kanazawa Y., 2004, Procedings of the British Machine Vision Conference, P247
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Lin, 2010, ARXIV10095055
   Litman R, 2015, PROC CVPR IEEE, P5243, DOI 10.1109/CVPR.2015.7299161
   Liu GC, 2013, IEEE T PATTERN ANAL, V35, P171, DOI 10.1109/TPAMI.2012.88
   Matas J, 2004, IMAGE VISION COMPUT, V22, P837, DOI 10.1016/j.imavis.2004.02.009
   Ni K, 2009, IEEE I CONF COMP VIS, P2193, DOI 10.1109/ICCV.2009.5459241
   Ozden KE, 2010, IEEE T PATTERN ANAL, V32, P1134, DOI 10.1109/TPAMI.2010.23
   Pekalska E., 2005, The Dissimilarity Representation for Pattern Recognition
   Pham TT, 2014, IEEE T PATTERN ANAL, V36, P1658, DOI 10.1109/TPAMI.2013.2296310
   Purkait P, 2014, LECT NOTES COMPUT SC, V8692, P672, DOI 10.1007/978-3-319-10593-2_44
   ROUSSEEUW PJ, 1993, J AM STAT ASSOC, V88, P1273, DOI 10.2307/2291267
   Soltanolkotabi M, 2014, ANN STAT, V42, P669, DOI 10.1214/13-AOS1199
   Stewart CV, 1997, IEEE T PATTERN ANAL, V19, P818, DOI 10.1109/34.608280
   Tanimoto T. T., 1958, ELEMENTARY MATH THEO
   Tepper M, 2014, SIAM J IMAGING SCI, V7, P2488, DOI 10.1137/140967325
   Toldo R, 2013, IMAGE VISION COMPUT, V31, P756, DOI 10.1016/j.imavis.2013.07.007
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Pham TT, 2014, IEEE T IMAGE PROCESS, V23, P4601, DOI 10.1109/TIP.2014.2346025
   Wong Hoi Sim, 2011, ICCV
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   Zass R, 2005, IEEE I CONF COMP VIS, P294
   Zass R., 2006, P INT C NEUR INF PRO, P1569
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
   Zuliani M., 2005, ICIP
NR 50
TC 9
Z9 11
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2017
VL 67
BP 1
EP 15
DI 10.1016/j.imavis.2017.09.005
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FM3DF
UT WOS:000414883800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Quan, W
   Li, TR
   Gao, SB
   Chen, JX
AF Quan, Wei
   Li, Tianrui
   Gao, Shibin
   Chen, Jim X.
TI Visual tracking with multiple Hough detectors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Multiple Hough detectors; Feature selection; Detector
   selection
ID ROBUST OBJECT TRACKING; OCCLUSION; SELECTION; FORESTS
AB We propose a visual tracking method using multiple Hough detectors to address the problem of long-term robust object tracking in unconstrained environments. The method constructs the detectors based on the feature selection by the mutual information. These detectors serve to learn the partial appearances of target and synchronously evaluate image locations via the voting based detection with the generalized Hough transform. According to the result of detections, the best detector is selected by the minimum entropy criterion and delivers the final hypotheses for target location. The feature selection allows our tracker to be able to obtain and use the most discriminative parts of target and thus more robust to its changes, e.g. occlusion and deformation. The detector selection can correct undesirable model updates and restore the tracker after tracking failure. Meanwhile, the Hough-based detection can reduce the amount of noise introduced during online self-training and thus effectively prevent the tracker from drifting. The method is evaluated on the CVPR2013 Visual Tracker Benchmark and the experimental results demonstrate our method outperforms other tracking algorithms in terms of both success rate and precision. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Quan, Wei; Gao, Shibin] Southwest Jiaotong Univ, Sch Elect Engn, Chengdu 610031, Sichuan, Peoples R China.
   [Li, Tianrui] Southwest Jiaotong Univ, Sch Informat Sci & Technol, Chengdu 610031, Sichuan, Peoples R China.
   [Chen, Jim X.] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
C3 Southwest Jiaotong University; Southwest Jiaotong University; George
   Mason University
RP Quan, W (corresponding author), Southwest Jiaotong Univ, Sch Elect Engn, Chengdu 610031, Sichuan, Peoples R China.
EM wquan@swjtu.edu.cn; trli@swjtu.edu.cn; gao_shi_bin@126.com;
   jchen@gmu.edu
RI Li, Tianrui/A-4889-2012; Li, Tianrui/F-4974-2019
OI Li, Tianrui/0000-0001-7780-104X
FU National Natural Science Foundation of China [61703350]; Science and
   Technology Project of Sichuan Province of China [2015JY0141]; Key
   Science Project of Sichuan Province of China [17ZA0392]; Key R&D Project
   of Sichuan Province of China [17ZDYF1517]
FX This work was supported in part by the National Natural Science
   Foundation of China (Grant No. 61703350), the Science and Technology
   Project of Sichuan Province of China (Grant No. 2015JY0141), the Key
   Science Project of Sichuan Province of China (Grant No. 17ZA0392), and
   the Key R&D Project of Sichuan Province of China (Grant No. 17ZDYF1517).
CR [Anonymous], IEEE C AC SPEECH SIG
   [Anonymous], 2006, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2001, PROC IEEE COMPUT SOC
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Belagiannis V, 2012, LECT NOTES COMPUT SC, V7575, P842, DOI 10.1007/978-3-642-33765-9_60
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Dinh TB, 2011, PROC CVPR IEEE, P1177, DOI 10.1109/CVPR.2011.5995733
   Duffner S, 2013, IEEE I CONF COMP VIS, P2480, DOI 10.1109/ICCV.2013.308
   Fan JL, 2012, IEEE T PATTERN ANAL, V34, P1633, DOI 10.1109/TPAMI.2011.257
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Gall J, 2009, PROC CVPR IEEE, P1022, DOI 10.1109/CVPRW.2009.5206740
   Godec M., 2010, 2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops, P19
   Grandvalet Y., 2005, CAP, V367, P281
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hua Y, 2014, LECT NOTES COMPUT SC, V8694, P172, DOI 10.1007/978-3-319-10599-4_12
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   KONONENKO I, 1991, LECT NOTES ARTIF INT, V482, P206, DOI 10.1007/BFb0017015
   Kwak S, 2011, IEEE I CONF COMP VIS, P1551, DOI 10.1109/ICCV.2011.6126414
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lee DY, 2014, PROC CVPR IEEE, P3486, DOI 10.1109/CVPR.2014.446
   Li X., 2008, IEEE C COMPUTER VISI, P1
   Lucey S., 2008, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587564
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Mahadevan V, 2013, IEEE T PATTERN ANAL, V35, P541, DOI 10.1109/TPAMI.2012.98
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Özuysal M, 2006, LECT NOTES COMPUT SC, V3953, P592, DOI 10.1007/11744078_46
   Ozuysal M., 2007, CVPR, P1, DOI DOI 10.1109/CVPR.2007.383123
   Pernici F, 2012, LECT NOTES COMPUT SC, V7585, P597, DOI 10.1007/978-3-642-33885-4_61
   Qin T, 2013, INT CONF ACOUST SPEE, P2327, DOI 10.1109/ICASSP.2013.6638070
   Quan W, 2014, VISUAL COMPUT, V30, P351, DOI 10.1007/s00371-013-0860-y
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Saffari Amir, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1393, DOI 10.1109/ICCVW.2009.5457447
   Supancic JS, 2013, PROC CVPR IEEE, P2379, DOI 10.1109/CVPR.2013.308
   Wang XM, 2015, IEEE I CONF COMP VIS, P4337, DOI 10.1109/ICCV.2015.493
   Wang XY, 2010, EBM 2010: INTERNATIONAL CONFERENCE ON ENGINEERING AND BUSINESS MANAGEMENT, VOLS 1-8, P200
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xing JL, 2013, IEEE I CONF COMP VIS, P665, DOI 10.1109/ICCV.2013.88
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
   Zuo Z, 2015, PATTERN RECOGN, V48, P3004, DOI 10.1016/j.patcog.2015.02.003
NR 50
TC 1
Z9 1
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2017
VL 66
BP 15
EP 25
DI 10.1016/j.imavis.2017.08.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FJ9AO
UT WOS:000413060000002
DA 2024-07-18
ER

PT J
AU Wang, XY
   Peng, ZM
   Kong, DH
   Zhang, P
   He, YM
AF Wang, Xiaoyang
   Peng, Zhenming
   Kong, Dehui
   Zhang, Ping
   He, Yanmin
TI Infrared dim target detection based on total variation regularization
   and principal component pursuit
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Infrared images; Dim target detection; Total variation regularization;
   Principal component pursuit
ID THRESHOLDING ALGORITHM; TRACK
AB Robust detection of infrared dim and small target contributes significantly to the infrared systems in many applications. Due to the diversity of background scene and unique characteristic of target, the detection of infrared targets remains a challenging problem. In this paper, a novel approach based on total variation regularization and principal component pursuit (TV-PCP) is presented to deal with this problem. The principal component pursuit model only considers the low-rank feature of background images, which will result in poor detection ability in non-uniform and non-smooth scenes. We take into account the total variation regularization term to thoroughly describe background feature, which can achieve good detection result as well as good background estimation result. Firstly, the input infrared image is transformed to a patch image model. Secondly, the TV-PCP model is presented on the patch image. An effective optimization algorithm is proposed to solve this model. Experiments on six real datasets show that the proposed method has superior detection ability under various backgrounds, especially with good background suppression performance and low false alarm rate. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Wang, Xiaoyang; Peng, Zhenming; Kong, Dehui; Zhang, Ping; He, Yanmin] Univ Elect Sci & Technol China, Sch Optoelect Informat, Chengdu 610054, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Peng, ZM (corresponding author), Univ Elect Sci & Technol China, Sch Optoelect Informat, Chengdu 610054, Peoples R China.
EM xywang1211@outlook.com; zmpeng@uestc.edu.cn; kongdehui2013@gmail.com;
   pingzh@uestc.edu.cn; heyanmin@uestc.edu.cn
RI Wang, Xiaoyang/T-4129-2019
OI Wang, Xiaoyang/0000-0001-9332-2700; Kong, Dehui/0000-0003-1890-6911;
   Peng, Zhenming/0000-0002-4148-3331
FU National Science Foundation of China [61571096, 41274127, 41301460,
   61308102]; Key Laboratory Fund of Beam Control, Chinese Academy of
   Sciences [2014LBC002]
FX This work is supported by the National Science Foundation of China
   (61571096, 41274127, 41301460, 61308102) and the Key Laboratory Fund of
   Beam Control, Chinese Academy of Sciences (2014LBC002).
CR Anderson KL, 1997, IEEE T AERO ELEC SYS, V33, P464, DOI 10.1109/7.575884
   [Anonymous], 2015, MICROCHIM ACTA, DOI DOI 10.1007/S00604-015-1623-4
   [Anonymous], 2010, 100920105055 ARXIV
   [Anonymous], 2013, 2013 IEEE INT C SIGN
   BARNIV Y, 1985, IEEE T AERO ELEC SYS, V21, P144, DOI 10.1109/TAES.1985.310548
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Blostein S. D., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P1068, DOI 10.1109/ICASSP.1988.196779
   BLOSTEIN SD, 1991, IEEE T SIGNAL PROCES, V39, P1611, DOI 10.1109/78.134399
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Cao Y, 2008, INT J INFRARED MILLI, V29, P385, DOI 10.1007/s10762-008-9334-0
   Chen CLP, 2014, IEEE T GEOSCI REMOTE, V52, P574, DOI 10.1109/TGRS.2013.2242477
   Davidson G., 2002, IEEE ELECT LETT, V38, P1128, DOI [10.1049/el:20020790, DOI 10.1049/EL:20020790]
   Fries R. W., 1989, 0E LASE 89, P19
   Gao C., 2015, ROBUST KRONECKER PRO, V119, P1
   Gao CQ, 2012, IEEE AERO EL SYS MAG, V27, P21, DOI 10.1109/MAES.2012.6196254
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   HADHOUD MM, 1988, IEEE T CIRCUITS SYST, V35, P485, DOI 10.1109/31.1775
   Han J., 2016, IEEE GEOSCI REMOTE S
   Han JH, 2014, IEEE GEOSCI REMOTE S, V11, P2168, DOI 10.1109/LGRS.2014.2323236
   He YJ, 2015, INFRARED PHYS TECHN, V68, P98, DOI 10.1016/j.infrared.2014.10.022
   Johnston LA, 2002, IEEE T AERO ELEC SYS, V38, P228, DOI 10.1109/7.993242
   Li C., 2009, EFFICIENT ALGORITHM
   Li L, 2014, ELECTRON LETT, V50, P510, DOI 10.1049/el.2014.0180
   Li ZZ, 2014, INFRARED PHYS TECHN, V67, P273, DOI 10.1016/j.infrared.2014.07.030
   Liu MH, 2015, IEEE T INF FOREN SEC, V10, P6, DOI 10.1109/TIFS.2014.2360582
   REED I, 1988, IEEE T AERO ELEC SYS, V24, P327, DOI 10.1109/7.7174
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Shang K, 2016, INFRARED PHYS TECHN, V76, P75, DOI 10.1016/j.infrared.2016.01.024
   Tonissen SM, 1998, IEEE T AERO ELEC SYS, V34, P796, DOI 10.1109/7.705887
   Wang ZY, 2013, IEEE T CIRC SYST VID, V23, P387, DOI 10.1109/TCSVT.2012.2204935
   Yin WT, 2007, J VIS COMMUN IMAGE R, V18, P240, DOI 10.1016/j.jvcir.2007.01.004
   Zeng M, 2006, INFRARED PHYS TECHN, V48, P67, DOI 10.1016/j.infrared.2005.04.006
NR 32
TC 104
Z9 118
U1 4
U2 41
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2017
VL 63
BP 1
EP 9
DI 10.1016/j.imavis.2017.04.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EY9IN
UT WOS:000404312400001
OA Bronze
DA 2024-07-18
ER

PT J
AU Sharifi, A
   Harati, A
   Vahedian, A
AF Sharifi, Ashraf
   Harati, Ahad
   Vahedian, Abedin
TI Marker-based human pose tracking using adaptive annealed particle swarm
   optimization with search space partitioning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pose tracking; Marker-based human pose estimation; Particle swarm
   optimization; Search space partitioning
ID BODY MOTION CAPTURE
AB Pose estimation and tracking of an articulated structure based on data from multiple cameras has seen numerous applications in recent years. In this paper, a marker-based human pose fracking algorithm from multi view video sequences is proposed. The purpose of the proposed algorithm is to present a low cost motion capture system that can be used as an alternative to high cost available commercial human motion capture systems. The problem is defined as the optimization of 45 parameters which define body pose model and is solved using a modified version of particle swarm optimization (PSO) algorithm. The objective of this optimization is to maximize a fitness function which formulates how much the body model matches with 2D marker coordinates in video frames. A sampling covariance matrix is used in the first part of the velocity equation of PSO and is annealed with iterations. The sampling covariance matrix is computed adaptively, based on variance of parameters in the swarm. One of the concerns in this algorithm is the high number of parameters to define the model of body pose. To tackle this problem, we partition the optimization state space into six stages that exploit the hierarchical structure of the skeletal model. The first stage optimizes the six parameters that define the global orientation and position of the body. Other stages relate to optimization of right and left hand, right and left leg and head orientation. In the proposed partitioning method previously optimized parameters are allowed some variation in each step that is called soft partitioning. Experimental results on Pose Estimation and Action Recognition (PEAR) database indicate that the proposed algorithm achieves lower, estimation error in tracking human motion compared with Annealed Particle Filter (APF) and Parametric Annealing (PA) methods. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Sharifi, Ashraf; Harati, Ahad; Vahedian, Abedin] Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Iran.
C3 Ferdowsi University Mashhad
RP Vahedian, A (corresponding author), Ferdowsi Univ Mashhad, Dept Comp Engn, Mashhad, Iran.
EM sharifi.a7@alumni.um.ac.ir; a.harati@um.ac.ir; vahedian@um.ac.ir
RI Vahedian, Abedin/Q-7812-2019; Harati, Ahad/P-4468-2015; Ghaderi,
   Bahar/T-7182-2018
OI Harati, Ahad/0000-0001-7263-0309; Ghaderi, Bahar/0000-0002-6160-8453
CR [Anonymous], P 19 BRIT MACH VIS C
   [Anonymous], P IEEE C EV COMP CEC
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   [Anonymous], FAIR EVALUATION 3D H
   Behrouzifar M, 2012, COMM COM INF SC, V295, P234
   Canton-Ferrer C, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/105476
   Cham Tat-Jen., 1999, IEEE COMPUTER SOC C, V2, P244, DOI DOI 10.1109/CVPR.1999.784636
   del Valle Y, 2008, IEEE T EVOLUT COMPUT, V12, P171, DOI 10.1109/TEVC.2007.896686
   Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c
   Deutscher J., 2001, COMP VIS PATT REC 20, V2
   Fleischmann P, 2012, LECT NOTES COMPUT SC, V7517, P479, DOI 10.1007/978-3-642-33140-4_42
   Guerra-Filho G.B., 2005, J THEORETICAL APPL I, VRITA 12, P61
   Isard M., 2012, INT J COMPUT VISION, V29, P5
   Ivekovic S, 2010, LECT NOTES COMPUT SC, V6024, P241, DOI 10.1007/978-3-642-12239-2_25
   Kaliamoorthi P, 2013, PATTERN RECOGN, V46, P1501, DOI 10.1016/j.patcog.2012.11.005
   Krzeszowski T, 2010, LECT NOTES COMPUT SC, V6374, P147, DOI 10.1007/978-3-642-15910-7_17
   Lehment N. H., 2010, IEEE C COMP VIS PATT, P87
   MacCormick J., 2000, IEEE European Conference on Computer Vision, P3, DOI DOI 10.1007/3-540-45053-X1
   Maddock M.M.S., MOTION CAPTURE FILE
   Malian A, 2005, PHOTOGRAMM REC, V20, P241, DOI 10.1111/j.1477-9730.2005.00319.x
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Moeslund ThomasB., 1999, Computer Vision-Based Human Motion Capture
   Nogueira P., Motion Capture Fundamentals A Critical and Comparative Analysis on Real-World Applications
   O'Brien JF, 2000, PROC GRAPH INTERF, P53
   OHYA J, 1994, INT C PATT RECOG, P750, DOI 10.1109/ICPR.1994.576430
   Pons-Moll G., 2011, Visual Analysis of Humans, P139
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Sharifi A, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P135, DOI 10.1109/ICCKE.2014.6993366
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Theobalt Christian., 2004, INT J IMAGE GRAPH, V4, P563
   Wang X., 2010, AUD LANG IM PROC ICA, P1094
   Zhao X., 2012, TECH REP
   Zhao X, 2008, PATTERN RECOGN, V41, P2470, DOI 10.1016/j.patcog.2008.01.004
NR 34
TC 6
Z9 6
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2017
VL 62
BP 28
EP 38
DI 10.1016/j.imavis.2017.03.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EX3GV
UT WOS:000403121500004
DA 2024-07-18
ER

PT J
AU Dai, SL
   Man, H
AF Dai, Shuanglu
   Man, Hong
TI Statistical adaptive metric learning in visual action feature set
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature set classification; Hybrid statistic modeling; Metric learning;
   Manifold selection
ID DISTANCE; POINT
AB Great variances in visual features often present significant challenges in human action recognitions. To address this common problem, this paper proposes a statistical adaptive metric learning (SAML) method by exploring various selections and combinations of multiple statistics in a unified metric learning framework. Most statistics have certain advantages in specific controlled environments, and systematic selections and combinations can adapt them to more realistic "in the wild" scenarios. In the proposed method, multiple statistics, include means, covariance matrices and Gaussian distributions, are explicitly mapped or generated in the Riemannian manifolds. Typically, d-dimensional mean vectors in R-d are mapped to a R-d x d space of symmetric positive definite (SPD) matrices Sym-(+)(d). Subsequently, by embedding the heterogeneous manifolds in their tangent Hilbert space, subspace combination with minimal deviation is selected from multiple statistics. Then Mahalanobis metrics are introduced to map them back into the Euclidean space. Unified optimizations are finally performed based on the Euclidean distances. In the proposed method, subspaces with smaller deviations are selected before metric learning. Therefore, by exploring different metric combinations, the final learning is more representative and effective than exhaustively learning from all the hybrid metrics. Experimental evaluations are conducted on human action recognitions in both static and dynamic scenarios. Promising results demonstrate that the proposed method performs effectively for human action recognitions in the wild. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Dai, Shuanglu; Man, Hong] Stevens Inst Technol, Dept Elect & Comp Engn, 1 Castle Point Hudson, Hoboken, NJ 07030 USA.
RP Dai, SL (corresponding author), Stevens Inst Technol, Dept Elect & Comp Engn, 1 Castle Point Hudson, Hoboken, NJ 07030 USA.
EM sdai1@stevens.edu
RI Dai, Shuanglu/AAO-1069-2020
FU National Science Foundation [1350763]; Direct For Computer & Info Scie &
   Enginr; Div Of Information & Intelligent Systems [1350763] Funding
   Source: National Science Foundation
FX This work was supported in part by the National Science Foundation under
   grant 1350763.
CR [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587735
   [Anonymous], STRUCTURE PRESERVING
   [Anonymous], 2007, American Mathematical Soc.
   [Anonymous], 2015, PATTERN RECOGN
   [Anonymous], 2013, AUTOMATIC FACE GESTU
   Arandjelovic O, 2005, PROC CVPR IEEE, P581
   Bregman L. M., 1967, USSR COMP MATH MATH, V7, P200, DOI [10.1016/0041-5553(67)90040-7, DOI 10.1016/0041-5553(67)90040-7]
   Cai Q, 2013, IEEE IMAGE PROC, P3740, DOI 10.1109/ICIP.2013.6738771
   Campos T. D., 2011, Applications of Computer Vision (WACV), 2011 IEEE Workshop on, P344
   Cevikalp H, 2010, PROC CVPR IEEE, P2567, DOI 10.1109/CVPR.2010.5539965
   Davis J. V., 2007, ICML, P209
   Dhillon IS, 2007, SIAM J MATRIX ANAL A, V29, P1120, DOI 10.1137/060649021
   Fukui K, 2005, SPRINGER TRAC ADV RO, V15, P192
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Hu Y, 2011, PROC CVPR IEEE, P121, DOI 10.1109/CVPR.2011.5995500
   Huang ZW, 2015, LECT NOTES COMPUT SC, V9005, P562, DOI 10.1007/978-3-319-16811-1_37
   Huang ZW, 2014, PROC CVPR IEEE, P1677, DOI 10.1109/CVPR.2014.217
   Huang ZW, 2013, IEEE I CONF COMP VIS, P3296, DOI 10.1109/ICCV.2013.409
   Jhuang H, 2007, IEEE I CONF COMP VIS, P1253
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Kulis B., 2006, P 23 INT C MACHINE L, P505
   Kulis B, 2009, J MACH LEARN RES, V10, P341
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Lu JW, 2013, IEEE I CONF COMP VIS, P329, DOI 10.1109/ICCV.2013.48
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Tistarelli M, 2008, LECT NOTES COMPUT SC, V5372, P67, DOI 10.1007/978-3-540-89991-4_8
   Wang RP, 2012, PROC CVPR IEEE, P2496, DOI 10.1109/CVPR.2012.6247965
   Wang RP, 2012, IEEE T IMAGE PROCESS, V21, P4466, DOI 10.1109/TIP.2012.2206039
   Wang RP, 2009, PROC CVPR IEEE, P429, DOI 10.1109/CVPRW.2009.5206850
   Wang ZJ, 2014, INFORM SCIENCES, V289, P59, DOI 10.1016/j.ins.2014.08.009
   Wu XX, 2011, PROC CVPR IEEE, P489, DOI 10.1109/CVPR.2011.5995624
   Yamaguchi O, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P318, DOI 10.1109/AFGR.1998.670968
   Zhen XT, 2014, INFORM SCIENCES, V281, P295, DOI 10.1016/j.ins.2014.05.021
   Zhu PF, 2013, IEEE I CONF COMP VIS, P2664, DOI 10.1109/ICCV.2013.331
NR 37
TC 2
Z9 3
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 138
EP 148
DI 10.1016/j.imavis.2016.04.003
PN 2
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300012
OA hybrid
DA 2024-07-18
ER

PT J
AU Nagpal, S
   Vatsa, M
   Singh, R
AF Nagpal, Shruti
   Vatsa, Mayank
   Singh, Richa
TI Sketch Recognition: What Lies Ahead?
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Biometrics Conference
CY OCT, 2015
CL London, ENGLAND
DE Facial sketch; Face recognition; Biometrics
ID FACE RECOGNITION
AB "What is the state-of-the-art in sketch recognition and what are some important future research directions in matching sketches with digital face images?" This opinion paper focuses on answering these questions through proposing three important steps that need to move the field forward: (i) create a large, real world forensic sketch database, (ii) develop fundamental understanding of human cognition of processing sketches, and (iii) develop improved algorithms for matching sketches with mugshot photos. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Nagpal, Shruti; Vatsa, Mayank; Singh, Richa] Indraprastha Inst Informat Technol, Delhi, India.
C3 Indraprastha Institute of Information Technology Delhi
RP Vatsa, M (corresponding author), IIIT Delhi, Okhla Phase 3, New Delhi 110020, India.
EM shrutin@iiitd.ac.in; mayank@iiitd.ac.in; rsingh@iiitd.ac.in
RI Vatsa, Mayank/AAR-7199-2020; Singh, Richa/M-9961-2017
OI Vatsa, Mayank/0000-0001-5952-2274; Singh, Richa/0000-0003-4060-4573
CR [Anonymous], PROC CVPR IEEE
   [Anonymous], INT C BIOM
   Bhatt HS, 2012, IEEE T INF FOREN SEC, V7, P1522, DOI 10.1109/TIFS.2012.2204252
   Choi Jonghyun., 2012, Proceedings of the American Education Research Association, Vancouver, BC, Canada, P1
   Chugh T., 2013, P IEEE INT C BIOM TH, P1, DOI DOI 10.1109/BTAS.2013.6712719
   Gao XB, 2008, NEUROCOMPUTING, V71, P1921, DOI 10.1016/j.neucom.2007.10.025
   Han H, 2013, IEEE T INF FOREN SEC, V8, P191, DOI 10.1109/TIFS.2012.2228856
   Kanwisher N, 1997, J NEUROSCI, V17, P4302
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Klum S, 2013, INT CONF BIOMETR
   Klum SJ, 2014, IEEE T INF FOREN SEC, V9, P2248, DOI 10.1109/TIFS.2014.2360825
   Liu J, 2010, J COGNITIVE NEUROSCI, V22, P203, DOI 10.1162/jocn.2009.21203
   Liu J, 2015, 2015 14TH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS (MVA), P77, DOI 10.1109/MVA.2015.7153137
   Liu QS, 2005, PROC CVPR IEEE, P1005
   Mittal P, 2013, IEEE IMAGE PROC, P2797, DOI 10.1109/ICIP.2013.6738576
   Pitcher D, 2011, EXP BRAIN RES, V209, P481, DOI 10.1007/s00221-011-2579-1
   Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tang X., 2004, IEEE Trans. Circuits Syst. Video Technol, V14, P50
   Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414
   Uhl RG, 1996, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.1996.517132
   Wang SL, 2012, PROC CVPR IEEE, P2216, DOI 10.1109/CVPR.2012.6247930
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P1955, DOI 10.1109/TPAMI.2008.222
   Xiao B, 2010, NEUROCOMPUTING, V73, P840, DOI 10.1016/j.neucom.2009.10.014
   Zhang W, 2011, PROC CVPR IEEE, P513, DOI 10.1109/CVPR.2011.5995324
   Zhang Y, 2010, IEEE T SYST MAN CY A, V40, P475, DOI 10.1109/TSMCA.2010.2041654
NR 27
TC 5
Z9 5
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
BP 9
EP 13
DI 10.1016/j.imavis.2016.03.019
PN 1
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA ED8BO
UT WOS:000389097100004
DA 2024-07-18
ER

PT J
AU Candemir, S
   Borovikov, E
   Santosh, KC
   Antani, S
   Thoma, G
AF Candemir, Sema
   Borovikov, Eugene
   Santosh, K. C.
   Antani, Sameer
   Thoma, George
TI RSILC: Rotation- and Scale-Invariant, Line-based Color-aware descriptor
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image descriptor; Local features; Spatial features; Rotation invariance;
   Scale invariance; Color aware
ID FACE-RECOGNITION; IMAGE CLASSIFICATION; FEATURES; SIFT
AB Modern appearance-based object recognition systems typically involve feature/descriptor extraction and matching stages. The extracted descriptors are expected to be robust to illumination changes and to reasonable (rigid or affine) image/object transformations. Some descriptors work well for general object matching, but gray-scale key-point-based methods may be suboptimal for matching line-rich color scenes/objects such as cars, buildings, and faces. We present a Rotation- and Scale-Invariant, Line-based Color-aware descriptor (RSILC), which allows matching of objects/scenes in terms of their key-lines, line-region properties, and line spatial arrangements. An important special application is face matching, since face characteristics are best captured by lines/curves. We tested RSILC performance on publicly available datasets and compared it with other descriptors. Our experiments show that RSILC is more accurate in line-rich object description than other well-known generic object descriptors. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Candemir, Sema; Borovikov, Eugene; Santosh, K. C.; Antani, Sameer; Thoma, George] US Natl Lib Med, Lister Hill Natl Ctr Biomed Commun, NIH, Bethesda, MD 20894 USA.
C3 National Institutes of Health (NIH) - USA; NIH National Library of
   Medicine (NLM)
RP Candemir, S (corresponding author), US Natl Lib Med, Lister Hill Natl Ctr Biomed Commun, NIH, Bethesda, MD 20894 USA.
EM sema.candemir@nih.gov; eugene.borovikov@nih.gov; santosh.kc@nih.gov;
   sameer.antani@nih.gov; george.thoma@nih.gov
RI Antani, Sameer/GVS-8371-2022; Candemir, Sema/X-2002-2019; Santosh,
   KC/H-1363-2012
OI Antani, Sameer/0000-0002-0040-1387; Candemir, Sema/0000-0001-8619-5619;
   Santosh, KC/0000-0003-4176-0236
FU National Institutes of Health, National Library of Medicine and Lister
   Hill National Center for Biomedical Communications
FX This research was supported by the Intramural Research Program of the
   National Institutes of Health, National Library of Medicine and Lister
   Hill National Center for Biomedical Communications. We would like to
   acknowledge the editorial assistance of the NIH Fellows Editorial board.
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   [Anonymous], 2006, P IEEE COMPUTER SOC, DOI DOI 10.1109/CVPR.2006.95
   [Anonymous], 2007, 0749 U MASS
   Bar M, 1996, PERCEPTION, V25, P343, DOI 10.1068/p250343
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bicego M., 2006, C COMP VIS PATT REC
   Borovikov E., 2002, 1 INT S 3D DAT PROC, P116
   Borovikov E, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON HEALTHCARE INFORMATICS (ICHI 2013), P131, DOI 10.1109/ICHI.2013.23
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cappelli R, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P443, DOI 10.1109/ICIAP.2007.4362818
   Davies G, 1981, PERCEIVING REMEMBERI
   Deboeverie F, 2011, LECT NOTES COMPUT SC, V6979, P109, DOI 10.1007/978-3-642-24088-1_12
   Dreuw P., 2009, BRIT MACH VIS C, P602
   Nguyen DT, 2014, NEUROCOMPUTING, V140, P242, DOI 10.1016/j.neucom.2014.03.017
   Nguyen DT, 2013, PATTERN RECOGN, V46, P1485, DOI 10.1016/j.patcog.2012.10.024
   Nguyen DT, 2010, IEEE IMAGE PROC, P4609, DOI 10.1109/ICIP.2010.5651633
   Farag A., 2004, Advanced Concepts for Intelligent Vision Systems, P125
   Freeman J., 1975, Computer graphics and image processing, V4, P156, DOI DOI 10.1016/S0146-664X(75)80007-4
   Gao YS, 2005, PATTERN RECOGN, V38, P1009, DOI 10.1016/j.patcog.2004.12.006
   Gao YS, 2002, IEEE T PATTERN ANAL, V24, P764, DOI 10.1109/TPAMI.2002.1008383
   Geusebroek JM, 2005, INT J COMPUT VISION, V61, P103, DOI 10.1023/B:VISI.0000042993.50813.60
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Jacobs C. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P277, DOI 10.1145/218380.218454
   Kim D, 2008, 2008 INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P51, DOI 10.1109/IMVIP.2008.15
   Kisku DR, 2007, 2007 IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P63, DOI 10.1109/AUTOID.2007.380594
   Liang Y., 2012, P 2012 ASIA PACIFIC, P1
   Lin SD, 2011, INT J INNOV COMPUT I, V7, P1639
   Liu C, 2008, LECT NOTES COMPUT SC, V5304, P28, DOI 10.1007/978-3-540-88690-7_3
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo J, 2007, INT CONF ACOUST SPEE, P593
   Luo M., 2006, SOFTCBIR OBJECT SEAR
   Manjunath B. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P373, DOI 10.1109/CVPR.1992.223162
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Ogale AS, 2005, IEEE INT CONF ROBOT, P819
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Santosh KC, 2014, INT J DOC ANAL RECOG, V17, P61, DOI 10.1007/s10032-013-0205-4
   Satpathy A, 2014, IEEE T IMAGE PROCESS, V24, P1953, DOI 10.1109/TIP.2014.2310123
   Tan XY, 2006, PATTERN RECOGN, V39, P1725, DOI 10.1016/j.patcog.2006.03.013
   Thoma G, 2012, IT PROF, V14, P13, DOI 10.1109/MITP.2012.25
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang ZL, 2013, IEEE T IMAGE PROCESS, V22, P4341, DOI 10.1109/TIP.2013.2272514
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Yang ZL, 2008, 2008 FOURTH INTERNATIONAL CONFERENCE ON INTELLIGENT INFORMATION HIDING AND MULTIMEDIA SIGNAL PROCESSING, PROCEEDINGS, P1422, DOI 10.1109/IIH-MSP.2008.335
   Ye Q.H.Z., INT C MECH SCI EL EN, P1135
   Ye Z., IEEE INT C SIGN PROC, P857
   Zhao WL, 2009, IEEE T IMAGE PROCESS, V18, P412, DOI 10.1109/TIP.2008.2008900
   Zong Z., 2010, IEEE INT S MULT 2010, P204
NR 54
TC 15
Z9 17
U1 0
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2015
VL 42
BP 1
EP 12
DI 10.1016/j.imavis.2015.06.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CT2BV
UT WOS:000362607900001
DA 2024-07-18
ER

PT J
AU Andalibi, M
   Hoberock, LL
   Mohamadipanah, H
AF Andalibi, Mehran
   Hoberock, Lawrence L.
   Mohamadipanah, Hossein
TI Effects of texture addition on optical flow performance in images with
   poor texture
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optical flow; Poor texture; Foreground detection; Laws' masks;
   F-measure; Boundary displacement error; Condition number
AB This paper investigates the effects of adding texture to images with poorly-textured regions on optical flow performance, namely the accuracy of foreground boundary detection and computation time. Despite significant improvements in optical flow computations, poor texture still remains a challenge to even the most accurate methods. Accordingly, we explored the effects of simple modification of images, rather than the algorithms. To localize and add texture to poorly-textured regions in the background, which induce the propagation of foreground optical flow, we first perform a texture segmentation using Laws' masks and generate a texture map. Next, using a binary frame difference, we constrain the poorly-textured regions to those with negligible motion. Finally, we calculate the optical flow for the modified images with added texture using the best optical flow methods available. It is shown that if the threshold used for binarizing the frame difference is in a specific range determined empirically, variations in the final foreground detection will be insignificant. Employing the texture addition in conjunction with leading optical flow methods on multiple real and animation sequences with different texture distributions revealed considerable advantages, including improvement in the accuracy of foreground boundary preservation, prevention of object merging, and reduction in the computation time. The F-measure and the Boundary Displacement Error metrics were used to evaluate the similarity between detected and ground-truth foreground masks. Furthermore, preventing foreground optical flow propagation and reduction in the computation time are discussed using analysis of optical flow convergence. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Andalibi, Mehran; Hoberock, Lawrence L.; Mohamadipanah, Hossein] Oklahoma State Univ, Adv Technol Res Ctr, Stillwater, OK 74078 USA.
C3 Oklahoma State University System; Oklahoma State University - Stillwater
RP Andalibi, M (corresponding author), Oklahoma State Univ, Adv Technol Res Ctr, Stillwater, OK 74078 USA.
EM mehran.andalibi@okstate.edu; larry.hoberock@okstate.edu;
   hossein.mohamadipanah@okstate.edu
CR Alvarez L, 2007, INT J COMPUT VISION, V75, P371, DOI 10.1007/s11263-007-0041-4
   [Anonymous], 1980, U SO CAL LOS ANG IM
   Aubert G, 1999, SIAM J APPL MATH, V60, P156, DOI 10.1137/S0036139998340170
   Black M.J., 1992, LNCS, P485
   BROX T, 2004, LNCS, V3024
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Bruhn Andres., 2005, IJCV, V61, P211
   Fleet D.J., 2002, BAYESIAN INFERENCE V, P139
   Frebmnet J., 2002, ECCV 02 P 7 EUR C 3
   Haussecker HW, 2001, IEEE T PATTERN ANAL, V23, P661, DOI 10.1109/34.927465
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   HUBER PJ, 1973, ANN STAT, V1, P799, DOI 10.1214/aos/1176342503
   Hubert M, 2008, COMPUT STAT DATA AN, V52, P5186, DOI 10.1016/j.csda.2007.11.008
   Jie Zhao, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P94, DOI 10.1109/ICIG.2011.122
   Kun L., 2009, P 2 INT CONG IMG SIG, P1
   LeVeque RJ, 2007, OTHER TITL APPL MATH, V98, P1, DOI 10.1137/1.9780898717839
   Liu T., 2007, COMP VIS PATT REC CV, P18
   Mitiche A, 2004, IEEE T IMAGE PROCESS, V13, P848, DOI 10.1109/TIP.2004.827235
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833
   Nir T, 2008, INT J COMPUT VISION, V76, P205, DOI 10.1007/s11263-007-0051-2
   Queiro J.F., MATH PAPERS HONOUR E
   Shulman D., 1989, Proceedings. Workshop on Visual Motion (IEEE Cat. No.89CH2716-9), P81, DOI 10.1109/WVM.1989.47097
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   TRefSthen L. N., 1997, NUMERICAL LINEAR ALG
   Vu C, 2011, J ELECTRON IMAGING, V20, DOI 10.1117/1.3549884
   Werlberger M., 2010, P CVPR IEEE
   WERLBERGER M., 2009, BMVC, V1, P3
   Yuan L, 2007, J SYST ENG ELECTRON, V18, P347, DOI 10.1016/S1004-4132(07)60097-8
   Zimmer H., 2009, LNCS, V5681, P214
NR 29
TC 4
Z9 4
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2015
VL 40
BP 1
EP 15
DI 10.1016/j.imavis.2015.04.008
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CO4YD
UT WOS:000359165900001
DA 2024-07-18
ER

PT J
AU Travieso, CM
   Zhang, JG
   Miller, P
   Alonso, JB
AF Travieso, Carlos M.
   Zhang, Jianguo
   Miller, Paul
   Alonso, Jesus B.
TI Using a Discrete Hidden Markov Model Kernel for lip-based biometric
   identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Discrete Hidden Markov Model Kernel; Image processing; Lip-based
   biometrics; Pattern recognition
ID SPEECH RECOGNITION; FACE; VALIDATION; FUSION
AB In this paper, a novel and effective lip-based biometric identification approach with the Discrete Hidden Markov Model Kernel (DHMMK) is developed. Lips are described by shape features (both geometrical and sequential) on two different grid layouts: rectangular and polar. These features are then specifically modeled by a DHMMK, and learnt by a support vector machine classifier. Our experiments are carried out in a ten-fold cross validation fashion on three different datasets, GPDS-ULPGC Face Dataset, PIE Face Dataset and RaFD Face Dataset Results show that our approach has achieved an average classification accuracy of 99.8%, 97.13%, and 98.10%, using only two training images per class, on these three datasets, respectively. Our comparative studies further show that the DHMMK achieved a 53% improvement against the baseline HMM approach. The comparative ROC curves also confirm the efficacy of the proposed lip contour based biometrics learned by DHMMK We also show that the performance of linear and RBF SVM is comparable under the frame work of DHMMK. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Travieso, Carlos M.; Alonso, Jesus B.] Univ Las Palmas Gran Canaria, Inst Technol Dev & Innovat Commun, Signal & Commun Dept, E-35017 Las Palmas Gran Canaria, Spain.
   [Zhang, Jianguo] Univ Dundee, Sch Comp, Dundee DD1 4HN, Scotland.
   [Miller, Paul] Queens Univ Belfast, Inst Elect Commun & Informat Technol, Belfast BT3 9DT, Antrim, North Ireland.
C3 Universidad de Las Palmas de Gran Canaria; University of Dundee; Queens
   University Belfast
RP Travieso, CM (corresponding author), Univ Las Palmas Gran Canaria, Inst Technol Dev & Innovat Commun, Signal & Commun Dept, Campus Univ Tafira,Sn,Ed Telecomunicac,Pabellon B, E-35017 Las Palmas Gran Canaria, Spain.
EM carlos.travieso@ulpgc.es; jgzhang@computing.dundee.ac.uk
RI Alonso-Hernández, Jesús B./N-5977-2014; Travieso-González, Carlos
   M./N-5967-2014
OI Alonso-Hernández, Jesús B./0000-0002-7866-585X; Travieso-González,
   Carlos M./0000-0002-4621-2768; zhang, jianguo/0000-0001-9317-0268
FU Royal Society of Edinburgh under RSE International Exchange Programme;
   Spanish Government [MCINN TEC2012-38630-C04-02]; EPSRC [EP/G034303/1,
   EP/J006238/1, EP/H049606/1, EP/K004379/1] Funding Source: UKRI
FX This work is partially supported by funds from The Royal Society of
   Edinburgh under RSE International Exchange Programme, 2012 to Carlos M.
   Travieso-Gonzalez; and by the Spanish Government, under Grant MCINN
   TEC2012-38630-C04-02.
CR Aleksic PS, 2006, P IEEE, V94, P2025, DOI 10.1109/JPROC.2006.886017
   Alizadeh S, 2008, INT CONF SIGN PROCES, P561, DOI 10.1109/ICOSP.2008.4697195
   [Anonymous], IEEE T IMAGE PROCESS
   [Anonymous], P EUROSPEECH 97
   [Anonymous], ASSP MAG IEEE
   [Anonymous], 2008, HDB BIOMETRICS
   [Anonymous], INT C COMPL SYST INT
   [Anonymous], 2010, 2 INT WORKSHOP INTEL
   [Anonymous], P INT C MULT COMP SY
   Braga-Neto UM, 2004, BIOINFORMATICS, V20, P374, DOI 10.1093/bioinformatics/btg419
   Cervantes J, 2008, NEUROCOMPUTING, V71, P611, DOI 10.1016/j.neucom.2007.07.028
   Chan CH, 2012, IEEE T INF FOREN SEC, V7, P602, DOI 10.1109/TIFS.2011.2175920
   Chetty G, 2007, LECT NOTES COMPUT SC, V4815, P469
   Chiniforoosh S., 2008, IEEE International Telecommunications Energy Conference, P1
   Coianiz T., 1996, NATO ADV STUDY I SPE, P391
   Dargham J.A., 2006, Information and Communication Technologies ICTTA, V1, P1546
   de la Cuesta AG, 2008, 2008 INTERNATIONAL MACHINE VISION AND IMAGE PROCESSING CONFERENCE, PROCEEDINGS, P83, DOI 10.1109/IMVIP.2008.13
   Dong L, 2005, EURASIP J APPL SIG P, V2005, P1382, DOI 10.1155/ASP.2005.1382
   Faraj MI, 2006, INT C PATT RECOG, P1059
   Ferrer MA, 2005, IEEE T PATTERN ANAL, V27, P993, DOI 10.1109/TPAMI.2005.125
   Fox NA, 2007, IEEE T MULTIMEDIA, V9, P701, DOI 10.1109/TMM.2007.893339
   Hernando J, 1997, SPEECH COMMUN, V21, P17, DOI 10.1016/S0167-6393(96)00074-X
   Jaakkola T, 2000, J COMPUT BIOL, V7, P95, DOI 10.1089/10665270050081405
   Jain AK, 2004, INT C PATT RECOG, P935, DOI 10.1109/ICPR.2004.1334413
   Kumar A, 2006, IEEE T IMAGE PROCESS, V15, P2454, DOI 10.1109/TIP.2006.875214
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Len Bui, 2010, Proceedings of the 2010 Fourth International Conference on Network and System Security (NSS 2010), P579, DOI 10.1109/NSS.2010.19
   Lewis T., 2000, ACM INT C P SERIES, V2, P61
   Liang YL, 2008, 2008 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND INFORMATION TECHNOLOGY, PROCEEDINGS, P229, DOI 10.1109/MMIT.2008.25
   Lin Z, 2010, IEEE T PATTERN ANAL, V32, P604, DOI 10.1109/TPAMI.2009.204
   Newman JL, 2010, INT CONF ACOUST SPEE, P5026, DOI 10.1109/ICASSP.2010.5495071
   Newman JL, 2009, INT CONF ACOUST SPEE, P4345, DOI 10.1109/ICASSP.2009.4960591
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Raheja Jagdish Lal, 2010, Proceedings of the 2nd International Conference on Machine Learning and Computing (ICMLC 2010), P3, DOI 10.1109/ICMLC.2010.13
   RAO RR, 1994, CONF REC ASILOMAR C, P587, DOI 10.1109/ACSSC.1994.471520
   Rohani R., 2008, IIT 2008 International Conference on Innovations in Information Technology, P747, DOI 10.1109/INNOVATIONS.2008.4781689
   Salazar A, 2006, Conf Proc IEEE Eng Med Biol Soc, V2006, P5747
   Travieso CM, 2011, NEUROCOMPUTING, V74, P2407, DOI 10.1016/j.neucom.2011.03.012
   Tselios K, 2012, IET BIOMETRICS, V1, P72, DOI 10.1049/iet-bmt.2011.0011
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang SL, 2012, PATTERN RECOGN, V45, P3328, DOI 10.1016/j.patcog.2012.02.016
   Wark T, 1998, INT C PATT RECOG, P123, DOI 10.1109/ICPR.1998.711095
   Yan Xiang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563107
   Yujie D., 2011, INT JOINT C BIOMETRI, P1
NR 45
TC 11
Z9 11
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1080
EP 1089
DI 10.1016/j.imavis.2014.10.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600010
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Monroy, A
   Bell, P
   Ommer, B
AF Monroy, Antonio
   Bell, Peter
   Ommer, Bjoern
TI Morphological analysis for investigating artistic images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape analysis; Registration; Grouping; Model selection; Stability
   analysis; Cultural heritage
AB This paper describes an approach for automatically analyzing the alterations of an original artwork during its reproduction. The overall deformation of the artwork is modelled by a piecewise linear model, where regions of the artwork that feature similar alterations are automatically inferred and assigned to the different model components. Model complexity, that is, the required number of affine components required for registration, is automatically estimated using a statistical stability analysis. The main challenge is to simultaneously solve three tasks: (i) inferring the correspondences between both shapes, (ii) identifying the groups in the image that share the same transformation, and (iii) estimating the transformation of these groups. Our approach is tested on controlled scenarios as well as on real historical images. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Monroy, Antonio; Bell, Peter; Ommer, Bjoern] Heidelberg Univ, HCI, D-69115 Heidelberg, Germany.
   [Monroy, Antonio; Bell, Peter; Ommer, Bjoern] Heidelberg Univ, Interdisciplinary Ctr Sci Comp, D-69115 Heidelberg, Germany.
   [Bell, Peter] Heidelberg Univ, Inst European Art Hist, D-69115 Heidelberg, Germany.
C3 Ruprecht Karls University Heidelberg; Ruprecht Karls University
   Heidelberg; Ruprecht Karls University Heidelberg
RP Ommer, B (corresponding author), Speyerer Str 6, D-69115 Heidelberg, Germany.
EM ommer@uni-heidelberg.de
OI Bell, Peter/0000-0003-4415-7408
CR [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], CVPR
   [Anonymous], CVPR
   Berg AC, 2005, PROC CVPR IEEE, P26
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Carque B., 2010, MANUELLEN REPRODUKTI
   Chang Y.S., 2012, HUMAN VISION ELECT I
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Commowick O., 2008, EFFICIENT LOCALLY AF
   da Silva N., 2008, CVPR
   Hongsheng L., 2011, ICCV
   Kanatani I., 2001, ICCV
   Lange T, 2004, NEURAL COMPUT, V16, P1299, DOI 10.1162/089976604773717621
   Lazic N., 2009, ICCV
   Maire Michael., 2008, CVPR
   Monroy A., 2011, ICIP
   Monroy A., 2012, SHAPING ART ART MORP
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   Paragios N., 2009, NIPS
   Rao C.R., 1999, Springer Series in Statistics
   Sykora D., 2009, AS RIGID AS POSSIBLE
   Usami Y, 2011, PROC SPIE, V7869, DOI 10.1117/12.873194
   Vidal R, 2005, IEEE T PATTERN ANAL, V27, P1945, DOI 10.1109/TPAMI.2005.244
   von Luxburg U., 2010, FDN TRENDS MACH LEAR, V2
   WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981
   Yanv J., 2006, ECCV
NR 26
TC 4
Z9 4
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2014
VL 32
IS 6-7
BP 414
EP 423
DI 10.1016/j.imavis.2014.04.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Arts &amp; Humanities Citation Index (A&amp;HCI)
SC Computer Science; Engineering; Optics
GA AJ4QM
UT WOS:000337660900004
DA 2024-07-18
ER

PT J
AU Idrees, H
   Warner, N
   Shah, M
AF Idrees, Haroon
   Warner, Nolan
   Shah, Mubarak
TI Tracking in dense crowds using prominence and neighborhood motion
   concurrence
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Crowd analysis; Dense crowds; Tracking; Prominence; Neighborhood motion
   concurrence; Hierarchical tracking
AB Methods designed for tracking in dense crowds typically employ prior knowledge to make this difficult problem tractable. In this paper, we show that it is possible to handle this problem, without any priors, by utilizing the visual and contextual information already available in such scenes.
   We propose a novel tracking method tailored to dense crowds which provides an alternative and complementary approach to methods that require modeling of crowd flow and, simultaneously, is less likely to fail in the case of dynamic crowd flows and anomalies by minimally relying on previous frames. Our method begins with the automatic identification of prominent individuals from the crowd that are easy to track. Then, we use Neighborhood Motion Concurrence to model the behavior of individuals in a dense crowd, this predicts the position of an individual based on the motion of its neighbors. When the individual moves with the crowd flow, we use Neighborhood Motion Concurrence to predict motion while leveraging five-frame instantaneous flow in case of dynamically changing flow and anomalies. All these aspects are then embedded in a framework which imposes hierarchy on the order in which positions of individuals are updated. Experiments on a number of sequences show that the proposed solution can track individuals in dense crowds without requiring any pre-processing, making it a suitable online tracking algorithm for dense crowds. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Idrees, Haroon; Shah, Mubarak] Univ Cent Florida, CRCV, Orlando, FL 32816 USA.
   [Warner, Nolan] Univ Nevada, Dept Comp Sci & Engn, Reno, NV 89557 USA.
   [Warner, Nolan] Univ Cent Florida, Natl Sci Fdn REU Program, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida;
   Nevada System of Higher Education (NSHE); University of Nevada Reno;
   State University System of Florida; University of Central Florida
RP Idrees, H (corresponding author), Univ Cent Florida, CRCV, Orlando, FL 32816 USA.
EM haroon@eecs.ucf.edu
RI Sahoo, Sarat Kumar/J-8765-2014
OI Sahoo, Sarat Kumar/0000-0001-5734-6844; Shah,
   Mubarak/0000-0001-6172-5572
FU U.S. Army Research Laboratory; U.S. Army Research Office
   [W911NF-09-1-0255]; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [1156990] Funding Source: National
   Science Foundation
FX This material is based upon work supported in part by the U.S. Army
   Research Laboratory and the U.S. Army Research Office under contract/
   grant number W911NF-09-1-0255.
CR [Anonymous], EUR C COMP VIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], ACM SIGGRAPH EUR S C
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], INT C IM PROC
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C ROB BIOM
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2011, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE WORKSH APPL COM
   [Anonymous], IEEE INT C ROB BIOM
   Chan AB, 2012, IEEE T IMAGE PROCESS, V21, P2160, DOI 10.1109/TIP.2011.2172800
   Fang Z, 2003, FIRE SAFETY J, V38, P271, DOI 10.1016/S0379-7112(02)00058-9
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Kratz L, 2012, IEEE T PATTERN ANAL, V34, P987, DOI 10.1109/TPAMI.2011.173
   Leal-Taixe L, 2011, 1 ICCV WORKSHOP MODE
   Moussaïd M, 2010, PLOS ONE, V5, DOI 10.1371/journal.pone.0010047
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Rodriguez M., 2011, IEEE INT C COMP VIS
   SMITH RA, 1995, SAFETY SCI, V18, P321, DOI 10.1016/0925-7535(94)00051-4
   Sugimura D, 2009, IEEE I CONF COMP VIS, P1467, DOI 10.1109/ICCV.2009.5459286
   Yang M., 2009, IEEE T PATTERN ANAL
   Zhan BB, 2008, MACH VISION APPL, V19, P345, DOI 10.1007/s00138-008-0132-4
NR 36
TC 27
Z9 29
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2014
VL 32
IS 1
BP 14
EP 26
DI 10.1016/j.imavis.2013.10.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AB0RV
UT WOS:000331500700002
DA 2024-07-18
ER

PT J
AU Pertuz, S
   Puig, D
   Garcia, MA
AF Pertuz, Said
   Puig, Domenec
   Angel Garcia, Miguel
TI Reliability measure for shape-from-focus
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image sequences; Focus measure; Shape from focus; Reliability; Depth-map
   carving
ID IMPROVING SHAPE; EXTENDED DEPTH; 3D MODEL; FIELD; FEATURES
AB Shape-from-focus (SFF) is a passive technique widely used in image processing for obtaining depth-maps. This technique is attractive since it only requires a single monocular camera with focus control, thus avoiding correspondence problems typically found in stereo, as well as more expensive capturing devices. However, one of its main drawbacks is its poor performance when the change in the focus level is difficult to detect. Most research in SFF has focused on improving the accuracy of the depth estimation. Less attention has been paid to the problem of providing quality measures in order to predict the performance of SFF without prior knowledge of the recovered scene. This paper proposes a reliability measure aimed at assessing the quality of the depth-map obtained using SFF. The proposed reliability measure (the R-measure) analyzes the shape of the focus measure function and estimates the likelihood of obtaining an accurate depth estimation without any previous knowledge of the recovered scene. The proposed R-measure is then applied for determining the image regions where SFF will not perform correctly in order to discard them. Experiments with both synthetic and real scenes are presented. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Pertuz, Said; Puig, Domenec] Univ Rovira & Virgili, Dept Comp Sci & Math, Intelligent Robot & Comp Vis Grp, Tarragona, Spain.
   [Angel Garcia, Miguel] Autonomous Univ Madrid, Dept Elect & Commun Technol, Madrid, Spain.
C3 Universitat Rovira i Virgili; Autonomous University of Madrid
RP Pertuz, S (corresponding author), Univ Rovira & Virgili, Dept Comp Sci & Math, Intelligent Robot & Comp Vis Grp, Tarragona, Spain.
EM said.pertuz@urv.cat; domenec.puig@urv.cat; miguelangel.garcia@uam.es
RI Pertuz, Said/I-5226-2019; Garcia, Miguel Angel/C-4304-2014
OI Pertuz, Said/0000-0001-8498-9917; Garcia, Miguel
   Angel/0000-0003-2611-6821
CR Aguet F, 2008, IEEE T IMAGE PROCESS, V17, P1144, DOI 10.1109/TIP.2008.924393
   [Anonymous], 2006, P IEEE INT C ACOUSTI, DOI DOI 10.1109/ICASSP.2006.1660387
   [Anonymous], 2009, 19 INT C COMPUTER GR
   Antunes M, 2005, LECT NOTES COMPUT SC, V3656, P174, DOI 10.1007/11559573_22
   Asif M, 2001, IEEE T IMAGE PROCESS, V10, P1670, DOI 10.1109/83.967395
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Buades A, 2005, MULTISCALE MODEL SIM, V4, P490, DOI 10.1137/040616024
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   Chen CY, 2008, IEEE T VIS COMPUT GR, V14, P200, DOI 10.1109/TVCG.2007.70625
   Dias J., 1991, P IEEE RSJ INT WORKS, V1, P249, DOI DOI 10.1109/IR0S.1991.174458
   Forster B, 2004, MICROSC RES TECHNIQ, V65, P33, DOI 10.1002/jemt.20092
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Friedman J, 2000, ANN STAT, V28, P400
   Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46
   Jahne B., 2004, PRACTICAL HDB IMAGE, V2nd
   Jiang ZM, 2005, 2005 IEEE International Conference on Mechatronics and Automations, Vols 1-4, Conference Proceedings, P1118
   Kodama K, 2007, INT CONF ACOUST SPEE, P769
   Lai-Man Po, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2589, DOI 10.1109/ICIP.2011.6116194
   Lin HY, 2001, PROC CVPR IEEE, P663
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Minhas R, 2011, PATTERN RECOGN, V44, P839, DOI 10.1016/j.patcog.2010.10.015
   Muhammad M. S., 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P2965, DOI 10.1109/ICIP.2011.6116283
   Muhammad MS, 2012, IEEE T PATTERN ANAL, V34, P564, DOI 10.1109/TPAMI.2011.144
   Muhammad MS, 2009, PROCEEDINGS OF THE 2009 INTERNATIONAL CONFERENCE OF COMPUTATIONAL SCIENCES AND ITS APPLICATIONS, P191, DOI 10.1109/ICCSA.2009.25
   Nayar S.K., 1989, Shape from Focus
   Nayar SK, 1996, IEEE T PATTERN ANAL, V18, P1186, DOI 10.1109/34.546256
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   Ng KC, 2001, IEEE INT CONF ROBOT, P2791, DOI 10.1109/ROBOT.2001.933045
   Pertuz S, 2013, PATTERN RECOGN, V46, P1415, DOI 10.1016/j.patcog.2012.11.011
   Pertuz S, 2013, IEEE T IMAGE PROCESS, V22, P1242, DOI 10.1109/TIP.2012.2231087
   Pradeep KS, 2007, IEEE T IMAGE PROCESS, V16, P1920, DOI 10.1109/TIP.2007.899188
   Pradeep KS, 2006, INT C PATT RECOG, P731
   Sagawa R, 2008, IEEE T PATTERN ANAL, V30, P686, DOI 10.1109/TPAMI.2007.70726
   Shoji H, 2006, 2006 IEEE 12TH DIGITAL SIGNAL PROCESSING WORKSHOP & 4TH IEEE SIGNAL PROCESSING EDUCATION WORKSHOP, VOLS 1 AND 2, P566, DOI 10.1109/DSPWS.2006.265487
   SUBBARAO M, 1995, IEEE T PATTERN ANAL, V17, P266, DOI 10.1109/34.368191
   SUBBARAO M, 1993, OPT ENG, V32, P2824, DOI 10.1117/12.147706
   Sundaram H, 1997, PROC CVPR IEEE, P814, DOI 10.1109/CVPR.1997.609421
   Tian J, 2010, IEEE IMAGE PROC, P1205, DOI 10.1109/ICIP.2010.5651791
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Tsai DC, 2012, IEEE T IMAGE PROCESS, V21, P459, DOI 10.1109/TIP.2011.2164417
   Watanabe M., 1995, TELECENTRIC OPTICS C
   Wong E., 2006, P IEEE INT C AC SPEE, V3
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
NR 43
TC 21
Z9 28
U1 1
U2 41
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 725
EP 734
DI 10.1016/j.imavis.2013.07.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900004
DA 2024-07-18
ER

PT J
AU Chen, W
   Mied, RP
AF Chen, Wei
   Mied, Richard P.
TI Optical flow estimation for motion-compensated compression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optical flow; Optical flow determination; Optical flow estimation;
   Displacement estimation; Velocity estimation; Motion compensation;
   Motion-compensated prediction; Motion-compensated interpolation;
   Motion-Compensated Compression
ID COMPUTATION
AB The computation of optical flow within an image sequence is one of the most widely used techniques in computer vision. In this paper, we present a new approach to estimate the velocity field for motion-compensated compression. It is derived by a nonlinear system using the direct temporal integral of the brightness conservation constraint equation or the Displaced Frame Difference (DFD) equation. To solve the nonlinear system of equations, an adaptive framework is used, which employs velocity field modeling, a nonlinear least-squares model, Gauss-Newton and Levenberg-Marquardt techniques, and an algorithm of the progressive relaxation of the over-constraint. The three criteria by which successful motion-compensated compression is judged are 1.) The fidelity with which the estimated optical flow matches the ground truth motion, 2.) The relative absence of artifacts and "dirty window" effects for frame interpolation, and 3.) The cost to code the motion vector field. We base our estimated flow field on a single minimized target function, which leads to motion-compensated predictions without incurring penalties in any of these three criteria. In particular, we compare our proposed algorithm results with those from Block-Matching Algorithms (BMA), and show that with nearly the same number of displacement vectors per fixed block size, the performance of our algorithm exceeds that of BMA in all the three above points. We also test the algorithm on synthetic and natural image sequences, and use it to demonstrate applications for motion-compensated compression. Published by Elsevier B.V.
C1 [Chen, Wei; Mied, Richard P.] USN, Res Lab, Remote Sensing Div, Washington, DC 20375 USA.
C3 United States Department of Defense; United States Navy; Naval Research
   Laboratory
RP Chen, W (corresponding author), USN, Res Lab, Remote Sensing Div, Washington, DC 20375 USA.
EM wei.chen@nrl.navy.mil
FU Office of Naval Research at the Naval Research Laboratory [WU-4279-02]
FX This research work was supported by the Office of Naval Research through
   the project WU-4279-02 at the Naval Research Laboratory.
CR Alvarez L., 1999, INTELLIGENCE, V13, p[1349, 775]
   Aubert G, 1999, SIAM J APPL MATH, V60, P156, DOI 10.1137/S0036139998340170
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Botella G, 2010, IEEE T VLSI SYST, V18, P616, DOI 10.1109/TVLSI.2009.2013957
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Cafforio C., 1983, IMAGE SEQUENCE PROCE, P104
   Chan Wai-Yip, 2001, IEEE SIGNAL PROCESS, V8
   Chen W, 2010, IEEE T GEOSCI REMOTE, V48, P1931, DOI 10.1109/TGRS.2009.2037316
   Chen W, 2008, J GEOPHYS RES-OCEANS, V113, DOI 10.1029/2008JC004747
   FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772
   Galvin B., 1998, P 1998 BRIT MACH VIS
   Ghanbari H., 1990, IEEE T CIRCUITS SYST, V37, P649
   Glazer F., 1983, P IEEE COMP VIS PATT
   González D, 2011, PROC SPIE, V8058, DOI 10.1117/12.883684
   HEITZ F, 1993, IEEE T PATTERN ANAL, V15, P1217, DOI 10.1109/34.250841
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Konrad J., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P1072, DOI 10.1109/ICASSP.1988.196780
   Kumar A, 1996, IEEE T IMAGE PROCESS, V5, P598, DOI 10.1109/83.491336
   Lee D.J., 2008, Int. Journal of Reconfigerable Computing, V2008, P8
   Lucas B., 1981, DARPA IU WORKSHOP, P121
   Lucas B.D., 1984, THESIS CARNEGIE MELL
   Mahalingam V, 2010, IEEE T VLSI SYST, V18, P29, DOI 10.1109/TVLSI.2008.2006900
   McCane B, 2001, COMPUT VIS IMAGE UND, V84, P126, DOI 10.1006/cviu.2001.0930
   Nagel H., 1990, LNCS, V427, P139
   Nagel H., 1983, INT JOINT C ART INT, V2, P945
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833
   NESI P, 1993, IMAGE VISION COMPUT, V11, P419, DOI 10.1016/0262-8856(93)90046-J
   Papenberg N, 2006, INT J COMPUT VISION, V67, P141, DOI 10.1007/s11263-005-3960-y
   Proesmans M., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P295
   Robbins J. D., 1983, IMAGE SEQUENCE PROCE, P76, DOI DOI 10.1007/978-3-642-81935-3_3
   SEFERIDIS V, 1993, OPT ENG, V32, P1464, DOI 10.1117/12.138613
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Stiller C, 1999, IEEE SIGNAL PROC MAG, V16, P70, DOI 10.1109/79.774934
   Thompson WB, 1998, INT J COMPUT VISION, V30, P163, DOI 10.1023/A:1008026031844
   URAS S, 1988, BIOL CYBERN, V60, P79, DOI 10.1007/BF00202895
   WALKER DR, 1984, IEEE T COMMUN, V32, P1128, DOI 10.1109/TCOM.1984.1095975
   Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973
NR 40
TC 12
Z9 14
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2013
VL 31
IS 3
BP 275
EP 289
DI 10.1016/j.imavis.2013.01.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 122NK
UT WOS:000317324600005
DA 2024-07-18
ER

PT J
AU Sheridan, P
   Thornton, B
AF Sheridan, Phillip
   Thornton, Barry
TI Contextual modulation via low-level vision processing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gabor wavelet; Contextual modulation; Primary visual cortex;
   Computational model; Orientation pinwheels
ID PRIMARY VISUAL-CORTEX; STRIATE CORTEX; CONTOUR-DETECTION; ORIENTATION;
   SELECTIVITY; CELLS; FACILITATION; SUPPRESSION
AB Gabor wavelets are well established as being useful for modeling neuronal response properties of the primary visual cortex. However, current Gabor models do not account for long-range contextual modulation. This paper introduces a new model which extends a state-of-the-art model of contextual modulation by incorporating long-range convolution at the scale of the visual field. The significance of this new mechanism is that it accounts for perceptual filling-in of occluded receptive fields with purely low-level vision processing. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Sheridan, Phillip] Griffith Univ, Sch Informat & Commun Technol, Meadowbrook, Qld 4131, Australia.
   [Thornton, Barry] Univ Technol Sydney, Dept Math, Sydney, NSW 2007, Australia.
   [Thornton, Barry] Univ Sydney, Sch Phys, Sydney, NSW 2006, Australia.
C3 Griffith University; Griffith University - Logan Campus; University of
   Technology Sydney; University of Sydney
RP Sheridan, P (corresponding author), Griffith Univ, Sch Informat & Commun Technol, Univ Dr, Meadowbrook, Qld 4131, Australia.
EM p.sheridan@griffith.edu.au
CR Alexander DM, 2010, COGN NEURODYNAMICS, V4, P1, DOI 10.1007/s11571-009-9098-9
   Alexander DM, 2004, VISION RES, V44, P857, DOI 10.1016/j.visres.2003.11.009
   Bair W, 2004, J NEUROSCI, V24, P7305, DOI 10.1523/JNEUROSCI.0554-04.2004
   Bianconi F, 2007, PATTERN RECOGN, V40, P3325, DOI 10.1016/j.patcog.2007.04.023
   BLAKEMORE C, 1972, EXP BRAIN RES, V15, P439
   BLASDEL GG, 1992, J NEUROSCI, V12, P3139, DOI 10.1523/JNEUROSCI.12-08-03139.1992
   BONHOEFFER T, 1991, NATURE, V353, P429, DOI 10.1038/353429a0
   Bruce V., 2003, Visual perception: Physiology, psychology, and ecology
   Cavanaugh JR, 2002, J NEUROPHYSIOL, V88, P2547, DOI 10.1152/jn.00693.2001
   DEVALOIS KK, 1979, J PHYSIOL-LONDON, V291, P483, DOI 10.1113/jphysiol.1979.sp012827
   FIORANI M, 1992, P NATL ACAD SCI USA, V89, P8547, DOI 10.1073/pnas.89.18.8547
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Huang WT, 2008, NEURAL NETWORKS, V21, P1182, DOI 10.1016/j.neunet.2008.06.001
   HUBEL DH, 1977, PROC R SOC SER B-BIO, V198, P1, DOI 10.1098/rspb.1977.0085
   Kimura R, 2009, J NEUROPHYSIOL, V101, P1463, DOI 10.1152/jn.90681.2008
   LAMME VAF, 1995, J NEUROSCI, V15, P1605
   Lamme VAF, 1998, P NATL ACAD SCI USA, V95, P3263, DOI 10.1073/pnas.95.6.3263
   Lee HC, 2003, IEEE IJCNN, P206
   Lee TS, 1998, VISION RES, V38, P2429, DOI 10.1016/S0042-6989(97)00464-1
   MAFFEI L, 1976, VISION RES, V16, P1131, DOI 10.1016/0042-6989(76)90253-4
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Murphy KM, 1998, CEREB CORTEX, V8, P237, DOI 10.1093/cercor/8.3.237
   NELSON JI, 1985, EXP BRAIN RES, V61, P54
   OBERMAYER K, 1993, J NEUROSCI, V13, P4114
   RAMACHANDRAN VS, 1992, SCI AM, V266, P86, DOI 10.1038/scientificamerican0592-86
   SANGER TD, 1988, BIOL CYBERN, V59, P405, DOI 10.1007/BF00336114
   Sceniak MP, 2001, J NEUROPHYSIOL, V85, P1873, DOI 10.1152/jn.2001.85.5.1873
   SCHILLER PH, 1976, J NEUROPHYSIOL, V39, P1334, DOI 10.1152/jn.1976.39.6.1334
   Sheridan P, 2000, IMAGE VISION COMPUT, V18, P907, DOI 10.1016/S0262-8856(00)00036-6
   Sheridan P, 2007, IEEE T IMAGE PROCESS, V16, P1355, DOI 10.1109/TIP.2007.891790
   Sillito AM, 1996, J PHYSIOL-PARIS, V90, P205, DOI 10.1016/S0928-4257(97)81424-6
   Tang QL, 2007, PATTERN RECOGN, V40, P3100, DOI 10.1016/j.patcog.2007.02.009
   Toth LJ, 1996, P NATL ACAD SCI USA, V93, P9869, DOI 10.1073/pnas.93.18.9869
   Ursino M, 2004, NEURAL NETWORKS, V17, P719, DOI 10.1016/j.neunet.2004.03.007
   Yao XZ, 2007, BRAIN RES, V1170, P140, DOI 10.1016/j.brainres.2007.06.077
   Zipser K, 1996, J NEUROSCI, V16, P7376
NR 36
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2012
VL 30
IS 4-5
BP 367
EP 377
DI 10.1016/j.imavis.2012.03.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 964WF
UT WOS:000305726700009
DA 2024-07-18
ER

PT J
AU Luo, HL
   Wei, H
   Hu, FX
AF Luo, Hui-Lan
   Wei, Hui
   Hu, Fan-Xing
TI Improvements in image categorization using codebook ensembles
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image categorization; Visual codebook; Ensemble learning
ID OBJECT; CLASSIFICATION; VOCABULARIES; RECOGNITION; FEATURES; TEXTURE
AB The problem of object category classification by committees or ensembles of classifiers, each of which is based on one diverse codebook, is addressed in this paper. Two methods of constructing visual codebook ensembles are proposed in this study. The first technique introduces diverse individual visual codebooks using different clustering algorithms. The second uses various visual codebooks of different sizes for constructing an ensemble with high diversity. Codebook ensembles are trained to capture and convey image properties from different aspects. Based on these codebook ensembles, different types of image representations can be acquired. A classifier ensemble can be trained based on different expression datasets from the same training image set. The use of a classifier ensemble to categorize new images can lead to improved performance. Detailed experimental analysis on a Pascal VOC challenge dataset reveals that the present ensemble approach performs well, consistently improves the performance of visual object classifiers, and results in state-of-the-art performance in categorization. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Luo, Hui-Lan; Wei, Hui; Hu, Fan-Xing] Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.
   [Luo, Hui-Lan] Jiangxi Univ Sci & Technol, Sch Informat Engn, Ganzhou, Peoples R China.
C3 Fudan University; Jiangxi University of Science & Technology
RP Wei, H (corresponding author), Fudan Univ, Sch Comp Sci, Shanghai, Peoples R China.
EM huilan_luo@fudan.edu.cn; weihui@fudan.edu.cn; 09210240013@fudan.edu.cn
RI Wei, Hui/K-5819-2019
FU National Natural Science Foundation of China (NSFC) [61105042,
   30990263]; 973 Program of China [2010CB327900]; Shanghai Key Laboratory
   of Intelligent Information Processing, China [IIPL-09-009]; Natural
   Science Foundation of Jiangxi Province, China [2010GZS0075]; Educational
   Commission of Jiangxi Province, China [GJJ11464, GJJ11465]
FX This work was supported by a National Natural Science Foundation of
   China (NSFC) project (No. 61105042 and Major Program No. 30990263), 973
   Program of China (No. 2010CB327900), Shanghai Key Laboratory of
   Intelligent Information Processing, China (Grant No. IIPL-09-009),
   Natural Science Foundation of Jiangxi Province, China (Project No.
   2010GZS0075), and Educational Commission of Jiangxi Province, China
   (Project No. GJJ11464 and GJJ11465). The authors thank the anonymous
   referees for their helpful comments.
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2003, INT C INT C MACH LEA, DOI DOI 10.1016/0026-2714(92)90278-S
   [Anonymous], 18 ANN C NEUR INF PR
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Dietterich TG, 2000, MACH LEARN, V40, P139, DOI 10.1023/A:1007607513941
   EVERINGHAM M, 2007, PASCAL VOC 07 CHALL
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242
   Fergus R, 2003, PROC CVPR IEEE, P264
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   HANSEN LK, 1990, IEEE T PATTERN ANAL, V12, P993, DOI 10.1109/34.58871
   JURIE F, 2005, P 10 IEEE INT C COMP, V1
   KARYPIS G, CLUTO SOFTWARE CLUST
   Larlus D, 2009, IMAGE VISION COMPUT, V27, P523, DOI 10.1016/j.imavis.2008.04.022
   Law MHC, 2004, PROC CVPR IEEE, P424
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Leibe B., 2003, BMVC
   Leibe B, 2008, IMAGE VISION COMPUT, V26, P15, DOI 10.1016/j.imavis.2007.08.012
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   LI FF, 2004, CVPR WORKSH GMBV
   Li Y., 2008, 4 INT C WIRELESS COM, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Marée R, 2005, PROC CVPR IEEE, P34
   Marszalek M., 2007, VIS REC CHALL WORKSH
   MARSZATEK M, 2008, LIMITS BAG OF FEATUR
   Melville P., 2003, In: International Joint Conference on Artificial Intelligence, V3, P505
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Nister D., 2006, IEEE COMP SOC C COMP, P2161, DOI [10.1109/cvpr.2006.264, DOI 10.1109/CVPR.2006.264, 10.1109/CVPR]
   Opelt A, 2006, IEEE T PATTERN ANAL, V28, P416, DOI 10.1109/TPAMI.2006.54
   Perronnin F, 2008, IEEE T PATTERN ANAL, V30, P1243, DOI 10.1109/TPAMI.2007.70755
   Rokach L, 2010, ARTIF INTELL REV, V33, P1, DOI 10.1007/s10462-009-9124-7
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Strehl A., 2002, J. Machine Learning Res, V3, P583
   Topchy A, 2005, IEEE T PATTERN ANAL, V27, P1866, DOI 10.1109/TPAMI.2005.237
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Vedaldi A., 2009, ICCV
   Vedaldi A., VLFEAT OPEN PORTABLE
   Wang G, 2009, PROC CVPR IEEE, P1367, DOI 10.1109/CVPRW.2009.5206816
   Weber M, 2000, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2000.854754
   Winn J, 2005, IEEE I CONF COMP VIS, P1800
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang T., 1996, BIRCH EFFICIENT DATA, V25, P103, DOI [DOI 10.1145/233269.233324, 10.1145/235968.233324]
NR 49
TC 6
Z9 7
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2011
VL 29
IS 11
BP 759
EP 773
DI 10.1016/j.imavis.2011.08.005
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 864EE
UT WOS:000298219000005
DA 2024-07-18
ER

PT J
AU Heinrich, SB
   Snyder, WE
   Frahm, JM
AF Heinrich, Stuart B.
   Snyder, Wesley E.
   Frahm, Jan-Michael
TI Maximum likelihood autocalibration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Autocalibration; Self-calibration; Maximum likelihood; Absolute dual
   quadric; Structure from motion
ID LEAST-SQUARES ESTIMATION; SELF-CALIBRATION; MOTION
AB This paper addresses the problem of autocalibration, which is a critical step in existing uncalibrated structure from motion algorithms that utilize an initialization to avoid the local minima in metric bundle adjustment. Currently, all known direct (not non-linear) solutions to the uncalibrated structure from motion problem solve for a projective reconstruction that is related to metric by some unknown homography, and hence a necessary step in obtaining a metric reconstruction is the subsequent estimation of the rectifying homography, known as autocalibration. Although autocalibration is a well-studied problem, previous approaches have relied upon heuristic objective functions, and have a reputation for instability. We propose a maximum likelihood objective and show that it can be implemented robustly and efficiently and often provides substantially greater accuracy, especially when there are fewer views or greater noise. E) (C) 2011 Elsevier B.V. All rights reserved.
C1 [Heinrich, Stuart B.; Snyder, Wesley E.] N Carolina State Univ, Dept Elect & Comp Engn, Raleigh, NC 27695 USA.
   [Frahm, Jan-Michael] Univ N Carolina, Dept Comp Sci, Chapel Hill, NC 27599 USA.
C3 North Carolina State University; University of North Carolina;
   University of North Carolina Chapel Hill
RP Heinrich, SB (corresponding author), N Carolina State Univ, Dept Elect & Comp Engn, Box 7911, Raleigh, NC 27695 USA.
EM sbheinri@ncsu.edu
FU Army Research Office [W911NF-09-1-0458]
FX We thank Dr. Andrea Fusielli and Dr. Riccardo Gherardi for providing the
   Piazza clei Signore reconstruction, Dr. Enrique Dunn for providing the
   video reconstruction and Richard Steffen for providing the Brandenburg
   Gate reconstruction. We thank Dr. Margaret J. Eppstein for her comments
   throughout, as well as the anonymous reviewers for their many specific
   suggestions. SBH was sponsored in part by the Army Research Office under
   grant W911NF-09-1-0458.
CR Agrawal M, 2004, IEEE IMAGE PROC, P3379
   [Anonymous], ECCV 92
   [Anonymous], THESIS U PARIS SUD P
   [Anonymous], COMP VIS WORKSH ICCV
   [Anonymous], THESIS ROBOTVIS GROU
   [Anonymous], 1981, COMMUNICATIONS ACM
   [Anonymous], MOT VID COMP 2007 WM
   [Anonymous], ECCV 2010 P 11 EUR C
   [Anonymous], 1996, J HOPKINS STUDIES MA
   [Anonymous], CAM CAL SEARCH INF C
   [Anonymous], CVPR 97
   [Anonymous], ICCV 99
   [Anonymous], ICCV 99
   [Anonymous], ROB AUT ICRA 2010 IE
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], ICCV 98
   Bocquillon B., 2007, IEEE COMPUTER SOC C, V0, P1, DOI [10.1109/CVPR.2007.383066, DOI 10.1109/CVPR.2007.383066]
   Chandraker M, 2010, INT J COMPUT VISION, V90, P236, DOI 10.1007/s11263-009-0305-2
   Chandraker Manmohan., 2007, IEEE Int'l Conf. on Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383288
   FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564
   Frahm JM, 2010, LECT NOTES COMPUT SC, V6314, P368, DOI 10.1007/978-3-642-15561-1_27
   Fusiello A, 2004, IEEE T PATTERN ANAL, V26, P1633, DOI 10.1109/TPAMI.2004.125
   Gao YY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P537
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   HARTLEY RI, 1992, LECT NOTES COMPUT SC, V588, P579
   Hartley RI, 1998, INT J COMPUT VISION, V26, P41, DOI 10.1023/A:1007984508483
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P133, DOI 10.1109/34.574792
   Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9
   HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368
   Kruppa E., 1913, Sitz.-Ber. Akad. Wiss., Wien, V122, P1939
   Lao WL, 2004, IEEE IMAGE PROC, P3391
   Lourakis M., 2004, 340 FORTH I COMP SCI
   Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   Mendonca P. R. S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P500, DOI 10.1109/CVPR.1999.786984
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nistér D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P116, DOI 10.1109/ICCV.2001.937612
   Pollefeys M, 1999, IEEE T PATTERN ANAL, V21, P707, DOI 10.1109/34.784285
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705
   Pollefeys M, 2002, LECT NOTES COMPUT SC, V2351, P837
   Pollefeys M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P349, DOI 10.1109/ICPR.1996.546047
   Ponce J., 2001, 3D Structure from Images - SMILE 2000. Second European Workshop on 3D Structure from Multiple Images of Large-Scale Environments. Revised Papers (Lecture Notes in Computer Science Vol.2018), P52
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Triggs B., 2000, VISION ALGORITHMS TH, P298, DOI DOI 10.1007/3-540-44480-7_21THISWORKWASSUPPORTEDINPARTBYTHEEUROPEAN
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Vieville T, 1996, INT J COMPUT VISION, V17, P7, DOI 10.1007/BF00127817
NR 48
TC 3
Z9 3
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2011
VL 29
IS 10
BP 653
EP 665
DI 10.1016/j.imavis.2011.07.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 848YP
UT WOS:000297091300002
DA 2024-07-18
ER

PT J
AU Larrey-Ruiz, J
   Verdú-Monedero, R
   Morales-Sánchez, J
   Angulo, J
AF Larrey-Ruiz, Jorge
   Verdu-Monedero, Rafael
   Morales-Sanchez, Juan
   Angulo, Jesus
TI Frequency domain regularization of <i>d</i>-dimensional structure
   tensor-based directional fields
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Directional field regularization; Variational methods; Frequency domain
   formulation; Orientation estimation
ID NONLINEAR DIFFUSION; IMAGE; COMPUTATION; ALGORITHM
AB The present work is intended to address two of the major difficulties that can be found when tackling the estimation of the local orientation of the data in a scene, a task which is usually accomplished by means of the computation of the structure tensor-based directional field. On one hand, the orientation information only exists in the non-homogeneous regions of the dataset, while it is zero in the areas where the gradient (i.e. the first-order intensity variation) remains constant. Due to this lack of information, there are many cases in which the overall shape of the represented objects cannot be precisely inferred from the directional field. On the other hand, the orientation estimation is highly dependent on the particular choice of the averaging window used for its computation (since a collection of neighboring gradient vectors is needed to obtain a dominant orientation), typically resulting in vector fields which vary from very irregular (thus yielding a noisy estimation) to very uniform (but at the expense of a loss of angular resolution). The proposed solution to both drawbacks is the regularization of the directional field; this process extends smoothly the previously computed vectors to the whole dataset while preserving the angular information of relevant structures. With this purpose, the paper introduces a suitable mathematical framework and deals with the d-dimensional variational formulation which is derived from it. The proposed formulation is finally translated into the frequency domain in order to obtain an increase of insight on the regularization problem, which can be understood as a low-pass filtering of the directional field. The frequency domain point of view also allows for an efficient implementation of the resulting iterative algorithm. Simulation experiments involving datasets of different dimensionality prove the validity of the theoretical approach. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Larrey-Ruiz, Jorge; Verdu-Monedero, Rafael; Morales-Sanchez, Juan] Univ Politecn Cartagena, Dept Tecnol Informac & Comunicac, Cartagena 30202, Spain.
   [Angulo, Jesus] MINES Paristech, CMM Ctr Morphol Math Math & Syst, F-77300 Fontainebleau, France.
C3 Universidad Politecnica de Cartagena; Universite PSL; MINES ParisTech
RP Larrey-Ruiz, J (corresponding author), Univ Politecn Cartagena, Dept Tecnol Informac & Comunicac, Cartagena 30202, Spain.
EM jorge.larrey@upct.es
RI Verdú-Monedero, Rafael/A-2473-2012; Morales-Sánchez, Juan/KHW-1192-2024
OI Verdú-Monedero, Rafael/0000-0001-9227-7397; Morales-Sánchez,
   Juan/0000-0002-2894-3292
FU Spanish Ministerio de Ciencia e Innovacion [TEC2009-12675]
FX This work is partially supported by the Spanish Ministerio de Ciencia e
   Innovacion, under grant TEC2009-12675.
CR Anderson M., 1998, SAE TECHNICAL PAPER, P1
   [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], 1999, NUMER MATH SCI COMP
   [Anonymous], 1999, Handbook of Computer Vision and Applications
   [Anonymous], 1977, SOLUTIONS ILL POSED
   Bai J, 2007, IEEE T IMAGE PROCESS, V16, P2492, DOI 10.1109/TIP.2007.904971
   Bazen A.M., 2001, P PRORISC2001 ANN WO, V12, P1
   Bazen AM, 2002, IEEE T PATTERN ANAL, V24, P905, DOI 10.1109/TPAMI.2002.1017618
   Behmardi D., 2008, Applied Mathematical Sciences, V2, P975
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Burgeth B, 2009, ADV PATTERN RECOGNIT, P125, DOI 10.1007/978-1-84882-299-3_6
   Christiansen O, 2007, INT J BIOMED IMAGING, V2007, DOI 10.1155/2007/27432
   Davis P. J., 1979, Circulant Matrices, V1st
   Engl H. W., 1996, REGULARIZATION INVER, V375
   Farnebäck G, 2000, INT C PATT RECOG, P135
   Feddern C, 2006, INT J COMPUT VISION, V69, P93, DOI 10.1007/s11263-006-6854-8
   Fernández JJ, 2003, J STRUCT BIOL, V144, P152, DOI 10.1016/j.jsb.2003.09.010
   Fischer B, 2004, LINEAR ALGEBRA APPL, V380, P107, DOI 10.1016/j.laa.2003.10.021
   Fischer B, 2003, J MATH IMAGING VIS, V18, P81, DOI 10.1023/A:1021897212261
   Fischer B, 1999, NUMER ALGORITHMS, V22, P1, DOI 10.1023/A:1019194421221
   Forsyth A.R., 1960, CALCULUS VARIATIONS
   Garding J, 1996, INT J COMPUT VISION, V17, P163, DOI 10.1007/BF00058750
   Gelfand I.M., 2000, Calculus of Variations
   Henn S, 2006, J MATH IMAGING VIS, V24, P195, DOI 10.1007/s10851-005-3621-3
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   KASS M, 1987, COMPUT VISION GRAPH, V37, P362, DOI 10.1016/0734-189X(87)90043-0
   Knutsson H., 1989, Proceedings of 6th Scandinavian Conference on Image Analysis, P244
   Kühne G, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P73, DOI 10.1109/ICIP.2001.958427
   Larrey-Ruiz J, 2007, SIGNAL PROCESS, V87, P2837, DOI 10.1016/j.sigpro.2007.05.028
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Maes F, 2003, P IEEE, V91, P1699, DOI 10.1109/JPROC.2003.817864
   Maragos P, 2009, IEEE IMAGE PROC, P2241, DOI 10.1109/ICIP.2009.5413961
   Mei Y, 2009, IMAGE VISION COMPUT, V27, P1169, DOI 10.1016/j.imavis.2008.11.003
   Modersitzki J., 2004, NUMER MATH SCI COMP
   Oppenheim A. V., 1999, DISCRETE TIME SIGNAL, DOI DOI 10.1049/EP.1977.0078
   Perona P, 1998, IEEE T IMAGE PROCESS, V7, P457, DOI 10.1109/83.661195
   Rao A. R., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P61, DOI 10.1109/CVPR.1989.37829
   *RES CTR CAES, 1999, JUL SOFTW DEV FRAM
   Rieger B, 2004, IMAGE VISION COMPUT, V22, P453, DOI 10.1016/j.imavis.2003.11.005
   Robb Katharina, 2007, 7th International Conference on Hybrid Intelligent Systems, HIS 2007, P320
   Roche A, 1998, LECT NOTES COMPUT SC, V1496, P1115, DOI 10.1007/BFb0056301
   Schladitz K, 2006, LECT NOTES COMPUT SC, V4245, P247
   Tankyevych O, 2008, I S BIOMED IMAGING, P1011, DOI 10.1109/ISBI.2008.4541170
   THERRIEN CW, 1992, DISCRETE RANDOM SIGN
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Tschumperle D., 2001, IEEE COMPUTER VISION, V1, P1
   Tschumperlé D, 2006, INT J COMPUT VISION, V68, P65, DOI 10.1007/s11263-006-5631-z
   Verdú-Monedero R, 2008, IEEE SIGNAL PROC LET, V15, P321, DOI 10.1109/LSP.2007.913588
   Verdú-Monedero R, 2008, LECT NOTES COMPUT SC, V5259, P542, DOI 10.1007/978-3-540-88458-3_49
   Weeks J., 1985, The Shape of Space: How to Visualize Surfaces and Three-dimensional Manifolds
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Weickert J., 2002, CONT MATH, P251
   Westin CF, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P381, DOI 10.1007/3-540-31272-2_24
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Yu ZY, 2006, IEEE IMAGE PROC, P2513, DOI 10.1109/ICIP.2006.312804
NR 58
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2011
VL 29
IS 9
BP 620
EP 630
DI 10.1016/j.imavis.2011.06.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 836PI
UT WOS:000296123200005
DA 2024-07-18
ER

PT J
AU Xue, JH
   Titterington, DM
AF Xue, Jing-Hao
   Titterington, D. Michael
TI Median-based image thresholding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Image thresholding; Laplace distributions; Mean
   absolute deviation from the median (MAD); Minimum error thresholding
   (MET); Otsu's method
ID GENERALIZED GAUSSIAN DISTRIBUTION
AB In order to select an optimal threshold for image thresholding that is relatively robust to the presence of skew and heavy-tailed class-conditional distributions, we propose two median-based approaches: one is an extension of Otsu's method and the other is an extension of Kittler and Illingworth's minimum error thresholding. We provide theoretical interpretation of the new approaches, based on mixtures of Laplace distributions. The two extensions preserve the methodological simplicity and computational efficiency of their original methods, and in general can achieve more robust performance when the data for either class is skew and heavy-tailed. We also discuss some limitations of the new approaches. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Xue, Jing-Hao] UCL, Dept Stat Sci, London WC1E 6BT, England.
   [Titterington, D. Michael] Univ Glasgow, Sch Math & Stat, Glasgow G12 8QQ, Lanark, Scotland.
C3 University of London; University College London; University of Glasgow
RP Xue, JH (corresponding author), UCL, Dept Stat Sci, Mortimer St, London WC1E 6BT, England.
EM jinghao@stats.ucl.ac.uk; michael.titterington@gla.ac.uk
RI cai, bo/G-1491-2010
FU EU
FX The NDT images are provided through the courtesy of Dr. Mehmet Sezgin.
   This work was partly supported by funding to J.-H.X. from the Internal
   Visiting Programme of the EU-funded PASCAL2 Network of Excellence. We
   are grateful for the referees' generous and constructive suggestions.
CR Bazi Y, 2007, PATTERN RECOGN, V40, P619, DOI 10.1016/j.patcog.2006.05.006
   Fan SKS, 2008, NEUROCOMPUTING, V72, P500, DOI 10.1016/j.neucom.2007.12.015
   FIELLER NRJ, 1992, J R STAT SOC C-APPL, V41, P127
   GLASBEY CA, 1993, CVGIP-GRAPH MODEL IM, V55, P532, DOI 10.1006/cgip.1993.1040
   Guo R, 1998, MACH VISION APPL, V10, P331, DOI 10.1007/s001380050083
   Hammouche K, 2010, ENG APPL ARTIF INTEL, V23, P676, DOI 10.1016/j.engappai.2009.09.011
   KITTLER J, 1985, IEEE T SYST MAN CYB, V15, P652, DOI 10.1109/TSMC.1985.6313443
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   KURITA T, 1992, PATTERN RECOGN, V25, P1231, DOI 10.1016/0031-3203(92)90024-D
   LEE H, 1990, IEEE T SYST MAN CYB, V20, P741, DOI 10.1109/21.57290
   Moser G, 2006, IEEE T GEOSCI REMOTE, V44, P2972, DOI 10.1109/TGRS.2006.876288
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1993, SIGNAL PROCESS, V33, P139, DOI 10.1016/0165-1684(93)90107-L
   Sahoo PK, 2006, PATTERN RECOGN LETT, V27, P520, DOI 10.1016/j.patrec.2005.09.017
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511
   Xue J.- H., 1999, J ELECT, V16, P336
   XUE JH, 2011, THRESHOLD SELE UNPUB
   XUE JH, 2011, IMAGE THRESHOL UNPUB
   Yan H, 1996, PATTERN RECOGN, V29, P2025, DOI 10.1016/S0031-3203(96)00050-7
   YE QZ, 1988, PATTERN RECOGN LETT, V7, P201, DOI 10.1016/0167-8655(88)90103-1
NR 22
TC 40
Z9 49
U1 3
U2 19
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2011
VL 29
IS 9
BP 631
EP 637
DI 10.1016/j.imavis.2011.06.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 836PI
UT WOS:000296123200006
DA 2024-07-18
ER

PT J
AU Akakin, HÇ
   Sankur, B
AF Akakin, Hatice Cinar
   Sankur, Bulent
TI Robust classification of face and head gestures in video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face and head gesture classification; Facial landmark tracking; Time
   series analysis; Fusion of classifiers
ID FACIAL ACTION; EXPRESSION RECOGNITION; TRACKING; POSE
AB Automatic analysis of head gestures and facial expressions is a challenging research area and it has significant applications in human-computer interfaces. We develop a face and head gesture detector in video streams. The detector is based on face landmark paradigm in that appearance and configuration information of landmarks are used. First we detect and track accurately facial landmarks using adaptive templates, Kalman predictor and subspace regularization. Then the trajectories (time series) of facial landmark positions during the course of the head gesture or facial expression are converted in various discriminative features. Features can be landmark coordinate time series, facial geometric features or patches on expressive regions of the face. We use comparatively, two feature sequence classifiers, that is, Hidden Markov Models (HMM) and Hidden Conditional Random Fields (HCRF), and various feature subspace classifiers, that is, ICA (Independent Component Analysis) and NMF (Non-negative Matrix Factorization) on the spatiotemporal data. We achieve 87.3% correct gesture classification on a seven-gesture test database, and the performance reaches 98.2% correct detection under a fusion scheme. Promising and competitive results are also achieved on classification of naturally occurring gesture clips of LIM-TwoTalk Corpus. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Akakin, Hatice Cinar; Sankur, Bulent] Bogazici Univ, Istanbul, Turkey.
C3 Bogazici University
RP Akakin, HÇ (corresponding author), Bogazici Univ, Istanbul, Turkey.
EM hatice.cinar@boun.edu.tr; bulent.sankur@boun.edu.tr
RI Sankur, Bulent/N-4663-2017
CR AKAKIN HC, 2007, 3DTV C KOS ISL GREEC, P1
   Salah AA, 2007, ANN TELECOMMUN, V62, P83
   [Anonymous], P SPIE
   [Anonymous], 1 COST 2101 WORKSH B
   Aran O, 2010, PATTERN RECOGN, V43, P1776, DOI 10.1016/j.patcog.2009.12.002
   ARI I, 2008, FACIAL FEATURE TRACK, P1
   Boker SM, 2009, PHILOS T R SOC B, V364, P3485, DOI 10.1098/rstb.2009.0152
   BOWDEN R, 2010, LILIR TWOTALK CORPUS
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   CRISTINACCE D, 2006, INT C AUT FAC GEST R
   DEMIRKIR C, 2005, AUDIO VIDEO BASED BI
   Dornaika F, 2008, INT J COMPUT VISION, V76, P257, DOI 10.1007/s11263-007-0059-7
   Ekman P., 1978, Facial action coding system
   Feris R. S., 2000, Proceedings 13th Brazilian Symposium on Computer Graphics and Image Processing (Cat. No.PR00878), P22, DOI 10.1109/SIBGRA.2000.883889
   Flynn PJ, 2003, LECT NOTES COMPUT SC, V2688, P44
   Gatica-Perez D, 2009, IMAGE VISION COMPUT, V27, P1775, DOI 10.1016/j.imavis.2009.01.004
   Hollander M., 2014, Nonparametric Statistical Methods, Solutions Manual, Vthird
   Hupont I., 2008, Electronic Letters on Computer Vision and Image Analysis, V7, P1, DOI DOI 10.5565/rev/elcvia.272
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Ji QA, 2006, IEEE T SYST MAN CY A, V36, P862, DOI 10.1109/TSMCA.2005.855922
   KALIOUBY RA, 2005, UCAMCLTR636
   KANAUJIA A, 2006, C COMP VIS PATT REC, P108
   Kang YG, 2006, LECT NOTES ARTIF INT, V4253, P707
   KAPOOR A, 2001, P WORKSH PERSP US IN
   Kapoor A, 2007, INT J HUM-COMPUT ST, V65, P724, DOI 10.1016/j.ijhcs.2007.02.003
   Knapp M.L., 2006, NONVERBAL COMMUNICAT, V7th
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lee D D, 2000, Adv. Neural Inf. Process., P535, DOI DOI 10.1186/GB-2013-14-4-R39
   Lin CJ, 2007, NEURAL COMPUT, V19, P2756, DOI 10.1162/neco.2007.19.10.2756
   MEHRABIAN A, 1967, J CONSULT PSYCHOL, V31, P248, DOI 10.1037/h0024648
   Morency L.P., 2005, P 7 INT C MULTIMODAL, P18, DOI DOI 10.1145/1088463.1088470
   MORENCY LP, 2007, HCRF LIB
   Morimoto C., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P461, DOI 10.1109/ICPR.1996.546990
   Murphy Kevin., 1998, KALMAN FILTER TOOLBO
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124
   Robinson P, 2009, PHILOS T R SOC B, V364, P3441, DOI 10.1098/rstb.2009.0198
   Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021
   SEONG C, 2006, PSIVT06, P453
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   SHEERMANCHASE T, 2009, IEEE INT WORKSH HUM
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Tong Y, 2007, PATTERN RECOGN, V40, P3195, DOI 10.1016/j.patcog.2007.02.021
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009
   Vinciarelli A, 2009, IMAGE VISION COMPUT, V27, P1743, DOI 10.1016/j.imavis.2008.11.007
   Wallach HM., 2004, TECHNICAL REPORTS CI, V24, P22
   Wang TH, 2009, PATTERN RECOGN, V42, P962, DOI 10.1016/j.patcog.2008.09.035
   Welch G., 1995, An introduction to the kalman filter
   Yang JH, 2009, IEEE T SYST MAN CY A, V39, P694, DOI 10.1109/TSMCA.2009.2018634
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   2004, P 17 INT C PATT REC
   2007, BOGAZICI U HEAD MOTI
NR 56
TC 27
Z9 28
U1 0
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2011
VL 29
IS 7
BP 470
EP 483
DI 10.1016/j.imavis.2011.03.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 786YW
UT WOS:000292344800004
DA 2024-07-18
ER

PT J
AU Kusuma, GP
   Chua, CS
AF Kusuma, Gede Putra
   Chua, Chin-Seng
TI PCA-based image recombination for multimodal 2D+3D face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image recombination; PCA transformation; Multimodal; Face recognition
ID 3D; DEPTH; 2D; EIGENFACES; COLOR; LOCALIZATION; APPEARANCE
AB Most of the existing approaches of multimodal 2D + 3D face recognition exploit the 2D and 3D information at the feature or score level. They do not fully benefit from the dependency between modalities. Exploiting this dependency at the early stage is more effective than the later stage. Early fusion data contains richer information about the input biometric than the compressed features or matching scores. We propose an image recombination for face recognition that explores the dependency between modalities at the image level. Facial cues from the 2D and 3D images are recombined into a more independent and discriminating data by finding transformation axes that account for the maximal amount of variances in the images. We also introduce a complete framework of multimodal 2D + 3D face recognition that utilizes the 2D and 3D facial information at the enrollment, image and score levels. Experimental results based on NTU-CSP and Bosphorus 3D face databases show that our face recognition system using image recombination outperforms other face recognition systems based on the pixel- or score-level fusion. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Kusuma, Gede Putra; Chua, Chin-Seng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chua, CS (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, 50 Nanyang Ave, Singapore 639798, Singapore.
EM kusuma@ntu.edu.sg; ecschua@ntu.edu.sg
RI Kusuma, Gede Putra/ABB-2836-2020; cai, bo/G-1491-2010
CR Abate AF, 2007, PATTERN RECOGN LETT, V28, P1885, DOI 10.1016/j.patrec.2006.12.018
   ABDELKADER CB, 2005, IMAGE VISION COMPUT, V23, P339
   ALYUZ N, 2008, 1 COST 2010 WORKSH B
   [Anonymous], 1 COST 2101 WORKSH B
   [Anonymous], 1988, STAT POWER ANAL BEHA
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Beumier C, 2001, PATTERN RECOGN LETT, V22, P1321, DOI 10.1016/S0167-8655(01)00077-0
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Bronstein AM, 2003, LECT NOTES COMPUT SC, V2688, P62
   Campadelli P, 2004, IMAGE VISION COMPUT, V22, P863, DOI 10.1016/j.imavis.2003.07.006
   Chang K., 2003, MULTIMODAL USER AUTH, P25
   Godil A, 2004, PROC SPIE, V5404, P351, DOI 10.1117/12.540754
   HUSKEN M, 2005, IEEE WORKSH FAC REC
   Jafri R, 2009, J INF PROCESS SYST, V5, P41, DOI 10.3745/JIPS.2009.5.2.041
   Johnson R.A., 2007, Applied multivariate statistial analysis, Vsixth
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Li SZ, 2005, LECT NOTES COMPUT SC, V3723, P44
   Lu X., 2005, 7 IEEE WORKSHOP APPL, P155
   Malassiotis S, 2005, PATTERN RECOGN, V38, P2537, DOI 10.1016/j.patcog.2005.02.001
   Maurer T., 2005, IEEE WORKSH FAC REC
   Mian AS, 2008, INT J COMPUT VISION, V79, P1, DOI 10.1007/s11263-007-0085-5
   *NTU CSP, NTU CSP 3D FAC DAT
   Papatheodorou T, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P321, DOI 10.1109/AFGR.2004.1301551
   Passalis G., 2005, CVPR 05, P171
   Passalis G, 2007, IEEE T PATTERN ANAL, V29, P218, DOI 10.1109/TPAMI.2007.37
   Tsalakanidou F, 2005, IEEE T IMAGE PROCESS, V14, P152, DOI 10.1109/TIP.2004.840714
   Tsalakanidou F, 2003, PATTERN RECOGN LETT, V24, P1427, DOI 10.1016/S0167-8655(02)00383-5
   Tsutsumi S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P306, DOI 10.1109/AFGR.1998.670966
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang JG, 2005, LECT NOTES COMPUT SC, V3546, P919
   Wang JG, 2007, J VLSI SIG PROC SYST, V49, P409, DOI 10.1007/s11265-007-0093-2
   Wang YJ, 2005, IMAGE VISION COMPUT, V23, P1018, DOI 10.1016/j.imavis.2005.07.005
   Wang YJ, 2002, PATTERN RECOGN LETT, V23, P1191, DOI 10.1016/S0167-8655(02)00066-1
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Xu CH, 2009, PATTERN RECOGN, V42, P1895, DOI 10.1016/j.patcog.2009.01.001
NR 35
TC 17
Z9 21
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2011
VL 29
IS 5
BP 306
EP 316
DI 10.1016/j.imavis.2010.12.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 751FT
UT WOS:000289603600002
DA 2024-07-18
ER

PT J
AU Arandiga, F
   Cohen, A
   Donat, R
   Matei, B
AF Arandiga, F.
   Cohen, A.
   Donat, R.
   Matei, B.
TI Edge detection insensitive to changes of illumination in the image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Edge detection; Multiscale analysis; Wavelet transform
ID PIECEWISE-SMOOTH FUNCTIONS; ENO SCHEMES; APPROXIMATION; INTERPOLATION;
   COMPRESSION
AB In this paper we present new edge detection algorithms which are motivated by recent developments on edge-adapted reconstruction techniques [F. Arandiga, A. Cohen, R. Donat, N. Dyn, B. Matei, Approximation of piecewise smooth functions and images by edge-adapted (ENO-EA) nonlinear multiresolution techniques, Appl. Comput. Harmon. Anal. 24 (2) (2008) 225-250]. They are based on comparing local quantities rather than on filtering and thresholding. This comparison process is invariant under certain transformations that model light changes in the image, hence we obtain edge detection algorithms which are insensitive to changes in illumination. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Arandiga, F.; Donat, R.] Univ Valencia, Dept Matemat Aplicada, E-46100 Burjassot, Spain.
   [Cohen, A.] Univ Paris 06, Lab Jacques Louis Lions, UMR 7598, F-75005 Paris, France.
   [Cohen, A.] CNRS, Lab Jacques Louis Lions, UMR 7598, F-75005 Paris, France.
   [Matei, B.] Univ Paris 13, Inst Galilee, Lab Anal Geometrie & Applicat, F-93430 Villetaneuse, France.
C3 University of Valencia; Sorbonne Universite; Universite Paris Cite;
   Centre National de la Recherche Scientifique (CNRS); CNRS - National
   Institute for Mathematical Sciences (INSMI); Centre National de la
   Recherche Scientifique (CNRS); CNRS - National Institute for
   Mathematical Sciences (INSMI); Universite Paris Cite; Sorbonne
   Universite; Universite Paris 13
RP Arandiga, F (corresponding author), Univ Valencia, Dept Matemat Aplicada, C Dr Moliner 50, E-46100 Burjassot, Spain.
EM arandiga@uv.es
RI Donat, Rosa/K-2966-2017; MATEI, Basarab/HTS-4446-2023; Arandiga,
   Francesc/J-9880-2017
OI Donat, Rosa/0000-0003-0428-447X; MATEI, Basarab/0000-0001-7946-530X;
   Arandiga, Francesc/0000-0001-9228-4159
FU  [MTM2008-00974]
FX This work was partially supported by MTM2008-00974. The authors thank V.
   Caselles for providing the window images, and the referees of this paper
   for their suggestions, that have helped us to improve the paper.
CR Amat S, 2001, APPL COMPUT HARMON A, V11, P273, DOI 10.1006/acha.2001.0356
   Arandiga F, 2007, APPL COMPUT HARMON A, V23, P181, DOI 10.1016/j.acha.2006.12.002
   Arandiga F, 2005, SIAM J NUMER ANAL, V43, P41, DOI 10.1137/S0036142903426245
   Aràndiga F, 2003, SIGNAL PROCESS, V83, P459, DOI 10.1016/S0165-1684(02)00445-0
   Aràndiga F, 2000, NUMER ALGORITHMS, V23, P175, DOI 10.1023/A:1019104118012
   Arandiga F, 2008, APPL COMPUT HARMON A, V24, P225, DOI 10.1016/j.acha.2007.06.009
   CANNY JF, 1986, IEEE T PATTERN ANAL, V8, P112
   HARTEN A, 1989, J COMPUT PHYS, V83, P148, DOI 10.1016/0021-9991(89)90226-X
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Prewitt J. M., 1970, Picture processing and psychopictorics, V10, P15
   SOBEL I, 1970, AIM21 STANF AI LAB
NR 12
TC 15
Z9 16
U1 1
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 553
EP 562
DI 10.1016/j.imavis.2009.09.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600001
DA 2024-07-18
ER

PT J
AU Taheri, S
   Ong, SH
   Chong, VFH
AF Taheri, S.
   Ong, S. H.
   Chong, V. F. H.
TI Level-set segmentation of brain tumors using a threshold-based speed
   function
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D segmentation; Threshold; Level-set
ID VOLUME; MODEL
AB The level set approach can be used as a powerful tool for 3D segmentation of a tumor to achieve an accurate estimation of its volume. A major challenge of such algorithms is to set the equation parameters, especially the speed function. In this paper, we introduce a threshold-based scheme that uses level sets for 3D tumor segmentation (TLS). In this scheme, the level set speed function is designed using a global threshold. This threshold is defined based on the idea of confidence interval and is iteratively updated throughout the evolution process. We propose two threshold-updating schemes, search-based and adaptive, that require different degrees of user involvement. TLS does not require explicit knowledge about the tumor and non-tumor density functions and can be implemented in an automatic or semi-automatic form depending on the complexity of the tumor shape. The proposed algorithm has been tested on magnetic resonance images of the head for tumor segmentation and its performance evaluated visually and quantitatively. The experimental results confirm the effectiveness of TLS and its superior performance when compared with a region-competition based method. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Taheri, S.; Ong, S. H.] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
   [Ong, S. H.] Natl Univ Singapore, Div Bioengn, Singapore 117576, Singapore.
   [Chong, V. F. H.] Natl Univ Singapore, Dept Diagnost Radiol, Natl Univ Hosp, Singapore 117576, Singapore.
C3 National University of Singapore; National University of Singapore;
   National University of Singapore
RP Ong, SH (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, E4-05-14, Singapore 117576, Singapore.
EM sima.taheri@gmail.com; eleongsh@nus.edu.sg; dnrcfhv@nus.edu.sg
RI Ong, Sim-Heng/R-9244-2019
OI Ong, Sim-Heng/0000-0003-2766-8150
CR ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098
   [Anonymous], 2001, LNCS, DOI DOI 10.1007/3-540-45468-3_62
   CHENG L, 2005, P INF PROC MED IM, P61
   CORSO J, 2007, P MED IM COMP COMP A, V1, P985
   Corso JJ, 2008, IEEE T MED IMAGING, V27, P629, DOI 10.1109/TMI.2007.912817
   Droske M., 2001, P ANN S INF PROC MED
   Fedkiw R., 2003, LEVEL SET METHODS DY
   Held K, 1997, IEEE T MED IMAGING, V16, P878, DOI 10.1109/42.650883
   Ho S, 2002, INT C PATT RECOG, P532, DOI 10.1109/ICPR.2002.1044788
   Ho S., 2003, SNAP: A software package for User-Guided Geodesic Snake Segmentation. Relatorio tecnico
   KHOTANLOU H, 2005, INT WORKSH FUZZ LOG, P312
   Lee CH, 2005, LECT NOTES COMPUT SC, V3765, P469
   Lefohn A., 2003, Interactive, GPU-based level sets for 3D brain tumor segmentation: Supplementary information
   Leventon M.E., 2000, STAT SHAPE INFLUENCE, V1, P316
   Liu JG, 2005, COMPUT MED IMAG GRAP, V29, P21, DOI 10.1016/j.compmedimag.2004.07.008
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Moonis G, 2002, AM J NEURORADIOL, V23, P356
   Ostle B., 1988, Statistics in research: Basic concepts and techniques for research workers, V4th
   Prastawa M, 2004, MED IMAGE ANAL, V8, P275, DOI 10.1016/j.media.2004.06.007
   Saini S, 2001, AM J ROENTGENOL, V176, P333, DOI 10.2214/ajr.176.2.1760333
   Sethian J. A., 1999, GEOMETRY FLUID MECH
   Sorensen AG, 2001, J CLIN ONCOL, V19, P551, DOI 10.1200/JCO.2001.19.2.551
   Su Q, 2007, P ANN INT IEEE EMBS, P6024
   TAHERI S, 2007, P 8 IEEE WORKSH APPL
   WEISSTEIN EW, CONVEX CONCAVE MATHW
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zhou JY, 2003, COMPUT BIOL MED, V33, P407, DOI 10.1016/S0010-4825(03)00018-0
   Zhou ZM, 2005, STUD HEALTH TECHNOL, V111, P629
NR 28
TC 91
Z9 98
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 26
EP 37
DI 10.1016/j.imavis.2009.04.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000004
DA 2024-07-18
ER

PT J
AU Lucey, S
   Wang, Y
   Cox, M
   Sridharan, S
   Cohn, JF
AF Lucey, Simon
   Wang, Yang
   Cox, Mark
   Sridharan, Sridha
   Cohn, Jeffery F.
TI Efficient constrained local model fitting for non-rigid face alignment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Constrained local models; Non-rigid face alignment; Active appearance
   models
AB Active appearance models (AAMs) have demonstrated great utility when being employed for non-rigid face alignment/tracking. The "simultaneous" algorithm for fitting an AAM achieves good non-rigid face registration performance, but has poor real time performance (2-3 fps). The "project-out" algorithm for fitting an AAM achieves faster than real time performance (>200 fps) but suffers from poor generic alignment performance. In this paper we introduce an extension to a discriminative method for non-rigid face registration/tracking referred to as a constrained local model (CLM). Our proposed method is able to achieve superior performance to the "simultaneous" AAM algorithm along with real time fitting speeds (35 fps). We improve upon the canonical CLM formulation, to gain this performance, in a number of ways by employing: (i) linear SVMs as patch-experts, (ii) a simplified optimization criteria, and (iii) a composite rather than additive warp update step. Most notably, our simplified optimization criteria for fitting the CLM divides the problem of finding a single complex registration/warp displacement into that of finding N simple warp displacements. From these N simple warp displacements, a single complex warp displacement is estimated using a weighted least-squares constraint. Another major advantage of this simplified optimization lends from its ability to be parallelized, a step which we also theoretically explore in this paper. We refer to our approach for fitting the CLM as the "exhaustive local search" (ELS) algorithm. Experiments were conducted on the CMU MultiPIE database. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Lucey, Simon; Wang, Yang; Cohn, Jeffery F.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   [Cox, Mark; Sridharan, Sridha] Queensland Univ Technol, Brisbane, Qld 4001, Australia.
C3 Carnegie Mellon University; Queensland University of Technology (QUT)
RP Lucey, S (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM slucey@cs.cmu.edu; wangy@cs.cmu.edu; md.cox@qut.edu.au;
   s.sridharan@qut.edu.au; jeffcohn@cs.cmu.edu
RI Lucey, Simon M/B-7556-2011; Lucey, Simon/HDO-1716-2022; Cox,
   Mark/B-7549-2011; Cox, Mark D/N-6513-2018
OI Sridharan, Sridha/0000-0003-4316-9001; Cox, Mark/0000-0002-8269-7918;
   Lucey, Simon/0000-0002-6326-042X
CR [Anonymous], 2008, IEEE INT C AUT FAC G
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], IEEE INT C COMP VIS
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   BAKER S, 2003, CMURITR03O1
   Bishop Christopher M, 2006, PATTERN RECOGNITION, DOI DOI 10.1117/1.2819119
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   GU L, 2007, IEEE INT C COMP VIS
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Milborrow S, 2007, THESIS U CAPE TOWN C
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Theobald BJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P149
   van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Zhou Y, 2003, PROC CVPR IEEE, P109
NR 19
TC 24
Z9 29
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2009
VL 27
IS 12
SI SI
BP 1804
EP 1813
DI 10.1016/j.imavis.2009.03.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 513PL
UT WOS:000271335000007
PM 20046797
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Felsberg, M
   Wiklund, J
   Granlund, G
AF Felsberg, Michael
   Wiklund, Johan
   Granlund, Goesta
TI Exploratory learning structures in artificial cognitive systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cognitive systems; COSPAL; Perception-action learning
ID PERCEPTION; RECOGNITION; CORTEX; LEVEL
AB The major goal of the COSPAL project is to develop an artificial cognitive system architecture, with the ability to autonomously extend its capabilities. Exploratory learning is one strategy that allows an extension of competences as provided by the environment of the system. Whereas classical learning methods aim at best for a parametric generalization, i.e., concluding from a number of samples of a problem class to the problem class itself, exploration aims at applying acquired competences to a new problem class, and to apply generalization on a conceptual level, resulting in new models. Incremental or online learning is a crucial requirement to perform exploratory learning.
   In the COSPAL project, we mainly investigate reinforcement-type learning methods for exploratory learning, and in this paper we focus on the organization of cognitive systems for efficient operation. Learning is used over the entire system. It is organized in the form of four nested loops, where the outermost loop reflects the user-reinforcement-feedback loop, the intermediate two loops switch between different solution modes at symbolic respectively sub-symbolic level, and the innermost loop performs the acquired competences in terms of perception-action cycles. We present a system diagram which explains this process in more detail.
   We discuss the learning strategy in terms of learning scenarios provided by the user. This interaction between user ('teacher') and system is a major difference to classical robotics systems, where the system designer places his world model into the system. We believe that this is the key to extendable robust system behavior and successful interaction of humans and artificial cognitive systems.
   We furthermore address the issue of bootstrapping the system, and, in particular, the visual recognition module. We give some more in-depth details about our recognition method and how feedback from higher levels is implemented. The described system is however work in progress and no final results are available yet. The available preliminary results that we have achieved so far, clearly point towards a successful proof of the architecture concept. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Felsberg, Michael; Wiklund, Johan; Granlund, Goesta] Linkoping Univ, Dept Elect Engn, Comp Vis Lab, SE-58183 Linkoping, Sweden.
C3 Linkoping University
RP Felsberg, M (corresponding author), Linkoping Univ, Dept Elect Engn, Comp Vis Lab, SE-58183 Linkoping, Sweden.
EM mfe@isy.liu.se; jowi@isy.liu.se; gosta@isy.liu.se
RI ; Wiklund, Johan/J-3285-2017
OI Felsberg, Michael/0000-0002-6096-3648; Wiklund,
   Johan/0000-0002-1105-2469
CR AHRNS I, 1995, P ICANN 95, V2
   ALZUBI S, 2006, HUMAN MOTION UNDERST
   Anderson SJ, 2002, P ROY SOC B-BIOL SCI, V269, P1225, DOI 10.1098/rspb.2002.1998
   [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], 2002, Cognitive Systems Res, DOI DOI 10.1016/S1389-0417(02)00046-3
   ANTONISSE J, 1991, SIGART B, V2, P25
   Arkin R., 1998, BEHAV BASED ROBOTICS
   BAJCSY R, 1995, LNCS
   Bar-aviv Ezer., 2006, BMVC
   Beymer D, 1996, SCIENCE, V272, P1905, DOI 10.1126/science.272.5270.1905
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   BOWDEN R, 2005, P 13 INT C IM AN PRO
   BROOKS RA, 1991, ARTIF INTELL, V47, P139, DOI 10.1016/0004-3702(91)90053-M
   BROOKS RA, 1986, IEEE T ROBOTIC AUTOM, V2, P14, DOI 10.1109/JRA.1986.1087032
   Capozza M., 2008, INT C COGN SYST COGS
   Chella A, 1997, ARTIF INTELL, V89, P73, DOI 10.1016/S0004-3702(96)00039-2
   CHRISTENSEN HI, 1993, ACTIVE ROBOT VISION
   CHUM O, 2006, P C COMP VIS PATT RE, V1
   Demiris Yiannis, 2005, From motor babbling to hierarchical learning by imitation: a robot developmental pathway
   DER R, 2006, ANIMALS ANIMATS, V9
   ELLIS L, 2007, WORKSH NONR REG TRAC
   ELLIS L, 2007, 5 INT C COMP VIS SYS
   Fayman JA, 1999, AUTON ROBOT, V6, P21, DOI 10.1023/A:1008868408574
   Felsberg M, 2006, IEEE T PATTERN ANAL, V28, P209, DOI 10.1109/TPAMI.2006.29
   FELSBERG M, 2005, AAAI FALL S REACT AN
   Felsberg M, 2007, J REAL-TIME IMAGE PR, V2, P103, DOI 10.1007/s11554-007-0044-y
   FORSSEN PE, 2006, 3 CAN C COMP ROB VIS
   FORSSEN PE, 2006, 2 INT COGN VIS WORKS
   FRANC V, 2006, K3332206 CZECH TU FA
   Gazzaniga M.S., 2002, Cognitive neuroscience: The biology of the mind, V2nd
   Gazzaniga M.S., 1985, The social brain: Discovering the networks of the mind
   GRANLUND G, 2005, KUNSTLICHE INTELLIGE, P18
   GRANLUND G, 1999, P 11 SCAND C IM AN S
   GRANLUND G, 2005, COGNITIVE VISION SYS
   Granlund GH, 1999, SIGNAL PROCESS, V74, P101, DOI 10.1016/S0165-1684(98)00204-7
   GRANLUND GH, 2000, P ALG FRAM PERC ACT
   Grèzes J, 2003, EUR J NEUROSCI, V17, P2735, DOI 10.1046/j.1460-9568.2003.02695.x
   Grimson W., 1990, OBJECT RECOGNITION C
   Haralick R. M., 1992, COMPUTER ROBOT VISIO
   HELD R, 1963, J COMP PHYSIOL PSYCH, V56, P872, DOI 10.1037/h0040546
   HERVE J, 1992, P IEEE C COMP VIS PA
   Hommel B, 2001, BEHAV BRAIN SCI, V24, P849, DOI 10.1017/S0140525X01000103
   HONG P, 2000, P 15 INT C PATT REC
   HOPPE F, 2007, THESIS U KIEL
   HOPPE F, 2006, P 18 INT C PATT REC
   Jeannerod M., 1997, The cognitive neuroscience of action
   Jeannerod M., 2006, Oxford Psychology Series
   Johansson B, 2006, MATH COMPUT MODEL, V43, P892, DOI 10.1016/j.mcm.2005.12.010
   JONSSON E, 2007, LNCS, V4522
   JONSSON E, 2006, 18 INT C PATT REC IC
   Jonsson E, 2009, IMAGE VISION COMPUT, V27, P1688, DOI 10.1016/j.imavis.2008.11.002
   Katz LC, 1996, SCIENCE, V274, P1133, DOI 10.1126/science.274.5290.1133
   KITTLER J, 2006, P 8 ADV CONC INT VIS
   KRUGER N, 2005, BVAI
   LARSSON F, 2007, P INT WORKSH ROB MAT
   Lee TS, 2003, J OPT SOC AM A, V20, P1434, DOI 10.1364/JOSAA.20.001434
   LEVINE M, 1996, P IEEE, V84, P1623
   Lungarella M, 2003, CONNECT SCI, V15, P151, DOI 10.1080/09540090310001655110
   MATAS J, 2007, IEEE INT C ROB AUT W
   Matsumoto K, 2003, SCIENCE, V301, P229, DOI 10.1126/science.1084204
   ONG E, 2006, P BRIT MACH VIS C 20, V2
   Ong EJ, 2009, IMAGE VISION COMPUT, V27, P1715, DOI 10.1016/j.imavis.2009.04.016
   Philipona D, 2003, NEURAL COMPUT, V15, P2029, DOI 10.1162/089976603322297278
   POGGIO T, 1990, NATURE, V343, P263, DOI 10.1038/343263a0
   PREHN H, 2006, 18 INT C PATT REC IC, V1
   Prescott TJ, 1999, ADAPT BEHAV, V7, P99, DOI 10.1177/105971239900700105
   Pulvermüller F, 2005, NAT REV NEUROSCI, V6, P576, DOI 10.1038/nrn1706
   Quintana J, 1999, CEREB CORTEX, V9, P213, DOI 10.1093/cercor/9.3.213
   RAO RPN, 1995, TR548 U ROCH
   RIESENHUBER M, 2000, 1695 MIT DEP BRAIN C
   Robertson EM, 2001, CEREB CORTEX, V11, P628, DOI 10.1093/cercor/11.7.628
   SALOMON R, 1998, SAB98
   SCHOLKOPF B, 1995, ADAPT BEHAV, V3, P311, DOI 10.1177/105971239500300303
   SCHRER D, 2005, ARTIFICIAL INTELLIGE
   Schwartz AB, 2004, SCIENCE, V303, P380, DOI 10.1126/science.1087788
   Sperry Roger., 1985, Science Moral Priority: Merging Mind, Brain, and Human Values
   Springer S.P., 1993, LEFT BRAIN RIGHT BRA, V4th
   Sumbre G, 2001, SCIENCE, V293, P1845, DOI 10.1126/science.1060976
   TELLER A, 1997, IM UND WORKSH
   ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234
   Vernon D, 2008, IMAGE VISION COMPUT, V26, P127, DOI 10.1016/j.imavis.2005.08.009
   Vernon D, 2007, IEEE T EVOLUT COMPUT, V11, P151, DOI 10.1109/TEVC.2006.890274
   Verschure P. F. M. J., 1992, Robotics and Autonomous Systems, V9, P181, DOI 10.1016/0921-8890(92)90054-3
   WINDRIDGE D, 2007, P INT C MACH VIS APP
   WINDRIDGE D, ACM COMPUTER S UNPUB
   WOOLDRIDGE M, 1995, KNOWL ENG REV, V10, P115, DOI 10.1017/S0269888900008122
   Ziemann U, 2001, J PHYSIOL-LONDON, V534, P625, DOI 10.1111/j.1469-7793.2001.t01-1-00625.x
   [No title captured]
NR 88
TC 9
Z9 9
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 2
PY 2009
VL 27
IS 11
SI SI
BP 1671
EP 1687
DI 10.1016/j.imavis.2009.02.012
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 498HJ
UT WOS:000270127800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Daliri, MR
   Torre, V
AF Daliri, Mohammad Reza
   Torre, Vincent
TI Shape and texture clustering: Best estimate for the clusters number
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape and texture clustering; Number of clusters; Symbolic
   representation; Shape context; Dynamic programming; Edit distance; SIFT
ID CLASSIFICATION; RECOGNITION
AB The most difficult problem in automatic clustering is the determination of the total number of final clusters N-cluster. In the present paper, a new method for finding N-cluster is proposed and is compared with previously developed methods. The proposed method is based on the minimization of the functional 0(N-cluster) = alpha N-cluster + beta Sigma(Ncluster)(i) 1/n(i) + 1/N-cluster Sigma(Ncluster)(i=1) dist(C-i) where n(i) is the number of shapes and textures in cluster C-i, dist(C-i) is the intra-cluster distance and alpha and beta are two parameters controlling the grain of the clustering. The proposed method provides almost perfect clustering for the Kimia-25, Kimia-99, MPEG-7 shape databases, subset of Brodatz, full Brodatz and UIUCTex texture databases and provides better results than all previously proposed methods for automatic clustering. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Daliri, Mohammad Reza; Torre, Vincent] Int Sch Adv Studies, I-34012 Basovizza, TS, Italy.
   [Daliri, Mohammad Reza] Abdus Salaam Int Ctr Theoret Phys, Italian Labs, ICTP Programme Training & Res, I-34014 Trieste, Italy.
C3 International School for Advanced Studies (SISSA); Abdus Salam
   International Centre for Theoretical Physics (ICTP)
RP Torre, V (corresponding author), Int Sch Adv Studies, Area Sci Pk,SS 14 Km 163-5,Edificio Q, I-34012 Basovizza, TS, Italy.
EM mdaliri@gwdg.de; torre@sissa.it
RI Daliri, Mohammad Reza/S-9308-2018; Daliri, Mohammad Reza/AAF-4609-2021
OI Daliri, Mohammad Reza/0000-0001-9241-8751
FU EU project [UE MRTN-CT2004-005439 VISIONTRAIN]
FX This work was supported by the EU project "UE MRTN-CT2004-005439
   VISIONTRAIN".
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   [Anonymous], 2005, Statistical and Inductive Inference by Minimum Message Length
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Burnham K. P., 2002, MODEL SELECTION MULT, DOI 10.1007/b97636
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Daliri MR, 2008, PATTERN RECOGN, V41, P1782, DOI 10.1016/j.patcog.2007.10.020
   Duta N, 2001, IEEE T PATTERN ANAL, V23, P433, DOI 10.1109/34.922703
   Fraley C, 1998, COMPUT J, V41, P578, DOI 10.1093/comjnl/41.8.578
   Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410
   Grunwald Peter, 2005, Advances in Minimum Description Length
   Hartigan J. A., 1975, CLUSTERING ALGORITHM, V458, P468
   Jain A., 1988, Algorithms for data clustering
   JULESZ B, 1981, NATURE, V290, P91, DOI 10.1038/290091a0
   KAPP AV, 2007, THESIS STANFORD U
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   KRZANOWSKI WJ, 1988, BIOMETRICS, V44, P23, DOI 10.2307/2531893
   KYRGYZOV IO, 2007, INT C MACH LEARN DAT
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Ling HB, 2007, IEEE T PATTERN ANAL, V29, P286, DOI 10.1109/TPAMI.2007.41
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McLachlan G. J., 1997, The EM Algorithm and Extensions, V473, P486
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Ristad ES, 1998, IEEE T PATTERN ANAL, V20, P522, DOI 10.1109/34.682181
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396
   Srivastava A, 2005, IEEE T PATTERN ANAL, V27, P590, DOI 10.1109/TPAMI.2005.86
   Tu ZW, 2004, LECT NOTES COMPUT SC, V3023, P195
   WALLACE CS, 1968, COMPUT J, V11, P185, DOI 10.1093/comjnl/11.2.185
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 35
TC 6
Z9 9
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1603
EP 1614
DI 10.1016/j.imavis.2009.04.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800017
DA 2024-07-18
ER

PT J
AU Li, CQ
   Li, SJ
   Asim, M
   Nunez, J
   Alvarez, G
   Chen, GR
AF Li, Chengqing
   Li, Shujun
   Asim, Muhammad
   Nunez, Juana
   Alvarez, Gonzalo
   Chen, Guanrong
TI On the security defects of an image encryption scheme
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cryptanalysis; Image encryption; Chaos; Known-plaintext attack;
   Chosen-plaintext attack
ID CRYPTANALYSIS
AB This paper studies the security of a recently-proposed chaos-based image encryption scheme and points out the following problems: (1) there exist a number of invalid keys and weak keys, and some keys are partially equivalent for encryption/decryption; (2) given one chosen plain-image, a subkey K-10 can be guessed with a smaller computational complexity than that of the simple brute-force attack: (3) given at most 128 chosen plain-images, a chosen-plaintext attack can possibly break the following part of the secret key: {K-i mod 128}(i=4)(10), which works very well when K-10 is not too large; (4) when K-10 is relatively small, a known-plaintext attack can be carried out with only one known plain-image to recover some visual information of any other plain-images encrypted by the same key. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Li, Chengqing; Chen, Guanrong] Univ Hong Kong, Dept Elect Engn, Kowloon Tong, Hong Kong, Peoples R China.
   [Li, Chengqing] Hong Kong Polytech Univ, Elect & Informat Engn Dept, Kowloon, Hong Kong, Peoples R China.
   [Li, Shujun] Univ Konstanz, Fachbereich Informat & Informat Wissensch, D-78457 Constance, Germany.
   [Asim, Muhammad] Univ Teknol PETRONAS, Tronoh 31750, Perak, Malaysia.
   [Nunez, Juana; Alvarez, Gonzalo] CSIC, Inst Fis Aplicada, Madrid 28006, Spain.
C3 University of Hong Kong; Hong Kong Polytechnic University; University of
   Konstanz; Universiti Teknologi Petronas; Consejo Superior de
   Investigaciones Cientificas (CSIC); CSIC - Instituto de Fisica Aplicada
   (IFA)
RP Li, CQ (corresponding author), Univ Hong Kong, Dept Elect Engn, 83 Tat Chee Ave, Kowloon Tong, Hong Kong, Peoples R China.
EM drchengqing@gmail.com
RI Chen, Guanrong/F-6000-2011; Li, Shujun/A-9032-2008; Li,
   Chengqing/B-9388-2008
OI Chen, Guanrong/0000-0003-1381-7418; Li, Shujun/0000-0001-5628-7328; Li,
   Chengqing/0000-0002-5385-7644; Alvarez, Gonzalo/0000-0002-8379-5595
FU Research Grants Council of the Hong Kong [523206]; Alexander von
   Humboldt Foundation, Germany; Zukunftskolleg, Universitat Konstanz,
   Germany; Ministerio de Educacion y Ciencia of Spain [SEG2004-02418]
FX Chengqing Li was partially supported by the Research Grants Council of
   the Hong Kong SAR Government under Project 523206 (PolyU 5232/06E).
   Shujun Li was partially supported by the Alexander von Humboldt
   Foundation, Germany, and by the Zukunftskolleg, Universitat Konstanz,
   Germany. Juana Nunez and Gonzalo Alvarez were partially supported by
   Ministerio de Educacion y Ciencia of Spain, Research Grant
   SEG2004-02418.
CR ALEXOPOULOS C, 1995, J ELECTRON IMAGING, V4, P251, DOI 10.1117/12.208654
   Alvarez G, 2003, PHYS LETT A, V319, P334, DOI 10.1016/j.physleta.2003.10.044
   Alvarez G, 2006, INT J BIFURCAT CHAOS, V16, P2129, DOI 10.1142/S0218127406015970
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chen HC, 2003, J SYST ARCHITECT, V49, P355, DOI 10.1016/S1383-7621(03)00087-0
   Chuang TJ, 1998, J ELECTRON IMAGING, V7, P350, DOI 10.1117/1.482651
   Chung KL, 1998, PATTERN RECOGN LETT, V19, P461, DOI 10.1016/S0167-8655(98)00017-8
   Furht B, 2005, INTERNET COMMUN SER, P95
   Furht B., 2006, Multimedia encryption and authentication techniques and applications
   Guo JI, 2002, IEE P-VIS IMAGE SIGN, V149, P237, DOI 10.1049/ip-vis:20020457
   Li CQ, 2008, CHAOS SOLITON FRACT, V37, P299, DOI 10.1016/j.chaos.2006.08.025
   Li CQ, 2006, IEE P-VIS IMAGE SIGN, V153, P1, DOI 10.1049/ip-vis:20045234
   Li CQ, 2004, LECT NOTES COMPUT SC, V3333, P418
   Li SJ, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2360697
   Li SJ, 2008, J SYST SOFTWARE, V81, P1130, DOI 10.1016/j.jss.2007.07.037
   Li SJ, 2008, IEEE T CIRC SYST VID, V18, P338, DOI 10.1109/TCSVT.2008.918116
   Li SJ, 2008, IEEE T CIRCUITS-I, V55, P1055, DOI 10.1109/TCSI.2008.916540
   Li SJ, 2008, SIGNAL PROCESS-IMAGE, V23, P212, DOI 10.1016/j.image.2008.01.003
   Li SJ, 2007, IEEE T CIRC SYST VID, V17, P214, DOI 10.1109/TCSVT.2006.888840
   Li SJ, 2005, INTERNET COMMUN SER, P133
   Mao YB, 2004, INT J BIFURCAT CHAOS, V14, P3613, DOI 10.1142/S021812740401151X
   Pareek N. K., 2005, Communications in Nonlinear Science and Numerical Simulation, V10, P715, DOI 10.1016/j.cnsns.2004.03.006
   Pareek NK, 2006, IMAGE VISION COMPUT, V24, P926, DOI 10.1016/j.imavis.2006.02.021
   Pareek NK, 2003, PHYS LETT A, V309, P75, DOI 10.1016/S0375-9601(03)00122-1
   Uhl A., 2005, Image and Video Encryption: From Digital Rights Management to Secured Personal Communication
   Zeng W., 2006, MULTIMEDIA SECURITY
NR 26
TC 131
Z9 135
U1 0
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1371
EP 1381
DI 10.1016/j.imavis.2008.12.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Riesen, K
   Bunke, H
AF Riesen, Kaspar
   Bunke, Horst
TI Approximate graph edit distance computation by means of bipartite graph
   matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Graph based representation; Graph edit distance; Bipartite graph
   matching
ID ASSIGNMENT; ALGORITHM
AB In recent years, the use of graph based object representation has gained popularity. Simultaneously, graph edit distance emerged as a powerful and flexible graph matching paradigm that can be used to address different tasks in pattern recognition, machine learning, and data mining. The key advantages of graph edit distance are its high degree of flexibility, which makes it applicable to any type of graph, and the fact that one can integrate domain specific knowledge about object similarity by means of specific edit cost functions. Its computational complexity, however, is exponential in the number of nodes of the involved graphs. Consequently, exact graph edit distance is feasible for graphs of rather small size only. In the present paper we introduce a novel algorithm which allows us to approximately, or suboptimally, compute edit distance in a substantially faster way. The proposed algorithm considers only local, rather than global, edge structure during the optimization process. In experiments on different datasets we demonstrate a substantial speed-up of our proposed method over two reference systems. Moreover, it is emprically verified that the accuracy of the suboptimal distance remains sufficiently accurate for various pattern recognition applications. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Riesen, Kaspar; Bunke, Horst] Univ Bern, Inst Appl Math & Sci Comp, CH-3012 Bern, Switzerland.
C3 University of Bern
RP Riesen, K (corresponding author), Univ Bern, Inst Appl Math & Sci Comp, Neubruckstr 10, CH-3012 Bern, Switzerland.
EM riesen@iam.unibe.ch; bunke@iam.unibe.ch
OI Riesen, Kaspar/0000-0002-9145-3157
CR Ambauen R, 2003, LECT NOTES COMPUT SC, V2726, P95
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], COIL100 COL U DEP CO
   [Anonymous], P 6 ANN ACM S THEOR
   [Anonymous], NATL SPECIAL DATABAS
   [Anonymous], LNCS
   [Anonymous], 2007, BRIDGING GAP GRAPH E
   [Anonymous], P 5 INT C DAT MIN
   Berman HM, 2000, NUCLEIC ACIDS RES, V28, P235, DOI 10.1093/nar/28.1.235
   Boeres MC, 2004, LECT NOTES COMPUT SC, V3059, P100
   BOURGEOIS F, 1971, COMMUN ACM, V14, P802, DOI 10.1145/362919.362945
   Bunke H, 1983, PATTERN RECOGN LETT, V1, P245, DOI 10.1016/0167-8655(83)90033-8
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9
   Dickinson PJ, 2003, LECT NOTES COMPUT SC, V2726, P13
   Dosch P, 2006, LECT NOTES COMPUT SC, V3926, P381
   Eshera M.A., 1984, Proceedings of the International Conference on Pattern Recognition (ICPR), P75
   ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232
   HART PE, 1968, IEEE T SYST SCI CYB, VSSC4, P100, DOI 10.1109/TSSC.1968.300136
   Henry E., 1900, Classification and Uses of Finger Prints
   Justice D, 2006, IEEE T PATTERN ANAL, V28, P1200, DOI 10.1109/TPAMI.2006.152
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Levenshtein V. I., 1966, SOV PHYS DOKL, V10, P707
   LUKS EM, 1982, J COMPUT SYST SCI, V25, P42, DOI 10.1016/0022-0000(82)90009-5
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Neuhaus M, 2005, LECT NOTES COMPUT SC, V3546, P191
   Neuhaus M, 2004, LECT NOTES COMPUT SC, V3138, P180
   Neuhaus M, 2006, PATTERN RECOGN, V39, P1852, DOI 10.1016/j.patcog.2006.04.012
   Riesen K, 2007, LECT NOTES COMPUT SC, V4538, P383
   Riesen K, 2007, LECT NOTES COMPUT SC, V4538, P1
   Robles-Kelly A, 2005, IEEE T PATTERN ANAL, V27, P365, DOI 10.1109/TPAMI.2005.56
   SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175
   Schomburg I, 2004, NUCLEIC ACIDS RES, V32, pD431, DOI 10.1093/nar/gkh081
   Sorlin S, 2005, LECT NOTES COMPUT SC, V3434, P172
   Torsello A, 2005, IEEE T PATTERN ANAL, V27, P1087, DOI 10.1109/TPAMI.2005.146
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   Zhou RW, 1995, PATTERN RECOGN LETT, V16, P1267, DOI 10.1016/0167-8655(95)00078-X
NR 37
TC 418
Z9 451
U1 5
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 950
EP 959
DI 10.1016/j.imavis.2008.04.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300012
DA 2024-07-18
ER

PT J
AU Cobzas, D
   Jagersand, M
   Sturm, P
AF Cobzas, Dana
   Jagersand, Martin
   Sturm, Peter
TI 3D SSD tracking with estimated 3D planes
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Visual tracking; SSD tracking; Image registration; Plane tracking; 3D
   model estimation
ID TIME VISUAL TRACKING; MODELS
AB We present a tracking method where full camera position and orientation is tracked from intensity differences ill a video sequence. The camera pose is calculated based on 3D planes, and hence does not depend on point correspondences. The plane based formulation also allows additional constraints to be naturally added, e.g., perpendicularity between walls, floor and ceiling surfaces, co-planarity of wall surfaces etc. A particular feature of our method is that the full 3D pose change is directly computed from temporal image differences without making a commitment to a particular intermediate (e.g., 2D feature) representation. We experimentally compared our method with regular 2D SSD tracking and found it more robust and stable. This is due to 3D consistency being enforced even in the low level registration of image regions. This yields better results than first computing (and hence committing to) 2D image features and then from these compute 3D pose. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Cobzas, Dana; Jagersand, Martin] Univ Alberta, Edmonton, AB T6G 2E8, Canada.
   [Sturm, Peter] INRIA Rhone Alpes, F-38334 Montbonnot St Martin, France.
C3 University of Alberta
RP Cobzas, D (corresponding author), Univ Alberta, Edmonton, AB T6G 2E8, Canada.
EM dana@cs.ualberta.ca; jag@cs.ualberta.ca; Peter.Sturm@inrialpes.fr
CR [Anonymous], 1981, P DARPA IMAGE UNDERS
   ARMSTRONG M, 1995, 2 AS C COMP VIS, P58
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   BAKER S, 2004, CMURITR0464
   Bartoli A, 2003, INT J COMPUT VISION, V52, P45, DOI 10.1023/A:1022318524906
   COBZAS D, 2004, ECCV 2004 WORKSH SPA
   COBZAS D, 2003, P SCAND C IM AN SCIA
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   GLEICHER M, 1997, CVPR97, P331
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Horn BKP, 1986, COMPUTER VISION
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Jurie F, 2002, IEEE T PATTERN ANAL, V24, P996, DOI 10.1109/TPAMI.2002.1017625
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   Ma Y., 2004, INVITATION 3D VISION
   Marchand É, 2001, IMAGE VISION COMPUT, V19, P941, DOI 10.1016/S0262-8856(01)00054-3
   SIMON G, 2000, IEEE ACM INT S AUGM
   TRIGGS W, 1997, CVRP, P609
   WERNER T, 2000, CZECH PATT REC WORKS
   Xiao J, 2004, P INT C COMP VIS PAT
NR 21
TC 14
Z9 15
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 69
EP 79
DI 10.1016/j.imavis.2006.10.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yuen, TYF
   Tsang, PWM
AF Yuen, Terry Y. F.
   Tsang, Peter W. M.
TI Affine invariant matching of broken boundaries based on particle swarm
   optimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE affine invariant matching; broken boundary; simple genetic algorithm;
   real coded genetic algorithm; particle swarm optimization; repeated
   trial
ID GENETIC ALGORITHM; RECOGNITION; CONVERGENCE
AB Affine invariant matching of broken image contours with model shapes is an important but difficult research topic in computer vision. One of the effective approaches to date encapsulates the process as an optimization problem which determines, with the use of a Simple Genetic Algorithm (SGA), the best matching score between pairs of object boundaries. Despite the moderate success of methods developed in this direction, the overall success rate is generally low and inconsistent amongst test trials. This unfavorable outcome could be due to the lack of adequate exploitation in an enormous and erratic search space, which is rather common in the context of shape matching. In this paper, a novel scheme based on Particle Swarm Optimization (PSO) is presented to overcome these problems. Experimental results reveal that the proposed method has outperformed SGA and Real Coded Genetic Algorithm (RCGA) in terms of speed, stability and success rate. In addition, the evolutionary behavior of PSO also permits the use of repeated trials to further enhance the success rate towards perfection with relatively fewer iterations. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Yuen, Terry Y. F.; Tsang, Peter W. M.] City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Tsang, PWM (corresponding author), City Univ Hong Kong, Dept Elect Engn, Tat Chee Ave, Kowloon, Hong Kong, Peoples R China.
EM eewmtsan@cityu.edu.hk
OI Tsang, Peter/0000-0003-0066-2031
CR Bhanu B., 1991, Proceedings of the Fourth International Conference on Genetic Algorithms and Their Applications, P362
   BORGEFORS G, 1988, IEEE T PATTERN ANAL, V10, P849, DOI 10.1109/34.9107
   Clerc M, 2002, IEEE T EVOLUT COMPUT, V6, P58, DOI 10.1109/4235.985692
   Goldberg D. E., 1989, GENETIC ALGORITHMS S
   Herrera F, 2003, INT J INTELL SYST, V18, P309, DOI 10.1002/int.10091
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Kennedy J, 1997, PROCEEDINGS OF 1997 IEEE INTERNATIONAL CONFERENCE ON EVOLUTIONARY COMPUTATION (ICEC '97), P303, DOI 10.1109/ICEC.1997.592326
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Khoo KG, 2002, PATTERN RECOGN LETT, V23, P1589, DOI 10.1016/S0167-8655(02)00123-X
   Lim HS, 1998, COMPUT ELECTR ENG, V24, P183, DOI 10.1016/S0045-7906(98)00001-9
   MICHALEWICZ Z, 1992, GENETIC ALGORITHMS D, P87
   Ozcan E, 1997, PATTERN RECOGN LETT, V18, P987, DOI 10.1016/S0167-8655(97)00123-2
   ROTH G, 1994, IEEE T PATTERN ANAL, V16, P901, DOI 10.1109/34.310686
   RUBE IAE, 2004, P 17 ICPR 04
   Shi Y., 1998, Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics), V1447, P591, DOI [10.1007/BFB0040810, DOI 10.1007/BFB0040810]
   Suganthan PN, 2002, PATTERN RECOGN, V35, P1883, DOI 10.1016/S0031-3203(01)00136-4
   TOET A, 1995, PATTERN RECOGN LETT, V16, P849, DOI 10.1016/0167-8655(95)00015-9
   Trelea IC, 2003, INFORM PROCESS LETT, V85, P317, DOI 10.1016/S0020-0190(02)00447-7
   Tsang MB., 2004, PHYS REV LETT, V92, DOI [10.1103/PhysRevLett.92.062701, DOI 10.1103/PHYSREVLETT.92.062701]
   Tsang PWM, 1997, IMAGE VISION COMPUT, V15, P819, DOI 10.1016/S0262-8856(97)00028-0
   Tsang PWM, 2003, IEE P-VIS IMAGE SIGN, V150, P107, DOI 10.1049/ip-vis:20030158
   Tsang PWM, 1997, P I MECH ENG I-J SYS, V211, P385, DOI 10.1243/0959651971539911
   Tsang PWM, 2001, PDPTA'2001: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED PROCESSING TECHNIQUES AND APPLICATIONS, P457
   Tsang PWM, 1997, PATTERN RECOGN LETT, V18, P631, DOI 10.1016/S0167-8655(97)00034-2
   TSANG PWM, 2002, MECH MACH VIS, P41
   WANG YK, 1996, P 13 INT C PATT REC, V2, P740
   Yan XQ, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1771, DOI 10.1109/ICMLC.2002.1175342
   Yuen SY, 2001, IMAGE VISION COMPUT, V19, P551, DOI 10.1016/S0262-8856(00)00100-1
   Zhang LH, 2003, PATTERN RECOGN LETT, V24, P9, DOI 10.1016/S0167-8655(02)00160-5
NR 29
TC 3
Z9 3
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1230
EP 1239
DI 10.1016/j.imavis.2008.02.011
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300005
DA 2024-07-18
ER

PT J
AU Sivignon, I
   Dupont, F
   Chassery, JM
AF Sivignon, Isabelle
   Dupont, Florent
   Chassery, Jean-Marc
TI Reversible vectorisation of 3D digital planar curves and applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE discrete polygon; 3D; vectorisation; modelling
ID DISCRETE REPRESENTATION; SURFACES; POLYHEDRIZATION; SEGMENTATION; LINES
AB This paper tackles the problem of the computation of a planar polygonal curve from a digital planar curve, such that the digital data can be exactly retrieved from the polygonal curve. The proposed transformation also provides an analytical modelling of a digital plane segment as a discrete polygon composed of a face, edges and vertices. A dual space representation of lines and planes is used to ensure that the computed curve remains inside the digital curve, and this tool enables to define a. very efficient algorithm. Applied on the digital plane segments resulting from the decomposition of a digital surface, this algorithm provides a set of polygons modelling exactly the digital surface. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Lyon 1, Lab LIRIS, CNRS, UMR 5205, F-69622 Villeurbanne, France.
   CNRS, Lab LIS, UMR 5083, F-38402 St Martin Dheres, France.
C3 Centre National de la Recherche Scientifique (CNRS); Institut National
   des Sciences Appliquees de Lyon - INSA Lyon; Universite Claude Bernard
   Lyon 1; Centre National de la Recherche Scientifique (CNRS)
RP Sivignon, I (corresponding author), Univ Lyon 1, Lab LIRIS, CNRS, UMR 5205, Batiment Nautibus 8 Blvd Niels Bohr, F-69622 Villeurbanne, France.
EM isabelle.sivignon@liris.cnrs.fr
OI Dupont, Florent/0000-0001-6611-4420
CR Andres E, 2003, GRAPH MODELS, V65, P92, DOI 10.1016/S1524-0703(03)00004-3
   ANDRES E, 1997, COMPUT GRAPH FORUM, V16, P3
   ANDRES E, 1996, SPIES INT S MED IM 9, V2707, P580
   [Anonymous], 1994, FDN COMPUTER SCI
   BORIANNE P, 1994, REVERSIBLE POLYHEDRI, P157
   BRIMKOV V, 2004, DIGITAL PLANARITY RE, P1
   Burguet J, 2000, LECT NOTES COMPUT SC, V1953, P222
   Coeurjolly D, 2004, P SOC PHOTO-OPT INS, V5300, P1, DOI 10.1117/12.525391
   DEBLEDRENNESSON I, 1995, INT J PATTERN RECOGN, V9, P635, DOI 10.1142/S0218001495000249
   DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550
   Francon J, 1996, THEOR COMPUT SCI, V156, P159, DOI 10.1016/0304-3975(95)00059-3
   FRANCON J, 1995, GRAPH MODEL IM PROC, V57, P20, DOI 10.1006/gmip.1995.1003
   Françon J, 1999, LECT NOTES COMPUT SC, V1568, P425
   Hardy G.H., 1989, INTRO THEORY NUMBERS, VFifth
   Hayes B, 2000, AM SCI, V88, P296, DOI 10.1511/2000.29.3334
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   KIM CE, 1982, COMPUT VISION GRAPH, V18, P369, DOI 10.1016/0146-664X(82)90005-3
   Klette R., 2004, DIGITAL GEOMETRY GEO
   KOVALEVSKY V, 1997, LNCS, V1953, P222
   Lincke C, 2003, DISCRETE APPL MATH, V125, P81, DOI 10.1016/S0166-218X(02)00225-1
   LINDENBAUM M, 1993, IEEE T PATTERN ANAL, V15, P949, DOI 10.1109/34.232082
   MCILROY MD, 1985, AT&T TECH J, V64, P481, DOI 10.1002/j.1538-7305.1985.tb00359.x
   REVEILLES JP, 2001, ELECT NOTES THEORETI, V46
   ROSENFELD A, 2001, INT WORKSH COMB IM A, V46
   Sivignon I, 2005, LECT NOTES COMPUT SC, V3429, P347
   Sivignon I, 2005, IMAGE VISION COMPUT, V23, P191, DOI 10.1016/j.imavis.2004.06.014
   Sivignon I, 2004, LECT NOTES COMPUT SC, V3322, P458
   WU LD, 1982, IEEE T PATTERN ANAL, V4, P247
NR 28
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1644
EP 1656
DI 10.1016/j.imavis.2006.06.022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zagorchev, L
   Goshtasby, A
   Satter, M
AF Zagorchev, Lyubomir
   Goshtasby, Ardeshir
   Satter, Martin
TI R-snakes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image segmentation; energy minimizing contours; R-snakes
ID INTERPOLATION TECHNIQUE; RECONSTRUCTION; SEGMENTATION
AB Energy minimizing contours or snakes are tools for delineating objects of interest in an image. Snakes are defined discretely or in continuous form with continuous snakes having advantages over discrete snakes. A continuous snake called B-snake has been previously defined using B-spline curves. In this paper, a continuous snake called R-snake is introduced that is based on rational Gaussian (RaG) curves and has advantages over B-snakes. Not only the stiffness of an R-snake can be varied continuously to delineate an object from coarse to fine, the stiffness of different parts of an R-snake can be adjusted to recover a shape with smooth as well as detailed parts. The formulation of R-snakes is presented and experimental results delineating various objects in synthetic and real images are presented and discussed. (C) 2006 Elsevier B.V. All rights reserved.
C1 Wright State Univ, Dept Comp Sci & Engn, Dayton, OH 45435 USA.
   Kettering Med Ctr, Nucl Med PET, Kettering, OH 45429 USA.
C3 University System of Ohio; Wright State University Dayton
RP Zagorchev, L (corresponding author), Philips Res N Amer, Briarcliff Manor, NY 10510 USA.
EM Lyubomir.Zagorchev@philips.com
CR ALEKSANDROV AD, 1964, MATH ITS CONTENT MET
   CHAKRABORTY A, 1995, BIZAIS, P189
   CHANG LW, 1991, CVGIP-GRAPH MODEL IM, V53, P382, DOI 10.1016/1049-9652(91)90041-H
   CHOEN I, 1992, P EUR C COMP VIS, P459
   CHOEN L, 1991, CVGIP-IMAG UNDERSTAN, V53, P211
   Cipolla R., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P616, DOI 10.1109/ICCV.1990.139606
   CIPOLLA R, 1995, LECT NOTES COMPUT SC, V1016
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   GAUCH JM, 1994, P SOC PHOTO-OPT INS, V2299, P72, DOI 10.1117/12.179272
   GIL D, 2003, LECT NOTES COMPUT SC, V2683, P261
   GOSHTASBY A, 1995, COMPUT AIDED DESIGN, V27, P363, DOI 10.1016/0010-4485(95)96800-2
   KAMBHAMETTU C, 1994, NONRIGID MOTION ANAL, P405
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Levienaise-Obadia B, 1999, IMAGE VISION COMPUT, V17, P583, DOI 10.1016/S0262-8856(98)00177-2
   LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733
   Liao CW, 1999, COMPUT VIS IMAGE UND, V73, P43, DOI 10.1006/cviu.1998.0694
   LIN WC, 1989, COMPUT VISION GRAPH, V48, P124, DOI 10.1016/0734-189X(89)90107-2
   Meegama RGN, 2003, IMAGE VISION COMPUT, V21, P551, DOI 10.1016/S0262-8856(03)00066-0
   MENET S, 1990, P 7 ISR C, P323
   Pardo XM, 2003, MED IMAGE ANAL, V7, P293, DOI 10.1016/S1361-8415(03)00014-8
   POON CS, 1994, ROBB, P90
   TERZOPOULOS D, 1994, ACM T GRAPHIC, V13, P103, DOI 10.1145/176579.176580
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
   WANG Y, 2001, P 2001 INT C IM PROC, V2, P769
   WANG Y, 2002, ICARV, V2, P793
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
NR 26
TC 1
Z9 2
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 945
EP 959
DI 10.1016/j.imavis.2006.07.008
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600016
DA 2024-07-18
ER

PT J
AU Passat, N
   Ronse, C
   Baruthio, J
   Armspach, JP
   Foucher, J
AF Passat, N.
   Ronse, C.
   Baruthio, J.
   Armspach, J. -P.
   Foucher, J.
TI Watershed and multimodal data for brain vessel segmentation: Application
   to the superior sagittal sinus
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE vessel segmentation; watershed segmentation; a priori knowledge
   integration; magnetic resonance imaging
ID BLOOD-VESSELS; MR; ANGIOGRAPHY; EXTRACTION; NETWORK
AB Magnetic resonance angiography (MRA) provides three-dimensional data of vascular structures by visualising the flowing blood signal. Algorithms dedicated to vessel segmentation generally detect the cerebral vascular tree by only seeking this high intensity blood signal in MRA data. The method presented in this paper proposes a different strategy which consists in using both MRA and classical MRI in order to integrate a priori anatomical knowledge for guidance of the vessel segmentation process. It then uses mathematical morphology tools to carry out a simultaneous segmentation of both blood signal in MRA and blood and wall signal in MRI, enabling to take advantage of a larger amount of information than previously proposed methods. This method is dedicated to the superior sagittal sinus segmentation; however, similar strategies could be considered for segmentation of other vascular structures. It has been performed on a database composed of 9 couples of MRA and MRI, providing results which have been validated and compared to other ones obtained with a region-growing algorithm. Their validation tends to prove that the proposed method is reliable even when the vascular signal is inhomogeneous or contains artifacts. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Strasbourg 1, LSIIT, UMR 7005, CNRS,ULP, F-67412 Illkirch Graffenstaden, France.
   Univ Strasbourg, IPB LNV, Inst Phys Biol,Hop Civil, Lab Neuroimagerie Vivo,UMR 7004,CNRS,ULP, F-67085 Strasbourg, France.
   Hop Civil, Unite Rech Psychopathol & Pharmacol Cognit, U405, INSERM, F-67091 Strasbourg, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universites de
   Strasbourg Etablissements Associes; Universite de Strasbourg; Centre
   National de la Recherche Scientifique (CNRS); CHU Strasbourg;
   Universites de Strasbourg Etablissements Associes; Universite de
   Strasbourg; Institut National de la Sante et de la Recherche Medicale
   (Inserm); CHU Strasbourg; Universites de Strasbourg Etablissements
   Associes; Universite de Strasbourg
RP Passat, N (corresponding author), Univ Strasbourg 1, LSIIT, UMR 7005, CNRS,ULP, Parc Innovat,Bd Sebastien Brant BP 10413, F-67412 Illkirch Graffenstaden, France.
EM passat@dpt-info.u-strasbg.fr
CR Bertrand G, 1996, PATTERN RECOGN LETT, V17, P115, DOI 10.1016/0167-8655(95)00100-X
   Beucher S., 1992, MATH MORPHOLOGY IMAG, P433
   Bosc M, 2003, LECT NOTES COMPUT SC, V2879, P981
   Cline HE, 1998, MAGNET RESON MED, V40, P697, DOI 10.1002/mrm.1910400509
   Cline HE, 2000, MAGNET RESON MED, V43, P892, DOI 10.1002/1522-2594(200006)43:6<892::AID-MRM16>3.0.CO;2-Q
   Dokládal P, 1999, LECT NOTES COMPUT SC, V1679, P98
   DUMOULIN CL, 1986, RADIOLOGY, V161, P717, DOI 10.1148/radiology.161.3.3786721
   DUMOULIN CL, 1989, MAGN RESON MED, V9, P139, DOI 10.1002/mrm.1910090117
   Gerig G., 1993, Information Processing in Medical Imaging. 13th International Conference, IPMI '93 Proceedings, P94, DOI 10.1007/BFb0013783
   Hoogeveen RM, 1998, JMRI-J MAGN RESON IM, V8, P1228, DOI 10.1002/jmri.1880080608
   Kirbas C, 2004, ACM COMPUT SURV, V36, P81, DOI 10.1145/1031120.1031121
   Kobashi S, 2001, IMAGE VISION COMPUT, V19, P185, DOI 10.1016/S0262-8856(00)00067-6
   Kobashi S, 1999, P SOC PHOTO-OPT INS, V3661, P968, DOI 10.1117/12.348489
   Naegel B, 2005, COMPUT IMAGING VIS, V30, P429
   NOLTE J, 2001, HUMAN BRAIN INTRO FU, P119
   Passat N, 2005, LECT NOTES COMPUT SC, V3804, P60
   Passat N, 2006, MED IMAGE ANAL, V10, P259, DOI 10.1016/j.media.2005.11.002
   Passat N, 2005, COMPUT IMAGING VIS, V30, P419
   Passat N, 2005, J MAGN RESON IMAGING, V21, P715, DOI 10.1002/jmri.20307
   PASSAT N, 2005, P ICASSP, V2, P737
   Pellot C, 1996, COMPUT MED IMAG GRAP, V20, P141, DOI 10.1016/0895-6111(96)00047-X
   SANDERSON AR, 1993, P VIP UTR NETH, P11
   Suri JS, 2002, IEEE T INF TECHNOL B, V6, P338, DOI 10.1109/TITB.2002.804136
   WEHRLI FW, 1986, RADIOLOGY, V160, P781, DOI 10.1148/radiology.160.3.3526407
   Wilkinson MHF, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P1093
   Wink O, 2000, IEEE T MED IMAGING, V19, P337, DOI 10.1109/42.848184
   Yim PJ, 2000, IEEE T MED IMAGING, V19, P568, DOI 10.1109/42.870662
   ZAHLTEN C, 1995, EUR J RADIOL, V19, P96, DOI 10.1016/0720-048X(94)00578-Z
NR 28
TC 18
Z9 23
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 512
EP 521
DI 10.1016/j.imavis.2006.03.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Vieira, LFM
   do Nascimento, ER
   Fernandes, FA
   Carceroni, RL
   Araújo, AD
AF Vieira, Luiz Filipe M.
   do Nascimento, Erickson R.
   Fernandes, Fernando A., Jr.
   Carceroni, Rodrigo L.
   Araujo, Arnaldo de A.
TI Fully automatic coloring of grayscale images
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE image coloring; color transfer; content-based image retrieval
ID RETRIEVAL
AB This paper introduces a methodology for adding color to grayscale images in a way that is completely automatic. Towards this goal, we build on a technique that was recently developed to transfer colors from a user-selected source image to a target grayscale image. More specifically, in order to eliminate the need for manual selection of the source image, we use content-based image retrieval methods to find suitable source images in an image database. To assess the merit of our methodology, we performed a survey where volunteers were asked to rate the plausibility of the colorings generated automatically for grayscale images. In most cases, automatically-colored images were rated either as totally plausible or as mostly plausible. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Fed Minas Gerais, Dept Ciencia Comp, BR-31270010 Belo Horizonte, MG, Brazil.
C3 Universidade Federal de Minas Gerais
RP Carceroni, RL (corresponding author), Univ Fed Minas Gerais, Dept Ciencia Comp, Av Antonio Carlos 6627, BR-31270010 Belo Horizonte, MG, Brazil.
EM carceron@dcc.ufmg.br
RI Nascimento, Erickson R./G-5374-2014
OI Nascimento, Erickson R./0000-0003-2973-2232
CR [Anonymous], 1998, Proc. SIGGRAPH, DOI 10.1145/280814.280820
   Ashikhmin M, 2003, IEEE COMPUT GRAPH, V23, P38, DOI 10.1109/MCG.2003.1210863
   Belongie S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P675, DOI 10.1109/ICCV.1998.710790
   Debevec P, 2000, COMP GRAPH, P145, DOI 10.1145/344779.344855
   EDGERTON GR, 2000, J POPULAR FILM   WIN
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gonzales Rafael C., 1987, DIGITAL IMAGE PROCES
   Goodrum A. A., 2000, Informing Science, V3, P63
   GREENELD GR, 2003, P INT C CENTR EUR CO, P189
   Hertzmann A, 2001, COMP GRAPH, P327, DOI 10.1145/383259.383295
   HERTZMANN A, 2002, P 13 EUR WORKSH REND, P233
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Mojsilovic A, 2004, INT J COMPUT VISION, V56, P79, DOI 10.1023/B:VISI.0000004833.39906.33
   Müller H, 2004, INT J COMPUT VISION, V56, P65, DOI 10.1023/B:VISI.0000004832.02269.45
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   REINHARD E, 1910, IEEE COMPUT GRAPH, P34
   Ruderman DL, 1998, J OPT SOC AM A, V15, P2036, DOI 10.1364/JOSAA.15.002036
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Schmid C, 2004, INT J COMPUT VISION, V56, P7, DOI 10.1023/B:VISI.0000004829.38247.b0
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tieu K, 2004, INT J COMPUT VISION, V56, P17, DOI 10.1023/B:VISI.0000004830.93820.78
   Wang T, 2004, INT J COMPUT VISION, V56, P37, DOI 10.1023/B:VISI.0000004831.53436.88
   WELSH T, 2002, P 29 ANN C COMP GRAP, P277, DOI DOI 10.1145/566570.566576
   Yang J, 2004, INT J COMPUT VISION, V56, P47, DOI 10.1023/B:VISI.0000004836.59343.e9
NR 27
TC 11
Z9 14
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 50
EP 60
DI 10.1016/j.imavis.2005.12.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600007
DA 2024-07-18
ER

PT J
AU Jiang, JM
   Weng, Y
   Li, PJ
AF Jiang, Jianmin
   Weng, Ying
   Li, PengJie
TI Dominant colour extraction in DCT domain
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE dominant colour features; MPEG-7; feature extraction in compressed
   domain
ID IMAGE RETRIEVAL; DESCRIPTORS; COEFFICIENTS
AB As most of MPEG and JPEG compression standards are DCT-based, we propose a simple, low-cost and fast algorithm to extract dominant colour features directly in DCT domain without involving full decompression to access the pixel data. As dominant colour is one of the colour features used in constructing MPEG-7 dominant colour descriptors, the proposed algorithm would provide useful technique for those already compressed videos and images, where MPEG-7 dominant colour descriptors are needed. While the proposed algorithm presents advantage's in terms of computing efficiency, i.e. eliminating the need of IDCT for compressed videos and images, extensive experiments also support that the proposed algorithm achieves competitive performances in extracting dominant colour features when compared with the pixel domain extraction described in MPEG-7. Crown Copyright (c) 2006 Published by Elsevier B.V. All rights reserved.
C1 Univ Bradford, Bradford BD7 1DP, W Yorkshire, England.
   Chinese Acad Sci, Inst Acoust, Beijing 100864, Peoples R China.
C3 University of Bradford; Chinese Academy of Sciences; Institute of
   Acoustics, CAS
RP Jiang, JM (corresponding author), Univ Bradford, Bradford BD7 1DP, W Yorkshire, England.
EM j.jiangl@bradford.ac.uk
RI xia, yu/E-6596-2012
CR Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   Brunelli R, 1999, J VIS COMMUN IMAGE R, V10, P78, DOI 10.1006/jvci.1997.0404
   Deng YN, 2001, IEEE T IMAGE PROCESS, V10, P140, DOI 10.1109/83.892450
   FENG G, IN PRESS PATTERN REC
   *ISO IEC, 2001, JTC1SC29WG11N4031 IS
   Jeannin S, 2001, IEEE T CIRC SYST VID, V11, P720, DOI 10.1109/76.927428
   Jiang JM, 2004, IEEE T CIRC SYST VID, V14, P595, DOI 10.1109/TCSVT.2004.826762
   Jiang JM, 2002, IEEE T SIGNAL PROCES, V50, P1160, DOI 10.1109/78.995072
   Ko B, 2001, PATTERN ANAL APPL, V4, P174, DOI 10.1007/s100440170015
   LIU MG, 2002, P ICASSP 02
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Reeves R, 1997, P SOC PHOTO-OPT INS, V3022, P398, DOI 10.1117/12.263428
   Sikora T, 2001, IEEE T CIRC SYST VID, V11, P696, DOI 10.1109/76.927422
   WALLACE GK, 1991, COMMUN ACM, V34, P31
NR 14
TC 24
Z9 28
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2006
VL 24
IS 12
BP 1269
EP 1277
DI 10.1016/j.imavis.2006.04.009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 107AH
UT WOS:000242142600001
DA 2024-07-18
ER

PT J
AU Miao, ZJ
   Gandelin, MH
   Yuan, BZ
AF Miao, Zhenjiang
   Gandelin, M. -H.
   Yuan, Baozong
TI A new image shape analysis approach and its application to flower shape
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image processing and analysis; pattern recognition; artificial
   intelligence; shape analysis
ID RECOGNITION
AB This paper describes a rose variety recognition program and proposes Modified Fourier Descriptor. Based on the modified descriptor, a new measurement, Angle Measurement, is proposed for image shape analysis. The rationality of this measurement is analyzed and its mathematical definition is given. We use it for rose flower shape analysis and the experiment results show that this measurement is quite efficient for image shape analysis. (c) 2006 Elsevier B.V. All rights reserved.
C1 Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Miao, ZJ (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM zjmiao@center.njtu.edu.cn
CR BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   Bruzzone L, 1999, IEEE T GEOSCI REMOTE, V37, P1179, DOI 10.1109/36.752239
   CORNELIS J, 1993, MED IMAGE PROCESSING, V11, P458
   Fu K.S., 1982, SYNTACTIC PATTERN RE, Vsecond
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   Jasjit S.S., 2005, Handbook of Biomedical Image Analysis. II
   KASHYAP RL, 1981, IEEE T INFORM THEORY, V27, P627, DOI 10.1109/TIT.1981.1056390
   KRISHNAMURTHY S, 1993, PATTERN RECOGN LETT, V14, P915, DOI 10.1016/0167-8655(93)90156-8
   Lillesand T. M., 2004, REMOTE SENSING IMAGE
   MCKEOWN DM, 1993, RES AUTOMATED ANAL R, P99
   MIAO Z, 2006, ENG APPL ARTIFICIAL, V19
   MIAO ZJ, 1994, ENG APPL ARTIF INTEL, V7, P593, DOI 10.1016/0952-1976(94)90064-7
   Miao ZJ, 2000, PATTERN RECOGN LETT, V21, P169, DOI 10.1016/S0167-8655(99)00144-0
   MIAO ZJ, 1997, P 6 IEEE INT C FUZZ, V2, P1083
   MIAO ZJ, 2007, COMPUTERIZED ROSE VA
   PLAMONDON R, 1993, PATTERN RECOGN, V26, P379, DOI 10.1016/0031-3203(93)90165-S
   Sonka M., 2004, COMPUTER VISION MATH
   TECH CH, 1998, IEEE T PATTERN ANAL, V10, P496
   *UPOV, 1990, GUID COND TESTS DIST
   VINCENT LM, 1994, P SPIE, V2181
   ZHAN CT, 1972, IEEE T COMPUT, V21, P269
   ZLOTNICK A, 1993, CVGIP-IMAG UNDERSTAN, V57, P243, DOI 10.1006/ciun.1993.1016
   2001, IEEE WORKSH BIOM IM
   2003, ICDAR 2003 7 INT C D
NR 25
TC 13
Z9 14
U1 1
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1115
EP 1122
DI 10.1016/j.imavis.2006.04.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300007
DA 2024-07-18
ER

PT J
AU Ormoneit, D
   Black, MJ
   Hastie, T
   Kjellström, H
AF Ormoneit, D
   Black, MJ
   Hastie, T
   Kjellström, H
TI Representing cyclic human motion using functional analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 14th Annual Neural Information Processing Systems Conference (NIPS)
CY NOV 27-DEC 02, 2000
CL DENVER, CO
DE human motion; functional data analysis; missing data; singular value
   decomposition; principal component analysis; motion capture; tracking
ID GAIT ANALYSIS; RECOGNITION; FRAMEWORK; CAPTURE; MODELS
AB We present a robust automatic method for modeling cyclic 3D human motion such as walking using motion-capture data. The pose of the body is represented by a time-series of joint angles which are automatically segmented into a sequence of motion cycles. The mean and the principal components of these cycles are computed using a new algorithm that enforces smooth transitions between the cycles by operating in the Fourier domain. Key to this method is its ability to automatically deal with noise and missing data. A learned walking model is then exploited for Bayesian tracking of 3D human motion. (C) 2005 Elsevier B.V. All rights reserved.
C1 Brown Univ, Dept Comp Sci, Providence, RI 02912 USA.
   Marshall Wace LLP, London WC2N 6HT, England.
   Stanford Univ, Dept Stat, Stanford, CA 94305 USA.
   Swedish Def Res Agcy, Dept IR Syst, SE-16490 Stockholm, Sweden.
C3 Brown University; Stanford University; Saab Group
RP Brown Univ, Dept Comp Sci, 115 Waterman St,Box 1910, Providence, RI 02912 USA.
EM d.ormoneit@mwam.com; black@cs.brown.edu; hastie@stat.stanford.edu;
   hedvig@nada.kth.se
RI Kjellström, Hedvig/AEF-4955-2022
OI Kjellström, Hedvig/0000-0002-5750-9655; Hastie,
   Trevor/0000-0002-0164-3142
CR ALLMEN M, 1990, INT C PATT REC, P365
   Amaya K, 1996, PROC GRAPH INTERF, P222
   ARIKAN O, 2002, SIGGRAPH, P438
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P267, DOI 10.1109/AFGR.2002.1004165
   BESSE P, 1986, PSYCHOMETRIKA, V51, P285, DOI 10.1007/BF02293986
   BLACK MJ, 1998, LNCS SERIES, V140, P909
   BOBICK A, 1996, INT C PATTERN REC, V1, P307
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bowden Richard, 2000, IEEE WORKSH HUM MOD, V2000
   Brand M, 2000, COMP GRAPH, P183, DOI 10.1145/344779.344865
   BRAND M, 1999, INT C COMP VIS, V2, P1237
   Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581
   Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382
   CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880
   CHAM T, 1999, P CVPR, V1, P239
   Collins RT, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P366, DOI 10.1109/AFGR.2002.1004181
   Cunado D, 2003, COMPUT VIS IMAGE UND, V90, P1, DOI [10.1016/S1077-3142(03)00008-0, 10.1010/SI077-3142(03)00008-0]
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   Deutscher J, 2005, INT J COMPUT VISION, V61, P185, DOI 10.1023/B:VISI.0000043757.18370.9c
   Faraway JJ, 1997, TECHNOMETRICS, V39, P254, DOI 10.2307/1271130
   FLOGG DC, 1983, IMAGE VISION COMPUT, V1, P5
   Gleicher M, 1999, COMPUT GRAPHICS-US, V33, P51, DOI 10.1145/345370.345409
   Goncalves L, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P234, DOI 10.1109/AFGR.1998.670954
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   HALL P, 1999, NONPARAMETRIC ESTIMA
   HASTIE T, 2000, IMPUTING MISSING DAT
   Howe NR, 2000, ADV NEUR IN, V12, P820
   Huang PS, 1999, IEE P-VIS IMAGE SIGN, V146, P93, DOI 10.1049/ip-vis:19990187
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1996, ECCV, P343
   Ju SX, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P38, DOI 10.1109/AFGR.1996.557241
   Kale A, 2004, IEEE T IMAGE PROCESS, V13, P1163, DOI 10.1109/TIP.2004.832865
   KOVAR L, 2002, SIGGRAPH, P491
   LEE J, 2002, INTERACTIVE CONTROL, P491
   Little J. J., 1998, Videre, V1
   MOLINA L, 2000, IEEE WORKSH HUM MOT, P137
   Murase H, 1996, PATTERN RECOGN LETT, V17, P155, DOI 10.1016/0167-8655(95)00109-3
   Murray M P, 1967, Am J Phys Med, V46, P290
   Nixon MS, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P139, DOI 10.1109/AFGR.2004.1301521
   OLSHEN RA, 1989, ANN STAT, V17, P1419, DOI 10.1214/aos/1176347372
   Ormoneit D, 2001, ADV NEUR IN, V13, P894
   PAVOLVIC V, 1999, ICCV, V1, P94
   Pullen K, 2000, COMP ANIM CONF PROC, P36, DOI 10.1109/CA.2000.889031
   Pullen Katherine., 2002, SIGGRAPH 02, P501
   Ramsey J., 1997, FUNCTIONAL DATA ANAL
   RICE JA, 1991, J ROY STAT SOC B MET, V53, P233
   ROHR K, 1994, CVGIP-IMAG UNDERSTAN, V59, P94, DOI 10.1006/ciun.1994.1006
   ROHR K, 1997, MOTION BASED RECOGNI, P171
   SEITZ SM, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P970, DOI 10.1109/CVPR.1994.323936
   SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651
   SHUM HY, 2002, P ACM SIGGRAPH, P465
   SIDENBLADH H, 2000, INT C AUT FAC GEST R, P368
   SIDENBLADH H, 2000, LNCS SERIES, V1813, P702
   SIDENBLADH H, 2001, THESIS KTH STOCKHOLM
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   Troje NF, 2002, J VISION, V2, P371, DOI 10.1167/2.5.2
   Troyanskaya O, 2001, BIOINFORMATICS, V17, P520, DOI 10.1093/bioinformatics/17.6.520
   Unuma Munetoshi, 1995, SIGGRAPH, P91
   URTASUN R, 2005, P IEEE COMP VIS PATT, V2, P932
   Urtasun Raquel, 2004, EUR C COMP VIS, P92
   Wachter S, 1999, COMPUT VIS IMAGE UND, V74, P174, DOI 10.1006/cviu.1999.0758
   Winter DA., 1991, WATERLOO BIOMECHANIC
   WREN CR, 1999, TR451 MIT
   Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726
   Yacoob Y, 2000, INT J COMPUT VISION, V36, P5, DOI 10.1023/A:1008173322902
NR 66
TC 41
Z9 51
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 12
PY 2005
VL 23
IS 14
BP 1264
EP 1276
DI 10.1016/j.imavis.2005.09.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 997KJ
UT WOS:000234243800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chetverikov, D
   Stepanov, D
   Krsek, P
AF Chetverikov, D
   Stepanov, D
   Krsek, P
TI Robust euclidean alignment of 3D point sets: the trimmed iterative
   closest point algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE registration; point sets; iterative closest point; least trimmed
   squares; robustness
ID REGISTRATION; REGRESSION
AB The problem of geometric alignment of two roughly pre-registered, partially overlapping, rigid, noisy 3D point sets is considered. A new natural and simple, robustified extension of the popular Iterative Closest Point (ICP) algorithm [IEEE Trans. Pattern Anal. Machine Intell. 14 (1992) 239] is presented, called Trimmed ICP (TrICP). The new algorithm is based on the consistent use of the Least Trimmed Squares approach in all phases of the operation. Convergence is proved and an efficient implementation is discussed. TrICP is fast, applicable to overlaps under 50%, robust to erroneous and incomplete measurements, and has easy-to-set parameters. ICP is a special case of TrICP when the overlap parameter is 100%. Results of a performance evaluation study on the SQUID database of 1100 shapes are presented. The tests compare TrICP and the Iterative Closest Reciprocal Point algorithm [Fifth International Conference on Computer Vision, 1995]. (C) 2004 Elsevier B.V. All rights reserved.
C1 Eotvos Lorand Univ, Comp & Automat Res Inst, H-1111 Budapest, Hungary.
   Czech Tech Univ, FEE, Ctr Appl Cybernet, Prague 6, Czech Republic.
C3 Hungarian Academy of Sciences; Hungarian Research Network; HUN-REN
   Institute for Computer Science & Control; Eotvos Lorand University;
   Czech Technical University Prague
RP Chetverikov, D (corresponding author), Eotvos Lorand Univ, Comp & Automat Res Inst, Kende U 13-17, H-1111 Budapest, Hungary.
EM csetverikov@sztaki.hu
RI Krsek, Pavel/C-8221-2011; Stepanov, Dmtrii/F-6498-2014
OI Krsek, Pavel/0000-0002-3071-1589; Stepanov, Dmtrii/0000-0003-3524-7030
CR [Anonymous], 2001, 3 INT C 3D DIG IM MO
   [Anonymous], P WORKSH AUSTR ASS P
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   BRUNNSTROM K, 1996, P 13 INT C PATT REC, V4, P689
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   CHETVERIKOV D, 1991, PATTERN RECOGN LETT, V12, P409, DOI 10.1016/0167-8655(91)90298-Z
   Chow CK, 2004, PATTERN RECOGN, V37, P105, DOI 10.1016/S0031-3203(03)00222-X
   Eggert DW, 1997, MACH VISION APPL, V9, P272, DOI 10.1007/s001380050048
   FITZGIBBON AW, 2001, BRIT MACH VIS C
   Friedman J. H., 1977, ACM Transactions on Mathematical Software, V3, P209, DOI 10.1145/355744.355745
   MEER P, 1991, INT J COMPUT VISION, V6, P59, DOI 10.1007/BF00127126
   PAJDLA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P390, DOI 10.1109/ICCV.1995.466913
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Pulli K., 1997, THESIS U WASHINGTON
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   ROUSSEEUW PJ, 1990, J AM STAT ASSOC, V85, P633, DOI 10.2307/2289995
   ROUSSEEUW PJ, 1984, J AM STAT ASSOC, V79, P871, DOI 10.2307/2288718
   ROUSSEEUW PJ, 1999, COMPUTING SCI STAT, V31, P451
   Trucco E, 1999, PATTERN RECOGN LETT, V20, P889, DOI 10.1016/S0167-8655(99)00055-0
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   University of Surrey Guildford UK, SQUID DAT SHAP QUER
   YE M, 2000, P INT C PATT REC, V3, P1064
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 23
TC 338
Z9 405
U1 8
U2 78
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2005
VL 23
IS 3
BP 299
EP 309
DI 10.1016/j.imavis.2004.05.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NO
UT WOS:000227221800003
DA 2024-07-18
ER

PT J
AU Kumar, MP
   Goyal, S
   Kuthirummal, S
   Jawahar, CV
   Narayanan, PJ
AF Kumar, MP
   Goyal, S
   Kuthirummal, S
   Jawahar, CV
   Narayanan, PJ
TI Discrete contours in multiple views: approximation and recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Indian Conference on Vision, Graphics and Image Processing (ICVGIP)
CY DEC 16-18, 2002
CL Ahmedabad, INDIA
DE planar shape recognition; polygonal approximation; Fourier transform;
   invariant; projective geometry; piecewise conic approximation
ID FOURIER DESCRIPTORS; ALGORITHM; OBJECTS; CURVES
AB Recognition of discrete planar contours under similarity transformations has received a lot of attention but little work has been reported on recognizing them under more general transformations. Planar object boundaries undergo projective or affine transformations across multiple views. We present two methods to recognize discrete curves in this paper. The first method computes a piecewise parametric approximation of the discrete curve that is projectively invariant. A polygon approximation scheme and a piecewise conic approximation scheme are presented here. The second method computes an invariant sequence directly from the sequence of discrete points on the curve in a Fourier transform space. The sequence is shown to be identical up to a scale factor in all affine related views of the curve. We present the theory and demonstrate its applications to several problems including numeral recognition, aircraft recognition, and homography computation. (C) 2004 Elsevier B.V. All rights reserved.
C1 Int Inst Informat Technol, Ctr Visual Informat Technol, Hyderabad 500019, Andhra Pradesh, India.
C3 International Institute of Information Technology Hyderabad
RP Int Inst Informat Technol, Ctr Visual Informat Technol, Hyderabad 500019, Andhra Pradesh, India.
EM jawahar@iiit.net
RI Rohlf, F J/A-8710-2008; Jawahar, C.V./ACR-3102-2022
OI Jawahar, C.V./0000-0001-6767-7057; Narayanan, P J/0000-0002-7164-4917
CR ANDERSON IM, 1984, IEEE T PATTERN ANAL, V6, P27, DOI 10.1109/TPAMI.1984.4767472
   ARBTER K, 1990, IEEE T PATTERN ANAL, V12, P640, DOI 10.1109/34.56206
   BOOKSTEIN FL, 1979, COMPUT VISION GRAPH, V9, P56, DOI 10.1016/0146-664X(79)90082-0
   DEHAEMER MJ, 1991, COMPUT GRAPH, V15, P175, DOI 10.1016/0097-8493(91)90071-O
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   HARTLEY R, 1994, P ARPA IU WORKSH DRP, V2, P1009
   Huttenlocher D. P., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P102
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   KUMAR MP, 2002, IND C COMP VIS GRAPH, P317
   Kuthirummal S, 2002, INT C PATT RECOG, P456, DOI 10.1109/ICPR.2002.1044757
   KUTHIRUMMAL S, 2002, IND C COMP VIS GRAPH, P323
   LEUNG MK, 1990, PATTERN RECOGN, V23, P69, DOI 10.1016/0031-3203(90)90049-Q
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   MOHR R, 1993, PROJECTIVE GEOMETRY
   Mundy J., 1992, GEOMETRIC INVARIANCE
   PAUWELS EJ, 1995, INT J COMPUT VISION, V14, P49, DOI 10.1007/BF01421488
   Pavlidis T., 1977, STRUCTURAL PATTERN R
   Salotti M, 2001, PATTERN RECOGN LETT, V22, P215, DOI 10.1016/S0167-8655(00)00088-X
   SHASHUA A, 1994, IEEE T PATTERN ANAL, V16, P778, DOI 10.1109/34.308472
   SHIRLEY P, 1990, P SAN DIEG WORKSH VO, V24, P63
   ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234
   VANGOOL LJ, 1992, GEOMETRIC INVARIANCE
   WALLACE TP, 1980, COMPUT VISION GRAPH, V13, P99, DOI 10.1016/S0146-664X(80)80035-9
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
NR 25
TC 11
Z9 11
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2004
VL 22
IS 14
BP 1229
EP 1239
DI 10.1016/j.imavis.2004.03.022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 882LG
UT WOS:000225939800010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dias, MB
   Buxton, BF
AF Dias, MB
   Buxton, BF
TI Separating shape and pose variations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE flexible shape models; linear combination of views; trifocal tensor;
   facial expression analysis
AB We have integrated a coupled-view Flexible Shape Model (FSM) and the Linear Combination of Views (LCV) technique to form an Integrated Shape and Pose Model (ISPM) of a 3D deformable object. The ISPM describes the object's intrinsic shape variations via the coupled-view FSM, while modelling its extrinsic pose variations via the LCV technique, all in a 2D image context. This enables us to model pose and shape independently in 2D. Our main contribution is the pose-alignment algorithm that separates pose and shape information. Some preliminary results are provided. (C) 2004 Elsevier B.V. All rights reserved.
C1 UCL, Dept Comp Sci, London WC1E 6BT, England.
C3 University of London; University College London
RP UCL, Dept Comp Sci, Gower St, London WC1E 6BT, England.
EM b.dias@cs.ucl.ac.uk
CR [Anonymous], STAT MODELS APPEARAN
   AVIDAN S, 1997, P ACM VRST 97, P103
   BRETZNER L, 1999, THESIS CVAP, P77
   COOTES T, 2000, P BRIT MACH VIS C, V1, P52
   DIAS MB, 2002, P BRIT MACH VIS C BM, P827
   Golub G.H., 1989, MATRIX COMPUTATIONS
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   HANSARD ME, 2000, P 6 EUR C COMP VIS, P191
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   KENNEDY DM, 1999, BMVC, V1, P305
   Koufakis I, 1999, IMAGE VISION COMPUT, V17, P1031, DOI 10.1016/S0262-8856(99)00005-0
   MENDONCA PRS, 1998, P 9 BRIT MACH VIS C, P125
   Peters G, 2000, RRD PATTERN RECOGNIT, V1, P179
   POLLARD S, 1998, P BMVC, V2, P770
   SHASHUA A, 1997, P INT WORKSH ALG FRA
   THORHALLSSON T, 1999, P INT C COMP VIS PAT, V1, P450
   ULLMAN S, 1991, IEEE T PATTERN ANAL, V13, P992, DOI 10.1109/34.99234
NR 17
TC 5
Z9 6
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 851
EP 861
DI 10.1016/j.imavis.2004.02.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300013
DA 2024-07-18
ER

PT J
AU Matas, J
   Chum, O
AF Matas, J
   Chum, O
TI Randomized RANSAC with <i>T<sub>d,d</sub></i> test
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RANSAC; randomized algorithm; epipolar geometry estimation
AB Many computer vision algorithms include a robust estimation step where model parameters are computed from a data set containing a significant proportion of outliers. The RANSAC algorithm is possibly the most widely used robust estimator in the field of computer vision. In the paper we show that under a broad range of conditions, RANSAC efficiency is significantly improved if its hypothesis evaluation step is randomized.
   A new randomized (hypothesis evaluation) version of the RANSAC algorithm, R-RANSAC, is introduced. Computational savings are achieved by typically evaluating only a fraction of data points for models contaminated with outliers. The idea is implemented in a two-step evaluation procedure. A mathematically tractable class of statistical preverification test of samples is introduced. For this class of preverification test we derive an approximate relation for the optimal setting of its single parameter. The proposed pre-test is evaluated on both synthetic data and real-world problems and a significant increase in speed is shown. (C) 2004 Elsevier B.V. All rights reserved.
C1 Czech Tech Univ, Dept Cybernet, Ctr Machine Percept, CZ-12135 Prague, Czech Republic.
   Univ Surrey, CVSSP, Guildford GU2 7XH, Surrey, England.
C3 Czech Technical University Prague; University of Surrey
RP Czech Tech Univ, Dept Cybernet, Ctr Machine Percept, 13, CZ-12135 Prague, Czech Republic.
EM matas@cmp.felk.cvut.cz; chum@cmp.felk.cvut.cz
RI Chum, Ondrej/F-5262-2015; , Matas/AAW-3282-2020
OI Matas, Jiri/0000-0003-0863-4844; Chum, Ondrej/0000-0001-7042-1810
CR CLARKE J, 1996, P 7 BMVC, P415
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Kittler Josef, 2003, LECT NOTES COMPUT SC, P236
   LEONARDIS A, 1997, TR47 PRIP TU WIEN
   MATAS J, 2001, CTUCMP200133 FEE CZE
   MCLAUCHLAN P, 2000, P BMVC, P616
   MYATT DR, 2002, BMVC02, V2, P458
   POLLEFEYS M, 1999, THESIS ESAT PSI KU L
   Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   SCHAFFALITZKY F, 2001, P 8 ICCV VANC CAN JU
   Torr P., 1995, THESIS U OXFORD
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Torr PHS, 1998, COMPUT VIS IMAGE UND, V71, P312, DOI 10.1006/cviu.1997.0559
   TUYTELAARS T, 2000, P 11 BMVC
NR 16
TC 119
Z9 148
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 837
EP 842
DI 10.1016/j.imavis.2004.02.009
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300011
DA 2024-07-18
ER

PT J
AU Ng, KC
   Ishiguro, H
   Trivedi, M
   Sogo, T
AF Ng, KC
   Ishiguro, H
   Trivedi, M
   Sogo, T
TI An integrated surveillance system - human tracking and view synthesis
   using multiple omni-directional vision sensors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE human tracking; multiple camera stereo; N-ocular stereo; human activity
   profiling; dynamic view synthesis; visual modeling; surveillance and
   monitoring; intelligent environments
ID STEREO; DEPTH
AB Accurate and efficient monitoring of dynamically changing environments is one of the most important requirements for visual surveillance systems. This paper describes the development of an integrated system for this monitoring purpose. The system consists of multiple omnidirectional vision sensors and was developed to address two specific surveillance tasks: (1) robust tracking and profiling of human activities; (2) dynamic synthesis of virtual views for observing the environment from arbitrary vantage points. (C) 2003 Elsevier B.V. All rights reserved.
C1 STMicroelect Inc, AST La Jolla Lab, San Diego, CA USA.
   Wakayama Univ, Dept Comp & Commun Sci, Wakayama, Japan.
   Univ Calif San Diego, ECE Dept, Comp Vis & Robot Res Lab, San Diego, CA 92103 USA.
   NEC Corp Ltd, Internet Syst Res Labs, Kawasaki, Kanagawa 213, Japan.
C3 STMicroelectronics; Wakayama University; University of California
   System; University of California San Diego; NEC Corporation
RP STMicroelect Inc, AST La Jolla Lab, San Diego, CA USA.
EM kim.ng@st.com
RI Sogo, Takuya/AAK-7075-2020
CR Adelson E.H., 1991, COMPUTATION MODELS V
   Boult TE, 1998, PROC CVPR IEEE, P966, DOI 10.1109/CVPR.1998.698724
   Boyd JE, 1998, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS, P249, DOI 10.1109/MMCS.1998.693651
   CAPELLA R, 1999, THESIS CALTECH SAN D
   COLLINS R, 1998, DARPA IM UND WORKSH
   Dalmia AK, 1996, MACH VISION APPL, V9, P43
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   GUREWITZ E, 1986, P ICPR, P966
   ISHIGURO H, 1992, IEEE T PATTERN ANAL, V14, P257, DOI 10.1109/34.121792
   Ishiguro H, 1997, INT JOINT CONF ARTIF, P36
   Ishiguro H, 2003, MACH VISION APPL, V14, P94, DOI 10.1007/s00138-002-0103-0
   ISHIGURO Hiroshi., 1998, PANORAMIC VISION, P433
   Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074
   KANADE T, 1997, DARPA IM UND WORKSH, V1, P3
   Kato K., 1999, Proceedings 1999 IEEE/RSJ International Conference on Intelligent Robots and Systems. Human and Environment Friendly Robots with High Intelligence and Emotional Quotients (Cat. No.99CH36289), P966, DOI 10.1109/IROS.1999.812805
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   LIPTON A, 1998, DARPA IM UND WORKSH, P115
   *LONGM GROUP, 1976, STAT METH RES PROD S, V13
   MARAPANE SB, 1994, IEEE T PAMI, V16
   Mori T., 1997, Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97 (Cat. No.97CH36108), P1334, DOI 10.1109/IROS.1997.656467
   Narayanan PJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P3, DOI 10.1109/ICCV.1998.710694
   NG K, 1999, C VID P IEEE VIS 99
   Ng KC, 2002, INT J COMPUT VISION, V47, P131, DOI 10.1023/A:1014589723611
   NG KC, 1998, P MULTIMEDIA SYSTEMS, V3528
   NG KC, 2001, IEEE WORKSH STER MUL
   OKUTOMI M, 1993, IEEE T PATTERN ANAL, V15, P353, DOI 10.1109/34.206955
   Seitz SM, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P17, DOI 10.1109/ICCV.1998.710696
   Shams S, 1996, P IEEE, V84, P1442, DOI 10.1109/5.537110
   SOGO T, 2001, PANORAMIC VISION SEN
   TRIVEDI MM, 2000, IEEE SYST MAN CYBERN
   YACHIDA M, 1986, 3 INT S ROB RES ISRR, P11
NR 32
TC 18
Z9 19
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2004
VL 22
IS 7
BP 551
EP 561
DI 10.1016/j.imavis.2003.09.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RT
UT WOS:000221481000004
DA 2024-07-18
ER

PT J
AU Sim, DG
   Kim, HK
   Park, RH
AF Sim, DG
   Kim, HK
   Park, RH
TI Invariant texture retrieval using modified Zernike moments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE texture; texture retrieval; translation; scaling; rotation; Zernike
   moments; invariant descriptor; visual descriptor; MPEG-7
ID CLASSIFICATION; ROTATION; SEGMENTATION
AB This paper presents an effective texture descriptor invariant to translation, scaling, and rotation for texture-based image retrieval applications. In order to find the minimal matching distance between two descriptors, existing frequency-layout descriptors require a lot of distance calculations with every possible combination of scaling and rotation values because they are not invariant to geometrical transformation. To cope with this problem, a new compact descriptor is proposed that is theoretically invariant to such transformations. The proposed descriptor is obtained by first calculating the power spectrum of an original texture image for translation invariance and then the power spectrum image is normalized for scale invariance. Finally, modified Zernike moments are calculated for rotation invariance. The proposed algorithm is simpler and lower than conventional algorithms in terms of the computational complexity. The effectiveness of the proposed descriptor for invariant texture retrieval is shown with various texture datasets by comparing the retrieval accuracy, the descriptor size, and the matching complexity of the proposed descriptor with those of conventional descriptors. (C) 2003 Elsevier B.V. All rights reserved.
C1 Hyundai Elect Ind Co Ltd, Mobile Telecommun Terminal Div, R&D Dept 9, Seoul, South Korea.
   Sejong Univ, Dept Software Engn, Seoul, South Korea.
   Sogang Univ, Dept Elect Engn, Seoul 100611, South Korea.
C3 Sejong University; Sogang University
RP Univ Washington, Dept Bioengn, POB 352500, Seattle, WA 98195 USA.
EM samsim@icsl.ee.washington.edu; hkkim@sejong.ac.kr;
   rhpark@ccs.sogang.ac.kr
RI kim, haekwang/G-1645-2013; Park, Rae-Hong/Q-7908-2019
OI Park, Rae-Hong/0000-0002-4792-2980
CR Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796
   Brodatz P., 1966, PHOTOGRAPHIC ALBUM A
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   Comer ML, 1999, IEEE T IMAGE PROCESS, V8, P408, DOI 10.1109/83.748895
   de Rivaz P., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P109, DOI 10.1109/ICIP.1999.821576
   DERIN H, 1987, IEEE T PATTERN ANAL, V9, P39, DOI 10.1109/TPAMI.1987.4767871
   Derrode S, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P877, DOI 10.1109/MMCS.1999.778603
   Derrode S, 2001, COMPUT VIS IMAGE UND, V83, P57, DOI 10.1006/cviu.2001.0922
   Do MN, 2002, IEEE T MULTIMEDIA, V4, P517, DOI 10.1109/TMM.2002.802019
   DUBUF JMH, 1990, PATTERN RECOGN, V23, P291, DOI 10.1016/0031-3203(90)90017-F
   Espinal F, 1998, OPT ENG, V37, P166, DOI 10.1117/1.601844
   Götze N, 2000, INT C PATT RECOG, P948
   Haley GM, 1999, IEEE T IMAGE PROCESS, V8, P255, DOI 10.1109/83.743859
   Kaplan LM, 1999, IEEE T IMAGE PROCESS, V8, P1572, DOI 10.1109/83.799885
   KASHYAP RL, 1986, IEEE T PATTERN ANAL, V8, P472, DOI 10.1109/TPAMI.1986.4767811
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Kruizinga P, 1999, IEEE T IMAGE PROCESS, V8, P1395, DOI 10.1109/83.791965
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Liu SC, 1997, IEEE T IMAGE PROCESS, V6, P1176, DOI 10.1109/83.605414
   Ma W.Y., 1995, Image Processing, 1995. Proceedings., V2, P256, DOI DOI 10.1109/ICIP.1995.537463
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MANJUNATH BS, 1999, ISOIECJTC1SC29WG11
   *MPEG 7 VID GROUP, 1999, ISOIECJTC1SC29WG11
   OHM JR, 1999, ISOIECJTC1SC29WG11
   PORLAPALLI H, 1998, IEEE T IND ELECTRON, V45, P142
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   RO YM, 1999, ISOIECJTC1SC29WG11
   RO YM, 1999, P IEEE INT C IM PROC, V2, P580
   SIM DG, 1999, ISOIECJTC1SC29WG11
   TABATABAI A, 1999, ISOMPEGP574
   Tang XO, 1998, IEEE T IMAGE PROCESS, V7, P1602, DOI 10.1109/83.725367
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Valkealahti K, 1998, IEEE T PATTERN ANAL, V20, P90, DOI 10.1109/34.655653
   Wang LZ, 1998, IEEE T IMAGE PROCESS, V7, P196, DOI 10.1109/83.660996
   WOUVER V, 1998, P ICPR BRISB AUSTR, P814
   Wu WR, 1996, IEEE T IMAGE PROCESS, V5, P1423, DOI 10.1109/83.536891
   ZIYOU X, 2002, P IEEE INT C IM PROC, P22
NR 39
TC 41
Z9 43
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2004
VL 22
IS 4
BP 331
EP 342
DI 10.1016/j.imavis.2003.11.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 778FW
UT WOS:000189229700006
DA 2024-07-18
ER

PT J
AU Saito, H
   Omata, K
   Wawa, S
AF Saito, H
   Omata, K
   Wawa, S
TI Recovery of shape and surface reflectance of specular object from
   relative rotation of light source
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE surface reflectance property; specular reflectance; shape recovery;
   photometric stereo; multiple light sources
ID RECONSTRUCTION; MODEL
AB In this paper, we present a method for recovery of shape and surface reflectance of specular object from color images taken with a rotating light source. The image sequence is taken with a fixed camera while the light source is relatively rotating around the axis parallel to the optical axis of the camera. By assuming Lambertian reflectance model for the object surface and the orthographic projection for the camera, we can derive a simple relationship between the body reflectance at every object surface point and the rotating angle of the light source. For adapting specular reflectance that can be represented by Phong's model,we develop the algorithm to extract only body reflectance component which obeys the simple relationship for estimating surface normals and body reflectance component. As a result,the object shape and body reflectance distribution of the object surface can be recovered. In addition to this, reflectance parameters of specularity are also estimated by minimize the fitting error of the specular reflectance model. For demonstrating the effectiveness of the proposed method, we show the shape, body reflectance, and specular reflectance of specular objects, which are successfully recovered by the proposed method. (C) 2003 Elsevier B.V. All rights reserved.
C1 Keio Univ, Dept Informat & Comp Sci, Kouhoku Ku, Yokohama, Kanagawa 2238522, Japan.
C3 Keio University
RP Saito, H (corresponding author), Keio Univ, Dept Informat & Comp Sci, Kouhoku Ku, 3-14-1 Hiyoshi, Yokohama, Kanagawa 2238522, Japan.
RI Saito, Hideo/D-6223-2014
OI Saito, Hideo/0000-0002-2421-9862
CR [Anonymous], 1989, Shape from shading
   Cho SY, 2000, IEEE T IND ELECTRON, V47, P1346, DOI 10.1109/41.887964
   Gunaratne P., 1998, Proceedings of IAPR Workshop on Machine Vision Applications, P282
   KANADE T, 1996, P IEEE CVPR 96
   KLINKER GJ, 1990, INT J COMPUT VISION, V4, P7, DOI 10.1007/BF00137441
   LU J, 1997, TR9705 U BRIT COL
   LU J, 1996, P IEEE CVPR, V96, P694
   NARAYANAN PJ, 1998, P ICCV 98
   NAYAR SK, 1989, P IEEE ICRA, V1, P28
   OTSUKI M, 1993, P AS C COMP VIS ACCV
   SATO K, 1985, J ROBOTIC SYST, V2, P27
   SATO Y, 1994, J OPT SOC AM A, V11, P2990, DOI 10.1364/JOSAA.11.002990
   SATO Y, 1997, P INT C IM AN PROC I, V2, P270
   Sato Y., 1997, Proceedings of the 24th annual conference on Computer graphics and interactive techniques, P379
   Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   TOMINAGA S, 1989, J OPT SOC AM A, V6, P576, DOI 10.1364/JOSAA.6.000576
   Yamada T, 2000, IEICE T INF SYST, VE83D, P1415
NR 18
TC 9
Z9 9
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2003
VL 21
IS 9
BP 777
EP 787
DI 10.1016/S0262-8856(03)00091-X
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 711QX
UT WOS:000184753500002
DA 2024-07-18
ER

PT J
AU Ancona, N
   Cicirelli, G
   Stella, E
   Distante, A
AF Ancona, N
   Cicirelli, G
   Stella, E
   Distante, A
TI Ball detection in static images with Support Vector - Machines for
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE support vector machines; classification; object detection
ID SELECTION; FEATURES
AB We present a general method for detecting balls in images at the aim of automatically detecting goals during a soccer match. The detector learns the object to detect by using a supervised learning scheme called Support Vector Machines, in which the examples are views of the object. Due to the attitude of the camera with respect to football ground, the system can be thought of as an electronic linesman which helps the referee in establishing the occurrence of a goal during a soccer match. Numerous theoretical and practical issues are addressed in the paper. The first one concerns the determination of negative examples relevant for the problem at hand and the training of a reference classifier in the case of an unbalanced number of positive and negative examples. The second one focuses on the reduction of the computational complexity of the reference classifier during the test phase, without increasing its generalization error. The third issue regards the problem of parameter selection. which is equivalent, in our context, to the problem of selecting, among the classifiers the machine implements, the one having performances similar to the reference classifier. Experimental results on real images show the performances of the proposed detection scheme. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 CNR, Ist Sistemi Intelligenti Automaz, I-70126 Bari, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR)
RP Ancona, N (corresponding author), CNR, Ist Sistemi Intelligenti Automaz, Via Amendola 166-5, I-70126 Bari, Italy.
RI Ancona, Nicola/E-9971-2013; Ancona, Nicola/AAD-4772-2022; Cicirelli,
   Grazia/B-7699-2015
OI Ancona, Nicola/0000-0003-0065-0321; Cicirelli,
   Grazia/0000-0003-1562-0467; STELLA, ETTORE/0000-0003-1770-1228
CR Blum AL, 1997, ARTIF INTELL, V97, P245, DOI 10.1016/S0004-3702(97)00063-5
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   CICIRELLI G, 1952, P IASTED INT C APPL
   COURANT R, 1989, METHODS MATH PHYSICS, V1
   EVGENIOUS T, 1999, 1654 AI MIT ART INT
   GIROSI F, 1995, NEURAL COMPUT, V7, P219, DOI 10.1162/neco.1995.7.2.219
   HAAS A, 2001, P SPIE MACH VIS 3 DI, V4567
   HEISELE B, 2000, 1687 AI MIT ART INT
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   POGGIO T, 1989, 1140 AI MIT ART INT
   PONTIL M, 1997, 1612 AI MIT ART INT
   REID I, 1996, 4 EUR C COMP VIS 96, VB, P647
   SCHOLKOPF B, 1996, 1599 AI MIT ART INT
   SUNG K, 1994, 1521 AI MIT ART INT
   Vapnik V., 1999, NATURE STAT LEARNING
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
   Weston J, 2001, ADV NEUR IN, V13, P668
NR 18
TC 22
Z9 23
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2003
VL 21
IS 8
BP 675
EP 692
DI 10.1016/S0262-8856(03)00063-5
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 706VM
UT WOS:000184475800001
DA 2024-07-18
ER

PT J
AU Wang, P
   Jiao, BQ
   Yao, PP
   Wei, XY
   Zhang, AH
AF Wang, Ping
   Jiao, Boqiao
   Yao, Pengpeng
   Wei, Xiaoyuan
   Zhang, Aihua
TI A robust direct linear transformation for camera pose estimation using
   points
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Perspective-n-point problem (P n P); Relative position and attitude;
   Pose estimation; Monocular vision; Vision-based navigation; Computer
   vision
ID EFFICIENT SOLUTION; OPTIMIZATION; ALGORITHM; ACCURATE
AB Camera pose estimation from 3D points and their 2D projections, known as the perspective-n-point (PnP) problem, is a fundamental task in computer vision. In this paper, we propose a robust direct linear transformation method for the PnP problem. The novelty lies in that a plane constraint based on the pinhole camera model is introduced, and an over-constrained linear equation system is obtained by merging the linear form of both the measured point correspondences and the plane constraint. As a result, our method successfully reduces the minimal number of point correspondences required by the linear solver to 4, and yields a unique solution for 4point, 5-point, and n-point pose estimation. Experiment results, using both synthetic and real data, show that our method is substantially faster, and offers the accuracy and precision comparable with that of state-of-the-art methods.
C1 [Wang, Ping; Jiao, Boqiao; Wei, Xiaoyuan; Zhang, Aihua] Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou 730050, Peoples R China.
   [Wang, Ping] Key Lab Gansu Adv Control Elect & Control Engn, Lanzhou 730050, Peoples R China.
   [Yao, Pengpeng] Zhuhai Fudan Innovat Inst, Zhuhai, Guangdong, Peoples R China.
C3 Lanzhou University of Technology
RP Wang, P (corresponding author), Lanzhou Univ Technol, Coll Elect & Informat Engn, Lanzhou 730050, Peoples R China.; Wang, P (corresponding author), Key Lab Gansu Adv Control Elect & Control Engn, Lanzhou 730050, Peoples R China.
EM pingwangsky@163.com
RI Wei, Xiaoyuan/ABG-2936-2021
OI Wei, Xiaoyuan/0000-0002-7628-1174
FU National Natural Science Foundation of China [62361039, 62001198,
   62363025]; Key Laboratory of Gansu Advanced Control for Industrial
   Processes [2022KX02]; Key R & D plan of Science and Technology Plan of
   Gansu Province-Social Development Field Project [23YFFA0064]; Science
   and Technology Program of Lanzhou [2022-2-58]
FX This work was supported by the National Natural Science Foundation of
   China (No.62361039, No.62001198, No.62363025) , the Key Laboratory of
   Gansu Advanced Control for Industrial Processes (No. 2022KX02) , the Key
   R & D plan of Science and Technology Plan of Gansu Province-Social
   Development Field Project (No. 23YFFA0064) , and the Science and
   Technology Program of Lanzhou (No.2022-2-58) .
CR Abdel-Aziz Y., 1971, ASP S CLOSE RANGE PH
   ABIDI MA, 1995, IEEE T PATTERN ANAL, V17, P534, DOI 10.1109/34.391388
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992
   Bronson R., 2009, An Introduction to Optimization
   Carmigniani J, 2011, HANDBOOK OF AUGMENTED REALITY, P3, DOI 10.1007/978-1-4614-0064-6_1
   Chen CS, 2004, IEEE T PATTERN ANAL, V26, P848, DOI 10.1109/TPAMI.2004.34
   Dani AP, 2012, IEEE T AUTOMAT CONTR, V57, P241, DOI 10.1109/TAC.2011.2162890
   Deretey E, 2015, INT C INDOOR POSIT
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gao XS, 2003, IEEE T PATTERN ANAL, V25, P930, DOI 10.1109/TPAMI.2003.1217599
   Garro V, 2012, SECOND JOINT 3DIM/3DPVT CONFERENCE: 3D IMAGING, MODELING, PROCESSING, VISUALIZATION & TRANSMISSION (3DIMPVT 2012), P262, DOI 10.1109/3DIMPVT.2012.40
   GOLUB GH, 1970, NUMER MATH, V14, P403, DOI 10.1007/BF02163027
   Gramegna T, 2004, ROBOT AUTON SYST, V48, P145, DOI 10.1016/j.robot.2004.05.001
   Haralick R. M., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P592, DOI 10.1109/CVPR.1991.139759
   Hartley RI, 2009, INT J COMPUT VISION, V82, P64, DOI 10.1007/s11263-008-0186-9
   Hesch JA, 2011, IEEE I CONF COMP VIS, P383, DOI 10.1109/ICCV.2011.6126266
   HORAUD R, 1989, COMPUT VISION GRAPH, V47, P33, DOI 10.1016/0734-189X(89)90052-2
   Hu ZY, 2002, IEEE T PATTERN ANAL, V24, P550, DOI 10.1109/34.993561
   Ke T, 2017, PROC CVPR IEEE, P4618, DOI 10.1109/CVPR.2017.491
   Kim S, 2021, J AEROSP INFORM SYST, V18, P659, DOI 10.2514/1.I010975
   Kneip L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2969, DOI 10.1109/CVPR.2011.5995464
   Kneip L, 2014, LECT NOTES COMPUT SC, V8689, P127, DOI 10.1007/978-3-319-10590-1_9
   Kukelova Z, 2008, LECT NOTES COMPUT SC, V5304, P302, DOI 10.1007/978-3-540-88690-7_23
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   Li SQ, 2012, IEEE T PATTERN ANAL, V34, P1444, DOI 10.1109/TPAMI.2012.41
   Li SQ, 2011, INT J PATTERN RECOGN, V25, P627, DOI 10.1142/S0218001411008774
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu CP, 2000, IEEE T PATTERN ANAL, V22, P610, DOI 10.1109/34.862199
   Marchand E, 2016, IEEE T VIS COMPUT GR, V22, P2633, DOI 10.1109/TVCG.2015.2513408
   Mehralian MA, 2020, IET IMAGE PROCESS, V14, P3774, DOI 10.1049/iet-ipr.2020.0606
   Middelberg S, 2014, LECT NOTES COMPUT SC, V8690, P268, DOI 10.1007/978-3-319-10605-2_18
   Mourikis AI, 2009, IEEE T ROBOT, V25, P264, DOI 10.1109/TRO.2009.2012342
   Nakano G., 2019, BMVC, P26
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Olsson C, 2009, IEEE T PATTERN ANAL, V31, P783, DOI 10.1109/TPAMI.2008.131
   Quan L, 1999, IEEE T PATTERN ANAL, V21, P774, DOI 10.1109/34.784291
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Schönberger JL, 2016, PROC CVPR IEEE, P4104, DOI 10.1109/CVPR.2016.445
   Schweighofer G., 2008, BMVC
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   Shepperd S. W., 1978, Journal of Guidance and Control, V1, P223, DOI [10.2514/3.55767b, DOI 10.2514/3.55767B]
   Silva M., Camera calibration using a color-depth camera: Points and lines based dlt including radial distortion
   Terzakis George, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P478, DOI 10.1007/978-3-030-58452-8_28
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Triggs B., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P278, DOI 10.1109/ICCV.1999.791231
   UMEYAMA S, 1991, IEEE T PATTERN ANAL, V13, P376, DOI 10.1109/34.88573
   Wang P, 2018, PATTERN RECOGN LETT, V108, P31, DOI 10.1016/j.patrec.2018.02.028
   Wang P, 2018, COMPUT VIS IMAGE UND, V166, P81, DOI 10.1016/j.cviu.2017.10.005
   Zheng YQ, 2013, IEEE I CONF COMP VIS, P2344, DOI 10.1109/ICCV.2013.291
   Zheng YQ, 2013, IEICE T INF SYST, VE96D, P1525, DOI 10.1587/transinf.E96.D.1525
NR 51
TC 0
Z9 0
U1 6
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104883
DI 10.1016/j.imavis.2023.104883
EA DEC 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN0H1
UT WOS:001139481100001
DA 2024-07-18
ER

PT J
AU Song, TT
   Zhang, X
   Yang, DG
   Ye, YC
   Liu, C
   Zhou, J
   Song, YZ
AF Song, Tingting
   Zhang, Xin
   Yang, Degang
   Ye, Yichen
   Liu, Chen
   Zhou, Jie
   Song, Yingze
TI Lightweight detection network based on receptive-field feature
   enhancement convolution and three dimensions attention for images
   captured by UAVs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Images captured by UAVs; Three dimensions attention
   mechanism; Novel convolutional operation; Features shift down-sampling
   convolution
ID OBJECT DETECTION
AB UAV sampling can not only adapt to various complex terrain environments but also provide a broader vision. However, images captured by UAVs usually contain complex backgrounds and a large number of small objects. This poses a significant challenge to some existing advanced object detectors. Moreover, some existing state-ofthe-art lightweight detectors have too many parameters and computational overheads, which are not friendly to lightweight devices. Responding to the above issues, we propose a single-stage detector named features enhancement and shift lightweight network in this work. Firstly, a lightweight adjust convolution is proposed, which unfolds the features and encodes the 3 x 3 background information into information-rich 1 x 1 features by averaging the pooling and convolution layers, which efficiently enhances the representation of 1 x 1 convolutional extracted features. Next, to efficiently suppress complex background information, we propose a threedimensions attention module, which interacts information on the C-W, C-H and H-W dimensions in a unique way to obtain three efficient attention maps that highlight important information to weaken irrelevant information. Moreover, we create a novel receptive-field feature enhancement convolution, which unfolds the features and then interacts the 3 x 3 features to obtain weighted weights. The 3 x 3 convolution combining weighted features becomes parametric unshared convolution in principle, which enhances the ability to capture detailed information. Finally, in order to retain richer object and semantic information, we carefully analyze the down-sampling convolution and propose a feature shift down-sampling convolution. Then we combine it and improve Neck to get a new lightweight Neck. Furthermore, experiments on the VisDrone-DET2021 dataset show that our method obtained 36.21% on mAP50, which is 9.78% higher than the baseline model YOLOv5n. Meanwhile, compared with the advanced lightweight networks YOLOX-tiny, YOLOv6n, YOLOv7-tiny, and YOLOv8n, our network achieves superior detection results using fewer number of parameters. We also compare our network with the latest networks trained on images captured by UAVs, and experimentally demonstrate that our network achieves excellent performance using only 1.7 M parameters and 8.3 GFLOPS.
C1 [Song, Tingting; Zhang, Xin; Yang, Degang; Liu, Chen; Zhou, Jie; Song, Yingze] Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.
   [Yang, Degang] Chongqing Engn Res Ctr Educ Big Data Intelligent P, Chongqing 401331, Peoples R China.
   [Ye, Yichen] Southwest Univ, Coll Elect & Informat Engn, Chongqing 400715, Peoples R China.
C3 Chongqing Normal University; Southwest University - China
RP Yang, DG (corresponding author), Chongqing Normal Univ, Coll Comp & Informat Sci, Chongqing 401331, Peoples R China.; Yang, DG (corresponding author), Chongqing Engn Res Ctr Educ Big Data Intelligent P, Chongqing 401331, Peoples R China.
EM yangdg@cqnu.edu.cn
RI Yang, Degang/J-1150-2014
OI Yang, Degang/0000-0002-8582-4302
FU Natural Science Foundation of Chongqing [CSTB2022NSCQ-MSX1200]; Science
   and Technology Research Program of Chongqing Municipal Education
   Commission [KJQN202200537, KJZD-M202300502]; Chongqing Normal University
   [21XLB035]
FX This research was supported in part by Natural Science Foundation of
   Chongqing (CSTB2022NSCQ-MSX1200) , in part by the Science and Technology
   Research Program of Chongqing Municipal Education Commission
   (KJQN202200537 and KJZD-M202300502) , in part by Chongqing Normal
   University Ph.D. Start -up Fund (21XLB035) .
CR Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Bouguettaya A, 2022, IEEE T NEUR NET LEAR, V33, P6047, DOI 10.1109/TNNLS.2021.3080276
   Chen NY, 2023, J SUPERCOMPUT, V79, P10117, DOI 10.1007/s11227-023-05065-x
   Cui LS, 2022, IEEE T CYBERNETICS, V52, P2300, DOI 10.1109/TCYB.2020.3004636
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Glenn J., 2022, YOLOV5 RELEASE V61
   Glenn Jocher, 2023, Ultralytics YOLOv8
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Hou QB, 2021, PROC CVPR IEEE, P13708, DOI 10.1109/CVPR46437.2021.01350
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang SH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P844, DOI 10.1109/ICCV48922.2021.00090
   Li CY, 2022, Arxiv, DOI [arXiv:2209.02976, 10.48550/arXiv.2209.02976]
   Li D, 2021, PROC CVPR IEEE, P12316, DOI 10.1109/CVPR46437.2021.01214
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu HY, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155817
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Lu XC, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3052575
   Lyu R, 2021, NanoDet-Plus: Super fast and high accuracy lightweight anchor-free object detection model
   Min K, 2022, NEURAL NETWORKS, V155, P439, DOI 10.1016/j.neunet.2022.08.029
   Ozcelik Y.B., 2023, CANK INT C SCI, P1
   Özcelik YB, 2023, FRACTAL FRACT, V7, DOI 10.3390/fractalfract7080598
   Qi GQ, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14020420
   Qi GJ, 2016, PROC CVPR IEEE, P2267, DOI 10.1109/CVPR.2016.249
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saini R, 2020, IEEE WINT CONF APPL, P1616, DOI [10.1109/WACV45572.2020.9093341, 10.1109/wacv45572.2020.9093341]
   Sarwar F, 2021, COMPUT ELECTRON AGR, V187, DOI 10.1016/j.compag.2021.106219
   Sezer A, 2021, SOLDER SURF MT TECH, V33, P291, DOI 10.1108/SSMT-04-2021-0013
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun W, 2022, APPL INTELL, V52, P8448, DOI 10.1007/s10489-021-02893-3
   Tan L, 2021, COMPUT ELECTR ENG, V93, DOI 10.1016/j.compeleceng.2021.107261
   Tian GY, 2021, NEUROCOMPUTING, V443, P292, DOI 10.1016/j.neucom.2021.03.016
   Vaswani A, 2021, PROC CVPR IEEE, P12889, DOI 10.1109/CVPR46437.2021.01270
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang PJ, 2020, IEEE T GEOSCI REMOTE, V58, P3377, DOI 10.1109/TGRS.2019.2954328
   Wang X, 2023, MULTIMEDIA SYST, V29, P3329, DOI 10.1007/s00530-023-01182-y
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu H, 2022, REMOTE SENS-BASEL, V14, DOI 10.3390/rs14163853
   Yag I, 2022, BIOLOGY-BASEL, V11, DOI 10.3390/biology11121732
   Yao QL, 2021, IEEE GEOSCI REMOTE S, V18, P23, DOI 10.1109/LGRS.2020.2967819
   Ye T, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3196319
   Yinpeng Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11027, DOI 10.1109/CVPR42600.2020.01104
   Zhan W, 2022, SOFT COMPUT, V26, P361, DOI 10.1007/s00500-021-06407-8
   Zhang L, 2022, FORESTS, V13, DOI 10.3390/f13070975
   Zhang RQ, 2022, NEUROCOMPUTING, V489, P377, DOI 10.1016/j.neucom.2022.03.033
   Zhang RQ, 2021, ISPRS J PHOTOGRAMM, V180, P283, DOI 10.1016/j.isprsjprs.2021.08.002
   Zhang XD, 2019, IEEE INT CONF COMP V, P118, DOI 10.1109/ICCVW.2019.00020
   Zhang ZY, 2020, IEEE GEOSCI REMOTE S, V17, P1884, DOI 10.1109/LGRS.2019.2956513
   Zhao Y, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3139994
   Zhu PF, 2022, IEEE T PATTERN ANAL, V44, P7380, DOI 10.1109/TPAMI.2021.3119563
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 57
TC 1
Z9 1
U1 12
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104855
DI 10.1016/j.imavis.2023.104855
EA NOV 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Z5GX4
UT WOS:001112369400001
DA 2024-07-18
ER

PT J
AU Sun, R
   Shan, XQ
   Wang, F
   Fan, ZG
AF Sun, Rui
   Shan, Xiaoquan
   Wang, Fei
   Fan, Zhiguo
TI Pose aligned modality-invariant feature learning for NIR-VIS
   heterogeneous face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE NIR -VIS; Face pose misalignment; Modality-invariant feature learning;
   Heterogeneous face recognition
AB Both pose disparities and modality differences with various modalities are significant difficulties that have an impact on recognition accuracy in heterogeneous face recognition. In this paper, we propose the pose aligned modality-invariant feature learning (PAMFL) method for NIR-VIS face recognition. This method disentangles the processing of the face pose and modality into independent stages. In the first phase, we construct the face pose alignment module (PAM). The built StyleGAN2-based generator incorporates pose estimation and feature mapping structures to alter the face shape in accordance with pose yaw angle instructions, eliminating the face pose misalignment. In the second phase, we build the modality-invariant feature learning module (MFLM). Modality-specific feature representations are learned using a pseudo-Siamese network in the shallow layer of the network, while modality-invariant feature representations are learned using a parameter sharing layer embedded in the deeper layer of the network. This module preserves all modality-invariant features while minimizing cross modality variation. Finally, comparative experiments on BUAA VisNir, CASIA NIR-VIS 2.0 and Oulu CASIA NIR-VIS datasets validate that the proposed PAMFL shows advanced performance in overcoming face pose misalignment and improving heterogeneous face recognition accuracy.
C1 [Sun, Rui] Hefei Univ Technol, Sch Comp & Informat, Anhui Prov Key Lab Ind Safety & Emergency Technol, Key Lab Knowledge Engn Big Data,Minist Educ, Hefei 230009, Peoples R China.
   [Shan, Xiaoquan; Wang, Fei; Fan, Zhiguo] Hefei Univ Technol, Sch Comp & Informat, Anhui Prov Key Lab Ind Safety & Emergency Technol, Hefei 230009, Peoples R China.
C3 Hefei University of Technology; Hefei University of Technology
RP Sun, R (corresponding author), Hefei Univ Technol, Sch Comp & Informat, Anhui Prov Key Lab Ind Safety & Emergency Technol, Key Lab Knowledge Engn Big Data,Minist Educ, Hefei 230009, Peoples R China.
EM sunrui@hfut.edu.cn
FU National Natural Science Foundation of China [61876057]; Natural Science
   Foundation of Anhui Province [2208085MF158]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61876057, in part by the Natural Science
   Foundation of Anhui Province under Grant 2208085MF158.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Cao KD, 2018, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2018.00544
   Chen J, 2009, PROC CVPR IEEE, P156, DOI 10.1109/CVPRW.2009.5206832
   Cui S, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3099506
   Duan B., 2020, P IEEE CVF C COMP VI
   Fu CY, 2023, IEEE T PATTERN ANAL, V45, P9135, DOI 10.1109/TPAMI.2022.3227180
   Gong DH, 2017, IEEE T IMAGE PROCESS, V26, P2079, DOI 10.1109/TIP.2017.2651380
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He R, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107618
   He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770
   He R, 2017, AAAI CONF ARTIF INTE, P2000
   Hu WP, 2022, IEEE T CIRC SYST VID, V32, P2411, DOI 10.1109/TCSVT.2021.3081514
   Hu WP, 2021, IEEE T MULTIMEDIA, V23, P145, DOI 10.1109/TMM.2020.2980201
   Huang D., 2012, Tech. Rep. IRIP-TR-12-FR-001, V3, P3
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kan MN, 2016, IEEE T PATTERN ANAL, V38, P188, DOI 10.1109/TPAMI.2015.2435740
   Klare BF, 2013, IEEE T PATTERN ANAL, V35, P1410, DOI 10.1109/TPAMI.2012.229
   Klare BF, 2011, IEEE T PATTERN ANAL, V33, P639, DOI 10.1109/TPAMI.2010.180
   Lei Z, 2009, PROC CVPR IEEE, P1123, DOI 10.1109/CVPRW.2009.5206860
   Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Liu DC, 2020, IEEE T NEUR NET LEAR, V31, P4699, DOI 10.1109/TNNLS.2019.2957285
   Liu DC, 2018, NEUROCOMPUTING, V302, P46, DOI 10.1016/j.neucom.2018.03.042
   Liu MY, 2017, ADV NEUR IN, V30
   Liu XX, 2016, INT CONF BIOMETR
   Lu JW, 2018, IEEE T PATTERN ANAL, V40, P1979, DOI 10.1109/TPAMI.2017.2737538
   Miao Y., 2022, Advances in Neural Information Processing Systems, V35, P22752
   Park Taesung, 2020, EUR C COMP VIS, P319, DOI [DOI 10.1007/978-3-030-58545-719, DOI 10.1007/978-3-030-58545-7_19]
   Peng CL, 2021, IEEE T INF FOREN SEC, V16, P346, DOI 10.1109/TIFS.2020.3013209
   Peng CL, 2017, IEEE T PATTERN ANAL, V39, P301, DOI 10.1109/TPAMI.2016.2542816
   Reale C, 2016, IEEE COMPUT SOC CONF, P320, DOI 10.1109/CVPRW.2016.47
   Saxena S, 2016, LECT NOTES COMPUT SC, V9915, P483, DOI 10.1007/978-3-319-49409-8_40
   Shao M, 2017, IEEE T NEUR NET LEAR, V28, P451, DOI 10.1109/TNNLS.2016.2517014
   Sheikh HR, 2006, IEEE T IMAGE PROCESS, V15, P3440, DOI 10.1109/TIP.2006.881959
   Song LX, 2018, AAAI CONF ARTIF INTE, P7355
   Sun R, 2022, IET IMAGE PROCESS, V16, P261, DOI 10.1049/ipr2.12350
   Tang XO, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P687, DOI 10.1109/ICCV.2003.1238414
   Wang HJ, 2020, INT CONF ACOUST SPEE, P1903, DOI [10.1109/icassp40776.2020.9054007, 10.1109/ICASSP40776.2020.9054007]
   Wu X, 2019, AAAI CONF ARTIF INTE, P9005
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Yang YM, 2023, IEEE T IMAGE PROCESS, V32, P5231, DOI 10.1109/TIP.2023.3309110
   Yu J, 2022, NEUROCOMPUTING, V494, P1, DOI 10.1016/j.neucom.2022.04.093
   Yu JC, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1018
   Zhang XC, 2015, PROC CVPR IEEE, P4511, DOI 10.1109/CVPR.2015.7299081
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu JY, 2014, IEEE T INF FOREN SEC, V9, P501, DOI 10.1109/TIFS.2014.2299977
NR 46
TC 0
Z9 0
U1 2
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104858
DI 10.1016/j.imavis.2023.104858
EA NOV 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Y7JO4
UT WOS:001106989000001
DA 2024-07-18
ER

PT J
AU Gao, F
   Liu, Y
   Shi, PB
   Jin, Y
   Yu, J
   Li, SD
AF Gao, Fang
   Liu, Yong
   Shi, Pengbo
   Jin, Yan
   Yu, Jun
   Li, Shaodong
TI Dual-scale point cloud completion network based on high-frequency
   feature fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Point cloud; Voxel; Dual -scale; Feature fusion; Shape completion
AB For many vision tasks and intelligent robotics applications, it is common that the scanned 3D point cloud is not complete, so inferring from the residual defect shape to the intact shape becomes an essential task. Previous 3D completion neural network models generally use voxel-based or point-based methods to learn and process 3D data. For the voxel-based models, the computational cost and memory increase exponentially with the improvement of input resolution, and fine-grained features cannot be guaranteed in the completed point cloud due to limited computational resources. Point-based models suffer from the lack of precision in feature acquisition and crude reconstruction of complicated structures, making it extremely hard to accomplish elaborated semantic shapes. Combining advantages of voxel-based and point-based feature extraction through the highfrequency feature fusion module, this paper proposes a dual-scale point cloud completion network called DSNet, which performs global feature analysis at the voxel scale, and local feature analysis at the point cloud scale. The fused features are then integrated into the decoding and generation process, so as to complete the point cloud completion task from coarse to fine. Experimental results, at both quantitative and qualitative perspectives, in several prevailing datasets demonstrate that our approach surpasses state-of-the-art point cloud completion networks and has a good generalization performance. Code is available at https://github.com/ engqing/DSNet.
C1 [Gao, Fang; Liu, Yong; Shi, Pengbo; Jin, Yan; Li, Shaodong] Guangxi Univ, Sch Elect Engn, Nanning 530004, Peoples R China.
   [Yu, Jun] Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
C3 Guangxi University; Chinese Academy of Sciences; University of Science &
   Technology of China, CAS
RP Yu, J (corresponding author), Univ Sci & Technol China, Dept Automat, Hefei 230027, Peoples R China.
EM harryjun@ustc.edu.cn
FU Guangxi Science and Technology Base and Talent Project [2020AC19253];
   Natural Science Foundation of China [62276242]; National Aviation
   Science Foundation [2022Z071078001]; CAAI-Huawei Mind Spore Open Fund
   [CAAIXSJLJJ- 2021-016B, CAAIXSJLJJ-2022-001A]; Anhui Province Key
   Research and Development Program [202104a05020007]; USTC-IAT Application
   Sci. & Tech. Achievement Cultivation Program [JL06521001Y]; Sci. & Tech.
   Innovation Special Zone [20-163-14-LZ-001-004-01]
FX This work was supported by the Guangxi Science and Technology Base and
   Talent Project under Grant 2020AC19253, Natural Science Foundation of
   China (62276242) , National Aviation Science Foundation (2022Z071078001)
   , CAAI-Huawei MindSpore Open Fund (CAAIXSJLJJ- 2021-016B,
   CAAIXSJLJJ-2022-001A) , Anhui Province Key Research and Development
   Program (202104a05020007) , USTC-IAT Application Sci. & Tech.
   Achievement Cultivation Program (JL06521001Y) , Sci. & Tech. Innovation
   Special Zone (20-163-14-LZ-001-004-01) .
CR Aggarwal Ashwani Kumar, 2022, WSEAS Transactions on Signal Processing, P60, DOI 10.37394/232014.2022.18.8
   Aiello E., 2022, ADV NEURAL INF PROCE, V35, P37349
   Arora K., 2018, Handbook of Research on Advanced Concepts in Real-time Image and Video Processing, P28, DOI 10.4018/978-1-5225-2848-7.ch002
   Berger M., 2014, Eurographics 2014-State of the Art Reports, V1, P161, DOI [DOI 10.2312/EGST.20141040, 10.2312/egst.20141040]
   Chauhan S., 2023, Soft Computing, P1
   Chauhan S, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105803
   Chenhang He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11870, DOI 10.1109/CVPR42600.2020.01189
   Cui YM, 2021, NEUROCOMPUTING, V432, P300, DOI 10.1016/j.neucom.2020.12.067
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dosovitskiy A, 2021, arXiv, DOI [10.48550/ARXIV.2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Fan HQ, 2017, PROC CVPR IEEE, P2463, DOI 10.1109/CVPR.2017.264
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Han B, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104371
   Han XG, 2017, IEEE I CONF COMP VIS, P85, DOI 10.1109/ICCV.2017.19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang XY, 2018, IEEE COMPUT SOC CONF, P1067, DOI 10.1109/CVPRW.2018.00141
   Ibrahim Y, 2023, IMAGE VISION COMPUT, V134, DOI 10.1016/j.imavis.2023.104675
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kingma D. P., 2014, arXiv
   Le T, 2018, PROC CVPR IEEE, P9204, DOI 10.1109/CVPR.2018.00959
   Li N, 2024, ACM COMPUT SURV, V56, DOI 10.1145/3603704
   Li YY, 2015, COMPUT GRAPH FORUM, V34, P435, DOI 10.1111/cgf.12573
   Liang P, 2021, APPL INTELL, V51, P2063, DOI 10.1007/s10489-020-02004-8
   Liu DF, 2021, AAAI CONF ARTIF INTE, V35, P6101
   Louati H, 2022, LECT NOTES ARTIF INT, V13501, P283, DOI 10.1007/978-3-031-16014-1_23
   Mahmoudi M, 2009, GRAPH MODELS, V71, P22, DOI 10.1016/j.gmod.2008.10.002
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mildenhall B, 2022, COMMUN ACM, V65, P99, DOI 10.1145/3503250
   Pan L, 2021, PROC CVPR IEEE, P8520, DOI 10.1109/CVPR46437.2021.00842
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qu Z, 2022, IMAGE VISION COMPUT, V125, DOI 10.1016/j.imavis.2022.104518
   Rusu RB, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1, DOI 10.1109/IROS.2009.5354683
   Stutz D, 2018, PROC CVPR IEEE, P1955, DOI 10.1109/CVPR.2018.00209
   Sun JH, 2016, IMAGE VISION COMPUT, V56, P49, DOI 10.1016/j.imavis.2016.09.002
   Talha AM, 2014, IMAGE VISION COMPUT, V32, P1102, DOI 10.1016/j.imavis.2014.08.010
   Tatarchenko M, 2019, PROC CVPR IEEE, P3400, DOI 10.1109/CVPR.2019.00352
   Tchapmi LP, 2019, PROC CVPR IEEE, P383, DOI 10.1109/CVPR.2019.00047
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang NY, 2018, LECT NOTES COMPUT SC, V11215, P55, DOI 10.1007/978-3-030-01252-6_4
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wen X, 2023, IEEE T PATTERN ANAL, V45, P852, DOI 10.1109/TPAMI.2022.3159003
   Wen X, 2021, PROC CVPR IEEE, P7439, DOI 10.1109/CVPR46437.2021.00736
   Wu H, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104193
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Xian YR, 2019, FRONT COMPUT SCI-CHI, V13, P170, DOI 10.1007/s11704-016-6191-1
   Xiang P, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5479, DOI 10.1109/ICCV48922.2021.00545
   Xie Haozhe, 2020, P EUR C COMP VIS
   Xu J., 2023, P 37 AAAI C ART INT, P3018
   Yida Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P70, DOI 10.1007/978-3-030-58580-8_5
   Yu XM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12478, DOI 10.1109/ICCV48922.2021.01227
   Yuan W, 2018, INT CONF 3D VISION, P728, DOI 10.1109/3DV.2018.00088
   Zhang R., 2021, arXiv
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
   Zhu LP, 2021, NEUROCOMPUTING, V461, P1, DOI 10.1016/j.neucom.2021.07.035
   Zitian Huang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7659, DOI 10.1109/CVPR42600.2020.00768
NR 59
TC 0
Z9 0
U1 10
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104818
DI 10.1016/j.imavis.2023.104818
EA SEP 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA T8XF4
UT WOS:001080752600001
DA 2024-07-18
ER

PT J
AU Wang, HB
   Cui, TX
   Yao, MZ
   Pang, HJ
   Du, YS
AF Wang, Huibing
   Cui, Tianxiang
   Yao, Mingze
   Pang, Huijuan
   Du, Yushan
TI Domain adaptive person search via GAN-based scene synthesis for
   cross-scene videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person search; Scene synthesis; Cross-scene videos
ID REIDENTIFICATION; NETWORK
AB Person search has recently been a challenging task in the computer vision domain, which aims to search specific pedestrians from real cameras.Nevertheless, most surveillance videos comprise only a handful of images of each pedestrian, which often feature identical backgrounds and clothing. Hence, it is difficult to learn more discriminative features for person search in real scenes. To tackle this challenge, we draw on Generative Adversarial Networks (GAN) to synthesize data from surveillance videos. GAN has thrived in computer vision problems because it produces high-quality images efficiently. We merely alter the popular Fast R-CNN model, which is capable of processing videos and yielding accurate detection outcomes. In order to appropriately relieve the pressure brought by the two-stage model, we design an Assisted-Identity Query Module (AIDQ) to provide positive images for the behind part. Besides, the proposed novel GAN-based Scene Synthesis model that can synthesize high-quality cross-id person images for person search tasks. In order to facilitate the feature learning of the GAN-based Scene Synthesis model, we adopt an online learning strategy that collaboratively learns the synthesized images and original images. Extensive experiments on two widely used person search benchmarks, CUHK-SYSU and PRW, have shown that our method has achieved great performance, and the extensive ablation study further justifies our GAN-synthetic data can effectively increase the variability of the datasets and be more
C1 [Wang, Huibing; Cui, Tianxiang; Yao, Mingze; Pang, Huijuan; Du, Yushan] Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.
   [Wang, Huibing] Dalian Maritime Univ, Dalian 116026, Liaoning, Peoples R China.
C3 Dalian Maritime University; Dalian Maritime University
RP Wang, HB (corresponding author), Dalian Maritime Univ, Sch Informat Sci & Technol, Dalian 116026, Peoples R China.; Wang, HB (corresponding author), Dalian Maritime Univ, Dalian 116026, Liaoning, Peoples R China.
EM huibing.wang@dlmu.edu.cn
FU National Natural Science Foundation of China [62002041]; Liaoning
   Fundamental Research Funds for Universities [62176037]; Liaoning
   Doctoral Research Startup Fund Project [LJKQZ2021010]; Dalian Science
   and Technology Innovation Fund [2021-BS-075, 2021JJ12GX028]; 
   [2022JJ12GX019]
FX This work was supported in part by the National Natural Science
   Foundation of China Grant 62002041, Grant 62176037, the Liaoning
   Fundamental Research Funds for Universities Grant LJKQZ2021010, the &
   nbsp; Liaoning Doctoral Research Startup Fund Project Grant 2021-BS-075
   and the Dalian Science and Technology Innovation Fund 2021JJ12GX028 and
   2022JJ12GX019.
CR Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Cao JL, 2022, PROC CVPR IEEE, P9448, DOI 10.1109/CVPR52688.2022.00924
   Chang XJ, 2018, LECT NOTES COMPUT SC, V11213, P86, DOI 10.1007/978-3-030-01240-3_6
   Chen D, 2020, AAAI CONF ARTIF INTE, V34, P10518
   Chen D, 2018, LECT NOTES COMPUT SC, V11211, P764, DOI 10.1007/978-3-030-01234-2_45
   Chen D, 2020, IEEE T IMAGE PROCESS, V29, P4669, DOI 10.1109/TIP.2020.2973513
   Chen H, 2021, PROC CVPR IEEE, P2004, DOI 10.1109/CVPR46437.2021.00204
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Cheng Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11949, DOI 10.1109/CVPR42600.2020.01197
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Di Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12612, DOI 10.1109/CVPR42600.2020.01263
   Dong JF, 2022, IEEE T PATTERN ANAL, V44, P4065, DOI 10.1109/TPAMI.2021.3059295
   Dong WK, 2020, PROC CVPR IEEE, P2582, DOI 10.1109/CVPR42600.2020.00266
   Eom C., 2021, IEEE Trans. Pattern Anal. Mach. Intell.
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Girshick R, 2015, PROC CVPR IEEE, P437, DOI 10.1109/CVPR.2015.7298641
   Han CC, 2019, IEEE I CONF COMP VIS, P9813, DOI 10.1109/ICCV.2019.00991
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang X, 2018, LECT NOTES COMPUT SC, V11207, P179, DOI 10.1007/978-3-030-01219-9_11
   Jiang GQ, 2022, IEEE T CIRC SYST VID, V32, P5307, DOI 10.1109/TCSVT.2022.3143848
   Lan X, 2018, LECT NOTES COMPUT SC, V11205, P553, DOI 10.1007/978-3-030-01246-5_33
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li ZJ, 2021, AAAI CONF ARTIF INTE, V35, P2011
   Liao SC, 2015, IEEE I CONF COMP VIS, P3685, DOI 10.1109/ICCV.2015.420
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liu HP, 2022, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2022, P1270, DOI 10.1145/3503161.3548265
   Liu H, 2017, IEEE I CONF COMP VIS, P493, DOI 10.1109/ICCV.2017.61
   Lv JY, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103875
   Ma Z, 2018, INT CONF WIRE COMMUN
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Qian B, 2023, Arxiv, DOI arXiv:2303.06869
   Qian B, 2022, LECT NOTES COMPUT SC, V13671, P449, DOI 10.1007/978-3-031-20083-0_27
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shen YH, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3397
   Shi W, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104335
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Sun XX, 2019, PROC CVPR IEEE, P608, DOI 10.1109/CVPR.2019.00070
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tang YZ, 2020, IEEE T IMAGE PROCESS, V29, P5641, DOI 10.1109/TIP.2020.2985545
   Wang GA, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P933
   Wang HB, 2023, IEEE T MULTIMEDIA, V25, P6629, DOI 10.1109/TMM.2022.3212270
   Wang HB, 2021, IEEE T MULTIMEDIA, V23, P3828, DOI 10.1109/TMM.2020.3032023
   Wang HB, 2021, NEUROCOMPUTING, V438, P55, DOI 10.1016/j.neucom.2020.06.148
   Wang HB, 2020, IEEE MULTIMEDIA, V27, P112, DOI 10.1109/MMUL.2020.2999464
   Wang HB, 2020, IEEE T VEH TECHNOL, V69, P10484, DOI 10.1109/TVT.2020.3009162
   Wang WG, 2019, PROC CVPR IEEE, P3059, DOI 10.1109/CVPR.2019.00318
   Wang Y., 2016, P 25 INT JOINT C ART, P2153
   Wang Y, 2022, SCI CHINA INFORM SCI, V65, DOI 10.1007/s11432-021-3383-y
   Wang Y, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3408317
   Wang ZH, 2013, PROC CVPR IEEE, P1690, DOI 10.1109/CVPR.2013.221
   Wu L, 2017, IMAGE VISION COMPUT, V57, P58, DOI 10.1016/j.imavis.2016.11.008
   Xiao JM, 2019, PATTERN RECOGN, V87, P332, DOI 10.1016/j.patcog.2018.10.028
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xu X, 2021, PATTERN RECOGN, V113, DOI 10.1016/j.patcog.2021.107827
   Ya Jing, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10675, DOI 10.1109/CVPR42600.2020.01069
   Yan YC, 2022, AAAI CONF ARTIF INTE, P3027
   Yan YC, 2021, PROC CVPR IEEE, P7686, DOI 10.1109/CVPR46437.2021.00760
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yang X, 2021, SIGIR '21 - PROCEEDINGS OF THE 44TH INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P1, DOI 10.1145/3404835.3462823
   Yang X, 2022, IEEE T IMAGE PROCESS, V31, P1204, DOI 10.1109/TIP.2022.3140611
   Yang X, 2018, IEEE T IMAGE PROCESS, V27, P791, DOI 10.1109/TIP.2017.2765836
   Yao HT, 2021, IEEE T IMAGE PROCESS, V30, P685, DOI 10.1109/TIP.2020.3038347
   Yao R, 2020, PATTERN RECOGN, V104, DOI 10.1016/j.patcog.2020.107350
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yu R, 2022, PROC CVPR IEEE, P7257, DOI 10.1109/CVPR52688.2022.00712
   Yu Z., 2021, IEEE Trans. Multimed
   Zeng KW, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103913
   Zhang Y, 2016, PROC CVPR IEEE, P1278, DOI 10.1109/CVPR.2016.143
   Zhao Y, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107938
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zhong YJ, 2020, PROC CVPR IEEE, P6826, DOI 10.1109/CVPR42600.2020.00686
NR 74
TC 2
Z9 2
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104796
DI 10.1016/j.imavis.2023.104796
EA AUG 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA S4IU1
UT WOS:001070828300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lad, BV
   Hashmi, MF
   Keskar, AG
AF Lad, Bhagyashree, V
   Hashmi, Mohammad Farukh
   Keskar, Avinash G.
TI LDWS-net: A learnable deep wavelet scattering network for RGB salient
   object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Boundary preservation; Convolutional neural network; Feature fusion;
   Salient object detection; Scattering wavelet network
AB In the salient object detection task, convolutional neural network (CNN) based models have been extensively used. However, preserving a variety of boundary features of objects is equally important while detecting the salient objects. Detecting salient objects with poor boundaries have a significant detrimental effect on the salient object detection (SOD) models' robustness and accuracy. The proposed method leverages a unique and novel edge-directed salient object detection network, which combines wavelet scattering network features with CNNbased features. This integration enables the network to capture both textural and high-level semantic information, leading to improved SOD performance. Additionally, a learnable wavelet scattering network allows for the efficient collection and preservation of textural aspects of objects. This network is seamlessly embedded into the encoder section of the proposed architecture, enhancing the discriminative power of the model. Furthermore, a weighted feature integration module (WFIM) is proposed in the decoder section to adaptively integrate linked nearby features by evaluating their relevance, resulting in improved representation and discrimination capabilities. Extensive testing on well-known benchmark SOD datasets demonstrates that the proposed LDWS-Net outperforms state-of-the-art techniques, exhibiting accurate identification of salient objects and efficient detection of their edges.
C1 [Lad, Bhagyashree, V; Keskar, Avinash G.] Visvesvaraya Natl Inst Technol, Dept Elect & Commun Engn, Nagpur 440010, India.
   [Hashmi, Mohammad Farukh] Natl Inst Technol Warangal, Dept Elect & Commun Engn, Hanamkonda 506004, Telangana, India.
C3 National Institute of Technology (NIT System); Visvesvaraya National
   Institute of Technology, Nagpur; National Institute of Technology (NIT
   System); National Institute of Technology Warangal
RP Hashmi, MF (corresponding author), Natl Inst Technol Warangal, Dept Elect & Commun Engn, Hanamkonda 506004, Telangana, India.
EM bhagyashreevl@students.vnit.ac.in; mdfarukh@nitw.ac.in;
   agkeskar@ece.vnit.ac.in
OI Keskar, Avinash/0000-0002-9660-1139; Lad,
   Bhagyashree/0000-0002-4529-4837
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Andreux M, 2020, J MACH LEARN RES, V21
   Birajadar Parmeshwar, 2023, ICT with Intelligent Applications: Proceedings of ICTIS 2022. Smart Innovation, Systems and Technologies (311), P705, DOI 10.1007/978-981-19-3571-8_64
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Davis JJ., 2006, PROC INT C MACHINE L, DOI DOI 10.1145/1143844.1143874
   Fan DP, 2018, Arxiv, DOI arXiv:1805.10421
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Gao J, 2023, IEEE T NEUR NET LEAR, V34, P3665, DOI 10.1109/TNNLS.2021.3118221
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang WH, 2022, DISPLAYS, V73, DOI 10.1016/j.displa.2022.102238
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Liao YW, 2023, DISPLAYS, V76, DOI 10.1016/j.displa.2022.102362
   Liu N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4702, DOI 10.1109/ICCV48922.2021.00468
   Liu RH, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11162616
   Mohammadi S, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107303
   Oyallon E, 2015, PROC CVPR IEEE, P2865, DOI 10.1109/CVPR.2015.7298904
   Qin XB, 2021, Arxiv, DOI arXiv:2101.04704
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wu YH, 2022, IEEE T IMAGE PROCESS, V31, P3125, DOI 10.1109/TIP.2022.3164550
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Yan XY, 2022, PATTERN RECOGN, V131, DOI 10.1016/j.patcog.2022.108904
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang PC, 2022, DISPLAYS, V72, DOI 10.1016/j.displa.2022.102160
   Zhang Q, 2021, IEEE T CIRC SYST VID, V31, P1804, DOI 10.1109/TCSVT.2020.3014663
   Zhao JX, 2019, IEEE I CONF COMP VIS, P8778, DOI 10.1109/ICCV.2019.00887
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhou XF, 2023, IEEE T CYBERNETICS, V53, P539, DOI 10.1109/TCYB.2022.3163152
   Zhuge MC, 2023, IEEE T PATTERN ANAL, V45, P3738, DOI 10.1109/TPAMI.2022.3179526
NR 37
TC 1
Z9 1
U1 10
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104748
DI 10.1016/j.imavis.2023.104748
EA JUL 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA O5GU1
UT WOS:001044101000001
DA 2024-07-18
ER

PT J
AU Wang, YX
   Yan, LP
   Feng, ZH
   Xia, YQ
   Xiao, B
AF Wang, Yuxuan
   Yan, Liping
   Feng, Zihang
   Xia, Yuanqing
   Xiao, Bo
TI Visual tracking using transformer with a combination of convolution and
   attention
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Attention; Transformer; Siamese networks
AB For Siamese-based trackers in the field of single object tracking, cross-correlation operation plays an important role. However, the cross-correlation essentially uses target feature to locally linearly match the search region, which leads to insufficient utilization or even loss of feature information. To effectively employ global context and sufficiently explore the relevance of template and search region, a novel matching operator is designed inspired by Transformer, which uses multi-head attention and embed a designed modulation module across the inputs of operator. Meanwhile, we equip our tracker with a multi-scale encoder/decoder strategy to gradually make more precise tracking. Finally, a complete tracking framework is presented named VTTR. The tracker consists of a feature extractor, a multi-scale encoder based on depth-wise convolution, a modified decoder as the matching operator and a prediction head. The proposed tracker is tested on many benchmarks and achieve excellent performance while running with fast speed.
C1 [Wang, Yuxuan; Yan, Liping; Feng, Zihang; Xia, Yuanqing] Beijing Inst Technol, Sch Automat, Key Lab Intelligent Control Decis Complex Syst, Beijing 100081, Peoples R China.
   [Xiao, Bo] Beijing Univ Posts & Telecommun, Sch Artificial Intelligence, Beijing 100876, Peoples R China.
C3 Beijing Institute of Technology; Beijing University of Posts &
   Telecommunications
RP Yan, LP (corresponding author), Beijing Inst Technol, Sch Automat, Key Lab Intelligent Control Decis Complex Syst, Beijing 100081, Peoples R China.
EM ylp@bit.edu.cn
OI xia, yuqin/0009-0007-4022-9175
FU National Key Research and Devel-opment Program of China
   [2018AAA0103203]; Na-tional Natural Science Foundation of China
   [62073036, 62076031]
FX This work was supported by the National Key Research and Devel-opment
   Program of China under Grant 2018AAA0103203, and the Na-tional Natural
   Science Foundation of China under Grant 62073036 and 62076031.
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P205, DOI 10.1007/978-3-030-58592-1_13
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bhat G, 2018, LECT NOTES COMPUT SC, V11206, P493, DOI 10.1007/978-3-030-01216-8_30
   Bingyan Liao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P429, DOI 10.1007/978-3-030-58542-6_26
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Cao ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P15437, DOI 10.1109/ICCV48922.2021.01517
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen X, 2021, PROC CVPR IEEE, P8122, DOI 10.1109/CVPR46437.2021.00803
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Cheng SY, 2021, PROC CVPR IEEE, P4419, DOI 10.1109/CVPR46437.2021.00440
   Choi J, 2019, IEEE I CONF COMP VIS, P911, DOI 10.1109/ICCV.2019.00100
   Danelljan M, 2020, PROC CVPR IEEE, P7181, DOI 10.1109/CVPR42600.2020.00721
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Du F, 2020, PROC CVPR IEEE, P6835, DOI 10.1109/CVPR42600.2020.00687
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fu ZH, 2021, PROC CVPR IEEE, P13769, DOI 10.1109/CVPR46437.2021.01356
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2017.128
   Guo DY, 2020, PROC CVPR IEEE, P6268, DOI 10.1109/CVPR42600.2020.00630
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Junliang Xing, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1698, DOI 10.1109/ICPR.2010.420
   Lee KH, 2015, IEEE T MULTIMEDIA, V17, P1429, DOI 10.1109/TMM.2015.2455418
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li SY, 2017, AAAI CONF ARTIF INTE, P4140
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Linyu Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P759, DOI 10.1007/978-3-030-58555-6_45
   Liu LW, 2012, INT C PATT RECOG, P565
   Loshchilov I., 2019, DECOUPLED WEIGHT DEC
   Ma F, 2022, PROC CVPR IEEE, P8771, DOI 10.1109/CVPR52688.2022.00858
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Peng Z., 2021, PROC 13 INT JOINT C, P952
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Sun XL, 2021, Arxiv, DOI arXiv:2104.15049
   Tao AD, 2020, Arxiv, DOI [arXiv:2005.10821, DOI 10.48550/ARXIV.2005.10821]
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P, 2020, PROC CVPR IEEE, P6577, DOI 10.1109/CVPR42600.2020.00661
   Wang N, 2021, PROC CVPR IEEE, P1571, DOI 10.1109/CVPR46437.2021.00162
   Xu YD, 2020, AAAI CONF ARTIF INTE, V34, P12549
   Yang Y, 2021, FRONT INFORM TECH EL, V22, P1551, DOI 10.1631/FITEE.2100463
   Yu YC, 2020, PROC CVPR IEEE, P6727, DOI 10.1109/CVPR42600.2020.00676
   Zhang ZP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13319, DOI 10.1109/ICCV48922.2021.01309
   Zhipeng Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P771, DOI 10.1007/978-3-030-58589-1_46
   Zhou XY, 2022, PROC CVPR IEEE, P8761, DOI 10.1109/CVPR52688.2022.00857
   Zhu LC, 2022, IEEE T MULTIMEDIA, V24, P668, DOI 10.1109/TMM.2021.3057503
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 57
TC 0
Z9 0
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104760
DI 10.1016/j.imavis.2023.104760
EA JUL 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA O3SZ5
UT WOS:001043061900001
DA 2024-07-18
ER

PT J
AU Chen, SL
   Zhang, H
   Sun, BL
   Li, HJ
   Ye, XC
   Wang, ZH
AF Chen, Shenglun
   Zhang, Hong
   Sun, Baoli
   Li, Haojie
   Ye, Xinchen
   Wang, Zhihui
TI Feature enhancement network for stereo matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo matching; Deep learning; Pyramid feature representation; Cross
   -modal fusion; Disparity weight loss
AB In general stereo matching methods, there are mainly two kinds of weaknesses: the interior of large objects with unclear texture; object boundaries and small objects. One of the reasons for the first case is the underuse of inter -feature and intra-feature contexts, leading to the lack of discriminability of feature representations. And the sec-ond case could be caused result from the loss of fine-grained structural information in the features. In this work, we present a novel stereo matching network to enhance the feature representations, which contains two prom-inent components: pyramid context enhancement module and cross-modal enhancement module. Pyramid con-text enhancement module first constructs multi-scale pyramid features to promote global representation, and then exploits the inter-feature and intra-feature contextual information to improve the discriminability of fea-tures. Cross-modal enhancement module proactively degrades features of RGB image and disparity map to im-plicitly extract structures, and fuses both structures to recover the modal consistent structural information of features. Moreover, we design a disparity weight loss function which can calculates the adaptive weight accord-ing to prediction error to balance the loss response. Extensive experiments demonstrate that our method boosts the performance, and achieves better results on five challenging datasets than other typical methods. Code is available at: https://github.com/csl1994/FENet. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Chen, Shenglun; Zhang, Hong; Sun, Baoli] Dalian Univ Technol, Sch Software Technol, Dalian 116000, Peoples R China.
   [Li, Haojie; Ye, Xinchen; Wang, Zhihui] Dalian Univ Technol, RU Int Sch Informat Sci Engn, DUT, Dalian 116000, Peoples R China.
C3 Dalian University of Technology; Dalian University of Technology
RP Wang, ZH (corresponding author), Dalian Univ Technol, RU Int Sch Informat Sci Engn, DUT, Dalian 116000, Peoples R China.
EM zhwang@dlut.edu.cn
RI wang, zhihui/HSF-6639-2023
FU National Natural Science Foundation of China (NSFC) [61976038, 61932020,
   U1908210]
FX Acknowledgments This work was supported by National Natural Science
   Foundation of China (NSFC) under Grants NO. 61976038, NO. 61932020 and
   NO. U1908210.
CR Badki A, 2020, PROC CVPR IEEE, P1597, DOI 10.1109/CVPR42600.2020.00167
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen SH, 2020, IEEE T IMAGE PROCESS, V29, P3763, DOI 10.1109/TIP.2020.2965989
   Chen W, 2022, IEEE ROBOT AUTOM LET, V7, P581, DOI 10.1109/LRA.2021.3130984
   Cheng Xuelian, 2020, Advances in Neural Information Processing Systems, V33
   Feihu Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P420, DOI 10.1007/978-3-030-58536-5_25
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   Hu J., 2018, PROC IEEECVF C COMPU, P7132, DOI DOI 10.1109/CVPR.2018.00745
   Li ZS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6177, DOI 10.1109/ICCV48922.2021.00614
   Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297
   Lipson L, 2021, INT CONF 3D VISION, P218, DOI 10.1109/3DV53792.2021.00032
   Liu H, 2022, CVPR, P5791
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Rao ZB, 2020, APSIPA TRANS SIGNAL, V9, DOI 10.1017/ATSIP.2020.16
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Schöps T, 2017, PROC CVPR IEEE, P2538, DOI 10.1109/CVPR.2017.272
   Shen ZL, 2021, PROC CVPR IEEE, P13901, DOI 10.1109/CVPR46437.2021.01369
   Shimizu M., 2002, Systems and Computers in Japan, V33, P1, DOI 10.1002/scj.10098
   Song X, 2020, INT J COMPUT VISION, V128, P910, DOI 10.1007/s11263-019-01287-w
   Song X, 2021, PROC CVPR IEEE, P10323, DOI 10.1109/CVPR46437.2021.01019
   Tankovich V, 2021, PROC CVPR IEEE, P14357, DOI 10.1109/CVPR46437.2021.01413
   Wang HL, 2021, IEEE ROBOT AUTOM LET, V6, P4353, DOI 10.1109/LRA.2021.3068108
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wu ZY, 2019, IEEE I CONF COMP VIS, P7483, DOI 10.1109/ICCV.2019.00758
   Xue TF, 2019, IMAGE VISION COMPUT, V91, DOI 10.1016/j.imavis.2019.05.006
   Xue YB, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104510
   Yang G., PROC IEEE C COMPUT V, P5515
   Yang GR, 2019, PROC CVPR IEEE, P899, DOI 10.1109/CVPR.2019.00099
   Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39
   Yang WD, 2020, FRONT ARTIF INTEL AP, V325, P2784, DOI 10.3233/FAIA200419
   Yang XW, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104336
   Yao CT, 2021, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR46437.2021.00603
   Ye XC, 2020, IEEE T IMAGE PROCESS, V29, P7427, DOI 10.1109/TIP.2020.3002664
   Zhang CH, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104424
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
   Zhang YR, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104088
   Zhang YM, 2020, AAAI CONF ARTIF INTE, V34, P12926
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 42
TC 2
Z9 2
U1 2
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2023
VL 130
AR 104614
DI 10.1016/j.imavis.2022.104614
EA JAN 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 8J3LX
UT WOS:000922322400001
DA 2024-07-18
ER

PT J
AU Abbaspour, M
   Masnadi-Shirazi, MA
AF Abbaspour, Mohammadjavad
   Masnadi-Shirazi, Mohammad Ali
TI Online multi-object tracking with 5-GLMB filter based on occlusion and
   identity switch handling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-object tracking; Generalized Labeled Multi-Bernoulli filter;
   Occlusion handler; ID switch handler
ID PARTICLE PHD FILTER; RANDOM FINITE SETS; MULTIPLE; TARGET
AB In this paper, we propose an online multi-object tracking (MOT) method based on the delta Generalized Labeled Multi-Bernoulli (5-GLMB) filter framework to address occlusion and miss-detection issues and recover identity switch (ID switch). Along with the principal 5-GLMB filter that performs multi-object tracking, we propose a one-step 5-GLMB filter to handle occlusion and miss-detection. The one-step 5-GLMB filter is non-iterative and only requires current measurements. The filter is based on a proposed measurement-to-reappeared track association method and addresses MOT issues by incorporating all occluded and miss-detected objects. We introduce a novel similarity metric to apply in the measurement-to-reappeared track association process to define the weight of hypothesized reappeared tracks. To ensure the track consistency, we also extend the principal 5GLMB filter to efficiently recover switched IDs using the cardinality density, size, and visual features of the hypothesized tracks. In addition, we perform an ablation study to demonstrate the contribution of the main parts of the proposed method. We evaluate the proposed method on well-known and publicly available test datasets focused on pedestrian tracking. Note that our proposed method is online and not based on the learning paradigm. So it does not use any additional source of information such as private detections and pre-trained networks. Despite that, we achieved a reliable performance in multiple persons tracking at complex scenes by applying occlusion/miss-detection and ID switch handlers. Experimental results show that the proposed tracker performs better or at least at the same level of the state-of-the-art online and offline MOT methods. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Abbaspour, Mohammadjavad; Masnadi-Shirazi, Mohammad Ali] Shiraz Univ, Sch Elect & Comp Engn, Shiraz, Iran.
C3 Shiraz University
RP Abbaspour, M (corresponding author), Shiraz Univ, Sch Elect & Comp Engn, Shiraz, Iran.
EM mj.abbaspour@shirazu.ac.ir; masnadi@shirazu.ac.ir
RI Abbaspour, Mohammadjavad/HPF-4454-2023
CR Abbaspour MJ, 2014, 2014 7TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P326, DOI 10.1109/ISTEL.2014.7000723
   Vo BN, 2017, IEEE T SIGNAL PROCES, V65, P1975, DOI 10.1109/TSP.2016.2641392
   Vo BN, 2014, IEEE T SIGNAL PROCES, V62, P6554, DOI 10.1109/TSP.2014.2364014
   Vo BT, 2013, IEEE T SIGNAL PROCES, V61, P3460, DOI 10.1109/TSP.2013.2259822
   Bae SH, 2018, IEEE T PATTERN ANAL, V40, P595, DOI 10.1109/TPAMI.2017.2691769
   Baisa NL, 2021, J VIS COMMUN IMAGE R, V80, DOI 10.1016/j.jvcir.2021.103279
   Baisa NL, 2019, J VIS COMMUN IMAGE R, V59, P257, DOI 10.1016/j.jvcir.2019.01.026
   Bergmann P, 2019, IEEE I CONF COMP VIS, P941, DOI 10.1109/ICCV.2019.00103
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Blackman SS, 2004, IEEE AERO EL SYS MAG, V19, P5, DOI 10.1109/MAES.2004.1263228
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Chen L, 2019, IEEE SIGNAL PROC LET, V26, P1613, DOI 10.1109/LSP.2019.2940922
   Chen L, 2018, IEEE INT CON MULTI, DOI 10.1097/PEC.0000000000001553
   Chu P, 2019, IEEE I CONF COMP VIS, P6171, DOI 10.1109/ICCV.2019.00627
   Dames PM, 2020, AUTON ROBOT, V44, P673, DOI 10.1007/s10514-019-09840-9
   Davey S.J., 2012, TRACK DETECT TECHNIQ, P311
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Feng PM, 2017, IEEE T MULTIMEDIA, V19, P725, DOI 10.1109/TMM.2016.2638206
   Fu ZY, 2019, IEEE T MULTIMEDIA, V21, P2277, DOI 10.1109/TMM.2019.2902480
   Fu ZY, 2018, IEEE ACCESS, V6, P14764, DOI 10.1109/ACCESS.2018.2816805
   Fu ZY, 2017, 2017 SENSOR SIGNAL PROCESSING FOR DEFENCE CONFERENCE (SSPD), P213
   Granström K, 2012, IEEE T AERO ELEC SYS, V48, P3268, DOI 10.1109/TAES.2012.6324703
   Gu XW, 2017, EVOL SYST-GER, V8, P167, DOI 10.1007/s12530-017-9195-7
   Henschel Roberto, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Proceedings, P770, DOI 10.1109/CVPRW.2019.00105
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Keuper M, 2020, IEEE T PATTERN ANAL, V42, P140, DOI 10.1109/TPAMI.2018.2876253
   Kim DY, 2019, PATTERN RECOGN, V90, P377, DOI 10.1016/j.patcog.2019.02.004
   Kim DY, 2017, INT CONF CONTR AUTO, P181, DOI 10.1109/ICCAIS.2017.8217572
   Lee SH, 2018, IEEE ACCESS, V6, P67316, DOI 10.1109/ACCESS.2018.2879535
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Mahler R., 1994, P 7 NAT S SENS FUS, V1, P187
   Mahler R, 2006, PROC SPIE, V6235, DOI 10.1117/12.667083
   Mahler RPS, 2003, IEEE T AERO ELEC SYS, V39, P1152, DOI 10.1109/TAES.2003.1261119
   MAHLER RPS, 1994, P SOC PHOTO-OPT INS, V2234, P287, DOI 10.1117/12.181026
   Ong J., IEEE T PATTERN ANAL
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Papi F, 2015, IEEE T SIGNAL PROCES, V63, P5487, DOI 10.1109/TSP.2015.2454478
   Peng JL, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107480
   Rathnayake T, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030929
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sheng H, 2019, IEEE T CIRC SYST VID, V29, P3660, DOI 10.1109/TCSVT.2018.2881123
   Sheng H, 2019, IEEE T CIRC SYST VID, V29, P3269, DOI 10.1109/TCSVT.2018.2882192
   Song YM, 2019, IEEE ACCESS, V7, P165103, DOI 10.1109/ACCESS.2019.2953276
   Stadler D, 2021, PROC CVPR IEEE, P10953, DOI 10.1109/CVPR46437.2021.01081
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu HF, 2019, PATTERN RECOGN, V94, P25, DOI 10.1016/j.patcog.2019.04.018
   Xiang J., IEEE T CIRC SYST VID
   Xiang Y, 2015, IEEE I CONF COMP VIS, P4705, DOI 10.1109/ICCV.2015.534
   Xu YH, 2020, PROC CVPR IEEE, P6786, DOI 10.1109/CVPR42600.2020.00682
   Yang F, 2016, PROC CVPR IEEE, P2129, DOI 10.1109/CVPR.2016.234
   Yang M, 2017, IEEE T IMAGE PROCESS, V26, P5667, DOI 10.1109/TIP.2017.2745103
   Yang M, 2016, COMPUT VIS IMAGE UND, V153, P16, DOI 10.1016/j.cviu.2016.05.003
   Yin JB, 2020, PROC CVPR IEEE, P6767, DOI 10.1109/CVPR42600.2020.00680
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
   Yoon K, 2020, IEEE ACCESS, V8, P38060, DOI 10.1109/ACCESS.2020.2975912
   Yoon YC, 2021, INFORM SCIENCES, V561, P326, DOI 10.1016/j.ins.2020.10.002
   Yoon YC, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P91
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhang XQ, 2021, VISUAL COMPUT, V37, P1089, DOI 10.1007/s00371-020-01854-0
   Zhang Y, 2020, IEEE T IMAGE PROCESS, V29, P6694, DOI 10.1109/TIP.2020.2993073
   Zhou H, 2019, IEEE T CIRC SYST VID, V29, P1011, DOI 10.1109/TCSVT.2018.2825679
NR 64
TC 4
Z9 4
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104553
DI 10.1016/j.imavis.2022.104553
EA OCT 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300004
DA 2024-07-18
ER

PT J
AU Dunnhofer, M
   Simonato, K
   Micheloni, C
AF Dunnhofer, Matteo
   Simonato, Kristian
   Micheloni, Christian
TI Combining complementary trackers for enhanced long-term visual object
   tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video tracking; Visual object tracking; Long-term visual tracking; Deep
   learning
AB Several different algorithms have been studied to combine the capabilities of baseline trackers in the context of short-term visual object tracking. Despite such an extended interest, the long-term setting has not been taken into consideration by previous studies. In this paper, we explicitly consider long-term tracking scenarios and provide a framework to fuse the characteristics of complementary state-of-the-art trackers to achieve enhanced tracking performance. Our strategy perceives whether the two trackers are following the target object through an online learned deep verification model. Such a target recognition strategy enables the activation of a decision strategy which selects the best performing tracker as well as it corrects their performance when failing. The proposed solution is studied extensively and the comparison with several other approaches reveals that it beats the state-of-the-art on the long-term visual tracking benchmarks LTB-35, LTB-5 0, TLP, and LaSOT. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Dunnhofer, Matteo; Simonato, Kristian; Micheloni, Christian] Univ Udine, Machine Learning & Percept Lab, Via Sci 206, I-33100 Udine, Italy.
C3 University of Udine
RP Dunnhofer, M (corresponding author), Univ Udine, Machine Learning & Percept Lab, Via Sci 206, I-33100 Udine, Italy.
EM matteo.dunnhofer@uniud.it
RI Micheloni, Christian/E-5427-2012
OI Dunnhofer, Matteo/0000-0002-1672-667X
FU  [ACHIEVE-ITN H2020]
FX Research supported by the ACHIEVE-ITN H2020 project.
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   [Anonymous], 2014, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-10599-4_13
   Bailer C, 2014, LECT NOTES COMPUT SC, V8695, P170, DOI 10.1007/978-3-319-10584-0_12
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bian TL, 2021, INT C PATT RECOG, P9585, DOI 10.1109/ICPR48806.2021.9412156
   Bolme D.S., IEEE C COMPUTER VISI, P2544
   Chen X., P IEEECVF C COMPUTER, P8126
   Choi S., 2020, ROBUST LONG TERM OBJ, Vabs/2008.04722
   Dai KN, 2020, PROC CVPR IEEE, P6297, DOI 10.1109/CVPR42600.2020.00633
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Dunnhofer M., 2020, ASIAN C COMPUTER VIS
   Dunnhofer M, 2021, IEEE ROBOT AUTOM LET, V6, P5016, DOI 10.1109/LRA.2021.3070816
   Dunnhofer M, 2019, IEEE INT CONF COMP V, P2290, DOI 10.1109/ICCVW.2019.00282
   Dunnhofer M, 2020, MED IMAGE ANAL, V60, DOI 10.1016/j.media.2019.101631
   Fan H, 2019, IEEE T IMAGE PROCESS, V28, P4130, DOI 10.1109/TIP.2019.2904789
   Fan Heng, 2019, IEEE C COMPUTER VISI, P1
   Fu HC, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103929
   Fu HC, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2020.103869
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Guo D., P IEEECVF C COMPUTER, P9543
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Huang L., 2020, AAAI C ARTIFICIAL IN, DOI [10.1609/aaai.v34i07.6758, DOI 10.1609/AAAI.V34I07.6758]
   Jung I, 2018, LECT NOTES COMPUT SC, V11208, P89, DOI 10.1007/978-3-030-01225-0_6
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kristan M., 2020, COMPUTER VISION ECCV, P547
   Kristan M., 2019, P IEEECVF INT C COMP
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Lukezic A, 2021, IEEE T CYBERNETICS, V51, P6305, DOI 10.1109/TCYB.2020.2980618
   Lukezic A, 2019, LECT NOTES COMPUT SC, V11362, P595, DOI 10.1007/978-3-030-20890-5_38
   Mayer C., 2021, P IEEECVFINTERNATION
   Moudgil A, 2019, LECT NOTES COMPUT SC, V11362, P629, DOI 10.1007/978-3-030-20890-5_40
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nousi P, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103933
   Raju PM, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104215
   Song Ke, 2020, P ADV NEUR INF PROC, V33, P11778
   Vaswani A, 2017, ADV NEUR IN, V30
   Voigtlaender P., 2020, IEEECVF C COMPUTER V
   Vojir T, 2016, COMPUT VIS IMAGE UND, V153, P109, DOI 10.1016/j.cviu.2016.05.007
   Wang N., P IEEECVF C COMPUTER, P1571
   Wang NY, 2014, PR MACH LEARN RES, V32, P1107
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xuan SY, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107698
   Yan B., 2021, P IEEECVF INT C COMP
   Yan B, 2019, IEEE I CONF COMP VIS, P2385, DOI 10.1109/ICCV.2019.00247
   Yi Z., 2021 IEEE INT C MULT, P1, DOI [10.1109/ICME51207.2021.9428424, DOI 10.1109/ICME51207.2021.9428424]
   Yoon J.H., EUROPEAN C COMPUTER, P28, DOI [10.1007/978-3-642-33765-9_3, DOI 10.1007/978-3-642-33765-9_3]
   Yu L, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104181
   Zhang Z., P IEEECVF C COMPUTER, P1024
NR 51
TC 11
Z9 11
U1 1
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104448
DI 10.1016/j.imavis.2022.104448
EA APR 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1F1NU
UT WOS:000794942300002
DA 2024-07-18
ER

PT J
AU Arantes, RB
   Vogiatzis, G
   Faria, DR
AF Arantes, Renato B.
   Vogiatzis, George
   Faria, Diego R.
TI Learning an augmentation strategy for sparse datasets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE GAN; Data augmentation; Semantic segmentation
AB The limited quantity of training data can hamper supervised machine learning methods, that generally need large amounts of data to avoid overfitting. Data augmentation has a long history of use with machine learning algorithms and is a straightforward method to overcome overfitting and improve model generalisation. However, data augmentation schemes are typically designed by hand and demand substantial domain knowledge to create suitable data transformations. This paper introduces a GAN based method that automatically learns an augmentation strategy appropriate for sparse datasets and can improve pixel-level semantic segmentation accuracy by filling the gaps in the training set. Our method can also be combined with other augmentation techniques to further improve performance. We evaluate the proposed method's feasibility on four datasets and three semantic segmentation models, leading to improvement in the mean intersection-over-union (mIoU) score of between 0.5 and 14 percentage points, under different circumstances. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Arantes, Renato B.; Vogiatzis, George; Faria, Diego R.] Aston Univ, Aston St, Birmingham B4 7ET, W Midlands, England.
C3 Aston University
RP Arantes, RB (corresponding author), Aston Univ, Aston St, Birmingham B4 7ET, W Midlands, England.
EM barr1801@aston.ac.uk; g.vogiatzis@aston.ac.uk; d.faria@aston.ac.uk
RI Faria, Diego R/B-4056-2011
OI Vogiatzis, George/0000-0002-3226-0603
FU Aston University
FX This work was financially supported by Aston University.
CR [Anonymous], 2017, arXiv preprint arXiv:1703.03108
   Arantes Renato B., 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P170, DOI 10.1007/978-3-030-64556-4_14
   Arantes Renato B., 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P80, DOI 10.1007/978-3-030-64556-4_7
   Arantes RB, 2019, LECT NOTES COMPUT SC, V11754, P423, DOI 10.1007/978-3-030-34995-0_38
   Armanious K, 2020, COMPUT MED IMAG GRAP, V79, DOI 10.1016/j.compmedimag.2019.101684
   Bahdanau D., 2014, 3 INT C LEARN REPR
   Bargsten L, 2020, INT J COMPUT ASS RAD, V15, P1427, DOI 10.1007/s11548-020-02203-1
   Bowles C., 2018, ARXIV PREPRINT ARXIV
   Brock A., 2018, PREPRINT
   Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Cheng J., 2016, LONG SHORT TERM MEMO, DOI DOI 10.18653/V1/D16-1053
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Ciresan Dan C., 2011, CORR
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Donahue J, 2019, Advances in Neural Information Processing Systems
   Fang HS, 2019, IEEE I CONF COMP VIS, P682, DOI 10.1109/ICCV.2019.00077
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han D, 2017, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR.2017.668
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hensel M, 2017, ADV NEUR IN, V30
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Huang Z., 2020, IEEE T PATT MACH INT, DOI [10.1109/TPAMI.2020.30070321-1, DOI 10.1109/TPAMI.2020.30070321-1]
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jackson P.T., CVPR WORKSH 2019, P83
   Jin HS, 2018, MED PHYS, V45, P2097, DOI 10.1002/mp.12846
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2020, BIOCHAR APPLICATIONS IN AGRICULTURE AND ENVIRONMENT MANAGEMENT, P167, DOI 10.1007/978-3-030-40997-5_8
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lemley J, 2017, IEEE ACCESS, V5, P5858, DOI 10.1109/ACCESS.2017.2696121
   Li Y, 2017, PROC CVPR IEEE, P4438, DOI 10.1109/CVPR.2017.472
   Lim S., 2019, Advances in Neural Information Processing Systems, V32
   Lin C., P IEEE INT C COMP VI, P6579
   Lin Chieh Hubert, 2019, P IEEE CVF INT C COM
   Lin M., 2013, ARXIV13124400
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lu C, P IEEE INT C COMP VI, P5168
   Luo Y, 2017, IEEE INT SYMP ELEC
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   Park T, 2019, PROC CVPR IEEE, P2332, DOI 10.1109/CVPR.2019.00244
   Paschali M., 2019, ARXIV PREPRINT ARXIV
   Pei K., 2017, ARXIV171201785
   Pei KX, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P1, DOI 10.1145/3132747.3132785
   Prince J. L., 2020, HDB MEDICAL IMAGE CO, P1, DOI DOI 10.1016/B978-0-12-816176-0.00006-5
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandfort V, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-52737-x
   Shanmugam D., 2020, ARXIV PREPRINT ARXIV
   Shelhamer E, 2017, IEEE T PATTERN ANAL, V39, P640, DOI 10.1109/TPAMI.2016.2572683
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simard PY, 2003, PROC INT CONF DOC, P958
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sixt L, 2018, FRONT ROBOT AI, V5, DOI 10.3389/frobt.2018.00066
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh N, 2020, MED IMAGE ANAL, V63, DOI 10.1016/j.media.2020.101693
   Tran T., 2017, NEURIPS 2017, P2797
   Tylecek R. S. Radim, 2013, P GCPR SAARBRUCHEN G
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wan L, 2013, P 30 INT C MACH LEAR, P1058, DOI DOI 10.5555/3042817.3043055
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Xinyue Zhu, 2018, Advances in Knowledge Discovery and Data Mining. 22nd Pacific-Asia Conference, PAKDD 2018. Proceedings: LNAI 10939, P349, DOI 10.1007/978-3-319-93040-4_28
   Yi X, 2019, MED IMAGE ANAL, V58, DOI 10.1016/j.media.2019.101552
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 83
TC 5
Z9 5
U1 8
U2 37
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104338
DI 10.1016/j.imavis.2021.104338
EA NOV 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA XF7PZ
UT WOS:000724261200001
DA 2024-07-18
ER

PT J
AU Wu, H
   An, D
   Zhu, XY
   Zhang, ZY
   Fan, GD
   Hua, Z
AF Wu, Hao
   An, Ding
   Zhu, Xiaoyu
   Zhang, Zhiyi
   Fan, Guodong
   Hua, Zhen
TI Multi-source material image optimized selection based multi-option
   composition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image composition; Material image; Sparse coding; Circular SA-GAN;
   Multi-scale composition
AB Image composition aims to composite a material region into a target image. Using this technique, more images could be interactive, as there are millions of images created daily in modern life. However, it is difficult for the majority of traditional composition methods to retrieve relatively realistic semantically valid material images. Also, even if the minority of traditional composition methods yield superior results, it remains difficult to retrieve adequate material images due to the limitation of existing semantically valid images. Artificial traces also significantly reduce the visual esthetic of composited results. Based on these problems, we propose a multi-source material image optimized selection based multi-option composition method. Firstly, a robust sparse coding based retrieval model is used to retrieve material images effectively. On this basis, the attention mechanism based circular SA-GAN model could generate many semantically valid material images that guarantee the adequacy of material images. Secondly, the pixel-level optimization based multi-scale composition model minimizes artificial traces and reduces computational burden. Finally, an experimental database using many images was built. Based on this model, adequate comparative experiments using multiple evaluation criteria fully show the proposed method's effectiveness and robustness. ? 2021 Elsevier B.V. All rights reserved.
C1 [Wu, Hao; An, Ding; Zhu, Xiaoyu; Zhang, Zhiyi] Beijing Normal Univ, Sch Artificial Intelligence, Beijing, Peoples R China.
   [Fan, Guodong; Hua, Zhen] Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai, Peoples R China.
C3 Beijing Normal University; Shandong Technology & Business University
RP Hua, Z (corresponding author), Shandong Technol & Business Univ, Sch Informat & Elect Engn, Yantai, Peoples R China.
EM huazhen@sdtbu.edu.cn
RI Hua, Zhen/AGN-6068-2022; Hua, Zhen/ABG-8734-2021; ZHU,
   XIAOYU/HJY-7240-2023; Zhang, xiaoyu/HTM-3222-2023; xiaoyu,
   zhang/JXY-7226-2024
OI Fan, Guodong/0000-0003-0382-6142
FU National Natural Science Foundation of China [62072043, 61977006,
   61772319]
FX This research is sponsored by National Natural Science Foundation of
   China (No.62072043, No.61977006, No. 61772319) .
CR Agarwala A, 2004, ACM T GRAPHIC, V23, P294, DOI 10.1145/1015706.1015718
   [Anonymous], 2001, Schooling for Tomorrow
   [Anonymous], 2005, Computational Aesthetics in Graphics, Visualization and Imaging, DOI [DOI 10.2312/COMPAESTH/COMPAESTH05/111-122, 10.2312/COMPAESTH/COMPAESTH05/111-122]
   Barnes C, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531330
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Gao Z., 2020, ACM T MULTIM COMPUT, V16, P1
   Gao Z, 2020, NEURAL NETWORKS, V125, P290, DOI 10.1016/j.neunet.2020.02.017
   Griffin G., 2007, CALTECH 256 OBJECT C
   Hays J, 2008, COMMUN ACM, V51, P87, DOI 10.1145/1400181.1400202
   Jacob JC, 2009, INT J COMPUT SCI ENG, V4, P73, DOI 10.1504/IJCSE.2009.026999
   Jiang Y, 2017, IGGRAPH ASIA 2017 TECHNICAL BRIEFS (SA'17), DOI 10.1145/3145749.3149440
   Levin A, 2004, LECT NOTES COMPUT SC, V2034, P377
   Lin S., 2020, 2020 IEEE CVF C COMP
   Ng, 2007, ADV NEURAL INF PROCE, P801
   Paris S, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964963
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Radford A., 2015, ARXIV151106434
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Schmid C., 2009, PONCE J SPATIAL PYRA, V3
   Simonyan K., 2018, P PERVASIVE DISPLAYS, DOI DOI 10.1145/3205873.3205877
   Sunkavalli K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778862
   Wolf L., 2016, ARXIV PREPRINT ARXIV
   Wu H, 2016, J VIS COMMUN IMAGE R, V38, P100, DOI 10.1016/j.jvcir.2016.02.011
   Wu H, 2015, NEUROCOMPUTING, V159, P157, DOI 10.1016/j.neucom.2014.12.088
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Yawitz M.A., 2003, U.S. Patent, Patent No. [6,597,375[P], 6597375]
   Young P., 2014, Transactions of the Association for Computational Linguistics, V2, P67
   Yu K, 2011, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2011.5995732
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
   Zheng M, 2011, IEEE T IMAGE PROCESS, V20, P1327, DOI 10.1109/TIP.2010.2090535
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 33
TC 6
Z9 6
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104123
DI 10.1016/j.imavis.2021.104123
EA FEB 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RD1DC
UT WOS:000633227000009
DA 2024-07-18
ER

PT J
AU Zhang, YR
   Li, YQ
   Wu, C
   Liu, B
AF Zhang, Yaru
   Li, Yaqian
   Wu, Chao
   Liu, Bin
TI Attention-guided aggregation stereo matching network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional neural network; Stereo matching; Attention mechanism;
   Guided cost volume
AB Existing stereo matching networks based on deep learning lack multi-level and multi-module attention and integration for feature information. Therefore, we propose an attention-guided aggregation stereo matching network to encode and integrate information multiple times. Specifically, we design a residual network based on the 2D channel attention block to adaptively calibrate weight response, improving the robustness of the feature representation. We also construct a 3D stacked hourglass structure based on the 3D channel attention block to calibrate the weight response of the 4D cost volume in the channel dimension, further enhancing the network guidance and aggregation capabilities. In addition, we introduce a 4D guided cost volume, which pre-groups the extracted image features and exploits the similarity measures in each group to guide the concatenation features, further realizing interactive learning of cost volume. The experimental results on the Scene Flow and KITTI benchmark datasets showed that the proposed network significantly improves the prediction disparity accuracy with a small increase in calculation time. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zhang, Yaru; Wu, Chao; Liu, Bin] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Li, Yaqian] Yanshan Univ, Key Lab Ind Comp Control Engn Hebei Prov, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University; Yanshan University
RP Li, YQ (corresponding author), Yanshan Univ, Key Lab Ind Comp Control Engn Hebei Prov, Qinhuangdao 066004, Hebei, Peoples R China.
EM yddqb410@163.com
RI Zhang, Yaru/JEP-7689-2023; Wang, Jiacheng/ABE-5948-2020
OI Wang, Jiacheng/0000-0003-4327-1508
FU Natural Science Foundation of Hebei Province [F2019203320]
FX This work is supported by the Natural Science Foundation of Hebei
   Province (No. F2019203320). Compliance with ethical standards.
CR Ba J., 2015, 3 INT C LEARN REPR, P1884
   Brandao P, 2019, PATTERN RECOGN LETT, V120, P75, DOI 10.1016/j.patrec.2018.12.002
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Cheng FY, 2015, PATTERN RECOGN, V48, P2269, DOI 10.1016/j.patcog.2015.01.002
   Cheon M., 2018, ARXIV181112043, V364, P269
   Dai Y., 2019 AS PAC SIGN INF
   Dhrisya K., 2020, International Journal of Information Technology, V12, P869, DOI 10.1007/s41870-020-00499-5
   Feng D, 2018, IEEE INT C INTELL TR, P3266, DOI 10.1109/ITSC.2018.8569814
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Jeon S, 2017, IEEE IMAGE PROC, P1007, DOI 10.1109/ICIP.2017.8296433
   Jie ZQ, 2018, PROC CVPR IEEE, P3838, DOI 10.1109/CVPR.2018.00404
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Li YJ, 2019, VISUAL COMPUT, V35, P257, DOI 10.1007/s00371-018-1491-0
   Liang ZF, 2018, PROC CVPR IEEE, P2811, DOI 10.1109/CVPR.2018.00297
   Liu MY, 2019, IEEE IMAGE PROC, P2434, DOI [10.1109/ICIP.2019.8803320, 10.1109/icip.2019.8803320]
   Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Sang HW, 2019, IEEE ACCESS, V7, P15152, DOI 10.1109/ACCESS.2019.2895271
   Schmid K, 2013, IEEE INT C INT ROBOT, P3955, DOI 10.1109/IROS.2013.6696922
   Song X, 2020, INT J COMPUT VISION, V128, P910, DOI 10.1007/s11263-019-01287-w
   Song X, 2019, LECT NOTES COMPUT SC, V11365, P20, DOI 10.1007/978-3-030-20873-8_2
   Yang GR, 2018, LECT NOTES COMPUT SC, V11211, P660, DOI 10.1007/978-3-030-01234-2_39
   Yu LD, 2018, AAAI CONF ARTIF INTE, P7517
   Zagoruyko S., 2015, PROC CVPR IEEE, P4353, DOI DOI 10.1109/CVPR.2015.7299064
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
   Zhang GH, 2019, IEEE ACCESS, V7, P51681, DOI 10.1109/ACCESS.2019.2911618
   Zhang JM, 2019, IEEE ROBOT AUTOM LET, V4, P1162, DOI 10.1109/LRA.2019.2894913
   Zhang L, AS C MACH LEARN PMLR, P81
   Zhang YA, 2020, IEEE INTELL SYST, V35, P18, DOI 10.1109/MIS.2020.2998040
   Zhang YM, 2020, IEEE ACM T NETWORK, V28, P1227, DOI 10.1109/TNET.2020.2979807
   Zhu ZD, 2019, C IND ELECT APPL, P1789, DOI [10.1109/iciea.2019.8834193, 10.1109/ICIEA.2019.8834193]
NR 36
TC 5
Z9 5
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2021
VL 106
AR 104088
DI 10.1016/j.imavis.2020.104088
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QK3PP
UT WOS:000620292700001
DA 2024-07-18
ER

PT J
AU Shi, CJ
   Zhang, WM
   Duan, CY
   Chen, HR
AF Shi, Caijuan
   Zhang, Weiming
   Duan, Changyu
   Chen, Houru
TI A pooling-based feature pyramid network for salient object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; U-shaped feature pyramid; Pooling;
   Convolutional neural network; Deep feature learning
AB How to effectively utilize and fuse deep features has become a critical point for salient object detection. Most existing methods usually adopt the convolutional features based on U-shape structures and fuse multi-scale convolutional features without fully considering the different characteristics between high-level features and low-level features. Furthermore, existing salient object detection methods rarely consider the role of pooling in convolutional neural networks. Moreover, there is still much room to improve the detection performance for ob-jects in complex scenes. To address the problems mentioned above, we propose a pooling-based feature pyramid (PFP) network to boost salient object detection performance in this paper. First, we design two U-shaped feature pyramid modules to capture rich semantic information from high-level features and to obtain clear saliency boundaries from low-level features respectively. Second, a pyramid pooling refinement module is designed to utilize the pooling to capture more semantic information. Third, a universal channel-wise attention (UCA) mod-ule is designed to select effective high-level features of multi-scale and multi-receptive -field for rich semantic in-formation, even in complex scenes. Finally, we fuse the selected high-level features and low-level features together, followed by an edge preservation loss to obtain accurate boundary location. Extensive experiments are conducted on five datasets and the experimental results indicate that our proposed method has the ability to get better salient object detection performance compared to the state-of-the-art methods.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Shi, Caijuan; Zhang, Weiming; Duan, Changyu; Chen, Houru] North China Univ Sci & Technol, Coll Artificial Intelligence, Tangshan 063210, Peoples R China.
C3 North China University of Science & Technology
RP Shi, CJ (corresponding author), North China Univ Sci & Technol, Coll Artificial Intelligence, Tangshan 063210, Peoples R China.
EM shicaijuan2011@gmail.com
RI Zhang, Wei-Ming/L-5761-2017
FU National Natural Science Foundation of China [61502143]; Distinguished
   Youth Foundation of North China University of Science and Technology
   [JQ201715]; Graduate Model Class Project of Hebei Province
   [KCJSX2019097]
FX This work was supported partly by the National Natural Science
   Foundation of China (61502143), Distinguished Youth Foundation of North
   China University of Science and Technology (JQ201715), the Graduate
   Model Class Project of Hebei Province (KCJSX2019097).
CR Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Borji A., 2012, 2012 IEEE COMPUTER S, P23, DOI 10.1109/CVPRW.2012.6239191
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Cheng, 2018, ADV NEURAL INF PROCE, P549, DOI 10.5555/3326943.3326994.
   Cheng MM, 2015, IEEE T PATTERN ANAL, V37, P569, DOI 10.1109/TPAMI.2014.2345401
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P4290, DOI 10.1109/TIP.2012.2199502
   Guo F, 2018, IEEE T CYBERNETICS, V48, P3159, DOI 10.1109/TCYB.2017.2761361
   He JF, 2012, PROC CVPR IEEE, P3005, DOI 10.1109/CVPR.2012.6248030
   Hinton G.E., 2018, INT C LEARN REPR
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hou QB, 2019, IEEE T PATTERN ANAL, V41, P815, DOI 10.1109/TPAMI.2018.2815688
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang ZL, 2013, PROC CVPR IEEE, P2043, DOI 10.1109/CVPR.2013.266
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin D, 2019, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2019.00767
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2019, IEEE I CONF COMP VIS, P1232, DOI 10.1109/ICCV.2019.00132
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Luo ZM, 2017, PROC CVPR IEEE, P6593, DOI 10.1109/CVPR.2017.698
   Nazarov, 2001, ANAL PDES MATH AP
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qi Q, 2019, IEEE INT CON MULTI, P1762, DOI 10.1109/ICME.2019.00303
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabour S, 2017, ADV NEUR IN, V30
   Su JM, 2019, IEEE I CONF COMP VIS, P3798, DOI 10.1109/ICCV.2019.00390
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang LZ, 2016, LECT NOTES COMPUT SC, V9908, P825, DOI 10.1007/978-3-319-46493-0_50
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2017, IEEE I CONF COMP VIS, P4039, DOI 10.1109/ICCV.2017.433
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wang W., 2020, ARXIV190409146V3CSCV
   Wang WG, 2019, PROC CVPR IEEE, P1448, DOI 10.1109/CVPR.2019.00154
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Xiao HX, 2018, IEEE T MULTIMEDIA, V20, P3239, DOI 10.1109/TMM.2018.2830098
   Xudong Wang, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P7281, DOI 10.1109/CVPR.2019.00746
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Zeng Y, 2019, PROC CVPR IEEE, P6067, DOI 10.1109/CVPR.2019.00623
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang PP, 2017, IEEE I CONF COMP VIS, P202, DOI 10.1109/ICCV.2017.31
   Zhang PP, 2017, IEEE I CONF COMP VIS, P212, DOI 10.1109/ICCV.2017.32
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
NR 67
TC 8
Z9 10
U1 1
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104099
DI 10.1016/j.imavis.2021.104099
EA JAN 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RD1DC
UT WOS:000633227000001
DA 2024-07-18
ER

PT J
AU Aldana-Iuit, J
   Mishkin, D
   Chum, O
   Matas, J
AF Aldana-Iuit, Javier
   Mishkin, Dmytro
   Chum, Ondrej
   Matas, Jiri
TI Saddle: Fast and repeatable features with good coverage
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Interest points; Fast detectors; Image matching
ID SCALE
AB A novel similarity-covariant feature detector that extracts points whose neighborhoods, when treated as a 3D intensity surface, have a saddle-like intensity profile is presented. The saddle condition is verified efficiently by intensity comparisons on two concentric rings that must have exactly two dark-to-bright and two bright-to-dark transitions satisfying certain geometric constraints. Saddle is a fast approximation of Hessian detector as ORB, that implements the FAST detector, is for Harris detector. We propose to use the matching strategy called the first geometric inconsistent with binary descriptors that is suitable for our feature detector, including experiments with fix point descriptors hand-crafted and learned. Experiments show that the Saddle features are general, evenly spread and appearing in high density in a range of images. The Saddle detector is among the fastest proposed. In comparison with detector with similar speed, the Saddle features show superior matching performance on number of challenging datasets. Compared to recently proposed deep-learning based interest point detectors and popular hand-crafted keypoint detectors, evaluated for repeatability in the ApolloScape dataset Huang et al. (2018), the Saddle detectors shows the best performance in most of the street-level view sequences a.k.a. traversals. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Aldana-Iuit, Javier; Mishkin, Dmytro; Chum, Ondrej; Matas, Jiri] Ctr Machine Percept, Karlovo Namesti 13, Prague 12135 2, Czech Republic.
C3 Czech Technical University Prague
RP Aldana-Iuit, J (corresponding author), Ctr Machine Percept, Karlovo Namesti 13, Prague 12135 2, Czech Republic.
EM aldanjav@cmp.felk.cvut.cz
RI Mishkin, Dmytro/GSI-5311-2022; Chum, Ondrej/F-5262-2015; ,
   Matas/AAW-3282-2020
OI Mishkin, Dmytro/0000-0001-8205-6718; Matas, Jiri/0000-0003-0863-4844
FU CONCIYTEY-CONACYT-Mexico PhD scholarship [216786]; CTU student grant
   [SGS17/185/OHK3/3T/13]; Austrian Ministry for Transport, Innovation and
   Technology; Federal Ministry of Science, Research and Economy; Province
   of Upper Austria; MSMT [LL1303 ERC-CZ]; Czech Science Foundation [GACR
   P103/12/G084]
FX Javier Aldana-Iuit was supported by CONCIYTEY-CONACYT-Mexico PhD
   scholarship 216786 and CTU student grant SGS17/185/OHK3/3T/13, Dmytro
   Mishkin by CTU student grant SGS17/185/OHK3/3T/13 and by the Austrian
   Ministry for Transport, Innovation and Technology, the Federal Ministry
   of Science, Research and Economy, and the Province of Upper Austria in
   the frame of the COMET center SCCH, Ondrej Chum by MSMT LL1303 ERC-CZ
   grant, and Jiri Matas by the Czech Science Foundation Project GACR
   P103/12/G084.
CR Agarwal S, 2009, IEEE I CONF COMP VIS, P72, DOI 10.1109/ICCV.2009.5459148
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Aldana-Iuit J, 2016, INT C PATT RECOG, P675, DOI 10.1109/ICPR.2016.7899712
   [Anonymous], 2018, EUR C COMP VIS WORKS
   [Anonymous], IJCPR
   [Anonymous], 2009, CVPR
   [Anonymous], CVPR 2019 WORKSH IM
   [Anonymous], HIGH RESOLUTION FEAT
   [Anonymous], ISMAR
   [Anonymous], 2006, ECCV
   [Anonymous], CISS
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Balntas V, 2017, PROC CVPR IEEE, P3852, DOI 10.1109/CVPR.2017.410
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chum O, 2007, IEEE I CONF COMP VIS, P496, DOI 10.1109/cvpr.2007.383172
   Förstner W, 2009, IEEE I CONF COMP VIS, P2256, DOI 10.1109/ICCV.2009.5459458
   Gurevich Y., 2000, ACM T COMPUT LOG, V1, P77, DOI DOI 10.1145/343369.343384
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hauagge DC, 2012, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2012.6247677
   Huang XY, 2018, IEEE COMPUT SOC CONF, P1067, DOI 10.1109/CVPRW.2018.00141
   Kelman Avi., 2007, CVPR
   Krajník T, 2017, ROBOT AUTON SYST, V88, P127, DOI 10.1016/j.robot.2016.11.011
   Lebeda K, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.95
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Li Y, 2014, IEEE T IMAGE PROCESS, V23, P1666, DOI 10.1109/TIP.2014.2302896
   Lindeberg T, 2015, J MATH IMAGING VIS, V52, P3, DOI 10.1007/s10851-014-0541-0
   Lindeberg Tony, 1991, THESIS
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Mikulik Andrej., 2014, ACCV
   Mishchuk A., 2017, P NIPS
   Mishkin D., 2015, BMVC
   Mishkin D, 2015, COMPUT VIS IMAGE UND, V141, P81, DOI 10.1016/j.cviu.2015.08.005
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Neumann L, 2013, PROC INT CONF DOC, P523, DOI 10.1109/ICDAR.2013.110
   Obdrzalek S., 2005, BMVC
   Perd'och M, 2009, PROC CVPR IEEE, P9, DOI 10.1109/CVPRW.2009.5206529
   Rosin PL, 1999, COMPUT VIS IMAGE UND, V73, P291, DOI 10.1006/cviu.1998.0719
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sattler Torsten., 2017, CoRR
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Se S, 2002, INT J ROBOT RES, V21, P735, DOI 10.1177/027836402761412467
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   Trzcinski T, 2013, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2013.370
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Verdie Y, 2015, PROC CVPR IEEE, P5279, DOI 10.1109/CVPR.2015.7299165
   Yu GS, 2011, IMAGE PROCESS ON LIN, V1, P11, DOI 10.5201/ipol.2011
   Zitnick CL, 2011, IEEE I CONF COMP VIS, P359, DOI 10.1109/ICCV.2011.6126263
NR 56
TC 2
Z9 2
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2020
VL 97
AR 103807
DI 10.1016/j.imavis.2019.08.011
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR7TU
UT WOS:000535899900001
DA 2024-07-18
ER

PT J
AU Tong, K
   Wu, YQ
   Zhou, F
AF Tong, Kang
   Wu, Yiquan
   Zhou, Fei
TI Recent advances in small object detection based on deep learning: A
   review
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Small object detection; Deep learning; Computer vision; Convolutional
   neural networks
ID PEDESTRIAN DETECTION; VEHICLE DETECTION; TRACKING; VISION; RECOGNITION;
   NETWORKS
AB Small object detection is a challenging problemin computer vision. It has beenwidely applied in defensemilitary, transportation, industry, etc. To facilitate in-depth understanding of small object detection, we comprehensively review the existing small object detection methods based on deep learning from five aspects, including multi-scale feature learning, data augmentation, training strategy, context-based detection and GAN-based detection. Then, we thoroughly analyze the performance of some typical small object detection algorithms on popular datasets, such as MS-COCO, PASCAL-VOC. Finally, the possible research directions in the future are pointed out from five perspectives: emerging small object detection datasets and benchmarks, multi- task joint learning and optimization, information transmission, weakly supervised small object detection methods and framework for small object detection task. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Tong, Kang; Wu, Yiquan; Zhou, Fei] Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Wu, YQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing, Peoples R China.
EM tkangcv@nuaa.edu.cn; mltd2099@163.com; F.zhouip@nuaa.edu.cn
RI zhou, fei/KLE-1174-2024
OI zhou, fei/0000-0001-8566-6968
FU National Natural Science Foundation of China [61573183]; Open Project
   Program of the National Laboratory of Pattern Recognition (NLPR)
   [201900029]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 61573183 and the Open Project Program of
   the National Laboratory of Pattern Recognition (NLPR) under Grant
   201900029.
CR [Anonymous], ABS180903193 CORR
   [Anonymous], 2020, RDSNET NEW DEEP ARCH
   [Anonymous], 2017, KINETICS HUMAN ACTIO
   [Anonymous], EUR C COMP VIS 2018
   [Anonymous], 2018, IEEE INT CON MULTI
   [Anonymous], 2018, LECT NOTES COMPUTER, DOI [DOI 10.1007/978-3-030-00764-5_51, 10.1007/978-3-030-00764-5_51]
   [Anonymous], 2019, ABS190207296 CORR
   [Anonymous], ABS170905054 CORR
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], INT C MULT RETR 2011
   [Anonymous], ABS171200960 CORR
   [Anonymous], 2016, P BRIT MACHINE VISIO
   Bai YC, 2018, LECT NOTES COMPUT SC, V11217, P210, DOI 10.1007/978-3-030-01261-8_13
   Bell S, 2016, PROC CVPR IEEE, P2874, DOI 10.1109/CVPR.2016.314
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Brunetti A, 2018, NEUROCOMPUTING, V300, P17, DOI 10.1016/j.neucom.2018.01.092
   Cai ZW, 2016, LECT NOTES COMPUT SC, V9908, P354, DOI 10.1007/978-3-319-46493-0_22
   Cao CQ, 2019, IEEE ACCESS, V7, P106838, DOI 10.1109/ACCESS.2019.2932731
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Chen Q, 2015, IEEE T PATTERN ANAL, V37, P13, DOI 10.1109/TPAMI.2014.2343217
   Chen XL, 2017, IEEE I CONF COMP VIS, P4106, DOI 10.1109/ICCV.2017.440
   Chen Y., 2017, Advances in neural information processing systems, P4467
   Cheng G, 2016, ISPRS J PHOTOGRAMM, V117, P11, DOI 10.1016/j.isprsjprs.2016.03.014
   Cui Lisha, 2020, [Science China. Information Science, 中国科学. 信息科学], V63
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Eggert C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P172, DOI 10.1145/3078971.3078990
   Eggert C, 2017, IEEE INT CON MULTI, P421, DOI 10.1109/ICME.2017.8019550
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guan LT, 2018, INT J COMPUT INT SYS, V11, P951
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Jiao LC, 2019, IEEE ACCESS, V7, P128837, DOI 10.1109/ACCESS.2019.2939201
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kanga A., 2017, ABS170106659 CORR
   Kembhavi A, 2011, IEEE T PATTERN ANAL, V33, P1250, DOI 10.1109/TPAMI.2010.182
   Kong T, 2017, PROC CVPR IEEE, P5244, DOI 10.1109/CVPR.2017.557
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krishna H, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P340, DOI 10.1109/ACPR.2017.149
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li JN, 2017, IEEE T MULTIMEDIA, V19, P944, DOI 10.1109/TMM.2016.2642789
   Li W, 2016, PATTERN RECOGN LETT, V83, P115, DOI 10.1016/j.patrec.2015.09.010
   Li ZM, 2018, AAAI CONF ARTIF INTE, P7073
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2018, PROC CVPR IEEE, P6985, DOI 10.1109/CVPR.2018.00730
   Liu Y, 2017, IEEE I CONF COMP VIS, P571, DOI 10.1109/ICCV.2017.69
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Morariu VI, 2014, IEEE WINT CONF APPL, P564, DOI 10.1109/WACV.2014.6836052
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Oh S, 2018, ISSCC DIG TECH PAP I, P328, DOI 10.1109/ISSCC.2018.8310317
   Ouyang WL, 2015, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2015.7298854
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shrivastava A, 2016, LECT NOTES COMPUT SC, V9905, P330, DOI 10.1007/978-3-319-46448-0_20
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Sivaraman S, 2013, IEEE T INTELL TRANSP, V14, P1773, DOI 10.1109/TITS.2013.2266661
   Wang NN, 2018, NEUROCOMPUTING, V275, P50, DOI 10.1016/j.neucom.2017.05.013
   Wu Q, 2018, IEEE T PATTERN ANAL, V40, P1367, DOI 10.1109/TPAMI.2017.2708709
   Wu XF, 2019, ACTA OTO-LARYNGOL, V139, P1122, DOI 10.1080/00016489.2019.1680864
   Wu Y, 2019, INT J COMPUT VISION, V127, P115, DOI 10.1007/s11263-018-1097-z
   Xiao JX, 2016, INT J COMPUT VISION, V119, P3, DOI 10.1007/s11263-014-0748-y
   Ye QX, 2015, IEEE T PATTERN ANAL, V37, P1480, DOI 10.1109/TPAMI.2014.2366765
   Yin XC, 2016, IEEE T IMAGE PROCESS, V25, P2752, DOI 10.1109/TIP.2016.2554321
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zeng XY, 2016, LECT NOTES COMPUT SC, V9911, P354, DOI 10.1007/978-3-319-46478-7_22
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang W, 2018, INT GEOSCI REMOTE SE, P2483, DOI 10.1109/IGARSS.2018.8517436
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou BL, 2019, INT J COMPUT VISION, V127, P302, DOI 10.1007/s11263-018-1140-0
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
   Zhu Y, 2015, PROC CVPR IEEE, P4703, DOI 10.1109/CVPR.2015.7299102
   Zhu Z., 2016, COMPUTER VISION PATT
   Zou Z., 2019, arXiv: 1905.05055v2, P1
NR 88
TC 247
Z9 272
U1 167
U2 1560
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2020
VL 97
AR 103910
DI 10.1016/j.imavis.2020.103910
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR7TU
UT WOS:000535899900003
HC Y
HP N
DA 2024-07-18
ER

PT J
AU Hendry
   Chen, RC
AF Hendry
   Chen, Rung-Ching
TI Automatic License Plate Recognition via sliding-window darknet-YOLO deep
   learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic License Plate Recognition; Deep learning; YOLO network
ID CONVOLUTIONAL NEURAL-NETWORKS
AB Automatic License Plate Recognition (ALPR) is an important research topic in the intelligent transportation system and image recognition fields. In this work, we address the problem of car license plate detection using a You Only Look Once (YOLO)-darknet deep learning framework. In this paper, we use YOLO's 7 convolutional layers to detect a single class. The detection method is a sliding-window process. The object is to recognize Taiwan's car license plates. We use an AOLP dataset which contained 6 digit car license plates. The sliding window detects each digit of the license plate, and each window is then detected by a single YOLO framework. The system achieves approximately 98.22% accuracy on license plate detection and 78% accuracy on license plate recognition. The system executes a single detection recognition phase, which needs around 800 ms to 1 s for each input image. The system is also tested with different condition complexities, such as rainy background, darkness and dimness, and different hues and saturation of images. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Hendry; Chen, Rung-Ching] Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
   [Hendry] Satya Wacana Christian Univ, Fac Informat Technol, Cent Java, Indonesia.
C3 Chaoyang University of Technology; Universitas Kristen Satya Wacana
RP Chen, RC (corresponding author), Chaoyang Univ Technol, Dept Informat Management, Taichung, Taiwan.
EM hendry@uksw.edu; crching@cyut.edu.tw
RI Hendry, Hendry/ACL-6413-2022
OI Hendry, Hendry/0000-0002-7387-2622
FU Ministry of Science and Technology, Taiwan [MOST-107-2221-E-324-018-MY2,
   MOST-106-2221-E-324-025]
FX This research is supported by the Ministry of Science and Technology,
   Taiwan, with the project numbers MOST-107-2221-E-324-018-MY2 and
   MOST-106-2221-E-324-025.
CR Ahmad IS, 2015, IEEE INT SYMP SIGNAL, P635, DOI 10.1109/ISSPIT.2015.7394415
   Anagnostopoulos CNE, 2008, IEEE T INTELL TRANSP, V9, P377, DOI 10.1109/TITS.2008.922938
   Baldominos A, 2018, NEUROCOMPUTING, V283, P38, DOI 10.1016/j.neucom.2017.12.049
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deb K, 2008, 2008 INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS, VOLS 1-4, P600
   Deng ZP, 2017, 2017 INTERNATIONAL WORKSHOP ON REMOTE SENSING WITH INTELLIGENT PROCESSING (RSIP 2017)
   Enzeng Dong, 2018, 2018 IEEE International Conference on Mechatronics and Automation (ICMA), P1184, DOI 10.1109/ICMA.2018.8484733
   Gupta MR, 2010, FOUND TRENDS SIGNAL, V4, P223, DOI 10.1561/2000000034
   Hsu GS, 2013, IEEE T VEH TECHNOL, V62, P552, DOI 10.1109/TVT.2012.2226218
   Jiao JB, 2009, PATTERN RECOGN, V42, P358, DOI 10.1016/j.patcog.2008.08.016
   Jung D, 2018, INT CONF ADV COMMUN, P36, DOI 10.23919/ICACT.2018.8323638
   Khryashchev V.V., 2018, 2018 SYST SIGN, P1, DOI 10.1109/SYNCHROINFO.2018.8457056
   Kulkarni SR, 2018, NEURAL NETWORKS, V103, P118, DOI 10.1016/j.neunet.2018.03.019
   Kumar T., 2016, PROC 5 INT C NETWORK, P53
   Li H, 2019, IEEE T INTELL TRANSP, V20, P1126, DOI 10.1109/TITS.2018.2847291
   Li H, 2018, IMAGE VISION COMPUT, V72, P14, DOI 10.1016/j.imavis.2018.02.002
   Lin KH, 2010, IEEE IMAGE PROC, P3945, DOI 10.1109/ICIP.2010.5649878
   Mathur N, 2016, PROCEDIA COMPUT SCI, V93, P431, DOI 10.1016/j.procs.2016.07.230
   Paoletti ME, 2018, ISPRS J PHOTOGRAMM, V145, P120, DOI 10.1016/j.isprsjprs.2017.11.021
   Putra M.H., 2018, J. Telecommun. Electron. Comput. Eng. (JTEC), V10, P67
   Rasheed S, 2012, LECT NOTES ENG COMP, P199
   Redmon J., 2016, PROC CVPR IEEE, DOI [10.1109/CVPR.2016.91, DOI 10.1109/CVPR.2016.91]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Safaei A, 2016, COMPUT ELECTR ENG, V56, P15, DOI 10.1016/j.compeleceng.2016.09.010
   Seo Y, 2019, EXPERT SYST APPL, V116, P328, DOI 10.1016/j.eswa.2018.09.022
   Sharma Neha, 2018, Procedia Computer Science, V132, P377, DOI 10.1016/j.procs.2018.05.198
   Sheng H, 2009, IEEE INTEL TRANSP SY, V1, P17, DOI 10.1109/MITS.2010.935911
   Tao WJ, 2018, ENG APPL ARTIF INTEL, V76, P202, DOI 10.1016/j.engappai.2018.09.006
   Wan SH, 2018, COMPUT ELECTR ENG, V72, P274, DOI 10.1016/j.compeleceng.2018.07.042
   Wang X., 2017, MULTIMED TOOLS APPL, V77, P3083
   Yang LH, 2018, 2018 IEEE 3RD INTERNATIONAL CONFERENCE ON CLOUD COMPUTING AND BIG DATA ANALYSIS (ICCCBDA), P331, DOI 10.1109/ICCCBDA.2018.8386537
   Zhang MM, 2018, IEEE T IMAGE PROCESS, V27, P2623, DOI 10.1109/TIP.2018.2809606
   Zheng D, 2005, PATTERN RECOGN LETT, V26, P2431, DOI 10.1016/j.patrec.2005.04.014
   2009, DEV SOL OR DOS, P1, DOI DOI 10.1109/CISE.2009.5364222
NR 34
TC 133
Z9 138
U1 9
U2 181
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2019
VL 87
BP 47
EP 56
DI 10.1016/j.imavis.2019.04.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IF3NV
UT WOS:000472988400005
DA 2024-07-18
ER

PT J
AU Chu, WS
   De la Torre, F
   Cohn, JF
AF Chu, Wen-Sheng
   De la Torre, Fernando
   Cohn, Jeffrey F.
TI Learning facial action units with spatiotemporal cues and multi-label
   sampling
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Multi-label learning; Deep learning; Spatio-temporal learning;
   Multi-label sampling; Facial action unit detection; Video analysis
ID EXPRESSION; RECOGNITION; EMOTION
AB Facial action units (AUs) can be represented spatially, temporally, and in terms of their correlation. Previous research focuses on one or another of these aspects or addresses them disjointly. We propose a hybrid network architecture that jointly models spatial and temporal representations and their correlation. In particular, we use a Convolutional Neural Network (CNN) to learn spatial representations, and a Long Short-Term Memory (LSTM) to model temporal dependencies among them. The outputs of CNNs and LSTMs are aggregated into a fusion network to produce per-frame prediction of multiple AUs. The hybrid network was compared to previous state-of-the-art approaches in two large FACS-coded video databases, GFT and BP4D, with over 400,000 AU-coded frames of spontaneous facial behavior in varied social contexts. Relative to standard multi-label CNN and feature-based state-of-the-art approaches, the hybrid system reduced person-specific biases and obtained increased accuracy for AU detection. To address class imbalance within and between batches during network training, we introduce multi-labeling sampling strategies that further increase accuracy when AUs are relatively sparse. Finally, we provide visualization of the learned AU models, which, to the best of our best knowledge, reveal for the first time how machines see AUs. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Chu, Wen-Sheng; De la Torre, Fernando; Cohn, Jeffrey F.] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   [Cohn, Jeffrey F.] Univ Pittsburgh, Dept Psychol, Pittsburgh, PA 15260 USA.
C3 Carnegie Mellon University; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); University of Pittsburgh
RP Chu, WS (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM wschu@cmu.edu
RI Chu, Wen-Sheng/AAF-6871-2019
OI Chu, Wen-Sheng/0000-0001-8592-6088
FU US National Institutes of Health [GM105004, MH096951]; Division of
   Computer and Network Systems [1629716]; NVIDIA; Division Of Computer and
   Network Systems; Direct For Computer & Info Scie & Enginr [1629716]
   Funding Source: National Science Foundation
FX This work was supported in part by the US National Institutes of Health
   grants GM105004 and MH096951 and Division of Computer and Network
   Systems grant number 1629716. The authors also thank NVIDIA for
   supporting this research with a Tesla K40c GPU, and Jiabei Zeng and
   Kaili Zhao for assisting partial experiments.
CR [Anonymous], LEARNING SPATIAL TEM
   [Anonymous], AFGR
   [Anonymous], WE ARE NOT ALL EQUAL
   [Anonymous], AFGR
   [Anonymous], AFGR
   [Anonymous], 2013, ICASSP
   [Anonymous], ICCV
   [Anonymous], ICCV
   [Anonymous], CVPR
   [Anonymous], WACV
   [Anonymous], ARXIV13126034
   [Anonymous], 2014, NIPS
   [Anonymous], CVPR
   [Anonymous], 2015, DEEP FAC REC BRIT MA
   [Anonymous], CVPR
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2014, OXFORD HDB AFFECTIVE
   [Anonymous], 2015, Automatic Face and Gesture Recognition
   [Anonymous], 2015, ACII
   [Anonymous], AFGR
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2015, CVPR
   [Anonymous], 2013, ICCV
   [Anonymous], AFGR
   [Anonymous], 2013, CVPR
   [Anonymous], IEEE C INT C COMP VI
   [Anonymous], 2010, CVPR WORKSH
   [Anonymous], CVPR
   [Anonymous], 2015, ACM MM
   [Anonymous], 2014, CVPR
   Chang Kai-Yueh., 2009, CVPR
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen J., 2009, CVPR
   Cohn JF, 2010, BEHAV RES METHODS, V42, P1079, DOI 10.3758/BRM.42.4.1079
   Donahue J., 2015, CVPR
   Du SC, 2015, DIALOGUES CLIN NEURO, V17, P443
   Ekman P., 2005, WHAT FACE REVEALS
   Ekman P., 2002, FACIAL ACTION CODING
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Haibo He, 2009, IEEE Transactions on Knowledge and Data Engineering, V21, P1263, DOI 10.1109/TKDE.2008.239
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LIN JH, 1991, IEEE T INFORM THEORY, V37, P145, DOI 10.1109/18.61115
   Martinez A, 2012, J MACH LEARN RES, V13, P1589
   Prati RC, 2015, KNOWL INF SYST, V45, P247, DOI 10.1007/s10115-014-0794-3
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Sun YM, 2009, INT J PATTERN RECOGN, V23, P687, DOI 10.1142/S0218001409007326
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P966, DOI 10.1109/TSMCB.2012.2200675
   WONG AKC, 1985, IEEE T PATTERN ANAL, V7, P599, DOI 10.1109/TPAMI.1985.4767707
   Yang S, 2014, LECT NOTES COMPUT SC, V8888, P269, DOI 10.1007/978-3-319-14364-4_26
   Yosinski J., 2015, ARXIV150606579
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhao K., 2016, CVPR
   Zhu YF, 2011, IEEE T AFFECT COMPUT, V2, P79, DOI 10.1109/T-AFFC.2011.10
NR 56
TC 12
Z9 13
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2019
VL 81
BP 1
EP 14
DI 10.1016/j.imavis.2018.10.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA HO1ZJ
UT WOS:000460710900001
PM 30524157
OA Green Accepted, Bronze
DA 2024-07-18
ER

PT J
AU Zhang, L
   Dou, P
   Kakadiaris, IA
AF Zhang, L.
   Dou, P.
   Kakadiaris, I. A.
TI Patch-based face recognition using a hierarchical multi-label matcher
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Convolutional neural network; Hierarchical multi-label
   classification
ID LOCAL BINARY PATTERNS; CLASSIFICATION; REPRESENTATION; CLASSIFIERS;
   EIGENFACES; ENSEMBLE; MODEL
AB This paper proposes a hierarchical multi-label matcher for patch-based face recognition. In signature generation, a face image is iteratively divided into multi-level patches. Two different types of patch divisions and signatures are introduced for 2D facial image and texture-lifted image, respectively. The matcher training consists of three steps. First, local classifiers are built to learn the local matching of each patch. Second, the hierarchical relationships defined between local patches are used to learn the global matching of each patch. Three ways are introduced to learn the global matching: majority voting, l(1) -regularized weighting, and decision rule. Last, the global matchings of different levels are combined as the final matching. Experimental results on different face recognition tasks demonstrate the effectiveness of the proposed matcher at the cost of gallery generalization. Compared with the UR2D system, the proposed matcher improves the Rank-1 accuracy significantly by 3% and 0.18% on the UHDB31 dataset and IJB-A dataset, respectively. (C) 2018 Published by Elsevier B.V.
C1 [Zhang, L.; Dou, P.; Kakadiaris, I. A.] Computat Biomed Lab, 4849 Calhoun Rd,Rm 373, Houston, TX 77204 USA.
RP Kakadiaris, IA (corresponding author), Computat Biomed Lab, 4849 Calhoun Rd,Rm 373, Houston, TX 77204 USA.
EM lzhang34@uh.edu; pdou@uh.edu; ioannisk@uh.edu
RI Dou, Pengfei/AAW-5035-2020
OI Kakadiaris, Ioannis/0000-0002-0591-1079
FU U.S. Department of Homeland Security [2015-ST-061-BSH001]
FX This material is based upon work supported by the U.S. Department of
   Homeland Security under Grant Award Number 2015-ST-061-BSH001. This
   grant is awarded to the Borders, Trade, and Immigration (BTI) Institute:
   A DHS Center of Excellence led by the University of Houston, and
   includes support for the project "Image and Video Person Identification
   in an Operational Environment: Phase I" awarded to the University of
   Houston. The views and conclusions contained in this document are those
   of the authors and should not be interpreted as necessarily representing
   the official policies, either expressed or implied, of the U.S.
   Department of Homeland Security.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], P INT C BIOM QUEENSL
   [Anonymous], 24 CVC U AUT BARC
   [Anonymous], PROC CVPR IEEE
   [Anonymous], PROC BRIT MACH, DOI DOI 10.1007/978-3-642-54233-6_1
   [Anonymous], 2014, LEARNING FACE REPRES
   [Anonymous], 2006, P IEEE C COMP VIS PA
   [Anonymous], P IEEE INT C COMP VI
   Azeem A, 2014, INT ARAB J INF TECHN, V11, P1
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Breiman L., 2001, Mach. Learn., V45, P5
   Chen SC, 2004, PATTERN RECOGN, V37, P1081, DOI 10.1016/j.patcog.2003.09.004
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   Dou P., 2015, Proc. Biometrics Theory, P1
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330
   Fagni T., 2007, Proceedings of the 3rd language technology conference, P24
   Friedman M, 1937, J AM STAT ASSOC, V32, P675, DOI 10.2307/2279372
   Friedman M, 1940, ANN MATH STAT, V11, P86, DOI 10.1214/aoms/1177731944
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Heisele B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P688, DOI 10.1109/ICCV.2001.937693
   IMAN RL, 1980, COMMUN STAT A-THEOR, V9, P571, DOI 10.1080/03610928008827904
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   Kakadiaris IA, 2017, COMPUT VIS IMAGE UND, V154, P137, DOI 10.1016/j.cviu.2016.04.012
   Kim TK, 2005, IMAGE VISION COMPUT, V23, P631, DOI 10.1016/j.imavis.2005.02.005
   Klare BF, 2015, PROC CVPR IEEE, P1931, DOI 10.1109/CVPR.2015.7298803
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Luo J, 2007, INT CONF ACOUST SPEE, P593
   Mansanet J, 2016, PATTERN RECOGN LETT, V70, P80, DOI 10.1016/j.patrec.2015.11.015
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Masi I, 2016, LECT NOTES COMPUT SC, V9909, P579, DOI 10.1007/978-3-319-46454-1_35
   Oh HJ, 2006, LECT NOTES COMPUT SC, V3851, P120
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Sermanet P., 2013, INT C LEARN REPR, DOI DOI 10.1016/J.VISRES.2006.11.009
   Shen FM, 2016, PATTERN RECOGN, V54, P94, DOI 10.1016/j.patcog.2016.01.010
   Silla CN, 2011, DATA MIN KNOWL DISC, V22, P31, DOI 10.1007/s10618-010-0175-9
   Simonyan K., 2014, 14091556 ARXIV
   Su Y, 2009, IEEE T IMAGE PROCESS, V18, P1885, DOI 10.1109/TIP.2009.2021737
   Sun Y., 2015, Journal of Computational and Graphical Statistics
   Sun Y, 2014, ADV NEUR IN, V27
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Valentini G, 2011, IEEE ACM T COMPUT BI, V8, P832, DOI 10.1109/TCBB.2010.38
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu X, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P446, DOI 10.1109/BTAS.2017.8272729
   Yang M, 2011, PROC CVPR IEEE, P625, DOI 10.1109/CVPR.2011.5995393
   Yuk J.S., 2010, Proc. Asian Conference on Computer Vision, P690
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang JQ, 2016, NEUROCOMPUTING, V184, P176, DOI 10.1016/j.neucom.2015.07.141
   Zhang L, 2017, PATTERN RECOGN, V70, P89, DOI 10.1016/j.patcog.2017.05.007
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang LF, 2015, INT CONF BIOMETR, P127, DOI 10.1109/ICB.2015.7139086
   Zhang LF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P158, DOI 10.1109/BTAS.2017.8272694
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao SY, 2014, ADV MATER SCI ENG, V2014, DOI 10.1155/2014/503483
   Zhu PF, 2012, LECT NOTES COMPUT SC, V7572, P822, DOI 10.1007/978-3-642-33718-5_59
NR 62
TC 3
Z9 4
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2018
VL 73
BP 28
EP 39
DI 10.1016/j.imavis.2018.03.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GH7SF
UT WOS:000433653000003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Georgakis, C
   Panagakis, Y
   Zafeiriou, S
   Pantic, M
AF Georgakis, Christos
   Panagakis, Yannis
   Zafeiriou, Stefanos
   Pantic, Maja
TI The Conflict Escalation Resolution (CONFER) Database
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic conflict analysis; Conflict intensity estimation; Conflict
   detection; Behavioral computing; Social signal processing; Behavioral
   annotation
ID AUTOMATIC DETECTION; BEHAVIOR; RECOGNITION; FEATURES; CORPUS
AB Conflict is usually defined as a high level of disagreement taking place when individuals act on incompatible goals, interests, or intentions. Research in human sciences has recognized conflict as one of the main dimensions along which an interaction is perceived and assessed. Hence, automatic estimation of conflict intensity in naturalistic conversations would be a valuable tool for the advancement of human-centered computing and the deployment of novel applications for social skills enhancement including conflict management and negotiation. However, machine analysis of conflict is still limited to just a few works, partially due to an overall lack of suitable annotated data, while it has been mostly approached as a conflict or (dis)agreement detection problem based on audio features only. In this work, we aim to overcome the aforementioned limitations by a) presenting the Conflict Escalation Resolution (CONFER) Database, a set of excerpts from audio-visual recordings of televised political debates where conflicts naturally arise, and b) reporting baseline experiments on audio-visual conflict intensity estimation. The database contains approximately 142 min of recordings in Greek language, split over 120 non-overlapping episodes of naturalistic conversations that involve two or three interactants. Subject- and session-independent experiments are conducted on continuous-time (frame-by-frame) estimation of real-valued conflict intensity, as opposed to binary conflict/non-conflict classification. For the problem at hand, the efficiency of various audio and visual features and fusion of them as well as various regression frameworks is examined. Experimental results suggest that there is much room for improvement in the design and development of automated multi-modal approaches to continuous conflict analysis. The CONFER Database is publicly available for non-commercial use at http://ibug.doc.ic.ac.uk/resources/confer/. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Georgakis, Christos; Panagakis, Yannis; Zafeiriou, Stefanos; Pantic, Maja] Imperial Coll London, Dept Comp, London, England.
   [Zafeiriou, Stefanos] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
   [Pantic, Maja] Univ Twente, Fac Elect Engn Math & Comp Sci, Enschede, Netherlands.
   [Panagakis, Yannis] Middlesex Univ, Dept Comp Sci, London, England.
C3 Imperial College London; University of Oulu; University of Twente;
   Middlesex University
RP Georgakis, C (corresponding author), Imperial Coll London, Dept Comp, London, England.
EM christos.georgakis@imperial.ac.uk
RI Panagakis, Yannis/AAZ-8090-2020
OI Panagakis, Ioannis/0000-0003-0153-5210
FU European Community Horizon [645094]; ERC [330237]; FiDiPro program of
   Tekes [1849/31/2015]
FX This work was funded by the European Community Horizon 2020
   [H2020/2014-2020] under grant agreement no. 645094 (SEWA). Yannis
   Panagakis was also partially funded by the ERC under the FP7 Marie Curie
   Intra-European Fellowship (project number: 330237). The work of Stefanos
   Zafeiriou was funded by the FiDiPro program of Tekes (project number:
   1849/31/2015).
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Alabort-i-Medina J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P679, DOI 10.1145/2647868.2654890
   Anderson T. W., 1962, Tech. Rep..
   [Anonymous], FACIAL EXPRESSION RE
   [Anonymous], GOTHENBG PAP THEOR L
   [Anonymous], SOCIAL SIGNAL PROCES
   [Anonymous], 2010, P ACMMM, DOI DOI 10.1145/1873951.1874102
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2012, 13 ANN C INT SPEECH
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], 2011, Visual Analysis of Humans, DOI DOI 10.1007/978-0-85729-997-0_26
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], 2013, 10 IEEE INT C WORKSH
   Antonakos E, 2015, PROC CVPR IEEE, P5435, DOI 10.1109/CVPR.2015.7299182
   Bilakhia S, 2015, PATTERN RECOGN LETT, V66, P52, DOI 10.1016/j.patrec.2015.03.005
   Bilakhia S, 2013, INT CONF AFFECT, P123, DOI 10.1109/ACII.2013.27
   Bousmalis K., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P746, DOI 10.1109/FG.2011.5771341
   Bousmalis K., 2009, P 3 INT C AFFECTIVE, P1, DOI [10.1109/ACII.2009.5349477, DOI 10.1109/ACII.2009.5349477]
   Bousmalis K, 2013, IMAGE VISION COMPUT, V31, P203, DOI 10.1016/j.imavis.2012.07.003
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Carletta J, 2007, LANG RESOUR EVAL, V41, P181, DOI 10.1007/s10579-007-9040-x
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chao LL, 2015, INT CONF AFFECT, P526, DOI 10.1109/ACII.2015.7344620
   Chen H, 2015, PROC CVPR IEEE, P1836, DOI 10.1109/CVPR.2015.7298793
   Chrysos GG, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P954, DOI 10.1109/ICCVW.2015.126
   COOPER VW, 1986, J NONVERBAL BEHAV, V10, P134, DOI 10.1007/BF01000009
   Cootes Tim, 2000, Image Process. Anal., V328, P223
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Georgakis Christos, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P4828, DOI 10.1109/ICASSP.2014.6854519
   Georgakis C, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1177, DOI 10.1145/2647868.2655026
   Georgakis C, 2016, IEEE T IMAGE PROCESS, V25, P2021, DOI 10.1109/TIP.2016.2539502
   George C., 2015, The international encyclopedia of digital communication and society, V1st ed., P1, DOI [https://doi.org/10.1002/9781118767771.wbiedcs139, DOI 10.1002/9781118767771.WBIEDCS139]
   Georgiou PC, 2011, LECT NOTES COMPUT SC, V6974, P87, DOI 10.1007/978-3-642-24600-5_12
   Graves A, 2005, NEURAL NETWORKS, V18, P602, DOI 10.1016/j.neunet.2005.06.042
   Graves A., 2013, RNNLIB: A recurrent neural network library for sequence learning problems
   Gunes H, 2013, IMAGE VISION COMPUT, V31, P120, DOI 10.1016/j.imavis.2012.06.016
   Gunes Hatice, 2011, INT C INT VIRT AG, P511
   Hirschberg Julia, 2004, P 42 ANN M ASS COMP, P669
   Huang D, 2011, IEEE T SYST MAN CY C, V41, P765, DOI 10.1109/TSMCC.2011.2118750
   Janin A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P364
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   JUDD CM, 1978, J CONFLICT RESOLUT, V22, P483, DOI 10.1177/002200277802200308
   Kaltwang S, 2016, IEEE T PATTERN ANAL, V38, P1748, DOI 10.1109/TPAMI.2015.2501824
   Kaltwang S, 2015, PROC CVPR IEEE, P296, DOI 10.1109/CVPR.2015.7298626
   Kim S, 2014, IEEE T AFFECT COMPUT, V5, P187, DOI 10.1109/TAFFC.2014.2324564
   Kim S, 2012, INT CONF ACOUST SPEE, P5089, DOI 10.1109/ICASSP.2012.6289065
   Lafferty John, 2001, INT C MACH LEARN ICM
   Levine J., 2008, Small groups: Key readings
   Liu X, 2013, PROC CVPR IEEE, P492, DOI 10.1109/CVPR.2013.70
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   McCowan Iain, 2005, Proceedings of the 5th International Conference on Methods and Techniques in Behavioral Research, V88
   Nicolaou MA, 2011, IEEE T AFFECT COMPUT, V2, P92, DOI 10.1109/T-AFFC.2011.9
   Nicolaou MA, 2014, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2014.6853852
   Nicolaou MA, 2014, IEEE T PATTERN ANAL, V36, P1299, DOI 10.1109/TPAMI.2014.16
   Panagakis Y., 2014, COMP VIS ECCV 2014 W, P306
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Pesarin A, 2012, COGN PROCESS, V13, P533, DOI 10.1007/s10339-011-0417-9
   Petridis S, 2011, IEEE T MULTIMEDIA, V13, P216, DOI 10.1109/TMM.2010.2101586
   Pianesi F, 2007, LANG RESOUR EVAL, V41, P409, DOI 10.1007/s10579-007-9060-6
   Potamianos G, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1097, DOI 10.1109/ICME.2000.871552
   Ringeval F, 2015, PATTERN RECOGN LETT, V66, P22, DOI 10.1016/j.patrec.2014.11.007
   Sagonas C., 2016, INT J COMPUT VIS
   Sagonas C., 2015, P IEEE INT C COMP VI
   Sagonas C, 2014, PROC CVPR IEEE, P1789, DOI 10.1109/CVPR.2014.231
   Schuller B, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P1564
   Schuller B, 2013, 2013 IEEE THIRD INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - BERLIN (ICCE-BERLIN)
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Smola AJ, 2004, STAT COMPUT, V14, P199, DOI 10.1023/B:STCO.0000035301.49549.88
   Tzimiropoulos G, 2013, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2013.79
   Valstar M, 2016, PROCEEDINGS OF THE 6TH INTERNATIONAL WORKSHOP ON AUDIO/VISUAL EMOTION CHALLENGE (AVEC'16), P3, DOI 10.1145/2988257.2988258
   Vapnik V, 1997, ADV NEUR IN, V9, P281
   Vinciarelli A., 2009, 2009 3rd International Conference on Affective Computing and Intelligent Interaction and Workshops, P1
   Vinciarelli A, 2012, IEEE T AFFECT COMPUT, V3, P69, DOI 10.1109/T-AFFC.2011.27
   Weninger F, 2015, J MACH LEARN RES, V16, P547
   Weninger F, 2013, FRONT PSYCHOL, V4, DOI 10.3389/fpsyg.2013.00292
   Wöllmer M, 2008, INTERSPEECH 2008: 9TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2008, VOLS 1-5, P597
   Zafeiriou L, 2016, IEEE T NEUR NET LEAR, V27, P1034, DOI 10.1109/TNNLS.2015.2435653
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
NR 78
TC 4
Z9 5
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2017
VL 65
SI SI
BP 37
EP 48
DI 10.1016/j.imavis.2016.12.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FJ3GM
UT WOS:000412618500005
DA 2024-07-18
ER

PT J
AU Yao, HT
   Zhang, DM
   Li, JT
   Zhou, JS
   Zhang, SL
   Zhang, YD
AF Yao, Hantao
   Zhang, Dongming
   Li, Jintao
   Zhou, Jianshe
   Zhang, Shiliang
   Zhang, Yongdong
TI DSP: Discriminative Spatial Part modeling for Fine-Grained Visual
   Categorization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Orientational Spatial Part model; Discriminative Spatial Part modeling;
   Fine-Grained Visual Categorization; CNN
ID LOCALIZATION; POSE
AB Different from the basic-level classification, the Fine-Grained Visual Categorization (FGVC) aims to classify objects belonging to the same species. Therefore, it is more challenging than the basic-level classification. Recently, significant advances have been achieved in FGVC. However, most of the existing methods require bounding boxes or part annotations for training and testing, resulting in limited usability and flexibility. To conquer these limitations, we aim to automatically detect the bounding boxes and parts for FGVC. The bounding boxes are acquired by transferring bounding boxes from training images to testing images. Based on the generated bounding boxes, we employ a multiple-layer Orientational Spatial Part (OSP) model to learn local parts for the object. To achieve more discriminative part modeling, the Discriminative Spatial Part (DSP) model is proposed to select the discriminative parts from OSP. Finally, we employ Convolutional Neural Network (CNN) as the feature extractor and train a linear SVM as the classifier. Extensive experiments on public benchmark datasets manifest the impressive performance of our method, i.e., classification accuracy achieves 79.8% on CUB-200-2011 and 85.7% on Aircraft, which are higher than many existing methods using manual annotations. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Yao, Hantao; Li, Jintao; Zhang, Yongdong] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Yao, Hantao; Zhang, Yongdong] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
   [Zhang, Dongming] Coordinat Ctr China, Natl Comp Network Emergency Response Tech Team, Beijing 100029, Peoples R China.
   [Zhou, Jianshe] Capital Normal Univ, Beijing Adv Innovat Ctr Imaging Technol, Beijing 100048, Peoples R China.
   [Zhang, Shiliang] Peking Univ, Elect Engn & Comp Sci, Beijing 100871, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Capital Normal University; Peking University
RP Zhang, YD (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.; Zhang, YD (corresponding author), Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
EM zhyd@ict.ac.cn
OI Zhang, Dongming/0000-0002-1237-7177
FU National Nature Science Foundation of China (NSFC) [61525206, 61672495,
   61572050, 91538111, 61620106009]; National Key Research and Development
   Plan of China [2016YFB0801203, 2016YFB0801200]
FX This work is an extension of previous work which was originally reported
   in Proceedings of 2015 IEEE International Conference on Mobile Services.
   This work was supported in part by National Nature Science Foundation of
   China (NSFC) (61525206, 61672495, 61572050, 91538111, 61620106009) and
   the National Key Research and Development Plan of China (2016YFB0801203,
   2016YFB0801200).
CR [Anonymous], 2011, CVPRW 2011
   [Anonymous], 2011, Technical Report CNS-TR-2011-001
   [Anonymous], 2010, CALTECH UCSD BIRDS
   [Anonymous], 2014, BRIT MACH VIS C BMVC
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2013, TECH REP
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], CVPR
   [Anonymous], 2013, Caffe: An open source convolutional architecture for fast feature embedding
   Branson S, 2010, LECT NOTES COMPUT SC, V6314, P438, DOI 10.1007/978-3-642-15561-1_32
   Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47
   Cinbis RG, 2013, IEEE I CONF COMP VIS, P2968, DOI 10.1109/ICCV.2013.369
   Dai JF, 2015, PROC CVPR IEEE, P3992, DOI 10.1109/CVPR.2015.7299025
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Farrell R, 2011, IEEE I CONF COMP VIS, P161, DOI 10.1109/ICCV.2011.6126238
   Felzenszwalb P. F., CVPR 2008
   Gavves E, 2013, IEEE I CONF COMP VIS, P1713, DOI 10.1109/ICCV.2013.215
   Göring C, 2014, PROC CVPR IEEE, P2489, DOI 10.1109/CVPR.2014.319
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Liu JX, 2013, IEEE I CONF COMP VIS, P2520, DOI 10.1109/ICCV.2013.313
   Liu JX, 2014, LECT NOTES COMPUT SC, V8690, P456, DOI 10.1007/978-3-319-10605-2_30
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Xie LX, 2013, IEEE I CONF COMP VIS, P1641, DOI 10.1109/ICCV.2013.206
   Yang S., 2012, Advances in Neural Information Processing Systems, P3122
   Yao HT, 2015, IEEE INT CONF MO, P360, DOI [10.1109/MobServ.2015.56, 10.1109/MS.2015.56]
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang N, 2013, IEEE I CONF COMP VIS, P729, DOI 10.1109/ICCV.2013.96
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
NR 35
TC 5
Z9 6
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2017
VL 63
BP 24
EP 37
DI 10.1016/j.imavis.2017.05.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EY9IN
UT WOS:000404312400003
DA 2024-07-18
ER

PT J
AU Sankowski, W
   Wlodarczyk, M
   Kacperski, D
   Grabowski, K
AF Sankowski, W.
   Wlodarczyk, M.
   Kacperski, D.
   Grabowski, K.
TI Estimation of measurement uncertainty in stereo vision system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo vision; Measurement uncertainty; Accuracy measurement
ID ERROR; TRACKING
AB Stereo vision systems are becoming increasingly popular and widespread. These systems are widely used in many applications, such as navigation of autonomous mobile robots, 3D measurements, object tracking, the movie industry, augmented reality or people tracking and identification systems. Surprisingly, in the literature, little attention is paid to practical verification procedures in which proper operation of the calibrated stereo vision system can be demonstrated. Therefore, in this paper, a novel approach is proposed that allows accurate estimation of the measurement uncertainty of the (x,y,z) coordinates reconstructed by the stereo vision system. The proposed method does not require any additional equipment beyond the standard calibration board and a general-purpose laser distance meter. The authors introduce a simulation model and mathematical formulas that can be employed to determine the accuracy of the stereo vision system precisely along each of the X, Y and Z axes. The measurement uncertainties obtained are statistically reliable because they are calculated with the use of a large amount of data. A series of experiments are conducted to confirm the correctness of the presented approach and to demonstrate how to apply the developed solution in practical applications. The proposed method can be easily integrated with both newly created and existing solutions because it does not require the introduction of any modifications in the system structure and calibration process. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Sankowski, W.; Wlodarczyk, M.; Kacperski, D.; Grabowski, K.] Lodz Univ Technol, Dept Microelectron & Comp Sci, Wolczanska 221-223, PL-90924 Lodz, Poland.
C3 Lodz University of Technology
RP Wlodarczyk, M (corresponding author), Lodz Univ Technol, Dept Microelectron & Comp Sci, Wolczanska 221-223, PL-90924 Lodz, Poland.
EM wsan@dmcs.pl; mwlodarczyk@dmcs.pl; dkacperski@dmcs.pl;
   kgrabowski@dmcs.pl
RI Sankowski, Wojciech/T-4558-2019; Grabowski, Kamil/AAI-4793-2021
OI Sankowski, Wojciech/0000-0001-5169-4901; Grabowski,
   Kamil/0000-0002-0362-8480
FU Polish National Centre for Research and Development
   [LIDER/027/591/L-4/12/NCBR/2013]
FX The presented research was funded by the Polish National Centre for
   Research and Development under project LIDER/027/591/L-4/12/NCBR/2013,
   titled "Non-Cooperative bioMetric system for Positive AuthentiCaTion"
   (COMPACT).
CR Abbaspour MJ, 2014, 2014 7TH INTERNATIONAL SYMPOSIUM ON TELECOMMUNICATIONS (IST), P326, DOI 10.1109/ISTEL.2014.7000723
   Anchini R, 2009, IEEE T INSTRUM MEAS, V58, P4, DOI 10.1109/TIM.2008.2004979
   [Anonymous], 2015, LEICA DISTO D3A BT U
   [Anonymous], 2015, The OpenCV Reference Manual, V3rd
   [Anonymous], 2016, INT J MICROELECTRON
   Cai L, 2010, PATTERN RECOGN, V43, P4028, DOI 10.1016/j.patcog.2010.06.012
   Chang Y., 2013, SID MID CHAPT SPRING, P78
   Di Leo G., 2011, INSTR MEAS TECHN C I, P1
   Fooladgar F, 2013, IEEE SENS J, V13, P4236, DOI 10.1109/JSEN.2013.2264480
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Kenney J. F., 1954, MATH STAT 1, P252
   Krishnan A. B., 2014, CORR
   KU HH, 1966, J RES NBS C ENG INST, VC 70, P263, DOI 10.6028/jres.070C.025
   Kulesza W., 1998, SCI METROLOGY
   Kytti M., 2011, P SPIE 3 DIMENSIONAL, P7864
   Lee S, 2014, INT CONF ADV COMMUN, P315, DOI 10.1109/ICACT.2014.6779188
   Marrón-Romera M, 2010, SENSORS-BASEL, V10, P8865, DOI 10.3390/s101008865
   Menze M, 2012, INT ARCH PHOTOGRAMM, V39-B3, P47
   Perek P, 2015, 2015 22ND INTERNATIONAL CONFERENCE MIXED DESIGN OF INTEGRATED CIRCUITS & SYSTEMS (MIXDES), P134, DOI 10.1109/MIXDES.2015.7208496
   Rossi L., 2011, P 7 MED COMB S
   Samper D., INT J ADV MANUF TECH, V67
   Schreve K., 2014, 15 INT WORKSHOP RES, P1, DOI DOI 10.1109/REM.2014.6920229
   Xu YF, 2013, IEEE CONF IMAGING SY, P317, DOI 10.1109/IST.2013.6729713
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 24
TC 33
Z9 36
U1 4
U2 45
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2017
VL 61
BP 70
EP 81
DI 10.1016/j.imavis.2017.02.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EU7HK
UT WOS:000401205700006
DA 2024-07-18
ER

PT J
AU Liu, M
   He, Y
   Wei, YL
   Xiang, P
AF Liu, Min
   He, Yue
   Wei, Yangliu
   Xiang, Peng
TI Plant cell tracking using Kalman filter based local graph matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cell tracking; Kalman filter; Local graph matching; Tracklets
   association; Tracklets adaptation
ID SEGMENTATION; MICROSCOPY; RECONSTRUCTION; LINEAGES
AB Automated tracking of cells in time lapse live-imaging datasets of developing multicellular tissues is required for high throughput spatio-temporal quantitative measurements of a range of cell behaviors, such as cell division, migration and cell growth. In this paper, a Kalman filter based local graph matching method is proposed to track the plant cells, by exploiting the tight spatial topology of neighboring cells in a multicellular field as contextual information. The Kalman filter is used to predict the movement of the cells, and then the local graph matching approach is used to search the target cells in the neighborhood of the predicted position. The combination of the Kalman filter and local graph matching greatly reduces the size of the searching region in the matching process and enhances the tracking stability as well. Furthermore, the cells' lineage tracklets could be associated by using the cells' spatial-temporal contextual information to obtain long-term lineages. Finally, we proposed a graph evolution method to enhance the association robustness by considering the statistical properties of individual cell tracklets. The effectiveness and efficiency of the proposed tracking method are validated by experiments on real datasets. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Liu, Min; He, Yue; Wei, Yangliu; Xiang, Peng] Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
C3 Hunan University
RP Liu, M (corresponding author), Hunan Univ, Coll Elect & Informat Engn, Changsha, Hunan, Peoples R China.
EM liu_min@hnu.edu.cn; yueh@hnu.edu.cn; yangliuw@hnu.edu.cn;
   xiang_peng@hnu.edu.cn
OI he, yue/0000-0002-7100-2615
FU National Natural Science Foundation of China [61301254]; Hunan
   Provincial Natural Science Foundation of China [14jj3069]
FX This work was supported in part by the National Natural Science
   Foundation of China under grant 61301254, and the Hunan Provincial
   Natural Science Foundation of China under grant 14jj3069.
CR Amat F, 2014, NAT METHODS, V11, P951, DOI [10.1038/NMETH.3036, 10.1038/nmeth.3036]
   Chakraborty A, 2015, MED IMAGE ANAL, V19, P149, DOI 10.1016/j.media.2014.09.008
   Chen L, 2016, IEEE J-STSP, V10, P185, DOI 10.1109/JSTSP.2015.2503924
   Chen L, 2013, BMC BIOINFORMATICS, V14, DOI 10.1186/1471-2105-14-328
   Daniyan A, 2014, UKSIM-AMSS EIGHTH EUROPEAN MODELLING SYMPOSIUM ON COMPUTER MODELLING AND SIMULATION (EMS 2014), P195, DOI 10.1109/EMS.2014.65
   DUBUISSON MP, 1994, INT C PATT RECOG, P566, DOI 10.1109/ICPR.1994.576361
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Dufour A, 2005, IEEE T IMAGE PROCESS, V14, P1396, DOI 10.1109/TIP.2005.852790
   Dzyubachyk O, 2010, IEEE T MED IMAGING, V29, P852, DOI 10.1109/TMI.2009.2038693
   Fernandez R, 2010, NAT METHODS, V7, P547, DOI [10.1038/NMETH.1472, 10.1038/nmeth.1472]
   Gor V., 2005, IEEE WORKSHOP COMPUT, P142
   Hu J, 2015, IEEE INT FUZZY SYST
   Li J, 2015, IEEE T INF FOREN SEC, V10, P507, DOI 10.1109/TIFS.2014.2381872
   Li K, 2008, MED IMAGE ANAL, V12, P546, DOI 10.1016/j.media.2008.06.001
   Liu M, 2011, MOL PLANT, V4, P922, DOI 10.1093/mp/ssr071
   Liu M, 2010, PLANT J, V62, P135, DOI 10.1111/j.1365-313X.2009.04117.x
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Magnusson KEG, 2015, IEEE T MED IMAGING, V34, P911, DOI 10.1109/TMI.2014.2370951
   Mkrtchyan K, 2011, IEEE IMAGE PROC
   Ong LS., 2010, IEEE COMP SOC C COMP, P71
   Padfield D, 2009, MED IMAGE ANAL, V13, P143, DOI 10.1016/j.media.2008.06.018
   Qiang Y., 2007, CONJUGATES MAGNETIC, P1, DOI [10.1201/9780429187469, DOI 10.1201/9780429187469]
   Santella A, 2014, BMC BIOINFORMATICS, V15, DOI 10.1186/1471-2105-15-217
   Song B, 2010, LECT NOTES COMPUT SC, V6311, P605, DOI 10.1007/978-3-642-15549-9_44
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Xia ZH, 2016, MULTIMED TOOLS APPL, V75, P1947, DOI 10.1007/s11042-014-2381-8
   Yan Y, 2014, IEEE T IMAGE PROCESS, V23, P5599, DOI 10.1109/TIP.2014.2365699
   ZHANG TZ, 2012, IEEE INT C AC SPEECH, P985
   Zheng WS, 2012, IEEE T PATTERN ANAL, V34, P762, DOI 10.1109/TPAMI.2011.164
   Zheng YH, 2015, J INTELL FUZZY SYST, V28, P961, DOI 10.3233/IFS-141378
   Zinan Zhao, 2012, 2012 15th International Conference on Information Fusion (FUSION 2012), P1676
NR 32
TC 16
Z9 18
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 154
EP 161
DI 10.1016/j.imavis.2016.08.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800016
DA 2024-07-18
ER

PT J
AU Jeni, LA
   Cohn, JF
   Kanade, T
AF Jeni, Laszlo A.
   Cohn, Jeffrey F.
   Kanade, Takeo
TI Dense 3D face alignment from 2D video for real-time use
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face alignment; Dense 3D model; Real-time method
ID ACTIVE APPEARANCE MODELS; HEAD; TRACKING; ROBUST; RECONSTRUCTION;
   REGISTRATION
AB To enable real-time, person-independent 3D registration from 2D video, we developed a 3D cascade regression approach in which facial landmarks remain invariant across pose over a range of approximately 60 degrees. From a single 2D image of a person's face, a dense 3D shape is registered in real time for each frame. The algorithm utilizes a fast cascade regression framework trained on high-resolution 3D face-scans of posed and spontaneous emotion expression. The algorithm first estimates the location of a dense set of landmarks and their visibility, then reconstructs face shapes by fitting a part-based 3D model. Because no assumptions are required about illumination or surface properties, the method can be applied to a wide range of imaging conditions that include 2D video and uncalibrated multi-view video. The method has been validated in a battery of experiments that evaluate its precision of 3D reconstruction, extension to multi-view reconstruction, temporal integration for videos and 3D head-pose estimation. Experimental findings strongly support the validity of real-time, 3D registration and reconstruction from 2D video. The software is available online at http://zface.org. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Jeni, Laszlo A.; Cohn, Jeffrey F.; Kanade, Takeo] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   [Cohn, Jeffrey F.] Univ Pittsburgh, Dept Psychol, Pittsburgh, PA 15260 USA.
C3 Carnegie Mellon University; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); University of Pittsburgh
RP Jeni, LA (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM laszlojem@cmu.edu
OI Jeni, Laszlo A./0000-0002-2830-700X; Kanade, Takeo/0000-0002-6267-6853
FU National Institute of Mental Health of the National Institutes of Health
   [MH096951]; Army Research Laboratory Collaborative Technology Alliance
   Program [W911NF-10-2-0016]; Carnegie Mellon University People Image
   Analysis Consortium; Division Of Computer and Network Systems; Direct
   For Computer & Info Scie & Enginr [1205195] Funding Source: National
   Science Foundation
FX Preparation of this publication was supported in part by the National
   Institute of Mental Health of the National Institutes of Health under
   Award Number MH096951, Army Research Laboratory Collaborative Technology
   Alliance Program under cooperative agreement W911NF-10-2-0016, and the
   Carnegie Mellon University People Image Analysis Consortium. The content
   is solely the responsibility of the authors and does not necessarily
   represent the official views of the sponsors.
CR Allen B, 2003, ACM T GRAPHIC, V22, P587, DOI 10.1145/882262.882311
   An KH, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P307, DOI 10.1109/IROS.2008.4650742
   [Anonymous], STAT SHAPE ANAL
   Asteriadis S., 2009, Proceedings of the International Workshop on A ective-Aware Virtual Agents and Social Robots - AFFINE '09, P1
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Aubry M, 2011, IEEE I CONF COMP VIS, P1411, DOI 10.1109/ICCV.2011.6126396
   Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Boker SM, 2011, J EXP PSYCHOL HUMAN, V37, P874, DOI 10.1037/a0021928
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Cao C, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601204
   Cao C, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2462012
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024
   Dantone M., 2012, REAL TIME FACIAL FEA
   Dimitrijevic M, 2004, PROC CVPR IEEE, P1034
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Ekman P., 2002, FACIAL ACTION CODING
   Girard JM, 2015, BEHAV RES METHODS, V47, P1136, DOI 10.3758/s13428-014-0536-1
   Gu L., 2006, COMP VIS PATT REC 20, V1, P1305, DOI DOI 10.1109/CVPR.2006.11
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448
   Kanaujia A, 2007, IEEE IMAGE PROC, P265
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Kobbelt L, 2000, COMP GRAPH, P103, DOI 10.1145/344779.344835
   Kumano S, 2009, INT J COMPUT VISION, V83, P178, DOI 10.1007/s11263-008-0185-x
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   Levy B., 2006, GEOM SHAP MOD APPL 2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1
   Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52
   Tena JR, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964971
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Tulyakov S., 2015, COMP VIS ICCV 2015 I, V1
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Vicente F, 2015, IEEE T INTELL TRANSP, V16, P2014, DOI 10.1109/TITS.2015.2396031
   Xiao J, 2003, INT J IMAG SYST TECH, V13, P85, DOI 10.1002/ima.10048
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yin LJ, 2008, IEEE INT CONF AUTOMA, P116
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang ZY, 2004, INT J COMPUT VISION, V58, P93, DOI 10.1023/B:VISI.0000015915.50080.85
NR 53
TC 60
Z9 63
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 13
EP 24
DI 10.1016/j.imavis.2016.05.009
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700003
PM 29731533
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Seo, JJ
   Kim, HI
   De Neve, W
   Ro, YM
AF Seo, Jeong-Jik
   Kim, Hyung-Il
   De Neve, Wesley
   Ro, Yong Man
TI Effective and efficient human action recognition using dynamic frame
   skipping and trajectory rejection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Frame skipping; Human action recognition (HAR); Motion descriptor;
   Motion trajectory; Optical flow
AB Human action recognition (HAR) is a core technology for human-computer interaction and video understanding, attracting significant research and development attention in the field of computer vision. However, in uncontrolled environments, achieving effective HAR is still challenging, due to the widely varying nature of video content. In previous research efforts, trajectory-based video representations have been widely used for HAR. Although these approaches show state-of-the-art HAR performance for various datasets, issues like a high computational complexity and the presence of redundant trajectories still need to be addressed in order to solve the problem of real-world HAR. In this paper, we propose a novel method for HAR, integrating a technique for rejecting redundant trajectories that are mainly originating from camera movement, without degrading the effectiveness of HAR. Furthermore, in order to facilitate efficient optical flow estimation prior to trajectory extraction, we integrate a technique for dynamic frame skipping. As a result, we only make use of a small subset of the frames present in a video clip for optical flow estimation. Comparative experiments with five publicly available human action datasets show that the proposed method outperforms state-of-the-art HAR approaches in terms of effectiveness, while simultaneously mitigating the computational complexity. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Seo, Jeong-Jik; Kim, Hyung-Il; De Neve, Wesley; Ro, Yong Man] Korea Adv Inst Sci & Technol, Sch Elect Engn, Image & Video Syst Lab, Daejeon, South Korea.
   [De Neve, Wesley] Univ Ghent, iMinds, Multimedia Lab, Ghent, Belgium.
C3 Korea Advanced Institute of Science & Technology (KAIST); Ghent
   University; IMEC
RP Ro, YM (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Image & Video Syst Lab, Daejeon, South Korea.
EM ymro@kaist.ac.kr
RI Ro, Yong Man/C-1731-2011; Kim, Hyung-Il/AAU-4895-2021; De Neve, Wesley
   Marcel/C-6480-2008; Ro, Yong Man/ABF-6817-2020
OI Kim, Hyung-Il/0000-0001-6425-549X; De Neve, Wesley
   Marcel/0000-0002-8190-3839; Ro, Yong Man/0000-0001-5306-6853
FU ICT R&D program of MSIP/IITP [Development of global multi-target
   tracking and event prediction techniques based on real-time large-scale
   video analysis]. [B010116-0525]
FX This work was supported by ICT R&D program of MSIP/IITP [B010116-0525,
   Development of global multi-target tracking and event prediction
   techniques based on real-time large-scale video analysis].
CR [Anonymous], IEEE C COMP VIS PATT
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Chen C.-Y., IEEE REG 10 C TENCON, P1
   Ciptadi A., EUR C COMP VIS 2014, P695
   Dalai N., EUR C COMP VIS 2006, P428
   Dollar P., IEEE INT WORKS VIS S, P65
   Farneback G., 13 SCAND C IM AN 200, P363
   Gaidon A, 2014, INT J COMPUT VISION, V107, P219, DOI 10.1007/s11263-013-0677-1
   Hwang J.-N., IEEE WORKS MULTIMEDI, P616
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Jones S, 2014, PROC CVPR IEEE, P820, DOI 10.1109/CVPR.2014.110
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kliper-Gross O., EUR C COMP VIS 2012, P256
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Laptev I., IEEE C COMP VIS PATT, P1
   Marszalek M., IEEE C COMP VIS PATT, P2929
   Mathe S., EUR C COMP VIS 2012, P842
   Matikainen P., IEEE INT C COMP VIS, P514
   Merrell P., IEEE INT C COMP VIS, P1
   Narayan S, 2014, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR.2014.337
   Niebles J. C., EUR C COMP VIS 2010, P392
   Perronnin F., EUR C COMP VIS 2010, P143
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Rubinstein R, 2008, Tech. rep.
   Scovanner P., ACM INT C MULT 2007, P357
   Seo J.-J., IEEE INT C AUT FAC G, P1
   Soomro Khurram, 2012, UCF101 DATASET 101 H
   Sun J., IEEE C COMP VIS PATT, P2004
   Wang H., 2013, ICCV WORKS ACTION RE
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang LM, 2014, IEEE T IMAGE PROCESS, V23, P810, DOI 10.1109/TIP.2013.2295753
   Willems G., EUR C COMP VIS C 200, P650
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu JX, 2014, PROC CVPR IEEE, P2577, DOI 10.1109/CVPR.2014.330
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
NR 41
TC 24
Z9 24
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 76
EP 85
DI 10.1016/j.imavis.2016.06.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700008
OA Green Published
DA 2024-07-18
ER

PT J
AU Bazzica, A
   Liem, CCS
   Hanjalic, A
AF Bazzica, Alessio
   Liem, Cynthia C. S.
   Hanjalic, Alan
TI Exploiting scene maps and spatial relationships in quasi-static scenes
   for video face clustering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video face annotation; Face clustering; Re-identification
ID FRAMEWORK
AB Video face clustering is a fundamental step in automatically annotating a video in terms of when and where (i.e., in which video shot and where in a video frame) a given person is visible. State-of-the-art face clustering solutions typically rely on the information derived from visual appearances of the face images. This is challenging because of a high degree of variation in these visual appearances due to factors like scale, viewpoint, head pose and facial expression. As a result, either the generated face clusters are not sufficiently pure, or their number is much higher than that of people appearing in the video. A possible way towards improved clustering performance is to analyze visual appearances of faces in specific contexts and take the contextual information into account when designing the clustering algorithm. In this paper, we focus on the context of quasi-static scenes, in which we can assume that the people's positions in a scene are (quasi-)stationary. We present a novel video clustering algorithm that exploits this property to match faces and efficiently propagate face labels across the scope of viewpoints, scale and level of zoom characterizing different frames and shots of a video. We also present a novel publicly available dataset of manually annotated quasi-static scene videos. Experimental assessment on the latter indicates that exploiting information derived by the scene and the spatial relationships between people can substantially improve the clustering performance compared to the state-of-the-art in the field. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Bazzica, Alessio; Liem, Cynthia C. S.; Hanjalic, Alan] Delft Univ Technol, Multimedia Comp Grp, Mekelweg 4, NL-2628 CD Delft, Netherlands.
C3 Delft University of Technology
RP Bazzica, A (corresponding author), Delft Univ Technol, Multimedia Comp Grp, Mekelweg 4, NL-2628 CD Delft, Netherlands.
EM A.Bazzica@tudelft.nl; C.C.S.Liem@tudelft.nl; A.Hanjalic@tudelft.nl
OI Hanjalic, Alan/0000-0002-5771-2549; Liem, Cynthia/0000-0002-5385-7695
FU European Union [601166]
FX The research leading to these results has received funding from the
   European Union Seventh Framework Programme FP7/2007-2013 through the
   PHENICX project under grant agreement no. 601166. We would like to thank
   Robbert Eggermont for his precious assistance with the INSY cluster.
CR Amigó E, 2009, INFORM RETRIEVAL, V12, P461, DOI 10.1007/s10791-008-9066-8
   [Anonymous], 2008, P 16 INT C MULTIMEDI, DOI [DOI 10.1145/1459359.1459577, 10.1145/1459359.1459577]
   [Anonymous], INTERSPEECH 2013 14
   [Anonymous], 2012, GRAPH BASED METHODS
   [Anonymous], IS T SPIE ELECT IMAG
   [Anonymous], 2010, P ACM INT C MULT
   [Anonymous], 2013, P 3 ACM C INT C MULT
   Apostolidis Evlampios, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6583, DOI 10.1109/ICASSP.2014.6854873
   Arya S, 1998, J ACM, V45, P891, DOI 10.1145/293347.293348
   Barr JR, 2014, IEEE WINT CONF APPL, P969, DOI 10.1109/WACV.2014.6835999
   Bazzica A, 2016, COMPUT VIS IMAGE UND, V144, P188, DOI 10.1016/j.cviu.2015.09.009
   Cao XC, 2015, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2015.7298657
   Clippingdale S., 2011, Proceedings of the 2011 IEEE International Symposium on Multimedia (ISM 2011), P416, DOI 10.1109/ISM.2011.75
   El Khoury E., 2010, PROC INT C MULTIMEDI, P295
   El Khoury E, 2014, MULTIMED TOOLS APPL, V68, P747, DOI 10.1007/s11042-012-1080-6
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kayal S, 2013, 2013 13TH UK WORKSHOP ON COMPUTATIONAL INTELLIGENCE (UKCI), P272, DOI 10.1109/UKCI.2013.6651316
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Masi I, 2013, IEEE COMPUT SOC CONF, P775, DOI 10.1109/CVPRW.2013.116
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Neumann L, 2012, PROC CVPR IEEE, P3538, DOI 10.1109/CVPR.2012.6248097
   Nocedal J., 1999, NUMERICAL OPTIMIZATI
   Schwab S, 2013, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2013-10
   Sivic J, 2009, PROC CVPR IEEE, P1145, DOI 10.1109/CVPRW.2009.5206513
   Snavely N, 2006, ACM T GRAPHIC, V25, P835, DOI 10.1145/1141911.1141964
   Steedly D, 2005, IEEE I CONF COMP VIS, P1300
   Vretos N, 2011, IMAGE VISION COMPUT, V29, P693, DOI 10.1016/j.imavis.2011.07.006
   Wu BY, 2013, PROC CVPR IEEE, P3507, DOI 10.1109/CVPR.2013.450
   Xiao SJ, 2014, LECT NOTES COMPUT SC, V8694, P123, DOI 10.1007/978-3-319-10599-4_9
   Zhang L., 2013, Proceedings of the 3rd ACM conference on International conference on multimedia retrieval, P9
   Zhang LY, 2014, INT J MULTIMED INF R, V3, P69, DOI 10.1007/s13735-014-0052-1
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zhi CH, 2011, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2011.5995680
   Zhou F, 2013, PROC CVPR IEEE, P2922, DOI 10.1109/CVPR.2013.376
NR 37
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 25
EP 43
DI 10.1016/j.imavis.2016.11.005
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800003
DA 2024-07-18
ER

PT J
AU Park, JM
   Song, GY
   Lee, JW
AF Park, Jeong-Min
   Song, Gwang-Yul
   Lee, Joon-Woong
TI Shape-indifferent stereo disparity based on disparity gradient
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dense stereo; Disparity gradient estimation; Disparity gradient
   refinement; Cost aggregation
ID ALGORITHM
AB A new algorithm capable of estimating disparity gradients to produce accurate dense disparities is proposed. Such a disparity gradient plays a critical role in acquiring accurate disparities for scenes with many different object shapes. The target is a road traffic scene because it contains various objects, including the road surface, vehicles, pedestrians, sidewalks, and walls. In this paper, we adopt several methods, such as initial matching cost computation, scanline optimization, left/right consistency check, and cost aggregation. However, disparity accuracy is slightly improved by the simple organization of such methods. Disparity quality decisively relies on the application of disparity gradients. Accordingly, in the proposed algorithm, cost aggregation is performed along the direction of the estimated disparity gradient in a disparity space image. This approach improves disparity quality significantly. However, this cost aggregation is time consuming. To reduce the time reqtired, we designed a new 2D integral cost technique. The robustness of the proposed algorithm is demonstrated through the disparity maps obtained from standard images on the Web, indoor images, and outdoor images of various road traffic scenes. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Park, Jeong-Min; Lee, Joon-Woong] Chonnam Natl Univ, Dept Ind Engn, 300 Yongbong Dong, Gwangju 500757, South Korea.
   [Song, Gwang-Yul] Korea Automot Technol Inst, Cheonan Shi, Chungnam, South Korea.
C3 Chonnam National University
RP Lee, JW (corresponding author), Chonnam Natl Univ, Dept Ind Engn, 300 Yongbong Dong, Gwangju 500757, South Korea.
EM ddungpark16@naver.com; skyclass@nate.com; joonlee@jnu.ac.kr
FU Chonnam National University [2016-0106]
FX This study was financially supported by Chonnam National University
   (grant number: 2016-0106).
CR [Anonymous], 2011, BMVC
   Antunes M., 2013, EFFICIENT STEREO MAT
   Baik Y. K., 12 KOR JAP WORKSH FR, P305
   Bleyer M, 2004, IEEE IMAGE PROC, P2997
   Chapra S.C., 2006, Numerical Methods for Engineers
   Geiger A., ACCV 2010, P25
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hong L, 2004, PROC CVPR IEEE, P74
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Lee KY, 2015, INT J AUTO TECH-KOR, V16, P107, DOI 10.1007/s12239-015-0012-7
   Lee KY, 2014, INT J CONTROL AUTOM, V12, P895, DOI 10.1007/s12555-013-0478-x
   Mei X., ICCV 2011, P6
   Mühlmann K, 2002, INT J COMPUT VISION, V47, P79, DOI 10.1023/A:1014581421794
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Sellers G., 2010, OPENGL SUPERBIBLE CO
   Shi CB, 2012, IEICE T INF SYST, VE95D, P699, DOI 10.1587/transinf.E95.D.699
   Song G. Y., P INT C COMP VIS SYS, P828
   Stentoumis C, 2014, ISPRS J PHOTOGRAMM, V91, P29, DOI 10.1016/j.isprsjprs.2014.02.006
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Z. F., CVPR 2008, P1
   Yamaguchi Y., ECCV 2012, P45
   Yang Q, BMVC 2008, P80
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zbontar J, 2016, J MACH LEARN RES, V17
   Zhang K, 2009, IEEE T CIRC SYST VID, V19, P1073, DOI 10.1109/TCSVT.2009.2020478
   Zhang Y., ICPR 2008, P1
NR 26
TC 2
Z9 2
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 102
EP 113
DI 10.1016/j.imavis.2016.11.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800009
DA 2024-07-18
ER

PT J
AU Li, T
   Meng, ZJ
   Ni, BB
   Shen, JB
   Wang, M
AF Li, Teng
   Meng, Zhijun
   Ni, Bingbing
   Shen, Jianbing
   Wang, Meng
TI Robust geometric <i>l<sub>p</sub></i>-norm feature pooling for image
   classification and action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature pooling; Spatial distribution; Image classification; Action
   recognition
ID ATTENTION
AB Feature pooling is a key component in modern visual classification system. However, the conventional two prevailing pooling techniques, namely average and max poolings, are not theoretically optimal, due to the unrecoverable loss of the spatial information during the statistical summarization and the underlying over-simplified assumption about the feature distribution. Addressing these issues, this paper proposes to generalize previous pooling methods toward a weighted l(p)-norm spatial pooling function tailored for class-specific feature spatial distribution. Optimizing such a pooling function toward discriminative class separability that is subject to a spatial smoothness constraint yields a so-called geometric l(p)-norm pooling (GLP) method. Furthermore, to handle the variation of object scale/position, which would affect not only. the learning of discriminative pooling weights but also the applicability of the learned weights, we propose a simple yet effective self-alignment step during both learning and testing to adaptively adjust the pooling weights for individual images. Image segmentation and visual saliency map are utilized to construct a directed pixel adjacency graph. The discriminative pooling weights are diffused using random walk on the constructed graph and therefore the discriminative pooling weights are propagated onto the salient and foreground region. This leads to a robust version of GLP (RGLP) which can cope with the misalignment of object position and scale in images. Comprehensive experiments validate the effectiveness of the proposed GLP feature pooling framework. The proposed random walk based self-alignment step can effectively alleviate the image misalignment issue and further boost classification accuracy. State-of-the-art image classification and action recognition performances are attained on several benchmarks. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Li, Teng] Anhui Univ, Hefei, Peoples R China.
   [Meng, Zhijun] Beihang Univ, Beijing, Peoples R China.
   [Ni, Bingbing] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [Shen, Jianbing] Beijing Inst Technol, Beijing, Peoples R China.
   [Wang, Meng] Hefei Univ Technol, Hefei, Peoples R China.
C3 Anhui University; Beihang University; Shanghai Jiao Tong University;
   Beijing Institute of Technology; Hefei University of Technology
RP Meng, ZJ (corresponding author), Beihang Univ, Beijing, Peoples R China.
EM mengzhijun@buaa.edu.cn
RI Shen, Jianbing/U-8796-2019
FU National Natural Science Foundation (NSF) of China [61572029, 61300056];
   Science and Technology Project of Anhui Province [1501b042207]
FX This work is supported by the National Natural Science Foundation (NSF)
   of China (No. 61572029, No. 61300056), and the Science and Technology
   Project of Anhui Province (No. 1501b042207).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], INT C COMP VIS
   [Anonymous], 2010, Computer Vision and Pattern Recognition (CVPR), 2010 IEEE Conference on, IEEE, DOI [DOI 10.1109/CVPR.2010.5540018, 10.1109/CVPR.2010.5540018]
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], EUR C COMP VIS
   Balasubramanian K., 2013, INT C MACH LEARN
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Boureau Y. L., 2010, P 27 INT C MACH LEAR, P111
   Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546
   Chen Q., 2011, COMPUTER VISION PATT
   Delaitre V., 2010, 21 BRIT MACH VIS C
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   FUKUSHIMA K, 1982, PATTERN RECOGN, V15, P455, DOI 10.1016/0031-3203(82)90024-3
   Gao SH, 2010, PROC CVPR IEEE, P3555, DOI 10.1109/CVPR.2010.5539943
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Griffin G., 2007, CALTECH 256 OBJECT C
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou X., 2007, COMPUTER VISION PATT
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jain P., 2008, COMPUTER VISION PATT
   Jarrett K., 2009, INT C COMP VIS
   jia Li L, 2010, ADV NEURAL INFORM PR
   Jiashi Feng, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2697, DOI 10.1109/CVPR.2011.5995370
   Kanan C., 2010, COMPUTER VISION PATT
   Khan FS, 2009, IEEE I CONF COMP VIS, P979, DOI 10.1109/ICCV.2009.5459362
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   Li F., 2010, Computer Vision and Pattern Recognition
   Li F.-F., 2004, CVPR WORKSH
   Li ZC, 2015, IEEE T IMAGE PROCESS, V24, P5343, DOI 10.1109/TIP.2015.2479560
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Li ZC, 2014, IEEE T KNOWL DATA EN, V26, P2138, DOI 10.1109/TKDE.2013.65
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moosmann F., 2006, ECCV WORKSHOP ON THE
   Ni B., 2009, COMPUTER VISION PATT
   Ranzato M., 2006, ADV NEURAL INFORM PR, V19, P1137, DOI DOI 10.7551/MITPRESS/7503.003.0147
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Sadeghi F., 2012, EUR C COMP VIS
   Serre Thomas., 2005, CVPR
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Shao L, 2014, IEEE T NEUR NET LEAR, V25, P1359, DOI 10.1109/TNNLS.2013.2293418
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Sharma G, 2012, PROC CVPR IEEE, P3506, DOI 10.1109/CVPR.2012.6248093
   Singh S., 2012, EUR C COMP VIS
   Torralba A., 2009, IEEE C COMP VIS PATT
   Wang ZL, 2013, IEEE T IMAGE PROCESS, V22, P537, DOI 10.1109/TIP.2012.2218826
   Yakhnenko O., 2011, TECHNICAL REPORT
   Yan SY, 2012, LECT NOTES COMPUT SC, V7575, P473, DOI 10.1007/978-3-642-33765-9_34
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang Jun, 2009, Proceedings of the 2009 2nd International Congress on Image and Signal Processing (CISP), DOI 10.1109/CISP.2009.5304123
   Yang L., 2008, Computer Vision and Pattern Recognition
   Yao BP, 2011, IEEE I CONF COMP VIS, P1331, DOI 10.1109/ICCV.2011.6126386
   Yu J, 2014, IEEE T CYBERNETICS, V44, P2431, DOI 10.1109/TCYB.2014.2307862
   Yu J, 2014, IEEE T IMAGE PROCESS, V23, P2019, DOI 10.1109/TIP.2014.2311377
   Yu J, 2014, IEEE T MULTIMEDIA, V16, P159, DOI 10.1109/TMM.2013.2284755
   Yu MC, 2015, INT SYMP NETW COD, P1, DOI [10.1109/IRMMW-THz.2015.7327562, 10.1080/0740817X.2014.999179, 10.1109/NETCOD.2015.7176778]
   Zhang H., 2006, COMPUTER VISION PATT
   Zhu F, 2014, INT J COMPUT VISION, V109, P42, DOI 10.1007/s11263-014-0703-y
NR 63
TC 16
Z9 18
U1 1
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 64
EP 76
DI 10.1016/j.imavis.2016.04.002
PN 2
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300004
DA 2024-07-18
ER

PT J
AU Vazquez-Fernandez, E
   Gonzalez-Jimenez, D
AF Vazquez-Fernandez, Esteban
   Gonzalez-Jimenez, Daniel
TI Face recognition for authentication on mobile devices
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Biometrics Conference
CY OCT, 2015
CL London, ENGLAND
DE Face recognition; Mobile devices; Biometrics
AB Accessing information from mobile devices has become mainstream nowadays; besides the clear benefits that mobility provides as a means to improve efficiency, productivity and user convenience, it in turn does require proper methods for secure access control. In this paper, we discuss the use of face biometric technology and share our thoughts on key related issues and concerns: usability, security, robustness against spoofing attacks, and user privacy among others. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Vazquez-Fernandez, Esteban; Gonzalez-Jimenez, Daniel] GRADIANT Galician Res & Dev Ctr Adv Telecommun, Pontevedra, Spain.
C3 Gradiant
RP Vazquez-Fernandez, E (corresponding author), GRADIANT Galician Res & Dev Ctr Adv Telecommun, Pontevedra, Spain.
EM evazquez@gradiant.org
RI Vazquez-Fernandez, Esteban/AAD-5379-2020; Gonzalez-Jimenez,
   Daniel/L-9580-2014
OI Vazquez-Fernandez, Esteban/0000-0001-7186-6213; 
CR B. Institute, 2015, TECH REP
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Chingovska I, 2013, INT CONF BIOMETR
   comScore, 2014, TECH REP
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Grother P., 2014, TECH REP
   Jain A. K., 2016, PATTERN RECOGN LETT
   Learned-Miller E., LABELED FACES WILD
   López MB, 2017, J REAL-TIME IMAGE PR, V13, P375, DOI 10.1007/s11554-014-0410-5
   Pascual A., 2014, TECH REP
   Rane S, 2014, IEEE MULTIMEDIA, V21, P94, DOI 10.1109/MMUL.2014.65
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
NR 13
TC 29
Z9 35
U1 2
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
BP 31
EP 33
DI 10.1016/j.imavis.2016.03.018
PN 1
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA ED8BO
UT WOS:000389097100009
DA 2024-07-18
ER

PT J
AU Zhang, L
   Li, CX
   Peng, PP
   Xiang, XZ
   Song, JK
AF Zhang Lei
   Li Changxi
   Peng Peipei
   Xiang Xuezhi
   Song Jingkuan
TI Towards optimal VLAD for human action recognition from still images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE VLAD; Empty cavity; Ambiguity; Generalized max pooling; Human activity
   recognition
AB Human action recognition from still image has recently drawn increasing attention in human behavior analysis and also poses great challenges due to the huge inter ambiguity and intra variability. Vector of locally aggregated descriptors (VLAD) has achieved state-of-the-art performance in many image classification tasks based on local features. The great success of VLAD is largely due to its high descriptive ability and computational efficiency. In this paper, towards optimal VLAD representations for human action recognition from still images, we improve VLAD by tackling three important issues including empty cavity, ambiguity and pooling strategies. The empty cavity limits the performance of VLAD and has long been overlooked. We investigate the empty cavity and provide an effective solution to deal with it, which improves the performance of VLAD; we enhance the codewords with middle level of assignments which are more reliable and can provide more useful information for realistic activity; we propose incorporating the generalized max pooling to replace sum pooling in VLAD, which is more reliable for the final representation. We have conducted extensive experiments on four widely-used benchmarks to validate the proposed method for human action recognition from still images. Our method produces competitive performance with state-of-the-art algorithms. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zhang Lei; Li Changxi; Peng Peipei; Xiang Xuezhi] Harbin Engn Univ, Harbin, Peoples R China.
   [Song Jingkuan] Univ Trento, Trento, Italy.
C3 Harbin Engineering University; University of Trento
RP Xiang, XZ (corresponding author), Harbin Engn Univ, Harbin, Peoples R China.
EM xiangxuezhi@hrbeu.edu.com
FU National Science Foundation of China [61571147, 61401113]; National
   Science Foundation of Heilongjiang Province [F2015027, LC201426];
   Fundamental Research Funds for the Central Universities [HEUCF150801]
FX Partly supported by National Science Foundation of China (61571147,
   61401113), National Science Foundation of Heilongjiang Province
   (F2015027, LC201426) and the Fundamental Research Funds for the Central
   Universities (HEUCF150801).
CR [Anonymous], 2011, INT C ARTIFICIAL INT
   [Anonymous], BAGS FEATURES SPATIA
   [Anonymous], GEN MAX POOLING
   [Anonymous], HIERARCHICAL MATCHIN
   Arandjelovic R., 2013, ALL ABOUT VLAD
   Bach F., 2004, LEARNING SPECTRAL CL
   Bagnell J. A., 2008, DIFFERENTIAL SPARSE
   Boureau Y., 2010, LEARNING MID LEVEL F
   Boureau Y.L., 2010, THEORETICAL ANAL FEA
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gong Y., 2010, LOCALITY CONSTRAINED
   Gong Y., 2009, LINEAR SPATIAL PYRAM
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Huang Y., 2011, SALIENT CODING IMAGE
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Jegou H., 2009, BURSTINESS VISUAL EL
   Jegou H., 2010, Aggregating local descriptors into a compact image representation
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   Jgou O. C. Hery, 2012, NEGATIVE EVIDENCES C
   Jiang Z., 2012, SUBMODULAR DICT LEAR
   Jurie F., 2006, SAMPLING STRATEGIES
   Khan FS, 2014, IEEE T IMAGE PROCESS, V23, P3633, DOI 10.1109/TIP.2014.2331759
   Li L., 2007, What, where and who? Classifying events by scene and object recognition
   Li Li-Jia., 2010, Object bank: A high-level image representation for scene classification semantic feature sparsification
   Liu L., 2011, DEFENSE SOFT ASSIGNM
   Mairal J., 2009, Online dictionary learning for sparse coding
   Mensink T., 2010, IMPROVING FISHER KER
   Philippe-Henri G., 2013, INRIA XEROX FGCOMP B
   Ponce J., 2008, SUPERVISED DICT LEAR
   Prest A, 2012, IEEE T PATTERN ANAL, V34, P601, DOI 10.1109/TPAMI.2011.158
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Shao L., 2015, INT J COMPUT VIS
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Sharma G., 2013, EXPANDED PARTS MODEL
   Sivic J., 2003, Video google: a text retrieval approach to object matching in videos
   Spyromitros-Xioufis E, 2014, IEEE T MULTIMEDIA, V16, P1713, DOI 10.1109/TMM.2014.2329648
   van de Sande K. E., 2014, CVPR 2014
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Yang J., 2010, Supervised translation-invariant sparse coding
   Yao B., 2010, MODELING MUTUAL CONT
   Yao B., 2010, GROUPLET STRUCTURE I
   Yao BP, 2012, IEEE T PATTERN ANAL, V34, P1691, DOI 10.1109/TPAMI.2012.67
   Yao Bangpeng, 2011, HUMAN ACTION RECOGNI
   Yu K, 2009, NONLINEAR LEARNING U
   Yu M., 2015, PATTERN ANAL MACH IN
   Zhang W, 2013, PATTERN RECOGN, V46, P3056, DOI 10.1016/j.patcog.2013.04.013
   Zhen XT, 2014, INFORM SCIENCES, V281, P295, DOI 10.1016/j.ins.2014.05.021
   Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916
NR 50
TC 6
Z9 6
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 53
EP 63
DI 10.1016/j.imavis.2016.03.002
PN 2
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300003
OA hybrid
DA 2024-07-18
ER

PT J
AU Tzelepis, C
   Galanopoulos, D
   Mezaris, V
   Patras, I
AF Tzelepis, Christos
   Galanopoulos, Damianos
   Mezaris, Vasileios
   Patras, Ioannis
TI Learning to detect video events from zero or very few video examples
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video event detection; Textual event description; Zero positive
   examples; Few positive examples; Related videos
AB In this work we deal with the problem of high-level event detection in video. Specifically, we study the challenging problems of i) learning to detect video events from solely a textual description of the event, without using any positive video examples, and ii) additionally exploiting very few positive training samples together with a small number of "related" videos. For learning only from an event's textual description, we first identify a general learning framework and then study the impact of different design choices for various stages of this framework. For additionally learning from example videos, when true positive training samples are scarce, we employ an extension of the Support Vector Machine that allows us to exploit "related" event videos by automatically introducing different weights for subsets of the videos in the overall training set Experimental evaluations performed on the large-scale TRECVID MED 2014 video dataset provide insight on the effectiveness of the proposed methods. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Tzelepis, Christos; Galanopoulos, Damianos; Mezaris, Vasileios] CERTH, Inst Informat Technol, 6th Km Charilaou Thermi Rd,POB 60361, Thessaloniki 57001, Greece.
   [Tzelepis, Christos; Patras, Ioannis] Queen Mary Univ London, Mile End Campus, London E1 4NS, England.
C3 Centre for Research & Technology Hellas; University of London; Queen
   Mary University London
RP Tzelepis, C (corresponding author), CERTH, Inst Informat Technol, 6th Km Charilaou Thermi Rd,POB 60361, Thessaloniki 57001, Greece.
EM tzelepis@iti.gr; dgalanop@iti.gr; bmezaris@iti.gr; i.patras@qmul.ac.uk
RI ; Tzelepis, Christos/O-6413-2015
OI Patras, Ioannis/0000-0003-3913-4738; Tzelepis,
   Christos/0000-0002-2036-9089
FU European Commission [FP7-600826 ForgetIT, FP7-287911 LinkedTV]
FX This work was supported by the European Commission under contracts
   FP7-600826 ForgetIT and FP7-287911 LinkedTV.
CR [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], NIST TRECVID VID RET
   [Anonymous], P ACM MULT
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], P 21 ACM INT C MULT
   [Anonymous], P TRECVID 2013
   [Anonymous], 2009, Technical report
   Bolles R., 2014, P TRECVID WORKSH
   Brown NR, 2005, SOC COGNITION, V23, P35, DOI 10.1521/soco.23.1.35.59194
   Carvalho D., P 13 INT SEM WEB C I, P177
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cheng H., 2014, Journal of Chinese Management, V1, P1, DOI DOI 10.1186/S40527-014-0003-7
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Douze M., 2014, The inria-lim-vocr and axes submissions to trecvid 2014 multimedia event detection
   Elhoseiny M, 2013, IEEE I CONF COMP VIS, P2584, DOI 10.1109/ICCV.2013.321
   Gabrilovich E, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1606
   Gkalelis N., 2014, P TRECVID WORKSH
   Gkalelis N., 2013, MULT EXP ICME IEEE I, P1
   Guangnan Y., 2014, P TRECVID WORKSH
   Habibian A, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P17, DOI 10.1145/2647868.2654913
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jiang L., 2015, INT C MULT RETR
   Jiang Yu-Gang., 2012, IJMIR, P1
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Li XR, 2013, IEEE T MULTIMEDIA, V15, P933, DOI 10.1109/TMM.2013.2238523
   Liu J, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS IEEE-ROBIO 2014, P297, DOI 10.1109/ROBIO.2014.7090346
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mensink T, 2014, PROC CVPR IEEE, P2441, DOI 10.1109/CVPR.2014.313
   Oh S., 2011, P CVPR, P3153, DOI DOI 10.1109/CVPR.2011.5995586
   Over P., 2014, Proceedings of TRECVID 2014
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Salton G, 1986, Introduction to Modern Information Retrieval
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Simonyan K., 2014, 14091556 ARXIV
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wu S, 2014, PROC CVPR IEEE, P2665, DOI 10.1109/CVPR.2014.341
   Wu Xiaoyun, 2004, P 10 ACM SIGKDD INT, P326, DOI [10.1145/1014052.1014089, 10.1145/1014052. 1014089]
   Younessian E., 2012, P 2 ACM INT C MULT R
   Zhai CX, 2004, ACM T INFORM SYST, V22, P179, DOI 10.1145/984321.984322
   Zhang D., 2002, ACM Multimedia, P315
NR 40
TC 10
Z9 10
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2016
VL 53
BP 35
EP 44
DI 10.1016/j.imavis.2015.09.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DX4YH
UT WOS:000384386500004
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU D'Orazio, T
   Marani, R
   Renò, V
   Cicirelli, G
AF D'Orazio, T.
   Marani, R.
   Reno, V.
   Cicirelli, G.
TI Recent trends in gesture recognition: how depth data has improved
   classical approaches
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Gesture recognition; RGB-D data; Features extraction; Classification
   approaches; On-line experiments
ID ALGORITHM; CONTEXT
AB This paper analyzes with a new perspective the recent state of-the-art on gesture recognition approaches that exploit both RGB and depth data (RGB-D images). The most relevant papers have been analyzed to point out which features and classifiers best work with depth data, if these fundamentals are specifically designed to process RGB-D images and, above all, how depth information can improve gesture recognition beyond the limit of standard approaches based on solely color images. Papers have been deeply reviewed finding the relation between gesture complexity and features/methodologies suitability. Different types of gestures are discussed, focusing attention on the kind of datasets (public or private) used to compare results, in order to understand weather they provide a good representation of actual challenging problems, such as: gesture segmentation, idle gesture recognition, and length gesture invariance. Finally the paper discusses on the current open problems and highlights the future directions of research in the field of processing of RGB-D data for gesture recognition. (C) 2016 Elsevier B.V. All rights reserved.
C1 [D'Orazio, T.; Marani, R.; Reno, V.; Cicirelli, G.] CNR Italy, ISSIA, Rome, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Studi sui Sistemi
   Intelligenti per l'Automazione (ISSIA-CNR)
RP D'Orazio, T (corresponding author), CNR ISSIA, Natl Res Council Italy, Inst Intelligent Syst Automat, Via Amendola 122 D-O, I-70126 Bari, BA, Italy.
EM dorazio@ba.issia.cnr.it
RI D'Orazio, Tiziana/H-5032-2019; Renò, Vito/AAF-5723-2019; Cicirelli,
   Grazia/B-7699-2015
OI D'Orazio, Tiziana/0000-0003-1473-7110; Renò, Vito/0000-0003-1830-4961;
   Marani, Roberto/0000-0002-5599-903X; Cicirelli,
   Grazia/0000-0003-1562-0467
CR Aggarwal JK, 2014, PATTERN RECOGN LETT, V48, P70, DOI 10.1016/j.patrec.2014.04.011
   Almetwally I, 2013, IEEE INT C NETW SENS, P463, DOI 10.1109/ICNSC.2013.6548783
   Althloothi S, 2014, PATTERN RECOGN, V47, P1800, DOI 10.1016/j.patcog.2013.11.032
   Chaaraoui AA, 2014, EXPERT SYST APPL, V41, P786, DOI 10.1016/j.eswa.2013.08.009
   [Anonymous], 2013, Consumer Depth Cameras for Computer Vision
   [Anonymous], ACT REC DAT COD
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], 2011, P 5 IEEE INT C AUTOM
   [Anonymous], OPENNI US GUID
   [Anonymous], 2011, CHALEARN GEST DAT CG
   Ballan L, 2012, LECT NOTES COMPUT SC, V7577, P640, DOI 10.1007/978-3-642-33783-3_46
   Bhattacharya S, 2012, PROC INT CONF EMERG, P348, DOI 10.1109/EAIT.2012.6407958
   Bingbing Ni, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1147, DOI 10.1109/ICCVW.2011.6130379
   Bodiroza S, 2013, ACMIEEE INT CONF HUM, P87, DOI 10.1109/HRI.2013.6483514
   Carmona Josep Maria, 2012, Progress in Pattern Recognition, Image Analysis, ComputerVision, and Applications. Proceedings 17th Iberoamerican Congress, CIARP 2012, P236, DOI 10.1007/978-3-642-33275-3_29
   Castiello C., 2005, IEEE C ADV VID SIGN
   Celebi S., 2013, Computer Vision Theory and Applications. Visapp
   ChaLearn, MULT GEST REC CHALL
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Chen X., 2012, LECT NOTES COMPUTER, V7575, P173
   Chen X, 2015, NEUROCOMPUTING, V149, P387, DOI 10.1016/j.neucom.2013.10.046
   Cicirelli G, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/59974
   D'Orazio T., 2014, 3rd International Conference on Pattern Recognition Applications and Methods (ICPRAM 2014). Proceedings, P741
   Dan Xu, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P689, DOI 10.1109/ROBIO.2012.6491047
   Ding IJ, 2015, APPL MATH MODEL, V39, P5769, DOI 10.1016/j.apm.2014.12.054
   Dominio F, 2014, PATTERN RECOGN LETT, V50, P101, DOI 10.1016/j.patrec.2013.10.010
   Dominio Fabio., 2013, Proceedings of the 4th ACM/IEEE international workshop on Analysis and retrieval of tracked events and motion in imagery stream, P9
   Du GL, 2014, IEEE T IND ELECTRON, V61, P5411, DOI [10.1109/TIE.2014.2301728, 10.1109/TIE.2014.230178]
   Escalera S., 2013, Multi-modal Gesture Recognition Challenge 2013: Dataset and Results
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Fujii T., 2014, INT MULTICONFERENCE
   Gu Y., 2012, INT C COMP APPL IND, P187
   Hachaj T, 2014, MULTIMEDIA SYST, V20, P81, DOI 10.1007/s00530-013-0332-2
   Hamissi M., 2013, INT J ELECT COMPUT E, V3, P770
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hasan M.M., 2012, CANADIAN J IMAGE PRO, V3, P12
   Hernández-Vela A, 2014, PATTERN RECOGN LETT, V50, P112, DOI 10.1016/j.patrec.2013.09.009
   Holte M. B., 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563161
   Hwang BW, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P243
   Ibraheem N.A., 2012, International Journal of human Computer Interaction (IJHCI)), V3, P1
   Itauma I.I., 2012, 20 SIGN PROC COMM AP
   Itauma I.I., 2012, IEEE T SMART PROCESS, V1
   Jacob MG, 2014, PATTERN RECOGN LETT, V36, P196, DOI 10.1016/j.patrec.2013.05.024
   Johanson G., 1975, SCI AM
   Kadous M.W., AUSTR SIGN LANGUAGE
   Kam Lai, 2012, Proceedings of the 2012 IEEE Southwest Symposium on Image Analysis & Interpretation (SSIAI 2012), P185, DOI 10.1109/SSIAI.2012.6202484
   Kayal O., 2014, IEEE 27 CAN C EL COM
   Keskin C, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS), DOI 10.1109/ICCVW.2011.6130391
   Krishnan R, 2015, PATTERN RECOGN, V48, P1302, DOI 10.1016/j.patcog.2014.10.026
   Kurakin A, 2012, EUR SIGNAL PR CONF, P1975
   LaViola J.J., 2013, 3D GESTURAL INTERACT
   Lee E.J., 2012, INT J MULTIMEDIA UBI, V7, P335
   Lee SW, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P645
   Leo M., 2005, 5 IASTED INT C VIS I
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Li XL, 2000, IEEE T PATTERN ANAL, V22, P371, DOI 10.1109/34.845379
   Li Y, 2012, 2012 17TH INTERNATIONAL CONFERENCE ON COMPUTER GAMES (CGAMES), P126, DOI 10.1109/CGames.2012.6314563
   Liu CY, 2013, INT CONF MACH LEARN, P381, DOI 10.1109/ICMLC.2013.6890498
   Liu HP, 2015, NEUROCOMPUTING, V149, P79, DOI 10.1016/j.neucom.2013.12.061
   Liu L., 2013, IJCAI
   Ma WY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON SMART CITY/SOCIALCOM/SUSTAINCOM (SMARTCITY), P1, DOI [10.1109/NEBEC.2015.7117114, 10.1109/SmartCity.2015.38]
   Mangera R., 2014, P INT C MACH VIS MAC
   Mangera R, 2013, P 2013 ANN S PATT RE, P5963
   Mauro dosSantos Anjo., 2012, P 11 BRAZILIAN S HUM, P259
   Miranda L, 2014, PATTERN RECOGN LETT, V39, P65, DOI 10.1016/j.patrec.2013.10.005
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Muñoz-Salinas R, 2008, PATTERN RECOGN LETT, V29, P319, DOI 10.1016/j.patrec.2007.10.011
   Murthy G.R.S., 2009, International Journal of Information Technology and Knowledge Management, V2, P405
   Neverova N, 2015, LECT NOTES COMPUT SC, V8925, P474, DOI 10.1007/978-3-319-16178-5_33
   Neverova N, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P484, DOI 10.1109/ICCVW.2013.69
   Nguyen-Duc-Thanh N., 2012, INT J ADV ROBOT SYST, V9
   Ofli F, 2013, IEEE WORK APP COMP, P53, DOI 10.1109/WACV.2013.6474999
   Oh J., 2013, P 2013 INT C INF SCI, P1
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   OpenNI organization, 2012, OPENKINECT PROJ
   Park CB, 2011, IMAGE VISION COMPUT, V29, P51, DOI 10.1016/j.imavis.2010.08.006
   Patsadu O., 2012, 2012 International Joint Conference on Computer Science and Software Engineering (JCSSE 2012), P28, DOI 10.1109/JCSSE.2012.6261920
   Peng Xiaojiang., 2014, European Conference on Computer Vision, P518
   Pisharady PK, 2013, PROCEEDINGS OF THE 2013 IEEE SYMPOSIUM ON COMPUTATIONAL INTELLIGENCE FOR MULTIMEDIA, SIGNAL AND VISION PROCESSING (CIMSIVP), P30, DOI 10.1109/CIMSIVP.2013.6583844
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ren Z., 2011, P ACM INT C MULT ACM
   Ren Z, 2013, IEEE T MULTIMEDIA, V15, P1110, DOI 10.1109/TMM.2013.2246148
   Reyes M., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1182, DOI 10.1109/ICCVW.2011.6130384
   Saponaro G, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON COLLABORATION TECHNOLOGIES AND SYSTEMS (CTS), P218
   Sempena Samsu., 2011, P INT C EL ENG INF, P1, DOI DOI 10.1109/ICEEI.2011.6021605
   Slama R, 2015, PATTERN RECOGN, V48, P556, DOI 10.1016/j.patcog.2014.08.011
   Song Y, 2014, IEEE T CIRC SYST VID, V24, P952, DOI 10.1109/TCSVT.2014.2302558
   Song Y, 2013, INT CONF BIOMED, P750, DOI 10.1109/BMEI.2013.6747040
   Suryanarayan Poonam, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3105, DOI 10.1109/ICPR.2010.760
   Tao Hongyong, 2012, 2012 IEEE 12th International Conference on Computer and Information Technology (CIT), P214, DOI 10.1109/CIT.2012.62
   Ting HY, 2014, LECT NOTES ELECTR EN, V291, P239, DOI 10.1007/978-981-4585-42-2_28
   Vieira AW, 2014, PATTERN RECOGN LETT, V36, P221, DOI 10.1016/j.patrec.2013.07.011
   Wan J, 2013, J MACH LEARN RES, V14, P2549
   Wang C, 2015, IEEE T MULTIMEDIA, V17, P29, DOI 10.1109/TMM.2014.2374357
   Wang HJ, 2013, J VIS COMMUN IMAGE R, V24, P1458, DOI 10.1016/j.jvcir.2013.10.004
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Webb J., BEGINNING KINECT PRO
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Wu D, 2016, IEEE MTT S INT MICR
   Wu D, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P945, DOI 10.1145/2647868.2654969
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Wu XY, 2012, INT SYM COMPUT INTEL, P294, DOI 10.1109/ISCID.2012.225
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67
   Yao Y, 2014, IEEE T CIRC SYST VID, V24, P1935, DOI 10.1109/TCSVT.2014.2302538
   Ye Gu, 2012, Proceedings of the 2012 IEEE International Conference on Robotics and Biomimetics (ROBIO), P1379, DOI 10.1109/ROBIO.2012.6491161
   Ye M., 2013, LECT NOTES COMPUTER, P149, DOI [10.1007/978-3-642-44964-2_8, DOI 10.1007/978-3-642-44964-2_8]
   Youwen Wang, 2012, 2012 4th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC), P274, DOI 10.1109/IHMSC.2012.76
   Zhang H., 2011, P 2011 IEEE RSJ INT, P2044, DOI [DOI 10.1109/IROS.2011.6094489, 10.1109/IROS.2011.6094489]
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao YX, 2012, ADV DIFFER EQU-NY, P1, DOI 10.1186/1687-1847-2012-15
   Zhu Y, 2014, IMAGE VISION COMPUT, V32, P453, DOI 10.1016/j.imavis.2014.04.005
NR 113
TC 36
Z9 36
U1 3
U2 52
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 56
EP 72
DI 10.1016/j.imavis.2016.05.007
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400005
DA 2024-07-18
ER

PT J
AU Rodriguez, M
   Orrite, C
   Medrano, C
   Makris, D
AF Rodriguez, Mario
   Orrite, Carlos
   Medrano, Carlos
   Makris, Dimitrios
TI A Time Flexible Kernel framework for video-based activity recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Activity recognition; Soft-assignment; Kernel methods; Support Vector
   Machine
AB This work deals with the challenging task of activity recognition in unconstrained videos. Standard methods are based on video encoding of low-level features using Fisher Vectors or Bag of Features. However, these approaches model every sequence into a single vector with fixed dimensionality that lacks any long-term temporal information, which may be important for recognition, especially of complex activities. This work proposes a novel framework with two main technical novelties: First, a video encoding method that maintains the temporal structure of sequences and second a Time Flexible Kernel that allows comparison of sequences of different lengths and random alignment. Results on challenging benchmarks and comparison to previous work demonstrate the applicability and value of our framework. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Rodriguez, Mario; Orrite, Carlos; Medrano, Carlos] Univ Zaragoza, I3A, CVLab, C Mariano Esquillor S-N, Zaragoza 50018, Spain.
   [Medrano, Carlos] Univ Zaragoza, EU Politecn, EduQTech, C Ciudad Escolar S-N, Teruel 44003, Spain.
   [Makris, Dimitrios] Univ Kingston, Digital Imaging Res Ctr, Penrhyn Rd, Kingston Upon Thames KT1 2EE, Surrey, England.
C3 University of Zaragoza; University of Zaragoza; Kingston University
RP Rodriguez, M (corresponding author), Univ Zaragoza, I3A, CVLab, C Mariano Esquillor S-N, Zaragoza 50018, Spain.
EM mrodrigo@unizar.es; corrite@unizar.es; ctmedra@unizar.es;
   d.makris@kingston.ac.uk
RI Makris, Dimitrios/D-4224-2009; Rodriguez, Mario/S-9475-2019
OI Makris, Dimitrios/0000-0001-6170-0236; Rodriguez,
   Mario/0000-0001-6324-940X; Medrano Sanchez, Carlos
   Tomas/0000-0001-7671-7540
FU Spanish Grant (MINECO) [TIN2013-45312-R]; Gobierno de Aragon; European
   Social Found; Spanish FPI Grant [BES-2011-043752, EEBB-I-14-08410]
FX This work was partially supported by Spanish Grant TIN2013-45312-R
   (MINECO), Gobierno de Aragon and the European Social Found. Mario
   Rodriguez was sponsored by Spanish FPI Grant BES-2011-043752 and
   EEBB-I-14-08410.
CR [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], 2013, INT C COMP VIS ICCV
   [Anonymous], ROBOTIC INTELLIGENCE
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], INT C IM PROC COMP V
   [Anonymous], EUR C MACH LEARN ECM
   [Anonymous], AS C COMP VIS ACCV
   [Anonymous], 2013, IEEE INT C COMP VIS
   [Anonymous], 2008, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], TRANSFER LEARNING HU
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], INT C MACH LEARN ICM
   Bishop C, 2007, RECOGNITION PATTERN
   Can EF, 2013, IEEE COMPUT SOC CONF, P251, DOI 10.1109/CVPRW.2013.44
   Choi J, 2013, COMPUT VIS IMAGE UND, V117, P660, DOI 10.1016/j.cviu.2013.02.003
   Gaidon A, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.30
   Gönen M, 2011, J MACH LEARN RES, V12, P2211
   Jebara T, 2004, J MACH LEARN RES, V5, P819
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Liang YM, 2009, IEEE T SYST MAN CY B, V39, P268, DOI 10.1109/TSMCB.2008.2005643
   Niebles JC, 2010, LECT NOTES COMPUT SC, V6312, P392, DOI 10.1007/978-3-642-15552-9_29
   Oh SM, 2011, PROC CVPR IEEE
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Rodríguez-Serrano JA, 2012, PATTERN ANAL APPL, V15, P415, DOI 10.1007/s10044-012-0269-7
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Vezzani R, 2010, LECT NOTES COMPUT SC, V6388, P286, DOI 10.1007/978-3-642-17711-8_29
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Xu D, 2008, IEEE T PATTERN ANAL, V30, P1985, DOI 10.1109/TPAMI.2008.129
   Zhou F, 2013, IEEE T PATTERN ANAL, V35, P582, DOI 10.1109/TPAMI.2012.137
NR 41
TC 10
Z9 10
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR-MAY
PY 2016
VL 48-49
BP 26
EP 36
DI 10.1016/j.imavis.2015.12.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO4GS
UT WOS:000377740400003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Kocamaz, MK
   Rasmussen, C
AF Kocamaz, Mehmet Kemal
   Rasmussen, Christopher
TI Approaches for automatic low-dimensional human shape refinement with
   priors or generic cues using RGB-D data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human shape refinement using RGB-D data; Multi-layer graph cut; Human
   body shape descriptor; Random decision forests; Refinement of
   low-dimensional representations; RGB-D
ID ENERGY MINIMIZATION; GRABCUT
AB Some human detection or tracking algorithms output a low-dimensional representation of the human body, such as a bounding box. Even though this representation is enough for some tasks, a more accurate and detailed point-wise representation of the human body is more useful for pose estimation and action recognition. The refinement process can produce a point-wise mask of the human body from its low-dimensional representation. In this paper, we tackle the problem of refining low-dimensional human shapes using RGB-D data with a novel and accurate method for this purpose. This algorithm combines low-level cues such as shape and color, and high level observations such as the estimated ground plane, in a multi-layer graph cut framework. In our algorithm, shape prior information is learned by training a classifier. Unlike some existing work, our method does not utilize or carry features from the internal steps of the methods which provide the bounding box, so our method can work on the outputs of any similar shape providers. Extensive experiments demonstrate that the proposed technique significantly outperforms other suitable methods. Moreover, a previously published refinement method is extended by incorporating more generic cues to serve this purpose. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Kocamaz, Mehmet Kemal] Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
   [Rasmussen, Christopher] Univ Delaware, Dept Comp & Informat Sci, Newark, DE 19716 USA.
C3 Carnegie Mellon University; University of Delaware
RP Kocamaz, MK (corresponding author), Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM kocamaz@cmu.edu; ras@udel.edu
CR Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   [Anonymous], P INT C INT ROB SYST
   [Anonymous], 2008, IEEE C COMPUTER VISI
   [Anonymous], P IEEE C COMP VIS PA
   Benenson R, 2012, PROC CVPR IEEE, P2903, DOI 10.1109/CVPR.2012.6248017
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y., 1999, P INT C COMP VIS ICC
   Boykov Y., 1999, P IEEE C COMP VIS PA, P26
   Boykov Yuri Y, 2001, P INT C COMP VIS ICC
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen LL, 2013, PATTERN RECOGN LETT, V34, P1995, DOI 10.1016/j.patrec.2013.02.006
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Gulshan V., 2011, P INT C COMP VIS ICC
   Hernandez-Vela A., IEEE C COMP VIS PATT, P33
   Hernández-Vela A, 2012, SENSORS-BASEL, V12, P15376, DOI 10.3390/s121115376
   Ikemura S, 2011, LECT NOTES COMPUT SC, V6495, P25, DOI 10.1007/978-3-642-19282-1_3
   Kim T, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P130, DOI 10.1109/ISM.2009.106
   Kocamaz M.K., 2013, P INT C INT ROB SYST
   Kocamaz M.K., INT S VIS COMP 2011, P506
   Lepetit V, 2005, PROC CVPR IEEE, P775
   Luber M., 2011, P INT C INT ROB SYST
   Luke R.H., 2008, Human segmentation from video in indoor environments using fused color and texture features
   Migniot C., 2013, INT C COMP VIS THEOR, P405
   Moosmann F., 2007, P ADV NEUR INF PROC
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Papadakis N, 2011, IEEE T PATTERN ANAL, V33, P144, DOI 10.1109/TPAMI.2010.56
   Plagemann C, 2010, IEEE INT CONF ROBOT, P3108, DOI 10.1109/ROBOT.2010.5509559
   Premebida C, 2009, J FIELD ROBOT, V26, P696, DOI 10.1002/rob.20312
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Sclaroff S, 2001, IEEE T PATTERN ANAL, V23, P475, DOI 10.1109/34.922706
   Sharma V., 2007, P INT C COMP VIS ICC, P1
   Shepherd B.A., 1983, P INT JOINT C ART IN, P473
   Shotton J, 2013, IEEE T PATTERN ANAL, V35, P2821, DOI 10.1109/TPAMI.2012.241
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
   Spinello L., 2008, P INT C ROB AUT ICRA
   Spinello L., 2008, P INT C INT ROB SYST
   Tuzel O., 2007, P IEEE C COMP VIS PA, P1
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vineet V., 2011, P BRIT MACH VIS C BM, P801
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wai M., 2007, P IEEE WORKSH MOT VI
   Yu T.-H., 2013, P IEEE C COMP VIS PA
   Zhao J., INT C COMP VIS ICCV, P1185
   Zhao Jian., 2012, Multimedia Tools and Applications, P1
   Zhao T., 2003, Proc. Computer Vision and Pattern Recognition (CVPR), V2, P406
   Zivkovic Z., 2007, P INT C INT ROB SYST
NR 51
TC 1
Z9 2
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2015
VL 40
BP 16
EP 27
DI 10.1016/j.imavis.2015.05.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CO4YD
UT WOS:000359165900002
DA 2024-07-18
ER

PT J
AU Lu, GF
   Zou, J
   Wang, Y
AF Lu, Gui-Fu
   Zou, Jian
   Wang, Yong
TI Incremental learning from chunk data for IDR/QR
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature extraction; Dimensionality reduction; Linear discriminant
   analysis; Small sample size problem; Incremental learning
ID LINEAR DISCRIMINANT-ANALYSIS; REDUCTION; ALGORITHM; LDA
AB IDR/QR, which is an incremental dimension reduction algorithm based on linear discriminant analysis (LDA) and QR decomposition, has been successfully employed for feature extraction and incremental learning. IDR/QR can update the discriminant vectors with light computation when new training samples are inserted into the training data set. However, IDR/QR has two limitations: 1) IDR/QR can only process new samples one instance after another even if a chunk of training samples is available at a time; and 2) the approximate trick is used in IDR/QR. Then there exists a gap in performance between incremental and batch IDR/QR solutions. To address the problems of IDR/QR, in this paper, we propose a new chunk IDR method which is capable of processing multiple data instances at a time and can accurately update the discriminant vectors when new data items are added dynamically. Experiments on some real databases demonstrate the effectiveness of the proposed algorithm over the original one. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Lu, Gui-Fu; Zou, Jian; Wang, Yong] Anhui Polytech Univ, Sch Comp & Informat, Wuhu 241000, Anhui, Peoples R China.
C3 Anhui Polytechnic University
RP Lu, GF (corresponding author), Anhui Polytech Univ, Sch Comp & Informat, Wuhu 241000, Anhui, Peoples R China.
EM luguifu_jsj@163.com
RI Wang, Yong/HLW-0025-2023
OI Wang, Yong/0000-0002-2719-1017
FU Anhui Provincial Natural Science Foundation [1308085MF95]; Pre-research
   Foundation of NSFC of Anhui Polytechnic University [zryy1305]; Key
   Laboratory of Intelligent Perception and Systems for High-Dimensional
   Information (Nanjing University of Science and Technology); Ministry of
   Education [30920130122005]; China Postdoctoral Science Foundation
   [2013M531251]; NSFC of China [61231002, 61073137, 61203243]; Natural
   Science Foundation of the Anhui Higher Education Institutions of China
   [KJ2013B031]; Jiangxi Provincial Natural Science Foundation of China
   [20122BAB211025]
FX This research is supported by Anhui Provincial Natural Science
   Foundation (No. 1308085MF95), the Pre-research Foundation of NSFC of
   Anhui Polytechnic University (zryy1305), the Key Laboratory of
   Intelligent Perception and Systems for High-Dimensional Information
   (Nanjing University of Science and Technology), Ministry of Education
   (Grant No. 30920130122005), China Postdoctoral Science Foundation
   (2013M531251), NSFC of China (Nos. 61231002, 61073137, 61203243), the
   Natural Science Foundation of the Anhui Higher Education Institutions of
   China (No. KJ2013B031) and Jiangxi Provincial Natural Science Foundation
   of China (20122BAB211025).
CR [Anonymous], P ACM SIGKDD SEATTL
   [Anonymous], P 18 ANN C NEUR INF
   [Anonymous], 2003, ADV NEURAL INFORM PR
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Chu DL, 2010, PATTERN RECOGN, V43, P1373, DOI 10.1016/j.patcog.2009.10.004
   Duda R., 1973, Pattern Classification and Scene Analysis
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Hall P, 2000, IEEE T PATTERN ANAL, V22, P1042, DOI 10.1109/34.877525
   Howland P, 2006, PATTERN RECOGN, V39, P277, DOI 10.1016/j.patcog.2005.06.013
   Kim TK, 2011, INT J COMPUT VISION, V91, P216, DOI 10.1007/s11263-010-0381-3
   Kim TK, 2007, PROC CVPR IEEE, P124
   Li HF, 2006, IEEE T NEURAL NETWOR, V17, P157, DOI 10.1109/TNN.2005.860852
   Lu GF, 2012, KNOWL-BASED SYST, V31, P19, DOI 10.1016/j.knosys.2012.01.016
   Lu GF, 2012, INFORM SCIENCES, V193, P72, DOI 10.1016/j.ins.2012.01.015
   Lu GF, 2012, PATTERN RECOGN, V45, P2510, DOI 10.1016/j.patcog.2012.01.018
   Pang S, 2005, IEEE T SYST MAN CY B, V35, P905, DOI 10.1109/TSMCB.2005.847744
   Peng Y., 2011, BOOSTING PERFORMANCE
   Uray M., 2007, PROC BRIT MACH VISIO, P272
   Wang XG, 2004, PROC CVPR IEEE, P564
   Weng JY, 2003, IEEE T PATTERN ANAL, V25, P1034, DOI 10.1109/TPAMI.2003.1217609
   Yan JQ, 2004, Proceedings of the World Engineers' Convention 2004, Vol A, Network Engineering and Information Society, P1
   Yan J, 2006, INFORM SCIENCES, V176, P2042, DOI 10.1016/j.ins.2005.11.005
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Ye JP, 2005, IEEE T KNOWL DATA EN, V17, P1208, DOI 10.1109/TKDE.2005.148
   Ye JP, 2005, IEEE T PATTERN ANAL, V27, P929, DOI 10.1109/TPAMI.2005.110
   Ye JP, 2004, IEEE T PATTERN ANAL, V26, P982, DOI 10.1109/TPAMI.2004.37
   Zha HY, 1999, SIAM J SCI COMPUT, V21, P782, DOI 10.1137/S1064827597329266
   Zhao HT, 2008, IEEE T SYST MAN CY B, V38, P210, DOI 10.1109/TSMCB.2007.908870
   Zheng WM, 2009, IEEE T INF FOREN SEC, V4, P418, DOI 10.1109/TIFS.2009.2025844
NR 30
TC 6
Z9 6
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2015
VL 36
BP 1
EP 8
DI 10.1016/j.imavis.2015.01.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CG2GV
UT WOS:000353093800001
DA 2024-07-18
ER

PT J
AU Wang, JJ
   Xiao, J
   Lin, WY
   Luo, CF
AF Wang, Jinjun
   Xiao, Jing
   Lin, Weiyao
   Luo, Chuanfei
TI Discriminative and generative vocabulary tree: With application to vein
   image authentication and recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vein identification; Vocabulary tree
ID FINGER-VEIN; ENHANCEMENT; SUBSPACE
AB Finger vein identification is a new biometric identification technology. While many existing works approach the problem by using shape matching which is the generative method, in this paper, we introduce a joint discriminative and generative algorithm for the task. Our method considers both the discriminative appearance of local image patches as well as their generative spatial layout. The method is based on the popular vocabulary tree model, where we utilize the hidden leaf node layer to calculate a generative confidence to weight the discriminative vote from the leaf node. The training process remains the same as building a conventional vocabulary tree, while the prediction process utilizes a proposed point set matching method to support non-parametric patch layout matching. In this way, the entire model retains the efficiency of the vocabulary tree model, which is much lighter than other similar models such as the constellation model (Fergus et al., 2003). The overall estimation follows the Bayesian theory. Experimental results show that our proposed joint model outperformed the purely generative or discriminative counterpart, and can offer competitive performance than existing methods for both the vein authentication and recognition tasks. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Wang, Jinjun] Xi An Jiao Tong Univ, Xian 710049, Shaanxi, Peoples R China.
   [Xiao, Jing] Epson Res & Dev Inc, San Jose, CA 95131 USA.
   [Lin, Weiyao; Luo, Chuanfei] Shanghai Jiao Tong Univ, Shanghai 200240, Peoples R China.
C3 Xi'an Jiaotong University; Shanghai Jiao Tong University
RP Wang, JJ (corresponding author), Xi An Jiao Tong Univ, 28 West Xianning Rd, Xian 710049, Shaanxi, Peoples R China.
EM jinjun@mail.xjtu.edu.cn; xiaoj@erd.epson.com
RI xiao, jing/HRB-7391-2023; luo, chuan/IVH-5370-2023; lin,
   yuxi/HKF-6212-2023
OI Lin, Weiyao/0000-0001-8307-7107
FU National Natural Science Foundation of China [61102100]; National High
   Technology Research and Development Program of China (863 Program)
   [2014AA015205]
FX This work is supported by National Natural Science Foundation of China
   under Grant No. 61102100, and the National High Technology Research and
   Development Program of China (863 Program) under Grant No. 2014AA015205.
CR [Anonymous], P NIPS 05
   [Anonymous], P CVPR 09
   [Anonymous], J BIOMED SCI ENG
   [Anonymous], P CVPR 10
   [Anonymous], 2004, IEEE COMP SOC C COMP
   [Anonymous], OPT ENG
   [Anonymous], P ACM MM 09
   [Anonymous], SENSORS
   [Anonymous], NIPS 01
   [Anonymous], MACH VIS APPL
   [Anonymous], P ICIP 09
   [Anonymous], P CVPR 10
   [Anonymous], UMINF0610
   [Anonymous], P VS PETS
   [Anonymous], INT WORKSH PATT REC
   [Anonymous], 2006, Handbook of Multibiometrics
   Asaari MSM, 2014, EXPERT SYST APPL, V41, P3367, DOI 10.1016/j.eswa.2013.11.033
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Everson R., 1998, Advances in Computational Mathematics
   Fergus R, 2003, PROC CVPR IEEE, P264
   Fidler S, 2006, IEEE T PATTERN ANAL, V28, P337, DOI 10.1109/TPAMI.2006.46
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Getreuer P, 2012, IMAGE PROCESS ON LIN, V2, P266, DOI 10.5201/ipol.2012.g-ace
   GOWER J., 2004, Procrustes Problems
   Grabner H., 2007, CVPR 07, P1
   Holub AD, 2005, IEEE I CONF COMP VIS, P136
   Hoshyan A., 2011, J AM SCI, V7, P192
   MacGregor P., 1991, Adv. Imaging, V6, P52
   Nister David, 2006, CVPR
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Qin HF, 2013, SENSORS-BASEL, V13, P15048, DOI 10.3390/s131115048
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song W, 2011, PATTERN RECOGN LETT, V32, P1541, DOI 10.1016/j.patrec.2011.04.021
   Tao H, 2005, IEEE I CONF COMP VIS, P864
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang J. X., 2008, Policy Research Working Paper - World Bank
   Wang L, 2008, PATTERN RECOGN, V41, P920, DOI 10.1016/j.patcog.2007.07.012
   Weber M, 2000, PROC CVPR IEEE, P101, DOI 10.1109/CVPR.2000.854754
   Xi XM, 2014, OPT ENG, V53, DOI 10.1117/1.OE.53.1.013108
   Yang L, 2014, NEUROCOMPUTING, V135, P218, DOI 10.1016/j.neucom.2013.12.029
   Yang WM, 2014, INFORM SCIENCES, V268, P20, DOI 10.1016/j.ins.2013.10.010
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
   Zhu H, 1999, COMPUT VIS IMAGE UND, V73, P281, DOI 10.1006/cviu.1998.0723
NR 43
TC 16
Z9 17
U1 0
U2 41
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2015
VL 34
BP 51
EP 62
DI 10.1016/j.imavis.2014.10.014
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA5OB
UT WOS:000348956600006
DA 2024-07-18
ER

PT J
AU Yu, QF
   Chao, ZC
   Jiang, GW
   Shang, Y
   Fu, SH
   Liu, XL
   Zhu, XW
   Liu, HB
AF Yu, Qifeng
   Chao, Zhichao
   Jiang, Guangwen
   Shang, Yang
   Fu, Sihua
   Liu, Xiaolin
   Zhu, Xianwei
   Liu, Haibo
TI The effects of temperature variation on videometric measurement and a
   compensation method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vision; Measurement; Temperature; Video; Experiment
ID DEFORMATION MEASUREMENT; CAMERA; CALIBRATION; SYSTEM; LENS
AB When a videometric system operates over a long period, temperature variations in the camera and its environment will affect the measurement results, which cannot be ignored. How to eliminate or compensate for the effects of such variations in temperature is an emergent problem. Starting with the image drift phenomenon, this paper presents an image-drift model that analyzes the relationship between variations in the camera parameters and drift in the coordinates of the image. A simplified model is then introduced by analyzing the coupling relationships among the variations in the camera parameters. Furthermore, a model of the relationship between the camera parameters and temperature variations is established with the system identification method. Finally, several compensation experiments on image drift are carried out, using the parameter-temperature relationship model calibrated with one arbitrary data set to compensate the others. The analyses and experiments demonstrate the feasibility and efficiency of the proposed method. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Yu, Qifeng; Shang, Yang; Zhu, Xianwei; Liu, Haibo] Natl Univ Def Technol, Coll Aerosp Sci & Engn, Changsha 410073, Hunan, Peoples R China.
   [Chao, Zhichao] Chongqing Commun Coll, Chongqing 400035, Peoples R China.
   [Jiang, Guangwen; Fu, Sihua] Natl Univ Def Technol, Coll OptoElect Sci & Engn, Changsha 410073, Hunan, Peoples R China.
   [Liu, Xiaolin] Natl Univ Def Technol, Coll Mechatron Engn & Automat, Changsha 410073, Hunan, Peoples R China.
   [Yu, Qifeng; Jiang, Guangwen; Shang, Yang; Fu, Sihua; Zhu, Xianwei; Liu, Haibo] Hunan Key Lab Videometr & Vis Nav, Changsha 410073, Hunan, Peoples R China.
C3 National University of Defense Technology - China; National University
   of Defense Technology - China; National University of Defense Technology
   - China
RP Yu, QF (corresponding author), Natl Univ Def Technol, Coll Aerosp Sci & Engn, Changsha 410073, Hunan, Peoples R China.
EM yuqifeng@vip.sina.com
RI Liu, Xiaolin/AAR-1424-2020; Liu, Bo Hai/HHN-6599-2022
OI Liu, Xiaolin/0000-0002-6909-117X; Liu, Bo Hai/0000-0002-6999-8927; Liu,
   Haibo/0000-0002-9465-9433
FU National Natural Science Foundations of China [11172323]; National Basic
   Research Program of China [2013CB733100]
FX This work is supported by the National Natural Science Foundations of
   China (No. 11172323) and the National Basic Research Program of China
   (2013CB733100).
CR Ansar A, 2003, IEEE T PATTERN ANAL, V25, P578, DOI 10.1109/TPAMI.2003.1195992
   Bass M., 2010, Optical Properties of Materials, Nonlinear Optics, Quantum Optics, VIV
   Bäumer S, 1999, P SOC PHOTO-OPT INS, V3737, P354, DOI 10.1117/12.360028
   Beyer H. A., 1992, GEOMETRIC RADIO ANAL
   Handel H, 2009, IPSJ Transaction on Computer Vision and Application, V1, P12
   Handel H., 2008, P SOC PHOTO-OPT INS
   JAMIESON TH, 1981, OPT ENG, V20, P156, DOI 10.1117/12.7972683
   Jiang GW, 2011, CHINESE SCI BULL, V56, P113, DOI 10.1007/s11434-010-4264-3
   [姜广文 Jiang Guangwen], 2010, [光学学报, Acta Optica Sinica], V30, P1308
   Kim H, 2000, INT C PATT RECOG, P354, DOI 10.1109/ICPR.2000.905351
   Li MX, 1996, IEEE T PATTERN ANAL, V18, P1105, DOI 10.1109/34.544080
   Ljung L, 1999, PRENTICE HALL INFORM, P503
   Podbreznik P., 2008, INT J COMPUT INF SCI, V2, P261
   Podbreznik P, 2012, MACH VISION APPL, V23, P953, DOI 10.1007/s00138-011-0330-3
   Pollefeys M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P90, DOI 10.1109/ICCV.1998.710705
   Robson S, 1993, P SPIE VIDEOMETRICS, VII, P66
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   WILLSON RG, 1994, P SOC PHOTO-OPT INS, V2350, P170, DOI 10.1117/12.189130
   Wong K. W., 1990, Proceedings of the SPIE - The International Society for Optical Engineering, V1395, P3
   Wu YF, 2004, ICIA 2004: PROCEEDINGS OF 2004 INTERNATIONAL CONFERENCE ON INFORMATION ACQUISITION, P358
   Yu QF, 2009, APPL OPTICS, V48, P4683, DOI 10.1364/AO.48.004683
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 22
TC 26
Z9 33
U1 0
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1021
EP 1029
DI 10.1016/j.imavis.2014.08.011
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600005
DA 2024-07-18
ER

PT J
AU Sikka, K
   Dhall, A
   Bartlett, MS
AF Sikka, Karan
   Dhall, Abhinav
   Bartlett, Marian Stewart
TI Classification and weakly, supervised pain localization using multiple
   segment representation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Emotion classification; Action classification; Pain; Temporal
   segmentation; Bag of Words; Weakly supervised learning; Boosting;
   Bagging
AB Automatic pain recognition from videos is a vital clinical application and, owing to its spontaneous nature, poses interesting challenges to automatic facial expression recognition (AFER) research. Previous pain vs no-pain systems have highlighted two major challenges: (1) ground truth is provided for the sequence, but the presence or absence of the target expression for a given frame is unknown, and (2) the time point and the duration of the pain expression event(s) in each video are unknown. To address these issues we propose a novel framework (referred to as MS-MIL) where each sequence is represented as a bag containing multiple segments, and multiple instance learning (MIL) is employed to handle this weakly labeled data in the form of sequence level ground-truth. These segments are generated via multiple clustering of a sequence or running a multi-scale temporal scanning window, and are represented using a state-of-the-art Bag of Words (BoW) representation. This work extends the idea of detecting facial expressions through 'concept frames' to 'concept segments' and argues through extensive experiments that algorithms such as MIL are needed to reap the benefits of such representation.
   The key advantages of our approach are: (1) joint detection and localization of painful frames using only sequence-level ground-truth, (2) incorporation of temporal dynamics by representing the data not as individual frames but as segments, and (3) extraction of multiple segments, which is well suited to signals with uncertain temporal location and duration in the video. Extensive experiments on UNBC-McMaster Shoulder Pain dataset highlight the effectiveness of the approach by achieving competitive results on both tasks of pain classification and localization in videos. We also empirically evaluate the contributions of different components of MS-MIL The paper also includes the visualization of discriminative facial patches, important for pain detection, as discovered by our algorithm and relates them to Action Units that have been associated with pain expression. We conclude the paper by demonstrating that MS-MIL yields a significant improvement on another spontaneous facial expression dataset, the FEEDTUM dataset. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Sikka, Karan; Bartlett, Marian Stewart] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Dhall, Abhinav] Australian Natl Univ, CSIT, Canberra, ACT 2601, Australia.
C3 University of California System; University of California San Diego;
   Australian National University
RP Sikka, K (corresponding author), Univ Calif San Diego, 9450 Gilman Dr 0440, La Jolla, CA 92093 USA.
EM ksikka@ucsd.edu; abhinav.dhall@anu.edu.au; mbartlett@ucsd.edu
RI Jha, Susmit/B-4838-2013; Dhall, Abhinav/AAF-4347-2019
OI Dhall, Abhinav/0000-0002-2230-1440
FU NSF [IIS-0905622]; NIH [NIH R01NR013500]
FX Support for this work was provided by NSF grant IIS-0905622 and NIH
   grant NIH R01NR013500. Any opinions, findings, conclusions or
   recommendations expressed in this material are those of the author(s)
   and do not necessarily reflect the views of the National Science
   Foundation. We would also like to thank Tingfan Wu, Gwen Littlewort,
   Mohsen Malmir, Deborah Forster and Ritwik Giri for helpful discussions.
CR [Anonymous], 2008, WORKSH FAC INR LIF D
   [Anonymous], 2013, CVPR
   Ashraf AB, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P9
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Cornelius R.R., 1996, SCI EMOTION RES TRAD
   CRAIG KD, 1991, PAIN, V46, P161, DOI 10.1016/0304-3959(91)90071-5
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Galleguillos C, 2008, LECT NOTES COMPUT SC, V5302, P193, DOI 10.1007/978-3-540-88682-2_16
   Huang J., 2014, PED AC SOC ANN M
   Kendall MG, 1938, BIOMETRIKA, V30, P81, DOI 10.2307/2332226
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Leung T, 2011, IEEE I CONF COMP VIS, P2056, DOI 10.1109/ICCV.2011.6126479
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lucey P.J., 2008, PATCH BASED ANAL VIS
   Lynch Mary E., 2010, CLIN PAIN MANAGEMENT
   Poggio Tomaso., 2002, Bagging regularizes
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Potamianos G., 2001, International Journal of Speech Technology, V4, P193, DOI 10.1023/A:1011352422845
   Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010
   Saeed Anwar, 2013, 2013 IEEE International Conference on Cybernetics (CYBCO), P122, DOI 10.1109/CYBConf.2013.6617455
   Serre T, 2005, PROC CVPR IEEE, P994
   Sikka K, 2012, LECT NOTES COMPUT SC, V7584, P250, DOI 10.1007/978-3-642-33868-7_25
   Simon T, 2010, PROC CVPR IEEE, P2737, DOI 10.1109/CVPR.2010.5539998
   Tax D. M. J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2917, DOI 10.1109/ICPR.2010.715
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Tian YL, 2005, HANDBOOK OF FACE RECOGNITION, P247, DOI 10.1007/0-387-27257-7_12
   Turk D.C., 2010, Handbook of pain assessment
   Turk DC, 2004, ARTHRITIS RES THER, V6, P151, DOI 10.1186/ar1196
   Viola P., 2006, Proceedings of Advances in Neural Information Processing Systems, V18, P1417
   Wallhoff Frank., 2004, Feedtum facial expression and emotion dataset
   Wang G., 2006, CVPR, P1597
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wohlhart Paul, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P132, DOI 10.1007/978-3-642-23123-0_14
   Xingxing Wang, 2013, Computer Vision - ACCV 2012. 11th Asian Conference on Computer Vision. Revised Selected Papers, P572, DOI 10.1007/978-3-642-37431-9_44
NR 41
TC 43
Z9 49
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 659
EP 670
DI 10.1016/j.imavis.2014.02.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700005
PM 25242853
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Arnay, R
   Acosta, L
AF Arnay, Rafael
   Acosta, Leopoldo
TI Contour-based focus of attention mechanism to speed up object detection
   and labeling in 3D scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D contour-based features; Object center voting; Focus of attention
ID RECOGNITION; MODEL
AB In this paper, a contour-based focus of attention approach is presented. Fast to compute, contour based features are extracted from 3D scenes and matched to model parts of objects. Local reference frames associated with the features induce a translation and rotation, resulting in a vote being cast for the presence of the object in a certain position within the scene. In these positions, HoG features are extracted and SVM classification is applied. Detection results and computation times are compared to those corresponding to a sliding window approach. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Arnay, Rafael; Acosta, Leopoldo] Univ La Laguna, Dept Syst Engn & Automat, San Cristobal la Laguna 38205, Santa Cruz De T, Spain.
C3 Universidad de la Laguna
RP Arnay, R (corresponding author), Univ La Laguna, Dept Syst Engn & Automat, C Astroffs Francisco Sanchez S-N, San Cristobal la Laguna 38205, Santa Cruz De T, Spain.
EM rafa@isaatc.ull.es
RI Arnay, Rafael/M-1738-2014; Arnay, Rafael/AAY-4737-2020; Acosta Sanchez,
   Leopoldo/I-5110-2015
OI Arnay, Rafael/0000-0002-9074-0488; Acosta Sanchez,
   Leopoldo/0000-0001-9428-4507
FU Spanish Ministry of Science and Technology [DPI2010-18349,
   DPI2013-46897]; Agencia Canaria de Investigacion, Innovacion y Sociedad
   de la Informacion (ACIISI)
FX The authors gratefully acknowledge the contribution of the Spanish
   Ministry of Science and Technology under Projects DPI2010-18349,
   DPI2013-46897 and the funds from the Agencia Canaria de Investigacion,
   Innovacion y Sociedad de la Informacion (ACIISI).
CR [Anonymous], PROBABILISTIC TRACKI
   [Anonymous], INT J COMPUT VIS
   [Anonymous], BRIT MACH VIS C
   [Anonymous], P 22 IEEE RSJ INT C
   [Anonymous], COMP VIS 2003 P 9 IE
   [Anonymous], 2011, P IEEE INT C ROB AUT
   [Anonymous], ROBOTIK 2012 P 7 GER
   [Anonymous], COMP VIS PATT REC 19
   [Anonymous], P 18 INT C IM PROC I
   [Anonymous], COMP VIS 1998 6 INT
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], P IEEE INT C COMP VI
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berg AC, 2005, PROC CVPR IEEE, P26
   Chen H, 2007, PATTERN RECOGN LETT, V28, P1252, DOI 10.1016/j.patrec.2007.02.009
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fergus R, 2004, LECT NOTES COMPUT SC, V3021, P242
   Ferrari V, 2008, IEEE T PATTERN ANAL, V30, P36, DOI 10.1109/TPAMI.2007.1144
   Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9
   Glasner D, 2012, IMAGE VISION COMPUT, V30, P923, DOI 10.1016/j.imavis.2012.09.006
   Johnson AE, 1998, IMAGE VISION COMPUT, V16, P635, DOI 10.1016/S0262-8856(98)00074-2
   Knopp J, 2010, LECT NOTES COMPUT SC, V6316, P589, DOI 10.1007/978-3-642-15567-3_43
   Lai KV, 2012, IEEE INT CONF ROBOT, P1330, DOI 10.1109/ICRA.2012.6225316
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145
   Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Novatnack J., 2007, COMPUTER VISION 2007, P1
   Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33
   Opelt A, 2006, LECT NOTES COMPUT SC, V3952, P575
   Rusu R. B., 2009, P IEEE INT C ROB AUT
   Shotton J, 2005, IEEE I CONF COMP VIS, P503
   STEIN F, 1992, IEEE T PATTERN ANAL, V14, P125, DOI 10.1109/34.121785
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   Tombari F., 2010, P 11 EUR C COMP VIS
   Tombari Federico, 2010, 2010 Fourth Pacific-Rim Symposium on Image and Video Technology, P349, DOI DOI 10.1109/PSIVT.2010.65
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang YJ, 2005, IMAGE VISION COMPUT, V23, P1018, DOI 10.1016/j.imavis.2005.07.005
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
NR 43
TC 2
Z9 2
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2014
VL 32
IS 5
BP 303
EP 320
DI 10.1016/j.imavis.2014.02.013
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AH3HI
UT WOS:000336013900001
DA 2024-07-18
ER

PT J
AU Zografos, V
   Lenz, R
   Felsberg, M
AF Zografos, Vasileios
   Lenz, Reiner
   Felsberg, Michael
TI The Weibull manifold in low-level image processing: An application to
   automatic image focusing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Weibull distribution; Image processing; Weibull manifold; Image
   autofocus
ID AUTOFOCUS ALGORITHM; EXTREME-VALUE; ASTIGMATISM
AB In this paper, we introduce a novel framework for low-level image processing and analysis. First, we process images with very simple, difference-based filter functions. Second, we fit the 2-parameter Weibull distribution to the filtered output. This maps each image to the 2D Weibull manifold. Third, we exploit the information geometry of this manifold and solve low-level image processing tasks as minimisation problems on point sets. For a proof-of-concept example, we examine the image autofocusing task. We propose appropriate cost functions together with a simple implicitly-constrained manifold optimisation algorithm and show that our framework compares very favourably against common autofocus methods from literature. In particular, our approach exhibits the best overall performance in terms of combined speed and accuracy. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Zografos, Vasileios; Lenz, Reiner; Felsberg, Michael] Linkoping Univ, Dept Elect Engn, Comp Vis Lab, SE-58183 Linkoping, Sweden.
C3 Linkoping University
RP Zografos, V (corresponding author), Linkoping Univ, Dept Elect Engn, Comp Vis Lab, SE-58183 Linkoping, Sweden.
EM zografos@isy.liu.se; reiner.lenz@liu.se; michael.felsberg@liu.se
OI Felsberg, Michael/0000-0002-6096-3648; Lenz, Reiner/0000-0001-7557-4904
FU ECs 7th Framework Programme [247947]; Swedish Foundation for Strategic
   Research [IIS11-0081]; Swedish Research Council
FX This work was supported with funding from the ECs 7th Framework
   Programme (FP7/2007-2013), grant agreement 247947 (GARNICS); by the
   Swedish Foundation for Strategic Research through grant IIS11-0081; and
   from the Swedish Research Council through a grant for the project
   Extended Target Tracking (within the Linnaeus environment CADICS).
CR Amari S.-i., 2000, METHODS INFORM GEOME, DOI DOI 10.1090/MMONO/191
   Bertin E, 2006, J PHYS A-MATH GEN, V39, P7607, DOI 10.1088/0305-4470/39/24/001
   Bhagavathy S., 2003, INT C IM PROC
   Boddeke F. R., 1994, Bioimaging, V2, P193, DOI 10.1002/1361-6374(199412)2:4<193::AID-BIO4>3.3.CO;2-C
   Bray MA, 2012, J BIOMOL SCREEN, V17, P266, DOI 10.1177/1087057111420292
   BRENNER JF, 1976, J HISTOCHEM CYTOCHEM, V24, P100, DOI 10.1177/24.1.1254907
   BROWN WK, 1989, J ASTROPHYS ASTRON, V10, P89, DOI 10.1007/BF02714980
   Canon Inc, DIG EOS SDK DIG IM D
   Cao LM, 2008, TAMKANG J MATH, V39, P45, DOI 10.5556/j.tkjm.39.2008.44
   Chen CM, 2006, IEEE T CONSUM ELECTR, V52, P1135, DOI 10.1109/TCE.2006.273125
   Chen CY, 2010, APPL SOFT COMPUT, V10, P296, DOI 10.1016/j.asoc.2009.07.007
   Choi KS, 1999, IEEE T CONSUM ELECTR, V45, P820, DOI 10.1109/30.793616
   ERASMUS SJ, 1982, J MICROSC-OXFORD, V127, P185, DOI 10.1111/j.1365-2818.1982.tb00412.x
   Evans M., 2001, WILEY SERIES PROBABI
   Fisher RA, 1925, P CAMB PHILOS SOC, V22, P700, DOI 10.1017/S0305004100009580
   Flannery B. P., 1992, NUMERICAL RECIPES C, DOI DOI 10.2277/052143064X
   Geusebroek JM, 2005, LECT NOTES COMPUT SC, V3459, P327
   Geusebroek JM, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P130
   Geusebroek JM, 2000, CYTOMETRY, V39, P1
   Goodman J. W., 1996, INTRO FOURIER OPTICS, V2nd
   GROEN FCA, 1985, CYTOMETRY, V6, P81, DOI 10.1002/cyto.990060202
   Gumbel E. J., 1958, Statistics of Extremes
   Han JW, 2011, IEEE T CONSUM ELECTR, V57, P232, DOI 10.1109/TCE.2011.5735507
   He J, 2003, IEEE T CONSUM ELECTR, V49, P257, DOI 10.1109/TCE.2003.1209511
   JUTAMULIA S, 1994, APPL OPTICS, V33, P6210, DOI 10.1364/AO.33.006210
   Kehtarnavaz N, 2003, REAL-TIME IMAGING, V9, P197, DOI 10.1016/S1077-2014(03)00037-8
   Lee SY, 2008, IEEE T CIRC SYST VID, V18, P1237, DOI 10.1109/TCSVT.2008.924105
   Lenz Reiner, 2012, CGIV 2012. 6th European Conference on Colour in Graphics, Imaging, and Vision, P200
   LENZ R, 1995, J VIS COMMUN IMAGE R, V6, P209, DOI 10.1006/jvci.1995.1019
   Lenz R., 2005, P ICIP 05
   Lenz R., 2012, ADV COLOR IMAGE PROC
   Lenz R, 2013, LECT NOTES COMPUT SC, V7786, P250, DOI 10.1007/978-3-642-36700-7_20
   NAYAR SK, 1994, IEEE T PATTERN ANAL, V16, P824, DOI 10.1109/34.308479
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   OLLER JM, 1987, SANKHYA SER A, V49, P17
   Ong KH, 1997, SCANNING, V19, P553, DOI 10.1002/sca.4950190805
   Rao C. R., 1945, B CALCUTTA MATH SOC, V37, P81, DOI [DOI 10.1007/978-1-4612-0919-5_15, DOI 10.1007/978-1-4612-0919-516]
   Rinne H., 2008, WEIBULL DISTRIBUTION, DOI [10.1201/9781420087444, DOI 10.1201/9781420087444]
   Rudnaya ME, 2012, J MATH IMAGING VIS, V44, P38, DOI 10.1007/s10851-011-0309-8
   Rudnaya ME, 2011, ULTRAMICROSCOPY, V111, P1043, DOI 10.1016/j.ultramic.2011.01.034
   Rudnaya M, 2011, LECT NOTES ENG COMP, P301
   Russell S., 2016, Artificial intelligence a modern approach
   Subbarao M, 1998, IEEE T PATTERN ANAL, V20, P864, DOI 10.1109/34.709612
   Tanaka N, 1999, ULTRAMICROSCOPY, V78, P103, DOI 10.1016/S0304-3991(99)00016-9
   Tenenbaum J.M., 1971, THESIS STANFORD U ST
   VOLLATH D, 1987, J MICROSC-OXFORD, V147, P279, DOI 10.1111/j.1365-2818.1987.tb02839.x
   Yang G, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2143
   Yanulevskaya V., 2008, SALIENT REGION DETEC
   Zografos V, 2011, LECT NOTES COMPUT SC, V6688, P579, DOI 10.1007/978-3-642-21227-7_54
NR 49
TC 7
Z9 8
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2013
VL 31
IS 5
BP 401
EP 417
DI 10.1016/j.imavis.2013.03.004
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 154YR
UT WOS:000319713100004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lin, HY
   Gu, KD
   Chang, CH
AF Lin, Huei-Yung
   Gu, Kai-Da
   Chang, Chia-Hong
TI Photo-consistent synthesis of motion blur and depth-of-field effects
   with a real camera model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth-of-field; Motion blur; Image synthesis
ID IMAGE; CALIBRATION; FUSION
AB Depth-of-field (DOF) and motion blur are important visual cues used for computer graphics and photography to illustrate focus of attention and object motion. In this work, we present a method for photo-realistic DOF and motion blur generation based on the characteristics of a real camera system. Both the depth-blur relation for different camera focus settings and the nonlinear intensity response of image sensors are modeled. The camera parameters are calibrated and used for defocus and motion blur synthesis. For a well-focused real scene image. DOF and motion blur effects are generated by post-processing techniques. Experiments have shown that the proposed method generates more photo-consistent results than the commonly used graphical models. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Lin, Huei-Yung] Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
   Natl Chung Cheng Univ, Adv Inst Mfg Hightech Innovat, Chiayi 621, Taiwan.
C3 National Chung Cheng University; National Chung Cheng University
RP Lin, HY (corresponding author), Natl Chung Cheng Univ, Dept Elect Engn, Chiayi 621, Taiwan.
EM lin@ee.ccu.edu.tw
RI Lin, Huei-Yung/H-2949-2012
FU National Science Council of Taiwan, R.O.C [NSC-96-2221-E-194-016-MY2]
FX This work is supported in part by the National Science Council of
   Taiwan, R.O.C, under Grant NSC-96-2221-E-194-016-MY2.
CR Agusanto K, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P208, DOI 10.1109/ISMAR.2003.1240704
   [Anonymous], DEPTH DEFOCUS REAL A
   Azuma R, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.963459
   Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   Berger M.-O., 1997, Computer Vision - ACCV '98. Third Asian Conference on Computer Vision. Proceedings, P360
   Brostow GJ, 2001, COMP GRAPH, P561, DOI 10.1145/383259.383325
   Cook R. L., 1984, Computers & Graphics, V18, P137
   Dachille F, 2000, COMP ANIM CONF PROC, P49, DOI 10.1109/CA.2000.889034
   De I, 2006, IMAGE VISION COMPUT, V24, P1278, DOI 10.1016/j.imavis.2006.04.005
   Debevec P., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P189, DOI 10.1145/280814.280864
   Debevec P. E., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P369, DOI 10.1145/258734.258884
   Egan K, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531399
   Favaro P, 2003, PROC CVPR IEEE, P579
   Goshtasby AA, 2005, IMAGE VISION COMPUT, V23, P611, DOI 10.1016/j.imavis.2005.02.004
   Haeberli P., 1990, Computer Graphics, V24, P309, DOI 10.1145/97880.97913
   Heidrich W, 1997, PROC GRAPH INTERF, P68
   Jacobs K, 2006, COMPUT GRAPH FORUM, V25, P29, DOI 10.1111/j.1467-8659.2006.00816.x
   Kolb C., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P317, DOI 10.1145/218380.218463
   Kutulakos KN, 1998, IEEE T VIS COMPUT GR, V4, P1, DOI 10.1109/2945.675647
   Lengyel J, 1998, COMPUTER, V31, P46, DOI 10.1109/2.689676
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Max N. L., 1985, Computer Graphics, V19, P85, DOI 10.1145/325165.325188
   Meinds K, 2003, VISION, MODELING, AND VISUALIZATION 2003, P337
   Mueller K, 1998, IEEE T VIS COMPUT GR, V4, P178, DOI 10.1109/2945.694987
   Mulder J.D., 2000, P ACM S VIRTUAL REAL, P129
   Ortiz A, 2006, IMAGE VISION COMPUT, V24, P1137, DOI 10.1016/j.imavis.2006.04.003
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Potmesil M., 1981, Computer Graphics, V15, P297, DOI 10.1145/965161.806818
   Potmesil M., 1983, Computer Graphics, V17, P389, DOI 10.1145/964967.801169
   Rokita P, 1996, IEEE COMPUT GRAPH, V16, P18, DOI 10.1109/38.486676
   Rush A., NONLINEAR SENSORS IM
   Schanz M, 2000, IEEE J SOLID-ST CIRC, V35, P932, DOI 10.1109/4.848200
   Schreiber WF., 1993, Fundamentals of electronic imaging systems : some aspects of image processing, V3rd
   Scofield B., 1992, GRAPHICS GEMS, P36
   Sung K, 2002, IEEE T VIS COMPUT GR, V8, P144, DOI 10.1109/2945.998667
   Wloka MM, 1996, VISUAL COMPUT, V12, P283
NR 36
TC 6
Z9 6
U1 0
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2012
VL 30
IS 9
BP 605
EP 618
DI 10.1016/j.imavis.2012.07.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 024EV
UT WOS:000310092600002
DA 2024-07-18
ER

PT J
AU García-Martín, A
   Martínez, JM
AF Garcia-Martin, Alvaro
   Martinez, Jose M.
TI On collaborative people detection and tracking in complex scenarios
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE People detection; People tracking; Collaborative system; Video
   surveillance
ID MOTION; VIDEO; SURVEILLANCE; FEATURES; COLOR
AB The main contributions of this paper covers two different aspects: people detection and tracking. A whole detection/tracking system that integrates appearance, motion and tracking information is presented. This system uses the information provided by each of the independent tasks to improve the final result of the system. The tracking information is integrated in the detection task improving the detection results and vice versa. The experimental results over an extensive and challenging video dataset point out the state of the art limitations in complex or realistic scenarios, and show that the proposed collaborative system significantly reduces these limitations and improves the results in this kind of scenarios. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Garcia-Martin, Alvaro; Martinez, Jose M.] Univ Autonoma Madrid, Escuela Politecn Super, Video Proc & Understanding Lab, E-28049 Madrid, Spain.
C3 Autonomous University of Madrid
RP García-Martín, A (corresponding author), Univ Autonoma Madrid, Escuela Politecn Super, Video Proc & Understanding Lab, E-28049 Madrid, Spain.
EM alvaro.garcia@uam.es; josem.martinez@uam.es
RI Garcia-Martin, Alvaro/C-8138-2014; Garcia-Martin, Alvaro/P-8502-2019;
   Martinez, Jose/A-1185-2008
OI Garcia-Martin, Alvaro/0000-0002-1705-3972; Garcia-Martin,
   Alvaro/0000-0002-1705-3972; Martinez, Jose/0000-0002-2236-1769
FU Universidad Autonoma de Madrid; Spanish Goverment [TEC2011-25995
   EventVideo]
FX This work has been partially supported by the Universidad Autonoma de
   Madrid ("FPI-UAM: Programa propio de ayudas para la Formacion de
   Personal Investigador") and by the Spanish Goverment (TEC2011-25995
   EventVideo).
CR Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   [Anonymous], TRECV 2008 EV SURV E
   [Anonymous], P ECCV
   [Anonymous], 2008, P CVPR
   [Anonymous], 2008, P 2008 IEEE C COMP V, DOI DOI 10.1109/CVPR.2008.4587533
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], MITCSAILTR2008 MIT
   [Anonymous], 2005, Computer Vision and Pattern Recognition-Workshops
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Chen M.-Y., 2009, Tech. Rep. CMU-CS- 09-161
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cremers D, 2003, IMAGE VISION COMPUT, V21, P77, DOI 10.1016/S0262-8856(02)00128-2
   Cutler R, 2000, IEEE T PATTERN ANAL, V22, P781, DOI 10.1109/34.868681
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Denman S, 2007, PATTERN RECOGN LETT, V28, P1232, DOI 10.1016/j.patrec.2007.02.008
   Ess A, 2009, IEEE T PATTERN ANAL, V31, P1831, DOI 10.1109/TPAMI.2009.109
   Garcia-Martin A., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P256, DOI 10.1109/AVSS.2011.6027333
   Garcia-Martin Alvaro, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P241, DOI 10.1109/AVSS.2010.33
   García-Martín A, 2012, PATTERN RECOGN LETT, V33, P152, DOI 10.1016/j.patrec.2011.09.038
   Giebel J, 2004, LECT NOTES COMPUT SC, V2034, P241
   Haering N, 2008, MACH VISION APPL, V19, P279, DOI 10.1007/s00138-008-0152-0
   Haritaoglu I, 1998, INT C PATT RECOG, P77, DOI 10.1109/ICPR.1998.711084
   Jepson AD, 2003, IEEE T PATTERN ANAL, V25, P1296, DOI 10.1109/TPAMI.2003.1233903
   Jie Yu, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P406, DOI 10.1007/978-3-642-23123-0_41
   Leibe B., 2007, PROC 205, P1
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Li Y, 2008, IEEE T PATTERN ANAL, V30, P1728, DOI 10.1109/TPAMI.2008.73
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Regazzoni CS, 2010, IEEE SIGNAL PROC MAG, V27, P16, DOI 10.1109/MSP.2010.937451
   Sidenbladh H, 2004, INT C PATT RECOG, P188, DOI 10.1109/ICPR.2004.1334092
   Viola P, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P734
   Wang JQ, 2008, IEEE T IMAGE PROCESS, V17, P235, DOI 10.1109/TIP.2007.914150
   Wojek C, 2009, PROC CVPR IEEE, P794, DOI 10.1109/CVPRW.2009.5206638
   Wu B, 2005, IEEE I CONF COMP VIS, P90
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Xu FL, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P115, DOI 10.1109/AVSS.2003.1217910
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 42
TC 14
Z9 14
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2012
VL 30
IS 4-5
BP 345
EP 354
DI 10.1016/j.imavis.2012.03.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 964WF
UT WOS:000305726700007
DA 2024-07-18
ER

PT J
AU Zhang, D
   He, JZ
   Du, MH
AF Zhang, Di
   He, Jiazhong
   Du, Minghui
TI Morphable model space based face super-resolution reconstruction and
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Super-resolution; Feature space; Image sequence; Image reconstruction
ID IMAGE-RECONSTRUCTION; ALGORITHM
AB Super-resolution image reconstruction is the process of producing a high-resolution image from a set of low-resolution images of the same scene. For the applications of performing face evaluation and/or recognition from low-resolution video surveillance, in the past, super-resolution image reconstruction was mainly used as a separate preprocessing step to obtain a high-resolution image in the pixel domain that is later passed to a face feature extraction and recognition algorithm. Such three-stage approach suffers a high degree of computational complexity. A low-dimensional morphable model space based face super-resolution reconstruction and recognition algorithm is proposed in this paper. The approach tries to construct the high-resolution information both required by reconstruction and recognition directly in the low dimensional feature space. We show that comparing with generic pixel domain algorithms, the proposed approach is more robust and more computationally efficient. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Zhang, Di; Du, Minghui] S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510641, Guangdong, Peoples R China.
   [Zhang, Di] Shaoguan Univ, Dept Comp Sci, Shaoguan 512005, Guangdong, Peoples R China.
   [He, Jiazhong] Shaoguan Univ, Dept Phys, Shaoguan 512005, Guangdong, Peoples R China.
C3 South China University of Technology; Shaoguan University; Shaoguan
   University
RP Zhang, D (corresponding author), S China Univ Technol, Sch Elect & Informat Engn, Guangzhou 510641, Guangdong, Peoples R China.
EM changnuode@163.com
FU National Nature Science Foundation of China [60772117]; Natural Science
   Foundation of Guangdong Province, China [07006491]
FX This research is supported by the National Nature Science Foundation of
   China (Research Grant # 60772117) and the Natural Science Foundation of
   Guangdong Province, China (Research Grant # 07006491).
CR [Anonymous], ORL DAT FAC
   [Anonymous], 2008, 2008 IEEE C COMP VIS
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Capel D, 2001, PROC CVPR IEEE, P627
   Chakrabarti A, 2007, IEEE T MULTIMEDIA, V9, P888, DOI 10.1109/TMM.2007.893346
   Elad M, 1997, IEEE T IMAGE PROCESS, V6, P1646, DOI 10.1109/83.650118
   Elad M, 2001, IEEE T IMAGE PROCESS, V10, P1187, DOI 10.1109/83.935034
   Farsiu S, 2004, IEEE T IMAGE PROCESS, V13, P1327, DOI 10.1109/TIP.2004.834669
   Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513
   Hardie RC, 1998, OPT ENG, V37, P247, DOI 10.1117/1.601623
   Hwang BW, 2003, IEEE T PATTERN ANAL, V25, P365, DOI 10.1109/TPAMI.2003.1182099
   Ji H, 2009, IEEE T PATTERN ANAL, V31, P649, DOI 10.1109/TPAMI.2008.103
   Jones MJ, 1998, INT J COMPUT VISION, V29, P107, DOI 10.1023/A:1008074226832
   Li B, 2010, IEEE SIGNAL PROC LET, V17, P20, DOI 10.1109/LSP.2009.2031705
   Liu C, 2001, PROC CVPR IEEE, P192
   Miravet C, 2007, IMAGE VISION COMPUT, V25, P1449, DOI 10.1016/j.imavis.2006.12.016
   Nguyen N, 2001, IEEE T IMAGE PROCESS, V10, P573, DOI 10.1109/83.913592
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Patti AJ, 2001, IEEE T IMAGE PROCESS, V10, P179, DOI 10.1109/83.892456
   Protter M, 2009, IEEE T IMAGE PROCESS, V18, P36, DOI 10.1109/TIP.2008.2008067
   Schultz RR, 1996, IEEE T IMAGE PROCESS, V5, P996, DOI 10.1109/83.503915
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   Sim T., 2001, CMU POSE ILLUMINATIO
   Tsai R.Y., 1984, Proc. Inst Elect Eng, V1, P317
   Wang ZF, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1569, DOI 10.1109/ICME.2008.4607748
   Zhang D, 2005, IMAGE VISION COMPUT, V23, P671, DOI 10.1016/j.imavis.2005.03.004
   Zhang D., 2005, OPTICAL ENG, V44, P1
NR 29
TC 20
Z9 20
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2012
VL 30
IS 2
BP 100
EP 108
DI 10.1016/j.imavis.2012.01.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 934ZJ
UT WOS:000303486200004
DA 2024-07-18
ER

PT J
AU Thi, TH
   Cheng, L
   Zhang, J
   Wang, L
   Satoh, S
AF Tuan Hue Thi
   Cheng, Li
   Zhang, Jian
   Wang, Li
   Satoh, Shinichi
TI Structured learning of local features for human action classification
   and localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Action localization; Structured Learning; Local
   spatio-temporal features; Hierarchical sparse Bayesian filter; Support
   vector machine; Dynamic conditional random fields; Structural support
   vector machine
ID RECOGNITION
AB Human action recognition is a promising yet non-trivial computer vision field with many potential applications. Current advances in bag-of-feature approaches have brought significant insights into recognizing human actions within complex context. It is, however, a common practice in literature to consider action as merely an orderless set of local salient features. This representation has been shown to be oversimplified, which inherently limits traditional approaches from robust deployment in real-life scenarios. In this work, we propose and show that, by taking into account global configuration of local features, we can greatly improve recognition performance. We first introduce a novel feature selection process called Sparse Hierarchical Bayes Filter to select only the most contributive features of each action type based on neighboring structure constraints. We then present the application of structured learning in human action analysis. That is, by representing human action as a complex set of local features, we can incorporate different spatial and temporal feature constraints into the learning tasks of human action classification and localization. In particular, we tackle the problem of action localization in video using structured learning with two alternatives: one is Dynamic Conditional Random Field from probabilistic perspective; the other is Structural Support Vector Machine from max-margin point of view. We evaluate our modular classification-localization framework on various testbeds, in which our proposed framework is proven to be highly effective and robust compared against bag-of-feature methods. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Tuan Hue Thi; Zhang, Jian] Natl ICI Australia, Kensington, NSW 2033, Australia.
   [Tuan Hue Thi] Univ New S Wales, Sch Comp Sci, Sydney, NSW 2052, Australia.
   [Zhang, Jian] Univ Technol Sydney, Fac Engn & Informat Technol, Sydney, NSW 2007, Australia.
   [Cheng, Li] ASTAR, Bioinformat Inst, Singapore, Singapore.
   [Wang, Li] Nanjing Forest Univ, Nanjing, Peoples R China.
C3 University of New South Wales Sydney; University of Technology Sydney;
   Agency for Science Technology & Research (A*STAR); A*STAR -
   Bioinformatics Institute (BII); Nanjing Forestry University
RP Thi, TH (corresponding author), Natl ICI Australia, 223 Anzac Parade, Kensington, NSW 2033, Australia.
EM TuanHue.Thi@nicta.com.au; chengli@bii.a-star.edu.sg;
   Jian.Zhang@nicta.com.au; wang.li.seu.nj@gmail.com; satoh@nii.ac.jp
RI Cheng, Li/AAU-6734-2020; Wang, Li/G-7123-2015
OI Cheng, Li/0000-0003-3261-3533; Wang, Li/0000-0002-5079-8992; Zhang,
   Jian/0000-0002-7240-3541
FU Australian Government; Australian Research Council through the ICT
   Centre of Excellence
FX NICTA is funded by the Australian Government as represented by the
   Department of Broadband, Communications and the Digital Economy and the
   Australian Research Council through the ICT Centre of Excellence
   program.
CR Abdel-Hamid MK, 2009, J ENZYM INHIB MED CH, V24, P722, DOI 10.1080/14756360802361514
   Ahmad M, 2008, PATTERN RECOGN, V41, P2237, DOI 10.1016/j.patcog.2007.12.008
   ALEXANDER K, 2004, LAB INVESTIGATION J, V84
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], 2008, P IEEE C COMP VIS PA
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2009, BMVC
   [Anonymous], P INT C COMP VIS
   [Anonymous], 2009, P IEEE C COMP VIS PA
   [Anonymous], 2001, P INT C MACH LEARN
   [Anonymous], P INT C PATT REC
   [Anonymous], P C COMP VIS PATT RE
   [Anonymous], INT J COMPUTER VISIO
   [Anonymous], 2005, ICCV
   [Anonymous], 2008, CVPR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2009, P IEEE C COMP VIS PA
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Carbonetto P, 2008, INT J COMPUT VISION, V77, P219, DOI 10.1007/s11263-007-0067-7
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DOLLAR P, INT C COMP VIS VS PE
   Dollar Piotr., 2005, PETS
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   GORELICK L, 1999, SHAPE REPRESENTATION, V2
   GORELICK L, 2004, SHAPE REPRESENTATION, V2
   GRUNDMANN M, 2008, P IEEE C COMP VIS PA
   GUO F, 2008, J IMAGE VIDEO PROCES, P4
   Harris C., 1988, P ALV VIS C, P5210
   JIANG H., 2006, P IEEE C COMP VIS PA
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Kadir T., 2003, International Conference on Visual Information Engineering (VIE 2003) (IEE Conf. Publ.No.495), P25, DOI 10.1049/cp:20030478
   KE Y, 2007, P INT C COMP VIS
   Ke Yan., 2007, ICCV
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   KUCK H, 2004, CONSTRAINED SEMISUPE
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   LAPTEV I, 2008, P IEEE C COMPUTER VI, V1, P20
   Lin Z, 2009, IEEE I CONF COMP VIS, P444
   LITCHFIELD JT, 1955, ANAL CHEM, V27, P299, DOI 10.1021/ac60098a038
   Liu J., 2008, IEEE COMP SOC C COMP
   Matikainen Pyry, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P514, DOI 10.1109/ICCVW.2009.5457659
   Moon HI, 2009, J ENZYM INHIB MED CH, V24, P328, DOI [10.1080/14756360802185731, 10.1080/14756360802185731 ]
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Oikonomopoulos A, 2011, IEEE T IMAGE PROCESS, V20, P1126, DOI 10.1109/TIP.2010.2076821
   Ramanan D, 2007, IEEE T PATTERN ANAL, V29, P65, DOI 10.1109/TPAMI.2007.250600
   Raptis M, 2010, LECT NOTES COMPUT SC, V6311, P577, DOI 10.1007/978-3-642-15549-9_42
   Scholkopf B., 1997, Artificial Neural Networks - ICANN '97. 7th International Conference Proceedings, P583, DOI 10.1007/BFb0020217
   Smeaton AlanF., 2006, MIR
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   SUN X, 2009, P IEEE C COMP VIS PA
   THAM SS, 2002, P INT C MACH LEARN
   THI T, 2010, 2010 INT C PATT REC, P3517
   Thi TH, 2010, IEEE IMAGE PROC, P1477, DOI 10.1109/ICIP.2010.5652843
   Tsochantaridis I., 2004, ICML, P104
   Tuan Hue Thi, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P204, DOI 10.1109/AVSS.2010.76
   Wang Y., 2006, IEEE Trans. Pattern Analysis and Machine Intelligence
   Wang Y, 2009, IEEE T PATTERN ANAL, V31, P1762, DOI 10.1109/TPAMI.2009.43
   WEINLAND D, 2008, IEEE C COMP VIS PATT, V13
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   WILLEMS G, 2008, EUROPEAN C COMPUTER, V23, P650
   Yeffet L, 2009, IEEE I CONF COMP VIS, P492, DOI 10.1109/ICCV.2009.5459201
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zelnik-Manor L, 2001, PROC CVPR IEEE, P123
NR 68
TC 19
Z9 21
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2012
VL 30
IS 1
BP 1
EP 14
DI 10.1016/j.imavis.2011.12.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900WC
UT WOS:000300921400001
DA 2024-07-18
ER

PT J
AU Nguyen, TM
   Wu, QMJ
AF Thanh Minh Nguyen
   Wu, Q. M. Jonathan
TI Dirichlet Gaussian mixture model: Application to image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dirichlet Gaussian mixture model; Dirichlet distribution; Spatial
   constraints; Gradient method; Image segmentation
ID RANDOM-FIELD MODEL; EM PROCEDURES; CLASSIFICATION; ALGORITHMS
AB Gaussian mixture model based on the Dirichlet distribution (Dirichlet Gaussian mixture model) has recently received great attention for modeling and processing data. This paper studies the new Dirichlet Gaussian mixture model for image segmentation. First, we propose a new way to incorporate the local spatial information between neighboring pixels based on the Dirichlet distribution. The main advantage is its simplicity, ease of implementation and fast computational speed. Secondly, existing Dirichlet Gaussian model uses complex log-likelihood function and require many parameters that are difficult to estimate. The total parameters in the proposed model lesser and the log-likelihood function have a simpler form. Finally, to estimate the parameters of the proposed Dirichlet Gaussian mixture model, a gradient method is adopted to minimize the negative log-likelihood function. Numerical experiments are conducted using the proposed model on various synthetic, natural and color images. We demonstrate through extensive simulations that the proposed model is superior to other algorithms based on the model-based techniques for image segmentation. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Thanh Minh Nguyen; Wu, Q. M. Jonathan] Univ Windsor, Dept Elect & Comp Engn, Windsor, ON N9B 3P4, Canada.
C3 University of Windsor
RP Nguyen, TM (corresponding author), Univ Windsor, Dept Elect & Comp Engn, 401 Sunset Ave, Windsor, ON N9B 3P4, Canada.
EM nguyen1j@uwindsor.ca; jwu@uwindsor.ca
RI Wu, Q.M.Jonathan/O-3234-2017; cai, bo/G-1491-2010
FU Canada Research Chair Program; AUTO21 NCE; NSERC
FX This research has been supported in part by the Canada Research Chair
   Program, AUTO21 NCE, and the NSERC Discovery grant.
CR [Anonymous], 2008, PASCAL 2008 RESULTS
   [Anonymous], THESIS U WASHINGTON
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Arbeláez P, 2009, PROC CVPR IEEE, P2294, DOI 10.1109/CVPRW.2009.5206707
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blekas K, 2005, IEEE T NEURAL NETWOR, V16, P494, DOI 10.1109/TNN.2004.841773
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Cai WL, 2007, PATTERN RECOGN, V40, P825, DOI 10.1016/j.patcog.2006.07.011
   Carreira-Perpin M., 2006, P 23 INT C MACH LEAR, P153, DOI DOI 10.1145/1143844.1143864
   Celeux G, 2003, PATTERN RECOGN, V36, P131, DOI 10.1016/S0031-3203(02)00027-4
   Chatzis SP, 2008, IEEE T FUZZY SYST, V16, P1351, DOI 10.1109/TFUZZ.2008.2005008
   Cheng J, 2006, IMAGE VISION COMPUT, V24, P473, DOI 10.1016/j.imavis.2006.01.018
   CHOI HS, 1991, IEEE T MED IMAGING, V10, P395, DOI 10.1109/42.97590
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cour T, 2005, PROC CVPR IEEE, P1124
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Diplaros A, 2007, IEEE T NEURAL NETWOR, V18, P798, DOI 10.1109/TNN.2007.891190
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Fjortoft R, 2003, IEEE T GEOSCI REMOTE, V41, P675, DOI 10.1109/TGRS.2003.809940
   Forbes F, 2003, IEEE T PATTERN ANAL, V25, P1089, DOI 10.1109/TPAMI.2003.1227985
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Ibrahim M, 2006, IMAGE VISION COMPUT, V24, P1065, DOI 10.1016/j.imavis.2006.03.001
   Jain A K, 1988, ALGORITHMS CLUSTERIN
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Johnson NL, 1997, Discrete multivariate distributions
   Kato Z, 2006, IMAGE VISION COMPUT, V24, P1103, DOI 10.1016/j.imavis.2006.03.005
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Laferté JM, 2000, IEEE T IMAGE PROCESS, V9, P390, DOI 10.1109/83.826777
   Li CM, 2005, PROC CVPR IEEE, P430
   Li L, 2010, IEEE T IMAGE PROCESS, V19, P1, DOI 10.1109/TIP.2009.2032341
   Li S. Z., 2009, Markov random field modeling in image analysis
   Madsen Rasmus E, 2005, P 22 INT C MACH LEAR, P545, DOI DOI 10.1145/1102351.1102420
   Marroquin JL, 2003, IEEE T PATTERN ANAL, V25, P1380, DOI 10.1109/TPAMI.2003.1240112
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Meila M., 2005, P 22 INT C MACH LEAR, P577, DOI DOI 10.1145/1102351.1102424
   Murtagh F, 2005, IMAGE VISION COMPUT, V23, P587, DOI 10.1016/j.imavis.2005.02.002
   Nguyen TM, 2010, IEEE T NEURAL NETWOR, V21, P1326, DOI 10.1109/TNN.2010.2054109
   Nguyen TM, 2008, IEEE IMAGE PROC, P3020, DOI 10.1109/ICIP.2008.4712431
   Nikou C, 2007, IEEE T IMAGE PROCESS, V16, P1121, DOI 10.1109/TIP.2007.891771
   Nikou C, 2010, IEEE T IMAGE PROCESS, V19, P2278, DOI 10.1109/TIP.2010.2047903
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   Qian W., 1991, Philosophical Transactions of the Royal Society, Series A (Physical Sciences and Engineering), V337, P407, DOI 10.1098/rsta.1991.0132
   Robles-Kelly A, 2002, IMAGE VISION COMPUT, V20, P725, DOI 10.1016/S0262-8856(02)00062-8
   Rudin W., 1987, REAL COMPLEX ANAL, P62
   Sanjay-Gopel S, 1998, IEEE T IMAGE PROCESS, V7, P1014, DOI 10.1109/83.701161
   SANTAGO P, 1993, IEEE T MED IMAGING, V12, P566, DOI 10.1109/42.241885
   Seber G.A.F., 1984, MULTIVARIATE OBSERVA, P482
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Titterington D. M., 1985, Statistical Analysis of Finite Mixture Distributions, V198
   Unnikrishnan R., 2005, IEEE Conference on Computer Vision and Pattern Recognition, CVPR Workshops 2005, San Diego, CA, USA, 21-23 September, 2005, page, P34, DOI 10.1109/CVPR.2005.390
   Wang JQ, 2004, IEEE T NEURAL NETWOR, V15, P159, DOI 10.1109/TNN.2003.820622
   Xiabi L., 2008, PATTERN RECOGN, V41, P84
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Yang XY, 2004, IMAGE VISION COMPUT, V22, P735, DOI 10.1016/j.imavis.2004.04.003
   ZHANG J, 1992, IEEE T SIGNAL PROCES, V40, P2570, DOI 10.1109/78.157297
   Zhang YY, 2001, IEEE T MED IMAGING, V20, P45, DOI 10.1109/42.906424
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 62
TC 21
Z9 26
U1 1
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2011
VL 29
IS 12
BP 818
EP 828
DI 10.1016/j.imavis.2011.09.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 873TJ
UT WOS:000298905600002
DA 2024-07-18
ER

PT J
AU Doré, V
   Moghaddam, RF
   Cheriet, M
AF Dore, Vincent
   Moghaddam, Reza Farrahi
   Cheriet, Mohamed
TI Non-local adaptive structure tensors Application to anisotropic
   diffusion and shock filtering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Structure tensor; PDEs; Adaptive tensor regularization; Anisotropic
   diffusion; Shock filter
ID GENERALIZED SOLUTION; RESTORED SIGNALS; SCALE-SPACE; IMAGE; MODELS
AB Structure tensors are used in several POE-based methods to estimate information on the local structure in the image, such as edge orientation. They have become a common tool in many image processing applications. To integrate the local data information, the structure tensor is based on a local regularization of a tensorial product. In this paper, we propose a new regularization model based on the non-local properties of the tensor product. The resulting non-local structure tensor is effective in the restitution of the non homogeneity of the local orientation of the structures. It is particularly efficient in texture regions where patches repeat non locally. The new tensor regularization also offers the advantage of automatically adapting the smoothing parameter to the local structures of the tensor product. Finally, we explain how this new adaptive structure tensor can be plugged into two PDEs: an anisotropic diffusion and a shock filter. Comparisons with other tensor regularization methods and other PDEs demonstrate the clear advantage of using the non-local structure tensor. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Dore, Vincent; Moghaddam, Reza Farrahi; Cheriet, Mohamed] Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, Montreal, PQ H3C 1K3, Canada.
   [Dore, Vincent] CSIRO, Australian E Hlth Res Ctr, Biomed Imaging ICT, Brisbane, Qld, Australia.
C3 University of Quebec; Ecole de Technologie Superieure - Canada;
   Commonwealth Scientific & Industrial Research Organisation (CSIRO)
RP Doré, V (corresponding author), Ecole Technol Super, Synchromedia Lab Multimedia Commun Telepresence, Montreal, PQ H3C 1K3, Canada.
EM vincent.dore@csiro.au; reza.farrahi@synchromedia.ca;
   mohamed.cheriet@etsmtl.ca
RI Dore, Vincent/A-7750-2011; Farrahi Moghaddam, Reza/E-7843-2015
OI Dore, Vincent/0000-0002-8051-0558; Farrahi Moghaddam,
   Reza/0000-0002-3046-1305
FU NSERC
FX This work has been sponsored by the NSERC
   (http://www.nserc-crsng.gc.ca).
CR ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   [Anonymous], INT C COMP VIS BOMB
   [Anonymous], 2006, Mathematical problems in image processing: Partial differential equations and the calculus of variations
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   Awate SP, 2006, IEEE T PATTERN ANAL, V28, P364, DOI 10.1109/TPAMI.2006.64
   Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433
   Brox T, 2006, IMAGE VISION COMPUT, V24, P41, DOI 10.1016/j.imavis.2005.09.010
   Buades A, 2005, PROC CVPR IEEE, P60, DOI 10.1109/cvpr.2005.38
   BUADES A, 2006, 200622 CMLA, V22
   CANTRELL CD, 2001, MEASUREMENT SCI TECH, V12
   Castaño-Moraga CA, 2007, SIGNAL PROCESS, V87, P263, DOI 10.1016/j.sigpro.2006.02.049
   Cheriet M, 2003, J MATH ANAL APPL, V279, P398, DOI 10.1016/S0022-247X(02)00714-X
   Cleveland W.S., 1995, Smoothing by local regression
   Doré V, 2009, IEEE T SIGNAL PROCES, V57, P1703, DOI 10.1109/TSP.2008.2011832
   FARRAHIMOGHADDA.R, 2011, PATTERN RECOGN, V44, P363
   Gijbels I, 2006, IEEE T PATTERN ANAL, V28, P1075, DOI 10.1109/TPAMI.2006.140
   Gilboa G, 2004, IEEE T PATTERN ANAL, V26, P1020, DOI 10.1109/TPAMI.2004.47
   Grewenig S, 2011, J VIS COMMUN IMAGE R, V22, P117, DOI 10.1016/j.jvcir.2010.11.001
   Guichard F, 2003, INT J COMPUT VISION, V52, P153, DOI 10.1023/A:1022904124348
   Guichard F, 2002, J PHYS IV, V12, P137, DOI 10.1051/jp42002006
   Kervrann C, 2006, IEEE T IMAGE PROCESS, V15, P2866, DOI 10.1109/TIP.2006.877529
   Kornprobst P, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL II, P458, DOI 10.1109/ICIP.1997.638807
   KOTHE U, 2003, ICCV 03 P 9 INT C CO, V1, P424
   Loader C., 1999, Statistics and Computing, DOI [10.1007/b98858, DOI 10.1007/B98858]
   MALLOWS CL, 1973, TECHNOMETRICS, V15, P661, DOI 10.2307/1267380
   Martín-Herrero J, 2007, IEEE T GEOSCI REMOTE, V45, P1386, DOI 10.1109/TGRS.2007.894569
   Meyer F, 2004, J MATH IMAGING VIS, V20, P59, DOI 10.1023/B:JMIV.0000011319.21884.39
   Nocedal J., 1999, NUMERICAL OPTIMIZATI
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Remaki L, 2003, J MATH ANAL APPL, V279, P189, DOI 10.1016/S0022-247X(02)00713-8
   Remaki L, 2000, IEEE T IMAGE PROCESS, V9, P970, DOI 10.1109/83.846240
   Rousseeuw P.J., 1986, ROBUST REGRESSION OU
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Tasdizen T, 2009, IEEE T IMAGE PROCESS, V18, P2649, DOI 10.1109/TIP.2009.2028259
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   VANDENBOOMGAARD R, 2002, P 2 INT WORKSH TEXT, P135
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J, 2003, LECT NOTES COMPUT SC, V2781, P1
   Weickert J, 2006, MATH VISUALIZATION
   Weickert J., 1996, ANISOTROPIC DIFFUSIO
   Wiest-Daesslé N, 2008, LECT NOTES COMPUT SC, V5242, P171, DOI 10.1007/978-3-540-85990-1_21
   Yaroslavsky L.P., 1985, Digital Picture Processing: An Introduction
NR 46
TC 8
Z9 10
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2011
VL 29
IS 11
BP 730
EP 743
DI 10.1016/j.imavis.2011.07.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 864EE
UT WOS:000298219000003
DA 2024-07-18
ER

PT J
AU Borji, A
   Ahmadabadi, MN
   Araabi, BN
   Hamidi, M
AF Borji, Ali
   Ahmadabadi, Majid Nil
   Araabi, Babak Nadjar
   Hamidi, Mandana
TI Online learning of task-driven object-based visual attention control
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Task-driven attention; Object-based attention; Top-down attention;
   Saliency-based model; Reinforcement learning; State space discretization
ID RECOGNITION; SCENE; MODELS; TIME
AB We propose a biologically-motivated computational model for learning task-driven and object-based visual attention control in interactive environments. In this model, top-down attention is learned interactively and is used to search for a desired object in the scene through biasing the bottom-up attention in order to form a need-based and object-driven state representation of the environment. Our model consists of three layers. First, in the early visual processing layer, most salient location of a scene is derived using the biased saliency-based bottom-up model of visual attention. Then a cognitive component in the higher visual processing layer performs an application specific operation like object recognition at the focus of attention. From this information, a state is derived in the decision making and learning layer. Top-down attention is learned by the U-TREE algorithm which successively grows an object-based binary tree. Internal nodes in this tree check the existence of a specific object in the scene by biasing the early vision and the object recognition parts. Its leaves point to states in the action value table. Motor actions are associated with the leaves. After performing a motor action, the agent receives a reinforcement signal from the critic. This signal is alternately used for modifying the tree or updating the action selection policy. The proposed model is evaluated on visual navigation tasks, where obtained results lend support to the applicability and usefulness of the developed method for robotics. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Borji, Ali; Ahmadabadi, Majid Nil; Araabi, Babak Nadjar] Inst Res Fundamental Sci, Sch Cognit Sci, Tehran, Iran.
   [Borji, Ali] Univ Bonn, Dept Comp Sci 3, D-5300 Bonn, Germany.
   [Ahmadabadi, Majid Nil; Araabi, Babak Nadjar] Univ Tehran, Dept Elect & Comp Engn, Control & Intelligent Proc Ctr Excellence, Tehran, Iran.
   [Hamidi, Mandana] IIT, I-16163 Genoa, Italy.
C3 University of Bonn; University of Tehran; Istituto Italiano di
   Tecnologia - IIT
RP Borji, A (corresponding author), Inst Res Fundamental Sci, Sch Cognit Sci, Niavaran Bldg,POB 19395-5746, Tehran, Iran.
EM borji@iai.uni-bonn.de; mnili@ut.ac.ir; araabi@ut.ac.ir;
   Mandana.hamidi@iit.it
RI Nadjar Araabi, Babak/C-5069-2017
OI Nadjar Araabi, Babak/0000-0002-5283-263X
CR [Anonymous], 2007, Integrated models of cognitive systems
   Asadpour M, 2006, SPRINGER TRAC ADV RO, V22, P79
   BORJI A, WORKSH MOT INT LEARN
   Borji A, 2008, NEURAL PROCESS LETT, V28, P97, DOI 10.1007/s11063-008-9084-y
   Borji A, 2011, MACH VISION APPL, V22, P61, DOI 10.1007/s00138-009-0192-0
   Chun M.M., 2001, BLACKWELL HDB SENSAT, P272
   CLARK A, 1999, J COGNITIVE SYSTEMS, V1, P5
   Connor CE, 2004, CURR BIOL, V14, pR850, DOI 10.1016/j.cub.2004.09.041
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   DUNCAN J, 1984, J EXP PSYCHOL GEN, V113, P501, DOI 10.1037/0096-3445.113.4.501
   Egeth HE, 1997, ANNU REV PSYCHOL, V48, P269, DOI 10.1146/annurev.psych.48.1.269
   EGLY R, 1994, J EXP PSYCHOL GEN, V123, P161, DOI 10.1037/0096-3445.123.2.161
   FERMULLER C, 1995, IMAGE VISION COMPUT, V13, P725, DOI 10.1016/0262-8856(95)98754-H
   GIBSON E, 1983, HDB CHILD PSYCHOL, V3, pCH1
   GONIC LMG, 1999, IEEE INT S COMP INT, P294
   GONIC LMG, 1999, P 12 BRAZ S COMP GRA, P143
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2001, J ELECTRON IMAGING, V10, P161, DOI 10.1117/1.1333677
   Jodogne S, 2007, J ARTIF INTELL RES, V28, P349, DOI 10.1613/jair.2110
   Kanwisher N., 1992, CURR DIR PSYCHOL SCI, V1, P26, DOI DOI 10.1111/1467-8721.EP10767835
   Kastner S, 2001, NEUROPSYCHOLOGIA, V39, P1263, DOI 10.1016/S0028-3932(01)00116-6
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Li ZP, 2002, TRENDS COGN SCI, V6, P9, DOI 10.1016/S1364-6613(00)01817-9
   LIANG JJ, 2006, IEEE T EVOLUTIONARY, V9, P3
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   MALJKOVIC V, 1994, MEM COGNITION, V22, P657, DOI 10.3758/BF03209251
   Maunsell JHR, 2006, TRENDS NEUROSCI, V29, P317, DOI 10.1016/j.tins.2006.04.001
   McCallum AK., 1995, PhD thesis
   MINUT S, 2001, 5 INT C AUT AG MONTR
   MOZER MC, 2005, NEURAL INFORM PROCES, V18, P923
   Navalpakkam V, 2005, VISION RES, V45, P205, DOI 10.1016/j.visres.2004.07.042
   Navalpakkam V., 2006, P IEEE C COMPUTER VI, P2049
   Oliva A, 2006, PROG BRAIN RES, V155, P23, DOI 10.1016/S0079-6123(06)55002-2
   PALETTA L, P 2005 IEEE COMP SOC
   Peters RJ, 2008, ACM T APPL PERCEPT, V5, DOI 10.1145/1279920.1279923
   Pfeifer R., 2006, How the body shapes the way we think: a new view of intelligence
   POSNER MI, 1980, Q J EXP PSYCHOL, V32, P3, DOI 10.1080/00335558008248231
   Reichle ED, 2006, PSYCHOL REV, V113, P390, DOI 10.1037/0033-295X.113.2.390
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   SERRE T, 2005, 2005036CBCL MIT
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Seymour B, 2004, NATURE, V429, P664, DOI 10.1038/nature02581
   Sprague N, 2007, ACM T APPL PERCEPT, V4, DOI 10.1145/1265957.1265960
   Sutton R., 1998, Reinforcement Learning: An Introduction
   Torralba A, 2003, J OPT SOC AM A, V20, P1407, DOI 10.1364/JOSAA.20.001407
   Triesch J, 2003, J VISION, V3, P86, DOI 10.1167/3.1.9
   Vapnik V., 1999, NATURE STAT LEARNING
   Walther D, 2005, COMPUT VIS IMAGE UND, V100, P41, DOI 10.1016/j.cviu.2004.09.004
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   WATKINS C, 1995, MACH LEARN, V8, P279
   Yarbus A.L., 1967, EYE MOVEMENTS VISION, DOI [10.1007/978-1-4899-5379-7, DOI 10.1007/978-1-4899-5379-7]
NR 52
TC 48
Z9 57
U1 0
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2010
VL 28
IS 7
SI SI
BP 1130
EP 1145
DI 10.1016/j.imavis.2009.10.006
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 603UP
UT WOS:000278233900007
DA 2024-07-18
ER

PT J
AU Jeon, G
   Anisetti, M
   Kim, D
   Bellandi, V
   Damiani, E
   Jeong, J
AF Jeon, Gwanggil
   Anisetti, Marco
   Kim, Donghyung
   Bellandi, Valerio
   Damiani, Ernesto
   Jeong, Jechang
TI Fuzzy rough sets hybrid scheme for motion and scene complexity adaptive
   deinterlacing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fuzzy control; Rough set; Deinterlacing; Directional interpolation;
   Motion analysis; Scene complexity analysis
ID EDGE-PRESERVING INTERPOLATION; ATTRIBUTE REDUCTION; ALGORITHM;
   APPROXIMATIONS; SYSTEM; MODEL
AB Current research activities in the field of deinterlacing include the selection of suitable deinterlacing methods and the estimation of the exact value of a missing line, This paper proposes a spatio-temporal domain fuzzy rough sets rule for selecting a deinterlacing method that is suitable for regions with high motion or frequent scene changes. The proposed algorithm consists of two parts. The first part is fuzzy rule-based edge-direction detection with an edge preserving part that utilizes fuzzy theory to find the most accurate edge direction and interpolates the missing pixels. Using the introduced gradients in the interpolation, the vertical resolution in the deinterlaced image is subjectively concealed. The second part of the proposed algorithm is a rough sets-assisted optimization which selects the most suitable of five different deinterlacing methods and Successively builds approximations of the deinterlaced sequence. Moreover, this approach employs a size reduction of the database system, keeping only the information essential for the process. The proposed algorithm is intended not only to be fast, but also to reduce deinterlacing artifacts. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Kim, Donghyung] ETRI, Broadcasting Media Res Grp, Radio & Broadcasting Res Div, Taejon 305700, South Korea.
   [Jeon, Gwanggil; Jeong, Jechang] Hanyang Univ, Dept Elect & Comp Engn, Seoul 133791, South Korea.
   [Anisetti, Marco; Bellandi, Valerio; Damiani, Ernesto] Univ Milan, Dept Informat Technol, I-26013 Crema, CR, Italy.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI);
   Hanyang University; University of Milan
RP Kim, D (corresponding author), ETRI, Broadcasting Media Res Grp, Radio & Broadcasting Res Div, 138 Gajeongno, Taejon 305700, South Korea.
EM kdh2465@etri.re.kr; windcap3l5@ece.hanyang.ac.kr
RI damiani, ernesto/AAI-5709-2020; damiani, ernesto/J-6060-2012; bellandi,
   valerio/M-7582-2019; Anisetti, Marco/AAC-9656-2021
OI damiani, ernesto/0000-0002-9557-6496; bellandi,
   valerio/0000-0003-4473-6258; Anisetti, Marco/0000-0002-5438-9467; Jeon,
   Gwanggil/0000-0002-0651-4278
FU Korea Research Foundation; Korean Government (MOEHRD)
   [KRF-2006-005-J04101]
FX The authors thank the associate editor and all of the anonymous
   reviewers for their valuable comments and questions that helped improve
   both the technical content and the presentation quality of this paper.
   This work was supported by the Korea Research Foundation Grant funded by
   the Korean Government (MOEHRD) (KRF-2006-005-J04101).
CR AGARWAL AK, 2005, P IEEE ICNSC, P855
   [Anonymous], DEINTERLACING KEY TE
   BELLERS EB, 1996, P PRORISC IEEE WORKS, P7
   Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P965, DOI 10.1016/j.patrec.2004.09.044
   Biswas M, 2006, IEEE T IMAGE PROCESS, V15, P2596, DOI 10.1109/TIP.2006.877405
   Bloch I, 2006, INT J APPROX REASON, V41, P77, DOI 10.1016/j.ijar.2005.06.011
   Brox P, 2007, FUZZY SET SYST, V158, P337, DOI 10.1016/j.fss.2006.10.014
   Carrato S, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P711, DOI 10.1109/ICIP.1996.560778
   Chen MJ, 2005, IMAGE VISION COMPUT, V23, P791, DOI 10.1016/j.imavis.2005.05.005
   Chen MJ, 2004, IEEE T CONSUM ELECTR, V50, P1202
   Chen XY, 2007, FUZZY SET SYST, V158, P2641, DOI 10.1016/j.fss.2007.05.016
   CHENGYI Z, 2008, J SYSTEMS ENG ELECT, V19, P94
   De Haan G, 1998, P IEEE, V86, P1839, DOI 10.1109/5.705528
   Deng TQ, 2007, INFORM SCIENCES, V177, P2308, DOI 10.1016/j.ins.2006.11.013
   DOYLE T, 1990, P 2 INT WORKSH SIGN, P412
   FAN YC, 2005, P ITRE 2005, V3, P200
   Gao XB, 2005, IEEE T CONSUM ELECTR, V51, P589, DOI 10.1109/TCE.2005.1468005
   Gong ZT, 2008, INFORM SCIENCES, V178, P1968, DOI 10.1016/j.ins.2007.12.005
   Greco S, 2006, INT J APPROX REASON, V41, P179, DOI 10.1016/j.ijar.2005.06.014
   Grzymala-Busse J., 1992, Intelligent Decision Support, volume 11 of Theory and Decision Library, V11, P3, DOI DOI 10.1007/978-94-015-7975-9_
   Gu JX, 2004, LECT NOTES COMPUT SC, V3212, P381
   Hassanien A, 2007, IMAGE VISION COMPUT, V25, P172, DOI 10.1016/j.imavis.2006.01.026
   Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/j.patrec.2005.09.004
   Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017
   JACK K, 2005, DEMYSTIFIED HDB DIGI
   Jensen R, 2005, FUZZY SET SYST, V149, P5, DOI 10.1016/j.fss.2004.07.014
   Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6
   JEON G, 2006, P IEEE ICIP, P1789
   Jeon G, 2007, IEEE T CONSUM ELECTR, V53, P725, DOI 10.1109/TCE.2007.381752
   Jeon G, 2006, IEEE T CONSUM ELECTR, V52, P1348, DOI 10.1109/TCE.2006.273155
   Jeon G, 2006, IEEE T CONSUM ELECTR, V52, P1013, DOI 10.1109/TCE.2006.1706501
   Kazanci O, 2008, INFORM SCIENCES, V178, P1343, DOI 10.1016/j.ins.2007.10.005
   KERRE EE, 2000, STUDIES FUZZINESS SO, V52, P194
   Kusiak A, 2001, IEEE T ELECTRON PACK, V24, P44, DOI 10.1109/6104.924792
   Li TJ, 2008, INFORM SCIENCES, V178, P892, DOI 10.1016/j.ins.2007.09.006
   Liu GL, 2008, INFORM SCIENCES, V178, P1651, DOI 10.1016/j.ins.2007.11.010
   Liu M, 2006, COMPUT MATH APPL, V51, P1571, DOI 10.1016/j.camwa.2005.10.017
   Liu M, 2006, COMPUT MATH APPL, V51, P1507, DOI 10.1016/j.camwa.2005.12.003
   Mohabey A, 2000, PEACHFUZZ 2000 : 19TH INTERNATIONAL CONFERENCE OF THE NORTH AMERICAN FUZZY INFORMATION PROCESSING SOCIETY - NAFIPS, P338, DOI 10.1109/NAFIPS.2000.877448
   Muneyasu M, 1998, J FRANKLIN I, V335B, P1145, DOI 10.1016/S0016-0032(97)00054-9
   Oh HS, 2000, IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - 2000 DIGEST OF TECHNICAL PAPERS, P52, DOI 10.1109/ICCE.2000.854493
   Pan L, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P1185, DOI 10.1109/ICMLC.2003.1259665
   Park MK, 2003, IEEE T CONSUM ELECTR, V49, P1508, DOI 10.1109/TCE.2003.1261260
   Petrosino A, 2006, INT J APPROX REASON, V41, P212, DOI 10.1016/j.ijar.2005.06.015
   Polkowski L, 2000, STUD FUZZ SOFT COMP, V56, P9
   PRODAN RS, 1986, PHILIPS J RES, V41, P576
   Ramponi G, 2001, IMAGE VISION COMPUT, V19, P451, DOI 10.1016/S0262-8856(00)00090-1
   Rovetta S, 2007, IMAGE VISION COMPUT, V25, P204, DOI 10.1016/j.imavis.2006.01.028
   Russo F, 1997, PROCEEDINGS OF THE SIXTH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS I - III, P1051, DOI 10.1109/FUZZY.1997.622854
   Sarkar M, 2007, FUZZY SET SYST, V158, P2134, DOI 10.1016/j.fss.2007.04.023
   Schulte S, 2007, IMAGE VISION COMPUT, V25, P1377, DOI 10.1016/j.imavis.2006.10.002
   Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016
   Su FZ, 2004, INT GEOSCI REMOTE SE, P1455
   Suresh RM, 2007, IMAGE VISION COMPUT, V25, P230, DOI 10.1016/j.imavis.2006.01.029
   SWAN PL, 1999, Patent No. 5864369
   Taguchi A, 2001, PROC SPIE, V4304, P98, DOI 10.1117/12.424966
   Ting HC, 1997, J VIS COMMUN IMAGE R, V8, P338, DOI 10.1006/jvci.1997.0364
   TORRES L, 2002, P PESW 2002, P627
   Tsai YC, 2006, EXPERT SYST APPL, V31, P436, DOI 10.1016/j.eswa.2005.09.038
   Wu WZ, 2003, INFORM SCIENCES, V151, P263, DOI 10.1016/S0020-0255(02)00379-1
   WU X, 2006, P ICGC 2006 ATL GA, P562
   Xu YH, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P3713
   Yoo H, 2002, IEEE T CONSUM ELECTR, V48, P954, DOI 10.1109/TCE.2003.1196426
   Zhang XF, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P2027
   Zhou L, 2008, INFORM SCIENCES, V178, P2448, DOI 10.1016/j.ins.2008.01.012
NR 65
TC 39
Z9 41
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 425
EP 436
DI 10.1016/j.imavis.2008.06.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600013
DA 2024-07-18
ER

PT J
AU Zucchelli, M
   Kosecká, J
AF Zucchelli, Marco
   Kosecka, Jana
TI Motion bias and structure distortion induced by intrinsic calibration
   errors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE structure and motion recovery; calibration sensitivity; optical flow
AB This article provides an account of sensitivity and robustness of structure and motion recovery with respect to the errors in intrinsic parameters of the camera. We demonstrate both analytically and in simulation, the interplay between measurement and calibration errors and their effect on motion and structure estimates. In particular we show that the calibration errors introduce an additional bias towards the optical axis, which has opposite sign to the bias typically observed by egomotion algorithms. The overall bias causes a distortion of the resulting 3D structure, which we express in a parametric form. The analysis and experiments are carried out in the differential setting for motion and structure estimation from image velocities. While the analytical explanations are derived in the context of linear techniques for motion estimation, we verify our observations experimentally on a variety of optimal and suboptimal motion and structure estimation algorithms. The obtained results illuminate and explain the performance and sensitivity of the differential structure and motion recovery techniques in the presence of calibration errors. (C) 2008 Published by Elsevier B.V.
C1 [Zucchelli, Marco] Karolinska Inst, Dept Biosci & Nutr, S-14157 Huddinge, Sweden.
   [Zucchelli, Marco] Royal Inst Technol, CVAP, S-10044 Stockholm, Sweden.
   [Kosecka, Jana] George Mason Univ, Dept Comp Sci, Fairfax, VA 22030 USA.
C3 Karolinska Institutet; Royal Institute of Technology; George Mason
   University
RP Zucchelli, M (corresponding author), Karolinska Inst, Dept Biosci & Nutr, S-14157 Huddinge, Sweden.
EM Marco.Zucchelli@biosci.ki.se
CR BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bouget Jean-Yves., CAMERA CALIBRATION T
   BOUGNOUX S, 1998, ICCV, V2, P790
   BRUSS AR, 1983, COMPUT VISION GRAPH, V21, P3, DOI 10.1016/S0734-189X(83)80026-7
   Cheong LF, 2001, INT J COMPUT VISION, V44, P199, DOI 10.1023/A:1012224215211
   Daniilidis K., 1996, Visual Navigation, P61
   Grossmann E, 2000, IMAGE VISION COMPUT, V18, P685, DOI 10.1016/S0262-8856(99)00072-4
   HEEGER DJ, 1992, INT J COMPUT VISION, V7, P95, DOI 10.1007/BF00128130
   Jepson AD., 1992, Linear subspace methods for recovering translational direction
   Kanatani K., 1993, GEOMETRIC COMPUTATIO
   KANATANI K, 1993, ICCV, P599
   KOSECKA J, 2000, IJCV, V36, P71
   KOSECKA J, 2001, MOTION BIAS STRUCTUR
   MacLean W. J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P753, DOI 10.1109/ICCV.1999.790297
   Oliensis J, 1996, PROC CVPR IEEE, P335, DOI 10.1109/CVPR.1996.517094
   SVODOBA T, 1996, WHAT CAN DONE BADLY
   TOMASI C, 1994, CVPR, P315
   Xiang T, 2003, INT J COMPUT VISION, V51, P111, DOI 10.1023/A:1021627622971
   ZHANG T, 1999, CVPR, V1, P164
   ZUCCHELLI M, 2001, BMVC, P183
NR 20
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 639
EP 646
DI 10.1016/j.imavis.2007.08.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900004
DA 2024-07-18
ER

PT J
AU Kemp, C
   Drummond, T
AF Kemp, Christopher
   Drummond, Tom
TI Multi-modal tracking using texture changes
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE RANSAC; texture; real-time; tracking; multi-modal
AB We present a method for efficiently generating a representation of a multi-modal posterior probability distribution. The technique combines ideas from RANSAC and particle filtering such that the 3D visual tracking problem can be partitioned into two levels, while maintaining multiple hypotheses throughout. A simple texture change-point detector finds multiple hypotheses for the position of image edgels. From these, multiple locations for each scene edge are generated. Finally, we determine the best pose of the whole structure. While the multi-modal representation is strongly related to particle filtering techniques, this approach is driven by data from the image. Hence the resulting system is able to perform robust visual tracking of all six degrees of freedom in real time. Real video sequences are used to compare the complete tracking system to previous systems. (c) 2007 Published by Elsevier B.V.
C1 [Kemp, Christopher; Drummond, Tom] Univ Cambridge, Dept Engn, Cambridge CB1 2PZ, England.
C3 University of Cambridge
RP Kemp, C (corresponding author), Univ Cambridge, Dept Engn, Cambridge CB1 2PZ, England.
EM ck231@cam.ac.uk
RI Kemp, Christopher G./I-8423-2019; Drummond, Tom/A-4696-2011
OI Kemp, Christopher G./0000-0003-1231-1546; Drummond,
   Tom/0000-0001-8204-5904
CR [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   ARMSTRONG M, 1995, P AS C COMP VIS, V1, P58
   Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   DITTRICH JS, 2002, THESIS GEORGIA I TEC
   Drummond T, 2002, IEEE T PATTERN ANAL, V24, P932, DOI 10.1109/TPAMI.2002.1017620
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   LOWE DG, 1992, INT J COMPUT VISION, V8, P113, DOI 10.1007/BF00127170
   Marchand E., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P262, DOI 10.1109/ICCV.1999.791229
   Shahrokni A, 2004, LECT NOTES COMPUT SC, V3022, P566
   Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935
   Stennett C., 1990, P BMVC, P1
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Torr PHS, 2003, IEEE T PATTERN ANAL, V25, P354, DOI 10.1109/TPAMI.2003.1182098
   VACCETTI L, 2003, P IEEE COMP VIS PATT, V2, P241
NR 17
TC 5
Z9 7
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 442
EP 450
DI 10.1016/j.imavis.2006.12.014
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500012
DA 2024-07-18
ER

PT J
AU Arens, M
   Gerber, R
   Nagel, HH
AF Arens, M.
   Gerber, R.
   Nagel, H. -H.
TI Conceptual representations between video signals and natural language
   descriptions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE cognitive vision; knowledge representation
ID RECOGNITION; SURVEILLANCE; MODELS
AB An artificial cognitive vision system associates video signals with conceptual descriptions of the depicted time-varying scene. This linkage is mediated by knowledge representation formalisms. An experimental implementation of such an approach yielded initial results for the conceptual description of videos recorded at innercity traffic scenes, see [M. Haag, H.-H. Nagel, Incremental recognition of traffic situations from video image sequences, Image and Vision Computing 18 (2) (2000) 137-153]. Accumulating experience with this system approach and its extension for the generation of natural language texts from videos caused us to redesign the overall computer vision system as well as the knowledge representation formalisms utilised within that system. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Karlsruhe TH, Fak Informat, Inst Algorithmen & Kognit Syst, D-76128 Karlsruhe, Germany.
C3 Helmholtz Association; Karlsruhe Institute of Technology
RP Arens, M (corresponding author), Univ Karlsruhe TH, Fak Informat, Inst Algorithmen & Kognit Syst, D-76128 Karlsruhe, Germany.
EM michel_arens@web.de
OI Arens, Michael/0000-0002-7857-0332
CR [Anonymous], P 15 EUR C ART INT A
   Arens M, 2003, LECT NOTES ARTIF INT, V2821, P149
   ARENS M, 2004, THESIS U KATLSRUHE B
   ARENS M, 2003, SGTEDITOR REFERENCE
   Arens M., 2003, P 26 GERM C ART INT
   Blocher A, 1995, INT JOINT CONF ARTIF, P417
   Bobick AF, 2000, COMMUN ACM, V43, P60, DOI 10.1145/330534.330541
   Bobick AF, 1999, PRESENCE-VIRTUAL AUG, V8, P369, DOI 10.1162/105474699566297
   Bobick AF, 1998, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1998.698609
   BOBICK AF, 1996, LECT NOTES COMPUTER, V1035, P23
   Brand M, 1997, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.1997.609450
   Bremond F, 1998, INT J HUM-COMPUT ST, V48, P375, DOI 10.1006/ijhc.1997.0176
   Buxton H, 2003, IMAGE VISION COMPUT, V21, P125, DOI 10.1016/S0262-8856(02)00127-0
   BUXTON H, 1995, ARTIF INTELL, V78, P431, DOI 10.1016/0004-3702(95)00041-0
   BUXTON H, 1994, P WORKSH INT NAT VIS, P231
   Fernyhough J, 2000, IMAGE VISION COMPUT, V18, P81, DOI 10.1016/S0262-8856(99)00023-2
   GALATA A, 2002, P EUR C ART INT, P741
   GALATA A, 2001, COMPUTER VISION IMAG, V81, P113
   GERBER R, 2002, P WORKSH COGN VIS 19, P1
   GERBER R, 2000, THESIS U KARLSRUHE K
   Haag M, 2000, IMAGE VISION COMPUT, V18, P137, DOI 10.1016/S0262-8856(99)00021-9
   HAZARIKA SM, 2002, P 8 C PRINC KNOWL RE, P14
   Howarth RJ, 2000, IMAGE VISION COMPUT, V18, P105, DOI 10.1016/S0262-8856(99)00025-6
   Howarth RJ, 1998, ARTIF INTELL, V100, P5, DOI 10.1016/S0004-3702(98)00004-6
   Intille SS, 2001, COMPUT VIS IMAGE UND, V81, P414, DOI 10.1006/cviu.2000.0896
   Intille SS, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P518
   INTILLE SS, 1999, P IEEE C COMP VIS PA, P1056
   Johnson N, 1998, PROC CVPR IEEE, P866, DOI 10.1109/CVPR.1998.698706
   Kamp H., 1993, From Discourse to Logic: Introduction to Modeltheoretic Semantics of Natural Language, Formal Logic and Discourse Representation Theory
   Moënne-Loccoz N, 2003, LECT NOTES COMPUT SC, V2626, P68
   NAGEL HH, 1988, IMAGE VISION COMPUT, V6, P59, DOI 10.1016/0262-8856(88)90001-7
   Nagel HH, 1998, 1998 IEEE WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P65
   Oliver N, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P7, DOI 10.1109/IVS.2000.898310
   Ottlik A, 2003, LECT NOTES COMPUT SC, V2781, P418
   Pinhanez CS, 1996, PROCEEDINGS OF THE THIRTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND THE EIGHTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE, VOLS 1 AND 2, P1116
   Rosario B., 1999, Proceedings of the Third International Conference on Autonomous Agents, P342, DOI 10.1145/301136.301225
   Rota NA, 2000, FR ART INT, V54, P673
   SCHAFER KH, 1996, THESIS U KARLSRUHE K, V135
   SCHIRRA JRJ, 1994, THESIS U SAARLANDES
   Vu VT, 2003, LECT NOTES COMPUT SC, V2626, P523
   VU VT, 2002, P 10 INT C CENTR EUR, P485
   VU VT, 2002, P ECAI 2002 WORKSH M
NR 42
TC 16
Z9 16
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 53
EP 66
DI 10.1016/j.imavis.2005.07.026
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100006
DA 2024-07-18
ER

PT J
AU Schulte, S
   De Witte, V
   Nachtegael, M
   Van der Weken, D
   Kerre, EE
AF Schulte, Stefan
   De Witte, Valerie
   Nachtegael, Mike
   Van der Weken, Dietrich
   Kerre, Etienne E.
TI Histogram-based fuzzy colour filter for image restoration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fuzzy filter; histogram; colour filter; impulse noise; image restoration
ID MEDIAN FILTERS; SYSTEMS; LOGIC
AB A new impulse noise reduction method for colour images, called histogram-based fuzzy colour filter (HFC), is presented in this paper. The HFC filter is particularly effective for reducing high-impulse noise in digital images while preserving edge sharpness. Colour images that are corrupted with noise are generally filtered by applying a greyscale algorithm on each colour component separately. This approach causes artefacts especially on edge or texture pixels. Vector-based filtering methods were successfully introduced to overcome this problem. In this paper, we discuss an alternative technique so that no artefacts are introduced. The main difference between the new proposed method and the classical vector-based methods is the usage of colour component differences for the detection of impulse noise and the preservation of the colour component differences. The construction of the HFC filter involves three steps: (1) the estimation of the original histogram of the colour component differences, (2) the construction of suitable fuzzy sets for representing the linguistic values of these differences and (3) the construction of fuzzy rules that determine the output. Extensive simulation results show that the proposed filter outperforms many well-known filters (including vector-based approaches). (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Ghent, Dept Appl Math & Comp Sci, Fuzziness & Uncertainty Modelling Res Unit, B-9000 Ghent, Belgium.
C3 Ghent University
RP Schulte, S (corresponding author), Univ Ghent, Dept Appl Math & Comp Sci, Fuzziness & Uncertainty Modelling Res Unit, Krijgslaan 281 Bldg S9, B-9000 Ghent, Belgium.
EM Stefan.Schulte@UGent.be; Valerie.De-witte@UGent.be;
   Mike.Nachtegael@UGent.be; Dietrich.VanderWeken@UGent.be;
   Etienne.Kerre@UGent.be
CR [Anonymous], 1998, FUZZY SETS APPROXIMA
   Arakawa K., 2000, Fuzzy Techniques in Image Processing, P222
   ASTOLA J, 1990, P IEEE, V78, P678, DOI 10.1109/5.54807
   Bami M, 1994, IEEE SIGNAL PROC LET, V1, P92, DOI 10.1109/97.295343
   Barni M, 2000, IEEE T IMAGE PROCESS, V9, P1704, DOI 10.1109/83.869182
   Bothorel S, 1997, INT J INTELL SYST, V12, P819, DOI 10.1002/(SICI)1098-111X(199711/12)12:11/12<819::AID-INT3>3.0.CO;2-#
   Chatzis V, 1999, IEEE T IMAGE PROCESS, V8, P731, DOI 10.1109/83.760339
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   David H. A., 2004, ORDER STAT
   Eng HL, 2001, IEEE T IMAGE PROCESS, V10, P242, DOI 10.1109/83.902289
   FARBIZ F, 1998, P 6 EUFIT C, P1417
   FARBIZ F, 2000, FUZZY TECHNIQUES IMA, V52, P194
   HARDIE RC, 1993, IEEE T SIGNAL PROCES, V41, P1061, DOI 10.1109/78.205713
   Huber P., 1981, Robust Statistics
   Kalaykov I, 2003, STUD FUZZ SOFT COMP, V122, P54
   Karakos DG, 1997, IEEE T IMAGE PROCESS, V6, P1038, DOI 10.1109/83.597278
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   LEE CC, 1990, IEEE T SYST MAN CYB, V20, P404, DOI 10.1109/21.52551
   Lee CS, 1997, FUZZY SET SYST, V89, P157, DOI 10.1016/S0165-0114(96)00075-9
   LEE CS, 2000, FUZZY TECHNIQUES IMA, V52, P172
   Lukac R, 2005, IEEE SIGNAL PROC MAG, V22, P74, DOI 10.1109/MSP.2005.1407717
   Lukac R, 2005, J INTELL ROBOT SYST, V42, P361, DOI 10.1007/s10846-005-1730-2
   Morillas S, 2005, REAL-TIME IMAGING, V11, P417, DOI 10.1016/j.rti.2005.06.007
   Nachtegael M, 2000, IEEE T FUZZY SYST, V8, P615, DOI 10.1109/91.873584
   Nachtegael M, 2001, FUZZY SET SYST, V124, P73, DOI 10.1016/S0165-0114(01)00013-6
   PLATANIOTIS KN, 2000, COLOR IMAGE PROESSIN
   REUSCH B, 1998, INT FOR MULT IM PROC, P841
   RUSSO F, 1995, IEEE T IMAGE PROCESS, V4, P1169, DOI 10.1109/83.403425
   Russo F, 1996, IEEE SIGNAL PROC LET, V3, P168, DOI 10.1109/97.503279
   Russo F, 1999, FUZZY SET SYST, V103, P265, DOI 10.1016/S0165-0114(98)00226-7
   Schulte S, 2006, IEEE T IMAGE PROCESS, V15, P1153, DOI 10.1109/TIP.2005.864179
   SCHULTE S, 2004, P E W FUZZ C, V81, P185
   Smolka B, 2003, REAL-TIME IMAGING, V9, P261, DOI 10.1016/j.rti.2003.09.015
   TAKAGI T, 1985, IEEE T SYST MAN CYB, V15, P116, DOI 10.1109/TSMC.1985.6313399
   Trahanias PE, 1993, IEEE T IMAGE PROCESS, V2, P528, DOI 10.1109/83.242362
   Trahanias PE, 1996, IEEE T IMAGE PROCESS, V5, P868, DOI 10.1109/83.503905
   VANDEVILLE D, 2000, STUDIES FUZZINESS SO, V52, P337
   VIERO T, 1994, IEEE T CIRC SYST VID, V4, P129, DOI 10.1109/76.285620
   Wang JH, 2002, IEEE T SYST MAN CY B, V32, P230, DOI 10.1109/3477.990880
   WANG JH, 1999, P NAT SCI COUNC A, V23, P630
NR 40
TC 37
Z9 39
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1377
EP 1390
DI 10.1016/j.imavis.2006.10.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000001
OA Green Published
DA 2024-07-18
ER

PT J
AU Wee, CY
   Paramesran, R
AF Wee, Chong-Yaw
   Paramesran, Raveendran
TI On the computational aspects of Zernike moments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Zernike moments; approximation error; geometrical error; numerical
   error; square-to-circular mapping; exact Zernike moments
ID IMAGE-ANALYSIS; CORNEAL SURFACES; RECOGNITION; CLASSIFICATION
AB The set of Zernike moments belongs to the class of continuous orthogonal moments which is defined over a unit disk in polar coordinate system. The approximation error of Zernike moments limits its applications in real discrete-space images. The approximation error of Zernike moments is divided into geometrical and numerical errors. In this paper, the geometrical and numerical errors of Zernike moments are explored and methods are proposed to minimize them. The geometrical error is minimized by mapping all the pixels of discrete image inside the unit disk. The numerical error is eliminated using the proposed exact Zernike moments where the Zernike polynomials are integrated mathematically over the corresponding intervals of the image pixels. The proposed methods also overcome the numerical instability problem for high order Zernike moments. Experimental results prove the superiority and reliability of the proposed methods in providing better image representation and reconstruction capabilities. The proposed methods are also not lacking in preserving the scale and translation invariant properties of Zernike moments. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Malaya, Dept Elect Engn, Fac Engn, Kuala Lumpur 50603, Malaysia.
C3 Universiti Malaya
RP Paramesran, R (corresponding author), Univ Malaya, Dept Elect Engn, Fac Engn, Kuala Lumpur 50603, Malaysia.
EM cywee2000@perdana.um.edu.my; ravee@um.edu.my
RI Paramesran, Raveendran/AAA-1895-2019
OI Paramesran, Raveendran/0000-0001-5093-7027
CR [Anonymous], 1948, Handbook of Mathematical Functions withFormulas, Graphs, and Mathematical Tables, DOI DOI 10.1119/1.15378
   Belkasim S. O., 1989, P 23 ANN AS C SIGN S, P167
   BELKASIM SO, 1991, PATTERN RECOGN, V24, P1117, DOI 10.1016/0031-3203(91)90140-Z
   Chong CW, 2003, PATTERN RECOGN, V36, P731, DOI 10.1016/S0031-3203(02)00091-2
   CHONG CW, 2003, THESIS U MALAYA MALA
   GHOSAL S, 1993, IEEE T ROBOTIC AUTOM, V9, P385, DOI 10.1109/70.246050
   GHOSAL S, 1994, IEEE IMAGE PROC, P934, DOI 10.1109/ICIP.1994.413246
   GHOSAL S, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P413, DOI 10.1109/ICPR.1992.202011
   Haddadnia J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P917
   Haddadnia J, 2003, EURASIP J APPL SIG P, V2003, P890, DOI 10.1155/S1110865703305128
   Iskander DR, 2002, IEEE T BIO-MED ENG, V49, P320, DOI 10.1109/10.991159
   Iskander DR, 2001, IEEE T BIO-MED ENG, V48, P87, DOI 10.1109/10.900255
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063
   Kim YS, 1997, PROC CVPR IEEE, P307
   LIAO S, 1993, THESIS U MANITOBA MA
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   PANG YH, 2003, J WSCG, V12, P1
   PAWLAK M, 1992, IEEE T INFORM THEORY, V38, P1698, DOI 10.1109/18.165444
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Teh C.-H., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P556, DOI 10.1109/CVPR.1988.196290
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   Wang LZ, 1998, IEEE T IMAGE PROCESS, V7, P196, DOI 10.1109/83.660996
   XIN Y, 2004, P CAN C EL COMP ENG, V2, P939
   Zernike F, 1934, PHYSICA, V1, P689
NR 28
TC 112
Z9 121
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 967
EP 980
DI 10.1016/j.imavis.2006.07.010
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600018
DA 2024-07-18
ER

PT J
AU Howe, NR
AF Howe, Nicholas R.
TI Silhouette lookup for monocular 3D pose tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE monocular tracking; articulated tracking; pose tracking; silhouette
   lookup; failure recovery
ID HUMAN MOTION
AB Computers should be able to detect and track the articulated 3D pose of a human being moving through a video sequence. Incremental tracking methods often prove slow and unreliable, and many must be initialized by a human operator before they can track a sequence. This paper describes a simple yet effective algorithm for tracking articulated pose, based upon looking up observations (such as body silhouettes) within a collection of known poses. The new algorithm runs quickly, can initialize itself without human intervention, and can automatically recover from critical tracking errors made while tracking previous frames in a video sequence. (c) 2006 Elsevier B.V. All rights reserved.
C1 Smith Coll, Northampton, MA 01063 USA.
C3 Smith College
RP Howe, NR (corresponding author), Smith Coll, Northampton, MA 01063 USA.
EM nhowe@cs.smith.edu
CR Agarwal A, 2004, PROC CVPR IEEE, P882
   [Anonymous], EUR C COMP VIS
   [Anonymous], IEEE COMP SOC C COMP
   BELKIN NJ, 1995, INFORM PROCESS MANAG, V31, P431, DOI 10.1016/0306-4573(94)00057-A
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berman AP, 1999, COMPUT VIS IMAGE UND, V75, P175, DOI 10.1006/cviu.1999.0772
   Brand M., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1237, DOI 10.1109/ICCV.1999.790422
   BREGLER C, 1998, IEEE COMP SOC C COMP
   DAVIS JW, 1998, INT WORKSH MOD MOT C, P12
   DiFranco DE, 2001, PROC CVPR IEEE, P307
   Hogg D., 1983, IMAGE VISION COMPUT, V1, P5, DOI DOI 10.1016/0262-8856(83)90003-3
   Horprasert T., 2000, P AS C COMP VIS
   Howe NicholasR., 2004, Better foreground segmentation through graph cuts
   Howe NR, 2000, ADV NEUR IN, V12, P820
   Ioffe S, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P690, DOI 10.1109/ICCV.2001.937589
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Karmann K.P., 1990, MOVING OBJECT RECOGN
   KWATRA V, 2001, IEEE COMP SOC C COMP, V2, P758
   LAN X, 2004, IEEE C COMP VIS PATT, V1, P722
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   OROURKE J, 1980, IEEE T PATTERN ANAL, V2, P522, DOI 10.1109/TPAMI.1980.6447699
   Ramanan D, 2003, PROC CVPR IEEE, P467
   ROSALES R, 2001, IEEE COMP SOC C COMP
   SCASSELLATI B, 1994, P SOC PHOTO-OPT INS, V2185, P2, DOI 10.1117/12.171777
   Shakhnarovich G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P750
   SIDENBLADH H, 2001, THESIS ROYAL I TECHN
   Sigal L, 2004, PROC CVPR IEEE, P421
   Sminchisescu C, 2003, PROC CVPR IEEE, P69
   SMINCHISESCU C, 2002, WSCG INT C COMP GRAH
   SULLIVAN J, 2002, EUR C COMP VIS
   Tomasi C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1441
   WACHTER S, 1997, NONRIGID ARTICULATED
   Zhong J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P44, DOI 10.1109/ICCV.2003.1238312
NR 33
TC 28
Z9 39
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 331
EP 341
DI 10.1016/j.imavis.2005.10.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhou, QM
   Aggarwal, JK
AF Zhou, Quming
   Aggarwal, J. K.
TI Object tracking in an outdoor environment using fusion of features and
   cameras
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Performance Evaluation of Tracking and Surveillance (PETS)
CY DEC09, 2001
CL Kauai, HI
SP IEEE
DE tracking; classification; extended Kalman filter; data fusion
ID LOCALIZATION; SURVEILLANCE; RECOGNITION; MOTION
AB This paper presents methods for tracking moving objects in an outdoor environment. A robust tracking is achieved using feature fusion and multiple cameras. The proposed method integrates spatial position, shape and color information to track object blobs. The, trajectories obtained from individual cameras are incorporated by an extended Kalman filter (EKF) to resolve object occlusion. Our results show that integrating simple features makes the tracking effective and that EKF improves the tracking accuracy when long-term or temporary occlusion occurs. The tracked objects are successfully classified into three categories: single person, people group, or vehicle. (c) 2005 Elsevier B.V. All rights reserved.
C1 Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA.
   Univ Texas, Dept Elect & Comp Engn, Austin, TX 78712 USA.
C3 Rice University; University of Texas System; University of Texas Austin
RP Zhou, QM (corresponding author), Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA.
EM quming@rice.edu
CR Anderson B. D. O., 1979, OPTIMAL FILTERING
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Bradshaw KJ, 1997, IEEE T PATTERN ANAL, V19, P219, DOI 10.1109/34.584099
   Cai Q., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P68, DOI 10.1109/ICPR.1996.546796
   Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119
   Dockstader SL, 2001, P IEEE, V89, P1441, DOI 10.1109/5.959340
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Foresti GL, 1998, IEEE T CIRC SYST VID, V8, P697, DOI 10.1109/76.728411
   Gutchess D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P733, DOI 10.1109/ICCV.2001.937598
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Iqbal Q, 2002, PATTERN RECOGN, V35, P1463, DOI 10.1016/S0031-3203(01)00139-X
   Kaneko T, 2003, PROC CVPR IEEE, P796
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   Park S, 2004, MULTIMEDIA SYST, V10, P164, DOI 10.1007/s00530-004-0148-1
   Raja Y, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P228, DOI 10.1109/AFGR.1998.670953
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   Rigoll G., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P342, DOI 10.1109/AFGR.2000.840657
   Sato K, 2004, COMPUT VIS IMAGE UND, V96, P100, DOI 10.1016/j.cviu.2004.02.003
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Strobel N, 2001, IEEE SIGNAL PROC MAG, V18, P22, DOI 10.1109/79.911196
   Tan TN, 1996, PROC CVPR IEEE, P397, DOI 10.1109/CVPR.1996.517103
   Tommasini T, 1998, PROC CVPR IEEE, P178, DOI 10.1109/CVPR.1998.698606
   Triesch J., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P102, DOI 10.1109/AFGR.2000.840619
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P26, DOI 10.1109/ICCV.2001.937590
   ZHOU Q, 2001, INT WORKSH PERF EV T
   ZHOU Q, 2005, HDB PATTERN RECOGNIT, P499
   ZHOU Q, 2003, P INT S COMP INF SCI, P430
NR 31
TC 59
Z9 77
U1 2
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2006
VL 24
IS 11
BP 1244
EP 1255
DI 10.1016/j.imavis.2005.06.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 101CJ
UT WOS:000241716200009
DA 2024-07-18
ER

PT J
AU Srivastava, A
   Liu, XW
   Hesher, C
AF Srivastava, A
   Liu, XW
   Hesher, C
TI Face recognition using optimal linear components of range images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; range imaging; optimal component analysis; nearest
   neighbor classifier; Grassmann manifold
ID EIGENFACES
AB This paper investigates the use of range images of faces for recognizing people. 3D scans of faces lead to range images that are linearly projected to low-dimensional subspaces for use in a classifier, say a nearest neighbor classifier or a support vector machine, to label people. Learning of subspaces is performed using an optimal component analysis, i.e. a stochastic optimization algorithm (on a Grassmann manifold) to find a subspace that maximizes classifier performance on the training image set. Results are presented for face recognition using FSU face database, and are compared with standard component anlyses such as PCA and ICA. This provides an efficient tool for analyzing certain aspects of facial shapes while avoiding a difficult task of geometric surface modeling. (c) 2005 Elsevier B.V. All rights reserved.
C1 Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA.
   Florida State Univ, Dept Comp Sci, Tallahassee, FL 32306 USA.
C3 State University System of Florida; Florida State University; State
   University System of Florida; Florida State University
RP Florida State Univ, Dept Stat, Tallahassee, FL 32306 USA.
EM anuj@stat.fsu.edu
RI Srivastava, Anuj/F-7417-2011; Srivastava, Anuj/L-4705-2019
CR [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   ARVO J, 1991, GRAPHICS GEMS, pR2
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   CHANG K, 2003, IEEE WORKSH AN MOD F
   CHELLAPPA R, 1995, P IEEE, V83, P705, DOI 10.1109/5.381842
   CHEN X, 2003, IEEE WORKSH AN MOD F
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Gallagher S, 2003, INFANT CHILD DEV, V12, P301, DOI 10.1002/icd.330
   Grenander U, 1998, Q APPL MATH, V56, P617, DOI 10.1090/qam/1668732
   Hallinan P., 1999, Two and Three-dimensional Patterns of the Face
   Hyvärinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   KRESSEL UHG, 2002, ADV KERNEL METHODS S, P255
   Liu XW, 2004, IEEE T PATTERN ANAL, V26, P662, DOI 10.1109/TPAMI.2004.1273986
   MALASSIOTIS S, 2001, P INT C IM PROC
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   O'Toole AJ, 1999, VISION RES, V39, P3145, DOI 10.1016/S0042-6989(99)00034-6
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   Robert Christian P., 1999, Monte Carlo Statistical Methods, V2
   Srivastava A, 2003, IMAGE VISION COMPUT, V21, P651, DOI 10.1016/S0262-8856(03)00061-1
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang YJ, 2001, 11TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P48, DOI 10.1109/ICIAP.2001.956984
NR 22
TC 19
Z9 23
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2006
VL 24
IS 3
BP 291
EP 299
DI 10.1016/j.imavis.2005.07.023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 031PI
UT WOS:000236716100008
DA 2024-07-18
ER

PT J
AU Karayiannis, NB
   Tao, GZ
AF Karayiannis, NB
   Tao, GZ
TI An improved procedure for the extraction of temporal motion strength
   signals from video recordings of neonatal seizures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE clustering; median filtering; morphological filtering; motion
   segmentation; motion strength signal; neonatal seizure; video recording
ID MOTOR-ACTIVITY SIGNALS; QUANTIFYING MOTION; SYSTEM; CLASSIFICATION;
   SEGMENTATION; COUNTY
AB This paper presents a procedure developed to extract quantitative motion information from video recordings of neonatal seizures in the form of temporal motion strength signals. Temporal motion strength signals are obtained from a sequence of video frames by measuring the displacement areas of the infants' moving body part(s) from frame to frame of the video sequence. The proposed motion segmentation procedure relies on the application of non-linear filtering, vector clustering, and morphological filtering to the differences between adjacent frames. The experiments indicate that temporal motion strength signals constitute a satisfactory representation of videotaped clinical events and may be used for automated seizure recognition. (C) 2005 Elsevier B.V. All rights reserved.
C1 Univ Houston, Dept Elect & Comp Engn, Houston, TX 77204 USA.
C3 University of Houston System; University of Houston
RP Univ Houston, Dept Elect & Comp Engn, N308 Engn Bldg 1, Houston, TX 77204 USA.
EM karayiannis@uh.edu
CR [Anonymous], 2018, VOLPES NEUROLOGY NEW
   BERGMAN I, 1983, ANN NEUROL, V14, P642, DOI 10.1002/ana.410140607
   Choi JG, 1997, IEEE T CIRC SYST VID, V7, P279, DOI 10.1109/76.564107
   Dowdy S., 2004, STAT RES
   DUFAUX F, P INT C IM PROC WASH, V1, P306
   ELLENBERG JH, 1984, ANN NEUROL, V15, P127, DOI 10.1002/ana.410150204
   Fenichel GM., 1990, Neonatal neurology
   Galic S, 2000, IWISPA 2000: PROCEEDINGS OF THE FIRST INTERNATIONAL WORKSHOP ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P63, DOI 10.1109/ISPA.2000.914892
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HOLDEN KR, 1982, PEDIATRICS, V70, P165
   IVES JR, 1978, ELECTROEN CLIN NEURO, V45, P412, DOI 10.1016/0013-4694(78)90193-1
   IVES JR, 1991, ELECTROEN CLIN NEURO, V79, P69, DOI 10.1016/0013-4694(91)90158-Z
   Karayiannis NB, 2005, IEEE T IMAGE PROCESS, V14, P890, DOI 10.1109/TIP.2005.849320
   Karayiannis NB, 2005, IEEE T BIO-MED ENG, V52, P1065, DOI 10.1109/TBME.2005.846715
   Karayiannis NB, 2005, IEEE T BIO-MED ENG, V52, P676, DOI 10.1109/TBME.2005.845154
   Karayiannis NB, 2005, IEEE T BIO-MED ENG, V52, P747, DOI 10.1109/TBME.2005.844047
   Karayiannis NB, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P11, DOI 10.1109/ICDSP.2002.1027807
   Karayiannis NB, 1999, IEEE T MED IMAGING, V18, P172, DOI 10.1109/42.759126
   Karayiannis NB, 2001, IEEE T MED IMAGING, V20, P965, DOI 10.1109/42.952733
   Krishnan S, 1996, PATTERN RECOGN LETT, V17, P803, DOI 10.1016/0167-8655(96)00047-5
   LANSKA MJ, 1995, NEUROLOGY, V45, P724, DOI 10.1212/WNL.45.4.724
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   MIZRAHI E M, 1986, American Journal of EEG Technology, V26, P81
   Mizrahi Eli M., 2001, Epilepsia, V42, P102
   MIZRAHI EM, 1987, NEUROLOGY, V37, P1837, DOI 10.1212/WNL.37.12.1837
   MIZRAHI EM, 1984, ANN NEUROL, V16, P383
   PENRY JK, 1975, BRAIN, V98, P427, DOI 10.1093/brain/98.3.427
   PIERELLI F, 1989, EPILEPSIA, V30, P513, DOI 10.1111/j.1528-1157.1989.tb05465.x
   RECTOR D, 1993, ELECTROEN CLIN NEURO, V87, P380, DOI 10.1016/0013-4694(93)90151-K
   ROLAND M, 1998, SIGNAL PROCESS, V66, P203
   RONEN GM, 1995, ANN NEUROL, V38, P518
   Saliba RM, 1999, AM J EPIDEMIOL, V150, P763, DOI 10.1093/oxfordjournals.aje.a010079
   SCHER MS, 1993, PEDIATRICS, V91, P128
   THOMPSON WB, 1980, IEEE T PATTERN ANAL, V2, P543, DOI 10.1109/TPAMI.1980.6447701
   ZHENG S, 1998, P IEEE WORKSH NEUR N, P214
NR 35
TC 6
Z9 6
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 27
EP 40
DI 10.1016/j.imavis.2005.09.009
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200003
DA 2024-07-18
ER

PT J
AU Wu, Y
   He, YJ
   Cai, HM
AF Wu, Y
   He, YJ
   Cai, HM
TI Optimal threshold selection algorithm in edge detection based on wavelet
   transform
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE optimal threshold selection; edge detection; wavelet transform; minimum
   entropy
AB This paper presents an optimal threshold selection algorithm, which selects the de-noising threshold according to the turbulent degree of detected edge points, in edge detection based on wavelet transform. First of all, adjacent domain division algorithm (ADDA) and parabola fitting algorithm (PFA) are used to separate edge curves from each other after wavelet transform. Then, the entropies, corresponding to different possible thresholds are computed according to the number and length of all the edge curves detected above. The threshold, which giving the minimum entropy, is selected as the optimal one to filter the noises. The experimental results show that our method can get better threshold than other ones, in a subjective view. (C) 2005 Elsevier Ltd All rights reserved.
C1 Shanghai Jiao Tong Univ, Dept Comp Sci & Technol, Shanghai 200030, Peoples R China.
C3 Shanghai Jiao Tong University
RP Shanghai Jiao Tong Univ, Dept Comp Sci & Technol, Shanghai 200030, Peoples R China.
EM wuyong@cs.sjtu.edu.cn
RI Cai, Hongmin/M-8240-2019; He, Yujia/JJG-0563-2023
OI Cai, Hongmin/0000-0002-2747-7234; 
CR Banjanin B, 2001, IMAGE VISION COMPUT, V19, P477, DOI 10.1016/S0262-8856(00)00093-7
   Chang JS, 1997, IMAGE VISION COMPUT, V15, P23, DOI 10.1016/S0262-8856(96)01087-6
   DONG C, 1998, COMPUTER ENG DESIGN, V19, P35
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   LAINE AF, 1995, 1995 IEEE INT S, V3, P1956
   Lázaro JC, 2002, ULTRASONICS, V40, P263, DOI 10.1016/S0041-624X(02)00149-X
   LIU Z, 2000, IND APPL C 2000 2000, V2, P1048
   Madchakham S., 2001, P ACRS 2001 22 AS C, V2, P1307
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   QIONG X, 2000, J SICHUAN I LIGHT IN, V13, P13
   Starck JL, 2002, IEEE T IMAGE PROCESS, V11, P670, DOI [10.1109/TIP.2002.1014998, 10.1117/12.408568]
   Zhang L, 2002, PATTERN RECOGN LETT, V23, P1771, DOI 10.1016/S0167-8655(02)00151-4
   ZHIQIN Z, 2000, RAD C 2000 IEEE 2000, P551
NR 14
TC 15
Z9 22
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1159
EP 1169
DI 10.1016/j.imavis.2005.07.012
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500005
DA 2024-07-18
ER

PT J
AU Pujol, O
   Gil, D
   Radeva, P
AF Pujol, O
   Gil, D
   Radeva, P
TI Fundamentals of Stop and Go active models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE deformable models; geodesic snakes; region-based segmentation
ID SNAKES; IMAGE
AB An efficient snake formulation should conform to the idea of picking the smoothest curve among all the shapes approximating an object of interest. In current geodesic snakes, the regularizing curvature also affects the convergence stage, hindering the latter at concave regions. In the present work, we make use of characteristic functions to define a novel geodesic formulation that decouples regularity and convergence. This term decoupling endows the snake with higher adaptability to non-convex shapes. Convergence is ensured by splitting the definition of the external force into an attractive vector field and a repulsive one. In our paper, we propose to use likelihood maps as approximation of characteristic functions of object appearance. The better efficiency and accuracy of our decoupled scheme are illustrated in the particular case of feature space-based segmentation. (c) 2005 Elsevier B.V. All rights reserved.
C1 Ctr Vis Comp, Barcelona 08193, Spain.
C3 Centre de Visio per Computador (CVC)
RP Ctr Vis Comp, Edifici O,Campus UAB, Barcelona 08193, Spain.
EM oriol@cvc.uab.es
RI Radeva, Petia/I-3385-2015; gil, debora/H-4320-2015; Pujol,
   Oriol/F-7146-2016
OI Radeva, Petia/0000-0003-0047-5172; gil, debora/0000-0002-2770-4767;
   Pujol, Oriol/0000-0001-7573-009X
CR CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chakraborty A, 1996, IEEE T MED IMAGING, V15, P859, DOI 10.1109/42.544503
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Duda R. O., 2000, PATTERN CLASSIFICATI
   EVANS LC, 1993, BERKELEY MATH LECT B, V3
   GIL D, 2003, EMMCVP 03
   Hofmann T, 1998, IEEE T PATTERN ANAL, V20, P803, DOI 10.1109/34.709593
   Jehan-Besson S, 2003, INT J COMPUT VISION, V53, P45, DOI 10.1023/A:1023031708305
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   McInerney T, 2000, MED IMAGE ANAL, V4, P73, DOI 10.1016/S1361-8415(00)00008-6
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P300, DOI 10.1109/CVPR.1999.784648
   PARAGIOS N, 1999, P COMP VIS PATT REC, V2, P422
   Pujol O., 2004, INT J IMAGE GRAPHICS, V4, P433
   PUJOL O, 2004, THESIS
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   SAMSON C, 1999, P SCAL SPAC THEOR CO, P26
   Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562
   TVEITO A, 1998, TEXTS APPL MATH, V269
   Xu CY, 1998, SIGNAL PROCESS, V71, P131, DOI 10.1016/S0165-1684(98)00140-6
   Xu CY, 2000, CONF REC ASILOMAR C, P483, DOI 10.1109/ACSSC.2000.911003
   YEZZI A, 1999, INT C IM PROC KOB JA
   ZHU SC, 9410 HARW ROB LAB
NR 24
TC 5
Z9 6
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2005
VL 23
IS 8
BP 681
EP 691
DI 10.1016/j.imavis.2005.03.007
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VD
UT WOS:000231400500001
DA 2024-07-18
ER

PT J
AU Rodtook, S
   Makhanov, SS
AF Rodtook, S
   Makhanov, SS
TI Numerical experiments on the accuracy of rotation moments invariants
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE rotation invariant moments; wavelets
ID IMAGE-ANALYSIS; ZERNIKE MOMENTS; RECOGNITION
AB Rotationally invariant moments constitute important techniques applicable to a versatile number of pattern recognition applications. Although the moments are invariant with regard to spatial transformations, in practice, due to the finite screen resolution, the spatial transformation themselves affect the invariance. This phenomenon jeopardizes the quality of pattern recognition. Therefore, this paper presents an experimental analysis of the accuracy and efficiency of discrimination under the impact of the most important spatial transformations such as rotation and scaling. We evaluate experimentally the impact of the noise induced by the spatial transformations oil the most popular basis functions such as Zernike polynomials, Mellin polynomials and wavelets. The analysis reveals that the wavelet based moment invariants constitute one of the best choices to construct noise resistant features. (c) 2005 Elsevier B.V. All rights reserved.
C1 Thammasat Univ, Sirindhorn Int Inst Technol, Informat Technol Program, Pathum Thani 12121, Thailand.
C3 Thammasat University
RP Rodtook, S (corresponding author), Thammasat Univ, Sirindhorn Int Inst Technol, Informat Technol Program, Rangsit Campus, Pathum Thani 12121, Thailand.
EM sittisak@siit.tu.ac.th
RI Makhanov, Stanislav/AAT-6430-2020; Rodtook, Annupan/GOV-7658-2022;
   S.Makhanov/ABA-3316-2020
OI S.Makhanov/0000-0002-1906-0359; Rodtook, Annupan/0000-0001-5433-1305
CR *FIN ARTS DEP THAI, 2000, VIS DAT THAI MUS INS
   Flusser J, 2000, PATTERN RECOGN, V33, P1405, DOI 10.1016/S0031-3203(99)00127-2
   Flusser J, 2002, PATTERN RECOGN, V35, P3015, DOI 10.1016/S0031-3203(02)00093-6
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   KAN C, 2001, WESCANEX 01 IEEE P, P511
   LI Y, 1995, PATTERN RECOGN, V25, P115
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   LIAO SX, 1997, C COMM POW COMP WESC, P157
   MUKUNDAN R, 1995, PATTERN RECOGN, V28, P1433, DOI 10.1016/0031-3203(95)00011-N
   Mukundan R, 2001, IEEE T IMAGE PROCESS, V10, P1357, DOI 10.1109/83.941859
   PASCHALAKIS S, 1999, IMAGE PROCESS ITS AP, V465, P245
   Shen DG, 1999, PATTERN RECOGN, V32, P151, DOI 10.1016/S0031-3203(98)00137-X
   SHEN J, 2001, SERIES MACHINE PERCE, V44, P17
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   THUILLARD M, SERIES ROBOTICES INT, V25
   WICKHAM JA, 1986, VISUAL AIRCRAFT RECO
   YANNI MK, 1995, THESIS U KENT
   Yap PT, 2003, IEEE T IMAGE PROCESS, V12, P1367, DOI 10.1109/TIP.2003.818019
NR 18
TC 7
Z9 7
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2005
VL 23
IS 6
BP 577
EP 586
DI 10.1016/j.imavis.2005.02.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 924CA
UT WOS:000228955100003
DA 2024-07-18
ER

PT J
AU Sivignon, I
   Breton, R
   Dupont, F
   Andrés, E
AF Sivignon, I
   Breton, R
   Dupont, F
   Andrés, E
TI Discrete analytical curve reconstruction without patches
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE discrete object; invertible Euclidean reconstruction
ID REPRESENTATION
AB Invertible Euclidean reconstruction methods without patches for 2D and 3D discrete curves are proposed. From a discrete 4-connected curve in 2D, or 6-connected curve in 3D, the proposed algorithms compute a polygonal line which digitization with the standard model is equal to all the pixels or voxels of the curve. The framework of this method is the discrete analytical geometry and parameter spaces are used in order to simplify the algorithms. Moreover, the reconstructed polyline is more compact than classical methods such as the Marching Cubes. (C) 2004 Elsevier B.V. All rights reserved.
C1 CNRS, UMR 5083, Lab LIS Grenoble, F-38402 St Martin Dheres, France.
   Univ Lyon 1, CNRS, FRE 2672, Lab LIRIS, F-69622 Villeurbanne, France.
   Univ Poitiers, CNRS, FRE 2731, Lab SIC, F-86962 Futuroscope, France.
C3 Centre National de la Recherche Scientifique (CNRS); Institut National
   des Sciences Appliquees de Lyon - INSA Lyon; Universite Claude Bernard
   Lyon 1; Centre National de la Recherche Scientifique (CNRS); Universite
   de Poitiers; Centre National de la Recherche Scientifique (CNRS)
RP CNRS, UMR 5083, Lab LIS Grenoble, 961,Rue Houille Blanche, F-38402 St Martin Dheres, France.
EM sivignon@lis.inpg.fr
OI Dupont, Florent/0000-0001-6611-4420
CR Andres E, 2003, GRAPH MODELS, V65, P92, DOI 10.1016/S1524-0703(03)00004-3
   ANDRES E, 2002, LNCS, V2301, P313
   Breton R, 2003, LECT NOTES COMPUT SC, V2886, P246
   COEURJOLLY D, 2002, THESIS U LUMIERE LYO
   Debled-Rennesson I., 1995, THESIS U L PASTEUR S
   DORST L, 1984, IEEE T PATTERN ANAL, V6, P450, DOI 10.1109/TPAMI.1984.4767550
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Freeman H., 1970, BOUNDARY ENCODING PR, P241
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Jonas A, 1997, PATTERN RECOGN, V30, P1803, DOI 10.1016/S0031-3203(97)00011-3
   KLETTE R, 2001, LECT NOTES COMPUT SC, V2059, P356
   LINDENBAUM M, 1993, IEEE T PATTERN ANAL, V15, P949, DOI 10.1109/34.232082
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Maitre H., 1985, Traitement du Signal, V2, P305
   MCILROY MD, 1985, AT&T TECH J, V64, P481, DOI 10.1002/j.1538-7305.1985.tb00359.x
   Milanfar P, 1996, PATTERN RECOGN LETT, V17, P209, DOI 10.1016/0167-8655(95)00111-5
   ROSENFELD A, 1995, PATTERN RECOGN LETT, V16, P305, DOI 10.1016/0167-8655(94)00102-9
   Veelaert P, 1999, J MATH IMAGING VIS, V11, P99, DOI 10.1023/A:1008325426721
   Vittone J, 2000, LECT NOTES COMPUT SC, V1953, P296
   VITTONE J, 1999, THESIS U J FOURIER
NR 20
TC 15
Z9 15
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 191
EP 202
DI 10.1016/j.imavis.2004.06.014
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Boufama, B
   Habed, A
AF Boufama, B
   Habed, A
TI Three-dimensional structure calculation: achieving accuracy without
   calibration
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE three-dimensional reconstruction; camera motion; essential matrix;
   self-calibration; Kruppa's equations
ID SELF-CALIBRATION; POINT CORRESPONDENCES; MOTION
AB The problem of Euclidean 3D reconstruction is closely related to the calibration of the camera. It is well known that self-calibration methods only provide an approximate solution to camera parameters and their accuracy is undermined by the correspondence problem. However, we demonstrate through this article, that recovering the Euclidean 3D structure of a scene can be achieved in an accurate manner without resorting to a highly precise estimate of the intrinsic parameters. Mainly, we describe a three-step procedure in which we jointly use the simplified form of the Kruppa's equations, a normalization of pixel coordinates and the Eight-Point algorithm to recover the three-dimensional structure with high accuracy even in the presence of noise. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada.
C3 University of Windsor
RP Boufama, B (corresponding author), Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada.
EM boufama@uwindsor.ca; habed@uwindsor.ca
CR [Anonymous], P ECCV
   BOUFAMA B, 1994, P 3 EUR C COMP VIS S, P199
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564
   Fusiello A, 2000, IMAGE VISION COMPUT, V18, P555, DOI 10.1016/S0262-8856(99)00065-7
   FUSIELLO A, 2001, LECT NOTES COMPUTER, V2124, P717
   Hartley R., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P761, DOI 10.1109/CVPR.1992.223179
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley R.I., 1993, Proc. DARPA Image Understanding Workshop, P745
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P133, DOI 10.1109/34.574792
   HEYDEN A, 1996, P 13 INT C PATT REC, V1
   HUANG TS, 1994, P IEEE, V82, P252, DOI 10.1109/5.265351
   Kruppa E., 1913, Sitz.-Ber. Akad. Wiss., Wien, V122, P1939
   LAVEST J, 1991, ACT 8 C AFCET REC FO, V1, P293
   LEE CH, 1990, COMPUT VISION GRAPH, V52, P309, DOI 10.1016/0734-189X(90)90078-A
   LEE J, 2000, IEEE T PATTERN ANAL, V22, P1199
   LEI C, 2002, ICPR02, V2, P308
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   LOURAKIS MI, 2000, P AS C COMP VIS TAIP, V1, P403
   Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991
   MA Y, 2000, P 6 EUR C COMP VIS D, P561
   MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171
   MENDONCA P, 1999, P C COMP VIS PATT RE, V1, P500
   Pollefeys M, 1999, IEEE T PATTERN ANAL, V21, P707, DOI 10.1109/34.784285
   Roth G, 2002, INT C PATT RECOG, P312, DOI 10.1109/ICPR.2002.1048302
   SHASHUA A, 1992, 1363 AI MIT
   Sturm P, 1997, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.1997.609467
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388
   WEINSHALL D, 1993, INT J COMPUT VISION, V10, P27, DOI 10.1007/BF01440845
   WENG JY, 1993, IEEE T PATTERN ANAL, V15, P864, DOI 10.1109/34.232074
   ZELLER C, 1996, 2793 INRIA
   ZHANG Z, 1998, P AS C COMP VIS HONG, P567
NR 35
TC 6
Z9 8
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 1039
EP 1049
DI 10.1016/j.imavis.2004.03.015
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800010
DA 2024-07-18
ER

PT J
AU Han, CC
AF Han, CC
TI A hand-based personal authentication using a coarse-to-fine strategy
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE personal authentication; hand geometry; palmprint feature; biometric
   system; coarse to fine strategy
ID DECISION-LEVEL FUSION; PALMPRINT IDENTIFICATION; STACK FILTERS;
   VERIFICATION; RECOGNITION; FEATURES; GLVQ
AB Biometrics-based verification is an effective approach to personal authentication using biological features extracted from the individual. In this paper, we propose specific verification technology by making use of hand-based features. Two hand-based features, the hand geometry and the palmprint, are simultaneously grabbed by the CCD camera-based devices. Basically, geometrical features of the hands are used to roughly verify the identity. The samples possessing the confused hand shapes should be to re-check by the palmprint features. First, the crucial points and the ROI of palmprint are determined in the preprocessing stage. The hand shape features of length 11 are computed from these detected points. Next, the multi-resolutional palmprint features are extracted from the ROI and the three middle fingers. In that way the reference vectors are obtained for computing the similarity values in various resolutions. In addition, the various verified results in multiple resolutions are integrated to achieve a better performance by using the positive Boolean function (PBF) and the bootstrapping method. Experimental results were conducted to show the effectiveness of our proposed approaches. (C) 2004 Elsevier B.V. All rights reserved.
C1 Natl United Univ, Dept Comp Sci & Informat Engn, Miaoli, Taiwan.
C3 National United University
RP Han, CC (corresponding author), Natl United Univ, Dept Comp Sci & Informat Engn, Miaoli, Taiwan.
EM cchan@chu.edu.tw
RI Han, Chin-Chuan/B-2642-2012
CR *AFB, 1999, 5 STEP GUID SEL BIOM
   ANDERSON C, 2003, PATTERN RECOGN, V36, P293
   Chatzis V, 1999, IEEE T SYST MAN CY A, V29, P674, DOI 10.1109/3468.798073
   Chibelushi CC, 2002, IEEE T MULTIMEDIA, V4, P23, DOI 10.1109/6046.985551
   COYLE EJ, 1988, IEEE T ACOUST SPEECH, V36, P1244, DOI 10.1109/29.1653
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   Golfarelli M, 1997, IEEE T PATTERN ANAL, V19, P786, DOI 10.1109/34.598237
   GONZALEZ AI, 1995, IEEE T NEURAL NETWOR, V6, P1012, DOI 10.1109/72.392266
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   Han CC, 1997, IEEE T SIGNAL PROCES, V45, P1857, DOI 10.1109/78.599960
   Hong L, 1998, IEEE T PATTERN ANAL, V20, P1295, DOI 10.1109/34.735803
   Joshi DG, 1998, PATTERN RECOGN, V31, P15, DOI 10.1016/S0031-3203(97)00034-4
   Karayiannis NB, 1996, IEEE T NEURAL NETWOR, V7, P1062, DOI 10.1109/72.536304
   Kohonen, 1989, SELF ORG ASS MEMORY
   PHILLIPS K, 1997, PC WEEK
   Prabhakar S, 2002, PATTERN RECOGN, V35, P861, DOI 10.1016/S0031-3203(01)00103-0
   Sato A, 1996, ADV NEUR IN, V8, P423
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wen CJ, 1996, OPT ENG, V35, P2721, DOI 10.1117/1.600837
   WENDT PD, 1986, IEEE T ACOUST SPEECH, V34, P898, DOI 10.1109/TASSP.1986.1164871
   You J, 2004, IEEE T CIRC SYST VID, V14, P234, DOI 10.1109/TCSVT.2003.821978
   You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
   ZUNKEL RL, 1999, BIOMETRICS, P87
NR 25
TC 65
Z9 74
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2004
VL 22
IS 11
BP 909
EP 918
DI 10.1016/j.imavis.2004.05.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 847MJ
UT WOS:000223396600005
DA 2024-07-18
ER

PT J
AU Xie, BL
   Ramesh, V
   Boult, T
AF Xie, BL
   Ramesh, V
   Boult, T
TI Sudden illumination change detection using order consistency
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Statistical Methods in Video Processing
CY JUN 01-02, 2002
CL COPENHAGEN, DENMARK
DE change detection; illumination change; order consistency
AB Effective change detection under dynamic illumination conditions is an active research topic. Most research has concentrated on adaptive statistical representations for the appearance of the background scene. There is limited work that develops the statistical models for background representation by taking into account an explicit model for the camera response function, the camera noise model, and illumination priors. Assuming a monotone but non-linear camera response function, a Phong shading model for the surface material, and a locally constant but spatially varying illumination, we show that the sign of the difference between two pixel measurements is maintained across global illumination changes. We use this result along with a statistical model for the camera noise to develop a change detection algorithm that deals with sudden changes in illumination. The performance evaluation of the algorithm is done through simulations and on real data. (C) 2003 Elsevier B.V. All rights reserved.
C1 Lehigh Univ, Dept Elect & Comp Engn, Bethlehem, PA 18015 USA.
   Siemens Corp Res, Princeton, NJ 08540 USA.
   Univ Colorado, Dept Comp Sci, Colorado Springs, CO 80933 USA.
C3 Lehigh University; Siemens AG; University of Colorado System; University
   of Colorado at Colorado Springs
RP Lehigh Univ, Dept Elect & Comp Engn, 19 Mem Dr W, Bethlehem, PA 18015 USA.
EM bix2@lehigh.edu
RI Boult, Terrance E./AAT-2134-2021
OI Boult, Terrance E./0000-0001-5007-2529
CR Boult TE, 2001, P IEEE, V89, P1382, DOI 10.1109/5.959337
   BUITUONG P, 1975, COMMUN ACM, V18, P311
   Collins R., 2000, CMURITR0012
   Comaniciu D, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P11, DOI 10.1109/VS.2000.856853
   ELGAMMAL A, 1999, FRAME RATE99
   Greiffenhagen M, 2000, PROC CVPR IEEE, P335, DOI 10.1109/CVPR.2000.854840
   GREIFFENHAGEN M, 2001, P IEEE C COMP VIS PA
   Huwer S, 2000, THIRD IEEE INTERNATIONAL WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P37, DOI 10.1109/VS.2000.856856
   OLIVER N, 1998, IUW98, P293
   Rittscher J., 2000, P EUR C COMP VIS
   Rosin PL, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P274, DOI 10.1109/ICCV.1998.710730
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Stenger B, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P294, DOI 10.1109/ICCV.2001.937532
   Toth D., 2000, 4th IEEE Southwest Symposium on Image Analysis and Interpretation, P3, DOI 10.1109/IAI.2000.839561
   Toyama K., 1999, The Proceedings of the Seventh IEEE International Conference on Computer Vision, V1, P255
   Tsin Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P480, DOI 10.1109/ICCV.2001.937555
NR 16
TC 37
Z9 41
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2004
VL 22
IS 2
BP 117
EP 125
DI 10.1016/j.imavis.2003.07.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 769DW
UT WOS:000188612000005
DA 2024-07-18
ER

PT J
AU Baligar, VP
   Patnaik, LM
   Nagabhushana, GR
AF Baligar, VP
   Patnaik, LM
   Nagabhushana, GR
TI High compression and low order linear predictor for lossless coding of
   grayscale images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image compression; bit-plane coding; quadtree decomposition; linear
   prediction
AB In this paper we propose a novel method for designing block-wise lossless image compression scheme using linear predictors. In this prediction scheme, the prediction for each pixel is formed by using a set of least-square-based linear prediction coefficients of the block to which the current pixel belongs. Predicted value of each pixel is subtracted from the actual value of the current pixel to get an error image. An error image is compressed using grayscale bit plane coding using quadtree method. Experimental results show that the compression performance of the proposed method is superior to Joint Photographics Expert Group's [1] JPEG-LS [IEEE Trans. Image Processing 9 (2000) 1309] method, and Classified Adaptive Prediction and Entropy Coding in terms of coding performance. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Indian Inst Sci, Dept High Voltage Engn, Bangalore 12, Karnataka, India.
   Indian Inst Sci, Dept Comp Sci & Automat, Microproc Applicat Lab, Bangalore 12, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore; Indian Institute of
   Science (IISC) - Bangalore
RP Indian Inst Sci, Dept High Voltage Engn, Bangalore 12, Karnataka, India.
EM baligar@hve.iisc.ernet.in; lalit@micro.iisc.ernet.in;
   grn@hve.iisc.ernet.in
RI Baligar, Vishwanath/AAA-7923-2019; Patil, Tanuja/AAC-4840-2019
CR Golchin F, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P110, DOI 10.1109/ICIP.1997.632006
   *ISO IEC, 1998, 144951 ISOIEC
   *ISO IEC, 2000, FDC154441 ISOIEC
   Jayant N.C., 1984, Digital Coding of Waveforms: Principles and Applications to Speech and Video
   Press W. H, 2001, NUMERICAL RECIPES C
   Raftery AE, 1997, J AM STAT ASSOC, V92, P179, DOI 10.2307/2291462
   SAMET H, 1980, COMMUN ACM, V23, P163, DOI 10.1145/358826.358836
   SCHWART JW, 1996, IEEE T AERO ELEC SYS, V2, P385
   TAKAHASI K, 1985, P ICC, P34
   Weinberger MJ, 2000, IEEE T IMAGE PROCESS, V9, P1309, DOI 10.1109/83.855427
   Wu XL, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P901, DOI 10.1109/ICIP.1998.727397
NR 11
TC 11
Z9 11
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2003
VL 21
IS 6
BP 543
EP 550
DI 10.1016/S0262-8856(03)00034-9
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 688BA
UT WOS:000183411300007
DA 2024-07-18
ER

PT J
AU Stegmann, MB
   Larsen, R
AF Stegmann, MB
   Larsen, R
TI Multi-band modelling of appearance
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE generative model; active appearance model; lighting invariance; face
   recognition; segmentation
AB Earlier work has demonstrated generative models capable of synthesising near photo-realistic grey-scale images of objects. These models have been augmented with colour information, and recently with edge information. This paper extends the active appearance model framework by modelling the appearance of both derived feature bands and an intensity band. As a special case of feature-band augmented appearance modelling we propose a dedicated representation with applications to face segmentation. The representation addresses a major problem within face recognition by lowering the sensitivity to lighting conditions. Results show that the localisation accuracy of facial features is considerably increased using this appearance representation under diffuse and directional lighting and at multiple scales. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Tech Univ Denmark, DK-2800 Lyngby, Denmark.
C3 Technical University of Denmark
RP Tech Univ Denmark, Richard Petersens Plads,Bldg 321, DK-2800 Lyngby, Denmark.
EM mbs@imm.dtu.dk
OI Larsen, Rasmus/0000-0001-8507-0523
CR [Anonymous], STAT MODELS APPEARAN
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Bosch HG, 2001, PROC SPIE, V4322, P257, DOI 10.1117/12.431095
   BRADSKI G, 1998, INTEL TECHNOLOGY J I
   COMON P, 1994, SIGNAL PROCESS, V36, P287, DOI 10.1016/0165-1684(94)90029-9
   Cootes T., 1998, Proc. ECCV, V2, P484
   Cootes TF, 2001, PROC CVPR IEEE, P1114
   Cootes TF, 2001, PROC SPIE, V4322, P236, DOI 10.1117/12.431093
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Edwards G., 1998, PROC 5 EUROPEAN C CO, V2, P581
   Edwards GJ, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P300, DOI 10.1109/AFGR.1998.670965
   Fisher N. I., 1993, STAT ANAL CIRCULAR D, DOI DOI 10.1017/CBO9780511564345
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Isidoro J, 1998, COMP ANIM CONF PROC, P137, DOI 10.1109/CA.1998.681918
   Jones MJ, 1998, INT J COMPUT VISION, V29, P107, DOI 10.1023/A:1008074226832
   MITCHELL S, 2001, MED IMAGING 2001 IMA, V1, P249
   Mitchell SC, 2001, IEEE T MED IMAGING, V20, P415, DOI 10.1109/42.925294
   Perona P., 1987, Proceedings of the IEEE Computer Society Workshop on Computer Vision (Cat. No.87TH0210-5), P16
   Sclaroff S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1146, DOI 10.1109/ICCV.1998.710860
   Stegmann M. B., 2001, P 10 DAN C PATT REC, P54
   STEGMANN MB, 2001, P 12 SCAND C IM AN S, V1, P90
   SWITZER P, 1984, 6 STANF U, P10
   THODBERG HH, 2002, MED IMAGING 2002 IMA
   Vetter T, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P22, DOI 10.1109/AFGR.1996.557239
NR 25
TC 36
Z9 65
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 61
EP 67
AR PII S0262-8856(02)00126-9
DI 10.1016/S0262-8856(02)00126-9
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800007
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Huang, ZY
   Qin, PZ
   Yu, Z
   Tahsin, L
   Wang, MY
   Liu, M
AF Huang, Zhiyong
   Qin, Pinzhong
   Yu, Zhi
   Tahsin, Lamia
   Wang, Mengyao
   Liu, Man
TI Transformer-based feature interactor for person re-identification with
   margin self-punishment loss
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Attention mechanism; Representation learning;
   Transformer
ID NETWORK; ATTENTION
AB Person re-identification aims to retrieve specific pedestrians from different cameras and scenes, in which extracting robust and discriminative features is crucial for this task. To explore the potential interactions among images and learn more robust representations, this paper proposes Transformer-based Feature Interactor(TFI) and improved Margin Self-punishment Softmax loss(MS-Softamx). The Transformer-based Feature Interactor consists of Group Channel Pyramid Attention(GCPA) and Neighbor Interaction Modeling(NIM). Firstly, the Group Channel Pyramid Attention module provides prior information for high-level semantics via low-level semantics. The attention information is gradually stacked from coarse to fine to obtain enhanced hierarchical multi-scale features. Then, Neighbor Interaction Modeling effectively model the input and similar neighbors to produce a more robust and discriminative image representation. To make TFI more focused on intra-class embedding learning, we also propose Margin Self-punishment Softmax guide deep network learning, which obtains a tighter custom classification boundary by pushing the inter-class threshold and minimizing the intraclass variance. The proposed method is verified on four datasets, and this achieves 92.8%/95.6% mAP/Rank-1 on Market1501, 86.1%/90.8% mAP/Rank-1 on DukeMTMC, 64.4%/ 81.2% mAP/Rank-1 on MSMT17, 79.7%/ 80.8% mAP/Rank-1 on CUHK03-detected and 81.8%/81.9% mAP/Rank-1 on CUHK03-labeled. Extensive experiments demonstrate that the proposed method achieves competitive performance with other state-of-the-art methods.
C1 [Huang, Zhiyong; Qin, Pinzhong; Yu, Zhi; Wang, Mengyao; Liu, Man] Chongqing Univ, Sch Microelect & Commun Engn, Chongqing 400044, Peoples R China.
   [Tahsin, Lamia] Univ Dev Alternat, Dept Comp Sci & Engn, Dhaka 1205, Bangladesh.
C3 Chongqing University
RP Huang, ZY (corresponding author), Chongqing Univ, Sch Microelect & Commun Engn, Chongqing 400044, Peoples R China.
EM zyhuang@cqu.edu.cn; pinzhongq@cqu.edu.cn; zhiy@cqu.edu.cn;
   wanmenyao@cqu.edu.cn; LiuMan@cqu.edu.cn
FU National Key Ramp;D Program of China [2021YFC2009200]
FX Acknowledgments This work was supported by grants from the National Key
   R&D Program of China (No. 2021YFC2009200) .
CR Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen CQ, 2022, IEEE T IMAGE PROCESS, V31, P2352, DOI 10.1109/TIP.2022.3141868
   Chen DP, 2018, PROC CVPR IEEE, P8649, DOI 10.1109/CVPR.2018.00902
   Chen GY, 2021, IEEE T IMAGE PROCESS, V30, P7663, DOI 10.1109/TIP.2021.3107211
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen X., 2021, arXiv
   Chen Y, 2022, PATTERN RECOGN LETT, V157, P90, DOI 10.1016/j.patrec.2022.03.020
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Fang PF, 2019, IEEE I CONF COMP VIS, P8029, DOI 10.1109/ICCV.2019.00812
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZY, 2022, NEURAL COMPUT APPL, V34, P20639, DOI 10.1007/s00521-022-07496-8
   Islam MA, 2017, PROC CVPR IEEE, P4877, DOI 10.1109/CVPR.2017.518
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Kuan Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P346, DOI 10.1007/978-3-030-58580-8_21
   Lei JJ, 2019, IEEE T CIRC SYST VID, V29, P2453, DOI 10.1109/TCSVT.2018.2866260
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YC, 2022, PEERJ COMPUT SCI, V8, DOI 10.7717/peerj-cs.1098
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu C, 2022, PATTERN RECOGN, V127, DOI 10.1016/j.patcog.2022.108654
   Liu W, 2017, ADV SOC SCI EDUC HUM, V99, P212
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Martinel N, 2020, IEEE T IMAGE PROCESS, V29, P7306, DOI 10.1109/TIP.2020.3000904
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Rao YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1005, DOI 10.1109/ICCV48922.2021.00106
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Sharma C, 2021, Arxiv, DOI arXiv:2106.03720
   Shizhen Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P647, DOI 10.1007/978-3-030-58539-6_39
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang HC, 2022, PROC CVPR IEEE, P7287, DOI 10.1109/CVPR52688.2022.00715
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xu J, 2018, PROC CVPR IEEE, P2119, DOI 10.1109/CVPR.2018.00226
   Yang B, 2022, MULTIMED TOOLS APPL, V81, P39169, DOI 10.1007/s11042-022-13170-x
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Zhang GW, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P516, DOI 10.1145/3474085.3475202
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao Jiaqi, 2022, IEEE Transactions on Multimedia
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, IEEE T CIRC SYST VID, V29, P3037, DOI 10.1109/TCSVT.2018.2873599
   Zhu JQ, 2018, IEEE T CIRC SYST VID, V28, P3183, DOI 10.1109/TCSVT.2017.2734740
   Zhu K, 2024, Arxiv, DOI arXiv:2104.00921
NR 63
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104752
DI 10.1016/j.imavis.2023.104752
EA JUL 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P1YF3
UT WOS:001048660300001
DA 2024-07-18
ER

PT J
AU Lv, G
   Sun, YN
   Nian, FD
   Zhu, MF
   Tang, WL
   Hu, ZZ
AF Lv, Gang
   Sun, Yining
   Nian, Fudong
   Zhu, Maofei
   Tang, Wenliang
   Hu, Zhenzhen
TI COME: Clip-OCR and Master ObjEct for text image captioning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image captioning; Graph convolution network; OCR; LSTM
AB Text image captioning aims to understand the scene text in images for generating image captions. The key chal-lenge of this task is to accurately and comprehensively understand the OCR tokens of scene text. Due to the dual modal of visual and textual features of scene text, expressing the multimodal semantic features of OCR tokens ac-curately is a challenging task. Additionally, since scene text cannot exist independently of specific objects and is always associated with its surroundings, establishing a scene graph centered around OCR tokens is also an impor-tant approach to understand its relationship with other objects in the image. In this paper, we propose a novel model named Clip -OCR and Master ObjEct (dubbed as COME) for text image captioning. First, we introduce a CLIP-OCR module to enhance the multimodal representation of OCR tokens. We separate the OCR representation into visual and textual items and narrow the similarity by contrastive learning. With the assistance of the CLIP -OCR module, we realize correlation alignment between different modes. Next, we propose the concept of master object for each OCR text and purify the OCR-oriented scene graph with it. The master object is defined as the ob-ject to which the OCR is attached, which bridges the semantic relationship between the OCR tokens and the image. We consider the master object as a proxy that connects OCR tokens and other regions in the image. By ex-ploring the master object for each OCR token, we build a purified scene graph based on the master object and then enrich the visual embedding by the Graph Convolution Network (GCN). Furthermore, we cluster the OCR tokens and append the hierarchical information on the input embedding to provide a complete representation. Experiments on the TextCaps validation set and test set demonstrate the effectiveness of the proposed framework.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Lv, Gang; Sun, Yining] Univ Sci & Technol China, Hefei, Peoples R China.
   [Lv, Gang; Sun, Yining] Chinese Acad Sci, Hefei Inst Phys Sci, Hefei, Peoples R China.
   [Nian, Fudong; Zhu, Maofei] Anhui Prov Engn Technol Res Ctr Intelligent Vehicl, Hefei, Peoples R China.
   [Tang, Wenliang; Hu, Zhenzhen] Hefei Univ Technol, Hefei, Peoples R China.
   [Lv, Gang] Chizhou Univ, Chizhou, Peoples R China.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Chinese Academy of Sciences; Hefei Institutes of Physical
   Science, CAS; Hefei University of Technology; Chizhou University
RP Lv, G (corresponding author), Univ Sci & Technol China, Hefei, Peoples R China.
EM lvgang@hfuu.edu.cn
FU University Synergy Innovation Program of Anhui Province [GXXT-2022-043];
   Excellent Scienti fic Research and Innovation Team of Anhui Colleges
   [2022AH010098]
FX Acknowledgements This work was supported by University Synergy
   Innovation Program of Anhui Province (Grant No. GXXT-2022-043) and
   Excellent Scienti fic Research and Innovation Team of Anhui Colleges
   (No.2022AH010098) .
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Baldrati A, 2022, PROC CVPR IEEE, P21434, DOI 10.1109/CVPR52688.2022.02080
   Bojanowski P., 2017, Transactions of the Association for Computational Linguistics, V5, P135, DOI DOI 10.1162/TACLA00051
   Borisyuk F, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P71, DOI 10.1145/3219819.3219861
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   Denkowski Michael, 2014, P 9 WORKSH STAT MACH, DOI [10.3115/v1/W14-3348, DOI 10.3115/V1/W14-3348]
   Gal R, 2022, ACM T GRAPHIC, V41, DOI 10.1145/3528223.3530164
   Hessel J., 2021, arXiv
   Hu NN, 2023, NEUROCOMPUTING, V519, P69, DOI 10.1016/j.neucom.2022.11.045
   Hu R., 2020, COMPUTER VISION ECCV, P742
   Hu Ronghang, 2020, 2020 IEEE CVF C COMP, P9992, DOI DOI 10.1109/CVPR42600.2020.01001
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Jing Wang, 2020, MM '20: Proceedings of the 28th ACM International Conference on Multimedia, P4337, DOI 10.1145/3394171.3413753
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li JH, 2021, ADV NEUR IN, V34
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Liu SQ, 2017, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2017.100
   Liu XB, 2018, PROC CVPR IEEE, P5676, DOI 10.1109/CVPR.2018.00595
   Lu XP, 2021, IEEE INT CONF COMP V, P2631, DOI 10.1109/ICCVW54120.2021.00297
   Luo HS, 2022, NEUROCOMPUTING, V508, P293, DOI 10.1016/j.neucom.2022.07.028
   Ma HY, 2022, PROC CVPR IEEE, P18030, DOI 10.1109/CVPR52688.2022.01752
   Ma Y., P 30 ACM INT C MULTI, P638
   Narasimhan M, 2021, 35 C NEURAL INFORM P, V34
   Nukrai D, 2022, Arxiv, DOI arXiv:2211.00575
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Radford A, 2021, PR MACH LEARN RES, V139
   Ram A., 2010, International Journal of Computer Applications, V3, P1, DOI DOI 10.5120/739-1038
   Ren S., 2015, NEURAL INFORM PROCES, V28, P91, DOI DOI 10.1109/TPAMI.2016.2577031
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Schlichtkrull M, 2018, LECT NOTES COMPUT SC, V10843, P593, DOI 10.1007/978-3-319-93417-4_38
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Singh Amanpreet, 2020, Mmf: A multimodal framework for vision and language research
   Song H., 2022, arXiv
   Tan JH, 2022, NEUROCOMPUTING, V482, P60, DOI 10.1016/j.neucom.2022.01.081
   Tang W., P 2022 INT C MULTIME, P39
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wang J, 2021, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR46437.2021.00136
   Wang ZK, 2021, AAAI CONF ARTIF INTE, V35, P2835
   Wang ZQ, 2022, PROC CVPR IEEE, P11676, DOI 10.1109/CVPR52688.2022.01139
   Xia Q L., 2021, NATURAL LANGUAGE PRO, P786, DOI 10.1007/978-3-030-88480-2_63
   Xu GH, 2021, PROC CVPR IEEE, P12632, DOI 10.1109/CVPR46437.2021.01245
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Xu Y., 2022, arXiv
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yang ZY, 2021, PROC CVPR IEEE, P8747, DOI 10.1109/CVPR46437.2021.00864
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Zhang WQ, 2022, AAAI CONF ARTIF INTE, P3335
   Zhou LW, 2020, AAAI CONF ARTIF INTE, V34, P13041
   Zhu Q, 2021, AAAI CONF ARTIF INTE, V35, P3608
NR 51
TC 3
Z9 3
U1 9
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104751
DI 10.1016/j.imavis.2023.104751
EA JUL 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N0EO1
UT WOS:001033854200001
DA 2024-07-18
ER

PT J
AU Hadikhani, P
   Lai, DTC
   Ong, WH
   Nadimi-Shahraki, MH
AF Hadikhani, Parham
   Lai, Daphne Teck Ching
   Ong, Wee-Hong
   Nadimi-Shahraki, Mohammad H.
TI Automatic Deep Sparse Multi-Trial Vector-based Differential Evolution
   clustering with manifold learning and incremental technique
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised learning; Deep clustering; Feature extraction; Dimension
   reduction; Image clustering; Evolutionary algorithm; Differential
   evolution; Auto-encoder
ID OPTIMIZATION; SEPARATION; NUMBER
AB Most deep clustering methods despite utilizing complex networks to learn better from data, use a shallow clus-tering method. These methods have difficulty in finding good clusters due to the lack of ability to handle between local search and global search to prevent premature convergence. In other words, they do not consider different aspects of the search and it causes them to get stuck in the local optimum. In addition, the majority of existing deep clustering approaches perform clustering with the knowledge of the number of clusters, which is not prac-tical in most real scenarios where such information is not available. To address these problems, this paper pre-sents a novel automatic deep sparse clustering approach based on an evolutionary algorithm called Multi-Trial Vector-based Differential Evolution (MTDE). Sparse auto-encoder is first applied to extract embedded features. Manifold learning is then adopted to obtain representation and extract the spatial structure of features. After-ward, MTDE clustering is performed without prior information on the number of clusters to find the optimal clus-tering solution. The proposed approach was evaluated on various datasets, including images and time-series. The results demonstrate that the proposed method improved MTDE by 18.94% on average and compared to the most recent deep clustering algorithms, is consistently among the top three in the majority of datasets.
C1 [Hadikhani, Parham; Lai, Daphne Teck Ching; Ong, Wee-Hong] Univ Brunei Darussalam, Sch Digital Sci, Bandar Seri Begawan, Brunei.
   [Nadimi-Shahraki, Mohammad H.] Islamic Azad Univ, Fac Comp Engn, Najafabad Branch, Tehran, Iran.
C3 University Brunei Darussalam; Islamic Azad University
RP Hadikhani, P (corresponding author), Univ Brunei Darussalam, Sch Digital Sci, Bandar Seri Begawan, Brunei.
EM 20h8561@ubd.edu.bn; daphne.lai@ubd.edu.bn; weehong.ong@ubd.edu.bn
RI Lai, Daphne Teck Ching/T-5917-2017; Nadimi-Shahraki, Mohammad
   H./Q-8701-2017
OI Lai, Daphne Teck Ching/0000-0001-8290-8941; Nadimi-Shahraki, Mohammad
   H./0000-0002-0135-1115
FU Universiti Brunei Darussalam [UBD/RSCH/1.11/FICBF (b) /2019/001];
   University of Brunei Darussalam
FX This work was supported by Grant UBD/RSCH/1.11/FICBF (b) /2019/001 from
   Universiti Brunei Darussalam. The authors declare the following
   financial interests/personal rela- tionships which may be considered as
   potential competing interests: Parham Hadikhani reports financial
   support was provided by University of Brunei Darussalam.
CR Astorga Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P658, DOI 10.1007/978-3-030-58592-1_39
   Breunig M. M., 2000, SIGMOD Record, V29, P93, DOI 10.1145/335191.335388
   Cai J., 2022, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P1
   Calinski T., 1974, Communications in Statistics-Simulation and Computation, V3, P1, DOI [10.1080/03610927408827101, DOI 10.1080/03610927408827101]
   Caron M, 2018, LECT NOTES COMPUT SC, V11218, P139, DOI 10.1007/978-3-030-01264-9_9
   Chang JL, 2017, IEEE I CONF COMP VIS, P5880, DOI [10.1109/ICCV.2017.626, 10.1109/ICCV.2017.627]
   Chuang Niu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P735, DOI 10.1007/978-3-030-58595-2_44
   Cieslak MC, 2020, MAR GENOM, V51, DOI 10.1016/j.margen.2019.100723
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dizaji KG, 2017, IEEE I CONF COMP VIS, P5747, DOI 10.1109/ICCV.2017.612
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Eiben AE, 2015, NATURE, V521, P476, DOI 10.1038/nature14544
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Geoffrey J.McLachlan., 1997, The EM algorithm and extensions/Geoffrey J. McLachlan
   Guo XF, 2020, IEEE T KNOWL DATA EN, V32, P1680, DOI 10.1109/TKDE.2019.2911833
   Guo XF, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1753
   Hadikhani P., 2022, FLEXIBLE MULTIOBJECT
   Hadikhani P., 2023, IEEE T MULTIMED
   Hadikhani P, 2022, PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE COMPANION, GECCO 2022, P487, DOI 10.1145/3520304.3528885
   Hadikhani P, 2022, Arxiv, DOI arXiv:2201.05314
   Hadikhani P, 2020, EVOL INTELL, V13, P695, DOI 10.1007/s12065-020-00384-x
   Hadikhani P, 2020, WIREL NETW, V26, P507, DOI 10.1007/s11276-019-02157-6
   Hartigan John A., 1975, Clustering Algorithms
   Hassan BA, 2021, COMPLEX INTELL SYST, V7, P2383, DOI 10.1007/s40747-021-00422-w
   Higuchi T, 2017, INTERSPEECH, P1183, DOI 10.21437/Interspeech.2017-721
   Hoffmann H, 2007, PATTERN RECOGN, V40, P863, DOI 10.1016/j.patcog.2006.07.009
   Hsu CC, 2018, IEEE T MULTIMEDIA, V20, P421, DOI 10.1109/TMM.2017.2745702
   Huang J., 2020, P IEEE CVF C COMP VI, P8849, DOI DOI 10.1109/CVPR42600.2020.00887
   Jabi M, 2021, IEEE T PATTERN ANAL, V43, P1887, DOI 10.1109/TPAMI.2019.2962683
   Jain A K, 1988, ALGORITHMS CLUSTERIN
   Ji P, 2017, ADV NEUR IN, V30
   Jiang ZX, 2017, Arxiv, DOI arXiv:1611.05148
   Junjie Zhao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P54, DOI 10.1007/978-3-030-58568-6_4
   Kao YC, 2014, INT J PROD RES, V52, P3466, DOI 10.1080/00207543.2013.867085
   Kaufman L., 2009, FINDING GROUPS DATA
   Koren Y., 2008, P 14 ACM SIGKDD INT, P426
   Krizhevsky Alex, 2009, LEARNING MULTIPLE LA
   Kumar V., 2016, CUSTOMER RELATIONSHI
   Le Ya, 2015, CS 231N, P3
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lei T, 2018, IEEE T FUZZY SYST, V26, P3027, DOI 10.1109/TFUZZ.2018.2796074
   Li FF, 2018, PATTERN RECOGN, V83, P161, DOI 10.1016/j.patcog.2018.05.019
   Li YY, 2012, NEUROCOMPUTING, V87, P90, DOI 10.1016/j.neucom.2012.02.008
   Li YF, 2021, AAAI CONF ARTIF INTE, V35, P8547
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   McConville R, 2021, INT C PATT RECOG, P5145, DOI 10.1109/ICPR48806.2021.9413131
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Menapace Willi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P736, DOI 10.1007/978-3-030-58604-1_44
   Min EX, 2018, IEEE ACCESS, V6, P39501, DOI 10.1109/ACCESS.2018.2855437
   Mukherjee S, 2019, AAAI CONF ARTIF INTE, P4610
   Murty MR, 2014, ADV INTELL SYST, V248, P1, DOI 10.1007/978-3-319-03107-1_1
   Ng A., 2011, CS294A LECT NOTES
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Omran MGH, 2006, PATTERN ANAL APPL, V8, P332, DOI 10.1007/s10044-005-0015-5
   Parsons L., 2004, SIGKDD Explor Newsl, V6, P90, DOI 10.1145/1007730.1007731
   Pinto RC, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0139931
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Price KV, 2013, Handbook of optimization, P187
   Reynolds D., 2015, ENCY BIOMETRICS, P827, DOI 10.1007/978-1-4899-7488-4_196
   Ricci F, 2011, RECOMMENDER SYSTEMS HANDBOOK, P1, DOI 10.1007/978-0-387-85820-3_1
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sadeghi M, 2023, Arxiv, DOI arXiv:2211.07136
   Shaham U, 2018, Arxiv, DOI arXiv:1801.01587
   Shi R, 2019, INT J ADV ROBOT SYST, V16, DOI 10.1177/1729881419853471
   Storn R, 1997, J GLOBAL OPTIM, V11, P341, DOI 10.1023/A:1008202821328
   Tanabe R, 2013, 2013 IEEE CONGRESS ON EVOLUTIONARY COMPUTATION (CEC), P71
   Thorndike R.L., 1953, Psychometrika, DOI DOI 10.1007/BF02289263
   Tibshirani R, 2001, J ROY STAT SOC B, V63, P411, DOI 10.1111/1467-9868.00293
   Tsai CF, 2002, I-SPAN'02: INTERNATIONAL SYMPOSIUM ON PARALLEL ARCHITECTURES, ALGORITHMS AND NETWORKS, PROCEEDINGS, P315, DOI 10.1109/ISPAN.2002.1004300
   Van Gansbeke Wouter, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12355), P268, DOI 10.1007/978-3-030-58607-2_16
   WANG PH, 1983, SIAM REV, V25, P442
   Wang Zhangyang., 2016, Proceedings of the 2016 SIAM International Conference on Data Mining, P369
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Xanthopoulos P., 2013, Robust data mining, P27, DOI [DOI 10.1007/978-0-387-78189-18, DOI 10.1007/978-1-4419-9878-1_4, 10.1007/978-0-387-78189-1_8, DOI 10.1007/978-0-387-78189-1_8, DOI 10.1007/978-1-4419-9878-14]
   Xie JY, 2016, PR MACH LEARN RES, V48
   Yang B., INT C MACH LEARN PML, P3861
   Yang JW, 2016, PROC CVPR IEEE, P5147, DOI 10.1109/CVPR.2016.556
   Yari M., 2020, J TELECOMMUN DIGIT E, V8, P68
   Yari M, 2021, Arxiv, DOI arXiv:2103.04119
   Zhang T, 2019, LECT NOTES COMPUT SC, V11365, P466, DOI 10.1007/978-3-030-20873-8_30
NR 83
TC 1
Z9 1
U1 3
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104712
DI 10.1016/j.imavis.2023.104712
EA JUN 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA K8CL8
UT WOS:001018662500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bacea, DS
   Oniga, F
AF Bacea, Dan-Sebastian
   Oniga, Florin
TI Single stage architecture for improved accuracy real-time object
   detection on mobile devices
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Convolutional neural networks; Lightweight object
   detectors; YOLO; Mobile devices
AB YOLOv4-tiny is one of the most representative lightweight one-stage object detection algorithms. In this paper, we propose Mini-YOLOv4-tiny, an improved lightweight one-stage object detector based on the YOLOv4-tiny. Typical compression techniques address both memory optimization and computational complexity, but compromise model accuracy. For model compression and speedup, we selectively cut the width of the last convolutional layers. To increase model performance, we propose several improvements with minimal impact on memory and inference time. First, we replace the Leaky-RELU activation function with Mish and fine-tune the data augmentation parameters. To enlarge the receptive field of the network, we propose a modified Spatial Pyramid Pooling module with a reduced number of convolutional blocks and filters, thus adding fewer Floating Point Operations (FLOPs) during the inference process. We performed experiments on the PASCAL VOC and MS COCO datasets and evaluated the inference speed on NVidia Jetson Nano and Raspberry PI 4 (model B). The experimental results show that our methods achieve 72.1% mAP@0.5 and 23.4% mAP@ [0.5:0.95] on the PASCAL VOC and MS COCO datasets, achieving state-of-the-art results among lightweight object detectors. Compared with YOLOv4-tiny on MS COCO, our method has 37% fewer parameters and requires 19% fewer FLOPs, while improving the Intersection over Union (IoU) by 4.02% and the average precision (interval 0.50:0.95) by 2.8%. On PASCAL VOC, MiniYOLOv4-tiny with an input size of 288 improves mAP@0.5 by 0.3%, while requiring 61% fewer FLOPS and running almost twice as fast. (c) 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http:// creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Bacea, Dan-Sebastian; Oniga, Florin] Tech Univ Cluj Napoca, Comp Sci Dept, Cluj Napoca, Romania.
C3 Technical University of Cluj Napoca
RP Oniga, F (corresponding author), Tech Univ Cluj Napoca, Comp Sci Dept, Cluj Napoca, Romania.
EM Dan.Bacea@cs.utcluj.ro; Florin.Oniga@cs.utcluj.ro
RI Oniga, Florin/C-4863-2011
OI Oniga, Florin/0000-0003-4875-2220
FU Romanian Ministry of Education and Research [PN-III-P4-PCE- 2021-1134];
   European Fund of Regional De-velopment through the Competitiveness
   Operational Programme [235/2020]
FX This work was supported by the ?DeepPerception - Deep Learning Based 3D
   Perception for Autonomous Driving ? grant funded by Romanian Ministry of
   Education and Research, code PN-III-P4-PCE- 2021-1134. Experiments were
   done on the computing infrastructure of the CLOUDUT Project, cofunded by
   the European Fund of Regional De-velopment through the Competitiveness
   Operational Programme 2014-2020, contract no. 235/2020.
CR [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Cai Y., 2021, P AAAI C ARTIFICIAL
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Dai JF, 2016, ADV NEUR IN, V29
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fang W, 2020, IEEE ACCESS, V8, P1935, DOI 10.1109/ACCESS.2019.2961959
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Ganesh P, 2022, IEEE WINT CONF APPL, P1311, DOI 10.1109/WACV51458.2022.00138
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo S, 2021, VISAPP: PROCEEDINGS OF THE 16TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS - VOL. 5: VISAPP, P25, DOI 10.5220/0010188000250035
   He K., 2017, IEEE INT C COMPUT VI
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Huang R, 2018, IEEE INT CONF BIG DA, P2503, DOI 10.1109/BigData.2018.8621865
   Jamiya SS, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165818
   Jiang ZC, 2020, Arxiv, DOI [arXiv:2011.04244, DOI 10.48550/ARXIV.2011.04244]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li X, 2020, ADV NEURAL INFORM PR, V33
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W., 2016, EUROPEAN C COMPUTER
   Liu Y., 2021, IEEE 7 INT C MULTIME
   Mingxing Tan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10778, DOI 10.1109/CVPR42600.2020.01079
   Misra D, 2020, Arxiv, DOI arXiv:1908.08681
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Redmon J., 2017, 2017 IEEE C COMP VIS
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2021, PROC CVPR IEEE, P13024, DOI 10.1109/CVPR46437.2021.01283
   Wang GB, 2022, IET COMPUT VIS, V16, P126, DOI 10.1049/cvi2.12072
   Wang GB, 2022, IET IMAGE PROCESS, V16, P145, DOI 10.1049/ipr2.12340
   Wang Q., 2020, IEEECVF C COMPUTER V
   Wong A, 2019, FIFTH WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING - NEURIPS EDITION (EMC2-NIPS 2019), P22, DOI 10.1109/EMC2-NIPS53020.2019.00013
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Zhang PY, 2019, IEEE INT CONF COMP V, P37, DOI 10.1109/ICCVW.2019.00011
   Zhang S, 2020, P IEEECVF C COMPUTER
   Zhao L, 2022, J ELECTRON IMAGING, V31, DOI 10.1117/1.JEI.31.1.013016
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
NR 46
TC 7
Z9 7
U1 3
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2023
VL 130
AR 104613
DI 10.1016/j.imavis.2022.104613
EA DEC 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7W8HA
UT WOS:000913747200001
OA hybrid
DA 2024-07-18
ER

PT J
AU Obayya, M
   Alotaibi, SS
   Dhahb, S
   Alabdan, R
   Al Duhayyim, M
   Hamza, MA
   Rizwanullah, M
   Motwakel, A
AF Obayya, Marwa
   Alotaibi, Saud S.
   Dhahb, Sami
   Alabdan, Rana
   Al Duhayyim, Mesfer
   Hamza, Manar Ahmed
   Rizwanullah, Mohammed
   Motwakel, Abdelwahed
TI Optimal deep transfer learning based ethnicity recognition on face
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ethnicity recognition; Face images; Deep learning; Fusion model;
   Hyperparameter tuning; Face recognition
AB In recent times, deep learning driven face image analysis has gained significant interest among several applica-tion areas like surveillance, security, biometrics, etc. The facial analysis intends to compute facial soft biometrics like ethnicity, expression, identification, age, gender, and so on. Among several biometrics, ethnicity recognition remains a hot research area. Recent advancements in computer vision (CV) and artificial intelligence (AI) models form the basis of an effective design of ethnicity recognition models. With this motivation, this paper introduces a novel Harris Hawks optimization with deep transfer learning based fusion model for face ethnicity recognition (HHODTLF-FER) model. The proposed HHODTLF-FER model is to determine the different kinds of ethnicity for applied facial images. A fusion of three pre-trained DL models, namely VGG16, Inception v3, and capsule net-works (CapsNet) models, are employed. In addition, bidirectional long short term memory (BiLSTM) model is ap-plied for ethnicity recognition and Classification. Finally, HHO algorithm is utilized to fine tune the hyperparameters contained in the BiLSTM model, showing the novelty of the work. In order to ensure the im-proved recognition performance of the HHODTLF-FER model, a wide ranging experimental analysis is performed using benchmark databases. The comprehensive comparative study highlighted the promising performance of the HHODTLF-FER model over the other approaches.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Obayya, Marwa] Princess Nourah bint Abdulrahman Univ, Coll Engn, Dept Biomed Engn, POB 84428, Riyadh 11671, Saudi Arabia.
   [Alotaibi, Saud S.] Umm Al Qura Univ, Coll Comp & Informat Syst, Dept Informat Syst, Mecca, Saudi Arabia.
   [Dhahb, Sami] King Khalid Univ, Coll Sci & Art Mahayil, Dept Comp Sci, Abha, Saudi Arabia.
   [Dhahb, Sami] Univ Tunis Manar, Higher Inst Comp, Lab LIMT, Res Team Intelligent Syst Imaging Artificial Vis S, Aryanah 2036, Tunisia.
   [Alabdan, Rana] Majmaah Univ, Coll Comp & Informat Sci, Dept Informat Technol, Al Majmaah 11952, Saudi Arabia.
   [Al Duhayyim, Mesfer] Prince Sattam bin Abdulaziz Univ, Coll Sci & Humanities Aflaj, Dept Comp Sci, Al Kharj, Saudi Arabia.
   [Hamza, Manar Ahmed; Rizwanullah, Mohammed; Motwakel, Abdelwahed] Prince Sattam bin Abdulaziz Univ, Dept Comp & Self Dev, Preparatory Year Deanship, Alkharj, Saudi Arabia.
C3 Princess Nourah bint Abdulrahman University; Umm Al Qura University;
   King Khalid University; Universite de Tunis-El-Manar; Majmaah
   University; Prince Sattam Bin Abdulaziz University; Prince Sattam Bin
   Abdulaziz University
RP Hamza, MA (corresponding author), Prince Sattam bin Abdulaziz Univ, Dept Comp & Self Dev, Preparatory Year Deanship, Alkharj, Saudi Arabia.
EM ma.hamza@psau.edu.sa
RI Alotaibi, Saud/AAE-5224-2019; Mohammed, Rizwanullah/AIB-6030-2022;
   Alabdan, Rana/H-3882-2017; Hamza, Manar/AHC-1078-2022; Al Duhayyim,
   Mesfer/AGP-7942-2022
OI Alotaibi, Saud/0000-0003-1082-513X; Mohammed,
   Rizwanullah/0000-0002-6951-8823; Alabdan, Rana/0000-0003-2410-486X; Al
   Duhayyim, Mesfer/0000-0003-4024-271X
FU King Khalid University [RGP 2/142/43]; Princess Nourah bint Abdulrahman
   University, Riyadh, Saudi Arabia [PNURSP2022R203]; Umm Al-Qura
   University [22UQU4210118DSR51]; Majmaah University [R-2022-xxx]
FX The authors extend their appreciation to the Deanship of Scientific
   Research at King Khalid University for funding this work under grant
   number (RGP 2/142/43) . Princess Nourah bint Abdulrahman University
   Researchers Supporting Project number (PNURSP2022R203) , Prin- cess
   Nourah bint Abdulrahman University, Riyadh, Saudi Arabia. The authors
   would like to thank the Deanship of Scientific Research at Umm Al-Qura
   University for supporting this work by Grant Code: (22UQU4210118DSR51) .
   The Authors would like to thank the Deanship of Scientific Research at
   Majmaah University for supporting this work under Project No.
   R-2022-xxx.
CR AlBdairi AJA, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12052605
   Bisogni C, 2022, IEEE T IND INFORM, V18, P5619, DOI 10.1109/TII.2022.3141400
   Carletti V, 2020, IEEE T PATTERN ANAL, V42, P2113, DOI 10.1109/TPAMI.2019.2910522
   Darabant AS, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9020195
   Dong N, 2020, APPL SOFT COMPUT, V93, DOI 10.1016/j.asoc.2020.106311
   Greco Antonio, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P472, DOI 10.1007/978-3-030-68790-8_37
   Greco A, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01123-z
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Hilal AM, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/4063354
   Kärkkäinen K, 2021, IEEE WINT CONF APPL, P1547, DOI 10.1109/WACV48630.2021.00159
   Kisan S., 2020, INT J ADV SCI TECHNO, V29, P3878
   Kosinski M, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-79310-1
   Liu AJ, 2020, Arxiv, DOI arXiv:2004.10998
   Mangla Monika, 2021, 2021 2nd International Conference on Secure Cyber Computing and Communications (ICSCCC), P170, DOI 10.1109/ICSCCC51823.2021.9478175
   Mukherjee P, 2022, Arxiv, DOI arXiv:2201.03002
   O'Toole AJ, 2021, ANNU REV VIS SCI, V7, P543, DOI 10.1146/annurev-vision-093019-111701
   Puc A, 2021, EUR SIGNAL PR CONF, P830, DOI 10.23919/Eusipco47968.2020.9287219
   Qassim H, 2018, 2018 IEEE 8TH ANNUAL COMPUTING AND COMMUNICATION WORKSHOP AND CONFERENCE (CCWC), P169, DOI 10.1109/CCWC.2018.8301729
   Savchenko Andrey V., 2021, 2021 IEEE 19th International Symposium on Intelligent Systems and Informatics (SISY), P119, DOI 10.1109/SISY52375.2021.9582508
   Serna I, 2022, ARTIF INTELL-AMST, V305, DOI 10.1016/j.artint.2022.103682
   Singla P, 2022, EARTH SCI INFORM, V15, P291, DOI 10.1007/s12145-021-00723-1
   Vo T, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110564
   Xiang CQ, 2018, IEEE SIGNAL PROC LET, V25, P1850, DOI 10.1109/LSP.2018.2873892
   Yucer S., 2022, P IEEE CVF WINT C AP, P995
   Zhang ZF, 2017, PROC CVPR IEEE, P4352, DOI 10.1109/CVPR.2017.463
NR 25
TC 2
Z9 2
U1 3
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104584
DI 10.1016/j.imavis.2022.104584
EA NOV 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500008
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Liu, XR
   Zhang, TL
AF Zhang, Qiang
   Liu, Xueru
   Zhang, Tianlu
TI RGB-T tracking by modality difference reduction and feature re-selection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RGB-T tracking; Modality difference; Feature re-selection
AB RGB-T tracking has attracted increasing attention, since visible and thermal data have strong complementary ad-vantages to improve the robustness of trackers. Most existing models focus on investigating efficient ways of fus-ing the complementary information from RGB and thermal images for better tracking performance. However, the modality differences caused by different imaging mechanisms may degrade the discriminability of the fused fea-tures. Meanwhile, compared with the unimodal features, the fused features may not always improve the tracking performance, especially when one of the input images contain much noisy information. In view of this, we pro-pose a novel RGB-T tracking model by simultaneously reducing modality difference and re-selecting discrimina-tive features from the fused features as well as from the unimodal features. To this end, a Modality Difference Compensation module (MDC) and a Feature Re-selection module (FRS) are presented. The former one reduces the modality differences between RGB and thermal features and obtains the fused features. The latter one adap-tively selects such discriminative features from the unimodal features and the fused features for the subsequent classification and regression. Exhausted experiments are conducted on three RGB-T tracking benchmark datasets, which verify that our proposed tracker performs favorably against some state-of-the-art tracking algorithms.(c) 2022 Published by Elsevier B.V.
C1 [Zhang, Qiang; Liu, Xueru; Zhang, Tianlu] Xidian Univ, Key Lab Elect Equipment Struct Design, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University
RP Zhang, TL (corresponding author), Xidian Univ, Key Lab Elect Equipment Struct Design, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
EM qzhang@xidian.edu.cn; xueruliu@stu.xidian.edu.cn;
   tianluzhang@stu.xidian.edu.cn
RI Zhang, Tianlu/HOH-7289-2023
OI Zhang, Tianlu/0000-0003-4592-5448
FU National Natural Science Foundation of China;  [61773301]
FX Acknowledgment This work is supported by the National Natural Science
   Foundation of China under Grant No. 61773301.
CR Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Chenglong Li, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P222, DOI 10.1007/978-3-030-58542-6_14
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Dunnhofer M, 2022, IMAGE VISION COMPUT, V122, DOI 10.1016/j.imavis.2022.104448
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Feng MZ, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jvcir.2020.102881
   Gao Y, 2019, P IEEE INT C COMPUTE
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li C., 2021, arXiv, DOI DOI 10.1109/TIP.2021.3130533
   Li CL, 2019, IEEE INT CONF COMP V, P2262, DOI 10.1109/ICCVW.2019.00279
   Li CL, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106977
   Li CL, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1856, DOI 10.1145/3123266.3123289
   Li CL, 2018, LECT NOTES COMPUT SC, V11217, P831, DOI 10.1007/978-3-030-01261-8_49
   Li CL, 2016, IEEE T IMAGE PROCESS, V25, P5743, DOI 10.1109/TIP.2016.2614135
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Nousi P, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103933
   Tang ZY, 2022, Arxiv, DOI arXiv:2201.08949
   Tu Z., 2021, IEEE T IMAGE PROCESS, V31, P85
   Wang X., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2107.10433
   Wu Y, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104188
   Xu Q, 2022, IEEE T MULTIMEDIA, V24, P567, DOI 10.1109/TMM.2021.3055362
   Yang R., 2019, 2019 IEEE INT C IMAG, P3975, DOI DOI 10.1109/ICIP.2019.8803528
   Zhang H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20020393
   Zhang LC, 2019, IEEE INT CONF COMP V, P2252, DOI 10.1109/ICCVW.2019.00278
   Zhang PY, 2021, IEEE T IMAGE PROCESS, V30, P3335, DOI 10.1109/TIP.2021.3060862
   Zhang TL, 2022, IEEE T CIRC SYST VID, V32, P1403, DOI 10.1109/TCSVT.2021.3072207
   Zhang XC, 2020, SIGNAL PROCESS-IMAGE, V84, DOI 10.1016/j.image.2019.115756
   Zhou JH, 2020, AAAI CONF ARTIF INTE, V34, P13017
   Zhu YB, 2021, IEEE T INTELL VEHICL, V6, P121, DOI 10.1109/TIV.2020.2980735
   Zhu YB, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P465, DOI 10.1145/3343031.3350928
NR 34
TC 5
Z9 6
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104547
DI 10.1016/j.imavis.2022.104547
EA SEP 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300011
DA 2024-07-18
ER

PT J
AU Yu, R
   Tian, CY
   Xia, WH
   Zhao, XY
   Wang, LJ
   Yang, YJ
AF Yu, Ran
   Tian, Chenyu
   Xia, Weihao
   Zhao, Xinyuan
   Wang, Liejun
   Yang, Yujiu
TI Real-time human-centric segmentation for complex video scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiple human tracking; Video instance segmentation; One -stage
   detector; Video understanding; Deep neural networks
AB Most existing video tasks related to "human" focus on the segmentation of salient humans, ignoring the unspec-ified others in the video. Few studies have focused on segmenting and tracking all humans in a complex video, including pedestrians and humans of other states (e.g., seated, riding, or occluded). In this paper, we propose a novel framework, abbreviated as HVISNet, that segments and tracks all presented people in given videos based on a one-stage detector. To better evaluate complex scenes, we offer a new benchmark called HVIS (Human Video Instance Segmentation), which comprises 1447 human instance masks in 805 high-resolution videos in di-verse scenes. Extensive experiments show that our proposed HVISNet outperforms the state-of-the-art methods in terms of accuracy at a real-time inference speed (30 FPS), especially on complex video scenes. We also notice that using the center of the bounding box to distinguish different individuals severely deteriorates the segmen-tation accuracy, especially in heavily occluded conditions. This common phenomenon is referred to as the ambig-uous positive samples problem. To alleviate this problem, we propose a mechanism named Inner Center Sampling to improve the accuracy of instance segmentation. Such a plug-and-play inner center sampling mech-anism can be incorporated in any instance segmentation model based on a one-stage detector to improve the performance. In particular, it gains 4.1 mAP improvement on the state-of-the-art method in the case of occluded humans. Code and data are available at https://github.com/IIGROUP/HVISNet.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yu, Ran; Tian, Chenyu; Xia, Weihao; Yang, Yujiu] Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Beijing, Peoples R China.
   [Zhao, Xinyuan] Huawei Technol Co Ltd, Shenzhen, Peoples R China.
   [Wang, Liejun] Xinjiang Univ, Sch Informat Sci & Engn, Urumqi, Peoples R China.
C3 Tsinghua University; Tsinghua Shenzhen International Graduate School;
   Huawei Technologies; Xinjiang University
RP Yang, YJ (corresponding author), Tsinghua Univ, Tsinghua Shenzhen Int Grad Sch, Beijing, Peoples R China.
EM yang.yujiu@sz.tsinghua.edu.cn
RI Yang, Yujiu/JGM-0303-2023; Xia, Weihao/AAG-9760-2021; Tian,
   Chenyu/ABC-6606-2020
OI Yang, Yujiu/0000-0002-6427-1024; Xia, Weihao/0000-0003-0087-3525; Tian,
   Chenyu/0000-0002-7748-5873
FU Key Program of the National Natural Science Foundation of China;
   Shenzhen Key Lab of Marine IntelliSense;  [U1903213]; 
   [ZDSYS20200811142605016]
FX This research was supported by the Key Program of the National Natural
   Science Foundation of China under Grant U1903213, the Shenzhen Key Lab
   of Marine IntelliSense and Computation under Con- tract
   ZDSYS20200811142605016.
CR [Anonymous], 2017, arXiv
   Athar Ali, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P158, DOI 10.1007/978-3-030-58621-8_10
   Bolya D, 2019, IEEE I CONF COMP VIS, P9156, DOI 10.1109/ICCV.2019.00925
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Chen X, 2019, Arxiv, DOI arXiv:1901.03814
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   Fan DP, 2019, PROC CVPR IEEE, P8546, DOI 10.1109/CVPR.2019.00875
   Galasso F, 2013, IEEE I CONF COMP VIS, P3527, DOI 10.1109/ICCV.2013.438
   Hao Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8570, DOI 10.1109/CVPR42600.2020.00860
   Huang X., 2020, P IEEECVF C COMPUTER
   Lee Y, 2020, P IEEE CVF C COMP VI
   Lin T.Y., 2014, P 13 EUR C COMP VIS, P740
   Lin Y., 2020, P IEEE CVF C COMP VI, P13144
   Maybeck P.S., 1990, Autonomous Robot Vehicles, P194
   Milan A, 2016, Arxiv, DOI arXiv:1603.00831
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pont-Tuset J, 2018, Arxiv, DOI arXiv:1704.00675
   Qi J., 2021, arXiv
   Qian YQ, 2020, IEEE T MULTIMEDIA, V22, P421, DOI 10.1109/TMM.2019.2929949
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen XY, 2017, IEEE I CONF COMP VIS, P3277, DOI 10.1109/ICCV.2017.353
   Shen XY, 2016, COMPUT GRAPH FORUM, V35, P93, DOI 10.1111/cgf.12814
   Sundberg P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2233, DOI 10.1109/CVPR.2011.5995364
   Tian Z, 2021, PROC CVPR IEEE, P5439, DOI 10.1109/CVPR46437.2021.00540
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tripathi S, 2017, Arxiv, DOI arXiv:1704.01152
   Voigtlaender P, 2019, PROC CVPR IEEE, P7934, DOI 10.1109/CVPR.2019.00813
   Xu ZB, 2020, Arxiv, DOI arXiv:2007.01549
   Yang LJ, 2019, IEEE I CONF COMP VIS, P5187, DOI 10.1109/ICCV.2019.00529
   Ye M, 2016, IEEE T MULTIMEDIA, V18, P2553, DOI 10.1109/TMM.2016.2605058
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zeng ZL, 2020, IEEE T MULTIMEDIA, V22, P3064, DOI 10.1109/TMM.2020.2969782
   Zhang JL, 2021, IEEE T MULTIMEDIA, V23, P3085, DOI 10.1109/TMM.2020.3020691
   Zhang SS, 2018, PROC CVPR IEEE, P6995, DOI 10.1109/CVPR.2018.00731
   Zhang SH, 2019, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2019.00098
   Zhenbo Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P264, DOI 10.1007/978-3-030-58452-8_16
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhi Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P282, DOI 10.1007/978-3-030-58452-8_17
   Zhishuai Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11343, DOI 10.1109/CVPR42600.2020.01136
NR 41
TC 0
Z9 0
U1 8
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104552
DI 10.1016/j.imavis.2022.104552
EA SEP 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5Q3YO
UT WOS:000873771400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bevandic, P
   Kreso, I
   Orsic, M
   Segvic, S
AF Bevandic, Petra
   Kreso, Ivan
   Orsic, Marin
   Segvic, Sinisa
TI Dense open-set recognition based on training with noisy negative images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dense prediction; Semantic segmentation; Dense open-set recognition;
   Outlier detection
AB Deep convolutional models often produce inadequate predictions for inputs which are foreign to the training distribution. Consequently, the problem of detecting outlier images has recently been receiving a lot of attention. Unlike most previous work, we address this problem in the dense prediction context. Our approach is based on two reasonable assumptions. First, we assume that the inlier dataset is related to some narrow application field (e.g. road driving). Second, we assume that there exists a general-purpose dataset which is much more diverse than the inlier dataset (e.g. ImageNet-1 k). We consider pixels from the general-purpose dataset as noisy negative samples since most (but not all) of them are outliers. We encourage the model to recognize borders between the known and the unknown by pasting jittered negative patches over inlier training images. Our experiments target two dense open-set recognition benchmarks (WildDash 1 and Fishyscapes) and one dense open set recognition dataset (StreetHazard). Extensive performance evaluation indicates competitive potential of the proposed approach. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Bevandic, Petra; Kreso, Ivan; Orsic, Marin; Segvic, Sinisa] Univ Zagreb, Fac Elect Engn & Comp, Zagreb, Croatia.
C3 University of Zagreb
RP Bevandic, P (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Zagreb, Croatia.
EM petra.bevandic@fer.hr
RI Šegvić, Siniša/Q-6868-2019; Bevandić, Petra/JAN-8096-2023
OI Šegvić, Siniša/0000-0001-7378-0536; Bevandić, Petra/0000-0002-8608-0624;
   Orsic, Marin/0000-0002-6583-2137
FU Croatian Science Foundation [IP-2020-02-5851 ADEPT, IP-2013-11-1395
   MULTICLOD]; European Regional Development Fund [KK.01.1.1.01.0009
   DATACROSS]
FX This work has been supported by the Croatian Science Foundation-grants
   IP-2020-02-5851 ADEPT, IP-2013-11-1395 MULTICLOD and the European
   Regional Development Fund under the grant KK.01.1.1.01.0009 DATACROSS.
CR Angus M., 2019, ARXIV
   [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Bergmann P, 2020, PROC CVPR IEEE, P4182, DOI 10.1109/CVPR42600.2020.00424
   Bevandic P., 2018, ARXIV
   Bevandic P, 2019, LECT NOTES COMPUT SC, V11824, P33, DOI 10.1007/978-3-030-33676-9_3
   Blum H, 2019, IEEE INT CONF COMP V, P2403, DOI 10.1109/ICCVW.2019.00294
   Bulò SR, 2018, PROC CVPR IEEE, P5639, DOI 10.1109/CVPR.2018.00591
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   DeVries T., 2018, ARXIV
   Franchi G., ECCV 2020, P105
   Franchi G., 2020, ARXIV
   Gal Y, 2016, PR MACH LEARN RES, V48
   Grathwohl Will, 2020, INT C LEARN REPR ICL
   Guo CA, 2017, PR MACH LEARN RES, V70
   Hendrycks D., 2019, ICLR
   Hendrycks D., ICML2022
   Hendrycks Dan, 2017, INT C LEARNING REPRE
   Hongjie Zhang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P102, DOI 10.1007/978-3-030-58580-8_7
   Hullermeier E., 2019, arXiv
   Kendall A., 2017, Advances in Neural Information Processing Systems, V30, P5574
   Kreso I., 2020, IEEE T INTELL TRANSP, P1
   Kreso I, 2017, IEEE INT CONF COMP V, P238, DOI 10.1109/ICCVW.2017.37
   Lambert J, 2020, PROC CVPR IEEE, P2876, DOI 10.1109/CVPR42600.2020.00295
   Lee Kimin, 2018, ICLR
   Liang S, 2017, AEBMR ADV ECON, V34, P1
   Malinin A, 2018, ADV NEUR IN, V31
   Meletis P, 2018, IEEE INT VEH SYM, P1045, DOI 10.1109/IVS.2018.8500398
   Nalisnick Eric, 2019, INT C LEARN REPR
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Perera P, 2019, IEEE T IMAGE PROCESS, V28, P5450, DOI 10.1109/TIP.2019.2917862
   Pinggera P, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1099, DOI 10.1109/IROS.2016.7759186
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scheirer WJ, 2014, IEEE T PATTERN ANAL, V36, P2317, DOI 10.1109/TPAMI.2014.2321392
   Smith L, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P560
   Xia Yingda, 2020, ECCV
   Yu F, 2017, PROC CVPR IEEE, P636, DOI 10.1109/CVPR.2017.75
   Zenati H, 2018, IEEE DATA MINING, P727, DOI 10.1109/ICDM.2018.00088
   Zendel O, 2018, LECT NOTES COMPUT SC, V11210, P407, DOI 10.1007/978-3-030-01231-1_25
   Zeng HQ, 2017, PROC INT CONF RECON
   Zhang PP, 2019, PATTERN RECOGN, V88, P702, DOI 10.1016/j.patcog.2018.12.021
   Zhang YY, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107486
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhu R, 2019, PROC CVPR IEEE, P2263, DOI 10.1109/CVPR.2019.00237
NR 46
TC 12
Z9 12
U1 2
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104490
DI 10.1016/j.imavis.2022.104490
EA JUN 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bhuiyan, A
   Huang, JX
AF Bhuiyan, Amran
   Huang, Jimmy Xiangji
TI STCA: Utilizing a spatio-temporal cross-attention network for enhancing
   video person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Re-identi fication; Deep learning; 3D-CNNs; Cross attention
AB Video-based re-identification (ReID) is a crucial task in computer vision that draws increasing attention due to advances in deep learning (DL) and modern computational devices. Despite recent success with CNN architectures, single models (e.g., 2D-CNNs or 3D-CNNs) alone failed to leverage temporal information with spatial cues. This is due to uncontrolled surveillance scenarios and variable poses leading to inevitable misalignment of ROIs across the tracklets, which is accompanied by occlusion and motion blur. In this context, designing temporal and spatial cues for two different models and their combinations can be beneficial, considering the global of a video-tracklet. 3D-CNNs allow encoding of temporal information while 2D-CNNs extract spatial or appearance information. In this paper, we propose a Spatio-Temporal Cross Attention (STCA) network to utilize both 2DCNNs and 3D-CNNs that calculate the cross attention mapping both from the layer of 3D-CNNs and 2D-CNNs along a person's trajectory to gate the following layers of 2D-CNNs; and highlight relevant appearance features for the person ReID. Given an input tracklet, the proposed cross attention (CA) is able to capture the salient regions that propagate throughout the tracklet to obtain the global view. This provides a spatio-temporal attention approach that can be dynamically aggregated with spatial features of 2D-CNNs to perform finer-grained recognition. Additionally, we exploit the advantage of utilizing cosine similarity while triplet sampling as well as for calculating the final recognition score. Experimental analyses on three challenging benchmark datasets indicate that integrating spatio-temporal cross attention into the state-of-the-art video ReID backbone CNN architecture allows for improving their recognition accuracy. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Bhuiyan, Amran; Huang, Jimmy Xiangji] York Univ, Sch Informat Technol, Informat Retrieval & Knowledge Management Res Lab, Toronto, ON, Canada.
   [Bhuiyan, Amran] Noakhali Sci & Technol Univ, Deptartment CSTE, Noakhali, Bangladesh.
C3 York University - Canada; Noakhali Science & Technology University
   (NSTU)
RP Bhuiyan, A; Huang, JX (corresponding author), York Univ, Sch Informat Technol, Informat Retrieval & Knowledge Management Res Lab, Toronto, ON, Canada.
EM amran@yorku.ca; jhuang@yorku.ca
RI Bhuiyan, Md Amran Hossen/ABC-6140-2021; Huang, Jimmy
   Xiangji/ABT-1811-2022
OI Bhuiyan, Md Amran Hossen/0000-0002-2069-0753; Huang, Jimmy
   Xiangji/0000-0003-1292-1491
FU Natural Sciences and Engineering Research Council (NSERC) of Canada;
   York Research Chairs (YRC) program
FX This research is supported by the research grant from Natural Sciences
   and Engineering Research Council (NSERC) of Canada and York Research
   Chairs (YRC) program. All the work was done when the first author was a
   postdoctoral fellow at the Information Retrieval and Knowledge
   Management Research Lab, York University, Canada. The authors gratefully
   appreciate the anonymous reviewers and associate editor for their
   valuable comments and constructive suggestions that greatly helped to
   improve the quality of the paper. We also acknowledge Compute Canada for
   providing us the computing resources to con-duct experiments.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Aich A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P152, DOI 10.1109/ICCV48922.2021.00022
   Bhuiyan A, 2020, IEEE WINT CONF APPL, P2664, DOI [10.1109/WACV45572.2020.9093370, 10.1109/wacv45572.2020.9093370]
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen CQ, 2022, IEEE T CIRC SYST VID, V32, P6100, DOI 10.1109/TCSVT.2022.3157130
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Eom C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12016, DOI 10.1109/ICCV48922.2021.01182
   Fu H, 2021, IMAGE VISION COMPUT
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Gao Jinyang., 2018, CoRR
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T., 2021, P IEEE CVF INT C COM, P1490
   Hermans Alexander, 2017, ARXIV170307737
   Hou RB, 2021, PROC CVPR IEEE, P2014, DOI 10.1109/CVPR46437.2021.00205
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Hou RB, 2019, ADV NEUR IN, V32
   Hu J., P IEEE C COMPUTER VI, P7132
   Islam K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103970
   Kay W., 2017, ARXIV170506950
   Kiran M, 2021, IMAGE VISION COMPUT, V113, DOI 10.1016/j.imavis.2021.104246
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li JN, 2019, AAAI CONF ARTIF INTE, P8618
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Liang ZH, 2016, IEEE INT C BIOINFORM, P493, DOI 10.1109/BIBM.2016.7822567
   Liao XY, 2019, LECT NOTES COMPUT SC, V11366, P620, DOI 10.1007/978-3-030-20876-9_39
   Liu C.-T., 2019, ARXIV190801683
   Liu GQ, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104068
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Liu JW, 2021, PROC CVPR IEEE, P4368, DOI 10.1109/CVPR46437.2021.00435
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu XH, 2021, PROC CVPR IEEE, P13329, DOI 10.1109/CVPR46437.2021.01313
   Liu Y, 2017, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2017.499
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Lv JY, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103875
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Mekhazni Djebril, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P159, DOI 10.1007/978-3-030-58583-9_10
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065
   Suh Y, 2018, LECT NOTES COMPUT SC, V11218, P418, DOI 10.1007/978-3-030-01264-9_25
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xinqian Gu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12347), P228, DOI 10.1007/978-3-030-58536-5_14
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yan YC, 2020, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR42600.2020.00297
   Yang F, 2022, NEUROCOMPUTING, V488, P424, DOI 10.1016/j.neucom.2022.03.032
   Zhang CR, 2022, NEUROCOMPUTING, V468, P33, DOI 10.1016/j.neucom.2021.10.018
   Zhang ZZ, 2020, INT CONF CONDIT MON, P404, DOI 10.1109/CVPR42600.2020.01042
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505
   Zhaohui Liang, 2014, 2014 IEEE International Conference on Bioinformatics and Biomedicine (BIBM), P556, DOI 10.1109/BIBM.2014.6999219
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 70
TC 5
Z9 5
U1 1
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104474
DI 10.1016/j.imavis.2022.104474
EA MAY 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1W0YE
UT WOS:000806506500007
DA 2024-07-18
ER

PT J
AU Chen, TY
   Li, ZX
   Wu, JL
   Ma, HF
   Su, BP
AF Chen, Tianyu
   Li, Zhixin
   Wu, Jingli
   Ma, Huifang
   Su, Bianping
TI Improving image captioning with Pyramid Attention and SC-GAN
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image captioning; Pyramid Attention network; Self-critical training;
   Reinforcement learning; Generative adversarial network; Sequence-level
   learning
AB Most of the existing image captioning models mainly use global attention, which represents the whole image fea-tures, local attention, representing the object features, or a combination of them; there are few models to inte-grate the relationship information between various object regions of the image. But this relationship information is also very instructive for caption generation. For example, if a football appears, there is a high prob-ability that the image also contains people near the football. In this article, the relationship feature is embedded into the global-local attention to constructing a new Pyramid Attention mechanism, which can explore the inter-nal visual and semantic relationship between different object regions. Besides, to alleviate the exposure bias problem and make the training process more efficient, we propose a new method to apply the Generative Adver-sarial Network into sequence generation. The greedy decoding method is used to generate an efficient baseline reward for self-critical training. Finally, experiments on MSCOCO dataset show that the model can generate more accurate and vivid captions and outperforms many recent advanced models in various prevailing evalua-tion metrics on both local and online test sets.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Chen, Tianyu; Li, Zhixin; Wu, Jingli] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
   [Ma, Huifang] Northwest Normal Univ, Coll Comp Sci & Engn, Lanzhou 730070, Peoples R China.
   [Su, Bianping] Xian Univ Architecture & Technol, Coll Sci, Xian 710055, Peoples R China.
C3 Guangxi Normal University; Northwest Normal University - China; Xi'an
   University of Architecture & Technology
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM lizx@gxnu.edu.cn
RI Li, Zhixin/ABI-9264-2022; LI, LIXIN/KFS-0074-2024; Ma,
   Huifang/JTV-4982-2023
OI Li, Zhixin/0000-0002-5313-6134; Ma, Huifang/0000-0002-5104-8982
FU National Natural Science Foundation of China [61966004, 61866004,
   61762015, 61762078]; Guangxi Natural Science Foundation
   [2019GXNSFDA245018]; Innovation Project of Guangxi Graduate Education
   [XYCBZ2021002]; Guangxi "Bagui Scholar" Teams for Innovation and
   Research Project; Guangxi Talent Highland Project of Big Data
   Intelligence and Application; Guangxi Collaborative Innovation Center of
   Multi-source Information Integration and Intelligent Processing
FX This work is supported by National Natural Science Foundation of China
   (Nos. 61966004, 61866004, 61762015, 61762078), Guangxi Natural Science
   Foundation (Nos. 2019GXNSFDA245018), Innovation Project of Guangxi
   Graduate Education (No. XYCBZ2021002), Guangxi "Bagui Scholar" Teams for
   Innovation and Research Project, Guangxi Talent Highland Project of Big
   Data Intelligence and Application, and Guangxi Collaborative Innovation
   Center of Multi-source Information Integration and Intelligent
   Processing.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   [Anonymous], 1997, NEURAL COMPUT
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Chen J., P IEEE C COMP VIS PA, P10890
   Cornia Marcella, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10575, DOI 10.1109/CVPR42600.2020.01059
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang FC, 2020, MACH LEARN, V109, P2313, DOI 10.1007/s10994-020-05919-y
   Huang L, 2019, IEEE I CONF COMP VIS, P4633, DOI 10.1109/ICCV.2019.00473
   Jiang WH, 2018, LECT NOTES COMPUT SC, V11206, P510, DOI 10.1007/978-3-030-01216-8_31
   Ke L, 2019, IEEE I CONF COMP VIS, P8887, DOI 10.1109/ICCV.2019.00898
   Li G, 2019, IEEE I CONF COMP VIS, P8927, DOI 10.1109/ICCV.2019.00902
   Li LH, 2018, IEEE T MULTIMEDIA, V20, P726, DOI 10.1109/TMM.2017.2751140
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Liu JH, 2020, AAAI CONF ARTIF INTE, V34, P11588
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Ranzato MarcAurelio, 2015, CoRR
   Rennie SJ, 2017, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2017.131
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Vaswani A, 2017, ADV NEUR IN, V30
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Wang JB, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107075
   Wang L, 2020, AAAI CONF ARTIF INTE, V34, P12176
   Wang WX, 2019, AAAI CONF ARTIF INTE, P8957
   Wang Z., P INT JOINT C ART IN, P659
   Wei HY, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3439734
   Wei HY, 2020, COMPUT VIS IMAGE UND, V201, DOI 10.1016/j.cviu.2020.103068
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang X, 2019, PROC CVPR IEEE, P10677, DOI 10.1109/CVPR.2019.01094
   Yao T, 2019, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2019.00271
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
   Yingwei Pan, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10968, DOI 10.1109/CVPR42600.2020.01098
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu LT, 2017, AAAI CONF ARTIF INTE, P2852
   Zhou YAN, 2020, PROC CVPR IEEE, P4776, DOI 10.1109/CVPR42600.2020.00483
NR 35
TC 15
Z9 15
U1 4
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104340
DI 10.1016/j.imavis.2021.104340
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4VF
UT WOS:000772585200004
DA 2024-07-18
ER

PT J
AU Naveen, S
   Kiran, MSSR
   Indupriya, M
   Manikanta, TV
   Sudeep, PV
AF Naveen, S.
   Kiran, M. S. S. Ram
   Indupriya, M.
   Manikanta, T. V.
   Sudeep, P. V.
TI Transformer models for enhancing AttnGAN based text to image generation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Generative Adversarial Networks (GANs); Natural Language Processing
   (NLP); Text to image synthesis; Transformers; Attention mechanism
AB Deep neural networks are capable of producing photographic images that depict given natural language text descriptions. Such models have huge potential in applications such as interior designing, video games, editing and facial sketching for digital forensics. However, only a limited number of methods in the literature have been developed for text to image (TTI) generation. Most of them use Generative Adversarial Networks (GAN) based deep learning methods. Attentional GAN (AttnGAN) is a popular GAN based TTI method that extracts meaningful information from the given text descriptions using attention mechanism. In this paper, we investigate the use of different Transformer models such as BERT, GPT2, XLNet with AttnGAN to solve the challenge of extracting semantic information from the text descriptions. Hence, the proposed AttnGAN(TRANS) architecture has three variants AttnGAN(BERT), AttnGAN(XL) and AttnGAN(GPT). The proposed method is successful over the conventional AttnGAN and gives a boosted inception score by 27.23% and a decline of Frechet inception distance by 49.9%. The results in our experiments indicate that the proposed method has the potential to outperform the contemporary state-of-the-art methods and validate the use of Transformer models in improving the performance of TTI generation. The code is made publicly available at https://github.com/sairamkiran9/AttnGAN-trans. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Naveen, S.; Kiran, M. S. S. Ram; Indupriya, M.; Manikanta, T. V.; Sudeep, P. V.] Natl Inst Technol Calicut, Calicut 673601, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Naveen, S; Sudeep, PV (corresponding author), Natl Inst Technol Calicut, Calicut 673601, Kerala, India.
EM sambangi_b170581ec@nitc.ac.in; muppana_b170114ec@nitc.ac.in;
   movva_b170782ec@nitc.ac.in; tentu_b170494ec@nitc.ac.in;
   sudeep.pv@nitc.ac.in
OI Sri Sai Ram Kiran, Muppana/0000-0003-2740-9917; P.V.,
   Sudeep/0000-0002-6738-7786; Naveen, Sambangi/0000-0002-2316-8450
CR Adi Y, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2702858
   Allen-Zhu Zeyuan, 2021, ARXIV210602619
   Brown T. B., 2020, Neural Information Processing Systems
   Cao YJ, 2019, IEEE ACCESS, V7, P14985, DOI 10.1109/ACCESS.2018.2886814
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Delp E, 2009, IEEE SIGNAL PROC MAG, V26, P14, DOI 10.1109/MSP.2008.931089
   Denton Emily L, Advances in Neural Information Processing Systems, P1486
   Devlin J., 2018, BERT PRE TRAINING DE
   Dey R, 2017, MIDWEST SYMP CIRCUIT, P1597, DOI 10.1109/MWSCAS.2017.8053243
   Gillioz Anthony, 2020, 2020 15th Conference on Computer Science and Information Systems (FedCSIS), P179, DOI 10.15439/2020F20
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   He P., 2020, INT C LEARNING REPRE
   Hinz Tobias, 2019, ARXIV PREPRINT ARXIV
   Hou XX, 2019, NEUROCOMPUTING, V341, P183, DOI 10.1016/j.neucom.2019.03.013
   Hu WP, 2020, INT CONF FRONT HAND, P133, DOI 10.1109/ICFHR2020.2020.00034
   Huang X, 2019, 2019 16TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV 2019), P73, DOI 10.1109/CRV.2019.00018
   Ji ZZ, 2020, IEEE ACCESS, V8, P100469, DOI 10.1109/ACCESS.2020.2994247
   Karnewar A., 2020, PROC IEEECVF C COMPU, P7799
   Karras T., 2018, INT CONFLEARN REPRES
   Khan M.Z., 2020, IEEE ACCESS
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Lastra-Díaz JJ, 2019, ENG APPL ARTIF INTEL, V85, P645, DOI 10.1016/j.engappai.2019.07.010
   Li B, 2021, J NEUROL, V268, P2042, DOI 10.1007/s00415-019-09596-3
   Li WH, 2019, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2019.00514
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Loew M., 2019, 2019 IEEE APPL IM PA, P1
   Migdol K., 2018, PIXELMRF CONVOLUTION
   Nasir OR, 2019, 2019 IEEE FIFTH INTERNATIONAL CONFERENCE ON MULTIMEDIA BIG DATA (BIGMM 2019), P58, DOI [10.1109/BigMM.2019.00-42, 10.1109/BigMM.2019.00020]
   Nguyen MT, 2021, ENG APPL ARTIF INTEL, V97, DOI 10.1016/j.engappai.2020.104100
   Obukhov Artem, 2020, Software Engineering Perspectives in Intelligent Systems. Proceedings of 4th Computational Methods in Systems and Software 2020. Advances in Intelligent Systems and Computing (AISC 1294), P102, DOI 10.1007/978-3-030-63322-6_8
   Oussidi A, 2018, 2018 INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS AND COMPUTER VISION (ISCV2018)
   Perinan-Pascual C., P 12 C SPAN ASS ART, P279
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Radford A., 2019, LANGUAGE MODELS ARE
   Reed S. E., 2016, ADV NEURAL INFORM PR, V29, P217
   Reed S, 2016, PR MACH LEARN RES, V48
   Salimans Tim, 2017, ICLR
   Shanshan Liu, 2020, IEEE Transactions on Artificial Intelligence, V1, P62, DOI 10.1109/TAI.2020.3028321
   Sharma Himanshu, 2020, 2020 International Conference on Power Electronics & IoT Applications in Renewable Energy and its Control (PARC), P325, DOI 10.1109/PARC49193.2020.236619
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Takase S., 2019, PROC NAACL
   Tao Ming, 2020, ARXIV200805865
   Toshpulatov M., IMAGE VISION COMPUTI
   Uchida S, 2018, JOINT INT CONF SOFT, P1433, DOI 10.1109/SCIS-ISIS.2018.00224
   van den Oord A, 2016, PR MACH LEARN RES, V48
   van den Oord Aaron., Advances in Neural Information Processing Systems, P4790
   Vaswani A, 2017, ADV NEUR IN, V30
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Wang ZX, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102904
   Wei RQ, 2020, IEEE ACCESS, V8, P153651, DOI 10.1109/ACCESS.2020.3018151
   Xu T, 2018, PROC CVPR IEEE, P1316, DOI 10.1109/CVPR.2018.00143
   Yang Zhilin, Advances in neural information processing systems, P5753
   Yin GJ, 2019, PROC CVPR IEEE, P2322, DOI 10.1109/CVPR.2019.00243
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhu M., P IEEE C COMP VIS PA, P5802
NR 59
TC 8
Z9 8
U1 9
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104284
DI 10.1016/j.imavis.2021.104284
EA SEP 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WC6NH
UT WOS:000704372400007
DA 2024-07-18
ER

PT J
AU Bai, L
   Wu, C
   Xie, F
   Wang, YM
AF Bai, Liu
   Wu, Cheng
   Xie, Feng
   Wang, Yiming
TI Crowd density detection method based on crowd gathering mode and
   multi-column convolutional neural network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Overcrowding; Crowd gathering safety; Video
   surveillance; Accident analysis and early warning
ID CELLULAR-AUTOMATA MODEL; DYNAMICS; BEHAVIOR
AB Crowds and stampedes often occur in crowd gathering places, resulting in a large number of casualties and causing great negative social impacts. Traditional research on the dynamic assessment of crowd gathering safety mainly relies on real-time video monitoring, but lacks reliable methods for processing a large amount of video data from different sources, different perspectives and different granularities. Based on Edward Hall's personal space theory, this article considers crowd psychology and other factors, and establishes static basic model of crowd gathering patterns. In order to fuse real-time multi-granularity surveillance videos with different perspectives, a multi-column convolutional neural network (M-CNN) was used to extract the local density characteristics of the crowd in a low-altitude perspective, thereby establishing a holographic model of the temporal and spatial evolution of the crowd situation, and a new crowd gathering safety assessment method. This method was actually applied to the safety assessment of crowd gathering in Suzhou landmark-Urban Living Fountain Square, and achieved good results, providing theoretical support for the safety management of crowd gathering places. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Bai, Liu; Wu, Cheng; Xie, Feng; Wang, Yiming] Soochow Univ, Sch Rail Transportat, Suzhou 215137, Jiangsu, Peoples R China.
C3 Soochow University - China
RP Wu, C (corresponding author), Soochow Univ, Sch Rail Transportat, Suzhou 215137, Jiangsu, Peoples R China.
EM 20174246009@stu.suda.edu.cn; cwu@suda.edu.cn
RI Wu, Cheng/AFP-6799-2022; bai, liu/KBD-2486-2024
OI Wu, Cheng/0000-0001-5451-3045; 
CR Ben XY, 2013, IET INTELL TRANSP SY, V7, P55, DOI 10.1049/iet-its.2011.0236
   Feliciani C, 2016, PHYSICA A, V451, P135, DOI 10.1016/j.physa.2016.01.057
   Fradi H, 2015, INFORM FUSION, V24, P3, DOI 10.1016/j.inffus.2014.09.005
   Ge WN, 2010, IEEE SIGNAL PROC MAG, V27, P107, DOI 10.1109/MSP.2010.937495
   Gordon C.C., 2010, TECHNICAL REPORT
   Grant JM, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3052930
   Hall Edward Twitchell, 1966, HIDDEN DIMENSION
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Helbing D, 2007, PHYS REV E, V75, DOI 10.1103/PhysRevE.75.046109
   Ji JW, 2018, PHYSICA A, V509, P1034, DOI 10.1016/j.physa.2018.06.055
   Johansson A, 2008, ADV COMPLEX SYST, V11, P497, DOI 10.1142/S0219525908001854
   Kok VJ, 2018, MULTIMED TOOLS APPL, V77, P20227, DOI 10.1007/s11042-017-5418-y
   Lin YC, 2004, APPL ERGON, V35, P173, DOI 10.1016/j.apergo.2004.01.004
   Luo HL, 2018, APPL SCI-BASEL, V8, DOI 10.3390/app8122367
   Meynberg O, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8060470
   Moussaïd M, 2011, P NATL ACAD SCI USA, V108, P6884, DOI 10.1073/pnas.1016507108
   Nagao K, 2018, PHYSICA A, V510, P145, DOI 10.1016/j.physa.2018.06.078
   Pu SL, 2017, PROCEDIA COMPUT SCI, V111, P154, DOI 10.1016/j.procs.2017.06.022
   Rao AS, 2015, VISUAL COMPUT, V31, P1533, DOI 10.1007/s00371-014-1032-4
   Tak S, 2018, TRANSPORTMETRICA A, V14, P484, DOI 10.1080/23249935.2017.1280559
   Was J, 2014, NEUROCOMPUTING, V146, P199, DOI 10.1016/j.neucom.2014.04.057
   Yang XX, 2014, PHYSICA A, V411, P63, DOI 10.1016/j.physa.2014.05.068
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zhao T, 2004, IEEE T PATTERN ANAL, V26, P1208, DOI 10.1109/TPAMI.2004.73
NR 25
TC 7
Z9 8
U1 1
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104084
DI 10.1016/j.imavis.2020.104084
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800010
DA 2024-07-18
ER

PT J
AU Munjal, B
   Aftab, AR
   Amin, S
   Brandlmaier, MD
   Tombari, F
   Galasso, F
AF Munjal, Bharti
   Aftab, Abdul Rafey
   Amin, Sikandar
   Brandlmaier, Meltem D.
   Tombari, Federico
   Galasso, Fabio
TI Joint detection and tracking in videos with identification features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Detection; Multi-object tracking; Re-identification; Online; Tracking by
   detection
AB Recent works have shown that combining object detection and tracking tasks, in the case of video data, results in higher performance for both tasks, but they require a high frame-rate as a strict requirement for performance. This assumption is often violated in real-world applications, when models run on embedded devices, often at only a few frames per second.
   Videos at low frame-rate suffer from large object displacements. Here re-identification features may support to match large-displaced object detections, but current joint detection and re-identification formulations degrade the detector performance, as these two are contrasting tasks. In the real-world application having separate detector and re-id models is often not feasible, as both the memory and runtime effectively double.
   Towards robust long-term tracking applicable to reduced-computational-power devices, we propose the first joint optimization of detection, tracking and re-identification features for videos. Notably, our joint optimization maintains the detector performance, a typical multi-task challenge. At inference time, we leverage detections for tracking (tracking-by-detection) when the objects are visible, detectable and slowly moving in the image. We leverage instead re-identification features to match objects which disappeared (e.g. due to occlusion) for several frames or were not tracked due to fast motion (or low-frame-rate videos). Our proposed method reaches the state-of-the-art on MOT, it ranks 1st in the UA-DETRAC'18 tracking challenge among online trackers, and 3rd overall. (C) 2020 Elsevier B.V. All tights reserved.
C1 [Munjal, Bharti; Aftab, Abdul Rafey; Amin, Sikandar; Brandlmaier, Meltem D.] OSRAM GmbH, Parkring 33 Garching, D-85748 Munich, Germany.
   [Munjal, Bharti; Tombari, Federico] Tech Univ Munich, Munich, Germany.
   [Galasso, Fabio] Sapienza Univ Rome, Rome, Italy.
C3 Osram; Siemens AG; Siemens Germany; Sanofi-Aventis; Technical University
   of Munich; Sapienza University Rome
RP Munjal, B (corresponding author), OSRAM GmbH, Parkring 33 Garching, D-85748 Munich, Germany.
EM munjalbharti@gmail.com
RI Galasso, Fabio/JSK-6738-2023
OI Galasso, Fabio/0000-0003-1875-7813
FU BMWi - Federal Ministry for Economic Affairs and Energy, Germany
   [19A16010D]
FX This research was partially supported by BMWi - Federal Ministry for
   Economic Affairs and Energy, Germany, under the grant number 19A16010D
   (MEC-View Project).
CR Almazan J., 2018, CORR, Vabs/1801.05339
   Amin S., 2017, IEEE, P1
   [Anonymous], 2016, CORR
   [Anonymous], 2018, CVPR
   Benenson R, 2015, LECT NOTES COMPUT SC, V8926, P613, DOI 10.1007/978-3-319-16181-5_47
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bochinski Erik, 2017, 2017 14th IEEE International Conference on Advanced Video and Signal-Based Surveillance (AVSS), DOI 10.1109/AVSS.2017.8078516
   Cai ZW, 2015, IEEE I CONF COMP VIS, P3361, DOI 10.1109/ICCV.2015.384
   Chen D, 2018, LECT NOTES COMPUT SC, V11211, P764, DOI 10.1007/978-3-030-01234-2_45
   Chen L, 2018, IEEE INT CON MULTI, DOI 10.1097/PEC.0000000000001553
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chu P, 2019, IEEE WINT CONF APPL, P161, DOI 10.1109/WACV.2019.00023
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Dai JF, 2016, ADV NEUR IN, V29
   Fang K., 2017, CORR
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   Fu ZY, 2019, IEEE T MULTIMEDIA, V21, P2277, DOI 10.1109/TMM.2019.2902480
   Girdhar R., 2018, CVPR
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Huang ZY, 2019, IEEE T IND ELECTRON, V66, P9798, DOI 10.1109/TIE.2018.2870413
   Kristan M, 2017, IEEE INT CONF COMP V, P1949, DOI 10.1109/ICCVW.2017.230
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Leal-Taixe L., 2017, CORR
   Lyu S., 2018, AVSS
   Lyu S., 2017, 2017 14 IEEE INT C, P1
   Lyu YZ, 2017, PROCEEDINGS OF THE 20TH INTERNATIONAL SYMPOSIUM ON ADVANCEMENT OF CONSTRUCTION MANAGEMENT AND REAL ESTATE, P1, DOI 10.1007/978-981-10-0855-9_1
   Mahmudov NI, 2019, MATH METHOD APPL SCI, V42, P5489, DOI 10.1002/mma.5446
   Munjal B., 2019, P BRIT MACH VIS C BM
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Real E, 2017, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR.2017.789
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Sanchez-Matilla R, 2016, LECT NOTES COMPUT SC, V9914, P84, DOI 10.1007/978-3-319-48881-3_7
   Tian W, 2020, IEEE T INTELL TRANSP, V21, P374, DOI 10.1109/TITS.2019.2892413
   Wang L, 2017, IEEE INT CON MULTI, P1135, DOI 10.1109/ICME.2017.8019461
   Wen LY, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102907
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu Y., 2020, IEEE T PATTERN ANAL, V37
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Yu F., 2020, ECCV
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhou H, 2019, IEEE T CIRC SYST VID, V29, P1011, DOI 10.1109/TCSVT.2018.2825679
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou X, 2018, BMVC
   Zhou ZW, 2018, INT C PATT RECOG, P1809, DOI 10.1109/ICPR.2018.8545450
   Zhu J, 2018, LECT NOTES COMPUT SC, V11209, P379, DOI 10.1007/978-3-030-01228-1_23
   Zhu X., 2018, CORR
NR 52
TC 12
Z9 14
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2020
VL 100
AR 103932
DI 10.1016/j.imavis.2020.103932
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA MY9GX
UT WOS:000558728800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yeo, D
   Lee, CO
AF Yeo, Doyeob
   Lee, Chang-Ock
TI Variational shape prior segmentation with an initial curve based on
   image registration technique
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape prior segmentation; Hierarchical image segmentation; Image
   registration; Free-form deformation
AB In general images, it is practically hard to distinguish only the desired object using the conventional image segmentation methods. In many cases, we can segment the desired object by using the shape information of the object in addition to the standard image segmentation. Chan and Zhu's model is not robust to the intensity changes of objects. In this paper, we propose a novel model for the shape prior segmentation that produces robust results using the hierarchical image segmentation and an attraction term. Moreover, we adopt an image registration technique and a multi-region image segmentation to get an initial for a given shape prior. Finally, we consider the free-form deformation in obtaining the shape function from the reference shape prior for real-world images. Numerical experiments demonstrate the results independent of intensities of objects and the location of the reference shape prior. All numerical calculations are automatic and progress without any user input. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Yeo, Doyeob; Lee, Chang-Ock] Korea Adv Inst Sci & Technol, Dept Math Sci, Daejeon 34141, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Yeo, D (corresponding author), Korea Adv Inst Sci & Technol, Dept Math Sci, Daejeon 34141, South Korea.
EM doyeob.yeo@kaist.ac.kr
RI Lee, Chang-Ock/C-1577-2011
FU National Research Foundation of Korea (NRF) - Ministry of Science and
   ICT (MSIT) [NRF-2017R1A2B4011627]
FX This work was supported by National Research Foundation of Korea (NRF)
   grant funded by Ministry of Science and ICT (MSIT)
   (NRF-2017R1A2B4011627).
CR [Anonymous], 2006, Mathematical problems in image processing: Partial differential equations and the calculus of variations
   [Anonymous], [No title captured]
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   Chan T, 2005, PROC CVPR IEEE, P1164
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen F, 2013, PROC CVPR IEEE, P1870, DOI 10.1109/CVPR.2013.244
   Chen SQ, 2012, IMAGE VISION COMPUT, V30, P1032, DOI 10.1016/j.imavis.2012.09.005
   Chen SQ, 2009, IEEE I CONF COMP VIS, P763, DOI 10.1109/ICCV.2009.5459290
   Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P388
   Cremers D., 2008, P IEEE C COMP VIS PA, P1
   Cremers D, 2007, TOP BIOMED ENG, P447, DOI 10.1007/978-0-387-68343-0_13
   Fundana K, 2007, IEEE IMAGE PROC, P285
   Jeon K, 2013, COMPUT MATH METHOD M, V2013, DOI 10.1155/2013/941745
   Le THN, 2016, PATTERN RECOGN, V54, P23, DOI 10.1016/j.patcog.2015.11.009
   Lewis JP, 1994, PROC CANAD IMAG PROC, P120
   Liu HZ, 2006, IEEE SIGNAL PROC LET, V13, P17, DOI 10.1109/LSP.2005.860549
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Mattes D, 2003, IEEE T MED IMAGING, V22, P120, DOI 10.1109/TMI.2003.809072
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   Riklin-Raviv T, 2004, LECT NOTES COMPUT SC, V2034, P50
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Schwarz L.A., 2007, Non-rigid Registration Using Free-form Deformations
   SUSSMAN M, 1994, J COMPUT PHYS, V114, P146, DOI 10.1006/jcph.1994.1155
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
NR 26
TC 6
Z9 6
U1 2
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103865
DI 10.1016/j.imavis.2019.103865
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900009
DA 2024-07-18
ER

PT J
AU Mustafa, HT
   Yang, J
   Zareapoor, M
AF Mustafa, Hafiz Tayyab
   Yang, Jie
   Zareapoor, Masoumeh
TI Multi-scale convolutional neural network for multi-focus image fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-focus image fusion; Convolutional neural network; Unsupervised;
   Structure similarity
ID QUALITY ASSESSMENT; SEGMENTATION
AB In this study, we present new deep learning (DL) method for fusing multi-focus images. Current multi-focus image fusion (MFIF) approaches based on DL methods mainly treat MFIF as a classification task. These methods use a convolutional neural network (CNN) as a classifier to identify pixels as focused or defocused pixels. However, due to unavailability of labeled data to train networks, existing DL-based supervised models for MFIF add Gaussian blur in focused images to produce training data. DL-based unsupervised models are also too simple and only applicable to perform fusion tasks other than MFIF. To address the above issues, we proposed a new MFIF method, which aims to learn feature extraction, fusion and reconstruction components together to produce a complete unsupervised end-to-end trainable deep CNN. To enhance the feature extraction capability of CNN, we introduce a Siamese multi-scale feature extraction module to achieve a promising performance. In our proposed network we applied multiscale convolutions along with skip connections to extract more useful common features from a multi-focus image pair. Instead of using basic loss functions to train the CNN, our model utilizes structure similarity (SSIM) measure as a training loss function. Moreover, the fused images are reconstructed in a multiscale manner to guarantee more accurate restoration of images. Our proposed model can process images with variable size during testing and validation. Experimental results on various test images validate that our proposed method yields better quality fused images that are superior to the fused images generated by compared state-of-the-art image fusion methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Mustafa, Hafiz Tayyab; Yang, Jie; Zareapoor, Masoumeh] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Mustafa, HT (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM mustafa.tayyab@hotmail.com
RI Mustafa, Tayyab/W-7957-2019; Zareapoor, Dr. Masoumeh/AAE-6067-2019;
   Yang, Jie/JCD-9867-2023
OI Zareapoor, Dr. Masoumeh/0000-0002-3991-0584; Zareapoor,
   Masoumeh/0000-0002-7569-9018
FU NSFC, China [61876107, 61572315, U1803261]; 973 Plan, China
   [2015CB856004]
FX This research is partly supported by NSFC, China (No: 61876107,
   61572315, U1803261) and 973 Plan, China (No. 2015CB856004).
CR Aslantas V, 2010, EXPERT SYST APPL, V37, P8861, DOI 10.1016/j.eswa.2010.06.011
   Azarang A, 2017, 2017 3RD INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION AND IMAGE ANALYSIS (IPRIA), P1, DOI 10.1109/PRIA.2017.7983017
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen Y, 2009, IMAGE VISION COMPUT, V27, P1421, DOI 10.1016/j.imavis.2007.12.002
   De I, 2013, INFORM FUSION, V14, P136, DOI 10.1016/j.inffus.2012.01.007
   Du CB, 2017, IEEE ACCESS, V5, P15750, DOI 10.1109/ACCESS.2017.2735019
   Erhan D, 2009, Univ Montr, V1341, P1
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goshtasby AA, 2007, INFORM FUSION, V8, P114, DOI 10.1016/j.inffus.2006.04.001
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossny M, 2010, ELECTRON LETT, V46, P1266, DOI 10.1049/el.2010.1778
   Krizhevsky A., 2014, The cifar-10 dataset
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   LI H, 1995, GRAPH MODEL IM PROC, V57, P235, DOI 10.1006/gmip.1995.1022
   Li M, 2006, PATTERN RECOGN LETT, V27, P1948, DOI 10.1016/j.patrec.2006.05.004
   Li ST, 2008, IMAGE VISION COMPUT, V26, P971, DOI 10.1016/j.imavis.2007.10.012
   Li ST, 2017, INFORM FUSION, V33, P100, DOI 10.1016/j.inffus.2016.05.004
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Li S, 2013, INFORM FUSION, V14, P147, DOI 10.1016/j.inffus.2011.07.001
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2018, INFORM FUSION, V42, P158, DOI 10.1016/j.inffus.2017.10.007
   Liu Y, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1070
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Liu Z, 2012, IEEE T PATTERN ANAL, V34, P94, DOI 10.1109/TPAMI.2011.109
   Masi G, 2016, REMOTE SENS-BASEL, V8, DOI 10.3390/rs8070594
   Mitianoudis N, 2008, IMAGE FUSION: ALGORITHMS AND APPLICATIONS, P85, DOI 10.1016/B978-0-12-372529-5.00010-X
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Palsson F, 2017, IEEE GEOSCI REMOTE S, V14, P639, DOI 10.1109/LGRS.2017.2668299
   Prabhakar KR, 2017, IEEE I CONF COMP VIS, P4724, DOI 10.1109/ICCV.2017.505
   Shutao Li, 2002, Information Fusion, V3, P17, DOI 10.1016/S1566-2535(01)00037-9
   Tang H, 2018, INFORM SCIENCES, V433, P125, DOI 10.1016/j.ins.2017.12.043
   Wan T, 2013, PATTERN RECOGN LETT, V34, P1001, DOI 10.1016/j.patrec.2013.03.003
   Wang Y., 2016, IEEE ACCESS
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yang B, 2017, INT J WAVELETS MULTI, V15, DOI 10.1142/S0219691317500370
   Yang B, 2010, IEEE T INSTRUM MEAS, V59, P884, DOI 10.1109/TIM.2009.2026612
   Yang C, 2008, INFORM FUSION, V9, P156, DOI 10.1016/j.inffus.2006.09.001
   Yosinski J., 2015, ARXIV150606579, V2015, P12
   Zhang Q, 2009, SIGNAL PROCESS, V89, P1334, DOI 10.1016/j.sigpro.2009.01.012
   Zhang Y, 2017, INFORM FUSION, V35, P81, DOI 10.1016/j.inffus.2016.09.006
   Zhao H, 2017, IEEE T COMPUT IMAG, V3, P47, DOI 10.1109/TCI.2016.2644865
   Zhao JY, 2007, INT J INNOV COMPUT I, V3, P1433
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
NR 46
TC 59
Z9 65
U1 3
U2 80
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2019
VL 85
BP 26
EP 35
DI 10.1016/j.imavis.2019.03.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HZ9DE
UT WOS:000469155200003
DA 2024-07-18
ER

PT J
AU Badea, M
   Florea, C
   Florea, L
   Vertan, C
AF Badea, Mihai
   Florea, Corneliu
   Florea, Laura
   Vertan, Constantin
TI Can we teach computers to understand art? Domain adaptation for
   enhancing deep networks capacity to de-abstract art
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolutional Neural Networks; Domain adaptation; Genre recognition;
   Painting analysis; Style transfer
AB Humans comprehend a natural scene at a single glance; painters and other visual artists, through their abstract representations, stressed this capacity to the limit. The performance of computer vision solutions matched that of humans in many problems of visual recognition. In this paper we address the problem of recognizing the genre (subject) in digitized paintings using Convolutional Neural Networks (CNN) as part of the more general dealing with abstract and/or artistic representation of scenes. Initially we establish the state of the art performance by training a CNN from scratch. In the next level of evaluation, we identify aspects that hinder the CNNs' recognition, such as artistic abstraction. Further, we test various domain adaptation methods that could enhance the subject recognition capabilities of the CNNs. The evaluation is performed on a database of 80,000 annotated digitized paintings, which is tentatively extended with artistic photographs, either original or stylized, in order to emulate artistic representations. Surprisingly, the most efficient domain adaptation is not the neural style transfer. Finally, the paper provides an experiment-based assessment of the abstraction level that CNNs are able to achieve. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Badea, Mihai; Florea, Corneliu; Florea, Laura; Vertan, Constantin] Univ Politehn Bucuresti, Image Proc & Anal Lab LAPI, Bucharest, Romania.
C3 National University of Science & Technology POLITEHNICA Bucharest
RP Florea, C (corresponding author), Univ Politehn Bucuresti, Image Proc & Anal Lab LAPI, Bucharest, Romania.
EM mbadea@imag.pub.ro; corneliu.florea@upb.ro; laura.florea@upb.ro;
   costantin.vertan@upb.ro
RI Florea, Laura Maria/I-6823-2013; Vertan, Constantin/F-4459-2015; Florea,
   Corneliu/B-5540-2012
OI Florea, Laura Maria/0000-0001-6095-9692; Florea,
   Corneliu/0000-0001-9754-6795
FU Romanian National Authority for Scientific Research and Innovation, CNCS
   UEFISCDI [PN-II-RU-TE-2014-4-0733]; CCCDI-UEFISCDI [96BM]
FX The work was supported by grants of the Romanian National Authority for
   Scientific Research and Innovation, CNCS UEFISCDI, number
   PN-II-RU-TE-2014-4-0733 and respectively, CCCDI-UEFISCDI, project number
   96BM. The authors would like to thank NVIDIA Corporation for donating
   the Tesla K40c GPU that helped run the experimental setup for this
   research.
CR Agarwal S, 2015, IEEE WINT CONF APPL, P588, DOI 10.1109/WACV.2015.84
   [Anonymous], 2014, CoRR
   [Anonymous], 2015, Large-scale classification of fine-art paintings: Learning the right metric on the right feature, DOI 10
   Aubry M., 2014, ACM T GRAPH, V33
   Aubry M., 2013, ACM T GRAPH, V33
   Badea M., 2017, SIGN CIRC SYST ISSCS, P1
   Bae SM, 2006, ACM T GRAPHIC, V25, P637, DOI 10.1145/1141911.1141935
   Bar Y, 2015, LECT NOTES COMPUT SC, V8925, P71, DOI 10.1007/978-3-319-16178-5_5
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bentkowska-Kafel A., 2010, COMPUTER VISION IMAG
   Borji A, 2018, IMAGE VISION COMPUT, V69, P1, DOI 10.1016/j.imavis.2017.10.001
   Cai H., 2015, INT C COMP VIS WORKS, P262
   Chen TC, 2017, AGEING SOC, V37, P1798, DOI 10.1017/S0144686X16000623
   Cichy RM, 2016, SCI REP-UK, V6, DOI 10.1038/srep27755
   Condorovici RG, 2013, LECT NOTES COMPUT SC, V8192, P262, DOI 10.1007/978-3-319-02895-8_24
   Crowley Elliot J., 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P721, DOI 10.1007/978-3-319-46604-0_50
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dean J., 2015, NIPS DEEP LEARNING R
   DiCarlo JJ, 2012, NEURON, V73, P415, DOI 10.1016/j.neuron.2012.01.010
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Donahue J, 2014, PR MACH LEARN RES, V32
   Florea C, 2017, LECT NOTES COMPUT SC, V10269, P337, DOI 10.1007/978-3-319-59126-1_28
   Florea C, 2017, IEEE WINT CONF APPL, P569, DOI 10.1109/WACV.2017.69
   Gatys L., 2016, Journal of Vision, V16, P326, DOI DOI 10.1167/16.12.326
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   Gupta Rajiv, 2015, P 19 INT C EV ASS SO, P1
   Hall P., 2015, Computational Visual Media, V1, P91, DOI DOI 10.1007/S41095-015-0017-1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herranz L, 2016, PROC CVPR IEEE, P571, DOI 10.1109/CVPR.2016.68
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karayev S., 2014, BRIT MACH VIS C
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li YH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2230
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   Monroy A, 2014, IMAGE VISION COMPUT, V32, P414, DOI 10.1016/j.imavis.2014.04.004
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Reinhard E, 2001, IEEE COMPUT GRAPH, V21, P34, DOI 10.1109/38.946629
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Sewards TV, 2011, NEUROPSYCHOLOGIA, V49, P277, DOI 10.1016/j.neuropsychologia.2010.11.018
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sunkavalli K, 2010, ACM T GRAPHIC, V29, DOI 10.1145/1778765.1778862
   Tan W. R., 2016, IEEE INT C IM PROC
   Thomas C, 2016, PROC CVPR IEEE, P3494, DOI 10.1109/CVPR.2016.380
   Ulyanov D., 2016, P 33 INT C INT C MAC, V48, P1349
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou B., 2014, Adv Neural Inf Proces Syst27
NR 50
TC 2
Z9 3
U1 1
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2018
VL 77
BP 21
EP 32
DI 10.1016/j.imavis.2018.06.009
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV7DT
UT WOS:000446282900003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ghorbel, E
   Boutteau, R
   Boonaert, J
   Savatier, X
   Lecoeuche, S
AF Ghorbel, Enjie
   Boutteau, Remi
   Boonaert, Jacques
   Savatier, Xavier
   Lecoeuche, Stephane
TI Kinematic Spline Curves: A temporal invariant descriptor for fast action
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RBG-D cameras; Action recognition; Low computational latency; Temporal
   normalization
ID REPRESENTATION; FEATURES; LATENCY; MOTION; JOINTS
AB Over the last few decades, action recognition applications have attracted the growing interest of researchers, especially with the advent of RGB-D cameras. These applications increasingly require fast processing. Therefore, it becomes important to include the computational latency in the evaluation criteria.
   In this paper, we propose a novel human action descriptor based on skeleton data provided by RGB-D cameras for fast action recognition. The descriptor is built by interpolating the kinematics of skeleton joints (position, velocity and acceleration) using a cubic spline algorithm. A skeleton normalization is done to alleviate anthropometric variability. To ensure rate invariance which is one of the most challenging issues in action recognition, a novel temporal normalization algorithm called Time Variable Replacement (TVR) is proposed. It is a change of variable of time by a variable that we call Normalized Action Time (NAT) varying in a fixed range and making the descriptors less sensitive to execution rate variability. To map time with NAT, increasing functions (called Time Variable Replacement Function (TVRF)) are used. Two different Time Variable Replacement Functions (TVRF) are proposed in this paper: the Normalized Accumulated kinetic Energy (NAE) of the skeleton and the Normalized Pose Motion Signal Energy (NPMSE) of the skeleton. The action recognition is carried out using a linear Support Vector Machine (SVM). Experimental results on five challenging benchmarks show the effectiveness of our approach in terms of recognition accuracy and computational latency. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Ghorbel, Enjie; Boonaert, Jacques; Lecoeuche, Stephane] Univ Lille, IMT Lille Douai, Unite Rech Informat & Automat, F-59000 Lille, France.
   [Ghorbel, Enjie; Boutteau, Remi; Savatier, Xavier] Normandie Univ, UNIROUEN, ESIGELEC, IRSEEM, F-76000 Rouen, France.
C3 Universite de Lille; IMT - Institut Mines-Telecom; IMT Nord Europe;
   Universite de Rouen Normandie
RP Ghorbel, E (corresponding author), Mines Douai IA, F-59508 Douai, France.
EM enjie.ghorbel@mines-douai.fr
RI Boutteau, Rémi/U-7674-2019; Ghorbel, Enjie/HRD-2176-2023; Lecoeuche,
   Stéphane/AAG-3139-2020; SAVATIER, Xavier/AAG-6093-2019
OI Boutteau, Rémi/0000-0003-1078-5043; Lecoeuche,
   Stéphane/0000-0002-5599-1185; GHORBEL, Enjie/0000-0002-6878-0141;
   BOONAERT, Jacques/0000-0002-8594-6959
CR [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], MEASURING BEHAV
   Bettadapura V, 2013, PROC CVPR IEEE, P2619, DOI 10.1109/CVPR.2013.338
   Boukharouba K., 2010, 2010 2nd International Conference on Image Processing Theory, Tools and Applications (IPTA 2010), P157, DOI 10.1109/IPTA.2010.5586767
   Brun L, 2016, COMPUT VIS IMAGE UND, V144, P3, DOI 10.1016/j.cviu.2015.09.003
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Coxeter HMS., 1973, Dover Books on Mathematics, V3rd
   Crammer K, 2002, MACH LEARN, V47, P201, DOI 10.1023/A:1013637720281
   Cuntoor NP, 2006, LECT NOTES COMPUT SC, V3852, P499
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Boor C., 2005, Spline Toolbox for use with MATLAB
   Devanne M, 2017, PATTERN RECOGN, V61, P222, DOI 10.1016/j.patcog.2016.07.041
   Devanne M, 2015, IEEE T CYBERNETICS, V45, P1340, DOI 10.1109/TCYB.2014.2350774
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Ellis C, 2013, INT J COMPUT VISION, V101, P420, DOI 10.1007/s11263-012-0550-7
   Evangelidis G, 2014, INT C PATT RECOG, P4513, DOI 10.1109/ICPR.2014.772
   Fanello SR, 2013, J MACH LEARN RES, V14, P2617
   Foggia P, 2013, IEEE SYS MAN CYBERN, P2910, DOI 10.1109/SMC.2013.496
   Fothergill S., 2012, P SIGCHI C HUM FACT, P1737, DOI DOI 10.1145/2207676.2208303
   Ghorbel E, 2016, INT C PATT RECOG, P919, DOI 10.1109/ICPR.2016.7899753
   Ghorbel E, 2015, INT CONF IMAG PROC, P61, DOI 10.1109/IPTA.2015.7367097
   Hammouche M., 2016, INT JOINT C COMP VIS
   Hussein, 2013, INT JOINT C ART INT
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Ke QH, 2017, IEEE SIGNAL PROC LET, V24, P731, DOI 10.1109/LSP.2017.2690339
   Kim SJ, 2014, PATTERN RECOGN LETT, V49, P40, DOI 10.1016/j.patrec.2014.05.018
   Klaser A., 2008, BRIT MACH VIS C
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu J, 2016, LECT NOTES COMPUT SC, V9907, P816, DOI 10.1007/978-3-319-46487-9_50
   Liu Z, 2016, IMAGE VISION COMPUT, V55, P93, DOI 10.1016/j.imavis.2016.04.004
   Luo JJ, 2014, PATTERN RECOGN LETT, V50, P139, DOI 10.1016/j.patrec.2014.03.024
   Miranda L., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P268, DOI 10.1109/SIBGRAPI.2012.44
   Ofli F, 2014, J VIS COMMUN IMAGE R, V25, P24, DOI 10.1016/j.jvcir.2013.04.007
   Ohn-Bar E, 2013, IEEE COMPUT SOC CONF, P465, DOI 10.1109/CVPRW.2013.76
   Onuma Kensuke, 2008, EUROGRAPHICS, P83
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   PADILLALOPEZ JR, 2014, ARXIV14077390
   Papadopoulos Georgios Th, 2014, MultiMedia Modeling. 20th Anniversary International Conference, MMM 2014. Proceedings: LNCS 8325, P473, DOI 10.1007/978-3-319-04114-8_40
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Qiao RZ, 2017, PATTERN RECOGN, V66, P202, DOI 10.1016/j.patcog.2017.01.015
   Rahmani H, 2017, IEEE I CONF COMP VIS, P5833, DOI 10.1109/ICCV.2017.621
   Rahmani H, 2016, IEEE T PATTERN ANAL, V38, P2430, DOI 10.1109/TPAMI.2016.2533389
   Sabri AQM, 2012, IEEE IMAGE PROC, P1401, DOI 10.1109/ICIP.2012.6467131
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Shan JJ, 2014, 2014 IEEE WORKSHOP ON ADVANCED ROBOTICS AND ITS SOCIAL IMPACTS (ARSO), P69, DOI 10.1109/ARSO.2014.7020983
   Shi YB, 2015, LECT NOTES ARTIF INT, V9227, P311, DOI 10.1007/978-3-319-22053-6_34
   Shukla P, 2013, MVA, P41
   Slama R, 2014, INT C PATT RECOG, P3499, DOI 10.1109/ICPR.2014.602
   Vemulapalli R, 2016, COMPUT VIS IMAGE UND, V152, P155, DOI 10.1016/j.cviu.2016.04.005
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Vidal Rene, 2007, Proceedings of the European Control Conference 2007 (ECC), P4853
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang X., 2012, IEEE COMP SOC C COMP, V2012, P14, DOI [DOI 10.1109/CVPRW.2012.6239232, 10.1109/CVPRW.2012.6239232]
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhu F, 2016, IMAGE VISION COMPUT, V55, P42, DOI 10.1016/j.imavis.2016.06.007
   Zhu Y, 2013, IEEE COMPUT SOC CONF, P486, DOI 10.1109/CVPRW.2013.78
NR 62
TC 10
Z9 11
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2018
VL 77
BP 60
EP 71
DI 10.1016/j.imavis.2018.06.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV7DT
UT WOS:000446282900006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Häne, C
   Heng, L
   Lee, GH
   Fraundorfer, F
   Furgale, P
   Sattler, T
   Pollefeys, M
AF Hane, Christian
   Heng, Lionel
   Lee, Gim Hee
   Fraundorfer, Friedrich
   Furgale, Paul
   Sattler, Torsten
   Pollefeys, Marc
TI 3D visual perception for self-driving cars using a multi-camera system:
   Calibration, mapping, localization, and obstacle detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fisheye camera; Multi-camera system; Calibration; Mapping; Localization;
   Obstacle detection
AB Cameras are a crucial exteroceptive sensor for self-driving cars as they are low-cost and small, provide appearance information about the environment, and work in various weather conditions. They can be used for multiple purposes such as visual navigation and obstacle detection. We can use a surround multi-camera system to cover the full 360-degree field-of-view around the car. In this way, we avoid blind spots which can otherwise lead to accidents. To minimize the number of cameras needed for surround perception, we utilize fisheye cameras. Consequently, standard vision pipelines for 3D mapping, visual localization, obstacle detection, etc. need to be adapted to take full advantage of the availability of multiple cameras rather than treat each camera individually. In addition, processing of fisheye images has to be supported. In this paper, we describe the camera calibration and subsequent processing pipeline for multi-fisheye-camera systems developed as part of the V-Charge project. This project seeks to enable automated valet parking for self-driving cars. Our pipeline is able to precisely calibrate multi-camera systems, build sparse 3D maps for visual navigation, visually localize the car with respect to these maps, generate accurate dense maps, as well as detect obstacles based on real-time depth map extraction. (C) 2017 Published by Elsevier B.V.
C1 [Hane, Christian] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
   [Sattler, Torsten; Pollefeys, Marc] Swiss Fed Inst Technol, Dept Comp Sci, Univ Str 6, CH-8092 Zurich, Switzerland.
   [Heng, Lionel] DSO Natl Labs, Informat Div, 12 Sci Pk Dr, Singapore 118225, Singapore.
   [Lee, Gim Hee] Natl Univ Singapore, Dept Comp Sci, 13 Comp Dr, Singapore 117417, Singapore.
   [Fraundorfer, Friedrich] Graz Univ Technol, Inst Comp Graph & Vis, Inffeldgasse 16, A-8010 Graz, Austria.
   [Furgale, Paul] Swiss Fed Inst Technol, Dept Mech & Proc Engn, Leonhardstr 21, CH-8092 Zurich, Switzerland.
   [Pollefeys, Marc] Microsoft, One Microsoft Way, Redmond, WA 98052 USA.
C3 University of California System; University of California Berkeley;
   Swiss Federal Institutes of Technology Domain; ETH Zurich; National
   University of Singapore; Graz University of Technology; Swiss Federal
   Institutes of Technology Domain; ETH Zurich; Microsoft
RP Häne, C (corresponding author), Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA 94720 USA.; Heng, L (corresponding author), DSO Natl Labs, Informat Div, 12 Sci Pk Dr, Singapore 118225, Singapore.; Lee, GH (corresponding author), Natl Univ Singapore, Dept Comp Sci, 13 Comp Dr, Singapore 117417, Singapore.
EM chaene@eecs.berkeley.edu; lionel_heng@dso.org.sg; gimhee.lee@nus.edu.sg;
   fraundorfer@icg.tugraz.at; paul.furgale@mavt.ethz.ch;
   sattlert@inf.ethz.ch; marc.pollefeys@inf.ethz.ch
RI Lee, Gim Hee/K-5241-2015; Sattler, Torsten/AAM-3155-2021; Pollefeys,
   Marc/I-7607-2013
OI Pollefeys, Marc/0000-0003-2448-2318
FU European Community's Seventh Framework Programme [269916]; 4DVideo ERC
   [210806]
FX This work is supported in parts by the European Community's Seventh
   Framework Programme (FP7/2007-2013) under grant #269916 (V-Charge) and
   4DVideo ERC Starting Grant Nr. 210806.
CR [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2008, COMPUTER VISION IMAG
   [Anonymous], INT S ROB RES ISRR
   [Anonymous], 2014, INT C 3D VIS 3DV
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2013, IEEE RSJ INT C INT R
   [Anonymous], 1981, COMMUNICATIONS ACM
   [Anonymous], 1997, Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], IEEE INT C ROB AUT I
   [Anonymous], 2006, IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C ROB AUT I
   [Anonymous], IEEE C COMP VIS PATT
   Carrera G, 2011, IEEE INT CONF ROBOT, P2652, DOI 10.1109/ICRA.2011.5980294
   Chambolle A, 2011, J MATH IMAGING VIS, V40, P120, DOI 10.1007/s10851-010-0251-1
   Furgale P, 2013, IEEE INT VEH SYM, P809, DOI 10.1109/IVS.2013.6629566
   Gallup D., 2007, C COMP VIS PATT REC
   Gallup D., 2010, INT C 3D DAT PROC VI
   Gonçalves RS, 2011, COMP MED SY
   Guo CX, 2012, IEEE INT CONF ROBOT, P3962, DOI 10.1109/ICRA.2012.6225339
   Halle C., 2015, IEEE RSJ INT C INT R
   Hane C., 2011, IEEE RSJ INT C INT R
   Haralick R. M., 1991, IEEE C COMP VIS PATT
   Heng L, 2015, J FIELD ROBOT, V32, P775, DOI 10.1002/rob.21540
   KANG SB, 2001, IEEE COMP SOC C COMP
   Kumar R.K., 2008, Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2008.4587676
   Lebraly Pierre, 2011, 2011 IEEE International Conference on Robotics and Automation, P221
   Lee G. H., 2014, INT C ROB AUT ICRA
   Lee G.H., 2015, The Int. J. Robotics Research (IJRR)
   Levinson J., 2010, IEEE INT C ROB AUT I
   Li B, 2013, IEEE INT C INT ROBOT, P1301, DOI 10.1109/IROS.2013.6696517
   Li H. D., 2008, IEEE C VIS PATT REC
   Moreno-Noguer F., 2007, INT C COMP VIS ICCV
   Pless R., 2003, IEEE C VIS PATT REV
   Quan L., 1999, PATTERN ANAL MACHINE
   Siegwart R., 2011, Introduction to Autonomous Mobile Robots, VSecond
   Stewenius H., 2005, WORKSH OMN VIS CAM N
   TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9
   YANG R, 2003, C COMP VIS PATT REC
   Ziegler J, 2014, IEEE INTEL TRANSP SY, V6, P8, DOI 10.1109/MITS.2014.2306552
NR 40
TC 133
Z9 147
U1 8
U2 106
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2017
VL 68
SI SI
BP 14
EP 27
DI 10.1016/j.imavis.2017.07.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FR9UP
UT WOS:000419418900003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhen, XT
   Shao, L
AF Zhen, Xiantong
   Shao, Ling
TI Action recognition via spatio-temporal local features: A comprehensive
   study
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Spatio-temporal local features; Feature coding;
   Bag-of-words; Sparse coding; Fisher kernel; VLAD; NBNN; Match kernels;
   Performance evaluation
ID DESCRIPTORS; VECTOR
AB Local methods based on spatio-temporal interest points (STIPs) have shown their effectiveness for human action recognition. The bag-of-words (BoW) model has been widely used and dominated in this field. Recently, a large number of techniques based on local features including improved variants of the BoW model, sparse coding (SC), Fisher kernels (FK), vector of locally aggregated descriptors (VLAD) as well as the naive Bayes nearest neighbor (NBNN) classifier have been proposed and developed for visual recognition. However, some of them are proposed in the image domain and have not yet been applied to the video domain and it is still unclear how effectively these techniques would perform on action recognition. In this paper, we provide a comprehensive study on these local methods for human action recognition. We implement these techniques and conduct comparison under unified experimental settings on three widely used benchmarks, i.e., the KTH, UCF-YouTube and HMDB51 datasets. We discuss insightfully the findings from the experimental results and draw useful conclusions, which are expected to guide practical applications and future work for the action recognition community. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zhen, Xiantong; Shao, Ling] Nanjing Univ Informat Sci & Technol, Coll Elect & Informat Engn, Nanjing, Jiangsu, Peoples R China.
   [Shao, Ling] Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
   [Zhen, Xiantong] Univ Sheffield, Dept Elect & Elect Engn, Sheffield S10 2TN, S Yorkshire, England.
C3 Nanjing University of Information Science & Technology; Northumbria
   University; University of Sheffield
RP Shao, L (corresponding author), Nanjing Univ Informat Sci & Technol, Coll Elect & Informat Engn, Nanjing, Jiangsu, Peoples R China.; Shao, L (corresponding author), Northumbria Univ, Dept Comp Sci & Digital Technol, Newcastle Upon Tyne NE1 8ST, Tyne & Wear, England.
EM ling.shao@ieee.org
RI Shao, Ling/D-3535-2011
OI Shao, Ling/0000-0002-8264-6117
CR [Anonymous], ELECT LETT COMP VISI
   [Anonymous], ANN ARBOR
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2009, COMPUT COMPLEX, DOI DOI 10.1002/HRDQ
   [Anonymous], BRIT C COMP VIS
   [Anonymous], 2013, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], SPARSE SPATIOTEMPORA
   [Anonymous], REPRESENTING PAIRWIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Boiman O., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587598
   Boureau YL, 2010, PROC CVPR IEEE, P2559, DOI 10.1109/CVPR.2010.5539963
   Cai ZW, 2014, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2014.83
   Campos T. D., 2011, Applications of Computer Vision (WACV), 2011 IEEE Workshop on, P344
   Cinbis RG, 2012, PROC CVPR IEEE, P2184, DOI 10.1109/CVPR.2012.6247926
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Everts I, 2013, PROC CVPR IEEE, P2850, DOI 10.1109/CVPR.2013.367
   Florent Perronnin Christopher, 2007, IEEE C COMPUTER VISI, P1
   Gaur U, 2011, IEEE I CONF COMP VIS, P2595, DOI 10.1109/ICCV.2011.6126548
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   Huang YZ, 2014, IEEE T PATTERN ANAL, V36, P493, DOI 10.1109/TPAMI.2013.113
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Kantorov V, 2014, PROC CVPR IEEE, P2593, DOI 10.1109/CVPR.2014.332
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Laptev I, 2007, COMPUT VIS IMAGE UND, V108, P207, DOI 10.1016/j.cviu.2006.11.023
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu LQ, 2011, IEEE I CONF COMP VIS, P2486, DOI 10.1109/ICCV.2011.6126534
   Liu Q, 2008, IEEE IC COMP COM NET, P1
   Lu ZW, 2011, IEEE I CONF COMP VIS, P1503, DOI 10.1109/ICCV.2011.6126408
   Lyu SW, 2005, PROC CVPR IEEE, P223
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   McCann S, 2012, PROC CVPR IEEE, P3650, DOI 10.1109/CVPR.2012.6248111
   Oikonomopoulos A, 2006, IEEE T SYST MAN CY B, V36, P710, DOI 10.1109/TSMCB.2005.861864
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Peng XJ, 2014, LECT NOTES COMPUT SC, V8693, P581, DOI 10.1007/978-3-319-10602-1_38
   Perronnin F, 2010, LECT NOTES COMPUT SC, V6314, P143, DOI 10.1007/978-3-642-15561-1_11
   Reddy KK, 2013, MACH VISION APPL, V24, P971, DOI 10.1007/s00138-012-0450-4
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shao L., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, P477
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Shapovalova N, 2012, LECT NOTES COMPUT SC, V7578, P55, DOI 10.1007/978-3-642-33786-4_5
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Sun L, 2014, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2014.336
   Tamrakar A, 2012, PROC CVPR IEEE, P3681, DOI 10.1109/CVPR.2012.6248114
   Thi TH, 2012, IMAGE VISION COMPUT, V30, P1, DOI 10.1016/j.imavis.2011.12.006
   Tuytelaars T, 2011, IEEE I CONF COMP VIS, P1824, DOI 10.1109/ICCV.2011.6126449
   van Gemert JC, 2010, IEEE T PATTERN ANAL, V32, P1271, DOI 10.1109/TPAMI.2009.132
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Vig E, 2012, LECT NOTES COMPUT SC, V7578, P84, DOI 10.1007/978-3-642-33786-4_7
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Wang H, 2011, PROC CVPR IEEE
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Wang J, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995493
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang S, 2012, PROC CVPR IEEE, P1370, DOI 10.1109/CVPR.2012.6247823
   Wong Shu-Fai, 2007, IEEE 11 INT C COMPUT, P1
   Wu BX, 2014, PROC CVPR IEEE, P2609, DOI 10.1109/CVPR.2014.334
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang S, 2015, PROC CVPR IEEE, P1610, DOI 10.1109/CVPR.2015.7298769
   Yang XD, 2014, LECT NOTES COMPUT SC, V8690, P727, DOI 10.1007/978-3-319-10605-2_47
   Zhang YM, 2012, LECT NOTES COMPUT SC, V7574, P707, DOI 10.1007/978-3-642-33712-3_51
   Zhen XT, 2013, IEEE T CIRC SYST VID, V23, P1182, DOI 10.1109/TCSVT.2013.2240916
   Zhu Y, 2011, LECT NOTES COMPUT SC, V6493, P660
NR 73
TC 30
Z9 32
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2016
VL 50
BP 1
EP 13
DI 10.1016/j.imavis.2016.02.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DP4KP
UT WOS:000378465100001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Messelodi, S
   Modena, CM
AF Messelodi, Stefano
   Modena, Carla Maria
TI Boosting Fisher vector based scoring functions for person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Fisher vector; Adaptive boosting; Likelihood
   ratio; Similarity ranking
AB In recent years, much effort has been put into the development of novel algorithms to solve the person re-identification problem. The goal is to match a given person's image against a gallery of people. In this paper, we propose a single-shot supervised method to compute a scoring function that, when applied to a pair of images, provides a score expressing the likelihood that they depict the same individual. The method is characterized by: (i) the usage of a set of local image descriptors based on Fisher vectors, (ii) the training of a pool of scoring functions based on the local descriptors, and (iii) the construction of a strong scoring function by means of an adaptive boosting procedure. The method has been tested on four data-sets and results have been compared with state-of-the-art methods clearly showing superior performance. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Messelodi, Stefano; Modena, Carla Maria] Fdn Bruno Kessler, I-38123 Trento, Italy.
C3 Fondazione Bruno Kessler
RP Modena, CM (corresponding author), Fdn Bruno Kessler, Via Sommarive 18, I-38123 Trento, Italy.
EM messelod@fbk.eu; modena@fbk.eu
RI Messelodi, Stefano/C-4370-2013; Modena, Carla Maria/M-3806-2019
OI Modena, Carla Maria/0000-0001-7015-8768
CR An L., IEEE INT C ADV VID S, P244
   Balderi D., INT ACM WORKSH MULT, P59
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Chatfield K., BRIT MACH VIS C 2011, P761
   D'Orazio T, 2012, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2012.6467181
   Dikmen M., AS C COMP VIS 2010 Q, P501
   Doretto G, 2011, J AMB INTEL HUM COMP, V2, P127, DOI 10.1007/s12652-010-0034-y
   Freund Y, 2004, J MACH LEARN RES, V4, P933, DOI 10.1162/1532443041827916
   Gray D., IEEE INT WORKSH PERF, P262
   Hirzer M., IEEE INT C ADV VID S, P203
   Hirzer M., EUR C COMP VIS 2012, P780
   Hirzer M., SCAND C IM AN LUND S, P91
   Jaakkola TS, 1999, ADV NEUR IN, V11, P487
   Kostinger M., IEEE C COMP VIS PATT, P2288
   Li W., IEEE C COMP VIS PATT, P3594
   Ma B., INT WORKSH REID CONJ, P413
   Ma BP, 2014, IMAGE VISION COMPUT, V32, P379, DOI 10.1016/j.imavis.2014.04.002
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Moghaddam B., INT C PATT REC 1996, P350
   Pedagadi S, 2013, PROC CVPR IEEE, P3318, DOI 10.1109/CVPR.2013.426
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Roweis S, 1998, ADV NEUR IN, V10, P626
   Saghafi MA, 2014, IET COMPUT VIS, V8, P455, DOI 10.1049/iet-cvi.2013.0180
   Sánchez J, 2013, INT J COMPUT VISION, V105, P222, DOI 10.1007/s11263-013-0636-x
   Satta R., 2013, ARXIV13075748V1 U CA
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Zheng W.-S., BRIT MACH VIS C 2009, P231
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
NR 28
TC 8
Z9 8
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2015
VL 44
BP 44
EP 58
DI 10.1016/j.imavis.2015.09.008
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CZ5EK
UT WOS:000367125100004
DA 2024-07-18
ER

PT J
AU Qi, XB
   Shen, LL
   Zhao, GY
   Li, QQ
   Pietikäinen, M
AF Qi, Xianbiao
   Shen, Linlin
   Zhao, Guoying
   Li, Qingquan
   Pietikainen, Matti
TI Globally rotation invariant multi-scale co-occurrence local binary
   pattern
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-scale co-occurrence LBP; Globally rotation invariant; Locally
   rotation invariant; Texture classification
ID TEXTURE CLASSIFICATION; SCALE
AB This paper proposes a globally rotation invariant multi-scale co-occurrence local binary pattern (MCLBP) feature for texture-relevant tasks. In MCLBP, we arrange all co-occurrence patterns into groups according to properties of the to-patterns, and design three encoding functions (Sum, Moment, and Fourier Pooling) to extract features from each group. The MCLBP can effectively capture the correlation information between different scales and is also globally rotation invariant (GRI). The MCLBP is substantially different from most existing LBP variants including the LBP, the CLBP, and the MSJ-LBP that achieves rotation invariance by locally rotation invariant (LRI) encoding. We fully evaluate the properties of the MCLBP and compare it with some powerful features on five challenging databases. Extensive experiments demonstrate the effectiveness of the MCLBP compared to the state-of-the-art LBP variants including the CLBP and the LBPHF. Meanwhile, the dimension and computational cost of the MCLBP is also lower than that of the CLBP_S/M/C and LBPHF_S_M. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Qi, Xianbiao; Shen, Linlin; Li, Qingquan] Shenzhen Univ, Shenzhen Key Lab Spatial Informat Smart Sensing &, Shenzhen, Guangdong, Peoples R China.
   [Qi, Xianbiao; Zhao, Guoying; Pietikainen, Matti] Univ Oulu, Dept Comp Sci & Engn, FIN-90014 Oulu, Finland.
C3 Shenzhen University; University of Oulu
RP Qi, XB (corresponding author), Shenzhen Univ, Shenzhen Key Lab Spatial Informat Smart Sensing &, Shenzhen, Guangdong, Peoples R China.
EM qixianbiao@gmail.com; llshen@szu.edu.cn; gyzhao@ee.oulu.fi;
   liqq@szu.edu.cn; mkp@ee.oulu.fi
RI Shen, Linlin/AEX-9392-2022; Zhao, Guoying/ABE-7716-2020
OI Shen, Linlin/0000-0003-1420-0815; Zhao, Guoying/0000-0003-3694-206X; Qi,
   Xianbiao/0000-0002-8493-1966
FU Academy of Finland; Info-tech Oulu; Shenzhen Scientific Research and
   Development Funding Program [ZDSY20121019111146499,
   JSGG20121026111056204]; Shenzhen Dedicated Funding of Strategic Emerging
   Industry Development Program [JCYJ20121019111128765]
FX This work was supported by the Academy of Finland and Info-tech Oulu. Q.
   Li and L. Shen are supported by grants from Shenzhen Scientific Research
   and Development Funding Program (No. ZDSY20121019111146499, No.
   JSGG20121026111056204), and Shenzhen Dedicated Funding of Strategic
   Emerging Industry Development Program (No. JCYJ20121019111128765).
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], ECCV
   [Anonymous], 2003, PROC IEEE COMPUT SOC
   [Anonymous], INT J COMPUT VISION
   [Anonymous], BMVC
   Boland MV, 2001, BIOINFORMATICS, V17, P1213, DOI 10.1093/bioinformatics/17.12.1213
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hong X., 2014, IEEE T IMAGE PROCESS
   Hu D., 2011, BMVC
   Li WB, 2012, LECT NOTES COMPUT SC, V7575, P345, DOI 10.1007/978-3-642-33765-9_25
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu C, 2010, PROC CVPR IEEE, P239, DOI [10.1109/CVPR.2010.5540207, 10.1109/ICCET.2010.5485248]
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Liu L, 2011, IEEE I CONF COMP VIS, P391, DOI 10.1109/ICCV.2011.6126267
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mäenpää T, 2003, LECT NOTES COMPUT SC, V2749, P885
   MAENPAA T, 2005, HDB PATTERN RECOGNIT
   Nanni L., 2010, P 2010 INT C IM PROC
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Nosaka R, 2011, LECT NOTES COMPUT SC, V7088, P82, DOI 10.1007/978-3-642-25346-1_8
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   Pietikainen M, 2011, COMPUT IMAGING VIS, V40, P1
   Qi XB, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.40
   Shannon C.E., 1948, MATH THEORY COMMUNIC, V117
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Wu JX, 2011, IEEE T PATTERN ANAL, V33, P1489, DOI 10.1109/TPAMI.2010.224
   Xiao Y, 2014, IEEE T IMAGE PROCESS, V23, P823, DOI 10.1109/TIP.2013.2295756
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
NR 42
TC 29
Z9 30
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2015
VL 43
BP 16
EP 26
DI 10.1016/j.imavis.2015.07.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CY0AU
UT WOS:000366069200002
DA 2024-07-18
ER

PT J
AU Ming, Y
AF Ming, Yue
TI Robust regional bounding spherical descriptor for 3D face recognition
   and emotion analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face recognition; Emotion analysis; Regional bounding spherical
   descriptor; Regional and global regression; Kullback-Leiber divergence
   (KLD)
AB 3D face recognition and emotion analysis play important roles in many fields of communication and edutainment An effective facial descriptor, with higher discriminating capability for face recognition and higher descriptiveness for facial emotion analysis, is a challenging issue. However, in the practical applications, the descriptiveness and discrimination are independent and contradictory to each other. 3D facial data provide a promising way to balance these two aspects. In this paper, a robust regional bounding spherical descriptor (RBSR) is proposed to facilitate 3D face recognition and emotion analysis. In our framework, we first segment a group of regions on each 3D facial point cloud by shape index and spherical bands on the human face. Then the corresponding facial areas are projected to regional bounding spheres to obtain our regional descriptor. Finally, a regional and global regression mapping (RGRM) technique is employed to the weighted regional descriptor for boosting the classification accuracy. Three largest available databases, FRGC v2, CASIA and BU-3DFE, are contributed to the performance comparison and the experimental results show a consistently better performance for 3D face recognition and emotion analysis. (C) 2015 Elsevier B.V. All rights reserved.
C1 Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Ming, Y (corresponding author), Beijing Univ Posts & Telecommun, Sch Elect Engn, Beijing Key Lab Work Safety Intelligent Monitorin, Beijing 100876, Peoples R China.
EM myname35875235@126.com
FU National Natural Science Foundation of China [NSFC-61402046]; Beijing
   University of Posts and Telecommunications [2013XZ10]
FX The work presented in this paper was supported by the National Natural
   Science Foundation of China (Grant No. NSFC-61402046), President Funding
   of Beijing University of Posts and Telecommunications (Grant No.
   2013XZ10).
CR Alyüz N, 2010, IEEE T INF FOREN SEC, V5, P425, DOI 10.1109/TIFS.2010.2054081
   [Anonymous], P IEEE COMP SOC C CO
   Bai XA, 2009, PROC CVPR IEEE, P1335, DOI 10.1109/CVPRW.2009.5206543
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733
   Cook J., 2006, PROC BRIT MACHINE VI, P83
   Dorai C, 1997, IEEE T PATTERN ANAL, V19, P1115, DOI 10.1109/34.625113
   Faltemier TC, 2008, IEEE T INF FOREN SEC, V3, P62, DOI 10.1109/TIFS.2007.916287
   Gao Y, 2012, IEEE T IMAGE PROCESS, V21, P2269, DOI 10.1109/TIP.2011.2170081
   Gao Y, 2011, IEEE T MULTIMEDIA, V13, P1007, DOI 10.1109/TMM.2011.2160619
   Gao Y, 2010, PATTERN RECOGN, V43, P1142, DOI 10.1016/j.patcog.2009.07.012
   Gökberk B, 2008, IEEE T SYST MAN CY B, V38, P155, DOI 10.1109/TSMCB.2007.908865
   Kakadiaris IA, 2007, IEEE T PATTERN ANAL, V29, P640, DOI 10.1109/TPAMI.2007.1017
   KULLBACK S, 1951, ANN MATH STAT, V22, P79, DOI 10.1214/aoms/1177729694
   Lee SH, 2011, IEEE T CONSUM ELECTR, V57, P1018, DOI 10.1109/TCE.2011.6018850
   Levy BC, 2004, IEEE T INFORM THEORY, V50, P89, DOI 10.1109/TIT.2003.821992
   Li XL, 2012, NEUROCOMPUTING, V82, P99, DOI 10.1016/j.neucom.2011.10.029
   Marras I, 2012, LECT NOTES COMPUT SC, V7584, P230, DOI 10.1007/978-3-642-33868-7_23
   Matikainen P., 2010, P EUR C COMP VIS, P1
   Mian AS, 2007, IEEE T PATTERN ANAL, V29, P1927, DOI 10.1109/TPAMI.2007.1105
   Ming Y, 2013, SPEECH COMMUN, V55, P71, DOI 10.1016/j.specom.2012.06.007
   Ming Y, 2012, IMAGE VISION COMPUT, V30, P524, DOI 10.1016/j.imavis.2012.05.001
   Ocegueda O, 2011, PROC CVPR IEEE, P641, DOI 10.1109/CVPR.2011.5995613
   Passalis G, 2011, IEEE T PATTERN ANAL, V33, P1938, DOI 10.1109/TPAMI.2011.49
   Peng HC, 2005, IEEE T PATTERN ANAL, V27, P1226, DOI 10.1109/TPAMI.2005.159
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Queirolo CC, 2010, IEEE T PATTERN ANAL, V32, P206, DOI 10.1109/TPAMI.2009.14
   Seshadri K., 2009, IEEE 3rd International Conference on Bio- metrics: Theory, Applications and System, P1
   Wang J, 2007, COMPUT VIS IMAGE UND, V108, P19, DOI 10.1016/j.cviu.2006.10.011
   Wang YM, 2010, IEEE T PATTERN ANAL, V32, P1858, DOI 10.1109/TPAMI.2009.200
   Xu C., 2009, AUTOMATIC 3D FACE RE
   Yang Y., 2011, P 22 INT JOINT C ART, P1589
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
NR 33
TC 36
Z9 38
U1 2
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2015
VL 35
BP 14
EP 22
DI 10.1016/j.imavis.2014.12.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CE4JD
UT WOS:000351796000002
DA 2024-07-18
ER

PT J
AU Aloimonos, Y
   Fermüller, C
AF Aloimonos, Yiannis
   Fermueller, Cornelia
TI The Cognitive Dialogue: A new model for vision implementing common sense
   reasoning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Vision and language; Integration of perception, action, and cognition;
   Cognition modulating image processing
AB We propose a new model for vision, where vision is part of an intelligent system that reasons. To achieve this we need to integrate perceptual processing with computational reasoning and linguistics. In this paper we present the basics of this formalism. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Aloimonos, Yiannis; Fermueller, Cornelia] Univ Maryland, Inst Adv Comp Studies, Comp Vis Lab, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Aloimonos, Y (corresponding author), Univ Maryland, Inst Adv Comp Studies, Comp Vis Lab, College Pk, MD 20742 USA.
EM yiannis@cs.umd.edu; fer@cfar.umd.edu
RI Aloimonos, Yiannis/AAI-2969-2020
OI Aloimonos, Yiannis/0000-0002-8152-4281
FU European Union [ICT-288382]; National Science Foundation [SMA-1248056];
   Direct For Social, Behav & Economic Scie; SBE Off Of Multidisciplinary
   Activities [1248056] Funding Source: National Science Foundation
FX The support of the European Union under the Cognitive Systems program
   (project POETICON++, ICT-288382) and the National Science Foundation
   under an INSPIRE grant in the Science of Learning Activities program,
   (grant SMA-1248056) is gratefully acknowledged.
CR Cruse Dvaid A, 1986, LEXICAL SEMANTICS
   Farhadi A, 2010, LECT NOTES COMPUT SC, V6314, P15, DOI 10.1007/978-3-642-15561-1_2
   Fire A., 2013, ANN M COGN SCI SOC C
   Forsyth D., 2009, WORDS PICTURES CATEG
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Miller GA, 2007, LANG RESOUR EVAL, V41, P209, DOI 10.1007/s10579-007-9044-6
   Pastra K., 2011, P AAAI INT WORKSH LA
   Pastra K, 2012, PHILOS T R SOC B, V367, P103, DOI 10.1098/rstb.2011.0123
   Summers-Stay D, 2012, IEEE INT C INT ROBOT, P4104, DOI 10.1109/IROS.2012.6385483
   Teo CL, 2012, IEEE INT CONF ROBOT, P374, DOI 10.1109/ICRA.2012.6224589
   Verschure PFMJ, 2012, BIOL INSPIR COGN ARC, V1, P55, DOI 10.1016/j.bica.2012.04.005
   Yang Y., 2014, Adv. Cognit. Syst, V3, P67
   Yu X., P INT C COMP VIS 201
NR 13
TC 5
Z9 5
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2015
VL 34
BP 42
EP 44
DI 10.1016/j.imavis.2014.10.010
PG 3
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA5OB
UT WOS:000348956600004
DA 2024-07-18
ER

PT J
AU Kenk, VS
   Mandeljc, R
   Kovacic, S
   Kristan, M
   Hajdinjak, M
   Pers, J
AF Kenk, Vildana Sulic
   Mandeljc, Rok
   Kovacic, Stanislav
   Kristan, Matej
   Hajdinjak, Melita
   Pers, Janez
TI Visual re-identification across large, distributed camera networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Re-identification; Distributed sensors; Smart cameras; Visual-sensor
   networks; Surveillance
ID NOVELTY DETECTION; VIDEO SURVEILLANCE; RECOGNITION
AB We propose a holistic approach to the problem of re-identification in an environment of distributed smart cameras. We model the re-identification process in a distributed camera network as a distributed multi-class classifier, composed of spatially distributed binary classifiers. We treat the problem of re-identification as an open-world problem, and address novelty detection and forgetting. As there are many tradeoffs in design and operation of such a system, we propose a set of evaluation measures to be used in addition to the recognition performance. The proposed concept is illustrated and evaluated on a new many-camera surveillance dataset and SAIVT-SoftBio dataset. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Kenk, Vildana Sulic; Mandeljc, Rok; Kovacic, Stanislav; Kristan, Matej; Pers, Janez] Univ Ljubljana, Fac Elect Engn, Machine Vis Lab, SI-1000 Ljubljana, Slovenia.
   [Hajdinjak, Melita] Univ Ljubljana, Fac Elect Engn, Lab Appl Math, SI-1000 Ljubljana, Slovenia.
C3 University of Ljubljana; University of Ljubljana
RP Kenk, VS (corresponding author), Univ Ljubljana, Fac Elect Engn, Machine Vis Lab, Trzaska 25, SI-1000 Ljubljana, Slovenia.
EM vildana.sulic@fe.uni-lj.si
FU Slovenian Research Agency [P2-0095, P2-0098, J2-4284, 1000-10-310118]
FX This work was supported by research programs P2-0095 and P2-0098,
   research project J2-4284 and the research grant 1000-10-310118, all by
   the Slovenian Research Agency. We would like to thank the SAIVT Research
   Labs at Queensland University of Technology (QUT) for freely supplying
   us with the SAIVT-SoftBio database for our research.
CR Andriluka M., 2008, IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)
   Angelov P, 2011, INT J INTELL SYST, V26, P189, DOI 10.1002/int.20462
   [Anonymous], ICCV 09 WS VIS SURV
   [Anonymous], 2011, ACM WORKSH HUM GEST
   [Anonymous], TECHNICAL REPORT
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 9 IEEE INT C ADV VID
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], P INT C IM AN PROC I
   [Anonymous], FDN STAT NATURAL LAN
   [Anonymous], 2012, DICTA
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P1, DOI 10.1109/AVSS.2010.68
   Bak Slawomir, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P435, DOI 10.1109/AVSS.2010.34
   Bak S, 2012, IMAGE VISION COMPUT, V30, P443, DOI 10.1016/j.imavis.2011.08.008
   Bauml M., 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P291, DOI 10.1109/AVSS.2011.6027339
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Chu Chun-Te., 2011, Proceedings of ACM/IEEE International Conference on Distributed Smart Cameras ICDSC, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Oliveira IO, 2009, EIGHTH IEEE INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING, PROCEEDINGS, P461, DOI 10.1109/DASC.2009.33
   Diehl CP, 2002, IEEE IJCNN, P2620, DOI 10.1109/IJCNN.2002.1007557
   Doretto G, 2011, J AMB INTEL HUM COMP, V2, P127, DOI 10.1007/s12652-010-0034-y
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hamdoun F., 2008, P IEEE C DISTRIBUTED, P1
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Javed O, 2005, PROC CVPR IEEE, P26
   Jelaca V, 2013, IMAGE VISION COMPUT, V31, P673, DOI 10.1016/j.imavis.2013.06.007
   Jungling Kai., 2011, COMPUTER VISION PATT, P55, DOI 10.1109/CVPRW.2011.5981771
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Lin Z, 2008, LECT NOTES COMPUT SC, V5358, P23, DOI 10.1007/978-3-540-89639-5_3
   Liu X, 2012, PATTERN RECOGN, V45, P4204, DOI 10.1016/j.patcog.2012.05.019
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Loy CC, 2009, PROC CVPR IEEE, P1988, DOI 10.1109/CVPRW.2009.5206827
   Markou M, 2003, SIGNAL PROCESS, V83, P2481, DOI 10.1016/j.sigpro.2003.07.018
   Martin N.J., 2012, Decreases in Psychological Well-Being Among American Adolescents, P1
   Murovec B, 2013, J SYST ARCHITECT, V59, P847, DOI 10.1016/j.sysarc.2013.05.010
   Owens J, 2002, LECT NOTES COMPUT SC, V2415, P1249
   Park U, 2006, INT C PATT RECOG, P1204
   Prosser B., 2008, British Machine Vision Conf., Leeds, P1
   Sadeghi-Tehran P., 2012, Proceedings 2012 IEEE Conference on Evolving and Adaptive Intelligent Systems (EAIS 2012), P108, DOI 10.1109/EAIS.2012.6232814
   Siebler Clemens., 2010, INT C DISTRIBUTED SM, P199
   Sulic V, 2011, IEEE T CIRC SYST VID, V21, P903, DOI 10.1109/TCSVT.2011.2133330
   Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Valera M, 2005, IEE P-VIS IMAGE SIGN, V152, P192, DOI 10.1049/ip-vis:20041147
   Vezzani R, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2543581.2543596
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Yong SP, 2012, PATTERN RECOGN, V45, P3439, DOI 10.1016/j.patcog.2012.02.036
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 52
TC 15
Z9 15
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2015
VL 34
BP 11
EP 26
DI 10.1016/j.imavis.2014.11.002
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA5OB
UT WOS:000348956600002
DA 2024-07-18
ER

PT J
AU Shoaib, M
   Yang, MY
   Rosenhahn, B
   Ostermann, J
AF Shoaib, Muhammad
   Yang, Michael Ying
   Rosenhahn, Bodo
   Ostermann, Joern
TI Estimating layout of cluttered indoor scenes using trajectory-based
   priors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Scene segmentation; Trajectory; Scene layout; Semantic context;
   Conditional random field
ID LATENT-VARIABLES; LINES
AB Given a surveillance video of a moving person, we present a novel method of estimating layout of a cluttered indoor scene. We propose an idea that trajectories of a moving person can be used to generate features to segment an indoor scene into different areas of interest. We assume a static uncalibrated camera. Using pixel-level color and perspective cues of the scene, each pixel is assigned to a particular class either a sitting place, the ground floor, or the static background areas like walls and ceiling. The pixel-level cues are locally integrated along global topological order of classes, such as sitting objects and background areas are above ground floor into a conditional random field by an ordering constraint. The proposed method yields very accurate segmentation results on challenging real world scenes. We focus on videos with people walking in the scene and show the effectiveness of our approach through quantitative and qualitative results. The proposed estimation method shows better estimation results as compared to the state of the art scene layout estimation methods. We are able to correctly segment 90.3% of background, 89.4% of sitting areas and 74.7% of the ground floor. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Shoaib, Muhammad; Yang, Michael Ying; Rosenhahn, Bodo; Ostermann, Joern] Leibniz Univ Hannover, Inst Informat Proc TNT, D-30167 Hannover, Germany.
C3 Leibniz University Hannover
RP Shoaib, M (corresponding author), Leibniz Univ Hannover, Inst Informat Proc TNT, Appelstr 9A, D-30167 Hannover, Germany.
EM shoaib@tnt.uni-hannover.de
RI Yang, Michael Ying/AAC-6698-2019
OI Yang, Michael Ying/0000-0002-0649-9987
CR Aksoy EE, 2011, INT J ROBOT RES, V30, P1229, DOI 10.1177/0278364911410459
   [Anonymous], P ROB SCI SYST SYDN
   [Anonymous], 2012, P EUR C COMP VIS ECC
   [Anonymous], CVPR
   [Anonymous], 2010, NIPS
   [Anonymous], 2012, ECCV
   [Anonymous], CVPR
   [Anonymous], 2011, P ADV NEURAL INFORM
   Barth A., 2010, PROBABILISTIC MULTI
   Criminisia A., 1999, P SPIE INT SOC OPTIC, V3576
   Debard Glen, 2012, Outdoor and Large-Scale Real-World Scene Analysis. 15th International Workshop on Theoretical Foundations of Computer Vision. Revised Selected Papers, P356, DOI 10.1007/978-3-642-34091-8_16
   Delong A, 2012, INT J COMPUT VISION, V96, P1, DOI 10.1007/s11263-011-0437-z
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Edgcomb A., 2012, TECHNICAL REPORT
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gould S, 2008, INT J COMPUT VISION, V80, P300, DOI 10.1007/s11263-008-0140-x
   Grabner H, 2011, PROC CVPR IEEE, P1529, DOI 10.1109/CVPR.2011.5995327
   Grompone von Gioi R., 2012, IMAGE PROCESSING LIN
   Gupta Abhinav, 2011, P COMP VIS PATT REC
   Hedau V, 2010, LECT NOTES COMPUT SC, V6316, P224, DOI 10.1007/978-3-642-15567-3_17
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Hu WM, 2004, IEEE T NEURAL NETWOR, V15, P135, DOI 10.1109/TNN.2003.820668
   Jiang Y., 2012, Learning Object Arrangements in 3D Scenes using Human Context
   Junejo I., 2006, VID SIGN BAS SURV 20, P92
   Lafferty J., 2001, ICML 01 P 18 INT C M
   Lee D., 2009, COMPUTER VISION PATT
   Matas J, 2000, COMPUT VIS IMAGE UND, V78, P119, DOI 10.1006/cviu.1999.0831
   McKenna SJ, 2005, PATTERN ANAL APPL, V7, P386, DOI 10.1007/s10044-004-0233-2
   Oriolo G, 1998, IEEE T SYST MAN CY B, V28, P316, DOI 10.1109/3477.678626
   Pero L.D., 2011, CVPR
   Qian C, 2008, IEEE SYS MAN CYBERN, P931
   Rusu R.B., 2009, THESIS TECHNISCHE U
   Saleemi I, 2010, PROC CVPR IEEE, P2069, DOI 10.1109/CVPR.2010.5539884
   Schuster M. J., 2010, 2010 10th IEEE-RAS International Conference on Humanoid Robots (Humanoids 2010), P152, DOI 10.1109/ICHR.2010.5686328
   Schwing A. G., 2012, P EUR C COMP VIS ECC
   Shoaib M, 2009, ICASSP INT C AC SPEE
   Shoaib M., 2010, 4 INT ICST C PERV CO
   Shoaib M., 2012, IEEE INT S CIRC SYST
   Shoaib M, 2011, EURASIP J ADV SIG PR, P1, DOI 10.1186/1687-6180-2011-129
   Shoaib Muhammad, 2010, 4 PAC RIM S IM VID T
   Thrun S, 2004, IEEE T ROBOTIC AUTOM, V20, P433, DOI 10.1109/TRA.2004.825520
   Tsai G, 2011, IEEE I CONF COMP VIS, P121, DOI 10.1109/ICCV.2011.6126233
   Wang HY, 2013, COMMUN ACM, V56, P92, DOI [10.1145/2436258.2436276, 10.1145/2436256.2436276]
   Wang HY, 2010, LECT NOTES COMPUT SC, V6314, P497
   Wu C, 2011, IEEE T SYST MAN CY A, V41, P375, DOI 10.1109/TSMCA.2010.2073701
   Xu K, 2002, PROC GRAPH INTERF, P25
   Yang YZ, 2013, PROC CVPR IEEE, P2563, DOI 10.1109/CVPR.2013.331
   Zhang T., 2011, NEURAL INFORM PROCES, P244
NR 49
TC 1
Z9 1
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 870
EP 883
DI 10.1016/j.imavis.2014.07.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900005
DA 2024-07-18
ER

PT J
AU McDuff, D
   El Kaliouby, R
   Senechal, T
   Demirdjian, D
   Picard, R
AF McDuff, Daniel
   El Kaliouby, Rana
   Senechal, Thibaud
   Demirdjian, David
   Picard, Rosalind
TI Automatic measurement of ad preferences from facial responses gathered
   over the Internet
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expressions; Preferences; Classification; Crowdsourcing
ID COMMERCIALS
AB We present an automated method for classifying "liking" and "desire to view again" of online video ads based on 3268 facial responses to media collected over the Internet. The results demonstrate the possibility for an ecologically valid, unobtrusive, evaluation of commercial "liking" and "desire to view again", strong predictors of marketing success, based only on facial responses. The area under the curve for the best "liking" classifier was 0.82 when using a challenging leave-one-commercial-out testing regime (accuracy = 81%). We build on preliminary findings and show that improved smile detection can lead to a reduction in misclassifications. Comparison of the two smile detection algorithms showed that improved smile detection helps correctly classify responses recorded in challenging lighting conditions and those in which the expressions were subtle. Temporal discriminative approaches to classification performed most strongly showing that temporal information about an individual's response is important; it is not just how much a viewer smiles but when they smile. The technique could be employed in personalizing video content that is presented to people while they view videos over the Internet or in copy testing of ads to unobtrusively quantify ad effectiveness. (C) 2014 Elsevier B.V. All rights reserved.
C1 [McDuff, Daniel; Picard, Rosalind] MIT, Media Lab, Cambridge, MA 02139 USA.
   [El Kaliouby, Rana; Senechal, Thibaud] Affectiva, Waltham, MA 02452 USA.
   [Demirdjian, David] MIT, CSAIL, Cambridge, MA 02139 USA.
C3 Massachusetts Institute of Technology (MIT); Massachusetts Institute of
   Technology (MIT)
RP McDuff, D (corresponding author), MIT, Media Lab, Cambridge, MA 02139 USA.
EM djmcduff@media.mit.edu; kaliouby@affectiva.com;
   thibaud.senechal@affectiva.com; demirdji@csail.mit.edu;
   picard@media.mit.edu
FU Media Lab Consortium Members
FX Richard Sadowsky, Oliver Wilder-Smith, Jay Turcot, Zhihong Zeng and
   Affectiva provided generous support in providing access to the
   crowdsourcing platform. Brian Staats provided a great front end design
   for the site. Jon Bruner and Forbes kindly promoted the work on their
   site. Google provided use of their facial feature tracker. This work was
   funded by the Media Lab Consortium Members.
CR Ambadar Z, 2009, J NONVERBAL BEHAV, V33, P17, DOI 10.1007/s10919-008-0059-5
   [Anonymous], 2011, P 13 INT C MULT INT
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], AUT FAC GEST REC 201
   Bolls PD, 2001, COMMUN RES, V28, P627, DOI 10.1177/009365001028005003
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   HALEY RI, 1991, J ADVERTISING RES, V31, P11
   Hazlett RL, 1999, J ADVERTISING RES, V39, P7
   Hoque ME, 2012, IEEE T AFFECT COMPUT, V3, P323, DOI 10.1109/T-AFFC.2012.11
   Joho H., 2011, MULTIMED TOOLS APPL, P1
   Kassam K.S., 2010, THESIS HARVARD U
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lucey P., 2010, Proceedings 2010 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2010), P255, DOI 10.1109/DICTA.2010.53
   McDuff D., 2010, Computer Vision and Pattern Recognition Workshops (CVPRW), P17, DOI [DOI 10.1109/CVPRW.2010.5543833, 10.1109/CVPRW.2010.5543833]
   McDuff D., 2013, COMP VIS PATT REC WO
   McDuff D, 2012, IEEE T AFFECT COMPUT, V3, P456, DOI 10.1109/T-AFFC.2012.19
   Micu AC, 2010, J ADVERTISING RES, V50, P137, DOI 10.2501/S0021849910091300
   Morency L.P., 2007, Proc. Computer Vision and Pattern Recognition, P1, DOI DOI 10.1109/CVPR.2007.383299
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Shan CF, 2012, IEEE T IMAGE PROCESS, V21, P431, DOI 10.1109/TIP.2011.2161587
   Smit EG, 2006, J ADVERTISING RES, V46, P73, DOI 10.2501/S0021849906060089
   Song Y., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P388, DOI 10.1109/FG.2011.5771431
   Teixeira T., 2010, J MARK RES
   Teixeira TS, 2010, MARKET SCI, V29, P783, DOI 10.1287/mksc.1100.0567
   Valstar MF, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P38
   Wang S.B., 2006, P IEEE COMP SOC C CO
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhao S., 2013, NEUROCOMPUTING
NR 30
TC 37
Z9 39
U1 3
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 630
EP 640
DI 10.1016/j.imavis.2014.01.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700002
DA 2024-07-18
ER

PT J
AU Bellavia, F
   Tegolo, D
   Valenti, C
AF Bellavia, F.
   Tegolo, D.
   Valenti, C.
TI Keypoint descriptor matching with context-based orientation estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image descriptors; Local features; Dominant orientation; Rotation
   invariance; Keypoint matching; SIFT; LIOP; MROGH
ID REPRESENTATION; DETECTORS; FEATURES
AB This paper presents a matching strategy to improve the discriminative power of histogram-based keypoint descriptors by constraining the range of allowable dominant orientations according to the context of the scene under observation. This can be done when the descriptor uses a circular grid and quantized orientation steps, by computing or providing a global reference orientation based on the feature matches.
   The proposed matching strategy is compared with the standard approaches used with the SIFT and GLOH descriptors and the recent rotation invariant MROGH and LIOP descriptors. A new evaluation protocol based on an approximated overlap error is presented to provide an effective analysis in the case of non-planar scenes, thus extending the current state-of-the-art results. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Bellavia, F.] Univ Florence, CVG, I-50139 Florence, Italy.
   [Tegolo, D.; Valenti, C.] Univ Palermo, DMI, I-90123 Palermo, Italy.
C3 University of Florence; University of Palermo
RP Bellavia, F (corresponding author), Univ Florence, CVG, I-50139 Florence, Italy.
EM fabio.bellavia@unifi.it; domenico.tegolo@unipa.it;
   cesare.valenti@unipa.it
RI Valenti, Cesare/V-2021-2019; Bellavia, Fabio/N-6790-2018
OI Bellavia, Fabio/0000-0002-1688-8476; VALENTI, Cesare
   Fabio/0000-0002-4961-2054; Tegolo, Domenico/0000-0001-5417-5584
FU University of Palermo FFR [B71J12001380001]
FX This work was supported partially by grant B71J12001380001, University
   of Palermo FFR 2012/2013.
CR [Anonymous], P BRIT MACH VIS C 20
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Bellavia F, 2011, IET COMPUT VIS, V5, P87, DOI 10.1049/iet-cvi.2009.0127
   Bellavia Fabio, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3460, DOI 10.1109/ICPR.2010.845
   Bellavia F, 2013, LECT NOTES COMPUT SC, V8156, P270
   Bellavia F, 2011, LECT NOTES COMPUT SC, V6978, P524, DOI 10.1007/978-3-642-24085-0_54
   Brown M, 2005, PROC CVPR IEEE, P510
   Brown M, 2011, IEEE T PATTERN ANAL, V33, P43, DOI 10.1109/TPAMI.2010.54
   Fan B, 2012, IEEE T PATTERN ANAL, V34, P2031, DOI 10.1109/TPAMI.2011.277
   Forssén PE, 2007, IEEE I CONF COMP VIS, P1530
   Fraundorfer F., 2005, Proceedings of computer vision and pattern recognition-CVPR workshops, P33
   Gauglitz S, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.93
   Gil A, 2010, MACH VISION APPL, V21, P905, DOI 10.1007/s00138-009-0195-x
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Ke Y, 2004, PROC CVPR IEEE, P506
   Lakemond R, 2013, IMAGE VISION COMPUT, V31, P921, DOI 10.1016/j.imavis.2013.09.002
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K., 2007, Affine Covariant Features
   Miksik O, 2012, INT C PATT RECOG, P2681
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Rubner Y., 1998, The Earth Mover's Distance as a metric for image retrieval
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Strecha C, 2008, PROC CVPR IEEE, P2838
   Takacs G, 2010, PROC CVPR IEEE, P934, DOI 10.1109/CVPR.2010.5540116
   Ullah F, 2004, PATTERN RECOGN, V37, P201, DOI 10.1016/S0031-3203(03)00184-5
   Wang ZH, 2011, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2011.6126294
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
NR 34
TC 23
Z9 26
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2014
VL 32
IS 9
BP 559
EP 567
DI 10.1016/j.imavis.2014.05.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AO6QY
UT WOS:000341477800001
DA 2024-07-18
ER

PT J
AU Lu, F
   Okabe, T
   Sugano, Y
   Sato, Y
AF Lu, Feng
   Okabe, Takahiro
   Sugano, Yusuke
   Sato, Yoichi
TI Learning gaze biases with head motion for head pose-free gaze estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gaze estimation; Free head motion; Head pose compensation;
   Appearance-based approach
ID TRACKING TECHNIQUES
AB When estimating human gaze directions from captured eye appearances, most existing methods assume a fixed head pose because head motion changes eye appearance greatly and makes the estimation inaccurate. To handle this difficult problem, in this paper, we propose a novel method that performs accurate gaze estimation without restricting the user's head motion. The key idea is to decompose the original free-head motion problem into subproblems, including an initial fixed head pose problem and subsequent compensations to correct the initial estimation biases. For the initial estimation, automatic image rectification and joint alignment with gaze estimation are introduced. Then compensations are done by either learning-based regression or geometric-based calculation. The merit of using such a compensation strategy is that the training requirement to allow head motion is not significantly increased; only capturing a 5-s video clip is required. Experiments are conducted, and the results show that our method achieves an average accuracy of around 30 by using only a single camera (C) 2014 Elsevier B.V. All rights reserved.
C1 [Lu, Feng; Sugano, Yusuke; Sato, Yoichi] Univ Tokyo, Tokyo 1538505, Japan.
   [Okabe, Takahiro] Kyushu Inst Technol, Kitakyushu, Fukuoka, Japan.
C3 University of Tokyo; Kyushu Institute of Technology
RP Lu, F (corresponding author), Univ Tokyo, Inst Ind Sci, Sato Lab, Meguro Ku, 4-6-1 Komaba, Tokyo 1538505, Japan.
EM lufeng@iis.u-tokyo.ac.jp
RI Sugano, Yusuke/X-3689-2019
OI Sugano, Yusuke/0000-0003-4206-710X
CR Asteriadis S., 2009, P INT WORKSH AFF AW
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Beymer D, 2003, PROC CVPR IEEE, P451
   Brolly X.L. C., 2004, Proc. of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW'04), V8, P134, DOI DOI 10.1109/CVPR.2004.92
   Chen JX, 2011, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.2011.5995675
   Guestrin ED, 2006, IEEE T BIO-MED ENG, V53, P1124, DOI 10.1109/TBME.2005.863952
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Heyman T., P 2 INT C POS CONT A
   Kang JJ, 2008, IEEE T BIO-MED ENG, V55, P2293, DOI 10.1109/TBME.2008.919722
   Li-Qun Xu, 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P428
   Lu F., ICPR2012
   Lu F., 2011, P 13 IEEE INT C COMP
   Morimoto CH, 2005, COMPUT VIS IMAGE UND, V98, P4, DOI 10.1016/j.cviu.2004.07.010
   Nagamatsu T, 2008, 2008 17TH IEEE INTERNATIONAL SYMPOSIUM ON ROBOT AND HUMAN INTERACTIVE COMMUNICATION, VOLS 1 AND 2, P59, DOI 10.1109/ROMAN.2008.4600643
   Nakazawa A, 2012, LECT NOTES COMPUT SC, V7573, P159, DOI 10.1007/978-3-642-33709-3_12
   Nguyen B.L., 2010, Proceedings of the 2010 Symposium on Information and Communication Technology, New York, NY, USA, P108, DOI DOI 10.1145/1852611.1852632
   Pomerleau D, 1994, Advances Neural Information Processing Systems, P753
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Sugano Y, 2008, LECT NOTES COMPUT SC, V5304, P656, DOI 10.1007/978-3-540-88690-7_49
   Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984
   Tan KH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P191, DOI 10.1109/ACV.2002.1182180
   Underwood G, 2005, COGNITIVE PROCESSES
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Valenti Roberto., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Villanueva A, 2008, IEEE T SYST MAN CY B, V38, P1123, DOI 10.1109/TSMCB.2008.926606
   Wang JG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P136
   Williams O., 2006, P IEEE C CVPR, V1, P230, DOI DOI 10.1109/CVPR.2006.285
   Yamazoe H, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P245, DOI 10.1145/1344471.1344527
   Yoo DH, 2005, COMPUT VIS IMAGE UND, V98, P25, DOI 10.1016/j.cviu.2004.07.011
   YOUNG LR, 1975, BEHAV RES METH INSTR, V7, P397, DOI 10.3758/BF03201553
   Zhu ZW, 2007, IEEE T BIO-MED ENG, V54, P2246, DOI 10.1109/TBME.2007.895750
NR 31
TC 58
Z9 61
U1 2
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2014
VL 32
IS 3
BP 169
EP 179
DI 10.1016/j.imavis.2014.01.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AE3CG
UT WOS:000333854000001
DA 2024-07-18
ER

PT J
AU Bova, N
   Ibáñez, O
   Cordón, O
AF Bova, Nicola
   Ibanez, Oscar
   Cordon, Oscar
TI Extended Topological Active Nets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deformable models; Active contours; Snakes; Level sets; Chan and Vese;
   Geodesic Active Contours; Active nets; Topological Active Nets; Extended
   Topological Active Nets; Local search optimization; Extemal force;
   Gradient Vector Flow; Vector Field Convolution
ID OPTIMIZATION; IMAGES; SNAKES
AB Topological Active Nets are promising parametric deformable models that integrate features of region-based and boundary-based segmentation techniques. Problems associated with the complexity of the model, however, have limited their utility. This paper introduces an extension of the model, defining a new behavior for changing its topology, as well as a novel external force definition and a new local search optimization procedure. In particular, we propose a new automatic pre-processing phase, a new external energy term based on the Extended Vector Field Convolution, node movement constraints to avoid crossing links, and different procedures to perform link cuts and hole detection. Moreover, the new local search procedure also incorporates heuristics to correct the position of eventually misplaced nodes. The proposal has been tested on 18 synthetic images which present different segmentation difficulties along with 3 real medical images. Its performance has been compared with that of the original Topological Active Net optimization approach along with both state-of-the-art parametric and geometric active contours: two snakes (based on Gradient Vector Flow and Vector Field Convolution), and two level sets (Chan and Vese, and Geodesic Active Contour). Our new method outperforms all the others for the given image sets, in terms of segmentation accuracy measured by using four standard segmentation metrics. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Bova, Nicola; Ibanez, Oscar; Cordon, Oscar] European Ctr Soft Comp, Mieres 33600, Asturias, Spain.
   [Cordon, Oscar] Univ Granada, Dept Comp Sci & Artificial Intelligence DECSAI, E-18071 Granada, Spain.
   [Cordon, Oscar] Univ Granada, Res Ctr Informat & Commun Technol CITIC UGR, E-18071 Granada, Spain.
C3 University of Granada; University of Granada
RP Bova, N (corresponding author), European Ctr Soft Comp, Mieres 33600, Asturias, Spain.
EM nicola.bova@gmail.com; oscar.ibanez@softcomputing.es;
   oscar.cordon@softcomputing.es
RI Cordon Garcia, Oscar/F-6672-2011; Ibanez, Oscar/B-2680-2015
OI Cordon Garcia, Oscar/0000-0001-5112-5629; Ibanez,
   Oscar/0000-0002-5301-8277
FU European Commission [238819]; Spanish Ministerio de Economia y
   Competitividad under the SOCOVIFI2 project [TIN2012-38525-001/CO2];
   Andalusian Department of Innovacion, Ciencia y Empresa [TIC-7745];
   Supercomputing Center of Galicia (CESGA), Spain
FX This work has been supported by the European Commission with the
   contract no. 238819 (MIBISOC Marie Curie ITN), the Spanish Ministerio de
   Economia y Competitividad under the SOCOVIFI2 project (references
   TIN2012-38525-001/CO2 http://www.softcomputing.es/ socovifi/), the
   Andalusian Department of Innovacion, Ciencia y Empresa (reference
   TIC-7745), including EDRF funding.; Part of the experiments related to
   this work was supported by the computing resources at the Supercomputing
   Center of Galicia (CESGA), Spain.
CR [Anonymous], PATTERN RECOGN IMAGE
   [Anonymous], OFELI OPEN FAST EFFI
   Barreira N, 2005, EURASIP J APPL SIG P, V2005, P1939, DOI 10.1155/ASP.2005.1939
   Barreira N, 2010, PATTERN RECOGN, V43, P255, DOI 10.1016/j.patcog.2009.06.005
   Bro-Nielsen M., 1994, ACTIVE NETS CUBES IM
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Courant R., 1953, Methods of mathematical physics, V1
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   He L, 2008, IMAGE VISION COMPUT, V26, P141, DOI 10.1016/j.imavis.2007.07.010
   HUTTENLOCHER DP, 1993, IEEE T PATTERN ANAL, V15, P850, DOI 10.1109/34.232073
   Ibáñez O, 2009, PATTERN RECOGN, V42, P907, DOI 10.1016/j.patcog.2008.09.005
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   Lee TH, 2008, I C COMP GRAPH IM VI, P339, DOI 10.1109/CGIV.2008.17
   Li B, 2007, IEEE T IMAGE PROCESS, V16, P2096, DOI 10.1109/TIP.2007.899601
   MacQueen J., 1967, P 5 BERK S MATH STAT, P281
   McInerney T, 1996, Med Image Anal, V1, P91, DOI 10.1016/S1361-8415(96)80007-7
   McInerney T, 1999, IEEE T MED IMAGING, V18, P840, DOI 10.1109/42.811261
   Novo J, 2012, EXPERT SYST APPL, V39, P12165, DOI 10.1016/j.eswa.2012.04.087
   Novo J, 2010, PATTERN RECOGN LETT, V31, P1781, DOI 10.1016/j.patrec.2010.01.027
   Novo J, 2009, IMAGE VISION COMPUT, V27, P1572, DOI 10.1016/j.imavis.2009.02.011
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009
   Radulescu T., 2009, 2009 9 INT C INF TEC, P1
   Sakaue K, 1996, SYST COMPUT JPN, V27, P40, DOI 10.1002/scj.4690270104
   Shi Y, 2008, IEEE T IMAGE PROCESS, V17, P645, DOI 10.1109/TIP.2008.920737
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yabuki N, 1999, ISCAS '99: PROCEEDINGS OF THE 1999 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 4, P98, DOI 10.1109/ISCAS.1999.779951
   YAMAMOTO K, 1995, IMAGE VISION COMPUT, V13, P335, DOI 10.1016/0262-8856(95)99720-L
   ZIJDENBOS AP, 1994, IEEE T MED IMAGING, V13, P716, DOI 10.1109/42.363096
NR 33
TC 4
Z9 5
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2013
VL 31
IS 12
BP 905
EP 920
DI 10.1016/j.imavis.2013.09.004
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 282DU
UT WOS:000329151300002
DA 2024-07-18
ER

PT J
AU Gong, XJ
   Liu, JY
   Zhou, WH
   Liu, JL
AF Gong, Xiaojin
   Liu, Junyi
   Zhou, Wenhui
   Liu, Jilin
TI Guided depth enhancement via a fast marching method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth enhancement; Image inpainting; Fast marching method
AB Range imaging sensors such as Kinect and time-of-flight cameras can produce aligned depth and color images in real time. However, the depth maps captured by such sensors contain numerous invalid regions and suffer from heavy noise. These defects more or less influence the use of depth information in practical applications. In order to enhance the depth maps, this paper proposes a new inpainting approach based on the fast marching method (FMM). We extend the inpainting model and the propagation strategy of FMM to incorporate color information for depth inpainting. An edge-preserving guided filter is further applied for noise reduction. To validate our algorithm, we perform experiments on both Kinect data and Middlebury dataset which, respectively, provide qualitative and quantitative results. Meanwhile, we also compare it to the original FMM and other two state-of-the-art depth enhancement methods. Experimental results show that our method performs better than the local methods in terms of both visual and metric qualities, and it achieves visually comparable results to the time-consuming global method. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Gong, Xiaojin; Liu, Junyi; Liu, Jilin] Zhejiang Univ, Dept Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
   [Zhou, Wenhui] Hangzhou Dianzi Univ, Sch Comp Sci & Technol, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Zhejiang University; Hangzhou Dianzi University
RP Gong, XJ (corresponding author), Zhejiang Univ, Dept Informat Sci & Elect Engn, Hangzhou 310027, Zhejiang, Peoples R China.
EM gongxj@zju.edu.cn; shshzaa@zju.edu.cn; zhouwenhui@hdu.edu.cn;
   liujl@zju.edu.cn
RI LIU, JIALIN/JXN-8034-2024; Zhou, Wenhui/AAL-8470-2021
OI Zhou, Wenhui/0000-0003-2216-8878
FU National Natural Science Foundation of China [61001171, 60534070,
   90820306]; Chinese Universities Scientific Fund
FX This research work is partially supported by the National Natural
   Science Foundation of China via grants 61001171, 60534070, and 90820306,
   and the Chinese Universities Scientific Fund.
CR Arias P, 2011, INT J COMPUT VISION, V93, P319, DOI 10.1007/s11263-010-0418-7
   Bryan E., VELOCITY ESTIMATION
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Daribo I., 2010, IEEE MMSP SAINT MALO
   Diebel J., 2005, NEURAL INFORM PROCES
   Dolson J, 2010, PROC CVPR IEEE, P1141, DOI 10.1109/CVPR.2010.5540086
   Freedman B., 2008, WO, Patent No. [2008/ 120217 A2, 2008120217]
   Hansard M., 2012, Time-of-Flight Cameras: Principles, Methods and Applications
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Janoch A., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P1168, DOI 10.1109/ICCVW.2011.6130382
   Kauff P, 2007, SIGNAL PROCESS-IMAGE, V22, P217, DOI 10.1016/j.image.2006.11.013
   Khoshelham K., 2011, ISPRS workshop laser scanning, V38, pW12
   Kim S.-Y., 2010, INT C PATT REC IST T
   Kopf J, 2007, ACM T GRAPHIC, V26, DOI [10.1145/1276377.1276497, 10.1145/1239451.1239547]
   Lazcano V., 2012, INT C IM PROC ORL FL
   Lei J., 2012, ACM INT C UB COMP PE
   Liu J., 2012, INT C PATT REC TSUK
   Lu JB, 2011, INT CONF ACOUST SPEE, P985
   Malladi R, 1996, IEEE T IMAGE PROCESS, V5, P1554, DOI 10.1109/83.541425
   Masnou S, 2002, IEEE T IMAGE PROCESS, V11, P68, DOI 10.1109/83.982815
   Min DB, 2012, IEEE T IMAGE PROCESS, V21, P1176, DOI 10.1109/TIP.2011.2163164
   Newcombe RA, 2011, INT SYM MIX AUGMENT, P127, DOI 10.1109/ISMAR.2011.6092378
   Pal CJ, 2012, INT J COMPUT VISION, V99, P319, DOI 10.1007/s11263-010-0385-z
   Paris S, 2009, INT J COMPUT VISION, V81, P24, DOI 10.1007/s11263-007-0110-8
   Park J, 2011, IEEE I CONF COMP VIS, P1623, DOI 10.1109/ICCV.2011.6126423
   Parker R., KINECT DEPTH INPAINT
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Qi F, 2013, PATTERN RECOGN LETT, V34, P70, DOI 10.1016/j.patrec.2012.06.003
   Ren X., 2012, INT C COMP VIS PATT
   Richardt C., 2012, COHERENT SPATIO TEMP, V31
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI 10.1023/A:1014573219977
   Sethian J., 1999, LEVEL SET METHODS FA
   Sethian JA, 1996, P NATL ACAD SCI USA, V93, P1591, DOI 10.1073/pnas.93.4.1591
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   Wang N., 2012, INT C PATT REC TSUK
   Wasza J., 2011, WORKSH IEEE C COMP V
   Wong U., 2009, INT C FIELD SERV ROB
   Wu HY, 2007, IEEE I CONF COMP VIS, P628, DOI 10.1109/cvpr.2007.383211
   Yin J., 2004, INT C CENTR EUR COMP
   Zhu JJ, 2010, IEEE T PATTERN ANAL, V32, P899, DOI 10.1109/TPAMI.2009.68
NR 42
TC 36
Z9 41
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 695
EP 703
DI 10.1016/j.imavis.2013.07.006
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900001
DA 2024-07-18
ER

PT J
AU Abaza, A
   Bourlai, T
AF Abaza, Ayman
   Bourlai, Thirimachos
TI On ear-based human identification in the mid-wave infrared spectrum
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Thermal infrared imaging; Thermal ear features; Score level fusion and
   multi-biometrics
ID FACE RECOGNITION; EIGENFACES
AB In this paper the problem of human ear recognition in the Mid-wave infrared (MWIR) spectrum is studied in order to illustrate the advantages and limitations of the ear-based biometrics that can operate in day and night time environments. The main contributions of this work are two-fold: First, a dual-band database is assembled that consists of visible (baseline) and mid-wave IR left and right profile face images. Profile face images were collected using a high definition mid-wave IR camera that is capable of acquiring thermal imprints of human skin. Second, a fully automated, thermal imaging based, ear recognition system is proposed that is designed and developed to perform real-time human identification.
   The proposed system tests several feature extraction methods, namely: (i) intensity-based such as independent component analysis (ICA), principal component analysis (PCA), and linear discriminant analysis (LDA); (ii) shape-based such as scale invariant feature transform (SIFT); as well as (iii) texture-based such as local binary patterns (LBP), and local ternary patterns (LTP). Experimental results suggest that LIP (followed by LBP) yields the best performance (Rank1 = 80:68%) on manually segmented ears and (Rank1 = 68:18%) on ear images that are automatically detected and segmented. By fusing the matching scores obtained by LBP and LTP, the identification performance increases by about 5%. Although these results are promising, the outcomes of our study suggest that the design and development of automated ear-based recognition systems that can operate efficiently in the lower part of the passive IR spectrum are very challenging tasks. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Abaza, Ayman] West Virginia High Tech Fdn, Fairmont, WV USA.
   [Bourlai, Thirimachos] W Virginia Univ, Morgantown, WV 26506 USA.
   [Abaza, Ayman] Cairo Univ, Cairo, Egypt.
C3 West Virginia University; Egyptian Knowledge Bank (EKB); Cairo
   University
RP Abaza, A (corresponding author), West Virginia High Tech Fdn, 1000 Technol Dr, Fairmont, WV USA.
EM aabaza@wvhtf.org
OI Bourlai, Thirimachos/0000-0001-8751-0836
FU CITeR [1003702CR]
FX This work was sponsored through CITeR award number 1003702CR to West
   Virginia University. The authors are grateful to FLIR Thermal Imaging
   for proving us a demo MWIR camera to perform our pilot data collection
   and to all faculty and students at West Virginia University for their
   contributions. Special thanks to Mr. Nnamdi Osia for his valuable
   participation and assistance with data collection.
CR Abaza A., 2013, ACM COMPUTE IN PRESS
   Abaza A., 2012, SPIE C DEF SEC SENS
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 1989, FORENSIC IDENTIFICAT
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Berry D., 1970, BR J ORAL SURG, V8, P242
   Bourlai T., 2009, INT C INF TECHN APPL
   Bourlai T., 2011, INT WORKSH INF FOR S
   Bourlai T., 2012, SPIE C DEF SEC SENS
   Bourlai T., 2013, SPIE NEWSROOM MAGAZI
   Ibrahim M., 2011, INT JOINT C BIOM IJC
   Islam S., 2008, IEEE WORKSH APPL COM
   Kumar A, 2012, PATTERN RECOGN, V45, P956, DOI 10.1016/j.patcog.2011.06.005
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Osia N., 2012, IEEE INT C TECHN HOM
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wolff LB, 2005, ADV PTRN RECOGNIT, P167
   Yuan L., 2007, 1 IEEE INT C BIOM TH
NR 22
TC 18
Z9 23
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2013
VL 31
IS 9
BP 640
EP 648
DI 10.1016/j.imavis.2013.06.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220EG
UT WOS:000324564300005
DA 2024-07-18
ER

PT J
AU Shahrian, E
   Rajan, D
AF Shahrian, Ehsan
   Rajan, Deepu
TI Using texture to complement color in image matting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Alpha matting; Texture matte
AB Current image matting methods based on color sampling use color to distinguish between foreground and background pixels. However, they fail when the corresponding color distributions overlap. Other methods that define correlation between neighboring pixels based on color aim to propagate the opacity parameter a from known pixels to unknown pixels. However, strong edges of textured regions may block the propagation of alpha. In this paper, a new matting strategy is proposed that delivers an accurate matte by considering texture as a feature that can complement color even if the foreground and background color distributions overlap and the image is a complex one with highly textured regions. The texture feature is extracted in such a way as to increase distinction between foreground and background regions. An objective function containing color and texture components is optimized to find the best foreground and background pair among a set of candidate pairs. The effectiveness of proposed method is compared quantitatively as well as qualitatively with other matting methods by evaluating their results on a benchmark dataset and a set of complex images. The evaluations show that the proposed method presented the best among state of the art matting methods. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Shahrian, Ehsan; Rajan, Deepu] Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Rajan, D (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore.
EM Ehsa0004@e.ntu.edu.sg; asdrajan@ntu.edu.sg
RI Rajan, Deepu/A-3666-2011
CR [Anonymous], 2008, P IEEE COMPUTER VISI
   Bai XF, 2007, IEEE IC COMP COM NET, P1
   Chuang Y., 2001, IEEE C COMP VIS PATT, V2, P7
   Cohen J., 1988, STAT POWER ANAL BEHA
   Gastal ESL, 2010, COMPUT GRAPH FORUM, V29, P575, DOI 10.1111/j.1467-8659.2009.01627.x
   Grady L, 2005, PROCEEDINGS OF THE FIFTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P423
   Kaiming He, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2049, DOI 10.1109/CVPR.2011.5995495
   Lee P., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2193, DOI 10.1109/CVPR.2011.5995665
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P1699, DOI 10.1109/TPAMI.2008.168
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Mirmehdi Majid., 2008, Handbook of Texture Analysis
   Mishima Y., 1994, US Patent, Patent No. [5,355,174, 5355174]
   Porter T., 1984, Computers & Graphics, V18, P253
   Rhemann C., 2009, P BRIT MACH VIS C, P1155
   Rhemann C, 2010, PROC CVPR IEEE, P2149, DOI 10.1109/CVPR.2010.5539894
   Rhemann C, 2009, PROC CVPR IEEE, P1826, DOI 10.1109/CVPRW.2009.5206503
   Ruzon MA, 2000, PROC CVPR IEEE, P18, DOI 10.1109/CVPR.2000.855793
   Shen Y., 2010, THESIS U ALBERTA
   Sun J, 2004, ACM T GRAPHIC, V23, P315, DOI 10.1145/1015706.1015721
   Wang J, 2005, IEEE I CONF COMP VIS, P936
   Wang J., 2007, 2007 IEEE C COMP VIS, P1
   Wang J, 2007, FOUND TRENDS COMPUT, V3, P97, DOI 10.1561/0600000019
   Yu SX, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P313, DOI 10.1109/iccv.2003.1238361
   Zheng YJ, 2009, IEEE I CONF COMP VIS, P889, DOI 10.1109/ICCV.2009.5459326
NR 24
TC 2
Z9 2
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2013
VL 31
IS 9
BP 658
EP 672
DI 10.1016/j.imavis.2013.06.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220EG
UT WOS:000324564300007
DA 2024-07-18
ER

PT J
AU Chang, IC
   Yu, JC
   Chang, CC
AF Chang, I-Cheng
   Yu, J. Cloud
   Chang, Chih-Chuan
TI A forgery detection algorithm for exemplar-based inpainting images using
   multi-region relation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Digital image forensics; Digital forgery detection; Exemplar-based
   inpainting; Multi-region relation; Weight transformation
ID EXPOSING DIGITAL FORGERIES; OBJECT REMOVAL; AUTHENTICATION
AB The identification of image authenticity has received much attention because of the increasing power of image editing methods. This paper proposes a novel forgery detection algorithm to recognize tampered inpainting images, which is one of the effective approaches for image manipulation. The proposed algorithm contains two major processes: suspicious region detection and forged region identification. Suspicious region detection searches the similarity blocks in an image to find the suspicious regions and uses a similarity vector field to remove the false positives caused by uniform area. Forged region identification applies a new method, multi-region relation (MRR), to identify the forged regions from the suspicious regions. The proposed approach can effectively recognize if an image is a forged one and identify the forged regions, even for the images containing the uniform background. Moreover, we propose a two-stage searching algorithm based on weight transformation to speed up the computation speed. The experimental results show that the proposed approach has good performance with fast speed under different kinds of inpainting images. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Chang, I-Cheng; Yu, J. Cloud; Chang, Chih-Chuan] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 National Dong Hwa University
RP Chang, IC (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
EM icchang@mail.ndhu.edu.tw
RI Yu, Cloud/F-3662-2014
OI Yu, Cloud/0000-0003-2767-3355
FU Ministry of Economic Affairs, Taiwan, ROC [100-EC-17-A-02-S1-032];
   National Science Council, Taiwan, ROC [NSC 101-2221-E-259-013]
FX This work was supported by the Ministry of Economic Affairs, Taiwan,
   ROC, under Grant No. 100-EC-17-A-02-S1-032 and National Science Council,
   Taiwan, ROC, under Grant No. NSC 101-2221-E-259-013.
CR [Anonymous], IEEE INT C DOC IM AN
   [Anonymous], P ACM C COMP GRAPH S
   [Anonymous], P 3 CAN C COMP ROB V
   [Anonymous], 2003, P DIG FOR RES WORKSH
   [Anonymous], INT C COMP GRAPH IM
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   Chuang YY, 2001, PROC CVPR IEEE, P264
   Criminisi A, 2004, IEEE T IMAGE PROCESS, V13, P1200, DOI 10.1109/TIP.2004.833105
   Farid H, 2009, IEEE SIGNAL PROC MAG, V26, P16, DOI 10.1109/MSP.2008.931079
   Hailing Huang, 2008, 2008 Pacific-Asia Workshop on Computational Intelligence and Industrial Application. PACIIA 2008, P272, DOI 10.1109/PACIIA.2008.240
   Hartung F, 1999, P IEEE, V87, P1079, DOI 10.1109/5.771066
   Johnson MK, 2007, LECT NOTES COMPUT SC, V4567, P311, DOI 10.1007/978-3-540-77370-2_21
   Johnson MK, 2007, IEEE T INF FOREN SEC, V2, P450, DOI 10.1109/TIFS.2007.903848
   Johnson Micah K, 2006, ACM WORKSHOP MULTIME, P48
   Lee J. B., 2007, INT C CONSUMER ELECT, P1
   Li WH, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P253, DOI 10.1109/ICME.2008.4607419
   Lin ZC, 2005, PROC CVPR IEEE, P1087
   Lin ZC, 2009, PATTERN RECOGN, V42, P2492, DOI 10.1016/j.patcog.2009.03.019
   Lu CS, 2003, IEEE T MULTIMEDIA, V5, P161, DOI 10.1109/TMM.2003.811621
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Luo Weiqi, 2007, Frontiers of Computer Science in China, V1, P166, DOI 10.1007/s11704-007-0017-0
   Mahdian B, 2008, IEEE T INF FOREN SEC, V3, P529, DOI 10.1109/TIFS.2004.924603
   Mahdian B, 2007, FORENSIC SCI INT, V171, P180, DOI 10.1016/j.forsciint.2006.11.002
   Mahdian B, 2008, 42ND ANNUAL 2008 IEEE INTERNATIONAL CARNAHAN CONFERENCE ON SECURITY TECHNOLOGY, PROCEEDINGS, P280, DOI 10.1109/CCST.2008.4751315
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P3948, DOI 10.1109/TSP.2005.855406
   Popescu AC, 2005, IEEE T SIGNAL PROCES, V53, P758, DOI 10.1109/TSP.2004.839932
   Qu ZH, 2008, INT CONF ACOUST SPEE, P1661, DOI 10.1109/ICASSP.2008.4517946
   Rey C, 2002, EURASIP J APPL SIG P, V2002, P613, DOI 10.1155/S1110865702204047
   Tang F, 2004, LECT NOTES COMPUT SC, V3321, P248
   Wong A, 2008, IEEE IMAGE PROC, P2600, DOI 10.1109/ICIP.2008.4712326
   Wu JY, 2006, INT C PATT RECOG, P810
   Wu Q, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P1222, DOI 10.1109/ICMLC.2008.4620591
   Zhang Z, 2008, PROCEEDINGS OF 2008 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P3463, DOI 10.1109/ICMLC.2008.4621003
NR 33
TC 65
Z9 69
U1 0
U2 42
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2013
VL 31
IS 1
BP 57
EP 71
DI 10.1016/j.imavis.2012.09.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 084RP
UT WOS:000314557100005
DA 2024-07-18
ER

PT J
AU Ha, SJ
   Lee, SH
   Cho, NI
AF Ha, Seong Jong
   Lee, Sang Hwa
   Cho, Nam Ik
TI Discrimination and description of repetitive patterns for enhancing the
   performance of feature-based recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object recognition; Feature matching; Repetitive pattern
ID MEAN SHIFT; IMAGE; SCALE
AB Conventional object retrieval or recognition methods based on feature matching sometimes fail when an object contains repetitive patterns, because features from repetitive patterns are too similar to each other. Specifically, when there arise many similar features in a query object due to repetitive patterns, they are usually not matched to the ones at the same positions of the reference object. Hence, the matching pairs between the query and reference image do not appear regular and thus homography estimation fails. In case when we use "nearest neighbor distance ratio" as a matching criterion, where enough distinction between the matched pairs should be secured, matching also fails due to similarity of features. In this paper, we propose a new feature matching strategy to alleviate this problem by discriminating repetitive patterns from the other salient ones and also by developing a way of utilizing the patterns for robust feature matching. Specifically, we first apply a conventional feature extraction method to a given image. Then we cluster features based on their similarity, i.e., we design a classifier that tells whether a feature is from a repetitive pattern or from a salient structure. For the effective use of repetitive patterns, we define a new descriptor based on support vector data description (SVDD) for describing clusters of similar features. In other words, a set of features from a pattern is defined to be a new feature in terms of its center and radius. For object recognition, the homography is found over the salient features by excluding repetitive features at first, which is then validated and refined by the repetitive patterns. The proposed method is tested with examples of matching buildings with repetitive patterns, and it is shown to be robuster and more reliable than the conventional methods. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Ha, Seong Jong; Lee, Sang Hwa; Cho, Nam Ik] Seoul Natl Univ, INMC, Sch EECS, Seoul, South Korea.
C3 Seoul National University (SNU)
RP Ha, SJ (corresponding author), Seoul Natl Univ, INMC, Sch EECS, Seoul, South Korea.
EM oanchovy@ispl.snu.ac.kr; lsh529@snu.ac.kr; nicho@snu.ac.kr
RI Cho, Nam Ik/I-5029-2014
OI cho, nam ik/0000-0001-5297-4649
FU National Research Foundation of Korea(NRF); Ministry of Education,
   Science and Technology [2012-0000913]; Ministry of Knowledge Economy
   (MKE)
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea(NRF) funded by the Ministry of
   Education, Science and Technology (No. 2012-0000913). And this research
   (paper) was also performed for the Intelligent Robotics Development
   Program, one of the Frontier R&D Programs funded by the Ministry of
   Knowledge Economy (MKE).
CR Agarwal P.K., 1998, PROC 9 ACM SIAM S DI, P658
   [Anonymous], 260 SWISS FED I TECH
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Boyd S., 2004, CONVEX OPTIMIZATION
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Doubek Petr, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3195, DOI 10.1109/ICPR.2010.782
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Forssén PE, 2007, IEEE I CONF COMP VIS, P1530
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   Harris C., 1988, ALVEY VISION C, P147151
   Lee JA, 2009, IEEE I CONF COMP VIS, P1258, DOI 10.1109/ICCV.2009.5459324
   Li Z., 2007, Computer Vision, P1
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, PATTERN RECOGN, V29, P627, DOI 10.1016/0031-3203(95)00115-8
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2003, PROC CVPR IEEE, P257
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Park M, 2009, IEEE T PATTERN ANAL, V31, P1804, DOI 10.1109/TPAMI.2009.73
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Schindler G., 2008, IEEE COMPUT SOC C CO, P1
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tax DMJ, 2004, MACH LEARN, V54, P45, DOI 10.1023/B:MACH.0000008084.60811.49
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Van Gool L., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P642, DOI 10.1007/BFb0015574
   Vapnik V., 1999, NATURE STAT LEARNING
   Zhang W, 2007, IMAGE VISION COMPUT, V25, P704, DOI 10.1016/j.imavis.2006.05.016
NR 35
TC 4
Z9 5
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2012
VL 30
IS 11
BP 817
EP 828
DI 10.1016/j.imavis.2012.06.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 052CW
UT WOS:000312176300003
DA 2024-07-18
ER

PT J
AU Elfiky, NM
   Gonzàlez, J
   Roca, FX
AF Elfiky, Noha M.
   Gonzalez, Jordi
   Xavier Roca, F.
TI Compact and adaptive spatial pyramids for scene recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Scene recognition; Spatial pyramids; Texture; Dimensionality reduction;
   Agglomerative information theory
ID CLASSIFICATION; TEXTURE
AB Most successful approaches on scene recognition tend to efficiently combine global image features with spatial local appearance and shape cues. On the other hand, less attention has been devoted for studying spatial texture features within scenes. Our method is based on the insight that scenes can be seen as a composition of micro-texture patterns. This paper analyzes the role of texture along with its spatial layout for scene recognition. However, one main drawback of the resulting spatial representation is its huge dimensionality. Hence, we propose a technique that addresses this problem by presenting a compact Spatial Pyramid (SP) representation. The basis of our compact representation, namely, Compact Adaptive Spatial Pyramid (CASP) consists of a two-stages compression strategy. This strategy is based on the Agglomerative Information Bottleneck (AIB) theory for (i) compressing the least informative SP features, and, (ii) automatically learning the most appropriate shape for each category. Our method exceeds the state-of-the-art results on several challenging scene recognition data sets. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Elfiky, Noha M.; Gonzalez, Jordi; Xavier Roca, F.] Univ Autonoma Barcelona, Dept Comp Sci, Edifici O,Campus Univ Autonoma Barcelona, Bellaterra 08193, Catalonia, Spain.
   [Elfiky, Noha M.; Gonzalez, Jordi; Xavier Roca, F.] Univ Autonoma Barcelona, Comp Vis Ctr, Edifici O,Campus Univ Autonoma Barcelona, Bellaterra 08193, Catalonia, Spain.
C3 Autonomous University of Barcelona; Centre de Visio per Computador
   (CVC); Autonomous University of Barcelona
RP Elfiky, NM (corresponding author), Univ Autonoma Barcelona, Dept Comp Sci, Edifici O,Campus Univ Autonoma Barcelona, Bellaterra 08193, Catalonia, Spain.; Elfiky, NM (corresponding author), Univ Autonoma Barcelona, Comp Vis Ctr, Edifici O,Campus Univ Autonoma Barcelona, Bellaterra 08193, Catalonia, Spain.
EM noha@cvc.uab.es; poal@cvc.uab.es; xavir@cvc.uab.es
RI Gonzàlez, Jordi/I-1812-2015; Roca Marva, F. Xavier/I-2013-2015
OI Gonzàlez, Jordi/0000-0001-8033-0306; Roca Marva, F.
   Xavier/0000-0002-7043-7334
FU Spanish Research Program Consolider-Ingenio MIPRCV [CSD200700018];
   Spanish Research Program Consolider-Ingenio Avanza I + D ViCoMo
   [TSI-020400-2009-133]; Spanish Research Program Consolider-Ingenio
   DiCoMa TSI-020400-2011-55;  [TIN2009-14501-C02-01]; 
   [TIN2009-14501-C02-02]
FX The authors acknowledge the support of the Spanish Research Programs
   Consolider-Ingenio 2010: MIPRCV (CSD200700018); Avanza I + D ViCoMo
   (TSI-020400-2009-133) and DiCoMa (TSI-020400-2011-55); along with the
   Spanish projects TIN2009-14501-C02-01 and TIN2009-14501-C02-02.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alvarez JM, 2010, PROC CVPR IEEE, P57, DOI 10.1109/CVPR.2010.5540228
   [Anonymous], 2010, CVPR
   [Anonymous], 2010, CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2010, CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2005, ICCV
   [Anonymous], 2008, FAC REAL LIF IM WORK
   [Anonymous], 2006, IEEECOMPUT SOC C COM
   [Anonymous], 2009, ICCV
   [Anonymous], 2007, VIS REC CHALL WORKSH
   [Anonymous], 2008, CVPR
   [Anonymous], 2009, CVPR
   [Anonymous], 2005, CVPR
   Bosch A., 2006, ECCV
   Bosch A, 2008, IEEE T PATTERN ANAL, V30, P712, DOI 10.1109/TPAMI.2007.70716
   Bosch Anna., 2007, CIVR
   Fulkerson B., 2008, ECCV
   Gehler Peter., 2009, ICCV
   Heikkilä M, 2006, IEEE T PATTERN ANAL, V28, P657, DOI 10.1109/TPAMI.2006.68
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Ikizler-Cinbis N, 2010, LECT NOTES COMPUT SC, V6311, P494, DOI 10.1007/978-3-642-15549-9_36
   Ito S., 2010, ECCV
   Kim K, 2010, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2010.5540128
   Lazebnik S, 2009, IEEE T PATTERN ANAL, V31, P1294, DOI 10.1109/TPAMI.2008.138
   Mäenpää T, 2004, PATTERN RECOGN, V37, P1629, DOI 10.1016/j.patcog.2003.11.011
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Oh SM, 2010, LECT NOTES COMPUT SC, V6311, P549
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Perina A, 2009, ICCV
   Schwartz WilliamRobson., 2009, ICCV
   Shroff N, 2010, PROC CVPR IEEE, P1911, DOI 10.1109/CVPR.2010.5539864
   Slonim N., 1999, NIPS
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Torralba A, 2003, INT J COMPUT VISION, V53, P169, DOI 10.1023/A:1023052124951
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   van de Weijer J, 2004, IEEE IMAGE PROC, P1835
   Vogel J, 2007, INT J COMPUT VISION, V72, P133, DOI 10.1007/s11263-006-8614-1
   Yeffet L., 2009, ICCV
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 43
TC 11
Z9 12
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 492
EP 500
DI 10.1016/j.imavis.2012.04.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100010
DA 2024-07-18
ER

PT J
AU Huang, TS
AF Huang, Thomas S.
TI Can the World-Wide Web Bridge the Semantic Gap?
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Opinion paper; New frontiers in computer vision
AB The World-Wide Web provides tremendous resources in Multimedia Data, Ubiquitous Interconnection, and Storage/Computing Power. In this short note, we raise but not answer the question: Can the WWW help bridge the Semantic Gap in Computer Vision? Even if the answer turns out to be NO, we hope that by exploring these resources, we may gain a deeper understanding of the Semantic Gap challenge. (c) 2011 Elsevier B.V. All rights reserved.
C1 Univ Illinois, Beckman Inst, Urbana, IL USA.
C3 University of Illinois System; University of Illinois Urbana-Champaign
RP Huang, TS (corresponding author), Univ Illinois, Beckman Inst, Urbana, IL USA.
EM huang@ifp.uiuc.edu
RI yan, shuicheng/HCH-9860-2022; yan, shuicheng/A-8531-2014
OI yan, shuicheng/0000-0003-4527-1018; yan, shuicheng/0000-0001-8906-3777
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   Cao L., 2009, P ACM MULT
   Qi G.-J., 2011, P INT WORLD WID WEB, V897
   Qi Guo-Jun., 2011, TPAMI
   Tsai M.-H., 2010, P ACM MULT
NR 6
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 463
EP 464
DI 10.1016/j.imavis.2011.10.001
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100001
OA hybrid
DA 2024-07-18
ER

PT J
AU Petrou, M
AF Petrou, Maria
TI The road to intelligence
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Intelligent systems; System architecture; Tower of knowledge; Human
   language
AB It is argued that robotic platforms are the way forward towards building intelligent systems, where multiple sensors and manipulation are used for cognitive processes. It is also argued that the cue for developing the right architecture for such a system is human language. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Petrou, Maria] Univ London Imperial Coll Sci Technol & Med, London SW7 2AZ, England.
C3 Imperial College London
EM maria.petrou@imperial.ac.uk
CR Petrou M, 2007, LECT NOTES COMPUT SC, V4756, P1
   Xu M, 2011, COMPUT VIS IMAGE UND, V115, P1581, DOI 10.1016/j.cviu.2011.08.001
NR 2
TC 1
Z9 1
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 474
EP 475
DI 10.1016/j.imavis.2011.10.005
PG 2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100006
OA hybrid
DA 2024-07-18
ER

PT J
AU Lo Presti, L
   La Cascia, M
AF Lo Presti, Liliana
   La Cascia, Marco
TI An on-line learning method for face association in personal photo
   collection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face descriptor; Data association; On-line learning; Semi-supervised
   learning; Digital libraries
AB Due to the widespread use of cameras, it is very common to collect thousands of personal photos. A proper organization is needed to make the collection usable and to enable an easy photo retrieval. In this paper, we present a method to organize personal photo collections based on "who" is in the picture. Our method consists in detecting the faces in the photo sequence and arranging them in groups corresponding to the probable identities. This problem can be conveniently modeled as a multi-target visual tracking where a set of on-line trained classifiers is used to represent the identity models. In contrast to other works where clustering methods are used, our method relies on a probabilistic framework; it does not require any prior information about the number of different identities in the photo album. To enable future comparison, we present experimental results on a public dataset and on a photo collection generated from a public face dataset. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Lo Presti, Liliana; La Cascia, Marco] Univ Palermo, I-90133 Palermo, Italy.
C3 University of Palermo
RP Lo Presti, L (corresponding author), Univ Palermo, I-90133 Palermo, Italy.
EM lopresti@dinfo.unipa.it
RI La Cascia, Marco/E-9612-2012
OI Lo Presti, Liliana/0000-0003-0833-4403; La Cascia,
   Marco/0000-0002-8766-6395
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], TRANS KNOWL DATA ENG
   [Anonymous], T PATTERN ANAL MACHI
   [Anonymous], GRAPH THEROY ITS APP
   [Anonymous], 2003, ACM Multimedia Conference
   [Anonymous], 2008, COMPUT SCI
   [Anonymous], P C MULT MM
   [Anonymous], 07 U MASS AMH
   [Anonymous], T KNOWLEDGE DATA ENG
   [Anonymous], 2001, PATTERN CLASSIFICATI
   [Anonymous], T PATTERN ANAL MACH
   [Anonymous], MULTIMEDIA TOOLS APP
   Ardizzone E, 2008, PROC SPIE, V6820, DOI 10.1117/12.766803
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bar-Shalom Y., 1987, Tracking and data association
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Beyer K, 1999, LECT NOTES COMPUT SC, V1540, P217
   Blum A., 1998, Proceedings of the Eleventh Annual Conference on Computational Learning Theory, P92, DOI 10.1145/279943.279962
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Choi J.Y., 2008, MIR 08, P44
   Chu WT, 2009, INT CONF ACOUST SPEE, P1141, DOI 10.1109/ICASSP.2009.4959790
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Crammer K, 2006, J MACH LEARN RES, V7, P551
   Gallagher AC, 2008, PROC CVPR IEEE, P1073
   Gu LX, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1998
   Hastie T, 1998, ANN STAT, V26, P451
   Heyer LJ, 1999, GENOME RES, V9, P1106, DOI 10.1101/gr.9.11.1106
   Nguyen HV, 2011, LECT NOTES COMPUT SC, V6493, P709
   Hillier F.S., 2001, INTRO OPERATIONS RES
   Huang GB, 2007, IEEE I CONF COMP VIS, P237, DOI 10.1109/iccv.2007.4408858
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jain R., 2010, INT C MULTIMEDIA, P1259, DOI DOI 10.1145/1873951.1874199
   Jolliffe I. T., 2002, PRINCIPAL COMPONENT
   Kang HM, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P1539, DOI 10.1109/ICME.2000.871061
   Kapoor A, 2009, IEEE I CONF COMP VIS, P1058, DOI 10.1109/ICCV.2009.5459392
   Kubat M., 1997, ADDRESSING CURSE IMB, V97, P179
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li SZ, 2001, PROC CVPR IEEE, P207
   Lu HC, 2011, LECT NOTES COMPUT SC, V6494, P511, DOI 10.1007/978-3-642-19318-7_40
   Masulli F, 2005, IEEE IJCNN, P155
   Minka Thomas P., 2003, A comparison of numerical optimizers for logistic regression
   Mitchell T., 1999, Proceedings of the Sixth International Colloquium on Cognitive Science, P2
   MUNKRES J, 1957, J SOC IND APPL MATH, V5, P32, DOI 10.1137/0105003
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Presti L. L., 2010, Proceedings 2010 IEEE International Symposium on Multimedia (ISM 2010), P318, DOI 10.1109/ISM.2010.55
   Prince Simon J. D., 2010, Proceedings of the 2010 Seventh Canadian Conference on Computer and Robot Vision (CRV 2010), P32, DOI 10.1109/CRV.2010.12
   Taigman Y., 2009, British Machine Vision Conference, P1
   Tan XY, 2007, LECT NOTES COMPUT SC, V4778, P168
   Tang F, 2007, IEEE I CONF COMP VIS, P992
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
NR 53
TC 5
Z9 5
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2012
VL 30
IS 4-5
BP 306
EP 316
DI 10.1016/j.imavis.2012.02.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 964WF
UT WOS:000305726700004
DA 2024-07-18
ER

PT J
AU Li, QQ
   Zou, Q
   Zhang, DQ
   Mao, QZ
AF Li, Qingquan
   Zou, Qin
   Zhang, Daqiang
   Mao, Qingzhou
TI FoSA: F* Seed-growing Approach for crack-line detection from pavement
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Line detection; Pavement crack; Seed-growing; Dynamic programming
ID CURVILINEAR FEATURES; ROADS
AB Most existing approaches for pavement crack line detection implicitly assume that pavement cracks in images are with high contrast and good continuity. This assumption does not hold in pavement distress detection practice, where pavement cracks are often blurry and discontinuous due to particle materials of road surface, crack degradation, and unreliable crack shadows. To this end, we propose in this paper FoSA - F* Seed-growing Approach for automatic crack-line detection, which extends the F* algorithm in two aspects. It exploits a seed-growing strategy to remove the requirement that the start and end points should be set in advance. Moreover, it narrows the global searching space to the interested local space to improve its efficiency. Empirical study demonstrates the correctness, completeness and efficiency of FoSA. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Li, Qingquan; Zou, Qin; Mao, Qingzhou] Wuhan Univ, Transportat Res Ctr, Wuhan 430079, Peoples R China.
   [Li, Qingquan; Zou, Qin] Wuhan Univ, Sch Remote Sensing & Informat Engn, Wuhan 430079, Peoples R China.
   [Zhang, Daqiang] Nanjing Normal Univ, Sch Comp Sci, Nanjing 210097, Jiangsu, Peoples R China.
C3 Wuhan University; Wuhan University; Nanjing Normal University
RP Zou, Q (corresponding author), Wuhan Univ, Transportat Res Ctr, Wuhan 430079, Peoples R China.
EM qqli@whu.edu.cn; qinnzou@gmail.com
RI Zou, Qin/GVU-2237-2022; Mao, Qingzhou/S-4688-2019; Zou,
   Qin/AFM-0040-2022
OI Mao, Qingzhou/0000-0002-7948-2828; Zou, Qin/0000-0001-7955-0782
FU National Natural Science Foundation of China [40721001]; Doctoral
   Foundation [20070486001]; Fundamental Research Funds for the Central
   Universities [20102130101000130]
FX The author Q. Q. Li acknowledges the supports from the National Natural
   Science Foundation of China on Innovation Team Program under grant no.
   40721001, and the Doctoral Foundation Program under grant no.
   20070486001. The author Q. Zou thanks the supports from the Fundamental
   Research Funds for the Central Universities under grant No.
   20102130101000130.
CR [Anonymous], P 5 IB S PATT REC LI
   [Anonymous], 2008, P 16 EUR SIGN PROC C
   [Anonymous], P INT C COMP EL ENG
   [Anonymous], 1889 INRIA HEBR U
   [Anonymous], 1956, NETWORK FLOW THEORY
   [Anonymous], ISPRS INT ARCH PHOTO
   [Anonymous], TRR J TRANSPORTATION
   [Anonymous], P INT C EL MEAS INST
   [Anonymous], J TRANSP ENG ASCE
   Ayenu-Prah A, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/861701
   Barat C, 2003, ISPA 2003: PROCEEDINGS OF THE 3RD INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, PTS 1 AND 2, P417
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Carlotto MJ, 2007, IEEE T IMAGE PROCESS, V16, P221, DOI 10.1109/TIP.2006.884949
   Cheng HD, 1999, J COMPUT CIVIL ENG, V13, P270, DOI 10.1061/(ASCE)0887-3801(1999)13:4(270)
   Cheng HD, 2001, TRANSPORT RES REC, P119
   FISCHLER MA, 1981, COMPUT VISION GRAPH, V15, P201, DOI 10.1016/0146-664X(81)90056-3
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006
   Gruen A, 1997, PHOTOGRAMM ENG REM S, V63, P985
   Hassani A, 2008, PAVEMENT CRACKING: MECHANISMS, MODELING, DETECTION, TESTING AND CASE HISTORIES, P891
   Hilditch C.J., 1969, MACHINE INTELLIGENCE, V4, P403
   Huang YX, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2177650
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   KIRSCHKE KR, 1992, J TRANSP ENG-ASCE, V118, P700, DOI 10.1061/(ASCE)0733-947X(1992)118:5(700)
   Li QQ, 2008, CISP 2008: FIRST INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING, VOL 2, PROCEEDINGS, P792, DOI 10.1109/CISP.2008.13
   Liu FF, 2008, KAM: 2008 INTERNATIONAL SYMPOSIUM ON KNOWLEDGE ACQUISITION AND MODELING, PROCEEDINGS, P610, DOI 10.1109/KAM.2008.29
   Liu L, 2007, IEEE T IMAGE PROCESS, V16, P1584, DOI 10.1109/TIP.2007.894288
   Marikhu R, 2007, LECT NOTES COMPUT SC, V4843, P85
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Merlet N, 1996, IEEE T PATTERN ANAL, V18, P426, DOI 10.1109/34.491623
   Oh H., 1997, Imaging Technologies, P138
   Oliveira Henrique, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P622
   Oliveira H, 2008, IEEE IMAGE PROC, P57, DOI 10.1109/ICIP.2008.4711690
   Petrou M, 1996, J MATER PROCESS TECH, V56, P158, DOI 10.1016/0924-0136(95)01831-X
   SAMADANI R, 1990, IEEE T GEOSCI REMOTE, V28, P669, DOI 10.1109/TGRS.1990.572977
   SONG KY, 1995, MACH VISION APPL, V8, P63, DOI 10.1007/BF01213639
   Subirats P, 2006, IEEE IMAGE PROC, P3037, DOI 10.1109/ICIP.2006.313007
   Tien Sy Nguyen, 2009, 2009 17th European Signal Processing Conference (EUSIPCO 2009), P617
   WANG FJ, 1988, IEEE T GEOSCI REMOTE, V26, P525, DOI 10.1109/36.7677
   Zhou J, 2006, OPT ENG, V45, DOI 10.1117/1.2172917
NR 40
TC 136
Z9 159
U1 2
U2 67
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2011
VL 29
IS 12
BP 861
EP 872
DI 10.1016/j.imavis.2011.10.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 873TJ
UT WOS:000298905600006
DA 2024-07-18
ER

PT J
AU Zunic, J
   Rosin, PL
AF Zunic, Jovisa
   Rosin, Paul L.
TI Measuring linearity of open planar curve segments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shape; Curves; Linearity measure; Image processing
ID MOMENT INVARIANTS; POINT SETS; SHAPE; TORTUOSITY; IMAGES; APPROXIMATION;
   RECOGNITION; CONVEXITY; BOUNDARY
AB In this paper we define a new linearity measure for open planar curve segments. We start with the integral of the squared distances between all the pairs of points belonging to the measured curve segment, and show that, for curves of a fixed length, such an integral reaches its maximum for straight line segments. We exploit this nice property to define a new linearity measure for open curve segments. The new measure ranges over the interval (0,1], and produces the value 1 if and only if the measured open line is a straight line segment. The new linearity measure is invariant with respect to translations, rotations and scaling transformations. Furthermore, it can be efficiently and simply computed using line moments. Several experimental results are provided in order to illustrate the behaviour of the new measure. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Zunic, Jovisa] Univ Exeter, Dept Comp Sci, Exeter EX4 4QF, Devon, England.
   [Rosin, Paul L.] Cardiff Univ, Sch Comp Sci, Cardiff CF24 3AA, S Glam, Wales.
   [Zunic, Jovisa] Serbian Acad Arts & Sci, Math Inst, Belgrade, Serbia.
C3 University of Exeter; Cardiff University; Serbian Academy of Sciences &
   Arts
RP Zunic, J (corresponding author), Univ Exeter, Dept Comp Sci, Exeter EX4 4QF, Devon, England.
EM J.Zunic@ex.ac.uk; Paul.Rosin@cs.cf.ac.uk
OI Rosin, Paul/0000-0002-4965-3884
FU Serbian Ministry of Science and Technology [OI174008]
FX The authors wish to thank: Dr Stefano Piermarocchi (University of
   Padova) for providing the fundus images and the manual tortuosity
   grading; and Dr Mario Munich and Prof Pietro Perona (Caltech) for
   providing the signature data. The research is partially supported by the
   Serbian Ministry of Science and Technology/project OI174008.
CR [Anonymous], 1998, Image processing, analysis, and machine vision
   Benhamou S, 2004, J THEOR BIOL, V229, P209, DOI 10.1016/j.jtbi.2004.03.016
   Bullitt E, 2003, IEEE T MED IMAGING, V22, P1163, DOI 10.1109/TMI.2003.816964
   CHEN CC, 1993, PATTERN RECOGN, V26, P683, DOI 10.1016/0031-3203(93)90121-C
   Coeurjolly D, 2004, IEEE T PATTERN ANAL, V26, P252, DOI 10.1109/TPAMI.2004.1262194
   Di Ruberto C, 2000, ELECTRON LETT, V36, P1691, DOI 10.1049/el:20001191
   El-Ghazal A, 2009, SIGNAL PROCESS-IMAGE, V24, P572, DOI 10.1016/j.image.2009.04.001
   Escalera S, 2011, IEEE T SYST MAN CY B, V41, P497, DOI 10.1109/TSMCB.2010.2060481
   Gautama T, 2004, IEEE T BIO-MED ENG, V51, P728, DOI 10.1109/TBME.2004.824122
   Gautama T, 2003, IEEE T MED IMAGING, V22, P636, DOI 10.1109/TMI.2003.812248
   Grisan E, 2008, IEEE T MED IMAGING, V27, P310, DOI 10.1109/TMI.2007.904657
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   Huxley MN, 2003, P LOND MATH SOC, V87, P591, DOI 10.1112/S0024611503014485
   Imre AR, 2009, APPL MATH COMPUT, V207, P90, DOI 10.1016/j.amc.2007.10.067
   Kakarala R, 1998, ELECTRON LETT, V34, P1392, DOI 10.1049/el:19980943
   Klette R, 1999, GRAPH MODEL IM PROC, V61, P274, DOI 10.1006/gmip.1999.0501
   Klette R., 2004, A. Rosenfeld Digital Geometry
   Manay S, 2006, IEEE T PATTERN ANAL, V28, P1602, DOI 10.1109/TPAMI.2006.208
   MELTER RA, 1993, PATTERN RECOGN LETT, V14, P83, DOI 10.1016/0167-8655(93)90080-W
   Mio W, 2007, INT J COMPUT VISION, V73, P307, DOI [10.1007/s11263-006-9968-0, 10.1007/s11263-006-996S-0]
   Munich ME, 2003, IEEE T PATTERN ANAL, V25, P200, DOI 10.1109/TPAMI.2003.1177152
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   Rahtu E, 2006, IEEE T PATTERN ANAL, V28, P1501, DOI 10.1109/TPAMI.2006.175
   ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Segundo MP, 2010, IEEE T SYST MAN CY B, V40, P1319, DOI 10.1109/TSMCB.2009.2038233
   Shu X, 2011, IMAGE VISION COMPUT, V29, P286, DOI 10.1016/j.imavis.2010.11.001
   Sladoje N, 2009, IEEE T PATTERN ANAL, V31, P357, DOI 10.1109/TPAMI.2008.184
   Stojmenovic M, 2008, PATTERN RECOGN, V41, P2503, DOI 10.1016/j.patcog.2008.01.013
   Stojmenovic M, 2007, LECT NOTES COMPUT SC, V4872, P274
   Stojmenovic M, 2008, J MATH IMAGING VIS, V30, P73, DOI 10.1007/s10851-007-0039-0
   Venkatraghavan Vikram, 2009, IEEE Signal Processing Letters, V16, P711, DOI 10.1109/LSP.2009.2022567
   Zhang DS, 2005, IMAGE VISION COMPUT, V23, P33, DOI 10.1016/j.imavis.2004.09.001
   Zunic J, 2003, IEEE T PATTERN ANAL, V25, P1193, DOI 10.1109/TPAMI.2003.1227997
   Zunic J, 2006, IEEE T IMAGE PROCESS, V15, P3478, DOI 10.1109/TIP.2006.877527
   Zunic J, 2009, APPL MATH COMPUT, V215, P3098, DOI 10.1016/j.amc.2009.10.003
   Zunic J, 2010, PATTERN RECOGN, V43, P47, DOI 10.1016/j.patcog.2009.06.017
NR 37
TC 10
Z9 10
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2011
VL 29
IS 12
BP 873
EP 879
DI 10.1016/j.imavis.2011.10.002
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 873TJ
UT WOS:000298905600007
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Celebi, ME
AF Celebi, M. Emre
TI Improving the performance of <i>k</i>-means for color quantization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Color quantization; Color reduction; Clustering; k-means
ID MEANS CLUSTERING-ALGORITHM; IMAGE QUANTIZATION; EDGE-DETECTION;
   INITIALIZATION; REDUCTION; SELECTION
AB Color quantization is an important operation with many applications in graphics and image processing. Most quantization methods are essentially based on data clustering algorithms. However, despite its popularity as a general purpose clustering algorithm, k-means has not received much respect in the color quantization literature because of its high computational requirements and sensitivity to initialization. In this paper, we investigate the performance of k-means as a color quantizer. We implement fast and exact variants of k-means with several initialization schemes and then compare the resulting quantizers to some of the most popular quantizers in the literature. Experiments on a diverse set of images demonstrate that an efficient implementation of k-means with an appropriate initialization strategy can in fact serve as a very effective color quantizer. (C) 2010 Elsevier B.V. All rights reserved.
C1 Louisiana State Univ, Dept Comp Sci, Shreveport, LA 71105 USA.
C3 Louisiana State University System; Louisiana State University Shreveport
RP Celebi, ME (corresponding author), Louisiana State Univ, Dept Comp Sci, Shreveport, LA 71105 USA.
EM ecelebi@lsus.edu
RI Celebi, M. Emre/G-2129-2012
OI Celebi, M. Emre/0000-0002-2721-6317
FU Louisiana Board of Regents [LEQSF2008-11-RD-A-12]
FX This publication was made possible by a grant from The Louisiana Board
   of Regents (LEQSF2008-11-RD-A-12). The author is grateful to the
   anonymous reviewers for their insightful suggestions and constructive
   comments that improved the quality and presentation of this paper.
CR Al Hasan M, 2009, PATTERN RECOGN LETT, V30, P994, DOI 10.1016/j.patrec.2009.04.013
   AlDaoud MB, 1996, PATTERN RECOGN LETT, V17, P451, DOI 10.1016/0167-8655(95)00119-0
   Aloise D, 2009, MACH LEARN, V75, P245, DOI 10.1007/s10994-009-5103-0
   [Anonymous], 2005, FINDING GROUPS DATA, DOI DOI 10.1002/9780470316801
   [Anonymous], THEORETICAL IN PRESS
   [Anonymous], P 2 WORLD ENF C
   [Anonymous], P 11 IB C AI ADV ART
   [Anonymous], 2007, P 18 ANN ACM SIAM S
   [Anonymous], P 5 SCAND C IM AN
   [Anonymous], 2007, DATA CLUSTERING THEO
   [Anonymous], HDB APPROXIMATION AL
   [Anonymous], P INT C IM IN PRESS
   [Anonymous], P 2009 INT C IM PROC
   [Anonymous], 2003, INT C INT C MACH LEA, DOI DOI 10.1016/0026-2714(92)90278-S
   [Anonymous], P 21 ANN S COMP GEOM
   [Anonymous], IEEE T INFORM THEORY
   BABU GP, 1993, PATTERN RECOGN LETT, V14, P763, DOI 10.1016/0167-8655(93)90058-L
   BABU PG, 1994, INDIAN J PURE AP MAT, V25, P85
   Balasubramanian R., 1994, Journal of Electronic Imaging, V3, P45, DOI 10.1117/12.165065
   BALASUBRAMANIAN R, 1991, J IMAGING TECHNOL, V17, P284
   Bezdek James C., 1981, PATTERN RECOGN
   Bing Z, 2004, PATTERN RECOGN LETT, V25, P1787, DOI 10.1016/j.patrec.2004.07.005
   Bottou L., 1995, Advances in Neural Information Processing Systems 7, P585
   Braudaway G.W., 1987, Proceedings of the Electronic Imaging Conference, P71
   Brun L, 2003, EL EN AP SI, P589
   Brun L., 2000, Proceedings of the 1st International Conference on Color in Graphics and Image Processing, P116
   Celebi ME, 2010, IET IMAGE PROCESS, V4, P70, DOI 10.1049/iet-ipr.2008.0172
   Chang CH, 2005, IEEE T NEURAL NETWOR, V16, P237, DOI 10.1109/TNN.2004.836543
   Chen TW, 2008, 2008 IEEE 10TH WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, VOLS 1 AND 2, P324, DOI 10.1109/MMSP.2008.4665097
   Cheng SC, 2001, PATTERN RECOGN LETT, V22, P845, DOI 10.1016/S0167-8655(01)00025-3
   DEKKER AH, 1994, NETWORK-COMP NEURAL, V5, P351, DOI 10.1088/0954-898X/5/3/003
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Deng YN, 2001, IEEE T IMAGE PROCESS, V10, P140, DOI 10.1109/83.892450
   EQUITZ WH, 1989, IEEE T ACOUST SPEECH, V37, P1568, DOI 10.1109/29.35395
   Feldman Dan, 2007, P 23 ANN S COMP GEOM, P11, DOI DOI 10.1145/1247069.1247072
   FLETCHER P, 1991, COMPUT GRAPH-UK, V15, P365, DOI 10.1016/0097-8493(91)90006-4
   FORGY EW, 1965, BIOMETRICS, V21, P768
   Fränti P, 2006, IEEE T PATTERN ANAL, V28, P1875, DOI 10.1109/TPAMI.2006.227
   GENTILE RS, 1990, J IMAGING TECHNOL, V16, P11
   Gervautz M, 1988, NEW TRENDS COMPUTER, P219, DOI DOI 10.1007/978-3-642-83492-920
   GOLDBERG N, 1991, IMAGE VISION COMPUT, V9, P303, DOI 10.1016/0262-8856(91)90035-N
   GONZALEZ TF, 1985, THEOR COMPUT SCI, V38, P293, DOI 10.1016/0304-3975(85)90224-5
   Heckbert P., 1982, Computer Graphics, V16, P297, DOI 10.1145/965145.801294
   HOCHBAUM DS, 1985, MATH OPER RES, V10, P180, DOI 10.1287/moor.10.2.180
   Hsieh IS, 2000, PATTERN RECOGN LETT, V21, P337, DOI 10.1016/S0167-8655(99)00165-8
   Hu YC, 2008, IMAGING SCI J, V56, P68, DOI 10.1179/174313107X214231
   Hu YC, 2008, IMAGING SCI J, V56, P29, DOI 10.1179/174313107X176298
   Hu YC, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2762241
   Huang YL, 2004, J INF SCI ENG, V20, P771
   Joy G., 1993, Visual Computer, V10, P62, DOI 10.1007/BF01905532
   Kanjanawanishkul K, 2005, J VIS COMMUN IMAGE R, V16, P311, DOI 10.1016/j.jvcir.2004.07.002
   Kanungo T, 2002, IEEE T PATTERN ANAL, V24, P881, DOI 10.1109/TPAMI.2002.1017616
   Kasuga H., 2000, Systems and Computers in Japan, V31, P33, DOI 10.1002/1520-684X(200007)31:8<33::AID-SCJ4>3.0.CO;2-C
   Katsavounidis I, 1994, IEEE SIGNAL PROC LET, V1, P144, DOI 10.1109/97.329844
   Khan SS, 2004, PATTERN RECOGN LETT, V25, P1293, DOI 10.1016/j.patrec.2004.04.007
   Kolen JF, 2002, IEEE T FUZZY SYST, V10, P263, DOI 10.1109/91.995126
   Kuo CT, 2007, PATTERN RECOGN, V40, P3691, DOI 10.1016/j.patcog.2007.03.025
   Lai JZC, 2008, PATTERN RECOGN, V41, P3677, DOI 10.1016/j.patcog.2008.06.005
   Likas A, 2003, PATTERN RECOGN, V36, P451, DOI 10.1016/S0031-3203(02)00060-2
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lo KC, 2003, PATTERN RECOGN LETT, V24, P2325, DOI 10.1016/S0167-8655(03)00058-8
   MILLIGAN GW, 1980, PSYCHOMETRIKA, V45, P325, DOI 10.1007/BF02293907
   Mojsilovic A, 2001, IEEE T IMAGE PROCESS, V10, P1712, DOI 10.1109/83.967399
   ORCHARD MT, 1991, IEEE T SIGNAL PROCES, V39, P2677, DOI 10.1109/78.107417
   Özdemir D, 2002, PATTERN RECOGN, V35, P1785, DOI 10.1016/S0031-3203(01)00170-4
   Papamarkos N, 2002, IEEE T SYST MAN CY B, V32, P44, DOI 10.1109/3477.979959
   PEI SC, 1995, IEEE T CIRC SYST VID, V5, P124, DOI 10.1109/76.388061
   Phillips SJ, 2002, LECT NOTES COMPUT SC, V2409, P166
   Redmond SJ, 2007, PATTERN RECOGN LETT, V28, P965, DOI 10.1016/j.patrec.2007.01.001
   Schaefer G, 2009, TELECOMMUN SYST, V40, P17, DOI 10.1007/s11235-008-9143-8
   Scheunders P, 1997, PATTERN RECOGN LETT, V18, P1379, DOI 10.1016/S0167-8655(97)00116-5
   SELIM SZ, 1984, IEEE T PATTERN ANAL, V6, P81, DOI 10.1109/TPAMI.1984.4767478
   Sertel O, 2009, J SIGNAL PROCESS SYS, V55, P169, DOI 10.1007/s11265-008-0201-y
   Sherkat N, 2005, PATTERN ANAL APPL, V8, P163, DOI 10.1007/s10044-005-0253-6
   Sirisathitkul Y, 2004, PATTERN RECOGN LETT, V25, P1025, DOI 10.1016/j.patrec.2004.02.012
   Smith A.R., 1978, P 5 ANN C COMP GRAPH, V12, P12, DOI [10.1145/965139.807361, DOI 10.1145/965139.807361]
   Turnbull D, 2005, IEEE T KNOWL DATA EN, V17, P580, DOI 10.1109/TKDE.2005.62
   UCHIYAMA T, 1994, PATTERN RECOGN, V27, P1415, DOI 10.1016/0031-3203(94)90074-4
   Velho L, 1997, X BRAZILIAN SYMPOSIUM ON COMPUTER GRAPHICS AND IMAGE PROCESSING, PROCEEDINGS, P203, DOI 10.1109/SIGRA.1997.625178
   VEREVKA O, 1995, GRAPH INTER, P128
   WAN SJ, 1990, COLOR RES APPL, V15, P52, DOI 10.1002/col.5080150109
   Wang SD, 2010, VISUAL COMPUT, V26, P445, DOI 10.1007/s00371-010-0436-z
   Wu X., 1991, Graphics Gems, V11, P126, DOI DOI 10.1016/B978-0-08-050754-5.50035-9
   WU XL, 1992, ACM T GRAPHIC, V11, P348, DOI 10.1145/146443.146475
   Xiang ZG, 1997, ACM T GRAPHIC, V16, P260, DOI 10.1145/256157.256159
   XIANG ZG, 1994, IEEE COMPUT GRAPH, V14, P44, DOI 10.1109/38.279043
   Yang CK, 1998, PATTERN RECOGN LETT, V19, P205, DOI 10.1016/S0167-8655(97)00166-9
   Yang CY, 1996, COMPUT GRAPH, V20, P577, DOI 10.1016/0097-8493(96)00028-3
NR 88
TC 110
Z9 116
U1 3
U2 37
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2011
VL 29
IS 4
BP 260
EP 271
DI 10.1016/j.imavis.2010.10.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 727UR
UT WOS:000287828800006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Crespo, J
AF Crespo, Jose
TI Adjacency stable connected operators and set levelings
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 8th International Symposium on Mathematical Morphology
CY OCT 10-13, 2007
CL Rio de Janeiro, BRAZIL
DE Image processing; Image analysis; Mathematical morphology; Connected
   operator; Adjacency stable operator; Leveling; Marker-based operator
ID MORPHOLOGICAL FILTERS; BINARY; RECONSTRUCTION; REPRESENTATION;
   SEGMENTATION
AB This paper studies morphological connected operators. Particularly, it focuses on an adjacency constraint, as well as on the so-called set levelings. Some important findings are reported in this work. First, the relationships between the so-called adjacency stable operators and set levelings are investigated, and an equivalence is established. This permits to apply some properties to the related operator class. Second, the implications and limits of a property presented elsewhere that states that certain connected operators can be expressed as a sequential composition of an opening and a closing (and vice-versa) based on markers are treated. Then, a commutative property that involves alternated attribute filters is presented. In addition, other related expressions are discussed. (C) 2010 Elsevier B.V. All rights reserved.
C1 Univ Politecn Madrid, Fac Informat, DLSIIS, Boadilla Del Monte 28660, Madrid, Spain.
C3 Universidad Politecnica de Madrid
RP Crespo, J (corresponding author), Univ Politecn Madrid, Fac Informat, DLSIIS, Campus Montegancedo, Boadilla Del Monte 28660, Madrid, Spain.
EM jcrespo@fi.upm.es
CR [Anonymous], P 8 INT S MATH MORPH
   [Anonymous], 1990, THESIS ECOLE MINES P
   [Anonymous], MORPHOLOGIE MATH
   [Anonymous], 1988, Morphological methods in image and signal processing
   BANON G, 2000, FORMAL INTRO DIGITAL
   Braga-Neto U, 2005, J MATH IMAGING VIS, V22, P199, DOI 10.1007/s10851-005-4890-6
   Braga-Neto U, 2003, J MATH IMAGING VIS, V19, P5, DOI 10.1023/A:1024476403183
   Braga-Neto U, 2003, COMPUT VIS IMAGE UND, V89, P70, DOI 10.1016/S1077-3142(03)00014-6
   Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066
   Crespo J, 1997, J MATH IMAGING VIS, V7, P85, DOI 10.1023/A:1008270125009
   Crespo J, 1998, PATTERN RECOGN, V31, P419, DOI 10.1016/S0031-3203(97)00062-9
   Crespo J, 1995, SIGNAL PROCESS, V47, P201, DOI 10.1016/0165-1684(95)00108-5
   CRESPO J, 2002, LECT NOTES COMPUTER, V2301, P165
   CRESPO J, 1993, IMAGE SEGMENTATION U, P52
   CRESPO J, 1993, THESIS SCH ELECT COM
   CRESPO J, 2007, P 8 INT S MATH MORPH, P215
   Crespo J, 2008, J MATH IMAGING VIS, V32, P251, DOI 10.1007/s10851-008-0098-x
   Crespo J, 2009, LECT NOTES COMPUT SC, V5720, P82, DOI 10.1007/978-3-642-03613-2_8
   Dimiccoli M, 2007, ISMM, P227
   Dougherty ER, 2003, SPIE TUTORIAL TEXTS, VTT5
   Garrido L, 1998, SIGNAL PROCESS, V66, P157, DOI 10.1016/S0165-1684(98)00004-8
   GOETCHERIAN V, 1980, PATTERN RECOGN, V12, P7, DOI 10.1016/0031-3203(80)90049-7
   GRIMAUD M, 1991, THESIS ECOLE MINES P
   Heijmans H., 1994, Advances in Electronics and Electron Physics
   Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703
   Jones R, 1999, COMPUT VIS IMAGE UND, V75, P215, DOI 10.1006/cviu.1999.0777
   KLEIN JC, 1976, THESIS U NANCY
   LANTUEJOUL C, 1984, PATTERN RECOGN, V17, P177, DOI 10.1016/0031-3203(84)90057-8
   Maragos P, 2003, INT J COMPUT VISION, V52, P121, DOI 10.1023/A:1022999923439
   MARAGOS P, 1990, P IEEE, V78, P690, DOI 10.1109/5.54808
   MARAGOS P, 2007, P 8 INT S MATH MORPH, V1, P125
   MATHERON G, 1988, MATH MORPHOLOGY, V2, P115
   Matheron G., 1975, Random sets and integral geometry
   MATHERON G, 1997, N5499MM CTR MORPH MA
   MATHERON G, 1988, MATH MORPHOLOGY, V2, P141
   Meyer F, 2004, J MATH IMAGING VIS, V20, P59, DOI 10.1023/B:JMIV.0000011319.21884.39
   Meyer F, 1998, COMP IMAG VIS, V12, P199
   Meyer F, 2000, J VIS COMMUN IMAGE R, V11, P245, DOI 10.1006/jvci.1999.0447
   Meyer F, 1998, COMP IMAG VIS, V12, P191
   Ronse C, 2005, J MATH IMAGING VIS, V22, P103, DOI 10.1007/s10851-005-4884-4
   Ronse C, 1998, J MATH IMAGING VIS, V8, P41, DOI 10.1023/A:1008210216583
   Ronse C, 2001, FUND INFORM, V46, P349
   SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Serra J, 1998, J MATH IMAGING VIS, V9, P231, DOI 10.1023/A:1008324520475
   Serra J., 2000, Fundamenta Informaticae, V41, P147
   SERRA J, 1993, P SOC PHOTO-OPT INS, V2030, P65, DOI 10.1117/12.146672
   SERRA J, 1988, MATH MORPHOLOGY, V2
   SERRA J, 1982, MATH MORPHOLOGY, V1
   Soille P, 2005, IMAGE VISION COMPUT, V23, P249, DOI 10.1016/j.imavis.2004.06.002
   Soille P, 2003, LECT NOTES COMPUT SC, V2886, P52
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   TEROL I, 2002, P INT S MATH MORPH I, P2002
   Vargas-Vazquez D, 2003, LECT NOTES COMPUT SC, V2886, P475
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
NR 55
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2010
VL 28
IS 10
SI SI
BP 1483
EP 1490
DI 10.1016/j.imavis.2010.04.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 638YK
UT WOS:000280936300007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Bunting, P
   Labrosse, F
   Lucas, R
AF Bunting, Peter
   Labrosse, Frederic
   Lucas, Richard
TI A multi-resolution area-based technique for automatic multi-modal image
   registration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image registration; Remote sensing; Multi-modal; Correlation
   coefficient; Network
ID MIXED-SPECIES FORESTS; QUEENSLAND; ARTIFACTS; COVER
AB To allow remotely sensed datasets to be used for data fusion, either to gain additional insight into the scene or for change detection, reliable spatial referencing is required. With modern remote sensing systems, reliable registration can be gained by applying an orbital model for spaceborne data or through the use of global positioning (GPS) and inertial navigation (INS) systems in the case of airborne data. Whilst, individually, these datasets appear well registered when compared to a second dataset from another source (e.g., optical to LiDAR or optical to radar) the resulting images may still be several pixels out of alignment. Manual registration techniques are often slow and labour intensive and although an improvement in registration is gained, there can still be some misalignment of the datasets. This paper outlines an approach for automatic image-to-image registration where a topologically regular grid of tie points was imposed within the overlapping region of the images. To ensure topological consistency, tie points were stored within a network structure inspired from Kohonen's self-organising networks 124]. The network was used to constrain the motion of the tie points in a manner similar to Kohonen's original method. Using multiple resolutions, through an image pyramid, the network structure was formed at each resolution level where connections between the resolution levels allowed tie point movements to be propagated within and to all levels. Experiments were carried out using a range of manually registered multi-modal remotely sensed datasets where known linear and non-linear transformations were introduced against which our algorithm's performance was tested. For single modality tests with no introduced transformation a mean error of 0.011 pixels was identified increasing to 3.46 pixels using multi-modal image data. Following the introduction of a series of translations a mean error of 4.98 pixels was achieve across all image pairs while a mean error of 7.12 pixels was identified for a series of non-linear transformations. Experiments using optical reflectance and height data were also conducted to compare the manually and automatically produced results where it was found the automatic results out performed the manual results. Some limitations of the network data structure were identified when dealing with very large errors but overall the algorithm produced results similar to, and in some cases an improvement over, that of a manual operator. We have also positively compared our method to methods from two other software packages: ITK and ITT ENVI. (C) 2010 Published by Elsevier B.V.
C1 [Bunting, Peter; Lucas, Richard] Aberystwyth Univ, Inst Geog & Earth Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
   [Labrosse, Frederic] Aberystwyth Univ, Dept Comp Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
C3 Aberystwyth University; Aberystwyth University
RP Bunting, P (corresponding author), Aberystwyth Univ, Inst Geog & Earth Sci, Aberystwyth SY23 3DB, Dyfed, Wales.
EM pete.bunting@aber.ac.uk; ffl@aber.ac.uk; rml@aber.ac.uk
RI Bunting, Peter J/GVT-0875-2022; Bunting, Pete/M-5839-2019
OI Bunting, Peter J/0000-0002-7435-0148; Bunting, Pete/0000-0002-7435-0148;
   Lucas, Richard/0000-0003-3010-3302
FU Aberystwyth University (Institute of Geography and Earth Sciences and
   Department of Computer Science)
FX The authors would like to thank Aberystwyth University (Institute of
   Geography and Earth Sciences and Department of Computer Science) for
   funding the research and the data providers for the provision of data,
   including Ball Aims (CASI), HyVista (HyMap), NASA/JPL (AIRSAR),
   Queensland Department of Natural Resources and Mines (Landsat/FPC) and
   JAXA (ALOS-PALSAR). Finally, we would also like thank the anonymous
   reviewers for their comments and suggestions.
CR [Anonymous], 1995, SELF ORG MAPS
   BARNEA DI, 1972, IEEE T COMPUT, VC 21, P179, DOI 10.1109/TC.1972.5008923
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Bunting P, 2006, REMOTE SENS ENVIRON, V101, P230, DOI 10.1016/j.rse.2005.12.015
   BUNTING P, 2008, P IEEE INT GEOSC REM, P212
   Campbell J.B., 1987, INTRO REMOTE SENSING
   CHALERMWAT P, 1999, THESIS G MASON U FAI
   CHAO A, 2003, P 6 INT C INF FUS, V1, P720
   CHEN H, 2002, SPIE C SENS FUS ARCH, V6, P122
   CHEN H, 2002, THESIS SYRACUSE U
   DECASTRO E, 1987, IEEE T PATTERN ANAL, V9, P700, DOI 10.1109/TPAMI.1987.4767966
   DIA X, 1997, INT GEOSC REM SENS S, P243
   DIA X, 1998, IEEE T GEOSCI REMOTE, V36, P1566
   Du J, 2006, INT J COMPUT MATH, V83, P49, DOI 10.1080/00207160500112944
   Emery WJ, 2003, IEEE T GEOSCI REMOTE, V41, P33, DOI 10.1109/TGRS.2002.808061
   FARSAII B, 1998, P SPIE C MATH MOD ES, P117
   GOSHTASBY A, 1986, IEEE T GEOSCI REMOTE, V24, P390, DOI 10.1109/TGRS.1986.289597
   INGBER L, 1989, MATH COMPUT MODEL, V12, P967, DOI 10.1016/0895-7177(89)90202-1
   Ingber L., 1996, Control and Cybernetics, V25, P33
   Inglada J, 2004, IEEE T GEOSCI REMOTE, V42, P2104, DOI 10.1109/TGRS.2004.835294
   Inglada J, 2007, IEEE T GEOSCI REMOTE, V45, P254, DOI 10.1109/TGRS.2006.882262
   *ITT VIS INF SOL, 2009, ENV US GUID
   Keller Y, 2006, IEEE T PATTERN ANAL, V28, P794, DOI 10.1109/TPAMI.2006.100
   Kern JP, 2007, IEEE T GEOSCI REMOTE, V45, P1494, DOI 10.1109/TGRS.2007.892599
   Labrosse F, 2006, J FIELD ROBOT, V23, P913, DOI 10.1002/rob.20159
   LBANEZ L, 2005, ITK SOFTWARE GUIDE S
   Le Moigne J, 2002, IEEE T GEOSCI REMOTE, V40, P1849, DOI 10.1109/TGRS.2002.802501
   Lee SI, 2008, J MED FOOD, V11, P518, DOI 10.1089/jmf.2007.0155
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas R, 2007, ISPRS J PHOTOGRAMM, V62, P165, DOI 10.1016/j.isprsjprs.2007.03.003
   Lucas RM, 2006, REMOTE SENS ENVIRON, V100, P388, DOI 10.1016/j.rse.2005.09.020
   Lucas RM, 2004, IEEE T GEOSCI REMOTE, V42, P2142, DOI 10.1109/TGRS.2004.834633
   Pluim JPW, 2000, COMPUT VIS IMAGE UND, V77, P211, DOI 10.1006/cviu.1999.0816
   PRATT WK, 1974, IEEE T AERO ELEC SYS, VAE10, P353, DOI 10.1109/TAES.1974.307828
   Svedlow M., 1976, S MACH PROC REM SENS
   Thevenaz P, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P265, DOI 10.1109/ICIP.1996.559484
   Tickle PK, 2006, FOREST ECOL MANAG, V223, P379, DOI 10.1016/j.foreco.2005.11.021
   Tilton JC, 1997, P IRW NASA GSFC, P133
   VARSHNEY PK, 2004, ADV IMAGE PROCESSING, P89
   Ventura A. D., 1990, IEEE T GEOSCI REMOTE, V28, P305
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   WOODS RP, 1993, J COMPUT ASSIST TOMO, V17, P536, DOI 10.1097/00004728-199307000-00004
   WOODS RP, 1992, J COMPUT ASSIST TOMO, V16, P620, DOI 10.1097/00004728-199207000-00024
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 44
TC 27
Z9 36
U1 1
U2 41
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1203
EP 1219
DI 10.1016/j.imavis.2009.12.005
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400004
DA 2024-07-18
ER

PT J
AU Chen, CH
   Yao, Y
   Page, D
   Abidi, B
   Koschan, A
   Abidi, M
AF Chen, Chung-Hao
   Yao, Yi
   Page, David
   Abidi, Besma
   Koschan, Andreas
   Abidi, Mongi
TI Camera handoff with adaptive resource management for multi-camera
   multi-object tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camera handoff; Multi-camera multi-object tracking; Resource management;
   Surveillance system
ID MOTION
AB Camera handoff is a crucial step to obtain a continuously tracked and consistently labeled trajectory of the object of interest in multi-camera surveillance systems. Most existing camera handoff algorithms concentrate on data association, namely consistent labeling, where images of the same object are identified across different cameras. However, there exist many unsolved questions in developing an efficient camera handoff algorithm. In this paper, we first design a trackability measure to quantitatively evaluate the effectiveness of object tracking so that camera handoff can be triggered timely and the camera to which the object of interest is transferred can be selected optimally. Three components are considered: resolution, distance to the edge of the camera's field of view (FOV), and occlusion. In addition, most existing real-time object tracking systems see a decrease in the frame rate as the number of tracked objects increases. To address this issue, our handoff algorithm employs an adaptive resource management mechanism to dynamically allocate cameras' resources to multiple objects with different priorities so that the required minimum frame rate is maintained. Experimental results illustrate that the proposed camera handoff algorithm can achieve a substantially improved overall tracking rate by 20% in comparison with the algorithm presented by Khan and Shah. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Chen, Chung-Hao] N Carolina Cent Univ, Dept Math & Comp Sci, Durham, NC 27713 USA.
   [Yao, Yi] GE Global Res Ctr, Nikayuna, NY 12309 USA.
   [Page, David] Third Dimens Technol LLC, Knoxville, TN 37920 USA.
   [Abidi, Besma; Koschan, Andreas; Abidi, Mongi] Univ Tennessee, Dept Elect Engn & Comp Sci, Imaging Robot & Intelligent Syst Lab, Knoxville, TN 37996 USA.
C3 University of North Carolina; North Carolina Central University; General
   Electric; University of Tennessee System; University of Tennessee
   Knoxville
RP Chen, CH (corresponding author), N Carolina Cent Univ, Dept Math & Comp Sci, Durham, NC 27713 USA.
EM chchen@nccu.edu; yyaol@utk.edu; davidpage@ieee.org; besma@utk.edu;
   akoschan@utk.edu; abidi@utk.edu
OI Page, David/0000-0003-3353-4300
FU University Research Program in Robotics [DOE-DE-FG52-2004NA25589]
FX This work was supported in part by the University Research Program in
   Robotics under Grant DOE-DE-FG52-2004NA25589.
CR [Anonymous], 2005, IEEE C COMP VIS PATT
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], PETS PERFORMANCE EVA
   Balcells M, 2005, PATTERN ANAL APPL, V7, P373, DOI 10.1007/s10044-004-0237-y
   BELEZNAI C, 2006, 18 INT C PATT REC JU
   Black J, 2001, P PERF EV TRACK SURV
   Calderara S, 2005, 13 INT C IM AN PROC
   Calderara S, 2008, IEEE T PATTERN ANAL, V30, P354, DOI 10.1109/TPAMI.2007.70814
   CHEN CH, 2007, T AM NUCL SOC WA NOV
   Choi JY, 2007, LECT NOTES COMPUT SC, V4815, P649
   DESILVA GC, 2005, IEEE INT C MULT EXP
   Fleuret F, 2008, IEEE T PATTERN ANAL, V30, P267, DOI 10.1109/TPAMI.2007.1174
   GULER S, 2003, IEEE P 32 APPL IM PA
   HAN M, 2004, IEEE C COMP VIS PATT
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P663, DOI 10.1109/TPAMI.2006.80
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Huang L, 2004, IEEE T VEH TECHNOL, V53, P547, DOI 10.1109/TVT.2003.823290
   JAVED O, 2003, IEEE INT C COMP VIS
   Kang J, 2003, IEEE INT C COMP VIS
   KANG J, 2005, IEEE WORKSH MOT VID
   KELLY P, 1995, P ACM MULT 95 MAY
   Khan S, 2003, IEEE T PATTERN ANAL, V25, P1355, DOI 10.1109/TPAMI.2003.1233912
   KLENNROCK L, 1975, QUEUING SYSTEMS THEO, V1
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   LIEN KC, 2006, 18 INT C PATT REC JU
   Lim FL, 2007, J VLSI SIG PROC SYST, V49, P343, DOI 10.1007/s11265-007-0091-4
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LUO X, 2005, IEEE C ADV VID SIGN
   NAGAI Y, 2005, 2 IFIP INT C WIR OPT
   Panneerselvam R., 2004, RES METHODOLOGY
   SEBE IO, 2005, SPIE DEF SEC S
   Shah M, 2003, MACH VISION APPL, V14, P210, DOI 10.1007/s00138-003-0124-3
   TIVEDI KS, 2001, PROBABILITY STAT REL
   Yao Y., 2008, P IEEE C COMP VIS PA
   YAO Y, 2006, IEEE INT C IM PROC A
   YAO Y, 2006, IEEE INT C ADV VID S
NR 36
TC 16
Z9 18
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 851
EP 864
DI 10.1016/j.imavis.2009.10.013
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200001
DA 2024-07-18
ER

PT J
AU Wei, W
   Xin, Y
AF Wei, Wang
   Xin, Yang
TI Rapid, man-made object morphological segmentation for aerial images
   using a multi-scaled, geometric image analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Man-made object segmentation; Multi-scaled geometric image analysis;
   Watershed; The non-subsampled contourlet transform
AB This paper describes a man-made object segmentation method for aerial images based on a modified watershed segmentation algorithm. Our segmentation procedure includes three steps: (I) a multi-scaled geometric image analysis of aerial images by the non-subsampled contourlet transform (NSCT) method, (2) watershed segmentation, and (3) region classification of man-made objects. First, background of multi-scaled geometric image analysis is introduced briefly, and NSCT is used to represent the features for the Purpose of man-made object segmentation. Thanks to the properties of NSCT, it not only avoids pseudo-Gibbs phenomena around singularities in image de-noising with regard to shift invariance, but it also enriches the set of basis functions, which makes it possible to extract orientational contour of man-made objects more effectively. In the NSCT decomposition step, the best basis selection is employed for ensuring maximum information content. Second, the "texture gradient" of combined features is calculated based on the first NSCT decomposition step and the resulting best basis selection, afterward the watershed transform is applied. According to their feature values, the aerial images are divided into several homogenous regions. Third, the fractional Brownian motion (fBm) model is used to determine the man-made object regions. Last, the experimental results show that the outcome of man-made object segmentation becomes more continuous and satisfying as a result of the homogenous texture-regions extraction and the modified watershed procedure. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Wei, Wang; Xin, Yang] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
C3 Shanghai Jiao Tong University
RP Wei, W (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
EM wangwei2002@sjtu.edu.cn; yangxin@sjtu.edu.cn
RI liu, sha/JXL-6600-2024; cai, bo/G-1491-2010
FU National Natural Science Foundation of China [60572154]
FX The work described in this paper was substantially supported by National
   Natural Science Foundation of China (No. 60572154). The authors would
   like to thank the anonymous reviewers for their constructive comments,
   and thank Sharon Ryan and Victor C. Wong for their kindly efforts to
   proofread and edit this paper.
CR BEUCHER S, 1979, P IEEE INT WORKSH IM
   Candes E.J., 1999, MONOSCALE RIDGELETS
   Candes E.J., 1998, Ridgelets: Theory and Applications
   Candes E.J., 1999, Curvelets - a surprisingly effective nonadaptive representation for objects with edges
   CANDES EJ, 2005, APPL COMPUT
   CARLOTTO MJ, 1996, GEOSCI REMOTE SENS S, V1, P34
   Chen SSB, 1998, SIAM J SCI COMPUT, V20, P33, DOI 10.1137/S1064827596304010
   Coifman R.R., TRANSLATION INVARIAN, P19956
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   COOPER BE, 1994, ELECTRON LETT, V30, P554, DOI 10.1049/el:19940287
   Cunha A. L., 2005, IEEE T IMAGE PROCESS, P1
   DAUBECHIES I, 1988, IEEE T INFORM THEORY, V34, P605, DOI 10.1109/18.9761
   Do MN, 2003, P SOC PHOTO-OPT INS, V5207, P560, DOI 10.1117/12.505948
   Do MN, 2002, CONF REC ASILOMAR C, P497
   DO MN, 2001, THESIS SWISS FEDERAL
   Donoho DL, 2000, P SOC PHOTO-OPT INS, V4056, P12, DOI 10.1117/12.381679
   DUBUF JMH, 1990, PATTERN RECOGN, V23, P291, DOI 10.1016/0031-3203(90)90017-F
   DUBUF JMH, DUBUF BIGUN TEXTURE
   ESLAMI R, 2003, 27 AS C SIGN SYST CO, V2, P1982
   Hill PR, 2003, IEEE T IMAGE PROCESS, V12, P1618, DOI 10.1109/TIP.2003.819311
   Jung CR, 2005, IMAGE VISION COMPUT, V23, P661, DOI 10.1016/j.imavis.2005.03.001
   Kim BG, 2003, PATTERN RECOGN LETT, V24, P2995, DOI 10.1016/S0167-8655(03)00160-0
   Levitt S, 1997, COMSIG '97 - PROCEEDINGS OF THE 1997 SOUTH AFRICAN SYMPOSIUM ON COMMUNICATIONS AND SIGNAL PROCESSING, P75, DOI 10.1109/COMSIG.1997.629985
   Li J, 2000, IEEE T SIGNAL PROCES, V48, P517, DOI 10.1109/78.823977
   LU Y, 2003, P SPIE C WAV APPL SI
   MALLAT SG, 1993, IEEE T SIGNAL PROCES, V41, P3397, DOI 10.1109/78.258082
   MATALON B, 2005, P SOC PHOTO-OPT INS, V5914, P1
   Mercier G, 2006, IEEE T GEOSCI REMOTE, V44, P2839, DOI 10.1109/TGRS.2006.881078
   Nguyen TT, 2005, IEEE T SIGNAL PROCES, V53, P3895, DOI 10.1109/TSP.2005.855410
   Reno AL, 1999, SECOND IEEE WORKSHOP ON VISUAL SURVEILLANCE (VS'99), PROCEEDINGS, P33, DOI 10.1109/VS.1999.780266
   Solka JL, 1998, IEEE T PATTERN ANAL, V20, P852, DOI 10.1109/34.709607
NR 31
TC 10
Z9 16
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 626
EP 633
DI 10.1016/j.imavis.2009.10.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600008
DA 2024-07-18
ER

PT J
AU Nakib, A
   Oulhadj, H
   Siarry, P
AF Nakib, A.
   Oulhadj, H.
   Siarry, P.
TI A thresholding method based on two-dimensional fractional
   differentiation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Two-dimensional fractional differentiation; Image thresholding; Image
   segmentation
ID IMAGE; ENTROPY
AB In this paper, we present a new thresholding technique based on two-dimensional fractional differentiation, that was obtained through the extension of the one-dimensional fractional differentiation. A new geometric interpretation of the two-dimensional fractional differentiation is also presented in the paper. The proposed method exploits the properties and the interpretations of the two-dimensional fractional differentiation. It is based on the assumption that there is a dependency between the pixels' gray-levels, that is translated into a correlation between pixels describing the same object. The effectiveness of the proposed method is demonstrated by using examples from real-world and synthetic images. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Nakib, A.; Oulhadj, H.; Siarry, P.] Univ Paris 12, LISSI, EA 3956, F-94010 Creteil, France.
C3 Universite Paris-Est-Creteil-Val-de-Marne (UPEC)
RP Siarry, P (corresponding author), Univ Paris 12, LISSI, EA 3956, 61 Ave Gen Gaulle, F-94010 Creteil, France.
EM nakib@univ-paris12.fr; oulhadj@univ-paris12.fr; siarry@univ-paris12.fr
RI nakib, amir/ABH-3646-2020
OI nakib, amir/0000-0001-9620-9324
CR Battaglia JL, 2001, INT J HEAT MASS TRAN, V44, P2671, DOI 10.1016/S0017-9310(00)00310-0
   Bazi Y, 2007, PATTERN RECOGN, V40, P619, DOI 10.1016/j.patcog.2006.05.006
   Borsotti M, 1998, PATTERN RECOGN LETT, V19, P741, DOI 10.1016/S0167-8655(98)00052-X
   de Albuquerque MP, 2004, PATTERN RECOGN LETT, V25, P1059, DOI 10.1016/j.patrec.2004.03.003
   FERDI Y, 2000, ITBM RBM, V21, P205
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Mathieu B, 2003, SIGNAL PROCESS, V83, P2421, DOI 10.1016/S0165-1684(03)00194-4
   Nakib A, 2007, SIGNAL PROCESS, V87, P2516, DOI 10.1016/j.sigpro.2007.04.001
   NAKIB A, 2009, ENG APPL AR IN PRESS
   Nakib A., 2005, C SOCIETE FRANCAISE, P134
   Ng HF, 2006, PATTERN RECOGN LETT, V27, P1644, DOI 10.1016/j.patrec.2006.03.009
   Oldham K., 1974, The Fractional Calculus, DOI DOI 10.1017/S0308210500019648
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Oustaloup A, 1996, MATH COMPUT SIMULAT, V41, P209, DOI 10.1016/0378-4754(95)00071-2
   Ramus-Serment C, 2002, CHAOS SOLITON FRACT, V14, P479, DOI 10.1016/S0960-0779(01)00223-5
   Sahoo PK, 2006, PATTERN RECOGN LETT, V27, P520, DOI 10.1016/j.patrec.2005.09.017
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   SNYDER W, 1990, PATTERN RECOGN LETT, V11, P803, DOI 10.1016/0167-8655(90)90034-Y
   WESZKA JS, 1979, IEEE T SYST MAN CYB, V9, P38
   Yin PY, 1999, SIGNAL PROCESS, V72, P85, DOI 10.1016/S0165-1684(98)00167-4
   Zahara E, 2005, PATTERN RECOGN LETT, V26, P1082, DOI 10.1016/j.patrec.2004.10.003
NR 22
TC 34
Z9 38
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1343
EP 1357
DI 10.1016/j.imavis.2008.12.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200011
DA 2024-07-18
ER

PT J
AU Sung, J
   Kim, D
AF Sung, Jaewon
   Kim, Daijin
TI Real-time facial expression recognition using STAAM and layered GDA
   classifier
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active appearance model; Stereo active appearance model; Facial
   expression recognition; Face tracking; Generalized discriminant
   analysis; A layered GDA classifier
ID ACTIVE APPEARANCE MODELS
AB This paper proposes a real-time person independent facial expression recognition in two parts: one is a model fitting part using a proposed stereo active appearance model (STAAM) and another is a person independent facial expression recognition using a layered generalized discriminant analysis (GDA) classifier. The STAAM fitting algorithm uses multiple calibrated perspective cameras to compute the 3D shape and rigid motion parameters. The use of calibration information reduces the number of model parameters, restricts the degree of freedom in the model parameters, and increases the accuracy and speed of fitting. The STAAM uses a modified simultaneous update fitting method that reduces the fitting computation greatly. Also, the layered GDA classifier combines 3D shape and 2D appearance to improve the recognition performance of person independent facial expressions. Experimental results show that (1) the STAAM shows a better fitting stability than the existing multiple-view AAM (MVAAM), (2) the modified simultaneous update algorithm accelerates the AAM fitting speed, and (3) the combination of the 3D shape and 2D appearance features using a layered GDA classifier improves the performance of facial expression recognition greatly. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Sung, Jaewon; Kim, Daijin] Pohang Univ Sci & Technol, Dept Comp Sci & Engn, Pohang 790784, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP Kim, D (corresponding author), Pohang Univ Sci & Technol, Dept Comp Sci & Engn, San 31, Pohang 790784, South Korea.
EM jwsung@postech.ac.kr; dkim@postech.ac.kr
FU Korea Science and Engineering Foundation (KOSEF)
   [R112002105070030(2008)]; Ministry of Knowledge Economy
FX This work was partially supported by the Korea Science and Engineering
   Foundation (KOSEF) through the Biometrics Engineering Research Center
   (BERC) at Yonsei University (R112002105070030(2008)). Also, this work
   was partially supported by the Intelligent Robotics Development Program,
   one of the 21st Century Frontier R&D Programs funded by the Ministry of
   Knowledge Economy.
CR Ahlberg J, 2003, INT J IMAG SYST TECH, V13, P8, DOI 10.1002/ima.10042
   [Anonymous], NEURAL COMPUTATION
   [Anonymous], BRIT MACH VIS C
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Chen Q, 2001, J VLSI SIG PROC SYST, V27, P127, DOI 10.1023/A:1008131816432
   CHUANG E, 2002, PACIFIC GRAPHICS
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   COHEN I, 2005, INT C COMP VIS
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Ekman P., 1978, Facial action coding system
   Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232
   Gokturk S. B., 2002, IEEE INT C AUT FAC G
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   GROSS R, 2003, CMURITR0305
   KANADE T, 1981, INT JOINT C ART INT, P674
   Koterba S., 2005, INT C COMP VIS
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   MICHEL P, 2003, INT C MULT INT
   MITTRAPIYANURUK P, 2004, INT C ROB AUT
   SUNG J, 2006, INT C PATT REC
   SUNG J, 2006, INT C IM PROC
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   WANG H, 2003, INT C COMP VIS
   XIAO J, 2004, IEEE C COMP VIS PATT
   XIAO J, 2002, IEEE INT C AUT FAC G
   ZHENG W, 2004, INT S NEUR NETW, P947
NR 29
TC 20
Z9 24
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1313
EP 1325
DI 10.1016/j.imavis.2008.11.010
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200008
DA 2024-07-18
ER

PT J
AU Zhang, YH
   Zhang, YS
   He, ZF
   Tang, XY
AF Zhang, Yinhui
   Zhang, Yunsheng
   He, Zifen
   Tang, Xiangyang
TI Multiscale fusion of wavelet-domain hidden Markov tree through graph cut
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Wavelet-domain hidden Markov tree; Multiscale fusion; Graph cut; Tobacco
   leaf inspection
ID SEGMENTATION
AB Since object boundaries appear blurry, reduced localization accuracy of wavelet-domain hidden Markov tree-based (WHMT) method poses a problem during the object extraction process. A novel approach to improve localization accuracy by fusing multiscale information of the tree model is presented. We start with calculating the multiscale classification likelihoods of wavelet coefficients by expectation-maximization (EM) algorithm. Energy function is then generated by combining boundary term estimated by classification likelihoods with regional term obtained by approximation coefficients. Through energy minimization via graph cuts, objects are extracted accurately from the images. A performance measure for tobacco leaf inspection is used to evaluate our algorithm. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Zhang, Yinhui; Zhang, Yunsheng; He, Zifen] Kunming Univ Sci & Technol, Fac Mech & Elect Engn, Kunming 650093, Peoples R China.
   [Tang, Xiangyang] Kunming Shipbldg Design & Res Inst, Kunming 650051, Peoples R China.
C3 Kunming University of Science & Technology
RP Zhang, YH (corresponding author), Kunming Univ Sci & Technol, Fac Mech & Elect Engn, Xuefu Rd 253, Kunming 650093, Peoples R China.
EM yinhui_z@yahoo.com.cn; zys0805@sina.com
RI liu, shilong/JZD-8395-2024
CR Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Choi H, 2001, IEEE T IMAGE PROCESS, V10, P1309, DOI 10.1109/83.941855
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DO MN, 2000, P SPIE C WAV APPL SI, P122
   FAN G, THESIS OKLAHOMA
   FAN GL, 2003, IEEE T CIRCUITS SYST, V50
   Ferrari RJ, 2007, PATTERN RECOGN, V40, P1148, DOI 10.1016/j.patcog.2006.07.007
   Gonzalez RC., 2011, DIGITAL IMAGE PROCES
   He ZY, 2008, PATTERN RECOGN, V41, P1295, DOI 10.1016/j.patcog.2007.08.017
   KATO Z, 1994, THESIS INRIA SOPHIA
   Li K, 2006, IEEE T PATTERN ANAL, V28, P119, DOI 10.1109/TPAMI.2006.19
   Lombaert H, 2005, IEEE I CONF COMP VIS, P259
   Mor E, 2005, IMAGE VISION COMPUT, V23, P1150, DOI 10.1016/j.imavis.2005.07.011
   Romberg JK, 2001, IEEE T IMAGE PROCESS, V10, P1056, DOI 10.1109/83.931100
   Sun JX, 2004, PATTERN RECOGN, V37, P1315, DOI 10.1016/j.patcog.2003.11.006
   Xu Q, 2005, PATTERN RECOGN LETT, V26, P1710, DOI 10.1016/j.patrec.2005.01.013
   Ye Z, 2002, INT C PATT RECOG, P729, DOI 10.1109/ICPR.2002.1048406
   Zhang YH, 2007, LECT NOTES COMPUT SC, V4842, P662
   Zhang YH, 2008, PROCEEDINGS OF THE 27TH CHINESE CONTROL CONFERENCE, VOL 4, P495, DOI 10.1109/CHICC.2008.4605142
NR 22
TC 9
Z9 10
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1402
EP 1410
DI 10.1016/j.imavis.2008.12.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200016
DA 2024-07-18
ER

PT J
AU Fauzi, MFA
   Lewis, PH
AF Fauzi, Mohammad Faizal Ahmad
   Lewis, Paul H.
TI Query by low-quality image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Content-based image retrieval; Low-quality image analysis; Wavelet
   transform
ID TEXTURE CLASSIFICATION; WAVELET; DECOMPOSITION; RETRIEVAL
AB The motivation for research on low-quality images comes from a requirement by some museums to respond to queries for pictorial information, submitted in the form of fax messages or other low-quality monochrome images of works of art. The museums have databases of high-resolution images of their artefact collections and the person submitting the query is asking typically whether the museum holds the artwork shown or perhaps some similar work. Often the query image will have no associated meta-data and will be produced from a low-resolution picture of the original artwork. The resulting poor quality image, received by the museum, leads to very poor retrieval accuracy when the fax is used in standard query by example searches using, for example, colour, spatial colour or texture matching algorithms. We propose a special retrieval algorithm in order to improve the retrieval accuracy in query by low-quality image application and evaluate it in comparison with more conventional algorithms. Throughout this paper, fax images will be used as the main source of low-quality image for query by low-quality image experiments. Nonetheless, some other forms of low-quality image will also be considered. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Fauzi, Mohammad Faizal Ahmad] Multimedia Univ, Fac Engn, Cyberjaya 63100, Selangor, Malaysia.
   [Lewis, Paul H.] Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
C3 Multimedia University; University of Southampton
RP Fauzi, MFA (corresponding author), Multimedia Univ, Fac Engn, Cyberjaya 63100, Selangor, Malaysia.
EM faizal1@mmu.edu.my; phl@ecs.soton.ac.uk
RI Fauzi, Mohammad Faizal Ahmad/J-9555-2012
OI Ahmad Fauzi, Mohammad Faizal/0000-0001-5382-6269
FU Faculty of Engineering, Multimedia University, Malaysia; School of
   Electronics and Computer Science at the University of Southampton, UK;
   EU [IST_1999_11978]
FX The authors are grateful to the Faculty of Engineering, Multimedia
   University, Malaysia and the School of Electronics and Computer Science
   at the University of Southampton, UK for financial support. We are also
   grateful to the EU for their support under Grant No. IST_1999_11978 (The
   Artiste Project), and to one of our collaborators, the Victoria and
   Albert Museum (London, UK) for use of their images.
CR Aujol JF, 2003, IEEE T IMAGE PROCESS, V12, P1634, DOI 10.1109/TIP.2003.819309
   Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   DAUBECHIES I, 1990, IEEE T INFORM THEORY, V36, P961, DOI 10.1109/18.57199
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   GEVERS T, 1997, IMAGE DATABASES MULT, P25
   Gonzales R., 1992, DIGITAL IMAGE PROCES
   GRAPS A, 1995, IEEE COMPUT SCI ENG, V2, P50, DOI 10.1109/99.388960
   LAINE A, 1993, IEEE T PATTERN ANAL, V15, P1186, DOI 10.1109/34.244679
   Li Z.-N., 2004, Fundamentals of Multimedia
   Ma WY, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB256
   Mallat S, 1996, P IEEE, V84, P604, DOI 10.1109/5.488702
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   *MATHWORKS INC, WAV TOOLB MATL VERS
   Nachtegael M, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P11, DOI 10.1109/FUZZ.2001.1007232
   NGUNYEN T, 1994, P ICCS, P188
   PENTLAND A, 1996, INT J COMPUTER VISIO
   PETERS RA, 1995, IEEE T IMAGE PROCESS, V4, P554, DOI 10.1109/83.382491
   Pun CM, 2004, IEEE T PATTERN ANAL, V26, P1228, DOI 10.1109/TPAMI.2004.67
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Swanson MD, 1996, IEEE T IMAGE PROCESS, V5, P1637, DOI 10.1109/83.544571
   Umbaugh SE., 1998, Computer Vision and Image Processing: A practical approach using CVIP tools, V6st ed.
   UNSER M, 1995, IEEE T IMAGE PROCESS, V4, P1549, DOI 10.1109/83.469936
   Wong HS, 2000, IEEE SYS MAN CYBERN, P1551, DOI 10.1109/ICSMC.2000.886078
   Yoshioka M, 1997, IEEE SYS MAN CYBERN, P2650, DOI 10.1109/ICSMC.1997.635335
   Zhang Q, 1996, PROCEEDINGS OF THE IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P218, DOI 10.1109/IAI.1996.493756
NR 28
TC 2
Z9 2
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 713
EP 724
DI 10.1016/j.imavis.2008.07.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000012
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Vatsa, M
   Singh, R
   Noore, A
AF Vatsa, Mayank
   Singh, Richa
   Noore, Afzel
TI Feature based RDWT watermarking for multimodal biometric system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Watermarking; Redundant Discrete Wavelet Transform; Face
   recognition; Voice recognition; Multimodal biometrics
ID FUSION
AB This paper presents a 3-level RDWT biometric watermarking algorithm to embed the voice biometric MFC coefficients in a color face image of the same individual for increased robustness, security and accuracy. Phase congruency model is used to compute the embedding locations which preserves the facial features from being watermarked and ensures that the face recognition accuracy is not compromised. The proposed watermarking algorithm uses adaptive user-specific watermarking parameters for improved performance. Using face, voice and multimodal recognition algorithms, and statistical evaluation, we show that the proposed RDWT watermarking algorithm is robust to different frequency and geometric attacks, and provides the multimodal biotnetric verification accuracy of 94%. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Vatsa, Mayank; Singh, Richa; Noore, Afzel] W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
C3 West Virginia University
RP Noore, A (corresponding author), W Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
EM mayankv@csee.wvu.edu; richas@csee.wvu.edu; noore@csee.wvu.edu
RI Vatsa, Mayank/AAR-7199-2020; Singh, Richa/M-9961-2017
OI Vatsa, Mayank/0000-0001-5952-2274; Singh, Richa/0000-0003-4060-4573
FU National Institute of Justice, United States Department of Justice.
   [2003-RC-CX-K001]
FX Authors would like to acknowledge Dr. M. Tistarelli and Dr. J. Bigun for
   their valuable suggestions. Authors thank the reviewers for their
   helpful and constructive comments. This research (Award No.
   2003-RC-CX-K001) was supported by the Office of Science and Technology,
   National Institute of Justice, United States Department of Justice.
CR [Anonymous], [No title captured]
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   ATICK JJ, 1996, NETWORK COMPUTATION, V7, P477
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bengio S., 2004, SPEAKER LANG RECOGNI, P237
   BOLLE RM, 2004, P SIN, P27
   Campbell J., 1999, Biometrics: Personal Identification in Networked Society
   Cao JG, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P277, DOI 10.1109/ICIP.2001.958478
   Cox IJ, 1996, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.1996.517076
   Dodis Y, 2004, LECT NOTES COMPUT SC, V3027, P523
   Fowler JE, 2005, IEEE SIGNAL PROC LET, V12, P629, DOI 10.1109/LSP.2005.853048
   Gunsel B, 2002, PATTERN RECOGN, V35, P2739, DOI 10.1016/S0031-3203(01)00250-3
   Hazen T., 2003, Proceedings of the 5th international conference on Multimodal Interfaces, P289
   Hien TD, 2006, SOFT COMPUT, V10, P1135, DOI 10.1007/s00500-005-0036-4
   Hien TD, 2006, SIGNAL PROCESS, V86, P2981, DOI 10.1016/j.sigpro.2005.12.003
   HIGGINS AL, 1993, P ICASSP, V2, P375
   HUA L, 2002, P IEEE INT C MULT EX, V2, P553
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jain AK, 2002, IEEE IMAGE PROC, P57
   Jain AK, 2003, IEEE T PATTERN ANAL, V25, P1494, DOI 10.1109/TPAMI.2003.1240122
   Jain AK, 2002, INT C PATT RECOG, P756, DOI 10.1109/ICPR.2002.1048100
   Kundur D, 1998, INT CONF ACOUST SPEE, P2969, DOI 10.1109/ICASSP.1998.678149
   Petitcolas FAP, 1999, P IEEE, V87, P1062, DOI 10.1109/5.771065
   Ratha N.K., 2000, P ACM MULTIMEDIA, P127
   Rioul O, 1991, IEEE SIGNAL PROC MAG, V8, P14, DOI 10.1109/79.91217
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Singh R, 2006, LECT NOTES COMPUT SC, V4338, P941
   Singh S.K., 2003, TAMKANG J SCI ENG, V6, P227
   Soutar C., 1999, Biometric Encryption, ICSA Guide to Cryptography
   STRANG G, 1996, WAVELET FILTER BANKS
   Ten Daubechies I., 1992, lecture on wavelets
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Uludag U, 2004, P IEEE, V92, P948, DOI 10.1109/JPROC.2004.827372
   Vatsa M., 2004, P WORKSHOP BIOMETRIC, P5
NR 34
TC 58
Z9 64
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 2
PY 2009
VL 27
IS 3
SI SI
BP 293
EP 304
DI 10.1016/j.imavis.2007.05.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 393QA
UT WOS:000262386600008
DA 2024-07-18
ER

PT J
AU Li, FH
   Woodham, RJ
AF Li, Fahong
   Woodham, Robert J.
TI Video analysis of hockey play in selected game situations
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Visual tracking; Motion analysis; Finite state machine
AB We present a proof of concept system to represent and reason about hockey play. The system takes as input player motion trajectory data tracked from game video and supported by knowledge of hockey strategy, game situation and specific player profiles. The raw motion trajectory data consists of space-time point sequences of player position registered to rink coordinates. The raw data is augmented with knowledge of forward/backward skating, possession of the puck and specific player attributes (e.g., shoots left, shoots right). We use a Finite State Machine (FSM) model to represent our total knowledge of each given situation. Most state transitions correspond to specific player actions (e.g., pass, shoot). Each transition has an associated Event Evaluation Function (EEF) to assign an immediate "reward" to the associated action. EEFs can take into account each player's spatio-temporal trajectory. Based on the augmented trajectory data, the FSMs and the EEFs, we describe what happened in each identified situation, assess the outcome, estimate when and where key play choices were made, and attempt to predict whether better alternatives were available to achieve understood goals. A textual natural language description and a simple 2D graphic animation of the analysis are produced as the output. The design is flexible to allow the substitution of different analysis modules and extensible to allow the inclusion of additional hockey situations. This paper extends the one published in CRV2005. (C) 2006 Elsevier B.V. All rights reserved.
C1 [Li, Fahong; Woodham, Robert J.] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.
C3 University of British Columbia
RP Li, FH (corresponding author), Univ British Columbia, Dept Comp Sci, 2366 Main Mall, Vancouver, BC V6T 1Z4, Canada.
EM fhli@cs.ubc.ca; woodham@cs.ubc.ca
CR ANDRE E, 1988, P 8 EUR C ART INT EC, P449
   Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794
   GONG Y, 1995, IEEE INT C MULT COMP, P167
   HAREL D, 1987, SCI COMPUT PROGRAM, V8, P231, DOI 10.1016/0167-6423(87)90035-9
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   Intille SS, 1999, SIXTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-99)/ELEVENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE (IAAI-99), P518
   Kawashima T., 1994, Proceedings 1994 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.94CH3405-8), P690, DOI 10.1109/CVPR.1994.323777
   Koprinska I, 2001, SIGNAL PROCESS-IMAGE, V16, P477, DOI 10.1016/S0923-5965(00)00011-4
   LASHKIA G, 2003, 16 INT C VIS INT HAL
   LI F, 2004, THESIS U BRIT COLUMB
   Li FH, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P152
   Misu T, 2002, INT C PATT RECOG, P556, DOI 10.1109/ICPR.2002.1044792
   NAGEL HH, 1988, IMAGE VISION COMPUT, V6, P59, DOI 10.1016/0262-8856(88)90001-7
   Okuma K., 2004, PROC EUROPEAN C COMP, V1, P28
   Percival L., 1997, HOCKEY HDB
   Retz-Schmidt G., 1991, User Modeling and User-Adapted Interaction, V1, P173, DOI 10.1007/BF00154477
   *ROBOCUP, ROBOCUP OFF SIT
   Schirra J. R. J., 1987, Applied Artificial Intelligence, V1, P287, DOI 10.1080/08839518708927976
   SMITH MA, 1996, HOCKEY PLAY BOOK TEA
   Stone P, 2000, AUTON ROBOT, V8, P345, DOI 10.1023/A:1008942012299
   Sudhir G, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P81, DOI 10.1109/CAIVD.1998.646036
   Xie LX, 2004, PATTERN RECOGN LETT, V25, P767, DOI 10.1016/j.patrec.2004.01.005
   Zhou W., 2000, ACM Workshops on Multimedia, P213
   HOCKEY VIDEOS
   HIGH LEVEL STRUCTURE
   PLAY MANAGER HOCKEY
   SUPER PUCK FOXTRAX
NR 27
TC 12
Z9 13
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 45
EP 58
DI 10.1016/j.imavis.2006.10.010
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700006
DA 2024-07-18
ER

PT J
AU Lu, CH
   Tsai, DM
AF Lu, Chi-He
   Tsai, Du-Ming
TI Independent component analysis-based defect detection in patterned
   liquid crystal display surfaces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE defect detection; surface inspection; TFT-LCD panels; independent
   component analysis
ID FACE RECOGNITION; SEPARATION; INSPECTION; ALGORITHMS
AB In this paper, we propose a machine vision approach for automatic detection of micro defects in periodically patterned surfaces and, especially, aim at thin film transistor liquid crystal display (TFT-LCD) panels. The proposed method is based on an image reconstruction scheme using independent component analysis (ICA). ICA is first applied to a faultless training image to determine the de-mixing matrix and the corresponding independent components (ICs). The ICs representing the global structure of the training image are then identified and the associated row vectors of those ICs in the de-mixing matrix are replaced with a de-mixing row representing the least structured region of the training image. The reformed de-mixing matrix is then used to reconstruct the TFT-LCD image under inspection. The resulting image can effectively remove the global structural pattern and preserve only local anomalies. A number of micro defects in different TFT-LCD panel surfaces are evaluated with the proposed method. The experiments show that the proposed method can well detect various ill-defined defects in periodically patterned surfaces. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Tsai, Du-Ming] Yuan Ze Univ, Dept Ind Engn & Management, Tao Yuan, Taiwan.
C3 Yuan Ze University
RP Tsai, DM (corresponding author), Yuan Ze Univ, Dept Ind Engn & Management, 135 Yuan Tung Rd, Tao Yuan, Taiwan.
EM iedmtsai@saturn.yzu.edu.tw
OI Lu, Chi-Jie/0000-0002-7911-2253
CR Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Beckmann CF, 2004, IEEE T MED IMAGING, V23, P137, DOI 10.1109/TMI.2003.822821
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Bell AJ, 1997, VISION RES, V37, P3327, DOI 10.1016/S0042-6989(97)00121-1
   Chen YW, 2002, INT C PATT RECOG, P351, DOI 10.1109/ICPR.2002.1047866
   Chou PB, 1997, MACH VISION APPL, V9, P201, DOI 10.1007/s001380050041
   CICHOCKI A., 2002, Adaptive Blind Signal and Image Processing: Learning Algorithms and Applications
   Déniz O, 2003, PATTERN RECOGN LETT, V24, P2153, DOI 10.1016/S0167-8655(03)00081-3
   Deville Y, 1996, IEICE T FUND ELECTR, VE79A, P1694
   Hawthorne J, 2000, LASER FOCUS WORLD, V36, P271
   Henly F.J., 1991, SID S, V32, P686
   Hoyer PO, 2000, NETWORK-COMP NEURAL, V11, P191, DOI 10.1088/0954-898X/11/3/302
   Hurri J., FASTICA PACKAGE
   Hurri J., 1996, Proc. NORSIG'96 (Nordic Signal Proc. Symposium), P475
   Hyvärinen A, 1999, IEEE T NEURAL NETWOR, V10, P626, DOI 10.1109/72.761722
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Ikeda S, 2000, NEURAL NETWORKS, V13, P1063, DOI 10.1016/S0893-6080(00)00071-X
   James CJ, 2003, IEEE T BIO-MED ENG, V50, P1108, DOI 10.1109/TBME.2003.816076
   Jenssen R, 2003, PATTERN RECOGN, V36, P2301, DOI 10.1016/S0031-3203(03)00131-6
   Jung TP, 2001, P IEEE, V89, P1107, DOI 10.1109/5.939827
   Kido T, 1995, IEEE J SEL TOP QUANT, V1, P993, DOI 10.1109/2944.488397
   Kim TK, 2004, PATTERN RECOGN, V37, P1873, DOI 10.1016/j.patcog.2004.01.019
   Koike Y, 1999, FUJITSU SCI TECH J, V35, P221
   Li SZ, 2005, IEEE T IMAGE PROCESS, V14, P705, DOI 10.1109/TIP.2005.847295
   Lu CJ, 2005, INT J ADV MANUF TECH, V25, P53, DOI 10.1007/s00170-003-1832-6
   Lu CJ, 2004, INT J PROD RES, V42, P4331, DOI 10.1080/00207540410001716480
   Manduchi R., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1054, DOI 10.1109/ICCV.1999.790387
   NAKASHIMA K, 1994, P 10 INT C INSTR MEA, P689
   NEWMAN TS, 1995, COMPUT VIS IMAGE UND, V61, P231, DOI 10.1006/cviu.1995.1017
   Park HM, 1999, ELECTRON LETT, V35, P2011, DOI 10.1049/el:19991358
   PARK JH, 2003, J SOC INF DISPLAY, V11, P283
   SOKOLOV SM, 1992, 1992 IEEE INTERNATIONAL CONF ON ROBOTICS AND AUTOMATION : PROCEEDINGS, VOLS 1-3, P1578, DOI 10.1109/ROBOT.1992.220027
   Tsai DM, 2005, INT J PROD RES, V43, P4589, DOI 10.1080/00207540500140732
   Vigário R, 2000, IEEE T BIO-MED ENG, V47, P589, DOI 10.1109/10.841330
   Yuen PC, 2002, PATTERN RECOGN, V35, P1247, DOI 10.1016/S0031-3203(01)00101-7
NR 36
TC 51
Z9 58
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 955
EP 970
DI 10.1016/j.imavis.2007.10.007
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800009
DA 2024-07-18
ER

PT J
AU Bin, TJ
   Lei, A
   Jiwen, C
   Wenjing, K
   Dandan, L
AF Bin, T. J.
   Lei, Ao
   Jiwen, Cui
   Wenjing, Kang
   Dandan, Liu
TI Subpixel edge location based on orthogonal Fourier-Mellin moments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE orthogonal Fourier-Mellin moment; subpixel edge location; rotation
   invariance
ID IMAGE-RECONSTRUCTION; REGISTRATION; RECOGNITION; ALGORITHM; OPERATOR;
   ZERNIKE
AB In order to satisfy the stringent requirements for edge location accuracies in such fields as medical image analysis and satellite remote sensing, an approach based on orthogonal Fourier-Mellin moments is proposed to use the lower radial orders and the rotation invariance of these moments to describe small objects in images, and edge location is accomplished by setting the edge in the vertical direction and analyzing the interrelationships among the orthogonal Fourier-Mellin moments with different orders and degrees, and consequently the specific characteristics of the edge can be fully extracted. Experimental results show that the proposed method can be used to achieve an edge location accuracy of 0.16 pixel for straight lines with noise and 0.23 pixel for curves with noise. It can therefore be concluded that the proposed method is an efficient approach to satisfy the stringent requirements for higher edge location accuracies in such fields as medical image analysis and satellite remote sensing. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Bin, T. J.; Lei, Ao; Jiwen, Cui; Wenjing, Kang; Dandan, Liu] Harbin Inst Technol, Ultra Precis Opt & Elect Instrument Engn Ctr, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Lei, A (corresponding author), Harbin Inst Technol, Ultra Precis Opt & Elect Instrument Engn Ctr, Harbin 150001, Peoples R China.
EM ac_lei@126.com
CR Althof RJ, 1997, IEEE T MED IMAGING, V16, P308, DOI 10.1109/42.585765
   [崔继文 CUI Jiwen], 2005, [光学技术, Optical Technology], V31, P779
   Derrode S, 2001, COMPUT VIS IMAGE UND, V83, P57, DOI 10.1006/cviu.2001.0922
   Ding Xing-hao, 2004, Journal of Applied Sciences, V22, P191
   GHOSAL S, 1993, PATTERN RECOGN, V26, P395
   Hsieh JW, 1997, IMAGE VISION COMPUT, V15, P511, DOI 10.1016/S0262-8856(96)00003-0
   Jang JH, 2002, PATTERN RECOGN, V35, P807, DOI 10.1016/S0031-3203(01)00073-5
   JENSEN K, 1995, IEEE T IMAGE PROCESS, V4, P285, DOI 10.1109/83.366477
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   Lee ES, 2003, IEEE T IMAGE PROCESS, V12, P826, DOI 10.1109/TIP.2003.811488
   LYVERS EP, 1989, IEEE T PATTERN ANAL, V11, P1293, DOI 10.1109/34.41367
   Ping ZL, 2000, OPT ENG, V39, P1260, DOI 10.1117/1.602488
   Qu YD, 2005, IMAGE VISION COMPUT, V23, P11, DOI 10.1016/j.imavis.2004.07.003
   SHEN J, 1995, PATTERN RECOGN, V28, P1159, DOI 10.1016/0031-3203(95)00005-K
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   Stone HS, 2001, IEEE T GEOSCI REMOTE, V39, P2235, DOI 10.1109/36.957286
   Sundaram R, 2003, OPT ENG, V42, P642, DOI 10.1117/1.1543564
NR 17
TC 58
Z9 72
U1 0
U2 23
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 563
EP 569
DI 10.1016/j.imavis.2007.07.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100008
DA 2024-07-18
ER

PT J
AU Dios, JRMD
   Arrue, BC
   Ollero, A
   Merino, L
   Gómez-Rodríguez, F
AF Dios, J. R. Martinez-de
   Arrue, B. C.
   Ollero, A.
   Merino, L.
   Gomez-Rodriguez, F.
TI Computer vision techniques for forest fire perception
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE perception systems; infrared and visual image processing; forest fires;
   sensor fusion
ID THRESHOLD SELECTION; AUTOMATIC DETECTION; SYSTEM
AB This paper presents computer vision techniques for forest fire perception involving measurement of forest fire properties (fire front, flame height, flame inclination angle, fire base width) required for the implementation of advanced forest fire-fighting strategies. The system computes a 3D perception model of the fire and could also be used for visualizing the fire evolution in remote computer systems. The presented system integrates the processing of images from visual and infrared cameras. It applies sensor fusion techniques involving also telemetry sensors, and GPS. The paper also includes some results of forest fire experiments. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Merino, L.] Univ Pablo Olavide, Escuela Politecn Super, Seville 41013, Spain.
   [Dios, J. R. Martinez-de; Arrue, B. C.; Ollero, A.; Gomez-Rodriguez, F.] Univ Seville, Escuela Super Ingn, Dpto Ing Sistemas & Automat, Seville 41092, Spain.
C3 Universidad Pablo de Olavide; University of Sevilla
RP Merino, L (corresponding author), Univ Pablo Olavide, Escuela Politecn Super, Crta Utrera,Km 1, Seville 41013, Spain.
EM jdedios@cartuja.us.es; barrue@cartuja.us.es; aollero@cartuja.us.es;
   Imercab@upo.es; gomezro@cartuja.us.es
RI Gomez Rodriguez, Francisco/F-3649-2012; Arrue Ulles, Begona
   Chiquinquira/O-9525-2015; Merino, Luis/B-2549-2013; Martinez de Dios,
   Jose Ramiro/C-2184-2015
OI Gomez Rodriguez, Francisco/0000-0001-8947-6408; Arrue Ulles, Begona
   Chiquinquira/0000-0003-1777-2675; Merino, Luis/0000-0003-4927-8647;
   Martinez de Dios, Jose Ramiro/0000-0001-9431-7831
CR [Anonymous], IEEE RSJ INT C INT R
   [Anonymous], 1994, Mathematical Programming
   Arrue BC, 2000, IEEE INTELL SYST APP, V15, P64, DOI 10.1109/5254.846287
   BARDSHAW A, 1991, IEEE C ADV ROB IN UK
   Coleman TF, 1996, SIAM J OPTIMIZ, V6, P418, DOI 10.1137/0806023
   Den Breejen E, 1998, P 3 INT C FOR FIR RE, P517
   DIERRE D, 2000, RES SPECIAL SESSION, P89
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Gunatilaka AH, 2001, IEEE T PATTERN ANAL, V23, P577, DOI 10.1109/34.927459
   Martinez-de Dios JR, 2006, INTELL AUTOM SOFT CO, V12, P419
   Martinez-de Dios JR, 2004, LECT NOTES COMPUT SC, V3211, P90
   Merino L, 2003, PROCEEDINGS OF THE 11TH INTERNATIONAL CONFERENCE ON ADVANCED ROBOTICS 2003, VOL 1-3, P351
   Merino L, 2006, J FIELD ROBOT, V23, P165, DOI 10.1002/rob.20108
   MOHAMADDJAFARI A, 1997, P 17 INT WORKSH MAX
   Ollero A, 2005, IEEE ROBOT AUTOM MAG, V12, P46, DOI 10.1109/MRA.2005.1458323
   Ollero A, 1999, CONTROL ENG PRACT, V7, P123, DOI 10.1016/S0967-0661(98)00141-5
   Phillips W, 2002, PATTERN RECOGN LETT, V23, P319, DOI 10.1016/S0167-8655(01)00135-0
   RIDLER TW, 1978, IEEE T SYST MAN CYB, V8, P630, DOI 10.1109/tsmc.1978.4310039
   San-Miguel-Ayanz J, 2005, NAT HAZARDS, V35, P361, DOI 10.1007/s11069-004-1797-2
   VIEGAS DX, 2002, P 4 INT C FOR FIR RE
   [No title captured]
NR 21
TC 102
Z9 112
U1 2
U2 25
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 550
EP 562
DI 10.1016/j.imavis.2007.07.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Junejo, IN
   Foroosh, H
AF Junejo, Imran N.
   Foroosh, Hassan
TI Euclidean path modeling for video surveillance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE path modeling; pedestrian surveillance; metric rectification; camera
   auto-calibration; trajectory clustering; route detection
ID SELF-CALIBRATION; CAMERA CALIBRATION; AUTOCALIBRATION; RECONSTRUCTION;
   SURFACES
AB In this paper, we address the issue of Euclidean path modeling in a single camera for activity monitoring in a multi-camera video surveillance system. The method consists of a path building training phase and a testing phase. During the unsupervised training phase, after auto-calibrating a camera and thereafter metric rectifying the input trajectories, a weighted graph is constructed with trajectories represented by the nodes, and weights determined by a similarity measure. Normalized-cuts are recursively used to partition the graph into prototype paths. Each path, consisting of a partitioned group of trajectories, is represented by a path envelope and an average trajectory. For every prototype path, features such as spatial proximity, motion characteristics, curvature, and absolute world velocity are then recovered directly in the rectified images or by registering to aerial views. During the testing phase, using our simple yet efficient similarity measures for these features, we seek a relation between the trajectories of an incoming sequence and the prototype path models to identify anomalous and unusual behaviors. Real-world pedestrian sequences are used to evaluate the steps, and demonstrate the practicality of the proposed approach. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Junejo, Imran N.; Foroosh, Hassan] Univ Cent Florida, CIL, Orlando, FL 32816 USA.
C3 State University System of Florida; University of Central Florida
RP Junejo, IN (corresponding author), Univ Cent Florida, CIL, 4000 Cent Florida Blvd, Orlando, FL 32816 USA.
EM ijunejo@cs.ucf.edu; foroosh@cs.ucf.edu
RI Junejo, Imran/ABA-2975-2020
CR Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694
   [Anonymous], MATRIX COMPUTATIONS
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   BOYD JE, 1999, INT C COMP VIS ICCV
   CAPRILE B, 1990, INT J COMPUT VISION, V4, P127, DOI 10.1007/BF00127813
   CIPOLLA R, 1999, P BRIT MACH VIS C, P382
   Colombo C, 2005, IEEE T PATTERN ANAL, V27, P99, DOI 10.1109/TPAMI.2005.14
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P321
   GRIMSON WEL, 1998, IEEE COMP SOC C COMP
   Habed A, 2006, IMAGE VISION COMPUT, V24, P498, DOI 10.1016/j.imavis.2006.01.013
   HARTLEY RI, 2004, MULTIPLE VIEW GOEMET
   JAVED O, 2002, 7 EUR C COMP VIS
   JAVED O, 2005, IEEE CVPR
   JOHNSON N, 1995, P BRIT MACH VIS C BM
   JUNEJO I, 2004, 17 C INT C PATT REC
   KANG J, 2003, P IEEE C COMP VIS PA
   Keogh E., 2002, Proceedings of the Twenty-eighth International Conference on Very Large Data Bases, P406
   KETTNAKER RZV, 1999, IEEE COMP SOC C COMP
   KHAN S, 2003, IEEE, V25
   Krahnstoever N., 2005, 10 IEEE INT C COMP V
   Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649
   Liebowitz D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P293, DOI 10.1109/ICCV.1999.791233
   Lv F., 2002, IEEE INT C PATT REC
   Makris D, 2002, IMAGE VISION COMPUT, V20, P895, DOI 10.1016/S0262-8856(02)00098-7
   Makris Dimitrios, 2004, IEEE C COMP VIS PATT
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   Press W. H., 1988, Numerical Recipes
   Semple JG., 1979, Algebraic Projective Geometry
   Seo Y, 2004, IMAGE VISION COMPUT, V22, P919, DOI 10.1016/j.imavis.2004.05.004
   SHEIKH Y, 2006, IEEE INT C COMP VIS
   SHEIKH Y, 2005, SPIE S DEF SEC
   Shi J., 2006, IEEE T PATTERN ANAL, V22, P888
   SHI J, 1998, P IEEE ICCV
   Sturm P, 1997, IMAGE VISION COMPUT, V15, P583, DOI 10.1016/S0262-8856(97)00015-2
   TIEU K, 2005, INT C COMP VIS
   Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Wong KYK, 2003, IEEE T PATTERN ANAL, V25, P147, DOI 10.1109/TPAMI.2003.1177148
   Wright E, 2005, PARTIAL ANSW, V3, P19
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 41
TC 14
Z9 17
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 512
EP 528
DI 10.1016/j.imavis.2007.07.006
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100005
DA 2024-07-18
ER

PT J
AU Bartoli, A
   Lapresté, JT
AF Bartoli, Adrien
   Lapreste, Jean-Thierry
TI Triangulation for points on lines
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE triangulation; Structure-From-Motion; point; line
ID VIEWS
AB Triangulation consists in finding a 3D point reprojecting the best as possible onto corresponding image points. It is classical to minimize the reprojection error, which, in the pinhole camera model case, is nonlinear in the 3D point coordinates. We study the triangulation of points lying on a 3D line, which is a typical problem for Structure-From-Motion in man-made environments. We show that the reprojection error can be minimized by finding the real roots of a polynomial in a single variable, which degree depends on the number of images. We use a set of transformations in 3D and in the images to make the degree of this polynomial as low as possible, and derive a practical reconstruction algorithm. Experimental comparisons with an algebraic approximation algorithm and minimization of the reprojection error using Gauss-Newton are reported for simulated and real data. Our algorithm finds the optimal solution with high accuracy in all cases, showing that the polynomial equation is very stable. It only computes the roots corresponding to feasible points, and can thus deal with a very large number of views-triangulation from hundreds of views is performed in a few seconds. Reconstruction accuracy is shown to be greatly improved compared to standard triangulation methods that do not take the line constraint into account. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Bartoli, Adrien; Lapreste, Jean-Thierry] Univ Clermont Ferrand, CNRS, LASMEA, Clermont Ferrand, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite Clermont
   Auvergne (UCA)
RP Bartoli, A (corresponding author), Univ Clermont Ferrand, CNRS, LASMEA, Clermont Ferrand, France.
EM Adrien.Bartoli@gmail.com
CR Acton F.S., 1990, Numerical Methods that Work
   BARTOLI A, 2004, P EUR C COMP VIS
   BARTOLI A, 2003, P INT C COMP VIS
   Chum O, 2005, COMPUT VIS IMAGE UND, V97, P86, DOI 10.1016/j.cviu.2004.03.004
   HARTLEY R, 2004, P INT C COMP VIS PAT
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   Luong QT, 1996, COMPUT VIS IMAGE UND, V64, P193, DOI 10.1006/cviu.1996.0055
   NISTER D, 2001, THESIS ROYAL I TECHN
   Oliensis J, 2002, IEEE T PATTERN ANAL, V24, P1618, DOI 10.1109/TPAMI.2002.1114853
   Schaefer HM, 2006, AM J TRANSPLANT, V6, P3, DOI 10.1111/j.1600-6143.2005.01196.x
   SCHAFFALITZKY F, 2002, P EUR C COMP VIS
   Schmid C, 2000, INT J COMPUT VISION, V40, P199, DOI 10.1023/A:1008135310502
   Tang AWK, 2006, PATTERN RECOGN, V39, P889, DOI 10.1016/j.patcog.2005.10.019
NR 14
TC 8
Z9 10
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 315
EP 324
DI 10.1016/j.imavis.2007.06.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Alpers, A
   Brunetti, S
AF Alpers, Andreas
   Brunetti, Sara
TI Stability results for the reconstruction of binary pictures from two
   projections
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE discrete tomography; stability; image reconstruction; uniqueness;
   projections
ID COMPUTATIONAL-COMPLEXITY; DISCRETE TOMOGRAPHY; LATTICE SETS
AB In the present paper we mathematically prove several stability results concerning the problem of reconstructing binary pictures from their noisy projections taken from two directions. Stability is a major requirement in practice, because projections are often affected by noise due to the nature of measurements. Reconstruction from projections taken along more than two directions is known to be a highly unstable task. Contrasting this result we prove several theorems showing that reconstructions from two directions closely resemble the original picture when the noise level is low and the original picture is uniquely determined by its projections. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Munich, Zentrum Math, D-85747 Munich, Germany.
   Univ Siena, Dipartimento Sci Matemat & Informat, I-53100 Siena, Italy.
C3 University of Munich; University of Siena
RP Alpers, A (corresponding author), Cornell Univ, Sch OR&IE, Rhodes Hall, Ithaca, NY 14853 USA.
EM alpers@orie.cornell.edu
RI Brunetti, Sara/I-5986-2012
OI Alpers, Andreas/0000-0003-0663-6037; BRUNETTI, Sara/0000-0001-8607-6900
CR Alpers A, 2006, SIAM J DISCRETE MATH, V20, P227, DOI 10.1137/040617443
   Alpers A, 2005, LECT NOTES COMPUT SC, V3429, P92
   Alpers A., 2001, LECT NOTES COMPUTER, V2243, P175
   Alpers A., 2003, THESIS TU MUNCHEN
   [Anonymous], 1957, Pacific Journal of Mathematics
   BRUALDI RA, 1980, LINEAR ALGEBRA APPL, V33, P159, DOI 10.1016/0024-3795(80)90105-6
   Brunetti S, 2005, DISCRETE APPL MATH, V147, P207, DOI 10.1016/j.dam.2004.09.012
   Brunetti S, 2003, LECT NOTES COMPUT SC, V2886, P398
   Fishburn P, 1997, DISCRETE APPL MATH, V75, P39, DOI 10.1016/S0166-218X(96)00083-2
   Gardner RJ, 1999, DISCRETE MATH, V202, P45, DOI 10.1016/S0012-365X(98)00347-1
   Gardner RJ, 2000, THEOR COMPUT SCI, V233, P91, DOI 10.1016/S0304-3975(97)00298-3
   Haber RM., 1960, Rend. Sem. Mat. Univ. Padova, V30, P24
   Herman G.T., 1999, Discrete Tomography: Foundations, Algorithms, and Applications
   IRVING RW, 1994, SIAM J COMPUT, V23, P170, DOI 10.1137/S0097539790191010
   KISIELOWSKI C, 1995, ULTRAMICROSCOPY, V58, P131, DOI 10.1016/0304-3991(94)00202-X
   Klette R., 2004, DIGITAL GEOMETRY
   Kuba A., 1989, Acta Cybernetica, V9, P121
   Matej S, 1999, APPL NUM HARM ANAL, P191
   Ryser H. J., 1960, American Mathematical Society. Bulletin, V66, P442, DOI [10.1090/S0002-9904-1960-10494-6, DOI 10.1090/S0002-9904-1960-10494-6]
   Ryser H. J., 1958, Canadian J. Math., V10, P57
   Ryser H.J., 1957, Canad. J. Math., V9, P371
   Sharif B., 2005, ELECT NOTES DISCRETE, V20, P555
   SHLIFERSTEIN AR, 1977, IEEE T COMPUT, V26, P958, DOI 10.1109/TC.1977.1674731
   SLUMP CH, 1982, COMPUT VISION GRAPH, V18, P18, DOI 10.1016/0146-664X(82)90097-1
   VALENTI C, 2003, ELECT NOTES DISCRETE, V12, P12
   WANG YR, 1975, IEEE T COMPUT, V24, P1032, DOI 10.1109/T-C.1975.224121
NR 26
TC 14
Z9 14
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1599
EP 1608
DI 10.1016/j.imavis.2006.06.014
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200008
DA 2024-07-18
ER

PT J
AU Dudek, G
   Borys, P
   Grzywna, ZJ
AF Dudek, Gabriela
   Borys, Przemyslaw
   Grzywna, Zbigniew J.
TI Lossy dictionary-based image compression method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image; compression; LZ77; quantization; noise
AB In this paper, we report on the new method of image compression. The method is based on LZ77 dictionary algorithm. We introduce two modifications such as quantization and noise levels. Experimental results presented in this paper prove that the new method of image compression gives promising results as compared with original LZ77 dictionary algorithm and JPEG2000. (C) 2006 Elsevier B.V. All rights reserved.
C1 Silesian Tech Univ, Sect Phys & Appl Math, Dept Phys Chem & Technol Polymers, Fac Chem, PL-44100 Gliwice, Poland.
C3 Silesian University of Technology
RP Dudek, G (corresponding author), Silesian Tech Univ, Sect Phys & Appl Math, Dept Phys Chem & Technol Polymers, Fac Chem, Ks M Strzody 9, PL-44100 Gliwice, Poland.
EM gdudek@mer.chemia.polsl.gliwice.pl
RI Borys, Przemysław/IUQ-1739-2023
OI Borys, Przemysław/0000-0002-6108-4952; Dudek,
   Gabriela/0000-0002-6182-2652; Grzywna, Zbigniew/0000-0002-0046-4169
CR Abut H., 1990, VECTOR QUANTIZATION
   [Anonymous], 2000, WAVELETS APPROXIMATI
   ATALLAH M, 2003, P ACM S APPL COMP SA, P282
   BALIGAR VP, 2003, IMAGE VIS COMPUT, V21
   Bauschke HH, 2003, IEEE T IMAGE PROCESS, V12, P843, DOI 10.1109/TIP.2003.812375
   Egger O, 1999, P IEEE, V87, P976, DOI 10.1109/5.763312
   Gersho A., 2003, Vector Quantization and Signal Compression
   Grzywna ZJ, 2003, ACTA PHYS POL B, V34, P3681
   Grzywna ZJ, 2001, ACTA PHYS POL B, V32, P1561
   Hankerson D, 1997, INTRO INFORM THEORY
   JAQUIN AE, 1993, P IEEE, V81
   Lonardi S, 2003, IEEE DATA COMPR CONF, P273
   Miano J., 1999, Compressed image file formats: Jpeg, png, gif, xbm, bmp
   NASRABADI MN, 1988, IEEE T COMMUN, V36
   Pennebaker W. B., 1993, JPEG: Still image data compression standard
   Sadakane K, 2000, IEICE T FUND ELECTR, VE83A, P2689
   Salomon D., 2004, Data Compression: the Complete Reference, V4th ed.
   Salomon D., 2002, GUIDE DATA COMPRESSI
   Savari SA, 1997, IEEE T INFORM THEORY, V43, P9, DOI 10.1109/18.567642
   Sayood K, 2017, Introduction to data compression
   Ziv Jacob, 1977, IEEE T INFORM THEORY, V23
NR 21
TC 7
Z9 7
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 883
EP 889
DI 10.1016/j.imavis.2006.07.001
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600010
DA 2024-07-18
ER

PT J
AU Benmoussat, N
   Belbachir, MF
   Benamar, B
AF Benmoussat, Nawal
   Belbachir, M. Faouzi
   Benamar, Beloufa
TI Motion estimation and compensation from noisy image sequences: A new
   filtering scheme
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image sequence; motion compensation; motion estimation
ID BLOCK-MATCHING ALGORITHM; ARCHITECTURES
AB Motion estimation and compensation are proposed to be used as a filtering scheme. This latter is perceived in the motion compensation stage, when noisy frames are predicted from a clean one in the same sequence. The prediction source frame can be obtained simply by filtering spatially one selected frame in the sequence. The filtering efficiency is under-constrained by the accuracy of the motion vector field estimated between the prediction source and the other noisy frames. A study has been conducted on the motion estimation from noisy image sequences showing the conditions under which the motion vector field accuracy is preserved. Simulation results have shown that a total decrease by about 80% in computation time is achieved compared to the classical motion-compensated filtering. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Sci & Technol Oran, Dept Elect Engn, El M Naouer, Algeria.
C3 Universite des Sciences et de la Technologie d'Oran Mohamed Boudiaf
RP Benmoussat, N (corresponding author), Univ Sci & Technol Oran, Dept Elect Engn, POB 1505, El M Naouer, Algeria.
EM Nawalbb@yahoo.com
CR BENMOUSSAT NB, 2000, THESIS U SCI TECHNOL
   BRAILEAN JC, 1995, P IEEE, V83, P1272, DOI 10.1109/5.406412
   Coulon F. D., 1984, THEORIE TRAITEMENT S
   DEVOS L, 1989, IEEE T CIRCUITS SYST, V36, P1309, DOI 10.1109/31.44347
   DUFAUX F, 1995, P IEEE, V83, P858, DOI 10.1109/5.387089
   KATSAGGELOS A, 1991, P SPIE VIS COMM IM P
   KOMAREK T, 1989, IEEE T CIRCUITS SYST, V36, P1301, DOI 10.1109/31.44346
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   OZKAN NK, 1993, IEEE T CIRCUITS SYST, V3
   REINEN TA, 1991, P SPIE VIS COMM IM P, P755
   SEZAN MI, 1991, INT CONF ACOUST SPEE, P2429, DOI 10.1109/ICASSP.1991.150891
   YANG KM, 1989, IEEE T CIRCUITS SYST, V36, P1317, DOI 10.1109/31.44348
NR 12
TC 3
Z9 3
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 686
EP 694
DI 10.1016/j.imavis.2006.05.010
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200014
DA 2024-07-18
ER

PT J
AU Lim, J
   Park, J
   Medioni, GG
AF Lim, Jaeguyn
   Park, Jonghyun
   Medioni, Gerard G.
TI Text segmentation in color images using tensor voting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE tensor voting; text segmentation; mean shift-based density estimation;
   adaptive median filter; color component analysis
AB In natural scene, text elements are corrupted by many types of noise, such as streaks, highlights, or cracks. These effects make the clean and automatic segmentation very difficult and can reduce the accuracy of further analysis such as optical character recognition. We propose a method to drastically improve segmentation using tensor voting as the main filtering step. We first decompose an image into chromatic and achromatic regions. We then identify text layers using tensor voting, and remove noise using adaptive median filter iteratively. Finally, density estimation for center modes detection and K-means clustering algorithm is performed later for segmentation of values according to hue or intensity component in the improved image. Excellent results are achieved in experiments on real images. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.
C3 University of Southern California
RP Lim, J (corresponding author), Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.
EM jaelim@korea.ac.kr; jonghyun@iris.usc.edu; medioni@iris.usc.edu
CR Chen DT, 2001, PROC CVPR IEEE, P621
   Chen XL, 2004, IEEE T IMAGE PROCESS, V13, P87, DOI 10.1109/TIP.2003.819223
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   COMANICIU D, 2001, IEEE T PATTERN ANAL, V24, P1
   Haritaoglu I, 2001, PROC CVPR IEEE, P408
   Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3
   Jia JY, 2004, IEEE T PATTERN ANAL, V26, P771, DOI 10.1109/TPAMI.2004.10
   Jia JY, 2003, PROC CVPR IEEE, P643
   JIE X, 2003, IEEE INT C IMAGE PRO, V1, P14
   Lee MS, 1999, COMPUT VIS IMAGE UND, V76, P54, DOI 10.1006/cviu.1999.0787
   LI C, 2001, INT C DOC AN REC, P1069
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Lucchese L., 2001, PINSA-A (Proceedings of the Indian National Science Academy) Part A (Physical Sciences), V67, P207
   Lucchese L, 1999, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES (CBAIVL'99) - PROCEEDINGS, P74, DOI 10.1109/IVL.1999.781127
   Medioni G., 2000, COMPUTATIONAL FRAMEW
   Moghaddamzadeh A, 1997, PATTERN RECOGN, V30, P867, DOI 10.1016/S0031-3203(96)00084-2
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   Rasmussen CE, 2000, ADV NEUR IN, V12, P554
   Sural S., 2002, P IEEE INT C IM PROC, DOI DOI 10.1109/ICIP.2002.1040019
   Tong WS, 2004, IEEE T PATTERN ANAL, V26, P594, DOI 10.1109/TPAMI.2004.1273934
   Ueda N, 1998, NEURAL NETWORKS, V11, P271, DOI 10.1016/S0893-6080(97)00133-0
   WANG HZ, 2002, INT C CONTROL AUTOMA, P326
   WANG HZ, 2003, DIGITAL IMAGE COMPUT, P10
   Yang J, 2002, INT CONF ACOUST SPEE, P2101
   Ye QX, 2004, IEEE IMAGE PROC, P2905
   Ye QX, 2005, IMAGE VISION COMPUT, V23, P565, DOI 10.1016/j.imavis.2005.01.004
   ZHANG C, 2000, IEEE INT C PATTERN R, V3, P3617
   Zhang J, 2002, FOURTH IEEE INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, PROCEEDINGS, P217, DOI 10.1109/ICMI.2002.1166996
   ZHONG Y, 1995, PATTERN RECOGN, V28, P1523, DOI 10.1016/0031-3203(95)00030-4
   2004, INT J DOCUMENT ANAL, V6, P271
NR 30
TC 25
Z9 28
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 671
EP 685
DI 10.1016/j.imavis.2006.05.011
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200013
DA 2024-07-18
ER

PT J
AU Song, LM
   Qu, XH
   Ye, SH
AF Song, LiMei
   Qu, XingHua
   Ye, ShengHua
TI Improved SFS 3D measurement based on BP neural network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE SFS; BP neural network; genetic algorithm; non-contact measurement
AB 3D surface measurement is an important requirement for modern industry. Non-contact optical method is a commonly used way to plot 2D and 3D measurement. Shape from shading (SFS) is a convenient 3D method because it can recover the 3D shape only from one image. But the existing SFS research has a lot of restriction, such as Lambertian illumination model. If the object is not under Lambertian model, the precision will decrease quickly. We propose an improved SFS based on BP neural network combining with genetic algorithm. This proposed SFS can provide the approximation of the reflectance model. So even the object is not under Lambertian light source, it can also be recovered and the precision has been greatly increased. It has been tested in the 3D reconstruction of synthetic vase, black and complex motorcar part, and really used in the online 3D measurement of work pieces. (c) 2006 Elsevier B.V. All rights reserved.
C1 SW Univ Sci & Technol, Informat Engn Coll, Prov Key Lab Robat Tech & Appl, Mianyang 621010, Sichuan, Peoples R China.
   Tianjin Univ, State Key Lab Precis Measuring Technol & Instrume, Tianjin 300072, Peoples R China.
C3 Southwest University of Science & Technology - China; Tianjin University
RP Song, LM (corresponding author), SW Univ Sci & Technol, Informat Engn Coll, Prov Key Lab Robat Tech & Appl, Mianyang 621010, Sichuan, Peoples R China.
EM lilymay1976@126.com
CR [Anonymous], 1989, Shape from shading
   Cho SY, 2000, IEEE T IND ELECTRON, V47, P1346, DOI 10.1109/41.887964
   Cho SY, 1999, NEUROCOMPUTING, V25, P115, DOI 10.1016/S0925-2312(99)00055-7
   Hirzinger G., 1996, IEEE T NEURAL NETWOR, V17, P985
   Horn B., 1970, SHAPE SHADING METHOD
   TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105
NR 6
TC 3
Z9 5
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 614
EP 622
DI 10.1016/j.imavis.2006.05.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200008
DA 2024-07-18
ER

PT J
AU Torres, RD
   Falcao, AX
AF Torres, R. da S.
   Falcao, A. X.
TI Contour salience descriptors for effective image retrieval and analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE shape analysis image processing; shape saliences; image foresting
   transform; multiscale skeletonization; shape exact dilation; image
   retrieval
ID PERCEPTUAL SHAPE DESCRIPTOR; FORESTING TRANSFORM; MOMENT INVARIANTS;
   RECOGNITION; SETS
AB This work exploits the resemblance between content-based image retrieval and image analysis with respect to the design of image descriptors and their effectiveness. In this context, two shape descriptors are proposed: contour saliences and segment saliences. Contour saliences revisits its original definition. where the location of concave points was a problem, and provides a robust approach to incorporate concave saliences. Segment saliences introduces salience values for contour segments, making it possible to use an optimal matching algorithm as distance function. The proposed descriptors are compared with convex contour saliences, curvature scale space, and beam angle statistics using a fish database with 11,000 images organized in 1100 distinct classes. The results indicate segment saliences as the most effective descriptor for this particular application and confirm the improvement of the contour salience descriptor in comparison with convex contour saliences. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Estadual Campinas, Dept Informat Syst, Inst Comp, BR-13084851 Sao Paulo, Brazil.
C3 Universidade Estadual de Campinas
RP Falcao, AX (corresponding author), Univ Estadual Campinas, Dept Informat Syst, Inst Comp, Av Albert Einstein 1251, BR-13084851 Sao Paulo, Brazil.
EM rtorres@ic.unicamp.br; afalcao@ic.unicamp.br
RI Torres, Ricardo da S./C-4526-2012; Falcão, Alexandre X/F-8361-2012
OI Falcão, Alexandre X/0000-0002-2914-5380; Torres,
   Ricardo/0000-0001-9772-263X
CR Abbasi S, 2000, IMAGE VISION COMPUT, V18, P199, DOI 10.1016/S0262-8856(99)00019-0
   [Anonymous], 1992, R. woods digital image processing
   Arica N, 2003, PATTERN RECOGN LETT, V24, P1627, DOI 10.1016/S0167-8655(03)00002-3
   Arica N, 2002, INT C PATT RECOG, P375, DOI 10.1109/ICPR.2002.1047923
   Aslandogan YA, 1999, IEEE T KNOWL DATA EN, V11, P56, DOI 10.1109/69.755615
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671
   Ciaccia P., 1997, 23 INT C VER LARG DA, P426
   Costa L., 2001, INT C QUAL CONTR ART, P23
   Costa LD, 1999, ELECTRON LETT, V35, P1829, DOI 10.1049/el:19991262
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Dijkstra E. W., 1959, NUMER MATH, V1, P269, DOI [10.1007/BF01386390, DOI 10.1007/BF01386390]
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272
   Dunn J. C., 1974, Journal of Cybernetics, V4, P95, DOI 10.1080/01969727408546059
   Falcao AX, 2004, IEEE T PATTERN ANAL, V26, P19, DOI 10.1109/TPAMI.2004.1261076
   Falcao AX, 2001, PROC SPIE, V4322, P468, DOI 10.1117/12.431120
   Falcao AX, 2002, PATTERN RECOGN, V35, P1571, DOI 10.1016/S0031-3203(01)00148-0
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P382, DOI 10.1006/cviu.1995.1062
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   LEYTON M, 1987, COMPUT VISION GRAPH, V38, P327, DOI 10.1016/0734-189X(87)90117-4
   Lin IJ, 1997, IEEE T SIGNAL PROCES, V45, P2701, DOI 10.1109/78.650096
   Lotufo R, 2000, COMPUT IMAGING VIS, V18, P341
   Mehtre BM, 1997, INFORM PROCESS MANAG, V33, P319, DOI 10.1016/S0306-4573(96)00069-6
   MING CY, 1999, THESIS CHINESE U HON
   Mokhtarian F, 2002, PATTERN RECOGN, V35, P31, DOI 10.1016/S0031-3203(01)00040-1
   Müller H, 2001, PATTERN RECOGN LETT, V22, P593, DOI 10.1016/S0167-8655(00)00118-5
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Torres RD, 2004, PATTERN RECOGN, V37, P1163, DOI 10.1016/j.patcog.2003.10.007
   TORRES RD, 2003, BRAZ S COMP GRAPH IM, P49
   TORRES RD, 2002, 14 INT C DIG SIGN PR, V2, P1089
   Traina C, 2002, IEEE T KNOWL DATA EN, V14, P244, DOI 10.1109/69.991715
   WANG YP, 1990, IEEE T PATTERN ANAL, V12, P1080, DOI 10.1109/34.61707
NR 35
TC 63
Z9 66
U1 1
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 3
EP 13
DI 10.1016/j.imavis.2005.12.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600002
DA 2024-07-18
ER

PT J
AU Bebis, G
   Gyaourova, A
   Singh, S
   Pavlidis, I
AF Bebis, George
   Gyaourova, Aglika
   Singh, Saurabh
   Pavlidis, Ioannis
TI Face recognition by fusing thermal infrared and visible imagery
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; infrared; visible; fusion; principal component
   analysis; wavelets
AB Thermal infrared (IR) imagery offers a promising alternative to visible imagery for face recognition due to its relative insensitive to variations in face appearance caused by illumination changes. Despite its advantages, however, thermal IR has several limitations including that it is opaque to glass. The focus of this study is on the sensitivity of thermal IR imagery to facial occlusions caused by eyeglasses. Specifically, our experimental results illustrate that recognition performance in the IR spectrum degrades seriously when eyeglasses are present in the probe image but not in the gallery image and vice versa. To address this serious limitation of IR, we propose fusing IR with visible imagery. Since IR and visible imagery capture intrinsically different characteristics of the observed faces, intuitively, a better face description could be found by utilizing the complimentary information present in the two spectra. Two different fusion schemes have been investigated in this study. The first one is pixel-based and operates in the wavelet domain, while the second one is feature-based and operates in the eigenspace domain. In both cases, we employ a simple and general framework based on Genetic Algorithms (GAs) to find an optimum fusion strategy. We have evaluated our approaches through extensive experiments using the Equinox face database and the eigenface recognition methodology. Our results illustrate significant performance improvements in recognition, suggesting that IR and visible fusion is a viable approach that deserves further consideration. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Nevada, Comp Vis Lab, Dept Comp Sci & Engn, Reno, NV 89557 USA.
   Univ Houston, Comp Vis Lab, Houston, TX USA.
C3 Nevada System of Higher Education (NSHE); University of Nevada Reno;
   University of Houston System; University of Houston
RP Bebis, G (corresponding author), Univ Nevada, Comp Vis Lab, Dept Comp Sci & Engn, Reno, NV 89557 USA.
EM bebis@cse.unr.edu; aglika@cse.unr.edu; saurabh@cse.unr.edu;
   pavlidis@cs.uh.edu
RI Pavlidis, Ioannis/AAH-3817-2019
OI Pavlidis, Ioannis/0000-0001-8025-2600
CR ADELSON EH, 1981, P C PATT REC IM PROC, P218
   [Anonymous], 0201 EQ CORP
   [Anonymous], IEEE COMP VIS PATT R
   [Anonymous], 1993, GENETIC PROGRAMMING
   Bebis G, 2002, IEEE T EVOLUT COMPUT, V6, P132, DOI 10.1109/4235.996013
   Bebis G., 2000, International Journal on Artificial Intelligence Tools (Architectures, Languages, Algorithms), V9, P225, DOI 10.1142/S0218213000000161
   BLUM R, 2004, MULTISENSOR IMAGE FU
   BUDDHARAJU P, 2004, IEEE INT WORKSH OBJ
   Cantu-Paz E., 2000, EFFICIENT ACCURATE P
   CHEN X, 2003, IEEE INT WORKSH AN M
   Chipman LJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC248
   Chui C. K., 1992, An Introduction to Wavelets, DOI 10.2307/2153134
   Dowdall J, 2003, IMAGE VISION COMPUT, V21, P565, DOI 10.1016/S0262-8856(03)00055-6
   DOWDALL J, 2003, INFRARED TECHNOLOGY, V29
   DOWDALL J, 2001, IEEE WORKSH COMP VIS
   EIDE A, 1996, SPIE C ORL
   ESHELMAN I, 1989, FDN GENETIC ALGORITH, P265
   Eveland CK, 2003, IMAGE VISION COMPUT, V21, P579, DOI 10.1016/S0262-8856(03)00056-8
   FOGEL D, 1992, EVOLUTIONARY COMPUTA
   FRIEDERICH G, 2003, 2 BMCV
   Goldberg David E, 1989, GENETIC ALGORITHMS S
   GYAOUROVA A, 2004, EUR COMP VIS C ECCV
   HEO J, 2004, IEEE INT WORKSH OBJ
   Jain A., 1999, PERSONAL IDENTIFICAT
   Jin Y, 2002, GEN EV COMP C
   KATZ A, 1994, IEEE T PATTERN ANAL, V16
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   LI H, 1994, IEEE IMAGE PROC, P51, DOI 10.1109/ICIP.1994.413273
   Manjunath B. S., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P373, DOI 10.1109/CVPR.1992.223162
   Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148
   Park JS, 2005, IEEE T PATTERN ANAL, V27, P805, DOI 10.1109/TPAMI.2005.103
   Pavlidis I, 2000, IEEE WORKSHOP ON COMPUTER VISION BEYOND THE VISIBLE SPECTRUM: METHODS AND APPLICATIONS, PROCEEDINGS, P15, DOI 10.1109/CVBVS.2000.855246
   Piella G., 2003, Information Fusion, V4, P259, DOI 10.1016/S1566-2535(03)00046-0
   PROKOSKI F, 2000, IEEE WORKSH COMP VIS
   Scheunders P, 2001, IMAGE VISION COMPUT, V19, P971, DOI 10.1016/S0262-8856(01)00058-0
   SELINGER A, 2004, IEEE INT WORKSH OBJ
   SHARMA R, 1999, ADV NEURAL INFORM PR, P11
   SOCOLINSKY D, 2004, IEEE C COMP VIS PATT
   Socolinsky DA, 2003, COMPUT VIS IMAGE UND, V91, P72, DOI 10.1016/S1077-3142(03)00075-4
   Socolinsky DA, 2002, INT C PATT RECOG, P217, DOI 10.1109/ICPR.2002.1047436
   Srivastava A, 2003, IMAGE VISION COMPUT, V21, P651, DOI 10.1016/S0262-8856(03)00061-1
   SUN Z, 2003, IEEE INT C ADV VID S
   Sun Z., 2002, IEEE WORKSH APPL COM
   Sun ZH, 2005, IEEE T INTELL TRANSP, V6, P125, DOI 10.1109/TITS.2005.848363
   Sun ZH, 2004, PATTERN RECOGN, V37, P2165, DOI 10.1016/j.patcog.2004.03.013
   Swets DL, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB595
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   VANI SSK, 2001, P ACRS, V1, P140
   Wilder J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P182, DOI 10.1109/AFGR.1996.557262
   WOLFF LB, 2001, IEEE WORKSH COMP VIS
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   ZHOU Y, 1993, IEEE WORKSH NEUR NET, P411
NR 52
TC 122
Z9 142
U1 2
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 727
EP 742
DI 10.1016/j.imavis.2006.01.017
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400008
DA 2024-07-18
ER

PT J
AU Pece, AEC
AF Pece, AEC
TI Contour tracking based on marginalized likelihood ratios
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE generative model; active contour; particle filters; EM algorithm; Kalman
   filter
ID VEHICLE TRACKING; MODEL; SHAPES
AB When fitting contour models to image data, it is necessary to take into account unmodelled shape variability. Traditionally, this has been done either by blurring the input image or by looking for image features in the neighborhood of the contour. A more statistically rigorous approach is to marginalize over all possible shape deformations. When this is done, the resulting likelihood model has similarities to both the blurring approach and the feature-based approach. A tracking application is used to demonstrate the marginalized likelihood model and compare it to the blurring approach. The best tracking results were obtained with the new model when combined with the Expeclation-Maxinlization (EM) algorithm. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen, Denmark.
   Heimdall Vis, DK-2500 Valby, Denmark.
C3 University of Copenhagen
RP Univ Copenhagen, Dept Comp Sci, Univ Pk 1, DK-2100 Copenhagen, Denmark.
EM aecp@heimdall-vision.com
CR [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], 1992, ACTIVE VISION
   Bar-Shalom Y., 1988, TRACKING DATA ASS
   Baumberg A, 1998, IMAGE VISION COMPUT, V16, P329, DOI 10.1016/S0262-8856(97)00065-6
   Blake A., 1998, ACTIVE CONTOURS
   Cootes T.F., 1999, STAT MODELS APPEARAN
   Coughlan J, 2000, COMPUT VIS IMAGE UND, V78, P303, DOI 10.1006/cviu.2000.0842
   Coughlan JM, 2002, LECT NOTES COMPUT SC, V2352, P453
   Dahlkamp H, 2004, LECT NOTES COMPUT SC, V3175, P71
   DAHLKAMP H, 2004, P WORKSH SPAT COH VI
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ferryman J., 2001, P 2 IEEE INT WORKSH
   Ferryman JM, 1997, ROBOT AUTON SYST, V19, P315, DOI 10.1016/S0921-8890(97)83348-9
   FERRYMAN JM, 2000, P 1 IEEE INT WORKSH
   Geman D, 1996, IEEE T PATTERN ANAL, V18, P1, DOI 10.1109/34.476006
   Haag M, 1999, INT J COMPUT VISION, V35, P295, DOI 10.1023/A:1008112528134
   Hanek R, 2004, INT J COMPUT VISION, V59, P233, DOI 10.1023/B:VISI.0000025799.44214.29
   Hansen DW, 2005, COMPUT VIS IMAGE UND, V98, P155, DOI 10.1016/j.cviu.2004.07.013
   HANSEN DW, 2004, P INT C COMP VIS PAT, V2, P159
   HANSEN DW, 2003, P WORKSH AN MOD FAC
   HUANG J, 1999, P IEEE C COMP VIS PA, V1, P541
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jepson AD, 2001, PROC CVPR IEEE, P415
   JOJIC N, 2001, P INT C COMP VIS PAT
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   Kollnig H, 1997, INT J COMPUT VISION, V23, P283, DOI 10.1023/A:1007927317325
   KOLLNIG H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P569, DOI 10.1109/ICCV.1995.466888
   LEUCK H, 1999, P IEEE COMP SOC C CO, V2, P360
   LEVIN A, 2002, ADV NEURAL INFORMATI, V15
   Li PH, 2003, IMAGE VISION COMPUT, V21, P111, DOI 10.1016/S0262-8856(02)00133-6
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P117, DOI 10.1023/A:1008097225773
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe D. G., 1985, Perceptual Organization and Visual Recognition
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   MacCormick J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P390, DOI 10.1109/ICCV.1998.710748
   MACLACHLAN GJ, 1997, EA ALGORITHM EXTENSI
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Oksendal B, 1995, Stochastic Differential Equations. An Introduction with Applications, VFourth
   Pece A, 1998, IMAGE VISION COMPUT, V16, P541, DOI 10.1016/S0262-8856(98)00098-5
   Pece AEC, 2002, J MATH IMAGING VIS, V17, P89, DOI 10.1023/A:1020677318841
   Pece AEC, 2002, ROBOT AUTON SYST, V39, P181, DOI 10.1016/S0921-8890(02)00203-8
   PECE AEC, 2003, P 3 WORKSH STAT COMP
   PECE AEC, IN PRESS IMAGE VIS C
   Pece AV, 2002, LECT NOTES COMPUT SC, V2350, P3
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Roberts, 1965, MACHINE PERCEPTION 3
   RUDERMAN DL, 1994, NETWORK-COMP NEURAL, V5, P517, DOI 10.1088/0954-898X/5/4/006
   Sidenbladh H, 2003, INT J COMPUT VISION, V54, P181, DOI 10.1023/A:1023765619733
   STEPHENS RS, 1989, P ALV VIS C, P85
   SUDDERTH EB, 2004, 2 WORKSH GEN MOD BAS
   SULLIVAN GD, 1992, PHILOS T ROY SOC B, V337, P361, DOI 10.1098/rstb.1992.0114
   Tissainayagam P, 2003, PATTERN RECOGN, V36, P2411, DOI 10.1016/S0031-3203(03)00088-8
   van Ginneken B, 2002, IEEE T MED IMAGING, V21, P924, DOI 10.1109/TMI.2002.803121
   Vermaak J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1110
   Worrall AD, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P137
   Xu C., 2000, HDB MEDICAL IMAGING, P129
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 2000, CONF REC ASILOMAR C, P483, DOI 10.1109/ACSSC.2000.911003
   Yuille AL, 2000, IEEE T PATTERN ANAL, V22, P160, DOI 10.1109/34.825754
NR 60
TC 5
Z9 7
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2006
VL 24
IS 3
BP 301
EP 317
DI 10.1016/j.imavis.2005.07.024
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 031PI
UT WOS:000236716100009
DA 2024-07-18
ER

PT J
AU Carmona-Poyato, A
   Fernández-García, NL
   Medina-Carnicer, R
   Madrid-Cuevas, FJ
AF Carmona-Poyato, A
   Fernández-García, NL
   Medina-Carnicer, R
   Madrid-Cuevas, FJ
TI Dominant point detection:: A new proposal
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE contour representation; contour description; dominant points
ID SHAPE REPRESENTATION; DIGITAL CURVES; POLYGONAL-APPROXIMATION; PLANAR
   CURVES; OBJECT RECOGNITION; CHAIN CODE; ALGORITHM; IDENTIFICATION;
   MULTISCALE
AB A new method for dominant point detection is presented. This method can be classified as search corner detection using some significant measurement other than curvature category, and needs no input parameters. A new and normalized measurement is described to compute the estimated curvature and to detect dominant points, and a new algorithm is proposed to eliminate collinear points using an optimization procedure. The experimental results show that this method is efficient, effective, reduces the number of dominant points as compared to other proposed methods, and the obtained contours using this objective function are properly adjusted to the original contour. (C) 2005 Elsevier Ltd All rights reserved.
C1 Univ Cordoba, E-14071 Cordoba, Spain.
C3 Universidad de Cordoba
RP Univ Cordoba, Campus Rabanales Ed Einstein, E-14071 Cordoba, Spain.
EM malcapoa@uco.es
RI Fernández García, Nicolás Luis/AAP-9118-2021; Medina-Carnicer,
   Rafael/G-3401-2015; Madrid-Cuevas, Francisco Jose/H-1396-2015;
   Carmona-Poyato, Angel/G-1593-2015
OI Fernández García, Nicolás Luis/0000-0002-1267-6986; Medina-Carnicer,
   Rafael/0000-0003-4481-0614; Madrid-Cuevas, Francisco
   Jose/0000-0001-6557-7431; Carmona-Poyato, Angel/0000-0002-8820-8396
CR ALOIMONOS J, 1988, P IEEE, V76, P899, DOI 10.1109/5.5964
   BALLARD DH, 1981, COMMUN ACM, V24, P310, DOI 10.1145/358645.358661
   Bandera A, 1999, PATTERN RECOGN LETT, V20, P49, DOI 10.1016/S0167-8655(98)00123-8
   CHUNG PC, 1994, PATTERN RECOGN, V27, P1505, DOI 10.1016/0031-3203(94)90128-7
   COHEN FS, 1995, IEEE T IMAGE PROCESS, V4, P1, DOI 10.1109/83.350818
   Cornic P, 1997, PATTERN RECOGN LETT, V18, P13, DOI 10.1016/S0167-8655(96)00116-X
   Davis L., 1986, Handbook of Pattern Recognition and Image Processing, P233
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   Fu AMN, 1997, PATTERN RECOGN LETT, V18, P55, DOI 10.1016/S0167-8655(96)00131-6
   Fu AMN, 1997, PATTERN RECOGN, V30, P1661, DOI 10.1016/S0031-3203(96)00183-5
   Garrido A, 1998, PATTERN RECOGN, V31, P791, DOI 10.1016/S0031-3203(97)00104-0
   Gonzalez R., 1996, TRATAMIENTO DIGITAL
   Gu YH, 2000, PATTERN RECOGN, V33, P1411, DOI 10.1016/S0031-3203(99)00131-4
   HENDERSON T, 1983, FUNDAMENTALS COMPUTE, P273
   Huang PW, 1999, PATTERN RECOGN LETT, V20, P163, DOI 10.1016/S0167-8655(98)00132-9
   IKEBE Y, 1982, SHAPE DESIGN REPRESE, P75
   LIN YJ, 1992, PATTERN RECOGN, V25, P17, DOI 10.1016/0031-3203(92)90003-2
   Loncaric S, 1998, PATTERN RECOGN, V31, P983, DOI 10.1016/S0031-2023(97)00122-2
   Marji M, 2004, PATTERN RECOGN, V37, P2113, DOI 10.1016/j.patcog.2004.03.004
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   MOKHTARIAN F, 1992, IEEE T PATTERN ANAL, V14, P789, DOI 10.1109/34.149591
   MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387
   PAVLIDIS T, 1980, IEEE T PATTERN ANAL, V2, P301, DOI 10.1109/TPAMI.1980.4767029
   PAVLIDIS T, 1978, COMPUT VISION GRAPH, V7, P243, DOI 10.1016/0146-664X(78)90115-6
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   PHAM S, 1986, COMPUTER VISION GRAP, V36, P244
   RAY BK, 1992, PATTERN RECOGN, V22, P443
   ROSENFELD A, 1973, IEEE T COMPUT, VC 22, P875, DOI 10.1109/TC.1973.5009188
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   SAGHRI JA, 1981, IEEE T PATTERN ANAL, V3, P533, DOI 10.1109/TPAMI.1981.4767146
   Sonka M., 1993, IMAGE PROCESSING ANA
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Urdiales C, 2002, PATTERN RECOGN, V35, P43, DOI 10.1016/S0031-3203(01)00041-3
   Van Otterloo P. J., 1991, CONTOUR ORIENTED APP
   WU JS, 1993, PATTERN RECOGN, V26, P471, DOI 10.1016/0031-3203(93)90103-4
   WU LD, 1982, IEEE T PATTERN ANAL, V4, P347, DOI 10.1109/TPAMI.1982.4767258
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Wu WY, 2003, IMAGE VISION COMPUT, V21, P517, DOI 10.1016/S0262-8856(03)00031-3
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   ZHU PF, 1995, IEEE T PATTERN ANAL, V17, P737, DOI 10.1109/34.400564
NR 40
TC 42
Z9 44
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1226
EP 1236
DI 10.1016/j.imavis.2005.07.025
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500011
DA 2024-07-18
ER

PT J
AU Reyes, L
   Bayro-Corrochano, E
AF Reyes, L
   Bayro-Corrochano, E
TI The projective reconstruction of points, lines, quadrics, plane conics
   and degenerate quadrics using uncalibrated cameras
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE computer vision; imaging geometry; projective reconstruction; bundle
   adjustment; N-views; epipolar constraint
ID GEOMETRIC APPROACH; MOTION
AB In this paper we present an algorithm for the simultaneous projective reconstruction of points, lines, quadrics, plane conics and degenerate quadrics using Bundle Adjustment. In contrast, most existing work on projective reconstruction focuses mainly on one type of primitive. Furthermore, for the reconstruction of quadrics (both full-rank and degenerate) and plane conics, a novel algorithm for the rectification of the outlines projected in n views is presented. Finally, we found out that due to the noise in the data, the global minimum of the classic cost function used in Bundle Adjustment may unfortunately break the topology of the quadrics. Hence, during the iterations of this method, we need to add the constraints to keep the quadrics within acceptable limits to preserve their topology. (c) 2005 Published by Elsevier B.V.
C1 CINVESTAV, Dept Comp Sci, Guadalajara 44550, Jalisco, Mexico.
C3 CINVESTAV - Centro de Investigacion y de Estudios Avanzados del
   Instituto Politecnico Nacional
RP Bayro-Corrochano, E (corresponding author), CINVESTAV, Dept Comp Sci, POB 31-438,Plaza La Luna,Lopez Mateos Sur 590, Guadalajara 44550, Jalisco, Mexico.
EM edb@gdl.cinvestav.mx
RI Reyes, Laura/HSI-0284-2023; cai, bo/G-1491-2010
CR [Anonymous], 2676 INRIA
   ASTROM K, 1998, SSAB S IM AN
   BARTOLI A, 2001, 4236 INRIA
   Bayro-Corrochano E, 2002, J MATH IMAGING VIS, V16, P131, DOI 10.1023/A:1013947415006
   Bayro-Corrochano E, 2000, J MATH IMAGING VIS, V13, P205, DOI 10.1023/A:1011293515286
   BERTHILSSON R, 1999, 7 INT C COMP VIS, V1, P674
   Carlsson S, 1998, INT J COMPUT VISION, V27, P227, DOI 10.1023/A:1007961913417
   CHAN Y, 2001, 8 INT C COMP VIS, V2, P644
   Cross G, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P25, DOI 10.1109/ICCV.1998.710697
   CROSS G, 2000, THESIS U OXFORD
   HARTLEY R, 1998, P 5 ECCV, V1, P20
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Kahl F, 1999, INT J COMPUT VISION, V33, P163, DOI 10.1023/A:1008192713051
   Kaucic R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P420, DOI 10.1109/ICCV.2001.937548
   MALIS E, 2001, 4377 INRIA
   MCLAUCHLAN PF, 1999, WORKSH MULT MOD AN V, P183
   REYES L, 2003, 3 INT C COMP VIS PAT
   Rother C, 2002, INT J COMPUT VISION, V49, P117, DOI 10.1023/A:1020189404787
   STURM P, 1996, 4 EUR C COMP VIS, V2, P709
   Triggs B., 1999, VISION ALGORITHMS TH, P298
NR 20
TC 7
Z9 8
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2005
VL 23
IS 8
BP 693
EP 706
DI 10.1016/j.imavis.2005.03.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VD
UT WOS:000231400500002
DA 2024-07-18
ER

PT J
AU Ye, QX
   Huang, QM
   Gao, W
   Zhao, DB
AF Ye, QX
   Huang, QM
   Gao, W
   Zhao, DB
TI Fast and robust text detection in images and video frames
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE text detection; multiscale wavelet feature; feature combination; SVM
   classification
ID CAPTION DETECTION
AB Text in images and video frames carries important information for visual content understanding and retrieval. In this paper, by using multiscale wavelet features, we propose a novel coarse-to-fine algorithm that is able to locate text lines even under complex background. First. in the coarse detection, after the wavelet energy feature is calculated to locate all possible text pixels, a density-based region growing method is developed to connect these pixels into regions which are further separated into candidate text lines by structural information. Secondly, in the fine detection, with four kinds of texture features extracted to represent the texture pattern of a text line, a forward search algorithm is applied to select the most effective features. Finally, an SVM classifier is used to identify true text from the candidates based on the selected features. Experimental results show that this approach can fast and robustly detect text lines under various conditions. (c) 2005 Elsevier B.V. All rights reserved.
C1 Chinese Acad Sci, Comp Technol Inst, Beijing 100864, Peoples R China.
   Chinese Acad Sci, Grad Sch, Beijing 100864, Peoples R China.
   Harbin Inst Technol, Dept Comp Sci, Harbin 150006, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Harbin Institute of Technology
RP Ke Xue Yuan S Rd,Zhong Guan Cun,Hai Dian Dist,POB, Beijing 100080, Peoples R China.
EM qxye@ict.ac.cn
RI Huang, Qingming/GLR-3473-2022; Zhao, Debin/JEP-0204-2023
OI Huang, Qingming/0000-0002-3025-7099; 
CR [Anonymous], 1995, CMUCS95186
   Chen DT, 2001, PROC CVPR IEEE, P621
   Chen DT, 2002, INT C PATT RECOG, P227, DOI 10.1109/ICPR.2002.1047438
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   FURHT B, 1995, VIDEO IMAGE PROCESSI, P226
   Heisele B, 2001, PROC CVPR IEEE, P18
   Hua XS, 2004, IEEE T CIRC SYST VID, V14, P498, DOI 10.1109/TCSVT.2004.825538
   HUA XS, 2002, INT C IM PROC NEW YO, P22
   Jain AK, 1998, PATTERN RECOGN, V31, P2055, DOI 10.1016/S0031-3203(98)00067-3
   JAIN AK, 2001, IEEE T PAMI, V2, P4
   Kim KI, 2003, IEEE T PATTERN ANAL, V25, P1631, DOI 10.1109/TPAMI.2003.1251157
   LI H, 1998, 028 LAMP MAR U
   LI H, 1999, ACM MULTIMEDIA, P385
   LI H, 1999, P SPIE 99 DOC REC RE
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Lienhart R, 2002, IEEE T CIRC SYST VID, V12, P256, DOI 10.1109/76.999203
   Luo B, 2003, IEEE IMAGE PROC, P297
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Sato T, 1999, MULTIMEDIA SYST, V7, P385, DOI 10.1007/s005300050140
   SATO T, 1998, IEEE WORKSH CONT BAS
   Sobottka K., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P57, DOI 10.1109/ICDAR.1999.791724
   SUNG K, 1994, 1521 AI
   Tang X, 2002, IEEE T NEURAL NETWOR, V13, P961, DOI 10.1109/TNN.2002.1021896
   Vapnik V., 1999, NATURE STAT LEARNING
   WOUWER GV, 1998, THESIS U ANTWERPEN B, P43
   WU TF, 2001, J MACHINE LEARNING R, P975
   Wu V, 1999, IEEE T PATTERN ANAL, V21, P1224, DOI 10.1109/34.809116
   YE Q, 2003, JOINT C 4 INT C INF
   Ye QX, 2004, IEEE IMAGE PROC, P2905
   ZHANG DQ, 2003, INT C COMP VIS PATT
   ZHONG Y, 1995, PATTERN RECOGN, V28, P1523, DOI 10.1016/0031-3203(95)00030-4
   Zhong Y, 2000, IEEE T PATTERN ANAL, V22, P385, DOI 10.1109/34.845381
NR 32
TC 193
Z9 226
U1 0
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2005
VL 23
IS 6
BP 565
EP 576
DI 10.1016/j.imavis.2005.01.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 924CA
UT WOS:000228955100002
DA 2024-07-18
ER

PT J
AU Kim, YH
   Martínez, AM
   Kak, AC
AF Kim, YH
   Martínez, AM
   Kak, AC
TI Robust motion estimation under varying illumination
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE motion estimation; optical-flow; illumination; robust statistics
ID OPTICAL-FLOW; RESTORATION
AB The optical-flow approach has emerged as a major technique for estimating scene and object motion in image sequences. However, the results obtained by most optical flow techniques are strongly affected by motion discontinuities and by large illumination changes. While there do exist many separate techniques for robust estimation of optical flow in the presence of motion discontinuities and for dealing with the problems caused by illumination variations, only a few integrated approaches have been proposed. However, most of these previously proposed integrated approaches use simple models of illumination variation; a common assumption being that illumination changes by either just a multiplicative factor or just an additive factor from frame to frame, but not both. Some other previously proposed integrated approaches are limited to specialized tasks such as image registration or change recovery.
   To remedy this shortcoming, this paper presents a new robust approach to general motion estimation in an integrated framework. Our approach deals simultaneously with motion discontinuities and large illumination variations. Our model of illumination variation is general, in the sense that it admits both multiplicative and additive effects. (C) 2004 Published by Elsevier B.V.
C1 Ohio State Univ, Sch Elect & Comp Engn, Columbus, OH 43210 USA.
   Ohio State Univ, Dept Elect & Comp Engn, Columbus, OH 43210 USA.
C3 University System of Ohio; Ohio State University; University System of
   Ohio; Ohio State University
RP Ohio State Univ, Sch Elect & Comp Engn, 2015 Neil Ave, Columbus, OH 43210 USA.
EM yeonho@ecn.purdue.edu; aleix@ee.eng.ohio-state.edu; kak@ecn.purdue.edu
RI Martinez, Aleix M/A-2380-2008
CR ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   [Anonymous], 1987, Visual Reconstruction
   AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   BERGEN JR, 1992, LECT NOTES COMPUT SC, V588, P237
   Black M, 1992, THESIS YALE U
   Black MJ, 2000, COMPUT VIS IMAGE UND, V78, P8, DOI 10.1006/cviu.1999.0825
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Darrell T., 1991, Proceedings of the IEEE Workshop on Visual Motion (Cat. No.91TH0390-5), P173, DOI 10.1109/WVM.1991.212810
   FLEET DJ, 1993, IEEE T PATTERN ANAL, V15, P1253, DOI 10.1109/34.250844
   FLEET DJ, 1991, CVGIP-IMAG UNDERSTAN, V53, P198, DOI 10.1016/1049-9660(91)90027-M
   GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040
   GEMAN D, 1992, IEEE T PATTERN ANAL, V14, P367, DOI 10.1109/34.120331
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gennert M. A., 1987, 975 MIT
   Haussecker HW, 2001, IEEE T PATTERN ANAL, V23, P661, DOI 10.1109/34.927465
   Horn B.K.P, 1986, Robot Vision
   KORN BKP, 1981, ARTIF INTELL, V17, P185
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Mukawa N, 1997, COMPUT VIS IMAGE UND, V66, P25, DOI 10.1006/cviu.1996.0500
   Mukawa N., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P507, DOI 10.1109/ICCV.1990.139583
   NAGEL HH, 1989, IEEE T PATTERN ANAL, V11, P13, DOI 10.1109/34.23110
   Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362
   Nestares O, 2001, IMAGE VISION COMPUT, V19, P339, DOI 10.1016/S0262-8856(00)00083-4
   ODOBEZ JM, 1995, VISUAL COMMUN IM DEC, P348
   RANGARAJAN A, 1993, MARKOV RANDOM FIELDS
   Rousseeuw P. J., 1987, ROBUST REGRESSION OU
   SAWHNEY HS, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P583
   Shang-Hong Lai, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P167, DOI 10.1109/CVPR.1999.784625
   SHULMAN D, 1989, P IEEE WORKSH VIS MO
   Tian TY, 1996, MACH VISION APPL, V9, P32, DOI 10.1007/BF01246637
   TREVES P, 1994, IEEE IMAGE PROC, P373, DOI 10.1109/ICIP.1994.413338
   Varga RS., 1962, Matrix Iterative Analysis
   VERRI A, 1989, IEEE T PATTERN ANAL, V11, P490, DOI 10.1109/34.24781
NR 34
TC 57
Z9 73
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2005
VL 23
IS 4
BP 365
EP 375
DI 10.1016/j.imavis.2004.05.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900NR
UT WOS:000227222100001
DA 2024-07-18
ER

PT J
AU Jonker, PP
AF Jonker, PP
TI Discrete topology on <i>N</i>-dimensional square tessellated grids
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE mathematical morphology; digital topology; N-dimensional shape;
   N-dimensional topological kernels; N-dimensional standing waves
ID DIGITAL DISTANCE TRANSFORMS; SHAPE PRIMITIVES; SKELETONIZATION;
   NEIGHBORHOODS; PRESERVATION; OPERATIONS
AB Topology preservation and detection is a well known concept in the processing of 2- and 3-dimensional binary images. These images can be considered as sets that are mapped on square tessellated (hyper cubic) grids. This paper describes how the formalisms derived for 2D and 3D images can be expanded to N-dimensional images, i.e. binary point sets that are aligned on an N-dimensional square tessellated grid. Topology preserving thinning of objects in an image, informally referred to as skeletonization, is based on the successive erosion of the boundary of an object until locally a primitive shape is detected, e.g. in 3D a surface or a curve. The detection of primitive shapes is done using shape primitives. The generation of shape primitive detectors is based on the possibility to describe the primitives for intrinsic or object dimensions (N) over tilde = N - 1 by quadratic equations of the form x(N) = Sigma(a(n)x(x) + b(n)x(n)(2)). From this, primitives for lower object dimensions can be derived. A formula is derived that predicts the number of unique shape primitives in each dimension. Their application in measurements on shapes, in conditions for topology detection as used in topology preserving thinning, as well as the determination of standing wave patterns in topological kernels, is described. Finally as on each element of an image at least one of the primitives matches, this can be used to measure the total content of length, area, volume, etc from the objects in the image. (C) 2004 Elsevier B.V. All rights reserved.
C1 Delft Univ Technol, Fac Appl Phys, Quantitat Imaging Grp, NL-2628 CJ Delft, Netherlands.
C3 Delft University of Technology
RP Jonker, PP (corresponding author), Delft Univ Technol, Fac Appl Phys, Quantitat Imaging Grp, Lorentzweg 1, NL-2628 CJ Delft, Netherlands.
EM pieter@ph.tn.tudelft.nl
RI Jonker, Pieter P/C-9655-2013
CR Alexandroff P.., 1961, Elementary concepts of Topology. A translation of (Alexandroff
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 1988, Morphological methods in image and signal processing
   [Anonymous], 1994, Morphological Image Operators
   ARCELLI C, 1975, ELECTRON LETT, V11, P140
   BECKERS ALD, 1992, CVGIP-IMAG UNDERSTAN, V55, P296, DOI 10.1016/1049-9660(92)90027-Z
   Borgefors G, 2003, DISCRETE APPL MATH, V125, P161, DOI 10.1016/S0166-218X(02)00229-9
   Borgefors G, 1999, PATTERN RECOGN, V32, P1225, DOI 10.1016/S0031-3203(98)00082-X
   Borgefors G, 1996, COMPUT VIS IMAGE UND, V64, P368, DOI 10.1006/cviu.1996.0065
   Coxeter HSM., 1974, REGULAR POLYTOPES
   GOLAY MJE, 1969, IEEE T COMPUT, VC 18, P733, DOI 10.1109/T-C.1969.222756
   Hilbert D., 1932, ANSCHAULICHE GEOMETR
   HILDITCH CJ, 1969, MACH INTELL, V4, P404
   Jonker P., 1995, Shape, Structure and Pattern Recognition, P71
   Jonker P. P., 1994, Proceedings of IAPR Workshop on Machine Vision Applications, P30
   Jonker PP, 2004, PATTERN RECOGN LETT, V25, P527, DOI 10.1016/j.patrec.2003.12.004
   Jonker PP, 2003, LECT NOTES COMPUT SC, V2886, P420
   Jonker PP, 2002, PATTERN RECOGN LETT, V23, P677, DOI 10.1016/S0167-8655(01)00144-1
   JONKER PP, 1996, LECT NOTES COMPUTER, V1121, P79
   JONKER PP, 1992, THESIS
   KONG TY, 1989, COMPUT GRAPH, V13, P159, DOI 10.1016/0097-8493(89)90058-7
   LAM L, 1992, IEEE T PATTERN ANAL, V2, P75
   LOBREGT S, 1980, IEEE T PATTERN ANAL, V2, P75, DOI 10.1109/TPAMI.1980.4766974
   Ma CM, 2001, PATTERN RECOGN LETT, V22, P1439, DOI 10.1016/S0167-8655(01)00083-6
   MA CM, 1994, CVGIP-IMAG UNDERSTAN, V59, P328, DOI 10.1006/ciun.1994.1023
   MALANDAIN C, 1992, P 11 ICPR HAG, V3
   Mullikin J. C., 1993, Bioimaging, V1, P6, DOI 10.1002/1361-6374(199303)1:1<6::AID-BIO3>3.3.CO;2-V
   RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4
   ROSENFEL.A, 1966, J ACM, V13, P471
   SAHA PK, 1994, PATTERN RECOGN, V27, P295, DOI 10.1016/0031-3203(94)90060-4
   Serra J., 1983, IMAGE ANAL MATH MORP
   Svensson S, 2003, LECT NOTES COMPUT SC, V2886, P317
   Svensson S, 2002, COMPUT VIS IMAGE UND, V88, P24, DOI 10.1006/cviu.2002.0976
   Toriwaki J., 1982, Proceedings of the 6th International Conference on Pattern Recognition, P414
   VERWER BJH, 1991, PATTERN RECOGN LETT, V12, P671, DOI 10.1016/0167-8655(91)90004-6
NR 35
TC 3
Z9 3
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 213
EP 225
DI 10.1016/j.imavis.2004.06.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800012
DA 2024-07-18
ER

PT J
AU Jhanwar, N
   Chaudhuri, S
   Seetharaman, G
   Zavidovique, B
AF Jhanwar, N
   Chaudhuri, S
   Seetharaman, G
   Zavidovique, B
TI Content based image retrieval using motif cooccurrence matrix
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Indian Conference on Vision, Graphics and Image Processing (ICVGIP)
CY DEC 16-18, 2002
CL Ahmedabad, INDIA
DE content-based retrieval; peano scan; optimal scan; cooccurrence matrix;
   image query; scan motif
ID COMPRESSION
AB We present a new technique for content based image retrieval using motif cooccurrence matrix (MCM). The MCM is derived from the motif transformed image. The whole image is divided into 2 X 2 pixel grids. Each grid is replaced by a scan motif that minimizes the local gradient while traversing the 2 X 2 grid forming a motif transformed image. The MCM is then defined as a 3D matrix whose (i,j,k) entry denotes the probability of finding a motif i at a distance k from the motif j in the transformed image. Conceptually, the MCM is quite similar to the color cooccurrence matrix (CCM), however, the retrieval using the MCM is better than the CCM since it captures the third order image statistics in the local neighborhood. Experiments confirm that the use of MCM considerably improves the retrieval performance. (C) 2004 Published by Elsevier B.V.
C1 Natl Univ Singapore, Sch Comp, Singapore, Singapore.
   Indian Inst Technol, Dept Elect Engn, Bombay 400076, Maharashtra, India.
   Univ Louisiana, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.
   Univ Paris 11, Inst Elect Fondamentale, F-91405 Orsay, France.
C3 National University of Singapore; Indian Institute of Technology System
   (IIT System); Indian Institute of Technology (IIT) - Bombay; University
   of Louisiana Lafayette; Universite Paris Saclay
RP Natl Univ Singapore, Sch Comp, Singapore, Singapore.
EM nitin@comp.nus.edu.sg
CR Aggarwal G, 2000, PROC CVPR IEEE, P255, DOI 10.1109/CVPR.2000.854802
   AKSHOY S, 1999, P IEEE C CVPR FORT C
   [Anonymous], 1890, Math. Ann.
   BIALLY T, 1969, IEEE T INFORM THEORY, V15, P658, DOI 10.1109/TIT.1969.1054385
   BUTZ AR, 1968, INFORM CONTROL, V12, P314, DOI 10.1016/S0019-9958(68)90367-7
   CHANG NS, 1980, IEEE T SOFTWARE ENG, V6, P519, DOI 10.1109/TSE.1980.230801
   CHANG P, 1997, P IEEE INT C CVPR FO, P498
   CHUA TS, 1998, P IEEE CVPR SANT BAR, P145
   Cula OG, 2001, PROC CVPR IEEE, P1041
   DAFNER R, 2000, EUROGRAPH ICS J, V19
   DELBIMBO A, 1999, J COMPUTER VISIONS I
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   Hilbert David, 1891, MATH ANN, V38, P459, DOI [DOI 10.1007/BF01199431, 10.1007/bf01199431]
   Hirashima N, 2002, J CLIN GASTROENTEROL, V34, P263, DOI 10.1097/00004836-200203000-00014
   Huang J, 1997, PROC CVPR IEEE, P762, DOI 10.1109/CVPR.1997.609412
   Huang J, 1997, ACM MULTIMEDIA 97, PROCEEDINGS, P325, DOI 10.1145/266180.266383
   JACOBS C, 1999, P SIGGRAPH NOV, P277
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555
   JHANWAR N, 2000, P 7 NATL C COMM IIT, P320
   JHANWAR N, 2002, INT C PATT REC AUG
   JOHANSSON B, 2002, SURVEY CONTENT BASED
   Jordan CL, 1998, COMPUT VIS IMAGE UND, V71, P198, DOI 10.1006/cviu.1998.0707
   KANAL L, 1965, IEEE T INFORMATION T, V11
   Konishi S, 2000, PROC CVPR IEEE, P125, DOI 10.1109/CVPR.2000.855809
   KUMAR S, 2000, P IEEE INT C IM PROC
   LEMPEL A, 1986, IEEE T INFORM THEORY, V32, P2, DOI 10.1109/TIT.1986.1057132
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   LEW M, 1999, IEEE T PATTERN ANAL, V21, P871
   Mandal MK, 1999, COMPUT VIS IMAGE UND, V75, P99, DOI 10.1006/cviu.1999.0766
   MENP T, 2002, IEEE T PATTERN ANAL, P971
   Nastar C, 1998, PROC CVPR IEEE, P547, DOI 10.1109/CVPR.1998.698659
   NEVATIA R, 1982, IEEE T PATTERN ANAL, V4, P476, DOI 10.1109/TPAMI.1982.4767291
   NGUYEN PT, 1982, IEEE T PAMI PAMI, V4
   NILBACK W, 1993, SPIE P STOR RETR IM, P173
   PASS G, 1996, 4 ACM INT MULT C NOV, P18
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   PICARD RW, 1994, INT CONF ACOUST SPEE, P129
   PONCE J, 2003, P COMP VIS PATT
   QUINQUETON J, 1981, IEEE T PATTERN ANAL, V3, P403, DOI 10.1109/TPAMI.1981.4767126
   RAMAN H, 1998, IND C COMP VIS DEC N, P351
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428
   SEETHARAMAN G, 1997, P IEEE WORKSH COMP A
   SEETHARAMAN G, 1998, P IEEE INT C IMAGE P
   SHIVARAM G, 1997, IEEE T IMAGE PROCESS
   SMITH JR, 1996, P MULT C BOST MA NOV
   Swain MichaelJ., 1991, International Journal of Computer Vision (IJCV), V7
   Tieu K, 2000, PROC CVPR IEEE, P228, DOI 10.1109/CVPR.2000.855824
   VARMA M, 2003, P COMP VIS PATT REC
   Wu JK, 1998, INFORM PROCESS MANAG, V34, P513, DOI 10.1016/S0306-4573(98)00017-X
   Wu Y, 2000, PROC CVPR IEEE, P222, DOI 10.1109/CVPR.2000.855823
   YOGESH S, 1999, WORKSH VIS MOD VIS V
   Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420
NR 53
TC 193
Z9 201
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2004
VL 22
IS 14
BP 1211
EP 1220
DI 10.1016/j.imavis.2004.03.026
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 882LG
UT WOS:000225939800008
DA 2024-07-18
ER

PT J
AU Mudur, SP
   Babji, SV
   Shikhare, D
AF Mudur, SP
   Babji, SV
   Shikhare, D
TI Advancing fan-front: 3D triangle mesh compression using fan based
   traversal
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Indian Conference on Vision, Graphics and Image Processing (ICVGIP)
CY DEC 16-18, 2002
CL Ahmedabad, INDIA
DE 3D compression; connectivity encoding; 3D triangle mesh; triangle fan
AB Connectivity compression techniques for very large 3D triangle meshes are based on clever traversals of the graph representing the mesh, so as to avoid the repeated references to vertices. In this paper we present a new algorithm for compressing large 3D triangle meshes through the successive conquest of triangle fans. The connectivity of vertices in a fan is implied. As each fan is traversed, the current mesh boundary is advanced by the fan-front. The process is recursively continued till the entire mesh is traversed. The mesh is then compactly encoded as a sequence of fan configuration codes. The fan configuration code comprehensively encodes the connectivity of the fan with the rest of the mesh. There is no need for any further special operators like split codes and additional vertex offsets. The number of fans is typically one-fourth of the total number of triangles. Only a few of the fan configurations occur with high frequency, enabling excellent connectivity information compression using range encoding. A simple implementation shows significant improvements, on the average, in bit-rate per vertex, compared to earlier reported techniques. (C) 2004 Elsevier B.V. All rights reserved.
C1 Concordia Univ, Dept Comp Sci, Montreal, PQ H3G 1M8, Canada.
   Hewlett Packard ISO, Bangalore, Karnataka, India.
   Natl Ctr Software Technol, Bombay, Maharashtra, India.
C3 Concordia University - Canada; Hewlett-Packard; Centre for Development
   of Advanced Computing (C-DAC)
RP Concordia Univ, Dept Comp Sci, Montreal, PQ H3G 1M8, Canada.
EM mudur@cs.concordia.ca; babji@hp.com; dinesh_shikhare@yahoo.com
CR Aleksandrov L, 1996, SIAM J DISCRETE MATH, V9, P129, DOI 10.1137/S0895480194272183
   ALLIEZ P, 2001, EUROGRAPHICS, P480
   [Anonymous], 1988, An introduction to solid modeling
   Bajaj C. L., 1999, Proceedings Visualization '99 (Cat. No.99CB37067), P307, DOI 10.1109/VISUAL.1999.809902
   Gotsman C, 2003, COMPUT GRAPH FORUM, V22, P99, DOI 10.1111/1467-8659.t01-1-00649
   GOTSMAN C, 2001, P EUR SUMM SCH PRIN
   GUIZIEC A, 1999, IEEE VIS 1999, P73
   GUMHOLD S, 1998, SIGGRAPH 98 C P, P133, DOI DOI 10.1145/280814.280836
   Isenburg M, 2000, COMP GRAPH, P263, DOI 10.1145/344779.344919
   Rossi R, 1998, RRD SYNTH ORG CHEM, V1, P47
   Schindler M, 1998, IEEE DATA COMPR CONF, P572, DOI 10.1109/DCC.1998.672314
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   TUTTE WT, 1962, CANADIAN J MATH, V14, P21, DOI 10.4153/CJM-1962-002-9
NR 13
TC 2
Z9 2
U1 1
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2004
VL 22
IS 14
BP 1165
EP 1173
DI 10.1016/j.imavis.2004.03.020
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 882LG
UT WOS:000225939800003
DA 2024-07-18
ER

PT J
AU Klein, GSW
   Drummond, TW
AF Klein, GSW
   Drummond, TW
TI Tightly integrated sensor fusion for robust visual tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE visual tracking; real-time vision; sensor fusion
ID VISION
AB This paper presents a novel method for increasing the robustness of visual tracking systems by incorporating information from inertial sensors. We show that more can be achieved than simply combining the sensor data within a statistical filter: besides using inertial data to provide predictions for the visual sensor, this data can be used to dynamically tune the parameters of each feature detector in the visual sensor. This allows the visual sensor to provide useful information even in the presence of substantial motion blur. Finally, the visual sensor can be used to calibrate the parameters of the inertial sensor to eliminate drift. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Cambridge, Dept Engn, Cambridge CB1 2PZ, England.
C3 University of Cambridge
RP Univ Cambridge, Dept Engn, Cambridge CB1 2PZ, England.
EM gswk2@cam.ac.uk; twd20@eng.cam.ac.uk
RI Drummond, Tom/A-4696-2011
OI Drummond, Tom/0000-0001-8204-5904
CR [Anonymous], 1992, ACTIVE VISION
   ARMSTRONG M, 1995, P AS C COMP VIS, V1, P58
   CHAI L, 1999, P IEEE ACM IWAR 99 O, P20
   DRUMMOND T, 1999, P BMVC, P574
   Ferrari V, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P87, DOI 10.1109/ISAR.2001.970518
   FURHMANN A, 2001, P IEEE INSTR MEAS TE
   Hoff WA, 1996, P SOC PHOTO-OPT INS, V2904, P538, DOI 10.1117/12.256311
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jiang BL, 2001, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDINGS, P97, DOI 10.1109/ISAR.2001.970519
   Klein G, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P113, DOI 10.1109/ISMAR.2003.1240694
   Koller, 1997, P ACM S VIRT REAL SO
   Marchand E., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P262, DOI 10.1109/ICCV.1999.791229
   Rehbinder H, 2001, MFI2001: INTERNATIONAL CONFERENCE ON MULTISENSOR FUSION AND INTEGRATION FOR INTELLIGENT SYSTEMS, P97, DOI 10.1109/MFI.2001.1013515
   SIMON G, 2000, P INT S AUGM REAL
   VARADARAJAN VS, 1974, GRADUATE TEXTS MATH, V102
   Welch G., 1997, Computer Graphics Proceedings, SIGGRAPH 97, P333, DOI 10.1145/258734.258876
   Yokokohji Y., 2000, Proceedings IEEE Virtual Reality 2000 (Cat. No.00CB37048), P247, DOI 10.1109/VR.2000.840505
   You SY, 2001, P IEEE VIRT REAL ANN, P71, DOI 10.1109/VR.2001.913772
NR 18
TC 27
Z9 92
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 769
EP 776
DI 10.1016/j.imavis.2004.02.007
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300004
DA 2024-07-18
ER

PT J
AU Park, SY
   Subbarao, M
AF Park, SY
   Subbarao, M
TI Automatic 3D model reconstruction based on novel pose estimation and
   integration techniques
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D reconstruction; range image; registration; pose estimation; pose
   integration
AB An automatic three-dimensional (3D) model reconstruction technique is presented to acquire complete and closed 3D models of real objects. The technique is based on novel approaches to pose estimation and integration. Two different poses of an object are used because a single pose often hides some surfaces from a range sensor. A second pose is used to expose such surfaces to the sensor. Two partial 3D models are reconstructed for two different poses of the object using a multi-view 3D modeling technique. The two 3D models are then registered in two steps-coarse registration, and its refinement. Coarse registration is facilitated by a novel pose estimation technique, which estimates a rigid transformation between two models. The pose is estimated by matching a stable tangent plane (STP) of each pose-model with the base tangent plane, which is invariant for a vision system. We employ geometric constraints to find the STP. After registration refinement, two models are integrated to a complete 3D model based on voxel classification defined in multi-view integration. Texture mapping is done to obtain a photo-realistic reconstruction of the object. Reconstruction results and error analysis are presented for several real objects. (C) 2004 Elsevier B.V. All rights reserved.
C1 SUNY Stony Brook, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Stony Brook
RP SUNY Stony Brook, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
EM parksy@ece.sunysb.edu; murali@ece.sunysb.edu
CR Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   Bernardini F, 2001, IEEE T VIS COMPUT GR, V7, P318, DOI 10.1109/2945.965346
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Fitzgibbon A., 1998, LECT NOTES COMPUTER, V1506, P155
   Hilton A., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P117, DOI 10.1007/BFb0015528
   Huber DF, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P153, DOI 10.1109/IM.2001.924424
   IKEUCHI K, 1995, CMUCS95197
   IWAKIRI Y, 2001, COMPUTER GRAPHICS FO, V20
   KANG SB, 1990, CMURITR9018
   KRIEGMAN DJ, 1992, CVGIP-IMAG UNDERSTAN, V55, P109, DOI 10.1016/1049-9660(92)90011-Q
   LANDER P, 1998, THESIS CARNEGIE MELL
   Lensch HPA, 2000, EIGHTH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P317, DOI 10.1109/PCCGA.2000.883955
   Lorensen W. E., 1987, COMPUTER GRAPHICS, V21
   Mirtich B., 1996, Journal of Graphics Tools, V1, P31, DOI DOI 10.1080/10867651.1996.10487458
   Niem W, 1999, IMAGE VISION COMPUT, V17, P125, DOI 10.1016/S0262-8856(98)00116-4
   PARK S, 2002, P VISION MODELING VI
   PARK S, 2002, INT C IM PROC
   PASKO A, 1995, VISUAL COMPUT, V11, P429, DOI 10.1007/BF02464333
   PULI K, 1997, THESIS U WASHINGTON
   Reed MK, 1999, IMAGE VISION COMPUT, V17, P99, DOI 10.1016/S0262-8856(98)00114-0
   RUSINKIEWICZ S, 2002, ACM T GRAPHICS
   Seitz SM, 1997, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.1997.609462
   Stamos I, 2003, PROC CVPR IEEE, P555
   Stamos I, 2002, COMPUT VIS IMAGE UND, V88, P94, DOI 10.1006/cviu.2002.0963
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Wong KYK, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P217, DOI 10.1109/ICCV.2001.937627
   Yang R, 1998, IEEE INT CONF ROBOT, P3115, DOI 10.1109/ROBOT.1998.680904
NR 28
TC 15
Z9 18
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2004
VL 22
IS 8
BP 623
EP 635
DI 10.1016/j.imavis.2004.01.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RV
UT WOS:000221481200004
DA 2024-07-18
ER

PT J
AU Li, PH
   Zhang, TW
   Ma, B
AF Li, PH
   Zhang, TW
   Ma, B
TI Unscented Kalman filter for visual curve tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Statistical Methods in Video Processing
CY JUN 01-02, 2002
CL COPENHAGEN, DENMARK
DE visual tracking; unscented Kalman filter; Kalman filter
AB Visual contour tracking in complex background is a difficult task. The measurement model is often nonlinear due to clutter in images. Traditional visual trackers based on Kalman filters employ simple linear measurement models, and often collapse during the tracking process. This paper presents a new contour tracker based on unscented Kalman filter that is superior to extended Kalman filter both in theory and in many practical situations. The new tracker employs a more accurate nonlinear measurement model, without computation of a Jacobian matrix. During each time step, the tracker makes multiple measurements in terms of the set of appropriately chosen sample points, thus obtaining the best observation according to the measurement density. The resulting algorithm is able to obtain a more exact estimate of the state of the system, while having the same order of complexity as that of an extend Kalman Filter. The experiments show that the new algorithm is superior to those based on Kalman filters. (C) 2003 Elsevier B.V. All rights reserved.
C1 Harbin Inst Technol, Dept Comp Sci & Engn, Harbin 150001, Hei Long Jiang, Peoples R China.
C3 Harbin Institute of Technology
RP Harbin Inst Technol, Dept Comp Sci & Engn, POB 321, Harbin 150001, Hei Long Jiang, Peoples R China.
EM peihualj@hotmail.com
RI zhang, tian/GZK-6001-2022
CR BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1
   BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225
   Blake A., 1998, ACTIVE CONTOURS
   Cipolla R, 1996, IMAGE VISION COMPUT, V14, P171, DOI 10.1016/0262-8856(96)84056-X
   Cipolla R., 1998, Computer Vision for Human-Machine Interaction
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1998, PROC 5 EUROPEAN C CO, V1, P893
   Julier Simon J, 2000, IEEE T AUTOMAT CONTR, p447~482
   Julier SJ, 2002, P AMER CONTR CONF, V1-6, P4555, DOI 10.1109/ACC.2002.1025369
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797
   Li PH, 2002, INT C PATT RECOG, P564, DOI 10.1109/ICPR.2002.1048366
   MacCormick J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P390, DOI 10.1109/ICCV.1998.710748
   MACCORMICK J, 1998, P 5 EUR C COMP VIS, P765
   Maccormickl J., 2000, Partitioned Sampling, Articulated Objects, and Interface-Quality Hand Tracking, P3
   MERSE R, 2000, P IEEE S AD SYST SIG
   MERWE R, 2000, CUEDFINFENGTR380
   Park H, 2001, IEEE T CIRC SYST VID, V11, P252, DOI 10.1109/76.905991
   Peterfreund N, 1999, IEEE T PATTERN ANAL, V21, P564, DOI 10.1109/34.771328
   Peterfreund N, 1999, COMPUT VIS IMAGE UND, V73, P346, DOI 10.1006/cviu.1998.0732
   Sullivan J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1068, DOI 10.1109/ICCV.1999.790391
   Terzopoulos D., 1992, TRACKING KALMAN SNAK, P3
   Wan E. A., 2001, UNSCENTED KALMAN FIL
NR 22
TC 69
Z9 86
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2004
VL 22
IS 2
BP 157
EP 164
DI 10.1016/j.imavis.2003.07.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 769DW
UT WOS:000188612000008
DA 2024-07-18
ER

PT J
AU Jones, GD
   Allsop, RE
   Gilby, JH
AF Jones, GD
   Allsop, RE
   Gilby, JH
TI Bayesian analysis for fusion of data from disparate imaging systems for
   surveillance
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Symposium on Probabilistic Models in Computer Vision
CY MAY, 2001
CL ENGLAND
SP British Mach Vis, Royal Stat Soc
DE data fusion; camera calibration; Markov random fields
AB This paper investigates whether the segmentation of surveillance images can be improved by fusing low-spatial-resolution thermal data with high-spatial-resolution visual information. The context of this investigation is the surveillance of sterile zones where an alarm is required should a person enter the zone and at no other time. The aim is to reduce false alarms due to wildlife movement or changes in environmental conditions. A calibration algorithm has been developed which maps correspondence between the two cameras. By concentrating the area of search on that indicated by the thermal camera, the analysis in both images can then be made more elaborate without undue computational effort. Segmentation of the highlighted object is achieved using Markov Random Fields. (C) 2003 Elsevier B.V. All rights reserved.
C1 Sira Ltd, London, England.
   UCL, Ctr Transport Studies, London, England.
C3 University of London; University College London
RP Sira Ltd, London, England.
EM gwynfor@croeso.com
RI Allsop, Richard/M-7859-2019
OI Allsop, Richard/0000-0002-1751-9373
CR [Anonymous], P INT C PATT REC, DOI 10.1109/ICPR.1990.118221
   Buxton Hilary., 1995, In International Conference on Computer Vision, P111
   FAIRWEATHER AJR, 1997, THESIS UCL
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Hodgetts MA, 1999, UNDERWATER TECHNOL, V23, P157, DOI 10.3723/175605499783259145
   JONES G, 2001, P DERA IEE WORKSH IN
   KADOTA TT, 1994, IEEE T INFORM THEORY, V40, P808, DOI 10.1109/18.335892
   KATO Z, 1606 INRIA
   Solberg AHS, 1996, IEEE T GEOSCI REMOTE, V34, P100, DOI 10.1109/36.481897
   WRIGHT WA, 1989, IMAGE VISION COMPUT, V7, P144, DOI 10.1016/0262-8856(89)90009-7
NR 10
TC 13
Z9 14
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2003
VL 21
IS 10
BP 843
EP 849
DI 10.1016/S0262-8856(03)00071-4
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 723KU
UT WOS:000185432200002
DA 2024-07-18
ER

PT J
AU KaewTrakulPong, P
   Bowden, R
AF KaewTrakulPong, P
   Bowden, R
TI A real time adaptive visual surveillance system for tracking
   low-resolution colour targets in dynamically changing scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Symposium on Probabilistic Models in Computer Vision
CY MAY, 2001
CL ENGLAND
SP British Mach Vis, Royal Stat Soc
DE visual surveillance; multiple target tracking; tracking through
   occlusion; low resolution target; Stochastic search; perceptualised
   colour; particle filter
AB This paper presents a variety of probabilistic models for tracking small-area targets which are common objects of interest in outdoor visual surveillance scenes. We address the problem of using appearance and motion models in classifying and tracking objects when detailed information of the object's appearance is not available. The approach relies upon motion, shape cues and colour information to help in associating objects temporally within a video stream. Unlike previous applications of colour and complex shape in object tracking, where relatively large-size targets are tracked, our method is designed to track small colour targets commonly found in outdoor visual surveillance. Our approach uses a robust background model based around online Expectation Maximisation to segment moving objects with very low false detection rates. The system also incorporates a shadow detection algorithm which helps alleviate standard environmental problems associated with such approaches. A colour transformation derived from anthropological studies to model colour distributions of low-resolution targets is used along with a probabilistic method of combining colour and motion information. A data association algorithm is applied to maintain tracking of multiple objects under circumstances. Simple shape information is employed to detect subtle interactions such as occlusion and camouflage. A novel guided search algorithm is then introduced to facilitate tracking of multiple objects during these events. This provides a robust visual tracking system which is capable of performing accurately and consistently within a real world visual surveillance arena. This paper shows the system successfully tracking multiple people moving independently and the ability of the approach to maintain trajectories in the presence of occlusions and background clutter. (C) 2003 Published by Elsevier B.V.
C1 King Mongkuts Univ Technol Thonburi, INC, Bangkok 10140, Thailand.
   Univ Surrey, ECM, CVSSP, Surrey GU2 7XH, England.
C3 King Mongkuts University of Technology Thonburi; University of Surrey
RP King Mongkuts Univ Technol Thonburi, INC, 91 Prachauthit Rd Suksawad 48 Bangmod,Thung Kharu, Bangkok 10140, Thailand.
EM ipakpong@kmutt.ac.th; r.bowden@surrey.ac.uk
RI Kaewtrakulpong, Pakorn/F-9084-2013; Bowden, Richard/AAF-8283-2019
OI Kaewtrakulpong, Pakorn/0000-0003-4761-714X; Bowden,
   Richard/0000-0003-3285-8020
CR [Anonymous], 1998, 4 IEEE WORKSH APPL C
   Bar-Shalom Y., 1995, MULTITARGET MULTISEN
   Bar-Shalom Yaakov., 1993, ESTIMATION TRACKING
   Berlin B., 1991, Basic color terms: Their universality and evolution
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Blackman S., 1999, Design and analysis of modern tracking systems
   BOWDEN R, 2002, SMART GRAPHICS 02, P124
   CARPANETO G, 1980, ACM T MATH SOFTWARE, V6, P104, DOI 10.1145/355873.355883
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   HORPRASERT T, 1999, FRAM RATE99 WORKSH
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   ISARD M, 1996, P EUR C COMP VIS CAM, V1, P343
   Kaewtrakulpong P., 2001, 2 EUR WORKSH ADV VID
   KAEWTRAKULPONG P, 2001, BMVC01
   KOLLER D, 1994, EUR C COMP VIS, P189
   Lipton AJ, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P8, DOI 10.1109/ACV.1998.732851
   McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   Raja Y., 1998, PROC EUROPEAN C COMP, P460
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   RASMUSSEN C, 1998, CVPR98, P16
   Seaborn M., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P103
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   STURGES J, 1995, COLOR RES APPL, V20, P364, DOI 10.1002/col.5080200605
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 28
TC 62
Z9 75
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2003
VL 21
IS 10
BP 913
EP 929
DI 10.1016/S0262-8856(03)00076-3
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 723KU
UT WOS:000185432200007
DA 2024-07-18
ER

PT J
AU Lee, HY
   Kim, T
   Park, W
   Lee, HK
AF Lee, HY
   Kim, T
   Park, W
   Lee, HK
TI Extraction of digital elevation models from satellite stereo images
   through stereo matching based on epipolarity and scene geometry
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereo matching; digital elevation model; epipolar geometry
ID ALGORITHM
AB This paper addresses the problem of generating digital elevation models from satellite images taken by linear pushbroom cameras. Since there exist unique geometric properties for linear pushbroom images, we argue that the conventional DEM generation schemes developed for perspective images are not suitable for satellite images. Using the geometric properties of linear pushbroom, images, we design a new matching strategy optimized for linear pushbroom image in three aspects: conjugate search method, correlation patch design and match sequence determination. We will discuss in what aspect conventional approaches and our new approach differ and show how performance has improved by hiring proper techniques. A series of experiments using SPOT panchromatic stereo pairs showed that our approach outperformed conventional approaches in terms of accuracy and processing time. (C) 2003 Elsevier B.V. All rights reserved.
C1 Korea Adv Inst Sci & Technol, Dept EECS, Taejon 305701, South Korea.
   Inha Univ, Dept Geoinformat Engn, Inchon 402751, South Korea.
   SaTReCi, Taejon 305811, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST); Inha
   University
RP Lee, HY (corresponding author), Korea Adv Inst Sci & Technol, Dept EECS, 373-1 Kusung Dong, Taejon 305701, South Korea.
RI Lee, Heung Kyu/C-1941-2011
CR AlRousan N, 1997, PHOTOGRAMM ENG REM S, V63, P965
   [Anonymous], 1985, South African Journal of Photogrammetry, Remote Sensing and Cartography
   DHOND UR, 1989, IEEE T SYST MAN CYB, V19, P1489, DOI 10.1109/21.44067
   Gupta R, 1997, IEEE T PATTERN ANAL, V19, P963, DOI 10.1109/34.615446
   Kim T, 2000, PHOTOGRAMM ENG REM S, V66, P961
   Kim T, 2001, PHOTOGRAMM ENG REM S, V67, P449
   Krupnik A, 2000, PHOTOGRAMM ENG REM S, V66, P1017
   ONeill M, 1996, IMAGE VISION COMPUT, V14, P225, DOI 10.1016/0262-8856(95)01061-0
   ORUN AB, 1994, PHOTOGRAMM ENG REM S, V60, P1431
   OTTO GP, 1989, IMAGE VISION COMPUT, V7, P83, DOI 10.1016/0262-8856(89)90001-2
   POLLARD SB, 1985, PERCEPTION, V14, P449, DOI 10.1068/p140449
   TATEISHI R, 1992, INT J REMOTE SENS, V13, P2517, DOI 10.1080/01431169208904061
   Zhang ZX, 2000, PHOTOGRAMM ENG REM S, V66, P625
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 14
TC 42
Z9 47
U1 0
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2003
VL 21
IS 9
BP 789
EP 796
DI 10.1016/S0262-8856(03)00092-1
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 711QX
UT WOS:000184753500003
DA 2024-07-18
ER

PT J
AU Cremers, D
   Schnörr, C
AF Cremers, D
   Schnörr, C
TI Statistical shape knowledge in variational motion segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE statistical learning; variational methods; motion segmentation;
   Mumford-Shah functional; region competition; shape recognition;
   diffusion snake
ID OPTICAL-FLOW; SNAKES; MODEL; COMPUTATION
AB We present a generative approach to model-based motion segmentation by incorporating a statistical shape prior into a novel variational segmentation method. The shape prior statistically encodes a training set of object outlines presented in advance during a training phase.
   In a region competition manner the proposed variational approach maximizes the homogeneity of the motion vector field estimated on a set of regions, thus evolving the separating discontinuity set. Due to the shape prior, this discontinuity set is not only sensitive to motion boundaries but also favors shapes according to the statistical shape knowledge.
   In numerical examples we verify several properties of the proposed approach: for objects which cannot be easily discriminated from the background by their appearance, the desired motion segmentation is obtained, although the corresponding segmentation based on image intensities fails. The region-based formulation facilitates convergence of the contour from its initialization over fairly large distances, and the estimated flow field is progressively improved during the gradient descent minimization. Due to the shape prior, partial occlusions of the moving object by 'unfamiliar' objects are ignored, and the evolution of the motion boundary is effectively restricted to the subspace of familiar shapes. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Univ Mannheim, Dept Math & Comp Sci, Comp Vis Graph & Pattern Recognit Grp, D-68131 Mannheim, Germany.
C3 University of Mannheim
RP Univ Mannheim, Dept Math & Comp Sci, Comp Vis Graph & Pattern Recognit Grp, D-68131 Mannheim, Germany.
EM cremers@uni-mannheim.de; schnoerr@uni-mannheim.de
OI Cremers, Daniel/0000-0002-3079-7984
CR AMBROSIO L, 1990, COMMUN PUR APPL MATH, V43, P999, DOI 10.1002/cpa.3160430805
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Blake A., 1998, ACTIVE CONTOURS
   Caselles V, 1996, SIAM J NUMER ANAL, V33, P2445, DOI 10.1137/S0036142994275044
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 1999, IMAGE VISION COMPUT, V17, P567, DOI 10.1016/S0262-8856(98)00175-9
   Cremers D, 2002, LECT NOTES COMPUT SC, V2351, P93
   Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915
   CREMERS D, 2002, LNCS, V2449, P472
   Farin G., 1997, Curves and surfaces for computer-aided geometric design: A practical guide
   Farnebäck G, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P171, DOI 10.1109/ICCV.2001.937514
   FARNEBACK G, 1999, THESIS LINKOPINGS U
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   HEAP T, 1997, BRIT MACH VIS C COLC
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kervrann C, 1999, IEEE T IMAGE PROCESS, V8, P583, DOI 10.1109/83.753745
   Kornprobst P, 1999, J MATH IMAGING VIS, V11, P5, DOI 10.1023/A:1008318126505
   Memin E, 1998, IEEE T IMAGE PROCESS, V7, P703, DOI 10.1109/83.668027
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   NESI P, 1993, IMAGE VISION COMPUT, V11, P419, DOI 10.1016/0262-8856(93)90046-J
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   Odobez JM, 1998, SIGNAL PROCESS, V66, P143, DOI 10.1016/S0165-1684(98)00003-6
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   SCHNORR C, 1992, INT J COMPUT VISION, V8, P153, DOI 10.1007/BF00127172
   SCHNORR C, 1994, 12 INT C PATT REC JE
   Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 27
TC 38
Z9 44
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 77
EP 86
AR PII S0262-8856(02)00128-2
DI 10.1016/S0262-8856(02)00128-2
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800009
DA 2024-07-18
ER

PT J
AU Oh, J
   Yoon, D
   Kim, I
AF Oh, Junseok
   Yoon, Donghwee
   Kim, Injung
TI One-shot Ultra-high-Resolution Generative Adversarial Network That
   Synthesizes 16K Images On A Single GPU
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE One-shot image synthesis; UHR image synthesis; Seamless subregion-wise
   super-resolution; Vertical coordinate convolution; Generative
   adversarial network (GAN)
AB We propose a one-shot ultra-high-resolution generative adversarial network (OUR-GAN) framework that generates non-repetitive 16K (16, 384 x 8, 640) images from a single training image and is trainable on a single consumer GPU. OUR-GAN generates an initial image that is visually plausible and varied in shape at low resolution, and then gradually increases the resolution by adding detail through super-resolution. Since OUR-GAN learns from a real ultra-high-resolution (UHR) image, it can synthesize large shapes with fine details and longrange coherence, which is difficult to achieve with conventional generative models that rely on the patch distribution learned from relatively small images. OUR-GAN can synthesize high-quality 16K images with 12.5 GB of GPU memory and 4K images with only 4.29 GB as it synthesizes a UHR image part by part through seamless subregion-wise super-resolution. Additionally, OUR-GAN improves visual coherence while maintaining diversity by applying vertical positional convolution. In experiments on the ST4K and RAISE datasets, OUR-GAN exhibited improved fidelity, visual coherency, and diversity compared with the baseline one-shot synthesis models. To the best of our knowledge, OUR-GAN is the first one-shot image synthesizer that generates non-repetitive UHR images on a single consumer GPU. The synthesized image samples are presented at https://our-gan.github.io.
C1 [Oh, Junseok; Yoon, Donghwee; Kim, Injung] Handong Global Univ, Sch CSEE, Pohang 37554, South Korea.
C3 Handong Global University
RP Kim, I (corresponding author), Handong Global Univ, Sch CSEE, Pohang 37554, South Korea.
EM junseokoh96@gmail.com; yoondonghwee@gmail.com; ijkim@handong.edu
OI Kim, Injung/0000-0003-4439-6097
FU MSIT (Ministry of Science and ICT) , Korea , under the National Program
   for Excellence in SW) [2023-0-00055]; POSCO
FX This research was supported by the MSIT (Ministry of Science and ICT) ,
   Korea, under the National Program for Excellence in SW) supervised by
   the IITP (Institute of Information & Communications Technology Planning
   & Evaluation) in 2023 (2023-0-00055) . This research was supported by
   POSCO.
CR Bergmann U., 2017, Proceedings of the 34th International Conference on Machine Learning-Volume, P469
   Dang-Nguyen D.T., 2015, P ACM MULT SYST C, P219
   Denton E, 2015, ADV NEUR IN, V28
   Elnekave A, 2022, LECT NOTES COMPUT SC, V13677, P544, DOI 10.1007/978-3-031-19790-1_33
   Esser P, 2021, PROC CVPR IEEE, P12868, DOI 10.1109/CVPR46437.2021.01268
   github, Caneorst., Ingan
   Granot N, 2022, PROC CVPR IEEE, P13450, DOI 10.1109/CVPR52688.2022.01310
   Gu SH, 2019, IEEE INT CONF COMP V, P3512, DOI 10.1109/ICCVW.2019.00435
   Gupta K, 2020, PROC CVPR IEEE, P4745, DOI 10.1109/CVPR42600.2020.00480
   Gur S., 2020, P 34 INT C NEUR INF, P16761
   Hassani A, 2022, Arxiv, DOI arXiv:2209.15001
   Hertz Amir, 2022, arXiv
   Hinz T, 2021, IEEE WINT CONF APPL, P1299, DOI 10.1109/WACV48630.2021.00134
   Ho J., 2020, Advances in neural information processing systems, V33, P6840
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jeong J, 2024, Arxiv, DOI arXiv:2303.15403
   Justin, EXPT STABLE DIFFUSIO
   Karras T, 2018, P INT C LEARN REPR I
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Karras Tero, 2020, IEEE C COMP VIS PATT
   Kim G, 2022, PROC CVPR IEEE, P2416, DOI 10.1109/CVPR52688.2022.00246
   Kulikov V, 2022, Arxiv, DOI arXiv:2211.16582
   Kwon M, 2022, Arxiv, DOI arXiv:2210.10960
   Liang J., Advances in Neural Information Processing Systems
   Liang JY, 2021, IEEE INT CONF COMP V, P1833, DOI 10.1109/ICCVW54120.2021.00210
   Liu R, 2018, ADV NEUR IN, V31
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Lu CC, 2020, Arxiv, DOI arXiv:2007.12411
   Luo WJ, 2016, ADV NEUR IN, V29
   Mokady Ron, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P6038, DOI 10.1109/CVPR52729.2023.00585
   Nichol A, 2022, Arxiv, DOI [arXiv:2112.10741, DOI 10.48550/ARXIV.2112.10741]
   Nikankin Y, 2023, Arxiv, DOI arXiv:2211.11743
   Oh J, 2023, Arxiv, DOI arXiv:2202.13799
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramesh A., 2022, arXiv, DOI 10.48550/arXiv.2204.06125
   Rombach R, 2022, PROC CVPR IEEE, P10674, DOI 10.1109/CVPR52688.2022.01042
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruiz Nataniel, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P22500, DOI 10.1109/CVPR52729.2023.02155
   Saharia C., 2022, Advances in Neural Information Processing Systems, V35, P36479
   Shaham T.R., 2019, IEEE I CONF COMP VIS
   Shocher A, 2019, Arxiv, DOI arXiv:1812.00231
   Shocher A, 2018, PROC CVPR IEEE, P3118, DOI 10.1109/CVPR.2018.00329
   Skorokhodov I, 2021, P IEEE CVF INT C COM, P14144
   Soh JW, 2020, PROC CVPR IEEE, P3513, DOI 10.1109/CVPR42600.2020.00357
   Sohl-Dickstein J, 2015, PR MACH LEARN RES, V37, P2256
   Stability-AI, stablediffusion
   Sungha Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9370, DOI 10.1109/CVPR42600.2020.00939
   Sushko V, 2023, Arxiv, DOI arXiv:2103.13389
   tamarott, Singan
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tumanyan Narek, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P1921, DOI 10.1109/CVPR52729.2023.00191
   Ulyanov D, 2016, PR MACH LEARN RES, V48
   Voynov A, 2023, Arxiv, DOI arXiv:2303.09522
   Wang D., 2021, 2021 IEEE INT C MULT, P1
   Wang D, 2023, INFORM FUSION, V98, DOI 10.1016/j.inffus.2023.101828
   Wang D, 2022, Arxiv, DOI [arXiv:2205.11876, DOI 10.48550/ARXIV.2205.11876]
   Wang JK, 2022, PR MACH LEARN RES
   Wang P, 2021, PROC CVPR IEEE, P3680, DOI 10.1109/CVPR46437.2021.00368
   Wang Weilun, 2022, arXiv
   Wang XP, 2018, IDEAS HIST MOD CHINA, V19, P1, DOI 10.1163/9789004385580_002
   Wu Qiucheng, 2023, 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P1900, DOI 10.1109/CVPR52729.2023.00189
   Xu XQ, 2024, Arxiv, DOI arXiv:2211.08332
   Zha ZC, 2023, IEEE T CIRC SYST VID, V33, P3947, DOI 10.1109/TCSVT.2023.3236636
   Zhang H, 2019, IEEE T PATTERN ANAL, V41, P1947, DOI 10.1109/TPAMI.2018.2856256
   Zhang H, 2017, IEEE I CONF COMP VIS, P5908, DOI 10.1109/ICCV.2017.629
   Zhang K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4771, DOI 10.1109/ICCV48922.2021.00475
   Zhang KH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14749, DOI 10.1109/ICCV48922.2021.01450
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
   Zhang ZC, 2022, AAAI CONF ARTIF INTE, P3408
   Zhang ZC, 2022, Arxiv, DOI arXiv:2105.07350
   Zhang ZZ, 2018, PROC CVPR IEEE, P6199, DOI 10.1109/CVPR.2018.00649
NR 71
TC 0
Z9 0
U1 2
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104815
DI 10.1016/j.imavis.2023.104815
EA SEP 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA U1CK4
UT WOS:001082251000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kawano, K
   Kutsuna, T
   Tokuhisa, R
   Nakamura, A
   Esaki, Y
AF Kawano, Keisuke
   Kutsuna, Takuro
   Tokuhisa, Ryoko
   Nakamura, Akihiro
   Esaki, Yasushi
TI StyleDiff: Attribute comparison between unlabeled datasets in latent
   disentangled space
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dataset comparing; StyleSpace; Optimal transport
AB One major challenge in machine learning applications is coping with mismatches between the datasets used in the development and those obtained in real-world applications. These mismatches may lead to inaccurate pre-dictions and errors, resulting in poor product quality and unreliable systems. To address the mismatches, it is important to understand in what sense the two datasets differ. In this study, we propose StyleDiff to inform developers about the types of mismatches between the two datasets in an unsupervised manner. Given two unlabeled image datasets, StyleDiff automatically extracts latent attributes that are distributed differently be-tween the given datasets and visualizes the differences in a human-understandable manner. For example, for an object detection dataset, latent attributes might include the time of day, weather, and traffic congestion of an image that are not explicitly labeled. StyleDiff helps developers understand the differences between the datasets with respect to such latent attribute distributions. Developers can then, for example, collect additional development data with these attributes and conduct additional tests for these attributes to enhance reliability. We demonstrate that StyleDiff accurately detects differences between datasets and presents them in an under-standable format using, for example, driving scene datasets.
C1 [Kawano, Keisuke; Kutsuna, Takuro; Tokuhisa, Ryoko; Nakamura, Akihiro; Esaki, Yasushi] Toyota Cent Res & Dev Labs Inc, 41-1 Yokomichi, Nagakute, Aichi 4801192, Japan.
C3 Toyota Central R&D Labs Inc
RP Kawano, K (corresponding author), Toyota Cent Res & Dev Labs Inc, 41-1 Yokomichi, Nagakute, Aichi 4801192, Japan.
EM kawano@mosk.tytlabs.co.jp
OI Esaki, Yasushi/0009-0002-4380-9769
CR Alaluf Y., 2022, arXiv
   Alaluf Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6691, DOI 10.1109/ICCV48922.2021.00664
   Alias-Free Generative Adversarial Networks (StyleGAN3), 2021, Official PyTorch implementation of the NeurIPS 2021 paper
   Alvarez-Melis D., 2020, ADV NEURAL INFORM PR, V33, P21428
   Alvarez-Melis D, 2018, Arxiv, DOI arXiv:1809.00013
   An J., 2015, Special Lecture on IE, V2, P1
   Bachem O, 2017, Arxiv, DOI arXiv:1703.06476
   Benamou JD, 2015, SIAM J SCI COMPUT, V37, pA1111, DOI 10.1137/141000439
   Breunig MM, 2000, SIGMOD REC, V29, P93, DOI 10.1145/335191.335388
   Chong MJ, 2020, PROC CVPR IEEE, P6069, DOI 10.1109/CVPR42600.2020.00611
   Chong Min Jin, 2021, P IEEE CVF INT C COM, P3887
   Coletta LFS, 2019, NEUROCOMPUTING, V358, P150, DOI 10.1016/j.neucom.2019.04.070
   Cuturi M., 2013, ADV NEURAL INFORM PR, P2292, DOI DOI 10.48550/ARXIV.1306.0895
   DOWSON DC, 1982, J MULTIVARIATE ANAL, V12, P450, DOI 10.1016/0047-259X(82)90077-X
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   github, 2021, ReStyle: A Residual-Based StyleGAN Encoder via Iterative Refinement (ICCV 2021)
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Harkonen E., 2020, Advances in Neural Information Processing Systems, V33, P9841
   Hensel M, 2017, ADV NEUR IN, V30
   Holub A, 2008, PROC CVPR IEEE, P885
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kawano K, 2022, AAAI CONF ARTIF INTE, P7115
   Kim Ki Hyun, 2019, INT C LEARNING REPRE
   Lang O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P673, DOI 10.1109/ICCV48922.2021.00073
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Marcel S., 2010, P 18 ACM INT C MULTI, P1485, DOI DOI 10.1145/1873951.1874254
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   Peyré G, 2019, FOUND TRENDS MACH LE, V11, P355, DOI 10.1561/2200000073
   Schölkopf B, 2000, ADV NEUR IN, V12, P582
   Sener O., 2018, ICLR POSTER
   Shui CJ, 2020, PR MACH LEARN RES, V108
   Wu ZZ, 2021, PROC CVPR IEEE, P12858, DOI 10.1109/CVPR46437.2021.01267
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
NR 34
TC 0
Z9 0
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104808
DI 10.1016/j.imavis.2023.104808
EA SEP 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA T4AV4
UT WOS:001077440100001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Boscaini, D
   Poiesi, F
AF Boscaini, Davide
   Poiesi, Fabio
TI PatchMixer: Rethinking network design to boost generalization for 3D
   point cloud understanding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D deep learning; Point cloud understanding; Classification;
   Segmentation; Transfer learning
AB The recent trend in deep learning methods for 3D point cloud understanding is to propose increasingly sophisticated architectures either to better capture 3D geometries or by introducing possibly undesired inductive biases. Moreover, prior works introducing novel architectures compared their performance on the same domain, devoting less attention to their generalization to other domains. We argue that the ability of a model to transfer the learnt knowledge to different domains is an important feature that should be evaluated to exhaustively assess the quality of a deep network architecture. In this work we propose PatchMixer, a simple yet effective architecture that extends the ideas behind the recent MLP-Mixer paper to 3D point clouds. The novelties of our approach are the processing of local patches instead of the whole shape to promote robustness to partial point clouds, and the aggregation of patch-wise features using an MLP as a simpler alternative to the graph convolutions or the attention mechanisms that are used in prior works. We evaluated our method on the shape classification and part segmentation tasks, achieving superior generalization performance compared to a selection of the most relevant deep architectures.
C1 [Boscaini, Davide; Poiesi, Fabio] Fdn Bruno Kessler, Technol Vis Lab, Via Sommar 18, I-38123 Trento, Italy.
C3 Fondazione Bruno Kessler
RP Boscaini, D (corresponding author), Fdn Bruno Kessler, Technol Vis Lab, Via Sommar 18, I-38123 Trento, Italy.
EM dboscaini@fbk.eu
FU European Union's Horizon Europe research and innovation programme
   [101058589]; PNRR project FAIR-Future AI Research [PE00000013]; NRRP MUR
   program-NextGenerationEU; Horizon Europe - Pillar II [101058589] Funding
   Source: Horizon Europe - Pillar II
FX This work was supported by the European Union's Horizon Europe research
   and innovation programme under grant agreement No 101058589 (AI-PRISM) ,
   and by the PNRR project FAIR-Future AI Research (PE00000013) , under the
   NRRP MUR program funded by the NextGenerationEU.
CR Achituve I, 2021, IEEE WINT CONF APPL, P123, DOI 10.1109/WACV48630.2021.00017
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   Astolfi P., 2020, MICCAI
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Boscaini D, 2016, COMPUT GRAPH FORUM, V35, P431, DOI 10.1111/cgf.12844
   Boscaini D, 2015, COMPUT GRAPH FORUM, V34, P13, DOI 10.1111/cgf.12693
   Boscaini D, 2016, ADV NEUR IN, V29
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Choe J, 2022, LECT NOTES COMPUT SC, V13687, P620, DOI 10.1007/978-3-031-19812-0_36
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Defferrard M, 2016, ADV NEUR IN, V29
   Engel N, 2021, IEEE ACCESS, V9, P134826, DOI 10.1109/ACCESS.2021.3116304
   Fang H.-S., 2020, P IEEECVF C COMPUTER, P11444
   Gainza P, 2020, NAT METHODS, V17, P184, DOI 10.1038/s41592-019-0666-6
   Guo MH, 2021, COMPUT VIS MEDIA, V7, P187, DOI 10.1007/s41095-021-0229-5
   Guo YL, 2021, IEEE T PATTERN ANAL, V43, P4338, DOI 10.1109/TPAMI.2020.3005434
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kipf TN, 2016, ARXIV
   Li YY, 2018, ADV NEUR IN, V31
   Loshchilov Ilya, 2016, arXiv
   Ma Xu, 2022, ICLR
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Monti F, 2017, PROC CVPR IEEE, P5425, DOI 10.1109/CVPR.2017.576
   Poiesi F, 2023, IEEE T PATTERN ANAL, V45, P3979, DOI 10.1109/TPAMI.2022.3175371
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qi CR, 2016, PROC CVPR IEEE, P5648, DOI 10.1109/CVPR.2016.609
   Qin C., 2019, NEURIPS
   Shen YF, 2022, PROC CVPR IEEE, P7213, DOI 10.1109/CVPR52688.2022.00708
   Simonovsky M, 2017, PROC CVPR IEEE, P29, DOI 10.1109/CVPR.2017.11
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Svoboda J., 2020, IJCB
   Tolstikhin I, 2021, ADV NEUR IN, V34
   Trockman A, 2022, Arxiv, DOI [arXiv:2201.09792, DOI 10.48550/ARXIV.2201.09792,09792]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic Petar, 2018, INT C LEARN REPR
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Chang AX, 2015, Arxiv, DOI arXiv:1512.03012
   Yi L, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980238
   Zhang Z., 2022, IJCV, V130
   Zhang ZY, 2019, IEEE I CONF COMP VIS, P1607, DOI 10.1109/ICCV.2019.00169
   Zhang ZY, 2019, INT CONF 3D VISION, P204, DOI 10.1109/3DV.2019.00031
   Zhao HS, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16239, DOI 10.1109/ICCV48922.2021.01595
   Zhou YJ, 2022, IEEE ROBOT AUTOM LET, V7, P6335, DOI 10.1109/LRA.2022.3156940
NR 48
TC 0
Z9 0
U1 3
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104768
DI 10.1016/j.imavis.2023.104768
EA AUG 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P8GJ0
UT WOS:001052997200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Cao, JZ
   Yao, ZJ
   Yu, LG
   Ling, BWK
AF Cao, Jiangzhong
   Yao, Zijie
   Yu, Lianggeng
   Ling, Bingo Wing-Kuen
TI WPE: Weighted prototype estimation for few-shot learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Few-shot learning; Knowledge transfer; Data augmentation; Prototype
   estimation; Image classification
ID NETWORK
AB Few-shot learning (FSL) is a challenging task that aims to transfer a model trained on base classes with adequate labeled data to accommodate novel classes with only a few training examples. In this paper, we propose a simple but effective weighted prototype estimation (WPE) method to improve FSL. We assume that similar classes have similar distributions in the feature space so that the prototypes of novel classes can be estimated by transferring information from their similar base classes. Specifically, the proposed method learns the Gaussian-like feature distributions of similar base classes with sufficient samples and then transfers the learned distributions to cali-brate the prototype of the novel class, which is weighted by its similarities. With the estimated prototype, more robust samples can be generated to improve the FSL task. Comparative experiments are conducted to evaluate the effectiveness of our proposed algorithm on three benchmark FSL datasets. The results show that our proposed method can generate more robust samples and significantly improve FSL, outperforming the state-of-the-art methods on these datasets.
C1 [Cao, Jiangzhong; Yao, Zijie; Yu, Lianggeng; Ling, Bingo Wing-Kuen] Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
C3 Guangdong University of Technology
RP Cao, JZ (corresponding author), Guangdong Univ Technol, Sch Informat Engn, Guangzhou 510006, Peoples R China.
EM cjz510@gdut.edu.cn; 2112003137@mail2.gdut.edu.cn;
   2112003153@mail2.gdut.edu.cn; yongquanling@gdut.edu.cn
CR [Anonymous], 2016, P BRIT MACH VIS C
   Antoniou Antreas, 2017, ARXIV171104340
   Bertinetto Luca, 2018, P INT C LEARN REPR
   Bin Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P438, DOI 10.1007/978-3-030-58548-8_26
   Chen W.Y., 2019, ICLR, DOI DOI 10.1109/MSR.2015.54
   Chen Y., 2020, ARXIV200304390
   Chen ZT, 2019, IEEE T IMAGE PROCESS, V28, P4594, DOI 10.1109/TIP.2019.2910052
   Chi ZQ, 2022, IEEE T CIRC SYST VID, V32, P4163, DOI 10.1109/TCSVT.2021.3125129
   Cui ZY, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104574
   Dai W, 2022, AM J NEURORADIOL, DOI 10.3174/ajnr.A7556
   Dixit M, 2017, PROC CVPR IEEE, P3328, DOI 10.1109/CVPR.2017.355
   Finn C, 2017, PR MACH LEARN RES, V70
   Fu W, 2022, IEEE SIGNAL PROC LET, V29, P982, DOI 10.1109/LSP.2022.3152686
   Hariharan B, 2017, IEEE I CONF COMP VIS, P3037, DOI 10.1109/ICCV.2017.328
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hosmer DW, 2013, WILEY SER PROBAB ST, P1
   Hu SX, 2022, PROC CVPR IEEE, P9058, DOI 10.1109/CVPR52688.2022.00886
   Hu YQ, 2021, LECT NOTES COMPUT SC, V12892, P487, DOI 10.1007/978-3-030-86340-1_39
   Kaya M, 2019, SYMMETRY-BASEL, V11, DOI 10.3390/sym11091066
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kwitt R, 2016, PROC CVPR IEEE, P78, DOI 10.1109/CVPR.2016.16
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li Z., 2017, Meta-sgd: Learning to learn quickly for few-shot learning
   Ling Jie, 2022, P IEEECVF C COMPUTER, P14564
   Ling Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13387, DOI 10.1109/CVPR42600.2020.01340
   Liu ZZ, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103924
   Lu J, 2020, Arxiv, DOI arXiv:2009.02653
   Lu J, 2018, PATTERN RECOGN, V80, P129, DOI 10.1016/j.patcog.2018.03.006
   Mangla P, 2020, IEEE WINT CONF APPL, P2207, DOI [10.1109/wacv45572.2020.9093338, 10.1109/WACV45572.2020.9093338]
   Mazumder P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104006
   Noble WS, 2006, NAT BIOTECHNOL, V24, P1565, DOI 10.1038/nbt1206-1565
   Pedregosa F, 2011, J MACH LEARN RES, V12, P2825
   Qin T., 2020, arXiv
   Ravi S., 2016, INT C LEARNING REPRE
   Ravichandran A, 2019, IEEE I CONF COMP VIS, P331, DOI 10.1109/ICCV.2019.00042
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Rusu A. A., 2019, INT C LEARN REPR
   Schwartz E, 2018, ADV NEUR IN, V31
   Shao S, 2022, IEEE T CIRC SYST VID, V32, P5151, DOI 10.1109/TCSVT.2021.3135023
   Shao S, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4193, DOI 10.1145/3474085.3475553
   Snell J, 2017, ADV NEUR IN, V30
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tukey J.W., 1977, EXPLORATORY DATA ANA
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Van Nhan Nguyen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P118, DOI 10.1007/978-3-030-58592-1_8
   Vanschoren J, 2018, Arxiv, DOI [arXiv:1810.03548, DOI 10.48550/ARXIV.1810.03548]
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wang YX, 2018, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR.2018.00760
   Wang Y, 2019, IEEE I CONF COMP VIS, P3522, DOI 10.1109/ICCV.2019.00362
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Wu JY, 2021, KNOWL-BASED SYST, V225, DOI 10.1016/j.knosys.2021.107129
   Xu JY, 2022, PROC CVPR IEEE, P8993, DOI 10.1109/CVPR52688.2022.00880
   Xu R, 2022, IEEE T CIRC SYST VID, V32, P8674, DOI 10.1109/TCSVT.2022.3196550
   Yang S., 2020, INT C LEARNING REPRE, P1
   Yaoyao Liu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P404, DOI 10.1007/978-3-030-58517-4_24
   Yu Z., 2020, CVPR, P12856
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zeng XK, 2022, COMPUT ELECTR ENG, V102, DOI 10.1016/j.compeleceng.2022.108133
   Zhang BQ, 2021, PROC CVPR IEEE, P3753, DOI 10.1109/CVPR46437.2021.00375
   Zhang B, 2022, IEEE T IMAGE PROCESS, V31, P2309, DOI 10.1109/TIP.2022.3154938
   Zhang HG, 2019, PROC CVPR IEEE, P2765, DOI 10.1109/CVPR.2019.00288
   Zhang J, 2019, IEEE I CONF COMP VIS, P1685, DOI 10.1109/ICCV.2019.00177
   Zhang RX, 2018, ADV NEUR IN, V31
NR 66
TC 3
Z9 3
U1 7
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104757
DI 10.1016/j.imavis.2023.104757
EA JUL 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P1WI2
UT WOS:001048610900001
DA 2024-07-18
ER

PT J
AU Feng, Y
   Chen, JL
   He, SL
   Xu, EY
AF Feng, Yong
   Chen, Jinglong
   He, Shuilong
   Xu, Enyong
TI ABC: Aligning binary centers for single-stage monocular 3D detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Autonomous driving; Single stage; Monocular detection; Double heads;
   Non-maximal suppression (NMS)
AB Precisely perceiving the environment through a 3D perspective is essential and challenging for autonomous navigation and driving. Existing techniques rely on depth from LiDAR data or disparity in stereo vision to solve the poorly presented problem of detecting far-off and occluded objects. This increases structure complexity and computation burden, especially for single-stage systems. We argue that existing well-established detectors have the intrinsic potential to detect full-scene objects, but the extrinsic capabilities are limited by the structure form and optimization. Hence, we propose a double-branch single-stage monocular 3D object detection framework that aligns binary centers of object. Structurally, we construct two symmetrical and independent detectors, respectively using different prediction manners for 3D box parameters. Functionally, two detection heads have different sensitivities for the same object due to disentangling alignment. During the training, the detection heads were trained separately to obtain specific ability and aligned to promote the convergence. At inference, predictions of two branches are filtered via depth-aware non-maximal suppression (NMS) to acquire comprehensive detection results. Extensive experiments demonstrate that the proposed method achieves the state-of-the-art performance in monocular 3D detection on the KITTI-3D benchmark. (C) 2023 Elsevier B.V. All rights reserved.
C1 [Feng, Yong; Chen, Jinglong] Xi An Jiao Tong Univ, State Key Lab Mfg & Syst Engn, Xian 710049, Peoples R China.
   [He, Shuilong] Guilin Univ Elect Technol, Sch Mech & Elect Engn, Guilin 541004, Peoples R China.
   [Xu, Enyong] Huazhong Univ Sci & Technol, Sch Mech Sci & Engn, Wuhan 430074, Peoples R China.
   [Xu, Enyong] Dongfeng Liuzhou Motor Co Ltd, Liuzhou 545005, Peoples R China.
C3 Xi'an Jiaotong University; Guilin University of Electronic Technology;
   Huazhong University of Science & Technology
RP Chen, JL (corresponding author), Xi An Jiao Tong Univ, State Key Lab Mfg & Syst Engn, Xian 710049, Peoples R China.
EM fengyong1997@stu.xjtu.edu.cn; jlstrive2008@mail.xjtu.edu.cn
RI 辛, 雨菲/JBS-6390-2023
FU Guangxi Science and Technology Major Project; Scientific research and
   technology development in Liuzhou [2021AAA0112]; National Natural
   Science Foundation of China [52275129]; Fundamental Research Funds for
   the Central Universities [XZY022022026, XZY022021006]
FX This work is supported financially by the Guangxi Science and Technology
   Major Project (No. Guike AA22068001) , Scientific research and
   technology development in Liuzhou (No. 2021AAA0112) , National Natural
   Science Foundation of China (No. 52275129) and Fundamental Research
   Funds for the Central Universities (No. XZY022022026, No. XZY022021006)
   .
CR Andrew A.M., 2001, Multiple view geometry in computer vision
   Bao WT, 2020, IEEE T IMAGE PROCESS, V29, P2753, DOI 10.1109/TIP.2019.2952201
   Beltrán J, 2018, IEEE INT C INTELL TR, P3517, DOI 10.1109/ITSC.2018.8569311
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Brazil Garrick, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P135, DOI 10.1007/978-3-030-58592-1_9
   Brazil G, 2019, IEEE I CONF COMP VIS, P9286, DOI 10.1109/ICCV.2019.00938
   Bulò SR, 2018, PROC CVPR IEEE, P5639, DOI 10.1109/CVPR.2018.00591
   Chabot F., P IEEE C COMP VIS PA, P2040
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen M., 2022, IEEE Sensors Journal
   Chen SN, 2020, APPL SOFT COMPUT, V97, DOI 10.1016/j.asoc.2020.106804
   Chen XZ, 2016, PROC CVPR IEEE, P2147, DOI 10.1109/CVPR.2016.236
   Chen XZ, 2015, ADV NEUR IN, V28
   Chen Y., P IEEECVF C COMPUTER, P12093
   Dai DY, 2021, WORLD ELECTR VEHIC J, V12, DOI 10.3390/wevj12030139
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Godard C, 2017, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2017.699
   Gu J., P IEEE CVF C COMP VI
   Guan H, 2022, PATTERN RECOGN, V132, DOI 10.1016/j.patcog.2022.108967
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   He T, 2019, AAAI CONF ARTIF INTE, P8409
   Hong DS, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103955
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   J”rgensen E, 2019, Arxiv, DOI arXiv:1906.08070
   Königshofe H, 2019, IEEE INT C INTELL TR, P1405, DOI 10.1109/ITSC.2019.8917330
   Kumar A., P IEEE CVF C COMP VI, P8973
   Kundu A, 2018, PROC CVPR IEEE, P3559, DOI 10.1109/CVPR.2018.00375
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li BY, 2019, PROC CVPR IEEE, P1019, DOI 10.1109/CVPR.2019.00111
   Li PL, 2019, PROC CVPR IEEE, P7636, DOI 10.1109/CVPR.2019.00783
   Li PX, 2021, IEEE ROBOT AUTOM LET, V6, P5565, DOI 10.1109/LRA.2021.3061343
   Li Peixuan, 2020, EUROPEAN C COMPUTER, P644
   Li Z., P IEEECVF C COMPUTER, P2791
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu YX, 2021, IEEE INT CONF ROBOT, P13018, DOI 10.1109/ICRA48506.2021.9561423
   Liu ZC, 2020, IEEE COMPUT SOC CONF, P4289, DOI 10.1109/CVPRW50498.2020.00506
   Lu Y., P IEEE CVF INT C COM, P3111
   Luo S., P IEEE CVF C COMP VI, P6145
   Ma XZ, 2021, PROC CVPR IEEE, P4719, DOI 10.1109/CVPR46437.2021.00469
   Manhardt F, 2019, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2019.00217
   Mousavian A., P IEEE C COMP VIS PA, P7074
   Park D., P IEEE CVF INT C COM, P3142
   Park JJ, 2019, PROC CVPR IEEE, P165, DOI 10.1109/CVPR.2019.00025
   Qian R., 2022, Pattern Recogn, Patent No. 108796
   Qin ZY, 2019, AAAI CONF ARTIF INTE, P8851
   Reading C., P IEEE CVF C COMP VI, P8555
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Shi X., P IEEE CVF INT C COM, P15172
   Simonelli Andrea, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P767, DOI 10.1007/978-3-030-58542-6_46
   Simonelli A, 2019, IEEE I CONF COMP VIS, P1991, DOI 10.1109/ICCV.2019.00208
   Tao CB, 2021, KNOWL-BASED SYST, V229, DOI 10.1016/j.knosys.2021.107346
   Wang GJ, 2022, IEEE T INTELL TRANSP, V23, P12953, DOI 10.1109/TITS.2021.3118698
   Wang T., C ROBOT LEARNING PML, P1475
   Wang T, 2021, IEEE INT CONF COMP V, P913, DOI 10.1109/ICCVW54120.2021.00107
   Wang Y., P IEEE CVF C COMP VI, P8445
   Wu Y., P IEEECVF C COMPUTER, P10186
   Xiang Y, 2017, IEEE WINT CONF APPL, P924, DOI 10.1109/WACV.2017.108
   Xiao WP, 2022, IMAGE VISION COMPUT, V127, DOI 10.1016/j.imavis.2022.104557
   Xie Z., 2022, SENSORS-BASEL, V22
   Xu B, 2018, PROC CVPR IEEE, P2345, DOI 10.1109/CVPR.2018.00249
   Xu ZB, 2020, AAAI CONF ARTIF INTE, V34, P12557
   Yan JJ, 2020, Arxiv, DOI arXiv:2001.06838
   Ye MS, 2020, PROC CVPR IEEE, P1628, DOI 10.1109/CVPR42600.2020.00170
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zhang YP, 2021, PROC CVPR IEEE, P3288, DOI 10.1109/CVPR46437.2021.00330
   Zhou DF, 2019, INT CONF 3D VISION, P85, DOI 10.1109/3DV.2019.00019
   Zhou XY, 2019, Arxiv, DOI [arXiv:1904.07850, 10.48550/arXiv.1904.07850]
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 70
TC 0
Z9 0
U1 4
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104741
DI 10.1016/j.imavis.2023.104741
EA JUN 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA L6VF1
UT WOS:001024610900001
DA 2024-07-18
ER

PT J
AU Sinha, KP
   Kumar, P
AF Sinha, Kumari Priyanka
   Kumar, Prabhat
TI Human activity recognition from UAV videos using a novel DMLC-CNN model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human activity recognition (HAR); Unmanned aerial vehicle (UAV)
   clustering; Segmentation; Diminutive multi-dimensional locality coding;
   based convolutional neural network; (DMLC-CNN); And anomaly detection
AB Human Activity Recognition (HAR) remains a challenging issue that requires to be resolved. Utilizing images, smart phones, or sensors, HAR could be done. Recent studies have explored HAR utilizing Unmanned Aerial Ve-hicle (UAV) videos. But, owing to numerous restrictions correlated to the platform, HAR from videos captured by drones remains a challenge. To resolve this issue, a novel mechanism for HAR from UAV videos utilizing the Di-minutive Multi-Dimensional Locality Coding based Convolutional Neural Network (DMLC-CNN) model is pro-posed. Primarily, the input video is converted into frames; also, Bounding Boxes (BBs) are produced for humans. For attaining the number of clusters grounded on human presence, the BB is given to the Robust Lucra-tive Sensitive Amalgam K-Nearest Neighbor (RoLSA-KNN) clustering. After that, utilizing the LR-fit-centric Supe-rior Photogrammetric Silhouette (LR-SPS) segmentation, the humans' silhouettes are segmented. The attained output is divided into patches; then, it is converted into stacked layer frames. Afterward, these frames are con-verted into a 3D kernel. The Diminutive Multi-Dimensional Hyper Graph (DMHG) extracted the features; then, the Locality-constrained Orthonormal Feature Space Coding (LOFSC) Algorithm encoded the extracted features. Lastly, for recognizing Human Activity (HA), DMLC-CNN is wielded. The proposed framework is contrasted with the conventional techniques. After experimental evaluation, the proposed mechanism was found to be more efficient in HAR.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Sinha, Kumari Priyanka] Nalanda Coll Engn, Dept Comp Sci & Engn, Chandi, Bihar, India.
   [Kumar, Prabhat] Natl Inst Technol Patna, Dept Comp Sci & Engn, Patna, Bihar, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Patna
RP Sinha, KP (corresponding author), Nalanda Coll Engn, Dept Comp Sci & Engn, Chandi, Bihar, India.
EM kumaripriyankas@outlook.com; prabhat@nitp.ac.in
CR Al Machot F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030825
   Challa SK, 2022, VISUAL COMPUT, V38, P4095, DOI 10.1007/s00371-021-02283-3
   Choi J, 2020, IEEE WINT CONF APPL, P1706, DOI 10.1109/WACV45572.2020.9093511
   Chung S, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071716
   Dang LM, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107561
   Detection D.O., 2021, AIRBORNE AIRCRAFT DE, P1
   Figueiredo D., 2020, TESTBED CONNECTED AR, P1, DOI [10.21528/cbic2019-131, DOI 10.21528/CBIC2019-131]
   Geraldes R, 2019, IEEE ACCESS, V7, P122583, DOI 10.1109/ACCESS.2019.2938249
   Han Peng, 2020, Advances in Visual Computing. 15th International Symposium, ISVC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12509), P276, DOI 10.1007/978-3-030-64556-4_22
   Hayat A, 2022, INFORMATION, V13, DOI 10.3390/info13060275
   Khan MA, 2023, ARAB J SCI ENG, V48, P2609, DOI 10.1007/s13369-021-05881-4
   Kiefer B., 2021, LEVERAGING SYNTHETIC, P1
   Kotecha K, 2021, DRONES-BASEL, V5, DOI 10.3390/drones5030087
   Li HB, 2020, IEEE SENS J, V20, P1191, DOI 10.1109/JSEN.2019.2946095
   Mantau AJ, 2022, DRONES-BASEL, V6, DOI 10.3390/drones6100290
   Mliki H, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107140
   Perera AG, 2019, DRONES-BASEL, V3, DOI 10.3390/drones3040082
   Sahoo SP, 2019, INT CONF ADVAN COMPU, P1012, DOI [10.1109/icaccs.2019.8728473, 10.1109/ICACCS.2019.8728473]
   Subramaniam RR, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103132
   Sultani W, 2021, COMPUT VIS IMAGE UND, V206, DOI 10.1016/j.cviu.2021.103186
   Varga L.A., 2022, COMPREHENSIVE ANAL O, P9876
   Varga LA, 2022, IEEE WINT CONF APPL, P3686, DOI 10.1109/WACV51458.2022.00374
   Wang J, 2021, SENSOR ACTUAT A-PHYS, V321, DOI 10.1016/j.sna.2021.112583
   Wu QT, 2020, IET INTELL TRANSP SY, V14, P278, DOI 10.1049/iet-its.2019.0455
   Yuan H, 2020, EURASIP J WIREL COMM, V2020, DOI 10.1186/s13638-020-1654-3
NR 25
TC 3
Z9 3
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2023
VL 134
AR 104674
DI 10.1016/j.imavis.2023.104674
EA APR 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA G3BC5
UT WOS:000987941700001
DA 2024-07-18
ER

PT J
AU Chen, HY
   Mei, X
   Ma, ZY
   Wu, XH
   Wei, YC
AF Chen, Haoyang
   Mei, Xue
   Ma, Zhiyuan
   Wu, Xinhong
   Wei, Yachuan
TI Spatial-temporal graph attention network for video anomaly detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video anomaly detection; Multiple instance learning; Graph convolutional
   network; Multi-head graph attention
ID CONVOLUTIONAL NETWORKS; LOCALIZATION
AB Video anomaly detection, which is weakly supervised by video-level annotations, is a frequent yet challenging task in computer vision owing to its unexpectedness, equivocality, rarity, irregularity, and diversity. Although previous seminal works successfully leveraged graph convolutions to assist in the detection of anomalies, they failed to subsequently explore the potential of this approach. In this study, we developed a spatial-temporal graph attention network (STGA), which, to the best of our knowledge, is the first effort to combine graph convolutions with a multi-head graph attention mechanism for video anomaly detection. Specifically, a spatial correlation graph and temporal dependence graph were devised to learn distinguishable representations with the complementation of graph attention techniques. Furthermore, STGA was incorporated within the multiple instance learning (MIL) pipeline, and optimized via top-k MIL ranking loss after a sparse continuous sampling strategy was put into effect. We conducted experiments using four multi-scale datasets to validate the efficacy of our model. Quantitatively, our method performs equivalently to the current best result on ShanghaiTech with a frame-level area under the curve (AUC) of 97.21%, obtains the second-best result on UCSD-Ped2 with a frame-level AUC of 97.4%, gains a frame-level AUC of 80.28% on UCF-Crime, and achieves a new state-of-the-art performance on TAD with a frame-level AUC of 91.42%. Additionally, our false alarm rate results outperform those obtained in previous studies on ShanghaiTech and UCF-Crime, which demonstrates the robustness of our approach. All relevant code has been made available at https://github.com/hychen96/STGA-VAD. & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Chen, Haoyang; Mei, Xue; Ma, Zhiyuan; Wu, Xinhong; Wei, Yachuan] Nanjing Tech Univ, Nanjing 211816, Peoples R China.
C3 Nanjing Tech University
RP Mei, X (corresponding author), Nanjing Tech Univ, Nanjing 211816, Peoples R China.
EM mx@njtech.edu.cn
OI Ma, Zhiyuan/0000-0002-9819-2164
FU Research Center of Security Video and Image Processing Engineering
   Technology of Guizhou (China) under Grant SRC-Open Project [20201001]
FX This work was supported by Research Center of Security Video and Image
   Processing Engineering Technology of Guizhou (China) under Grant
   SRC-Open Project ([20201001).
CR Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8097, DOI 10.1109/ICCV48922.2021.00801
   Bao LQ, 2019, IEEE COMPUT SOC CONF, P1496, DOI 10.1109/CVPRW.2019.00191
   Bertasius G, 2021, PR MACH LEARN RES, V139
   Calderara S, 2011, COMPUT VIS IMAGE UND, V115, P1099, DOI 10.1016/j.cviu.2011.03.003
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Cheng Y, 2021, AAAI CONF ARTIF INTE, V35, P1157
   Doshi K, 2022, IEEE WINT CONF APPL, P3007, DOI 10.1109/WACV51458.2022.00306
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan LF, 2019, IEEE I CONF COMP VIS, P5723, DOI 10.1109/ICCV.2019.00582
   Feng JC, 2021, PROC CVPR IEEE, P14004, DOI 10.1109/CVPR46437.2021.01379
   Gao K., 2022, CVPR, P19497
   Georgescu MI, 2021, PROC CVPR IEEE, P12737, DOI 10.1109/CVPR46437.2021.01255
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   He CK, 2018, MULTIMED TOOLS APPL, V77, P29573, DOI 10.1007/s11042-017-5255-z
   Huang D, 2020, AAAI CONF ARTIF INTE, V34, P11021
   Hyunjong Park, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14360, DOI 10.1109/CVPR42600.2020.01438
   Jaechul Kim, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2921, DOI 10.1109/CVPRW.2009.5206569
   Suarez JJP, 2020, Arxiv, DOI arXiv:2009.14146
   Jiang F, 2011, COMPUT VIS IMAGE UND, V115, P323, DOI 10.1016/j.cviu.2010.10.008
   Jingli Wang, 2021, Arabian Journal of Geosciences, V14, DOI 10.1007/s12517-021-06893-y
   Kaur Phulpreet, 2018, 2018 International Conference on Advances in Computing, Communication Control and Networking (ICACCCN). Proceedings, P607, DOI 10.1109/ICACCCN.2018.8748454
   Li C, 2013, NEUROCOMPUTING, V119, P94, DOI 10.1016/j.neucom.2012.03.040
   Li J, 2020, AAAI CONF ARTIF INTE, V34, P4626
   Li WX, 2015, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2015.7299056
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liu JF, 2021, IEEE INT CONF ROBOT, P3374, DOI 10.1109/ICRA48506.2021.9561605
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   Liu ZA, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13568, DOI 10.1109/ICCV48922.2021.01333
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Luo WX, 2021, NEUROCOMPUTING, V444, P332, DOI 10.1016/j.neucom.2019.12.148
   Luo WX, 2017, IEEE I CONF COMP VIS, P341, DOI 10.1109/ICCV.2017.45
   Luo WX, 2017, IEEE INT CON MULTI, P439, DOI 10.1109/ICME.2017.8019325
   Lv H, 2021, PROC CVPR IEEE, P15420, DOI 10.1109/CVPR46437.2021.01517
   Lv H, 2021, IEEE T IMAGE PROCESS, V30, P4505, DOI 10.1109/TIP.2021.3072863
   Markovitz Amir, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10536, DOI 10.1109/CVPR42600.2020.01055
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Kipf TN, 2017, Arxiv, DOI arXiv:1609.02907
   Nayak R, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104078
   Pang GS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3439950
   Peng Wu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P322, DOI 10.1007/978-3-030-58577-8_20
   Purwanto D, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P173, DOI 10.1109/ICCV48922.2021.00024
   Ribeiro M, 2018, PATTERN RECOGN LETT, V105, P13, DOI 10.1016/j.patrec.2017.07.016
   Medel JR, 2016, Arxiv, DOI arXiv:1612.00390
   Sabzalian Behnam, 2019, 2019 4th International Conference on Pattern Recognition and Image Analysis (IPRIA), P173, DOI 10.1109/PRIA.2019.8786007
   Soldan Mattia, 2021, P IEEE CVF INT C COM, P3224
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sunkesula SPR, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P691, DOI 10.1145/3394171.3413778
   Tian Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4955, DOI 10.1109/ICCV48922.2021.00493
   Tomei M, 2021, COMPUT VIS IMAGE UND, V206, DOI 10.1016/j.cviu.2021.103187
   Tsai YHH, 2019, PROC CVPR IEEE, P10416, DOI 10.1109/CVPR.2019.01067
   Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003
   Varga V, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9534302
   Vaswani A, 2017, ADV NEUR IN, V30
   Veličkovic P, 2018, Arxiv, DOI arXiv:1710.10903
   Wan BY, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102722
   Wang SQ, 2018, NEUROCOMPUTING, V277, P161, DOI 10.1016/j.neucom.2016.08.156
   Wang WG, 2019, IEEE I CONF COMP VIS, P9235, DOI 10.1109/ICCV.2019.00933
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   Xiankai Lu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P661, DOI 10.1007/978-3-030-58580-8_39
   Xinhui Wu, 2020, Pattern Recognition. 5th Asian Conference, ACPR 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12047), P274, DOI 10.1007/978-3-030-41299-9_22
   Xu D, 2014, NEUROCOMPUTING, V143, P144, DOI 10.1016/j.neucom.2014.06.011
   Xue R., 2020, 2020 5 INT C UNIVERS, P1, DOI [10.1109/uv50937.2020.9426191, DOI 10.1109/UV50937.2020.9426191]
   Yan S., 2018, AAAI, P1
   Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550
   Zhang JG, 2019, IEEE IMAGE PROC, P4030, DOI [10.1109/ICIP.2019.8803657, 10.1109/icip.2019.8803657]
   Zhang Si, 2019, Comput Soc Netw, V6, P11, DOI 10.1186/s40649-019-0069-y
   Zhang Y, 2016, PATTERN RECOGN, V51, P443, DOI 10.1016/j.patcog.2015.09.005
   Zhang Zhu, 2020, P IEEECVF C COMPUTER, P10668
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhu SJ, 2020, Arxiv, DOI arXiv:2004.00222
   Zhu Y, 2019, Arxiv, DOI arXiv:1907.10211
NR 74
TC 4
Z9 4
U1 7
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2023
VL 131
AR 104629
DI 10.1016/j.imavis.2023.104629
EA JAN 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA M3MZ9
UT WOS:001029266900001
DA 2024-07-18
ER

PT J
AU Srivastava, A
   Chanda, S
   Pal, U
AF Srivastava, Abhishek
   Chanda, Sukalpa
   Pal, Umapada
TI AGA-GAN: Attribute Guided Attention Generative Adversarial Network with
   U-Net for face hallucination
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face hallucination; Generative adversarial network; U-Net; Spatial
   attention
ID SUPERRESOLUTION
AB The performance of facial super-resolution methods relies on their ability to recover facial structures and salient features effectively. Even though the convolutional neural network and generative adversarial network-based methods deliver impressive performances on face hallucination tasks, the ability to use attributes associated with the low-resolution images to improve performance is unsatisfactory. In this paper, we propose an Attribute Guided Attention Generative Adversarial Network which employs novel attribute guided attention (AGA) mod-ules to identify and focus the generation process on various facial features in the image. Stacking multiple AGA modules enables the recovery of both high and low-level facial structures. We design the discriminator to learn discriminative features by exploiting the relationship between the high-resolution image and their corre-sponding facial attribute annotations. We then explore the use of U-Net based architecture to refine existing predictions and synthesize further facial details. Extensive experiments across several metrics show that our AGA-GAN and AGA-GAN +U-Net framework outperforms several other cutting-edge face hallucination state-of-the-art methods. We also demonstrate the viability of our method when every attribute descriptor is not known and thus, establishing its application in real-world scenarios. Our code is available at https://github. com/NoviceMAn-prog/AGA-GAN.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Srivastava, Abhishek] Northwestern Univ, Machine & Hybrid Intelligence Lab, Chicago, IL 60611 USA.
   [Chanda, Sukalpa] Ostfold Univ Coll, Dept Comp Sci & Commun, Halden, Norway.
   [Pal, Umapada] Indian Stat Inst, Comp Vis & Pattern Recognit Unit, Kolkata 700108, W Bengal, India.
C3 Northwestern University; Ostfold University College; Indian Statistical
   Institute; Indian Statistical Institute Kolkata
RP Srivastava, A (corresponding author), Northwestern Univ, Machine & Hybrid Intelligence Lab, Chicago, IL 60611 USA.
EM abhishek.srivastava@northwestern.edu; sukalpa@ieee.org;
   umapada@isical.ac.in
RI Pal, Umapada/AAC-4930-2022
FU Research Council of Norway
FX This is a collaborative research work between Indian Statistical
   Institute, Kolkata, India and Ostfold University College, Halden,
   Norway. Theexperiments in this paper were performed on a high
   performance com-puting platform"Experimental Infrastructure for
   Exploration ofExascale Computing"(eX3), which is funded by the Research
   Council of Norway.
CR Baker S., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P83, DOI 10.1109/AFGR.2000.840616
   Chang H, 2004, PROC CVPR IEEE, P275, DOI 10.1109/cvpr.2004.1315043
   Chen CF, 2021, IEEE T IMAGE PROCESS, V30, P1219, DOI 10.1109/TIP.2020.3043093
   Chen XZ, 2020, NEUROCOMPUTING, V376, P119, DOI 10.1016/j.neucom.2019.09.079
   Deng J., 2009, J ALLOY COMPD, P248, DOI DOI 10.1016/j.jallcom.2006.10.076
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Grm K, 2020, IEEE T IMAGE PROCESS, V29, P2150, DOI 10.1109/TIP.2019.2945835
   Gunturk BK, 2003, IEEE T IMAGE PROCESS, V12, P597, DOI 10.1109/TIP.2003.811513
   Hsu CC, 2019, IEEE T IMAGE PROCESS, V28, P6225, DOI 10.1109/TIP.2019.2924554
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang CE, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21237817
   Huang CE, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175973
   Huang HB, 2017, IEEE I CONF COMP VIS, P1698, DOI 10.1109/ICCV.2017.187
   Indradi SD, 2019, 2019 7 INT C INFORM, P1
   Jiang K, 2020, IEEE T MULTIMEDIA, V22, P2734, DOI 10.1109/TMM.2019.2960586
   Lanaras C, 2018, ISPRS J PHOTOGRAMM, V146, P305, DOI 10.1016/j.isprsjprs.2018.09.018
   Lee CH, 2018, IEEE COMPUT SOC CONF, P834, DOI 10.1109/CVPRW.2018.00115
   Liang Y, 2013, SIGNAL PROCESS, V93, P445, DOI 10.1016/j.sigpro.2012.08.014
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Liu C, 2001, PROC CVPR IEEE, P192
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Ma X, 2010, PATTERN RECOGN, V43, P2224, DOI 10.1016/j.patcog.2009.12.019
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mnih V, 2014, Arxiv, DOI [arXiv:1406.6247, DOI 10.48550/ARXIV.1406.6247, 10.48550/arXiv.1406.6247]
   Rakotonirina NC, 2020, INT CONF ACOUST SPEE, P3637, DOI 10.1109/ICASSP40776.2020.9054071
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Salimans T, 2016, Arxiv, DOI [arXiv:1606.03498, DOI 10.48550/ARXIV.1606.03498]
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun J, 2011, IEEE T IMAGE PROCESS, V20, P1529, DOI 10.1109/TIP.2010.2095871
   Szegedy C., 2017, PROC AAAI C ARTIFI I, V31
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang LB, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1551, DOI 10.1145/3394171.3413965
   Yu X, 2016, LECT NOTES COMPUT SC, V9909, P318, DOI 10.1007/978-3-319-46454-1_20
   Zhang KB, 2015, IEEE T IMAGE PROCESS, V24, P846, DOI 10.1109/TIP.2015.2389629
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang XJ, 2008, IEEE T IMAGE PROCESS, V17, P887, DOI 10.1109/TIP.2008.924279
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhou EJ, 2015, AAAI CONF ARTIF INTE, P3871
   Zou WWW, 2012, IEEE T IMAGE PROCESS, V21, P327, DOI 10.1109/TIP.2011.2162423
NR 49
TC 6
Z9 6
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104534
DI 10.1016/j.imavis.2022.104534
EA SEP 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5S1KH
UT WOS:000874957400003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xue, YB
   Zhang, DD
   Li, LD
   Li, SY
   Wang, YX
AF Xue, Yanbing
   Zhang, Doudou
   Li, Leida
   Li, Shiyin
   Wang, Yuxin
TI Lightweight multi-scale convolutional neural network for real time
   stereo matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo matching; Multi-scale; Refinement; Lightweight
AB In order to accurately estimate disparities in textureless and slim regions, spatial pyramid pooling and stacked 3D CNN, which can capture global context information, are widely used in state-of-the-art stereo matching algo-rithms. Unfortunately, the computational complexity and high memory consumption make these methods not friendly to real-time applications such as autonomous driving and augmented realities. In order to balance the real-time performance and accuracy, we design lightweight multi-scale convolutional neural network for real-time stereo matching. First, Lightweight multi-scale 2D and 3D CNN modules are proposed for feature extraction and initial disparity computation respectively. Both of above modules only run on a low resolution to further re -duce the amount of calculation. Second, multi-scale RGB images guided network is utilized to refine the final dis-parity estimation. Experiments on several datasets show that the proposed algorithm can achieve competitive results with speed of 64fps on a NIVDIA 1080 GPU.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Xue, Yanbing; Li, Leida; Li, Shiyin] China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.
   [Xue, Yanbing; Zhang, Doudou] Tianjin Univ technol, Sch Comp Sci & Engn, Tianjin 300384, Peoples R China.
   [Li, Leida] Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.
   [Wang, Yuxin] Tianjin Agr Univ, Sch Comp & Informat Engn, Tianjin 300392, Peoples R China.
C3 China University of Mining & Technology; Tianjin University of
   Technology; Xidian University; Tianjin Agricultural University
RP Li, LD (corresponding author), China Univ Min & Technol, Sch Informat & Control Engn, Xuzhou 221116, Peoples R China.; Li, LD (corresponding author), Xidian Univ, Sch Artificial Intelligence, Xian 710071, Peoples R China.; Wang, YX (corresponding author), Tianjin Agr Univ, Sch Comp & Informat Engn, Tianjin 300392, Peoples R China.
EM ldli@xidian.edu.cn; wangyx@tjau.edu.cn
RI Zhang, Doudou/JXN-2720-2024; Li, Li/AEM-3636-2022; li, li/HII-4157-2022
FU National Natural Science Foundation of China [61872270]
FX Acknowledgements The authors would like to express appreciation for the
   financial sup-port provided by the National Natural Science Foundation
   of China (61872270) .
CR [Anonymous], ECCV
   [Anonymous], 2017, P IEEE C COMP VIS PA
   Bahdanau D, 2016, Arxiv, DOI [arXiv:1409.0473, 10.48550/arXiv.1409.0473]
   Chabra R, 2019, PROC CVPR IEEE, P11778, DOI 10.1109/CVPR.2019.01206
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen QF, 2017, IEEE I CONF COMP VIS, P2516, DOI 10.1109/ICCV.2017.273
   Chen QF, 2017, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2017.168
   Dovesi Pier Luigi, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P10780, DOI 10.1109/ICRA40945.2020.9196784
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3
   Gharbi M, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073592
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hirschmüller H, 2005, PROC CVPR IEEE, P807, DOI 10.1109/cvpr.2005.56
   Hosni A, 2009, IEEE IMAGE PROC, P2093, DOI 10.1109/ICIP.2009.5414478
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Laga H, 2022, IEEE T PATTERN ANAL, V44, P1738, DOI 10.1109/TPAMI.2020.3032602
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Nie WZ, 2021, IEEE T MULTIMEDIA, V23, P1021, DOI 10.1109/TMM.2020.2991532
   Nie WZ, 2021, IEEE T MULTIMEDIA, V23, P1962, DOI 10.1109/TMM.2020.3006371
   Nie WZ, 2022, IEEE T CIRC SYST VID, V32, P992, DOI 10.1109/TCSVT.2021.3070969
   Odena A., 2016, DISTILL, V1, pe3, DOI 10.23915/distill.00003.-URL
   Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108
   Papandreou G, 2015, PROC CVPR IEEE, P390, DOI 10.1109/CVPR.2015.7298636
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shaked A, 2017, PROC CVPR IEEE, P6901, DOI 10.1109/CVPR.2017.730
   Song X, 2019, LECT NOTES COMPUT SC, V11365, P20, DOI 10.1007/978-3-030-20873-8_2
   Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028
   Wang Q, 2020, IEEE INT CONF ROBOT, P101, DOI [10.1109/icra40945.2020.9197031, 10.1109/ICRA40945.2020.9197031]
   Yang M., 2020, P IEEECVF C COMPUTER, P12885, DOI DOI 10.1109/CVPR42600.2020.01290
   Yang XW, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104336
   Yin ZC, 2019, PROC CVPR IEEE, P6037, DOI 10.1109/CVPR.2019.00620
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
NR 39
TC 4
Z9 5
U1 3
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104510
DI 10.1016/j.imavis.2022.104510
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800009
DA 2024-07-18
ER

PT J
AU Iqbal, J
   Rawal, H
   Ha, R
   Chi, YT
   Ali, M
AF Iqbal, Javed
   Rawal, Hamza
   Ha, Rehan
   Chi, Yu-Tseh
   Ali, Mohsen
TI Distribution regularized self-supervised learning for domain adaptation
   of semantic segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic segmentation; Self -supervised learning; Domain adaptation;
   Multi -modal distribution learning
AB This paper proposes a novel pixel-level distribution regularization scheme (DRSL) for self-supervised domain ad-aptation of semantic segmentation. In a typical setting, the classification loss forces the semantic segmentation model to greedily learn the representations that capture inter-class variations in order to determine the decision (class) boundary. Due to the domain-shift, this decision boundary is unaligned in the target domain, resulting in noisy pseudo labels adversely affecting self-supervised domain adaptation. To overcome this limitation, along with capturing inter-class variation, we capture pixel-level intra-class variations through class-aware multi -modal distribution learning (MMDL). Thus, the information necessary for capturing the intra-class variations is explicitly disentangled from the information necessary for inter-class discrimination. Features captured thus are much more informative, resulting in pseudo-labels with low noise. This disentanglement allows us to per-form separate alignments in discriminative space and multi-modal distribution space, using cross-entropy based self-learning for former. For later, we propose novel stochastic mode alignment method, by explicitly de-creasing the distance between the target and source pixels that map to the same mode. The distance metric learn-ing loss, computed over pseudo-labels and backpropagated from multi-modal modeling head, acts as the regularizer over the base network shared with the segmentation head. The results from comprehensive experi-ments on synthetic to real domain adaptation setups, i.e., GTA-V/SYNTHIA to Cityscapes, show that DRSL outper-forms many existing approaches (a minimum margin of 2.3% and 2.5% in mIoU for SYNTHIA to Cityscapes).(c) 2022 Elsevier B.V. All rights reserved.
C1 [Iqbal, Javed; Rawal, Hamza; Ha, Rehan; Ali, Mohsen] Informat Technol Univ, Lahore 54000, Pakistan.
   [Chi, Yu-Tseh] Facebook, 1 Hacker Way, Menlo Pk, CA 94025 USA.
C3 Facebook Inc
RP Iqbal, J (corresponding author), Informat Technol Univ, Lahore 54000, Pakistan.
EM javed.iqbal@itu.edu.pk; mscs18004@itu.edu.pk; rehan.hafiz@itu.edu.pk;
   jchi@fb.com; mohsen.ali@itu.edu.pk
RI Iqbal, Javed/ABB-8148-2020; Ali, Mohsen/GQQ-7190-2022
OI Iqbal, Javed/0000-0003-3056-5128; 
CR [Anonymous], 2021, ADV NEURAL INFORM PR
   [Anonymous], 2017, COMP VIS ICCV 2017 I, DOI DOI 10.1109/ICCV.2017.220
   [Anonymous], 2017, ICCV
   Chang WL, 2019, PROC CVPR IEEE, P1900, DOI 10.1109/CVPR.2019.00200
   Chen C, 2020, AAAI CONF ARTIF INTE, V34, P3422
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y., IEEE C COMP VIS PATT
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Dai D., 2019, INT J COMPUT VIS, P1
   Deng Z., 2019, P IEEE CVF INT C COM
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004
   Guo XQ, 2021, PROC CVPR IEEE, P3926, DOI 10.1109/CVPR46437.2021.00392
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hoffman J, 2018, PR MACH LEARN RES, V80
   Hsu HK, 2020, IEEE WINT CONF APPL, P738, DOI [10.1109/WACV45572.2020.9093358, 10.1109/wacv45572.2020.9093358]
   Iqbal J., 2020, IEEE WINT C APPL COM
   Iqbal J, 2022, NEUROCOMPUTING, V501, P844, DOI 10.1016/j.neucom.2022.05.086
   Karlinsky L, 2019, PROC CVPR IEEE, P5192, DOI 10.1109/CVPR.2019.00534
   Khodabandeh M, 2019, IEEE I CONF COMP VIS, P480, DOI 10.1109/ICCV.2019.00057
   Kumagai A, 2019, AAAI CONF ARTIF INTE, P4106
   Li YM, 2019, PROC CVPR IEEE, P8712, DOI 10.1109/CVPR.2019.00892
   Lian Q, 2019, IEEE I CONF COMP VIS, P6757, DOI 10.1109/ICCV.2019.00686
   Luo YW, 2019, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2019.00261
   Mancini M, 2018, PROC CVPR IEEE, P3771, DOI 10.1109/CVPR.2018.00397
   Myeongjin Kim, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12972, DOI 10.1109/CVPR42600.2020.01299
   Nguyen-Meidine L, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104096
   Pan F, 2020, PROC CVPR IEEE, P3763, DOI 10.1109/CVPR42600.2020.00382
   Pinheiro PO, 2018, PROC CVPR IEEE, P8004, DOI 10.1109/CVPR.2018.00835
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schrom S, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104209
   Subhani M.N., 2020, P EUR C COMP VIS ECC, P1
   Tsai YH, 2019, IEEE I CONF COMP VIS, P1456, DOI 10.1109/ICCV.2019.00154
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Vu T.-H., 2019, IEEE INT C COMP VIS
   Wei DM, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278040
   Wu ZF, 2019, PATTERN RECOGN, V90, P119, DOI 10.1016/j.patcog.2019.01.006
   Xu RJ, 2019, IEEE I CONF COMP VIS, P1426, DOI 10.1109/ICCV.2019.00151
   Yang JY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9174, DOI 10.1109/ICCV48922.2021.00906
   Zhang B, 2020, IEEE IMAGE PROC, P2221, DOI 10.1109/ICIP40778.2020.9190829
   Zhang JT, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P3001, DOI 10.1109/ICASSP.2018.8462111
   Zhang QM, 2019, ADV NEUR IN, V32
   Zhonghao Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12632, DOI 10.1109/CVPR42600.2020.01265
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
   Zou Y, 2019, IEEE I CONF COMP VIS, P5981, DOI 10.1109/ICCV.2019.00608
NR 47
TC 4
Z9 4
U1 2
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104504
DI 10.1016/j.imavis.2022.104504
EA JUL 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3F6VI
UT WOS:000830804100003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Soni, PK
   Choudhary, A
AF Soni, Pramod Kumar
   Choudhary, Ayesha
TI Grassmann manifold based framework for automated fall detection from a
   camera
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human fall detection; Assistive living; Grassmann manifolds; Grassmann
   graph embedding discriminant; analysis
ID DETECTION SYSTEM
AB In this paper, we propose a Grassmann manifold based novel, real-time framework for automated fall detection in an indoor environment using a single camera. Fall is an activity that is uncontrolled, unintentional, involuntary and can occur while a person is doing any daily living activity. This is especially true for the elderly and the sick, for whom a fall can lead to further complications that may cause irreversible damage to their health. Therefore, it is important to develop a non-intrusive, automated fall detection method such that an alert can be raised in case a fall occurs. We propose a Grassmann manifold based framework for fall detection from a single camera that is also capable of recognizing other daily living activities (DLA) such as walking, sitting, etc. We perform experi-ments using publicly available datasets and our experimental results show that the fall detection and recognition accuracy of our proposed framework is comparable with the state of the art. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Soni, Pramod Kumar; Choudhary, Ayesha] Jawaharlal Nehru Univ, Sch Comp & Syst Snences, New Delhi, India.
C3 Jawaharlal Nehru University, New Delhi
RP Choudhary, A (corresponding author), Jawaharlal Nehru Univ, Sch Comp & Syst Snences, New Delhi, India.
EM ayeshac@mail.jnu.ac.in
CR Akagündüz E, 2017, IEEE J BIOMED HEALTH, V21, P756, DOI 10.1109/JBHI.2016.2570300
   Alesin A, 2018, PROCEEDINGS OF THE 2018 IEEE CONFERENCE OF RUSSIAN YOUNG RESEARCHERS IN ELECTRICAL AND ELECTRONIC ENGINEERING (EICONRUS), P1850, DOI 10.1109/EIConRus.2018.8317468
   Auvinet E, 2011, IEEE T INF TECHNOL B, V15, P290, DOI 10.1109/TITB.2010.2087385
   Auvinet Edouard., 2010, Multiple cameras fall dataset, P1350
   Bhandari S, 2017, IEEE GLOB CONF CONSU
   Bian ZP, 2015, IEEE J BIOMED HEALTH, V19, P430, DOI 10.1109/JBHI.2014.2319372
   Cai X, 2020, IEEE ACCESS, V8, P44493, DOI 10.1109/ACCESS.2020.2978249
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Chavan SC, 2017, 2017 INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P1135, DOI 10.1109/ICCONS.2017.8250644
   Daher M, 2015, I CON ADV BIOMED ENG, P93, DOI 10.1109/ICABME.2015.7323259
   de Quadros T, 2018, IEEE SENS J, V18, P5082, DOI 10.1109/JSEN.2018.2829815
   Djelouat H., 4 INT C ADV BIOM ENG, P1
   Ejupi A, 2017, IEEE T BIO-MED ENG, V64, P1602, DOI 10.1109/TBME.2016.2614230
   Erol B, 2017, IEEE RAD CONF, P819, DOI 10.1109/RADAR.2017.7944316
   Feng Q, 2020, PATTERN RECOGN LETT, V130, P242, DOI 10.1016/j.patrec.2018.08.031
   Harandi M. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2705, DOI 10.1109/CVPR.2011.5995564
   Harrou F, 2017, IEEE INSTRU MEAS MAG, V20, P49, DOI 10.1109/MIM.2017.8121952
   Junior C.L.B., 2018, IEEE LAT AM T, V16, P1084
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Liu SH, 2016, INT CONF ACOUST SPEE, P799, DOI 10.1109/ICASSP.2016.7471785
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   Ma X, 2014, IEEE J BIOMED HEALTH, V18, P1915, DOI 10.1109/JBHI.2014.2304357
   Merrouche F, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P586, DOI 10.1109/SIPROCESS.2016.7888330
   Miao Y., P 19 ACM INT C MULT, P416
   Mirmahboub B, 2013, IEEE T BIO-MED ENG, V60, P427, DOI 10.1109/TBME.2012.2228262
   Muheidat F, 2018, IEEE INT C SEMANT CO, P329, DOI 10.1109/ICSC.2018.00068
   Nadee C., AS PAC SIGN INF TECH, P930
   Núñez-Marcos A, 2017, WIREL COMMUN MOB COM, DOI 10.1155/2017/9474806
   Planinc R, 2013, PERS UBIQUIT COMPUT, V17, P1063, DOI 10.1007/s00779-012-0552-z
   Rathi N, 2017, PROC NAECON IEEE NAT, P241, DOI 10.1109/NAECON.2017.8268778
   Ren LM, 2019, IEEE ACCESS, V7, P77702, DOI 10.1109/ACCESS.2019.2922708
   Rougier C, 2011, IEEE T CIRC SYST VID, V21, P611, DOI 10.1109/TCSVT.2011.2129370
   Sadreazami H, 2020, IEEE T CIRCUITS-II, V67, P197, DOI 10.1109/TCSII.2019.2904498
   Stone EE, 2015, IEEE J BIOMED HEALTH, V19, P290, DOI 10.1109/JBHI.2014.2312180
   Sun G., P AS PAC C IM PROC E, P172
   Thome N, 2008, IEEE T CIRC SYST VID, V18, P1522, DOI 10.1109/TCSVT.2008.2005606
   Yang L, 2016, DIGIT COMMUN NETW, V2, P24, DOI 10.1016/j.dcan.2015.12.001
   Yun YX, 2015, IEEE IMAGE PROC, P3280, DOI 10.1109/ICIP.2015.7351410
   Zerrouki N, 2016, PROCEEDINGS OF 2016 8TH INTERNATIONAL CONFERENCE ON MODELLING, IDENTIFICATION & CONTROL (ICMIC 2016), P665, DOI 10.1109/ICMIC.2016.7804195
   Zhang J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030946
   Zhang SG, 2016, PROCEEDINGS OF 2016 5TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT), P781, DOI 10.1109/ICCSNT.2016.8070265
NR 41
TC 9
Z9 9
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104431
DI 10.1016/j.imavis.2022.104431
EA APR 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0Z8DH
UT WOS:000791301700001
DA 2024-07-18
ER

PT J
AU Yang, X
   Sun, SM
   Chen, W
   Liu, J
AF Yang, Xue
   Sun, Shiming
   Chen, Wei
   Liu, Jing
TI Underwater bubble plume image generative model based on noise prior and
   multi conditional labels
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Underwater bubble plumes; Noise prior; VAEs; Multi conditional label;
   Generative model; Discriminative model
ID GAN
AB The characteristics of underwater bubble plume dispersion behavior are important to assess and manage potential risks of underwater gas pipelines. In order to generate sufficient image samples for underwater bubble plume research based on artificial intelligence, we try to design an optimized generative adversarial network. In this paper, a novel underwater bubble plume image generative model that combines noise prior and multi conditional labels is proposed and evaluated using different testing dataset. In the proposed framework, the noise prior which contains the image attributes and the category features are trained with the help of VAEs, prior noise and multi conditional labels are utilized to construct the generative and discriminative models. Finally, 3 types of the underwater bubble plume images generated from the experiment is contrasted and evaluated. The experimental results show that,compared with the existing methods text2img and CGANs,the FID values of the generated images are reduced by 97.4% and 22.8% on SUIM dataset, and the FID values are reduced by 97.4% and 22.8% on BUBBLE dataset, our proposed framework achieves satisfactory and promising performance.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yang, Xue; Chen, Wei; Liu, Jing] Nanjing Inst Technol, Sch Innovat & Entrepreneurship, Nanjing 211167, Jiangsu, Peoples R China.
   [Sun, Shiming] Nanjing Power Grid Dispatching & Control Branch N, Nanjing 211106, Jiangsu, Peoples R China.
C3 Nanjing Institute of Technology
RP Yang, X (corresponding author), Nanjing Inst Technol, Sch Innovat & Entrepreneurship, Nanjing 211167, Jiangsu, Peoples R China.
EM yangxue@njit.edu.cn
FU Natural Science Foundation of Nan-jing Institute of Technology
   [CKJB202009]
FX Acknowledgments This work was supported by the Natural Science
   Foundation of Nan-jing Institute of Technology (No. CKJB202009) .
CR Al-Lashi RS, 2018, IEEE J OCEANIC ENG, V43, P72, DOI 10.1109/JOE.2017.2660099
   Ami Takeyuki, 2019, Multiphase Science and Technology, V31, P1
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Bruce GD, 2020, OPT LETT, V45, P1926, DOI 10.1364/OL.388960
   Chen XY, 2019, IEEE T IND ELECTRON, V66, P9350, DOI 10.1109/TIE.2019.2893840
   Chernykh D, 2020, GEOSCIENCES, V10, DOI 10.3390/geosciences10100411
   David L, 2021, AICHE J
   Denos K, 2017, OCEANS-IEEE
   Edge C., 2020, GENERATIVE APPROACH, P1
   Etha SA, 2019, PHYS REV E, V99, DOI 10.1103/PhysRevE.99.053101
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guarneri M., 2020, ASPAI 2020 BERL
   Hensel M, 2017, ADV NEUR IN, V30
   Hu G, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/1214301
   Huang Y, 2016, APPL OPTICS, V55, P242, DOI 10.1364/AO.55.000242
   Jia LL, 2019, IEEE ACCESS, V7, P79477, DOI 10.1109/ACCESS.2019.2923418
   Johnson Justin, 2016, Computer Vision - ECCV 2016. 14th European Conference. Proceedings: LNCS 9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Kingma D. P., 2014, arXiv
   Li G, 2020, INT J MULTIPHAS FLOW, V125, DOI 10.1016/j.ijmultiphaseflow.2020.103230
   Li H., 2019, J HARBIN I TECHNOL N, V26, P11
   Li XH, 2019, J HAZARD MATER, V367, P676, DOI 10.1016/j.jhazmat.2019.01.015
   Liu M., 2018, 2018 OCEANS MTS IEEE, P1
   Liu X.D., 2019, INSTRUMENTATION, V6, P67
   Liu XD, 2020, IEEE GEOSCI REMOTE S, V17, P1488, DOI 10.1109/LGRS.2019.2950056
   Ma S, 2018, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2018.00593
   Matteoli S, 2018, INT GEOSCI REMOTE SE, P4599, DOI 10.1109/IGARSS.2018.8518236
   Mirza M., 2014, ARXIV PREPRINT ARXIV, P2672, DOI 10.48550/arXiv.1411.1784
   O'Malley DJ, 2019, CAN J CHEM ENG, V97, P2843, DOI 10.1002/cjce.23637
   Odena A, 2017, PR MACH LEARN RES, V70
   [潘青青 Pan Qingqing], 2019, [海洋预报, Marine Forecasts], V36, P97
   Qiao TT, 2019, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2019.00160
   Shi J, 2020, CHINESE PHYS B, V29, DOI 10.1088/1674-1056/ab9285
   Teixeira B., 2019, P IEEE OCEANS, P1
   Wang BB, 2019, J FLUID MECH, V874, P102, DOI 10.1017/jfm.2019.461
   Wang J, 2020, IEEE ACCESS, V8, P130719, DOI 10.1109/ACCESS.2020.3003351
   Wang W., 2015, RES OPTICAL MEASURIN
   Yang XL, 2018, CAN GEOTECH J, V55, P577, DOI 10.1139/cgj-2016-0694
   Yang X, 2019, IEEE T MULTIMEDIA, V21, P746, DOI 10.1109/TMM.2018.2865828
   Yu XL, 2019, LECT NOTES COMPUT SC, V11188, P66, DOI 10.1007/978-3-030-05792-3_7
   Zhang H., 2019, INFRARED LASER ENG, V48, P270
   Zhang H, 2019, INFRARED LASER ENG, V48
   Zhang W., 2017, J. Acoust. Soc. Amer., V141, P3917, DOI 10.1121/1.4988849
NR 43
TC 0
Z9 0
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104373
DI 10.1016/j.imavis.2022.104373
EA FEB 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400001
DA 2024-07-18
ER

PT J
AU Zeng, XX
   Hu, RY
   Shi, W
   Qiao, Y
AF Zeng, Xiaoxing
   Hu, Ruyun
   Shi, Wu
   Qiao, Yu
TI Multi-view self-supervised learning for 3D facial texture reconstruction
   from single image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; 3D face reconstruction; UV texture reconstruction;
   Convolutional neural networks
ID MODEL
AB Recent years witnessed that deep learning based methods have achieved significant progresses in recovering 3D face shape from single image. However, reconstructing realistic 3D facial texture from single image is still a challenging task due to the unavailability of large-scale training datasets and the low expression ability of previous statistical texture models (e.g. 3DMM). In this paper, we introduce a novel deep architecture trained by self supervision with multi-view setup, to reconstruct 3D facial texture. Specifically, we first obtain incomplete UV texture map from input facial image, and then introduce a Texture Completion Network (TC-Net) to inpaint missing areas. To train TC-Net, firstly, we collect 50,000 triplets of facial images from in-the-wild videos, each triplet consists of a nearly frontal, a left-side, and a right-side facial images. With this dataset, we propose a novel multi view consistency loss that ensures consistent photometric, face identity, 3DMM identity, and UV texture among multi-view facial images. This loss allows to optimize TC-Net in a self-supervision way without using ground truth texture map as supervision. In addition, multi-view input images are only required in training to provide self-supervision, and our method only needs single input image in inference. Extensive experiments show that our method achieves state-of-the-art performance in both qualitative and quantitative comparisons. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zeng, Xiaoxing; Hu, Ruyun; Shi, Wu; Qiao, Yu] Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
   [Zeng, Xiaoxing] Univ Chinese Acad Sci, Shenzhen Coll Adv Technol, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Shenzhen Institute of Advanced Technology,
   CAS; Chinese Academy of Sciences; University of Chinese Academy of
   Sciences, CAS
RP Qiao, Y (corresponding author), Chinese Acad Sci, Shenzhen Inst Adv Technol, Shenzhen 518055, Peoples R China.
EM xx.zeng@siat.ac.cn; ry.hu@siat.ac.cn; wu.shi@siat.ac.cn;
   yu.qiao@siat.ac.cn
RI Qiao, Yu/ABD-5787-2021; Yu, Qiao/IAP-6999-2023
FU National Natural Science Foundation of China [U1613211, U1813218];
   Shenzhen Research Program [JCYJ20170818164704758, JCYJ20150925163005055]
FX This work was supported by National Natural Science Foundation of China
   (U1613211, U1813218) , and Shenzhen Research Program
   (JCYJ20170818164704758, JCYJ20150925163005055) .
CR Alexander O, 2010, IEEE COMPUT GRAPH, V30, P20, DOI 10.1109/MCG.2010.65
   [Anonymous], 2009, State of the Art in Example-Based Texture Synthesis R
   Bas A., P IEEE INT C COMP VI, P904
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2004, 2ND INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P293, DOI 10.1109/TDPVT.2004.1335212
   Bonneel N, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2661229.2661253
   Booth J, 2014, IEEE IMAGE PROC, P4672, DOI 10.1109/ICIP.2014.7025947
   Cao C, 2014, IEEE T VIS COMPUT GR, V20, P413, DOI 10.1109/TVCG.2013.249
   Cao KD, 2018, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2018.00544
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chang F.J., 2019, ARXIV PREPRINT ARXIV
   Chen YJ, 2020, IEEE T IMAGE PROCESS, V29, P8696, DOI 10.1109/TIP.2020.3017347
   Chung JS, 2018, INTERSPEECH, P1086
   Deng JK, 2018, PROC CVPR IEEE, P7093, DOI 10.1109/CVPR.2018.00741
   Deng Y., P IEEE C COMP VIS PA
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Fan X, 2021, IEEE T MULTIMEDIA, V23, P1252, DOI 10.1109/TMM.2020.2994506
   Feng Y, 2018, LECT NOTES COMPUT SC, V11218, P557, DOI 10.1007/978-3-030-01264-9_33
   Gecer B, 2019, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2019.00125
   Genova K, 2018, PROC CVPR IEEE, P8377, DOI 10.1109/CVPR.2018.00874
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Güler RA, 2017, PROC CVPR IEEE, P2614, DOI 10.1109/CVPR.2017.280
   Ichim AE, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766974
   Jackson AS, 2017, IEEE I CONF COMP VIS, P1031, DOI 10.1109/ICCV.2017.117
   Kato H, 2018, PROC CVPR IEEE, P3907, DOI 10.1109/CVPR.2018.00411
   King DB, 2015, ACS SYM SER, V1214, P1
   Li YJ, 2017, PROC CVPR IEEE, P5892, DOI 10.1109/CVPR.2017.624
   Lin JK, 2020, PROC CVPR IEEE, P5890, DOI 10.1109/CVPR42600.2020.00593
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Tran L, 2018, PROC CVPR IEEE, P7346, DOI 10.1109/CVPR.2018.00767
   Paszke A, 2019, ADV NEUR IN, V32
   Paysan P, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P296, DOI 10.1109/AVSS.2009.58
   Pighin F., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P75, DOI 10.1145/280814.280825
   Pulli K., 1997, Rendering Techniques '97. Proceedings of the Eurographics Workshop. Eurographics, P23
   Ravi N., ARXIV200708501
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ruiz N, 2018, IEEE COMPUT SOC CONF, P2155, DOI 10.1109/CVPRW.2018.00281
   Sela M, 2017, IEEE I CONF COMP VIS, P1585, DOI 10.1109/ICCV.2017.175
   Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319
   Tewari A, 2019, PROC CVPR IEEE, P10804, DOI 10.1109/CVPR.2019.01107
   Tewari A, 2020, IEEE T PATTERN ANAL, V42, P357, DOI 10.1109/TPAMI.2018.2876842
   Tewari A, 2017, IEEE INT CONF COMP V, P1274, DOI 10.1109/ICCVW.2017.153
   Thies J, 2016, PROC CVPR IEEE, P2387, DOI 10.1109/CVPR.2016.262
   Trân AT, 2017, PROC CVPR IEEE, P1493, DOI 10.1109/CVPR.2017.163
   Tran L, 2019, PROC CVPR IEEE, P1126, DOI 10.1109/CVPR.2019.00122
   Tran L, 2021, IEEE T PATTERN ANAL, V43, P157, DOI 10.1109/TPAMI.2019.2927975
   Tran L, 2017, PROC CVPR IEEE, P1283, DOI 10.1109/CVPR.2017.141
   Tu XG, 2021, IEEE T MULTIMEDIA, V23, P1160, DOI 10.1109/TMM.2020.2993962
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao J, 2018, P INT JOINT C ARTIFI, V2, P11
   Zhao Jian, 2019, P INT JOINT C ART IN
NR 51
TC 4
Z9 4
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104311
DI 10.1016/j.imavis.2021.104311
EA SEP 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WB1NI
UT WOS:000703345700005
DA 2024-07-18
ER

PT J
AU Ma, TH
   Yang, MM
   Rong, H
   Qian, YR
   Tian, Y
   Al-Nabhan, N
AF Ma, Tinghuai
   Yang, Mingming
   Rong, Huan
   Qian, Yurong
   Tian, Yuan
   Al-Nabhan, Najla
TI Dual-path CNN with Max Gated block for text-based person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cross-modal matching; Person re-identification; Dual-path CNN; Word
   embedding
ID CLASSIFICATION; MODEL
AB Text-based person re-identification (Re-id) is an important task in video surveillance, which consists of retrieving the corresponding person's image given a textual description from a large gallery of images. It is difficult to directly match visual contents with the textual descriptions due to the modality heterogeneity. On the one hand, the textual embedding are not discriminative enough, which originates from the high abstraction of the textual descriptions. One the other hand, Global average pooling (GAP) is commonly utilized to extract more general or smoothed features implicitly but ignores salient local features, which are more important for the cross-modal matching problem. With that in mind, a novel Dual-path CNN with Max Gated block (DCMG) is proposed to extract discriminative word embedding and make visual-textual association concern more on remarkable features of both modalities. The proposed framework is based on two deep residual CNNs jointly optimized with cross modal projection matching (CMPM) loss and cross-modal projection classification (CMPC) loss to embed the two modalities into a joint feature space. First, the pre-trained language model, BERT, is combined with the convolutional neural network (CNN) to learn better word embedding in the text-to-image matching domain. Second, the global Max pooling (GMP) layer is applied to make the visual textual features focus more on the salient part. To further alleviate the noise of the maxed-pooled features, the gated block (GB) is proposed to produce an attention map that focuses on meaningful features of both modalities. Finally, extensive experiments are conducted on the benchmark dataset, CUHK-PEDES, in which our approach achieves the rank-1 score of 55.81% and outperforms the state-of-the-art method by 1.3%. We also evaluate our method on two generic retrieval datasets (Flickr30K, Oxford-102 Flowers) and obtain the competitive performance. Code is available at https://github.com/voriarty/Dual-path-CNN-with-Max-Gated-block-for-Text-Based-Person-Re-identification
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Ma, Tinghuai; Yang, Mingming] Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
   [Rong, Huan] Nanjing Univ Informat Sci & Technol, Sch Artificial Intelligence, Nanjing 210044, Jiangsu, Peoples R China.
   [Qian, Yurong] Xinjiang Univ, Urumqi 830008, Peoples R China.
   [Tian, Yuan] Nanjing Inst Technol, Nanjing 211167, Jiangsu, Peoples R China.
   [Al-Nabhan, Najla] KingSaud Univ, Dept Comp Sci, Riyadh 11362, Saudi Arabia.
C3 Nanjing University of Information Science & Technology; Nanjing
   University of Information Science & Technology; Xinjiang University;
   Nanjing Institute of Technology
RP Ma, TH (corresponding author), Nanjing Univ Informat Sci & Technol, Sch Comp & Software, Nanjing 210044, Jiangsu, Peoples R China.
EM thma@nuist.edu.cn
RI Tian, Yuan/AFV-8924-2022
FU National Science Foundation of China; Deanship of Scientific Research at
   King Saud University [RG-1441-331]
FX This work was supported in part by National Science Foundation of China
   (No.U1736105). The authors extend their appreciation to the Deanship of
   Scientific Research at King Saud University for funding this work
   through research group no. RG-1441-331.
CR [Anonymous], 2013, 1 INT C LEARN REPR I
   Bonev B, 2013, COMPUT VIS IMAGE UND, V117, P214, DOI 10.1016/j.cviu.2012.11.007
   Chen TL, 2018, IEEE WINT CONF APPL, P1879, DOI 10.1109/WACV.2018.00208
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Devlin J., 2018, BERT PRE TRAINING DE
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Glorot X., 2010, P INT C ART INT STAT, P249
   Goodfellow I.J., P NEUR INF PROC SYST, P2672
   Hao Y, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107533
   Hao Y, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P57, DOI 10.1145/3343031.3351006
   Hao Y, 2019, AAAI CONF ARTIF INTE, P8385
   Jing Y., P AAAI C ART INT
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Karpathy A, 2017, IEEE T PATTERN ANAL, V39, P664, DOI 10.1109/TPAMI.2016.2598339
   Kordopatis-Zilos G, 2019, IEEE T MULTIMEDIA, V21, P2638, DOI 10.1109/TMM.2019.2905741
   Li JN, 2020, IEEE T IMAGE PROCESS, V29, P4461, DOI 10.1109/TIP.2020.2972108
   Li K, 2019, IEEE T NEUR NET LEAR, V30, P1896, DOI 10.1109/TNNLS.2018.2875429
   Li LL, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107110
   Li S., 2020, PATTERN RECOGN, V97
   Li S, 2018, IEEE T PATTERN ANAL, V40, P2963, DOI 10.1109/TPAMI.2017.2764893
   Li S, 2017, IEEE I CONF COMP VIS, P1908, DOI 10.1109/ICCV.2017.209
   Li S, 2017, PROC CVPR IEEE, P5187, DOI 10.1109/CVPR.2017.551
   Liao WZ, 2020, NEUROCOMPUTING, V382, P188, DOI 10.1016/j.neucom.2019.11.074
   Lin X, 2016, LECT NOTES COMPUT SC, V9906, P261, DOI 10.1007/978-3-319-46475-6_17
   Lin YT, 2020, IEEE T IMAGE PROCESS, V29, P5481, DOI 10.1109/TIP.2020.2982826
   Liu Y, 2017, IEEE I CONF COMP VIS, P4127, DOI 10.1109/ICCV.2017.442
   Lokoc J, 2018, IEEE T MULTIMEDIA, V20, P3361, DOI 10.1109/TMM.2018.2830110
   Ma TH, 2022, IEEE T AFFECT COMPUT, V13, P60, DOI 10.1109/TAFFC.2019.2932061
   Ma TH, 2020, FUTURE GENER COMP SY, V105, P533, DOI 10.1016/j.future.2019.12.022
   Ma TH, 2019, EXPERT SYST APPL, V115, P346, DOI 10.1016/j.eswa.2018.08.010
   Ma TH, 2018, NEUROCOMPUTING, V296, P33, DOI 10.1016/j.neucom.2018.03.029
   Mikolov T., 2013, ADV NEURAL INFORM PR, V26, P3111, DOI DOI 10.5555/2999792.2999959
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Niu K, 2020, IEEE T IMAGE PROCESS, V29, P5542, DOI 10.1109/TIP.2020.2984883
   Pennington Jeffrey, 2014, PROCEEDINGS, P1532
   Peters M.E., P ANN C N AM CHAPT A, P2227
   Plummer BA, 2017, INT J COMPUT VISION, V123, P74, DOI 10.1007/s11263-016-0965-7
   Qiao SS, 2020, IEEE T IMAGE PROCESS, V29, P1299, DOI 10.1109/TIP.2019.2940683
   Radford Alec, IMPROVING LANGUAGE U
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Ren C., 2019, PATTERN RECOGN, V96
   Rong H, 2019, INFORM SCIENCES, V488, P158, DOI 10.1016/j.ins.2019.03.023
   Sarafianos N, 2019, IEEE I CONF COMP VIS, P5813, DOI 10.1109/ICCV.2019.00591
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Sun Y, 2014, ADV NEUR IN, V27
   Tang YZ, 2020, IEEE T IMAGE PROCESS, V29, P5641, DOI 10.1109/TIP.2020.2985545
   Tang YZ, 2020, NEURAL NETWORKS, V124, P223, DOI 10.1016/j.neunet.2020.01.012
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang GC, 2019, AAAI CONF ARTIF INTE, P8933
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang L, 2016, PROC CVPR IEEE, P5005, DOI 10.1109/CVPR.2016.541
   Wang R, 2019, INFORM PROCESS MANAG, V56, DOI 10.1016/j.ipm.2019.102098
   Wang Y., P INT C AC SPEECH SI, P2057
   Wong WJ, 2020, PATTERN RECOGN, V101, DOI 10.1016/j.patcog.2020.107203
   Zagoruyko S., 2017, P INT C LEARN REPR
   Zhang Y., P EUR C COMP VIS, P707
   Zheng ZD, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3383184
NR 58
TC 8
Z9 8
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104168
DI 10.1016/j.imavis.2021.104168
EA APR 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Noonan, J
   Rivlin, E
   Rotstein, H
AF Noonan, John
   Rivlin, Ehud
   Rotstein, Hector
TI NeuralPlan: Neural floorplan radiance fields for accelerated view
   synthesis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual scene representations; Intelligent systems; Neural rendering
AB We propose an approach for quickly building a visual representation of a full indoor building. Our goal is to enable intelligent systems which frequently and regularly monitor buildings to assist personnel operating remotely, a need of special importance in these days. Prior work in neural scene representations for view synthesis focuses on single objects and small scenes and does not scale to full buildings in short timeframes. We propose introducing the floorplan and learning a neural floorplan radiance field, mapping floorplan 3D points and view directions to emitted radiance, and rendering via a sinusoidal multi-layer perceptron (MLP) neural renderer. To incorporate local priors and further accelerate the overall learning, we use a hypernetwork which maps a floorplan surface normal to the parameters of the neural renderer, thus defining the scene by a space of local neural rendering functions across the building. This allows shared knowledge, reasoned in function space, of performing the neural rendering from various vantage points in the scene based on similar building structure represented in the floorplan surface normal, and facilitates meta-knowledge pre-training across multiple buildings. The meta knowledge is used to initialize the parameters of the hypernetwork at test time for the target building. Our approach performs significantly accelerated learning of neural floorplan radiance fields in around 15 min for full buildings on a single commodity GPU, and renders in real-time at 64 Hz, allowing for immersive visual experiences. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Noonan, John; Rivlin, Ehud] Technion Israel Inst Technol, Dept Comp Sci, Intelligent Syst Lab, IL-3200003 Haifa, Israel.
   [Rotstein, Hector] Technion Israel Inst Technol, Dept Elect Engn, IL-3200003 Haifa, Israel.
   [Rotstein, Hector] Rafael Adv Def Syst Ltd, Haifa, Israel.
C3 Technion Israel Institute of Technology; Technion Israel Institute of
   Technology; RAFAEL ADVANCED DEFENSE SYSTEMS
RP Noonan, J (corresponding author), Technion Israel Inst Technol, Dept Comp Sci, Intelligent Syst Lab, IL-3200003 Haifa, Israel.
EM john.noonan@cs.technion.ac.il
CR Bao Zhipeng, 2020, ARXIV200806981
   Bi S., 2020, European Conference on Computer Vision (ECCV), P294
   Buehler C, 2001, COMP GRAPH, P425, DOI 10.1145/383259.383309
   Chabra Rohan, 2020, P EUR C COMP VIS
   Chen AP, 2018, P ACM COMPUT GRAPH, V1, DOI 10.1145/3203192
   Chen S. E., 1993, Computer Graphics Proceedings, P279, DOI 10.1145/166117.166153
   Chibane J., 2020, Adv. Neural Inf. Process. Syst
   Dupont E., 2020, INT C MACHINE LEARNI, V119, P2761
   Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Habtegebrial T. Amberbir, 2020, ADV NEURAL INF PROCE, V33
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hedman P, 2018, SIGGRAPH ASIA'18: SIGGRAPH ASIA 2018 TECHNICAL PAPERS, DOI 10.1145/3272127.3275084
   Henderson Paul, 2020, P IEEECVF C COMPUTER, P7498
   Huang LM, 2020, IEEE CONF COMPUT, P592, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162921
   Huang Y., ARXIV200911997
   Huh Minyoung, 2020, ECCV
   Jachnik J, 2012, INT SYM MIX AUGMENT, P91, DOI 10.1109/ISMAR.2012.6402544
   Jiang CY, 2020, PROC CVPR IEEE, P6000, DOI 10.1109/CVPR42600.2020.00604
   Kanthilatha N, 2020, QUATERNARY, V3, DOI 10.3390/quat3010003
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Kato H, ARXIV200612057
   Li Z., ARXIV200715194
   Liao YY, 2020, PROC CVPR IEEE, P5870, DOI 10.1109/CVPR42600.2020.00591
   Liu Lingjie, 2020, NEURIPS, V33, P15651
   Liu Ming-Yu, 2020, ARXIV PREPRINT ARXIV
   Liu S, 2020, ROUT MUSIC COMPANION, P196
   Lunz S., ARXIV200212674
   Mallya A., 2020, ECCV, V12353, P359, DOI DOI 10.1007/978-3-030-58598-3_22
   Maximov M, 2019, IEEE I CONF COMP VIS, P8728, DOI 10.1109/ICCV.2019.00882
   Mildenhall B, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322980
   Ng R, 2020, PROC EUROPEAN C COMP
   Nguyen-Phuoc T., ARXIV200208988
   Niemeyer M, 2020, PROC CVPR IEEE, P3501, DOI 10.1109/CVPR42600.2020.00356
   Noonan J, 2020, ROBOTICS, V9, DOI 10.3390/robotics9030069
   Noonan J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19030634
   Oechsle M., ARXIV200312406
   Oechsle M, 2019, IEEE I CONF COMP VIS, P4530, DOI 10.1109/ICCV.2019.00463
   Peng Houwen, 2020, ADV NEUR IN
   Peng Songyou, 2020, Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part III 16, P523
   Rahaman N, 2019, PR MACH LEARN RES, V97
   Rematas K, 2020, PROC CVPR IEEE, P5416, DOI 10.1109/CVPR42600.2020.00546
   Schwarz Katja, 2020, NEURIPS
   Sitzmann V., 2020, ADV NEURAL INF PROCE, V33, P7462
   Sitzmann V, 2019, ADV NEUR IN, V32
   Snavely N., ARXIV201007492
   Storkey A., ARXIV200405439
   Su SL, 2020, PROC CVPR IEEE, P3664, DOI 10.1109/CVPR42600.2020.00372
   Tewari A., 2020, ARXIV200403805
   Tucker R, 2020, PROC CVPR IEEE, P548, DOI 10.1109/CVPR42600.2020.00063
   Wiles Olivia, CVPR
   Wood DN, 2000, COMP GRAPH, P287, DOI 10.1145/344779.344925
   Xia F, 2020, IEEE ROBOT AUTOM LET, V5, P713, DOI 10.1109/LRA.2020.2965078
   Yuksel C, 2019, COMPUT GRAPH FORUM, V38, P535, DOI 10.1111/cgf.13656
   Yunjey Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8185, DOI 10.1109/CVPR42600.2020.00821
   Zhang JY, 2021, COMPUT ECON, V58, P867, DOI 10.1007/s10614-020-10055-9
   Zhang R, 2018, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.2018.00068
NR 57
TC 1
Z9 1
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104148
DI 10.1016/j.imavis.2021.104148
EA MAR 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600003
DA 2024-07-18
ER

PT J
AU Cao, ZJ
   Shamsolmoali, P
   Yang, J
AF Cao, Zhijie
   Shamsolmoali, Pourya
   Yang, Jie
TI Synthetic guided domain adaptive and edge aware network for crowd
   counting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Crowd counintg; Synthetic guided; Edge aware; Domain adaption
AB Crowd counting is an important surveillance application and receives significant attention from the computer vision community. Most of the current methods treat crowd counting by density map estimation and use the Fully Convolution Network (FCN) for prediction. The mainstream framework is to predict density maps and use the sum up the density maps to get the number of people. In such methods, the main drawback is the poor local quality of the dense part and the sparse part of an image. As we investigated, it is due to the lack of an efficient method to learn the heads' structure information. To address the above problem, in this paper, we propose a domain adaptive model called synthetic guided learning that learns features' structure from synthetic data. We also propose a multi-scale edge-aware loss for improving the boundary clearness of the estimated density map. Our experimental results show, learning from the structure information effectively improves the density maps' estimation quality and promotes the counting accuracy. Comprehensive experiments and comparisons with state-of-the-art methods on four publicly available data sets demonstrate the superiority of our proposed method. We provide a reference implementation of this technique at https://github. com/MRJTM/SGEANet. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Cao, Zhijie; Shamsolmoali, Pourya; Yang, Jie] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
EM cao_zhijie@sjtu.edu.cn; pshams@sjtu.edu.cn; jieyang@sjtu.edu.cn
RI Yang, Jie/JCD-9867-2023
FU NSFC, China [61-876107, U1803261]; Committee of Science and Technology,
   Shanghai, China [19510711200]
FX This research is partly supported by NSFC, China (No: 61-876107,
   U1803261), Committee of Science and Technology, Shanghai, China (No.
   19510711200).
CR Cao XK, 2018, LECT NOTES COMPUT SC, V11209, P757, DOI 10.1007/978-3-030-01228-1_45
   Chang WL, 2019, PROC CVPR IEEE, P1900, DOI 10.1109/CVPR.2019.00200
   Cheng ZQ, 2019, IEEE I CONF COMP VIS, P6151, DOI 10.1109/ICCV.2019.00625
   Guo D, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1823, DOI 10.1145/3343031.3350881
   Idrees H, 2018, LECT NOTES COMPUT SC, V11206, P544, DOI 10.1007/978-3-030-01216-8_33
   Jiang XL, 2019, PROC CVPR IEEE, P6126, DOI 10.1109/CVPR.2019.00629
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu CC, 2019, PROC CVPR IEEE, P1217, DOI 10.1109/CVPR.2019.00131
   Liu J, 2018, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2018.00545
   Liu L, 2021, IEEE T MULTIMEDIA, V23, P1060, DOI 10.1109/TMM.2020.2992979
   Liu LB, 2019, IEEE I CONF COMP VIS, P1774, DOI 10.1109/ICCV.2019.00186
   Liu WZ, 2019, PROC CVPR IEEE, P5094, DOI 10.1109/CVPR.2019.00524
   Liu XL, 2018, PROC CVPR IEEE, P7661, DOI 10.1109/CVPR.2018.00799
   Liu YT, 2019, PROC CVPR IEEE, P6462, DOI 10.1109/CVPR.2019.00663
   Ma ZH, 2019, IEEE I CONF COMP VIS, P6141, DOI 10.1109/ICCV.2019.00624
   Torres DM, 2019, IMAGE VISION COMPUT, V89, P197, DOI 10.1016/j.imavis.2019.07.006
   Rad MS, 2019, IEEE I CONF COMP VIS, P2710, DOI 10.1109/ICCV.2019.00280
   Ranjan V, 2018, LECT NOTES COMPUT SC, V11211, P278, DOI 10.1007/978-3-030-01234-2_17
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sam DB, 2018, PROC CVPR IEEE, P3618, DOI 10.1109/CVPR.2018.00381
   Sam DB, 2017, PROC CVPR IEEE, P4031, DOI 10.1109/CVPR.2017.429
   Shamsolmoali P, 2021, IEEE T GEOSCI REMOTE, V59, P4673, DOI 10.1109/TGRS.2020.3016086
   Shamsolmoali P, 2019, IMAGE VISION COMPUT, V88, P9, DOI 10.1016/j.imavis.2019.03.006
   Shen Z, 2018, PROC CVPR IEEE, P5245, DOI 10.1109/CVPR.2018.00550
   Shi MJ, 2019, PROC CVPR IEEE, P7271, DOI 10.1109/CVPR.2019.00745
   Shi ZL, 2019, IEEE I CONF COMP VIS, P4199, DOI 10.1109/ICCV.2019.00430
   Sindagi VA, 2017, IEEE I CONF COMP VIS, P1879, DOI 10.1109/ICCV.2017.206
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Wang H., 2020, IMAGE VISION COMPUT
   Wang Q, 2019, PROC CVPR IEEE, P8190, DOI 10.1109/CVPR.2019.00839
   Wang WH, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.103986
   Wang XL, 2016, LECT NOTES COMPUT SC, V9908, P318, DOI 10.1007/978-3-319-46493-0_20
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan ZY, 2019, IEEE I CONF COMP VIS, P952, DOI 10.1109/ICCV.2019.00104
   Zhang AR, 2019, IEEE I CONF COMP VIS, P6787, DOI 10.1109/ICCV.2019.00689
   Zhang A, 2019, IEEE I CONF COMP VIS, P5713, DOI 10.1109/ICCV.2019.00581
   Zhang C, 2015, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2015.7298684
   Zhang YY, 2016, PROC CVPR IEEE, P589, DOI 10.1109/CVPR.2016.70
   Zheng CX, 2018, LECT NOTES COMPUT SC, V11211, P798, DOI 10.1007/978-3-030-01234-2_47
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu L., 2019, ARXIV190201115
NR 43
TC 2
Z9 2
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104026
DI 10.1016/j.imavis.2020.104026
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800009
DA 2024-07-18
ER

PT J
AU Chaudhuri, U
   Banerjee, B
   Bhattacharya, A
   Datcu, M
AF Chaudhuri, Ushasi
   Banerjee, Biplab
   Bhattacharya, Avik
   Datcu, Mihai
TI CrossATNet - a novel cross-attention based framework for sketch-based
   image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Neural networks; Sketch-based image retrieval; Cross-modal retrieval;
   Deep-learning; Cross-attention network; Cross-triplets
ID GRAPH CONVOLUTIONAL NETWORK
AB We propose a novel framework for cross-modal zero-shot learning (ZSL) in the context of sketch-based image retrieval (SBIR). Conventionally, the SBIR schema mainly considers simultaneous mappings among the two image views and the semantic side information. Therefore, it is desirable to consider fine-grained classes mainly in the sketch domain using highly discriminative and semantically rich feature space. However, the existing deep generative modeling based SBIR approaches majorly focus on bridging the gaps between the seen and unseen classes by generating pseudo-unseen-class samples. Besides, violating the ZSL protocol by not utilizing any unseen-class information during training, such techniques do not pay explicit attention to modeling the discriminative nature of the shared space. Also, we note that learning a unified feature space for both the multi-view visual data is a tedious task considering the significant domain difference between sketches and the color images. In this respect, as a remedy, we introduce a novel framework for zero-shot SBIR. While we define a cross-modal triplet loss to ensure the discriminative nature of the shared space, an innovative cross-modal attention learning strategy is also proposed to guide feature extraction from the image domain exploiting information from the respective sketch counterpart. In order to preserve the semantic consistency of the shared space, we consider a graph CNN based module which propagates the semantic class topology to the shared space. To ensure an improved response time during inference, we further explore the possibility of representing the shared space in terms of hash-codes. Experimental results obtained on the benchmark TU-Berlin and the Sketchy datasets confirm the superiority of CrossATNet in yielding the state-of-the-art results. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Chaudhuri, Ushasi; Banerjee, Biplab; Bhattacharya, Avik] Indian Inst Technol, Bombay, Maharashtra, India.
   [Datcu, Mihai] Deutsch Zentrum Luft & Raumfahrt DLR, Cologne, Germany.
   [Banerjee, Biplab] Ctr Machine Intelligence & Data Sci C MINDS, Bombay, Maharashtra, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bombay; Helmholtz Association; German Aerospace
   Centre (DLR)
RP Chaudhuri, U (corresponding author), Indian Inst Technol, Bombay, Maharashtra, India.
EM ushasi@iitb.ac.in
RI Chaudhuri, Ushasi/AAB-8284-2021; Chaudhuri, Ushasi/AAQ-3568-2020
OI Chaudhuri, Ushasi/0000-0003-2970-9227; 
CR Akata Z, 2015, PROC CVPR IEEE, P2927, DOI 10.1109/CVPR.2015.7298911
   [Anonymous], 2016, PROCEEDINGS OF THE I, DOI DOI 10.1109/CVPR.2016.649
   [Anonymous], 2017, CVPR
   [Anonymous], ARXIV160308861
   Chaudhuri U., 2004, ARXIV190404794
   Chaudhuri U, 2019, COMPUT VIS IMAGE UND, V184, P22, DOI 10.1016/j.cviu.2019.04.004
   Dutta A, 2019, PROC CVPR IEEE, P5084, DOI 10.1109/CVPR.2019.00523
   Farhadi A, 2009, PROC CVPR IEEE, P1778, DOI 10.1109/CVPRW.2009.5206772
   Ferecatu M., 2004, P 6 ACM SIGMM INT WO, P23
   Fu YW, 2018, IEEE SIGNAL PROC MAG, V35, P112, DOI 10.1109/MSP.2017.2763441
   Gavat I., 2007, PV 2007 INT C ENS LO
   Geirhos R., ARXIV181112231
   Gune O., 2018, BMVC, P218
   Khan N, 2019, NEUROCOMPUTING, V357, P36, DOI 10.1016/j.neucom.2019.05.024
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Li Y., 2018, ADV NEURAL INFORM PR, P820, DOI DOI 10.48550/ARXIV.1801.07791
   Lu P., ARXIV181204275
   Mittal A., 2018, ECCV, P300
   Pandey A, 2020, IEEE WINT CONF APPL, P2529, DOI 10.1109/WACV45572.2020.9093402
   Parida KK, 2020, IEEE WINT CONF APPL, P3240, DOI [10.1109/wacv45572.2020.9093438, 10.1109/WACV45572.2020.9093438]
   Qi YG, 2016, IEEE IMAGE PROC, P2460, DOI 10.1109/ICIP.2016.7532801
   Qin J, 2017, PROC CVPR IEEE, P6728, DOI 10.1109/CVPR.2017.712
   Qing Liu, 2019, 2019 IEEE/CVF International Conference on Computer Vision (ICCV). Proceedings, P3661, DOI 10.1109/ICCV.2019.00376
   Reed S, 2016, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2016.13
   Sangkloy P, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925954
   Shen YM, 2018, PROC CVPR IEEE, P3598, DOI 10.1109/CVPR.2018.00379
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   Verma VK, 2018, PROC CVPR IEEE, P4281, DOI 10.1109/CVPR.2018.00450
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Xu F., IEEE T GEOSCI REMOTE
   Yu Q, 2017, INT J COMPUT VISION, V122, P411, DOI 10.1007/s11263-016-0932-3
   Zhang J., 2018, P EUROPEAN C COMPUTE, P297
   Zhang ZM, 2015, IEEE I CONF COMP VIS, P4166, DOI 10.1109/ICCV.2015.474
NR 33
TC 19
Z9 19
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104003
DI 10.1016/j.imavis.2020.104003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800006
OA Green Accepted, Green Submitted
DA 2024-07-18
ER

PT J
AU Singh, A
   Arora, A
   Nigam, A
AF Singh, Avantika
   Arora, Ashish
   Nigam, Aditya
TI Cancelable Iris template generation by aggregating patch level ordinal
   relations with its holistically extended performance and security
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ordinal measures; BioHashing; Cancelability; Security analysis
   (unlinkability; Revocability; Statistical; Non-invertibility); Domain
   knowledge; Aggregation learning
ID RECOGNITION; BIOMETRICS; PRIVACY
AB Nowadays, biometric-based authentication is gaining immense popularity due to the widespread usage of digital activities. Among various biometric traits, the iris is one of the most discriminative, accurate, and popularly used biometrics. However, due to its immutable nature, it is highly vulnerable to adversarial attacks if stolen and thus poses a severe security threat. Here, in this work, we propose a cancelable iris biometric authentication system that stores a transformed version of the original iris template and thus enables cancelation and re-enrolment in case if the original template is stolen. Firstly, for extracting discriminative iris features, we have proposed a novel deep architecture based on aggregation learning. This deep architecture makes use of qualitative measure (ordinal measure), unlike popularly used quantitative measures. The usage of ordinal measures in this work enables to encode distinctive iris features quite well. Later generated iris features are protected using state-of-theart two representative cancelable biometric techniques, namely BioHashing and 2(N) discretized BioPhasor. Finally, in order to justify the efficacy of the proposed architecture, we have presented rigorous and holistic security analysis. To the best of our knowledge, this is the first work that has presented such an in-depth analysis of any deep network in the context of cancelable iris biometrics. Experimental results over four datasets viz. CASIA-V3 Interval, CASIA-Lamp, IITD, and IITK demonstrate the efficacy of the proposed framework in terms of security and accuracy. Further, for better network explainability, we have also performed layer-specific heatmap and feature map analysis to ascertain what exactly our novel deep architecture is learning. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Singh, Avantika; Nigam, Aditya] Indian Inst Technol Mandi, Sch Comp & Elect Engn, Mandi, Himachal Prades, India.
   [Arora, Ashish] Indian Inst Technol Dharwad, Comp Sci & Engn Dept, Dharwad, Karnataka, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Mandi; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) - Dharwad
RP Singh, A (corresponding author), Indian Inst Technol Mandi, Sch Comp & Elect Engn, Mandi, Himachal Prades, India.
EM d16027@students.iitmandi.ac.in; 160010008@iitdh.ac.in;
   aditya@iitmandi.ac.in
RI Singh, Avantika/JLN-2000-2023
CR Abadi M., 2020, TENSORFLOW LARGE SCA
   Ahmad S., 2020, ABS190706147 CORR
   [Anonymous], 2011, JTC1SC27 ISOIEC
   [Anonymous], 2009, Technical report
   [Anonymous], 2018, DOI IEEE ACCESS, DOI [DOI 10.1109/AC, DOI 10.1109/ACCESS.2017.2784352]
   [Anonymous], 2008, IEEE 19 INT C PATT R
   [Anonymous], 2014, MAJOR INT DEPLOYMENT
   Bendale A, 2012, COMM COM INF SC, V304, P408
   Bloice M.D., 2017, ARXIV170804680, V2, P1, DOI DOI 10.21105/JOSS.00432
   Boles WW, 1998, IEEE T SIGNAL PROCES, V46, P1185, DOI 10.1109/78.668573
   Buko B., 2022, ABS151203385 CORR, V22, P8878
   Chin CS, 2006, COMPUT VIS IMAGE UND, V102, P169, DOI 10.1016/j.cviu.2006.01.002
   Connie T, 2005, INFORM PROCESS LETT, V93, P1, DOI 10.1016/j.ipl.2004.09.014
   Daugman J, 2002, IEEE IMAGE PROC, P33
   Daugman J., 2015, ENCY BIOMETRICS 2015, P973, DOI [10.1007/978-1-4899-7488-4_307, DOI 10.1007/978-1-4899-7488-4_307]
   Daugman J, 2019, IET BIOMETRICS, V8, P185, DOI 10.1049/iet-bmt.2018.5199
   Davida GI, 1998, 1998 IEEE SYMPOSIUM ON SECURITY AND PRIVACY - PROCEEDINGS, P148, DOI 10.1109/SECPRI.1998.674831
   DeAngelis I. O. G.C., NEUROPHYSIOLOGY, V69, P1091
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XB, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185997
   Dwivedi R, 2017, COMPUT SECUR, V65, P373, DOI 10.1016/j.cose.2016.10.004
   European Council, 2016, REG EUR PARL COUNC P
   Feng Q, 2008, ISCSCT 2008: INTERNATIONAL SYMPOSIUM ON COMPUTER SCIENCE AND COMPUTATIONAL TECHNOLOGY, VOL 2, PROCEEDINGS, P572, DOI 10.1109/ISCSCT.2008.226
   Gilbert AC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1703
   Gomez-Barrero M, 2018, INFORM FUSION, V42, P37, DOI 10.1016/j.inffus.2017.10.003
   Gomez-Barrero M, 2018, IEEE T INF FOREN SEC, V13, P1406, DOI 10.1109/TIFS.2017.2788000
   Gomez-Barrero M, 2016, INFORM SCIENCES, V370, P18, DOI 10.1016/j.ins.2016.06.046
   Jin ATB, 2004, PATTERN RECOGN, V37, P2245, DOI 10.1016/j.patcog.2004.04.011
   Juefei-Xu F, 2017, PROC CVPR IEEE, P4284, DOI 10.1109/CVPR.2017.456
   Karabat C, 2012, IEICE T INF SYST, VE95D, P1547, DOI 10.1587/transinf.E95.D.1547
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Lai YL, 2017, PATTERN RECOGN, V64, P105, DOI 10.1016/j.patcog.2016.10.035
   Li YH, 2019, MOB INF SYST, V2019, DOI 10.1155/2019/6142839
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu NAF, 2016, PATTERN RECOGN LETT, V82, P154, DOI 10.1016/j.patrec.2015.09.016
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Masek L., 2003, THESIS CITESEER
   Minaee S., 2020, ABS181204822 CORR
   Minaee S., 2020, ABS170201334 CORR
   Nandakumar K, 2015, IEEE SIGNAL PROC MAG, V32, P88, DOI 10.1109/MSP.2015.2427849
   Nanni L, 2006, NEUROCOMPUTING, V69, P2390, DOI 10.1016/j.neucom.2006.05.001
   Ngo DCL, 2006, IEEE T CIRC SYST VID, V16, P771, DOI 10.1109/TCSVT.2006.873780
   Nigam A, 2015, LECT NOTES COMPUT SC, V9257, P506, DOI 10.1007/978-3-319-23117-4_44
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P54, DOI 10.1109/MSP.2015.2434151
   Pillai JK, 2010, INT CONF ACOUST SPEE, P1838, DOI 10.1109/ICASSP.2010.5495383
   Rahulkar AD, 2012, IEEE T INF FOREN SEC, V7, P230, DOI 10.1109/TIFS.2011.2166069
   Raja K.B., 2019, P 10 INT C BIOM THEO
   Raja KB, 2019, 2019 5TH IEEE INTERNATIONAL CONFERENCE ON IDENTITY, SECURITY, AND BEHAVIOR ANALYSIS (ISBA 2019), DOI [10.1109/isba.2019.8778470, 10.1109/btas46853.2019.9185986]
   Ratha NK, 2007, IEEE T PATTERN ANAL, V29, P561, DOI 10.1109/TPAMI.2007.1004
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Rathgeb C, 2015, INT CONF BIOMETR, P422, DOI 10.1109/ICB.2015.7139105
   Rathgeb C., 2013, P ICB, P1, DOI DOI 10.1109/ICB.2013.6612976
   Rathgeb C., 2015, 3rd Intrl. Wrks on biometrics and forensics, P1, DOI DOI 10.1109/IWBF.2015.7110225
   Ren M., 2019, INT C BIOM ICB CRET, P1, DOI [10.1109/ICB45273.2019.8987369, DOI 10.1109/ICB45273.2019.8987369]
   Rosenberger C, 2018, ICISSP: PROCEEDINGS OF THE 4TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS SECURITY AND PRIVACY, P216, DOI 10.5220/0006550502160224
   Sadhya D, 2019, IEEE T INF FOREN SEC, V14, P2972, DOI 10.1109/TIFS.2019.2907014
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Simonyan K., 2020, ABS14091556 CORR
   Singh A, 2020, J AMB INTEL HUM COMP, V11, P1905, DOI 10.1007/s12652-019-01297-z
   Soliman R, 2018, P NATL A SCI INDIA A, P1
   Soutar C, 1998, P SOC PHOTO-OPT INS, V3314, P178, DOI 10.1117/12.304705
   STEVENS SS, 1946, SCIENCE, V103, P677, DOI 10.1126/science.103.2684.677
   Sun ZN, 2009, IEEE T PATTERN ANAL, V31, P2211, DOI 10.1109/TPAMI.2008.240
   Syarif MA, 2014, LECT NOTES COMPUT SC, V8836, P644, DOI 10.1007/978-3-319-12643-2_78
   Teoh ABJ, 2006, IEEE T PATTERN ANAL, V28, P1892, DOI 10.1109/TPAMI.2006.250
   Teoh ABJ, 2007, LECT NOTES COMPUT SC, V4642, P435
   Tieniu Tan, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P35
   Umer S, 2017, INFORM SCIENCES, V406, P102, DOI 10.1016/j.ins.2017.04.026
   Van Rullen R, 2001, NEURAL COMPUT, V13, P1255, DOI 10.1162/08997660152002852
   Wang K., 2020, ABS200100989 CORR
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xu, 2017, MATH PROBL ENG, V2017, P1
   Zanlorensi LA, 2020, IET BIOMETRICS, V9, P68, DOI 10.1049/iet-bmt.2019.0116
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao Z, 2017, IEEE I CONF COMP VIS, P3829, DOI 10.1109/ICCV.2017.411
NR 77
TC 10
Z9 10
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104017
DI 10.1016/j.imavis.2020.104017
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800007
DA 2024-07-18
ER

EF