FN Clarivate Analytics Web of Science
VR 1.0
PT J
AU Xie, XH
   Mirmehdi, M
AF Xie, Xianghua
   Mirmehdi, Majid
TI Radial basis function based level set interpolation and evolution for
   deformable modelling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deformable model; Level set; Radial basis function; Re-initialisation
   free
ID ACTIVE CONTOURS; SEGMENTATION; TEXTURE
AB We present a study in level set representation and evolution using radial basis functions (RBFs) for active contour and active surface models. It builds on recent works by others who introduced RBFs into level sets for structural topology optimisation. Here, we introduce the concept into deformable models and present a new level set formulation able to handle more complex topological changes, in particular perturbation away from the evolving front. In the conventional level set technique, the initial active contour/surface is implicitly represented by a signed distance function and periodically re-initialised to maintain numerical stability. We interpolate the initial distance function using RBFs on a much coarser grid, which provides great potential in modelling in high dimensional space. Its deformation is considered as an updating of the RBF interpolants, an ordinary differential equation (ODE) problem, instead of a partial differential equation (PDE) problem, and hence it becomes much easier to solve. Re-initialisation is found no longer necessary, in contrast to conventional finite difference method (FDM) based level set approaches. The proposed level set updating scheme is efficient and does not suffer from self-flattening while evolving, hence it avoids large numerical errors. Further, more complex topological changes are readily achievable and the initial contour or surface can be placed arbitrarily in the image. These properties are extensively demonstrated on both synthetic and real 2D and 3D data. We also present a novel active contour model, implemented with this level set scheme, based on multiscale learning and fusion of image primitives from vector-valued data, e.g. colour images, without channel separation or decomposition. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Xie, Xianghua] Univ Swansea, Dept Comp Sci, Swansea SA2 8PP, W Glam, Wales.
   [Mirmehdi, Majid] Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.
C3 Swansea University; University of Bristol
RP Xie, XH (corresponding author), Univ Swansea, Dept Comp Sci, Swansea SA2 8PP, W Glam, Wales.
EM x.xie@swansea.ac.uk; majid@cs.bris.ac.uk
OI Xie, Xianghua/0000-0002-2701-8660; Mirmehdi, Majid/0000-0002-6478-1403
CR Adalsteinsson D, 1999, J COMPUT PHYS, V148, P2, DOI 10.1006/jcph.1998.6090
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Brox T, 2009, INT J COMPUT VISION, V84, P184, DOI 10.1007/s11263-008-0153-5
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Cecil T, 2004, J COMPUT PHYS, V196, P327, DOI [10.1016/j.jcp.2003.11.010, 10.1016/j.jcp. 2003.11.010]
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   FRANKE R, 1982, MATH COMPUT, V38, P181, DOI 10.2307/2007474
   Gelas A, 2007, IEEE T IMAGE PROCESS, V16, P1873, DOI 10.1109/TIP.2007.898969
   GREENGARD L, 1987, J COMPUT PHYS, V73, P325, DOI 10.1016/0021-9991(87)90140-9
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   LENGLET C, 2004, SEGMENTATION 3D PROB
   Li CM, 2005, PROC CVPR IEEE, P430
   Manduchi R, 2000, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2000.855805
   MANDUCHI R, 1999, ICCV99, P956
   Morse BS, 2005, PROC CVPR IEEE, P285
   Muller M. G., 2004, NSF DARPA CARGO ANN, P1
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2004, IEEE T PATTERN ANAL, V26, P402, DOI 10.1109/TPAMI.2004.1262337
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Ramlau R, 2007, J COMPUT PHYS, V221, P539, DOI 10.1016/j.jcp.2006.06.041
   Suri JS, 2001, IEEE ENG MED BIOL, V20, P84, DOI 10.1109/51.940054
   Turk G, 2002, ACM T GRAPHIC, V21, P855, DOI 10.1145/571647.571650
   Wang SY, 2007, J COMPUT PHYS, V221, P395, DOI 10.1016/j.jcp.2006.06.029
   Xie X., 2007, ANN BRIT MACHINE VIS, V1, P1
   XIE X, 2007, BRIT MACH VIS C, P1040
   Xie XH, 2008, IEEE T PATTERN ANAL, V30, P632, DOI 10.1109/TPAMI.2007.70737
   Xie XH, 2007, IEEE T PATTERN ANAL, V29, P1454, DOI 10.1109/TPAMI.2007.1038
   Xie XH, 2010, IEEE T IMAGE PROCESS, V19, P154, DOI 10.1109/TIP.2009.2032891
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
NR 32
TC 31
Z9 34
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2011
VL 29
IS 2-3
BP 167
EP 177
DI 10.1016/j.imavis.2010.08.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 707NV
UT WOS:000286294200007
DA 2024-07-18
ER

PT J
AU Ma, YD
   Liu, L
   Zhan, K
   Wu, YQ
AF Ma, Yide
   Liu, Li
   Zhan, Kun
   Wu, Yongqing
TI Pulse-coupled neural networks and one-class support vector machines for
   geometry invariant texture retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pulse-coupled neural network (PCNN); Intersecting cortical model (ICM);
   Texture retrieval; Support vector machine (SVM); Feature extraction
ID IMAGE RETRIEVAL; FEATURES; ROTATION; SCALE
AB The pulse-coupled neural network (PCNN) has been widely used in image processing. The outputs of PCNN represent unique features of original stimulus and are invariant to translation, rotation, scaling and distortion, which is particularly suitable for feature extraction. In this paper, PCNN and intersecting cortical model (ICM), which is a simplified version of PCNN model, are applied to extract geometrical changes of rotation and scale invariant texture features, then an one-class support vector machine based classification method is employed to train and predict the features. The experimental results show that the pulse features outperform of the classic Gabor features in aspects of both feature extraction time and retrieval accuracy, and the proposed one-class support vector machine based retrieval system is more accurate and robust to geometrical changes than the traditional Euclidean distance based system. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Ma, Yide; Liu, Li; Zhan, Kun] Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Gansu, Peoples R China.
   [Wu, Yongqing] Lanzhou Univ, Sch Math & Stat, Lanzhou 730000, Gansu, Peoples R China.
C3 Lanzhou University; Lanzhou University
RP Ma, YD (corresponding author), Lanzhou Univ, Sch Informat Sci & Engn, Lanzhou 730000, Gansu, Peoples R China.
EM ydma@lzu.edu.cn
RI Zhan, Kun/D-1741-2017; wu, yongqing/A-2352-2013
OI Wu, Yongqing/0000-0002-3078-1667
FU National Natural Science Foundation of China [60572011, 60872109];
   Program for New Century Excellent Talents in University [NCET-06-0900];
   Natural Science Foundation of Gansu Province, China [0710RJZA015]
FX This paper is jointly supported by National Natural Science Foundation
   of China (Nos. 60572011 and 60872109), Program for New Century Excellent
   Talents in University (No. NCET-06-0900), and Project supported by the
   Natural Science Foundation of Gansu Province, China (No. 0710RJZA015).
CR [Anonymous], 2006, LIBSVM: a library for support vector machines
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   EDVARDSSON L, 2004, DIGITAL IMAGE SEARCH
   Ekblad U, 2004, NUCL INSTRUM METH A, V525, P392, DOI 10.1016/j.nima.2004.03.102
   Han J, 2007, IMAGE VISION COMPUT, V25, P1474, DOI 10.1016/j.imavis.2006.12.015
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hsu C.-W., 2003, PRACTICAL GUIDE SUPP
   JOHNSON JL, 1994, APPL OPTICS, V33, P6239, DOI 10.1364/AO.33.006239
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   Kinser JM, 1996, P SOC PHOTO-OPT INS, V2760, P563, DOI 10.1117/12.235951
   Lindblad T., 1998, Image Processing Using Pulse-Coupled Neural Networks
   Ma Yide, 2008, PULSE COUPLED NEURAL
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Müller KR, 2001, IEEE T NEURAL NETWOR, V12, P181, DOI 10.1109/72.914517
   Schölkopf B, 2001, NEURAL COMPUT, V13, P1443, DOI 10.1162/089976601750264965
   Seo KK, 2007, EXPERT SYST APPL, V33, P491, DOI 10.1016/j.eswa.2006.05.030
   Soh LK, 1999, IEEE T GEOSCI REMOTE, V37, P780, DOI 10.1109/36.752194
   Wang L, 2009, ICECT: 2009 INTERNATIONAL CONFERENCE ON ELECTRONIC COMPUTER TECHNOLOGY, PROCEEDINGS, P157, DOI 10.1109/ICECT.2009.133
   Wu RS, 2009, EXPERT SYST APPL, V36, P4451, DOI 10.1016/j.eswa.2008.05.037
   Xu H, 2008, IEEE INT C NETW SENS, P602
   Zhang D.S., 2000, PROC 1 IEEE PACIFIC, P392
   Zhang JW, 2007, NEURAL NETW WORLD, V17, P121
NR 24
TC 20
Z9 25
U1 0
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2010
VL 28
IS 11
BP 1524
EP 1529
DI 10.1016/j.imavis.2010.03.006
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 639KD
UT WOS:000280972800003
DA 2024-07-18
ER

PT J
AU Kiselman, CO
AF Kiselman, Christer O.
TI Inverses and quotients of mappings between ordered sets
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 8th International Symposium on Mathematical Morphology
CY OCT 10-13, 2007
CL Rio de Janeiro, BRAZIL
DE Preordered set; Complete lattice; Generalized inverse of a mapping;
   Division of mappings; Epigraph; Hypograph; Galois connection; Residuated
   mapping; Adjunction; Dilation; Erosion; Ethmomorphism; Morphological
   filter; Cleistomorphism; Closure operator; Anoiktomorphism; Kernel
   operator
ID MATHEMATICAL MORPHOLOGY; LATTICES
AB In this paper, we study inverses and quotients of mappings between ordered sets, in particular between complete lattices, which are analogous to inverses and quotients of positive numbers. We investigate to what extent a generalized inverse can serve as a left inverse and as a right inverse, and how an inverse of an inverse relates to the identity mapping. The generalized inverses and quotients are then used to create a convenient formalism for dilations and erosions as well as for cleistomorphisms (closure operators) and anoiktomorphisms (kernel operators). (C) 2009 Elsevier B.V. All rights reserved.
C1 Uppsala Univ, Dept Math, SE-75106 Uppsala, Sweden.
C3 Uppsala University
RP Kiselman, CO (corresponding author), Uppsala Univ, Dept Math, POB 480, SE-75106 Uppsala, Sweden.
EM kiselman@math.uu.se
CR [Anonymous], 1994, Morphological Image Operators
   BANON GJF, 1993, SIGNAL PROCESS, V30, P299, DOI 10.1016/0165-1684(93)90015-3
   Birkhoff G., 1940, Lattice Theory
   Birkhoff G., 1995, LATTICE THEORY, VXXV
   BLOCH I, 1995, PATTERN RECOGN, V28, P1341, DOI 10.1016/0031-3203(94)00312-A
   Blyth T, 1972, Residuation Theory
   Blyth T.S., 2005, UNIVERSITEX
   BOMAN J, 1967, MATH SCAND, V20, P249, DOI 10.7146/math.scand.a-10835
   DAVEY BA, 2003, INTRO LATTICES ORDER
   DENG TQ, 2000, PNAR0012 CWI
   DENG TQ, 2000, PNAR0014 CWI
   Dubreil P., 1964, LECONS ALGEBRE MODER
   FENCHEL W, 1949, CAN J MATH, V1, P73, DOI 10.4153/CJM-1949-007-x
   Ganter B, 1999, Formal concept analysis: Mathematical foundations
   Gierz G., 1980, A Compendium of Continuous Lattices
   Gierz G., 2003, CONTINUOUS LATTICES
   Gratzer G., 2003, GEN LATTICE THEORY
   Heijmans HJAM, 1998, J MATH IMAGING VIS, V8, P199, DOI 10.1023/A:1008226416181
   HEIJMANS HJAM, 1990, COMPUT VISION GRAPH, V50, P245, DOI 10.1016/0734-189X(90)90148-O
   Heijmans HJAM, 1997, SIGNAL PROCESS, V59, P17, DOI 10.1016/S0165-1684(97)00036-4
   Kaufmann A., 1988, Fuzzy Mathematical Models in Engineering and Management Science
   Kiselman C. O., 2002, LECT NOTES UPPSALA U
   KISELMAN CO, 1969, B SOC MATH FR, V97, P329
   Kiselman CO, 2002, T AM MATH SOC, V354, P2035, DOI 10.1090/S0002-9947-02-02915-X
   KISELMAN CO, 2007, MATH MORPHOLOGY ITS, P27
   KRIEGL A, 1990, MATH NACHR, V147, P39, DOI 10.1002/mana.19901470105
   Kriegl A., 1997, The Convenient Setting of Global Analysis, V53
   Matheron G., 1975, Random sets and integral geometry
   MICHOR P, 1984, CAHIERS TOPOLOGIE GE, V25, P113
   Michor P., 1984, CAHIERS TOPOLOGIE GE, V25, P63
   Ore O, 1944, T AM MATH SOC, V55, P493, DOI 10.2307/1990305
   PETERMANN E, 1979, J PURE APPL ALGEBRA, V15, P271
   Ronse C, 1998, APPL ALGEBR ENG COMM, V9, P45, DOI 10.1007/s002000050095
   RONSE C, 1990, SIGNAL PROCESS, V21, P129, DOI 10.1016/0165-1684(90)90046-2
   RONSE C, 1991, CVGIP-IMAG UNDERSTAN, V54, P74, DOI 10.1016/1049-9660(91)90076-2
   Serra J, 2006, J MATH IMAGING VIS, V24, P83, DOI 10.1007/s10851-005-3616-0
   SERRA J, 1986, ELEMENTS THEORIE OPT
   Serra J., 1983, IMAGE ANAL MATH MORP
   SERRA J, 1987, 39 CTR MORPH MATH EC
   Serra J., 1988, IMAGE ANAL MATH MORP
   Singer I., 1997, Abstract Convex Analysis
   SLADOJE N, 2005, THESIS ACTA U AGR SU, P112
   Stoltenberg-Hansen Viggo., 1994, MATH THEORY DOMAINS
   Stromberg T., 1996, DISSERTATIONES MATH, V352
   Ward M, 1939, T AM MATH SOC, V45, P335, DOI 10.2307/1990008
NR 45
TC 4
Z9 4
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2010
VL 28
IS 10
SI SI
BP 1429
EP 1442
DI 10.1016/j.imavis.2009.06.014
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 638YK
UT WOS:000280936300002
DA 2024-07-18
ER

PT J
AU Lee, H
   Seo, Y
   Lee, SW
AF Lee, Hyunjung
   Seo, Yongduek
   Lee, Sang Wook
TI Removing outliers by minimizing the sum of infeasibilities
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE The L-infinity optimization; Outlier removal; The sum of infeasibilities
ID OPTIMIZATION
AB This paper shows that we can classify latent outliers efficiently through the process of minimizing the sum of infeasibilities (SOI). The SOI minimization has been developed in the area of convex optimization to find an initial solution, solve a feasibility problem, or check out some inconsistent constraints. It was also adopted recently as an approximation method to minimize a robust error function under the framework of the L-infinity norm minimization for geometric vision problems. In this paper, we show that the 501 minimization is practically effective in collecting outliers when it is applied to geometric vision problems. In particular, this method is useful in structure and motion reconstruction where methods such as RAN-SAC are not applicable. We demonstrate the effectiveness of the method through experiments with synthetic and real data sets. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Lee, Hyunjung; Seo, Yongduek; Lee, Sang Wook] Sogang Univ, Dept Media Technol, Seoul, South Korea.
C3 Sogang University
RP Seo, Y (corresponding author), Sogang Univ, Dept Media Technol, Seoul, South Korea.
EM whitetobi@sogang.ac.kr; yndk@sogang.ac.kr; slee@sogang.ac.kr
OI SEO, Yongduek/0000-0002-0570-2197
FU MCST/MKE/KEIT
FX This work was supported by the strategic technology development program
   of MCST/MKE/KEIT. [2008-F-030-01, Development of Full 3D Reconstruction
   Technology for Broadcasting Communication Fusion].
CR AGARWAL S, 2008, IEEE COMP SOC C COMP
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 1982, COMBINATORIAL OPTIMI
   [Anonymous], 2006, P IEEE C COMP VIS PA
   ASTROM K, 2007, ICCV 07
   Boyd S.P., 2004, Convex optimization, DOI [10.1017/CBO9780511804441, DOI 10.1017/CBO9780511804441]
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   *GNU LIN PROGR KIT, 2006, FSF
   HARTLEY R, 2004, P IEEE C COMP VIS PA
   Kahl F, 2008, IEEE T PATTERN ANAL, V30, P1603, DOI 10.1109/TPAMI.2007.70824
   Ke Q, 2007, IEEE T PATTERN ANAL, V29, P1834, DOI 10.1109/TPAMI.2007.1083
   Olsson C., 2008, CVPR, P1
   OLSSON C, 2007, IEEE INT C COMP VIS
   Rousseeuw P. J, 1987, Robust Regression and Outlier Detection
   Salzmann M, 2007, IEEE I CONF COMP VIS, P1578
   Seo Y, 2007, IEEE I CONF COMP VIS, P668
   Sturm JF, 1999, OPTIM METHOD SOFTW, V11-2, P625, DOI 10.1080/10556789908805766
NR 17
TC 2
Z9 4
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 881
EP 889
DI 10.1016/j.imavis.2009.11.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200004
DA 2024-07-18
ER

PT J
AU Lu, XQ
   Sun, Y
   Bai, GF
AF Lu, Xiaoqiang
   Sun, Yi
   Bai, Gangfeng
TI Adaptive wavelet-Galerkin methods for limited angle tomography
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Limited angle tomography; Ill-posed inverse problem; Adaptive
   wavelet-Galerkin method
ID X-RAY TOMOGRAPHY; EXTERIOR RADON-TRANSFORM; COMPUTED-TOMOGRAPHY;
   IMAGE-RECONSTRUCTION; ITERATIVE RECONSTRUCTION; STATISTICAL INVERSION;
   INCOMPLETE DATA; RADIOGRAPHS; PROJECTIONS; ALGORITHM
AB This paper studied incomplete data problems of computed tomography that frequently occur in medical or industrial imaging, for example, when the high-density region of objects can only be penetrated by Xrays at a limited angular range. When projection data are available only in an angular range, the incomplete data problem can be attributed to the limited angle problem, which is a severely ill-posed inverse problem. In this paper, a numerical method for the treatment of inverse problems based on an adaptive wavelet-Galerkin method is introduced and investigated. The paper focuses especially on how to avoid inverse crimes in numerical simulations. The method used here combines numerical simplicity and characteristics of adapting to the unknown smoothness of a reconstructed image, which leads to significant reduction in the Computational cost. The reconstruction strategy has a comparable performance with a significant reduction in computational time. Crown Copyright (C) 2009 Published by Elsevier B.V. All rights reserved.
C1 [Lu, Xiaoqiang; Sun, Yi; Bai, Gangfeng] Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116023, Liaoning Prov, Peoples R China.
C3 Dalian University of Technology
RP Sun, Y (corresponding author), Dalian Univ Technol, Sch Elect & Informat Engn, Dalian 116023, Liaoning Prov, Peoples R China.
EM luxq666666@126.com; lslwf@dlut.edu.cn
CR ANDERSEN AH, 1989, IEEE T MED IMAGING, V8, P50, DOI 10.1109/42.20361
   BEILEI W, 2003, IEEE 29 ANN P BIOENG, P61
   Byrne C, 2000, INVERSE PROBL, V16, P1405, DOI 10.1088/0266-5611/16/5/316
   Candès E, 2005, PROC SPIE, V5674, P76, DOI 10.1117/12.600722
   Candès EJ, 2006, IEEE T INFORM THEORY, V52, P489, DOI 10.1109/TIT.2005.862083
   COLTON DL, 1998, INVERSE ACOUSTIC ROM
   DAVISON ME, 1983, SIAM J APPL MATH, V43, P428, DOI 10.1137/0143028
   Delaney AH, 1998, IEEE T IMAGE PROCESS, V7, P204, DOI 10.1109/83.660997
   FUJIEDA I, 1990, IEEE T NUCL SCI, V37, P585, DOI 10.1109/23.106681
   GRUNBAUM FA, 1980, NUMER FUNC ANAL OPT, V2, P31, DOI 10.1080/01630568008816043
   HANSON KM, 1983, J OPT SOC AM, V73, P1501, DOI 10.1364/JOSA.73.001501
   KARP JS, 1988, IEEE T MED IMAGING, V7, P21, DOI 10.1109/42.3925
   Kolehmainen V, 2003, PHYS MED BIOL, V48, P1465, DOI 10.1088/0031-9155/48/10/315
   KUDO H, 1991, J OPT SOC AM A, V8, P1148, DOI 10.1364/JOSAA.8.001148
   LAWRENCE MC, 1989, ULTRAMICROSCOPY, V31, P285, DOI 10.1016/0304-3991(89)90051-X
   LEWITT RM, 1990, J OPT SOC AM A, V7, P1834, DOI 10.1364/JOSAA.7.001834
   LOUIS AK, 1986, NUMER MATH, V48, P251, DOI 10.1007/BF01389474
   MEDOFF BP, 1987, IMAGE RECOVERY THEOR, P29
   NASSI M, 1982, IEEE T BIO-MED ENG, V29, P333, DOI 10.1109/TBME.1982.324900
   Natterer F., 1986, The Mathematics of Computerized Tomography
   Natterer F., 2001, SIAM monographs on mathematical modeling and computation
   Persson M, 2001, PHYS MED BIOL, V46, P853, DOI 10.1088/0031-9155/46/3/318
   Popa C, 2004, MATH COMPUT SIMULAT, V65, P579, DOI 10.1016/j.matcom.2004.01.021
   PRINCE JL, 1990, OPT ENG, V29, P535, DOI 10.1117/12.55622
   QUINTO ET, 1983, J MATH ANAL APPL, V95, P437, DOI 10.1016/0022-247X(83)90118-X
   QUINTO ET, 1988, INVERSE PROBL, V4, P867, DOI 10.1088/0266-5611/4/3/019
   QUINTO ET, 1993, SIAM J MATH ANAL, V24, P1215, DOI 10.1137/0524069
   Rantala M, 2006, IEEE T MED IMAGING, V25, P210, DOI 10.1109/TMI.2005.862206
   REIS ML, 1992, INVERSE PROBL, V8, P623, DOI 10.1088/0266-5611/8/4/011
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   SAUER K, 1994, IEEE T NUCL SCI, V41, P1780, DOI 10.1109/23.317389
   SEZAN K., 1987, Image Recovery, P415
   SIDKY EY, 2006, IEEE MED IM SAN DIEG
   Siltanen S, 2003, PHYS MED BIOL, V48, P1437, DOI 10.1088/0031-9155/48/10/314
   SMITH RT, 1991, APPL OPTICS, V30, P573, DOI 10.1364/AO.30.000573
   TAM KC, 1981, OPT ENG, V20, P586, DOI 10.1117/12.7972766
   Wang G, 1996, SCANNING, V18, P582
   ZHIJEWSKI W, 2006, PHYS MED BIOL, V51, P1877
NR 38
TC 15
Z9 16
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 696
EP 703
DI 10.1016/j.imavis.2009.10.011
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600014
DA 2024-07-18
ER

PT J
AU Freedman, D
   Turek, MW
AF Freedman, Daniel
   Turek, Matthew W.
TI Graph cuts with many-pixel interactions: Theory and applications to
   shape modelling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Graph cuts; Shape modelling
AB Many problems in computer vision can be posed in terms of energy minimization, where the relevant energy function models the interactions of many pixels. Finding the global or near-global minimum of such functions tends to be difficult, precisely due to these interactions of large (> 3) numbers of pixels. In this paper, we derive a set of sufficient conditions under which energies which are functions of discrete binary variables may be minimized using graph cut techniques. We apply these conditions to the problem of incorporating shape priors in segmentation. Experimental results demonstrate the validity of this approach. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Freedman, Daniel] RPI, Dept Comp Sci, Troy, NY USA.
C3 Rensselaer Polytechnic Institute
RP Freedman, D (corresponding author), Hameyasdim 68-B, IL-30900 Zikhron Yaaqov, Israel.
EM d.e.freedman@gmail.com
FU US National Science Foundation [IIS-0133144]
FX This work was supported in part by the US National Science Foundation,
   under Award IIS-0133144.
CR [Anonymous], 2001, Interactive graph cuts for optimal boundary & region segmentation of objects in nd images, DOI DOI 10.1109/ICCV.2001.937505
   Boros E, 2002, DISCRETE APPL MATH, V123, P155, DOI 10.1016/S0166-218X(01)00336-5
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   BOYKOV Y, 2003, P ICCV
   BOYKOV Y, 1999, P 7 IEEE INT C COMP, V1, P377
   CHAN T, 2005, IEEE COMP SOC C COMP, V2
   Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P388
   Cremers D, 2006, INT J COMPUT VISION, V69, P335, DOI 10.1007/s11263-006-7533-5
   Cremers Daniel., 2003, 2nd IEEE Workshop on Variational, Geometric and Level Set Methods in Computer Vision, P169
   Freedman D, 2005, PROC CVPR IEEE, P755
   FREEDMAN D, 2005, IEEE COMP SOC C COMP, V2
   Gastaud M, 2004, IEEE T CIRC SYST VID, V14, P726, DOI 10.1109/TCSVT.2004.826758
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Kolmogorov V., 2002, P ECCV
   KUMAR MP, 2005, IEEE COMP SOC C COMP, V1
   LOVASZ L, 1998, COMBINATORIAL OPTIMI
   PAPADIMITRIOU CH, 1986, ALGORITHMIC THEORY N
   Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78
NR 19
TC 0
Z9 1
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 467
EP 473
DI 10.1016/j.imavis.2009.07.006
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300017
DA 2024-07-18
ER

PT J
AU Mallot, HA
   Basten, K
AF Mallot, Hanspeter A.
   Basten, Kai
TI Embodied spatial cognition: Biological and artificial systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Spatial cognition; Spatial memory; Landmark use; Graph representations;
   Embodiment
ID PATH-INTEGRATION; PLACE RECOGNITION; VIEW-GRAPHS; DESERT ANTS;
   NAVIGATION; ROUTE; MAP; BEES; KNOWLEDGE; SPACE
AB In this paper, we sketch out a computational theory of spatial cognition motivated by navigational behaviours, ecological requirements, and neural mechanisms as identified in animals and man. Spatial cognition is considered in the context of a cognitive agent built around the action-perception cycle. Besides sensors and effectors, the agent comprises multiple memory structures including a working memory and a longterm memory stage. Spatial longterm memory is modelled along the graph approach, treating recognizable places or poses as nodes and navigational actions as links. Models of working memory and its interaction with reference memory are discussed. The model provides an overall framework of spatial cognition which can be adapted to model different levels of behavioural complexity as well as interactions between working and longterm memory. A number of design questions for building cognitive robots are derived from comparison with biological systems and discussed in the paper. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Mallot, Hanspeter A.; Basten, Kai] Univ Tubingen, Fac Biol, Dept Cognit Neurobiol, D-72076 Tubingen, Germany.
C3 Eberhard Karls University of Tubingen
RP Basten, K (corresponding author), Univ Tubingen, Fac Biol, Dept Cognit Neurobiol, D-72076 Tubingen, Germany.
EM hanspeter.mallot@uni-tuebingen.de; kai.basten@uni-tuebingen.de
RI Mallot, Hanspeter A/H-7888-2016
FU European Commission [FP6-2003-NEST-PATH]; Deutsche
   Forschungsgemeinschaft [SFB 550]
FX The work described in the paper was supported by the European Commission
   (FP6-2003-NEST-PATH Project "Wayfinding") and the Deutsche
   Forschungsgemeinschaft (SFB 550).
CR ALLEN GL, 1979, CHILD DEV, V50, P1062, DOI 10.2307/1129332
   [Anonymous], 1978, Cogn. Sci, DOI [DOI 10.1207/S15516709COG0202_3, DOI 10.1207/S15516709COG02023, 10.1016/S0364-0213(78)80003-2]
   [Anonymous], 1977, SYSTEMS NEUROSCIENCE
   [Anonymous], 2003, Spatial Cognition Computation, DOI DOI 10.1207/S15427633SCC0304_5
   APPLEYARD D, 1970, ENVIRON BEHAV, V2, P100, DOI 10.1177/001391657000200106
   Arleo A, 2004, IEEE T NEURAL NETWOR, V15, P639, DOI 10.1109/TNN.2004.826221
   Baddeley AD., 1986, Working memory
   Bailenson JN, 2000, MEM COGNITION, V28, P306, DOI 10.3758/BF03213808
   Bee MA, 2002, P ROY SOC B-BIOL SCI, V269, P1443, DOI 10.1098/rspb.2002.2041
   BENEDIKT ML, 1979, ENVIRON PLANN B, V6, P47, DOI 10.1068/b060047
   Bisch-Knaden S, 2003, J COMP PHYSIOL A, V189, P181, DOI 10.1007/s00359-003-0389-z
   CARTWRIGHT BA, 1987, BIOL CYBERN, V57, P85, DOI 10.1007/BF00318718
   CARTWRIGHT BA, 1982, NATURE, V295, P560, DOI 10.1038/295560a0
   CHENG K, 1986, COGNITION, V23, P149, DOI 10.1016/0010-0277(86)90041-7
   Christou CG, 1999, MEM COGNITION, V27, P996, DOI 10.3758/BF03201230
   Collett M, 2000, BIOL CYBERN, V83, P245, DOI 10.1007/s004220000168
   CORNELL EH, 1994, MEM COGNITION, V22, P633, DOI 10.3758/BF03209249
   Cramer AE, 1997, NATURE, V387, P464, DOI 10.1038/387464a0
   Durier V, 2004, J EXP BIOL, V207, P2401, DOI 10.1242/jeb.01043
   Dyer FC, 1996, J EXP BIOL, V199, P147
   Eichenbaum H, 1996, CURR OPIN NEUROBIOL, V6, P187, DOI 10.1016/S0959-4388(96)80072-9
   Foo P, 2005, J EXP PSYCHOL LEARN, V31, P195, DOI 10.1037/0278-7393.31.2.195
   Franz MO, 1998, AUTON ROBOT, V5, P111, DOI 10.1023/A:1008821210922
   Franz MO, 2000, ROBOT AUTON SYST, V30, P133, DOI 10.1016/S0921-8890(99)00069-X
   Franz MO, 1998, BIOL CYBERN, V79, P191, DOI 10.1007/s004220050470
   FUJITA N, 1993, GEOGR ANAL, V25, P295
   Gallagher S., 2005, BODY SHAPES MIND
   Gallistel C. R., 1990, The Organization of Learning
   Gaussier P, 2002, BIOL CYBERN, V86, P15, DOI 10.1007/s004220100269
   Gengler S, 2005, BEHAV BRAIN RES, V164, P73, DOI 10.1016/j.bbr.2005.06.009
   Gillner S, 1998, J COGNITIVE NEUROSCI, V10, P445, DOI 10.1162/089892998562861
   GILLNER S, COGNITION IN PRESS
   Hafting T, 2005, NATURE, V436, P801, DOI 10.1038/nature03721
   Hartley T, 2003, NEURON, V37, P877, DOI 10.1016/S0896-6273(03)00095-3
   Hauser M.D., 2000, WILD MINDS WHAT ANIM
   Hauser MD, 2002, SCIENCE, V298, P1569, DOI 10.1126/science.298.5598.1569
   HEFT H, 1979, ENVIRON PSYCH NONVER, V3, P172, DOI 10.1007/BF01142591
   HERMER L, 1994, NATURE, V370, P57, DOI 10.1038/370057a0
   Hermer-Vazquez L, 1999, COGNITIVE PSYCHOL, V39, P3, DOI 10.1006/cogp.1998.0713
   HILLIER B, 1993, ENVIRON PLANN B, V20, P29, DOI 10.1068/b200029
   Hübner W, 2007, AUTON ROBOT, V23, P183, DOI 10.1007/s10514-007-9040-0
   Hurlebaus R, 2008, LECT NOTES ARTIF INT, V5248, P104, DOI 10.1007/978-3-540-87601-4_10
   Ishikawa T, 2006, COGNITIVE PSYCHOL, V52, P93, DOI 10.1016/j.cogpsych.2005.08.003
   Janzen G, 2004, NAT NEUROSCI, V7, P673, DOI 10.1038/nn1257
   Jeffery KJ, 2006, EXP BRAIN RES, V169, P218, DOI 10.1007/s00221-005-0138-3
   Keefe J.O., 1978, HIPPOCAMPUS COGNITIV
   Klatzky R. L., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P1
   Kohler M, 2005, NEUROBIOL LEARN MEM, V83, P1, DOI 10.1016/j.nlm.2004.05.011
   Kuipers B, 2003, ENVIRON BEHAV, V35, P81, DOI 10.1177/0013916502238866
   Kuipers B, 2000, ARTIF INTELL, V119, P191, DOI 10.1016/S0004-3702(00)00017-5
   Lakoff G., 1987, Women, Fire, and Dangerous Things: What Categories Reveal About the Mind
   Mallot HA, 2000, PERCEPTION, V29, P43, DOI 10.1068/p2865
   MALLOT HA, 1999, KOGNITIONSWISSENSCHA, V8, P40
   MCNAMARA TP, 1984, J EXP PSYCHOL LEARN, V10, P723, DOI 10.1037/0278-7393.10.4.723
   McNamara TP, 1997, COGNITIVE PSYCHOL, V34, P160, DOI 10.1006/cogp.1997.0669
   McNaughton BL, 2006, NAT REV NEUROSCI, V7, P663, DOI 10.1038/nrn1932
   Menzel R, 1996, J EXP BIOL, V199, P141
   Menzel R, 2005, P NATL ACAD SCI USA, V102, P3040, DOI 10.1073/pnas.0408550102
   Menzel R, 2006, J COMP PHYSIOL A, V192, P889, DOI 10.1007/s00359-006-0136-3
   Merkle T, 2006, J THEOR BIOL, V240, P385, DOI 10.1016/j.jtbi.2005.10.003
   O'Keefe J, 1998, PHILOS T ROY SOC B, V353, P1333, DOI 10.1098/rstb.1998.0287
   Ohashi K, 2007, BEHAV ECOL, V18, P1, DOI [10.1093/beheco/ar1053, 10.1093/beheco/arl053]
   Philbeck JW, 2005, PSICOLOGICA, V26, P7
   Restat JD, 2004, PERCEPTION, V33, P667, DOI 10.1068/p5030
   Rolls ET, 1998, J NEUROPHYSIOL, V79, P1797, DOI 10.1152/jn.1998.79.4.1797
   ROSSEL S, 1982, P NATL ACAD SCI-BIOL, V79, P4451, DOI 10.1073/pnas.79.14.4451
   Schaub A, 2007, J COMP PHYSIOL A, V193, P1185, DOI 10.1007/s00359-007-0269-z
   SCHMAJUK NA, 1992, BIOL CYBERN, V67, P165, DOI 10.1007/BF00201023
   Schmid W, 2002, IEEE J SEL TOP QUANT, V8, P256, DOI 10.1109/2944.999178
   SCHOLKOPF B, 1995, ADAPT BEHAV, V3, P311, DOI 10.1177/105971239500300303
   Schweizer K., 1998, Spatial Cognition. An Interdisciplinary Approach to Representing and Processing Spatial Knowledge, P19
   Siegel A W, 1975, Adv Child Dev Behav, V10, P9, DOI 10.1016/S0065-2407(08)60007-5
   Spelke ES, 2007, DEVELOPMENTAL SCI, V10, P89, DOI 10.1111/j.1467-7687.2007.00569.x
   Squire L. R., 1987, Memory and brain
   Stamps JA, 1999, Q REV BIOL, V74, P291, DOI 10.1086/393163
   Stürzl W, 2006, ROBOT AUTON SYST, V54, P300, DOI 10.1016/j.robot.2005.12.001
   Thrun S, 1998, ARTIF INTELL, V99, P21, DOI 10.1016/S0004-3702(97)00078-7
   Tolman E. C, 1932, PURPOSIVE BEHAV ANIM
   TOLMAN EC, 1948, PSYCHOL REV, V55, P189, DOI 10.1037/h0061626
   Trullier O, 1997, PROG NEUROBIOL, V51, P483, DOI 10.1016/S0301-0082(96)00060-3
   Vogeley K, 2004, J COGNITIVE NEUROSCI, V16, P817, DOI 10.1162/089892904970799
   von Frisch K., 1967, DANCE LANGUAGE ORIEN
   Waller D, 2007, MEM COGNITION, V35, P910, DOI 10.3758/BF03193465
   Wehner R, 2006, CURR BIOL, V16, P75, DOI 10.1016/j.cub.2005.11.035
   WEHNER R, 1985, NATURE, V315, P228, DOI 10.1038/315228a0
   Wehner R, 2003, J COMP PHYSIOL A, V189, P579, DOI 10.1007/s00359-003-0431-1
   Wiener J.M., 2006, Spatial Cognition and Computation, V6, P333, DOI [DOI 10.1207/S15427633SCC0604_3, 10.1207/s15427633scc06043, DOI 10.1207/S15427633SCC06043]
   Wiener JM, 2007, PERCEPTION, V36, P1066, DOI 10.1068/p5587
   Wiener JM, 2004, J ENVIRON PSYCHOL, V24, P475, DOI 10.1016/j.jenvp.2004.09.006
   Zeil J, 1996, J EXP BIOL, V199, P245
   Zeil J, 2003, J OPT SOC AM A, V20, P450, DOI 10.1364/JOSAA.20.000450
   ZHANG SW, 1995, P NATL ACAD SCI USA, V92, P3029, DOI 10.1073/pnas.92.7.3029
   Zugaro MB, 2001, J NEUROSCI, V21, DOI 10.1523/JNEUROSCI.21-14-j0001.2001
NR 93
TC 34
Z9 37
U1 2
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 2
PY 2009
VL 27
IS 11
SI SI
BP 1658
EP 1670
DI 10.1016/j.imavis.2008.09.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 498HJ
UT WOS:000270127800003
DA 2024-07-18
ER

PT J
AU Kollreider, K
   Fronthaler, H
   Bigun, J
AF Kollreider, K.
   Fronthaler, H.
   Bigun, J.
TI Non-intrusive liveness detection by face images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face liveness; Liveness detection; Anti-spoofing measures; Optical flow;
   Motion of lines; Optical flow of lines; Orientation estimation; Face
   part models; Retinotopic vision; Local Gabor decomposition; Support
   vector machine classification
ID AUTHENTICATION
AB A technique evaluating liveness in face image sequences is presented. To ensure the actual presence of alive face in contrast to a photograph (playback attack), is a significant problem in face authentication to the extent that anti-spoofing measures are highly desirable. The purpose of the proposed system is to assist in a biometric authentication framework, by adding liveness awareness in a non-intrusive manner. Analyzing the trajectories of certain parts of alive face reveals valuable information to discriminate it against a spoofed one. The proposed system uses a lightweight novel optical flow, which is especially applicable in face motion estimation based on the structure tensor and inputs of a few frames. For reliable face part detection, the system utilizes a model-based local Gabor decomposition and SVM experts, where selected points from a retinotopic grid are used to form regional face models. Also the estimated optical flow is exploited to detect a face part. The whole procedure, starting with three images as input and finishing in a liveness score, is executed in near real-time without special purpose hardware. Experimental results on the proposed system are presented on both a public database and spoofing attack simulations. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Kollreider, K.; Fronthaler, H.; Bigun, J.] Halmstad Univ, SE-30118 Halmstad, Sweden.
C3 Halmstad University
RP Kollreider, K (corresponding author), Halmstad Univ, SE-30118 Halmstad, Sweden.
EM klaus.kollreider@ide.hh.se; hartwig.fronthaler@ide.hh.se;
   josef.bigun@ide.hh.se
RI Bigun, Josef/AGW-4060-2022
OI Bigun, Josef/0000-0002-4929-1262
CR [Anonymous], SPECIFICATION SHEET
   [Anonymous], 2002, Inf. Secur. Tech. Rep., DOI DOI 10.1016/S1363-4127(02)00407-7
   [Anonymous], 1984, STUDIES BRAIN FUNCTI
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bigun ES, 1997, LECT NOTES COMPUT SC, V1206, P291, DOI 10.1007/BFb0016008
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   BIGUN J, 1994, INT C PATT RECOG, P184, DOI 10.1109/ICPR.1994.577153
   Bigun J, 2004, CIHSPS 2004: PROCEEDINGS OF THE 2004 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE FOR HOMELAND SECURITY AND PERSONAL SAFETY, P104, DOI 10.1109/CIHSPS.2004.1360218
   Bigun J., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P433
   BIGUN J, 1993, P DSP CAES C NIC CYP, P229
   Bigun J., 2006, Vision with Direction
   CHETTY G, 2006, BIOM S
   CHOUDHURY T, 1999, 2 INT C AUD VIS BIOM
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Duc B, 1999, IEEE T IMAGE PROCESS, V8, P504, DOI 10.1109/83.753738
   Fasel IR, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P242, DOI 10.1109/AFGR.2002.1004161
   Frischholz RW, 2000, COMPUTER, V33, P64, DOI 10.1109/2.820041
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   GRANLUND GH, 1978, COMPUT VISION GRAPH, V8, P155, DOI 10.1016/0146-664X(78)90047-3
   HUBEL DH, 1959, J PHYSIOL-LONDON, V148, P574, DOI 10.1113/jphysiol.1959.sp006308
   JAIN A, 1999, AUDIO VIDEO BASED PE, P182
   KNUTSSON H, 1982, THESIS LINKOPING U
   Kollreider K, 2005, FOURTH IEEE WORKSHOP ON AUTOMATIC IDENTIFICATION ADVANCED TECHNOLOGIES, PROCEEDINGS, P75, DOI 10.1109/AUTOID.2005.20
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Li JW, 2004, P SOC PHOTO-OPT INS, V5404, P296, DOI 10.1117/12.541955
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Messer K, 1999, Second International Conference on Audio and Video-based Biometric Person Authentication, P72
   Ratha NK, 2001, IBM SYST J, V40, P614, DOI 10.1147/sj.403.0614
   Smeraldi F, 2002, PATTERN RECOGN LETT, V23, P463, DOI 10.1016/S0167-8655(01)00178-7
   Smeraldi F, 1998, 1998 5TH INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL - PROCEEDINGS, P684, DOI 10.1109/AMC.1998.743637
   SMERALDI F, 1998, INT C IM PROC ICIP 9, V3, P163
   TISTARELLI M, 1993, IEEE T PATTERN ANAL, V15, P401, DOI 10.1109/34.206959
   Yarbus Alfred L., 1967, EYE MOVEMENTS
NR 33
TC 113
Z9 130
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 2
PY 2009
VL 27
IS 3
SI SI
BP 233
EP 244
DI 10.1016/j.imavis.2007.05.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 393QA
UT WOS:000262386600003
DA 2024-07-18
ER

PT J
AU Malagón-Borja, L
   Fuentes, O
AF Malagon-Borja, Luis
   Fuentes, Olac
TI Object detection using image reconstruction with PCA
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Object detection; Pedestrian detection; Principal Component Analysis;
   Support Vector Machines
ID EIGENFACES
AB In this paper, we present an object detection system and its application to pedestrian detection in still images, without assuming any a priori knowledge about the image. The system works as follows: in a first stage a classifier examines each location in the image at different scales. Then in a second stage the system tries to eliminate false detections based on heuristics. The classifier is based on the idea that Principal Component Analysis (PCA) can compress optimally only the kind of images that were used to compute the principal components (PCs), and that any other kind of images will not be compressed well using a few components. Thus the classifier performs separately the PCA from the positive examples and from the negative examples; when it needs to classify a new pattern it projects it into both sets of PCs and compares the reconstructions, assigning the example to the class with the smallest reconstruction error. The system is able to detect frontal and rear views of pedestrians, and usually can also detect side views of pedestrians despite not being trained for this task. Comparisons with other pedestrian detection systems show that our system has better performance in positive detection and in false detection rate. Additionally, we show that the performance of the system can be further improved by combining the classifier based on PCA reconstruction with a conventional classifier using a Support Vector Machine. (C) 2007 Published by Elsevier B.V.
C1 [Fuentes, Olac] Univ Texas El Paso, Dept Comp Sci, El Paso, TX 79968 USA.
   [Malagon-Borja, Luis] INAOE, Dept Comp Sci, Puebla 72840, Mexico.
C3 University of Texas System; University of Texas El Paso; Instituto
   Nacional de Astrofisica, Optica y Electronica
RP Fuentes, O (corresponding author), Univ Texas El Paso, Dept Comp Sci, El Paso, TX 79968 USA.
EM jmb@inaoep.mx; ofuentes@utep.edu
CR AVIDAN S, 2003, P IEEE C COMP VIS PA
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   De la Torre F, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P362, DOI 10.1109/ICCV.2001.937541
   FABLET R, 2002, P EUR C COMP VIS, P476
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Jabri S., 2000, Proceedings of the International Conference on Pattern Recognition, P4627
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   MOHAN A, 1999, 1664 AI MIT CTR BIOL
   MOLER CB, 1973, SIAM J NUMER ANAL, V10, P241, DOI 10.1137/0710024
   Nayar SK, 1996, IEEE INT CONF ROBOT, P2321, DOI 10.1109/ROBOT.1996.506510
   Oren M, 1997, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.1997.609319
   OREN M, 1997, P IM UND WORKSH, P207
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   PAPAGEORGIOU C, 1997, THESIS MIT CAMBRIDGE
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vapnik V., 1999, NATURE STAT LEARNING
   Viola P, 2005, INT J COMPUT VISION, V63, P153, DOI 10.1007/s11263-005-6644-8
   Witten I. H., 2005, DATA MINING PRACTICA
   Yang MH, 2000, ADV NEUR IN, V12, P862
   Zhao L, 2000, IEEE T INTELL TRANSP, V1, P148, DOI 10.1109/6979.892151
NR 25
TC 50
Z9 55
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 2
EP 9
DI 10.1016/j.imavis.2007.03.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700002
DA 2024-07-18
ER

PT J
AU Leung, C
   Appleton, B
   Sun, CM
AF Leung, Carlos
   Appleton, Ben
   Sun, Changming
TI Iterated dynamic programming and quadtree subregioning for fast stereo
   matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereo matching; energy minimisation; iterated dynamic programming;
   quadtree subregioning
AB The application of energy minimisation methods for stereo matching has been demonstrated to produce high quality disparity maps. However, the majority of these methods are known to be computationally expensive requiring minutes of computation. In this paper, we propose a fast minimisation scheme that produces high quality stereo reconstructions for significantly reduced running time, requiring only a few seconds of computation. The minimisation scheme is carried out using our iterated dynamic programming algorithm, which iterates over entire rows and columns for fast stereo matching. A quadtree subregioning process is also used for efficient computation of a matching cost volume where iterated dynamic programming operates on. (c) 2008 Published by Elsevier B.V.
C1 [Leung, Carlos; Appleton, Ben] Univ Queensland, ITEE, Brisbane, Qld 4072, Australia.
   [Sun, Changming] CSIRO Math & Informat Sci, N Ryde, NSW 1670, Australia.
C3 University of Queensland; Commonwealth Scientific & Industrial Research
   Organisation (CSIRO)
RP Leung, C (corresponding author), Suncorp, POB 1453, Brisbane, Qld 4001, Australia.
EM carlos.leung@gmail.com; appleton@google.com; changming.sun@csiro.au
RI Whitford, Linda M/C-2470-2009; Sun, Changming/A-3276-2008
OI Sun, Changming/0000-0001-5943-1989
CR [Anonymous], 1999, THESIS CORNELL U
   [Anonymous], 1993, RR2013 INRIA
   Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146
   Birchfield S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P489, DOI 10.1109/ICCV.1999.791261
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040
   GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gimel'farb G. L., 1992, International Journal of Imaging Systems and Technology, V4, P7, DOI 10.1002/ima.1850040104
   ISHIKAWA H, 1998, P EUR C COMP VIS, P232
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   LEUNG C, 2004, BRIT MACH VIS C, V1, P97
   LEUNG C, 2006, THESIS U QUEENSLAND
   LEUNG C, ITERATED DYNAMIC PRO
   LLOYD SA, 1985, GEC-J RES, V3, P18
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763
   Schapira AHV, 2002, EUR J NEUROL, V9, P7, DOI 10.1046/j.1468-1331.9.s3.9.x
   Sun C, 1997, DIGITAL IMAGE COMPUT, P95
   Sun CM, 2003, PATTERN RECOGN, V36, P709, DOI 10.1016/S0031-3203(02)00085-7
   Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703
NR 22
TC 8
Z9 10
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1371
EP 1383
DI 10.1016/j.imavis.2007.11.013
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700007
DA 2024-07-18
ER

PT J
AU Ramanathan, S
   Kassim, AA
   Tan, TS
AF Ramanathan, Subramanian
   Kassim, Ashraf A.
   Tan, Tiow-Seng
TI Impact of vertex clustering on registration-based 3D dynamic mesh coding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D dynamic meshes; data compression; computer animation
ID COMPRESSION
AB 3D dynamic meshes are associated with voluminous data and need to be encoded for efficient storage and transmission. We study the impact of vertex clustering on registration-based dynamic mesh coding, where compact mesh motion representation is achieved by computing correspondences for the mesh segments from the temporal reference to obtain high compression performance. Clustering algorithms segment the mesh into smaller pieces and the compression performance is directly related to how effectively these pieces can describe the mesh motion. In this paper, we demonstrate that the use of efficient vertex clustering schemes in the compression framework can bring about a 10% improvement in compression performance. (c) 2008 Published by Elsevier B.V.
C1 [Ramanathan, Subramanian; Kassim, Ashraf A.] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
   [Tan, Tiow-Seng] Natl Univ Singapore, Sch Comp, Singapore 117590, Singapore.
C3 National University of Singapore; National University of Singapore
RP Kassim, AA (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 10 Kent Ridge Crescent, Singapore 119260, Singapore.
EM eleashra@nus.edu.sg
OI Subramanian, Ramanathan/0000-0001-9441-7074; Kassim,
   Ashraf/0000-0001-7435-8564
CR Ahn JH, 2001, ELECTRON LETT, V37, P1445, DOI 10.1049/el:20010993
   ALEXA M, 2000, EUROGRAPHICS, V19, P411
   AMJOUN R, 2007, EFFICIENT COMPRESSIO
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Brand M., 2003, P 9 INT WORKSH ART I
   CHOW M, 1997, P VIS 97
   COHENOR D, 1999, P VIS 99
   DEERING M, 1995, P 22 ANN C COMP GRAP, P13
   GUMHOLD S, 1998, P SIGGRAPH 98, P133
   Gupta S, 2002, COMPUT VIS IMAGE UND, V87, P116, DOI 10.1006/cviu.2002.0987
   Guskov I., 2004, Proc. 2004 ACM SIG- GRAPH/Eurographics Symp. Comput. Animation (SCA '04), P183
   HENDRICKSON B, 1995, SIAM J SCI COMPUT, V16, P452, DOI 10.1137/0916028
   Hendrickson B., 1995, SUPERCOMPUTING
   IBARRIA L, 1999, P ACM SIGGRAPH S COM
   KANUNGO T, 1991, P 16 ANN S COMP GEOM, P100
   Karni Z, 2004, COMPUT GRAPH-UK, V28, P25, DOI 10.1016/j.cag.2003.10.002
   Katz S, 2003, ACM T GRAPHIC, V22, P954, DOI 10.1145/882262.882369
   Kernighan B. W., 1970, The Bell System Technical Journal, V49, P291, DOI [10.1002/j.1538-7305.1970.tb01770.x, DOI 10.1002/J.1538-7305.1970.TB01770.X]
   KOENEN R, 2000, OVERVIEW MPEG 4 STAN
   LENGYEL JE, 1999, SI3D 99, P89, DOI DOI 10.1145/300523.300533
   LI J, 1998, P IEEE INT C IM PROC
   Li X., 2001, P 2001 S INT 3D GRAP, P35, DOI DOI 10.1145/364338.364343
   Liu R, 2004, 12TH PACIFIC CONFERENCE ON COMPUTER GRAPHICS AND APPLICATIONS, PROCEEDINGS, P298
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   MULLER K, 2005, ICIP05, P589
   Pajarola R, 2000, IEEE T VIS COMPUT GR, V6, P79, DOI 10.1109/2945.841122
   PAYAN F, 2005, P IEEE ACIDCA ICMI 2
   Rossignac J, 1999, IEEE T VIS COMPUT GR, V5, P47, DOI 10.1109/2945.764870
   Sattler Mirko, 2005, P ACM SIGGRAPH EUR S, P209
   Shamir A, 2000, IEEE VISUAL, P423, DOI 10.1109/VISUAL.2000.885724
   SIMON HD, 1991, P C PAR METH LARG SC
   Stefanoski N, 2006, IEEE IMAGE PROC, P2973, DOI 10.1109/ICIP.2006.312961
   Taubin G, 1998, ACM T GRAPHIC, V17, P84, DOI 10.1145/274363.274365
   Touma C, 1998, GRAPHICS INTERFACE '98 - PROCEEDINGS, P26
   VARAKLIOTIS S, 2001, P INT C MULT EXP, P353
   Weiss Y., 1999, INT C COMPUTER VISIO, P975
   Yang JH, 2002, IEEE T CIRC SYST VID, V12, P1178, DOI 10.1109/TCSVT.2002.806814
   ZHANG H, 2005, P VIS MOD VIS
NR 38
TC 6
Z9 10
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 1012
EP 1026
DI 10.1016/j.imavis.2007.11.005
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800014
DA 2024-07-18
ER

PT J
AU Stewénius, H
   Nistér, D
   Kahl, F
   Schaffalitzky, F
AF Stewenius, Henrik
   Nister, David
   Kahl, Fredrik
   Schaffalitzky, Frederik
TI A minimal solution for relative pose with unknown focal length
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE computer vision; relative pose; relative orientation; camera calibration
ID MOTION
AB Assume that we have two perspective images with known intrinsic parameters except for an unknown common focal length. It is a minimally constrained problem to find the relative orientation between the two images given six corresponding points. To this problem which to the best of our knowledge was unsolved we present an efficient solver. Through numerical experiments we demonstrate that the algorithm is correct, numerically stable and useful. The solutions are found through eigen-decomposition of a 15 x 15 matrix. The matrix itself is generated in closed form. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Stewenius, Henrik] Univ Kentucky, Ctr Visualizat & Virtual Environm, Lexington, KY 40506 USA.
   [Nister, David] Microsoft Res, Microsoft Live Labs, Redmond, WA USA.
   [Kahl, Fredrik] Lund Univ, Ctr Math Sci, S-22100 Lund, Sweden.
   [Schaffalitzky, Frederik] Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England.
C3 University of Kentucky; Microsoft; Lund University; University of Oxford
EM hstewenius@gmail.com
CR [Anonymous], 1997, Ideals, Varieties, and Algorithms: An Introduction to Computational Algebraic Geometry and Commutative Algebra
   [Anonymous], P CVPR
   [Anonymous], 1993, SPRINGER SERIES INFO
   [Anonymous], 1998, USING ALGEBRAIC GEOM, DOI DOI 10.1007/978-1-4757-6911-1
   Demazure Michel, 1988, RR0882 INRIA
   FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997
   Faugére JC, 1999, J PURE APPL ALGEBRA, V139, P61, DOI 10.1016/S0022-4049(99)00005-5
   GRAYSON D, 1993, MACAULAY 2
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   KAHL F, 1999, IEEE COMPUTER VISION, V2, P366
   KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377
   Kruppa E., 1913, Sitz.-Ber. Akad. Wiss., Wien, V122, P1939
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   NISTER D, 2004, P 8 EUR C COMP VIS, V2, P41
   PHILIP J, 1996, PHOTOGRAMM REC, V15, P589, DOI DOI 10.1111/0031-868X.00066
   Stefanovic P, 1973, ITC J, V3, P417
   Stewenius H., 2005, THESIS LUND U
   Torr PHS, 1999, INT J COMPUT VISION, V32, P27, DOI 10.1023/A:1008140928553
   TRAVERSO C, 1989, LECT NOTES COMPUTER
   WINKLER F, J SYMBOLIC COMPUTATI, V6, P287
NR 20
TC 28
Z9 35
U1 2
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 871
EP 877
DI 10.1016/j.imavis.2007.10.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800001
OA Green Published
DA 2024-07-18
ER

PT J
AU Cui, SH
   Liu, J
AF Cui, Shi Hua
   Liu, Jie
TI Simplified patterns for extracting the isosurfaces of solid objects
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE surface reconstruction; marching cubes; isosurface; triangulation
ID ALGORITHM; GENERATION
AB By moving the positions of isosurface vertice from the cube edge interpolation points as in the standard marching cubes (MC), to the centers of the corresponding occupied cube vertices, this paper presents a set of much simpler triangulation patterns for isosurface extraction. Compared with the MC algorithm, the new design gives much fewer triangles, less extraction time, and exhibits remarkable resistance against dot noises, and the generated isosurface somewhat retains the object sharpness on convex surfaces. Among the whole 256 cases, the MC algorithm utilizes 254 for triangulation, while the present algorithm considers only 178. On the assumption that each case occurs once, 820 triangles will be extracted in the standard MC algorithm, while the present algorithm creates only 308 triangles. Extraction results using solid shapes and a real anatomical dataset demonstrate the considerable reduction in vertices, edges, triangles, and extracting time via the present patterns, with comparable rendering quality with the MC approach. And extraction experiments on 2 noisy datasets further verified the strong resistance to dot noise of the present algorithm. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Cui, Shi Hua; Liu, Jie] Beijing Jiaotong Univ, Sch Comp & Informat Technol, Inst Informat Sci, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University
RP Cui, SH (corresponding author), Beijing Jiaotong Univ, Sch Comp & Informat Technol, Inst Informat Sci, Beijing 100044, Peoples R China.
EM seacui@vip.sina.com
RI zhou, chuyue/JOJ-9001-2023
CR ARAUJO BRD, 2005, COMPUTER GRAPHICS, V29, P686
   Chuang JH, 1995, COMPUT GRAPH-UK, V19, P805, DOI 10.1016/0097-8493(95)00051-8
   Delibasis KS, 2001, COMPUT MED IMAG GRAP, V25, P343, DOI 10.1016/S0895-6111(00)00082-3
   Gironés X, 1998, J MOL GRAPH MODEL, V16, P190, DOI 10.1016/S1093-3263(99)00009-1
   Lee TY, 2001, COMPUT MED IMAG GRAP, V25, P405, DOI 10.1016/S0895-6111(00)00084-7
   Lindblad J, 2005, IMAGE VISION COMPUT, V23, P111, DOI 10.1016/j.imavis.2004.06.012
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   Montani C, 2000, COMPUT AIDED GEOM D, V17, P207, DOI 10.1016/S0167-8396(99)00049-7
   Montani C., 1994, Visual Computer, V10, P353, DOI 10.1007/BF01900830
   Nielson GA, 2004, COMPUT AIDED GEOM D, V21, P751, DOI 10.1016/j.cagd.2004.07.006
   Nooruddin FS, 2003, IEEE T VIS COMPUT GR, V9, P191, DOI 10.1109/TVCG.2003.1196006
   Oh KM, 1996, VISUAL COMPUT, V12, P406
   Rajon DA, 2003, COMPUT MED IMAG GRAP, V27, P411, DOI 10.1016/S0895-6111(03)00032-6
   SHU RB, 1995, VISUAL COMPUT, V11, P202
   Tsai MD, 2004, COMPUT MED IMAG GRAP, V28, P307, DOI 10.1016/j.compmedimag.2004.05.001
   Zhou C, 1995, COMPUT GRAPH-UK, V19, P793, DOI 10.1016/0097-8493(95)00050-X
   ZHOU C, 1994, COMPUT GRAPH-UK, V18, P845, DOI 10.1016/0097-8493(94)90011-6
   Zhu YC, 2005, IEEE T VIS COMPUT GR, V11, P306, DOI 10.1109/TVCG.2005.50
NR 18
TC 2
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 174
EP 186
DI 10.1016/j.imavis.2007.02.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500003
DA 2024-07-18
ER

PT J
AU Pi, L
   Shen, CM
   Li, F
   Fan, J
AF Pi, Ling
   Shen, Chaomin
   Li, Fang
   Fan, Jinsong
TI A variational formulation for segmenting desired objects in color images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE active contours; Chan-Vese model; desired objects; discrimination
   function
ID ACTIVE CONTOURS
AB This paper presents a new variational formulation for detecting interior and exterior boundaries of desired object(s) in color images. The classical level set methods can handle changes in topology, but can not detect interior boundaries. The Chan-Vese model can detect the interior and exterior boundaries of all objects, but cannot detect the boundaries of desired object(s) only. Our method combines the advantages of both methods. In our algorithm, a discrimination function on whether a pixel belongs to the desired object(s) is given. We define a modified Chan-Vese functional and give the corresponding evolution equation. Our method also improves the classical level set method by adding a penalizing term in the energy functional so that the calculation of the signed distance function and re-initialization can be avoided. The initial curve and the stopping function are constructed based on that discrimination function. The initial curve locates near the boundaries of the desired object(s), and converges to the boundaries efficiently. In addition, our algorithm can be implemented by using only simple central difference scheme, and no upwind scheme is needed. This algorithm has been applied to real images with a fast and accurate result. The existence of the minimizer to the energy functional is proved in the Appendix A. (C) 2007 Elsevier B.V. All rights reserved.
C1 Shanghai Jiao Tong Univ, Dept Math, Shanghai 200240, Peoples R China.
   E China Normal Univ, Joint Lab Imaging Sci & Technol, Shanghai 200062, Peoples R China.
   E China Normal Univ, Dept Comp Sci, Shanghai 200062, Peoples R China.
   E China Normal Univ, Dept Math, Shanghai 200062, Peoples R China.
   Southwest Univ, Dept Math, Chongqing 400715, Peoples R China.
   Wenzhou Univ, Sch Math & Informat Sci, Wenzhou 325000, Zhejiang, Peoples R China.
C3 Shanghai Jiao Tong University; East China Normal University; East China
   Normal University; East China Normal University; Southwest University -
   China; Wenzhou University
RP Pi, L (corresponding author), Shanghai Jiao Tong Univ, Dept Math, Shanghai 200240, Peoples R China.
EM piling@sjtu.edu.cn; cmshen@cs.ecnu.edu.cn; lifangswnu@126.com;
   fjs@wzu.edu.cn
CR Anderson T.W., 1962, Tech. rep.
   [Anonymous], 2002, SURFACES
   [Anonymous], 1983, GEOMETRICAL METHODS
   [Anonymous], 1989, GRADUATE TEXTS MATH
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   GIUSTI E, 1984, MINIMAL SURFACES FUC
   Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kimmel R, 2003, GEOMETRIC LEVEL SET METHODS IN IMAGING, VISION AND GRAPHICS, P59, DOI 10.1007/0-387-21810-6_4
   Li CM, 2005, PROC CVPR IEEE, P430
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Peng DP, 1999, J COMPUT PHYS, V155, P410, DOI 10.1006/jcph.1999.6345
   SAPIRO G, 1995, 113 HEWL PACK LABS
   Sethian J., 1999, LEVEL SET METHODS FA
   Wang YM, 1998, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1998.698628
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
NR 23
TC 25
Z9 30
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1414
EP 1421
DI 10.1016/j.imavis.2006.12.013
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000004
DA 2024-07-18
ER

PT J
AU Wilkinson, MHF
AF Wilkinson, Michael H. F.
TI Attribute-space connectivity and connected filters
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE mathematical morphology; connectivity; hyperconnectivity; multi-scale
   analysis; connected filters; perceptual grouping
ID IMAGE; OPERATORS; OPENINGS
AB In this paper connected operators from mathematical morphology are extended to a wider class of operators, which are based on connectivities in higher dimensional spaces, similar to scale spaces, which will be called attribute-spaces. Though some properties of connected filters are lost, granulometries can be defined under certain conditions, and pattern spectra in most cases. The advantage of this approach is that regions can be split into constituent parts before filtering more naturally than by using partitioning connectivities. Furthermore, the approach allows dealing with overlap, which is impossible in connectivity. A theoretical comparison to hyperconnectivity suggests the new concept is different. The theoretical results are illustrated by several examples. These show how attribute-space connected filters merge the ability of filtering based on local structure using classical, structuring-element-based filters to the object-attribute-based filtering of connected filters, and how this differs from similar attempts using second-generation connectivity. 2006 Elsevier B.V. All rights reserved.
C1 Univ Groningen, Inst Math & Comp Sci, NL-9700 AV Groningen, Netherlands.
C3 University of Groningen
RP Wilkinson, MHF (corresponding author), Univ Groningen, Inst Math & Comp Sci, POB 800, NL-9700 AV Groningen, Netherlands.
EM m.h.f.wilkinson@rug.nl
RI Wilkinson, Michael H.F./C-2386-2009; Wilkinson, Michael/AAA-8471-2020;
   Wilkinson, Michael/Q-2847-2019
OI Wilkinson, Michael H.F./0000-0001-6258-1128; Wilkinson,
   Michael/0000-0001-6258-1128; Wilkinson, Michael/0000-0001-6258-1128
CR Braga-Neto U, 2003, J MATH IMAGING VIS, V19, P5, DOI 10.1023/A:1024476403183
   Braga-Neto U, 2003, COMPUT VIS IMAGE UND, V89, P70, DOI 10.1016/S1077-3142(03)00014-6
   Breen EJ, 1996, COMPUT VIS IMAGE UND, V64, P377, DOI 10.1006/cviu.1996.0066
   Cohen LD, 2001, J MATH IMAGING VIS, V14, P225, DOI 10.1023/A:1011281928379
   Gdalyahu Y, 2001, IEEE T PATTERN ANAL, V23, P1053, DOI 10.1109/34.954598
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703
   HUBEL DH, 1968, J PHYSIOL-LONDON, V195, P215, DOI 10.1113/jphysiol.1968.sp008455
   KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3
   Kruizinga P, 1999, IEEE T IMAGE PROCESS, V8, P1395, DOI 10.1109/83.791965
   Le Pouliquen F, 2002, INT C PATT RECOG, P688, DOI 10.1109/ICPR.2002.1044848
   MARAGOS P, 1989, IEEE T PATTERN ANAL, V11, P701, DOI 10.1109/34.192465
   MARAGOS P, 1990, IEEE T PATTERN ANAL, V12, P498, DOI 10.1109/34.55110
   Meijster A, 2002, IEEE T PATTERN ANAL, V24, P484, DOI 10.1109/34.993556
   Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532
   OUZOUNIS GK, 2005, P INT C IM PROC, P844
   OUZOUNIS GK, 2005, P INT S MATH MORPH I, P65
   Rieger B, 2003, LECT NOTES COMPUT SC, V2756, P17
   Ronse C, 1998, J MATH IMAGING VIS, V8, P41, DOI 10.1023/A:1008210216583
   SALEMBIER P, 1995, IEEE T IMAGE PROCESS, V4, P1153, DOI 10.1109/83.403422
   Salembier P, 1998, IEEE T IMAGE PROCESS, V7, P555, DOI 10.1109/83.663500
   Selinger A, 1999, COMPUT VIS IMAGE UND, V76, P83, DOI 10.1006/cviu.1999.0788
   Serra J, 1998, J MATH IMAGING VIS, V9, P231, DOI 10.1023/A:1008324520475
   Sofou A, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P1087, DOI 10.1109/ICIP.2001.958316
   Soille P, 2001, IEEE T PATTERN ANAL, V23, P1313, DOI 10.1109/34.969120
   Tzafestas CS, 2002, J MATH IMAGING VIS, V17, P109, DOI 10.1023/A:1020629402912
   Urbach ER, 2002, MATHEMATICAL MORPHOLOGY, PROCEEDINGS, P305
   Wertheimer M., 1958, READINGS PERCEPTION, P115
   [No title captured]
NR 29
TC 27
Z9 27
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 426
EP 435
DI 10.1016/j.imavis.2006.04.015
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600005
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Hassanien, A
AF Hassanien, AboulElla
TI Fuzzy rough sets hybrid scheme for breast cancer detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE rough sets; fuzzy image processim; mammograms; classification; feature
   extraction; rule and reduct generation; similarity measure; gray-level
   co-occurrence matrices
AB This paper introduces a hybrid scheme that combines the advantages of fuzzy sets and rough sets in conjunction with statistical feature extraction techniques. An application of breast cancer imaging has been chosen and hybridization scheme have been applied to see their ability and accuracy to classify the breast cancer images into two outcomes: cancer or non-cancer. The introduced scheme starts with fuzzy image processing as pre-processirig techniques to enhance the contrast of the whole image; to extracts the region of interest and then to enhance the edges surrounding the region of interest. A subsequently extract features from the segmented regions of the interested regions using the gray-level co-occurrence matrix is presented. Rough sets approach for generation of all reducts that contains minimal number of attributes and rules is introduced. Finally, these rules can then be passed to a classifier for discrimination for different regions of interest to test whether they are cancer or non-cancer. To measure the similarity, a new rough set distance function is presented. The experimental results show that the hybrid scheme applied in this study perform well reaching over 98% in overall accuracy with minimal number of generated rules. (This paper was not presented at any IFAC meeting). (c) 2006 Elsevier B.V. All rights reserved.
C1 Kuwait Univ, Coll Business Adm, Quantitat Methods & Informat Syst Dept, Safat 13060, Kuwait.
C3 Kuwait University
RP Hassanien, A (corresponding author), Kuwait Univ, Coll Business Adm, Quantitat Methods & Informat Syst Dept, POB 5969, Safat 13060, Kuwait.
EM abo@cba.edu.kw
RI Hassanien, Aboul ella/O-5672-2014
OI Hassanien, Aboul ella/0000-0002-9989-6681
CR [Anonymous], ROUGH SETS KNOWLEDGE
   [Anonymous], 2000, Fuzzy image enhancement: an overview, fuzzy techniques in image processing
   [Anonymous], 1996, ADV KNOWLEDGE DISCOV
   [Anonymous], 2000, ser. Studies in Fuzziness and Soft Computing
   BAZAN J, 1994, LECT NOTES ARTIF INT, V869, P346
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   BOVIS KJ, 2002, P 6 INT WORKSH DIG M
   BOVIS KJ, 2000, P 5 INT WORKSH DIG M, V11, P547
   Chi Zheru., 1996, Advances in fuzzy systems. Applications and theory, V10
   GRZYMALABUSSE J, 1999, COMMUN ACM, V38, P1
   GUNTHER G, 2000, PHYSICA, P545
   HARALICK RM, 1979, P IEEE, V67, P786, DOI 10.1109/PROC.1979.11328
   HASANIEN AE, 2003, INT J STUDIES INFORM, V12, P33
   Hassanien A. E., 2003, Studies in Informatics and Control, V12, P21
   Hassanien AE, 2004, LECT NOTES ARTIF INT, V3070, P1002
   Hassanien AE, 2004, J AM SOC INF SCI TEC, V55, P954, DOI 10.1002/asi.20042
   KARSSEMEIJ N, 1993, P INF PROC MED IM IP
   Kent R. E., 1994, P INT WORKSH ROUGH S, P248
   KRYSZKIEWICZ M, 1994, P INT WORKSH ROUGH S, P261
   KRYSZKIEWICZ M, 1996, 1 EUR C INT TECHN SO, V1, P204
   Nachtegael M, 2001, 10TH IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1-3, P3, DOI 10.1109/FUZZ.2001.1007230
   NICO K, 1998, DIGITAL MAMMOGRAPHY
   NING S, 1994, P 3 PAC RIM INT C AR, V431, P437
   PAL SK, 2002, ROUGH NEURO COMPUTIN
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Peters JF, 2001, COMPUT INTELL-US, V17, P493, DOI 10.1111/0824-7935.00160
   Setiono R, 2000, ARTIF INTELL MED, V18, P205, DOI 10.1016/S0933-3657(99)00041-X
   ZIMMERMAN JB, 1988, IEEE T MED IMAGING, V7, P304, DOI 10.1109/42.14513
NR 28
TC 96
Z9 104
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 172
EP 183
DI 10.1016/j.imavis.2006.01.026
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700006
DA 2024-07-18
ER

PT J
AU Torreao, JRA
   Fernandes, JL
   Leitao, HCG
AF Torreao, Jose R. A.
   Fernandes, Joao L.
   Leitao, Helena C. G.
TI A novel approach to photometric motion
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE photometric motion; physics-based vision; shape from shading
ID SHAPE; CONSTRAINTS
AB Photometric motion, as introduced by Pentland, employs both reflectance map and optical flow information for the estimation of shape from image sequences of dynamic scenes. It is thus a coupled geometric/photometric process, similarly as the disparity-based photometric stereo, which combines matching and image irradiance equations for surface reconstruction from photometric stereo input. Exploiting the parallel between those two processes, we have arrived at a novel formulation for the photometric-motion shape estimation problem, whose distinctive feature is that of being based on the irradiance change, due to the motion, at a given point in the image plane, and not, as in Pentland's proposal, at a fixed location on the moving surface. We are thus able to obtain an easily implementable procedure which yields good-quality shape estimates for rotating surfaces, and which can also be extended to single-input shape reconstruction. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Fed Fluminense, Inst Comp, BR-24210240 Niteroi, RJ, Brazil.
   Pontificia Univ Catolica Parana, Programa Pos Grad Informat Aplicada, BR-80215901 Curitiba, Parana, Brazil.
C3 Universidade Federal Fluminense; Pontificia Universidade Catolica do
   Parana
RP Torreao, JRA (corresponding author), Univ Fed Fluminense, Inst Comp, BR-24210240 Niteroi, RJ, Brazil.
EM jrat@ic.uff.br
CR BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   FETTER AL, 1980, THEORETICAL MACHANIC
   Gupta N, 1997, INT J COMPUT VISION, V22, P81, DOI 10.1023/A:1007931911114
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   KIM B, 1991, COMPUTER VISION GRAP, V53, P416
   LEE KM, 1992, P IEEE C COMP VIS PA, P179
   PENTLAND A, 1991, IEEE T PATTERN ANAL, V13, P879, DOI 10.1109/34.93807
   PENTLAND AP, 1990, INT J COMPUT VISION, V4, P153, DOI 10.1007/BF00127815
   Samaras D, 2003, IEEE T PATTERN ANAL, V25, P247, DOI 10.1109/TPAMI.2003.1177155
   Stein GP, 2000, IEEE T PATTERN ANAL, V22, P992, DOI 10.1109/34.877522
   Torreao JRA, 2003, IMAGE VISION COMPUT, V21, P1045, DOI 10.1016/j.imavis.2003.08.007
   Torreao JRA, 1998, J OPT SOC AM A, V15, P2966, DOI 10.1364/JOSAA.15.002966
   Torreao JRA, 2001, PATTERN RECOGN, V34, P2367, DOI 10.1016/S0031-3203(00)00168-0
   TORREAO JRA, 1995, MACH VISION APPL, V8, P163, DOI 10.1007/BF01215811
   TOTTEAO JRA, 2002, PATTERNS RECOGNITION, V23, P1755
   Worthington PL, 1999, IEEE T PATTERN ANAL, V21, P1250, DOI 10.1109/34.817406
   Zhang L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P618, DOI 10.1109/ICCV.2003.1238405
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
NR 18
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 126
EP 135
DI 10.1016/j.imavis.2005.12.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600014
DA 2024-07-18
ER

PT J
AU Gandhi, T
   Trivedi, MM
AF Gandhi, Tarak
   Trivedi, Mohan M.
TI Reconfigurable omnidirectional camera array calibration with a linear
   moving object
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE calibration; panoramic vision; stereo vision; surveillance
ID SELF-CALIBRATION; VIDEO; STREAMS; MOTION; SHAPE
AB Reconfigurable omnidirectional camera arrays are useful for applications where multiple cameras working together are to be deployed at a short notice. This paper proposes a multi-camera calibration approach for such arrays using a 1D object such as a person, moving parallel to itself. The moving object is separated from the background and correspondences between multiple cameras are obtained using location of the object in all the cameras in multiple frames. The approximate orientation of the cameras is individually determined using vanishing points. The non-linear 3D problem of multi-camera calibration can then be approximated by a 2D problem in plan view. An initial solution for the relative positions and orientations of multiple cameras is obtained using the factorization approach. A non-linear optimization stage is then used to correct the approximations, and to minimize the geometric error between the observed and the projected omni pixel coordinates. Numerous experiments are performed with simulated data sets as well as real image sequences to evaluate the performance of this approach. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Calif San Diego, Comp Vis & Robot Res Lab, La Jolla, CA 92093 USA.
C3 University of California System; University of California San Diego
RP Gandhi, T (corresponding author), Univ Calif San Diego, Comp Vis & Robot Res Lab, 9500 Gilman Dr 0434, La Jolla, CA 92093 USA.
EM tgandhi@ucsd.edu; mtrivedi@ucsd.edu
CR ALIAGA D, 2001, IEEE INT C COMP VIS, V1, P127
   Antone M, 2002, INT J COMPUT VISION, V49, P143, DOI 10.1023/A:1020141505696
   Baker S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P35, DOI 10.1109/ICCV.1998.710698
   Barreto J. P., 2004, P 5 WORKSH OMN VIS C
   Benosman R., 2001, PANORAMIC VISION SEN
   Chen C, 2000, PROC CVPR IEEE, P520, DOI 10.1109/CVPR.2000.854901
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   GANDHI T, 2004, 2 ACM INT WORKSH VID, P12
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Huang KS, 2003, MACH VISION APPL, V14, P103, DOI 10.1007/s00138-003-0106-5
   Jacobs D, 1997, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.1997.609321
   Lee L, 2000, IEEE T PATTERN ANAL, V22, P758, DOI 10.1109/34.868678
   Lv FJ, 2002, INT C PATT RECOG, P562, DOI 10.1109/ICPR.2002.1044793
   Martin D.J., 2003, PROC, P147
   Martinec D, 2002, LECT NOTES COMPUT SC, V2351, P355
   Pedersini F, 1999, SIGNAL PROCESS, V77, P309, DOI 10.1016/S0165-1684(99)00042-0
   Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098
   Sogo T, 2001, MG COMP SCI, P359
   Sturm P., 1996, EUROPEAN C COMPUTER, P709, DOI DOI 10.1007/3-540-61123-1
   Svoboda T, 2005, PRESENCE-VIRTUAL AUG, V14, P407, DOI 10.1162/105474605774785325
   SVOBODA T, MULTICAMERA SELF CAL
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Zhang ZY, 2002, LECT NOTES COMPUT SC, V2353, P161
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 26
TC 4
Z9 4
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 935
EP 948
DI 10.1016/j.imavis.2006.02.020
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200003
DA 2024-07-18
ER

PT J
AU Zhou, SS
   Wang, WW
   Zhou, LH
AF Zhou Shui-sheng
   Wang Wei-wei
   Zhou Li-hua
TI A new technique for generalized learning vector quantization algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE LVQ algorithm; competitive network; image compression; codebook;
   stimulating coefficient
ID FUZZY ALGORITHMS
AB The disadvantage of the generalized learning vector quantization (GLVQ) and fuzzy generalization learning vector quantization (FGLVQ) algorithms is discussed in this paper. And a revised generalized learning vector quantization (RGLVQ) algorithm is proposed to overcome the disadvantage of GLVQ and FGLVQ. Furthermore, by introducing a stimulating coefficient in completing step, a new competing technique to improve the performance of the LVQ neural network is proposed also. The proposed algorithms are tested and evaluated using the IRIS data set. And the efficiency of the proposed algorithms is also illustrated by their use in codebook design for image compression based on vector quantization, and the training time for RGLVQ algorithm is reduced by 10% as compared with FGLVQ while the performance is similar. The new competing technique is also used to generate codebook and PSNR is improved in experiments. (c) 2005 Elsevier B.V. All rights reserved.
C1 Xidian Univ, Sch Sci, Xian 710071, Peoples R China.
   Xidian Univ, Multimedia Technol Inst, Xian 710071, Peoples R China.
C3 Xidian University; Xidian University
RP Zhou, SS (corresponding author), Xidian Univ, Sch Sci, 2 TaiBai Rd, Xian 710071, Peoples R China.
EM sszhou@mail.xidian.edu.cn
RI wang, weiwei/AAI-2245-2020; 周, 丽敏/JEO-3613-2023; Zhou, Li/GSE-4531-2022
CR Gersho A., 2003, Vector Quantization and Signal Compression
   GONZALEZ AI, 1995, IEEE T NEURAL NETWOR, V6, P1012, DOI 10.1109/72.392266
   Hsieh CH, 2000, IEEE T IMAGE PROCESS, V9, P321, DOI 10.1109/83.826771
   Karayiannis NB, 1998, IEEE T IMAGE PROCESS, V7, P1223, DOI 10.1109/83.704313
   Karayiannis NB, 1997, IEEE T NEURAL NETWOR, V8, P505, DOI 10.1109/72.572091
   Karayiannis NB, 1996, IEEE T NEURAL NETWOR, V7, P1196, DOI 10.1109/72.536314
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   KOHONEN T, 1990, P INT JOINT C NEUR N, V1, P545
   NSSER MN, 1988, IEEE T COMMUN, V36, P957
   PAL NR, 1993, IEEE T NEURAL NETWOR, V4, P549, DOI 10.1109/72.238310
NR 10
TC 6
Z9 6
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 649
EP 655
DI 10.1016/j.imavis.2005.03.005
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400001
DA 2024-07-18
ER

PT J
AU Yao, ZR
   Li, HB
AF Yao, Zhengrong
   Li, Haibo
TI Tracking a detected face with dynamic programming
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE model-based coding; face tracking; face detection; Dynamic Programming
AB In this paper, we consider the problem of tracking a Moving human face in front of a video camera in real-time for a model-based coding application. The 3D head tracking in a MBC system could be implemented sequentially as 2D location tracking, coarse 3D orientation estimation and accurate 3D motion estimation. This work focuses on the 2D location tracking of one face object through continuously using a face detector. The face detection scheme is based on a boosted cascade of simple Haar-like feature classifiers. Although such a detector demonstrated rapid processing speed, high detection rate can only be achieved for rather strictly near front faces. This introduces the 'loss of tracking' problem when used in 2D tracking. This paper suggests an easy method of solving the pose problem by using the technique of Dynamic Programming. The Haar-like facial features used in the 2D face detector are spatially arranged into a 1D deformable face graph and the Dynamic Programming matching is used to handle the 'loss of track' problem. Dynamic Programming matches the deformed version of the face graph extracted from a rotated face with the template taken online before 'loss of tracking' happens. Since the deformable face graph covers a big pose variation, the developed technique is robust in tracking rotated faces. Embedding Haar-like facial features into a deformable face graph is the key feature Of Our tracking scheme. A real time tracking system based on this technique has been set tip and tested. Encouraging results have been got and are reported. (c) 2005 Elsevier B.V. All rights reserved.
C1 Umea Univ, Digital Media Lab, S-90187 Umea, Sweden.
C3 Umea University
RP Yao, ZR (corresponding author), Umea Univ, Digital Media Lab, S-90187 Umea, Sweden.
EM zhengrong.yao@scalado.com
CR AIZAWA K, 1989, SIGNAL PROCESSING IM, V1
   AMIT Y, 1996, IEEE PAMI, V18
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], MSRTR9865
   Bradski Gary R, 1998, P IEEE 4 WORKSH APPL
   FORCHHEIMER R, 1983, P INT PICT COD S PCS, P116
   Horn B.K.P, 1986, Robot Vision
   LI H, 1993, THESIS LINKOPING U
   LI HB, 1993, IEEE T PATTERN ANAL, V15, P545, DOI 10.1109/34.216724
   Lienhart R., 2002, P INT C IM PROC
   MCKENNA SJ, 1997, P 1 INT C AUD VID BI
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   NOHRE R, 1996, LITHISYR1823 LINK U
   OMURA JK, 1969, IEEE T INFORM THEORY, V15, P177, DOI 10.1109/TIT.1969.1054239
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Tomasi C, 1991, DETECTION TRACKING P
   Verma RC, 2003, IEEE T PATTERN ANAL, V25, P1215, DOI 10.1109/TPAMI.2003.1233896
   VIOLA P, 2001, CVPR2001
   WELSH WJ, 1987, P INT PICT COD S
   ZHANG ZQ, 2002, P 5 INT C AUT FAC GE
NR 20
TC 8
Z9 11
U1 2
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2006
VL 24
IS 6
BP 573
EP 580
DI 10.1016/j.imavis.2005.09.007
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 061NB
UT WOS:000238878200004
DA 2024-07-18
ER

PT J
AU Choi, SY
   Lee, JM
AF Choi, SY
   Lee, JM
TI Applications of moving windows technique to autonomous vehicle
   navigation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE moving window; lane detection; obstacle detection; mobile robot;
   corridor driving
AB A 'Moving Window' scheme for detecting lanes, obstacles and corridor environments from the images captured by a CCD camera ill all automobile or mobile robot is proposed. processing the input dynamic images in real time requires high performance hardware as well as efficient software. In order to relieve these requirements for detecting the useful information from the images in real time, a 'Moving Window' scheme is proposed. For each image frame, the 'Moving Window' is newly defined and it is moved in a certain direction that is predicted by the Kalman filtering technique. By detecting (he useful information, it becomes possible to search the obstacles within the driving lane of an automobile or mobile robot. The obstacle call be verified through the correlation between the stochastic characteristics of the suspected obstacle and the actual obstacle in a database. The feasibility of the proposed algorithm is demonstrated through the Simulated experiments of the freeway and the corridor driving. (c) 2005 Elsevier B.V. All rights reserved.
C1 Pusan Natl Univ, Intelligent Robot Lab, Pusan, South Korea.
C3 Pusan National University
RP Pusan Natl Univ, Intelligent Robot Lab, Pusan, South Korea.
EM jmlee@pusan.ac.kr
CR Behringer R, 1998, IEEE T ROBOTIC AUTOM, V14, P810, DOI 10.1109/70.720356
   Broggi A, 2003, IEEE T IND ELECTRON, V50, P18, DOI 10.1109/TIE.2002.807688
   Bücher T, 2003, IEEE T IND ELECTRON, V50, P62, DOI 10.1109/TIE.2002.807650
   CHARLES E, 1990, VISION NAVIGATION, P9
   Choi SY, 2003, J ROBOTIC SYST, V20, P65, DOI 10.1002/rob.10072
   Chu JW, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P750
   HAROLD W, 1985, KALMAN FILTERING THE, P16
   HIRANO M, 1993, IEEE IEE VEH NAV INF
   Jain R., 1995, Machine vision, V5, P140, DOI DOI 10.1016/B978-012206093-9/50008-3
   KAKINAMI T, 1995, AUTONOMOUS VEHICLE C
   Kim SB, 2004, VTC2004-FALL: 2004 IEEE 60TH VEHICULAR TECHNOLOGY CONFERENCE, VOLS 1-7, P4075
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   Kwon W, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P2596, DOI 10.1109/ROBOT.1999.773988
   LEONGARCIA A, 1994, PROBABILITY RANDOM P, P280
   Miura J, 2002, IEEE T INTELL TRANSP, V3, P136, DOI 10.1109/TITS.2002.801421
   Ng KS, 1999, IEEE T CONSUM ELECTR, V45, P236, DOI 10.1109/30.754441
   NIKOLAOS P, 1996, IEEE T VEH TECHNOL, V45, P744
   Oh SY, 2000, IEEE T VEH TECHNOL, V49, P997, DOI 10.1109/25.845116
   PARK JW, 1999, P 1999 INT C MECH TE, P95
   ROBERT M, 1993, COMPUTER ROBOT VISIO, P61
   SAUL A, 1992, NUMERICAL RECIPES C, P656
   Sotelo MA, 2004, IEEE T INTELL TRANSP, V5, P69, DOI 10.1109/TITS.2004.828175
   Veeraraghavan H, 2003, IEEE T INTELL TRANSP, V4, P78, DOI 10.1109/TITS.2003.821212
   Yamamoto T, 2001, IEEE T GEOSCI REMOTE, V39, P976, DOI 10.1109/36.921415
NR 24
TC 5
Z9 6
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 120
EP 130
DI 10.1016/j.imavis.2005.09.016
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900002
DA 2024-07-18
ER

PT J
AU Zhou, Q
   Ma, LM
   Chelberg, D
AF Zhou, Q
   Ma, LM
   Chelberg, D
TI Adaptive object detection and recognition based on a feedback strategy
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object detection; object recognition; Markov random field
ID COLOR; DESIGN
AB Detecting and recognizing objects in environments with unpredictable illumination changes remains a challenging task. Existing algorithms employ a passive methodology to deal with these environments, where learning is performed from many samples taken under various lighting conditions or with some pre-designed color constancy models. In this paper, the challenges of unpredictable illumination changes are addressed through a feedback strategy. With the use of feedback, self-adaptation in object detection and recognition is possible in response to variable illumination. Self-adaptation is achieved through feedback from the recognition phase to the detection phase. A multilevel Markov random field (MRF) is adopted to model both the detection and recognition processes. The original MRF approach is extended to a model that encodes simultaneous object detection and recognition. Experimental results show the feasibility of the proposed framework. (C) 2005 Elsevier B.V. All rights reserved.
C1 Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
C3 University System of Ohio; Ohio University
RP Chrontel Inc, 2210 OToole Ave,STE 100, San Jose, CA 95131 USA.
EM qzhou@chrontel.com
CR [Anonymous], IEEE T PATTERN ANAL
   Asada M, 1999, ROBOT AUTON SYST, V29, P3, DOI 10.1016/S0921-8890(99)00033-0
   Celenk M, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993626
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   FUNT B, 1998, 5 EUR C COMP VIS, P445
   GEORGHIADES A, 1998, FAC IEEE C COMP VIS
   Gevers T, 1999, PATTERN RECOGN, V32, P453, DOI 10.1016/S0031-3203(98)00036-3
   HEALEY G, 1994, J OPT SOC AM A, V11, P3003, DOI 10.1364/JOSAA.11.003003
   Jacob M, 2004, IEEE T PATTERN ANAL, V26, P1007, DOI 10.1109/TPAMI.2004.44
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   KEITH J, 2001, VIDEO DEMYSTIFIED
   LEUNG TK, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P637, DOI 10.1109/ICCV.1995.466878
   Lim J.S., 1990, Two-dimensional Signal and Image Processing
   Moghaddam B, 1997, IEEE T PATTERN ANAL, V19, P696, DOI 10.1109/34.598227
   MUMFORD D, 1999, 2 3 DIMENSIONAL PATT
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   PERONA P, 1995, IEEE T PATTERN ANAL, V17, P488, DOI 10.1109/34.391394
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Shashua A, 1997, INT J COMPUT VISION, V21, P99, DOI 10.1023/A:1007975506780
   Sigal L, 2004, IEEE T PATTERN ANAL, V26, P862, DOI 10.1109/TPAMI.2004.35
   STAN L, 2001, MARKOV RANDOM FIELD
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   Theodoridis S., 1999, Pattern recognition, P3
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   VELOSO M, 1998, AI MAG, P1
NR 27
TC 4
Z9 4
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 80
EP 93
DI 10.1016/j.imavis.2005.09.014
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200008
DA 2024-07-18
ER

PT J
AU Jung, CR
   Kelber, CR
AF Jung, CR
   Kelber, CR
TI Lane following and lane departure using a linear-parabolic model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE machine vision; Hough transform; lane detection; lane following; lane
   departure; driver assistance system
ID VISION SYSTEM
AB This paper proposes a technique for unwanted lane departure detection. Initially, lane boundaries are detected using a combination of the edge distribution function and a modified Hough transform. In the tracking stage, a linear-parabolic lane model is used: in the near vision field, a linear model is used to obtain robust information about lane orientation; in the far field, a quadratic function is used, so that curved parts of the road can be efficiently tracked. For lane departure detection, orientations of both lane boundaries are used to compute a lane departure measure at each frame, and an alarm is triggered when such measure exceeds a threshold. Experimental results indicate that the proposed system can fit lane boundaries in the presence of several image artifacts, such as sparse shadows, lighting changes and bad conditions of road painting, being able to detect in advance involuntary lane crossings. (C) 2005 Elsevier Ltd All rights reserved.
C1 Univ Vale Rio dos Sinos, UNISINOS, PIPCA, Grad Sch Appl Comp, BR-93022000 Sao Leopoldo, RS, Brazil.
C3 Universidade do Vale do Rio dos Sinos (Unisinos)
RP Univ Vale Rio dos Sinos, UNISINOS, PIPCA, Grad Sch Appl Comp, Av UNISINOS 950, BR-93022000 Sao Leopoldo, RS, Brazil.
EM crjung@unisinos.br; kelber@unisinos.br
RI Jung, Claudio R/G-2439-2012
CR Apostoloff N, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P558, DOI 10.1109/IVS.2003.1212973
   Bertozzi M, 1998, IEEE T IMAGE PROCESS, V7, P62, DOI 10.1109/83.650851
   *DENATRAN, AN EST AC TRANS ANN
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Enkelmann W., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P356, DOI 10.1109/IVS.1995.528307
   HAGEN J, UN CHRONICLE ONLINE
   Jung CR, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P891
   LeBlanc DJ, 1996, IEEE CONTR SYST MAG, V16, P61, DOI 10.1109/37.546271
   Lee JW, 2003, IEEE IV2003: INTELLIGENT VEHICLES SYMPOSIUM, PROCEEDINGS, P100, DOI 10.1109/IVS.2003.1212891
   Lee JW, 2002, COMPUT VIS IMAGE UND, V86, P52, DOI 10.1006/cviu.2002.0958
   McCall JC, 2004, 2004 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P533
   OGORMAN F, 1976, IEEE T COMPUT, V25, P449, DOI 10.1109/TC.1976.1674627
   Park JW, 2003, PATTERN RECOGN LETT, V24, P2301, DOI 10.1016/S0167-8655(03)00056-4
   Pomerleau D., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P506, DOI 10.1109/IVS.1995.528333
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Rao A., 1990, TAXONOMY TEXTURE DES
   Risack R, 2000, PROCEEDINGS OF THE IEEE INTELLIGENT VEHICLES SYMPOSIUM 2000, P356, DOI 10.1109/IVS.2000.898369
   Wang Y, 2000, PATTERN RECOGN LETT, V21, P677, DOI 10.1016/S0167-8655(00)00021-0
   Wang Y, 2004, IMAGE VISION COMPUT, V22, P269, DOI 10.1016/j.imavis.2003.10.003
   Wang Y., 1998, IEEE INT C INTELLIGE, P51
NR 20
TC 92
Z9 109
U1 3
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1192
EP 1202
DI 10.1016/j.imavis.2005.07.018
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500008
DA 2024-07-18
ER

PT J
AU Hilton, A
AF Hilton, A
TI Scene modelling from sparse 3D data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE scene modelling; sparse data; recursive reconstruction;
   structure-from-motion
AB Sparse 3D measurements of real scenes are readily estimated from N-view image sequences using structure-from-motion techniques. In this paper, we present a geometric theory for reconstruction of surface models from sparse 3D data captured from N camera views. Based on this theory, we introduce a general N-view algorithm for reconstruction of 3D models of arbitrary scenes from sparse data. This algorithm reconstructs a surface model which converges to an approximation of the real scene surfaces and is consistent with the feature visibility in all N-views. To achieve efficient reconstruction independent of the number of views a recursive reconstruction algorithm is developed which integrates the feature visibility independently for each view. This approach is shown to converge to an approximation of the real scene structure and have a computational cost which is linear in the number of views. It is assumed that structure-from-motion estimates of 3D feature locations are consistent with the multiple view visual geometry and do not contain outliers. Uncertainty in 3D feature estimates is incorporated in the feature visibility to achieve reliable reconstruction in the presence of noise inherent in estimates of 3D scene structure from real image sequences. Results are presented for reconstruction of both real and synthetic scenes together with an evaluation of the reconstruction performance in the presence of noise. The algorithm presented in this paper provides a reliable and computationally efficient approach to model reconstruction from sparse 3D scene data. (c) 2005 Elsevier B.V. All rights reserved.
EM a.hilton@surrey.ac.uk
RI Hilton, Adrian/N-3736-2014
OI Hilton, Adrian/0000-0003-4223-238X
CR [Anonymous], 4 EUR C COMP VIS ECC
   [Anonymous], 1994, Computational Geometry in C
   Atkinson KB., 1996, CLOSE RANGE PHOTOGRA
   BEARDSLEY P, 1996, EUR C COMP VIS, P683
   BESL P, 1994, LECT NOTES COMPUTER, V994, P191
   BRUZZONE E, 1992, ECCV, P368
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   DEHEVEC P, 1996, MODELLING RENDERING
   ELHAKIM S, 1998, ISPRS INT S REAL TIM, P331
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   FAUGERAS OD, 1990, ARTIF INTELL, V44, P41, DOI 10.1016/0004-3702(90)90098-K
   Fitzgibbon A.W., 1998, P EUROPEAN SIGNAL PR, P1261
   Gortler S. J., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P43, DOI 10.1145/237170.237200
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   KANG SB, 1999, SPIE, V3641, P2
   KUTULAKOS KN, 1999, IEEE INT C COMP VIS, P307
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   MCLAUCHLAN PF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P314, DOI 10.1109/ICCV.1995.466923
   MCLAUCHLAN PF, 1999, 499 VSSP U SURR DEP
   Niem W, 1997, INTERNATIONAL CONFERENCE ON RECENT ADVANCES IN 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P173, DOI 10.1109/IM.1997.603863
   Roth Gerhard., 1995, Proceedings of the DND/CSA Robotics and Knowledge Based Systems Workshop, P349
   SEQUEIRA V, 1999, AUTOMATED RECONSTRUC
   SOUCY M, 1995, IEEE T PATTERN ANAL, V17, P344, DOI 10.1109/34.385982
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Szeliski Richard., 1997, P SIGGRAPH 97 COMPUT, P251, DOI DOI 10.1145/258734.258861
   Taylor CJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P184
   Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P485, DOI 10.1109/ICCV.1998.710762
   TRIGGS B, 2001, LECT NOTES COMPUTER
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   [No title captured]
NR 30
TC 17
Z9 20
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2005
VL 23
IS 10
BP 900
EP 920
DI 10.1016/j.imavis.2005.05.018
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 962PQ
UT WOS:000231745100005
DA 2024-07-18
ER

PT J
AU Chen, MJ
   Huang, CH
   Lee, WL
AF Chen, MJ
   Huang, CH
   Lee, WL
TI A fast edge-oriented algorithm for image interpolation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE interpolation; zooming; enlargement; video image; real-time; edge
AB This paper introduces a fast algorithm for image interpolation. By using this method, real-time enlargement of video images is accessible. The basic idea of the algorithm is to partition digital images into homogeneous and edge areas based on the analysis of the local structure on the images. In addition, in order to have better performance on interpolating images, specified algorithms are assigned to interpolate each classified areas, respectively. Experimental results show that the subjective quality of the interpolated images is substantially improved by using the proposed algorithm compared with that of using conventional interpolation algorithms. The computational complexity of the proposed algorithm is much lower than those of others mentioned in this paper. We also successfully implemented real-time enlargement of QCIF video sequences to OF sequences with better image quality in low bit-rate environment. (c) 2005 Elsevier B.V. All rights reserved.
C1 Natl Dong Hwa Univ, Dept Elect Engn, Hualien, Taiwan.
   Tzu Chi Coll Technol, Dept Radiol Technol, Hualien, Taiwan.
C3 National Dong Hwa University; Tzu Chi University of Science & Technology
RP Natl Dong Hwa Univ, Dept Elect Engn, 1 Sec 2,Da Hsueh Rd, Hualien, Taiwan.
EM cmj@mail.ndhu.edu.tw
RI LEE, Wee Leong/E-8559-2012
OI Chen, Mei-Juan/0000-0003-3382-8296
CR BAYRAKER SD, 1995, IEEE INT C ACOUSTICS, V4, P2383
   Darwish AM, 1997, IEE P-VIS IMAGE SIGN, V144, P207, DOI 10.1049/ip-vis:19971342
   Jiang H, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P369, DOI 10.1109/ICIP.2002.1038982
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Khriji L., 1998, Proceedings of the Tenth International Conference on Microelectronics (Cat. No.98EX186), P236, DOI 10.1109/ICM.1998.825608
   LEE C, 1999, INT C IMAGE PROCESSI, V3, P787
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Pratt W.K, 1978, DIGITAL IMAGE PROCES
   Shi HJ, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL I, PROCEEDINGS, P785
   Zeng B, 2001, SIGNAL PROCESS, V81, P431, DOI 10.1016/S0165-1684(00)00219-X
NR 10
TC 87
Z9 113
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2005
VL 23
IS 9
BP 791
EP 798
DI 10.1016/j.imavis.2005.05.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VF
UT WOS:000231400700003
DA 2024-07-18
ER

PT J
AU Kumar, R
   Makkapati, V
AF Kumar, R
   Makkapati, V
TI Encoding of multispectral and hyperspectral image data using wavelet
   transform and gain shape vector quantization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multispectral image; hyperspectral image; wavelet transform; gain-shape
   vector quantization; BFOS algorithm; rate-distortion optimization;
   JPEG-2000
ID COMPRESSION
AB An effective and lossy compression technique for multispectral and hyperspectral image data minimizes both the spatial and spectral correlations while preserving the spectral characteristics of the data. In this paper, we combine wavelet transform and a variant of vector quantization for decorrelating both spatial and spectral information, and thus aim to achieve superior quality. We use 2-D wavelet transform followed by Kronecker-Product Gain-Shape Vector Quantization. This is coupled with the generalized BFOS for obtaining an optimal bit-rate. The pixels within the subbands of multi- and hyper-spectral images exhibit greater spectral redundancy which is thus exploited by designing multiresolution codebooks. Results are presented for multispectral and hyperspectral data taken from different sensors in different bands.
   The results obtained with our scheme are compared with other techniques designed for multi-/hyper-spectral image data and the Wavelet-based JPEG-2000. The computational requirement of the proposed technique is lower in comparison with other vector-quantization techniques. (c) 2005 Elsevier B.V. All rights reserved.
C1 Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
   Honeywell Technol Solut Lab 151 1, Bangalore 560076, Karnataka, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kharagpur; Honeywell
RP Kumar, R (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Kharagpur 721302, W Bengal, India.
EM rkumar@cse.iitkgp.ernet.in; vishnu.makkapati@honeywell.com
RI Kumar, Rajeev/I-3506-2019; Makkapati, Vishnu Vardhan/C-3040-2008
OI Kumar, Rajeev/0000-0001-5545-6919; Makkapati, Vishnu
   Vardhan/0000-0003-3300-2806; Kumar, Rajeev/0000-0003-0233-6563
CR ABOUSLEMAN GP, 1995, IEEE T GEOSCI REMOTE, V33, P26, DOI 10.1109/36.368225
   AMATO F, 1997, P INT C IMAGE PROCES, V1, P612
   Antonini M, 1992, IEEE T IMAGE PROCESS, V1, P205, DOI 10.1109/83.136597
   Baker R. L., 1988, Proceedings of the SPIE - The International Society for Optical Engineering, V974, P255, DOI 10.1117/12.948466
   Breiman L, 1998, BIOMETRICS, DOI [10.1201/9781315139470, DOI 10.2307/2530946]
   Canta GR, 1998, IEEE T IMAGE PROCESS, V7, P668, DOI 10.1109/83.668024
   CHOU PA, 1989, IEEE T INFORM THEORY, V35, P299, DOI 10.1109/18.32124
   Duda R. O., 2000, PATTERN CLASSIFICATI
   EPSTEIN BR, 1992, P DAT COMPR C SNOWB, P200
   Furht B., 1996, VIDEO IMAGE PROCESSI
   Garey M.R., 1979, COMPUTERS INTRACTABI
   Gelli G, 1999, IEEE T IMAGE PROCESS, V8, P476, DOI 10.1109/83.753736
   Gersho A., 2003, Vector Quantization and Signal Compression
   GUPTA S, 1992, IEEE T GEOSCI REMOTE, V30, P491, DOI 10.1109/36.142927
   KAARNA A, 2002, J IMAGING SOC JAPAN, V41, P379
   KUMAR R, 2000, P PPSN SAB WORKSH MU
   Lee J, 1999, IEEE T IMAGE PROCESS, V8, P453, DOI 10.1109/83.753734
   MAKKAPATI V, 2002, P 3 IND C COMP VIS G, P191
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Marcellin M. W., 2000, Proceedings DCC 2000. Data Compression Conference, P523, DOI 10.1109/DCC.2000.838192
   RISKIN EA, 1991, IEEE T INFORM THEORY, V37, P400, DOI 10.1109/18.75264
   SABIN MJ, 1984, IEEE T ACOUST SPEECH, V32, P474, DOI 10.1109/TASSP.1984.1164346
   SAGHRI JA, 1991, OPT ENG, V30, P934, DOI 10.1117/12.55888
   Sayood K, 2017, Introduction to data compression
   TSENG YH, 2002, ASIAN J GEOINFORMATI
   TSENG YH, 2002, COMMUNICATION    JUN
   VAISEY J, 1998, P IEEE INT C IM PROC, P712
   WESTERINK PH, 1988, P ICASSP 88, P757
NR 28
TC 11
Z9 13
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2005
VL 23
IS 8
BP 721
EP 729
DI 10.1016/j.imavis.2005.01.006
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VD
UT WOS:000231400500004
DA 2024-07-18
ER

PT J
AU Govindu, VM
   Werman, M
AF Govindu, VM
   Werman, M
TI On using priors in affine matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Indian Conference on Vision, Graphics and Image Processing (ICVGIP)
CY DEC 16-18, 2002
CL Ahmedabad, INDIA
DE affine transformations; affine invariants; probabilistic models;
   recognition
AB In this paper, we consider the generative model for affine transformations on point sets and show how a priori information on the noise and the transformation can be incorporated into the model resulting in more accurate algorithms. While invariants have been widely used, the existing literature fails to fully account for the uncertainties introduced by both noise and the transformation. We show how using such priors leads to algorithms for Bayesian estimation and a probabilistic interpretation of invariants which addresses the limitations of current methods. We present synthetic and real results for object recognition, image registration and determining object planarity to demonstrate the power of using priors for image comparison. (C) 2004 Elsevier B.V. All rights reserved.
C1 Hebrew Univ Jerusalem, Dept Comp Sci, IL-91904 Jerusalem, Israel.
C3 Hebrew University of Jerusalem
RP Govindu, VM (corresponding author), HIG 25,Simhapuri Layout, Visakhapatnam 530047, Andhra Pradesh, India.
EM venu@narmada.org; werman@cs.huji.ac.il
CR Brown L.G., 1992, ACM COMPUT SURV, V24, P325, DOI DOI 10.1145/146370.146374
   FITZGIBBON A, 2002, AFLINE INVARIANT CLU, V3
   Keren D, 2003, LECT NOTES COMPUT SC, V2616, P72
   Leung TK, 1998, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1998.698677
   Mardia K., 1998, STAT SHAPE ANAL
   Mundy J., 1992, GEOMETRIC INVARIANCE
   RIGOUTSOS I, 1995, COMPUT VIS IMAGE UND, V62, P11, DOI 10.1006/cviu.1995.1038
   Sinclair D, 1996, INT J COMPUT VISION, V18, P77, DOI 10.1007/BF00126141
   WOLFSON H, 1988, ICCV88, P238
NR 9
TC 4
Z9 6
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2004
VL 22
IS 14
BP 1157
EP 1164
DI 10.1016/j.imavis.2004.03.019
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 882LG
UT WOS:000225939800002
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Sharma, P
   Parashar, A
   Banerjee, S
   Kalra, P
AF Sharma, P
   Parashar, A
   Banerjee, S
   Kalra, P
TI An uncalibrated fightfield acquisition system
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Indian Conference on Vision, Graphics and Image Processing (ICVGIP)
CY DEC 16-18, 2002
CL Ahmedabad, INDIA
DE acquisition; lightfield; image based rendering
AB Acquisition of image data for lightfield usually requires an expensive, complex and bulky setup. In this paper, we describe a simple method of acquiring the image data set. The method requires a normal handheld video camera, which is taken around the object to be rendered. We employ homography from the viewing/camera plane to the lightfield plane for obtaining the ray intersections with the lightfield planes. The computations involved are simple and make the method suitable for online lightfield acquisition. (C) 2004 Elsevier B.V. All rights reserved.
C1 Indian Inst Technol, Dept Comp Sci & Engn, New Delhi 110016, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Delhi
RP Indian Inst Technol, Dept Comp Sci & Engn, New Delhi 110016, India.
EM sharma@vlsicad.ucsd.edu; parashar@cse.psu.edu; suban@cse.iitd.ernet.in;
   pkalra@cse.iitd.ernet.in
CR Adelson EH, 1991, COMPUTATIONAL MODELS
   BREGLER C, 1999, SIGGRAPH COURSE
   GORTLER RSS, 1996, SIGGRAPH 96, P43
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Isaksen A, 2000, COMP GRAPH, P297, DOI 10.1145/344779.344929
   KOCH R, 1999, ICCV99, P585
   Levoy M., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P31, DOI 10.1145/237170.237199
   NARAYANAN PJ, 1998, INDIAN C COMPUTER VI
   SLATER M, 2000, TUTORIAL LIGHTFIELD
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
NR 10
TC 1
Z9 2
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2004
VL 22
IS 14
BP 1197
EP 1202
DI 10.1016/j.imavis.2004.03.023
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 882LG
UT WOS:000225939800006
DA 2024-07-18
ER

PT J
AU Luo, JB
   Singhal, A
   Etz, SP
   Gray, RT
AF Luo, JB
   Singhal, A
   Etz, SP
   Gray, RT
TI A computational approach to determination of main subject regions in
   photographic images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image understanding; main subject; region of interest; semantic object
   class; saliency; belief networks; observer studies; scalable
   configuration
ID COLOR IMAGES; SEGMENTATION; OBJECTS
AB We present a computational approach to main subject detection, which provides a measure of saliency or importance for different regions that are associated with different subjects in an image with unconstrained scene content. It is built primarily upon selected image semantics, with low-level vision features also contributing to the decision. The algorithm consists of region segmentation, perceptual grouping, feature extraction, and probabilistic reasoning. To accommodate the inherent ambiguity in the problem as reflected by the ground truth (probabilistic in nature), we have developed a novel training mechanism for Bayes nets based on fractional frequency counting. Using a set of images spanning the 'photo space,' experimental results have shown the promise of our approach in that most of the regions that independent observers ranked as the main subject are also labeled as such by our system. In addition, without reorganization and retraining, the Bayes net-based framework lends itself to performance scalable configurations to suit different applications that have different requirements of accuracy and speed. This paper focuses on a high level description of the complete system used to solve the overall problem, while providing necessary descriptions of the component algorithms. (C) 2003 Elsevier B.V. All rights reserved.
C1 Eastman Kodak Co, Elect Imaging Prod, Res & Dev, Div Imaging Sci, Rochester, NY 14650 USA.
C3 Eastman Kodak
RP Luo, JB (corresponding author), Eastman Kodak Co, Elect Imaging Prod, Res & Dev, Div Imaging Sci, 1-65-RL,MC 01816,1700 Dewey Ave, Rochester, NY 14650 USA.
EM luo@image.kodak.com
RI Luo, Jiebo/AAI-7549-2020
OI Luo, Jiebo/0000-0002-4516-9729
CR [Anonymous], P IEEE INT WORKSH CO
   Batlle J, 2000, IMAGE VISION COMPUT, V18, P515, DOI 10.1016/S0262-8856(99)00040-2
   CHEN S, 2002, P CVPRIP
   Cohen Y, 2003, PATTERN RECOGN, V36, P2349, DOI 10.1016/S0031-3203(03)00120-1
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   DAVIS P, 1972, PHOTOGRAPHY
   ETZ S, 2000, IMAGING SPIE, V3959
   FEININGER A, 1949, FEININGER PHOTOGRAPH
   FUNG RM, 1995, COMMUN ACM, V38
   Hogg R.V., 1988, Probability and Statistical Inference, V3rd
   Iqbal Q, 2002, PATTERN RECOGN, V35, P1463, DOI 10.1016/S0031-3203(01)00139-X
   JACOBS DW, 1992, ROBUST EFFICIENT DET
   Kemeny J., 1978, Mathematical Models in the Social Sciences
   KWOH CK, 1996, USING HIDDEN NODES B, P88
   LUO J, 1997, P IEEE INT C IM PROC
   LUO J, 2000, P IEEE INT C COMP VI
   LUO J, 2002, P IEEE INT C MULT EX
   Luo JB, 2002, IEEE T IMAGE PROCESS, V11, P201, DOI 10.1109/83.988954
   Luo JB, 2003, PATTERN RECOGN, V36, P2781, DOI 10.1016/S0031-3203(03)00170-5
   Luo JB, 2002, IEEE T PATTERN ANAL, V24, P1147, DOI 10.1109/TPAMI.2002.1023811
   MARICHAL X, 1996, P IEEE INT C IM PROC
   Milanese R., 1993, THESIS U GENEVA SWIT
   MOHAN R, 1992, IEEE T PATTERN ANAL, V14, P616, DOI 10.1109/34.141553
   NG KC, 1991, P 7 INT C UNC AI LOS
   Ohta Y., 1985, KNOWLEDGE BASED INTE
   OSBERGER W, 1998, P IEEE INT C PATT RE
   Pearl J., 1988, PROBABILISTIC REASON
   PRADHAN M, 1996, ARTIF INTELL, P85
   RIMEY RD, 1994, INT J COMPUT VISION, V12, P173, DOI 10.1007/BF01421202
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   SARKAR S, 2000, J COMPUT VISION IMAG, P79
   Sclaroff S, 2001, IEEE T PATTERN ANAL, V23, P475, DOI 10.1109/34.922706
   SEGUR RK, 2000, IS T IMAGE P IMAGE Q
   SINGHAL A, 2003, P SPIE IS T S EL IM
   SINGHAL A, 2000, FUSION 2000 3 INT C
   SINGHAL A, 2001, THESIS U ROCHESTER
   SINGHAL A, 2003, P IEEE INT C COMP VI
   SPRAGUE N, 2002, P IEEE INT C PATT RE
   SyedaMahmood TF, 1997, INT J COMPUT VISION, V21, P9, DOI 10.1023/A:1007919421801
   Tu ZW, 2002, IEEE T PATTERN ANAL, V24, P657, DOI 10.1109/34.1000239
   ZHAO J, 1996, P INT S SIGN PROC IT
NR 41
TC 23
Z9 27
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2004
VL 22
IS 3
BP 227
EP 241
DI 10.1016/j.imavis.2003.09.012
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 776RH
UT WOS:000189130100006
DA 2024-07-18
ER

PT J
AU Shelley, P
   Li, XB
   Han, B
AF Shelley, P
   Li, XB
   Han, B
TI A hybrid quantization scheme for image compression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image compression; quantization; wavelet coefficient tree; measure of
   coarseness
ID LATTICE VECTOR QUANTIZATION
AB This paper presents a new quantization algorithm that combines the quantization strategies of two existing methods. For uniformly smooth or detailed images, the new method improves upon both of the individual quantization strategies that make it up over 85% of the time, while a certain class of images mixing smoothness and detail are improved upon over 77% of the time. Even more important than the results, however, is the algorithm for combining the quantization strategies, which can be applied to other, more recent strategies to achieve even better results. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E1, Canada.
C3 University of Alberta
RP Univ Alberta, Dept Comp Sci, Edmonton, AB T6G 2E1, Canada.
EM shelley@cs.ualberta.ca; li@cs.ualberta.ca; bhan@ualberta.ca
CR Cosman P. C., 1995, Proceedings. DCC '95 Data Compression Conference (Cat. No.95TH8037), P33, DOI 10.1109/DCC.1995.515493
   Fowler JE, 1997, IEEE DATA COMPR CONF, P317, DOI 10.1109/DCC.1997.582055
   Hahn PJ, 1996, DCC '96 - DATA COMPRESSION CONFERENCE, PROCEEDINGS, P340, DOI 10.1109/DCC.1996.488339
   HAMZAOUI R, 1997, P IEEE DAT COMPR C
   Knipe J, 1998, IEEE T SIGNAL PROCES, V46, P239, DOI 10.1109/78.651227
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   SAMPSON DG, 1994, ELECTRON LETT, V30, P1477, DOI 10.1049/el:19941039
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   SHELLEY P, 2001, THESIS U ALBERTA
   WU XL, 1995, IEEE T IMAGE PROCESS, V4, P34, DOI 10.1109/83.350815
NR 10
TC 4
Z9 4
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2004
VL 22
IS 3
BP 203
EP 213
DI 10.1016/j.imavis.2003.09.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 776RH
UT WOS:000189130100004
DA 2024-07-18
ER

PT J
AU Wu, HHP
AF Wu, HHP
TI Patient information extraction in digitized X-ray imagery
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE document image analysis; film scanner; picture archiving and
   communication system; patient information extraction; radiograph
ID UNCONSTRAINED HANDWRITTEN NUMERALS; COMPUTER-AIDED DIAGNOSIS;
   NEURAL-NETWORK; RECOGNITION; SYSTEM
AB Digital imagery is gradually replacing the traditional radiograph with the development of digital radiography and film scanner. This paper presents a new method to extract the patient information number (PIN) field automatically from the film-scanned image using image analysis technique. In order to evaluate the PIN field extraction algorithm, two formats of label acquired from two different hospitals are tested. Given the available films with no constraints on the way the labels are written and positioned, the correct field extraction rates are 73 and 84%, respectively. The film is rejected and will not be filed automatically if the PIN field was not extracted successfully. For the properly extracted PIN field, numerals representing patient's ID inside can then be recognized by a multilayer cluster neural network with a 99% recognition rate. This extracted PIN information is linked with Radiology Information System or Hospital Information System and the image scanned from the film can be filed into database automatically. The efficiency this method offers can greatly simplify the image filing process and improve the user-friendliness of the overall image digitization system. We believe the success of this technique will benefit the development of the Picture Archiving and Communication System and teleradiology. (C) 2003 Elsevier B.V. All rights reserved.
C1 Natl Yunlin Univ Sci & Technol, Dept Elect Engn, Touliu, Taiwan.
C3 National Yunlin University Science & Technology
RP Wu, HHP (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Elect Engn, 123 Univ Rd,Sect 3, Touliu, Taiwan.
EM wuhp@yuntech.edu.tw
CR [Anonymous], 1992, R. woods digital image processing
   BEIGI HSM, 1994, P ICIP, V1, P169
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cao XH, 2000, IEEE ENG MED BIOL, V19, P80, DOI 10.1109/51.870234
   Casey R., 1992, Machine Vision and Applications, V5, P143, DOI 10.1007/BF02626994
   Cui YT, 1998, MACH VISION APPL, V10, P308, DOI 10.1007/s001380050081
   FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112
   Giger ML, 2000, COMPUT SCI ENG, V2, P39, DOI 10.1109/5992.877391
   Inamura K, 1996, IEEE COMMUN MAG, V34, P46, DOI 10.1109/35.526887
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lee SW, 1996, IEEE T PATTERN ANAL, V18, P648, DOI 10.1109/34.506416
   Lo S C, 1993, J Digit Imaging, V6, P48
   MACMAHON H, 1993, RADIOGRAPHICS, V13, P72
   PALUMBO PW, 1992, COMPUTER, V25, P34, DOI 10.1109/2.144438
   Penedo MG, 1998, IEEE T MED IMAGING, V17, P872, DOI 10.1109/42.746620
   SCHURMANN J, 1992, P IEEE, V80, P1101, DOI 10.1109/5.156473
   SUEN CY, 1992, P IEEE, V80, P1162, DOI 10.1109/5.156477
   Taylor S. L., 1992, Machine Vision and Applications, V5, P211, DOI 10.1007/BF02626999
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511
   TSUJIMOTO S, 1992, P IEEE, V80, P1133, DOI 10.1109/5.156475
   Yu SY, 2000, IEEE T MED IMAGING, V19, P115, DOI 10.1109/42.836371
   1992, IEEE J SELECTED AREA
NR 22
TC 1
Z9 1
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2004
VL 22
IS 3
BP 215
EP 226
DI 10.1016/j.imavis.2003.09.015
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 776RH
UT WOS:000189130100005
DA 2024-07-18
ER

PT J
AU Yanai, K
   Shindo, M
   Noshita, K
AF Yanai, K
   Shindo, M
   Noshita, K
TI A fast image-gathering system from the World-Wide Web using a PC cluster
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image search; image gathering; world wide web; content-based image
   retrieval; PC cluster
ID COLOR; RETRIEVAL
AB Due to the recent explosive progress of WWW (World-Wide Web), we can easily access a large number of images on WWW. There are, however, no established methods to make use of WWW as a large image database. In this paper, we describe an automatic image-gathering system from WWW, in which we use both keywords and image features. By exploiting some existing keyword-based search engines and selecting images by their image features, our system obtains, with high accuracy, images that are relevant to query keywords. Our system has the following two novel properties: (1) It does not need to make a huge index for a great number of images on the whole WWW because of taking advantage of commercial keyword-based text-search engines. (2) It can gather a lot of images related to given keywords full-automatically without a user's intervention during the processing. The system has been implemented on a parallel PC cluster, which enables us to gather more than one hundred images from WWW in about one minute. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Electrocommun, Dept Comp Sci, Chofu, Tokyo 1828585, Japan.
C3 University of Electro-Communications - Japan
RP Yanai, K (corresponding author), Univ Electrocommun, Dept Comp Sci, 1-5-1 Chofugaoka, Chofu, Tokyo 1828585, Japan.
EM yanai@igo.ics.uec.ac.jp; shindo-m@igo.cs.uec.ac.jp; noshita@cs.uec.ac.jp
OI Yanai, Keiji/0000-0002-0431-183X
CR [Anonymous], P EUR C COMP VIS
   Barnard K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P408, DOI 10.1109/ICCV.2001.937654
   BARNARD K, 2001, P IEEE COMPUTER VISI
   BELONGIE S, 1997, 07939 UC BERK CS TEC
   BIMBO AD, 1999, VISUAL INFORMATION R
   Duda R. O., 2000, PATTERN CLASSIFICATI
   FRAMKEL C, 1996, TR9614 U CHIC
   Gevers T, 2000, IEEE T IMAGE PROCESS, V9, P102, DOI 10.1109/83.817602
   GEVERS T, 1997, P VISUAL 97
   GUDIVADA VN, 1995, COMPUTER, V28, P18, DOI 10.1109/2.410145
   HAFNER J, 1995, IEEE T PATTERN ANAL, V17, P729, DOI 10.1109/34.391417
   Kasturi R., 1996, INT WORKSH IM DAT MU, P75
   Lew MS, 2000, COMPUTER, V33, P46, DOI 10.1109/2.881694
   MARSLAND TA, 1985, IEEE T PATTERN ANAL, V7, P442, DOI 10.1109/TPAMI.1985.4767683
   MORI Y, 1999, P 1 INT WORKSH MUTL
   Rowe NC, 1998, INFORM PROCESS MANAG, V34, P95, DOI 10.1016/S0306-4573(97)00048-4
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sclaroff S, 1999, COMPUT VIS IMAGE UND, V75, P86, DOI 10.1006/cviu.1999.0765
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Smith JR, 1997, IEEE MULTIMEDIA, V4, P12, DOI 10.1109/93.621578
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   YANAI K, 2003, IN PRESS P ACM INT C
NR 22
TC 7
Z9 7
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2004
VL 22
IS 1
BP 59
EP 71
DI 10.1016/j.imavis.2003.08.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 763BB
UT WOS:000188048400006
DA 2024-07-18
ER

PT J
AU Roh, YJ
   Park, WS
   Cho, H
AF Roh, YJ
   Park, WS
   Cho, H
TI Correcting image distortion in the X-ray digital tomosynthesis system
   for PCB solder joint inspection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE X-ray digital tomosynthesis; image distortion; polynomial model; self
   organizing feature map
AB X-ray digital tomosynthesis (DT), which makes a cross-sectional image of 3D objects, has been researched and implemented in industrial applications nowadays, such as printed circuit board (PCB) inspection and inspection of electronic parts and other industrial parts/products. In this method, a cross-section image is obtained from a synthesis of more than two images projected from different views. However, distortion in X-ray images in practical imaging situation breaks the correspondences between those images and prevents us from acquiring accurate cross-section images. In this research, we propose a series of image correction method, which is composed of a neural network-based feature extraction for the distorted image and building a polynomial mapping function. The distorted raw image is sequentially corrected in terms of shape and intensity by using a reference pattern. To avoid corruption in feature extraction for the distorted image, an edge-filtered image is utilized rather than using a binarized one. Kohonen neural network is then employed to automatically group the edge points and localize the features, the pattern centers, without any pre-knowledge about the characteristics of the distortion. The proposed correction method is implemented to an actual DT system by carrying out a series of experiments on PCB. The results reveal the validity of the proposed image correction method and also verify the usefulness of the developed system for application of solder joint inspection. (C) 2003 Elsevier B.V. All rights reserved.
C1 Korea Adv Inst Sci & Technol, Dept Mech Engn, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Cho, H (corresponding author), Korea Adv Inst Sci & Technol, Dept Mech Engn, 373-1 Kusong Dong, Taejon 305701, South Korea.
CR ADAMS J, 1991, SPIE INTEGRATED CIRC, V1464, P484
   An JN, 1997, IMAGE VISION COMPUT, V15, P861, DOI 10.1016/S0262-8856(97)00030-9
   BLACK DL, 1991, IEMT S, P207
   CHO HS, 1997, DEV PCB SOLDER JOINT
   DOI H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P575, DOI 10.1109/ICCV.1995.466887
   Kang ST, 1999, NDT&E INT, V32, P9, DOI 10.1016/S0963-8695(98)00031-0
   Kang ST, 1999, MATER EVAL, V57, P841
   KANG ST, 1998, THESIS KOREA ADV I S
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   Roh YJ, 1999, P SOC PHOTO-OPT INS, V3836, P168, DOI 10.1117/12.360270
   ROH YJ, 1998, SPIE S INT SYST ADV, V3528, P248
   ROH YJ, 1999, J ICASE, V5, P558
   Rooks SM, 1995, IEEE T COMPON PACK A, V18, P851, DOI 10.1109/95.477473
   ROOKS SM, 1994, SURF MOUNT INT C SAN, P51
   SIEWERT TA, 1994, MATER EVAL, P1194
   STIEL GM, 1993, IEEE T MED IMAGING, V12, P314, DOI 10.1109/42.232261
   WAHLE A, 1996, 18 ANN INT C IEEE EN, P654
NR 17
TC 10
Z9 15
U1 1
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2003
VL 21
IS 12
BP 1063
EP 1075
DI 10.1016/S0262-8856(03)00117-3
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 737UW
UT WOS:000186251000005
DA 2024-07-18
ER

PT J
AU Adams, NJ
   Williams, CKI
AF Adams, NJ
   Williams, CKI
TI Dynamic trees for image modelling
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Symposium on Probabilistic Models in Computer Vision
CY MAY, 2001
CL ENGLAND
SP British Mach Vis, Royal Stat Soc
DE Bayesian image modelling; belief networks; dynamic tree; variational
   inference; mean field; expectation-maximisation
ID NETWORKS
AB This paper introduces a new class of image model which we call dynamic trees or DTs. A dynamic tree model specifies a prior over structures of trees, each of which is a forest of one or more tree-structured belief networks (TSBN). In the literature standard tree-structured belief network models have been found to produce 'blocky' segmentations when naturally occurring boundaries within an image did not coincide with those of the subtrees in the rigid fixed structure of the network. Dynamic trees have a flexible architecture which allows the structure to vary to create configurations where the subtree and image boundaries align, and experimentation with the model has shown significant improvements.
   For large models the number of tree configurations quickly becomes intractable to enumerate over, presenting a problem for exact inference. Techniques such as Gibbs sampling over trees and search using simulated annealing have been considered, but a variational approximation based upon mean field was found to work faster while still producing a good approximation to the true model probability distribution. We look briefly at this mean field approximation before deriving an EM-style update based upon mean field inference for learning the parameters of the dynamic tree model.
   After development of algorithms for learning the dynamic tree model is applied to a database of images of outdoor scenes where all of its parameters are learned. DTs are seen to offer significant improvement in performance over the fixed-architecture TSBN and in a coding comparison the DT achieves 0.294 bits per pixel (bpp) compression compared to 0.378 bpp for lossless JPEG on images of seven colours. (C) 2003 Published by Elsevier B.V.
C1 Univ Edinburgh, Sch Informat, Inst Adapt & Neural Computat, Edinburgh EH1 2QL, Midlothian, Scotland.
C3 University of Edinburgh
RP Univ Edinburgh, Sch Informat, Inst Adapt & Neural Computat, 5 Forrest Hill, Edinburgh EH1 2QL, Midlothian, Scotland.
EM nicka@dai.ed.ac.uk; c.k.i.williams@ed.ac.uk
CR Adams NJ, 1999, IEE CONF PUBL, P527, DOI 10.1049/cp:19991163
   ADAMS NJ, 2001, 4 INT ICSC S SOFT CO
   ADAMS NJ, 2001, THESIS U EDINBURGH 5
   Adamy ST, 2000, J SURFACTANTS DETERG, V3, P151, DOI 10.1007/s11743-000-0119-y
   [Anonymous], 1995, NEURAL COMPUTATION
   [Anonymous], HDB BRAIN THEORY NEU
   [Anonymous], 1993, Statistical Language Learning
   [Anonymous], 1981, Internal Report 81-2
   BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898
   CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641
   CHOU PA, 1989, P SOC PHOTO-OPT INS, V1199, P852
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   DEBONET JS, 1998, ADV NEURAL INFORMATI, V10
   FENG X, 1998, P SPIE, V3457
   Feng XJ, 2002, IEEE T PATTERN ANAL, V24, P467, DOI 10.1109/34.993555
   FIEGUTH PW, 1994, IEEE IMAGE PROC, P1, DOI 10.1109/ICIP.1994.413519
   Friedman N., 1998, PROC 14 C UNCERTAINT, P129
   Geiger D, 1996, ARTIF INTELL, V82, P45, DOI 10.1016/0004-3702(95)00014-3
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GEMAN S, 1994, CICSP411 BROWN U DIV
   Hinton GE, 2000, ADV NEUR IN, V12, P463
   HINTON GE, 1998, NEURAL NETWORKS MACH
   Irving WW, 1997, IEEE T IMAGE PROCESS, V6, P1517, DOI 10.1109/83.641412
   Jordan MI, 1998, NATO ADV SCI I D-BEH, V89, P105
   Lauritzen S. L., 1996, GRAPHICAL MODELS, V17
   Little RJ, 1987, STAT ANAL MISSING DA
   LUETTGEN MR, 1995, IEEE T IMAGE PROCESS, V4, P194, DOI 10.1109/83.342185
   MONTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307, DOI 10.1109/34.88566
   Pearl J., 1988, PROBABILISTIC REASON
   SAUL LK, 1996, EXPLOITING TRACTABLE, V8
   STORKEY AJ, 2001, P 8 INT WORKSH ART I
   Williams CKI, 1999, ADV NEUR IN, V11, P634
   WILLIAMS CKI, 1990, THESIS U TORONTO
NR 33
TC 16
Z9 20
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2003
VL 21
IS 10
BP 865
EP 877
DI 10.1016/S0262-8856(03)00073-8
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 723KU
UT WOS:000185432200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ding, J
   Zhang, Z
   Wang, QY
   Wang, HB
AF Ding, Jun
   Zhang, Zhen
   Wang, Qiyu
   Wang, Huibin
TI SCTrans: Self-align and cross-align transformer for few-shot
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic segmentation; Few-shot learnving; Few-shot segmentation
AB Few-shot Semantic Segmentation (FSS) refers to train a segmentation model that can be generalized to novel categories with limited labeled images. One challenge of FSS is spatial inconsistency between support and query images, e.g., appearance and texture. Most existing methods are only committed to utilizing the semantic-level prototypes of support images to guide mask predictions. These methods, nevertheless, only focus on the most discriminate regions of the object rather than holonomic feature representations. Besides, another question exists that the lack of interaction between paired support and query images. In this paper, we propose a self-align and cross-align transformer (SCTrans) to remedy the above limitations. Specifically, we design a feature fusion module (FFM) to incorporate low-level information from the query branch into mid-level semantic features, boosting the semantic representations of query images. In addition, a feature alignment module is designed to bidirectionally propagate semantic information from support to query images conditioned on more representative support and query features, increasing both intra-class similarities and inter-class differences. Extensive experiments on PASCAL-5i and COCO-20i show that our SCTrans significantly advances the state-of-the-art methods.
C1 [Ding, Jun; Zhang, Zhen; Wang, Qiyu; Wang, Huibin] Hohai Univ, Sch Informat, Nanjing 210044, Peoples R China.
C3 Hohai University
RP Zhang, Z (corresponding author), Hohai Univ, Sch Informat, Nanjing 210044, Peoples R China.
EM 211607010110@hhu.edu.cn; zz_hhuc@hhu.edu.cn; 1806020129@hhu.edu.cn;
   hbwang@hhu.edu.cn
FU China Postdoctoral Science Foundation
FX The authors declare the following financial interests/personal
   re-lationships which may be considered as potential competing interests:
   Zhen Zhang reports financial support was provided by the China
   Postdoctoral Science Foundation.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Boyu Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P763, DOI 10.1007/978-3-030-58598-3_45
   Cao L, 2022, arXiv
   Chen L.-C., 2018, Pertanika J. Trop. Agric. Sci., P801, DOI [10.1007/978-3-030-01234-2_49, DOI 10.1007/978-3-030-01234-249, DOI 10.1007/978-3-030-01234-2_49]
   Chen LC, 2016, Arxiv, DOI arXiv:1412.7062
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Cheng B, 2021, ADV NEUR IN, V34
   Cho Seokju, 2021, ADV NEURAL INF PROCE, V34, P9011
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dong N., 2018, BMVC, V4, P4
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Hariharan B, 2014, LECT NOTES COMPUT SC, V8695, P297, DOI 10.1007/978-3-319-10584-0_20
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Nguyen K, 2019, IEEE I CONF COMP VIS, P622, DOI 10.1109/ICCV.2019.00071
   Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656
   Li G, 2021, PROC CVPR IEEE, P8330, DOI 10.1109/CVPR46437.2021.00823
   Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926
   Li ZC, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3240195
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu BH, 2021, PROC CVPR IEEE, P9742, DOI 10.1109/CVPR46437.2021.00962
   Liu H., 2021, arXiv, DOI DOI 10.48550/ARXIV.2107.00782
   Liu WD, 2022, Arxiv, DOI arXiv:2108.08518
   Liu WD, 2022, INT J COMPUT VISION, V130, P3140, DOI 10.1007/s11263-022-01677-7
   Liu WD, 2020, PROC CVPR IEEE, P4164, DOI 10.1109/CVPR42600.2020.00422
   Liu YW, 2022, PROC CVPR IEEE, P11563, DOI 10.1109/CVPR52688.2022.01128
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Loshchilov I, 2019, Arxiv, DOI arXiv:1711.05101
   Lu ZH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P8721, DOI 10.1109/ICCV48922.2021.00862
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shaban A, 2017, Arxiv, DOI [arXiv:1709.03410, DOI 10.48550/ARXIV.1709.03410]
   Shi XY, 2022, LECT NOTES COMPUT SC, V13680, P151, DOI 10.1007/978-3-031-20044-1_9
   Snell J, 2017, ADV NEUR IN, V30
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tang H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P610, DOI 10.1145/3394171.3413884
   Tang Hao, 2023, M3net: Multiview encoding, matching, and fusion for few-shot fine-grained action recognition
   Tian ZT, 2022, IEEE T PATTERN ANAL, V44, P1050, DOI 10.1109/TPAMI.2020.3013717
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang KX, 2019, IEEE I CONF COMP VIS, P9196, DOI 10.1109/ICCV.2019.00929
   Zha ZC, 2023, IEEE T CIRC SYST VID, V33, P3947, DOI 10.1109/TCSVT.2023.3236636
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhang GW, 2021, ADV NEUR IN, V34
   Zhang XL, 2020, IEEE T CYBERNETICS, V50, P3855, DOI 10.1109/TCYB.2020.2992433
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
NR 45
TC 0
Z9 0
U1 5
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2024
VL 142
AR 104893
DI 10.1016/j.imavis.2023.104893
EA DEC 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IJ0U4
UT WOS:001165848400001
DA 2024-07-18
ER

PT J
AU Li, XP
   Wu, SQ
   Wu, JX
   Xie, SL
   Agaian, S
AF Li, Xiaopan
   Wu, Shiqian
   Wu, Jiaxin
   Xie, Shoulie
   Agaian, Sos
TI Perception-guided defocus blur detection based on SVD feature
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Defocus blur detection; Re -blurred singular value difference;
   Perceptual weight; Matting Laplace
AB Defocus blur detection aims to identify out-of-focus regions in a single image. Although defocus blur detection has attracted more and more attention in recent years, it still faces some challenges. In particular, the in-focus regions with low contrast are easily misidentified as out-of-focus regions. To address this problem, a perception-guided defocus blur detection method is proposed to estimate defocus blur amounts at edge locations from a single image based on the singular value decomposition (SVD) features. Inspired by the fact that blurring the clear region produces significant changes in SVD domain as compared with re-blurring the blurred one, new SVD features are extracted based on re-blurred singular value difference (RESVD) of the corresponding local gradient patches. Then, perceptual weight based on Just Noticeable Blur (JNB) is introduced to guide the sparse blur map estimation obtained with the SVD features. Finally, the full defocus blur map is constructed from the sparse defocus blur map by the Matting Laplace algorithm. Visual evaluations are conducted on the CUHK, DUT and CTCUG datasets, employing mean absolute error (MAE) and F beta-measure as quantitative evaluation metrics. The experimental results demonstrate that the proposed defocus blur detection method is superior to 13 state-ofthe-art methods. On the DUT dataset, the proposed method yields a high F beta-measure (0.802) with a low MAE (0.081) compared to other methods (F beta <= 0.799, MAE >= 0.099). On the CUHK and CTCUG datasets, our method achieves the best balance between F beta-measure and MAE. Furthermore, our method results in better visual effects than other methods regarding realism and quality.
C1 [Li, Xiaopan; Wu, Shiqian; Wu, Jiaxin] Wuhan Univ Sci & Technol, Inst Robot & Intelligent Syst, Sch Informat Sci & Engn, Wuhan 430081, Peoples R China.
   [Wu, Shiqian] Hubei Prov Key Lab Intelligent Informat Proc & Rea, Wuhan 430072, Peoples R China.
   [Xie, Shoulie] ASTAR, Inst Infocomm Res, Singapore 138632, Singapore.
   [Agaian, Sos] CUNY, Coll Staten Isl, Dept Comp Sci, New York, NY 10314 USA.
C3 Wuhan University of Science & Technology; Agency for Science Technology
   & Research (A*STAR); A*STAR - Institute for Infocomm Research (I2R);
   City University of New York (CUNY) System; College of Staten Island
   (CUNY)
RP Wu, SQ (corresponding author), Wuhan Univ Sci & Technol, Inst Robot & Intelligent Syst, Sch Informat Sci & Engn, Wuhan 430081, Peoples R China.
EM lxp2017@wust.edu.cn; shiqian.wu@wust.edu.cn; wujiaxin@wust.edu.cn;
   slxie@i2r.a-star.edu.sg; sos.agaian@csi.cuny.edu
RI Wu, Shiqian/W-4067-2019; Wu, Jiaxin/ABG-8803-2021; Agaian, Sos
   s/IZE-1724-2023
OI Wu, Shiqian/0000-0002-6383-7663; Wu, Jiaxin/0000-0003-0618-2469; Agaian,
   Sos s/0000-0003-4601-4507
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Bac S, 2007, COMPUT GRAPH FORUM, V26, P571, DOI 10.1111/j.1467-8659.2007.01080.x
   Chakrabarti A, 2010, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2010.5539954
   Crete F, 2007, PROC SPIE, V6492, DOI 10.1117/12.702790
   Eisinger RW, 2020, J INFECT DIS, V222, P1432, DOI 10.1093/infdis/jiz442
   Ferzli R, 2009, IEEE T IMAGE PROCESS, V18, P717, DOI 10.1109/TIP.2008.2011760
   Golestaneh SA, 2017, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2017.71
   Guan JW, 2015, J VIS COMMUN IMAGE R, V29, P1, DOI 10.1016/j.jvcir.2015.01.007
   Huang R, 2018, NEUROCOMPUTING, V285, P154, DOI 10.1016/j.neucom.2018.01.041
   Karaali A, 2018, IEEE T IMAGE PROCESS, V27, P1126, DOI 10.1109/TIP.2017.2771563
   Khan A, 2021, INT J OPT, V2021, DOI 10.1155/2021/2785225
   Khan A, 2022, FRONT COMPUT SCI-CHI, V16, DOI 10.1007/s11704-020-9526-x
   Lai WS, 2016, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2016.188
   Lee H, 2014, IEEE IMAGE PROC, P4427, DOI 10.1109/ICIP.2014.7025898
   Lee J, 2021, PROC CVPR IEEE, P2034, DOI 10.1109/CVPR46437.2021.00207
   Lee J, 2019, PROC CVPR IEEE, P12214, DOI 10.1109/CVPR.2019.01250
   Levin A, 2008, IEEE T PATTERN ANAL, V30, P228, DOI 10.1109/TPAMI.2007.1177
   Li JX, 2023, IEEE T IMAGE PROCESS, V32, P1158, DOI 10.1109/TIP.2023.3240856
   Li ZC, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3240195
   Liang X, 2022, COMPLEX INTELL SYST, V8, P1323, DOI 10.1007/s40747-021-00592-7
   Lyu WJ, 2020, J VIS COMMUN IMAGE R, V69, DOI 10.1016/j.jvcir.2020.102797
   Ma M, 2020, SIGNAL PROCESS, V176, DOI 10.1016/j.sigpro.2020.107670
   Narwaria M, 2012, IEEE T SYST MAN CY B, V42, P347, DOI 10.1109/TSMCB.2011.2163391
   Oh TH, 2018, LECT NOTES COMPUT SC, V11208, P663, DOI 10.1007/978-3-030-01225-0_39
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park J, 2017, PROC CVPR IEEE, P2760, DOI 10.1109/CVPR.2017.295
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Petschnigg G, 2004, ACM T GRAPHIC, V23, P664, DOI 10.1145/1015706.1015777
   Qi S, 2022, IMAGE VISION COMPUT, V122, DOI 10.1016/j.imavis.2022.104449
   Sang QB, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0108073
   Sang QB, 2014, J VIS COMMUN IMAGE R, V25, P1625, DOI 10.1016/j.jvcir.2014.08.002
   Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Shnayderman A, 2006, IEEE T IMAGE PROCESS, V15, P422, DOI 10.1109/TIP.2005.860605
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Su W, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104487
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Tang C, 2016, IEEE SIGNAL PROC LET, V23, P1652, DOI 10.1109/LSP.2016.2611608
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tang H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P610, DOI 10.1145/3394171.3413884
   Tang LJ, 2018, MULTIMED TOOLS APPL, V77, P5637, DOI 10.1007/s11042-017-4477-4
   Wu S., 2009, P INT C INF COMM SIG, P1
   Xiao HM, 2019, J VIS COMMUN IMAGE R, V59, P52, DOI 10.1016/j.jvcir.2018.12.048
   Xin SM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2208, DOI 10.1109/ICCV48922.2021.00223
   Xu GD, 2017, IEEE I CONF COMP VIS, P5381, DOI 10.1109/ICCV.2017.574
   Xu X, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3532866
   Yan SL, 2022, Arxiv, DOI arXiv:2208.14365
   Yi X, 2016, IEEE T IMAGE PROCESS, V25, P1626, DOI 10.1109/TIP.2016.2528042
   Zha ZC, 2023, IEEE T CIRC SYST VID, V33, P3947, DOI 10.1109/TCSVT.2023.3236636
   [章秀华 Zhang Xiuhua], 2022, [电子与信息学报, Journal of Electronics & Information Technology], V44, P3987
   Zhang Y, 2013, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2013.145
   Zhao F, 2022, IEEE T CIRC SYST VID, V32, P2719, DOI 10.1109/TCSVT.2021.3095347
   Zhao W., 2023, IEEE Trans. Multimed.
   Zhao WD, 2022, LECT NOTES COMPUT SC, V13690, P569, DOI 10.1007/978-3-031-20056-4_33
   Zhao WD, 2021, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR46437.2021.00686
   Zhao WD, 2020, IEEE T PATTERN ANAL, V42, P1884, DOI 10.1109/TPAMI.2019.2906588
   Zhao WD, 2018, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2018.00325
   Zhu T, 2016, IEEE IMAGE PROC, P2673, DOI 10.1109/ICIP.2016.7532844
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 59
TC 0
Z9 0
U1 4
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104845
DI 10.1016/j.imavis.2023.104845
EA OCT 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA X9MG3
UT WOS:001101603400001
DA 2024-07-18
ER

PT J
AU Li, HG
   Qian, WH
   Cao, JD
   Liu, P
AF Li, Huaguang
   Qian, Wenhua
   Cao, Jinde
   Liu, Peng
TI Improving defocus blur detection via adaptive supervision prior-tokens
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Defocus blur detection; Prior -tokens supervision; Feature fusion
   network; Adaptive detection
ID MAP ESTIMATION; IMAGE; TRACKING; FUSION
AB The Defocus Blur Detection (DBD) technique is devised to accurately identify regions of blurriness within images. The prediction difficulty of defocused pixels is closely associated with their spatial location. Owing to the cluttered background, pixels near the edges are more prone to erroneous predictions. To address the issue of uneven pixel distribution at the edges of defocused regions, we deliberately decouple the original labels into Prior-Tokaens: Edge Transition Detail Region (EDR) and Structure Body Region (SBR). Subsequently, we propose a novel adaptive multi-supervised network comprising a feature extraction module, a feature fusion network (FFN), and a Multi-scale Channel Attention Module (MCAM). This method harnesses complementary features between SBR and EDR, furnishing a tailored feature learning strategy that outperforms traditional singlesupervised techniques. Furthermore, considering that features generated with varying receptive fields contain information at different levels, we introduce MCAM to identify feature pixels at different scales, enhancing semantic relevance. Moreover, for images with complex scenes, an adaptive learning scheme is developed to selectively fuse low-level detail features and high-level semantic information, thereby enhancing the model's generalization capability. The proposed approach outperforms state-of-the-art techniques on various evaluation metrics, as demonstrated through qualitative and quantitative analyses of popular public datasets.
C1 [Li, Huaguang; Qian, Wenhua; Liu, Peng] Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Peoples R China.
   [Qian, Wenhua; Cao, Jinde] Southeast Univ, Sch Math, Nanjing 210096, Peoples R China.
C3 Yunnan University; Southeast University - China
RP Qian, WH (corresponding author), Yunnan Univ, Sch Informat Sci & Engn, Kunming 650500, Peoples R China.
EM huaguangli@mail.ynu.edu.cn; whqian@ynu.edu.cn; jdcao@seu.edu.cn;
   liupeng0606@mail.ynu.edu.cn
RI Cao, Jinde/D-1482-2012
OI Cao, Jinde/0000-0003-3133-7119
FU Yunnan University; Research Foundation of Yunnan Province
   [202001BB050043, 202105AF150011]; National Natural Science Foundation of
   China [62162065]; Provincial Foundation for Leaders of Disciplines in
   Science and Technology [2019HB121]
FX This work was supported by the Research Foundation of Yunnan Province
   No. 202001BB050043 and 202105AF150011, National Natural Science
   Foundation of China under Grants No.62162065, Provincial Foundation for
   Leaders of Disciplines in Science and Technology No.2019HB121.
CR Bi HB, 2023, PATTERN RECOGN, V136, DOI 10.1016/j.patcog.2022.109194
   Chakrabarti A, 2010, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2010.5539954
   Du ZX, 2023, IMAGE VISION COMPUT, V137, DOI 10.1016/j.imavis.2023.104789
   Golestaneh SA, 2017, PROC CVPR IEEE, P596, DOI 10.1109/CVPR.2017.71
   He QB, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3152250
   Jiwei Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13002, DOI 10.1109/CVPR42600.2020.01302
   Karaali A, 2018, IEEE T IMAGE PROCESS, V27, P1126, DOI 10.1109/TIP.2017.2771563
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee J, 2019, PROC CVPR IEEE, P12214, DOI 10.1109/CVPR.2019.01250
   Li HG, 2022, KNOWL-BASED SYST, V255, DOI 10.1016/j.knosys.2022.109682
   Li JX, 2023, IEEE T IMAGE PROCESS, V32, P1158, DOI 10.1109/TIP.2023.3240856
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Ma KD, 2018, IEEE T IMAGE PROCESS, V27, P5155, DOI 10.1109/TIP.2018.2847421
   Mansour RF, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104229
   Nejati M, 2015, INFORM FUSION, V25, P72, DOI 10.1016/j.inffus.2014.10.004
   Pang YW, 2016, IEEE T CYBERNETICS, V46, P2220, DOI 10.1109/TCYB.2015.2472478
   Park J, 2017, PROC CVPR IEEE, P2760, DOI 10.1109/CVPR.2017.295
   Purohit K, 2018, IEEE IMAGE PROC, P2202, DOI 10.1109/ICIP.2018.8451765
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Qu Z, 2022, IMAGE VISION COMPUT, V125, DOI 10.1016/j.imavis.2022.104518
   Ran R, 2023, IEEE T CYBERNETICS, V53, P4148, DOI 10.1109/TCYB.2023.3238200
   Saha S, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3174651
   Shandoosti HR, 2016, INFORM FUSION, V27, P150, DOI 10.1016/j.inffus.2015.06.006
   Shi JP, 2015, PROC CVPR IEEE, P657, DOI 10.1109/CVPR.2015.7298665
   Shi JP, 2014, PROC CVPR IEEE, P2965, DOI 10.1109/CVPR.2014.379
   Su B, 2011, Proceedings of the 19th ACM International Conference on Multimedia. MM'11, DOI [DOI 10.1145/2072298.2072024, DOI 10.5555/1785794.1785825]
   Sunitha G, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104404
   Tai YW, 2009, IEEE IMAGE PROC, P1797, DOI 10.1109/ICIP.2009.5414620
   Tang C, 2020, AAAI CONF ARTIF INTE, V34, P12063
   Tang C, 2021, IEEE T MULTIMEDIA, V23, P624, DOI 10.1109/TMM.2020.2985541
   Tang C, 2022, IEEE T PATTERN ANAL, V44, P955, DOI 10.1109/TPAMI.2020.3014629
   Tang C, 2016, IEEE SIGNAL PROC LET, V23, P1652, DOI 10.1109/LSP.2016.2611608
   Tang C, 2013, OPT LETT, V38, P1706, DOI 10.1364/OL.38.001706
   Tang CR, 2023, IMAGE VISION COMPUT, V138, DOI 10.1016/j.imavis.2023.104783
   Tang LF, 2022, INFORM FUSION, V82, P28, DOI 10.1016/j.inffus.2021.12.004
   Tian CW, 2023, PATTERN RECOGN, V134, DOI 10.1016/j.patcog.2022.109050
   Tong K, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104471
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang LG, 2021, PROC CVPR IEEE, P4915, DOI 10.1109/CVPR46437.2021.00488
   Wu RM, 2019, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR.2019.00834
   Xiao CJ, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104470
   Xu GD, 2017, IEEE I CONF COMP VIS, P5381, DOI 10.1109/ICCV.2017.574
   Yang R., 2022, EUROPEAN C COMPUTER, P174
   Yi X, 2016, IEEE T IMAGE PROCESS, V25, P1626, DOI 10.1109/TIP.2016.2528042
   Yongri Piao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9057, DOI 10.1109/CVPR42600.2020.00908
   Yu E, 2022, NEUROCOMPUTING, V486, P215, DOI 10.1016/j.neucom.2021.11.035
   Zeng FG, 2022, LECT NOTES COMPUT SC, V13687, P659, DOI 10.1007/978-3-031-19812-0_38
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhao SL, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3233089
   Zhao W., 2022, IEEE Trans. Neural Netw. Learn. Syst.
   Zhao W., 2023, IEEE Trans. Multimed.
   Zhao WD, 2021, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR46437.2021.00686
   Zhao WD, 2019, PROC CVPR IEEE, P8897, DOI 10.1109/CVPR.2019.00911
   Zhao WD, 2020, IEEE T IMAGE PROCESS, V29, P1356, DOI 10.1109/TIP.2019.2942505
   Zhao WD, 2020, IEEE T PATTERN ANAL, V42, P1884, DOI 10.1109/TPAMI.2019.2906588
   Zhu ZD, 2023, IEEE T PATTERN ANAL, V45, P13344, DOI 10.1109/TPAMI.2023.3292075
   Zhuo SJ, 2011, PATTERN RECOGN, V44, P1852, DOI 10.1016/j.patcog.2011.03.009
NR 59
TC 1
Z9 1
U1 1
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104842
DI 10.1016/j.imavis.2023.104842
EA OCT 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Y9HG5
UT WOS:001108291100001
DA 2024-07-18
ER

PT J
AU Liu, YJ
   Wang, ZY
   Zhang, WX
   Li, ZM
AF Liu, Yujie
   Wang, Zhaoyong
   Zhang, Wenxin
   Li, Zongmin
TI DGSN: Learning how to segment pedestrians from other datasets for
   occluded person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person ReID; Segmentation; Occluded; Image enhancement; Domain
   generalization
ID NETWORK
AB In this paper, we present three major challenges in occluded person Re-Identification (ReID): different occlusions, background interference, and dataset bias. To address the first and second challenges, our approach incorporates pedestrian segmentation to distinguish between pedestrian and non-pedestrian regions. Additionally, to tackle the third challenge, we introduce an effective image enhancement method called Enhanced Random Occluding (ERO). ERO leverages other datasets with segmentation annotations to compensate for the lack of detailed annotations in ReID datasets. We compare the effectiveness of ERO with existing methods. To utilize the prior knowledge obtained by ERO, we introduce the Priori Segmentation Module (PSM) and the Domain Generalization Module (DGM). The PSM module enables learning out-of-domain prior knowledge without relying on external networks, while the DGM module transfers this knowledge to the current domain. Finally, we utilize the obtained segmentation results as attention maps for feature aggregation. ERO, PSM, and DGM together constitute the Domain Generalization Segmentation Network (DGSN). Our experimental results on occluded and holistic person ReID benchmarks demonstrate the superiority of the proposed DGSN. On the Occluded-Duke dataset, we achieved a mAP of 69.9% (+ 2.0%) and a rank-1 accuracy of 60.7% (+0.3%), surpassing state-of-the-art methods significantly.
C1 [Liu, Yujie; Wang, Zhaoyong; Zhang, Wenxin; Li, Zongmin] China Univ Petr Huadong, Qingdao Campus, Qingdao 266580, Peoples R China.
C3 China University of Petroleum
RP Liu, YJ (corresponding author), China Univ Petr Huadong, Qingdao Campus, Qingdao 266580, Peoples R China.
EM liuyujie@upc.edu.cn; wangzhaoyong@s.upc.edu.cn;
   zhangwenxin@s.upc.edu.cn; lizongmin@upc.edu.cn
RI Zhang, Wenxin/GLR-4643-2022
OI Zhang, Wenxin/0000-0003-0568-7369
FU National Key Research and Development Program of China [2019YFF0301800]
FX The National Key Research and Development Program of China (Grant no.
   2019YFF0301800) .
CR Aiadi O., 2022, J. Ambient. Intell. Humaniz. Comput., P1
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chen PX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11813, DOI 10.1109/ICCV48922.2021.01162
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Eom C, 2019, ADV NEUR IN, V32
   Gao S, 2020, P IEEE CVF C COMP VI, P11744
   Ge YX, 2018, ADV NEUR IN, V31
   Guo MH, 2022, COMPUT VIS MEDIA, V8, P331, DOI 10.1007/s41095-022-0271-y
   He LX, 2018, Arxiv, DOI arXiv:1810.07399
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   He ST, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P14993, DOI 10.1109/ICCV48922.2021.01474
   Huang HJ, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102789
   Jia MX, 2023, IEEE T MULTIMEDIA, V25, P1294, DOI 10.1109/TMM.2022.3141267
   Jia MX, 2021, AAAI CONF ARTIF INTE, V35, P1673
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Khirodkar R, 2019, IEEE WINT CONF APPL, P1932, DOI 10.1109/WACV.2019.00210
   Kuan Zhu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P346, DOI 10.1007/978-3-030-58580-8_21
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li HJ, 2021, PROC CVPR IEEE, P6725, DOI 10.1109/CVPR46437.2021.00666
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2905, DOI 10.1109/TMM.2020.2965491
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Peng Xi, 2022, IEEE T PATTERN ANAL
   Peng XB, 2018, IEEE INT CONF ROBOT, P3803, DOI 10.1109/ICCABS.2018.8541936
   Prakash A, 2019, IEEE INT CONF ROBOT, P7249, DOI [10.1109/icra.2019.8794443, 10.1109/ICRA.2019.8794443]
   Rao YM, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1005, DOI 10.1109/ICCV48922.2021.00106
   Ren X, 2020, AS C MACH LEARN PMLR, P17
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Shen YT, 2018, LECT NOTES COMPUT SC, V11219, P508, DOI 10.1007/978-3-030-01267-0_30
   Somers V, 2023, IEEE WINT CONF APPL, P1613, DOI 10.1109/WACV56688.2023.00166
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tan HC, 2023, IEEE T NEUR NET LEAR, V34, P8210, DOI 10.1109/TNNLS.2022.3144163
   Tan Lei, 2022, MM '22: Proceedings of the 30th ACM International Conference on Multimedia, P531, DOI 10.1145/3503161.3547764
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Tobin J, 2017, IEEE INT C INT ROBOT, P23
   Tremblay J, 2018, IEEE COMPUT SOC CONF, P1082, DOI 10.1109/CVPRW.2018.00143
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang JD, 2023, IEEE T KNOWL DATA EN, V35, P8052, DOI 10.1109/TKDE.2022.3178128
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang ZK, 2022, PROC CVPR IEEE, P4744, DOI 10.1109/CVPR52688.2022.00471
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu L, 2016, Arxiv, DOI arXiv:1601.07255
   Yan C, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11855, DOI 10.1109/ICCV48922.2021.01166
   Yan C, 2022, IEEE T MULTIMEDIA, V24, P1665, DOI 10.1109/TMM.2021.3069562
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Ye M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13547, DOI 10.1109/ICCV48922.2021.01331
   Yue XY, 2019, IEEE I CONF COMP VIS, P2100, DOI 10.1109/ICCV.2019.00219
   Yunpeng Zhai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9018, DOI 10.1109/CVPR42600.2020.00904
   Zang XH, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104330
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhang X, 2018, Arxiv, DOI arXiv:1711.08184
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhu K, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3301856
   Zhuo JX, 2019, Arxiv, DOI arXiv:1907.03253
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 68
TC 3
Z9 3
U1 5
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104844
DI 10.1016/j.imavis.2023.104844
EA OCT 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA X9LS2
UT WOS:001101589300001
DA 2024-07-18
ER

PT J
AU Li, SB
   Wang, ZY
   Liu, YX
   Zhang, YW
   Zhu, JZ
   Cui, XR
   Liu, JH
AF Li, Shibao
   Wang, Zhaoyu
   Liu, Yixuan
   Zhang, Yunwu
   Zhu, Jinze
   Cui, Xuerong
   Liu, Jianhang
TI FSformer: Fast-Slow Transformer for video action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Two-stream; Transformer; Self-attention
AB Two-stream networks have achieved good results on action recognition datasets by modeling the interdependence of various motions. However, previous two-stream networks focus on action modeling but ignore concentrating on the difference in importance between different short-term actions, causing the limitation of the model's action modeling capabilities between different short-term actions. Therefore, we propose a Short-term Action Differentiated Attention (SADA) module based on the two-stream structure with different temporal resolution inputs. We embed the SADA module in a novel two-stream transformer architecture called Fast-Slow Transformer (FSformer). The SADA module dramatically pays attention to the difference between the importance of different short-term actions. It can: (i) deploy attention from the video frames to learn the differentiated knowledge of the importance of different short-term action feature information for action recognition, (ii) fuse rich importance difference knowledge and context information through a novel Fast-Slow Attention mechanism. Overall, the SADA module significantly focuses on the difference in importance of short-term actions and improves action recognition performance. We evaluate our method's effectiveness on three challenging denselylabeled action datasets and achieve results over the state-of-the-art.
C1 [Li, Shibao; Wang, Zhaoyu; Liu, Yixuan; Zhang, Yunwu; Zhu, Jinze; Cui, Xuerong] China Univ Petr East China, Coll Oceanog & Space Informat, Qingdao 266580, Peoples R China.
   [Liu, Jianhang] China Univ Petr East China, Coll Comp Sci & Technol, Qingdao 266580, Peoples R China.
C3 China University of Petroleum; China University of Petroleum
RP Li, SB (corresponding author), China Univ Petr East China, Coll Oceanog & Space Informat, Qingdao 266580, Peoples R China.
EM lishibao@upc.edu.cn; z21160033@s.upc.edu.cn; s20160019@s.upc.edu.cn;
   b22160014@s.upc.edu.cn; s22160026@s.upc.edu.cn; cuixuerong@163.com;
   liujianhang@upc.edu.cn
RI Wang, Zhaoyu/KIA-1324-2024
OI Wang, Zhaoyu/0009-0006-3715-6684; Zhang, Yunwu/0009-0003-8439-6005
FU National Natural Science Foundation of China [61972417]; Natural Science
   Foundation of Shan-dong Province [ZR2020MF005]
FX This work is supported by the National Natural Science Foundation of
   China (No. 61972417) and the Natural Science Foundation of Shan-dong
   Province (No. ZR2020MF005) .
CR Aziere N, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104567
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chu XX, 2021, ADV NEUR IN
   Dai R, 2022, PROC CVPR IEEE, P20009, DOI 10.1109/CVPR52688.2022.01941
   Dai R, 2023, IEEE T PATTERN ANAL, V45, P2533, DOI 10.1109/TPAMI.2022.3169976
   Dai R, 2021, IEEE WINT CONF APPL, P2969, DOI 10.1109/WACV48630.2021.00301
   Dosovitskiy A., An Image is Worth 16x16 Words: Transformers for Image Recognition at S cale
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2020, PROC CVPR IEEE, P200, DOI 10.1109/CVPR42600.2020.00028
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2017, PROC CVPR IEEE, P7445, DOI 10.1109/CVPR.2017.787
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Guo MH, 2021, Arxiv, DOI arXiv:2105.02358
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jiang Y.-G., 2014, THUMOS challenge: Action recognition with a large number of classes
   Kahatapitiya K, 2021, PROC CVPR IEEE, P8381, DOI 10.1109/CVPR46437.2021.00828
   Kingma D. P., 2014, arXiv
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Liu Z., 2021, arXiv
   Lu YH, 2023, IMAGE VISION COMPUT, V131, DOI 10.1016/j.imavis.2023.104633
   Park J, 2018, Arxiv, DOI [arXiv:1807.06514, 10.48550/arXiv.1807.06514, DOI 10.48550/ARXIV.1807.06514]
   Piergiovanni AJ, 2019, PR MACH LEARN RES, V97
   Piergiovanni AJ, 2018, PROC CVPR IEEE, P5304, DOI 10.1109/CVPR.2018.00556
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Ryoo Michael S., 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12365), P654, DOI 10.1007/978-3-030-58565-5_39
   Ryoo MS, 2020, Arxiv, DOI arXiv:1905.13209
   Sigurdsson GA, 2017, PROC CVPR IEEE, P5650, DOI 10.1109/CVPR.2017.599
   Sigurdsson GA, 2016, LECT NOTES COMPUT SC, V9905, P510, DOI 10.1007/978-3-319-46448-0_31
   Simonyan K, 2014, ADV NEUR IN, V27
   Tan J, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13506, DOI 10.1109/ICCV48922.2021.01327
   Tirupattur P, 2021, PROC CVPR IEEE, P1460, DOI 10.1109/CVPR46437.2021.00151
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang XZ, 2023, IMAGE VISION COMPUT, V129, DOI 10.1016/j.imavis.2022.104595
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Yeung S, 2018, INT J COMPUT VISION, V126, P375, DOI 10.1007/s11263-017-1013-y
   Zhang H, 2021, Arxiv, DOI arXiv:2105.14447
   Zhang Q., 2021, Advances in Neural Information Processing Systems
   Zhu K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P184, DOI 10.1109/ICCV48922.2021.00025
NR 42
TC 2
Z9 2
U1 8
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104740
DI 10.1016/j.imavis.2023.104740
EA JUL 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N7BX6
UT WOS:001038533100001
DA 2024-07-18
ER

PT J
AU Li, D
   Tang, YQ
   Zhang, ZZ
   Zhang, WS
AF Li, Ding
   Tang, Yongqiang
   Zhang, Zhizhong
   Zhang, Wensheng
TI Cross-stream contrastive learning for self-supervised skeleton-based
   action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Self-supervised learning; Contrastive learning; Skeleton-based action
   recognition
AB Self-supervised skeleton-based action recognition enjoys a rapid growth along with the development of contras-tive learning. The existing methods rely on imposing invariance to augmentations of 3D skeleton within a single data stream, which merely leverages the easy positive pairs and limits the ability to explore the complicated movement patterns. In this paper, we advocate that the defect of single-stream contrast and the lack of necessary feature transformation are responsible for easy positives, and therefore propose a Cross-Stream Contrastive Learning framework for skeleton-based action Representation learning (CSCLR). Specifically, the proposed CSCLR not only utilizes intra-stream contrast pairs, but introduces inter-stream contrast pairs as hard samples to formulate a better representation learning. Besides, to further exploit the potential of positive pairs and in-crease the robustness of self-supervised representation learning, we propose a Positive Feature Transformation (PFT) strategy which adopts feature-level manipulation to increase the variance of positive pairs. To validate the effectiveness of our method, we conduct extensive experiments on three benchmark datasets NTU-RGB + D 60, NTU-RGB + D 120 and PKU-MMD. Experimental results show that our proposed CSCLR exceeds the state-of-the-art methods on a diverse range of evaluation protocols. (c) 2023 Published by Elsevier B.V.
C1 [Li, Ding; Zhang, Wensheng] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.
   [Li, Ding; Tang, Yongqiang; Zhang, Wensheng] Chinese Acad Sci, Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing 100190, Peoples R China.
   [Zhang, Zhizhong] East China Normal Univ, Sch Comp Sci & Software Engn, Shanghai 200050, Peoples R China.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Chinese Academy of Sciences; Institute of Automation, CAS; East
   China Normal University
RP Zhang, WS (corresponding author), Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100049, Peoples R China.; Tang, YQ; Zhang, WS (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Multimodal Artificial Intelligence S, Beijing 100190, Peoples R China.
EM yongqiang.tang@ia.ac.cn; zhangwenshengia@hotmail.com
FU National Key R&D Program of China [2021ZD0113601]; National Natural
   Science Foundation of China [62106266, 62006139, 62173328, 62206293]
FX Acknowledgements This work is supported in part by the National Key R&D
   Program of China (No. 2021ZD0113601) and in part by the National Natural
   Science Foundation of China (No. 62106266, No. 62006139, No. 62173328
   and No. 62206293) .
CR Afham M, 2022, PROC CVPR IEEE, P9892, DOI 10.1109/CVPR52688.2022.00967
   [Anonymous], 2017, AUTOMATIC DIFFERENTI
   Arandjelovic R, 2017, IEEE I CONF COMP VIS, P609, DOI 10.1109/ICCV.2017.73
   Chen T, 2020, Arxiv, DOI [arXiv:2002.05709, DOI 10.48550/ARXIV.2002.05709]
   Chen T, 2020, Arxiv, DOI arXiv:2006.10029
   Chen XL, 2020, Arxiv, DOI arXiv:2003.04297
   Chen YX, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13339, DOI 10.1109/ICCV48922.2021.01311
   Cheng Y.-B., 2021, P 2 ACM INT C MULTIM, P1, DOI DOI 10.1145/3444685.3446289
   Chi HG, 2022, PROC CVPR IEEE, P20154, DOI 10.1109/CVPR52688.2022.01955
   Desai K, 2021, PROC CVPR IEEE, P11157, DOI 10.1109/CVPR46437.2021.01101
   Hjelm RD, 2019, Arxiv, DOI arXiv:1808.06670
   Ding XP, 2021, IEEE T IMAGE PROCESS, V30, P6869, DOI 10.1109/TIP.2021.3099407
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Freire-Obregón D, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-021-01264-9
   Gao XH, 2023, IEEE T MULTIMEDIA, V25, P405, DOI 10.1109/TMM.2021.3127040
   Guo TY, 2022, AAAI CONF ARTIF INTE, P762
   Hochreiter S., 2001, FIELD GUIDE DYNAMICA
   Huang J, 2022, IEEE T CIRC SYST VID, V32, P3475, DOI 10.1109/TCSVT.2021.3114209
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Kun Su, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9628, DOI 10.1109/CVPR42600.2020.00965
   Li C, 2017, IEEE INT CONF MULTI
   Li LG, 2021, PROC CVPR IEEE, P4739, DOI 10.1109/CVPR46437.2021.00471
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Lin LL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2490, DOI 10.1145/3394171.3413548
   Liu J, 2018, IEEE T IMAGE PROCESS, V27, P1586, DOI 10.1109/TIP.2017.2785279
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu Y, 2022, IEEE T IMAGE PROCESS, V31, P1978, DOI 10.1109/TIP.2022.3147032
   Liu ZY, 2020, PROC CVPR IEEE, P140, DOI 10.1109/CVPR42600.2020.00022
   Lo Presti L, 2016, PATTERN RECOGN, V53, P130, DOI 10.1016/j.patcog.2015.11.019
   Misra I, 2020, PROC CVPR IEEE, P6706, DOI 10.1109/CVPR42600.2020.00674
   Morgado P, 2021, PROC CVPR IEEE, P12470, DOI 10.1109/CVPR46437.2021.01229
   Owens A, 2018, LECT NOTES COMPUT SC, V11210, P639, DOI 10.1007/978-3-030-01231-1_39
   Pan T, 2021, PROC CVPR IEEE, P11200, DOI 10.1109/CVPR46437.2021.01105
   Qiang Nie, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12364), P102, DOI 10.1007/978-3-030-58529-7_7
   Radford A, 2021, PR MACH LEARN RES, V139
   Rao HC, 2021, INFORM SCIENCES, V569, P90, DOI 10.1016/j.ins.2021.04.023
   Sariyildiz M.B., 2020, EUROPEAN C COMPUTER, P153
   Shi L, 2019, PROC CVPR IEEE, P7904, DOI 10.1109/CVPR.2019.00810
   Shi L, 2019, PROC CVPR IEEE, P12018, DOI 10.1109/CVPR.2019.01230
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Sun N, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104141
   Thoker FM, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1655, DOI 10.1145/3474085.3475307
   Tian YL, 2020, Arxiv, DOI arXiv:2005.10243
   van den Oord A, 2019, Arxiv, DOI arXiv:1807.03748
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vemulapalli R, 2016, PROC CVPR IEEE, P4471, DOI 10.1109/CVPR.2016.484
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Verma V, 2019, Arxiv, DOI arXiv:1806.05236
   Wang HQ, 2022, PROC CVPR IEEE, P16020, DOI 10.1109/CVPR52688.2022.01557
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang SY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13403, DOI 10.1109/ICCV48922.2021.01317
   Yang Y, 2022, IEEE T CIRC SYST VID, V32, P8623, DOI 10.1109/TCSVT.2022.3194350
   Zhang HY, 2018, Arxiv, DOI [arXiv:1710.09412, DOI 10.48550/ARXIV.1710.09412]
   Zheng NG, 2018, AAAI CONF ARTIF INTE, P2644
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou KY, 2021, Arxiv, DOI [arXiv:2104.02008, DOI 10.48550/ARXIV.2104.02008]
   Zhu R., 2021, PROC IEEECVF INT C C, P10306
NR 59
TC 3
Z9 3
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104689
DI 10.1016/j.imavis.2023.104689
EA MAY 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA I8AM1
UT WOS:001004957900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Mahmood, BA
   Kurnaz, S
AF Mahmood, Baraa Adil
   Kurnaz, Sefer
TI An investigational FW-MPM-LSTM approach for face recognition using
   defective data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Imperfect face data; Wavelet transform; Fractal model;
   MPM-LSTM
ID ALGORITHM
AB Facial recognition systems are based on the features and traits of the face, since the systems are classified as bio-metric systems. Additionally, they are founded on the image processing, machine vision and machine learning principles. From images, imperfect information is considered by face recognition systems. A variety of image re-construction mechanisms is vital in this situation in order to match faces. The proposed method calls for image enhancement at the pre-processing stage. Following the image segmentation and reconstruction stage, the best facial features are extracted using features such the eyes, cheeks, face area and lips. By means of fractal model and wavelet transform the operation is performed. Using the Moore Penrose Matrix, the LSTM neural net-work is then improved also known as the MPM-LSTM, to train and test the system. From experimental results, the outcomes show that the proposed methodology performs better than the contemporary techniques.(c) 2023 Published by Elsevier B.V.
C1 [Mahmood, Baraa Adil; Kurnaz, Sefer] Altinbas Univ, Dept Elect & Comp Engn, Istanbul, Turkiye.
C3 Altinbas University
RP Mahmood, BA (corresponding author), Altinbas Univ, Dept Elect & Comp Engn, Istanbul, Turkiye.
EM baraa.mahmood@ogr.altinbas.edu.tr; sefer.kurnaz@altinbas.edu.tr
CR Andersen SM, 2014, PERS INDIV DIFFER, V60, P36, DOI 10.1016/j.paid.2013.12.011
   Atawneh S, 2017, MULTIMED TOOLS APPL, V76, P18451, DOI 10.1007/s11042-016-3930-0
   Bah SM, 2020, ARRAY-NY, V5, DOI 10.1016/j.array.2019.100014
   Benuwa BB, 2020, SCI AFR, V7, DOI 10.1016/j.sciaf.2019.e00249
   Bukar AM, 2017, IET COMPUT VIS, V11, P650, DOI 10.1049/iet-cvi.2016.0486
   Chen J, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104214
   Deeba F, 2019, INT J ADV COMPUT SC, V10, P274
   Ding CX, 2017, PATTERN RECOGN, V66, P144, DOI 10.1016/j.patcog.2016.11.024
   Ding CX, 2015, IEEE T MULTIMEDIA, V17, P2049, DOI 10.1109/TMM.2015.2477042
   Jadhav Akshara, 2017, INTERRES J ENG TECHN, V04
   Kumar PM, 2019, CLUSTER COMPUT, V22, pS7733, DOI 10.1007/s10586-017-1323-4
   Li ZC, 2015, IEEE T PATTERN ANAL, V37, P2085, DOI 10.1109/TPAMI.2015.2400461
   Marcetic D, 2016, 2016 39TH INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1365, DOI 10.1109/MIPRO.2016.7522352
   Mohamed Kutty Naeema, 2017, Int J Adv Res Comput Sci Softw Eng, V7, P334
   Nisha MD., 2017, Int. J. Exp. Diabetes Res, V5, P297
   O'Connor B., 2013, INT J ARTIFICIAL INT, V4, P25, DOI DOI 10.5121/IJAIA.2013.4603
   Olk B, 2011, VISION RES, V51, P1659, DOI 10.1016/j.visres.2011.05.007
   Punjani Ali Akbar, 2017, INTERJ ADV RES COMPU, V6
   Richler JJ, 2011, VISION RES, V51, P333, DOI 10.1016/j.visres.2010.11.014
   Saypadith S, 2018, ASIAPAC SIGN INFO PR, P1318, DOI 10.23919/APSIPA.2018.8659751
   Tanaka JW, 2014, ATTEN PERCEPT PSYCHO, V76, P1000, DOI 10.3758/s13414-014-0628-0
   Taubert J, 2011, VISION RES, V51, P1273, DOI 10.1016/j.visres.2011.04.002
   Ugail H, 2018, VISUAL COMPUT, V34, P1243, DOI 10.1007/s00371-018-1494-x
   Zhang T, 2018, PATTERN RECOGN LETT, V107, P33, DOI 10.1016/j.patrec.2017.09.011
NR 24
TC 1
Z9 1
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2023
VL 132
AR 104644
DI 10.1016/j.imavis.2023.104644
EA FEB 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 9W3RM
UT WOS:000948997400001
DA 2024-07-18
ER

PT J
AU Gurpinar, C
   Takir, S
   Bicer, E
   Uluer, P
   Arica, N
   Kose, H
AF Gurpinar, Cemal
   Takir, Seyma
   Bicer, Erhan
   Uluer, Pinar
   Arica, Nafiz
   Kose, Hatice
TI Contrastive learning based facial action unit detection in children with
   hearing impairment for a socially assistive robot platform?
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Contrastive learning; Facial action unit detection; Child -robot
   interaction; Transfer learning; Domain adaptation; Covariate shift
ID EMOTION RECOGNITION; ATTENTION; NETWORK
AB This paper presents a contrastive learning-based facial action unit detection system for children with hearing im-pairments to be used on a socially assistive humanoid robot platform. The spontaneous facial data of children with hearing impairments was collected during an interaction study with Pepper humanoid robot, and tablet -based game. Since the collected dataset is composed of limited number of instances, a novel domain adaptation extension is applied to improve facial action unit detection performance, using some well-known labelled datasets of adults and children. Furthermore, since facial action unit detection is a multi-label classification prob-lem, a new smoothing parameter, beta, is introduced to adjust the contribution of similar samples to the loss func-tion of the contrastive learning. The results show that the domain adaptation approach using children's data (CAFE) performs better than using adult's data (DISFA). In addition, using the smoothing parameter beta leads to a significant improvement on the recognition performance. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Gurpinar, Cemal; Takir, Seyma; Bicer, Erhan; Kose, Hatice] Istanbul Tech Univ, Istanbul, Turkey.
   [Uluer, Pinar] Galatasaray Univ, Istanbul, Turkey.
   [Arica, Nafiz] Bahcesehir Univ, Istanbul, Turkey.
   [Arica, Nafiz] Piri Reis Univ, Istanbul, Turkey.
C3 Istanbul Technical University; Galatasaray University; Bahcesehir
   University; Piri Reis University
RP Gurpinar, C (corresponding author), Istanbul Tech Univ, Istanbul, Turkey.
EM gurpinarcemal@itu.edu.tr; takir21@itu.edu.tr; bicer21@itu.edu.tr;
   puluer@gsu.edu.tr; nafiz.arica@pirireis.edu.tr; hatice.kose@itu.edu.tr
RI Uluer, Pinar/AAA-4903-2020; Bicer, Erhan/HJZ-5024-2023; Kose,
   Hatice/C-6322-2013; TAKIR, Seyma/HKV-2995-2023
OI Uluer, Pinar/0000-0003-2923-6220; Kose, Hatice/0000-0003-4796-4766; 
FU NVIDIA
FX We gratefully acknowledge the support of NVIDIA Corporation with the
   donation of the Titan V and Jetson TX2 GPU used for this research. We
   are thankful for the Roborehab project team, mainly Prof. Duygun
   Erol-Barkana, and Assist.Prof. Selma Yilar for their support in the data
   collection.
CR Abdi J, 2018, BMJ OPEN, V8, DOI 10.1136/bmjopen-2017-018815
   Albiero V, 2018, IEEE IMAGE PROC, P2037, DOI 10.1109/ICIP.2018.8451267
   [Anonymous], 1998, KAROLINSKA DIRECTED
   [Anonymous], 2000, MONOGRAPH CODI UNPUB
   Baglayici Engin, 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12662), P36, DOI 10.1007/978-3-030-68790-8_4
   Barros Pablo, 2020, SN Comput Sci, V1, P321, DOI 10.1007/s42979-020-00325-6
   Bartl-Pokorny KD, 2021, IEEE ACCESS, V9, P165433, DOI 10.1109/ACCESS.2021.3132785
   Bell S, 2015, ACM T GRAPHIC, V34, DOI 10.1145/2766959
   Breuer R., 2017, A deep learning perspective on the origin of facial expressions. arXiv preprint arXiv:1705.01842, DOI DOI 10.48550/ARXIV.1705.01842
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Canal FZ, 2022, INFORM SCIENCES, V582, P593, DOI 10.1016/j.ins.2021.10.005
   Cano S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155166
   Chen YJ, 2021, IEEE ROBOT AUTOM LET, V6, P7619, DOI 10.1109/LRA.2021.3098944
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Corneanu C, 2018, LECT NOTES COMPUT SC, V11216, P309, DOI 10.1007/978-3-030-01258-8_19
   Dalvi C, 2021, IEEE ACCESS, V9, P165806, DOI 10.1109/ACCESS.2021.3131733
   Friesen W.V., 1978, FACIAL ACTION CODING, P3
   Gao XQ, 2010, J EXP CHILD PSYCHOL, V105, P98, DOI 10.1016/j.jecp.2009.09.001
   Ghosh S, 2021, PATTERN RECOGN LETT, V144, P13, DOI 10.1016/j.patrec.2021.01.012
   Goodfellow Ian J., 2013, Neural Information Processing. 20th International Conference, ICONIP 2013. Proceedings: LNCS 8228, P117, DOI 10.1007/978-3-642-42051-1_16
   Gudi A, 2015, IEEE INT CONF AUTOMA
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Hammal Z, 2017, INT CONF AFFECT, P216, DOI 10.1109/ACII.2017.8273603
   Hassouneh A., 2020, Inf. Med. Unlocked, V20, DOI DOI 10.1016/J.IMU.2020.100372
   Hu M, 2021, IEEE SIGNAL PROC LET, V28, P698, DOI 10.1109/LSP.2021.3063609
   Hu M, 2019, J VIS COMMUN IMAGE R, V59, P176, DOI 10.1016/j.jvcir.2018.12.039
   Jacob GM, 2021, PROC CVPR IEEE, P7676, DOI 10.1109/CVPR46437.2021.00759
   Kanero J, 2018, CHILD DEV PERSPECT, V12, P146, DOI 10.1111/cdep.12277
   Khan RA, 2019, IMAGE VISION COMPUT, V83-84, P61, DOI 10.1016/j.imavis.2019.02.004
   Leppänen JM, 2006, ADV CHILD DEV BEHAV, V34, P207, DOI 10.1016/S0065-2407(06)80008-X
   Li S, 2019, IEEE T IMAGE PROCESS, V28, P356, DOI 10.1109/TIP.2018.2868382
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Liu ZL, 2020, LECT NOTES COMPUT SC, V11962, P514, DOI 10.1007/978-3-030-37734-2_42
   Lobue V, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01532
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2015, PR MACH LEARN RES, V37, P97
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mohan K, 2021, NEURAL COMPUT APPL, V33, P9125, DOI 10.1007/s00521-020-05676-y
   Motiian S, 2017, Arxiv, DOI arXiv:1709.10190
   Ertugrul IO, 2019, FRONT COMP SCI-SWITZ, V1, DOI 10.3389/fcomp.2019.00011
   Ortac G, 2020, ACTA INFOLOGICA, V4, P1
   Qayyum A, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104375
   Rajan S, 2020, IET IMAGE PROCESS, V14, P1373, DOI 10.1049/iet-ipr.2019.1188
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
   Tsou YT, 2021, J DEAF STUD DEAF EDU, V26, P469, DOI 10.1093/deafed/enab022
   Uluer P, 2023, INT J SOC ROBOT, V15, P643, DOI 10.1007/s12369-021-00830-5
   Uluer P, 2020, IEEE ROMAN, P567, DOI 10.1109/RO-MAN47096.2020.9223534
   Utkin LV, 2019, Arxiv, DOI [arXiv:1911.07702, DOI 10.48550/ARXIV.1911.07702]
   Vaswani A, 2023, Arxiv, DOI [arXiv:1706.03762, DOI 10.48550/ARXIV.1706.03762, 10.48550/arXiv.1706.03762]
   Wang LF, 2022, IEEE COMPUT SOC CONF, P2469, DOI 10.1109/CVPRW56347.2022.00276
   Witherow MA, 2020, PROC SPIE, V11511, DOI 10.1117/12.2569454
   Witherow MA, 2019, PROC SPIE, V11139, DOI 10.1117/12.2530397
   Xia Y, 2017, IEEE INT CONF COMP V, P1673, DOI 10.1109/ICCVW.2017.196
   Zhang ZY, 1999, INT J PATTERN RECOGN, V13, P893, DOI 10.1142/S0218001499000495
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zheng Z., 2019, Human-computer interaction. Recognition and interaction technologies, P201
   Zhi RC, 2020, VISUAL COMPUT, V36, P1067, DOI 10.1007/s00371-019-01707-5
NR 62
TC 0
Z9 0
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104572
DI 10.1016/j.imavis.2022.104572
EA NOV 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500011
DA 2024-07-18
ER

PT J
AU Alsubai, S
   Hamdi, M
   Abdel-Khalek, S
   Alqahtani, A
   Binbusayyis, A
   Mansour, RF
AF Alsubai, Shtwai
   Hamdi, Monia
   Abdel-Khalek, Sayed
   Alqahtani, Abdullah
   Binbusayyis, Adel
   Mansour, Romany F.
TI Bald eagle search optimization with deep transfer learning enabled
   age-invariant face recognition model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Age invariant face recognition; Facial image analysis; Age progression;
   Deep transfer learning; Hyperparameter tuning
AB Facial aging variation is a challenging process in the design of face recognition system because of high intra-personal differences instigated by age progression. Age-invariant face recognition (AIFR) models find applicabil-ity in several real time applications such as criminal identification, missing person detection, and so on. The main issue is the high intra-personal disparities because of complicated and non-linear age progression process. An essential component of face recognition model is the extraction of important features from the facial images for reducing intrapersonal differences produced by illumination, expression, pose, age, etc. The recent advances of machine learning (ML) and deep learning (DL) models pave a way for effective design of AIFR models. In this view, this study presents a new Bald Eagle Search Optimization with Deep Transfer Learning Enabled AFIR (BESDTL-AIFR) model. The presented BESDTL-AIFR model primarily pre-processes the facial images to enhance the quality. Besides, the BESDTL-AIFR model utilizes Inception v3 model for learning high level deep features. Next, these features are passed into the optimal deep belief network (DBN) model for face recognition. Finally, the hyperparameters of the DBN model are optimally chosen by the use of BES algorithm. Experimentation analysis on challenging benchmark datasets pointed out the promising outcomes of the BESDTL-AIFR model compared to recent approaches. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Alsubai, Shtwai] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn & Sci, Dept Comp Sci, PO, Box 151, Al Kharj 11942, Saudi Arabia.
   [Hamdi, Monia] Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
   [Abdel-Khalek, Sayed] Taif Univ, Coll Sci, Dept Math, POB 11099, Taif 21944, Saudi Arabia.
   [Abdel-Khalek, Sayed] Sohag Univ, Fac Sci, Dept Math, Sohag, Egypt.
   [Alqahtani, Abdullah; Binbusayyis, Adel] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn & Sci, Al Kharj, Saudi Arabia.
   [Mansour, Romany F.] New Valley Univ, Fac Sci, Dept Math, El Kharga 72511, Egypt.
C3 Prince Sattam Bin Abdulaziz University; Princess Nourah bint Abdulrahman
   University; Taif University; Egyptian Knowledge Bank (EKB); Sohag
   University; Prince Sattam Bin Abdulaziz University
RP Hamdi, M (corresponding author), Princess Nourah bint Abdulrahman Univ, Coll Comp & Informat Sci, Dept Informat Technol, POB 84428, Riyadh 11671, Saudi Arabia.
EM Sa.alsubai@psau.edu.sa; mshamdi@pnu.edu.sa; sabotalb@tu.edu.sa;
   Aq.alqahtani@psau.edu.sa; a.binbusayyis@psau.edu.sa;
   romanyf@sci.nvu.edu.eg
RI Mansour, Romany F./AAB-6085-2021; Binbusayyis, Adel/AHA-0326-2022;
   Alqahtani, Abdullah Qunayfith/DWN-4582-2022; Alsubai,
   Shtwai/ABW-9013-2022; Hamdi, Monia/ABG-1263-2021
OI Mansour, Romany F./0000-0001-5857-8495; Alqahtani, Abdullah
   Qunayfith/0000-0002-2859-1629; Alsubai, Shtwai/0000-0002-6584-7400;
   Hamdi, Monia/0000-0003-3690-9868; Binbusayyis, Adel/0000-0001-9683-2175
FU Princess Nourah bint Abdulrahman University Researchers
   [PNURSP2022R125]; Princess Nourah bint Abdulrahman University, Riyadh,
   Saudi Arabia
FX This research was funded by Princess Nourah bint Abdulrahman University
   Researchers Supporting Project number (PNURSP2022R125) , Princess Nourah
   bint Abdulrahman University, Riyadh, Saudi Arabia.
CR Alsattar HA, 2020, ARTIF INTELL REV, V53, P2237, DOI 10.1007/s10462-019-09732-5
   Asif A, 2021, COMM COM INF SC, V1463, P101, DOI 10.1007/978-3-030-88113-9_8
   Boussaad L, 2022, INT J APPL METAHEURI, V13, DOI 10.4018/IJAMC.290540
   Boussaad L, 2022, J KING SAUD UNIV-COM, V34, P2975, DOI 10.1016/j.jksuci.2020.10.002
   Gai JB, 2021, MEASUREMENT, V185, DOI 10.1016/j.measurement.2021.110079
   Hou X., 2021, P IEEECVF INT C COMP, P3692
   Huang ZZ, 2021, PROC CVPR IEEE, P7278, DOI 10.1109/CVPR46437.2021.00720
   Li Y, 2018, PATTERN RECOGN, V75, P51, DOI 10.1016/j.patcog.2017.10.015
   Liu XH, 2020, SYMMETRY-BASEL, V12, DOI 10.3390/sym12010146
   Moustafa A.A., 2020, INT J ELECT COMPUT E, V10
   Moustafa AA, 2020, SIGNAL IMAGE VIDEO P, V14, P1027, DOI 10.1007/s11760-020-01635-1
   Okokpujie K., 2021, Bulletin of Electrical Engineering and Informatics, V10, P179, DOI [10.11591/eei.v10i1.2356, DOI 10.11591/EEI.V10I1.2356]
   Shakeel MS, 2019, PATTERN RECOGN, V93, P442, DOI 10.1016/j.patcog.2019.04.028
   Shao SY, 2017, CHIN J MECH ENG-EN, V30, P1347, DOI 10.1007/s10033-017-0189-y
   Sharma N, 2021, MULTIMED TOOLS APPL, V80, P33911, DOI 10.1007/s11042-021-11252-w
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tripathi RK, 2021, EXPERT SYST APPL, V175, DOI 10.1016/j.eswa.2021.114786
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xie JC, 2022, IEEE T INF FOREN SEC, V17, P399, DOI 10.1109/TIFS.2022.3142998
   Yan CG, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3472810
   Yousaf A, 2020, EXPERT SYST, V37, DOI 10.1111/exsy.12503
   Zhao J, 2022, IEEE T PATTERN ANAL, V44, P474, DOI 10.1109/TPAMI.2020.3011426
   US
NR 23
TC 12
Z9 13
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104545
DI 10.1016/j.imavis.2022.104545
EA SEP 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5S1KH
UT WOS:000874957400002
DA 2024-07-18
ER

PT J
AU Shahbazi, M
   Bayat, MH
   Tarvirdizadeh, B
AF Shahbazi, Mohammad
   Bayat, Mohammad Hosein
   Tarvirdizadeh, Bahram
TI A motion model based on recurrent neural networks for visual object
   tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Single -object tracking; Motion model; Long short-term memory; Recurrent
   neural network
ID SIAMESE
AB Object tracking algorithms typically leverage on either or both appearance and motion features of target(s). It is common in multi-object tracking to use both features, whereas the role of motion features in single-object trackers has less been explored. Based on the Long Short-Term Memory (LSTM) architecture of recurrent neural networks, we train a novel motion model to be incorporated into the off-the-shelf single-object trackers. The developed model predicts the target location in each frame based on the history of processed motion features in a few prior frames. This aids the tracking algorithm in dynamically updating the search region location, as apposed to static or probabilistic region settings. We incorporate the model into three state-of-the-art CNN-based trackers, namely GOTURN, SiamFC, and DiMP and illustrate the tracking performance enhancements on popular benchmarks. Significant improvements are achieved specially on the sequences rendering challeng-ing situations such as Low Resolution, Out-of-Plane Rotation, Motion Blur, Fast Motion, and Occlusion. The motion model has a low computational cost and complies with the real-time execution of the base trackers.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Bayat, Mohammad Hosein; Tarvirdizadeh, Bahram] Univ Tehran, Fac New Sci & Technol, Dept Mechatron Engn, Adv Serv Robots ASR Lab, Tehran, Iran.
   [Shahbazi, Mohammad] Iran Univ Sci & Technol, Sch Mech Engn, Tehran, Iran.
C3 University of Tehran; Iran University Science & Technology
RP Shahbazi, M (corresponding author), Iran Univ Sci & Technol, Sch Mech Engn, Tehran, Iran.
EM shahbazi@iust.ac.ir
RI Shahbazi, Mohammad/AAQ-6725-2020
OI Shahbazi, Mohammad/0000-0001-9479-6756
CR Babaee M, 2018, IEEE IMAGE PROC, P2715, DOI 10.1109/ICIP.2018.8451140
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bhat Goutam, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12368), P205, DOI 10.1007/978-3-030-58592-1_13
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Chu Q, 2017, IEEE I CONF COMP VIS, P4846, DOI 10.1109/ICCV.2017.518
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jia Y., 2014, P 22 ACM INT C MULT, P675
   Kalman R E., 1960, J BASIC ENG, V82, P35, DOI DOI 10.1115/1.3662552
   Kashiani H, 2019, IMAGE VISION COMPUT, V83-84, P17, DOI 10.1016/j.imavis.2019.02.003
   Kristan M., P IEEE INT C COMPUTE, P1949
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Milan A., 2016, ARXIV
   Milan A, 2017, AAAI CONF ARTIF INTE, P4225
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Qiu J, 2020, COMPUT VIS IMAGE UND, V195, DOI 10.1016/j.cviu.2020.102951
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sadeghian A, 2017, IEEE I CONF COMP VIS, P300, DOI 10.1109/ICCV.2017.41
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Wang YF, 2021, SYMMETRY-BASEL, V13, DOI 10.3390/sym13020266
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu YW, 2017, IEEE ACCESS, V5, P23969, DOI 10.1109/ACCESS.2017.2764419
   Xu JR, 2019, IEEE I CONF COMP VIS, P3987, DOI 10.1109/ICCV.2019.00409
NR 31
TC 9
Z9 9
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2022
VL 126
AR 104533
DI 10.1016/j.imavis.2022.104533
EA AUG 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5A4KL
UT WOS:000862857600002
DA 2024-07-18
ER

PT J
AU Durrant, A
   Leontidis, G
AF Durrant, Aiden
   Leontidis, Georgios
TI Hyperspherically regularized networks for self-supervision
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Self -supervised learning; Representation learning; Representation
   separability; Image classi fication
AB Bootstrap Your Own Latent (BYOL) introduced an approach to self-supervised learning avoiding the contrastive paradigm and subsequently removing the computational burden of negative sampling associated with such methods. However, we empirically find that the image representations produced under the BYOL's self -distillation paradigm are poorly distributed in representation space compared to contrastive methods. This work empirically demonstrates that feature diversity enforced by contrastive losses is beneficial to image repre-sentation uniformity when employed in BYOL, and as such, provides greater inter-class representation separabil-ity. Additionally, we explore and advocate the use of regularization methods, specifically the layer-wise minimization of hyperspherical energy (i.e. maximization of entropy) of network weights to encourage repre-sentation uniformity. We show that directly optimizing a measure of uniformity alongside the standard loss, or regularizing the networks of the BYOL architecture to minimize the hyperspherical energy of neurons can pro-duce more uniformly distributed and therefore better performing representations for downstream tasks. (c) 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Durrant, Aiden; Leontidis, Georgios] Univ Aberdeen, Dept Comp Sci, Aberdeen AB24 3UE, Scotland.
   [Durrant, Aiden; Leontidis, Georgios] Univ Aberdeen, Interdisciplinary Ctr Data, Aberdeen AB24 3UE, Scotland.
   [Durrant, Aiden; Leontidis, Georgios] Univ Aberdeen, AI, Aberdeen AB24 3UE, Scotland.
C3 University of Aberdeen; University of Aberdeen; University of Aberdeen
RP Durrant, A (corresponding author), Univ Aberdeen, Dept Comp Sci, Aberdeen AB24 3UE, Scotland.; Durrant, A (corresponding author), Univ Aberdeen, Interdisciplinary Ctr Data, Aberdeen AB24 3UE, Scotland.; Durrant, A (corresponding author), Univ Aberdeen, AI, Aberdeen AB24 3UE, Scotland.
EM a.durrant.20@abdn.ac.uk
OI Leontidis, Georgios/0000-0001-6671-5568
CR [Anonymous], 2018, ADV NEURAL INF PROCE
   Caron M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9630, DOI 10.1109/ICCV48922.2021.00951
   Caron Mathilde, 2020, 34 C NEUR INF PROC S, V33, P9912
   Chen TL, 2021, Advances in Neural Information Processing Systems, V34
   Chen XC, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207010
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Gidaris S, 2021, PROC CVPR IEEE, P6826, DOI 10.1109/CVPR46437.2021.00676
   Grill J.-B., 2020, P NEURIPS
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2020, C COMP VIS PATT REC, P2, DOI [DOI 10.1109/CVPR42600.2020.00975, 10.1109/CVPR42600.2020.00975]
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3065386
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li Q, 2020, INT J MACH LEARN CYB, V11, P2221, DOI 10.1007/s13042-020-01111-9
   Lin RM, 2020, PROC CVPR IEEE, P6916, DOI 10.1109/CVPR42600.2020.00695
   Richemond P.H., 2020, ARXIV201010241
   Shi H., 2020, ARXIV201110944
   Tarvainen A, 2017, ADV NEUR IN, V30
   Thomson JJ, 1904, PHILOS MAG, V7, P237, DOI 10.1080/14786440409463107
   Tian Y., 2020, NeurIPS, V33, P6827
   vandenOord Aaron, 2018, ARXIV180703748
   Wang T, 2020, INT C MACH LEARN, P9929, DOI DOI 10.1109/CVPR.2019.00516
   Xu JC, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P4503
   Zbontar J, 2021, PR MACH LEARN RES, V139
   Zhang Y., 2022, IMAGE VIS COMPUT
NR 25
TC 3
Z9 3
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104494
DI 10.1016/j.imavis.2022.104494
EA JUL 2022
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3F6VI
UT WOS:000830804100005
OA hybrid, Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Zhang, J
   Li, W
   Li, ZX
AF Zhang, Jia
   Li, Wei
   Li, Zhixin
TI Distinguishing foreground and background alignment for unsupervised
   domain adaptative semantic segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic segmentation; Self -supervised learning; pseudo labels;
   Attention mechanism; Focal loss
AB Unsupervised domain adaptive semantic segmentation uses the knowledge learned from the labeled source domain dataset to guide the segmentation of the target domain. However, this domain migration method will cause a large inter-domain difference due to the different feature distributions between the source domain and the target domain. We use the self-supervised learning method to generate pseudo labels for the target domain, so that the corresponding pixels are directly aligned with the source domain according to the segmentation loss. Through observation, it is found that the spatial distribution of the background class in the source domain and the target domain has a small difference, and the appearance of the same class of the foreground class will also be quite different. We use the method of distinguishing alignment between foreground and background classes. We understand that acquiring the rich space and channel information on the feature map during the convolution process is essential for fine-grained semantic segmentation. Therefore, in order to obtain the dependency relationship between the channels of the feature map and the spatial position information, we use a channel and spatial parallel attention module. This module enables the network to select and amplify valuable space and channel information from the global information and suppress useless information. In addition, we introduce focal loss to solve the problem of class imbalance in the data set. Experiments show that our method achieves better segmentation performance in unsupervised domain adaptive semantic segmentation. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhang, Jia; Li, Wei; Li, Zhixin] Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
C3 Guangxi Normal University
RP Li, ZX (corresponding author), Guangxi Normal Univ, Guangxi Key Lab Multisource Informat Min & Secur, Guilin 541004, Peoples R China.
EM lizx@gxnu.edu.cn
RI Li, Zhixin/ABI-9264-2022
OI Li, Zhixin/0000-0002-5313-6134
FU National Natural Science Foundation of China [61966004, 61866004];
   Guangxi Natural Science Foundation [2019GXNSFDA245018]; Guangxi "Bagui
   Scholar" Teams for Innovation and Research Project; Guangxi Talent
   Highland Project of Big Data Intelligence and Application, Guangxi
   Collaborative Innovation Center of Multi -source Information Integration
   and Intelligent Processing
FX This work is supported by the National Natural Science Foundation of
   China (Nos. 61966004, 61866004) , the Guangxi Natural Science Foundation
   (No. 2019GXNSFDA245018) , the Guangxi "Bagui Scholar" Teams for
   Innovation and Research Project, the Guangxi Talent Highland Project of
   Big Data Intelligence and Application, Guangxi Collaborative Innovation
   Center of Multi -source Information Integration and Intelligent
   Processing.
CR Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Chen MH, 2019, IEEE I CONF COMP VIS, P2090, DOI 10.1109/ICCV.2019.00218
   Chen YH, 2018, PROC CVPR IEEE, P7892, DOI 10.1109/CVPR.2018.00823
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Du L, 2019, IEEE I CONF COMP VIS, P982, DOI 10.1109/ICCV.2019.00107
   Haoran Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P642, DOI 10.1007/978-3-030-58568-6_38
   Hoffman J., INT C MACHINE LEARNI, P1989, DOI [10.1109/igarss39084.2020.9323650, DOI 10.1109/IGARSS39084.2020.9323650]
   Hoffman J, 2016, Arxiv, DOI arXiv:1612.02649
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang J., 2022, ADV NEURAL INF PROCE, V34, DOI [10.1109/cvpr42600.2020.00966, DOI 10.1109/CVPR42600.2020.00966]
   Huang J., 2020, P EUR C COMP VIS, P705
   Kang G., 2020, ARXIV PREPRINT ARXIV
   Laine S, 2017, Arxiv, DOI [arXiv:1610.02242, DOI 10.48550/ARXIV.1610.02242]
   Li YS, 2019, PROC CVPR IEEE, P6929, DOI 10.1109/CVPR.2019.00710
   Lin Tsung-Yi, 2020, IEEE Trans Pattern Anal Mach Intell, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Luo X, 2021, Arxiv, DOI arXiv:2106.12123
   Luo YW, 2019, IEEE I CONF COMP VIS, P6777, DOI 10.1109/ICCV.2019.00688
   Luo YW, 2019, PROC CVPR IEEE, P2502, DOI 10.1109/CVPR.2019.00261
   LV F, 2018, EUR C COMP VIS ECCV
   Ma HY, 2021, PROC CVPR IEEE, P4050, DOI 10.1109/CVPR46437.2021.00404
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Subhani M. N., 2020, P EUR C COMP VIS, P290
   Tsai YH, 2019, IEEE I CONF COMP VIS, P1456, DOI 10.1109/ICCV.2019.00154
   Tsai YH, 2018, PROC CVPR IEEE, P7472, DOI 10.1109/CVPR.2018.00780
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang Y., 2021, P IEEE CVF INT C COM, P9092
   Yang JH, 2020, AAAI CONF ARTIF INTE, V34, P12613
   Zhang H, 2019, PR MACH LEARN RES, V97
   Zheng ZD, 2021, INT J COMPUT VISION, V129, P1106, DOI 10.1007/s11263-020-01395-y
   Zhou QQ, 2020, IEEE T IMAGE PROCESS, V29, P7578, DOI 10.1109/TIP.2020.3004267
   Zhou QQ, 2019, IEEE T MULTIMEDIA, V21, P1183, DOI 10.1109/TMM.2018.2875360
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zou Y, 2018, LECT NOTES COMPUT SC, V11207, P297, DOI [10.1007/978-3-030-01219-9_, 10.1007/978-3-030-01219-9_18]
   Zou Y, 2019, IEEE I CONF COMP VIS, P5981, DOI 10.1109/ICCV.2019.00608
NR 38
TC 7
Z9 7
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104513
DI 10.1016/j.imavis.2022.104513
EA JUL 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3F6VI
UT WOS:000830804100006
DA 2024-07-18
ER

PT J
AU Stolberg-Larsen, J
   Sommer, S
AF Stolberg-Larsen, Jakob
   Sommer, Stefan
TI Atlas generative models and geodesic interpolation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Generative networks; Manifold learning; Manifold atlas; Geodesic
   interpolation
AB Generative neural networks have a well recognized ability to estimate underlying manifold structure of high di-mensional data. However, if a single latent space is used, it is not possible to faithfully represent a manifold with topology different from Euclidean space. In this work we define the general class of Atlas Generative Models (AGMs), models with hybrid discrete-continuous latent space that estimate an atlas on the underlying data man-ifold together with a partition of unity on the data space. We identify existing examples of models from various popular generative paradigms that fit into this class. Due to the atlas interpretation, ideas from non-linear latent space analysis and statistics, e.g. geodesic interpolation, which has previously only been investigated for models with simply connected latent spaces, may be extended to the entire class of AGMs in a natural way. We exemplify this by generalizing an algorithm for graph based geodesic interpolation to the setting of AGMs, and verify its per-formance experimentally.(c) 2022 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Stolberg-Larsen, Jakob; Sommer, Stefan] Univ Copenhagen, Dept Comp Sci, Copenhagen, Denmark.
C3 University of Copenhagen
RP Sommer, S (corresponding author), Univ Copenhagen, Dept Comp Sci, Copenhagen, Denmark.
EM sommer@di.ku.dk
RI Sommer, Stefan/G-3138-2013
OI Sommer, Stefan/0000-0001-6784-0328
FU Villum Foundation [00022924]; Novo Nordisk Foundation [NNF18OC0052000]
FX Thework presented in this paperwas supported by the VillumFoundation
   grant 00022924 and the Novo Nordisk Foundation grant NNF18OC0052000.
CR [Anonymous], 2018, ARXIV180300156
   Arvanitidis G., 2018, ICLR
   Chen NT, 2018, PR MACH LEARN RES, V84
   Chen NT, 2019, LECT NOTES COMPUT SC, V11728, P554, DOI 10.1007/978-3-030-30484-3_45
   Chen Xi, 2016, Advances in Neural Information Processing Systems (NIPS), V29
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Kingma D. P., 2014, arXiv
   Kingma DP, 2014, ADV NEUR IN, V27
   Kuhnel L., 2018, ARXIV180507632
   Makhzani A., 2016, 4 INT C LEARN REPR W
   Pineau E., 2018, ARXIV180608240
   Ramachandran Prajit, 2018, 6 INT C LEARN REPR W
   Schonsheck S., 2020, ARXIV191210094
   Shao H, 2018, IEEE COMPUT SOC CONF, P428, DOI 10.1109/CVPRW.2018.00071
   Spurr A., 2017, LECT NOTES COMPUTER, P119
   Tolstikhin I., 2018, 6 INT C LEARNING REP
   Xiao H., 2017, ARXIV170807747
NR 18
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104433
DI 10.1016/j.imavis.2022.104433
EA APR 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1F1NU
UT WOS:000794942300004
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Sunitha, G
   Geetha, K
   Neelakandan, S
   Pundir, AKS
   Hemalatha, S
   Kumar, V
AF Sunitha, Gurram
   Geetha, K.
   Neelakandan, S.
   Pundir, Aditya Kumar Singh
   Hemalatha, S.
   Kumar, Vinay
TI Intelligent deep learning based ethnicity recognition and classification
   using facial images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Ethnicity recognition; Facial analysis; Deep learning; Facial landmarks;
   Image classification; Parameter tuning
ID FACE; MODEL
AB Recently, computer vision-based face image analysis has sparked considerable interest in a variety of applications such as surveillance, security, biometrics and so on. The goal of the facial analysis was to derive facial soft biomet-rics such as identification, gender, age, ethnicity, expression and so on. Among these, ethnicity recognition re-mains a hot study topic, a major aspect of society with profound linkages to a variety of environmental and social concerns. The introduction of machine learning (ML) and deep learning (ML) technologies has proven ad-vantageous for effective ethnicity recognition and classification. In this regard, the IDL-ERCFI technique, which is based on intelligent DL, is designed in this paper. The IDL-ERCFI technique's purpose is to distinguish and classify ethnicity based on facial photos. The IDL-ERCFI technique uses face landmarks to align photos before sending them to the network. Furthermore, the proposed model employs an Exception network as a feature extractor. Be-cause the retrieved features are high-dimensional, the feature reduction procedure employs the principal com-ponent analysis (PCA) technique, which is effective in overcoming the "curse of dimensionality." Furthermore, the ethnicity classification procedure is carried out using an optimal kernel extreme learning machine (KELM), with parameter tuning of the KELM model carried out using the glow worm swarm optimization (GSO) tech-nique. A complete experimental analysis is carried out to demonstrate the superiority of the IDL-ERCFI technique over the other techniques.(c) 2022 Published by Elsevier B.V.
C1 [Sunitha, Gurram] Sree Vidyanikethan Engn Coll, Dept CSE, Tirupati, Andhra Pradesh, India.
   [Geetha, K.] SRM Inst Sci & Technol, Sch Comp, Dept Comp Technol, Kattankulathur, India.
   [Neelakandan, S.] RMK Engn Coll, Dept CSE, Gummidipoondi, India.
   [Pundir, Aditya Kumar Singh] Arya Coll Engn & Informat Technol, Dept ECE, Jaipur, Rajasthan, India.
   [Hemalatha, S.] Kongu Engn Coll, Dept Comp Applicat, Erode, India.
   [Kumar, Vinay] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
C3 SRM Institute of Science & Technology Chennai; R.M.K. Engineering
   College; Kongu Engineering College; GLA University
RP Neelakandan, S (corresponding author), RMK Engn Coll, Dept CSE, Gummidipoondi, India.
EM gurramsunitha@gmail.com; geethak5@srmist.edu.in; snksnk17@gmail.com;
   vinay.kumar@gla.ac.in
RI Sunitha, Gurram/AAS-2823-2020; Subramani, Neelakandan/AAQ-3136-2021;
   PUNDIR, ADITYA KUMAR SINGH/H-2778-2017
OI Sunitha, Gurram/0000-0002-3305-8167; Subramani,
   Neelakandan/0000-0001-8583-0019; PUNDIR, ADITYA KUMAR
   SINGH/0000-0002-6762-9263; S, Hemalatha/0000-0002-0738-9501
CR Ahmed A, 2008, LECT NOTES COMPUT SC, V5304, P69, DOI 10.1007/978-3-540-88690-7_6
   Ahmed MA, 2022, J KING SAUD UNIV-COM, V34, P4579, DOI 10.1016/j.jksuci.2020.11.029
   Al-Humaidan NA, 2021, IEEE ACCESS, V9, P50755, DOI 10.1109/ACCESS.2021.3069022
   Alafif T., 2017, IEEE INT C MACH LEAR
   AlBdairi AJA, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/6385281
   Anwar I, 2017, CYBERN INF TECHNOL, V17, P152, DOI 10.1515/cait-2017-0036
   Asha P, 2022, ENVIRON RES, V205, DOI 10.1016/j.envres.2021.112574
   Chen HL, 2016, NEUROCOMPUTING, V184, P131, DOI 10.1016/j.neucom.2015.07.138
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cyril CPD, 2021, CONCURRENT ENG-RES A, V29, P386, DOI 10.1177/1063293X211031485
   Darabant AS, 2021, MATHEMATICS-BASEL, V9, DOI 10.3390/math9020195
   Fu SY, 2014, IEEE T PATTERN ANAL, V36, P2483, DOI 10.1109/TPAMI.2014.2321570
   Greco A, 2020, MACH VISION APPL, V31, DOI 10.1007/s00138-020-01123-z
   Han H, 2018, IEEE T PATTERN ANAL, V40, P2597, DOI 10.1109/TPAMI.2017.2738004
   Jain DK, 2022, IEEE T IND INFORM, V18, P4884, DOI 10.1109/TII.2021.3138915
   Kalinga A.T.N., 2021, THESIS, P2021
   Kamalraj R, 2021, MEASUREMENT, V183, DOI 10.1016/j.measurement.2021.109804
   Kavitha T, 2022, INTERDISCIP SCI, V14, P113, DOI 10.1007/s12539-021-00467-y
   Khan K., 2021, ARXIV210402471
   Krishnanand KN, 2005, 2005 IEEE SWARM INTELLIGENCE SYMPOSIUM, P84
   Ma Z., 2016, MATH PROBL ENG, V2016
   Madhan E., 2020, Journal of Computational and Theoretical Nanoscience, V17, P2237, DOI DOI 10.1166/JCTN.2020.8877
   Matkowski W.M., 2020, 2020 IEEE INT JOINT, P1
   Neelakandan S, 2022, INTELL AUTOM SOFT CO, V32, P1617, DOI 10.32604/iasc.2022.022209
   Neelakandan S., 2020, Procedia Computer Science, V172, P145, DOI [10.1016/j.procs.2020.05.022, DOI 10.1016/J.PROCS.2020.05.022]
   Neelakandan S., 2020, J COMPUT THEOR NANOS, V17, P2230, DOI DOI 10.1166/JCTN.2020.8876
   Reshma G, 2022, INTELL AUTOM SOFT CO, V31, P621, DOI 10.32604/iasc.2022.019117
   Seidenari L, 2019, MACH VISION APPL, V30, P359, DOI 10.1007/s00138-018-0991-2
   Sukumaran A, 2020, INT J INTELL COMPUT, V13, P365, DOI 10.1108/IJICC-03-2020-0020
   Vo T, 2018, SYMMETRY-BASEL, V10, DOI 10.3390/sym10110564
   Venu D, 2022, OPTIK, V252, DOI 10.1016/j.ijleo.2021.168545
   Wang M, 2019, IEEE I CONF COMP VIS, P692, DOI 10.1109/ICCV.2019.00078
   Wang Mei, 2021, CVPR2020
   Wong KO, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0241239
NR 34
TC 30
Z9 30
U1 4
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104404
DI 10.1016/j.imavis.2022.104404
EA MAR 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0N8RO
UT WOS:000783099100004
DA 2024-07-18
ER

PT J
AU Ding, GQ
   Imamoglu, N
   Caglayan, A
   Murakawa, M
   Nakamura, R
AF Ding, Guanqun
   Imamoglu, Nevrez
   Caglayan, Ali
   Murakawa, Masahiro
   Nakamura, Ryosuke
TI SalFBNet: Learning pseudo-saliency distribution via feedback
   convolutional networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feedback networks; Human gaze; Pseudo-saliency; Selective fixation and
   non-fixation error
ID VISUAL-ATTENTION
AB Feed-forward only convolutional neural networks (CNNs) may ignore intrinsic relationships and potential benefits of feedback connections in vision tasks such as saliency detection, despite their significant representation capabilities. In this work, we propose a feedback-recursive convolutional framework (SalFBNet) for saliency detection. The proposed feedback model can learn abundant contextual representations by bridging a recursive pathway from higher-level feature blocks to low-level layers. Moreover, we create a large-scale Pseudo-Saliency dataset to alleviate the problem of data deficiency in saliency detection. We first use the proposed feedback model to learn saliency distribution from pseudo-ground-truth. Afterwards, we fine-tune the feedback model on existing eye-fixation datasets. Furthermore, we present a novel Selective Fixation and Non-Fixation Error (sFNE) loss to facilitate the proposed feedback model to better learn distinguishable eye-fixation-based features. Extensive experimental results show that our SalFBNet with fewer parameters achieves competitive results on the public saliency detection benchmarks, which demonstrate the effectiveness of proposed feedback model and Pseudo-Saliency data.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Ding, Guanqun; Murakawa, Masahiro] Univ Tsukuba, Grad Sch Sci & Technol, Tsukuba, Ibaraki 3058577, Japan.
   [Ding, Guanqun; Imamoglu, Nevrez; Caglayan, Ali; Murakawa, Masahiro; Nakamura, Ryosuke] Natl Inst Adv Ind Sci & Technol, Tokyo 1350064, Japan.
C3 University of Tsukuba; National Institute of Advanced Industrial Science
   & Technology (AIST)
RP Ding, GQ; Imamoglu, N (corresponding author), Natl Inst Adv Ind Sci & Technol, Tokyo 1350064, Japan.
EM guanqun.ding@aist.go.jp; nevrez.imamoglu@aist.go.jp
RI Caglayan, Ali/AAF-1688-2020; Imamoglu, Nevrez/B-1746-2017
OI Caglayan, Ali/0000-0002-3408-8659; Guanqun, Ding/0000-0002-0199-4612;
   Imamoglu, Nevrez/0000-0002-2661-599X
CR [Anonymous], 2014, Advances in Neural Information Processing Systems
   Bruce N., 2010, Journal of Vision, V7, P950, DOI [10.1167/7.9.950, DOI 10.1167/7.9.950]
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338
   Che ZH, 2020, IEEE T IMAGE PROCESS, V29, P2287, DOI 10.1109/TIP.2019.2945857
   Chen JS, 2016, PROC CVPR IEEE, P507, DOI 10.1109/CVPR.2016.61
   Cheng M.-M., 2021, IEEE T PATT ANAL MAC, V1
   Cheng MM, 2014, VISUAL COMPUT, V30, P443, DOI 10.1007/s00371-013-0867-4
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Cornia M, 2016, LECT NOTES COMPUT SC, V9914, P302, DOI 10.1007/978-3-319-48881-3_21
   Deng X, 2021, IEEE T IMAGE PROCESS, V30, P3098, DOI 10.1109/TIP.2021.3058764
   Ding G., 17 INT C MACH VIS AP, P1
   Droste R., EUR C COMP VISIONSPR, P419
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Fan SJ, 2018, PROC CVPR IEEE, P7521, DOI 10.1109/CVPR.2018.00785
   Fang S, 2017, IEEE T NEUR NET LEAR, V28, P1095, DOI 10.1109/TNNLS.2016.2522440
   Fosco C., P IEEE CVF C COMP VI, P4473
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia S, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103887
   Jiang HZ, 2013, PROC CVPR IEEE, P2083, DOI 10.1109/CVPR.2013.271
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Judd T., 2012, A benchmark of computational models of saliency to predict human fixations
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim K., 2021, IEEE INT C COMP VIS, P6567
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kroner A, 2020, NEURAL NETWORKS, V129, P261, DOI 10.1016/j.neunet.2020.05.004
   Kümmerer M, 2018, LECT NOTES COMPUT SC, V11220, P798, DOI 10.1007/978-3-030-01270-0_47
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li PQ, 2021, NEUROCOMPUTING, V429, P199, DOI 10.1016/j.neucom.2020.10.083
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Li Z, 2019, PROC CVPR IEEE, P3862, DOI 10.1109/CVPR.2019.00399
   Linardos A., 2021, P IEEECVF INT C COMP, P12919
   Nguyen D.T., P 33 INT C NEUR INF, P204
   Pan J., 2017, PROC CVPR SCENE UNDE, P1
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Shi JP, 2016, IEEE T PATTERN ANAL, V38, P717, DOI 10.1109/TPAMI.2015.2465960
   Simonyan K, 2015, IEEE INT C ICLR
   Tartaglione G, 2021, INT J CONTROL, V94, P2252, DOI 10.1080/00207179.2019.1699667
   ummerer M. K, INT C LEARN REPR, P1
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang S, 2020, IEEE T MULTIMEDIA, V22, P2163, DOI 10.1109/TMM.2019.2947352
   Zamir A.R, P IEEE C COMP VIS PA, P1308
   Zhang DW, 2020, IEEE T PATTERN ANAL, V42, P1755, DOI 10.1109/TPAMI.2019.2900649
   Zhang J., 2020, IEEE T PATT ANAL MAC
   Zhang JM, 2013, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2013.26
NR 56
TC 12
Z9 14
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104395
DI 10.1016/j.imavis.2022.104395
EA FEB 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500004
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Tay, CP
   Yap, KH
AF Tay, Chiat-Pin
   Yap, Kim-Hui
TI Attribute saliency network for person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Person attribute; Attention or saliency map;
   Attribute learning
ID RECOGNITION
AB This paper proposes the Attribute Saliency Network (ASNet), a deep learning model that utilizes attribute and saliency map learning for person re-identification (re-ID) task. Many re-ID methods used human pose or local body parts, either fixed position or auto-learn, to guide the learning. Person attributes, though can describe a person in greater details, are seldom used in retrieving the person's images. We therefore propose to integrate the person attributes learning into the re-ID model, and let it learns together with the person identity networks. With this arrangement, there is a synergistic effect and thus better representations are encoded. In addition, both visual and text retrievals, such as query by clothing colors, hair length, etc., are possible. We also propose to improve the granularity of the heatmap, by generating two global person attributes and body part saliency maps to capture fine-grained details of the person and thus enhance the discriminative power of the encoded vectors. As a result, we are able to achieve state-of-the-art performances. On the Market1501 dataset, we achieve 90.5% mAP and 96.3% Rank 1 accuracy. On DukeMTMC-reID, we obtained 82.7% mAP and 90.6% Rank 1 accuracy. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Tay, Chiat-Pin; Yap, Kim-Hui] Nanyang Technol Univ, Singapore, Singapore.
C3 Nanyang Technological University
RP Tay, CP (corresponding author), Nanyang Technol Univ, Singapore, Singapore.
EM chiatpin001@e.ntu.edu.sg
OI Tay, Chiat Pin/0000-0002-4984-9780
CR Bazzani L, 2016, IEEE WINT CONF APPL, DOI 10.1109/wacv.2016.7477688
   Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Chen YH, 2018, PROC CVPR IEEE, P1189, DOI 10.1109/CVPR.2018.00130
   Choe J, 2019, PROC CVPR IEEE, P2214, DOI 10.1109/CVPR.2019.00232
   Cui Y, 2016, PROC CVPR IEEE, P1153, DOI 10.1109/CVPR.2016.130
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding C., 2020, IEEE T PATTERN ANAL, DOI [10.1109/TPAMI.2020.30249001-1, DOI 10.1109/TPAMI.2020.30249001-1]
   Figueira D., 2014, COMPUTER VISION ECCV, P241
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Güler RA, 2018, PROC CVPR IEEE, P7297, DOI 10.1109/CVPR.2018.00762
   Hao Y, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107533
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hoffer E, 2015, LECT NOTES COMPUT SC, V9370, P84, DOI 10.1007/978-3-319-24261-3_7
   Hou RB, 2019, PROC CVPR IEEE, P9309, DOI 10.1109/CVPR.2019.00954
   Ji Z, 2020, PATTERN RECOGN LETT, V138, P170, DOI 10.1016/j.patrec.2020.07.018
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li HF, 2021, IEEE T INF FOREN SEC, V16, P1480, DOI 10.1109/TIFS.2020.3036800
   Li HF, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107414
   Li JN, 2022, IEEE T PATTERN ANAL, V44, P622, DOI 10.1109/TPAMI.2019.2929036
   Li PK, 2022, IEEE T PATTERN ANAL, V44, P3260, DOI 10.1109/TPAMI.2020.3048039
   Li SZ, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107016
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li Y., 2020, J PHYS C SERIES
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Liao YY, 2016, IEEE INT CONF ROBOT, P2318, DOI 10.1109/ICRA.2016.7487381
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1109/PLASMA.2013.6634954, 10.1017/S1368980013002176]
   Lin YT, 2019, PATTERN RECOGN, V95, P151, DOI 10.1016/j.patcog.2019.06.006
   Liu G., IMAGE VISION COMPUT, V106
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Luo H, 2019, PATTERN RECOGN, V94, P53, DOI 10.1016/j.patcog.2019.05.028
   Nguyen BX, 2021, IEEE COMPUT SOC CONF, P3487, DOI 10.1109/CVPRW53098.2021.00388
   Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668
   Quan RJ, 2019, IEEE I CONF COMP VIS, P3749, DOI 10.1109/ICCV.2019.00385
   Raj SS, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103956
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun YF, 2020, PROC CVPR IEEE, P6397, DOI 10.1109/CVPR42600.2020.00643
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tay C.P., 2019, IEEE INT SYMP CIRC S, P1, DOI DOI 10.1109/iscas.2019.8702566
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Wang C, 2018, LECT NOTES COMPUT SC, V11208, P384, DOI 10.1007/978-3-030-01225-0_23
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang J, 2014, PROC CVPR IEEE, P1386, DOI 10.1109/CVPR.2014.180
   Wang JY, 2018, PROC CVPR IEEE, P2275, DOI 10.1109/CVPR.2018.00242
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang Z, 2020, IEEE T IMAGE PROCESS, V29, P2013, DOI 10.1109/TIP.2019.2946975
   Watson G, 2020, MULTIMED TOOLS APPL, V79, P6463, DOI 10.1007/s11042-019-08499-9
   Wei LH, 2019, IEEE T MULTIMEDIA, V21, P986, DOI 10.1109/TMM.2018.2870522
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu SH, 2019, INT J PAVEMENT ENG, V20, P33, DOI 10.1080/10298436.2016.1248204
   Yaghoubi E, 2021, PATTERN RECOGN LETT, V143, P50, DOI 10.1016/j.patrec.2020.12.017
   Yaghoubi E, 2020, IMAGE VISION COMPUT, V102, DOI 10.1016/j.imavis.2020.103981
   Yaghoubi E, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10165608
   Yang JW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1074, DOI 10.1145/3240508.3240645
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yu BS, 2018, LECT NOTES COMPUT SC, V11210, P71, DOI 10.1007/978-3-030-01231-1_5
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang ZZ, 2019, PROC CVPR IEEE, P667, DOI 10.1109/CVPR.2019.00076
   Zhao YR, 2019, PROC CVPR IEEE, P4908, DOI 10.1109/CVPR.2019.00505
   Zhao Y, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104000
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng M, 2018, IEEE COMPUT SOC CONF, P1974, DOI 10.1109/CVPRW.2018.00251
   Zheng Z., P IEEECVF C COMPUTER, P2138
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhou JM, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103931
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhou SP, 2019, IEEE I CONF COMP VIS, P8039, DOI 10.1109/ICCV.2019.00813
   Zhu XK, 2019, PATTERN RECOGN, V95, P211, DOI 10.1016/j.patcog.2019.06.007
NR 90
TC 2
Z9 2
U1 2
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104298
DI 10.1016/j.imavis.2021.104298
EA SEP 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WB1NI
UT WOS:000703345700004
DA 2024-07-18
ER

PT J
AU Li, RC
   Wu, XJ
   Wu, C
   Xu, TY
   Kittler, J
AF Li, Rong-Chang
   Wu, Xiao-Jun
   Wu, Cong
   Xu, Tian-Yang
   Kittler, Josef
TI Dynamic information enhancement for video classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video classification; Spatiotemporal modelling; Explicitly encoding;
   Adaptive excitation
AB How to extract and integrate spatiotemporal information for video classification is a major challenge. Advanced approaches adopt 2D, and 3D convolution kernels, or their variants as a basis of a spatiotemporal modeling process. However, 2D convolution kernels perform poorly along the temporal dimension, while 3D convolution kernels tend to create confusion between the spatial and temporal sources of information, with an increased risk of explosion of the number of model parameters. In this paper, we develop a more explicit way to improve the spatiotemporal modeling capacity of a 2D convolution network, which integrates two components: (1) Using Motion Intensification Block (MIB) to mandate a specific subset of channels to explicitly encode temporal clues to complement the spatial patterns extracted by other channels, achieving controlled diversity in the convolution calculations. (2) Using Spatial-temporal Squeeze-and-excitation (ST-SE) block to intensify the fused features reflecting the importance of different channels. In this manner, we improve the spatiotemporal dynamic information within the 2D backbone network, without performing complex temporal convolutions. To verify the effectiveness of the proposed approach, we conduct extensive experiments on challenging benchmarks. Our model achieves a competitive result on Something-Something V1, Something-Something V2, and a state-of-the-art performance on the Diving48 dataset, providing supporting evidence for the merits of the proposed methodology of spatiotemporal information encoding and fusion for video classification. (c) 2021 Published by Elsevier B.V.
C1 [Li, Rong-Chang; Wu, Xiao-Jun; Wu, Cong] Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
   [Xu, Tian-Yang; Kittler, Josef] Univ Surrey, Ctr Vis Speech & Signal Proc, Guildford GU2 7XH, Surrey, England.
C3 Jiangnan University; University of Surrey
RP Wu, XJ (corresponding author), Jiangnan Univ, Sch Artificial Intelligence & Comp Sci, Wuxi, Jiangsu, Peoples R China.
EM xiaojun_wu_jnu@163.com
RI Xu, Tianyang/AAE-1982-2019; Li, Rongchang/T-6425-2017
OI Xu, Tianyang/0000-0002-9015-3128; 
FU National Natural Science Foundation of China [U1836218, 62020106012,
   61902153]; 111 Project of Ministry of Education of China [B12018]; EPSRC
   Programme Grant (FACER2VM) [EP/N007743/1]; EPSRC/MURI/Dstl Project
   [EP/R013616/1]
FX This work was supported in part by the National Natural Science
   Foundation of China (U1836218, 62020106012, 61902153), the 111 Project
   of Ministry of Education of China (B12018), the EPSRC Programme Grant
   (FACER2VM) EP/N007743/1 and the EPSRC/MURI/Dstl Project under Grant
   EP/R013616/1.
CR Adeli V, 2019, IMAGE VISION COMPUT, V90, DOI 10.1016/j.imavis.2019.08.009
   Bertasius Gedas, 2018, ARXIV181204172
   Bottou Leon, 2012, Neural Networks: Tricks of the Trade. Second Edition: LNCS 7700, P421, DOI 10.1007/978-3-642-35289-8_25
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feichtenhofer C., 2016, ADV NEURAL INFORM PR, P3468
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Goyal R, 2017, IEEE I CONF COMP VIS, P5843, DOI 10.1109/ICCV.2017.622
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   He FX, 2019, IMAGE VISION COMPUT, V81, P34, DOI 10.1016/j.imavis.2018.12.002
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hu J., 2018, P IEEECVF C COMPUTER, P7132
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jiang BY, 2019, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2019.00209
   Kanojia G., P IEEE C COMP VIS PA, P0
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li X., P IEEE CVF C COMP VI, P1092
   Li Yingwei, 2018, P EUR C COMP VIS ECC
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Liu H., 2020 IEEE INT C IM P, P1801
   Liu ZY, 2020, AAAI CONF ARTIF INTE, V34, P11669
   Luo CX, 2019, IEEE I CONF COMP VIS, P5511, DOI 10.1109/ICCV.2019.00561
   Mahdisoltani F., 2018, ARXIV PREPRINT ARXIV
   Martinez B, 2019, IEEE I CONF COMP VIS, P5481, DOI 10.1109/ICCV.2019.00558
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ramachandran P., 2017, CoRR
   Roy AG, 2018, LECT NOTES COMPUT SC, V11070, P421, DOI 10.1007/978-3-030-00928-1_48
   Simonyan K, 2014, ADV NEUR IN, V27
   Szegedy C., 2015, P IEEE C COMP VIS PA, P1
   Tran D, 2018, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2018.00675
   Wang H., P IEEE CVF C COMP VI, P352
   Wang L., 2016, P ECCV
   Wang XL, 2018, LECT NOTES COMPUT SC, V11209, P413, DOI 10.1007/978-3-030-01228-1_25
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2018, LECT NOTES COMPUT SC, V11219, P318, DOI 10.1007/978-3-030-01267-0_19
   Yang C., P IEEE CVF C COMP VI, P591
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang BW, 2016, PROC CVPR IEEE, P2718, DOI 10.1109/CVPR.2016.297
   Zhou BL, 2018, LECT NOTES COMPUT SC, V11205, P831, DOI 10.1007/978-3-030-01246-5_49
   Zhu X., P IEEE INT C COMP VI, P3494
   Zolfaghari M, 2018, LECT NOTES COMPUT SC, V11206, P713, DOI 10.1007/978-3-030-01216-8_43
   Zong M, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104108
NR 45
TC 2
Z9 2
U1 5
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2021
VL 114
AR 104244
DI 10.1016/j.imavis.2021.104244
EA AUG 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UR9HP
UT WOS:000697051200006
DA 2024-07-18
ER

PT J
AU Wang, ZQ
   Liu, Z
   Wei, WJ
   Duan, HZ
AF Wang, Ziqiang
   Liu, Zhi
   Wei, Weijie
   Duan, Huizhan
TI SalED: Saliency prediction with a pithy encoder-decoder architecture
   sensing local and global information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Saliency prediction; Fixation prediction; Convolutional neural networks;
   Encoder-decoder
ID VISUAL-ATTENTION; NEURAL-NETWORK; MODEL
AB This paper proposes a deep convolutional neural network with a concise and effective encoder-decoder architec-ture for saliency prediction. Local and global contextual features make a considerable contribution to saliency prediction. In order to integrate and exploit these features more thoroughly, in the proposed pithy architecture, we deploy a dense and global context connection structure between the encoder and decoder, after that, a multi-scale readout module is designed to process various information from the previous portion of the decoder with different parallel mapping relationships for full-scale accurate results. Our model ranks first in light of multiple metrics on two famous saliency benchmarks and performs good generalization on other datasets. Besides, we evaluate the precision and the speed of our model with different backbones. The saliency prediction performance of VGGNet-Based, ResNet-based, and DenseNet-based model gradually increases while the speed also drops off. And the experiments illustrate that our model performs better than other models even if replacing the backbone of our model with the same backbone of the compared model. Therefore, we can provide optional versions of our model for different requirements of performance and efficiency.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wang, Ziqiang; Liu, Zhi; Wei, Weijie; Duan, Huizhan] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Wang, Ziqiang; Liu, Zhi; Wei, Weijie; Duan, Huizhan] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
RI wang, ziqiang/E-5993-2016; LIU, Zhi/D-4518-2012
OI LIU, Zhi/0000-0002-8428-1131; Wang, Ziqaing/0000-0002-4083-5411
FU National Natural Science Foundation of China [61771301]
FX This work was supported by the National Natural Science Foundation of
   China under Grant No. 61771301.
CR [Anonymous], 2008, Advances in neural information processing systems
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], MIT Saliency Benchmark
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2017, ARXIV170101081
   [Anonymous], 2018, CAAI T INTELL TECHNO, DOI DOI 10.1049/trit.2018.1012
   Borji A, 2014, IEEE T SYST MAN CY-S, V44, P523, DOI 10.1109/TSMC.2013.2279715
   Bruce N., 2005, ADV NEURAL INFORM PR, V18, P155
   Bylinskii Z, 2019, IEEE T PATTERN ANAL, V41, P740, DOI 10.1109/TPAMI.2018.2815601
   Bylinskii Z, 2016, LECT NOTES COMPUT SC, V9909, P809, DOI 10.1007/978-3-319-46454-1_49
   Cerf M, 2009, J VISION, V9, DOI 10.1167/9.12.10
   Che ZH, 2020, IEEE T IMAGE PROCESS, V29, P2287, DOI 10.1109/TIP.2019.2945857
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Cornia M, 2016, INT C PATT RECOG, P3488, DOI 10.1109/ICPR.2016.7900174
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dodge SF, 2018, IEEE T IMAGE PROCESS, V27, P4080, DOI 10.1109/TIP.2018.2834826
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jetley S, 2016, PROC CVPR IEEE, P5753, DOI 10.1109/CVPR.2016.620
   Ji Z, 2019, IEEE I CONF COMP VIS, P5753, DOI 10.1109/ICCV.2019.00585
   Jia S., 2018, ARXIV180501047
   Jiang L, 2019, AAAI CONF ARTIF INTE, P8521
   Jiang M, 2015, PROC CVPR IEEE, P1072, DOI 10.1109/CVPR.2015.7298710
   Judd T, 2012, MIT TECHNICAL REPORT
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kingma D. P, 2015, International Conference on Learning Representations
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kroner A, 2020, NEURAL NETWORKS, V129, P261, DOI 10.1016/j.neunet.2020.05.004
   Kruthiventi SSS, 2017, IEEE T IMAGE PROCESS, V26, P4446, DOI 10.1109/TIP.2017.2710620
   Kümmerer M, 2017, IEEE I CONF COMP VIS, P4799, DOI 10.1109/ICCV.2017.513
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Li J, 2013, IEEE T PATTERN ANAL, V35, P996, DOI 10.1109/TPAMI.2012.147
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Lin M., 2014, P 2014 INT C LEARN R
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu N, 2018, IEEE T IMAGE PROCESS, V27, P3264, DOI 10.1109/TIP.2018.2817047
   Matthias Kummerer, 2015, INT C LEARN REPR
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Qi F, 2019, IEEE ACCESS, V7, P60428, DOI 10.1109/ACCESS.2019.2915630
   Reddy N., 2020, INT C INT ROB SYST
   Russell BC, 2008, INT J COMPUT VISION, V77, P157, DOI 10.1007/s11263-007-0090-8
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tavakoli HR, 2017, NEUROCOMPUTING, V244, P10, DOI 10.1016/j.neucom.2017.03.018
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang WG, 2018, PROC CVPR IEEE, P1711, DOI 10.1109/CVPR.2018.00184
   Wang WG, 2018, IEEE T IMAGE PROCESS, V27, P2368, DOI 10.1109/TIP.2017.2787612
   Yang S, 2020, IEEE T MULTIMEDIA, V22, P2163, DOI 10.1109/TMM.2019.2947352
   Zhang JM, 2016, IEEE T PATTERN ANAL, V38, P889, DOI 10.1109/TPAMI.2015.2473844
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
   Zhou F, 2020, IEEE T IMAGE PROCESS, V29, P8490, DOI 10.1109/TIP.2020.3016464
NR 59
TC 16
Z9 16
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104149
DI 10.1016/j.imavis.2021.104149
EA MAR 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600009
DA 2024-07-18
ER

PT J
AU Wang, RP
   Cui, Y
   Song, X
   Chen, K
   Fang, H
AF Wang, Ruiping
   Cui, Yong
   Song, Xiao
   Chen, Kai
   Fang, Hong
TI Multi-information-based convolutional neural network with attention
   mechanism for pedestrian trajectory prediction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth map; Pose; 2D-3D size information; Convolutional neural network;
   Trajectory prediction
ID MODELS
AB Predicting pedestrian trajectory is useful in many applications, such as autonomous driving and unmanned vehicles. However, it is a challenging task because of the complexity of the interactions among pedestrians and the environment. Most existing works employ long short-term memory networks to learn pedestrian behaviors, but their prediction accuracy is not good, and their computing speed is relatively slow. To tackle this problem, we propose a multi-information-based convolutional neural network (MI-CNN) to incorporate the historical trajectory, depth map, pose, and 2D-3D size information to predict the future trajectory of the pedestrian subject. After training, we evaluate our model on crowded videos in the public datasets MOT16 and MOT20. Experiments demonstrate that the proposed method outperforms state-of-the-art approaches both in prediction accuracy and computing speed.
   (c) 2021 Published by Elsevier B.V.
C1 [Wang, Ruiping; Cui, Yong; Chen, Kai] Beihang Univ BUAA, Sch Automat Sci & Elect Engn, Beijing, Peoples R China.
   [Song, Xiao] Beihang Univ BUAA, Sch Cyber Sci & Technol, Beijing, Peoples R China.
   [Fang, Hong] Sci & Technol Space Phys Lab, Beijing, Peoples R China.
C3 Beihang University; Beihang University
RP Song, X (corresponding author), Beihang Univ BUAA, Sch Cyber Sci & Technol, Beijing, Peoples R China.
EM songxiao@buaa.edu.cn
RI Alidadi, Mehdi/HJZ-0235-2023
OI Alidadi, Mehdi/0000-0001-5183-7829; Fang, Hong/0000-0001-9430-4408
FU National Key Research and Development Program of China [2018YFB1702703]
FX This work was supported by the National Key Research and Development
   Program of China under Grant 2018YFB1702703.
CR Alahi A, 2017, COMPUT VIS PATT REC, P183, DOI 10.1016/B978-0-12-809276-7.00011-4
   Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   Bartoli F, 2018, INT C PATT RECOG, P1941, DOI 10.1109/ICPR.2018.8545447
   Belagiannis V., 2019, FORECASTING PEOPLE T
   Brazil G, 2019, IEEE I CONF COMP VIS, P9286, DOI 10.1109/ICCV.2019.00938
   Chen K, 2021, IEEE T CIRC SYST VID, V31, P1764, DOI 10.1109/TCSVT.2020.3013254
   Cheng B., 2019, Higherhrnet: Scale-aware representation learning for bottom-up human pose estimation
   Cheng B, 2018, J ENG-JOE, P1468, DOI 10.1049/joe.2018.8316
   Cheng H, 2018, LECT NOTES GEOINF CA, P309, DOI 10.1007/978-3-319-78208-9_16
   Coscia P, 2018, IMAGE VISION COMPUT, V69, P81, DOI 10.1016/j.imavis.2017.11.006
   Dendorfer P., ARXIV PREPRINT ARXIV, P1
   Ding M., 2019, Learning depth-guided convolutions for monocular 3d object detection
   Enzweiler M, 2010, PROC CVPR IEEE, P982, DOI 10.1109/CVPR.2010.5540110
   Gupta A, 2018, PROC CVPR IEEE, P2255, DOI 10.1109/CVPR.2018.00240
   Helbing D, 2000, NATURE, V407, P487, DOI 10.1038/35035023
   HELBING D, 1995, PHYS REV E, V51, P4282, DOI 10.1103/PhysRevE.51.4282
   Hug R., 2017, INT WORKSH REPR AN R, P20
   Liang JW, 2019, PROC CVPR IEEE, P5718, DOI 10.1109/CVPR.2019.00587
   Lin K, 2016, IEEE T AUTOM SCI ENG, V13, P1294, DOI 10.1109/TASE.2016.2543242
   Lu Y, 2019, IMAGE VISION COMPUT, V90, DOI 10.1016/j.imavis.2019.08.012
   Luo YF, 2018, IEEE ROBOT AUTOM LET, V3, P3418, DOI 10.1109/LRA.2018.2852793
   Manh H., 2018, ARXIV PREPRINT ARXIV, P1
   Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64
   Morris Brendan Tran, 2018, 2019 IEEE INT VEH S
   Niki P., 2017, ADV NEURAL INFORM PR
   Park SH, 2018, IEEE INT VEH SYM, P1672, DOI 10.1109/IVS.2018.8500658
   Raghu D., 2018, JCP, V13, P1127
   Reid I., 2016, ABS160300831 CORR, P1
   Rösmann C, 2017, IEEE ASME INT C ADV, P1255, DOI 10.1109/AIM.2017.8014190
   Rozo L, 2016, IEEE T ROBOT, V32, P513, DOI 10.1109/TRO.2016.2540623
   Sadeghian A, 2019, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2019.00144
   Saqib M, 2017, INT CONF IMAG VIS
   Song X, 2021, IEEE T INTELL TRANSP, V22, P3285, DOI 10.1109/TITS.2020.2981118
   Song X, 2019, IEEE T INTELL TRANSP, V20, P3142, DOI 10.1109/TITS.2018.2873118
   Song X, 2016, PHYSICA A, V447, P455, DOI 10.1016/j.physa.2015.12.041
   Srinivasaraghavan G., 2017, P NIPS, P1
   Tabuada P, 2005, IEEE T ROBOT, V21, P387, DOI 10.1109/TRO.2004.839224
   Vemula A., 2018, 2018 IEEE INT C ROB, P1
   Xu TH, 2016, IEEE T INTELL TRANSP, V17, P2385, DOI 10.1109/TITS.2016.2515063
   Xu YY, 2018, PROC CVPR IEEE, P5275, DOI 10.1109/CVPR.2018.00553
   Xue H., 2017, INT C DIG IM COMP TE, P1
   Xue H, 2018, IEEE WINT CONF APPL, P1186, DOI 10.1109/WACV.2018.00135
   Yao JX, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.103971
   Zhao CC, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107182
NR 44
TC 13
Z9 15
U1 7
U2 58
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104110
DI 10.1016/j.imavis.2021.104110
EA FEB 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RD1DC
UT WOS:000633227000008
DA 2024-07-18
ER

PT J
AU Zhu, YH
   Jiang, YZ
AF Zhu, Yinghui
   Jiang, Yuzhen
TI Optimization of face recognition algorithm based on deep learning multi
   feature fusion driven by big data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Big data; Face recognition; Deep learning; Multi-feature fusion
ID TRANSFORM; PCA
AB Today, with the rapid development of science and technology, the era of big data has been proposed and triggered reforms in all walks of life. Face recognition is a biometric recognition method with the characteristics of non-contact, non mandatory, friendly and harmonious, which has a good application prospect in the fields of national security and social security. With the deepening of the research on face recognition, small-scale face recognition has achieved good recognition results, but in the era of big data, the existing small-scale face recognition methods have gradually failed to meet the social needs, and how to get a good face recognition effect in the era of big data has become a new research hotspot. Based on this, this paper aims to optimize the existing face recognition algorithm, study the face recognition method driven by big data, and propose a deep learning multi feature fusion face recognition algorithm driven by big data. First, for the problem that 2DPCA (Two-dimensional Principle Component Analysis) can well extract the global features of the face under large samples, but the local features of the face are difficult to process, this paper uses the LBP (Local Binary Pattern, LBP) algorithm to extract the texture features of the face, and the extracted texture features are integrated with the global features extracted by 2DPCA to multi-feature fusion, so that the fused features can take into account both global and local features, and have better recognition results. Then using the obtained fusion features as input, training in a convolutional neural network, and measuring the similarity based on the feature vectors of the sample set and the training set after the training, can realize multi-feature fusion face recognition. Through the analysis of simulation experiments, it is found that, compared with the use of global features or local features alone, the fusion features obtained by multi-feature fusion of global features extracted by 2DPCA and local features extracted by LBP algorithm have better recognition effect in the big data environment. After convolutional neural network trains and recognizes this feature, a high recognition accuracy rate is obtained, which can show that the face recognition method designed in this paper has good application potential in the era of big data. In the background of big data, the accuracy of face recognition can reach more than 90%, which can meet the needs of society well. (c) 2020 Published by Elsevier B.V.
C1 [Zhu, Yinghui; Jiang, Yuzhen] Hanshan Normal Univ, Sch Comp & Informat Engn, Chaozhou, Guangdong, Peoples R China.
C3 Hanshan Normal University
RP Jiang, YZ (corresponding author), Hanshan Normal Univ, Sch Comp & Informat Engn, Chaozhou, Guangdong, Peoples R China.
EM jyz366@163.com
RI zhu, yinghui/AAJ-1436-2020
FU Teaching Quality and Teaching Reform Project of Guangdong
   Universities,China [191171-DXSSJJXJD-32]; Teaching ReformProject of
   Hanshan Normal University,China [[2019]67-2-10]; Research Project of
   Hanshan Normal University,China [XS201908]
FX The study was supported by "Teaching Quality and Teaching Reform Project
   of Guangdong Universities,China (Grant No.191171-DXSSJJXJD-32)" and
   "Teaching ReformProject of Hanshan Normal University,China (Grant
   No.[2019]67-2-10)" and "Research Project of Hanshan Normal
   University,China (Grant No. XS201908)".
CR ABHIJITGHOSH A, 2018, OPT SPECTROSC+, V124, P437
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Anbarasan M, 2020, COMPUT COMMUN, V150, P150, DOI 10.1016/j.comcom.2019.11.022
   Basavegowda HS, 2020, CAAI T INTELL TECHNO, V5, P22, DOI 10.1049/trit.2019.0028
   Bengio Y, 2017, NEURAL COMPUT, V29, P555, DOI 10.1162/NECO_a_00934
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Cheng GL, 2017, IEEE T GEOSCI REMOTE, V55, P3322, DOI 10.1109/TGRS.2017.2669341
   Fang YM, 2018, MULTIMED TOOLS APPL, V77, P29829, DOI 10.1007/s11042-018-5805-z
   Gardezi SJS, 2017, J MED IMAG HEALTH IN, V7, P30, DOI 10.1166/jmihi.2017.1982
   [郭继昌 Guo Jichang], 2018, [电子科技大学学报, Journal of University of Electronic Science and Technology of China], V47, P481
   Jiao JB, 2017, INT J COMPUT VISION, V124, P204, DOI 10.1007/s11263-017-1015-9
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee DS, 2016, IEEE T NETW SCI ENG, V3, P117, DOI 10.1109/TNSE.2016.2586848
   Li B, 2019, PATTERN RECOGN IMAGE, V29, P258, DOI 10.1134/S1054661819020044
   NAIKI T, 1995, BIORHEOLOGY, V32, P43
   Ortega-Zamorano F, 2017, NEURAL PROCESS LETT, V46, P899, DOI 10.1007/s11063-017-9655-x
   Park J, 2018, IEEE T MICROW THEORY, V66, P1644, DOI 10.1109/TMTT.2017.2772782
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Rafii Z, 2018, IEEE SIGNAL PROC MAG, V35, P88, DOI 10.1109/MSP.2018.2855727
   Saba L, 2017, J MED SYST, V41, DOI 10.1007/s10916-017-0745-0
   Toka O, 2018, COMMUN FAC SCI UNIV, V67, P1, DOI 10.1501/Commua1_0000000856
   Wang LP, 2017, PATTERN RECOGN, V63, P182, DOI 10.1016/j.patcog.2016.10.004
   Xu H, 2019, IEEE T CYBERNETICS, V49, P3968, DOI 10.1109/TCYB.2018.2856208
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang XB, 2017, ELECTR POW SYST RES, V146, P270, DOI 10.1016/j.epsr.2017.01.035
   Zhu F, 2017, J NANOELECTRON OPTOE, V12, P452, DOI 10.1166/jno.2017.2049
   2017, FLOW TURB COMBUST, V99, P25
NR 28
TC 25
Z9 25
U1 8
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104023
DI 10.1016/j.imavis.2020.104023
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800008
DA 2024-07-18
ER

PT J
AU Zhu, M
   Zhang, H
   Zhang, J
   Zhuo, L
AF Zhu, Mu
   Zhang, Hui
   Zhang, Jing
   Zhuo, Li
TI Multi-level prediction Siamese network for real-time UAV visual tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE UAV tracking; Small target; Feature fusion; Multi-level prediction
ID OBJECT TRACKING; BENCHMARK
AB Existing deployed Unmanned Aerial Vehicles (UAVs) visual trackers are usually based on the correlation filter framework. Although thesemethods have certain advantages of lowcomputational complexity, the tracking performance of small targets and fast motion scenarios is not satisfactory. In this paper, we present a novel multilevel prediction Siamese network (MLPS) for object tracking in UAV videos, which consists of Siamese feature extraction module and multi-level prediction module. The multi-level prediction module can make full use of the characteristics of each layer features to achieve robust evaluation of targets with different scales. Meanwhile, for small-size target tracking, we design a residual feature fusion block, which is used to constrain the low-level feature representation by using high-level abstract semantics, and obtain the improvement of the tracker's ability to distinguish scene details. In addition, we propose a layer attention fusion block which is sensitive to the informative features of each layers to achieve adaptive fusion of different levels of correlation responses by dynamically balancing the multi-layer features. Sufficient experiments on several UAV tracking benchmarks demonstrate that MLPS achieves state-of-the-art performance and runs at a speed over 97 FPS. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Zhu, Mu; Zhang, Hui; Zhang, Jing; Zhuo, Li] Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
   [Zhang, Hui; Zhang, Jing; Zhuo, Li] Beijing Univ Technol, Beijing Key Lab Computat Intelligence & Intellige, Beijing, Peoples R China.
C3 Beijing University of Technology; Beijing University of Technology
RP Zhang, H (corresponding author), Beijing Univ Technol, Fac Informat Technol, Beijing, Peoples R China.
EM zhumu@emails.bjut.edu.cn; huizhang@bjut.edu.cn; zhj@bjut.edu.cn;
   zhuoli@bjut.edu.cn
OI ZHANG, JING/0000-0003-1290-0738
FU National Natural Science Foundation of China [61602018, 61971016];
   Beijing Municipal Natural Science Foundation Cooperation Beijing
   Education Committee [KZ 201810005002]
FX The work in this paper is supported by the National Natural Science
   Foundation of China (No.61602018 and No.61971016), Beijing Municipal
   Natural Science Foundation Cooperation Beijing Education Committee (No.
   KZ 201810005002 and No. KZ 201910005007).
CR [Anonymous], 2015, CORR
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Chen ZD, 2020, PROC CVPR IEEE, P6667, DOI 10.1109/CVPR42600.2020.00670
   Cheng H, 2017, IEEE INT C INT ROBOT, P1732, DOI 10.1109/IROS.2017.8205986
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2017, IEEE T PATTERN ANAL, V39, P1561, DOI 10.1109/TPAMI.2016.2609928
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fan H, 2019, IEEE T IMAGE PROCESS, V28, P4130, DOI 10.1109/TIP.2019.2904789
   Fu CH, 2014, IEEE INT CONF ROBOT, P5441, DOI 10.1109/ICRA.2014.6907659
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Huang LH, 2021, IEEE T PATTERN ANAL, V43, P1562, DOI 10.1109/TPAMI.2019.2957464
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Huang ZY, 2019, IEEE I CONF COMP VIS, P2891, DOI 10.1109/ICCV.2019.00298
   Jung I, 2018, LECT NOTES COMPUT SC, V11208, P89, DOI 10.1007/978-3-030-01225-0_6
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li SY, 2017, AAAI CONF ARTIF INTE, P4140
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H, 2018, ADV ENERGY MATER, V8, DOI 10.1002/aenm.201701616
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Mueller M, 2016, LECT NOTES COMPUT SC, V9905, P445, DOI 10.1007/978-3-319-46448-0_27
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Possegger H, 2015, PROC CVPR IEEE, P2113, DOI 10.1109/CVPR.2015.7298823
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang GT, 2019, PROC CVPR IEEE, P3638, DOI 10.1109/CVPR.2019.00376
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang NY, 2015, IEEE I CONF COMP VIS, P3101, DOI 10.1109/ICCV.2015.355
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yan JH, 2018, J ELECTRON IMAGING, V27, DOI 10.1117/1.JEI.27.5.053010
   Yin YJ, 2016, IEEE T INSTRUM MEAS, V65, P510, DOI 10.1109/TIM.2015.2509318
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang TZ, 2017, PROC CVPR IEEE, P4819, DOI [10.1109/CVPR.2017.512, 10.1109/ICCV.2017.469]
   Zhang ZP, 2019, PROC CVPR IEEE, P4586, DOI 10.1109/CVPR.2019.00472
   Zhu Z, 2018, LECT NOTES COMPUT SC, V11213, P103, DOI 10.1007/978-3-030-01240-3_7
NR 50
TC 12
Z9 12
U1 2
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2020
VL 103
AR 104002
DI 10.1016/j.imavis.2020.104002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA OH7WK
UT WOS:000582804000010
DA 2024-07-18
ER

PT J
AU Gong, XP
   Liu, XB
   Li, YS
   Li, HY
AF Gong, Xiaopeng
   Liu, Xiabi
   Li, Yushuo
   Li, Huiyu
TI A novel co-attention computation block for deep learning based image
   co-segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visualco-attention; Imageco-segmentation; Deeplearning;
   Correlationcalculation; Averagepooling
ID COSEGMENTATION
AB The correlation between images is crucial for solving the image co-segmentation problem that is segmenting common and salient objects from a set of related images. This paper proposes a novel co-attention computation block to compute the visual correlation between images for improving the co-segmentation performance. Here 'co-attention' means that we obtain the co-attention features in encoded features of an image to guide the attention in another image. To this purpose, we firstly introduce top-k average pooling to compute the channel co-attention descriptor. Then we explore the correlation between features in different spatial positions to get the spatial co-attention descriptor. Finally, these two types of co-attention descriptors are multiplied to generate a fused one. We obtain such a fused co-attention descriptor for each image and use it to produce the co-attention augmented feature map for the following processing in the applications. We embed the proposed co-attention block into a U-shaped Siamese network for fulfilling the image co-segmentation. It is proven to be able to improve the performance effectively in the experiments. To our best knowledge, it leads to the currently best results on Internet dataset and iCoseg dataset. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Gong, Xiaopeng; Liu, Xiabi; Li, Yushuo; Li, Huiyu] Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Liu, XB (corresponding author), Beijing Inst Technol, Sch Comp Sci, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM liuxiabi@bit.edu.cn
FU National Natural Science Foundation of China [81171407]; Beijing
   Municipal Science and Technology Project [Z181100001918002]
FX This work was supported in part by National Natural Science Foundation
   of China [grant number 81171407] and the Beijing Municipal Science and
   Technology Project [grant number Z181100001918002].
CR [Anonymous], 2016, CITY SCAPES DATASET
   Batra D, 2010, PROC CVPR IEEE, P3169, DOI 10.1109/CVPR.2010.5540080
   Cech J, 2010, IEEE T PATTERN ANAL, V32, P1568, DOI 10.1109/TPAMI.2009.176
   Chai YN, 2012, LECT NOTES COMPUT SC, V7572, P794, DOI 10.1007/978-3-642-33718-5_57
   Corbetta M, 2002, NAT REV NEUROSCI, V3, P201, DOI 10.1038/nrn755
   Dai JF, 2013, IEEE I CONF COMP VIS, P1305, DOI 10.1109/ICCV.2013.165
   Faktor A, 2013, IEEE I CONF COMP VIS, P1297, DOI 10.1109/ICCV.2013.164
   Fu HZ, 2015, PROC CVPR IEEE, P4428, DOI 10.1109/CVPR.2015.7299072
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Han JW, 2018, IEEE T IMAGE PROCESS, V27, P1639, DOI 10.1109/TIP.2017.2781424
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Hochbaum DS, 2009, IEEE I CONF COMP VIS, P269, DOI 10.1109/ICCV.2009.5459261
   Hsu KJ, 2019, PROC CVPR IEEE, P8838, DOI 10.1109/CVPR.2019.00905
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu YT, 2018, LECT NOTES COMPUT SC, V11212, P56, DOI 10.1007/978-3-030-01237-3_4
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jerripothula KR, 2017, PROC CVPR IEEE, P3881, DOI 10.1109/CVPR.2017.413
   Jerripothula KR, 2016, IEEE T MULTIMEDIA, V18, P1896, DOI 10.1109/TMM.2016.2576283
   Jia X, 2015, IEEE I CONF COMP VIS, P2407, DOI 10.1109/ICCV.2015.277
   Joulin A, 2010, PROC CVPR IEEE, P1943, DOI 10.1109/CVPR.2010.5539868
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Kim E, 2012, PROC CVPR IEEE, P686, DOI 10.1109/CVPR.2012.6247737
   Kim G, 2012, PROC CVPR IEEE, P837, DOI 10.1109/CVPR.2012.6247756
   Kim G, 2011, IEEE I CONF COMP VIS, P169, DOI 10.1109/ICCV.2011.6126239
   Kolmogorov V., 2006, P IEEE CVPR, V1, P993, DOI DOI 10.1109/CVPR.2006.91
   Lee C, 2015, PROC CVPR IEEE, P3837, DOI 10.1109/CVPR.2015.7299008
   Li Weihao, 2018, ASIAN C COMPUT VIS, P638
   Li Y, 2016, NEUROCOMPUTING, V172, P225, DOI 10.1016/j.neucom.2014.12.110
   Liang XP, 2017, NEUROCOMPUTING, V247, P126, DOI 10.1016/j.neucom.2017.03.060
   Liu Z, 2014, NEUROCOMPUTING, V135, P107, DOI 10.1016/j.neucom.2013.12.050
   Ma JZ, 2017, IEEE T IMAGE PROCESS, V26, P1216, DOI 10.1109/TIP.2016.2631883
   Meng FM, 2016, COMPUT VIS IMAGE UND, V146, P67, DOI 10.1016/j.cviu.2016.02.004
   Meng FM, 2013, IEEE T CYBERNETICS, V43, P725, DOI 10.1109/TSMCB.2012.2215316
   Meng FM, 2012, IEEE T MULTIMEDIA, V14, P1429, DOI 10.1109/TMM.2012.2197741
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Mukherjee Lopamudra, 2011, Proc IEEE Comput Soc Conf Comput Vis Pattern Recognit, P1881, DOI 10.1109/CVPR.2011.5995420
   Mukherjee L, 2009, PROC CVPR IEEE, P2028, DOI 10.1109/CVPRW.2009.5206652
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Oh SW, 2018, PROC CVPR IEEE, P7376, DOI 10.1109/CVPR.2018.00770
   Quan R, 2016, PROC CVPR IEEE, P687, DOI 10.1109/CVPR.2016.81
   Rubinstein M, 2013, PROC CVPR IEEE, P1939, DOI 10.1109/CVPR.2013.253
   Rubio JC, 2012, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2012.6247745
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Sun J, 2013, IEEE I CONF COMP VIS, P3400, DOI 10.1109/ICCV.2013.422
   Taniai T, 2016, PROC CVPR IEEE, P4246, DOI 10.1109/CVPR.2016.460
   Tao ZQ, 2017, AAAI CONF ARTIF INTE, P4285
   Vicente S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2217, DOI 10.1109/CVPR.2011.5995530
   Wang C, 2017, IEEE T IMAGE PROCESS, V26, P5825, DOI 10.1109/TIP.2017.2750410
   Wang F, 2013, IEEE I CONF COMP VIS, P849, DOI 10.1109/ICCV.2013.110
   Wang WG, 2016, IEEE T MULTIMEDIA, V18, P1011, DOI 10.1109/TMM.2016.2545409
   Wang ZX, 2013, IEEE I CONF COMP VIS, P393, DOI 10.1109/ICCV.2013.56
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yuan ZH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3371
   Zhu HY, 2014, IEEE WINT CONF APPL, P485, DOI 10.1109/WACV.2014.6836062
NR 55
TC 9
Z9 10
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2020
VL 101
AR 103973
DI 10.1016/j.imavis.2020.103973
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NP4HG
UT WOS:000570137900007
DA 2024-07-18
ER

PT J
AU Fu, HC
   Zhang, YH
   Zhou, WN
   Wang, XF
   Zhang, HL
AF Fu, Hengcheng
   Zhang, Yihong
   Zhou, Wuneng
   Wang, Xiaofeng
   Zhang, Huanlong
TI Learning reliable-spatial and spatial-variation regularization
   correlation filters for visual tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Correlation filters; Visual tracking; Spatial regularization
ID OBJECT TRACKING; ROBUST
AB Single-object tracking is a significant and challenging computer vision problem. Recently, discriminative correlation filters (DCF) have shown excellent performance. But there is a theoretical defects that the boundary effect, caused by the periodic assumption of training samples, greatly limit the tracking performance. Spatially regularized DCF (SRDCF) introduces a spatial regularization to penalize the filter coefficients depending on their spatial location, which improves the tracking performance a lot. However, this simple regularization strategy implements unequal penalties for the target area filter coefficients, which makes the filter learn a distorted object appearance model. In this paper, a novel spatial regularization strategy is proposed, utilizing a reliability map to approximate the target area and to keep the penalty coefficients of relevant region consistent. Besides, we introduce a spatial variation regularization component that the second-order difference of the filter, which smooths changes of filter coefficients to prevent the filter over-fitting current frame. Furthermore, an efficient optimization algorithm called alternating direction method of multipliers (ADMM) is developed. Comprehensive experiments are performed on three benchmark datasets: OTB-2013, OTB-2015 and TempleColor-128, and our algorithm achieves a more favorable performance than several state-of-the-art methods. Compared with SRDCF, our approach obtains an absolute gain of 6.6% and 5.1% in mean distance precision on OTB-2013 and OTB-2015, respectively. Our approach runs in real-time on a CPU. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Fu, Hengcheng; Zhang, Yihong; Zhou, Wuneng; Wang, Xiaofeng] Donghua Univ, Coll Informat Sci & Technol, Shanghai 201620, Peoples R China.
   [Zhang, Huanlong] Zhengzhou Univ Light Ind, Coll Elect & Informat Engn, 5 Dongfeng Rd, Zhengzhou, Peoples R China.
C3 Donghua University; Zhengzhou University of Light Industry
RP Zhang, YH; Zhou, WN (corresponding author), Donghua Univ, Coll Informat Sci & Technol, Shanghai 201620, Peoples R China.
EM 2181342@mail.dhu.edu.cn; zhangyh@dhu.edu.cn; wnzhou@dhu.edu.cn;
   xiaofeng_wang@dhu.edu.cn
OI Wang, Xiaofeng/0000-0002-8134-0917
FU National Natural Science Foundation of China [61573095, 61903077,
   61873246]; Special Project Funding for the Shanghai Municipal Commission
   of Economy and Information Civil-Military Inosculation Project; Shanghai
   Sailing Program [19YF1402500]
FX This work is partially supported by the National Natural Science
   Foundation of China (Nos. 61573095, 61903077, 61873246), the Special
   Project Funding for the Shanghai Municipal Commission of Economy and
   Information Civil-Military Inosculation Project (No. JMRH-2018-1042) and
   the Shanghai Sailing Program (No. 19YF1402500). Also, we are very
   grateful to editors and reviewers for their insightful comments and
   suggestions.
CR [Anonymous], P COMP VIS PATT REC
   [Anonymous], P COMP VIS PATT REC
   [Anonymous], 2006, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2006.215
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bai YC, 2012, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2012.6247884
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan Martin, 2014, P BRIT MACH VIS C 20
   De la Torre F, 2003, INT J COMPUT VISION, V54, P117, DOI 10.1023/A:1023709501986
   Galoogahi HK, 2015, PROC CVPR IEEE, P4630, DOI 10.1109/CVPR.2015.7299094
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Ho J, 2004, PROC CVPR IEEE, P782
   Hong S, 2015, PR MACH LEARN RES, V37, P597
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Hu WM, 2015, IEEE T PATTERN ANAL, V37, P816, DOI 10.1109/TPAMI.2014.2353628
   Hu WM, 2012, IEEE T PATTERN ANAL, V34, P2420, DOI 10.1109/TPAMI.2012.42
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Liang PP, 2015, IEEE T IMAGE PROCESS, V24, P5630, DOI 10.1109/TIP.2015.2482905
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Mueller M, 2017, PROC CVPR IEEE, P1387, DOI 10.1109/CVPR.2017.152
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Ning JF, 2016, PROC CVPR IEEE, P4266, DOI 10.1109/CVPR.2016.462
   Qi YK, 2018, IEEE T IMAGE PROCESS, V27, P3857, DOI 10.1109/TIP.2018.2797482
   van de Weijer J, 2009, IEEE T IMAGE PROCESS, V18, P1512, DOI 10.1109/TIP.2009.2019809
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wang NY, 2013, IEEE I CONF COMP VIS, P657, DOI 10.1109/ICCV.2013.87
   Wang W, 2018, IEEE T CIRC SYST VID, V28, P1609, DOI 10.1109/TCSVT.2017.2684759
   Wang X, 2019, IEEE T CYBERNETICS, V49, P146, DOI 10.1109/TCYB.2017.2768570
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Zhang H., 2019, IEEE ACCESS, V7
   Zhang HL, 2019, IEEE ACCESS, V7, P168575, DOI 10.1109/ACCESS.2019.2954500
   Zhang HL, 2018, IEEE ACCESS, V6, P75383, DOI 10.1109/ACCESS.2018.2872524
   Zhang L, 2017, PROC CVPR IEEE, P5825, DOI 10.1109/CVPR.2017.617
   Zhang SP, 2013, NEUROCOMPUTING, V100, P31, DOI 10.1016/j.neucom.2011.11.031
   Zhang TZ, 2015, PROC CVPR IEEE, P150, DOI 10.1109/CVPR.2015.7298610
   Zhang X, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124685
   Zuo WM, 2019, IEEE T PATTERN ANAL, V41, P1158, DOI 10.1109/TPAMI.2018.2829180
NR 46
TC 8
Z9 9
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103869
DI 10.1016/j.imavis.2020.103869
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900014
DA 2024-07-18
ER

PT J
AU Yang, M
   Pei, MT
   Jia, YD
AF Yang, Min
   Pei, Mingtao
   Jia, Yunde
TI Online maximum a posteriori tracking of multiple objects using
   sequential trajectory prior
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Online multi-object tracking; Sequential trajectory prior; Maximum a
   posteriori; Data association
ID DATA ASSOCIATION; MULTIOBJECT TRACKING; APPEARANCE; MODEL
AB In this paper, we address the problem of online multi-object tracking based on the Maximum a Posteriori (MAP) framework. Given the observations up to the current frame, we estimate the optimal object trajectories via two MAP estimation stages: object detection and data association. By introducing the sequential trajectory prior. i.e., the prior information from previous frames about "good" trajectories. into the two MAP stages, the inference of optimal detections is refined and the association correctness between trajectories and detections is enhanced. Furthermore, the sequential trajectory prior allows the two MAP stages to interact with each other in a sequential manner, which jointly optimizes the detections and trajectories to facilitate online multi-object tracking. Compared with existing methods, our approach is able to alleviate the association ambiguity caused by noisy detections and frequent inter-object interactions without using sophisticated association likelihood models. The experiments on publicly available challenging datasets demonstrate that our approach provides superior tracking performance over state-of-the-art algorithms in various complex scenes. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Yang, Min; Pei, Mingtao; Jia, Yunde] Beijing Inst Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Pei, MT (corresponding author), Beijing Inst Technol, Beijing Lab Intelligent Informat Technol, Beijing 100081, Peoples R China.
EM peimt@bit.edu.cn
FU Natural Science Foundation of China (NSFC) [61972038, 61375044]; Key
   Laboratory of Advanced Information Science and Network Technology of
   Beijing [XDXX1601]
FX This work was supported in part by the Natural Science Foundation of
   China (NSFC) under grant nos. 61972038 and 61375044, and by the Key
   Laboratory of Advanced Information Science and Network Technology of
   Beijing (XDXX1601).
CR Andriluka M, 2008, PROC CVPR IEEE, P1873, DOI 10.1109/CVPR.2008.4587583
   [Anonymous], EUR C COMP VIS
   [Anonymous], IET COMPUT VIS
   Bae SH, 2014, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2014.159
   Bae SH, 2014, IEEE T IMAGE PROCESS, V23, P2820, DOI 10.1109/TIP.2014.2320821
   Benfold B, 2011, PROC CVPR IEEE
   Bernardin K, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/246309
   Bowman C, 2009, DIR DEV, P1, DOI 10.1596/978-0-8213-7909-7
   Breitenstein MD, 2011, IEEE T PATTERN ANAL, V33, P1820, DOI 10.1109/TPAMI.2010.232
   Chari V, 2015, PROC CVPR IEEE, P5537, DOI 10.1109/CVPR.2015.7299193
   Collins RT, 2014, LECT NOTES COMPUT SC, V8690, P298, DOI 10.1007/978-3-319-10605-2_20
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dehghan A, 2015, PROC CVPR IEEE, P4091, DOI 10.1109/CVPR.2015.7299036
   Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Ess A, 2008, PROC CVPR IEEE, P1857
   Geiger A, 2014, IEEE T PATTERN ANAL, V36, P1012, DOI 10.1109/TPAMI.2013.185
   Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   Luo WH, 2014, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2014.168
   McLaughlin N, 2015, IEEE T CYBERNETICS, V45, P1276, DOI 10.1109/TCYB.2014.2348314
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pirsiavash H, 2011, PROC CVPR IEEE, P1201, DOI 10.1109/CVPR.2011.5995604
   Possegger H, 2014, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2014.170
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   Shu G, 2012, PROC CVPR IEEE, P1815, DOI 10.1109/CVPR.2012.6247879
   Song XA, 2008, LECT NOTES COMPUT SC, V5304, P642, DOI 10.1007/978-3-540-88690-7_48
   Tang SY, 2015, PROC CVPR IEEE, P5033, DOI 10.1109/CVPR.2015.7299138
   Wang S., 2016, INT J COMPUT VISION, P1
   Wen LY, 2014, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2014.167
   Wu B, 2007, INT J COMPUT VISION, V75, P247, DOI 10.1007/s11263-006-0027-7
   Wu Z, 2012, PROC CVPR IEEE, P1948, DOI 10.1109/CVPR.2012.6247896
   Yang B, 2014, INT J COMPUT VISION, V107, P203, DOI 10.1007/s11263-013-0666-4
   Yoon JH, 2016, PROC CVPR IEEE, P1392, DOI 10.1109/CVPR.2016.155
   Yoon JH, 2015, IEEE WINT CONF APPL, P33, DOI 10.1109/WACV.2015.12
   Yuan Li, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2953, DOI 10.1109/CVPRW.2009.5206735
   Zhang L, 2008, INT C WAVEL ANAL PAT, P11, DOI 10.1109/ICWAPR.2008.4635742
NR 39
TC 5
Z9 5
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103867
DI 10.1016/j.imavis.2019.103867
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900010
DA 2024-07-18
ER

PT J
AU Singh, P
   Kadi, VSR
   Namboodiri, VP
AF Singh, Pravendra
   Kadi, Vinay Sameer Raja
   Namboodiri, Vinay P.
TI FALF ConvNets: Fatuous auxiliary loss based filter-pruning for efficient
   deep CNNs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Filter pruning; Model compression; Convolutional neural network; Image
   recognition; Deep learning
AB Obtaining efficient Convolutional Neural Networks (CNNs) are imperative to enable their application for a wide variety of tasks (classification, detection, etc.). While several methods have been proposed to solve this problem, we propose a novel strategy for solving the same that is orthogonal to the strategies proposed so far. We hypothesize that if we add a fatuous auxiliary task, to a network which aims to solve a semantic task such as classification or detection, the filters devoted to solving this frivolous task would not be relevant for solving the main task of concern. These filters could be pruned and pruning these would not reduce the performance on the original task. We demonstrate that this strategy is not only successful, it in fact allows for improved performance for a variety of tasks such as object classification, detection and action recognition. An interesting observation is that the task needs to be fatuous so that any semantically meaningful filters would not be relevant for solving this task. We thoroughly evaluate our proposed approach on different architectures (LeNet, VGG-16, ResNet, Faster RCNN, SSD-512, C3D, and MobileNet V2) and datasets (MNIST, CIFAR, ImageNet, GTSDB, COCO, and UCF101) and demonstrate its generalizability through extensive experiments. Moreover, our compressed models can be used at run-time without requiring any special libraries or hardware. Our model compression method reduces the number of FLOPS by an impressive factor of 6.03X and GPU memory footprint by more than 17X for VGG-16, significantly outperforming other state-of-the-art filter pruning methods. We demonstrate the usability of our approach for 3D convolutions and various vision tasks such as object classification, object detection, and action recognition. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Singh, Pravendra; Namboodiri, Vinay P.] Indian Inst Technol Kanpur, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
   [Kadi, Vinay Sameer Raja] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Kanpur; Carnegie Mellon University
RP Singh, P (corresponding author), Indian Inst Technol Kanpur, Dept Comp Sci & Engn, Kanpur, Uttar Pradesh, India.
EM psingh@iitk.ac.in; vkadi@andrew.cmu.edu; vinaypn@iitk.ac.in
RI Singh, Pravendra/ABC-9247-2020
OI Singh, Pravendra/0000-0003-1001-2219; Namboodiri,
   Vinay/0000-0001-5262-9722
CR [Anonymous], 2018, IJCAI
   [Anonymous], 1993, ADV NEURAL INFORM PR
   [Anonymous], 2017, P 31 C NEUR INF PROC
   [Anonymous], 2016, ARXIVI60207360
   [Anonymous], 2017, ICLR
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 2016, ADV NEURAL INFORM PR
   [Anonymous], 1990, Adv Neural Inform Process Syst.
   [Anonymous], 2014, P BRIT MACHINE VISIO
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Denton E, 2014, ADV NEUR IN, V27
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Han S., 2015, ARXIV151000149
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2234
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Houben S, 2013, IEEE INT C INTELL TR, P7, DOI 10.1109/ITSC.2013.6728595
   Hu Hengyuan, 2016, Network trimming: A data-driven neuron pruning approach towards efficient deep architectures
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang ZH, 2018, LECT NOTES COMPUT SC, V11220, P317, DOI 10.1007/978-3-030-01270-0_19
   Lebedev V, 2016, PROC CVPR IEEE, P2554, DOI 10.1109/CVPR.2016.280
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H., 2017, P ICLR
   Lin J, 2017, ADV NEUR IN, V30
   Lin SH, 2019, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR.2019.00290
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Luo J.-H., 2017, An entropy-based pruning method for cnn compression
   Luo J. -H., 2018, IEEE T PATTERN ANAL
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Miao H, 2017, PROC INT CONF DATA, P571, DOI 10.1109/ICDE.2017.112
   Mittal D, 2019, MACH VISION APPL, V30, P203, DOI 10.1007/s00138-018-01001-9
   Mittal D, 2018, IEEE WINT CONF APPL, P848, DOI 10.1109/WACV.2018.00098
   Neklyudov Kirill, 2017, P 31 INT C NEUR INF, V30, P6775, DOI 10.5555/3295222.3295422
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh P, 2019, IEEE WINT CONF APPL, P1166, DOI 10.1109/WACV.2019.00129
   Wen W, 2016, ADV NEUR IN, V29
   Ye Jianbo, 2018, INT C LEARN REPR
   Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
   Zhou H, 2016, LECT NOTES COMPUT SC, V9908, P662, DOI 10.1007/978-3-319-46493-0_40
NR 48
TC 14
Z9 14
U1 6
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103857
DI 10.1016/j.imavis.2019.103857
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lu, Y
   Kim, DW
   Kim, S
   Jung, SW
AF Lu, Yucheng
   Kim, Dong-Wook
   Kim, Sesong
   Jung, Seung-Won
TI Foreground extraction via dual-side cameras on a mobile device using
   long short-term trajectory analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dual-side cameras; Foreground extraction; Gaussian mixture model;
   Trajectory analysis
ID MOVING OBJECT DETECTION; DYNAMIC SCENES; SEGMENTATION
AB This paper presents a foreground extraction method for live-streaming videos using dual-side cameras on mobile devices. Compared to conventional methods, which estimate both foreground and background models from the front camera, the proposed method uses the rear camera to infer the reference background model. To this end, the short-term trajectory analysis is first performed to cluster point trajectories of the front camera, and then the long-term trajectory analysis is performed to compare the paths of the clustered trajectories with the reference path obtained from the rear camera. In particular, clusters having high correlation are classified as background using the Gaussian mixture model. Additionally, a pixel-wise segmentation map is obtained via graph-based segmentation. Experimental results show that the proposed method is robust under a variety of camera motion, outperforming state-of-the-art methods. Code and dataset can be found at https://github.com/YCL92/dualCamSeg. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Lu, Yucheng; Kim, Dong-Wook; Kim, Sesong; Jung, Seung-Won] Dongguk Univ, Dept Multimedia Engn, 30,Pildong Ro 1 Gil, Seoul, South Korea.
C3 Dongguk University
RP Jung, SW (corresponding author), Dongguk Univ, Dept Multimedia Engn, 30,Pildong Ro 1 Gil, Seoul, South Korea.
EM swjung83@dongguk.edu
RI Kim, Dong Wook/JCE-1975-2023; Lu, Yucheng/GQR-2077-2022
OI Jung, Seung-Won/0000-0002-0319-4467; Lu, Yucheng/0000-0003-2990-5252
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT Future Planning
   [NRF-2017R1D1A1A09000558]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Science, ICT Future Planning (NRF-2017R1D1A1A09000558).
CR [Anonymous], BMVC
   [Anonymous], 2013, P INT C MOB SYST APP
   [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   [Anonymous], ARXIV170901140
   Azmanova A, 2015, ROUTL ADV DEMOCRATIC, P1
   Bronshtein I.N., 2013, Handbook of Mathematics
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Dimitriou N, 2015, IMAGE VISION COMPUT, V36, P70, DOI 10.1016/j.imavis.2015.01.005
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Fragkiadaki K, 2012, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2012.6247883
   Jacob GM, 2017, IMAGE VISION COMPUT, V64, P10, DOI 10.1016/j.imavis.2017.05.002
   Jiyoung K., 2017, US Patent, Patent No. [9, 92017621812]
   Keuper M, 2015, IEEE I CONF COMP VIS, P3271, DOI 10.1109/ICCV.2015.374
   Lee DS, 2005, IEEE T PATTERN ANAL, V27, P827, DOI 10.1109/TPAMI.2005.102
   Lee KY, 2009, IEEE I CONF COMP VIS, P1397
   Lee YJ, 2011, IEEE I CONF COMP VIS, P1995, DOI 10.1109/ICCV.2011.6126471
   Lezama J., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3369, DOI 10.1109/CVPR.2011.6044588
   Li CL, 2015, PROC CVPR IEEE, P5519, DOI 10.1109/CVPR.2015.7299191
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Ma TY, 2012, PROC CVPR IEEE, P670, DOI 10.1109/CVPR.2012.6247735
   Märki N, 2016, PROC CVPR IEEE, P743, DOI 10.1109/CVPR.2016.87
   McLachlan G., 2004, FINITE MIXTURE MODEL
   Mittal A, 2004, PROC CVPR IEEE, P302
   Mittal A, 2009, COMPUT VIS IMAGE UND, V113, P63, DOI 10.1016/j.cviu.2008.07.004
   Musatenko Y.S., 2014, US Patent App, Patent No. [13 (/729), 137292014211]
   Myers J. L., 2013, Research design and statistical analysis, DOI DOI 10.4324/9780203726631
   Narayana M, 2013, IEEE I CONF COMP VIS, P1577, DOI 10.1109/ICCV.2013.199
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Ochs P, 2012, PROC CVPR IEEE, P614, DOI 10.1109/CVPR.2012.6247728
   Papazoglou A, 2013, IEEE I CONF COMP VIS, P1777, DOI 10.1109/ICCV.2013.223
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   Sivan I., 2017, US Patent, Patent No. [9 (661), 96612017215]
   Sundaram N, 2010, LECT NOTES COMPUT SC, V6311, P438, DOI 10.1007/978-3-642-15549-9_32
   Venkatraman S., 2016, US Patent, Patent No. [9, 9330471]
   Wehrwein S., 2017, P BRIT MACH VIS C BM, P1
   Wenxin Liu, 2015, 2015 IEEE International Vacuum Electronics Conference (IVEC), P1, DOI 10.1109/IVEC.2015.7224043
   Xue YW, 2012, INT CONF ACOUST SPEE, P1485, DOI 10.1109/ICASSP.2012.6288171
   Yazdi M, 2018, COMPUT SCI REV, V28, P157, DOI 10.1016/j.cosrev.2018.03.001
   Zaitsev G., 2018, US Patent, Patent No. [9, 92018860452]
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 41
TC 1
Z9 1
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2019
VL 90
AR 103808
DI 10.1016/j.imavis.2019.08.012
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JU0WT
UT WOS:000501400600005
DA 2024-07-18
ER

PT J
AU Khan, RA
   Crenn, A
   Meyer, A
   Bouakaz, S
AF Khan, Rizwan Ahmed
   Crenn, Arthur
   Meyer, Alexandre
   Bouakaz, Saida
TI A novel database of children's spontaneous facial expressions
   (LIRIS-CSE)
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expressions database; Spontaneous expressions; Convolutional
   neural network; Expression recognition; Transfer learning
ID EMOTION RECOGNITION
AB Computing environment is moving towards human-centered designs instead of computer centered designs and human's tend to communicate wealth of information through affective states or expressions. Traditional Human Computer Interaction (HCI) based systems ignores bulk of information communicated through those affective states and just caters for user's intentional input. Generally, for evaluating and benchmarking different facial expression analysis algorithms, standardized databases are needed to enable a meaningful comparison. In the absence of comparative tests on such standardized databases it is difficult to find relative strengths and weaknesses of different facial expression recognition algorithms. In this article we present a novel video database for Children's Spontaneous facial Expressions (LIRIS-CSE). Proposed video database contains six basic spontaneous facial expressions shown by 12 ethnically diverse children between the ages of 6 and 12 years with mean age of 7.3 years. To the best of our knowledge, this database is first of its kind as it records and shows spontaneous facial expressions of children. Previously there were few database of children expressions and all of them show posed or exaggerated expressions which are different from spontaneous or natural expressions. Thus, this database will be a milestone for human behavior researchers. This database will be a excellent resource for vision community for benchmarking and comparing results. In this article, we have also proposed framework for automatic expression recognition based on Convolutional Neural Network (CNN) architecture with transfer learning approach. Proposed architecture achieved average classification accuracy of 75% on our proposed database i.e. LIRIS-CSE. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Khan, Rizwan Ahmed] Barrett Hodgson Univ, Fac IT, Karachi, Pakistan.
   [Khan, Rizwan Ahmed; Crenn, Arthur; Meyer, Alexandre; Bouakaz, Saida] Univ Claude Bernard Lyon1, LIRIS, Villeurbanne, France.
C3 Institut National des Sciences Appliquees de Lyon - INSA Lyon;
   Universite Claude Bernard Lyon 1
RP Khan, RA (corresponding author), Barrett Hodgson Univ, Fac IT, Karachi, Pakistan.; Khan, RA (corresponding author), Univ Claude Bernard Lyon1, LIRIS, Villeurbanne, France.
EM rizwan17@gmail.com
RI Khan, PhD, Rizwan Ahmed/N-7134-2018; Khan, Rizwan Hasan/F-8276-2014;
   Khan, Dr Rizwan/JQW-7885-2023
OI Khan, PhD, Rizwan Ahmed/0000-0003-0819-800X; Khan, Rizwan
   Hasan/0000-0002-9965-8982; MEYER, Alexandre/0000-0002-0249-1048
FU Region Auvergne-Rhone-Alpes, France
FX This work was funded by the Region Auvergne-Rhone-Alpes, France
   (http://www.auvergnerhonealpes.fr/).
CR [Anonymous], 2005, ICME
   [Anonymous], 31 AAAI C ART INT
   [Anonymous], COMP VIS PATT REC WO
   [Anonymous], INT JOINT C NEUR NET
   [Anonymous], 2014, VERY DEEP CONVOLUTIO
   [Anonymous], ARXIV171007557 CORR
   [Anonymous], ABS180308834 CORR
   [Anonymous], ARXIV18020359 CORR
   [Anonymous], TECH REP
   [Anonymous], 2015, NATURE, DOI [DOI 10.1038/NATURE14539, 10.1038/nature14539]
   [Anonymous], 2014, INT C LEARN REPR
   [Anonymous], ARXIV14126980 CORR
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], ARXIV180301164 CORR
   [Anonymous], 2010, INT LANG RES EV C
   [Anonymous], 2010, IEEE COMPUTER SOC C
   [Anonymous], 1976, Pictures of facial affect
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LF, 2018, INFORM SCIENCES, V428, P49, DOI 10.1016/j.ins.2017.10.044
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalrymple KA, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0079131
   Deng Jia, 2009, P CVPR
   Egger HL, 2011, INT J METH PSYCH RES, V20, P145, DOI 10.1002/mpr.343
   Ekman P., 1971, Nebraska symposium on motivation, V19, P207
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Khan RA, 2019, FRONT COMPUT SCI-CHI, V13, P183, DOI 10.1007/s11704-017-6114-9
   Khan RA, 2015, LECT NOTES COMPUT SC, V9475, P304, DOI 10.1007/978-3-319-27863-6_28
   Khan RA, 2013, PATTERN RECOGN LETT, V34, P1159, DOI 10.1016/j.patrec.2013.03.022
   Ko BC, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18020401
   LeCun Y, 2010, IEEE INT SYMP CIRC S, P253, DOI 10.1109/ISCAS.2010.5537907
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Lobue V, 2015, FRONT PSYCHOL, V5, DOI 10.3389/fpsyg.2014.01532
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Pantic M., 2006, Human Computing and Machine Understanding of Human Behavior: A Survey
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sullivan MW, 2003, INFANT YOUNG CHILD, V16, P120, DOI 10.1097/00001163-200304000-00005
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Widen SC, 2013, PSYCHOL BULL, V139, P271, DOI 10.1037/a0031640
   Zeiler M.D., European conference on computer vision, P818
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhou BL, 2018, IEEE T PATTERN ANAL, V40, P1452, DOI 10.1109/TPAMI.2017.2723009
NR 44
TC 42
Z9 43
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR-APR
PY 2019
VL 83-84
BP 61
EP 69
DI 10.1016/j.imavis.2019.02.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA HW6TR
UT WOS:000466824000006
OA Green Submitted, Bronze
DA 2024-07-18
ER

PT J
AU Nappi, M
   Ricciardi, S
   Tistarelli, M
AF Nappi, Michele
   Ricciardi, Stefano
   Tistarelli, Massimo
TI Context awareness in biometric systems and methods: State of the art and
   future scenarios
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometric systems; Context-awareness; Context-adaptive biometrics; State
   of the art survey
ID FACE RECOGNITION; FUSION
AB In the last decade, research in biometrics has been focused on augmenting the algorithmic performance to address a growing range of applications, not limited to person authentication/recognition. The concept of context awareness emerged as a possible key-factor for both performance optimization and operational adaptation of the capture, extraction, matching and decision stages. This may be particularly effective for multi-biometrics systems. The knowledge of the context in which a task is being performed, may provide useful information to the system in several manners. For example, it may allow to adapt to a specific environmental condition, such as shadow or light exposure. On the other hand, it may be possible to select the best available algorithm, among a given set to address the task at hand, which best performs within the given context. This paper aims to provide an overall vision of the main contributions available so far in the field of context-aware biometric systems and methods. The survey is not confined to a particular biometric modality or processing stage, but rather spans the state of the art of several biometric modalities and approaches. A taxonomy of context-aware biometric systems and methods is also proposed, along with a comparison of their features, aims and performances. The analysis will be complemented with a critical discussion about the state of the art also suggesting some future application scenarios. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Nappi, Michele] Univ Salerno, Dept Comp Sci, I-84084 Fisciano, SA, Italy.
   [Ricciardi, Stefano] Univ Molise, Dept Biosci, I-84084 Pesche, IS, Italy.
   [Tistarelli, Massimo] Univ Sassari, Comp Vis Lab, I-07041 Alghero, SS, Italy.
C3 University of Salerno; University of Molise; University of Sassari
RP Ricciardi, S (corresponding author), Univ Molise, Dept Biosci, I-84084 Pesche, IS, Italy.
EM mnappi@unisa.it; stefano.ricciardi@unimol.it; tista@uniss.it
RI Tistarelli, Massimo/AAH-9437-2021; Nappi, Michele/X-3089-2019
OI Tistarelli, Massimo/0000-0002-3406-3048; 
CR Abate A.F., 2015, ATTI ACCAD PELORITAN, V93, P4
   Abate AF, 2011, J AMB INTEL HUM COMP, V2, P81, DOI 10.1007/s12652-010-0030-2
   Abowd GD, 1999, LECT NOTES COMPUT SC, V1707, P304
   Acampora G, 2005, CAMP 2005: Seventh International Workshop on Computer Architecture for Machine Perception , Proceedings, P327
   Acampora G., 2007, ARTIF INTELL, P1
   Al-Muhtadi J., PERV COMP COM 2003 P, P489
   Andronikou V., 2012, BIOM MEAS SYST SEC M, P1
   [Anonymous], SHEEP GOATS LAMBS WO
   Bächlin M, 2009, LECT NOTES COMPUT SC, V5558, P1040, DOI 10.1007/978-3-642-01793-3_105
   Bardram JE, 2003, LECT NOTES COMPUT SC, V2864, P107
   Basu Anirban, 2016, 2016 14th Annual Conference on Privacy, Security and Trust (PST), P329, DOI 10.1109/PST.2016.7906982
   Bazazian Shermin, 2015, Transactions on Computational Science XXV: LNCS 9030, P115, DOI 10.1007/978-3-662-47074-9_7
   Bazazian S., 2012, SPIE DEFENSE SECURIT
   Brown M. G., 1996, SUPPORTING USER MOBI, P69
   Chowdhury M. A., 2009, Proceedings of the 2009 World Congress on Privacy, Security, Trust and the Management of e-Business. CONGRESS 2009, P227, DOI 10.1109/CONGRESS.2009.20
   Cooperstock J. R., 1995, Human Factors in Computing Systems. CHI'95 Conference Proceedings, P170
   Eagle N, 2006, PERS UBIQUIT COMPUT, V10, P255, DOI 10.1007/s00779-005-0046-3
   ELROD S, 1993, COMMUN ACM, V36, P84, DOI 10.1145/159544.159626
   Feng T., 2014, P 15 WORKSH MOB COMP, P1, DOI 10.1145/2565585.2565592
   Feng T., 2015, TECHN HOM SEC HST 20, P1
   Frances A., 2009, Psychiatric Times, P1
   Geng X, 2010, PATTERN RECOGN, V43, P3660, DOI 10.1016/j.patcog.2010.04.012
   Guralnik Valerie, 2010, US. Patent Application No., Patent No. [12/715,520, 12715520]
   Hao Q, 2013, 2013 IEEE INTERNATIONAL MULTI-DISCIPLINARY CONFERENCE ON COGNITIVE METHODS IN SITUATION AWARENESS AND DECISION SUPPORT (COGSIMA), P98, DOI 10.1109/CogSIMA.2013.6523829
   Heishman Ric., 2004, Computer Vision and Pattern Recognition Workshop, V5, P69
   Hu J., 2004, Proceedings of the first workshop on pervasive privacy security, privacy, and trust, P1
   Jones G. J., 2005, UDM 05, P53
   Kantarci B, 2015, IEEE INT CONF CL NET, P81, DOI 10.1109/CloudNet.2015.7335286
   Komulainen Jukka, 2013, 2013 IEEE 6 INT C BI
   Kukula EP, 2007, LECT NOTES COMPUT SC, V4561, P904
   Li Yuk L, 2012, US Patent, Patent No. [8,255,698, 8255698]
   Mansour Abdeljebar, 2016, 2016 International Conference on Wireless Networks and Mobile Communications (WINCOM), P278, DOI 10.1109/WINCOM.2016.7777227
   Martin H, 2011, 14 INT C INF FUS, P1
   Menon V, 2008, LECT NOTES COMPUT SC, V5061, P75, DOI 10.1007/978-3-540-69293-5_8
   Nam MY, 2007, NEUROCOMPUTING, V70, P648, DOI 10.1016/j.neucom.2006.10.036
   Pedraza J, 2013, NEUROCOMPUTING, V109, P49, DOI 10.1016/j.neucom.2012.03.023
   Pedraza J., 2010, INT J BIOSCIENCE BIO, V2, P13
   Primo A., 2015, BIOM THEOR APPL SYST, P1
   Primo A, 2014, IEEE COMPUT SOC CONF, P98, DOI 10.1109/CVPRW.2014.20
   Qian K, 2014, IET BIOMETRICS, V3, P101, DOI 10.1049/iet-bmt.2013.0057
   Rafiqi Sohail, 2014, P 7 INT C PERVASIVE, DOI [10.1145/2674396.2674445, DOI 10.1145/2674396.2674445]
   Rekimoto J, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P68, DOI 10.1109/ISWC.1998.729531
   Riva O., 2012, USENIX Security Symposium, P301
   Ross A., 2009, Biometrics: Theory, Applications, and Systems, P1
   Sathyanarayana A, 2011, INFORM FUSION, V12, P293, DOI 10.1016/j.inffus.2010.06.004
   Schilit B., 1994, 1994 1 WORKSHOP MOBI, P85, DOI [DOI 10.1109/WMCSA.1994.16, 10.1109/WMCSA.1994.16]
   Schmalenstroeer J, 2010, IEEE J-STSP, V4, P845, DOI 10.1109/JSTSP.2010.2050519
   Song Zhexuan, 2011, US. Patent Application No., Patent No. [12/816,966, 12816966]
   Theofanos M. F., 2012, USABILITY BIOMETRICS, P231
   Witte H, 2013, 2013 FOURTH INTERNATIONAL CONFERENCE ON EMERGING SECURITY TECHNOLOGIES (EST), P29, DOI 10.1109/EST.2013.38
   Wójtowicz A, 2016, PERS UBIQUIT COMPUT, V20, P195, DOI 10.1007/s00779-016-0905-0
   Young NM, 2006, LECT NOTES ARTIF INT, V4251, P532
   Yuk L U, 2010, U. S. Patent Application No., Patent No. [12/342,621, 12342621]
NR 53
TC 13
Z9 14
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2018
VL 76
BP 27
EP 37
DI 10.1016/j.imavis.2018.05.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GR1TB
UT WOS:000442333500003
DA 2024-07-18
ER

PT J
AU Verlekar, TT
   Soares, LD
   Correia, PL
AF Verlekar, Tanmay Tulsidas
   Soares, Luis Ducla
   Correia, Paulo Lobato
TI Gait recognition in the wild using shadow silhouettes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Shadow biometrics; Gait recognition; Biometric recognition; View
   invariant
ID IMAGE-ANALYSIS; IDENTIFICATION; MODEL
AB Gait recognition systems allow identification of users relying on features acquired from their body movement while walking. This paper discusses the main factors affecting the gait features that can be acquired from a 2D video sequence, proposing a taxonomy to classify them across four dimensions. It also explores the possibility of obtaining users' gait features from the shadow silhouettes by proposing a novel gait recognition system. The system includes novel methods for: (i) shadow segmentation, (ii) walking direction identification, and (iii) shadow silhouette rectification.
   The shadow segmentation is performed by fitting a line through the feet positions of the user obtained from the gait texture image (GTI). The direction of the fitted line is then used to identify the walking direction of the user. Finally, the shadow silhouettes thus obtained are rectified to compensate for the distortions and deformations resulting from the acquisition setup, using the proposed four-point correspondence method. The paper additionally presents a new database, consisting of 21 users moving along two walking directions, to test the proposed gait recognition system. Results show that the performance of the proposed system is equivalent to that of the state-of-the-art in a constrained setting, but performing equivalently well in the wild, where most state-of-the-art methods fail The results also highlight the advantages of using rectified shadow silhouettes over body silhouettes under certain conditions. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Verlekar, Tanmay Tulsidas; Correia, Paulo Lobato] Univ Lisbon, Inst Super Tecn, Inst Telecomunicacoes, Lisbon, Portugal.
   [Soares, Luis Ducla] Inst Univ Lisboa ISCTE IUL, Inst Telecomunicacoes, Lisbon, Portugal.
C3 Instituto de Telecomunicacoes; Universidade de Lisboa; Instituto
   Universitario de Lisboa; Instituto de Telecomunicacoes
RP Verlekar, TT (corresponding author), Univ Lisbon, Inst Super Tecn, Inst Telecomunicacoes, Lisbon, Portugal.
EM ttv@lx.it.pt
RI Verlekar, Tanmay/AAB-9026-2020; Correia, Paulo Lobato/C-9933-2010;
   Soares, Luis/F-3166-2011
OI Correia, Paulo Lobato/0000-0001-6525-9572; Verlekar,
   Tanmay/0000-0001-5534-4351; Soares, Luis/0000-0001-9738-639X
FU Instituto de Telecomunicacoes under Fundacao para a Ciencia e Tecnologia
   [UID/EEA/50008/2013]
FX This work was partially supported by Instituto de Telecomunicacoes under
   Fundacao para a Ciencia e Tecnologia Grant UID/EEA/50008/2013.
CR [Anonymous], 2006, IEEE Transactions on Pattern Analysis and Machine Intelligence, DOI DOI 10.1109/TPAMI.2006.38
   [Anonymous], 2015, WILEY ENCY ELECT ELE, DOI DOI 10.1002/047134608X.W8261
   [Anonymous], 2007, NIK 2007 C
   Bashir K., 2009, 3 INT C CRIM DET PRE
   Bashir K, 2010, PATTERN RECOGN LETT, V31, P2052, DOI 10.1016/j.patrec.2010.05.027
   Bouchrika I, 2016, MULTIMED TOOLS APPL, V75, P1201, DOI 10.1007/s11042-014-2364-9
   Connie T, 2017, IEEE T CYBERNETICS, V47, P1395, DOI 10.1109/TCYB.2016.2545693
   Connie T, 2016, NEUROCOMPUTING, V216, P534, DOI 10.1016/j.neucom.2016.08.002
   Das Choudhury S, 2015, PATTERN RECOGN, V48, P798, DOI 10.1016/j.patcog.2014.09.022
   Das Choudhury S, 2012, PATTERN RECOGN, V45, P3414, DOI 10.1016/j.patcog.2012.02.032
   Fazenda J., 2005, INT C COMP TOOL EURO
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Goffredo M, 2010, IEEE T SYST MAN CY B, V40, P997, DOI 10.1109/TSMCB.2009.2031091
   Guan Y., 2012, 14 ACM MULT SEC WORK
   Guan Y., 2013, 2013 INT C IEEE
   Guan Y, 2014, IET BIOMETRICS, V3, P84, DOI 10.1049/iet-bmt.2013.0062
   Hartley R., 2003, Multiple View Geometry in Computer Vision, P155
   Iwama H., 2012, IEEE T INF FOREN SEC, V5, P7
   Iwashita Y., 2011, 26 INT C IM VIS COMP
   Iwashita Y., 2014, 2014 5 INT C ALC HEN
   Iwashita Y., 2010, BRIT MACH VIS C BMVC
   Iwashita Y., 2012, 3 INT C EM SEC TECHN
   Iwashita Y., 2009, S BIOINSP LEARN INT
   Iwashita Y., 2010, 2010 17 IEEE INT C H
   Iwashita Y, 2014, PATTERN RECOGN LETT, V48, P60, DOI 10.1016/j.patrec.2014.04.004
   Iwashita Y, 2013, SENSORS-BASEL, V13, P7884, DOI 10.3390/s130607884
   Iwashita Y, 2012, PATTERN RECOGN LETT, V33, P2148, DOI 10.1016/j.patrec.2012.07.022
   Iwashita Y, 2012, PROC SPIE, V8371, DOI 10.1117/12.919605
   Jean F, 2009, PATTERN RECOGN, V42, P2936, DOI 10.1016/j.patcog.2009.05.006
   Jia N., 2015, BIOM SPEC INT GROUP
   Kale A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P143, DOI 10.1109/AVSS.2003.1217914
   Khalid B., 2010, BRIT MACH VIS C
   Kusakunniran W., 2010, IEEE C COMP VIS PATT
   Kusakunniran W, 2009, IEEE 12 INT C COMP V
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Kusakunniran W, 2012, PATTERN RECOGN LETT, V33, P882, DOI 10.1016/j.patrec.2011.04.014
   Lee CP, 2014, J VIS COMMUN IMAGE R, V25, P1489, DOI 10.1016/j.jvcir.2014.05.006
   Liang YL, 2016, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-016-0126-5
   Liu NB, 2010, INT CON DISTR COMP S, DOI 10.1109/ICDCS.2010.83
   Lv ZW, 2015, SENSORS-BASEL, V15, P932, DOI 10.3390/s150100932
   Makihara Y., 2012, IPSJ T COMPUT VISION, V4, P53, DOI DOI 10.2197/IPSJTCVA.4.53
   Michalak J, 2009, PSYCHOSOM MED, V71, P580, DOI 10.1097/PSY.0b013e3181a2515c
   Muramatsu D., 2012, ARB VIEW TRANSF MOD
   Nguyen  T.-N., 2014, P 5 S INF COMM TECHN
   Nieto-Hidalgo M, 2016, J BIOMED INFORM, V63, P82, DOI 10.1016/j.jbi.2016.08.003
   Reátegui J, 2013, IEEE INT C BIOINF BI
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shinzaki M., 2015, C APPL COMP VIS WAVC
   Stoica A., 2008, RECOGNITION HUMANS T
   Verlekar T., 2016, BIOMETRICS SPECIAL I
   Verlekar T., 2017, 25 EUR SIGN PROC C E
   Verlekar TT, 2016, I W BIOMETRIC FORENS
   Verlekar TT, 2017, IET BIOMETRICS, V6, P299, DOI 10.1049/iet-bmt.2016.0118
   Xu C, 2016, P AS C COMP VIS, P52
   Zhao GY, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P529
NR 55
TC 12
Z9 13
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2018
VL 76
BP 1
EP 13
DI 10.1016/j.imavis.2018.05.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GR1TB
UT WOS:000442333500001
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Villota, JCP
   da Silva, FL
   Jacomini, RD
   Costa, AHR
AF Perafan Villota, Juan Carlos
   da Silva, Felipe Leno
   Jacomini, Ricardo de Souza
   Reali Costa, Anna Helena
TI Pairwise registration in indoor environments using adaptive combination
   of 2D and 3D cues
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pairwise registration; RGB-D data; Local descriptors; Keypoint detectors
ID FINE REGISTRATION; SIGNATURES
AB Pairwise frame registration of indoor scenes with sparse 2D local features is not particularly robust under varying lighting conditions or low visual texture. In this case, the use of 3D local features can be a solution, as such attributes come from the 3D points themselves and are resistant to visual texture and illumination variations. However, they also hamper the registration task in cases where the scene has little geometric structure. Frameworks that use both types of features have been proposed, but they do not take into account the type of scene to better explore the use of 2D or 3D features. Because varying conditions are inevitable in real indoor scenes, we propose a new framework to improve pairwise registration of consecutive frames using an adaptive combination of sparse 2D and 3D features. In our proposal, the proportion of 2D and 3D features used in the registration is automatically defined according to the levels of geometric structure and visual texture contained in each scene. The effectiveness of our proposed framework is demonstrated by experimental results from challenging scenarios with datasets including unrestricted RGB-D camera motion in indoor environments and natural changes in illumination. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Perafan Villota, Juan Carlos; da Silva, Felipe Leno; Jacomini, Ricardo de Souza; Reali Costa, Anna Helena] Univ Sao Paulo, Dept Engn Comp & Sistemas Digitais, Escola Politecn, Ave Prof Luciano Gualberto,Trav 3,158, Sao Paulo, Brazil.
   [Perafan Villota, Juan Carlos] Univ Autonoma Occidente, Dept Automat & Elect, Fac Ingn, Cll 25 115-85 Km 2 Via Cali Jamundi, Cali, Colombia.
C3 Universidade de Sao Paulo; Universidad Autonoma de Occidente
RP Costa, AHR (corresponding author), Univ Sao Paulo, Dept Engn Comp & Sistemas Digitais, Escola Politecn, Ave Prof Luciano Gualberto,Trav 3,158, Sao Paulo, Brazil.
EM jcperafan@uao.edu.co; f.leno@usp.br; ricardo.jacomini@usp.br;
   anna.reali@usp.br
RI da Silva, Felipe Leno/N-4124-2014; Costa, Anna Helena Reali/I-2469-2012
OI da Silva, Felipe Leno/0000-0003-4703-2061; Costa, Anna Helena
   Reali/0000-0001-7309-4528
FU CAPES; CNPq [311608/2014-0, 425860/2016-7]; Sao Paulo Research
   Foundation (FAPESP) [2015/16310-4, 2016/21047-3]; Fundacao de Amparo a
   Pesquisa do Estado de Sao Paulo (FAPESP) [16/21047-3, 15/16310-4]
   Funding Source: FAPESP
FX The authors acknowledge CAPES, CNPq (grants 311608/2014-0 and
   425860/2016-7), and Sao Paulo Research Foundation (FAPESP grants
   2015/16310-4 and 2016/21047-3) for their financial support.
CR Aldoma A, 2016, IEEE T PATTERN ANAL, V38, P1383, DOI 10.1109/TPAMI.2015.2491940
   [Anonymous], 2013, MULTIMEDIA UBIQUITOU, DOI DOI 10.1007/978-94-007-6738-6124
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bylow E, 2013, ROB SCI SYST C RSS
   Calonder M, 2008, LECT NOTES COMPUT SC, V5302, P58, DOI 10.1007/978-3-540-88682-2_6
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Desbrun M, 1999, COMP GRAPH, P317, DOI 10.1145/311535.311576
   Díez Y, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2692160
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199
   Filipe S, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS (VISAPP), VOL 1, P476
   Fiolka Torsten, 2012, Spatial Cognition VIII. Proceedings of the International Conference, Spatial Cognition 2012, P74, DOI 10.1007/978-3-642-32732-2_5
   Firman M, 2013, IEEE INT C INT ROBOT, P1107, DOI 10.1109/IROS.2013.6696488
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Flint A., 2007, 9 BIENN C AUSTR PATT, P182, DOI [DOI 10.1109/DICTA.2007.4426794, 10.1109/DICTA.2007.4426794]
   Geiger A, 2015, LECT NOTES COMPUT SC, V9358, P183, DOI 10.1007/978-3-319-24947-6_15
   Guo Y., INT J COMPUT VIS, V116
   Gupta S, 2015, INT J COMPUT VISION, V112, P133, DOI 10.1007/s11263-014-0777-6
   Hansch R., 2014, REMOTE SENS SPAT INF, P57
   Hansung Kim, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P202, DOI 10.1109/3DV.2014.51
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Henry P, 2012, INT J ROBOT RES, V31, P647, DOI 10.1177/0278364911434148
   Holz D, 2015, IEEE ROBOT AUTOM MAG, V22, P110, DOI 10.1109/MRA.2015.2432331
   Kanade T, CMUCS91132
   Li S, 2015, IEEE INT CONF ROBOT, P6374, DOI 10.1109/ICRA.2015.7140094
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manoj PS, 2015, IEEE INT CONF ROBOT, P4216, DOI 10.1109/ICRA.2015.7139780
   Morell-Gimenez V, 2014, SENSORS-BASEL, V14, P8547, DOI 10.3390/s140508547
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   Villota JCP, 2015, 2015 12TH LATIN AMERICAN ROBOTICS SYMPOSIUM AND 2015 3RD BRAZILIAN SYMPOSIUM ON ROBOTICS (LARS-SBR), P309, DOI 10.1109/LARS-SBR.2015.38
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Russell B. C., 2009, ADV NEURAL INF PROCE, P1
   Russell J., 2010, ARTIFICIAL INTELLIGE
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salti S., 2012, 2 JOINT 3DIM 3DPVT C, V1, P425
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Shao TJ, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366155
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Steder B., 2010, WORKSH DEF SOLV REAL
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tykkälä T, 2014, J VIS COMMUN IMAGE R, V25, P207, DOI 10.1016/j.jvcir.2013.02.009
   Wang CC, 2007, INT J ROBOT RES, V26, P889, DOI 10.1177/0278364907081229
   Xie J, 2015, J VIS COMMUN IMAGE R, V32, P194, DOI 10.1016/j.jvcir.2015.08.007
   Xie ZX, 2010, IMAGE VISION COMPUT, V28, P563, DOI 10.1016/j.imavis.2009.09.006
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
NR 49
TC 4
Z9 5
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 113
EP 124
DI 10.1016/j.imavis.2017.08.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100010
DA 2024-07-18
ER

PT J
AU Yu, YH
   Wu, QS
   Kirubarajan, T
   Uehara, Y
AF Yu, Yuanhao
   Wu, Qingsong
   Kirubarajan, T.
   Uehara, Yasuo
TI Robust discriminative tracking via structured prior regularization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Semi-supervised learning; Multi-objective optimization;
   Random Forest
ID OBJECT DETECTION; VISUAL TRACKING; MODEL; RECOGNITION
AB In this paper, we address the problem of tracking an object in a video sequence given its location in the first frame and no other information. Many existing discriminative tracking algorithms usually train a classifier in an on-line manner to separate the object of interest from the background. Slight inaccuracies in the tracking may result in incorrectly labelled training set, which can degrade the tracker. Although a number of approaches such as semi-supervised learning and multiple instance learning have been developed to address this problem, some critical issues still remain unsolved. This work aims to mitigate the shortcomings by exploiting a reliable generative model to support the discriminative learning process. A prior model based on a set of structured Dirichlet-multinomial distributions is proposed to preserve the target's structure information. This prior is then formulated as a regularization term in a training objective function, which casts the tracking task as a prior regularized semi-supervised learning problem. A multi-objective optimization method is developed to search for the solution, taking advantage of a decision maker inside to control the conflicts between different modules. The experiments show that this proposed method outperforms standard algorithms on challenging datasets. It is also demonstrated that the algorithm significantly mitigates the error accumulation effect. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Yu, Yuanhao; Wu, Qingsong; Kirubarajan, T.] McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
   [Uehara, Yasuo] Toyota Motor Engn & Mfg North Amer Inc, Erlanger, KY USA.
C3 McMaster University; Toyota Motor Corporation
RP Yu, YH (corresponding author), McMaster Univ, Dept Elect & Comp Engn, Hamilton, ON, Canada.
EM yuy32@mcmaster.ca
OI Yu, Yuanhao/0000-0001-8176-9716
CR Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   [Anonymous], 2015, IEEE INT C COMP VIS
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], ENHANCED FLOCK TRACK
   [Anonymous], COMPUT VIS IMAGE UND
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Babu RV, 2015, IMAGE VISION COMPUT, V33, P44, DOI 10.1016/j.imavis.2014.10.006
   Balan A.O., 2006, COMPUTER VISION PATT, V1, P758
   Bengio Y., 2005, Semi-Supervised Learning
   Breiman L., 2001, Mach. Learn., V45, P5
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Corduneanu A., 2003, PROC 19 C UNCERTAINT, P151
   Criminisi A., 2013, DECISION FORESTCOM, DOI DOI 10.1007/978-1-4471-4929-3
   Du SZ, 2014, IEEE SIGNAL PROC LET, V21, P51, DOI 10.1109/LSP.2013.2290547
   Everingham M., 2005, The PASCAL Visual Object Classes Challenge Results (VOC 2005)
   Grabner H., 2006, BMVC, P47
   Grabner H, 2008, LECT NOTES COMPUT SC, V5302, P234, DOI 10.1007/978-3-540-88682-2_19
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kalal Z, 2010, PROC CVPR IEEE, P49, DOI 10.1109/CVPR.2010.5540231
   Karanam S, 2015, IEEE COMPUT SOC CONF
   Kwon J, 2013, IEEE T PATTERN ANAL, V35, P2427, DOI 10.1109/TPAMI.2013.32
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Leibe B, 2008, IEEE T PATTERN ANAL, V30, P1683, DOI 10.1109/TPAMI.2008.170
   Leistner C, 2009, IEEE I CONF COMP VIS, P506, DOI 10.1109/ICCV.2009.5459198
   Lepetit V, 2006, IEEE T PATTERN ANAL, V28, P1465, DOI 10.1109/TPAMI.2006.188
   Li A, 2015, International Symposium 2015-Modelling and Informationalization in Exercise Health and Technology, P1
   Li HX, 2016, IEEE T IMAGE PROCESS, V25, P1834, DOI 10.1109/TIP.2015.2510583
   LIU X., 2007, INT C COMPUTER VISIO, P1
   Mann Gideon S, 2007, P 24 INT C MACH LEAR, P593, DOI DOI 10.1145/1273496.1273571
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Nejhum S.M. Shahed., 2008, Proceedings IEEE Conference on Computer Vision and Pattern Recognition, P1
   Ng K.W., 2011, DIRICHLET RELATED DI
   Payet N, 2013, IEEE T PATTERN ANAL, V35, P1066, DOI 10.1109/TPAMI.2012.194
   Pedersoli M, 2015, INT J COMPUT VISION, V111, P137, DOI 10.1007/s11263-014-0736-2
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sevilla-Lara L, 2012, PROC CVPR IEEE, P1910, DOI 10.1109/CVPR.2012.6247891
   Shotton J, 2008, PROC CVPR IEEE, P1245
   Stalder Severin, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1409, DOI 10.1109/ICCVW.2009.5457445
   Szummer M, 2002, ADV NEUR IN, V14, P945
   Wang D, 2013, PROC CVPR IEEE, P2371, DOI 10.1109/CVPR.2013.307
   Wang N., 2013, Advances in Neural Information Processing Systems, P809
   Wen LY, 2014, IEEE T IMAGE PROCESS, V23, P785, DOI 10.1109/TIP.2013.2293430
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Wu Y, 2011, IEEE I CONF COMP VIS, P1100, DOI 10.1109/ICCV.2011.6126357
   Yang X, 2015, NEUROCOMPUTING, V159, P35, DOI 10.1016/j.neucom.2015.02.046
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang JM, 2014, LECT NOTES COMPUT SC, V8694, P188, DOI 10.1007/978-3-319-10599-4_13
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   Zhang KH, 2014, IEEE T PATTERN ANAL, V36, P2002, DOI 10.1109/TPAMI.2014.2315808
   Zhang KH, 2013, PATTERN RECOGN, V46, P397, DOI 10.1016/j.patcog.2012.07.013
   Zhang L, 2014, IEEE T PATTERN ANAL, V36, P756, DOI 10.1109/TPAMI.2013.221
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 57
TC 2
Z9 2
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2018
VL 69
BP 68
EP 80
DI 10.1016/j.imavis.2017.11.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FW1QS
UT WOS:000425075100006
DA 2024-07-18
ER

PT J
AU Gharani, P
   Karimi, HA
AF Gharani, Pedram
   Karimi, Hassan A.
TI Context-aware obstacle detection for navigation by visually impaired
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Obstacle detection; Indoor navigation; Visual navigation; Visually
   impaired
ID OPTICAL-FLOW ESTIMATION; MOBILE ROBOT; SYSTEM; VISION; SENSOR
AB This paper presents a context-aware smartphone-based based visual obstacle detection approach to aid visually impaired people in navigating indoor environments. The approach is based on processing two consecutive frames (images), computing optical flow, and tracking certain points to detect obstacles. The frame rate of the video stream is determined using a context-aware data fusion technique for the sensors on smartphones. Through an efficient and novel algorithm, a point dataset on each consecutive frames is designed and evaluated to check whether the points belong to an obstacle. In addition to determining the points based on the texture in each frame, our algorithm also considers the heading of user movement to find critical areas on the image plane. We validated the algorithm through experiments by comparing it against two comparable algorithms. The experiments were conducted in different indoor settings and the results based on precision, recall, accuracy, and f-measure were compared and analyzed. The results show that, in comparison to the other two widely used algorithms for this process, our algorithm is more precise. We also considered time-to-contact parameter for clustering the points and presented the improvement of the performance of clustering by using this parameter. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Gharani, Pedram; Karimi, Hassan A.] Univ Pittsburgh, Sch Comp & Informat, Geoinformat Lab, Pittsburgh, PA USA.
C3 Pennsylvania Commonwealth System of Higher Education (PCSHE); University
   of Pittsburgh
RP Gharani, P (corresponding author), Univ Pittsburgh, Sch Comp & Informat, Geoinformat Lab, Pittsburgh, PA USA.
EM peg25@pitt.edu
OI Gharani, Pedram/0000-0003-3383-8910
CR [Anonymous], 2008, WORKSH COMP VIS APPL
   [Anonymous], 2013, THESIS
   Bao L, 2004, LECT NOTES COMPUT SC, V3001, P1, DOI 10.1007/978-3-540-24646-6_1
   Batavia P.H., 1999, Computer Standards Interfaces, V20, P466, DOI DOI 10.1016/S0920-5489(99)91018-8
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   Benjamin J.M., 1973, P SAN DIEG BIOM S
   Boroujeni NS, 2012, IEEE IMAGE PROC, P65, DOI 10.1109/ICIP.2012.6466796
   Bousbia-Salah M, 2011, J INTELL ROBOT SYST, V64, P387, DOI 10.1007/s10846-011-9555-7
   Browning NA, 2009, COGNITIVE PSYCHOL, V59, P320, DOI 10.1016/j.cogpsych.2009.07.002
   Camus T., 1994, REAL TIME OPTICAL FL
   Cheng CC, 2010, IEEE T CONSUM ELECTR, V56, P1739, DOI 10.1109/TCE.2010.5606320
   Cimiano P., 2004, P 16 EUR C ART INT E
   Costa P, 2012, PROCEDIA COMPUT SCI, V14, DOI 10.1016/j.procs.2012.10.010
   Cui H., 2010, VIRTUAL SIGHT HAPTIC
   El-Gaaly T., 2013, Visual Obstacle Avoidance for Autonomous Watercraft using Smartphones
   Fallah N, 2013, INTERACT COMPUT, V25, P21, DOI 10.1093/iwc/iws010
   Farmer LW., 1997, FDN ORIENTATION MOBI, V2, P231
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Ganz A, 2014, IEEE ENG MED BIO, P3662, DOI 10.1109/EMBC.2014.6944417
   Ganz A, 2011, IEEE ENG MED BIO, P856, DOI 10.1109/IEMBS.2011.6090223
   Golledge R.G., 1997, J VISUAL IMPAIRMENT, V91, P446, DOI DOI 10.1177/0145482X9709100505
   Guerrero LA, 2012, SENSORS-BASEL, V12, P8236, DOI 10.3390/s120608236
   Harper S, 2003, DISABIL REHABIL, V25, P940, DOI 10.1080/0963828031000090533
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Helal A, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P149, DOI 10.1109/ISWC.2001.962119
   Horn B. K. P., 1981, Artificial Intelligence
   Jose J., 2012, Proceedings of the 1st International Conference on Pattern Recognition Applications and Methods. ICPRAM 2012, P515
   Katz BFG, 2012, VIRTUAL REAL-LONDON, V16, P253, DOI 10.1007/s10055-012-0213-6
   Ke Y, 2004, PROC CVPR IEEE, P506
   KIRA K, 1992, MACHINE LEARNING /, P249
   Liu HY, 2003, IEEE T IMAGE PROCESS, V12, P1170, DOI 10.1109/TIP.2003.815296
   Low T., 1998, Australasian Conference on Robotics and Automation, P1
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lucas B.D., 1981, 7 INT JT C ART INT
   MALLOT HA, 1991, BIOL CYBERN, V64, P177, DOI 10.1007/BF00201978
   Marston JR, 2003, J VISUAL IMPAIR BLIN, V97, P475, DOI 10.1177/0145482X0309700803
   Murray D, 2000, AUTON ROBOT, V8, P161, DOI 10.1023/A:1008987612352
   Nakju J.L., 2004, ISARC, V2004, P1
   O'Donovan P., 2005, INT J COMPUT VISION, V2005, P1
   Ohya A, 1998, IEEE T ROBOTIC AUTOM, V14, P969, DOI 10.1109/70.736780
   Peng E, 2010, LECT NOTES COMPUT SC, V6406, P590, DOI 10.1007/978-3-642-16355-5_45
   Pradeep V, 2010, PROC CVPR IEEE, P1514, DOI 10.1109/CVPR.2010.5539792
   Ran L., P 2 IEEE ANN C PERV, P23
   Ravi N., 2005, Aaai, P1541
   Ren M, 2012, J NAVIGATION, V65, P617, DOI 10.1017/S0373463312000252
   Robnik-Sikonja M, 2003, MACH LEARN, V53, P23, DOI 10.1023/A:1025667309714
   Rodríguez A, 2012, SENSORS-BASEL, V12, P17476, DOI 10.3390/s121217476
   Roentgen U.R., 2008, J. Vis. Impair. Blind, V102, P702, DOI [DOI 10.1177/0145482X0810201105, 10.1177/0145482X0810201105]
   Rublee Ethan., 2011, ORB: an efficient alternative to SIFT or SURF
   Saeedi S, 2014, SENSORS-BASEL, V14, P5742, DOI 10.3390/s140405742
   Shaohua Qian, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P441, DOI 10.1007/978-3-642-37484-5_36
   Song KT, 2001, IEEE INT CONF ROBOT, P2891, DOI 10.1109/ROBOT.2001.933060
   Souhila K., 2007, International Journal of Advanced Robotic Systems, V4, P13
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tang J., 2014, Data Classification, V37, DOI DOI 10.1201/B17320
   Tapu R, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P444, DOI 10.1109/ICCVW.2013.65
   Tistarelli M., 1993, IEEE T PATTERN ANAL, V15, P401
   Ulrich I, 2001, IEEE T SYST MAN CY A, V31, P131, DOI 10.1109/3468.911370
   Xu A., 2008, Computer Vision and Image Understanding (CVIU), V110, P1
   Zhang M.-L., 2005, GRAN COMP 2005 IEEE, P718
   Zheng YQ, 2014, PROCEEDINGS OF THE 20TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING (MOBICOM '14), P471, DOI 10.1145/2639108.2639124
   Zingg S, 2010, IEEE INT CONF ROBOT, P3361, DOI 10.1109/ROBOT.2010.5509777
NR 62
TC 29
Z9 29
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2017
VL 64
BP 103
EP 115
DI 10.1016/j.imavis.2017.06.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA FH0ZW
UT WOS:000410870200009
DA 2024-07-18
ER

PT J
AU Sun, T
   Sun, L
   Yeung, DY
AF Sun, Ting
   Sun, Lin
   Yeung, Dit-Yan
TI Fine-grained categorization via CNN-based automatic extraction and
   integration of object-level and part-level features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fine-grained categorization; Part-based-features; Automatic part
   detection; CNN-based
AB Fine-grained categorization can benefit from part-based features which reveal subtle visual differences between object categories. Handcrafted features have been widely used for part detection and classification. Although a recent trend seeks to learn such features automatically using powerful deep learning models such as convolutional neural networks (CNN), their training and possibly also testing require manually provided annotations which are costly to obtain. To relax these requirements, we assume in this study a general problem setting in which the raw images are only provided with object-level class labels for model training with no other side information needed. Specifically, by extracting and interpreting the hierarchical hidden layer features learned by a CNN, we propose an elaborate CNN-based system for fine-grained categorization. When evaluated on the Caltech-UCSD Birds-200-2011, FGVC-Aircraft, cars and Stanford dogs datasets under the setting that only object-level class labels are used for training and no other annotations are available for both training and testing, our method achieves impressive performance that is superior or comparable to the state of the art. Moreover, it sheds some light on ingenious use of the hierarchical features learned by CNN which has wide applicability well beyond the current fine-grained categorization task. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Sun, Ting; Sun, Lin; Yeung, Dit-Yan] Hong Kong Univ Sci & Technol, Hong Kong, Hong Kong, Peoples R China.
C3 Hong Kong University of Science & Technology
RP Sun, T (corresponding author), Hong Kong Univ Sci & Technol, Hong Kong, Hong Kong, Peoples R China.
EM tsun@ust.hk
OI Sun, Ting/0000-0002-9376-0142
FU Hong Kong University of Science and Technology
FX I am fully supported with regular postgraduate studentship from the Hong
   Kong University of Science and Technology.
CR [Anonymous], 2014, P BRIT MACH VIS C, DOI 10.5244/C.28.87
   [Anonymous], 2014, ATTENTION FINE GRAIN
   [Anonymous], 2013, Tech. rep.
   Berg T, 2014, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2014.259
   Berg T, 2013, IEEE I CONF COMP VIS, P9, DOI 10.1109/ICCV.2013.9
   Berg T, 2013, PROC CVPR IEEE, P955, DOI 10.1109/CVPR.2013.128
   Chai Y, 2013, IEEE I CONF COMP VIS, P321, DOI 10.1109/ICCV.2013.47
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   CIMPOI M, 2015, PROC CVPR IEEE, P3828, DOI DOI 10.1109/CVPR.2015.7299007
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   Donahue J, 2014, PR MACH LEARN RES, V32
   Farrell R, 2011, IEEE I CONF COMP VIS, P161, DOI 10.1109/ICCV.2011.6126238
   Göring C, 2014, PROC CVPR IEEE, P2489, DOI 10.1109/CVPR.2014.319
   Guo S., 2017, IEEE T IMAGE PROCESS
   Huang C. W., 2016, 2016 International Conference of Asian Union of Magnetics Societies (ICAUMS), DOI 10.1109/ICAUMS.2016.8479951
   Huang C, 2017, IEEE T MULTIMEDIA, V19, P673, DOI 10.1109/TMM.2016.2631122
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Iscen A, 2015, IEEE T IMAGE PROCESS, V24, P2369, DOI 10.1109/TIP.2015.2423557
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaufman P.J., 1990, FINDING GROUPS DATA
   Khosla A., 2011, P CVPR WORKSHOP FINE, V2
   Krause J, 2015, PROC CVPR IEEE, P5546, DOI 10.1109/CVPR.2015.7299194
   Krause J, 2014, INT C PATT RECOG, P26, DOI 10.1109/ICPR.2014.15
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 1990, ADV NEURAL INFORM PR, P396
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Qian Q, 2015, PROC CVPR IEEE, P3716, DOI 10.1109/CVPR.2015.7298995
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Sermanet P., 2014, INT C LEARN REPR
   Simon M, 2015, IEEE I CONF COMP VIS, P1143, DOI 10.1109/ICCV.2015.136
   Simon M, 2015, LECT NOTES COMPUT SC, V9004, P162, DOI 10.1007/978-3-319-16808-1_12
   Simonyan K., 2013, arXiv preprint arXiv:1312.6034
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, P IEEE C COMP VIS PA
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Wang DQ, 2015, IEEE I CONF COMP VIS, P2399, DOI 10.1109/ICCV.2015.276
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wang YM, 2016, PROC CVPR IEEE, P1163, DOI 10.1109/CVPR.2016.131
   Welinder P., 2010, TECH REP, V200
   Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885
   Xie LX, 2016, IEEE T CIRC SYST VID, V26, P1251, DOI 10.1109/TCSVT.2015.2461978
   Xu Z, 2017, IEEE T IMAGE PROCESS, V26, P135, DOI 10.1109/TIP.2016.2621661
   Xu ZW, 2015, PROC CVPR IEEE, P1798, DOI 10.1109/CVPR.2015.7298789
   Yang SX, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/5089767
   Yao BP, 2012, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2012.6248088
   Yao HT, 2016, IEEE T IMAGE PROCESS, V25, P4858, DOI 10.1109/TIP.2016.2599102
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang N, 2012, PROC CVPR IEEE, P3665, DOI 10.1109/CVPR.2012.6248364
   Zhang XP, 2016, PROC CVPR IEEE, P1134, DOI 10.1109/CVPR.2016.128
   Zhang XP, 2016, IEEE T IMAGE PROCESS, V25, P878, DOI 10.1109/TIP.2015.2509425
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, P1713, DOI 10.1109/TIP.2016.2531289
   Zhou B., 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.319
   Zhou B., 2014, CORR, V1412, P6856
NR 65
TC 9
Z9 10
U1 0
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2017
VL 64
BP 47
EP 66
DI 10.1016/j.imavis.2017.06.003
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FH0ZW
UT WOS:000410870200005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Yan, HB
AF Yan, Haibin
TI Kinship verification using neighborhood repulsed correlation metric
   learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Kinship verification; Metric learning; Correlation metric; Face
   recognition; Soft biometrics
ID HUMAN AGE ESTIMATION; FACIAL EXPRESSION RECOGNITION; FACE RECOGNITION;
   SEQUENCES
AB Kinship verification is an interesting and challenging problem in human face analysis, which has received increasing interests in computer vision and biometrics in recent years. This paper presents a neighborhood repulsed correlation metric learning (NRCML) method for kinship verification via facial image analysis. Most existing metric learning based kinship verification methods are developed with the Euclidian similarity metric, which is not powerful enough to measure the similarity of face samples, especially when they are captured in wild conditions. Motivated by the fact that the correlation similarity metric can better handle face variations than the Euclidian similarity metric, we propose a NRCML method by using the correlation similarity measure where the kin relation of facial images can be better highlighted. Since negative kinship samples are usually less than positive samples, we automatically identify the most discriminative negative samples in the training set to learn the distance metric so that the most discriminative encoded by negative samples can better exploited. Experimental results show the efficacy of the proposed approach. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Yan, Haibin] Beijing Univ Posts & Telecommun, Sch Automat, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Yan, HB (corresponding author), Beijing Univ Posts & Telecommun, Sch Automat, Beijing 100876, Peoples R China.
EM eyanhaibin@bupt.edu.cn
FU National Natural Science Foundation of China [61603048]
FX This work is supported by the National Natural Science Foundation of
   China under Grant 61603048.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], AS C COMP VIS
   [Anonymous], P ADV NEURAL INFORM
   [Anonymous], IEEE T CYBERN
   [Anonymous], 2005, IEEE INT C INF ACQ
   [Anonymous], 2014, IEEE T INF FORENSICS
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Dal Martello MF, 2006, J VISION, V6, P1356, DOI 10.1167/6.12.2
   Deng WH, 2012, IEEE T PATTERN ANAL, V34, P1864, DOI 10.1109/TPAMI.2012.30
   Dibeklioglu H, 2013, IEEE I CONF COMP VIS, P1497, DOI 10.1109/ICCV.2013.189
   Du S, 2009, IEEE T SYST MAN CY B, V39, P1408, DOI 10.1109/TSMCB.2009.2018137
   Fang RG, 2013, IEEE IMAGE PROC, P2983, DOI 10.1109/ICIP.2013.6738614
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fu Y, 2008, IEEE T MULTIMEDIA, V10, P578, DOI 10.1109/TMM.2008.921847
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Guillaumin M, 2009, IEEE I CONF COMP VIS, P498, DOI 10.1109/ICCV.2009.5459197
   Guo GD, 2008, IEEE T IMAGE PROCESS, V17, P1178, DOI 10.1109/TIP.2008.924280
   Guo GD, 2012, IEEE T INSTRUM MEAS, V61, P2322, DOI 10.1109/TIM.2012.2187468
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Guo YH, 2014, INT C PATT RECOG, P4287, DOI 10.1109/ICPR.2014.735
   Gutta S, 2000, IEEE T NEURAL NETWOR, V11, P948, DOI 10.1109/72.857774
   Haibin Yan, 2015, 2015 Visual Communications and Image Processing (VCIP), P1, DOI 10.1109/VCIP.2015.7457930
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Kohli N., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P245, DOI 10.1109/BTAS.2012.6374584
   Lanitis A., 2008, IEEE INT C AUTOMATIC, P1
   Li XS, 2015, 2015 INTERNATIONAL CONFERENCE ON INDUSTRIAL INFORMATICS - COMPUTING TECHNOLOGY, INTELLIGENT TECHNOLOGY, INDUSTRIAL INFORMATION INTEGRATION (ICIICII), P1, DOI 10.1109/ICIICII.2015.88
   Liong VE, 2015, PROC CVPR IEEE, P2475, DOI 10.1109/CVPR.2015.7298862
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2007, PATTERN RECOGN LETT, V28, P2401, DOI 10.1016/j.patrec.2007.08.004
   Lu JW, 2016, IEEE T CIRC SYST VID, V26, P529, DOI 10.1109/TCSVT.2015.2412831
   Lu JW, 2015, IEEE I CONF COMP VIS, P3721, DOI 10.1109/ICCV.2015.424
   Lu JW, 2015, PROC CVPR IEEE, P1137, DOI 10.1109/CVPR.2015.7298717
   Lu JW, 2015, IEEE T IMAGE PROCESS, V24, P5356, DOI 10.1109/TIP.2015.2481327
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu JW, 2015, IEEE T INF FOREN SEC, V10, P79, DOI 10.1109/TIFS.2014.2363792
   Lu JW, 2015, IEEE T INF FOREN SEC, V10, P1371, DOI 10.1109/TIFS.2015.2408431
   Lu JW, 2014, IEEE T INF FOREN SEC, V9, P51, DOI 10.1109/TIFS.2013.2291969
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Lu JW, 2013, IEEE T INF FOREN SEC, V8, P510, DOI 10.1109/TIFS.2013.2243146
   Lu JW, 2013, IEEE T HUM-MACH SYST, V43, P249, DOI 10.1109/TSMCC.2012.2192727
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Lu JW, 2012, IEEE T INF FOREN SEC, V7, P944, DOI 10.1109/TIFS.2012.2188389
   Lu JW, 2010, IEEE T SYST MAN CY B, V40, P958, DOI 10.1109/TSMCB.2009.2032926
   Lu JW, 2010, IEEE T INF FOREN SEC, V5, P71, DOI 10.1109/TIFS.2009.2035976
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Moghaddam B., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P306, DOI 10.1109/AFGR.2000.840651
   Shao M., 2011, CVPR 2011 WORKSH, P60, DOI DOI 10.1109/CVPRW.2011.5981801
   Somanath G., 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P105, DOI 10.1109/BTAS.2012.6374564
   Tran D, 2008, LECT NOTES COMPUT SC, V5302, P548, DOI 10.1007/978-3-540-88682-2_42
   Wolf L, 2011, IEEE T PATTERN ANAL, V33, P1978, DOI 10.1109/TPAMI.2010.230
   Xia S., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, P2539, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422
   Xia SY, 2012, INT C PATT RECOG, P549
   Xia SY, 2012, IEEE T MULTIMEDIA, V14, P1046, DOI 10.1109/TMM.2012.2187436
   Xiao B., 2009, Proceedings of the 17th ACM international conference on Multimedia, P451
   Yan HB, 2014, IEEE T INF FOREN SEC, V9, P1169, DOI 10.1109/TIFS.2014.2327757
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
   Zheng WM, 2006, IEEE T NEURAL NETWOR, V17, P233, DOI 10.1109/TNN.2005.860849
   Zhou X., 2011, ACM Multimedia, P953
   Zhou Xiuzhuang, 2012, P 20 ACM INT C MULT, P725, DOI [DOI 10.1145/2393347, DOI 10.1145/2393347.2396297]
NR 61
TC 42
Z9 45
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 91
EP 97
DI 10.1016/j.imavis.2016.08.009
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800010
DA 2024-07-18
ER

PT J
AU Sun, JH
   Zhang, J
   Zhang, GJ
AF Sun, Junhua
   Zhang, Jie
   Zhang, Guangjun
TI An automatic 3D point cloud registration method based on regional
   curvature maps
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D point cloud; Local shape descriptor; Regional curvature distribution;
   3D surface registration
ID MATCHING ALGORITHM; REPRESENTATION
AB 3D point cloud registration is a fundamental and critical issue in 3D reconstruction and object recognition. Most of the existing methods are based on local shape descriptor. In this paper, we propose a discriminative and robust local shape descriptor-Regional Curvature Map (RCM). The keypoint and its neighboring points are firstly projected onto a 2D plane according to a robust mapping against normal errors. Then, the projection points are quantized into corresponding bins of the 2D support region and their weighted curvatures are encoded into a curvature distribution image. Based on the RCM, an efficient and accurate 3D point cloud registration method is presented. We firstly find 3D point correspondences by a RCM searching and matching strategy based on the sub-regions of the RCM. Then, a coarse registration can be achieved with geometrically consistent point correspondences, followed by a fine registration based on a modified iterative closest point (ICP) algorithm. The experimental results demonstrate that the RCM is distinctive and robust against normal errors and varying point cloud density. The corresponding registration method can achieve a higher registration precision and efficiency compared with two existing registration methods. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Sun, Junhua; Zhang, Jie; Zhang, Guangjun] Beihang Univ, Key Lab Precis Optomechatron Technol, XueYuan Rd 37, Beijing 100191, Peoples R China.
C3 Beihang University
RP Zhang, GJ (corresponding author), Beihang Univ, Key Lab Precis Optomechatron Technol, XueYuan Rd 37, Beijing 100191, Peoples R China.
EM gjzhang@buaa.edu.cn
RI Zhang, Jie/W-4106-2019
FU National Natural Science Foundation of China [61275162]; Innovation
   Foundation of BUAA
FX This work is supported by National Natural Science Foundation of China
   under Grant No. 61275162 and the Innovation Foundation of BUAA for Ph.D.
   Graduates. We would like to thank the Computer Science Department of
   Stanford University for providing the 3D Scanning Repository, the Vision
   Laboratory of University of Western Australia for providing the 3D
   Scanning Dataset and the Oakland 3D point cloud dataset.
CR Aiger D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360684
   Andoni A, 2006, ANN IEEE SYMP FOUND, P459
   Bae KH, 2008, ISPRS J PHOTOGRAMM, V63, P36, DOI 10.1016/j.isprsjprs.2007.05.012
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Chua CS, 1997, INT J COMPUT VISION, V25, P63, DOI 10.1023/A:1007981719186
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Johnson AE, 1999, IMAGE VISION COMPUT, V17, P135, DOI 10.1016/S0262-8856(98)00117-6
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kybic J, 2012, SIGNAL PROCESS, V92, P1302, DOI 10.1016/j.sigpro.2011.11.027
   Liu YH, 2006, IMAGE VISION COMPUT, V24, P762, DOI 10.1016/j.imavis.2006.01.009
   Lucchese L, 2002, IEEE T PATTERN ANAL, V24, P1468, DOI 10.1109/TPAMI.2002.1046160
   Malassiotis S, 2007, IEEE T PATTERN ANAL, V29, P1285, DOI 10.1109/TPAMI.2007.1060
   Men H, 2011, IEEE INT CONF ROBOT, P1511
   Mian AS, 2006, INT J COMPUT VISION, V66, P19, DOI 10.1007/s11263-005-3221-0
   Munoz D, 2009, PROC CVPR IEEE, P975, DOI 10.1109/CVPRW.2009.5206590
   Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33
   Park SY, 2011, MACH VISION APPL, V22, P563, DOI 10.1007/s00138-010-0248-1
   Park SY, 2003, PATTERN RECOGN LETT, V24, P2967, DOI 10.1016/S0167-8655(03)00157-0
   Rodrigues M, 2002, COMPUT VIS IMAGE UND, V87, P1, DOI 10.1006/cviu.2002.0978
   Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012
   Sun Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P263, DOI 10.1109/ICCV.2001.937634
   Tam GKL, 2013, IEEE T VIS COMPUT GR, V19, P1199, DOI 10.1109/TVCG.2012.310
   Yamany SM, 2002, IEEE T PATTERN ANAL, V24, P1105, DOI 10.1109/TPAMI.2002.1023806
   Yu TH, 2013, INT J COMPUT VISION, V102, P180, DOI 10.1007/s11263-012-0563-2
   Yu Zhong, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P689, DOI 10.1109/ICCVW.2009.5457637
NR 27
TC 15
Z9 15
U1 7
U2 69
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2016
VL 56
BP 49
EP 58
DI 10.1016/j.imavis.2016.09.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EF1FW
UT WOS:000390071700004
DA 2024-07-18
ER

PT J
AU Suryanto, CH
   Xue, JH
   Fukui, K
AF Suryanto, Chendra Hadi
   Xue, Jing-Hao
   Fukui, Kazuhiro
TI Randomized time warping for motion recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature extraction; Dynamic time warping; Subspace method; Hankel
   matrix; Motion recognition
ID ALIGNMENT; SUBSPACE; SEQUENCE
AB Dynamic time warping (DTW) has been widely used for the alignment and comparison of two sequential patterns. In DTW, dynamic programming is used to avoid an exhaustive search for the alignment. In this paper, we propose a randomized extension of the DTW concept, termed randomized time warping (RTW), for motion recognition. RTW generates time elastic (TE) features by randomly sampling the sequential data while retaining the temporal information. A set of TE features is represented by a low-dimensional subspace, called the sequence hypothesis (Hypo) subspace, and the similarity between two sequential patterns is defined by the canonical angles between the two corresponding Hypo subspaces. In essence, RTW simultaneously computes multiple degrees of similarities between a number of warped patterns' pair candidates, while in practice, RTW generalizes the Hankel matrix commonly used in modeling of system dynamics. We demonstrate the applicability of RTW through experiments on gesture recognition using three public datasets, namely, the Cambridge gesture database, a subset of the one-shot-learning dataset from the ChaLearn Gesture Challenge, and the KTH action dataset. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Suryanto, Chendra Hadi; Fukui, Kazuhiro] Univ Tsukuba, Dept Comp Sci, Grad Sch Syst & Informat Engn, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan.
   [Xue, Jing-Hao] UCL, Dept Stat Sci, London WC1E 6BT, England.
C3 University of Tsukuba; University of London; University College London
RP Suryanto, CH (corresponding author), Univ Tsukuba, Dept Comp Sci, Grad Sch Syst & Informat Engn, 1-1-1 Tennodai, Tsukuba, Ibaraki 3058573, Japan.
EM chendra@cvlab.cs.tsukuba.ac.jp; jinghao.xue@ucl.ac.uk;
   kfukui@cs.tsukuba.ac.jp
OI Suryanto, Chendra Hadi/0000-0001-5844-2635
FU JSPS KAKENHI [25282173]; Grants-in-Aid for Scientific Research
   [25282173] Funding Source: KAKEN
FX We would like to thank Dr. Yasuhiro Ohkawa, Prof. Hideitsu Hino, and
   Prof. Seiichi Uchida for discussions and suggestions. This work was
   supported by JSPS KAKENHI Grant (No. 25282173).
CR Aggarwal JK, 2011, ACM COMPUT SURV, V43, DOI 10.1145/1922649.1922653
   [Anonymous], 2001, CHALEARN GEST DAT
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587730
   Bahlmann C, 2004, IEEE T PATTERN ANAL, V26, P299, DOI 10.1109/TPAMI.2004.1262308
   Binlong Li, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3193, DOI 10.1109/CVPR.2011.5995672
   Cai D, 2011, VLDB J, V20, P21, DOI 10.1007/s00778-010-0189-3
   Darrell T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P335, DOI 10.1109/CVPR.1993.341109
   Fanello SR, 2013, J MACH LEARN RES, V14, P2617
   Felzenszwalb PF, 2011, IEEE T PATTERN ANAL, V33, P721, DOI 10.1109/TPAMI.2010.135
   Fukui K., 2003, 11 INT S ROBOTICS RE, P192
   Fukui K, 2015, IEEE T PATTERN ANAL, V37, P2164, DOI 10.1109/TPAMI.2015.2408358
   Goussies NA, 2014, J MACH LEARN RES, V15, P3667
   Hamm Jihun, 2008, P 25 INT C MACH LEAR, P376, DOI DOI 10.1145/1390156.1390204
   Harandi MehrtashT., 2013, Pattern Recognition Letters
   Jiang ZL, 2012, IEEE T PATTERN ANAL, V34, P533, DOI 10.1109/TPAMI.2011.147
   Katayama T, 1999, AUTOMATICA, V35, P1635, DOI 10.1016/S0005-1098(99)00072-2
   Kawahara Y., 2006, P C WORKSH NEUR INF, V19, P665
   Kim TK, 2007, IEEE T PATTERN ANAL, V29, P1005, DOI 10.1109/TPAMI.2007.1037
   Kim TK, 2009, IEEE T PATTERN ANAL, V31, P1415, DOI 10.1109/TPAMI.2008.167
   Lichtenauer JF, 2008, IEEE T PATTERN ANAL, V30, P2040, DOI 10.1109/TPAMI.2008.123
   Lui YM, 2012, J MACH LEARN RES, V13, P3297
   Lui YM, 2010, PROC CVPR IEEE, P833, DOI 10.1109/CVPR.2010.5540131
   Maeda K., 1985, Transactions of the Institute of Electronics and Communication Engineers of Japan, Part D, VJ68D, P345
   Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996
   Nakagawa S., 1988, Journal of the Institution of Electronics and Telecommunication Engineers, V34, P87
   NEEDLEMAN SB, 1970, J MOL BIOL, V48, P443, DOI 10.1016/0022-2836(70)90057-4
   Ohkawa Y, 2012, IEICE T INF SYST, VE95D, P1619, DOI 10.1587/transinf.E95.D.1619
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shariat S, 2011, IEEE I CONF COMP VIS, P2572, DOI 10.1109/ICCV.2011.6126545
   Wang Y, 2007, LECT NOTES COMPUT SC, V4814, P240
   Zhang XR, 2013, PATTERN RECOGN, V46, P1819, DOI 10.1016/j.patcog.2012.10.011
   Zhou F., 2009, ADV NEURAL INFORM PR, V22, P1
   Zhou F, 2012, PROC CVPR IEEE, P1282, DOI 10.1109/CVPR.2012.6247812
NR 35
TC 14
Z9 17
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2016
VL 54
BP 1
EP 11
DI 10.1016/j.imavis.2016.07.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EB6UG
UT WOS:000387520500001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gutierrez-Gomez, D
   Guerrero, JJ
AF Gutierrez-Gomez, Daniel
   Guerrero, J. J.
TI True scaled 6 DoF egocentric localisation with monocular wearable
   systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Monocular SLAM; Wearable vision; Egocentric localisation
ID SLAM; MONOSLAM; CAMERA
AB In this work we present a novel approach to obtain scaled odometry and map estimates when performing monocular SLAM with wearable cameras. After proving first that the oscillation of the body during walking can be observed in the odometric estimate from a monocular SLAM algorithm, we develop a method to estimate the walking speed from the frequency of this oscillation. Having the real walking speed, a scale factor can be dynamically computed to obtain a true scaled estimate of the map and visual odometry, avoiding scale drift on long term trajectories. Although the algorithm requires the person to be walking in order to estimate the scale, the experiments, carried out in outdoor and indoor environments and with different types of cameras, show that our method is reliable and robust to challenging situations like stops, changes in pace or stairs, and provides a significant improvement with respect to the initial unscaled estimate. It also outperforms state-of-the-art solutions to correct the scale drift in monocular SLAM, giving in addition the absolute scale of the trajectory and the 3D observed scene. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Gutierrez-Gomez, Daniel; Guerrero, J. J.] Univ Zaragoza, Inst Invest Ingn Aragon I3A, Zaragoza 50018, Spain.
C3 University of Zaragoza
RP Gutierrez-Gomez, D; Guerrero, JJ (corresponding author), Univ Zaragoza, Inst Invest Ingn Aragon I3A, Zaragoza 50018, Spain.
EM danielgg@unizar.es; josechu.guerrero@unizar.es
RI Guerrero, Jose J./K-5435-2014
OI Guerrero, Jose J./0000-0001-5209-2267
FU Ministerio de Economia y Competitividad; European Union
   [DPI2014-61792-EXP, DPI2015-65962-R]; Ministerio de Educacion, Cultura y
   Deporte [FPU AP2012-5507]
FX This work was supported by the Ministerio de Economia y Competitividad
   and European Union (project DPI2014-61792-EXP and DPI2015-65962-R) and
   Ministerio de Educacion, Cultura y Deporte (scholarship FPU
   AP2012-5507).
CR Aghazadeh O., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3297, DOI 10.1109/CVPR.2011.5995731
   Alcantarilla PF, 2012, IEEE INT CONF ROBOT, P1290, DOI 10.1109/ICRA.2012.6224690
   [Anonymous], 2000, P EUR C COMP VIS
   [Anonymous], 2000, Dr. Dobb's Journal of Software Tools
   Aoki H., 1999, P 3 IEEE INT S WEAR, P37
   Badino H., 2011, MVA, P185
   Baglietto M, 2011, ROBOT AUTON SYST, V59, P1060, DOI 10.1016/j.robot.2011.08.005
   Botterill T., 2012, IEEE T SYST MAN CY B, P1767
   Castle RO, 2010, IMAGE VISION COMPUT, V28, P1548, DOI 10.1016/j.imavis.2010.03.009
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276
   Civera J, 2010, J FIELD ROBOT, V27, P609, DOI 10.1002/rob.20345
   Cumani A., 2004, WSEAS Transactions on Computers, V3, P625
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Engel J, 2012, IEEE INT C INT ROBOT, P2815, DOI 10.1109/IROS.2012.6385458
   Eudes Alexandre, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P290, DOI 10.1109/ICPR.2010.80
   Fathi A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3281, DOI 10.1109/CVPR.2011.5995444
   Fathi A, 2012, PROC CVPR IEEE, P1226, DOI 10.1109/CVPR.2012.6247805
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   GRIEVE DW, 1966, ERGONOMICS, V9, P379, DOI 10.1080/00140136608964399
   Gutierrez D., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P343, DOI 10.1109/ICCVW.2011.6130262
   Gutierrez-Gomez D., 2013, INT S WEAR COMP ISWC, P9
   Gutiérrez-Gómez D, 2012, IEEE INT C INT ROBOT, P4276, DOI 10.1109/IROS.2012.6385607
   Hansen P, 2011, IEEE INT CONF ROBOT
   Hesch JA, 2010, INT J ROBOT RES, V29, P1400, DOI 10.1177/0278364910373160
   Hodges S, 2011, MEMORY, V19, P685, DOI 10.1080/09658211.2011.605591
   Kitani K. M., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3241, DOI 10.1109/CVPR.2011.5995406
   Klein George, 2007, P1
   Kneip Laurent, 2014, IEEE INT C ROB AUT I
   Kourogi M, 2001, FIFTH INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS, PROCEEDINGS, P107, DOI 10.1109/ISWC.2001.962109
   Kuo AD, 2001, J BIOMECH ENG-T ASME, V123, P264, DOI 10.1115/1.1372322
   Lothe P, 2010, PROC CVPR IEEE, P863, DOI 10.1109/CVPR.2010.5540127
   Lupton T, 2008, IEEE INT CONF ROBOT, P3698, DOI 10.1109/ROBOT.2008.4543778
   Mann S., 1997, Personal Technologies, V1, P21, DOI [10.1007/BF01317885, DOI 10.1007/BF01317885]
   Mann Steve, 2011, P 19 ACM INT C MULTI, P1325, DOI [DOI 10.1145/2072298.2072005, 10.1145/2072298.2072005]
   Mayol W.W., 2003, INT S ROB RES SIEN I, P325
   Mayol-Cuevas WW, 2009, IEEE T SYST MAN CY A, V39, P414, DOI 10.1109/TSMCA.2008.2010848
   Mitzel D, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.8
   Montemerlo M, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P593
   Mur-Artal R, 2015, IEEE T ROBOT, V31, P1147, DOI 10.1109/TRO.2015.2463671
   Murillo A.C., 2012, 2 IEEE WORKSH EG 1 P
   Nützi G, 2011, J INTELL ROBOT SYST, V61, P287, DOI 10.1007/s10846-010-9490-z
   Pirsiavash H, 2012, PROC CVPR IEEE, P2847, DOI 10.1109/CVPR.2012.6248010
   Ren XF, 2010, PROC CVPR IEEE, P3137, DOI 10.1109/CVPR.2010.5540074
   Rituerto Alejandro, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P348, DOI 10.1109/ICPR.2010.94
   Scaramuzza D, 2008, IEEE T ROBOT, V24, P1015, DOI 10.1109/TRO.2008.2004490
   Scaramuzza D, 2009, IEEE I CONF COMP VIS, P1413, DOI 10.1109/ICCV.2009.5459294
   Scaramuzza D, 2009, IEEE INT CONF ROBOT, P488
   Song SY, 2014, PROC CVPR IEEE, P1566, DOI 10.1109/CVPR.2014.203
   Strasdat H., 2010, Robotics: Science and Systems, V2, P5, DOI [10.1.1. 165.7975, DOI 10.15607/RSS.2010.VI.010]
   Wu CC, 2013, 2013 INTERNATIONAL CONFERENCE ON 3D VISION (3DV 2013), P127, DOI 10.1109/3DV.2013.25
   ZARRUGH MY, 1974, EUR J APPL PHYSIOL O, V33, P293, DOI 10.1007/BF00430237
NR 53
TC 6
Z9 6
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 178
EP 194
DI 10.1016/j.imavis.2016.05.015
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400014
DA 2024-07-18
ER

PT J
AU Cech, J
   Franc, V
   Uricár, M
   Matas, J
AF Cech, Jan
   Franc, Vojtech
   Uricar, Michal
   Matas, Jiri
TI Multi-view facial landmark detection by using a 3D shape model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face; Landmarks; Detection; Localization; 3D model; Shape; Occlusions
AB An algorithm for accurate localization of facial landmarks coupled with a head pose estimation from a single monocular image is proposed. The algorithm is formulated as an optimization problem where the sum of individual landmark scoring functions is maximized with respect to the camera pose by fitting a parametric 3D shape model. The landmark scoring functions are trained by a structured output SVM classifier that takes a distance to the true landmark position into account when learning. The optimization criterion is non-convex and we propose a robust initialization scheme which employs a global method to detect a raw but reliable initial landmark position. Self-occlusions causing landmarks invisibility are handled explicitly by excluding the corresponding contributions from the data term. This allows the algorithm to operate correctly for a large range of viewing angles. Experiments on standard "in-the-wild" datasets demonstrate that the proposed algorithm outperforms several state-of-the-art landmark detectors especially for non-frontal face images. The algorithm achieves the average relative landmark localization error below 10% of the interocular distance in 983% of the 300 W dataset test images. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Cech, Jan; Franc, Vojtech; Uricar, Michal; Matas, Jiri] Czech Tech Univ, Ctr Machine Percept, Dept Cybernet, Fac Elect Engn, Prague, Czech Republic.
C3 Czech Technical University Prague
RP Cech, J (corresponding author), Czech Tech Univ, Ctr Machine Percept, Dept Cybernet, Fac Elect Engn, Prague, Czech Republic.
EM cechj@cmp.felk.cvut.cz; xfrancv@cmp.felk.cvut.cz;
   uricamic@cmp.felk.cvut.cz; matas@cmp.felk.cvut.cz
RI Uřičář, Michal/AAY-9965-2020; Franc, Vojtěch/JAC-6432-2023; ,
   Matas/AAW-3282-2020
OI Uřičář, Michal/0000-0002-2606-4470; Franc, Vojtěch/0000-0001-7189-1224;
   Matas, Jiri/0000-0003-0863-4844
FU Czech Science Foundation [GACR P103/12/G084];  [ERC-CZ LL1303]
FX The first and the last author were supported by the Czech Science
   Foundation Project GACR P103/12/G084. The second author was supported by
   the project ERC-CZ LL1303.
CR Amberg B, 2011, IEEE I CONF COMP VIS, P455, DOI 10.1109/ICCV.2011.6126275
   Ang L., 2011, P ICIP
   [Anonymous], P CVPR
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Baltrusaitis T., 2012, P CVPR
   Cao X., 2012, P CVPR
   Cech J., 2014, P ICPR
   Cootes T., P BMVC 2006, P929
   Cristinacce D., P BMVC 2006, P929
   Fanelli G, 2013, IEEE INT CONF AUTOMA
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Grunert JA., 1841, Grunerts Archiv fur Mathematik und Physik, V1, P238
   Gu Lie, 2006, P CVPR
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Koestinger M., 2011, IEEE INT C COMP VIS, P2144, DOI DOI 10.1109/ICCVW.2011.6130513
   Lepetit V, 2009, INT J COMPUT VISION, V81, P155, DOI 10.1007/s11263-008-0152-6
   NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.1090/S0025-5718-1980-0572855-7
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C., 2013, P CVPR W
   Sagonas C., 2013, P ICCV W
   Snavely N, 2008, INT J COMPUT VISION, V80, P189, DOI 10.1007/s11263-007-0107-3
   Sochman J, 2005, PROC CVPR IEEE, P150
   Teo CH, 2010, J MACH LEARN RES, V11, P311
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Tzimiropoulos G., 2014, P CVPR
   Uricar M., 2015, P BIOM WILD IEEE FG
   Uricar M., P VISAPP 2012, P547
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zhao X, 2011, IEEE T SYST MAN CY B, V41, P1417, DOI 10.1109/TSMCB.2011.2148711
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 33
TC 15
Z9 19
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2016
VL 47
BP 60
EP 70
DI 10.1016/j.imavis.2015.11.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO5LL
UT WOS:000377824500007
DA 2024-07-18
ER

PT J
AU Parvez, MT
AF Parvez, Mohammad Tanvir
TI Optimized polygonal approximations through vertex relocations in contour
   neighborhoods
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Polygonal approximation; Dominant points; Point neighborhood; Vertex
   relocation
ID DOMINANT POINT DETECTION; DIGITAL PLANAR CURVES; DIGITIZED-CURVES;
   ALGORITHM; REPRESENTATION; RECOGNITION
AB This paper presents yet another algorithm for finding polygonal approximations of digital planar curves; however, with a significant distinction: the vertices of an approximating polygon need not lie on the contour itself. This approach gives us more flexibility to reduce the approximation error of the polygon compared to the conventional way, where the vertices of the polygon are restricted to lie on the contour. To compute the approximation efficiently, we adaptively define a local neighborhood of each point on the contour. The vertices of the polygonal approximation are allowed to 'move around' in the neighborhoods. In addition, we demonstrate a general approach where the error measure of an already computed polygonal approximation can possibly be reduced further by vertex relocation, without increasing the number of dominant points. Moreover, the proposed method is non-parametric, requiring no parameter to set for any particular application. Suitability of the proposed algorithm is validated by testing on several databases and comparing with existing methods. (C) 2014 Elsevier B.V. All rights reserved.
C1 Qassim Univ, Dept Comp Engn, Qasim 51477, Saudi Arabia.
C3 Qassim University
RP Parvez, MT (corresponding author), Qassim Univ, Dept Comp Engn, Qasim 51477, Saudi Arabia.
EM m.parvez@qu.edu.sa
FU Qassim University, Saudi Arabia
FX We thank Qassim University, Saudi Arabia, for partially supporting this
   research work. The author is grateful to Prof. Sabri A. Mahmoud for
   critical comments at the early stage of this work. The author also
   thanks the anonymous reviewers for their comments that greatly improved
   the clarity of the paper.
CR ABUHAIBA ISI, 1994, IEEE T PATTERN ANAL, V16, P664, DOI 10.1109/34.295912
   Attneave F., 1954, PSYCHOL REV, V61, P189, DOI DOI 10.1037/H0054663
   Awrangjeb M, 2012, IEEE T IMAGE PROCESS, V21, P4167, DOI 10.1109/TIP.2012.2200493
   BELLMAN R, 1961, COMMUN ACM, V4, P284, DOI 10.1145/366573.366611
   Carmona-Poyato A, 2005, IMAGE VISION COMPUT, V23, P1226, DOI 10.1016/j.imavis.2005.07.025
   Carmona-Poyato A, 2010, PATTERN RECOGN, V43, P14, DOI 10.1016/j.patcog.2009.06.010
   Chau CP, 2001, IEE P-VIS IMAGE SIGN, V148, P363, DOI 10.1049/ip-vis:20010576
   HOSUR PI, 1999, IEEE 3 WORKSH MULT S, P309
   Jeannin S., 1999, ISOIECITC1SC29WG11MP
   Kolesnikov A, 2012, PATTERN RECOGN LETT, V33, P1329, DOI 10.1016/j.patrec.2012.02.015
   Marji M, 2004, PATTERN RECOGN, V37, P2113, DOI 10.1016/j.patcog.2004.03.004
   Marji M, 2003, PATTERN RECOGN, V36, P2239, DOI 10.1016/S0031-3203(03)00119-5
   Masood A, 2008, PATTERN RECOGN, V41, P227, DOI 10.1016/j.patcog.2007.05.021
   MONTNARI U, 1970, COMMUN ACM, V13, P41, DOI 10.1145/361953.361967
   Nguyen TP, 2011, PATTERN RECOGN, V44, P32, DOI 10.1016/j.patcog.2010.06.022
   Parvez MT, 2013, PATTERN RECOGN, V46, P141, DOI 10.1016/j.patcog.2012.07.012
   Parvez MT, 2010, PATTERN RECOGN LETT, V31, P1997, DOI 10.1016/j.patrec.2010.06.007
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   Prasad DK, 2012, IMAGE VISION COMPUT, V30, P843, DOI 10.1016/j.imavis.2012.06.010
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   Stone H., 1961, Math. Comp., P40, DOI DOI 10.1090/S0025-5718-1961-0119390-6
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Wu WY, 2003, PATTERN RECOGN, V36, P2231, DOI 10.1016/S0031-3203(03)00087-6
   Zhang DS, 2004, PATTERN RECOGN, V37, P1, DOI 10.1016/j.patcog.2003.07.008
   Zhu Y, 1997, IEE P-VIS IMAGE SIGN, V144, P8, DOI 10.1049/ip-vis:19970985
NR 25
TC 10
Z9 10
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2015
VL 34
BP 1
EP 10
DI 10.1016/j.imavis.2014.10.012
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA5OB
UT WOS:000348956600001
DA 2024-07-18
ER

PT J
AU Yang, X
   Qiao, H
   Liu, ZY
AF Yang, Xu
   Qiao, Hong
   Liu, Zhi-Yong
TI Feature correspondence based on directed structural model matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature correspondence; Directed structural model; Graph matching
ID GRAPH; RECOGNITION; ALGORITHM
AB Feature correspondence lays the foundation for many tasks in computer vision and pattern recognition. In this paper the directed structural model is utilized to represent the feature set, and the correspondence problem is then formulated as the structural model matching. Compared with the undirected structural model, the proposed directed model provides more discriminating ability and invariance against rotation and scale transformations. Finally, the recently proposed convex-concave relaxation procedure (CCRP) is generalized to approximately solve the problem. Extensive experiments on synthetic and real data witness the effectiveness of the proposed method. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Yang, Xu; Qiao, Hong; Liu, Zhi-Yong] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Liu, ZY (corresponding author), Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
EM xu.yang@ia.ac.cn; hong.qiao@ia.ac.cn; zhiyong.liu@ia.ac.cn
RI zhang, liwen/L-7005-2016
FU National Science Foundation of China (NSFC) [61375005, 61033011,
   61210009, 61101221]; National Key Technology RD Program [2012BAI34B02]
FX The authors would like to thank the editors and anonymous reviewers
   whose comments and suggestions greatly improved the manuscript. This
   work was supported by the National Science Foundation of China (NSFC)
   (grants 61375005, 61033011, 61210009, 61101221) and by National Key
   Technology R&D Program (grant 2012BAI34B02).
CR [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], ICPR WORKSH LEARN AD
   [Anonymous], 2010, 2010 4 IEEE INT C BI, DOI DOI 10.1109/BTAS.2010.5634496
   [Anonymous], 2012, Proceedings of the Asian Conference on Machine Learning, volume 25 of Proceedings of Machine Learning Research
   [Anonymous], P IEEE INT C COMP VI
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Belongie S, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P20, DOI 10.1109/IVL.2000.853834
   Berg AC, 2005, PROC CVPR IEEE, P26
   Boyd S., 2004, CONVEX OPTIMIZATION
   Caetano TS, 2009, IEEE T PATTERN ANAL, V31, P1048, DOI 10.1109/TPAMI.2009.28
   Carcassoni M, 2003, PATTERN RECOGN, V36, P193, DOI 10.1016/S0031-3203(02)00054-7
   Conte D, 2007, STUD COMPUT INTELL, V52, P85
   Dorkó G, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P634
   Duchenne O, 2011, IEEE T PATTERN ANAL, V33, P2383, DOI 10.1109/TPAMI.2011.110
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Frank M., 1956, Naval research logistics quarterly, V3, P95, DOI [10.1002/nav.3800030109, DOI 10.1002/NAV.3800030109]
   FUKUSHIMA M, 1984, TRANSPORT RES B-METH, V18, P169, DOI 10.1016/0191-2615(84)90029-8
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Huang K, 2002, PATTERN RECOGN, V35, P2467, DOI 10.1016/S0031-3203(01)00222-9
   Jaggi M., 2013, P 30 INT C MACH LEAR, V28, P427
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lee J, 2011, PROC CVPR IEEE, P1633, DOI 10.1109/CVPR.2011.5995387
   Leordeanu M, 2005, IEEE I CONF COMP VIS, P1482
   Liu CL, 2011, PROC INT CONF DOC, P37, DOI 10.1109/ICDAR.2011.17
   Liu ZY, 2012, IEEE T PATTERN ANAL, V34, P1451, DOI 10.1109/TPAMI.2012.45
   Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151
   Ng ES, 2010, IEEE IMAGE PROC, P2693, DOI 10.1109/ICIP.2010.5651903
   Noma A., 2010, Proceedings of the 23rd SIBGRAPI Conference on Graphics, Patterns and Images (SIBGRAPI 2010), P186, DOI 10.1109/SIBGRAPI.2010.33
   Qiu HJ, 2006, PATTERN RECOGN, V39, P22, DOI 10.1016/j.patcog.2005.06.014
   Schellewald C, 2005, LECT NOTES COMPUT SC, V3757, P171, DOI 10.1007/11585978_12
   Siddiqi K, 1999, INT J COMPUT VISION, V35, P13, DOI 10.1023/A:1008102926703
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Torresani L, 2008, LECT NOTES COMPUT SC, V5303, P596, DOI 10.1007/978-3-540-88688-4_44
   UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778
   Wallraven C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P257
   Yarkony J, 2010, PROC CVPR IEEE, P887, DOI 10.1109/CVPR.2010.5540122
   Zaslavskiy M, 2009, IEEE T PATTERN ANAL, V31, P2227, DOI 10.1109/TPAMI.2008.245
   Zhou F, 2012, PROC CVPR IEEE, P127, DOI 10.1109/CVPR.2012.6247667
NR 39
TC 11
Z9 19
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2015
VL 33
BP 57
EP 67
DI 10.1016/j.imavis.2014.11.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AZ5KY
UT WOS:000348261100005
DA 2024-07-18
ER

PT J
AU De Marsico, M
   Galdi, C
   Nappi, M
   Riccio, D
AF De Marsico, Maria
   Galdi, Chiara
   Nappi, Michele
   Riccio, Daniel
TI FIRME: Face and Iris Recognition for Mobile Engagement
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Android; Face authentication; Iris authentication; Identity management;
   Mobile computing; Open source; Pervasive computing; Security; Spoofing
   detection
ID QUOTIENT IMAGE
AB Mobile devices, namely phones and tablets, have long gone "smart". Their growing use is both a cause and an effect of their technological advancement. Among the others, their increasing ability to store and exchange sensitive information, has caused interest in exploiting their vulnerabilities, and the opposite need to protect users and their data through secure protocols for access and identification on mobile platforms. Face and iris recognition are especially attractive, since they are sufficiently reliable, and just require the webcam normally equipping the involved devices. On the contrary, the alternative use of fingerprints requires a dedicated sensor. Moreover, some Icinds of biometrics lend themselves to uses that go beyond security. Ambient intelligence services bound to the recognition of a user, as well as social applications, such as automatic photo tagging on social networks, can especially exploit face recognition. This paper describes FIRME (Face and Iris Recognition for Mobile Engagement) as a biometric application based on a multimodal recognition of face and iris, which is designed to be embedded in mobile devices. Both design and implementation of FIRME rely on a modular architecture, whose workflow includes separate and replaceable packages. The starting one handles image acquisition. From this point, different branches perform detection, segmentation, feature extraction, and matching for face and iris separately. As for face, an antispoofing step is also performed after segmentation. Finally, results from the two branches are fused. In order to address also security-critical applications, FIRME can perform continuous reidentification and best sample selection. To further address the possible limited resources of mobile devices, all algorithms are optimized to be low-demanding and computation-light. (C) 2014 Elsevier B.V. All rights reserved.
C1 [De Marsico, Maria] Univ Roma La Sapienza, Rome, Italy.
   [Galdi, Chiara; Nappi, Michele] Univ Salerno, Salerno, Italy.
   [Riccio, Daniel] Univ Naples Federico II, I-80138 Naples, Italy.
C3 Sapienza University Rome; University of Salerno; University of Naples
   Federico II
RP De Marsico, M (corresponding author), Univ Roma La Sapienza, Rome, Italy.
EM demarsico@di.uniroma1.it; cgaldi@unisa.it; mnappi@unisa.it;
   daniel.riccio@unina.it
RI De Marsico, Maria/K-6684-2015; Nappi, Michele/X-3089-2019; Riccio,
   Daniel/JGM-4522-2023; Galdi, Chiara/A-6073-2017
OI De Marsico, Maria/0000-0002-1391-8502; Galdi,
   Chiara/0000-0002-7129-0709; Nappi, Michele/0000-0002-2517-2867; Riccio,
   Daniel/0000-0002-5844-0602
CR [Anonymous], GLOB MOB STAT 2012 A
   [Anonymous], ISI 58 WORLD STAT C
   De Marsico M., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P73, DOI 10.1109/ICB.2012.6199761
   De Marsico M., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2857, DOI 10.1109/ICPR.2010.700
   De Marsico M, 2011, IEEE T SYST MAN CY C, V41, P481, DOI 10.1109/TSMCC.2010.2060326
   De Marsico M, 2010, IEEE IMAGE PROC, P1597, DOI 10.1109/ICIP.2010.5650758
   DeMarsico M, 2012, SPRINGER J
   Derawi M. O., 2010, Proceedings of the 2010 Sixth International Conference on Intelligent Information Hiding and Multimedia Signal Processing (IIHMSP 2010), P306, DOI 10.1109/IIHMSP.2010.83
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   IBM X-Force, 2011, BUILT NOT BOLT SMART
   Ijiri Y., 2006, P 7 INT C MOB DAT MA, P1
   Jain AK, 2004, COMMUN ACM, V47, P34, DOI 10.1145/962081.962102
   Jeong DS, 2006, LECT NOTES COMPUT SC, V3832, P457
   Khan MK, 2008, CHAOS SOLITON FRACT, V35, P519, DOI 10.1016/j.chaos.2006.05.061
   Ko JG, 2007, ETRI J, V29, P399, DOI 10.4218/etrij.07.0206.0141
   Lu HQ, 2007, PROCEEDING OF THE 2007 IEEE/WIC/ACM INTERNATIONAL CONFERENCE ON WEB INTELLIGENCE AND INTELLIGENT AGENT TECHNOLOGY, WORKSHOPS, P480
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Sasse M. A., 1994, P INET 94 JENC5 C, P251
   Shashua A, 2001, IEEE T PATTERN ANAL, V23, P129, DOI 10.1109/34.908964
   Sideco F., 2012, MOBILE COMMUNICATION
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   Tresadern P, 2013, IEEE PERVAS COMPUT, V12, P79, DOI 10.1109/MPRV.2012.54
   Trewin S, 2012, 28TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2012), P159
   Wang HT, 2004, IEEE IMAGE PROC, P1397
NR 24
TC 92
Z9 98
U1 1
U2 42
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1161
EP 1172
DI 10.1016/j.imavis.2013.12.014
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600017
DA 2024-07-18
ER

PT J
AU Dharmagunawardhana, C
   Mahmoodi, S
   Bennett, M
   Niranjan, M
AF Dharmagunawardhana, Chathurika
   Mahmoodi, Sasan
   Bennett, Michael
   Niranjan, Mahesan
TI Gaussian Markov random field based improved texture descriptor for image
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gaussian Markov random field; Texture feature extraction; Local feature
   distributions; Local linear regression; Texture segmentation; Natural
   image analysis
ID CLASSIFICATION; REGRESSION; FEATURES; FILTERS; SCALE
AB This paper proposes a novel robust texture descriptor based on Gaussian Markov random fields (GMRFs). A spatially localized parameter estimation technique using local linear regression is performed and the distributions of local parameter estimates are constructed to formulate the texture features. The inconsistencies arising in localized parameter estimation are addressed by applying generalized inverse, regularization and an estimation window size selection criterion. The texture descriptors are named as local parameter histograms (LPHs) and are used in texture segmentation with the k-means clustering algorithm. The segmentation results on general texture datasets demonstrate that LPH descriptors significantly improve the performance of classical GMRF features and achieve better results compared to the state-of-the-art texture descriptors based on local feature distributions. Impressive natural image segmentation results are also achieved and comparisons to the other standard natural image segmentation algorithms are also presented. LPH descriptors produce promising texture features that integrate both statistical and structural information about a texture. The region boundary localization can be further improved by integrating colour information and using advanced segmentation algorithms. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Dharmagunawardhana, Chathurika; Mahmoodi, Sasan; Niranjan, Mahesan] Univ Southampton, Sch Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
   [Bennett, Michael] Univ Hosp Southampton NHS Fdn Trust, Southampton Resp Biomed Res, Natl Inst Hlth Res, Southampton, Hants, England.
C3 University of Southampton; University of Southampton; University
   Hospital Southampton NHS Foundation Trust
RP Dharmagunawardhana, C (corresponding author), Univ Southampton, Sch Elect & Comp Sci, Bldg 1, Southampton SO17 1BJ, Hants, England.
EM cd6g10@ecs.soton.ac.uk; sm3@ecs.soton.ac.uk;
   michael.bennett@soton.ac.uk; mn@ecs.soton.ac.uk
OI Bennett, Michael/0000-0002-2930-4900; Niranjan,
   Mahesan/0000-0001-7021-140X
CR [Anonymous], P INT C IM PROC IEEE
   [Anonymous], P IEEE INT C AC SPEE
   [Anonymous], P 3 BMVC WORKSH
   [Anonymous], 2008, ELECT LETT COMPUTER
   [Anonymous], P 8 IEEE INT C SIGN
   [Anonymous], NATURAL IMAGE SEGMEN
   [Anonymous], 3 INT C COMP VIS THE
   [Anonymous], 7 NAT S PATT REC IM
   [Anonymous], P IEEE INT C IM PROC
   [Anonymous], INT WORKSH TEXT AN S
   [Anonymous], RANDOM FIELD MODELIN
   [Anonymous], MAP EM MRFS ALL USER
   [Anonymous], 2008, P 2008 19 INT C PATT
   Besag J, 1995, BIOMETRIKA, V82, P733, DOI 10.2307/2337341
   Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428
   Bosnjak A, 1998, COMPUT CARDIOL, V25, P457, DOI 10.1109/CIC.1998.731901
   Brodatz P., 1996, TEXTURES PHOTOGRAPHI
   Çesmeli E, 2001, IEEE T NEURAL NETWOR, V12, P394, DOI 10.1109/72.914533
   CHELLAPPA R, 1985, IEEE T ACOUST SPEECH, V33, P959, DOI 10.1109/TASSP.1985.1164641
   Comer ML, 1999, IEEE T IMAGE PROCESS, V8, P408, DOI 10.1109/83.748895
   Dana KJ, 1997, PROC CVPR IEEE, P151, DOI 10.1109/CVPR.1997.609313
   Deng HW, 2004, IEEE T PATTERN ANAL, V26, P951, DOI 10.1109/TPAMI.2004.30
   Descombes X, 1999, IEEE T IMAGE PROCESS, V8, P490, DOI 10.1109/83.753737
   Dharmagunawardhana C, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.88
   Dharmagunawardhana C, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3, P44
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Gupta MR, 2008, IEEE T IMAGE PROCESS, V17, P936, DOI 10.1109/TIP.2008.922429
   Houhou N, 2009, NUMER MATH-THEORY ME, V2, P445, DOI 10.4208/nmtma.2009.m9007s
   Kim DH, 2006, INT C PATT RECOG, P365
   Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Liu XW, 2003, IEEE T IMAGE PROCESS, V12, P661, DOI 10.1109/TIP.2003.812327
   Mahmoudi S.R., 2011, Proc. of ESA Annual Meeting, P1, DOI DOI 10.1109/ICEAC.2011.6136695
   MANJUNATH BS, 1991, IEEE T PATTERN ANAL, V13, P478, DOI 10.1109/34.134046
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Mobahi H, 2011, INT J COMPUT VISION, V95, P86, DOI 10.1007/s11263-011-0444-0
   Myung IJ, 2003, J MATH PSYCHOL, V47, P90, DOI 10.1016/S0022-2496(02)00028-7
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T, 2001, PATTERN RECOGN, V34, P727, DOI 10.1016/S0031-3203(00)00010-8
   Penrose R., 1956, P CAMB PHILOS SOC, P17, DOI 10.1017/s0305004100030929
   Petrou Maria., 2006, IMAGE PROCESSING DEA
   Pietikäinen M, 2000, PATTERN RECOGN, V33, P43, DOI 10.1016/S0031-3203(99)00032-1
   Portilla J, 2003, IEEE T IMAGE PROCESS, V12, P1338, DOI 10.1109/TIP.2003.818640
   Rue Havard, 2005, Gaussian Markov Random Fields: Theory and Applications, DOI DOI 10.1201/9780203492024
   Sagiv C, 2006, IEEE T IMAGE PROCESS, V15, P1633, DOI 10.1109/TIP.2006.871133
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Stan S, 2002, PATTERN RECOGN LETT, V23, P1229, DOI 10.1016/S0167-8655(02)00070-3
   Sujaritha M., 2010, Int J Signal Process, V6, P28
   SULLIVAN BJ, 1984, IEEE T ACOUST SPEECH, V32, P1201, DOI 10.1109/TASSP.1984.1164462
   Takeda H, 2007, IEEE T IMAGE PROCESS, V16, P349, DOI 10.1109/TIP.2006.888330
   Trevor H., 2009, The Elements of Statistical Learning: Data Mining, Inference, and Prediction
   Tuceryan M., 1998, HDB PATTERN RECOGNIT, V2nd
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Xia Y, 2006, IEEE T IMAGE PROCESS, V15, P3559, DOI 10.1109/TIP.2006.877513
   Xun Huang, 2011, 2011 International Conference on Image Analysis and Signal Processing (IASP 2011), P167, DOI 10.1109/IASP.2011.6109022
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang JG, 2002, INT C PATT RECOG, P901, DOI 10.1109/ICPR.2002.1048450
   Zhao YD, 2007, IEEE T GEOSCI REMOTE, V45, P1458, DOI 10.1109/TGRS.2007.892602
   Zhu SC, 1998, INT J COMPUT VISION, V27, P107, DOI 10.1023/A:1007925832420
   Zhu SQ, 2012, LECT NOTES COMPUT SC, V7576, P101, DOI 10.1007/978-3-642-33715-4_8
NR 60
TC 24
Z9 26
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 884
EP 895
DI 10.1016/j.imavis.2014.07.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900006
DA 2024-07-18
ER

PT J
AU Smolyanskiy, N
   Huitema, C
   Liang, L
   Anderson, SE
AF Smolyanskiy, Nikolai
   Huitema, Christian
   Liang, Lin
   Anderson, Sean Eron
TI Real-time 3D face tracking based on active appearance model constrained
   by depth data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face tracking; Active Appearance Models; Morphable models; Fitting;
   Gradient descent; Kinect
AB Active Appearance Model (AMM) is an algorithm for fitting a generative model of object shape and appearance to an input image. MM allows accurate, real-time tracking of human faces in 2D and can be extended to track faces in 3D by constraining its fitting with a linear 3D morphable model. Unfortunately, this MM-based 3D tracking does not provide adequate accuracy and robustness, as we show in this paper. We introduce a new constraint into MM fitting that uses depth data from a commodity RGBD camera (Kinect). This addition significantly reduces 3D tracking errors. We also describe how to initialize the 3D morphable face model used in our tracking algorithm by computing its face shape parameters of the user from a batch of tracked frames. The described face tracking algorithm is used in Microsoft's Kinect system. (C) 2014 The Authors. Published by Elsevier B.V.
C1 [Smolyanskiy, Nikolai; Huitema, Christian; Liang, Lin; Anderson, Sean Eron] Microsoft, Redmond, WA 98052 USA.
C3 Microsoft
RP Smolyanskiy, N (corresponding author), Microsoft, Redmond, WA 98052 USA.
EM nikolays@microsoft.com; huitema@microsoft.com; lliang@microsoft.com;
   seana@microsoft.com
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   BAKER S, 2004, CMURITR0414
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Bouaziz S., 2013, ACM T GRAPHICS SIGGR
   Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0
   Cootes TF, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P748, DOI 10.1109/ICCV.2001.937601
   Lengagne R, 1998, INT C PATT RECOG, P637, DOI 10.1109/ICPR.1998.711224
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377
   Scott IM, 2003, LECT NOTES COMPUT SC, V2732, P258
   Weise T., 2011, ACM T GRAPHICS SIGGR
   Xiao J, 2004, PROC CVPR IEEE, P535
   Zhang W, 2008, LECT NOTES COMPUT SC, V5303, P720, DOI 10.1007/978-3-540-88688-4_53
   Zhou MC, 2010, PROC CVPR IEEE, P701, DOI 10.1109/CVPR.2010.5540146
NR 18
TC 32
Z9 37
U1 0
U2 21
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 860
EP 869
DI 10.1016/j.imavis.2014.08.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900004
OA hybrid
DA 2024-07-18
ER

PT J
AU Bai, YC
   Tang, M
AF Bai, Yancheng
   Tang, Ming
TI Robust visual tracking via augmented kernel SVM
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature representation; Appearance model; Augmented Kernel Matrix (AKM)
AB Most current tracking approaches utilize only one type of feature to represent the target and learn the appearance model of the target just by using the current frame or a few recent ones. The limited representation of one single type of feature might not represent the target well. What's more, the appearance model learning from the current frame or a few recent ones is intolerant of abrupt appearance changes in short time intervals. These two factors might cause the track's failure. To overcome these two limitations, in this paper, we apply the Augmented Kernel Matrix (AKM) classification to combine two complementary features, pixel intensity and LBP (Local Binary Pattern) features, to enrich the target's representation. Meanwhile, we employ the AKM clustering to group the tracking results into a few aspects. And then, the representative patches are selected and added into the training set to learn the appearance model. This makes the appearance model cover more aspects of the target appearance and more robust to abrupt appearance changes. Experiments compared with several state-of-the-art methods on challenging sequences demonstrate the effectiveness and robustness of the proposed algorithm. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Bai, Yancheng; Tang, Ming] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100864, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Tang, M (corresponding author), Room 1404,Intelligent Bldg, Beijing 100190, Peoples R China.
EM ycbai@nlpr.ia.ac.cn; tangm@nlpr.ia.ac.cn
FU National Natural Science Foundation of China [61375035]
FX We thank the reviewers and editors for helpful feedbacks. This work is
   supported by the National Natural Science Foundation of China under
   Grants No. 61375035.
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2007, Computer Vision
   [Anonymous], 2007, 2007 IEEE C COMP VIS
   [Anonymous], 2004, P 21 INT C MACH LEAR
   Awais M, 2011, LECT NOTES COMPUT SC, V6713, P137, DOI 10.1007/978-3-642-21557-5_16
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Bai YC, 2012, PROC CVPR IEEE, P1854, DOI 10.1109/CVPR.2012.6247884
   Ben-Hur A, 2002, J MACH LEARN RES, V2, P125, DOI 10.1162/15324430260185565
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Gehler P, 2009, IEEE I CONF COMP VIS, P221, DOI 10.1109/ICCV.2009.5459169
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   KIM T.-K., 2010, 2010 IEEE COMPUTER S, P1
   Kwon J, 2011, IEEE I CONF COMP VIS, P1195, DOI 10.1109/ICCV.2011.6126369
   Kwon J, 2010, PROC CVPR IEEE, P1269, DOI 10.1109/CVPR.2010.5539821
   Lee WJ, 2011, LECT NOTES COMPUT SC, V6713, P116, DOI 10.1007/978-3-642-21557-5_14
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Park DW, 2012, PROC CVPR IEEE, P1964, DOI 10.1109/CVPR.2012.6247898
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Tang M, 2012, IEEE T IMAGE PROCESS, V21, P3273, DOI 10.1109/TIP.2012.2189580
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Viola P., 2006, Proceedings of Advances in Neural Information Processing Systems, V18, P1417
   Vishwanathan S., 2010, Proc. of Neural Information Processing Systems, P2361
   Yan F, 2010, LECT NOTES COMPUT SC, V5997, P175, DOI 10.1007/978-3-642-12127-2_18
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
NR 27
TC 8
Z9 9
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 465
EP 475
DI 10.1016/j.imavis.2014.04.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600002
DA 2024-07-18
ER

PT J
AU Ma, BP
   Su, Y
   Jurie, F
AF Ma, Bingpeng
   Su, Yu
   Jurie, Frederic
TI Covariance descriptor based on bio-inspired features for person
   re-identification and face verification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image representation; Person re-identification; Face verification;
   Biologically inspired features; Covariance descriptor
ID OBJECT RECOGNITION; CLASSIFICATION
AB Avoiding the use of complicated pre-processing steps such as accurate face and body part segmentation or image normalization, this paper proposes a novel face/person image representation which can properly handle background and illumination variations. Denoted as gBiCov, this representation relies on the combination of Biologically Inspired Features (BIF) and Covariance descriptors [1]. More precisely, gBiCov is obtained by computing and encoding the difference between BIF features at different scales. The distance between two persons can then be efficiently measured by computing the Euclidean distance of their signatures, avoiding some time consuming operations in Riemannian manifold required by the use of Covariance descriptors. In addition, the recently proposed KISSME framework [2] is adopted to learn a metric adapted to the representation. To show the effectiveness of gBiCov, experiments are conducted on three person re-identification tasks (VIPeR, i-LIDS and ETHZ) and one face verification task (LFW), on which competitive results are obtained. As an example, the matching rate at rank 1 on the VIPeR dataset is of 31.11%, improving the best previously published result by more than 10. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Ma, Bingpeng] Univ China Acad Sci, Sch Comp & Control Engn, Beijing, Peoples R China.
   [Su, Yu; Jurie, Frederic] Univ Caen Basse Normandie, GREYC CNRS UMR 6072, Caen, France.
C3 Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS; Centre National de la Recherche Scientifique (CNRS); Universite de
   Caen Normandie
RP Jurie, F (corresponding author), Univ Caen Basse Normandie, GREYC CNRS UMR 6072, Caen, France.
EM bpma@ucas.ac.cn; nanosuyu@gmail.com; frederic.jurie@unicaen.fr
FU OSEO; French State agency for innovation; ANR
   [ANR-08-SECU-008-01/SCARFACE]; National Natural Science Foundation of
   China [61003103, 61173065]
FX This work was partly realized as part of the Quaero Program funded by
   the OSEO, French State agency for innovation and by the ANR, grant
   reference ANR-08-SECU-008-01/SCARFACE. The first author' is partially
   supported by National Natural Science Foundation of China under contract
   Nos. 61003103 and 61173065.
CR [Anonymous], P IEEE INT C COMP VI
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2007, 10 INT WORKSH PERF E
   [Anonymous], P AS C COMP VIS
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2009, PROC BRIT MACH VIS C
   [Anonymous], P INT C ADV VID SIGN
   [Anonymous], BRAZ S COMP GRAPH IM
   [Anonymous], P BRIT MACH VIS C
   Ayedi W., 2011, PATTERN RECOGN LETT, P1902
   Aziz Kheir-Eddine, 2011, Proceedings of the 2011 8th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2011), P303, DOI 10.1109/AVSS.2011.6027341
   Aziz KE, 2011, LECT NOTES COMPUT SC, V6754, P170, DOI 10.1007/978-3-642-21596-4_18
   Bak S., 2010, P INT WORKSH ACT MON
   Bak S., 2011, P INT C ADV VID SIGN
   Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Davis J. V., 2007, ICML, P209
   Ess A., 2008, COMPUTER VISION PATT, V2008, P1, DOI [10.1109/CVPR.2008.4587581, DOI 10.1109/CVPR.2008.4587581]
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Figueira D, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P111, DOI 10.1109/AVSS.2013.6636625
   Gandhi T, 2007, MACH VISION APPL, V18, P207, DOI 10.1007/s00138-006-0063-x
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Globerson A., 2006, METRIC LEARNING COLL
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Guo GD, 2009, PROC CVPR IEEE, P112, DOI 10.1109/CVPRW.2009.5206681
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Huang G.B., 2008, PROC WORKSHOP FACES
   Jungling Kai., 2011, COMPUTER VISION PATT, P55, DOI 10.1109/CVPRW.2011.5981771
   Köstinger M, 2012, PROC CVPR IEEE, P2288, DOI 10.1109/CVPR.2012.6247939
   Ma BP, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.57
   Meyers E, 2008, INT J COMPUT VISION, V76, P93, DOI 10.1007/s11263-007-0058-8
   Mignon A, 2012, PROC CVPR IEEE, P2666, DOI 10.1109/CVPR.2012.6247987
   Moon H, 2001, PERCEPTION, V30, P303, DOI 10.1068/p2896
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Perronnin F, 2010, PROC CVPR IEEE, P3384, DOI 10.1109/CVPR.2010.5540009
   Riesenhuber M, 1999, NAT NEUROSCI, V2, P1019, DOI 10.1038/14819
   Ruiz-del-Solar J, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/184617
   Satta R., 2011, INT C IM AN PROC
   Satta R., 2011, INT WORKSH SIM BAS P
   Seo HJ, 2011, IEEE T INF FOREN SEC, V6, P1275, DOI 10.1109/TIFS.2011.2159205
   Serre T, 2005, PROC CVPR IEEE, P994
   Song DJ, 2010, IEEE T IMAGE PROCESS, V19, P174, DOI 10.1109/TIP.2009.2032939
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Ying Zhang, 2011, Proceedings of the Sixth International Conference on Image and Graphics (ICIG 2011), P368, DOI 10.1109/ICIG.2011.40
   Zheng WS, 2013, IEEE T PATTERN ANAL, V35, P653, DOI 10.1109/TPAMI.2012.138
   Zheng WS, 2011, PROC CVPR IEEE, P649, DOI 10.1109/CVPR.2011.5995598
NR 53
TC 213
Z9 237
U1 0
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2014
VL 32
IS 6-7
BP 379
EP 390
DI 10.1016/j.imavis.2014.04.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AJ4QM
UT WOS:000337660900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhu, ZF
   Chen, Q
   Zhao, Y
AF Zhu, Zhenfeng
   Chen, Qian
   Zhao, Yao
TI Ensemble dictionary learning for saliency detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Saliency detection; Dictionary learning; Sparse representation; Ensemble
   learning
ID VISUAL-ATTENTION
AB The human visual system (HSV) is quite adept at swiftly detecting objects of interest in complex visual scene. Simulating human visual system to detect visually salient regions of an image has been one of the active topics in computer vision. Inspired by random sampling based bagging ensemble learning method, an ensemble dictionary learning (EDL) framework for saliency detection is proposed in this paper. Instead of learning a universal dictionary requiring a large number of training samples to be collected from natural images, multiple over-complete dictionaries are independently learned with a small portion of randomly selected samples from the input image itself, resulting in more flexible multiple sparse representations for each of the image patches. To boost the distinctness of salient patch from background region, we present a reconstruction residual based method for dictionary atom reduction. Meanwhile, with the obtained multiple probabilistic saliency responses for each of the patches, the combination of them is finally carried out from the probabilistic perspective to achieve better predictive performance on saliency region. Experimental results on several open test datasets and some natural images demonstrate that the proposed EDL for saliency detection is much more competitive compared with some existing state-of-the-art algorithms. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Zhu, Zhenfeng] Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
   Beijing Key Lab Adv Informat Sci & Network Techno, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Zhu, ZF (corresponding author), Beijing Jiaotong Univ, Inst Informat Sci, Beijing 100044, Peoples R China.
EM zhfzhu@bjtu.edu.cn
RI Chen, Qian/G-1349-2011
OI Chen, Qian/0000-0001-7541-1419
FU National Basic Research Program of China [2012CB316400]; National
   Natural Science Foundation of China [61025013, 61172129, 61210006];
   Program for Changjiang Scholars and Innovative Research Team in
   University [IRT201206]; Program for New Century Excellent Talents in
   University [13-0661]; Fundamental Research Funds for the Central
   Universities [2012JBZ012]; Natural Science Foundation of Beijing, China
   [4112043]
FX This work was supported in part by the National Basic Research Program
   of China (no. 2012CB316400), the National Natural Science Foundation of
   China (no. 61025013, no. 61172129, and no. 61210006), the Program for
   Changjiang Scholars and Innovative Research Team in University (no.
   IRT201206), the Program for New Century Excellent Talents in University
   (no. 13-0661), the Fundamental Research Funds for the Central
   Universities (no. 2012JBZ012), and the Natural Science Foundation of
   Beijing, China (no. 4112043). The authors would like to thank the
   anonymous reviewers for their constructive and valuable comments.
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2011, Proceedings of the 19th ACM international conference on Multimedia
   [Anonymous], 2004, CVPR
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Bradley AP, 2003, J VIS COMMUN IMAGE R, V14, P232, DOI 10.1016/S1047-3203(03)00037-3
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Fang YM, 2012, IEEE T IMAGE PROCESS, V21, P3888, DOI 10.1109/TIP.2012.2199126
   Gao D, 2007, IEEE INT C COMP VIS
   Han JW, 2006, IEEE T CIRC SYST VID, V16, P141, DOI 10.1109/TCSVT.2005.859028
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hong R., 2012, ACM T MULTIM COMPUT, V7, P1551
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Hou Xiaodi, 2008, ADV NEURAL INFORM PR
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Kanan C, 2009, VIS COGN, V17, P979, DOI 10.1080/13506280902771138
   Kienzle Wolf., 2006, ADV NEURAL INFORM PR
   Kreutz-Delgado K, 2003, NEURAL COMPUT, V15, P349, DOI 10.1162/089976603762552951
   Lang CY, 2012, IEEE T IMAGE PROCESS, V21, P1327, DOI 10.1109/TIP.2011.2169274
   Li B., 2012, AAAI 12
   Ma Y.F., 2003, ACM INT C MULT
   Ouerhani N., 2004, ELECT LETT COMPUTER, V3, P13, DOI [10.5565/rev/elcvia.66, DOI 10.5565/REV/ELCVIA.66]
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Sprague N., 2003, Advances in Neural Information Processing Systems Vol. 16
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Tosic I, 2011, IEEE SIGNAL PROC MAG, V28, P27, DOI 10.1109/MSP.2010.939537
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Zhou Z., 2009, Ensemble learning. Encyclopedia of biometrics, DOI DOI 10.1007/978-0-387-73003-5_293
NR 32
TC 17
Z9 18
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2014
VL 32
IS 3
BP 180
EP 188
DI 10.1016/j.imavis.2013.12.015
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AE3CG
UT WOS:000333854000002
DA 2024-07-18
ER

PT J
AU Tavakoli, HR
   Rahtu, E
   Heikkilä, J
AF Tavakoli, Hamed Rezazadegan
   Rahtu, Esa
   Heikkila, Janne
TI Stochastic bottom-up fixation prediction and saccade generation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Saccadic eye movement; Fixation prediction; Saliency; Scanpaths
ID SPATIOTEMPORAL SALIENCY; MODEL; ATTENTION; IMAGE
AB In this article, a novel technique for fixation prediction and saccade generation will be introduced. The proposed model simulates saccadic eye movement to incorporate the underlying eye movement mechanism into saliency estimation. To this end, a simple salience measure is introduced. Afterwards, we derive a system model for saccade generation and apply it in a stochastic filtering framework. The proposed model will dynamically make a saccade toward the next predicted fixation and produces saliency maps. Evaluation of the proposed model is carried out in terms of saccade generation performance and saliency estimation. Saccade generation evaluation reveals that the proposed model outperforms inhibition of return. Also, experiments signify integration of eye movement mechanism into saliency estimation boosts the results. Finally, comparison with several saliency models shows the proposed model performs aptly. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Tavakoli, Hamed Rezazadegan; Rahtu, Esa; Heikkila, Janne] Univ Oulu, Ctr Machine Vis Res, Dept Comp Sci & Engn, Oulu, Finland.
C3 University of Oulu
RP Tavakoli, HR (corresponding author), Univ Oulu, Ctr Machine Vis Res, Dept Comp Sci & Engn, Oulu, Finland.
EM Hamed.Rezazadegan@ee.oulu.fiemail; Esa.Rahtu@ee.oulu.fiemail;
   jth@ee.oulu.fi
RI Tavakoli, Hamed R./O-9942-2016
OI Tavakoli, Hamed R./0000-0002-9466-9148; Rahtu, Esa/0000-0001-8767-0864
CR Achanta R, 2008, LECT NOTES COMPUT SC, V5008, P66
   [Anonymous], THESIS
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   [Anonymous], 2003, STATISTICS-ABINGDON, DOI DOI 10.1080/02331880309257
   [Anonymous], 2008, NIPS
   [Anonymous], 2009, IEEE INT C COMP VIS
   [Anonymous], THESIS
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Avraham T, 2010, IEEE T PATTERN ANAL, V32, P693, DOI 10.1109/TPAMI.2009.53
   Bian P, 2009, LECT NOTES COMPUT SC, V5506, P251, DOI 10.1007/978-3-642-02490-0_31
   Boccignone G, 2004, PHYSICA A, V331, P207, DOI 10.1016/j.physa.2003.09.011
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Borji A, 2013, IEEE T PATTERN ANAL, V35, P185, DOI 10.1109/TPAMI.2012.89
   Brockmann D., 1999, ART NEUR NETW 1999 I, V1
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   BUNDESEN C, 1990, PSYCHOL REV, V97, P523, DOI 10.1037/0033-295X.97.4.523
   Cheng G., 2008, TRANSPORTATION RES B, P1
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Garcia-Diaz A, 2009, LECT NOTES COMPUT SC, V5807, P343
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI 10.1109/CVPR.2010.5539929
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Hae Jong Seo, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P45, DOI 10.1109/CVPR.2009.5204207
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hooge ITC, 2005, VISION RES, V45, P1901, DOI 10.1016/j.visres.2005.01.030
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2009, Advances in neural information processing systems, V49, P1295, DOI [10.1016/j.visres.2008.09.007, DOI 10.1016/J.VISRES.2008.09.007]
   Jarodzka H., 2010, P S EYE TRACK RES AP, P211, DOI [10.1145/1743666, DOI 10.1145/1743666, DOI 10.1145/1743666.1743718]
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Kootstra A.N.G., 2008, BMVC
   Land MF, 2002, NEUROCASE, V8, P80, DOI 10.1076/neur.8.1.80.16239
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Le Meur O, 2013, BEHAV RES METHODS, V45, P251, DOI 10.3758/s13428-012-0226-9
   Li J, 2010, INT J COMPUT VISION, V90, P150, DOI 10.1007/s11263-010-0354-6
   Li Y, 2010, LECT NOTES COMPUT SC, V5994, P246
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Marat S, 2009, INT J COMPUT VISION, V82, P231, DOI 10.1007/s11263-009-0215-3
   Martinez-Conde S, 2004, NAT REV NEUROSCI, V5, P229, DOI 10.1038/nrn1348
   Najemnik J, 2005, NATURE, V434, P387, DOI 10.1038/nature03390
   Otero-Millan J, 2008, J VISION, V8, DOI 10.1167/8.14.21
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   Rahtu E., 2010, P 11 EUR C COMP VIS
   Ramanathan S, 2010, LECT NOTES COMPUT SC, V6314, P30, DOI 10.1007/978-3-642-15561-1_3
   Renninger LW, 2007, J VISION, V7, DOI 10.1167/7.3.6
   Seo HJ, 2009, J VISION, V9, DOI 10.1167/9.12.15
   Tatler B., 2007, VIS RES, V14
   Tatler BW, 2009, VIS COGN, V17, P1029, DOI 10.1080/13506280902764539
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   Tavakoli HR, 2011, LECT NOTES COMPUT SC, V6688, P666, DOI 10.1007/978-3-642-21227-7_62
   Torralba A., 2003, J OPT SOC AM, V20
   Unema PJA, 2005, VIS COGN, V12, P473, DOI 10.1080/13506280444000409
   Walther D, 2006, NEURAL NETWORKS, V19, P1395, DOI 10.1016/j.neunet.2006.10.001
   Wang W., 2011, IEEE COMPUTER VISION
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Yan JC, 2010, IEEE SIGNAL PROC LET, V17, P739, DOI 10.1109/LSP.2010.2053200
   Yang YZ, 2010, LECT NOTES COMPUT SC, V6315, P631, DOI 10.1007/978-3-642-15555-0_46
   Yanulevskaya V, 2012, P 20 ACM INT C MULT, P349, DOI [10.1145/2393347.2393399, DOI 10.1145/2393347.2393399]
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 61
TC 22
Z9 23
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2013
VL 31
IS 9
BP 686
EP 693
DI 10.1016/j.imavis.2013.06.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220EG
UT WOS:000324564300009
DA 2024-07-18
ER

PT J
AU Rapp, V
   Bailly, K
   Senechal, T
   Prevost, L
AF Rapp, Vincent
   Bailly, Kevin
   Senechal, Thibaud
   Prevost, Lionel
TI Multi-Kernel Appearance Model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial feature localization; Multiple-kernel learning; Two-stage
   classifiers; SIFT descriptor; Deformable model alignment; Gauss-Newton
   optimization
ID FEATURE LOCALIZATION; FACIAL FEATURES; ROBUST; ILLUMINATION; POSE
AB Automatic facial landmarking is a crucial prerequisite of many applications dedicated to face analysis. In this paper we describe a two-step method. In a first step, each landmark position in the image is predicted independently. To achieve fast and accurate localizations, we implement detectors based on a two-stage classifier and we use multiple kernel learning algorithms to combine multi-scale features. In a second step, to increase the robustness of the system, we introduce spatial constraints between landmarks. To this end, parameters of a deformable shape model are optimized using the first step outputs through a Gauss-Newton algorithm. Extensive experiments have been carried out on different databases (PIE, LFPW, Cohn-Kanade, Face Fix and BioID), assessing the accuracy and the robustness of the proposed approach. They show that the proposed algorithm is not significantly affected by small rotations, facial expressions or natural occlusions and can be favorably compared with the current state of the art landmarking systems. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Rapp, Vincent; Bailly, Kevin] Univ Paris 06, CNRS, ISIR, UMR 7222, F-75005 Paris, France.
   [Senechal, Thibaud] Affectiva Inc, Waltham, MA USA.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS)
RP Rapp, V (corresponding author), Univ Paris 06, CNRS, ISIR, UMR 7222, F-75005 Paris, France.
EM vincent.rapp@isir.upmc.fr; kevin.bailly@isir.upmc.fr;
   thibaud.senechal@affectiva.com; lionel.prevost@univ-ag.fr
OI Bailly, Kevin/0000-0001-7802-3673
FU French National Agency (ANR) in the frame of its Technological Research
   CONTINT program (IMMEMO) [ANR-09-CORD-012]
FX This work has been partially supported by the French National Agency
   (ANR) in the frame of its Technological Research CONTINT program
   (IMMEMO, project number ANR-09-CORD-012) and the Cap Digital Business
   cluster for digital content
CR [Anonymous], INT J COMPUT VIS
   [Anonymous], P BRIT MACH VIS C BM, DOI DOI 10.1007/978-1-4471-3201-1_2
   [Anonymous], 2010, PATTERN RECOGN
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], P AS C COMP VIS ACCV
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], P IEEE C FAC GEST RE
   Bailly K, 2012, INT C PATT RECOG, P1112
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2012, LECT NOTES COMPUT SC, V7578, P278, DOI 10.1007/978-3-642-33786-4_21
   Cristinacce D., 2003, BRIT MACHINE VISION, V1, P231
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Cristinacce D., 2007, British Mach. Vision Conf, P880
   Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024
   Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32
   Duffner S, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P316, DOI 10.1109/ISPA.2005.195430
   Eckhardt M, 2009, INT J PATTERN RECOGN, V23, P379, DOI 10.1142/S0218001409007247
   Efraty B., 2011, IJCB, P1
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   GOODALL C, 1991, J ROY STAT SOC B MET, V53, P285, DOI 10.1111/j.2517-6161.1991.tb01825.x
   Gourier N, 2004, IEEE SYS MAN CYBERN, P617
   Gu L., 2006, COMP VIS PATT REC 20, V1, P1305, DOI DOI 10.1109/CVPR.2006.11
   Hanif SM, 2008, PATTERN RECOGN LETT, V29, P1094, DOI 10.1016/j.patrec.2007.09.016
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   Little G, 2005, INT CONF ACOUST SPEE, P89
   Liu XM, 2009, IEEE T PATTERN ANAL, V31, P1941, DOI 10.1109/TPAMI.2008.238
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Movellan J. R., 2002, Open Source Document, V40, P1
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Platt JC, 2000, ADV NEUR IN, P61
   Rakotomamonjy A, 2008, J MACH LEARN RES, V9, P2491
   Rapp V., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P265, DOI 10.1109/FG.2011.5771409
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Scholkopf B., 2002, Encyclopedia of Biostatistics
   Senechal T, 2010, LECT NOTES ARTIF INT, V5998, P141, DOI 10.1007/978-3-642-12159-3_13
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Vedaldi A, 2009, IEEE I CONF COMP VIS, P606, DOI 10.1109/ICCV.2009.5459183
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vukadinovic D, 2005, IEEE SYS MAN CYBERN, P1692
   Wang Y., 2008, PROC IEEE INT CONE C, P1
   Wimmer M, 2008, IEEE T PATTERN ANAL, V30, P1357, DOI 10.1109/TPAMI.2007.70793
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 54
TC 3
Z9 4
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2013
VL 31
IS 8
BP 542
EP 554
DI 10.1016/j.imavis.2013.04.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 185TO
UT WOS:000321993400002
DA 2024-07-18
ER

PT J
AU Elgammal, A
   Lee, CS
AF Elgammal, Ahmed
   Lee, Chan-Su
TI Homeomorphic Manifold Analysis (HMA): Generalized separation of style
   and content on manifolds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Style and content; Manifold embedding; Kernel methods; Human Motion
   Analysis; Gait analysis; Facial expression analysis
ID DIMENSIONALITY REDUCTION; TRACKING; SHAPE; APPROXIMATION; PEOPLE; MODELS
AB The problem of separation of style and content is an essential element of visual perception, and is a fundamental mystery of perception. This problem appears extensively in different computer vision applications. The problem we address in this paper is the separation of style and content when the content lies on a low-dimensional nonlinear manifold representing a dynamic object. We show that such a setting appears in many human motion analysis problems. We introduce a framework for learning parameterization of style and content in such settings. Given a set of topologically equivalent manifolds, the Homeomorphic Manifold Analysis (HMA) framework models the variation in their geometries in the space of functions that maps between a topologically-equivalent common representation and each of them. The framework is based on decomposing the style parameters in the space of nonlinear functions that map between a unified embedded representation of the content manifold and style-dependent visual observations. We show the application of the framework in synthesis, recognition, and tracking of certain human motions that follow this setting, such as gait and facial expressions. (C) 2012 Published by Elsevier B.V.
C1 [Elgammal, Ahmed] Rutgers State Univ, Dept Comp Sci, Piscataway, NJ 08854 USA.
   [Lee, Chan-Su] Yeungnam Univ, Dept Elect Engn, Gyongsan 712749, Gyeongbuk Do, South Korea.
C3 Rutgers University System; Rutgers University New Brunswick; Yeungnam
   University
RP Elgammal, A (corresponding author), Rutgers State Univ, Dept Comp Sci, 110 Frelinghuysen Rd, Piscataway, NJ 08854 USA.
EM elgammal@cs.rutgers.edu; chansu@ynu.ac.kr
OI Elgammal, Ahmed/0000-0003-2761-4822
FU NSF [IIS-0328991, IIS-0546372]
FX This work was funded by NSF award IIS-0328991 and NSF CAREER award
   IIS-0546372.
CR Andriluka M, 2010, PROC CVPR IEEE, P623, DOI 10.1109/CVPR.2010.5540156
   [Anonymous], P NIPS
   [Anonymous], KALMAN FILTERING NEU
   [Anonymous], P 9 INT WORKSH AI ST
   [Anonymous], BRIT MACH VIS C
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Bengio Y, 2004, NEURAL COMPUT, V16, P2197, DOI 10.1162/0899766041732396
   Bengio Y., 2004, P NIPS
   Bowden Richard, 2000, IEEE WORKSH HUM MOD, P10
   Brand M., 1999, ICCV, V2, P1237, DOI DOI 10.1109/ICCV.1999.790422
   BREGLER C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P494, DOI 10.1109/ICCV.1995.466899
   Brubaker MA, 2010, INT J COMPUT VISION, V87, P140, DOI 10.1007/s11263-009-0274-5
   Cheng Shinko Y., 2007, CVPR EHUM2 2 WORKSH
   Christoudias CM, 2005, PROC CVPR IEEE, P1067
   Chui HL, 2000, PROC CVPR IEEE, P44, DOI 10.1109/CVPR.2000.854733
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Corazza S, 2010, INT J COMPUT VISION, V87, P156, DOI 10.1007/s11263-009-0284-3
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995
   Elgammal A, 2004, PROC CVPR IEEE, P681
   Elgammal A., 2005, P CVPR
   Elgammal A, 2007, COMPUT VIS IMAGE UND, V106, P31, DOI 10.1016/j.cviu.2005.09.010
   Elgammal A, 2009, IEEE T PATTERN ANAL, V31, P520, DOI 10.1109/TPAMI.2008.101
   Fablet R, 2002, LECT NOTES COMPUT SC, V2350, P476
   Gall J, 2010, INT J COMPUT VISION, V87, P75, DOI 10.1007/s11263-008-0173-1
   Gross R., 2001, TR0118 CARN MELL U
   Ham J., 2004, P 21 INT C MACH LEAR, DOI DOI 10.1145/1015330.1015417
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   KAPTEYN A, 1986, PSYCHOMETRIKA, V51, P269, DOI 10.1007/BF02293984
   KIMELDOR.GS, 1970, ANN MATH STAT, V41, P495, DOI 10.1214/aoms/1177697089
   KIMELDORF G, 1971, J MATH ANAL APPL, V33, P82, DOI 10.1016/0022-247X(71)90184-3
   Lee C.-S., 2005, P BRIT MACH VIS C, P739
   Lee C.-S., 2007, P ICCV
   Levin A, 2002, LECT NOTES COMPUT SC, V2352, P635
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Magnus J.R., 1999, MATRIX DIFFERENTIAL
   MARIMONT DH, 1992, J OPT SOC AM A, V9, P1905, DOI 10.1364/JOSAA.9.001905
   Moon Kooksang., 2006, CVPR, P198, DOI 10.1109/CVPR.2006.148
   Morariu V. I., 2006, IEEE COMPUT SOC C CO, P545
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Ormoneit D., 2000, P IEEE WORKSH HUM MO, P2
   Peters J, 2017, ADAPT COMPUT MACH LE
   POGGIO T, 1990, P IEEE, V78, P1481, DOI 10.1109/5.58326
   Rahimi A, 2005, PROC CVPR IEEE, P868
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   Shashua A., 2001, P CVPR
   Sigal Leonid., 2006, HUMANEVA SYNCHRONIZE, DOI DOI 10.1007/S11263-009-0273-6
   Sminchisescu C., 2004, Proc. 21st International Conference on Machine Learning, P96
   Tenenbaum JB, 2000, NEURAL COMPUT, V12, P1247, DOI 10.1162/089976600300015349
   Tenenbaum JB, 1998, ADV NEUR IN, V10, P682
   Tian T.-P., 2005, CVPR Learning Workshop, P50
   Torki M., 2010, P ICPR
   Torki M., 2010, P CVPR
   Toyama K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P50, DOI 10.1109/ICCV.2001.937599
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Urtasun R, 2005, IEEE I CONF COMP VIS, P403
   Urtasun R., 2006, 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'06), V1, P238, DOI DOI 10.1109/CVPR.2006.15
   Vasilescu MAO, 2002, LECT NOTES COMPUT SC, V2350, P447
   Vasilescu MAO, 2002, INT C PATT RECOG, P456, DOI 10.1109/ICPR.2002.1047975
   Wang J.M., 2005, P NIPS, p6.4.2
   Xu XY, 2007, IEEE I CONF COMP VIS, P968
NR 65
TC 15
Z9 17
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2013
VL 31
IS 4
BP 291
EP 310
DI 10.1016/j.imavis.2012.12.003
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 136QV
UT WOS:000318379400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Brown, RG
   Chase, JG
   Hann, CE
AF Brown, Richard G.
   Chase, J. Geoffrey
   Hann, Chris E.
TI A pointwise smooth surface stereo reconstruction algorithm without
   correspondences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo vision; Photogrammetry; 3D reconstruction; Medical applications
AB This paper describes an algorithm for 3D reconstruction of a smooth surface with a relatively dense set of self-similar point features from two calibrated views. We bypass the usual correspondence problem by triangulating a point in space from all pairs of features satisfying the epipolar constraint. The surface is then extracted from the resulting point cloud by taking advantage of the statistical and geometric properties of the point distribution on the surface. Results are presented for computer simulations and for a laboratory experiment on a silicon gel phantom used in a breast cancer screening project. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Brown, Richard G.] Univ Canterbury, Blue Fern High Performance Comp Ctr, Christchurch 8140, New Zealand.
   [Brown, Richard G.] Univ Canterbury, Dept Math & Stat, Christchurch 8140, New Zealand.
   [Chase, J. Geoffrey; Hann, Chris E.] Univ Canterbury, Dept Mech Engn, Christchurch 8140, New Zealand.
C3 University of Canterbury; University of Canterbury; University of
   Canterbury
RP Brown, RG (corresponding author), Univ Canterbury, Blue Fern High Performance Comp Ctr, Private Bag 4800, Christchurch 8140, New Zealand.
EM richard.brown@canterbury.ac.nz
RI Chase, Geoff/B-1584-2012
OI Chase, Geoff/0000-0001-9989-4849
FU Tertiary Education Commission (TEC)
FX Thanks to the Tertiary Education Commission (TEC) for providing funding
   through a Top Achiever Doctoral Scholarship for RGB. Thanks also to the
   anonymous referees for constructive reviews and for suggesting
   references and improvements to the content and presentation.
CR Brown R., 2008, THESIS U CANTERBURY
   Dellaert F, 2000, PROC CVPR IEEE, P557, DOI 10.1109/CVPR.2000.854916
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Harris C., 1988, ALVEY VISION C, P147151
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   LAURENTINI A, 1994, IEEE T PATTERN ANAL, V16, P150, DOI 10.1109/34.273735
   Li M., 2003, GRAPH INT P 2003 CAN
   Lotz T, 2010, IEEE ENG MED BIO, P3077, DOI 10.1109/IEMBS.2010.5626116
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matusik W, 2001, SPRING EUROGRAP, P115
   Peters A, 2005, JSME INT J C-MECH SY, V48, P562, DOI 10.1299/jsmec.48.562
   Pons JP, 2005, PROC CVPR IEEE, P822
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Sun J., 2002, Proceedings of the European Conference on Computer Vision, P450
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   Vedaldi A., VLFEAT OPEN PORTABLE
NR 18
TC 7
Z9 7
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2012
VL 30
IS 9
BP 619
EP 629
DI 10.1016/j.imavis.2012.06.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 024EV
UT WOS:000310092600003
DA 2024-07-18
ER

PT J
AU Sangineto, E
   Cupelli, M
AF Sangineto, Enver
   Cupelli, Marco
TI Real-time viewpoint-invariant hand localization with cluttered
   backgrounds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hand detection; Articulated object recognition; Model based techniques;
   Geometric constraints; Graph matching; Curve matching
ID VISION; POSE; RECOGNITION; CAPTURE
AB Over the past few years there has been a growing interest in visual interfaces based on gestures. Using gestures as a mean to communicate with a computer can be helpful in applications such as gaming platforms, domotic environments, augmented reality or sign language interpretation to name a few. However, a serious bottleneck for such interfaces is the current lack of accurate hand localization systems, which are necessary for tracking (re-)initialization and hand pose understanding. In fact, human hand is an articulated object with a very large degree of appearance variability which is difficult to deal with. For instance, recent attempts to solve this problem using machine learning approaches have shown poor generalization capabilities over different viewpoints and finger spatial configurations.
   In this article we present a model based approach to articulated hand detection which splits this variability problem by separately searching for simple finger models in the input image. A generic finger silhouette is localized in the edge map of the input image by combining curve and graph matching techniques. Cluttered backgrounds and thick textured images, which usually make it hard to compare edge information with silhouette models (e.g., using chamfer distance or voting based methods) are dealt with in our approach by simultaneously using connected curves and topological information. Finally, detected fingers are clustered using geometric constraints. Our system is able to localize in real time a hand with variable finger configurations in images with complex backgrounds, different lighting conditions and different positions of the hand with respect to the camera. Experiments with real images and videos and a simple visual interface are presented to validate the proposed method. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Sangineto, Enver] Ist Italian Tecnol, Pattern Anal & Comp Vis PAVIS, I-16163 Genoa, Italy.
   [Cupelli, Marco] Gepin SpA, I-00143 Rome, Italy.
C3 Istituto Italiano di Tecnologia - IIT
RP Sangineto, E (corresponding author), Ist Italian Tecnol, Pattern Anal & Comp Vis PAVIS, Via Morego 30, I-16163 Genoa, Italy.
EM Enver.Sangineto@iit.it
RI Sangineto, Enver/AAS-9542-2020
OI Sangineto, Enver/0000-0002-5187-4133
CR [Anonymous], 2004, 2004 C COMP VIS PATT
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2003, BMVC CITESEER, DOI DOI 10.5244/C.17.60
   Ardovini A, 2008, PATTERN RECOGN, V41, P1867, DOI 10.1016/j.patcog.2007.11.010
   Athitsos V, 2003, PROC CVPR IEEE, P432
   Belongie S, 2000, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P20, DOI 10.1109/IVL.2000.853834
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cheung  S., 2004, VIDEO COMMUNICATIONS
   Colombo C, 2003, IEEE T SYST MAN CY B, V33, P677, DOI 10.1109/TSMCB.2003.814281
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Doublet J., 2006, P COGN SYST INT SENS
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Fischler M., 1977, IEEE T COMPUT, VC-26, P236
   Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399
   Freeman WT, 1998, IEEE COMPUT GRAPH, V18, P42, DOI 10.1109/38.674971
   Holden E., 1997, THESIS U W AUSTR
   KOLSCH M, 2004, INT C MOB UB SYST MO
   Kolsch M., 2004, INT C AUT FAC GEST R
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liu Nianjun., 2005, P DIGITAL IMAGE COMP, P59
   Moeslund TB, 2003, MACH VISION APPL, V14, P237, DOI 10.1007/s00138-002-0090-1
   MOESLUND TB, 2000, WORKSH HUM MOD AN SY
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Nolker C., 1999, LECT NOTES ARTIF INT, P61
   Ong E., 2004, P INT C AUT FAC GEST
   Ong SCW, 2005, IEEE T PATTERN ANAL, V27, P873, DOI 10.1109/TPAMI.2005.112
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Ramanam D., 2003, CVPR 2003 MAD WI
   Ruiz-del-Solar J., 2003, INT C IM AN PROC ICI
   Shimada N, 2001, IEEE ICCV WORKSHOP ON RECOGNITION, ANALYSIS AND TRACKING OF FACES AND GESTURES IN REAL-TIME SYSTEMS, PROCEEDINGS, P23, DOI 10.1109/RATFG.2001.938906
   Sigal L, 2004, PROC CVPR IEEE, P421
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   Torralba A, 2007, IEEE T PATTERN ANAL, V29, P854, DOI 10.1109/TPAMI.2007.1055
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wachs JP, 2010, J REAL-TIME IMAGE PR, V5, P231, DOI 10.1007/s11554-010-0150-0
   Wu Y, 2001, IEEE SIGNAL PROC MAG, V18, P51
   Zhou HN, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1102, DOI 10.1109/ICCV.2003.1238472
NR 39
TC 9
Z9 10
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2012
VL 30
IS 1
BP 26
EP 37
DI 10.1016/j.imavis.2011.11.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 900WC
UT WOS:000300921400003
DA 2024-07-18
ER

PT J
AU Olague, G
   Trujillo, L
AF Olague, Gustavo
   Trujillo, Leonardo
TI Evolutionary-computer-assisted design of image operators that detect
   interest points using genetic programming
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Interest points; Computer assisted design; Evolutionary computation;
   Genetic programming; Evolutionary computer vision
ID SPECIAL-ISSUE; DESCRIPTORS; PERFORMANCE; ACCURATE
AB This work describes a way of designing interest point detectors using an evolutionary-computer-assisted design approach. Nowadays, feature extraction is performed through the paradigm of interest point detection due to its simplicity and robustness for practical applications such as: image matching and view-based object recognition. Genetic programming is used as the core functionality of the proposed human-computer framework that significantly augments the scope of interest point design through a computer assisted learning process. Indeed, genetic programming has produced numerous interest point operators, many with unique or unorthodox designs. The analysis of those best detectors gives us an advantage to achieve a new level of creative design that improves the perspective for human-machine innovation. In particular, we present two novel interest point detectors produced through the analysis of multiple solutions that were obtained through single and multi-objective searches. Experimental results using a well-known testbed are provided to illustrate the performance of the operators and hence the effectiveness of the proposal. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Olague, Gustavo; Trujillo, Leonardo] Ctr Invest Cient & Educ Super Ensenada, Div Fis Aplicada, Dept Ciencias Computac, Proyecto Evovis, Ensenada 22860, BC, Mexico.
   [Trujillo, Leonardo] Inst Tecnol Tijuana, Tijuana, BC, Mexico.
C3 CICESE - Centro de Investigacion Cientifica y de Educacion Superior de
   Ensenada
RP Olague, G (corresponding author), Ctr Invest Cient & Educ Super Ensenada, Div Fis Aplicada, Dept Ciencias Computac, Proyecto Evovis, Km 107 Carretera Tijuana Ensenada, Ensenada 22860, BC, Mexico.
EM olague@cicese.mx; leonardo.trujillo.ttl@gmail.com
RI Olague, Gustavo/L-7795-2014; Trujillo, Leonardo/L-2939-2017
OI Olague, Gustavo/0000-0001-5773-9517; Trujillo,
   Leonardo/0000-0003-1812-5736
CR [Anonymous], 2004, METAHEURISTICS MULTI
   [Anonymous], 2003, 2003002 IND I TECHN
   [Anonymous], 2002, Foundations of Genetic Programming
   [Anonymous], 2009, PROC GECCO
   Beaudet P. R., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P579
   Bradski G., 2008, LEARNING OPENCV COMP, DOI DOI 10.1109/MRA.2009.933612
   Cagnoni S, 2008, EVOL COMPUT, V16, P437, DOI 10.1162/evco.2008.16.4.437
   Cagnoni S., 2008, EURASIP BOOK SERIES, V8
   Coello CA., 2002, Evolutionary algorithms for solving multi-objective problems, DOI [10.1007/978-1-4757-5184-0, DOI 10.1007/978-1-4757-5184-0]
   Corne D. W., 2000, Parallel Problem Solving from Nature PPSN VI. 6th International Conference. Proceedings (Lecture Notes in Computer Science Vol.1917), P839
   da Fountoura-Costa L., 2009, SHAPE CLASSIFICATION
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   De Jong K.A., 2001, EVOLUTIONARY COMPUTA
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   DICKINSON SJ, 2009, OBJECT CATEGORIZATIO
   Forstner W., 1986, International Archives of the Photogrammetry, V26, P150
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Fostner W., 1987, ISPRS INTERCOMMISSIO, P149
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hernández B, 2007, COMPUT VIS IMAGE UND, V106, P258, DOI 10.1016/j.cviu.2006.08.012
   Holland J.H., 1992, Adaptation in Natural and Artificial Systems, DOI DOI 10.7551/MITPRESS/1090.001.0001
   Howard D, 2006, PATTERN RECOGN LETT, V27, P1275, DOI 10.1016/j.patrec.2005.07.025
   Jaskowski W, 2008, EVOL COMPUT, V16, P439, DOI 10.1162/evco.2008.16.4.439
   KENNEY CS, 2005, INT C COMP VIS PATT
   Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4
   Koza J. R., 2000, Genetic Programming and Evolvable Machines, V1, P121, DOI 10.1023/A:1010076532029
   Koza JR, 2010, GENET PROGRAM EVOL M, V11, P251, DOI 10.1007/s10710-010-9112-3
   KOZA JR, 1994, STAT COMPUT, V4, P87, DOI 10.1007/BF00175355
   Krawiec K, 2005, IEEE T SYST MAN CY B, V35, P409, DOI 10.1109/TSMCB.2005.846644
   Krawiec K., 2002, Genetic Programming and Evolvable Machines, V3, P329, DOI 10.1023/A:1020984725014
   Lin YQ, 2005, IEEE T SYST MAN CY C, V35, P156, DOI 10.1109/TSMCC.2004.841912
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   McGlone C., 2004, MANUAL PHOTOGRAMMETR, V5th
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Miles J, 2006, LECT NOTES ARTIF INT, V4200, P492
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Muller H., 2010, IMAGE CLEF EXPT EVAL
   Noble A., 1989, THESIS OXFORD U
   Olague G, 2005, PATTERN RECOGN LETT, V26, P27, DOI 10.1016/j.patrec.2004.08.026
   Olague G, 2002, PATTERN RECOGN, V35, P927, DOI 10.1016/S0031-3203(01)00076-0
   Olague G, 2002, PHOTOGRAMM ENG REM S, V68, P423
   Olague G, 2006, PATTERN RECOGN LETT, V27, P1161, DOI 10.1016/j.patrec.2005.07.013
   Parmee I. C., 1997, EVOLUTIONARY ALGORIT, P453
   Perez CB, 2008, INT C PATT RECOG, P3201
   Poli R., 2008, A Field Guide to Genetic Programming
   PUENTE C, 2009, GECCO 09 P 11 ANN C, P1593
   Puente C, 2011, PHOTOGRAMM ENG REM S, V77, P363, DOI 10.14358/PERS.77.4.363
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Song A, 2008, EVOL COMPUT, V16, P461, DOI 10.1162/evco.2008.16.4.461
   Spector L, 2003, GENET PROGR SER, V6, P11
   Spector L, 2006, ARTIF INTELL, V170, P1251, DOI 10.1016/j.artint.2006.10.009
   Spector Lee, 2008, P 10 ANN C GENETIC E, P1291, DOI [DOI 10.1145/1389095.1389343, 10.1145/1389095.1389343]
   Szeliski Richard., 2011, Computer Vision
   Tissainayagam P, 2004, IMAGE VISION COMPUT, V22, P663, DOI 10.1016/j.imavis.2004.02.001
   Trajkovic M, 1998, IMAGE VISION COMPUT, V16, P75, DOI 10.1016/S0262-8856(97)00056-5
   TRUJILLO L, 2008, P GEN EV COMP C GECC, P1299
   Trujillo L, 2006, GECCO 2006: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOL 1 AND 2, P887
   Trujillo L, 2006, INT C PATT RECOG, P211
   Trujillo L, 2008, EVOL COMPUT, V16, P483, DOI 10.1162/evco.2008.16.4.483
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   Yang GH, 2007, IEEE T PATTERN ANAL, V29, P1973, DOI [10.1109/TPAMI.2007.1116, 10.1109/TPAMl.2007.1116.]
   Zhang MJ, 2003, EURASIP J APPL SIG P, V2003, P841, DOI 10.1155/S1110865703303063
   Zhang Y, 2005, GECCO 2005: GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, VOLS 1 AND 2, P795
   Zitzler E., 2002, P C EVOLUTIONARY COM, P19
NR 69
TC 48
Z9 50
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2011
VL 29
IS 7
BP 484
EP 498
DI 10.1016/j.imavis.2011.03.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 786YW
UT WOS:000292344800005
DA 2024-07-18
ER

PT J
AU Zhang, KH
   Zhang, L
   Song, HH
   Zhou, WG
AF Zhang, Kaihua
   Zhang, Lei
   Song, Huihui
   Zhou, Wengang
TI Active contours with selective local or global segmentation: A new
   formulation and level set method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active contours; Geodesic active contours; Chan-Vese model; Image
   segmentation; Level set method
ID IMAGE SEGMENTATION; MUMFORD; MODEL
AB A novel region-based active contour model (ACM) is proposed in this paper. It is implemented with a special processing named Selective Binary and Gaussian Filtering Regularized Level Set (SBGFRLS) method, which first selectively penalizes the level set function to be binary, and then uses a Gaussian smoothing kernel to regularize it. The advantages of our method are as follows. First, a new region-based signed pressure force (SPF) function is proposed, which can efficiently stop the contours at weak or blurred edges. Second, the exterior and interior boundaries can be automatically detected with the initial contour being anywhere in the image. Third, the proposed ACM with SBGFRLS has the property of selective local or global segmentation. It can segment not only the desired object but also the other objects. Fourth, the level set function can be easily initialized with a binary function, which is more efficient to construct than the widely used signed distance function (SDF). The computational cost for traditional re-initialization can also be reduced. Finally, the proposed algorithm can be efficiently implemented by the simple finite difference scheme. Experiments on synthetic: and real images demonstrate the advantages of the proposed method over geodesic active contours (GAC) and Chan-Vese (C-V) active contours in terms of both efficiency and accuracy. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Zhang, Kaihua; Zhang, Lei] Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
   [Song, Huihui; Zhou, Wengang] Univ Sci & Technol China, Dept Elect Engn & Informat Sci, Hefei 230027, Peoples R China.
C3 Hong Kong Polytechnic University; Chinese Academy of Sciences;
   University of Science & Technology of China, CAS
RP Zhang, L (corresponding author), Hong Kong Polytech Univ, Dept Comp, Hong Kong, Hong Kong, Peoples R China.
EM zhkhua@mail.ustc.edu.cn; cslzhang@comp.polyu.edu.hk;
   freebird@mail.ustc.edu.cn; zhwg@mail.ustc.edu.cn
RI ZHANG, Kaihua/ABE-9067-2020; Zhang, Lei/P-8881-2014
OI ZHANG, Kaihua/0000-0002-1613-3401; Zhang, Lei/0000-0002-2078-4215
FU Hong Kong RGC [PolyU 551/08E]; Hong Kong Polytechnic University [A-SA08]
FX This research is Supported by the Hong Kong RGC General Research Fund
   (PolyU 551/08E) and the Hong Kong Polytechnic University Internal
   Research Fund (A-SA08).
CR [Anonymous], 2002, SURFACES
   [Anonymous], 2007, P IEEE COMP SOC C CO
   Aubert G., 2002, MATH PROBLEMS IMAGE
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   DAVATZIKOS CA, 1995, IEEE T MED IMAGING, V14, P65, DOI 10.1109/42.370403
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Li CM, 2008, IEEE T IMAGE PROCESS, V17, P1940, DOI 10.1109/TIP.2008.2002304
   Li CM, 2005, PROC CVPR IEEE, P430
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   PARAGIOS N, 2000, IEEE T PATTERN ANAL, V22, P1
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Ronfard R., 2002, INT J COMPUT VISION, V46, P223
   Shi YG, 2005, PROC CVPR IEEE, P34
   Tsai A, 2001, IEEE T IMAGE PROCESS, V10, P1169, DOI 10.1109/83.935033
   Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Xu CY, 2000, CONF REC ASILOMAR C, P483, DOI 10.1109/ACSSC.2000.911003
   Xu N, 2007, COMPUT VIS IMAGE UND, V107, P210, DOI 10.1016/j.cviu.2006.11.004
   Zhu GP, 2007, OPT ENG, V46, DOI 10.1117/1.2740762
NR 24
TC 566
Z9 698
U1 2
U2 137
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 668
EP 676
DI 10.1016/j.imavis.2009.10.009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600012
DA 2024-07-18
ER

PT J
AU Brox, T
   Rousson, M
   Deriche, R
   Weickert, J
AF Brox, Thomas
   Rousson, Mikael
   Deriche, Rachid
   Weickert, Joachim
TI Colour, texture, and motion in level set based segmentation and tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Tracking; Level set methods; Nonlinear diffusion;
   Texture; Motion
ID GEODESIC ACTIVE REGIONS; UNSUPERVISED SEGMENTATION; DIFFUSION;
   FRAMEWORK; CONTOURS; COMPUTATION; FLOW
AB This paper introduces an approach for the extraction and combination of different cues in a level set based image segmentation framework. Apart from the image grey value or colour, we suggest to add its spatial and temporal variations, which may provide important further characteristics. It often turns out that the combination of colour, texture, and motion permits to distinguish object regions that cannot be separated by one cue alone. We propose a two-step approach. In the first stage, the input features are extracted and enhanced by applying coupled nonlinear diffusion. This ensures coherence between the channels and deals with outliers. We use a nonlinear diffusion technique, closely related to total variation flow, but being strictly edge enhancing. The resulting features are then employed for a vector-valued front propagation based on level sets and statistical region models that approximate the distributions of each feature. The application of this approach to two-phase segmentation is followed by an extension to the tracking of multiple objects in image sequences. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Brox, Thomas] Univ Calif Berkeley, Berkeley, CA 94720 USA.
   [Rousson, Mikael] Romix, Polar Rose, F-06902 Sophia Antipolis, France.
   [Deriche, Rachid] INRIA, ENS, ENPC, Odyssee Project Team, F-06902 Sophia Antipolis, France.
   [Weickert, Joachim] Univ Saarland, Math Image Anal Grp, D-66041 Saarbrucken, Germany.
C3 University of California System; University of California Berkeley;
   Ecole des Ponts ParisTech; Inria; Saarland University
RP Brox, T (corresponding author), Univ Calif Berkeley, Surtardja Dai Hall, Berkeley, CA 94720 USA.
EM brox@eecs.berkeley.edu; mikael.rousson@gmail.com;
   Rachid.Deriche@sophia.inria.fr; weickert@mia.uni-saarland.de
RI Deriche, Rachid/AAM-9869-2021
OI Deriche, Rachid/0000-0002-4643-8417
FU IMAVIS [HPMT-CT-2000-00040]; Marie Curie Fellowship; European project
   Cogvisys [3E010361]; Deutsche Forschungsgemeinschaft (DFG) [WE 2602/1-1]
FX This work was funded by the projects IMAVIS HPMT-CT-2000-00040 within
   the framework of the Marie Curie Fellowship Training Sites Programme as
   well as the European project Cogvisys numbered 3E010361, and the project
   WE 2602/1-1 of the Deutsche Forschungsgemeinschaft (DFG). This is
   gratefully acknowledged. We further want to thank Leo Grady and the two
   anonymous reviewers for their useful comments that helped to improve the
   manuscript.
CR ACAR R, 1994, INVERSE PROBL, V10, P1217, DOI 10.1088/0266-5611/10/6/003
   ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098
   Andreu F., 2001, DIFFERENTIAL INTEGRA, V14, P321
   [Anonymous], 1987, Visual Reconstruction
   [Anonymous], LECT NOTES MATH
   [Anonymous], THESIS SAARLAND U GE
   [Anonymous], 39 UCLA MATH DEP
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   [Anonymous], 2003, Geometric Level Set Methods in Imaging, Vision, and Graphics
   BAKER S, 2007, P INT C COMP VIS
   Belongie S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P675, DOI 10.1109/ICCV.1998.710790
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Brox T, 2006, VISUALIZATION AND PROCESSING OF TENSOR FIELDS, P17, DOI 10.1007/3-540-31272-2_2
   Brox T, 2006, IMAGE VISION COMPUT, V24, P41, DOI 10.1016/j.imavis.2005.09.010
   Brox T, 2003, LECT NOTES COMPUT SC, V2756, P353
   Brox T, 2003, LECT NOTES COMPUT SC, V2695, P86
   Brox T, 2006, J VIS COMMUN IMAGE R, V17, P1053, DOI 10.1016/j.jvcir.2005.06.001
   Brox T, 2006, IEEE T IMAGE PROCESS, V15, P3213, DOI 10.1109/TIP.2006.877481
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   CASELLES V, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P694, DOI 10.1109/ICCV.1995.466871
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   CHOPP DL, 1993, J COMPUT PHYS, V106, P77, DOI 10.1006/jcph.1993.1092
   Clark JJ., 1990, Data fusion for sensory information processing systems
   Cremers D, 2004, LECT NOTES COMPUT SC, V3175, P36
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   CROSS GR, 1983, IEEE T PATTERN ANAL, V5, P25, DOI 10.1109/TPAMI.1983.4767341
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Dibos F, 2000, SIAM J NUMER ANAL, V37, P646, DOI 10.1137/S0036142998334838
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Feng XB, 2003, ESAIM-MATH MODEL NUM, V37, P533, DOI 10.1051/m2an:2003041
   Gabor D., 1946, Journal of the Institution of Electrical Engineers-part III: radio and communication engineering, V93, P429, DOI [DOI 10.1049/JI-3-2.1946.0074, 10.1049/ji-3-2.1946.0074]
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   HAYMAN E, 2002, P EUR C COMP VIS, V3, P469
   Keeling SL, 2002, INVERSE PROBL, V18, P175, DOI 10.1088/0266-5611/18/1/312
   KHAN S, 2001, COMPUTER VISION PATT, P11
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   Kim JM, 2005, IEEE T IMAGE PROCESS, V14, P1486, DOI 10.1109/TIP.2005.854442
   Kühne G, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P73, DOI 10.1109/ICIP.2001.958427
   Lucas B. D., 1981, P IJCAI, P674
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147
   Mumford D., 1985, Proceedings CVPR '85: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No. 85CH2145-1), P22
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   OZYILDIZ E, 2002, PATTERN RECOGNITION, V35
   Paragios N, 2005, COMPUT VIS IMAGE UND, V97, P259, DOI 10.1016/j.cviu.2003.04.001
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Paragios N, 2002, J VIS COMMUN IMAGE R, V13, P249, DOI 10.1006/jvci.2001.0475
   PARZEN E, 1962, ANN MATH STAT, V33, P1065, DOI 10.1214/aoms/1177704472
   Peng DP, 1999, J COMPUT PHYS, V155, P410, DOI 10.1006/jcph.1999.6345
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RAO AR, 1991, CVGIP-GRAPH MODEL IM, V53, P157, DOI 10.1016/1049-9652(91)90059-S
   Rousson M, 2002, LECT NOTES COMPUT SC, V2351, P78
   Rousson M, 2003, PROC CVPR IEEE, P699
   Rousson M, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P56, DOI 10.1109/MOTION.2002.1182214
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   SAGIV C, 2002, P TEXT 2002 2 INT WO
   Sethian J., 1999, LEVEL SET METHODS FA
   SPENGLER M, 2001, LECT NOTES COMPUTER, V2095, P93
   Stiller C, 1999, IEEE SIGNAL PROC MAG, V16, P70, DOI 10.1109/79.774934
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Tschumperlé D, 2001, PROC CVPR IEEE, P948
   Tschumperlé D, 2002, INT J COMPUT VISION, V50, P237, DOI 10.1023/A:1020870207168
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3
   WEICKERT J, 2000, COMPUTER VISION APPL, P439
   Weickert J., 1997, ADV COMPUTER VISION
   Weickert J., 2002, CONT MATH, P251
   Zhao HK, 1996, J COMPUT PHYS, V127, P179, DOI 10.1006/jcph.1996.0167
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 73
TC 62
Z9 78
U1 0
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 376
EP 390
DI 10.1016/j.imavis.2009.06.009
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Littlewort, GC
   Bartlett, MS
   Lee, K
AF Littlewort, Gwen C.
   Bartlett, Marian Stewart
   Lee, Kang
TI Automatic coding of facial expressions displayed during posed and
   genuine pain
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Machine learning; Computer vision; Malingering; Facial expression;
   Spontaneous behavior; Automated FACS
ID LOW-BACK-PAIN; DETECTING DECEPTION; REAL-TIME; ACCURACY; BEHAVIOR
AB We present initial results from the application of an automated facial expression recognition system to spontaneous facial expressions of pain. In this study, 26 participants were videotaped under three experimental conditions: baseline, posed pain, and real pain. The real pain condition consisted of cold pressor pain induced by submerging the arm in ice water. Our goal was to (1) assess whether the automated measurements were consistent with expression measurements obtained by human experts, and (2) develop a classifier to automatically differentiate real from faked pain in a subject-independent manner from the automated measurements. We employed a machine learning approach in a two-stage system. In the first stage, a set of 20 detectors for facial actions from the Facial Action Coding System operated on the continuous video stream. These data were then passed to a second machine learning stage, in which a classifier was trained to detect the difference between expressions of real pain and fake pain. Naive human subjects tested on the same videos were at chance for differentiating faked from real pain, obtaining only 49% accuracy. The automated system was successfully able to differentiate faked from real pain. In an analysis of 26 subjects with faked pain before real pain, the system obtained 88% correct for subject independent discrimination of real versus fake pain on a 2-alternative forced choice. Moreover, the most discriminative facial actions in the automated system were consistent with findings using human expert FACS codes. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Littlewort, Gwen C.; Bartlett, Marian Stewart] Univ Calif San Diego, Inst Neural Computat, Machine Percept Lab, La Jolla, CA 92093 USA.
   [Lee, Kang] Univ Toronto, Toronto, ON M5R 2X2, Canada.
C3 University of California System; University of California San Diego;
   University of Toronto
RP Littlewort, GC (corresponding author), Univ Calif San Diego, Inst Neural Computat, Machine Percept Lab, La Jolla, CA 92093 USA.
EM gwen@mplab.ucsd.edu; marni@salk.edu; kang.lee@utoronto.ca
FU NSF [CNS-0454233, 0340851]; Direct For Computer & Info Scie & Enginr;
   Division Of Computer and Network Systems [0340851] Funding Source:
   National Science Foundation
FX Portions of the research in this paper use the MMI Facial Expression
   Database collected by M. Pantic and M.F. Valstar. Support for this work
   was provided by NSF CNS-0454233 and NSF ADVANCE award 0340851. Any
   opinions, findings, and conclusions or recommendations expressed in this
   material are those of the author(s) and do not necessarily reflect the
   views of the National Science Foundation.
CR [Anonymous], 2011, International Journal of Wavelets Multiresolution and Information Processing, DOI DOI 10.1142/S021969130400041X
   [Anonymous], 2005, P IEEE INT C MULT EX
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   CRAIG KD, 1991, PAIN, V46, P161, DOI 10.1016/0304-3959(91)90071-5
   CRAIG KD, 1985, J PERS SOC PSYCHOL, V48, P1080, DOI 10.1037/0022-3514.48.4.1089
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Ekman P., 2005, WHAT FACE REVEALS BA
   Ekman P., 2001, TELLING LIES CLUES D, V2nd
   Ekman P, 1978, FACIAL ACTION CODING
   FASEL IR, 2005, COMPUTER VISION IMAG, P98
   FISHBAIN DA, 2006, PERS SOC PSYCHOL REV, V10, P214
   FRANK MG, 1993, J PERS SOC PSYCHOL, V64, P83, DOI 10.1037/0022-3514.64.1.83
   GROSSMAN SA, 1991, J PAIN SYMPTOM MANAG, V6, P53, DOI 10.1016/0885-3924(91)90518-9
   Hadjistavropoulos HD, 1996, PAIN, V65, P251, DOI 10.1016/0304-3959(95)00218-9
   Hill ML, 2004, CLIN J PAIN, V20, P415, DOI 10.1097/00002508-200411000-00006
   Hill ML, 2002, PAIN, V98, P135, DOI 10.1016/S0304-3959(02)00037-4
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Larochette AC, 2006, PAIN, V126, P64, DOI 10.1016/j.pain.2006.06.013
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Morecraft RJ, 2001, BRAIN, V124, P176, DOI 10.1093/brain/124.1.176
   Pantic M., 2006, PROC MULTIMODAL INTE, P239
   Prkachin KM, 2007, CAN J NURS RES, V39, P88
   Prkachin KM, 2005, PAIN, V114, P328, DOI 10.1016/j.pain.2005.01.001
   Prkachin KM, 2002, BEHAV RES THER, V40, P595, DOI 10.1016/S0005-7967(01)00075-4
   PRKACHIN KM, 1992, PAIN, V51, P57, DOI 10.1016/0304-3959(92)90009-Z
   RINN WE, 1984, PSYCHOL BULL, V95, P52, DOI 10.1037/0033-2909.95.1.52
   Schmidt KL, 2003, BIOL PSYCHOL, V65, P49, DOI 10.1016/S0301-0511(03)00098-X
   Schneiderman H, 1998, PROC CVPR IEEE, P45, DOI 10.1109/CVPR.1998.698586
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   VURAL E, 2007, P BIENN C DIG SIGN P
NR 30
TC 140
Z9 155
U1 0
U2 24
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2009
VL 27
IS 12
SI SI
BP 1797
EP 1803
DI 10.1016/j.imavis.2008.12.010
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 513PL
UT WOS:000271335000006
DA 2024-07-18
ER

PT J
AU Haenselmann, T
   Busse, M
   Kopf, S
   King, T
   Effelsberg, W
AF Haenselmann, Thomas
   Busse, Marcel
   Kopf, Stephan
   King, Thomas
   Effelsberg, Wolfgang
TI Multi perspective panoramic imaging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Panoramic imaging; Multi-perspective; Image stitching; Warping
ID ALIGNMENT
AB Panoramic images have only been feasible if all contributing image patches share a common center of projection. Then, they can be consolidated into a single image using perspective transforms. In contrast to that, we propose a novel non-linear warping scheme which allows the merging of multi-perspective images, thus taking advantage of scattered cameras. Therefore, a polygonal cut is defined in two source images to be merged, Usually, the layout of the cuts does not allow a user to stitch both images together naively. Thus, two convex combinations of a warped and a canonic coordinate system are applied so that both source images fit together at the cutting edge while the inevitable distortion decreases towards the borders of the image to obtain a natural appearance. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Haenselmann, Thomas; Busse, Marcel; Kopf, Stephan; King, Thomas; Effelsberg, Wolfgang] Univ Mannheim, Dept Appl Comp Sci 4, D-68159 Mannheim, Germany.
C3 University of Mannheim
RP Haenselmann, T (corresponding author), Univ Mannheim, Dept Appl Comp Sci 4, A5 6, D-68159 Mannheim, Germany.
EM haenselmann@informatik.uni-mannheim.de;
   effelsberg@informatik.uni-mannheim.de
OI Kopf, Stephan/0000-0002-1140-6685
CR AGARWALA A, 2006, ACM T GRAPH P SIGGRA
   BARNARD GN, 1866, BARNARDS PHOTOGRAPHI
   BEIER T, 1992, COMP GRAPH, V26, P35, DOI 10.1145/142920.134003
   Candocia FM, 2003, IEEE T IMAGE PROCESS, V12, P1485, DOI 10.1109/TIP.2003.819222
   Davis J, 1998, PROC CVPR IEEE, P354, DOI 10.1109/CVPR.1998.698630
   Farin D., 2005, Automatic Video Segmentation Employing Object/Camera Modeling Techniques
   KAPPE E, 2004, WORKSH BROADB ADV SE
   KIM J, 2003, IEEE COMPUT GRAPH, P16
   KUMAR R, 1994, P ARPA IM UND WORKSH
   MANN S, 1997, IEEE T IMAG IN PRESS, V6
   MANN S, 338 TR MIT
   MANN S, 1994, P IEEE T IM PROC AUS
   Maxwell E.A., 1951, General Homogeneous Coordinates in Space of Three Dimensions
   Maxwell E.A., 1946, The methods of plane projective geometry based on the use of general momogeneous coordinates
   RADEMACHER P, P SIGGRAPH
   ROBERTS IG, 1965, 1405 MS MIT LINC LAB
   Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589
   Shum HY, 1999, COMP GRAPH, P299, DOI 10.1145/311535.311573
   Szeliski R, 1996, IEEE COMPUT GRAPH, V16, P22, DOI 10.1109/38.486677
   Szeliski R., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P44, DOI 10.1109/ACV.1994.341287
   Szeliski R., 2005, HDB MATH MODELS COMP
   SZELISKI R, 1997, P ACM SIGGRAPH SAR F
   VAISH V, 2004, P CVPR 2004 WASH DC
   VALLANCE S, 2002, P PAN SYDN AR WORKSH
   WILBURN B, 2004, P C COMP VIS PATT RE
   WILBURN B, 2005, P SIGGRAPH
   WILBURN B, 2002, P MED PROC 2002 SPIE
   WOOD DN, P SIGGRAPH
NR 28
TC 11
Z9 14
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 391
EP 401
DI 10.1016/j.imavis.2008.06.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600009
DA 2024-07-18
ER

PT J
AU Shao, WZ
   Wei, ZH
AF Shao, Wen-Ze
   Wei, Zhi-Hui
TI Edge-and-corner preserving regularization for image interpolation and
   reconstruction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Interpolation; Magnification; Structure tensor; Shock filtering;
   Corner-preserving; Partial differential equation; Super-resolution;
   Inpainting
ID SHOCK FILTERS; DIFFUSION; SIGNAL; CURVATURE; FRAMEWORK; SPLINES; CURVES;
   PDES
AB The edge and corner structures are two categories of perceptually important image characteristics, and hence, edge-and-comer preserving regularization is required for many problems in image processing. In this paper, the first novelty is to propose a new edge-and-comer preserving approach for image interpolation, based on the coupling of robust orientation diffusion, edge shock filtering, and a type of newly designed corner shock filtering. The proposed interpolation scheme is not only able to remove the staircase artifacts along the edge structures, but also able to restrain the rounding artifacts around the corner structures. The second novelty in this paper is to analyze the filtering behavior of two standard structure tensor based variational PDE (partial differential equation) approaches, following which an edge-and-cornet preserving common PDE framework is proposed for different applications in image processing. Numerous experimental results confirm the effectiveness of the proposed interpolation approach, and demonstrate its superiority to other interpolation algorithms. The common PDE framework is applied to several other image processing problems, including image denoising, deringing, deblocking, inpainting, and super-resolution reconstruction. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Shao, Wen-Ze] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Jiansu, Peoples R China.
   [Wei, Zhi-Hui] Nanjing Univ Sci & Technol, Grad Sch, Nanjing 210094, Jiansu, Peoples R China.
C3 Nanjing University of Science & Technology; Nanjing University of
   Science & Technology
RP Shao, WZ (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Xiaolingwei 200, Nanjing 210094, Jiansu, Peoples R China.
EM shaowenze@qinalong.com; gswei@mail.njust.edu.cn
FU Natural Science Foundation of China [60672074]; National High-Tech
   Research and Development Plan of China [2007AA12E100]; National Research
   Foundation for the Doctoral Program of Higher Education of China
   [200606018]; Natural Science Foundation of Jiangsu Province of China
   [BK2006569]; Technology Creation Plan for the Graduate Students in
   Jiangsu Province of China
FX The authors thank the reviewers for valuable comments that helped
   improve the clarity of presentation of this paper. Many thanks are also
   given to Dr. Xiao Liang, Dr. Zhang Jun, Dr. Luo Jia, Dr. Sun Yubao and
   Dr. Liu Hongyi for their helpful discussions. This work was supported in
   part by the Natural Science Foundation of China under Grant No.
   60672074, by the National High-Tech Research and Development Plan of
   China under Grant No. 2007AA12E100, by the National Research Foundation
   for the Doctoral Program of Higher Education of China under Grant No.
   200606018, by the Natural Science Foundation of Jiangsu Province of
   China under Grant No. BK2006569, and by the Technology Creation Plan for
   the Graduate Students in Jiangsu Province of China.
CR Allebach J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P707, DOI 10.1109/ICIP.1996.560768
   ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   Aly HA, 2005, IEEE T IMAGE PROCESS, V14, P1647, DOI 10.1109/TIP.2005.851684
   [Anonymous], LECT NOT COMPUT SCI
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   BELAHMIDI A, 2004, P INT C IM PROC JAN
   BIGUN J, 1991, IEEE T PATTERN ANAL, V13, P775, DOI 10.1109/34.85668
   Blu T, 2004, IEEE T IMAGE PROCESS, V13, P710, DOI 10.1109/TIP.2004.826093
   Borman S, 1999, 1998 MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, PROCEEDINGS, P374, DOI 10.1109/MWSCAS.1998.759509
   BOVIK A, 2000, HDB IMAGE VIDEO PROC, P895
   Carey WK, 1999, IEEE T IMAGE PROCESS, V8, P1293, DOI 10.1109/83.784441
   Chabat F, 1999, IMAGE VISION COMPUT, V17, P761, DOI 10.1016/S0262-8856(98)00150-4
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Charbonnier P, 1997, IEEE T IMAGE PROCESS, V6, P298, DOI 10.1109/83.551699
   DILECCE V, 1999, P INT C DOC AN REC L
   DRESCHLER L, 1982, INT C PATT REC, P542
   EI-Khamy SE, 2005, DIGIT SIGNAL PROCESS, V15, P137, DOI 10.1016/j.dsp.2004.10.003
   El-Khamy SE, 2004, IEEE MEDITERR ELECT, P247, DOI 10.1109/MELCON.2004.1347057
   ELKHAMY SE, INT J SIGNA IN PRESS
   ELKHAMY SE, 2003, P IEEE MWSAS CAIR EG
   GAGE ME, 1984, INVENT MATH, V76, P357, DOI 10.1007/BF01388602
   Gilboa G, 2002, LECT NOTES COMPUT SC, V2350, P399
   Glasbey CA., 1995, IMAGE ANAL BIOL SCI
   Golub G.H., 1989, MATRIX COMPUTATIONS
   GRAYSON MA, 1987, J DIFFER GEOM, V26, P285
   Guichard F., 1998, Proceedings of the European Signal Processing Conference, V3, P1741
   HEKOTETOU N, 1995, IEEE T CONSUM ELECTR, V41, P1118
   HOU HS, 1978, IEEE T ACOUST SPEECH, V26, P508
   KASS M, 1987, COMPUTER GRAPHICS IM, V37, P363
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4
   Kuwahara M., 1976, Digital Processing of Biomedical Images, P187, DOI [DOI 10.1007/978-1-4684-0769-3_13, 10.1007/978-1-4684-0769-313, DOI 10.1007/978-1-4684-0769-313, 10.1007/978-1-4684-0769-3_13]
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P1521, DOI 10.1109/83.951537
   Malgouyres F, 2001, SIAM J NUMER ANAL, V39, P1, DOI 10.1137/S0036142999362286
   Malladi R, 1996, GRAPH MODEL IM PROC, V58, P127, DOI 10.1006/gmip.1996.0011
   MORSE BS, 1998, 5 IEEE INT C IM PROC
   Muñoz A, 2001, IEEE T IMAGE PROCESS, V10, P1365, DOI 10.1109/83.941860
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   OSHER S, 1990, SIAM J NUMER ANAL, V27, P919, DOI 10.1137/0727053
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   SAPIRO G, 2000, GEOMETRIC PARTIAL DI, P241
   Schantz H. F., 1992, Remittance and Document Processing Today, V14, p11, 13
   SCHULTZ RR, 1994, IEEE T IMAGE PROCESS, V3, P233, DOI 10.1109/83.287017
   SHARR H, 2003, P 9 IEEE INT C COMP, V2, P840
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Tschumperlé D, 2002, IEEE SIGNAL PROC MAG, V19, P16, DOI 10.1109/MSP.2002.1028349
   Tschumperle D, 2002, THESIS U NICE SOPHIA
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P834, DOI 10.1109/78.193221
   UNSER M, 1993, IEEE T SIGNAL PROCES, V41, P821, DOI 10.1109/78.193220
   Unser M, 1999, IEEE SIGNAL PROC MAG, V16, P22, DOI 10.1109/79.799930
   VANDENBOOMGAARD R, 2002, P TEXT 2002 2 INT WO
   WANG Q, 2001, P IEEE INT C IM PROC, V3, P401
   Weickert J., 1995, Computer Analysis of Images and Patterns. 6th International Conference, CAIP'95. Proceedings, P230
   Weickert J, 2003, LECT NOTES COMPUT SC, V2781, P1
   Weickert J, 2002, J VIS COMMUN IMAGE R, V13, P103, DOI 10.1006/jvci.2001.0495
   Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973
   Weickert J, 1999, INT J COMPUT VISION, V31, P111, DOI 10.1023/A:1008009714131
   Weickert J, 1996, THESIS U KAISERSLAUT
   Weickert J., 1994, SCALE SPACE PROPERTI
   Weickert J., 1998, ANISOTROPIC DIFFUSIO, V1
   Weickert J., 2002, CONT MATH, P251
   Yang GZ, 1996, IMAGE VISION COMPUT, V14, P135, DOI 10.1016/0262-8856(95)01047-5
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424
   Zuniga O. A., 1983, Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition, P30
NR 66
TC 23
Z9 28
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1591
EP 1606
DI 10.1016/j.imavis.2008.03.002
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500004
DA 2024-07-18
ER

PT J
AU Chan, YK
   Ho, YA
   Liu, YT
   Chen, RC
AF Chan, Yung-Kuan
   Ho, Yu-An
   Liu, Yi-Tung
   Chen, Rung-Ching
TI A ROI image retrieval method based on CVAAO
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RCI image retrieval; color-based image retrieval; color histogram; fuzzy
   color histogram; hierarchical overlapping segmentation
ID COLOR
AB A novel image feature called color variances among adjacent objects (CVAAO) is proposed in this study. Characterizing the color variances between contiguous objects in an image, CVAAO can effectively describe the principal colors and texture distribution of the image and is insensitive to distortion and scale variations of images. Based on CVAAO, a CVAAO-based image retrieval method is constructed. When given a full image, the CVAAO-based image retrieval method delivers the database images most similar to the full image to the user. This paper also presents a CVAAO-based ROI image retrieval method. When given a clip, the CVAAO-based ROI image retrieval method submits to the user a database image containing a target region most similar to the clip. The experimental results show that the CVAAO-based ROI image retrieval method can offer impressive results in finding out the database images that meet user requirements. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Chan, Yung-Kuan] Natl Chung Hsing Univ, Dept Management Informat Syst, Taichung 402, Taiwan.
   [Ho, Yu-An] Natl Chung Hsing Univ, Dept Comp Sci, Taichung 402, Taiwan.
   [Liu, Yi-Tung; Chen, Rung-Ching] Chaoyang Univ Technol, Dept Informat Management, Wufeng, Taichung County, Taiwan.
C3 National Chung Hsing University; National Chung Hsing University;
   Chaoyang University of Technology
RP Chan, YK (corresponding author), Natl Chung Hsing Univ, Dept Management Informat Syst, 250 Kuokuang Rd, Taichung 402, Taiwan.
EM ykchan@nchu.edu.tw; yaho@nchu.edu.tw; s9014613@mail.cyut.edu.tw;
   crching@mail.cyut.edu.tw
OI Chan, Yung-Kuan/0000-0002-1556-0567
CR [Anonymous], 1999, Genetic Algorithms: Concepts and Designs
   Bezdek James C., 1981, PATTERN RECOGN
   Brunelli R, 2001, PATTERN RECOGN, V34, P1625, DOI 10.1016/S0031-3203(00)00054-6
   DIMAI A, 1997, 177 SWISS FED I TECH
   Dunn J. C., 1973, Journal of Cybernetics, V3, P32, DOI 10.1080/01969727308546046
   Fuertes JM, 2001, PATTERN RECOGN LETT, V22, P323, DOI 10.1016/S0167-8655(00)00128-8
   GEVERS T, 2001, EEE T PATTERN ANAL M, V26, P113
   Guillamet D, 2000, INT C PATT RECOG, P422, DOI 10.1109/ICPR.2000.906102
   Han J, 2002, IEEE T IMAGE PROCESS, V11, P944, DOI 10.1109/TIP.2002.801585
   Hill B, 1997, ACM T GRAPHIC, V16, P109, DOI 10.1145/248210.248212
   Hua KA, 1999, ACM MULTIMEDIA 99, PROCEEDINGS, P225, DOI 10.1145/319463.319610
   KANKANHALLI MS, 2001, PATTERN RECOGN, V22, P323
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   Stehling RO, 2001, 2001 INTERNATIONAL DATABASE ENGINEERING & APPLICATIONS SYMPOSIUM, PROCEEDINGS, P356, DOI 10.1109/IDEAS.2001.938104
   Su MS, 2001, IEEE T PATTERN ANAL, V23, P674, DOI 10.1109/34.927466
   Vu K, 2003, IEEE T KNOWL DATA EN, V15, P1045, DOI 10.1109/TKDE.2003.1209021
   WANG JZ, 2000, P INT C IM PROC THES, V1, P22
NR 17
TC 18
Z9 20
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2008
VL 26
IS 11
BP 1540
EP 1549
DI 10.1016/j.imavis.2008.04.019
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 354SJ
UT WOS:000259659000010
DA 2024-07-18
ER

PT J
AU Nonato, LG
   Lizier, MAS
   Batista, J
   de Oliveira, MCF
   Castelo, A
AF Nonato, L. G.
   Lizier, M. A. S.
   Batista, J.
   de Oliveira, M. C. F.
   Castelo, A.
TI Topological triangle characterization with application to object
   detection from images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object detection; object modeling from images; topological triangle
   characterization; Morse operators; 2D triangular meshes
ID COMPUTATION
AB A novel mathematical framework inspired on Morse Theory for topological triangle characterization in 2D meshes is introduced that is useful for applications involving the creation of mesh models of objects whose geometry is not known a priori. The framework guarantees a precise control of topological changes introduced as a result of triangle insertion/removal operations and enables the definition of intuitive high-level operators for managing the mesh while keeping its topological integrity. An application is described in the implementation of an innovative approach for the detection of 2D objects from images that integrates the topological control enabled by geometric modeling with traditional image processing techniques. (C) 2008 Published by Elsevier B.V.
C1 [Nonato, L. G.; Lizier, M. A. S.; Batista, J.; de Oliveira, M. C. F.; Castelo, A.] Univ Sao Paulo, Inst Ciencias Matemat & Comp, BR-13560970 Sao Carlos, SP, Brazil.
C3 Universidade de Sao Paulo
RP Nonato, LG (corresponding author), Univ Sao Paulo, Inst Ciencias Matemat & Comp, Av Trabalhador Sao Carlense 400,CP 668, BR-13560970 Sao Carlos, SP, Brazil.
EM gnonato@icmc.usp.br
RI Lizier, Mario/G-1572-2012; Oliveira, Maria/ISB-2741-2023; Nonato, Luis
   Gustavo/D-5782-2011; Castelo, Antonio/E-6808-2011; Ferreira de Oliveira,
   Maria Cristina/D-9257-2011
OI Lizier, Mario/0000-0001-9123-5822; Castelo, Antonio/0000-0001-8009-4577;
   Ferreira de Oliveira, Maria Cristina/0000-0002-4729-5104
CR [Anonymous], 1990, The design and analysis of spatial data structures
   [Anonymous], 1982, IMAGE ANAL MATH MORP
   [Anonymous], 1963, MORSE THEORY AM 51, DOI [10.1515/9781400881802, DOI 10.1515/9781400881802]
   BATISTA J, 1999, IMAGE PROCESSING ITS, V456, P440
   BAUMGART B., 1975, NATL COMPUTER C AFIP, P589, DOI DOI 10.1145/1499949.1500071
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Codrea MC, 2005, COMPUT GRAPH-UK, V29, P441, DOI 10.1016/j.cag.2005.03.005
   Comaniciu D, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P297, DOI 10.1109/ICIP.2002.1038964
   Comer ML, 2000, IEEE T IMAGE PROCESS, V9, P1731, DOI 10.1109/83.869185
   DiazdeLeon SJL, 1996, PATTERN RECOGN, V29, P471, DOI 10.1016/0031-3203(95)00098-4
   GRAY SB, 1971, IEEE T COMPUT, VC 20, P551, DOI 10.1109/T-C.1971.223289
   GUIBAS L, 1985, ACM T GRAPHIC, V4, P74, DOI 10.1145/282918.282923
   Herman GT., 1998, Geometry of digital spaces
   HUERTAS A, 1986, IEEE T PATTERN ANAL, V8, P651, DOI 10.1109/TPAMI.1986.4767838
   Ji L, 2002, IMAGE VISION COMPUT, V20, P147, DOI 10.1016/S0262-8856(01)00093-2
   KOLLIAS S, 1994, INT CONF ACOUST SPEE, P569
   KONG TY, 1989, COMPUT VISION GRAPH, V48, P357, DOI 10.1016/0734-189X(89)90147-3
   LOPES H, 1992, CURVES SURFACES CO 3, V1830, P270
   Malandain G, 1998, IMAGE VISION COMPUT, V16, P317, DOI 10.1016/S0262-8856(97)00074-7
   Mantyla M., 1987, INTRO SOLID MODELING
   Nonato LG, 2004, IEEE T IMAGE PROCESS, V13, P216, DOI [10.1109/TIP.2003.819908, 10.1109/tip.2003.819908]
   Novianto S, 2003, PATTERN RECOGN LETT, V24, P365, DOI 10.1016/S0167-8655(02)00261-1
   Sun Y, 2005, IEICE T INF SYST, VE88D, P1021, DOI 10.1093/ietisy/e88-d.5.1021
   WILSON R, 1990, PATTERN RECOGN, V23, P1413, DOI 10.1016/0031-3203(90)90087-2
   Yang YY, 2003, IEEE T IMAGE PROCESS, V12, P866, DOI 10.1109/TIP.2003.812757
   Zhang Hong-mei, 2002, Journal of Software, V13, P1779
NR 26
TC 1
Z9 1
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1081
EP 1093
DI 10.1016/j.imavis.2007.11.011
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300002
DA 2024-07-18
ER

PT J
AU Tseng, HW
   Chang, CC
AF Tseng, Hsien-Wen
   Chang, Chin-Chen
TI An extended difference expansion algorithm for reversible watermarking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE reversible watermarking; difference expansion; data embedding
AB In this paper, a very high-capacity reversible watermarking algorithm is proposed. The algorithm extends Tian's method by histogram shifting to form a new type of pixel pair, which is called the shiftable pixel pair. The shiftable pixel pairs can increase the embedding capacity of a digital image while keeping the distortion low. Experimental results also show that the algorithm provides a large embedding capacity without making noticeable distortion. Besides, the original image can be completely restored after extraction. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Chang, Chin-Chen] Feng Chia Univ, Dept Comp Sci & Informat Engn, Taichung 40724, Taiwan.
   [Tseng, Hsien-Wen] Chaoyang Univ Technol, Dept Informat Management, Wufeng 4139, Taichung County, Taiwan.
C3 Feng Chia University; Chaoyang University of Technology
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Comp Sci & Informat Engn, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM hwtseng@cyut.edu.tw; ccc@cs.ccu.edu.tw
RI Tseng, Hsien-Wen/JUF-2625-2023; Chang, Ching-Chun/JAN-6210-2023
CR Alattar AM, 2004, IEEE T IMAGE PROCESS, V13, P1147, DOI 10.1109/TIP.2004.828418
   Barton J. M., 1997, United States Patent, Patent No. [5646997, 5,646,997]
   Celik MU, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157
   De Vleeschouwer C, 2003, IEEE T MULTIMEDIA, V5, P97, DOI 10.1109/TMM.2003.809729
   Fridrich J, 2002, P SOC PHOTO-OPT INS, V4675, P572, DOI 10.1117/12.465317
   Fridrich J, 2002, EURASIP J APPL SIG P, V2002, P185, DOI 10.1155/S1110865702000537
   Honsinger C. W., 2001, US Patent, Patent No. [6,278,791, 6278791]
   MACQ B, 2000, P EUSIPCO TAMP FINL, P533
   Niu XM, 2006, INT J INNOV COMPUT I, V2, P1301
   Tian J, 2003, IEEE T CIRC SYST VID, V13, P890, DOI 10.1109/TCSVT.2003.815962
   Voigt M, 2004, P 2004 MULT SEC WORK, P160, DOI DOI 10.1145/1022431.1022459
NR 11
TC 28
Z9 35
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1148
EP 1153
DI 10.1016/j.imavis.2007.12.005
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300008
DA 2024-07-18
ER

PT J
AU Hu, YC
   Su, BH
   Tsou, CC
AF Hu, Yu-Chen
   Su, Bing-Hwang
   Tsou, Chih-Chiang
TI Fast VQ codebook search algorithm for grayscale image coding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image compression; vector quantization; LBG algorithm; codebook
ID VECTOR QUANTIZATION; ENCODING ALGORITHM; IMPROVEMENT
AB In this paper, a fast codebook search algorithm that is equivalent to the full search algorithm for image vector quantization is proposed. The image encoding procedure of VQ needs to find the closest codewords in the codebook for image blocks. A great deal of computational cost is consumed in the image encoding procedure. The proposed algorithm employs two test conditions to speedup the image encoding procedure without incurring any extra image distortion. According to the results, an average 95.23%, reduction of execution time can be achieved when the codebook of 256 codewords is used in the proposed algorithm. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Hu, Yu-Chen] Providence Univ, Dept Comp Sci & Informat Engn, Taichung 433, Taiwan.
   [Su, Bing-Hwang; Tsou, Chih-Chiang] Providence Univ, Dept Comp Sci & Informat Management, Taichung 433, Taiwan.
C3 Providence University - Taiwan; Providence University - Taiwan
RP Hu, YC (corresponding author), Providence Univ, Dept Comp Sci & Informat Engn, Taichung 433, Taiwan.
EM ychu@pu.edu.tw; bhsu@pu.edu.tw; chihchiang.tsou@gmail.com
RI Hu, Yu-Chen/AAT-5264-2020; Hui, Yu/JOZ-3598-2023; Tsou,
   Chih-Chiang/K-3272-2013
OI Hu, Yu-Chen/0000-0002-5055-3645; Tsou, Chih-Chiang/0000-0003-4507-5463
CR BEI CD, 1985, IEEE T COMMUN, V33, P1132, DOI 10.1109/TCOM.1985.1096214
   Chang CC, 1998, IEEE T CONSUM ELECTR, V44, P1201
   Chen CQ, 2004, IEEE SIGNAL PROC LET, V11, P167, DOI 10.1109/LSP.2003.819869
   Gersho A., 2003, Vector Quantization and Signal Compression
   Hsieh CH, 2000, IEEE T IMAGE PROCESS, V9, P321, DOI 10.1109/83.826771
   Hu YC, 2003, IMAGING SCI J, V51, P221, DOI 10.1080/13682199.2003.11784428
   Huang CM, 1993, IEEE T IMAGE PROCESS, V2, P108, DOI 10.1109/83.210871
   HUANG SH, 1990, ELECTRON LETT, V26, P1618, DOI 10.1049/el:19901037
   LI WH, 1995, IEEE T CIRC SYST VID, V5, P119, DOI 10.1109/76.388060
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Pan JS, 2003, IEEE T IMAGE PROCESS, V12, P265, DOI 10.1109/TIP.2003.810587
   Pan ZB, 2005, IEEE SIGNAL PROC LET, V12, P609, DOI 10.1109/LSP.2005.851263
   RA SW, 1993, IEEE T CIRCUITS-II, V40, P576, DOI 10.1109/82.257335
   SOLEYMANI MR, 1989, IEEE T COMMUN, V37, P656, DOI 10.1109/26.31152
   SONG BC, 2002, IEEE T IMAGE PROCESS, V4, P325
   TORRES L, 1994, IEEE T COMMUN, V42, P208, DOI 10.1109/TCOMM.1994.577009
   Wu KS, 2000, IEEE T CIRC SYST VID, V10, P59, DOI 10.1109/76.825859
   Xiong HL, 2004, IEEE SIGNAL PROC LET, V11, P474, DOI 10.1109/LSP.2004.824054
NR 19
TC 34
Z9 40
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 657
EP 666
DI 10.1016/j.imavis.2007.08.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900006
DA 2024-07-18
ER

PT J
AU Stolkin, R
   Greig, A
   Hodgetts, M
   Gilby, J
AF Stolkin, Rustam
   Greig, Alistair
   Hodgetts, Mark
   Gilby, John
TI An EM/E-MRF algorithm for adaptive model based tracking in extremely
   poor visibility
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE tracking; segmentation; pose estimation; Markov random field;
   expectation maximisation; MRF; EM; poor visibility; robot vision
ID STATISTICAL-ANALYSIS
AB This paper addresses the problems of visual tracking in conditions of extremely poor visibility. The human visual system can often correctly interpret images that are of such poor quality that they contain insufficient explicit information to do so. We assert that such systems must therefore make use of prior knowledge in several forms.
   A tracking algorithm is presented which combines observed data (the current image) with predicted data derived from prior knowledge of the object being viewed and an estimate of the camera's motion. During image segmentation, a predicted image is used to estimate class conditional distribution models and an Extended-Markov Random Field technique is used to combine observed image data with expectations of that data within a probabilistic framework. Interpretations of scene content and camera position are then mutually improved using Expectation Maximisation. Models of background and tracked object are continually relearned and adapt iteratively with each new image frame.
   The algorithm is tested using real video sequences, filmed in poor visibility conditions with complete pre-measured ground-truth data. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Stolkin, Rustam; Hodgetts, Mark; Gilby, John] Sira Technol Ctr, Chislehurst BR7 5EH, Kent, England.
   [Stolkin, Rustam; Greig, Alistair] UCL, Dept Mech Engn, London WC1E 7JE, England.
   [Stolkin, Rustam] Stevens Inst Technol, Ctr Maritime Syst, Hoboken, NJ 07030 USA.
C3 University of London; University College London; Stevens Institute of
   Technology
RP Stolkin, R (corresponding author), Stevens Inst Technol, Ctr Maritime Syst, Hoboken, NJ 07030 USA.
EM RStolkin@stevens.edu; A_Greig@meng.ucl.ac.uk; mchodgetts@ukonline.co.uk;
   John.Gilby@sira.co.uk
RI GREIG, Alistair/B-1693-2009
CR [Anonymous], P INT C PATT REC, DOI 10.1109/ICPR.1990.118221
   [Anonymous], 1992, ACTIVE VISION
   [Anonymous], P 6 INT C ADV PATT R
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Besl P. J., 1985, ACM COMPUTING SURVEY, V17
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   BLAKE A, 2000, 11 BRIT MACH VIS C P
   BOUTHEMY P, 1989, P IEEE INT C AC SPEE, V3, P1651
   BOYCOV Y, 1999, P INT C COMP VIS, V1, P345
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Bradski GR, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P214, DOI 10.1109/ACV.1998.732882
   CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995
   CHRISTMAS WJ, 1996, P 7 BRIT MACH VIS C, P555
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   COOTES TF, 1997, P BRIT MACH VIS C, P110
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DRUMMOND T, 1999, P 10 BRIT MACH VIS C
   ELGAMMAL A, 1999, P IEEE FRAM RAT WORK
   FAUGERAS OR, 1986, INT J ROBOTICS RES, V5
   Foresti G. L., 2001, IEEE T SYSTEMS MAN B, V31
   FOX D, 1999, P 16 NATL C ART INT
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GENNERY DB, 1992, INT J COMPUT VISION, V7, P243, DOI 10.1007/BF00126395
   Gibbs W., 1902, ELEMENTARY PRINCIPLE
   GRIMSON WEL, 1998, COMPUTER VISION PATT
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Ising E, 1925, Z PHYS, V31, P253, DOI 10.1007/BF02980577
   Jones GD, 2003, IMAGE VISION COMPUT, V21, P843, DOI 10.1016/S0262-8856(03)00071-4
   KANADE T, 1998, P DARPA IM UND WORKS, V1, P3
   Kohli P, 2005, IEEE I CONF COMP VIS, P922
   LACEY A, 2001, P BRIT MACH VIS C, P203
   LOWE D, 1992, INT J COMPUT VISION, V8, P441
   Markov A.A., 1906, B SOC PHYS MATH, V2, P155
   MARROQUIN J, 1987, J AM STAT ASSOC, V82, P76, DOI 10.2307/2289127
   MEIER T, 1997, IEEE INT C IM PROC I, V1, P216
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   NEAL RM, 1993, NEW VIEW EM ALGORITH
   Nocedal J., 1999, NUMERICAL OPTIMIZATI
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   STOLKIM R, 2005, C COMP ROB VIS IEEE, P210
   STOLKIN R, 2000, P 11 BRIT MACH VIS C, P715
   STOLKIN R, 2005, INT C COMP VIS BENCO, P25
   STOLKIN R, 2006, J MEASUREMENT SCI TE
   Ullman S., 1996, High level vision
   VERGHESE G, 1994, P VISION INTERFACE, V94, P202
   Watkins WR, 2000, P SOC PHOTO-OPT INS, V4023, P20, DOI 10.1117/12.389357
   WUNSCH P, 1996, P 13 INT C PATT REC, P77
   Zhang J., 2000, APS COMM NETW MULTIM, P301
NR 51
TC 27
Z9 30
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2008
VL 26
IS 4
BP 480
EP 495
DI 10.1016/j.imavis.2007.06.008
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 264QQ
UT WOS:000253304100003
DA 2024-07-18
ER

PT J
AU Kato, Z
AF Kato, Zoltan
TI Segmentation of color images via reversible jump MCMC sampling
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE unsupervised image segmentation; color; parameter estimation; normal
   mixture identification; Markov random fields; reversible jump Markov
   chain Monte Carlo simulated annealing
ID UNSUPERVISED SEGMENTATION; PARAMETER-ESTIMATION; BAYESIAN-ANALYSIS;
   UNKNOWN NUMBER; MIXTURE-MODELS; MARKOV-CHAINS
AB Reversible jump Markov chain Monte Carlo (RJMCMC) is a recent method which makes it possible to construct reversible Markov chain samplers that jump between parameter subspaces of different dimensionality. In this paper, we propose a new RJMCMC sampler for multivariate Gaussian mixture identification and we apply it to color image segmentation. For this purpose, we consider a first order Markov random field (MRF) model where the singleton energies derive from a multivariate Gaussian distribution and second order potentials favor similar classes in neighboring pixels. The proposed algorithm finds the most likely number of classes, their associated model parameters and generates a segmentation of the image by classifying the pixels into these classes. The estimation is done according to the Maximum A Posteriori (MAP) criterion. The algorithm has been validated on a database of real images with human segmented ground truth. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Szeged, Inst Informat, H-6701 Szeged, Hungary.
C3 Szeged University
RP Kato, Z (corresponding author), Univ Szeged, Inst Informat, POB 652, H-6701 Szeged, Hungary.
EM kato@inf.u-szeged.hu
RI Kato, Zoltan/AAD-6406-2019; cai, bo/G-1491-2010
CR [Anonymous], 2002, ART H SIG PROC LIB
   [Anonymous], 1997, THESIS U OXFORD
   [Anonymous], 2003, Highly structured stochastic systems
   [Anonymous], 2003, Image analysis, random fields and Markov chain Monte Carlo methods: a mathematical introduction
   Barker SA, 2000, PATTERN RECOGN, V33, P587, DOI 10.1016/S0031-3203(99)00074-6
   BESAG J, 1986, J R STAT SOC B, V48, P259
   Brooks SP, 2003, J R STAT SOC B, V65, P3, DOI 10.1111/1467-9868.03711
   Chalmond B., 2003, Modeling and Inverse Problems in Image Analysis
   Cremers D, 2002, INT J COMPUT VISION, V50, P295, DOI 10.1023/A:1020826424915
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Giordana N, 1997, IEEE T PATTERN ANAL, V19, P465, DOI 10.1109/34.589206
   Green PJ, 1995, BIOMETRIKA, V82, P711, DOI 10.1093/biomet/82.4.711
   Gupta L, 1998, PATTERN RECOGN, V31, P315, DOI 10.1016/S0031-3203(97)00045-9
   HASTINGS WK, 1970, BIOMETRIKA, V57, P97, DOI 10.1093/biomet/57.1.97
   HUANG CL, 1992, PATTERN RECOGN, V25, P1217, DOI 10.1016/0031-3203(92)90023-C
   Kato Z, 2001, PATTERN RECOGN LETT, V22, P309, DOI 10.1016/S0167-8655(00)00106-9
   KATO Z, 1999, 0199R055 ERCIMCWI
   Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005
   LAKSHMANAN S, 1989, IEEE T PATTERN ANAL, V11, P799, DOI 10.1109/34.31443
   Langan DA, 1998, IEEE T IMAGE PROCESS, V7, P180, DOI 10.1109/83.660995
   LIU JQ, 1994, IEEE T PATTERN ANAL, V16, P689, DOI 10.1109/34.297949
   Mardia K. V., 1979, MULTIVARIATE ANAL, P457
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Mumford D., 1996, PERCEPTION BAYESIAN, P25
   Mumford D., 1994, GEOMETRY DRIVEN DIFF, P141
   PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   Richardson S, 1997, J ROY STAT SOC B MET, V59, P731, DOI 10.1111/1467-9868.00095
   Robert CP, 2000, J R STAT SOC B, V62, P57, DOI 10.1111/1467-9868.00219
   Sangwine S. J., 1998, The colour image processing handbook
   Schraudolph NN, 1999, NEURAL COMPUT, V11, P853, DOI 10.1162/089976699300016467
   Stephens M, 2000, ANN STAT, V28, P40, DOI 10.1214/aos/1016120364
   WON CS, 1992, CVGIP GMIP, V54, P208
   Zhu SC, 1999, IEEE T PATTERN ANAL, V21, P1158, DOI 10.1109/34.809109
NR 38
TC 35
Z9 44
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 361
EP 371
DI 10.1016/j.imavis.2006.12.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500005
DA 2024-07-18
ER

PT J
AU Cui, JS
   Zha, HB
   Zhao, HJ
   Shibasaki, R
AF Cui, Jinshi
   Zha, Hongbin
   Zhao, Huijing
   Shibasaki, Ryosuke
TI Multi-modal tracking of people using laser scanners and video camera
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multi-modal; multiple people tracking; laser scanner; video camera;
   surveillance
AB Inspite extensive research on visual tracking of multiple people in computer vision area, the robustness and usability of visual trackers are still discouraging. Recently, a few laser-based detection and tracking methods have been developed in robotics area. However, poor features provided by laser data make the tracker fail in many situations. In this paper, we present a novel method that aims at reliably detecting and tracking multiple people in an open area. Multiple laser scanners and one camera are used as input sensors. In detection stage, laser-based detection algorithm captures newly appeared people and initializes the mean-shift-based visual tracker. In tracking stage, laser-based feet trajectory tracking result and visual body region tracking result are combined with a decision-level Bayesian fusion method. The experimental results demonstrate reliable and real-time performance of the method. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Cui, Jinshi; Zha, Hongbin; Zhao, Huijing] Peking Univ, State Key Lab Machine Percept, Beijing, Peoples R China.
   [Shibasaki, Ryosuke] Univ Tokyo, Ctr Spatial Informat Sci, Tokyo, Japan.
C3 Peking University; University of Tokyo
RP Cui, JS (corresponding author), Peking Univ, State Key Lab Machine Percept, Beijing, Peoples R China.
EM cjs@cis.pku.edu.cn
CR Blanco J., 2003, C ADV ROB
   Byers Z., 2003, IEEE C ROB SYST
   Comaniciu D., 2003, IEEE Trans. Pattern Anal. Machine Intell, V25
   Elgammal AM, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P145, DOI 10.1109/ICCV.2001.937617
   FOD A, 2002, IEEE C ROBOTICS AUTO, P3025
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   HAN B, 2004, IEEE C COMP VIS PATT
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   KLUGE B, 2001, IEEE C ROB AUT
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   NISHIMURA T, 2002, SPIE
   Scheutz M., 2004, IEEE C ROB SYST
   SCHULZ D, 2001, IEEE C COMPUT VIS PA
   Siebel NT, 2002, LECT NOTES COMPUT SC, V2353, P373
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Zhao HJ, 2005, IEEE T SYST MAN CY A, V35, P283, DOI 10.1109/TSMCA.2005.843396
   Zhao HJ, 2001, PHOTOGRAMM ENG REM S, V67, P1143
   ZHAO T, 2003, IEEE C COMPUT VIS PA
NR 18
TC 42
Z9 53
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 240
EP 252
DI 10.1016/j.imavis.2007.05.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500008
DA 2024-07-18
ER

PT J
AU Heidemann, G
AF Heidemann, Gunther
TI Region saliency as a measure for colour segmentation stability
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE colour segmentation; saliency; adaptation; unsupervised learning
ID FUZZY C-MEANS; IMAGE SEGMENTATION; ALGORITHMS; RECOGNITION; INFORMATION;
   ATTENTION
AB This paper proposes a goodness function for colour segmentation, which allows to predict whether the segmented regions will be stable against noise, variation of lighting, and change of viewpoint. As such a measure, colour saliency defined from average border contrast is proposed. While the idea to maximise border contrast in segmentation is not novel per se, it is shown here empirically that maximisation of border contrast indeed leads to improved region stability. Experiments for three different algorithms show that the effect is independent of the particular functional principle of segmentation. Thus, the measure can be applied for the automatic and context-free optimisation of segmentation parameters. (c) 2007 Elsevier B.V. All rights reserved.
C1 Univ Stuttgart, Intelligent Syst Grp, D-70569 Stuttgart, Germany.
C3 University of Stuttgart
RP Heidemann, G (corresponding author), Univ Stuttgart, Intelligent Syst Grp, Univ Str 38, D-70569 Stuttgart, Germany.
EM ais@vis.uni-stuttgart.de
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   AHALT SC, 1990, NEURAL NETWORKS, V3, P277, DOI 10.1016/0893-6080(90)90071-R
   Alexander DC, 2001, INT J COMPUT VISION, V44, P87, DOI 10.1023/A:1011870913626
   Borsotti M, 1998, PATTERN RECOGN LETT, V19, P741, DOI 10.1016/S0167-8655(98)00052-X
   Braun E, 1999, PATTERN RECOGN LETT, V20, P1085, DOI 10.1016/S0167-8655(99)00075-6
   Carevic D, 1997, GRAPH MODEL IM PROC, V59, P27, DOI 10.1006/gmip.1996.0402
   Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   CHU CC, 1993, IEEE T PATTERN ANAL, V15, P1241, DOI 10.1109/34.250843
   COLE BL, 1990, VISUAL SEARCH, P407
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Comaniciu D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1197, DOI 10.1109/ICCV.1999.790416
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   FINDLAY JM, 1980, PERCEPTION, V9, P7, DOI 10.1068/p090007
   Gonzales R., 1992, DIGITAL IMAGE PROCES
   GROSSBERG S, 1987, COGNITIVE SCI, V11, P23, DOI 10.1111/j.1551-6708.1987.tb00862.x
   HARALICK R, 1986, GRAPHICS IMAGE PROCE, V29, P100
   HARTMANN G, 1987, BIOL CYBERN, V57, P73, DOI 10.1007/BF00318717
   Heidemann G, 2004, IEEE T PATTERN ANAL, V26, P817, DOI 10.1109/TPAMI.2004.29
   Heidemann G, 2004, COMPUT VIS IMAGE UND, V94, P234, DOI 10.1016/j.cviu.2003.10.009
   Horowitz S.L., 1974, PROC, P424
   Ikonomakis N, 2000, J INTELL ROBOT SYST, V28, P5, DOI 10.1023/A:1008163913937
   Ito N, 1996, INFORM SCIENCES, V92, P277, DOI 10.1016/0020-0255(96)00039-4
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   LIM YW, 1990, PATTERN RECOGN, V23, P935, DOI 10.1016/0031-3203(90)90103-R
   Littmann E, 1997, IEEE T NEURAL NETWOR, V8, P175, DOI 10.1109/72.554203
   LIU JQ, 1994, IEEE T PATTERN ANAL, V16, P689, DOI 10.1109/34.297949
   Ma WY, 2000, IEEE T IMAGE PROCESS, V9, P1375, DOI 10.1109/83.855433
   Macqueen J., 1965, Proc of Berkeley Symposium on Mathematical Statistics Probability, P281
   Martin D., 2001, P ICCV, P416, DOI [DOI 10.1109/ICCV.2001.937655, 10.1109/ICCV.2001.937655]
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Moghaddamzadeh A, 1997, PATTERN RECOGN, V30, P867, DOI 10.1016/S0031-3203(96)00084-2
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   OHLANDER R, 1978, COMPUT VISION GRAPH, V8, P313, DOI 10.1016/0146-664X(78)90060-6
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   PALMER SE, 1983, HUMAN MACHINE VISION
   PRESS HW, 1992, NUMERICAL RECIPES
   Priese L., 1995, Proceedings of the Intelligent Vehicles '95. Symposium (Cat. No.95TH8132), P310, DOI 10.1109/IVS.1995.528299
   Priese L., 1993, P MUST DAGM S, P297
   Privitera CM, 2000, IEEE T PATTERN ANAL, V22, P970, DOI 10.1109/34.877520
   REHRMANN V, 1994, THESIS FOLBACH
   REHRMANN V, 1998, P 3 AS C COMP VIS
   REHRMANN V, 1997, P 30 ISATA INT S AUT
   Saber E, 1997, IMAGE VISION COMPUT, V15, P769, DOI 10.1016/S0262-8856(97)00019-X
   Sammouda M, 2002, J BIOMED INFORM, V35, P92, DOI 10.1016/S1532-0464(02)00501-4
   Schenone A, 1996, COMPUT MED IMAG GRAP, V20, P119, DOI 10.1016/0895-6111(96)00008-0
   SCHETTINI R, 1993, PATTERN RECOGN LETT, V14, P499, DOI 10.1016/0167-8655(93)90030-H
   Scheunders P, 1997, PATTERN RECOGN LETT, V18, P1379, DOI 10.1016/S0167-8655(97)00116-5
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Senders JW, 1997, P SOC PHOTO-OPT INS, V3016, P186, DOI 10.1117/12.274513
   SIEBERT A, 1998, SPIE C STOR RETR IM, V6, P14
   SKARBEK W, 1997, 32 TU BERL DEP COMP
   STRASTERS KC, 1991, PATTERN RECOGN LETT, V12, P307, DOI 10.1016/0167-8655(91)90414-H
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   Weeks AR, 1997, P SOC PHOTO-OPT INS, V3026, P143, DOI 10.1117/12.271117
   Yang JF, 2002, SIGNAL PROCESS, V82, P461, DOI 10.1016/S0165-1684(01)00196-7
   Yarbus A.L., 1967, EYE MOVEMENTS VISION, DOI [10.1007/978-1-4899-5379-7, DOI 10.1007/978-1-4899-5379-7]
   YASNOFF WA, 1977, PATTERN RECOGN, V9, P217, DOI 10.1016/0031-3203(77)90006-1
   Zhang YJ, 1996, PATTERN RECOGN, V29, P1335, DOI 10.1016/0031-3203(95)00169-7
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
   Zucker S. W., 1976, Computer Graphics and Image Processing, V5, P382, DOI 10.1016/S0146-664X(76)80014-7
   Zugaj D, 1998, PATTERN RECOGN, V31, P105, DOI 10.1016/S0031-3203(97)00027-7
NR 62
TC 8
Z9 11
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 211
EP 227
DI 10.1016/j.imavis.2007.05.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500006
DA 2024-07-18
ER

PT J
AU Vernon, D
AF Vernon, David
TI Cognitive vision: The case for embodied perception
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE cognitive vision; embodiment; cognitivist systems; dynamical systems;
   enactive systems
ID RECOGNITION; ORGANIZATION; FRAMEWORK; SYSTEMS
AB This paper considers arguments for the necessity of embodiment in cognitive vision systems. We begin by delineating the scope of cognitive vision, and follow this by a survey of the various approaches that can be taken to the realization of artificial cognitive vision systems, focussing on cognitive aspects. These range from the cognitivist symbolic representational paradigm, through connectionist systems and self-organizing dynamical systems, to the enactive cognition paradigm. We then consider various arguments for embodiment, beginning with paradigm-specific cases, and concluding with a paradigm-independent argument for embodied perception and cognition. We explore briefly different forms of embodiment and their relevance to the foregoing viewpoints. We highlight some of the key problems associated with embodied cognitive vision, including the phylogeny/ontogeny trade-off in artificial systems and the developmental limitations imposed by real-time environmental coupling. Finally, we conclude by considering some aspects of natural cognitive systems to see how they can provide insights to help in addressing these problems. (c) 2006 Elsevier B.V. All rights reserved.
C1 Etisalat Univ Coll, Sharjah, U Arab Emirates.
C3 Khalifa University of Science & Technology
RP Vernon, D (corresponding author), Etisalat Univ Coll, Sharjah, U Arab Emirates.
EM david@vernon.eu
OI Vernon, David/0000-0002-9782-3788
CR [Anonymous], P EUR 99 3 EUR WORKS
   [Anonymous], LNCS
   [Anonymous], LNCS
   [Anonymous], REPRESENTATION MIND
   [Anonymous], MIND DESIGN PHILOS P
   [Anonymous], 1978, BIOL COGNITION
   [Anonymous], LNCS
   [Anonymous], P INT SPEECH IM UND
   [Anonymous], P 15 EUR C ART INT A
   [Anonymous], 1994, MIT PRESS BRADFORD B
   [Anonymous], HDB BRAIN THEORY NEU
   [Anonymous], 1988, NEURAL INFORM PROCES
   [Anonymous], 1995, Mind as Motion: Explorations in the Dynamics of Cognition
   [Anonymous], 2002, The imitative mind: Development, evolution, and brain bases
   [Anonymous], KI Z KUNSTLICHE INTE
   [Anonymous], KI Z KUNSTLICHE INTE
   [Anonymous], 1986, UNDERSTANDING COMPUT
   Arens M, 2002, LECT NOTES ARTIF INT, V2479, P268
   Arens M, 2002, FRONT ARTIF INTEL AP, V77, P455
   AUER P, 2005, ECVISION EUROPEAN NE
   BALLARD DH, 1991, ARTIF INTELL, V48, P57, DOI 10.1016/0004-3702(91)90080-4
   Bickhard M. H., 2000, CC-AI, The Journal for the Integrated Study of Artificial Intelligence, Cognitive Science and Applied Epistemology, V17, P111
   Brachman RJ, 2002, IEEE INTELL SYST, V17, P67, DOI 10.1109/MIS.2002.1134363
   Brooks Rodney A., 2002, Flesh and Machines: How Robots Will Change Us
   BUXTON H, 2002, WORKSH COGN VIS ZUR
   BUXTON H, 2002, ECCV WORKSH GEN MOD
   BUXTON H, 2002, INT C PATT REC QUEB
   CHRISTENSEN HI, 2003, 03441 COGN VIS SYST
   Clark A., 2001, MINDWARE INTRO PHILO
   Craighero L, 2004, CURR BIOL, V14, P331, DOI 10.1016/j.cub.2004.01.054
   CROWLEY JL, KI Z KUNSTLICHE INTE
   Crutchfield JP, 1998, BEHAV BRAIN SCI, V21, P635, DOI 10.1017/S0140525X98291734
   Dickmanns ED, 2004, AI MAG, V25, P10
   Draper BA, 2003, LECT NOTES COMPUT SC, V2626, P1
   DREYFUS H. L., 1979, MIND DESIGN PHILOSOP, P161
   Gallese V, 1996, BRAIN, V119, P593, DOI 10.1093/brain/119.2.593
   Gegenfurtner K, 1999, NATURE, V398, P291, DOI 10.1038/18563
   GEGENFURTNER KR, 2002, CURR BIOL, V10, P805
   GERBER R, 2002, COGN VIS WORKSH ZUR
   GIBSON GJ, 2000, ECOLOGICAL APPROACH
   Gibson J., 1979, The ecological approach to visual perception
   Gibson J.J., 1950, PERCEPTION VISUAL WO
   GRANLUND G, KI Z KUNSTLICHE INTE
   Granlund GH, 2004, AI MAG, V25, P51
   Granlund GH, 1999, SIGNAL PROCESS, V74, P101, DOI 10.1016/S0165-1684(98)00204-7
   GRANLUND GH, 2002, COGNITIVE VISION BAC
   GRANLUND GH, 1999, P SCIA99
   HARNAD S, 1990, PHYSICA D, V42, P335, DOI 10.1016/0167-2789(90)90087-6
   Hollnagel E, 1999, INT J HUM-COMPUT ST, V51, P339, DOI 10.1006/ijhc.1982.0313
   HOLLNAGEL E, 2002, SUBSTANCE COGNITIVE
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Jogan M, 2003, LECT NOTES COMPUT SC, V2626, P460
   Jones Marggie., 1994, Neural Computing and Applications, V2, P2
   Kelso J. S., 1995, DYNAMIC PATTERNS SEL
   KIHLSTROM JF, 1987, SCIENCE, V237, P1445, DOI 10.1126/science.3629249
   Kohler W., 1940, Dynamics in psychology
   LINSKER R, 1988, COMPUTER, V21, P105, DOI 10.1109/2.36
   Maillot N, 2003, LECT NOTES COMPUT SC, V2626, P44
   MARR D, 1977, ARTIF INTELL, V9, P37, DOI 10.1016/0004-3702(77)90013-3
   MATURANA HR, 1975, INT J MAN MACH STUD, V7, P313, DOI 10.1016/S0020-7373(75)80015-0
   Maturana HR, 1980, AUTOPOIESIS COGNITIO
   Maturana Humberto, 1987, The Tree of Knowledge: The Biological Roots of Human Understanding
   Meltzoff AN, 1997, EARLY DEV PARENTING, V6, P179, DOI 10.1002/(SICI)1099-0917(199709/12)6:3/4<179::AID-EDP157>3.0.CO;2-R
   Metta G, 2003, ADAPT BEHAV, V11, P109, DOI 10.1177/10597123030112004
   Metta G, 1999, NEURAL NETWORKS, V12, P1413, DOI 10.1016/S0893-6080(99)00070-2
   METTA G, IN PRESS P 5 INT WOR
   Nagel HH, 2004, AI MAG, V25, P31
   Nagel HH, 2003, LECT NOTES COMPUT SC, V2626, P34
   NEUMANN B, IN PRESS LNCS, P235
   NEWELL A, 1976, COMMUN ACM, V19, P113, DOI 10.1145/360018.360022
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pauli J, 2002, PATTERN RECOGN LETT, V23, P803, DOI 10.1016/S0167-8655(01)00157-X
   PHILIPONA D, NEURAL COMPUTATION, V15
   PHILIPONA D, 2004, ADV NEURAL INFORM PR, V16
   PINKER S, 1984, COGNITION, V18, P1, DOI 10.1016/0010-0277(84)90021-0
   Rao R.P. N., 2004, In Imitation and Social Learning in Robots, Humans, and Animals
   Reiter R., 2001, Knowledge in Action: Logical Foundations for Specifying and Implementing Dynamical Systems
   Rizzolatti G, 1996, COGNITIVE BRAIN RES, V3, P131, DOI 10.1016/0926-6410(95)00038-0
   Rosander K, 2002, EXP BRAIN RES, V146, P257, DOI 10.1007/s00221-002-1161-2
   Sandini G, 2004, IEEE-RAS INT C HUMAN, P13
   SANDINI G, 1997, HUMAN SENSORI MOTOR
   SantosVictor J, 1997, ROBOT AUTON SYST, V19, P299, DOI 10.1016/S0921-8890(96)00058-9
   Shah M, 2002, INT J COMPUT VISION, V50, P103, DOI 10.1023/A:1020323930790
   SHEPARD RN, 1984, COGNITION, V18, P161, DOI 10.1016/0010-0277(84)90024-6
   SIVAK B, 1990, NEUROPSYCHOLOGIA, V28, P1095, DOI 10.1016/0028-3932(90)90143-C
   SLOMAN A, 2005, IJCAI 05
   SLOMAN A, 2005, INT WORKSH GRAND CHA
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Spelke ES, 2000, AM PSYCHOL, V55, P1233, DOI 10.1037/0003-066X.55.11.1233
   Susi T, 2003, PROCEEDINGS OF THE TWENTY-FIFTH ANNUAL CONFERENCE OF THE COGNITIVE SCIENCE SOCIETY, PTS 1 AND 2, P1134
   Thelen E., 1995, MIND MOTION EXPLORAT, P69
   Town C, 2003, LECT NOTES COMPUT SC, V2626, P54
   TSOTSOS JK, 2005, LNCS, P27
   Varela F. J., 1979, Principles of Biological Autonomy
   Varela F.J., 1992, Understanding Origins-Contemporary Views on the Origin of Life, Mind and Society, Boston Studies in the Philosophy of Science, V130, P235
   von Hofsten C, 2004, TRENDS COGN SCI, V8, P266, DOI 10.1016/j.tics.2004.04.002
   Von Hofsten C, 2003, HANDBOOK OF DEVELOPMENTAL PSYCHOLOGY, P114
   VONHOFSTEN C, 1982, DEV PSYCHOL, V18, P450, DOI 10.1037/0012-1649.18.3.450
   WARREN WH, 1984, J EXP PSYCHOL HUMAN, V10, P683, DOI 10.1037/0096-1523.10.5.683
   ZIEMKE T, 2001, MODELING COGNITIVE D, V85, P75
NR 100
TC 31
Z9 32
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 127
EP 140
DI 10.1016/j.imavis.2005.08.009
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100011
DA 2024-07-18
ER

PT J
AU Birchfield, ST
   Natarajan, B
   Tomasi, C
AF Birchfield, Stanley T.
   Natarajan, Braga
   Tomasi, Carlo
TI Correspondence as energy-based segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereo; motion; correspondence; segmentation; multiway-cut; graph cuts;
   affine; energy minimization
AB We pose the correspondence problem as one of energy-based segmentation. In this framework, correspondence assigns each pixel in an image to exactly one of several non-overlapping regions, and it also computes a displacement function for each region. The framework is better able to capture the scene geometry than the more direct formulation of matching pixels in two or more images, particularly when the surfaces in the scene are not fronto-parallel. To illustrate the framework, we present a specific correspondence algorithm that minimizes an energy functional by alternating between (1) segmenting the image into a number of non-overlapping regions using the multiway-cut algorithm of Boykov, Veksler, and Zabih; and (2) finding the affine parameters describing the displacement of the pixels in each region. After convergence, a final step escapes local minima due to over-segmentation. The basic algorithm is extended in two ways: using ground control points to detect long, thin regions; and warping segmentation results to efficiently process image sequences. Experiments on real images show the algorithm's ability to find an accurate segmentation and displacement map, as well as discontinuities and creases, on a wide variety of stereo and motion imagery. (c) 2006 Elsevier B.V. All rights reserved.
C1 Clemson Univ, Dept Elect & Comp Engn, Clemson, SC 29634 USA.
   Duke Univ, Dept Comp Sci, Durham, NC 27708 USA.
C3 Clemson University; Duke University
RP Birchfield, ST (corresponding author), Clemson Univ, Dept Elect & Comp Engn, Clemson, SC 29634 USA.
EM stb@clemson.edu
CR [Anonymous], 1987, Visual Reconstruction
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2001, P INT C COMP VIS
   AYER S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P777, DOI 10.1109/ICCV.1995.466859
   Baker H.M., 1981, PROC 7 INT JOINT C A, P631
   Belhumeur P. N., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P431, DOI 10.1109/ICCV.1993.378184
   Birchfield S, 1999, INT J COMPUT VISION, V35, P269, DOI 10.1023/A:1008160311296
   Bleyer M, 2005, ISPRS J PHOTOGRAMM, V59, P128, DOI 10.1016/j.isprsjprs.2005.02.008
   Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   BOYKOV Y, 1999, P IEEE C COMP VIS PA
   COHEN LD, 1989, P IEEE C COMP VIS PA
   DARRELL T, 1995, IEEE T PATTERN ANAL, V17, P474, DOI 10.1109/34.391395
   Fua P., 1991, P 12 INT JOINT C ART, P1292
   GEIGER D, 1995, INT J COMPUT VISION, V14, P211, DOI 10.1007/BF01679683
   GLEICHER M, 1997, P IEEE C COMP VIS PA
   INTILLE SS, 1994, P 3 EUR C COMP VIS, P179
   Jepson A., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P760, DOI 10.1109/CVPR.1993.341161
   Kim J., 2003, P INT C COMP VIS
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   KOLMOGOROV V, 2002, P INT C COMP VIS
   LIN MH, 2003, P IEEE C COMP VIS PA
   LOPEZ A, 2001, SCAND C IM AN
   Mittal A, 2003, INT J COMPUT VISION, V51, P189, DOI 10.1023/A:1021849801764
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   RANDRIAMASY S, 1992, DIRECT COOPERATION R
   Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   WANG JYA, 1994, IEEE T IMAGE PROCESS, V3, P625, DOI 10.1109/83.334981
   Weiss Y, 1996, PROC CVPR IEEE, P321, DOI 10.1109/CVPR.1996.517092
   ZABIH R, 2004, P IEEE C COMP VIS PA
NR 33
TC 13
Z9 20
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1329
EP 1340
DI 10.1016/j.imavis.2006.08.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000013
DA 2024-07-18
ER

PT J
AU Schalk, P
   Ofner, R
   O'Leary, P
AF Schalk, P.
   Ofner, R.
   O'Leary, P.
TI Pipe eccentricity measurement using laser triangulation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE eccentricity measurement; laser triangulation; metric vision; circle
   fitting; uncertainty
AB A pipe eccentricity measurement system based on laser triangulation is presented. The custom measurement head implements the Scheimpflug condition to ensure maximum working depth and integrates an FPGA to perform real time image processing at a rate of 200 frames per second. The eccentricity of the pipe is estimated by approximating the position of the upper tangent point of the pipe and used as a measure of its straightness. The correlation coefficients for the parameters r, x(0) and y(0) estimating from a least square approximation of a circle via the algebraic distance are theoretically derived, demonstrated using Monte-Carlo simulation and experimentally verified. It is shown that perturbation of the measurement, leads to less uncertainty in the estimated position of the tangent point than for the centre point. Harmonic filtering based on Elliptical Fourier Descriptors is used to filter the measurement data.
   Laboratory measurements show that the repeatability is in the order of 1 mu m. The accuracy of industrial measurements exhibits a systematic bias of -4 mu m and has a standard deviation of 2.6 mu m. Selected measurements from the production plant are presented to show that the deviation of the cross-section of the pipe from a perfect circle can be determined from the measured radius of curvature. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Min & Met Leoben, Chair Automat, A-8700 Leoben, Austria.
C3 University of Leoben
RP Schalk, P (corresponding author), Univ Min & Met Leoben, Chair Automat, A-8700 Leoben, Austria.
EM peter.schalk@unileoben.ac.at
RI O'Leary, Paul L/K-4998-2012
CR EICHLER J, 1998, LASER
   FAUSTER E, 2002, 2 WSEAS INT C SIGN S, P6
   Harker M, 2005, P SOC PHOTO-OPT INS, V5674, P354, DOI 10.1117/12.586499
   HARKER M, 2005, BRIT MACH VIS C, V1, P310
   Lu RS, 2001, SENSOR ACTUAT A-PHYS, V94, P95, DOI 10.1016/S0924-4247(01)00683-5
   Merklinger H. M., 1996, PHOTO TECHNIQUES, V17, P56
   Nievergelt Y, 2001, LINEAR ALGEBRA APPL, V331, P43, DOI 10.1016/S0024-3795(01)00263-4
   OFNER R, 2000, THESIS U LEOBEN
   OLEARY P, 2005, METRIC VISION GEOMET
   Oppenheim A. V., 1989, Discrete -Time Signal Processing
NR 10
TC 22
Z9 26
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1194
EP 1203
DI 10.1016/j.imavis.2006.04.021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300016
DA 2024-07-18
ER

PT J
AU McKenna, SJ
   Nait-Charif, H
AF McKenna, S. J.
   Nait-Charif, H.
TI Tracking human motion using auxiliary particle filters and iterated
   likelihood weighting
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE human tracking; particle filters; iterated likelihood weighting;
   supportive environments; head tracking
AB Bayesian particle filters have become popular for tracking human motion in cluttered scenes. The most commonly used filters suffer from two drawbacks. First, the prior used for the filtering step is often poor due to relatively large, poorly modelled inter-frame motion. Second, the use of the prior as an importance function results in inefficient sampling of the posterior. The use of the auxiliary particle filter (APF) and the novel iterated likelihood weighting filter (ILW) are proposed here in order to help address these problems. Experimental results comparing the filters' accuracy and consistency are presented for a scenario in which a person is tracked in an overhead view using an ellipse model. A likelihood model based on combined region (colour) and boundary (gradient) cues is motivated and used. The ILW filter is shown to outperform both Condensation and the APF on typical sequences from this scenario. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Dundee, Sch Comp, Dundee DD1 4HN, Scotland.
C3 University of Dundee
RP McKenna, SJ (corresponding author), Univ Dundee, Sch Comp, Dundee DD1 4HN, Scotland.
EM stephen@computing.dundee.ac.uk; hammadi@computing.dundee.ac.uk
RI Charif, Hammadi Nait/AAG-6142-2020; McKenna, Stephen/AAL-8335-2020
OI McKenna, Stephen/0000-0003-0530-2035
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225
   Carpenter J, 1999, IEE P-RADAR SON NAV, V146, P2, DOI 10.1049/ip-rsn:19990255
   CHAM T, 1998, IEEE C COMP VIS PATT, V7, P239
   Choo K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P321, DOI 10.1109/ICCV.2001.937643
   Deutscher J, 2001, PROC CVPR IEEE, P669
   Deutscher J, 2000, PROC CVPR IEEE, P126, DOI 10.1109/CVPR.2000.854758
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   Gustafsson F, 2002, IEEE T SIGNAL PROCES, V50, P425, DOI 10.1109/78.978396
   ISARD M, 1996, EUR C COMP VIS, V1, P343
   Isard M., 1998, PROC 5 EUROPEAN C CO, V1, P893
   KING O, 2000, ECCV, P695
   LI P, 2002, 1 INT WORKSH GEN MOD, P61
   Magee DR, 2002, IMAGE VISION COMPUT, V20, P581, DOI 10.1016/S0262-8856(02)00047-1
   Musso C, 2001, STAT ENG IN, P247
   Newell, 2003, HUMAN CTR COMPUTING, P512
   Nummiaro K., 2002, Proceedings of International Workshop on Generative-Model-Based Vision, V2002/01, P53
   Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179
   ROBERTS TJ, 2002, BRIT MACH VIS C, P333
   Rui Y, 2001, PROC CVPR IEEE, P786
   TORMA P, 2001, 5 IFAC S NONL CONTR, P715
   Tweed D., 2002, BMVC, P283
   Vlassis N, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P7, DOI 10.1109/ROBOT.2002.1013331
   Walter M., 1999, BMVC99. Proceedings of the 10th British Machine Vision Conference, P23
   West M., 1993, Computing Science and Statistics: Proceedings of 24th Symphosium on the Interface, P325
   ZLOCHIN M, 2001, ARTIFICIAL NEURAL NE, P141
NR 27
TC 36
Z9 42
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 852
EP 862
DI 10.1016/j.imavis.2006.06.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600007
DA 2024-07-18
ER

PT J
AU Jolly, EK
   Fleury, M
AF Jolly, E. K.
   Fleury, M.
TI Multi-sector algorithm for hardware acceleration of the general Hough
   transform
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT PDVIM Workshop 2006
CY FEB, 2006
CL Monteliard, FRANCE
DE Hough transform; CORDIC; FPGA
ID ARCHITECTURE; PROCESSOR
AB The Multi-Sector Algorithm (MSA) is a simplification of the CORDIC algorithm to more closely meet the requirements for real-time general Hough transform applications. The MSA can form a pipeline, and multiple angle rotations are performed in parallel. The whole has been tested on Virtex platform FPGAs to find straight edges within images. Angular resolution is incrementally scalable. Video-rate processing is easily achieved. The ability to run independent MS units in parallel is only limited by on-chip memory restrictions. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Essex, Dept Elect Syst Engn, Colchester CO4 3SQ, Essex, England.
C3 University of Essex
RP Fleury, M (corresponding author), Univ Essex, Dept Elect Syst Engn, Colchester CO4 3SQ, Essex, England.
EM ekjol@essex.ac.uk; fleum@essex.ac.uk
CR Andraka R., 1998, FPGA'98. ACM/SIGDA International Symposium on Field Programmable Gate Arrays, P191, DOI 10.1145/275107.275139
   Bensaali F, 2004, LECT NOTES COMPUT SC, V3203, P991
   BOWEN M, 1998, LANGUAGE REFERENCE M
   Bruguera JD, 1996, J VLSI SIG PROCESS S, V12, P207, DOI 10.1007/BF00924986
   Davies E.R., 1997, MACHINE VISION THEOR, V2nd
   DENG DDS, 2001, P PAN SYDN AR WORKSH, P51
   DEPRETTERE E, 1984, INT C AC SPEECH SIGN
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Fleury M., 2001, IEE Proceedings-Software, V148, P31, DOI 10.1049/ip-sen:20010213
   Fleury M., 2005, MILITARY AERONAUTICS, P133
   HANAHARA K, 1988, IEEE T PATTERN ANAL, V10, P121, DOI 10.1109/34.3876
   HILLS M, 2003, INT C VIS INF ENG VI
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   *IONN SEM, 2000, IA64250 HIST HOUGH T
   LI HW, 1986, COMPUT VISION GRAPH, V36, P139, DOI 10.1016/0734-189X(86)90073-3
   Maharatna K, 2001, PATTERN RECOGN, V34, P1503, DOI 10.1016/S0031-3203(00)00080-7
   OGORMAN F, 1976, IEEE T COMPUT, V25, P449, DOI 10.1109/TC.1976.1674627
   Pan Y, 1999, IEEE T SYST MAN CY A, V29, P417, DOI 10.1109/3468.769762
   RHODES FM, 1988, IEEE T PATTERN ANAL, V10, P106, DOI 10.1109/34.3873
   ROSENFELD A, 1988, COMPUT VISION GRAPH, V41, P293, DOI 10.1016/0734-189X(88)90104-1
   Strzodka R, 2003, 12TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P188, DOI 10.1109/ICIAP.2003.1234048
   TIMMERMANN D, 1989, ELECTRON LETT, V25, P205, DOI 10.1049/el:19890147
   Wilton SJE, 1999, IEEE T VLSI SYST, V7, P80, DOI 10.1109/92.748203
   *XIL INC, 2002, VIRT 2 PLATF EPGA HD
   XU L, 1990, PATTERN RECOGN LETT, V11, P331, DOI 10.1016/0167-8655(90)90042-Z
   ZHOU F, 1995, INT C DIG SIGN PROC
NR 26
TC 7
Z9 7
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 970
EP 976
DI 10.1016/j.imavis.2006.02.016
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200006
DA 2024-07-18
ER

PT J
AU Rajwade, A
   Levine, MD
AF Rajwade, Ajit
   Levine, Martin D.
TI Facial pose from 3D data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D pose estimation; range data; discrete wavelet transform; support
   vector regression; dimensionality reduction; principal components
   analysis
ID SUPPORT VECTOR MACHINES
AB The distribution of the apparent 3D shape of human faces across the view-sphere is complex, owing to factors such as variations in identity, facial expression, minor occlusions and noise. In this paper, we use the technique of support vector regression on wavelet sub-bands to learn a model relating facial shape (obtained from 3D scanners) to 3D pose in an identity-invariant manner. The proposed method yields an estimation accuracy of 97-99% within an error of +/- 9 degrees on a large set of data obtained from two different sources. The method could be used for pose estimation in a view-invariant face recognition system. (c) 2006 Elsevier B.V. All rights reserved.
C1 McGill Univ, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.
C3 McGill University
RP Rajwade, A (corresponding author), Univ Florida, 123 Grinter Hall, Gainesville, FL 32601 USA.
EM ajitvr@cim.mcgill.ca
CR Amenta Nina, 2001, P 6 ACM S SOL MOD AP
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   CATMULL E, THESIS U UTAL SALT L
   CHANG CC, 2001, LIBSVM LIB SUPP VECT
   Chang K., 2003, WORKSH MULT US AUTH
   CHOI M, 1998, BRIT MACH VIS C
   Hattori K, 1998, INT C PATT RECOG, P1183, DOI 10.1109/ICPR.1998.711908
   Huang J, 1998, INT C PATT RECOG, P154, DOI 10.1109/ICPR.1998.711102
   LEVINE M, UNPUB 3D VIEW INVARI
   Li SZ, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P674, DOI 10.1109/ICCV.2001.937691
   LI Y, 2000, P IEEE INT C AUT FAC, P300
   Li YM, 2004, IMAGE VISION COMPUT, V22, P413, DOI 10.1016/j.imavis.2003.12.005
   Malassiotis S, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P859
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Motwani MC, 2001, IEEE IMAGE PROC, P1050, DOI 10.1109/ICIP.2001.959229
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   Romdhani S, 2002, LECT NOTES COMPUT SC, V2353, P3
   Sarris N, 2001, GRAPH MODELS, V63, P333, DOI 10.1006/gmod.2001.0563
   Srinivasan S, 2002, INT C PATT RECOG, P302, DOI 10.1109/ICPR.2002.1047456
   TSALAKANIDOU F, 2004, 2 INT C 3DPVT
   Wei YC, 2002, IEEE IMAGE PROC, P281
NR 25
TC 9
Z9 10
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2006
VL 24
IS 8
BP 849
EP 856
DI 10.1016/j.imavis.2006.02.010
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 082IX
UT WOS:000240381100006
DA 2024-07-18
ER

PT J
AU Spagnolo, P
   Orazio, TD
   Leo, M
   Distante, A
AF Spagnolo, P.
   Orazio, T. D'
   Leo, M.
   Distante, A.
TI Moving object segmentation by background subtraction and temporal
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE moving object segmentation; temporal analysis; background updating
ID TRACKING
AB In this paper, we address the problem of moving object segmentation using background subtraction. Solving this problem is very important for many applications: visual surveillance of both in outdoor and indoor environments, traffic control, behavior detection during sport activities, and so on. All these applications require as a first step, the detection of moving objects in the observed scene before applying any further technique for object recognition and activity identification.
   We propose a reliable foreground segmentation algorithm that combines temporal image analysis with a reference background image. We are especially careful of the core problem arising in the analysis of outdoor daylight scenes: continuous variations of lighting conditions that cause unexpected changes in intensities on the background reference image. In this paper, a new approach for background adaptation to changes in illumination is presented. All the pixels in the image, even those covered by foreground objects, are continuously updated in the background model. The experimental results demonstrate the effectiveness of the proposed algorithm when applied in different outdoor and indoor environments. (C) 2006 Elsevier B.V. All rights reserved.
C1 CNR, Ist Studi Sistemi Intelligent Automaz, I-70126 Bari, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Studi sui Sistemi
   Intelligenti per l'Automazione (ISSIA-CNR)
RP Orazio, TD (corresponding author), CNR, Ist Studi Sistemi Intelligent Automaz, Via Amendola 122-D-1, I-70126 Bari, Italy.
EM spagnolo@ba.issia.cnr.it; spagnolo@ba.issia.cnr.it; leo@ba.issia.cnr.it;
   distante@ba.issia.cnr.it
RI Leo, Marco/AAG-6296-2019; D'Orazio, Tiziana/H-5032-2019; Spagnolo,
   Paolo/AAX-7082-2020
OI Leo, Marco/0000-0001-5636-6130; D'Orazio, Tiziana/0000-0003-1473-7110;
   Spagnolo, Paolo/0000-0001-9129-9375
CR [Anonymous], DARP IU WORKSH
   BRANCA A, 2002, P INT C PATT REC QUE
   Chalidabhongse T., 2003, P JOINT IEEE INT WOR, P1937
   Collins R., 2000, CMURITR0012
   ELGAMMAL A, 1999, IEEE FRAM RAT WORKSH
   Fejes S., ICCV 98 4 7 JAN BOMB
   FEJES S, DARPA 97 2 5 FEBR VI
   FEJES S, 1997, CARTR866 U MAR
   Friedman N., 1997, UNCERTAINTY ARTIFICI
   Grimson E., 1998, COMP VIS PATT REC C, P22
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Herrero-Jaraba E, 2003, PATTERN RECOGN LETT, V24, P2079, DOI 10.1016/S0167-8655(03)00045-X
   Ivanov Y, 1998, 1998 IEEE WORKSHOP ON VISUAL SURVEILLANCE, PROCEEDINGS, P49
   JABRI S, ICPR 2000 3 8 SEPT B, P627
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   KOLLER D, 1994, P INT C PATT REC ISR
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Lim SN, 2005, PROC CVPR IEEE, P1071
   Mittal A, 2004, PROC CVPR IEEE, P302
   Monnet A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1305
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Thongkamwitoon T, 2005, IEEE INT SYMP CIRC S, P3785, DOI 10.1109/ISCAS.2005.1465454
   Toyama K., 1999, The Proceedings of the Seventh IEEE International Conference on Computer Vision, V1, P255
   WIXSON L, ICCV 99 20 27 SEPT C
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   Wu QZ, 2005, PATTERN RECOGN LETT, V26, P555, DOI 10.1016/j.patrec.2004.09.010
   Wu QZ, 2002, PATTERN RECOGN LETT, V23, P1529, DOI 10.1016/S0167-8655(02)00116-2
NR 28
TC 101
Z9 130
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 411
EP 423
DI 10.1016/j.imavis.2006.01.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600002
DA 2024-07-18
ER

PT J
AU Tang, WK
   Hung, YS
AF Tang, W. K.
   Hung, Y. S.
TI A subspace method for projective reconstruction from multiple images
   with missing data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multiple views; subspace method; factorization method; structure from
   motion
AB In this paper, we consider the problem of projective reconstruction based on the subspace method. Unlike existing subspace methods which require that all the points are visible in all views, we propose an algorithm to estimate projective shape, projective depths and missing data iteratively. All these estimation problems are formulated within a subspace framework in terms of the minimization of a single consistent objective function, hence ensuring the convergence of the iterative solution. Experimental results using both synthetic data and real images are provided to illustrate the performance of the proposed method. (C) 2006 Published by Elsevier B.V.
C1 Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Tang, WK (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
EM wktang@eee.hku.hk; yshung@eee.hku.hk
RI Tang, Arvin/C-1767-2009; Hung, Yeung Sam/C-1852-2009
CR [Anonymous], 2000, LNCS, DOI DOI 10.1007/3-540-44480-7
   [Anonymous], EUR C COMP VIS ECCV
   Chen G., 1999, INT C COMP VIS PATT, V2, P55
   Chen GQ, 2002, IMAGE VISION COMPUT, V20, P103, DOI 10.1016/S0262-8856(01)00090-7
   FAUGERAS O, 1995, J OPT SOC AM A, V12, P465, DOI 10.1364/JOSAA.12.000465
   Han M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P163, DOI 10.1109/ICCV.2001.937513
   HAN M, 2000, CMURITR0009 C MELLON
   HARTLEY R, 1993, LECT NOTES COMPUTER, V825, P237
   Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5
   Hung YS, 2006, INT J COMPUT VISION, V66, P305, DOI 10.1007/s11263-005-3675-0
   Mahamud S, 2001, PROC CVPR IEEE, P1018
   Mahamud S, 2000, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2000.854872
   Oliensis J, 1999, IEEE T PATTERN ANAL, V21, P665, DOI 10.1109/34.777379
   SPARR G, 1996, IEEE INT C PATT REC
   Tang WK, 2006, COMPUT VIS IMAGE UND, V101, P166, DOI 10.1016/j.cviu.2005.07.007
   TANG WK, 2002, LNCS, V2449, P387
   TANG WK, 2004, THESIS U HONG KONG
   Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170
NR 18
TC 9
Z9 12
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 515
EP 524
DI 10.1016/j.imavis.2006.02.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600010
DA 2024-07-18
ER

PT J
AU Shih, FY
   Cheng, SX
AF Shih, FY
   Cheng, SX
TI Automatic seeded region growing for color image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image segmentation; color image processing; seeded region growing;
   region-merging
ID EDGE; ALGORITHM; HOMOGENEITY; INFORMATION; LINKING
AB In this paper, we present an automatic seeded region growing algorithm for color image segmentation. First, the input RGB color image is transformed into YCbCr color space. Second, the initial seeds are automatically selected. Third, the color image is segmented into regions where each region corresponds to a seed. Finally, region-merging is used to merge similar or small regions. Experimental results show that our algorithm can produce good results as favorably compared to some existing algorithms. (c) 2005 Elsevier B.V. All rights reserved.
C1 New Jersey Inst Technol, Coll Comp Sci, Comp Vis Lab, Newark, NJ 07102 USA.
C3 New Jersey Institute of Technology
RP Shih, FY (corresponding author), New Jersey Inst Technol, Coll Comp Sci, Comp Vis Lab, Newark, NJ 07102 USA.
EM shih@njit.edu
RI Wang, Xiaojing/HNI-4384-2023
OI Wang, Xiaojing/0000-0001-6921-3619
CR ADAMS R, 1994, IEEE T PATTERN ANAL, V16, P641, DOI 10.1109/34.295913
   BASAK J, 1994, IEEE T SYST MAN CYB, V24, P413, DOI 10.1109/21.278991
   Chai D., 2000, TENCON, V2, P421
   Cheng HD, 1998, IEEE T IMAGE PROCESS, V7, P1084, DOI 10.1109/83.701171
   Cheng HD, 2002, PATTERN RECOGN, V35, P373, DOI 10.1016/S0031-3203(01)00054-1
   Cheng HD, 2001, PATTERN RECOGN, V34, P2259, DOI 10.1016/S0031-3203(00)00149-7
   CHU CC, 1993, IEEE T PATTERN ANAL, V15, P1241, DOI 10.1109/34.250843
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Fan JP, 2001, IEEE T IMAGE PROCESS, V10, P1454, DOI 10.1109/83.951532
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   HADDON JF, 1990, IEEE T PATTERN ANAL, V12, P929, DOI 10.1109/34.58867
   Hojjatoleslami SA, 1998, IEEE T IMAGE PROCESS, V7, P1079, DOI 10.1109/83.701170
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   IKONOMAKIS N, 1997, P IEEE C DIGITAL SIG, V1, P299
   MARTELLI A, 1976, COMMUN ACM, V19, P73, DOI 10.1145/359997.360004
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254
   NALWA VS, 1987, COMPUT VISION GRAPH, V40, P79, DOI 10.1016/0734-189X(87)90057-0
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   PAVLIDIS T, 1990, IEEE T PATTERN ANAL, V12, P225, DOI 10.1109/34.49050
   Saha PK, 2001, IEEE T PATTERN ANAL, V23, P689, DOI 10.1109/34.935844
   SALEMBIER P, 1994, SIGNAL PROCESS, V38, P359, DOI 10.1016/0165-1684(94)90155-4
   Shih FY, 2004, INFORM SCIENCES, V167, P9, DOI 10.1016/j.ins.2003.07.020
   Tremeau A, 1997, PATTERN RECOGN, V30, P1191, DOI 10.1016/S0031-3203(96)00147-1
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   WONG AKC, 1989, IEEE T SYST MAN CYB, V19, P641
NR 28
TC 264
Z9 312
U1 8
U2 70
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2005
VL 23
IS 10
BP 877
EP 886
DI 10.1016/j.imavis.2005.05.015
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 962PQ
UT WOS:000231745100003
DA 2024-07-18
ER

PT J
AU Hu, WC
AF Hu, WC
TI Multiprimitive segmentation based on meaningful breakpoints for fitting
   digital planar curves with line segments and conic arcs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multiprimitive; segmentation; conic arcs; breakpoint
ID DOMINANT POINT DETECTION; CORNER DETECTION; CIRCULAR ARCS; APPROXIMATION
AB This paper presents a multiprimitive segmentation method with line segments and conic arcs based on the types of breakpoints. In this method, a joint tuning procedure is proposed to merge consecutive segments and adjust their locations to achieve more accurate and stable conic arcs. No threshold is required in the multiprimitive segmentation by using the proposed scheme. And, the types of breakpoints among line segments and conic arcs are defined and they are useful and meaningful for pattern recognition and shape analysis. Besides, the computational complexity of the proposed method is O(n log n) which is lower than most other conic fitting methods. Further, the concept of types of breakpoints can be easily extended to other primitives. (c) 2005 Elsevier B.V. All rights reserved.
C1 Natl Penghu Inst Technol, Dept Comp Sci & Informat Engn, Makung, Penghu, Taiwan.
C3 National Penghu University of Science & Technology
RP Natl Penghu Inst Technol, Dept Comp Sci & Informat Engn, 300 Liu Ho Rd,, Makung, Penghu, Taiwan.
EM wchu@npit.edu.tw
CR Ahn SJ, 2001, PATTERN RECOGN, V34, P2283, DOI 10.1016/S0031-3203(00)00152-7
   ASADA H, 1986, IEEE T PATTERN ANAL, V8, P2, DOI 10.1109/TPAMI.1986.4767747
   Chabat F, 1999, IMAGE VISION COMPUT, V17, P761, DOI 10.1016/S0262-8856(98)00150-4
   Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   Horng JH, 2003, PATTERN RECOGN LETT, V24, P565, DOI 10.1016/S0167-8655(02)00277-5
   Horng JH, 2002, PATTERN RECOGN LETT, V23, P1657, DOI 10.1016/S0167-8655(02)00129-0
   Li LY, 1999, IEEE T PATTERN ANAL, V21, P1204, DOI 10.1109/34.809113
   Mortenson M. E, 1990, COMPUTER GRAPHICS HD
   RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805
   ROSIN PL, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P75
   ROSIN PL, 1995, IEEE T PATTERN ANAL, V17, P1140, DOI 10.1109/34.476507
   ROSIN PL, 1989, IMAGE VISION COMPUT, V7, P109, DOI 10.1016/0262-8856(89)90004-8
   Sarkar B, 2003, PATTERN RECOGN LETT, V24, P2869, DOI 10.1016/S0167-8655(03)00145-4
   Sarkar B, 2003, PATTERN RECOGN LETT, V24, P2585, DOI 10.1016/S0167-8655(03)00103-X
   Sheu HT, 1999, IEEE T PATTERN ANAL, V21, P791, DOI 10.1109/34.784310
   Sheu HT, 1996, PATTERN RECOGN, V29, P819, DOI 10.1016/0031-3203(95)00121-2
   Sporring J, 2000, IMAGE VISION COMPUT, V18, P261, DOI 10.1016/S0262-8856(99)00017-7
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
   Tsai D. M., 1996, PATTERN RECOGN, V29, P85
   Wang GY, 2002, PATTERN RECOGN LETT, V23, P1695, DOI 10.1016/S0167-8655(02)00132-0
   Wu WY, 2003, IMAGE VISION COMPUT, V21, P517, DOI 10.1016/S0262-8856(03)00031-3
   Zeid I., 1991, CAD/CAM Theory and Practice
   Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2
   Zhu QM, 1999, IMAGE VISION COMPUT, V17, P645, DOI 10.1016/S0262-8856(98)00148-6
NR 24
TC 14
Z9 17
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2005
VL 23
IS 9
BP 783
EP 789
DI 10.1016/j.imavis.2005.05.004
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VF
UT WOS:000231400700002
DA 2024-07-18
ER

PT J
AU Brandt, SS
AF Brandt, SS
TI Conditional solutions for the affine reconstruction of <i>N</i>-views
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE affine triangulation; affine reconstruction; bundle adjustment; image
   registration; degeneracy identification; multiple view geometry
ID MISSING DATA; FACTORIZATION METHOD; AUTOMATIC ALIGNMENT; MOTION;
   RECOVERY; CAMERA; SHAPE
AB The known factorisation algorithm for the maximum likelihood affine reconstruction requires that all the feature points used must be visible in all views. We derive here a conditional solution for the 3D coordinates of the feature points and translation vectors given the inhomogeneous affine projection matrices, but no single feature point needs to be visible in all views. The solution represents closed-form maximum likelihood, generalised affine triangulation under missing data and unknown translations, and it implies two iterative algorithms for the maximum likelihood affine reconstruction where all the measured data may be used. For the case where at least four non-coplanar points are visible in all views, a non-iterative solution for affine reconstruction with missing data is also proposed. As reported, the closed form-expression additionally has applications in affine bundle adjustment and identifying degenerate configurations. (c) 2005 Elsevier B.V. All rights reserved.
C1 Aalto Univ, Lab Computat Engn, FI-02015 Helsinki, Finland.
C3 Aalto University
RP Brandt, SS (corresponding author), Aalto Univ, Lab Computat Engn, POB 9203, FI-02015 Helsinki, Finland.
EM sami.brandt@tkk.fi
OI Brandt, Sami/0000-0003-2141-9815
CR [Anonymous], 1981, Practical Optimization
   [Anonymous], 1992, NUMERICAL RECIPES C
   Brandt S, 2001, J STRUCT BIOL, V136, P201, DOI 10.1006/jsbi.2001.4443
   Brandt S, 2001, J STRUCT BIOL, V133, P10, DOI 10.1006/jsbi.2001.4343
   BRANDT S, 2002, THESIS HELSINKI U TE
   COHEN J, 1976, ACTA INFORM, V6, P341, DOI 10.1007/BF00268135
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Frank J., 1992, Electron Tomography: Three-dimensional imaging with the transmission electron microscope
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley RI, 1997, COMPUT VIS IMAGE UND, V68, P146, DOI 10.1006/cviu.1997.0547
   Irani M, 2000, LECT NOTES COMPUT SC, V1842, P539
   Jacobs D, 1997, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.1997.609321
   Jacobs DW, 2001, COMPUT VIS IMAGE UND, V82, P57, DOI 10.1006/cviu.2001.0906
   Kahl F, 1999, INT J COMPUT VISION, V33, P163, DOI 10.1023/A:1008192713051
   KOENDERINK JJ, 1991, J OPT SOC AM A, V8, P377, DOI 10.1364/JOSAA.8.000377
   Lawrence M.C., 1992, ELECT TOMOGRAPHY, P197, DOI DOI 10.1007/978-1-4757-2163-8_8
   MA S, 1993, INT J COMPUT VISION, V1, P7
   Morris DD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P696, DOI 10.1109/ICCV.1998.710793
   Poelman CJ, 1997, IEEE T PATTERN ANAL, V19, P206, DOI 10.1109/34.584098
   Quan L, 1996, PROC CVPR IEEE, P803, DOI 10.1109/CVPR.1996.517164
   Quan L, 1996, INT J COMPUT VISION, V19, P93, DOI 10.1007/BF00131149
   QUAN L, 1998, LECT NOTES COMPUTER, V1506, P32
   Reid ID, 1996, INT J COMPUT VISION, V18, P41, DOI 10.1007/BF00126139
   Rother C, 2002, INT J COMPUT VISION, V49, P117, DOI 10.1023/A:1020189404787
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553
   SHUM HY, 1995, IEEE T PATTERN ANAL, V17, P854, DOI 10.1109/34.406651
   Slama C.C., 1980, MANUAL PHOTOGRAMMETR, Vfourth
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torr P., 1995, THESIS U OXFORD
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   WENG JY, 1992, IEEE T PATTERN ANAL, V14, P318, DOI 10.1109/34.120327
   Wiberg T., 1976, Second Symposium on Computational Statistics, P229
NR 34
TC 4
Z9 4
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2005
VL 23
IS 7
BP 619
EP 630
DI 10.1016/j.imavis.2005.01.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 940LX
UT WOS:000230147100001
DA 2024-07-18
ER

PT J
AU Ekenel, HK
   Sankur, L
AF Ekenel, HK
   Sankur, L
TI Multiresolution face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multiresolution analysis; discrete wavelet transform; independent
   component analysis; principal component analysis; fusion
AB In this paper the contribution of multiresolution analysis to the face recognition performance is examined. We refer to the paradigm that in classification tasks, the use of multiple observations and their judicious fusion at the data, feature or decision level improves the correct decision performance. In our proposed method, prior to the subspace projection operation like principal or independent component analysis, we employ multiresolution analysis to decompose the image into its subbands. Our aim is to search for the subbands that are insensitive to the variations in expression and in illumination. The classification performance is improved by fusing the information coming from the subbands that attain individually high correct recognition rates. The proposed algorithm is tested on face images that differ in expression or illumination separately, obtained from CMU PIE, FERET and Yale databases. Significant performance gains are attained, especially against illumination perturbations. (c) 2004 Elsevier B.V. All rights reserved.
C1 Bogazici Univ, Dept Elect & Elect Engn, Istanbul, Turkey.
C3 Bogazici University
RP Bogazici Univ, Dept Elect & Elect Engn, Istanbul, Turkey.
EM ekenelha@boun.edu.tr
RI EKENEL, HAZIM KEMAL/A-5293-2016; Sankur, Bulent/N-4663-2017
OI EKENEL, HAZIM KEMAL/0000-0003-3697-8548; 
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   [Anonymous], 1992, 10 LECT WAVELETS
   Bartlett MS, 1998, P SOC PHOTO-OPT INS, V3299, P528, DOI 10.1117/12.320144
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BRUNELLI R, 1993, IEEE T PATTERN ANAL, V15, P1042, DOI 10.1109/34.254061
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   Feng GC, 2000, J ELECTRON IMAGING, V9, P226, DOI 10.1117/1.482742
   Garcia C, 2000, IMAGE VISION COMPUT, V18, P289, DOI 10.1016/S0262-8856(99)00056-6
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Li B, 2002, KNOWL-BASED SYST, V15, P343, DOI 10.1016/S0950-7051(01)00172-1
   LIU Y, 2003, P 2003 IEEE INT WORK
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IEEE T IMAGE PROCESS, V7, P1150, DOI 10.1109/83.704308
   Sim T., 2002, P IEEE INT C AUT FAC
   TANG J, 2000, J VISUALIZATION SOC, V20, P303
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
NR 17
TC 102
Z9 113
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2005
VL 23
IS 5
BP 469
EP 477
DI 10.1016/j.imavis.2004.09.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 917XA
UT WOS:000228501300002
DA 2024-07-18
ER

PT J
AU Braquelaire, A
   Kerautret, B
AF Braquelaire, A
   Kerautret, B
TI Reconstruction of lambertian surfaces by discrete equal height contours
   and regions propagation
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE computer vision; shape from shading; photometric stereo; discrete
   geometry
ID SHAPE; IMAGES
AB This paper describes two new methods for the reconstruction of discrete surfaces from shading images. Both approaches are based on the reconstruction of a discrete surface by mixing photometric and geometric techniques. The processing of photometric information is based on reflectance maps, which are classic tools of Shape from Shading. The geometric features are extracted from the discrete surface and propagated along the surface. The propagation is based in one case on equal height discrete contour propagation and in the other case on region propagation. Both methods allow photometric stereo. Results of reconstruction from synthetic and real images are presented. (C) 2004 Elsevier B.V. All rights reserved.
C1 CNRS, UMR 5800, LaBRI, F-33405 Talence, France.
C3 Universite de Bordeaux; Centre National de la Recherche Scientifique
   (CNRS)
RP Kerautret, B (corresponding author), CNRS, UMR 5800, LaBRI, 351 Cours Liberat, F-33405 Talence, France.
EM achille@labri.fr; kerautre@labri.fr
CR [Anonymous], P 2 INT C COMP VIS
   Braquelaire A, 2003, LECT NOTES COMPUT SC, V2886, P257
   Braquelaire JP, 1999, GRAPH MODEL IM PROC, V61, P16, DOI 10.1006/prmp.1999.0488
   FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909
   Horn B K P, 1970, Tech. Rep.
   HORN BKP, 1977, ARTIF INTELL, V8, P201, DOI 10.1016/0004-3702(77)90020-0
   IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0
   Kerautret B., 2003, C GMPCA ARCH, P164
   KIMMEL R, 1995, COMPUT VIS IMAGE UND, V62, P47, DOI 10.1006/cviu.1995.1040
   KIMMEL R, 1995, INT J COMPUT VISION, V16, P107, DOI 10.1007/BF01539551
   LEE CH, 1985, ARTIF INTELL, V26, P439
   SAITO H, 1995, ACCV 95, V3, P348
   Samaras D, 2003, IEEE T PATTERN ANAL, V25, P247, DOI 10.1109/TPAMI.2003.1177155
   Taylor W. F., 1992, GEOMETRY COMPUTER
   Th-urmer Grit, 1997, EUROGRAPHICS, V16
   THURMER G, 1998, VARYING NEIGHBOURHOO, P616
   TSAI PS, 1994, IMAGE VISION COMPUT, V12, P487, DOI 10.1016/0262-8856(94)90002-7
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Yamada T., 1998, IAPR WORKSH MACH VIS
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   ZHANG R, 1997, IMAGE VISION COMPUT, P801
NR 21
TC 5
Z9 6
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 177
EP 189
DI 10.1016/j.imavis.2004.06.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800009
DA 2024-07-18
ER

PT J
AU Stelldinger, P
   Köthe, U
AF Stelldinger, P
   Köthe, U
TI Towards a general sampling theory for shape preservation
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE shape preservation; digitization; discretization; sampling theory;
   topology; hausdorff distance; r-regularity
ID DIGITIZATION
AB Computerized image analysis makes statements about the continuous world by looking at a discrete representation. Therefore, it is important to know precisely which information is preserved during digitization. We analyze this question in the context of shape recognition. Existing results in this area are based on very restricted models and thus not applicable to real imaging situations. We present generalizations in several directions: first, we introduce a new shape similarity measure that approximates human perception better. Second, we prove a geometric sampling theorem for arbitrary dimensional spaces. Third, we extend our sampling theorem to two-dimensional images that are subjected to blurring by a disk point spread function. Our findings are steps towards a general sampling theory for shapes that shall ultimately describe the behavior of real optical systems. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Hamburg, Cognit Syst Grp, D-22527 Hamburg, Germany.
C3 University of Hamburg
EM koethe@informatik.uni-hamburg.de
OI Stelldinger, Peer/0000-0001-8079-2797
CR Giraldo A, 1999, PATTERN RECOGN, V32, P365, DOI 10.1016/S0031-3203(98)00101-0
   Keller P.E., 1982, Algorithms for Graphics and Image Processing, V42, P709, DOI 10.1109/23.467888
   KOTHE U, 2003, LECT NOTES COMPUTER, V2886
   Latecki L., 1998, Discrete Representation of Spatial Objects in Computer Vision
   Latecki LJ, 1998, J MATH IMAGING VIS, V8, P131, DOI 10.1023/A:1008273227913
   Ronse C, 2000, J MATH IMAGING VIS, V12, P219, DOI 10.1023/A:1008366032284
   Serra J., 1983, IMAGE ANAL MATH MORP
   Stelldinger P, 2003, LECT NOTES COMPUT SC, V2781, P108
   STELLDINGER P, 2003, THESIS U HAMBURG
   TAJINE M, 2000, TOPOLOGICAL PROPERTI, P41
NR 10
TC 23
Z9 23
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 237
EP 248
DI 10.1016/j.imavis.2004.06.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800014
DA 2024-07-18
ER

PT J
AU Soh, J
AF Soh, J
TI Computational method for document object locator combination
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th International Conference on Vision Interface
CY MAY 27-29, 2002
CL Calgary, CANADA
DE document object; object location; decision combination; address block
   location
ID INFORMATION FUSION
AB This paper presents a method for combining multiple document object locators tuned to different object characteristics, with the goal of achieving location performance excelling that of any individual locator. The method includes (i) a scheme for consistent representation of locator outputs regardless of output levels, (ii) the notion of object correspondence and their applications to determining what decisions to combine, (iii) a mechanism for representing knowledge of locators and its use for dynamic locator selection, and (iv) functions for combining confidence values of objects. Results from experiments in postal address block location using three locators and 1,100 envelope images are presented. (C) 2004 Elsevier B.V. All rights reserved.
C1 Elect & Telecommun Res Inst, Intelligent Robot Res Div, Taejon, South Korea.
C3 Electronics & Telecommunications Research Institute - Korea (ETRI)
RP Soh, J (corresponding author), Elect & Telecommun Res Inst, Intelligent Robot Res Div, 161 Gajeong Dong, Taejon, South Korea.
EM soh@etri.re.kr
CR [Anonymous], 1989, APPL LINEAR REGRESSI
   ARBUCKLE TD, 1995, INT J UNCERTAIN FUZZ, V3, P217, DOI 10.1142/S0218488595000153
   BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560
   GOVINDARAJU V, 2003, P 7 INT C DOC AN REC, V1
   Huang Y. S., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P598, DOI 10.1109/ICDAR.1993.395664
   Jain AK, 1999, PATTERN RECOGN LETT, V20, P1371, DOI 10.1016/S0167-8655(99)00108-7
   Jain R., 1995, MACHINE VISION
   JELINEK J, 1988, P 3 USPS ADV TECHN C, P264
   KAMEL M, 1993, CVGIP-GRAPH MODEL IM, V55, P203, DOI 10.1006/cgip.1993.1015
   Lii J., 1993, Proceedings of the Second International Conference on Document Analysis and Recognition (Cat. No.93TH0578-5), P330, DOI 10.1109/ICDAR.1993.395721
   LIU Y, 1992, P 2 INT C DOC AN REC, P278
   Menoti D, 2003, PROC INT CONF DOC, P699
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Palumbo P. W., 1986, Proceedings of the SPIE - The International Society for Optical Engineering, V697, P278, DOI 10.1117/12.976229
   PALUMBO PW, 1992, COMPUTER, V25, P34, DOI 10.1109/2.144438
   PANKANTI S, 1995, IEEE T PATTERN ANAL, V17, P831, DOI 10.1109/34.406649
   RAHMAN A.F. R., 2003, International Journal on Document Analysis and Recognition (IJDAR), V5, P166
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Sugeno M., 1977, FUZZY AUTOMATA DECIS
   TAHANI H, 1990, IEEE T SYST MAN CYB, V20, P733, DOI 10.1109/21.57289
   WONG G, 1992, P 11 INT C PATT REC, V3, P185
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   XUE J, 1999, P 5 INT C DOC AN REC, P737
NR 23
TC 2
Z9 2
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2004
VL 22
IS 12
BP 1015
EP 1029
DI 10.1016/j.imavis.2004.03.016
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 855VU
UT WOS:000224003800008
DA 2024-07-18
ER

PT J
AU Kanazawa, Y
   Kanatani, K
AF Kanazawa, Y
   Kanatani, K
TI Image mosaicing by stratified matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Statistical Methods in Video Processing
CY JUN 01-02, 2002
CL COPENHAGEN, DENMARK
DE template matching; feature point correspondence; robust estimation;
   LMedS; image mosaicing; homography
AB We present a robust method for automatically matching points over two images for image mosaicing: after extracting feature points using a feature detector, we progressively estimate the rotation, the scale change, and the projective distortion between the two images by random voting and variable template matching. Using real images, we demonstrate that our method allows accurate image mosaicing even when conventional methods fail. (C) 2003 Published by Elsevier B.V.
C1 Toyohashi Univ Technol, Dept Knowledge Based Informat Engn, Toyohashi, Aichi 4418580, Japan.
   Okayama Univ, Dept Informat Technol, Okayama 7008530, Japan.
C3 Toyohashi University of Technology; Okayama University
RP Toyohashi Univ Technol, Dept Knowledge Based Informat Engn, Toyohashi, Aichi 4418580, Japan.
EM kanazawa@tutkie.tut.ac.jp; kanatani@suri.it.okayama-u.ac.jp
RI Chesca, Boris/B-3709-2018
CR [Anonymous], P EUR C COMP VIS
   BERGEN JR, 1992, P 2 EUR C COMP VIS, P237
   Chabat F, 1999, IMAGE VISION COMPUT, V17, P761, DOI 10.1016/S0262-8856(98)00150-4
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Kanatani K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P73, DOI 10.1109/ICCV.1999.791200
   KANATANI K, 2003, INT J IMAGE GRAPHICS, V3
   Kanatani K., 1996, Statistical optimization for geometric computation: theory and practice
   Kanazawa Y., 2001, 3D Structure from Images - SMILE 2000. Second European Workshop on 3D Structure from Multiple Images of Large-Scale Environments. Revised Papers (Lecture Notes in Computer Science Vol.2018), P35
   KANAZAWA Y, 2001, P 8 INT C COMP VIS V, P586
   Lee MS, 2002, IEEE T PATTERN ANAL, V24, P824, DOI 10.1109/TPAMI.2002.1008388
   Lourakis MIA, 2003, IEEE T PATTERN ANAL, V25, P271, DOI 10.1109/TPAMI.2003.1177157
   Maciel J, 2003, IEEE T PATTERN ANAL, V25, P187, DOI 10.1109/TPAMI.2003.1177151
   Maciel J, 2002, IMAGE VISION COMPUT, V20, P683, DOI 10.1016/S0262-8856(02)00058-6
   Olson CF, 2002, IEEE T PATTERN ANAL, V24, P853, DOI 10.1109/TPAMI.2002.1008392
   Pilu M, 1997, PROC CVPR IEEE, P261, DOI 10.1109/CVPR.1997.609330
   REISFELD D, 1995, INT J COMPUT VISION, V14, P119, DOI 10.1007/BF01418978
   Rousseeuw P. J., 1987, ROBUST REGRESSION OU
   Schaffalitzky F, 2002, LECT NOTES COMPUT SC, V2350, P414
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Szeliski R, 1997, P 24 ANN C COMP GRAP, P251
   Torr PHS, 2003, IEEE T PATTERN ANAL, V25, P354, DOI 10.1109/TPAMI.2003.1182098
   van Wyk MA, 2002, IEEE T PATTERN ANAL, V24, P988, DOI 10.1109/TPAMI.2002.1017624
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
   Zoghlami I, 1997, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.1997.609359
NR 27
TC 23
Z9 27
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2004
VL 22
IS 2
BP 93
EP 103
DI 10.1016/j.imavis.2003.07.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 769DW
UT WOS:000188612000003
DA 2024-07-18
ER

PT J
AU Chen, FS
   Fu, CM
   Huang, CL
AF Chen, FS
   Fu, CM
   Huang, CL
TI Hand gesture recognition using a real-time tracking method and hidden
   Markov models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE hand gesture recognition; hidden Markov model; hand tracking
ID ALGORITHM; FOURIER; WORD
AB In this paper, we introduce a hand gesture recognition system to recognize continuous gesture before stationary background. The system consists of four modules: a real time hand tracking and extraction, feature extraction, hidden Markov model (HMM) training, and gesture recognition. First. we apply a real-time hand tracking and extraction algorithm to trace the moving hand and extract the hand region, then we use the Fourier descriptor (FD) to characterize spatial features and the motion analysis to characterize the temporal features. We combine the spatial and temporal features of the input image sequence as our feature vector. After having extracted the feature vectors, we apply HMMs to recognize the input gesture. The gesture to be recognized is separately scored against different HMMs. The model with the highest score indicates the corresponding gesture. In the experiments, we have tested our system to recognize 20 different gestures, and the recognizing rate is above 90%. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Natl Tsing Hua Univ, Inst Elect Engn, Hsinchu 300, Taiwan.
C3 National Tsing Hua University
RP Natl Tsing Hua Univ, Inst Elect Engn, Hsinchu 300, Taiwan.
EM cllhuang@ee.nthu.edu.tw
CR [Anonymous], P ANN C ROB SOC JAP
   [Anonymous], P IEEE 2 INT WORKSH
   [Anonymous], P IEEE 2 INT C AUT F
   [Anonymous], P IEEE 2 INT C AUT F
   BAUDEL T, 1993, COMMUN ACM, V36, P28, DOI 10.1145/159544.159562
   BOBICK AF, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P382
   DARRELL TP, 1992, 197 MIT MED LAB PERC
   DAVIS J, 1994, IEE P VIS IM SIGN PO, P141
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huang CL, 1998, MACH VISION APPL, V10, P292, DOI 10.1007/s001380050080
   KUNDU A, 1989, PATTERN RECOGN, V22, P283, DOI 10.1016/0031-3203(89)90076-9
   Liang RH, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P558, DOI 10.1109/AFGR.1998.671007
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   LOCKTON R, 2002, P BRIT MACH VIS C
   NAGAYA S, 1996, P IEEE 2 INT WORKSH
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   PERSOON E, 1977, IEEE T SYST MAN CYB, V7, P170, DOI 10.1109/TSMC.1977.4309681
   RABINER LR, 1983, AT&T TECH J, V62, P1075, DOI 10.1002/j.1538-7305.1983.tb03115.x
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Schlenzig J., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P187, DOI 10.1109/ACV.1994.341308
   SHRIDHAR M, 1984, PATTERN RECOGN, V17, P515, DOI 10.1016/0031-3203(84)90049-9
   STARNER T, 1905, P INT WORKSH AUT FAC
   STURMAN DJ, 1994, IEEE COMPUT GRAPH, V14, P30, DOI 10.1109/38.250916
   Takahashi T., 1992, Systems and Computers in Japan, V23, P38, DOI 10.1002/scj.4690230304
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P465
NR 28
TC 305
Z9 356
U1 0
U2 50
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2003
VL 21
IS 8
BP 745
EP 758
DI 10.1016/S0262-8856(03)00070-2
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 706VM
UT WOS:000184475800006
DA 2024-07-18
ER

PT J
AU Meegama, RGN
   Rajapakse, JC
AF Meegama, RGN
   Rajapakse, JC
TI NURBS snakes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE active contours; non-unifonn rational B-spline; energy minimisation;
   boundary extraction; snakes
ID ACTIVE CONTOUR MODELS; SEGMENTATION
AB A new formulation of energy minimising splines, based on Non-Uniform Rational B-Spline (NURBS) curves, is presented. The existing snake models do not facilitate the local control of their shapes without increasing the number of control points. The introduction of NURBS renders more flexibility into the snake model due to the weighting parameters that are made to adapt according to the curvature of the contour. The proposed snake model was tested on both synthetic and real images; the new model demonstrated more local flexibility than the previous models and is capable of attracting to complex boundaries of the objects with increased accuracy. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Comp Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Nanyang Technol Univ, Sch Comp Engn, Nanyang Ave, Singapore 639798, Singapore.
EM asjagath@ntu.edu.sg; rgayan@slt.lk
RI Nguyen, Minh/KHW-4288-2024; Rajapakse, Jagath/B-8485-2008
OI Rajapakse, Jagath/0000-0001-7944-1658
CR [Anonymous], IM UND WORKSH PITTSB
   Atkins MS, 1998, IEEE T MED IMAGING, V17, P98, DOI 10.1109/42.668699
   Brigger P, 2000, IEEE T IMAGE PROCESS, V9, P1484, DOI 10.1109/83.862624
   BRYGEL M, 2000, VIDEO BOOK SURG
   Chakraborty A, 1996, IEEE T MED IMAGING, V15, P859, DOI 10.1109/42.544503
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   DAVATZIKOS CA, 1995, IEEE T MED IMAGING, V14, P65, DOI 10.1109/42.370403
   Fenster SD, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P420, DOI 10.1109/ICCV.1998.710753
   GAO J, 1998, P IEEE INT C IM PROC, V3, P323
   Ji LL, 1998, P ANN INT IEEE EMBS, V20, P609, DOI 10.1109/IEMBS.1998.745472
   Jones TD, 2000, IEEE T MED IMAGING, V19, P1202, DOI 10.1109/42.897812
   Kang DJ, 1999, ELECTRON LETT, V35, P1070, DOI 10.1049/el:19990716
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Klein AK, 1997, IEEE T MED IMAGING, V16, P468, DOI 10.1109/42.640737
   LABROOSE F, 2001, P INT C CENTR EUR CO, P206
   LAI KF, 1995, IEEE T PATTERN ANAL, V17, P1084, DOI 10.1109/34.473235
   Lam K.-M., 1994, ISSIPNN '94. 1994 International Symposium on Speech, Image Processing and Neural Networks Proceedings (Cat. No.94TH0638-7), P17, DOI 10.1109/SIPNN.1994.344976
   LI X, 1999, IEEE C COMP VIS PATT, V2, P434
   MATSUZAWA Y, 1999, P INT C IM PROC, V3, P198
   McInerney T, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P171, DOI 10.1109/MMBIA.1996.534069
   MCINERNEY T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P840, DOI 10.1109/ICCV.1995.466850
   NEUENSCHWANDER W, 1994, P INT C PATT REC, V1, P613
   Pardo XM, 2001, IMAGE VISION COMPUT, V19, P461, DOI 10.1016/S0262-8856(00)00092-5
   Piegl L, 1995, NURBS BOOK
   Priest E.R., 1984, SOLAR MAGNETO HYDROD
   Qin H, 1996, IEEE T VIS COMPUT GR, V2, P85, DOI 10.1109/2945.489389
   XU D, 1999, P IEEE SIGN PROC SOC, P429
   Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665
NR 29
TC 21
Z9 25
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2003
VL 21
IS 6
BP 551
EP 562
DI 10.1016/S0262-8856(03)00066-0
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 688BA
UT WOS:000183411300008
DA 2024-07-18
ER

PT J
AU Beghdadi, A
   Mesbah, M
   Monteil, J
AF Beghdadi, A
   Mesbah, M
   Monteil, J
TI A fast incremental approach for accurate measurement of the displacement
   field
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE optical flow; motion estimation; template matching; cross-correlation;
   multiresolution analysis
ID OPTICAL-FLOW ESTIMATION; IMAGE FLOW; VISUAL-MOTION; ALGORITHM; VELOCITY;
   DEFORMATIONS; SEGMENTATION; CONSTRAINTS; COMPUTATION; MODELS
AB A fast method for accurate measurement of displacement field that combines template matching and differential techniques is proposed. This method, which is able to deal with the problems of non-rigid object movement as well as large inter frame displacements, operates in three steps. First, a sparse displacement field is obtained by a classic template matching technique. Then. this information is propagated through the overall image to obtain a dense displacement field. Finally, this field is considered as approximate solution before the use of classical differential technique for optical flow estimation. To illustrate the efficiency of the proposed procedure, a number of experimental results using both synthetic and real images are presented and discussed. The results show significant improvement over those obtained using standard multigrid approaches. especially in the cases of textured. very structured images or large inter frame displacements. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Paris 13, Inst Galilee, Lab Traitement & Transport Informat, F-93400 Villetaneuse, France.
   Queensland Univ Technol, Signal Proc Res Ctr, Brisbane, Qld 4001, Australia.
C3 Universite Paris 13; Queensland University of Technology (QUT)
RP Beghdadi, A (corresponding author), Univ Paris 13, Inst Galilee, Lab Traitement & Transport Informat, 99 Ave,L2TI, F-93400 Villetaneuse, France.
RI Beghdadi, Azeddine/ABF-9801-2022
OI Beghdadi, Azeddine/0000-0002-5595-0615
CR ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   ANANDAN JP, 1993, MOTION ANAL IMAGE SE, P1
   ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   [Anonymous], 1885, CRELLE J
   [Anonymous], 1981, P 7 INT JOINT C ART
   [Anonymous], 1988, International journal of computer vision
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   BenAmar N, 1996, SCANNING, V18, P327, DOI 10.1002/sca.1996.4950180501
   Black MJ, 1996, IEEE T PATTERN ANAL, V18, P972, DOI 10.1109/34.541407
   CORNELIUS N, 1983, SIGGRAPH SIGART INTE, P50
   DELBIMBO A, 1995, IEEE T IMAGE PROCESS, V4, P460, DOI 10.1109/83.370674
   DIAB Z, 1995, CHAMP MOUVEMENT FLUX
   ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X
   ENKELMANN W, 1986, WORKSH MOT REPR AN K, P81
   FENNEMA CL, 1979, COMPUT VISION GRAPH, V9, P301, DOI 10.1016/0146-664X(79)90097-2
   FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772
   Ghosal S, 1996, IEEE T PATTERN ANAL, V18, P181, DOI 10.1109/34.481542
   GLAZER F, 1984, MULTIRESOLUTION IMAG, P312
   Golub G.H., 1989, MATRIX COMPUTATIONS
   GORCE J.M., 1994, Innov. Techn. Biol. Med, V15
   HALL EL, 1979, COMPUTER IMAGE PROCE
   HEEGER DJ, 1987, J OPT SOC AM A, V4, P1455, DOI 10.1364/JOSAA.4.001455
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   LIN T, 1994, IMAGE RECONSTRUCTION
   MAILLOUX GE, 1989, IEEE T MED IMAGING, V8, P143, DOI 10.1109/42.24862
   MAK MW, 1993, SIGNAL PROCESS-IMAGE, V6, P335
   Memin E, 1998, IEEE T IMAGE PROCESS, V7, P703, DOI 10.1109/83.668027
   MEMIN E, 1996, INTERNAL PUBLICATION, V1057, P1
   MGUIL-TOUCHAL S., 1996, Colloque National Mecamat (Aussois), P179
   Mitiche A, 1996, INT J COMPUT VISION, V19, P29, DOI 10.1007/BF00131147
   MITICHE A, 1987, PATTERN RECOGN, V20, P173, DOI 10.1016/0031-3203(87)90051-3
   MONGRAIN R, 1993, THESIS U MONTREAL, P117
   Monteil J, 2000, REV METALL-PARIS, V97, P229, DOI 10.1051/metal/200097020229
   NAGEL HH, 1987, ARTIF INTELL, V33, P299, DOI 10.1016/0004-3702(87)90041-5
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8
   NESI P, 1995, COMPUT VIS IMAGE UND, V62, P59, DOI 10.1006/cviu.1995.1041
   Odobez J.-M., 1995, Traitement du Signal, V12, P113
   OTTE M, 1994, P 3 EUR C COMP VIS E, P1
   PAQUIN R, 1983, COMPUT VISION GRAPH, V21, P205, DOI 10.1016/S0734-189X(83)80037-1
   PERRONE JA, 1990, J OPT SOC AM A, V7, P264, DOI 10.1364/JOSAA.7.000264
   QING XW, 1995, IEEE T PATTERN ANAL, V17
   RUAN S, 1993, INNOV TECHN BIOL MED, V14
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   SCHUNCK BG, 1989, IEEE T PATTERN ANAL, V11, P1010, DOI 10.1109/34.42834
   Singh A., 1990, Proceedings. Third International Conference on Computer Vision (Cat. No.90CH2934-8), P168, DOI 10.1109/ICCV.1990.139516
   TRETIAK O, 1984, P 7 INT C PATT REC M, P16
   VERRI A, 1990, J OPT SOC AM A, V7, P912, DOI 10.1364/JOSAA.7.000912
   WATSON AB, 1985, J OPT SOC AM A, V2, P322, DOI 10.1364/JOSAA.2.000322
   WAXMAN AM, 1985, INT J ROBOT RES, V4, P95, DOI 10.1177/027836498500400307
   WOHN KY, 1983, PATTERN RECOGN, V16, P563, DOI 10.1016/0031-3203(83)90072-9
   ZITOVA B, 2000, P CZECH PATT REC WOR
NR 51
TC 7
Z9 8
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2003
VL 21
IS 4
BP 383
EP 399
DI 10.1016/S0262-8856(03)00014-3
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 669PH
UT WOS:000182359300005
DA 2024-07-18
ER

PT J
AU Yushkevich, P
   Fletcher, PT
   Joshi, S
   Thall, A
   Pizer, SM
AF Yushkevich, P
   Fletcher, PT
   Joshi, S
   Thall, A
   Pizer, SM
TI Continuous medial representations for geometric object modeling in 2D
   and 3D
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE medial representation; skeleton; shape modeling
ID SPLINE SURFACES; SHAPE
AB We describe a novel continuous medial representation for object geometry and a deformable templates method for fitting the representation to images. Our representation simultaneously describes the boundary and medial loci of geometrical objects, always maintaining Blum's symmetric axis transform (SAT) relationship. Cubic b-splines define the continuous medial locus and the associated thickness field, which in turn generate the object boundary. We present geometrical properties of the representation and derive a set of constraints on the b-spline parameters. The 2D representation encompasses branching medial loci; the 3D version can model objects with a single medial surface, and the extension to branching medial surfaces is a subject of ongoing research. We present preliminary results of segmenting 2D and 3D medical images. The representation is ultimately intended for use in statistical shape analysis. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Univ N Carolina, Med Image Display & Anal Grp, Chapel Hill, NC 27514 USA.
C3 University of North Carolina; University of North Carolina Chapel Hill
RP Univ N Carolina, Med Image Display & Anal Grp, Chapel Hill, NC 27514 USA.
EM pauly@cs.unc.edu
RI Yushkevich, Paul/O-6115-2014
OI Yushkevich, Paul/0000-0001-8543-4016
CR [Anonymous], GENETIC ALGORITHMS P
   [Anonymous], THESIS U N CAROLINA
   August J, 1999, COMPUT VIS IMAGE UND, V76, P231, DOI 10.1006/cviu.1999.0802
   Aylward SR, 2002, IEEE T MED IMAGING, V21, P61, DOI 10.1109/42.993126
   Blanding Robert., 1999, Proceedings of the Fifth ACM Symposium on Solid Modeling and Ap- plications, SMA '99, P141
   BLOOMENTHAL J, 1991, COMP GRAPH, V25, P251, DOI 10.1145/127719.122757
   BLUM H, 1978, PATTERN RECOGN, V10, P167, DOI 10.1016/0031-3203(78)90025-0
   Carr JC, 2001, COMP GRAPH, P67, DOI 10.1145/383259.383266
   CATMULL E, 1978, COMPUT AIDED DESIGN, V10, P350, DOI 10.1016/0010-4485(78)90110-0
   CHEN D, 1999, TR99014 U N CAR
   DAMON J, 2002, SMOOTHNESS GEOMETRY
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   DELINGETTE H, 1994, CVPR94, P856
   FARIN G, 1995, CURVES SURFACES CAGD
   GASCUEL MP, 1993, COMPUT GRAPH, V27, P313
   GELSTON SM, 1995, COMPUT AIDED GEOM D, V12, P27, DOI 10.1016/0167-8396(94)E0055-V
   Giblin P, 2000, PROC CVPR IEEE, P566, DOI 10.1109/CVPR.2000.855870
   HOFFMANN CM, 1996, P 6 IMA C MATH SURF, V6, P249
   Igarashi T, 1999, COMP GRAPH, P409, DOI 10.1145/311535.311602
   JOSHI PSS, 2001, MED IMAGE COMPUTING, V2208, P862
   JOSHI S, 2002, UNPUB IEEE TMI
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   Markosian L, 1999, COMP GRAPH, P393, DOI 10.1145/311535.311595
   NACKMAN LR, 1982, THESIS U N CAROLINA
   Naf M, 1996, PROCEEDINGS OF THE IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, P139, DOI 10.1109/MMBIA.1996.534066
   OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U
   Peters J, 1996, COMPUT AIDED GEOM D, V13, P101, DOI 10.1016/0167-8396(95)00017-8
   Piegl Les, 1996, NURBS BOOK, Vsecond, DOI DOI 10.1007/978-3-642-97385-7
   Pizer SM, 1999, IEEE T MED IMAGING, V18, P851, DOI 10.1109/42.811263
   Sherstyuk A, 1999, SHAPE MODELING INTERNATIONAL '99 - INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P56, DOI 10.1109/SMA.1999.749324
   Siddiqi K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P828, DOI 10.1109/ICCV.1999.790307
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   STORTI DW, 1997, SMA 97 P 4 S SOL MOD, P141
   STYNER M, 2001, INT C INF PROC MED I, P503
   Szekely G, 1996, Med Image Anal, V1, P19, DOI 10.1016/S1361-8415(01)80003-7
   TEIXEIRA RC, 1998, THESIS HARVARD U CAM
   THALL A, 2000, TR00005 U N CAR
   TSAO YF, 1984, COMPUT VISION GRAPH, V25, P348, DOI 10.1016/0734-189X(84)90200-7
   U.S. National Library of Medicine, VIS HUM PROJ
   VERMEER PJ, 1994, THESIS PURDUE U
   Yushkevich P., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P402
   Zhu SC, 1996, INT J COMPUT VISION, V20, P187
NR 42
TC 48
Z9 58
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 17
EP 27
AR PII S0262-8856(02)00135-X
DI 10.1016/S0262-8856(02)00135-X
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Agbodike, O
   Zhang, WJ
   Chen, JH
   Wang, L
AF Agbodike, Obinna
   Zhang, Weijin
   Chen, Jenhui
   Wang, Lei
TI Face and body-shape integration model for cloth-changing person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cloth-changing; CNN; Detection; Feature-mask; Person re-identification
ID VIDEO SURVEILLANCE; NETWORK
AB Among the existing deep learning-based person re-identification (ReID) methods, human parsing based on semantic segmentation is the most promising solution for ReID because such models can learn to identify finegrained details of different body parts or apparel of a target semantically. However, intra-class variations such as illumination changes, multi-pose angles, and cloth-changing (CC) across different non-overlapping camera viewpoints present a crucial challenge for this approach. Among these challenges, a person CC is the most distinctive problem for ReID models, which often fail to associate the target in new cloth against the learned feature semantics of the previous cloth worn in a different timeline. In this paper, we propose a face and body shape integration (FBI) network as a tactical solution to address the long-term person CC-ReID problem. The FBI comprises hierarchically stacked parsing and edge prediction (PEP) CNN blocks that generate fine-grained human-parsing output at the initial stage. We then aligned the PEP to our proposed model agnostic plug-in feature overlay module (FOM) to mask cloth-relevant body attributes except the facial features pooled from the input sample. Thus, our human parsing PEP and FOM modules are attuned to discriminatively learn cloth irrelevant features of the target pedestrian(s) to optimize the effectiveness of person ReID in solitary or minimally crowded areas. In our extensive person CC-ReID experiments, our FBI model achieves 83.4/61.8 in R1 and 91.7/65.8 in mAP evaluation results on the PRCC and LTCC datasets, respectively; thereby significantly out competing several previous state-of-the-art ReID methods, and validating the effectiveness of the FBI.
C1 [Agbodike, Obinna; Zhang, Weijin; Chen, Jenhui] Chang Gung Univ, Dept Comp Sci & Informat Engn, Taoyuan 33302, Taiwan.
   [Chen, Jenhui] Chang Gung Mem Hosp, Dept Surg, Div Breast Surg & Gen Surg, Taoyuan 33375, Taiwan.
   [Chen, Jenhui] Ming Chi Univ Technol, Dept Elect Engn, New Taipei City 24301, Taiwan.
   [Wang, Lei] Dalian Univ Technol, Sch Software, Dalian 116620, Peoples R China.
C3 Chang Gung University; Chang Gung Memorial Hospital; Ming Chi University
   of Technology; Dalian University of Technology
RP Chen, JH (corresponding author), Chang Gung Univ, Dept Comp Sci & Informat Engn, Taoyuan 33302, Taiwan.; Chen, JH (corresponding author), Chang Gung Mem Hosp, Dept Surg, Div Breast Surg & Gen Surg, Taoyuan 33375, Taiwan.; Chen, JH (corresponding author), Ming Chi Univ Technol, Dept Elect Engn, New Taipei City 24301, Taiwan.
EM jhchen@mail.cgu.edu.tw; lei.wang@dlut.edu.cn
RI Agbodike, Obinna/KIG-7784-2024; zhang, weijin/HLQ-3532-2023
OI Agbodike, Obinna/0000-0003-1297-952X; 
FU National Science and Technology Council, Taiwan
   [110-2221-E-182-041-MY3]; Chang Gung Memorial Hospital, Taoyuan, Taiwan
   [CMRPD2N0051]
FX This work was supported by the National Science and Technology Council,
   Taiwan, under Grant 110-2221-E-182-041-MY3 and in part by the Chang Gung
   Memorial Hospital, Taoyuan, Taiwan, under Grant CMRPD2N0051.
CR Adil M, 2020, IEEE ACCESS, V8, P177351, DOI 10.1109/ACCESS.2020.3023594
   Agbodike O, 2023, IEEE ACCESS, V11, P99470, DOI 10.1109/ACCESS.2023.3313946
   Arkushin D., 2022, arXiv, P1
   Bansal V, 2022, IEEE WINT CONF APPL, P602, DOI 10.1109/WACVW54805.2022.00066
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chang FJ, 2017, IEEE INT CONF COMP V, P1599, DOI 10.1109/ICCVW.2017.188
   Chen GY, 2019, IEEE T IMAGE PROCESS, V28, P4192, DOI 10.1109/TIP.2019.2908062
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen SN, 2020, IEEE SIGNAL PROC LET, V27, P1460, DOI 10.1109/LSP.2020.3016528
   Chen X, 2018, IEEE ACCESS, V6, P14567, DOI 10.1109/ACCESS.2018.2803787
   Chen YC, 2018, IEEE T PATTERN ANAL, V40, P392, DOI 10.1109/TPAMI.2017.2666805
   Cho YJ, 2018, IEEE T IMAGE PROCESS, V27, P3739, DOI 10.1109/TIP.2018.2815840
   Chrysos GG, 2022, IEEE T PATTERN ANAL, V44, P4021, DOI 10.1109/TPAMI.2021.3058891
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Gu XQ, 2022, PROC CVPR IEEE, P1050, DOI 10.1109/CVPR52688.2022.00113
   Han K., 2023, P IEEECVF C COMPUTER, P22066
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He TY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1470, DOI 10.1109/ICCV48922.2021.00152
   Hong PX, 2021, PROC CVPR IEEE, P10508, DOI 10.1109/CVPR46437.2021.01037
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Huang Y, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P11875, DOI 10.1109/ICCV48922.2021.01168
   Huang Y, 2020, IEEE T CIRC SYST VID, V30, P3459, DOI 10.1109/TCSVT.2019.2948093
   Huang YK, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P365, DOI 10.1145/3343031.3350994
   Jiang KZ, 2020, IEEE T IMAGE PROCESS, V29, P8549, DOI 10.1109/TIP.2020.3016869
   Jin K, 2019, IEEE INT CONF MULTI, P162, DOI 10.1109/ICMEW.2019.00-93
   Jin X, 2022, PROC CVPR IEEE, P14258, DOI 10.1109/CVPR52688.2022.01388
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Kweon HJ, 2023, IEEE SIGNAL PROC LET, V30, P334, DOI 10.1109/LSP.2023.3262447
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li DW, 2019, IEEE T IMAGE PROCESS, V28, P1575, DOI 10.1109/TIP.2018.2878349
   Li PK, 2022, IEEE T PATTERN ANAL, V44, P3260, DOI 10.1109/TPAMI.2020.3048039
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li X, 2015, IEEE I CONF COMP VIS, P3765, DOI 10.1109/ICCV.2015.429
   Luna CA, 2021, EXPERT SYST APPL, V182, DOI 10.1016/j.eswa.2021.115287
   Miao JX, 2022, IEEE T NEUR NET LEAR, V33, P4624, DOI 10.1109/TNNLS.2021.3059515
   Nodehi H, 2022, IEEE T CIRC SYST VID, V32, P147, DOI 10.1109/TCSVT.2021.3059250
   Porrello A., 2023, P EUR C COMP VIS, P93
   Qin WC, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104551
   Ren X., 2023, P INT JOINT C NEUR N, P1
   Ruan T, 2019, AAAI CONF ARTIF INTE, P4814
   Sala R, 2006, 2006 IEEE INTERNATIONAL WORKSHOP ON MEASUREMENT SYSTEMS FOR HOMELAND SECURITY, CONTRABAND DETECTION & PERSONAL SAFETY, P10, DOI 10.1109/MSHS.2006.314341
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shu XJ, 2022, IEEE T CIRC SYST VID, V32, P4390, DOI 10.1109/TCSVT.2021.3128214
   Shu XJ, 2021, IEEE SIGNAL PROC LET, V28, P1365, DOI 10.1109/LSP.2021.3091924
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Terhörst P, 2023, IEEE WINT CONF APPL, P3473, DOI 10.1109/WACV56688.2023.00348
   Wan FB, 2020, IEEE COMPUT SOC CONF, P3620, DOI 10.1109/CVPRW50498.2020.00423
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang K, 2020, INT J INTELL SYST, V35, P1881, DOI 10.1002/int.22276
   Wang Q., 2023, P AS C COMP VIS ACCV, P2270
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3508, DOI 10.1109/TPAMI.2021.3055780
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang XP, 2021, IEEE T IMAGE PROCESS, V30, P3017, DOI 10.1109/TIP.2021.3056223
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Wu JB, 2022, IEEE IMAGE PROC, P1016, DOI 10.1109/ICIP46576.2022.9897243
   Wu Y., 2019, DETECTRON2
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Wu ZY, 2015, IEEE T PATTERN ANAL, V37, P1095, DOI 10.1109/TPAMI.2014.2360373
   Xia FT, 2016, AAAI CONF ARTIF INTE, P3632
   Xuelin Qian, 2021, Computer Vision - ACCV 2020. 15th Asian Conference on Computer Vision. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12624), P71, DOI 10.1007/978-3-030-69535-4_5
   Yadav DK, 2017, COMM COM INF SC, V721, P471, DOI 10.1007/978-981-10-5427-3_49
   Yaghoubi E, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104288
   Yang FX, 2020, IEEE T MULTIMEDIA, V22, P2444, DOI 10.1109/TMM.2019.2957928
   Yang HR, 2023, IEEE T CIRC SYST VID, V33, P1236, DOI 10.1109/TCSVT.2022.3209209
   Yang QZ, 2021, IEEE T PATTERN ANAL, V43, P2029, DOI 10.1109/TPAMI.2019.2960509
   Yao HT, 2021, IEEE T IMAGE PROCESS, V30, P685, DOI 10.1109/TIP.2020.3038347
   Ye JW, 2020, IEEE T IMAGE PROCESS, V29, P1177, DOI 10.1109/TIP.2019.2930146
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye S, 2020, PATTERN RECOGN IMAGE, V30, P827, DOI 10.1134/S1054661820040136
   Zhang SF, 2020, IEEE SIGNAL PROC LET, V27, P850, DOI 10.1109/LSP.2020.2994815
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhou F, 2021, IEEE ACCESS, V9, P129490, DOI 10.1109/ACCESS.2021.3090057
   Zhu K, 2020, Arxiv, DOI arXiv:2007.13467
NR 75
TC 0
Z9 0
U1 9
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104843
DI 10.1016/j.imavis.2023.104843
EA OCT 2023
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA X9DJ0
UT WOS:001101371900001
DA 2024-07-18
ER

PT J
AU Murtaza, S
   Belharbi, S
   Pedersoli, M
   Sarraf, A
   Granger, E
AF Murtaza, Shakeeb
   Belharbi, Soufiane
   Pedersoli, Marco
   Sarraf, Aydin
   Granger, Eric
TI DiPS: Discriminative pseudo-label sampling with self-supervised
   transformers for weakly supervised object localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Weakly supervised object localization; Self-supervised learning; Vision
   transformers; Deep learning
AB Self-supervised vision transformers (SSTs) have shown great potential to yield rich localization maps that highlight different objects in an image. However, these maps remain class-agnostic since the model is unsupervised. They often tend to decompose the image into multiple maps containing different objects while being unable to distinguish the object of interest from background noise objects. In this paper, Discriminative Pseudo label Sampling (DiPS) is introduced to leverage these class-agnostic maps for weakly-supervised object localization (WSOL), where only image-class labels are available. Given multiple attention maps, DiPS relies on a pre trained classifier to identify the most discriminative regions of each attention map. This ensures that the selected ROIs cover the correct image object while discarding the background ones, and, as such, provides a rich pool of diverse and discriminative proposals to cover different parts of the object. Subsequently, these proposals are used as pseudo-labels to train our new transformer-based WSOL model designed to perform classification and localization tasks. Unlike standard WSOL methods, DiPS optimizes performance in both tasks by using a transformer encoder and a dedicated output head for each task, each trained using dedicated loss functions. To avoid overfitting a single proposal and promote better object coverage, a single proposal is randomly selected among the top ones for a training image at each training step. Experimental results1 on the challenging CUB, ILSVRC, OpenImages, and TelDrone datasets indicate that our architecture, in combination with our transformer-based proposals, can yield better localization performance than state-of-the-art methods.
C1 [Murtaza, Shakeeb; Belharbi, Soufiane; Pedersoli, Marco; Granger, Eric] ETS Montreal, Dept Syst Engn, Lab Imagerie Vis & Intelligence Artificielle, Montreal, PQ, Canada.
   [Sarraf, Aydin] Global AI Accelerator, Ericsson, Montreal, PQ, Canada.
C3 University of Quebec; Ecole de Technologie Superieure - Canada;
   AstraZeneca
RP Murtaza, S (corresponding author), ETS Montreal, Dept Syst Engn, Lab Imagerie Vis & Intelligence Artificielle, Montreal, PQ, Canada.
EM shakeeb.murtaza.1@ens.etsmtl.ca; soufiane.belharbi.1@ens.etsmtl.ca;
   marco.pedersoli@etsmtl.ca; aydin.sarraf@ericsson.com;
   eric.granger@etsmtl.ca
RI Murtaza, Shakeeb/R-7566-2017
OI Murtaza, Shakeeb/0000-0002-8066-6907
FU Mathematics of Information Technology and Complex Systems; Natural
   Sciences and Engineering Research Council of Canada
FX This research was supported by the Mathematics of Information Technology
   and Complex Systems and the Natural Sciences and Engineering Research
   Council of Canada. We also acknowledge Digital Research Alliance of
   Canada for their provision of computing resources.
CR Abnar S, 2020, 58TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2020), P4190
   Bai Haotian, 2022, ECCV
   Bau D, 2017, PROC CVPR IEEE, P3319, DOI 10.1109/CVPR.2017.354
   Belharbi S., 2022, MIDL
   Belharbi S, 2024, Arxiv, DOI arXiv:2303.09044
   Belharbi Soufiane, 2023, WACV
   Belharbi Soufiane, 2022, WACV
   Benenson R, 2019, PROC CVPR IEEE, P11692, DOI 10.1109/CVPR.2019.01197
   Caron M., 2021, ICCV
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen XL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9620, DOI 10.1109/ICCV48922.2021.00950
   Chen Z., 2022, AAAI
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Choe J, 2020, PROC CVPR IEEE, P3130, DOI 10.1109/CVPR42600.2020.00320
   Choe J, 2019, PROC CVPR IEEE, P2214, DOI 10.1109/CVPR.2019.00232
   Desai S, 2020, IEEE WINT CONF APPL, P972, DOI [10.1109/wacv45572.2020.9093360, 10.1109/WACV45572.2020.9093360]
   Dosovitskiy Alexey, 2021, ICLR
   Fong R, 2019, IEEE I CONF COMP VIS, P2950, DOI 10.1109/ICCV.2019.00304
   Fu R., 2020, ARXIV
   Gao W, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2866, DOI 10.1109/ICCV48922.2021.00288
   Gupta S, 2022, IEEE COMPUT SOC CONF, P4100, DOI 10.1109/CVPRW56347.2022.00455
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ki Minsong, 2020, P AS C COMP VIS
   Kim Eunji, 2022, CVPR
   Kim J., 2021, PROC IEEECVF INT C C, P3427
   Kolesnikov A, 2016, LECT NOTES COMPUT SC, V9908, P695, DOI 10.1007/978-3-319-46493-0_42
   KRAHENBUHL P, 2011, ADV NEURAL INFORM PR, P109, DOI DOI 10.5555/2986459.2986472
   Lee J, 2019, PROC CVPR IEEE, P5262, DOI 10.1109/CVPR.2019.00541
   Li Chunyuan, 2022, ICLR
   Li Ming, 2022, arXiv
   Lin YQ, 2023, PROC CVPR IEEE, P15305, DOI 10.1109/CVPR52729.2023.01469
   Meng M, 2022, IEEE T IMAGE PROCESS, V31, P7130, DOI 10.1109/TIP.2022.3220055
   Meng M, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3365, DOI 10.1109/ICCV48922.2021.00337
   Meng M, 2022, IEEE T IMAGE PROCESS, V31, P1774, DOI 10.1109/TIP.2022.3145238
   Murtaza S, 2023, IEEE WINT CONF APPL, P155, DOI 10.1109/WACVW58289.2023.00021
   Naidu R, 2020, Arxiv, DOI [arXiv:2010.03023, DOI 10.48550/ARXIV.2010.03023]
   Oquab M, 2015, PROC CVPR IEEE, P685, DOI 10.1109/CVPR.2015.7298668
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pan XJ, 2021, PROC CVPR IEEE, P11637, DOI 10.1109/CVPR46437.2021.01147
   Rahimi A., 2020, ECCV
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Rony J., 2023, Machine Learning for Biomedical Imaging, V2, P96
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Singh KK, 2017, IEEE I CONF COMP VIS, P3544, DOI 10.1109/ICCV.2017.381
   Su H., 2022, BMVC
   Tang M, 2018, LECT NOTES COMPUT SC, V11220, P524, DOI 10.1007/978-3-030-01270-0_31
   Wang H., 2020, CVPR WORKSHOPS
   Wang HF, 2020, Arxiv, DOI [arXiv:2006.14255, 10.48550/arXiv.2006.14255, DOI 10.48550/ARXIV.2006.14255]
   Wang X, 2018, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2018.00147
   Wang Yuqing, 2020, CVPR
   Wei J, 2021, PROC CVPR IEEE, P5989, DOI 10.1109/CVPR46437.2021.00593
   Wei Jun, 2021, CVPR
   Wei YC, 2017, PROC CVPR IEEE, P6488, DOI 10.1109/CVPR.2017.687
   Wei YC, 2018, PROC CVPR IEEE, P7268, DOI 10.1109/CVPR.2018.00759
   Welinder P., 2010, Technical Report CNS-TR-2010-001
   Wonho Bae, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P618, DOI 10.1007/978-3-030-58555-6_37
   Wu PY, 2022, PROC CVPR IEEE, P14228, DOI 10.1109/CVPR52688.2022.01385
   Xie JH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P132, DOI 10.1109/ICCV48922.2021.00020
   Xie Jinheng, 2022, CVPR
   Xie ZD, 2022, PROC CVPR IEEE, P9643, DOI 10.1109/CVPR52688.2022.00943
   Xu J., 2022, CVPR
   Xue HL, 2019, IEEE I CONF COMP VIS, P6588, DOI 10.1109/ICCV.2019.00669
   Yang S, 2020, IEEE WINT CONF APPL, P2930, DOI 10.1109/WACV45572.2020.9093566
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang X, 2018, LECT NOTES COMPUT SC, V11219, P614, DOI 10.1007/978-3-030-01267-0_36
   Zhang X, 2021, AUTOPHAGY, V17, P1519, DOI 10.1080/15548627.2020.1840796
   Zhang XL, 2018, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2018.00144
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu L., 2023, PAMI
   Zhu L, 2022, LECT NOTES COMPUT SC, V13670, P176, DOI 10.1007/978-3-031-20080-9_11
NR 73
TC 1
Z9 1
U1 6
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104838
DI 10.1016/j.imavis.2023.104838
EA OCT 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CB1U8
UT WOS:001122707700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Du, ZX
   Wang, X
   Wang, Q
AF Du, Zexing
   Wang, Xue
   Wang, Qing
TI Perceiving local relative motion and global correlations for weakly
   supervised group activity recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Group activity recognition; Local relative motion information; Weakly
   supervision; Global correlations
AB This paper presents a weakly supervised approach for group activity recognition by exploiting the local relative motion and global correlations among entities. Most existing approaches of group recognition characterize motions of group activities based on the coordinates of individuals or feature maps without excluding the camera motion, which is a combination of local relative motion and camera motion. To address this problem, we utilize a simple but effective Local Relative Motion Module (LRMM): a 3D-CNN-based network to exploit the local movement. We further employ a Global Correlation Module (GCM) to establish relationships among different feature patches for capturing the entire scene. We have evaluated the proposed method on sports and group activity video. The method has achieved state-of-the-art performance on three challenging datasets for weakly supervised group activity recognition. The method has also outperformed some approaches trained with much stronger supervision in the comparative evaluation.
C1 [Du, Zexing; Wang, Xue; Wang, Qing] Northwestern Polytech Univ, Sch Comp Sci, Youyixi Rd 127, Xian 710072, Shaanxi, Peoples R China.
C3 Northwestern Polytechnical University
RP Wang, Q (corresponding author), Northwestern Polytech Univ, Sch Comp Sci, Youyixi Rd 127, Xian 710072, Shaanxi, Peoples R China.
EM duzexing@mail.nwpu.edu.cn; qwang@nwpu.edu.cn
OI Wang, Xue/0009-0003-5224-906X
FU NSFC [61801396];  [62031023]
FX This work was supported by NSFC under Grant 62031023 and Grant 61801396.
CR Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14
   Amer MR, 2014, LECT NOTES COMPUT SC, V8694, P572, DOI 10.1007/978-3-319-10599-4_37
   Arnab A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P6816, DOI 10.1109/ICCV48922.2021.00676
   Azar SM, 2019, PROC CVPR IEEE, P7884, DOI 10.1109/CVPR.2019.00808
   Bagautdinov T, 2017, PROC CVPR IEEE, P3425, DOI 10.1109/CVPR.2017.365
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen J, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104214
   Choi W, 2014, IEEE T PATTERN ANAL, V36, P1242, DOI 10.1109/TPAMI.2013.220
   Dosovitskiy Alexey, 2021, ICLR
   Ehsanpour Mahsa, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P177, DOI 10.1007/978-3-030-58545-7_11
   El Ogri O, 2021, SIGNAL PROCESS-IMAGE, V98, DOI 10.1016/j.image.2021.116410
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Freire-Obregón D, 2022, MACH VISION APPL, V33, DOI 10.1007/s00138-021-01264-9
   Gavrilyuk K, 2020, PROC CVPR IEEE, P836, DOI 10.1109/CVPR42600.2020.00092
   Han MF, 2022, PROC CVPR IEEE, P2980, DOI 10.1109/CVPR52688.2022.00300
   He KM, 2020, IEEE T PATTERN ANAL, V42, P386, DOI [10.1109/TPAMI.2018.2844175, 10.1109/ICCV.2017.322]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu GY, 2020, PROC CVPR IEEE, P977, DOI 10.1109/CVPR42600.2020.00106
   Ibrahim MS, 2016, PROC CVPR IEEE, P1971, DOI 10.1109/CVPR.2016.217
   Kim D, 2022, PROC CVPR IEEE, P20051, DOI 10.1109/CVPR52688.2022.01945
   Lan T, 2012, PROC CVPR IEEE, P1354, DOI 10.1109/CVPR.2012.6247821
   Li SC, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P13648, DOI 10.1109/ICCV48922.2021.01341
   Li W., 2022, PROC 31 INT JOINT C, P1102, DOI 10.24963/ijcai.2022/154
   Lin J, 2019, IEEE I CONF COMP VIS, P7082, DOI 10.1109/ICCV.2019.00718
   Lin WY, 2013, IEEE T CIRC SYST VID, V23, P1980, DOI 10.1109/TCSVT.2013.2269780
   Lin WY, 2010, IEEE T CIRC SYST VID, V20, P1057, DOI 10.1109/TCSVT.2010.2057013
   Liu Z, 2022, PROC CVPR IEEE, P3192, DOI 10.1109/CVPR52688.2022.00320
   Pramono Rizard Renanda Adhi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P71, DOI 10.1007/978-3-030-58452-8_5
   Qi MS, 2018, LECT NOTES COMPUT SC, V11214, P104, DOI 10.1007/978-3-030-01249-6_7
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodriguez M, 2016, IMAGE VISION COMPUT, V48-49, P26, DOI 10.1016/j.imavis.2015.12.006
   Rui Yan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P208, DOI 10.1007/978-3-030-58598-3_13
   Shu TM, 2017, PROC CVPR IEEE, P4255, DOI 10.1109/CVPR.2017.453
   Shu TM, 2015, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR.2015.7299088
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tamura M, 2022, LECT NOTES COMPUT SC, V13664, P19, DOI 10.1007/978-3-031-19772-7_2
   Tang YS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1283, DOI 10.1145/3240508.3240576
   Tarashima S., 2021, BRIT MACHINE VISION
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang MS, 2017, PROC CVPR IEEE, P7408, DOI 10.1109/CVPR.2017.783
   Wongun Choi, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1282, DOI 10.1109/ICCVW.2009.5457461
   Wu JC, 2019, PROC CVPR IEEE, P9956, DOI 10.1109/CVPR.2019.01020
   Yan R, 2022, IEEE T NEUR NET LEAR, V33, P7574, DOI 10.1109/TNNLS.2021.3085567
   Yan R, 2023, IEEE T PATTERN ANAL, V45, P6955, DOI 10.1109/TPAMI.2020.3034233
   Yan R, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P1292, DOI 10.1145/3240508.3240572
   Yuan HJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7456, DOI 10.1109/ICCV48922.2021.00738
   Yuan HJ, 2021, AAAI CONF ARTIF INTE, V35, P3261
   Zalluhoglu C, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2020.103870
   Zhang PZ, 2020, IEEE T IMAGE PROCESS, V29, P29, DOI 10.1109/TIP.2019.2918725
NR 52
TC 4
Z9 4
U1 7
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104789
DI 10.1016/j.imavis.2023.104789
EA AUG 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Q1BM3
UT WOS:001054938100001
DA 2024-07-18
ER

PT J
AU Bai, SJ
   Bai, J
   Xu, H
   Tuo, J
   Liu, M
AF Bai, Shaojin
   Bai, Jing
   Xu, Hao
   Tuo, Jiwen
   Liu, Min
TI PAGML: Precise Alignment Guided Metric Learning for sketch-based 3D
   shape retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Sketch -based 3D shape retrieval; Cross-modality retrieval;
   Master-auxiliary network; Triplet rigid center loss; Precise alignment
AB Sketch-based 3D shape retrieval has always been a hot research topic in the computer vision community. The main challenge is to alleviate the cross-modality discrepancies such that the retrieval accuracies can be improved. In this paper, we propose a novel Precise Alignment Guided Metric Learning (PAGML) method based on master-auxiliary cross-modality retrieval framework. An auxiliary learning network is developed to indirectly guide the master learning model to extract features of rich semantic information, so as to achieve a semantic alignment between the cross-modality data. Furthermore, affected by the intra-class variability and inter-class imbalance issue, the learned class distributions may exhibit unevenness in the common embedding space and cause poor retrieval performance. A loss function dedicated for cross-modality retrieval is designed to achieve a rigid alignment between sketches and 3D shapes of the same category by pulling their rich semantic represen-tations to the rigid center of the category. As a result, a more precise alignment between the cross-modality embedding features of the same category is approached gradually, which further alleviates the cross-modality discrepancies, inter-class variability, and inter-class imbalance, thus improving the cross-modality retrieval ac-curacies. Extensive experiments on two public benchmark datasets demonstrate that the proposed PAGML sur -passes the state-of-the-art methods in retrieval accuracy and has excellent generalization abilities to unseen classes.
C1 [Bai, Shaojin; Bai, Jing; Xu, Hao; Tuo, Jiwen] North Minzu Univ, Sch Comp Sci & Engn, Yinchuan 750021, Peoples R China.
   [Bai, Jing] State Ethn Affairs Commiss, Key Lab Images & Graph Intelligent Proc, IGIPLab, Yinchuan 750021, Peoples R China.
   [Liu, Min] Purdue Univ, Sch Mech Engn, W Lafayette, IN 47907 USA.
C3 North Minzu University; Purdue University System; Purdue University
RP Bai, J (corresponding author), North Minzu Univ, Sch Comp Sci & Engn, Yinchuan 750021, Peoples R China.
EM 19995281956@163.com; baijing@nun.edu.cn; xu_05160018@163.com;
   zb_tjw@163.com; liu66@purdue.edu
RI Bai, Jing/HGD-3571-2022
FU National Natural Science Foundation of China [62162001, 61762003];
   Natural Science Foundation of Ningxia Province of China [2022AAC02041];
   Ningxia Excellent Talent Program
FX This work was supported by the National Natural Science Foundation of
   China (62162001, 61762003) , the Natural Science Foundation of Ningxia
   Province of China (2022AAC02041) , and the Ningxia Excellent Talent
   Program. Furthermore, the authors would like to thank the editor and the
   anonymous reviewers for their constructive comments on this paper.
CR [Anonymous], 2013, SHREC' 13 track: large scale sketchbased 3D shape retrieval
   [Anonymous], 2018, P EUR C COMP VIS
   As'ari MA, 2014, IMAGE VISION COMPUT, V32, P260, DOI 10.1016/j.imavis.2014.02.002
   Bai J, 2019, ENTROPY-SWITZ, V21, DOI 10.3390/e21040369
   Chen JX, 2019, PROC CVPR IEEE, P791, DOI 10.1109/CVPR.2019.00088
   Dai GX, 2017, AAAI CONF ARTIF INTE, P4002
   Dai GX, 2018, IEEE T IMAGE PROCESS, V27, P3374, DOI 10.1109/TIP.2018.2817042
   Dai WD, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102925
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dey S, 2019, PROC CVPR IEEE, P2174, DOI 10.1109/CVPR.2019.00228
   Du ZH, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104421
   Eitz M, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2185520.2185527
   Furuya T, 2013, 2013 INTERNATIONAL CONFERENCE ON CYBERWORLDS (CW), P274, DOI 10.1109/CW.2013.60
   Gao K, 2020, LECT NOTES COMPUT SC, V12396, P299, DOI 10.1007/978-3-030-61609-0_24
   Godil A.A., 2014, SHREC 14 TRACK SHAPE, P121
   Ha D, 2017, Arxiv, DOI arXiv:1704.03477
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XW, 2018, PROC CVPR IEEE, P1945, DOI 10.1109/CVPR.2018.00208
   Jiaxin Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P105, DOI 10.1007/978-3-030-58555-6_7
   Kodirov E, 2017, PROC CVPR IEEE, P4447, DOI 10.1109/CVPR.2017.473
   Lei YJ, 2019, PATTERN RECOGN, V96, DOI 10.1016/j.patcog.2019.106981
   Li B, 2017, MULTIMED TOOLS APPL, V76, P26603, DOI 10.1007/s11042-016-4187-3
   Li B, 2015, COMPUT VIS IMAGE UND, V131, P1, DOI 10.1016/j.cviu.2014.10.006
   Li B, 2014, COMPUT VIS IMAGE UND, V119, P57, DOI 10.1016/j.cviu.2013.11.008
   Li YN, 2017, PROC CVPR IEEE, P5207, DOI 10.1109/CVPR.2017.553
   Liang S, 2021, IEEE T IMAGE PROCESS, V30, P8632, DOI 10.1109/TIP.2021.3118979
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, 10.48550/arXiv.1301.3781]
   Oussama A, 2023, MULTIMED TOOLS APPL, V82, P10795, DOI 10.1007/s11042-022-13788-x
   Qi A., 2018, BMVC, P11
   Saavedra J.M., 2011, Proceedings of the 1st ACM International Conference on Multimedia Retrieval, P1
   Sariyildiz MB, 2019, PROC CVPR IEEE, P2163, DOI 10.1109/CVPR.2019.00227
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shilane P, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P167, DOI 10.1109/smi.2004.1314504
   Song D, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104482
   Sousa P, 2010, J VISUAL LANG COMPUT, V21, P69, DOI 10.1016/j.jvlc.2009.12.001
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tabia H, 2017, NEUROCOMPUTING, V253, P24, DOI 10.1016/j.neucom.2017.01.101
   Tasse FP, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2980253
   Tatsuma A, 2012, ASIAPAC SIGN INFO PR
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Xian YQ, 2018, PROC CVPR IEEE, P5542, DOI 10.1109/CVPR.2018.00581
   Xie J, 2017, PROC CVPR IEEE, P3615, DOI 10.1109/CVPR.2017.385
   Xinxin Luo, 2020, 2020 IEEE International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA), P757, DOI 10.1109/ICIBA50161.2020.9276900
   Xu P, 2021, IEEE T CIRC SYST VID, V31, P3366, DOI 10.1109/TCSVT.2020.3041586
   Xu P, 2022, IEEE T NEUR NET LEAR, V33, P5150, DOI 10.1109/TNNLS.2021.3069230
   Xu XX, 2022, Arxiv, DOI arXiv:2003.09869
   Xu YZ, 2020, IEEE T MULTIMEDIA, V22, P2950, DOI 10.1109/TMM.2020.2966882
   Xu YZ, 2018, INT C DIGITAL HOME, P311, DOI 10.1109/ICDH.2018.00061
   Yasseen Z, 2017, VISUAL COMPUT, V33, P565, DOI 10.1007/s00371-016-1328-7
   Zeng XX, 2020, IMAGE VISION COMPUT, V93, DOI 10.1016/j.imavis.2019.10.006
   Zhu F, 2016, AAAI CONF ARTIF INTE, P3683
   Zhu F, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104405
   Zhu JW, 2022, IMAGE VISION COMPUT, V124, DOI 10.1016/j.imavis.2022.104507
NR 54
TC 3
Z9 3
U1 7
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104756
DI 10.1016/j.imavis.2023.104756
EA JUL 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N7TK8
UT WOS:001038990800001
DA 2024-07-18
ER

PT J
AU Zhao, ZP
   Hao, K
   Liu, XF
   Zheng, TC
   Xu, JJ
   Cui, SY
   He, C
   Zhou, J
   Zhao, GM
AF Zhao, Zuopeng
   Hao, Kai
   Liu, Xiaofeng
   Zheng, Tianci
   Xu, Junjie
   Cui, Shuya
   He, Chen
   Zhou, Jie
   Zhao, Guangming
TI MCANet: Hierarchical cross-fusion lightweight transformer based on
   multi-ConvHead attention for object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Feature fusion; Transformer; Attention mechanism
AB The visual Transformer model based on self-attention has achieved better performance than convolutional neural networks in object detection tasks. However, existing visual Transformer models are typically heavy-weight to extract global features. In contrast, CNNs can extract features with fewer parameters and computational costs. To combine the advantages of convolutional processing at the local level with the advantages of the Trans-former's global interaction, this paper proposes MCANet, a Hierarchical Cross-Fusion Lightweight Transformer Based on Multi-ConvHead Attention for Object Detection. To bi-directionally fuse local and global features, MCANet adds two improved transformers (MCA-Former) for global interaction and two novel feature fusion modules MCA-CSP. MCA-Former uses a novel self-attention computation method named Multi-ConvHead Atten-tion(MCA) based on multi-scale depth-separable convolution, which reduces the computational cost by 2/3. Meanwhile, the number of model parameters is reduced to 9.49 M by using channel segmentation and multi-layer cross-fusion strategies. On the Pascal VOC and COCO datasets, the proposed model outperforms YOLOv4-Tiny in terms of AP by 2.43% and 1.8%, respectively. Additionally, MCANet is also superior to many latest light-weight object detection models. Results of various ablation experiments also verify the effectiveness of the pro-posed method. & COPY; 2023 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY license (http://creativecommons.org/licenses/by/4.0/).
C1 [Zhao, Zuopeng; Hao, Kai; Liu, Xiaofeng; Zheng, Tianci; Xu, Junjie; Cui, Shuya; He, Chen; Zhou, Jie; Zhao, Guangming] China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
C3 China University of Mining & Technology
RP Hao, K (corresponding author), China Univ Min & Technol, Sch Comp Sci & Technol, Xuzhou 221116, Jiangsu, Peoples R China.
EM TS20170012A31@cumt.edu.cn
RI 许, 俊杰/HHC-2199-2022; Xu, Junjie/KMA-6697-2024
FU National Natural Science Foun-dation of China [51874300]; Xuzhou Key
   Ramp;D Program [KC18082]
FX Acknowledgments This research was supported by the National Natural
   Science Foun-dation of China (no. 51874300) and Xuzhou Key R&D Program
   (no. KC18082) .
CR Aziere N, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104567
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Caglayan A, 2022, IMAGE VISION COMPUT, V122, DOI 10.1016/j.imavis.2022.104453
   Cai ZW, 2018, PROC CVPR IEEE, P6154, DOI 10.1109/CVPR.2018.00644
   Carion N., 2020, EUR C COMP VIS, P213, DOI DOI 10.1007/978-3-030-58452-8_13
   Chen Y., 2022, P IEEECVF C COMPUTER, P5270, DOI DOI 10.48550/ARXIV.2108.05895
   chuanqi305, 2018, CHUANQI305 MOB SSD
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dong XY, 2022, PROC CVPR IEEE, P12114, DOI 10.1109/CVPR52688.2022.01181
   Dosovitskiy A, 2021, Arxiv, DOI arXiv:2010.11929
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fang YX, 2021, ADV NEUR IN
   Fu C.-Y., 2017, arXiv
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Graham B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12239, DOI 10.1109/ICCV48922.2021.01204
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang L, 2023, IEEE SENS J, V23, P20681, DOI 10.1109/JSEN.2022.3220341
   Hubel DH, 1998, NEURON, V20, P401, DOI 10.1016/S0896-6273(00)80984-8
   Jia XZ, 2022, IMAGE VISION COMPUT, V127, DOI 10.1016/j.imavis.2022.104549
   Jocher G., 2022, Zenodo, V2, P2
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li CY, 2022, Arxiv, DOI [arXiv:2209.02976, 10.48550/arXiv.2209.02976]
   Li F, 2022, PROC CVPR IEEE, P13609, DOI 10.1109/CVPR52688.2022.01325
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S., 2022, arXiv
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mehta S, 2022, Arxiv, DOI [arXiv:2110.02178, DOI 10.48550/ARXIV.2110.02178]
   Iandola FN, 2016, Arxiv, DOI arXiv:1602.07360
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Peng ZL, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P357, DOI 10.1109/ICCV48922.2021.00042
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ruan WenLong, 2022, 2022 3rd International Conference on Computer Vision, Image and Deep Learning & International Conference on Computer Engineering and Applications (CVIDL & ICCEA), P46, DOI 10.1109/CVIDLICCEA56201.2022.9824440
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen ZQ, 2017, IEEE I CONF COMP VIS, P1937, DOI 10.1109/ICCV.2017.212
   Song HJ, 2021, Arxiv, DOI arXiv:2110.03921
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Vaswani A, 2021, PROC CVPR IEEE, P12889, DOI 10.1109/CVPR46437.2021.01270
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu HP, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P22, DOI 10.1109/ICCV48922.2021.00009
   Xiao T., 2021, NEURIPS, V34, P30392
   Xie P., 2022, KNOWLEDGE MANAGEMENT, P281
   Xu N, 2022, NEUROCOMPUTING, V491, P522, DOI 10.1016/j.neucom.2021.12.030
   Yuan L, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P538, DOI 10.1109/ICCV48922.2021.00060
   Zeng K, 2022, NEUROCOMPUTING, V493, P15, DOI 10.1016/j.neucom.2022.04.062
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao Z., 2021, COMPUT INTEL NEUROSC, V2021
   Zhao Z., 2020, COMPUT INTEL NEUROSC, V2020
   Zhao ZP, 2023, IETE J RES, V69, P5497, DOI 10.1080/03772063.2021.1982409
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 62
TC 8
Z9 8
U1 2
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104715
DI 10.1016/j.imavis.2023.104715
EA JUN 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA L2GH6
UT WOS:001021487600001
OA hybrid
DA 2024-07-18
ER

PT J
AU Sharma, D
   Selwal, A
AF Sharma, Deepika
   Selwal, Arvind
TI SFincBuster: Spoofed fingerprint buster via incremental learning using
   leverage bagging classifier
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fingerprint; Spoof attacks; Anti -spoofing; Synthetic fingerprint;
   Incremental learning; VGG19
ID PRESENTATION ATTACK DETECTION; LIVENESS DETECTION; FEATURES
AB The fingerprint presentation attack detection (PAD) studies are extensively explored by investigators to augment the security aspects of human authentication in biometric systems. Although existing approaches yield promising results while evaluated on data having same distribution as the training data, but their performance is declined in scenarios when data is gathered from unknown environment. In these situations model is learned with the new type of fake samples by re-training the entire model. Nevertheless, it has been a non-trivial concern to re-train the entire system to tackle the newly created fake samples as unseen artifacts are generated continuously in real-time scenarios. In this work, we expound a novel incremental learning-based approach namely; SFincBuster that can work effectively in the challenging real-time scenarios and can handle both new data as well as new ob-servations from old classes. We train a leveraging bagging ensemble (LBE) in incremental fashion regardless of the extracted deep-level features (using pre-trained VGG19 network) being too large to accommodate into sys-tem memory, it is still possible to train our model effectively. Furthermore, the LBE integrates the simplicity of classical bagging with augmented randomization to the input and outcome of the base classifiers. To tackle the issue of change in distribution that arises with gradual changes from learned fakes to entirely new fingerprint ar-tifacts, the SFincBuster employs LBE with ADWIN (Adaptive WINDowing) technique that continuously evaluate the performance of underlying base model and whenever a change is detected the weakest classifier is substituted with a new one. Our approach achieves high classification accuracy, even though it is not prerequisite to access all features at once. The SFincBuster is trained and evaluated on LivDet 2009, LivDet 2011, LivDet 2013, LivDet 2015 and LivDet 2021 benchmark datasets and yields maximum average classification accuracy (ACA) of 98.65% on LivDet 2013 and LivDet 2015 datasets. The model exhibits stupendous generalization capabilities with an average classification error rate (ACER) of 1.39% for known fakes (KF) and 2.84% for unknown fakes (UF). Fi-nally, the comparable investigation perceives that the SFincBuster model demonstrates a noteworthy perfor-mance gain over the similar state-of-the-art (SOTA) approaches and achieve an improved benchmark for real-time cross-sensor, cross-material and cross-dataset scenarios.& COPY; 2023 Published by Elsevier B.V.
C1 [Sharma, Deepika; Selwal, Arvind] Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, India.
C3 Central University of Jammu
RP Sharma, D (corresponding author), Cent Univ Jammu, Dept Comp Sci & Informat Technol, Samba 181143, India.
EM sharmadeepika749@gmail.com
CR Agarwal S, 2022, MACH LEARN APPL, V7, DOI 10.1016/j.mlwa.2021.100210
   Agarwal S, 2020, EXPERT SYST APPL, V146, DOI 10.1016/j.eswa.2019.113160
   Alshdadi AA, 2020, BIOMED SIGNAL PROCES, V61, DOI 10.1016/j.bspc.2020.102039
   Bifet A, 2010, LECT NOTES ARTIF INT, V6321, P135, DOI 10.1007/978-3-642-15880-3_15
   Bifet A, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P443
   Busch C., 2017, ISO IEC STANDARDS TE
   Casula R., 2021, IEEE INT JOINT C BIO, P1
   Chugh T., 2019, INT C BIOM ICB 2019
   Chugh T, 2021, IEEE T INF FOREN SEC, V16, P42, DOI 10.1109/TIFS.2020.2990789
   Dubey RK, 2016, IEEE T INF FOREN SEC, V11, P1461, DOI 10.1109/TIFS.2016.2535899
   Evans N., 2014, HDB BIOMETRIC ANTISP, DOI [10.1007/978-1-4471-6524-8, DOI 10.1007/978-1-4471-6524-8]
   Gajawada R, 2019, INT CONF BIOMETR
   Ghiani L, 2013, INT CONF BIOMETR, DOI 10.1109/ICB.2013.6613027
   González-Soler LJ, 2021, IEEE ACCESS, V9, P5806, DOI 10.1109/ACCESS.2020.3048756
   Grosz SA, 2020, IEEE/IAPR INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2020), DOI 10.1109/ijcb48548.2020.9304863
   Jain AK, 2006, IEEE T INF FOREN SEC, V1, P125, DOI 10.1109/TIFS.2006.873653
   Jian W, 2021, IEEE ACCESS, V9, P2229, DOI 10.1109/ACCESS.2020.3047723
   Jiang YJ, 2018, J ELECTR COMPUT ENG, V2018, DOI 10.1155/2018/1539298
   Jung HY, 2018, ELECTRON LETT, V54, P564, DOI 10.1049/el.2018.0621
   Jung HY, 2019, IEEE ACCESS, V7, P118986, DOI 10.1109/ACCESS.2019.2936890
   Khade S., 2018, 2018 IEEE PUN IEEE, P1
   Kho JB, 2019, EXPERT SYST APPL, V116, P52, DOI 10.1016/j.eswa.2018.08.055
   Kim W., 2016, IEEE SIGNAL PROC LET, V1, P1, DOI DOI 10.1109/LSP.2016.2636158
   Kolberg Jascha, 2021, IEEE Transactions on Biometrics, Behavior, and Identity Science, V3, P190, DOI 10.1109/TBIOM.2021.3050036
   Li ZC, 2023, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2023.3240195
   Liu F, 2021, IEEE T IMAGE PROCESS, V30, P2394, DOI 10.1109/TIP.2021.3052341
   Marcialis GL., 2009, IMAGE ANAL PROCESSIN
   Mura V, 2015, INT CONF BIOMETR THE
   Nogueira RF, 2016, IEEE T INF FOREN SEC, V11, P1206, DOI 10.1109/TIFS.2016.2520880
   Park E, 2019, IEEE T INF FOREN SEC, V14, P3016, DOI 10.1109/TIFS.2019.2907184
   Park Y, 2018, SOFT COMPUT, V22, P4175, DOI 10.1007/s00500-017-2707-3
   Polikar R., 2001, IEEE Transactions on Systems, Man and Cybernetics, V31
   Rattani A., 2023, AUTOMATIC ADAPTATION
   Rattani A, 2015, IEEE T INF FOREN SEC, V10, P2447, DOI 10.1109/TIFS.2015.2464772
   Sharma D, 2021, PATTERN RECOGN LETT, V152, P225, DOI 10.1016/j.patrec.2021.10.013
   Sharma D, 2022, MULTIMED TOOLS APPL, V81, P22129, DOI 10.1007/s11042-021-11254-8
   Sharma D, 2022, VISUAL COMPUT, V38, P2999, DOI 10.1007/s00371-021-02173-8
   Sharma RP, 2019, VISUAL COMPUT, V35, P1393, DOI 10.1007/s00371-018-01618-x
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang H, 2022, PATTERN RECOGN, V130, DOI 10.1016/j.patcog.2022.108792
   Tang H, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P610, DOI 10.1145/3394171.3413884
   Tian S, 2021, IEEE IMAGE PROC, P2478, DOI 10.1109/ICIP42928.2021.9506685
   Tolosana R, 2020, IEEE T INF FOREN SEC, V15, P1261, DOI 10.1109/TIFS.2019.2934867
   Uliyan DM, 2020, ENG SCI TECHNOL, V23, P264, DOI 10.1016/j.jestch.2019.06.005
   Xia ZH, 2020, IEEE T SYST MAN CY-S, V50, P1526, DOI 10.1109/TSMC.2018.2874281
   Xia ZH, 2017, SIGNAL IMAGE VIDEO P, V11, P381, DOI 10.1007/s11760-016-0936-z
   Yambay D., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P208, DOI 10.1109/ICB.2012.6199810
   Yuan CS, 2019, SOFT COMPUT, V23, P5157, DOI 10.1007/s00500-018-3182-1
   Yuan CS, 2019, IEEE ACCESS, V7, P26953, DOI 10.1109/ACCESS.2019.2901235
   Zha ZC, 2023, IEEE T CIRC SYST VID, V33, P3947, DOI 10.1109/TCSVT.2023.3236636
   Zhang YL, 2020, IEEE ACCESS, V8, P183391, DOI 10.1109/ACCESS.2020.3027846
   Zhang YL, 2020, IEEE ACCESS, V8, P84141, DOI 10.1109/ACCESS.2020.2990909
   Zhang YL, 2019, IEEE ACCESS, V7, P91476, DOI 10.1109/ACCESS.2019.2927357
NR 53
TC 0
Z9 0
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104713
DI 10.1016/j.imavis.2023.104713
EA JUN 2023
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA K3XY7
UT WOS:001015813800001
DA 2024-07-18
ER

PT J
AU Rohlfs, C
AF Rohlfs, Chris
TI Problem-dependent attention and effort in neural networks with
   applications to image resolution and model selection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Attention; Neural networks; Propensity scores; Ensemble learning; Deep
   learning; Computer vision; Image resolution; Flops
AB This paper introduces two new ensemble-based methods to reduce the data and computation costs of image clas-sification. They can be used with any set of classifiers and do not require additional training. In the first approach, data usage is reduced by only analyzing a full-sized image if the model has low confidence in classifying a low-resolution pixelated version. When applied on the best performing classifiers considered here, data usage is re-duced by 61.2% on MNIST, 69.6% on KMNIST, 56.3% on FashionMNIST, 84.6% on SVHN, 40.6% on ImageNet, and 27.6% on ImageNet-V2, all with a less than 5% reduction in accuracy. However, for CIFAR-10, the pixelated data are not particularly informative, and the ensemble approach increases data usage while reducing accuracy. In the second approach, compute costs are reduced by only using a complex model if a simpler model has low con-fidence in its classification. Computation cost is reduced by 82.1% on MNIST, 47.6% on KMNIST, 72.3% on FashionMNIST, 86.9% on SVHN, 89.2% on ImageNet, and 81.5% on ImageNet-V2, all with a less than 5% reduction in accuracy; for CIFAR-10 the corresponding improvements are smaller at 13.5%. When cost is not an object, choosing the projection from the most confident model for each observation increases validation accuracy to 81.0% from 79.3% for ImageNet and to 69.4% from 67.5% for ImageNet-V2. Code available at:https://github. com/carohlfs/imavis. & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Rohlfs, Chris] Columbia Univ, Dept Elect Engn, Mudd 1310,500 West 120th St, New York, NY 10027 USA.
C3 Columbia University
RP Rohlfs, C (corresponding author), Columbia Univ, Dept Elect Engn, Mudd 1310,500 West 120th St, New York, NY 10027 USA.
EM car2228@columbia.edu
CR An SHY, 2020, Arxiv, DOI [arXiv:2008.10400, DOI 10.48550/ARXIV.2008.10400]
   Nguyen A, 2015, PROC CVPR IEEE, P427, DOI 10.1109/CVPR.2015.7298640
   Bolukbasi T, 2017, PR MACH LEARN RES, V70
   Clanuwat T., 2018, NEURAL INFORM PROCES, V32
   Cordonnier JB, 2021, PROC CVPR IEEE, P2351, DOI 10.1109/CVPR46437.2021.00238
   Kabir HD, 2022, Arxiv, DOI arXiv:2007.03347
   Dosovitskiy Alexey, 2021, ICLR
   Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194
   Foret Pierre, 2021, INT C LEARNING REPRE
   Gal Y, 2016, PR MACH LEARN RES, V48
   Gao MF, 2018, PROC CVPR IEEE, P6926, DOI 10.1109/CVPR.2018.00724
   Gong YC, 2014, Arxiv, DOI arXiv:1412.6115
   Graf, 2017, ARXIV160808710, P1, DOI DOI 10.48550/ARXIV.1608.08710
   Han  S., 2015, ARXIV151000149
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han YZ, 2022, IEEE T PATTERN ANAL, V44, P7436, DOI 10.1109/TPAMI.2021.3117837
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2015, Arxiv, DOI arXiv:1503.02531
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G., 2018, INT C LEARNING REPRE
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kaya Y., 2019, IEEE ACCESS, V7, P6250
   Kaya Y, 2019, PR MACH LEARN RES, V97
   Koziarski M, 2018, INT J AP MAT COM-POL, V28, P735, DOI 10.2478/amcs-2018-0056
   Krishnamoorthi R, 2018, Arxiv, DOI arXiv:1806.08342
   Krizhevsky A, 2014, Arxiv, DOI arXiv:1404.5997
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lee CY, 2015, JMLR WORKSH CONF PRO, V38, P562
   Lewinson E, 2020, DATA SCI
   Liu K, 2022, TRAIN CIFAR10 PYTORC
   Massoli FV, 2020, IMAGE VISION COMPUT, V99, DOI 10.1016/j.imavis.2020.103927
   Mishra NK, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104290
   Paszke A, 2019, ADV NEUR IN, V32
   Polino A., 2018, ARXIV180205668
   Recht B, 2019, PR MACH LEARN RES, V97
   Rohlfs C, 2022, Arxiv, DOI [arXiv:2209.01610, 10.48550/arXiv.2209.01610, DOI 10.48550/ARXIV.2209.01610]
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabottke CF, 2020, RADIOL-ARTIF INTELL, V2, DOI 10.1148/ryai.2019190015
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinz FH, 2019, NEURON, V103, P967, DOI 10.1016/j.neuron.2019.08.034
   Spreng RN, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01231-7
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2020, Arxiv, DOI arXiv:1905.11946
   Tanveer MS, 2021, INT C PATT RECOG, P4789, DOI 10.1109/ICPR48806.2021.9412221
   Teerapittayanon S, 2016, INT C PATT RECOG, P2464, DOI 10.1109/ICPR.2016.7900006
   Wang F., 2020, SCI REP-UK, V10
   Wang K, 2011, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2011.6126402
   WOLPERT DH, 1992, NEURAL NETWORKS, V5, P241, DOI 10.1016/S0893-6080(05)80023-1
   Wortsmann M., 2022, INT C MACHINE LEARNI, V39
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang L, 2020, PROC CVPR IEEE, P2366, DOI 10.1109/CVPR42600.2020.00244
   Yang WM, 2019, IEEE T MULTIMEDIA, V21, P3106, DOI 10.1109/TMM.2019.2919431
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Yu J., 2022, Trans. Mach. Learn. Res.
   Yuan LZ, 2019, PROC CVPR IEEE, P12175, DOI 10.1109/CVPR.2019.01246
   Zagoruyko S, 2017, Arxiv, DOI arXiv:1605.07146
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
NR 62
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104696
DI 10.1016/j.imavis.2023.104696
EA MAY 2023
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA J8BA8
UT WOS:001011810000001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xiao, YQ
   Wu, YJ
AF Xiao, Yuqi
   Wu, Yongjun
TI Robust visual tracking based on modified mayfly optimization algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Mayfly optimization algorithm; Scale adaptive tracking
   frame
AB In this study, MOA is applied to visual target tracking for the first time, and a novel meta-heuristic tracking algo-rithm with efficiency and precision is obtained. Similar to the common problems of other classical swarm intel-ligence algorithms, standard MOA faces a high probability of falling into local extremals, early maturity anda low efficiency of a late convergence speed. Therefore, super-MOA, a modified MOA method, is proposed in this study. By designing the updating mechanism, the position and velocity parameters of ephemera are monitored and dynamically adjusted with the iteration degree, and the balance of the global and local optimization process in different iteration stages is improved. A mayfly progeny mutation strategy was proposed to alleviate the prema-turity problem of the standard MOA algorithm. Meanwhile, we introduce a chaos algorithm to reconstruct the velocity parameter iteration mechanism, which alleviates the efficiency loss caused by the frequent repeated searching of historical locations by mayflies in standard MOA. In addition, we further understand and improve the parameters such as the dynamic gravitational coefficient and dance coefficient during the courtship flight of mayflies. We also design a frame size adaptive adjustment strategy, which effectively decreases the interfer-ence of invalid features. In terms of experiments, we compare this algorithm with other classical trackers from the qualitative, quantitative and statistical perspectives through OTB2015, VOT2018 and typical large-scale benchmarks. Sufficient tracking experiments in various tracking scenes show that our tracker performs great in terms of efficiency, robustness and accuracy. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Xiao, Yuqi] West Anhui Univ, Sch Mech & Vehicle Engn, Luan City 237012, Anhui, Peoples R China.
   [Wu, Yongjun] ChongqingJiaotong Univ, Sch Traff & Transportat, Chongqing 400074, Peoples R China.
C3 West Anhui University
RP Xiao, YQ (corresponding author), West Anhui Univ, Sch Mech & Vehicle Engn, Luan City 237012, Anhui, Peoples R China.
EM csuxyq@163.com
RI Xiao, Yuqi/AFE-4884-2022
OI Wu, Yongjun/0000-0001-9073-6633
CR Abbaspour M, 2022, IMAGE VISION COMPUT, V127, DOI 10.1016/j.imavis.2022.104553
   Abdelpakey MH, 2022, IMAGE VISION COMPUT, V127, DOI 10.1016/j.imavis.2022.104550
   Bhat PG, 2021, IEEE SENS J, V21, P10112, DOI 10.1109/JSEN.2021.3054815
   Danelljan M., 2014, Accurate Scale Estimation for Robust Visual Tracking
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2016, PROC CVPR IEEE, P1430, DOI 10.1109/CVPR.2016.159
   Danelljan M, 2016, LECT NOTES COMPUT SC, V9909, P472, DOI 10.1007/978-3-319-46454-1_29
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Fan H., 2019, 2019 IEEE CVF C COMP
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Guari Q, 2019, J CANCER, V10, P4876, DOI 10.7150/jca.28769
   Hong ZB, 2015, PROC CVPR IEEE, P749, DOI 10.1109/CVPR.2015.7298675
   Jahwar A, 2021, Journal of Applied Science and Technology Trends, V2, P01, DOI 10.38094/jastt20161
   Kaveh A, 2014, ADV ENG SOFTW, V76, P9, DOI 10.1016/j.advengsoft.2014.05.012
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li Y, 2015, LECT NOTES COMPUT SC, V8926, P254, DOI 10.1007/978-3-319-16181-5_18
   Li YH, 2022, Arxiv, DOI arXiv:1902.02804
   Liu JX, 2020, INFORM FUSION, V53, P289, DOI 10.1016/j.inffus.2019.06.012
   Müller M, 2018, LECT NOTES COMPUT SC, V11205, P310, DOI 10.1007/978-3-030-01246-5_19
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Natesan G, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22176405
   Shahbazi M, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104533
   Wang L, 2020, NEURAL PROCESS LETT, V52, P2607, DOI 10.1007/s11063-020-10363-z
   Wang MM, 2017, PROC CVPR IEEE, P4800, DOI 10.1109/CVPR.2017.510
   Wang N, 2018, PROC CVPR IEEE, P4844, DOI 10.1109/CVPR.2018.00509
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Xu C, 2021, J NETW COMPUT APPL, V176, DOI 10.1016/j.jnca.2020.102913
   Yan B, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10428, DOI 10.1109/ICCV48922.2021.01028
   Yu MX, 2022, IMAGE VISION COMPUT, V126, DOI 10.1016/j.imavis.2022.104546
   Zeng YL, 2022, APPL INTELL, V52, P4973, DOI 10.1007/s10489-021-02651-5
   Zervoudakis K, 2020, COMPUT IND ENG, V145, DOI 10.1016/j.cie.2020.106559
   Zha YF, 2022, IET COMPUT VIS, V16, P317, DOI 10.1049/cvi2.12090
NR 33
TC 3
Z9 3
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104691
DI 10.1016/j.imavis.2023.104691
EA MAY 2023
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA I2XO6
UT WOS:001001465600001
DA 2024-07-18
ER

PT J
AU Luo, XH
   Liu, Z
   Wei, WJ
   Ye, LW
   Zhang, TH
   Xu, LH
   Wang, JJ
AF Luo, Xinhui
   Liu, Zhi
   Wei, Weijie
   Ye, Linwei
   Zhang, Tianhong
   Xu, Lihua
   Wang, Jijun
TI Few-shot personalized saliency prediction using meta-learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Personalized saliency prediction; Few-shot learning; Meta-learning; Deep
   learning; Hard samples
ID VISUAL SALIENCY; MODEL; RECOGNITION
AB Personalized saliency maps (PSMs) reflect the gaze patterns of different subjects. Current works of saliency prediction explore the common trend in fixation distribution across all observers as a task. Personalized saliency prediction takes the personal preference of each individual into account. In other words, it considers each subject as a task. Due to the difficulty of obtaining individual labeled data, limited works are focusing on personalized saliency prediction. Our goal is to train a model that can quickly adapt to a new subject by using a few labeled data from the new subject. This paper proposes a meta-learning-based method to solve the few-shot personalized saliency prediction problem and predict better saliency maps of different subjects. Our method learns model parameters to fast adapt to new subjects. In addition, we design a Hard Samples Selection (HSS) strategy to make the training process more effective. Specifically, due to the adaptability of the model to different subjects is reflected in the value of the loss function during training, we regard subjects with high loss function values as hard samples. Then we can select hard samples online and retrain the model based on them to improve the saliency prediction performance. Experimental results show that our proposed method is better than existing methods on the PSM dataset for personalized saliency prediction. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Luo, Xinhui; Liu, Zhi] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Key Lab Specialty Fiber Opt & Opt Access Networks, Joint Int Res Lab Specialty Fiber Opt & Adv Commun, Shanghai 200444, Peoples R China.
   [Luo, Xinhui; Liu, Zhi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Wei, Weijie] Univ Amsterdam, Atlas Lab, NL-1098 XH Amsterdam, Netherlands.
   [Ye, Linwei] Wenzhou Univ, Coll Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
   [Zhang, Tianhong; Xu, Lihua; Wang, Jijun] Shanghai Jiao Tong Univ, Shanghai Mental Hlth Ctr, Sch Med, Shanghai Key Lab Psychot Disorders, Shanghai 200030, Peoples R China.
C3 Shanghai University; Shanghai University; University of Amsterdam;
   Wenzhou University; Shanghai Jiao Tong University
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Key Lab Specialty Fiber Opt & Opt Access Networks, Joint Int Res Lab Specialty Fiber Opt & Adv Commun, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
RI Zhang, TianHong/IQS-6148-2023; Xu, Lihua/ABF-4012-2021; LIU,
   Zhi/D-4518-2012
OI Zhang, TianHong/0000-0002-5379-7119; LIU, Zhi/0000-0002-8428-1131
FU National Natural Science Founda-tion of China [62171269, 82171544];
   Scienceand Technology Commission of Shanghai Municipality [21S31903100]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of China under Grants 62171269 and 82171544, and by the
   Scienceand Technology Commission of Shanghai Municipality under Grant
   21S31903100.
CR [Anonymous], 2016, OPTIMIZATION MODEL F
   [Anonymous], 2013, Adv. Neural Inf. Process. Syst
   Borji A, 2011, IEEE INT CONF ROBOT, P1902
   Cornia M, 2018, IEEE T IMAGE PROCESS, V27, P5142, DOI 10.1109/TIP.2018.2851672
   Fei-Fei L, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1134, DOI 10.1109/ICCV.2003.1238476
   Flores CF, 2019, PATTERN RECOGN, V94, P62, DOI 10.1016/j.patcog.2019.05.002
   Finn C, 2017, PR MACH LEARN RES, V70
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Goodfellow J., 2014, ADV NEURAL INF PROCE, V27
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GL, 2017, IEEE ICC
   Huang LJ, 2020, PATTERN RECOGN LETT, V138, P608, DOI 10.1016/j.patrec.2020.09.017
   Huang X, 2015, IEEE I CONF COMP VIS, P262, DOI 10.1109/ICCV.2015.38
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jia S, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103887
   Kang B., P IEEECVF INT C COMP, P8420
   Kingma D. P., 2015, PROC INT C LEARN REP, P1
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krishna O, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0193149
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kroner A, 2020, NEURAL NETWORKS, V129, P261, DOI 10.1016/j.neunet.2020.05.004
   Kummerer M., 2014, ARXIV14111045
   Li AQ, 2018, IEEE ACCESS, V6, P16099, DOI 10.1109/ACCESS.2018.2800294
   Lin S., 2018, ARXIV180207931
   Lin T.-Y., 2014, CoRR, P740
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Nichol A., 2018, ARXIV PREPRINT
   Pan J., 2017, PROC IEEE C COMPUT V
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Reddy MKK, 2020, IEEE WINT CONF APPL, P2803, DOI [10.1109/WACV45572.2020.9093409, 10.1109/wacv45572.2020.9093409]
   Reddy N, 2020, IEEE INT C INT ROBOT, P10241, DOI 10.1109/IROS45743.2020.9341574
   Rezende DJ, 2016, PR MACH LEARN RES, V48
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Santoro A, 2016, PR MACH LEARN RES, V48
   Schmidhuber J., 1987, On Learning How to Learn: The meta-meta- ... hook ...
   Sheng H, 2020, IEEE INTERNET THINGS, V7, P9611, DOI 10.1109/JIOT.2020.2980549
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tay CP, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104298
   Triantafyllidou D, 2018, BIG DATA RES, V11, P65, DOI 10.1016/j.bdr.2017.06.002
   Vig E, 2014, PROC CVPR IEEE, P2798, DOI 10.1109/CVPR.2014.358
   Wang ZQ, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104149
   Wei WJ, 2021, NEUROCOMPUTING, V453, P610, DOI 10.1016/j.neucom.2020.06.125
   Xu YY, 2019, IEEE T PATTERN ANAL, V41, P2975, DOI 10.1109/TPAMI.2018.2866563
   Xu YY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3887
   Yang S, 2020, IEEE T MULTIMEDIA, V22, P2163, DOI 10.1109/TMM.2019.2947352
NR 51
TC 7
Z9 7
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104491
DI 10.1016/j.imavis.2022.104491
EA JUN 2022
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 2J7XL
UT WOS:000815864800004
DA 2024-07-18
ER

PT J
AU Romero, A
   León, J
   Arbeláez, P
AF Romero, Andres
   Leon, Juan
   Arbelaez, Pablo
TI Multi-view dynamic facial action unit detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
ID EXPRESSION RECOGNITION; OPTICAL-FLOW
AB We propose a novel convolutional neural network approach to address the fine-grained recognition problem of multi-view dynamic facial action unit detection. We leverage recent gains in large-scale object recognition by formulating the task of predicting the presence or absence of a specific action unit in a still image of a human face as holistic classification. We then explore the design space of our approach by considering both shared and independent representations for separate action units, and also different CNN architectures for combining color and motion information. We then move to the novel setup of the FERA 2017 Challenge, in which we propose a multi-view extension of our approach that operates by first predicting the viewpoint from which the video was taken, and then evaluating an ensemble of action unit detectors that were trained for that specific viewpoint. Our approach is holistic, efficient, and modular, since new action units can be easily included in the overall system. Our approach significantly outperforms the baseline of the FERA 2017 Challenge, with an absolute improvement of 14% on the F1-metric. Additionally, it compares favorably against the winner of the FERA 2017 Challenge. (c) 2018 Elsevier B.V. All rights reserved.
C1 [Romero, Andres; Leon, Juan] Univ Andes, Bogota, Colombia.
C3 Universidad de los Andes (Colombia)
RP Romero, A (corresponding author), Univ Andes, Bogota, Colombia.
EM rv.andres10@uniandes.edu.co; jc.leon@uniandes.edu.co
RI Romero, Andrés/ABE-9965-2020
OI Romero, Andrés/0000-0002-7118-5175; Arbelaez, Pablo/0000-0001-5244-2407
FU NVIDIA Corporation
FX Acknowledgments This work was partially supported by a Google Research
   Award Latin America. We are grateful to NVIDIA Corporation for donating
   the GPUs used in this work.
CR Almaev T, 2015, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2015.430
   [Anonymous], 2014, ECCV
   [Anonymous], 2013, AUTOMATIC FACE GESTU
   [Anonymous], 2000, DR DOBBS J SOFTW TOO
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2010, CVPR
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cao Q., 2018, IEEE INT CONF AUTOMA
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Chéron G, 2015, IEEE I CONF COMP VIS, P3218, DOI 10.1109/ICCV.2015.368
   Chu W.-S., ARXIV PREPRINT
   Cootes T.F., 1998, IEEE Trans. on Pattern Analysis and Machine Intelligence (PAMI)
   Dai JF, 2016, PROC CVPR IEEE, P3150, DOI 10.1109/CVPR.2016.343
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du SC, 2014, P NATL ACAD SCI USA, V111, pE1454, DOI 10.1073/pnas.1322355111
   Ekman P., 1978, APA PsycTests, DOI DOI 10.1037/T27734-000
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Eleftheriadis S, 2015, IEEE I CONF COMP VIS, P3792, DOI 10.1109/ICCV.2015.432
   Gkioxari G, 2015, PROC CVPR IEEE, P759, DOI 10.1109/CVPR.2015.7298676
   Gudi A, 2015, IEEE INT CONF AUTOMA
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   He J, 2017, IEEE INT CONF AUTOMA, P848, DOI 10.1109/FG.2017.108
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Jaiswal S, 2016, IEEE WINT CONF APPL
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kahou S.E., 2014, ECCV
   Kaltwang S, 2015, PROC CVPR IEEE, P296, DOI 10.1109/CVPR.2015.7298626
   Kingma D., ARXIV PREPRINT
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Liu P, 2014, PROC CVPR IEEE, P1805, DOI 10.1109/CVPR.2014.233
   Liu YJ, 2016, IEEE T AFFECT COMPUT, V7, P299, DOI 10.1109/TAFFC.2015.2485205
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mavadati M, 2016, IEEE COMPUT SOC CONF, P1452, DOI 10.1109/CVPRW.2016.182
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   OJALA T, 1994, INT C PATT RECOG, P582, DOI 10.1109/ICPR.1994.576366
   P EKMAN-WV FRIESEN-JC HAGER, 2002, FACIAL ACTION CODING
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Peng XJ, 2016, LECT NOTES COMPUT SC, V9908, P744, DOI 10.1007/978-3-319-46493-0_45
   Simonyan Karen, ARXIV PREPRINT
   Szegedy C, 2015, P IEEE C COMP VIS PA
   Tang CG, 2017, IEEE INT CONF AUTOMA, P878, DOI 10.1109/FG.2017.113
   Valstar M.F., ARXIV PREPRINT
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P966, DOI 10.1109/TSMCB.2012.2200675
   Wang ZH, 2013, IEEE I CONF COMP VIS, P3304, DOI 10.1109/ICCV.2013.410
   Xie SN, 2015, IEEE I CONF COMP VIS, P1395, DOI [10.1109/ICCV.2015.164, 10.1007/s11263-017-1004-z]
   Yang JM, 2016, PROC CVPR IEEE, P193, DOI 10.1109/CVPR.2016.28
   Yang LJ, 2015, PROC CVPR IEEE, P3973, DOI 10.1109/CVPR.2015.7299023
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng JB, 2015, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2015.413
   Zhang X, 2014, IMAGE VISION COMPUT, V32, P692, DOI 10.1016/j.imavis.2014.06.002
   Zhang Z, 2016, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2016.374
   Zhao KL, 2016, PROC CVPR IEEE, P3391, DOI 10.1109/CVPR.2016.369
   Zhao KL, 2015, PROC CVPR IEEE, P2207, DOI 10.1109/CVPR.2015.7298833
NR 56
TC 3
Z9 3
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 103723
DI 10.1016/j.imavis.2018.09.014
EA MAY 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1U7WO
UT WOS:000805618300001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Gandapur, MQ
AF Gandapur, Maryam Qasim
TI E2E-VSDL: End-to-end video surveillance-based deep learning model to
   detect and prevent criminal activities
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Criminal activities; Video surveillance; End-to-end deep learning; CNN;
   BiGRU
ID CRIME PREDICTION
AB Crime detection and their prediction is a fundamental process to reduce criminal activities before they actually happen. Moreover, the detection method is vital since can it potentially can save the victim's life, avoid alltime strain, and harm to the public/private property. In addition, it can be useful in predicting the possible terrorist activities. Crime detection using deep learning models is an attention-grabbing research area. Detecting and reducing the criminal activities is imperative to develop a peaceful society. Video surveillance automates the hazardous situations and enables a law enforcement system to take effective steps towards public safety. In this paper, an end-to-end deep learning model is proposed which is based on Bi-directional gated recurrent unit (BiGRU) and Convolutional neural network (CNN) to detect and prevent criminal activities. The CNN extracts the spatial features from video frames whereas temporal and local motion features are extracted by the BiGRU from multiple frames CNN extracted features. The focused bag is created to select those video frames which indicate certain actions. Moreover, ranked-based loss is used to effectively detect and classify the suspicious activities. For classification of activities, various machine learning classifiers are used. The proposed deep learning video surveillance technique is able to track human trails and detect criminal events. The CAVIAR dataset is used to examine the proposed technique for video surveillance-based crime detection with a performance accuracy of almost 98.86%. The alerts received from the proposed technique can also be examined, demonstrates that the practiced video surveillance cameras systems can effectively detect unusual and criminal activities. In addition, the proposed technique showed considerable performance accuracy and outscored the related state-of-the-art (SOTA)DL models including CNN-LSTM, CNN, HMM, and DBN and achieved 21.88% absolute improvement in crime detection accuracy. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Gandapur, Maryam Qasim] Shaheed Benazir Bhutto Univ, Dept Law, Dir, Khyber Pakhtunk, Pakistan.
RP Gandapur, MQ (corresponding author), Shaheed Benazir Bhutto Univ, Dept Law, Dir, Khyber Pakhtunk, Pakistan.
EM maryam@sbbu.edu.pk
CR Alkanhal L, 2020, INT J ADV COMP ENCE, V11
   Alves LGA, 2018, PHYSICA A, V505, P435, DOI 10.1016/j.physa.2018.03.084
   Athanesious J, 2020, IET IMAGE PROCESS, V14, P1881, DOI 10.1049/iet-ipr.2019.0549
   Bandekar S. R., 2020, Procedia Computer Science, V172, P122, DOI DOI 10.1016/J.PROCS.2020.05.018
   Bharati, 2018, INT RES J ENG TECHNO, V5, P1037
   Borges J., 2017, 2017 IEEE SMARTWORLD
   Chen DY, 2020, IMAGE VISION COMPUT, V98, DOI 10.1016/j.imavis.2020.103915
   Chung-Hsien Yu, 2011, 2011 IEEE International Conference on Data Mining Workshops, P779, DOI 10.1109/ICDMW.2011.56
   Crowley J.L, 2004, CONTEXT AWARE VISION
   Das P, 2021, INFORM SCIENCES, V562, P279, DOI 10.1016/j.ins.2021.02.002
   Easwaramoorthy S, 2016, 2016 INT C REC TREND, P1, DOI DOI 10.1109/ICETETS.2016.7603054
   Ghafir I, 2019, IEEE ACCESS, V7, P99508, DOI 10.1109/ACCESS.2019.2930200
   Gorr W., 2000, International journal of forecasting, P743
   HOSSAIN S., 2020, INT C COMP SCI COMM, P277
   Jangra M., 2019, International Journal of Computer Science and Mobile Computing, V8, P134
   Jha P., 2019, INT J RECENT TECHNOL, V8, P1
   Joshi K. A., 2012, INT J SOFT COMPUT EN, V2, P44
   Joshi RC, 2019, INT J INTERACT MULTI, V5, P28, DOI 10.9781/ijimai.2019.01.001
   Kang HW, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0176244
   Ki S, 2020, IEEE ACCESS, V8, P228605, DOI 10.1109/ACCESS.2020.3046194
   Kim S, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P415, DOI 10.1109/IEMCON.2018.8614828
   Manikandan VP, 2022, IMAGE VISION COMPUT, V120, DOI 10.1016/j.imavis.2022.104406
   Manogaran G, 2020, MULTIMED TOOLS APPL, V79, P16155, DOI 10.1007/s11042-019-7526-3
   McClendon Lawrence., 2015, MACHINE LEARNING APP, V2, DOI [DOI 10.5121/MLAIJ.2015.2101, 10.5121/mlaij.2015.2101, https://doi.org/10.5121/mlaij.2015.2101]
   Navalgund U. V., 2018, P 2018 INT C CIRC SY, P1, DOI DOI 10.1109/ICCSDET.2018.8821168
   Nguyen T.T, 2017, J ADV INFORMAT TECHN, V8
   Obuandike Georgina N., 2015, INT J ADV RES ARTIF, V4, DOI [10.14569/IJARAI.2015.041207, DOI 10.14569/IJARAI.2015.041207]
   Prithi S., 2020, International Journal of Computer Science and Mobile Computing, V9, P221
   Qin ZX, 2021, ADV SCI, V8, DOI 10.1002/advs.202100001
   Rummens A, 2017, APPL GEOGR, V86, P255, DOI 10.1016/j.apgeog.2017.06.011
   Saleem N, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104389
   Selvaganapathy S, 2018, INF SECUR J, V27, P145, DOI 10.1080/19393555.2018.1456577
   Selvaraj A, 2020, COMPUT INTELL-US, V36, P1569, DOI 10.1111/coin.12292
   Shah N, 2021, VIS COMPUT IND BIOME, V4, DOI 10.1186/s42492-021-00075-z
   Shojaee Somayeh, 2013, International Journal of Digital Content Technology and its Applications, V7, P361, DOI 10.4156/jdcta.vol7.issue9.43
   Socha R, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12156210
   Stalidis P, 2018, FORECASTING
   Sujatha R., 2013, INT J SOC APPLICA CO, V2, P229
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun C. C., 2014, Journal of Digital Information Management, V12, P321
   Sung CS, 2021, MULTIMED TOOLS APPL, V80, P34297, DOI 10.1007/s11042-021-10809-z
   Tabedzki C., 2018, HOME BEL AIR PREDICT, P520
   Tsakanikas V, 2018, COMPUT ELECTR ENG, V70, P736, DOI 10.1016/j.compeleceng.2017.11.011
   Tung F, 2011, IMAGE VISION COMPUT, V29, P230, DOI 10.1016/j.imavis.2010.11.003
   Tyagi D., 2018, Int. J. Eng. Technol. Manag. Res., V5, P67
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Vanhoenshoven F, 2018, SMART INNOV SYST TEC, V72, P255, DOI 10.1007/978-3-319-59421-7_24
   Yi SH, 2022, IMAGE VISION COMPUT, V120, DOI 10.1016/j.imavis.2022.104397
   Liu Y, 2021, CONNECT SCI, V33, P719, DOI 10.1080/09540091.2021.1875987
   Zhang HZ, 2020, IEEE ACCESS, V8, P45343, DOI 10.1109/ACCESS.2020.2978247
   Zhu Q, 2019, INFORM MANAGE
NR 51
TC 12
Z9 13
U1 5
U2 32
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104467
DI 10.1016/j.imavis.2022.104467
EA MAY 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L9ND
UT WOS:000799606300008
DA 2024-07-18
ER

PT J
AU Zhang, ZJ
   Chang, Y
   Zhong, S
   Yan, LX
   Zou, X
AF Zhang, Zhijun
   Chang, Yi
   Zhong, Sheng
   Yan, Luxin
   Zou, Xu
TI Learning dynamic background for weakly supervised moving object
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Moving object detection; Dynamic background; Data-driven discriminative
   prior; Low-rank framework
ID ROBUST MATRIX FACTORIZATION; LOW-RANK; ALGORITHMS; IMAGE
AB Moving Object Detection (MOD) aims at extracting foreground moving objects in videos from static cameras. While low-rank based approaches have achieved impressive success in the MOD task, their performance remains limited on dynamics background scenes. The main reason is that dynamic clutters, e.g., swaying leaves and rippers, are easy to mix up with moving objects in the decomposition model which simply classify the sparse noise as foregrounds. In order to improve the generalization ability of low-rank based moving object detectors, we suggest adding an explicit dynamic clutter component in the decomposition framework with realistic dynamic background modeling. Then the dynamic clutter can be learned through object-free video data due to their self similarity across time and space. Thus, the moving objects can be naturally separated by a tensor-based decomposition model which formulates the static background by a unidirectional low-rank tensor, learns the dynamic clutter by a two-stream neural network, and constrains moving objects with spatiotemporal continuity. To further provide a more accurate object detection result, an objectness prior is embedded into our model in an attention manner. Extensive experimental results on the challenging datasets of dynamic background clearly demonstrate the superior performance of our model over the state-of-the-art in terms of quantitative metrics and visual quality.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhang, Zhijun; Chang, Yi; Zhong, Sheng; Yan, Luxin; Zou, Xu] Huazhong Univ Sci & Technol, Wuhan, Peoples R China.
   [Chang, Yi] Pengcheng Lab, Shenzhen, Peoples R China.
C3 Huazhong University of Science & Technology
RP Zhang, ZJ; Zou, X (corresponding author), Huazhong Univ Sci & Technol, Wuhan, Peoples R China.
EM zhangzhijun@hust.edu.cn
RI 辛, 雨菲/JBS-6390-2023; Zhang, Zhijun/HTN-1545-2023
OI Zhang, Zhijun/0000-0001-6916-2356
FU National Natural Science Foundation of China (NSFC) [62176100]; Central
   Guidance on Local Sci-ence and Technology Development Fund of Hubei
   Province [2021BEE056]
FX Acknowledgements This work is supported by the National Natural Science
   Foundation of China (NSFC) grant 62176100, and the Central Guidance on
   Local Sci-ence and Technology Development Fund of Hubei Province grant
   2021BEE056.
CR [Anonymous], 1987, READINGS COMPUTER VI, DOI DOI 10.1016/B978-0-08-051581-6.50057-X
   Bakkay MC, 2018, IEEE IMAGE PROC, P4018, DOI 10.1109/ICIP.2018.8451603
   Bouwmans T, 2019, NEURAL NETWORKS, V117, P8, DOI 10.1016/j.neunet.2019.04.024
   Bouwmans T, 2014, COMPUT VIS IMAGE UND, V122, P22, DOI 10.1016/j.cviu.2013.11.009
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brutzer S., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P1937, DOI 10.1109/CVPR.2011.5995508
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Cao XC, 2016, IEEE T CYBERNETICS, V46, P1014, DOI 10.1109/TCYB.2015.2419737
   Cao ZH, 2020, IEEE T FUZZY SYST, V28, P14, DOI 10.1109/TFUZZ.2019.2905823
   Chang Y, 2017, PROC CVPR IEEE, P5901, DOI 10.1109/CVPR.2017.625
   Chen BH, 2014, IEEE T MULTIMEDIA, V16, P837, DOI 10.1109/TMM.2014.2298377
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Cui XY, 2012, LECT NOTES COMPUT SC, V7572, P612, DOI 10.1007/978-3-642-33718-5_44
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Ebadi SE, 2018, IEEE T PATTERN ANAL, V40, P2273, DOI 10.1109/TPAMI.2017.2745573
   Everingham M, 2012, PASCAL VISUAL OBJECT
   Fazel M., 2002, THESIS STANFORD U ST
   Gao Z, 2014, IEEE T PATTERN ANAL, V36, P1975, DOI 10.1109/TPAMI.2014.2314663
   Guyon C, 2012, IEEE IMAGE PROC, P1225, DOI 10.1109/ICIP.2012.6467087
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Hu WR, 2017, IEEE T IMAGE PROCESS, V26, P724, DOI 10.1109/TIP.2016.2627803
   Hu ZX, 2020, IEEE ACCESS, V8, P41026, DOI 10.1109/ACCESS.2020.2977273
   Javed S., INT C IM CRIM PREV D, P1
   Javed S, 2017, IEEE T IMAGE PROCESS, V26, P5840, DOI 10.1109/TIP.2017.2746268
   Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711
   Kingma D. P., 2014, arXiv
   Lefkimmiatis S, 2018, PROC CVPR IEEE, P3204, DOI 10.1109/CVPR.2018.00338
   Li LY, 2004, IEEE T IMAGE PROCESS, V13, P1459, DOI 10.1109/TIP.2004.836169
   Li S. Z., 2009, Markov random field modeling in image analysis
   Lim LA, 2020, PATTERN ANAL APPL, V23, P1369, DOI 10.1007/s10044-019-00845-9
   Lim LA, 2018, PATTERN RECOGN LETT, V112, P256, DOI 10.1016/j.patrec.2018.08.002
   Liu X, 2015, IEEE T IMAGE PROCESS, V24, P2502, DOI 10.1109/TIP.2015.2419084
   Lu CY, 2020, IEEE T PATTERN ANAL, V42, P925, DOI 10.1109/TPAMI.2019.2891760
   Mazumder R, 2010, J MACH LEARN RES, V11, P2287
   Meng DY, 2013, IEEE I CONF COMP VIS, P1337, DOI 10.1109/ICCV.2013.169
   Mu Y, 2020, PATTERN RECOGN LETT, V130, P4, DOI 10.1016/j.patrec.2018.12.012
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Shakeri M, 2017, IEEE I CONF COMP VIS, P5133, DOI 10.1109/ICCV.2017.548
   Shakeri M, 2016, COMPUT VIS IMAGE UND, V146, P27, DOI 10.1016/j.cviu.2016.02.009
   Sobral A, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P946, DOI 10.1109/ICCVW.2015.125
   Sobral A, 2014, COMPUT VIS IMAGE UND, V122, P4, DOI 10.1016/j.cviu.2013.12.005
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Tezcan MO, 2020, IEEE WINT CONF APPL, P2763, DOI [10.1109/WACV45572.2020.9093464, 10.1109/wacv45572.2020.9093464]
   Tezcan MO, 2021, IEEE ACCESS, V9, P53849, DOI 10.1109/ACCESS.2021.3071163
   Tian YL, 2012, MACH VISION APPL, V23, P967, DOI 10.1007/s00138-011-0377-1
   Tom AJ, 2020, IEEE T IMAGE PROCESS, V29, P7590, DOI 10.1109/TIP.2020.3004696
   Wang NY, 2013, IEEE I CONF COMP VIS, P1785, DOI 10.1109/ICCV.2013.224
   Wang Y, 2014, IEEE COMPUT SOC CONF, P393, DOI 10.1109/CVPRW.2014.126
   Xin B, 2015, PROC CVPR IEEE, P4676, DOI 10.1109/CVPR.2015.7299099
   Xu J, 2013, IEEE I CONF COMP VIS, P3376, DOI 10.1109/ICCV.2013.419
   Yang JY, 2020, SIGNAL PROCESS, V168, DOI 10.1016/j.sigpro.2019.107362
   Yang WH, 2017, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2017.183
   Yang YC, 2019, PROC CVPR IEEE, P879, DOI 10.1109/CVPR.2019.00097
   Yong HW, 2018, IEEE T PATTERN ANAL, V40, P1726, DOI 10.1109/TPAMI.2017.2732350
   Zeng DD, 2019, IEEE ACCESS, V7, P153869, DOI 10.1109/ACCESS.2019.2899348
   Zeng DD, 2018, IEEE ACCESS, V6, P16010, DOI 10.1109/ACCESS.2018.2817129
   Zhang K, 2017, IEEE T IMAGE PROCESS, V26, P3142, DOI 10.1109/TIP.2017.2662206
   Zhang ZM, 2017, IEEE T SIGNAL PROCES, V65, P1511, DOI 10.1109/TSP.2016.2639466
   Zhang ZM, 2014, PROC CVPR IEEE, P3842, DOI 10.1109/CVPR.2014.485
   Zhao Q, 2014, PR MACH LEARN RES, V32, P55
   Zhou T., 2011, P ICML, P33
   Zhou XW, 2013, IEEE T PATTERN ANAL, V35, P597, DOI 10.1109/TPAMI.2012.132
NR 63
TC 4
Z9 4
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104425
DI 10.1016/j.imavis.2022.104425
EA MAR 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0N8RO
UT WOS:000783099100005
DA 2024-07-18
ER

PT J
AU Fu, H
   Zhang, K
   Li, HY
   Wang, JY
   Wang, Z
AF Fu, Hui
   Zhang, Ke
   Li, Haoyu
   Wang, Jingyu
   Wang, Zhen
TI Spatial temporal and channel aware network for video-based person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video-based Re-ID; Spatial temporal feature; Channel segmentation;
   Groupshuffle convolution
AB As a challenging computer vision task, video-based person Re-IDentification (Re-ID) has been intensively stud-ied, and recent works have achieved a series of satisfactory results by capturing spatial temporal relationships. However, extensive observations have found that the same feature vector generated by a convolutional neural network contains considerable redundant information in the channel dimension. This issue is seldom investi-gated. A Spatial Temporal and Channel Aware Network (STCAN) for video-based ReID is studied in this paper. It jointly considers spatial temporal and channel information. Firstly, the Spatial Attention Enhanced (SAE) convolutional network is developed as the backbone network to learn spatial enhanced features from video frames. Secondly, a Channel Segmentation and Group Shuffle (CSGS) convolution module is designed to jointly address temporal and channel relations. Finally, a Two Branch Weighted Fusion (TBWF) mechanism is intro-duced to enhance the robustness of the Re-ID network by fusing the output of the SAE backbone network and CSGS. Comprehensive experiments are conducted on three large-scale datasets MARS, LSVID, and P-DESTRE. The experimental results imply that the STCAN can effectively improve the performance of video-based Re-ID and outperform several state-of-the-art methods.(c) 2021 Published by Elsevier B.V.
C1 [Fu, Hui; Zhang, Ke; Li, Haoyu; Wang, Jingyu] Northwestern Polytech Univ, Sch Astronaut, Xian 710072, Peoples R China.
   [Wang, Jingyu; Wang, Zhen] Northwestern Polytech Univ, Sch Artificial Intelligence OPt & Elect iOPEN, Xian 710072, Peoples R China.
C3 Northwestern Polytechnical University; Northwestern Polytechnical
   University
RP Li, HY (corresponding author), Northwestern Polytech Univ, Sch Astronaut, Xian 710072, Peoples R China.
EM fuhuinova@mail.nwpu.edu.cn; zhangke@nwpu.edu.cn; lihaoyu@nwpu.edu.cn;
   jywang@nwpu.edu.cn; zhenwang0@gmail.com
RI LI, HAOYU/AAK-5564-2020; Wang, Jingyu/GQH-5898-2022; Fu,
   Hui/JFT-0778-2023
OI LI, HAOYU/0000-0001-9056-291X; Fu, Hui/0000-0003-2519-0712
FU National Natural Science Foun-dation of China [61502391, U1803263];
   Innovation Capability Support Program of Shaanxi [2021KJXX-103]; Key
   Technology Research and Devel-opment Program of Science and
   Technology-Scientific and Technologi-cal Innovation Team of Shaanxi
   Province [2020TD-013]
FX Acknowledgments This work is supported in part by the National Natural
   Science Foun-dation of China under Grant 61502391 and U1803263, and in
   part by the Innovation Capability Support Program of Shaanxi under Grant
   2021KJXX-103, and in part by the Key Technology Research and
   Devel-opment Program of Science and Technology-Scientific and
   Technologi-cal Innovation Team of Shaanxi Province under Grant
   2020TD-013.
CR [Anonymous], ARXIV161203928
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen Q., 2013, ARXIV131254400
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   Dai J, 2019, IEEE T IMAGE PROCESS, V28, P1366, DOI 10.1109/TIP.2018.2878505
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Gao Jinyang., 2018, CoRR
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gong WC, 2020, NEUROCOMPUTING, V383, P295, DOI 10.1016/j.neucom.2019.11.050
   Gu XQ, 2019, IEEE I CONF COMP VIS, P9646, DOI 10.1109/ICCV.2019.00974
   Han K, 2020, PROC CVPR IEEE, P1577, DOI 10.1109/CVPR42600.2020.00165
   Hermans Alexander, 2017, ARXIV170307737
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Islam K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103970
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar SVA, 2021, IEEE T INF FOREN SEC, V16, P1696, DOI 10.1109/TIFS.2020.3040881
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li JN, 2019, AAAI CONF ARTIF INTE, P8618
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li XL, 2020, IEEE T IMAGE PROCESS, V29, P5571, DOI 10.1109/TIP.2020.2985284
   Li XL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2201
   Li XL, 2017, AAAI CONF ARTIF INTE, P4147
   Liu GQ, 2021, IMAGE VISION COMPUT, V106, DOI 10.1016/j.imavis.2020.104068
   Liu YH, 2019, AAAI CONF ARTIF INTE, P8786
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Lv JY, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103875
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Qiu ZF, 2017, IEEE I CONF COMP VIS, P5534, DOI 10.1109/ICCV.2017.590
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Rao S., 2018, ARXIV181011261
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Sifre Laurent, 2014, ARXIV14031687, P1, DOI [10.48550/arXiv.1403.1687, DOI 10.48550/ARXIV.1403.1687]
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song WR, 2021, APPL INTELL, V51, P788, DOI 10.1007/s10489-020-01844-8
   Subramaniam A, 2019, IEEE I CONF COMP VIS, P562, DOI 10.1109/ICCV.2019.00065
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Wang JY, 2022, IEEE T CYBERNETICS, V52, P10393, DOI 10.1109/TCYB.2021.3069836
   Wang JY, 2022, IEEE T NEUR NET LEAR, V33, P3634, DOI 10.1109/TNNLS.2021.3053840
   Wang Q, 2020, INT SYM QUAL ELECT, P1, DOI [10.1109/isqed48828.2020.9137057, 10.1109/ISQED48828.2020.9137057, 10.1109/CVPR42600.2020.01155]
   Wang ZW, 2019, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.2019.00066
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yaghoubi E, 2021, PATTERN RECOGN LETT, V143, P50, DOI 10.1016/j.patrec.2020.12.017
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yuan P., 2020, ARXIV201007621
   Zhang HY, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277958
   Zhang RM, 2019, IEEE T IMAGE PROCESS, V28, P4870, DOI 10.1109/TIP.2019.2911488
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhang ZZ, 2020, INT CONF CONDIT MON, P404, DOI 10.1109/CVPR42600.2020.01042
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
NR 59
TC 6
Z9 6
U1 0
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2022
VL 118
AR 104356
DI 10.1016/j.imavis.2021.104356
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0F3OZ
UT WOS:000777273700003
DA 2024-07-18
ER

PT J
AU Samet, N
   Akbas, E
AF Samet, Nermin
   Akbas, Emre
TI HPRNet: Hierarchical point regression for whole-body human pose
   estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Whole-body human pose estimation; Multi-person pose estimation; Facial
   landmark detection; Bottom-up human pose estimation; Hand keypoint
   Estimation
AB In this paper, we present a newbottom-up one-stage method for whole-body pose estimation, which we call "hierarchical point regression," or HPRNet for short. In standard body pose estimation, the locations of similar to 17 major joints on the human body are estimated. Differently, in whole-body pose estimation, the locations of finegrained keypoints (68 on face, 21 on each hand and 3 on each foot) are estimated as well, which creates a scale variance problem that needs to be addressed. To handle the scale variance among different body parts, we build a hierarchical point representation of body parts and jointly regress them. The relative locations of fine-grained keypoints in each part (e.g. face) are regressed in reference to the center of that part, whose location itself is estimated relative to the person center. In addition, unlike the existing two-stage methods, our method predicts whole-body pose in a constant time independent of the number of people in an image. On the COCO WholeBody dataset, HPRNet significantly outperforms all previous bottom-up methods on the keypoint detection of all whole-body parts (i.e. body, foot, face and hand); it also achieves state-of-the-art results on face (75.4 AP) and hand (50.4 AP) keypoint detection. Code and models are available at https://github. com/nerminsamet/HPRNet.git. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Samet, Nermin; Akbas, Emre] Middle East Tech Univ, Ankara, Turkey.
C3 Middle East Technical University
RP Samet, N (corresponding author), Middle East Tech Univ, Ankara, Turkey.
EM nermin@ceng.metu.edu.tr; emre@ceng.metu.edu.tr
RI Akbas, Emre/B-6857-2008; Samet, Nermin/ABA-3888-2020
OI Akbas, Emre/0000-0002-3760-6722; Samet, Nermin/0000-0001-9247-2504
CR [Anonymous], 2017, IEEE INT S CIRC SYST
   [Anonymous], 2020, HUAWEI ML KITS FACE
   Bulat A, 2016, LECT NOTES COMPUT SC, V9911, P717, DOI 10.1007/978-3-319-46478-7_44
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Cao Z, 2021, IEEE T PATTERN ANAL, V43, P172, DOI 10.1109/TPAMI.2019.2929257
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Choi H., 2020, COMPUTER VISION ECCV, P769
   Cimen Gokcen, 2018, 12 INT C COMP GRAPH
   Deng JK, 2020, PROC CVPR IEEE, P5202, DOI 10.1109/CVPR42600.2020.00525
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Elhayek A, 2018, LECT NOTES COMPUT SC, V11162, P28, DOI 10.1007/978-3-030-01790-3_3
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   He Kaiming, 2017, P IEEE INT C COMPUTE
   Hidalgo G, 2019, IEEE I CONF COMP VIS, P6981, DOI 10.1109/ICCV.2019.00708
   Huang LJ, 2019, PATTERN RECOGN, V92, P165, DOI 10.1016/j.patcog.2019.03.010
   Insafutdinov E, 2017, PROC CVPR IEEE, P1293, DOI 10.1109/CVPR.2017.142
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Iqbal U., ARXIV210413502, V2021
   Iqbal U, 2017, PROC CVPR IEEE, P4654, DOI 10.1109/CVPR.2017.495
   Jin S., 2020, COMPUTER VISION ECCV, P196
   Jin S, 2019, PROC CVPR IEEE, P5657, DOI 10.1109/CVPR.2019.00581
   Jin Sheng, 2017, ICCV PoseTrack Workshop
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   King DB, 2015, ACS SYM SER, V1214, P1
   Kocabas M, 2018, LECT NOTES COMPUT SC, V11215, P437, DOI 10.1007/978-3-030-01252-6_26
   Kumarapu L, 2021, PATTERN RECOGN LETT, V147, P16, DOI 10.1016/j.patrec.2021.03.028
   Kundu J.N., 2020, EUR C COMP VIS
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Newell A., 2016, ARXIV161105424
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Oberweger M., 2015, Hands deep in deep learning for hand pose estimation, P21, DOI DOI 10.1177/0093650215617505
   Oberweger M, 2017, IEEE INT CONF COMP V, P585, DOI 10.1109/ICCVW.2017.75
   Papandreou G, 2018, LECT NOTES COMPUT SC, V11218, P282, DOI 10.1007/978-3-030-01264-9_17
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Paszke A, 2019, ADV NEUR IN, V32
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Samet N., HOUGHNET INTEGRATING, V2021
   Samet N., 2020, EUR C COMP VIS
   Sharp T, 2015, CHI 2015: PROCEEDINGS OF THE 33RD ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, P3633, DOI 10.1145/2702123.2702179
   Sridhar S, 2015, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2015.7298941
   Sun K., 2019, P IEEE C COMPUTER VI, DOI DOI 10.48550/ARXIV.1904.04514
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Trigeorgis G, 2016, PROC CVPR IEEE, P4177, DOI 10.1109/CVPR.2016.453
   Tzimiropoulos G, 2015, PROC CVPR IEEE, P3659, DOI 10.1109/CVPR.2015.7298989
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xu WP, 2019, IEEE T VIS COMPUT GR, V25, P2093, DOI 10.1109/TVCG.2019.2898650
   Yan A, 2019, PROC CVPR IEEE, P7914, DOI 10.1109/CVPR.2019.00811
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang ZP, 2016, IEEE T PATTERN ANAL, V38, P918, DOI 10.1109/TPAMI.2015.2469286
   Zhou X., 2019, ABS190407850 ARXIV
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
NR 59
TC 7
Z9 7
U1 2
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104285
DI 10.1016/j.imavis.2021.104285
EA SEP 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WC6NH
UT WOS:000704372400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wilms, C
   Frintrop, S
AF Wilms, Christian
   Frintrop, Simone
TI DeepFH segmentations for superpixel-based object proposal refinement
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object proposals; Image segmentation; Superpixels
AB Class-agnostic object proposal generation is an important first step in many object detection pipelines. However, object proposals of modern systems are rather inaccurate in terms of segmentation and only roughly adhere to object boundaries. Since typical refinement steps are usually not applicable to thousands of proposals, we pro -pose a superpixel-based refinement system for object proposal generation systems. Utilizing precise superpixels and superpixel pooling on deep features, we refine initial coarse proposals in an end-to-end learned system. Fur-thermore, we propose a novel DeepFH segmentation, which enriches the classic Felzenszwalb and Huttenlocher (FH) segmentation with deep features leading to improved segmentation results and better object proposal re-finements. On the COCO dataset with LVIS annotations, we show that our refinement based on DeepFH superpixels outperforms state-of-the-art methods and leads to more precise object proposals. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wilms, Christian; Frintrop, Simone] Univ Hamburg, Dept Informat, Vogt Koelln Str 30, D-22527 Hamburg, Germany.
C3 University of Hamburg
RP Wilms, C (corresponding author), Univ Hamburg, Dept Informat, Vogt Koelln Str 30, D-22527 Hamburg, Germany.
EM wilms@informatik.uni-hamburg.de; frintrop@informatik.uni-hamburg.de
RI Wilms, Christian/IUP-4926-2023
OI Frintrop, Simone/0000-0002-9475-3593
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ahn J, 2019, PROC CVPR IEEE, P2204, DOI 10.1109/CVPR.2019.00231
   Ahn J, 2018, PROC CVPR IEEE, P4981, DOI 10.1109/CVPR.2018.00523
   [Anonymous], 2015, ADV NEURAL INF PROCE
   [Anonymous], CoRR abs/1511.07122
   [Anonymous], 2017, ARXIV170205711
   Chen LC, 2018, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2018.00422
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Gidaris S., 2016, arXiv preprint arXiv:1606.04446
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gupta A, 2019, PROC CVPR IEEE, P5351, DOI 10.1109/CVPR.2019.00550
   He K., 2017, IEEE C COMP VIS PATT, P2961, DOI DOI 10.1109/ICCV.2017.322
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   He Y, 2017, PROC CVPR IEEE, P7158, DOI 10.1109/CVPR.2017.757
   Hosang Jan, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P814, DOI 10.1109/TPAMI.2015.2465908
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hu HX, 2017, PROC CVPR IEEE, P2280, DOI 10.1109/CVPR.2017.245
   Jampani V, 2018, LECT NOTES COMPUT SC, V11211, P363, DOI 10.1007/978-3-030-01234-2_22
   Kirillov A., CVPR 2020, P9799
   Kwak S, 2017, AAAI CONF ARTIF INTE, P4111
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li RY, 2018, PROC CVPR IEEE, P5745, DOI 10.1109/CVPR.2018.00602
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Luengo I., BMVC 2016
   Ming-Yu Liu, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2097, DOI 10.1109/CVPR.2011.5995323
   Park H., 2017, BMVC
   Pinheiro P.O., NIPS 2015, P1990
   Pinheiro PO, 2016, LECT NOTES COMPUT SC, V9905, P75, DOI 10.1007/978-3-319-46448-0_5
   Pont-Tuset J, 2017, IEEE T PATTERN ANAL, V39, P128, DOI 10.1109/TPAMI.2016.2537320
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   sep A. O, ICRA 2020, P10031
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   Tu WC, 2018, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.2018.00066
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Wilms C., ICPR 2020, P4996
   Wilms C., GCPR 2017, P333
   Wilms C., ACCV 2018, P678
   Wilms C., ICPR 2020, P4965
   Yang F., CVPR 2020, P13964
   Yao J, 2015, PROC CVPR IEEE, P2947, DOI 10.1109/CVPR.2015.7298913
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
NR 43
TC 2
Z9 2
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2021
VL 114
AR 104263
DI 10.1016/j.imavis.2021.104263
EA AUG 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UR9HP
UT WOS:000697051200007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tang, WM
   Qiu, GP
AF Tang, Wenming
   Qiu, Guoping
TI Dense graph convolutional neural networks on 3D meshes for 3D object
   segmentation and classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D meshes; Graph neural network; Densely connected; Classification;
   Segmentation
AB This paper presents new designs of graph convolutional neural networks (GCNs) on 3D meshes for 3D object segmentation and classification. We use the faces of the mesh as basic processing units and represent a 3D mesh as a graph where each node corresponds to a face. To enhance the descriptive power of the graph, we introduce a 1 ring face neighborhood structure to derive novel multi-dimensional spatial and structure features to represent the graph nodes. Based on this new graph representation, we then design a densely connected graph convolutional block which aggregates local and regional features as the key construction component to build effective and efficient practical GCN models for 3D object classification and segmentation. We present experimental results to show that our new technique performs comparably to state of the art across a number of benchmark datasets where our models are also shown to have smaller number of parameters. We also present ablation studies to demonstrate the soundness of our design principles and the effectiveness of our practical models. (c) 2021 Published by Elsevier B.V.
C1 [Tang, Wenming; Qiu, Guoping] Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen, Peoples R China.
   [Tang, Wenming; Qiu, Guoping] Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.
   [Tang, Wenming; Qiu, Guoping] Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen, Peoples R China.
   [Qiu, Guoping] Univ Nottingham, Sch Comp Sci, Nottingham, England.
C3 Shenzhen University; Shenzhen University; Shenzhen Institute of
   Artificial Intelligence & Robotics for Society; University of Nottingham
RP Qiu, GP (corresponding author), Shenzhen Univ, Coll Elect & Informat Engn, Shenzhen, Peoples R China.; Qiu, GP (corresponding author), Shenzhen Univ, Guangdong Key Lab Intelligent Informat Proc, Shenzhen, Peoples R China.; Qiu, GP (corresponding author), Shenzhen Inst Artificial Intelligence & Robot Soc, Shenzhen, Peoples R China.; Qiu, GP (corresponding author), Univ Nottingham, Sch Comp Sci, Nottingham, England.
EM guoping.qiu@nottingham.ac.uk
RI 辛, 雨菲/JBS-6390-2023
OI Qiu, Guoping/0000-0002-5877-5648
FU Education Department of Guangdong Province, PR China [2019KZDZX1028]
FX This work is partially supported by the Education Department of
   Guangdong Province, PR China, under project No 2019KZDZX1028.
CR Ahmed E., ARXIV180801462
   Anguelov D, 2005, ACM T GRAPHIC, V24, P408, DOI 10.1145/1073204.1073207
   [Anonymous], ARXIV180700652
   Bastings J., ARXIV170404675
   Bogo F, 2014, PROC CVPR IEEE, P3794, DOI 10.1109/CVPR.2014.491
   Bronstein AM, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1899404.1899405
   Bruna J., ARXIV PREPRINT ARXIV
   Bu R., ARXIV180107791
   Choi H, ARXIV200809047
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dominguez M, 2017, IEEE IMAGE PROC, P3929, DOI 10.1109/ICIP.2017.8297019
   Ezuz D, 2017, COMPUT GRAPH FORUM, V36, P49, DOI 10.1111/cgf.13244
   Feng Y, MESHNET MESH NEURAL, DOI [10.1609/AAAI.V33I01.33018279, DOI 10.1609/AAAI.V33I01.33018279]
   Fout A, 2017, ADV NEUR IN, V30
   Giorgi Daniela, 2007, SHREC Competition, V8
   Guo ZJ, 2019, T ASSOC COMPUT LING, V7, P297, DOI 10.1162/tacl_a_00269
   Haim N, 2019, IEEE I CONF COMP VIS, P632, DOI 10.1109/ICCV.2019.00072
   Hamaguchi T., ARXIV170605674
   Hanocka R, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322959
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Huang J., ARXIV180201698
   King DB, 2015, ACS SYM SER, V1214, P1
   Kipf T.N., 2017, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Kostrikov I, 2018, PROC CVPR IEEE, P2540, DOI 10.1109/CVPR.2018.00269
   Kumawat S, 2019, PROC CVPR IEEE, P4898, DOI 10.1109/CVPR.2019.00504
   Lahav A, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3414685.3417806
   Larsson G., ARXIV160507648
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Litany O, 2018, PROC CVPR IEEE, P1886, DOI 10.1109/CVPR.2018.00202
   Maron H, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073616
   Masci J, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P832, DOI 10.1109/ICCVW.2015.112
   Meyer N, 2003, VISUALIZATION AND MATHEMATICS III, P35
   Milano F, C NEUR INF PROC SYST
   Poulenard A, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3272127.3275102
   Qi C., 2017, NeurIPS, P5105, DOI [10.1109/ CVPR.2017.16, DOI 10.1109/CVPR.2017.16]
   Sinha A, 2016, LECT NOTES COMPUT SC, V9910, P223, DOI 10.1007/978-3-319-46466-4_14
   Srivastava R. K., 2015, Advances in Neural Information Processing Systems, P2377
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Verma N, 2018, PROC CVPR IEEE, P2598, DOI 10.1109/CVPR.2018.00275
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Wang Y, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3326362
   Wang YH, 2012, ACM T GRAPHIC, V31, DOI 10.1145/2366145.2366184
   Wei X, 2020, PROC CVPR IEEE, P1847, DOI 10.1109/CVPR42600.2020.00192
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Wu ZZ, 2019, IEEE COMPUT GRAPH, V39, P77, DOI 10.1109/MCG.2019.2891634
   Xu KYL, 2018, PR MACH LEARN RES, V80
   Zhao HX, 2006, LECT NOTES COMPUT SC, V4035, P442
NR 53
TC 7
Z9 7
U1 4
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2021
VL 114
AR 104265
DI 10.1016/j.imavis.2021.104265
EA AUG 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UR9HP
UT WOS:000697051200002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Peng, JQ
   Liu, YQ
   Jiang, HC
AF Peng, Jingquan
   Liu, Yanqing
   Jiang, Haochen
TI Semantic and edge-based visual odometry by joint minimizing semantic and
   edge distance error
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Edge-based visual odometry; Semantic visual odometry; distance transform
   (DT); Edge alignment; Semantic segmentation
AB In recent years, the progress made in deep learning for semantic segmentation has advanced development of semantic visual odometry (VO). Along with point-based and direct methods, VO has recently used edge features. However, mismatches are common in scenes in which the distribution of edges is complex owing to the lack of appropriate descriptors for edges at the present. In this paper, we propose a semantic-segmentation-aided edge-based VO (DSEVO). It is intended to improve the localization accuracy by de-creasing mismatches in the edge alignment. In the reprojection process, the semantic and edge distance re-si dual are considered to reduce the mismatches of edges between different frames. Then, camera motion estimation is accomplished by jointly minimizing the semantic and edge cost function. Our proposed method was evaluated on the public VKITTI and TUM RGB-D datasets. It was compared with state-of-the-art methods, including the respective feature-point-based, direct, and edge-based methods. We imple-mented a semantic-edge-based VO system. The experimental results showed that our method achieved the highest accuracy on most of the testing sequences. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Peng, Jingquan; Liu, Yanqing; Jiang, Haochen] Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Biovis Syst Lab, Shanghai 200050, Peoples R China.
   [Peng, Jingquan; Jiang, Haochen] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Institute of Microsystem &
   Information Technology, CAS; Chinese Academy of Sciences; University of
   Chinese Academy of Sciences, CAS
RP Liu, YQ (corresponding author), Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Biovis Syst Lab, Shanghai 200050, Peoples R China.
EM pengjq@mail.sim.ac.cn; lyq@mail.sim.ac.cn; jianghc@mail.sim.ac.cn
OI Jiang, Haochen/0000-0003-3081-0891
FU National Natural Science Foundation of China [62003326]; Shanghai
   Municipal Science and Technology Major Project [2018SHZDZX01];
   (Zhangjiang Lab); Shanghai Sailing Program [20YF1457000]
FX This project was supported by the National Natural Science Foundation of
   China (Grant No.62003326), the Shanghai Municipal Science and Technology
   Major Project (No. 2018SHZDZX01, Zhangjiang Lab), and the Shanghai
   Sailing Program (No. 20YF1457000).
CR Acharjya P.P., 2012, Global Journal of Computer Science and Technology, V12, P28
   [Anonymous], 2018, PROC EUR C COMPUT VI
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Engel J, 2018, IEEE T PATTERN ANAL, V40, P611, DOI 10.1109/TPAMI.2017.2658577
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Fraundorfer Friedrich, 2017, BMVC
   Gaidon A, 2016, PROC CVPR IEEE, P4340, DOI 10.1109/CVPR.2016.470
   Gao X, 2018, IEEE INT C INT ROBOT, P2198, DOI 10.1109/IROS.2018.8593376
   Grupp Michael., EVO PYTHON PACKAGE E
   Huttenlocher, 2012, THEORY COMPUT, V8, P415, DOI [10.4086/toc.2012.v008a019, DOI 10.4086/TOC.2012.V008A019]
   Joshi S.R., 2013, 2012 3 AS HIM INT C
   Kendall Alex, 2017, ADV NEURAL INFORM PR, V30, DOI DOI 10.5555/3295222.3295309
   Kerl C., 2012, THESIS TU
   Kim C., EDGE BASED VISUAL OD
   Klein George, 2007, P1
   Krombach N, 2018, ROBOT AUTON SYST, V109, P38, DOI 10.1016/j.robot.2018.08.002
   Kuse M, 2016, IEEE INT CONF ROBOT, P573, DOI 10.1109/ICRA.2016.7487181
   Li Peiliang, 2018, P ECCV, P646
   Maity S, 2017, IEEE INT CONF COMP V, P2408, DOI 10.1109/ICCVW.2017.284
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Narita G, 2019, IEEE INT C INT ROBOT, P4205, DOI [10.1109/IROS40897.2019.8967890, 10.1109/iros40897.2019.8967890]
   Podder P., 2018, 2018 INT C CURR TREN
   Schenk F, 2019, IEEE INT CONF ROBOT, P154, DOI [10.1109/icra.2019.8794462, 10.1109/ICRA.2019.8794462]
   Schenk F, 2017, IEEE INT C INT ROBOT, P1297, DOI 10.1109/IROS.2017.8202305
   Schönberger JL, 2018, PROC CVPR IEEE, P6896, DOI 10.1109/CVPR.2018.00721
   Schubert D., 2018, EUR C COMP VIS ECCV
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tardos JD, 2021, IEEE T ROBOT
   Wang R, 2017, IEEE I CONF COMP VIS, P3923, DOI 10.1109/ICCV.2017.421
   Wu X., 2019, ARXIV190400738
   Wu XL, 2020, IEEE INT C INT ROBOT, P4923, DOI 10.1109/IROS45743.2020.9341052
   Xu JG, 2020, IEEE INFOCOM SER, P1828, DOI [10.1109/INFOCOM41043.2020.9155438, 10.1109/infocom41043.2020.9155438]
   Yi Zhou, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P6261, DOI 10.1109/ICRA.2017.7989742
   Yu C, 2018, IEEE INT C INT ROBOT, P1168, DOI 10.1109/IROS.2018.8593691
   Yu X, 2018, IEEE INT C INT ROBOT, P3196, DOI 10.1109/IROS.2018.8594358
   Yu ZD, 2017, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2017.191
   Zaganidis A, 2018, IEEE ROBOT AUTOM LET, V3, P2942, DOI 10.1109/LRA.2018.2848308
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhou Y, 2019, IEEE T ROBOT, V35, P184, DOI 10.1109/TRO.2018.2875382
NR 39
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104240
DI 10.1016/j.imavis.2021.104240
EA JUL 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900008
DA 2024-07-18
ER

PT J
AU Chen, J
   Samuel, RDJ
   Poovendran, P
AF Chen, Jun
   Samuel, R. Dinesh Jackson
   Poovendran, Parthasarathy
TI LSTM with bio inspired algorithm for action recognition in sports videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Spatial pyramid pooling SPP-net; Long short term
   memory networks (LSTM) with bio-inspired algorithm (BIA) framework
AB Nowadays, Sport-related movement recognition plays an essential part in the wellbeing of people's lives. The mention of human movements and gestures is often studied in sports to help analyze, guide, and evaluate activity. The automatic detection of sports-related signals helps find the injuries or indirect physical issues in the human body. Action recognition patterns with complicated motion status and periodicity in sports games can help to more accurately estimate the duration of successful action states. Actions are recognized by identifying the activity in a clip. Quality evaluation of action assigns a quantitative score based on the performance of the action. Based on the score, the action states are analyzed. The main issue of sports game identification correctly tracks the behavior of sportspeople. In this paper, Long Short Term Memory networks (LSTM) with a Bioinspired Algorithm (BIA) framework have been proposed to recognize the action of a sportsperson and motivate a person to improve sports skills. Action recognition and classification can also be used to produce matching or practice output statistics automatically. The proposed LSTM-BIA utilizes predefined actions by modeling the monitoring effects with discriminative temporal signals. It uses the Spatial pyramid pooling SPP-net to obtain the robust characteristic of each frame's tracked area. The new SPP-net network structure will produce an adjusted description irrespective of the scale and resolution of the object. It could be used for identification and entity recognition and enables variable-length image input into CNN. The experimental results show that the proposed method can evaluate the actual action of sportspersons with high accuracy when compared to other methods. (c) 2021 Published by Elsevier B.V.
C1 [Chen, Jun] Jingchu Univ Technol, Dept Phys Educ, Jingmen 448000, Hubei, Peoples R China.
   [Samuel, R. Dinesh Jackson] Oxford Brookes Univ, Fac Technol Design & Environm, Visual Artificial Intelligence Lab, Oxford, England.
   [Poovendran, Parthasarathy] Cloud Vantage Solut, Chennai, India.
C3 Jingchu University of Technology; Oxford Brookes University
RP Chen, J (corresponding author), Jingchu Univ Technol, Dept Phys Educ, Jingmen 448000, Hubei, Peoples R China.
EM chenjun1163@sina.com
RI Samuel, Dinesh Jackson/AAG-7420-2019
OI Samuel, Dinesh Jackson/0000-0002-1582-7161
CR Bavelier D, 2019, NEURON, V104, P147, DOI 10.1016/j.neuron.2019.09.031
   Cust EE, 2019, J SPORT SCI, V37, P568, DOI 10.1080/02640414.2018.1521769
   Khan MA, 2024, MULTIMED TOOLS APPL, V83, P14885, DOI 10.1007/s11042-020-08806-9
   Kim C, 2019, SUSTAINABILITY-BASEL, V11, DOI 10.3390/su11205687
   Loia Vincenzo, 2019, Journal of Physical Education and Sport, V19, P1740, DOI 10.7752/jpes.2019.s5254
   Lokesh S, 2019, NEURAL COMPUT APPL, V31, P1521, DOI 10.1007/s00521-018-3466-5
   Mathan K, 2018, DES AUTOM EMBED SYST, V22, P225, DOI 10.1007/s10617-018-9205-4
   Muthu B., 2020, ACM T ASIAN LOW RESO, P1
   Qi MS, 2020, IEEE T CIRC SYST VID, V30, P549, DOI 10.1109/TCSVT.2019.2894161
   Rahmad N.A., 2019, Indonesian Journal of Electrical Engineering and Computer Science, V14, P1330, DOI 10.11591/ijeecs.v14.i3.pp1330-1335
   Rajsp A, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10093013
   Schmidt A, 2019, J COGN ENHANCE, V3, P281, DOI 10.1007/s41465-018-0096-x
   Shakeel PM, 2019, IEEE ACCESS, V7, P5577, DOI 10.1109/ACCESS.2018.2883957
   Sriram S, 2020, IEEE CONF COMPUT, P189, DOI 10.1109/INFOCOMWKSHPS50562.2020.9162668
   Tejero-de-Pablos A., 2016, 2016 IEEE INT C MULT, P1, DOI [10.1109/ICME.2016.7552938, DOI 10.1109/ICME.2016.7552938]
   Tejero-de-Pablos A, 2018, IEEE T MULTIMEDIA, V20, P2000, DOI 10.1109/TMM.2018.2794265
   Wang L, 2020, IEEE T IMAGE PROCESS, V29, P15, DOI 10.1109/TIP.2019.2925285
   Wang W, 2019, IEEE ACCESS, V7, P117165, DOI 10.1109/ACCESS.2019.2936604
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Yang Y, 2019, PATTERN RECOGN, V85, P60, DOI 10.1016/j.patcog.2018.07.030
   Yunwei Li, 2019, Journal of Physics: Conference Series, V1345, DOI 10.1088/1742-6596/1345/5/052008
   Zhou YZ, 2018, PROC CVPR IEEE, P449, DOI 10.1109/CVPR.2018.00054
NR 22
TC 30
Z9 30
U1 2
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104214
DI 10.1016/j.imavis.2021.104214
EA JUN 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100006
DA 2024-07-18
ER

PT J
AU Wu, Y
   Liu, Z
   Zhou, XF
   Ye, LW
   Wang, Y
AF Wu, Yong
   Liu, Zhi
   Zhou, Xiaofei
   Ye, Linwei
   Wang, Yang
TI ATCC: Accurate tracking by criss-cross location attention
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Target state estimation; Criss-Cross location attention
AB In recent years, discriminative correlation filters (DCF) and Siamese networks based trackers have significantly advanced the performance in tracking. However, the problem of accurate target state estimation is not fully solved yet. Therefore, in this paper, we propose a Criss-Cross Location Attention (CCLA) module, which pays more concerns to global and local contextual information and is used for the adaptation of IoU-Net based trackers. Besides, our CCLA module has capability of high computational efficiency with a slight increase of network parameters. Then, we present our tracker called ATCC, a Siamese architecture with CCLA. Finally, we evaluate our tracker on OTB100, VOT-2018, LaSOT, and TrackingNet benchmark datasets. Experimental results show that our tracker performs favorably against other state-of-the-art trackers, while operating at 30 FPS on single GPU. We will release the code and models at https://github.com/yongwuSHU/atcc.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wu, Yong; Liu, Zhi] Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.
   [Wu, Yong; Liu, Zhi] Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
   [Zhou, Xiaofei] Hangzhou Dianzi Univ, Inst Informat & Control, Hangzhou 310018, Peoples R China.
   [Ye, Linwei] Wenzhou Univ, Coll Comp Sci & Artificial Intelligence, Wenzhou 325035, Peoples R China.
   [Wang, Yang] Univ Manitoba, Dept Compter Sci, Winnipeg, MB R3T 2N2, Canada.
C3 Shanghai University; Shanghai University; Hangzhou Dianzi University;
   Wenzhou University; University of Manitoba
RP Liu, Z (corresponding author), Shanghai Univ, Shanghai Inst Adv Commun & Data Sci, Shanghai 200444, Peoples R China.; Liu, Z (corresponding author), Shanghai Univ, Sch Commun & Informat Engn, Shanghai 200444, Peoples R China.
EM liuzhisjtu@163.com
RI Zhang, Han/JMR-0670-2023; LIU, Zhi/D-4518-2012; WU, YONG/GWM-4056-2022
OI LIU, Zhi/0000-0002-8428-1131; WU, YONG/0000-0002-3256-6012
FU National Natural Science Foundation of China [61771301, 61901145]
FX This work has been supported by the National Natural Science Foundation
   of China under Grants 61771301 and 61901145.
CR [Anonymous], PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018
   [Anonymous], 2018, LECT NOTES COMPUT SC
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Bhat G, 2019, IEEE I CONF COMP VIS, P6181, DOI 10.1109/ICCV.2019.00628
   Bolme DS, 2010, PROC CVPR IEEE, P2544, DOI 10.1109/CVPR.2010.5539960
   Chen MY, 2020, NEUROCOMPUTING, V405, P259, DOI 10.1016/j.neucom.2020.03.090
   Danelljan M, 2019, PROC CVPR IEEE, P4655, DOI 10.1109/CVPR.2019.00479
   Danelljan M, 2017, PROC CVPR IEEE, P6931, DOI 10.1109/CVPR.2017.733
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Danelljan M, 2014, PROC CVPR IEEE, P1090, DOI 10.1109/CVPR.2014.143
   Fan H, 2019, PROC CVPR IEEE, P7944, DOI 10.1109/CVPR.2019.00814
   Fan H, 2019, PROC CVPR IEEE, P5369, DOI 10.1109/CVPR.2019.00552
   Fu J, 2019, PROC CVPR IEEE, P3141, DOI 10.1109/CVPR.2019.00326
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.128, 10.1109/ICCV.2017.129]
   Gongyang Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P665, DOI 10.1007/978-3-030-58520-4_39
   Guo Q, 2017, IEEE I CONF COMP VIS, P1781, DOI 10.1109/ICCV.2017.196
   He A., 2018, P EUR C COMP VIS ECC
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Henriques JF, 2012, LECT NOTES COMPUT SC, V7575, P702, DOI 10.1007/978-3-642-33765-9_50
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu W., 2017, ABS170404057 CORR
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Kristan M, 2019, LECT NOTES COMPUT SC, V11129, P3, DOI 10.1007/978-3-030-11009-3_1
   Li B, 2019, PROC CVPR IEEE, P4277, DOI 10.1109/CVPR.2019.00441
   Li B, 2018, PROC CVPR IEEE, P8971, DOI 10.1109/CVPR.2018.00935
   Li F, 2018, PROC CVPR IEEE, P4904, DOI 10.1109/CVPR.2018.00515
   Li GY, 2020, IEEE T IMAGE PROCESS, V29, P4873, DOI 10.1109/TIP.2020.2976689
   Li X, 2019, PROC CVPR IEEE, P1369, DOI 10.1109/CVPR.2019.00146
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lukezic A, 2017, PROC CVPR IEEE, P4847, DOI 10.1109/CVPR.2017.515
   Maybank S, 27 INT JOINT C ART I, P985
   Nam H, 2016, PROC CVPR IEEE, P4293, DOI 10.1109/CVPR.2016.465
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang Q, 2018, PROC CVPR IEEE, P4854, DOI 10.1109/CVPR.2018.00510
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Yang M.-H., 2018, NEURAL INFORM PROCES
   Zhu Z., 2018, 2018 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2018.8508710
NR 39
TC 5
Z9 5
U1 0
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2021
VL 111
AR 104188
DI 10.1016/j.imavis.2021.104188
EA APR 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SN6GI
UT WOS:000658385700011
DA 2024-07-18
ER

PT J
AU Rajasekhar, GP
   Granger, E
   Cardinal, P
AF Rajasekhar, Gnana Praveen
   Granger, Eric
   Cardinal, Patrick
TI Deep domain adaptation with ordinal regression for pain assessment using
   weakly-labeled videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep domain adaptation; Weakly-supervised learning; Multiple instance
   learning; Ordinal regression; Pain intensity estimation
AB Estimation of pain intensity from facial expressions captured in videos has an immense potential for health care applications. Given the challenges related to subjective variations of facial expressions, and to operational capture conditions, the accuracy of state-of-the-art deep learning (DL) models for recognizing facial expressions may decline. Domain adaptation (DA) has been widely explored to alleviate the problem of domain shifts that typically occur between video data captured across various source (laboratory) and target (operational) domains. Moreover, given the laborious task of collecting and annotating videos, and the subjective bias due to ambiguity among adjacent intensity levels, weakly-supervised learning (WSL) is gaining attention in such applications. State-ofthe-art WSL models are typically formulated as regression problems, and do not leverage the ordinal relationship among pain intensity levels, nor the temporal coherence of multiple consecutive frames. This paper introduces a new DL model for weakly-supervised DA with ordinal regression (WSDA-OR) that can be adapted using target domain videos with coarse labels provided on a periodic basis. The WSDA-OR model enforces ordinal relationships among the intensity levels assigned to target sequences, and associates multiple relevant frames to sequence-level labels (instead of a single frame). In particular, it learns discriminant and domain-invariant feature representations by integrating multiple instance learning with deep adversarial DA, where soft Gaussian labels are used to efficiently represent the weak ordinal sequence-level labels from the target domain. The proposed approach was validated using the RECOLA video dataset as fully-labeled source domain data, and UNBC-McMaster shoulder pain video dataset as weakly-labeled target domain data. We have also validated WSDA-OR on BIOVID and Fatigue (private) datasets for sequence level estimation. Experimental results indicate that our proposed approach can significantly improve performance over the state-of-the-art models, allowing to achieve a greater pain localization accuracy. Code is available on GitHub link: https://github.com/praveena2j/ WSDAOR.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Rajasekhar, Gnana Praveen; Granger, Eric; Cardinal, Patrick] Univ Quebec Montreal, Lab Imagerie Vis & Intelligence Artificielle, Ecole Technol Super, Montreal, PQ, Canada.
C3 University of Quebec; University of Quebec Montreal; Ecole de
   Technologie Superieure - Canada
RP Rajasekhar, GP (corresponding author), Univ Quebec Montreal, Lab Imagerie Vis & Intelligence Artificielle, Ecole Technol Super, Montreal, PQ, Canada.
EM gnanapraveen.rajasekar.1@ens.etsmtl.ca; Eric.Granger@etsmtl.ca;
   Patrick.Cardinal@etsmtl.ca
OI Granger, Eric/0000-0001-6116-7945
FU Fonds de recherche du Quebec -Nature et technologies (FRQNT); Natural
   Sciences and Engineering Council of Canada (NSERC)
FX This research was supported by the Fonds de recherche du Quebec -Nature
   et technologies (FRQNT) and the Natural Sciences and Engineering Council
   of Canada (NSERC).
CR Ayral T, 2021, IEEE WINT CONF APPL, P3028, DOI 10.1109/WACV48630.2021.00307
   Cardinal P., 2020, DEEP WEAKLY SU UNPUB
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chu W, 2005, J MACH LEARN RES, V6, P1019
   de Melo W. C., 2019, COMBINING GLOBAL LOC
   de Melo WC, 2020, INT CONF ACOUST SPEE, P1080, DOI [10.1109/icassp40776.2020.9054375, 10.1109/ICASSP40776.2020.9054375]
   Díaz R, 2019, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2019.00487
   Exprada, 2020, PATTERN RECOGN, V100, P107
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gonfaus J.M., 2018, IEEE T CYBERNETICS, P1
   Hofmann Thomas, 2002, NIPS, V15
   Hsu KJ, 2014, IEEE T IMAGE PROCESS, V23, P1722, DOI 10.1109/TIP.2014.2307436
   Ilse M, 2018, PR MACH LEARN RES, V80
   Jamal A., 2018, BMVC
   Lynch M, 2001, J Intraven Nurs, V24, P85
   Meng G., 2019, ICCV
   Niu ZX, 2016, PROC CVPR IEEE, P4920, DOI 10.1109/CVPR.2016.532
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Praveen R. Gnana, 2021, WEAKLY SUPERVISED LE
   Ringeval F, 2013, IEEE INT CONF AUTOMA
   Ruiz A, 2018, IEEE T IMAGE PROCESS, V27, P3969, DOI 10.1109/TIP.2018.2830189
   Sangineto E, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P357, DOI 10.1145/2647868.2654916
   Shimodaira H, 2000, J STAT PLAN INFER, V90, P227, DOI 10.1016/S0378-3758(00)00115-4
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Sikka K, 2014, IMAGE VISION COMPUT, V32, P659, DOI 10.1016/j.imavis.2014.02.008
   Sikka Karan, 2014, ICMI
   Solomon P.E., 2011, PAINFUL DATA UNBCMCM
   Sun M, 2016, INT C PATT RECOG, P3270, DOI 10.1109/ICPR.2016.7900139
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan Zichang, 2017, AGE ESTIMATION BASED
   Tavakolian M, 2019, INT J COMPUT VISION, V127, P1413, DOI 10.1007/s11263-019-01191-3
   Wang F, 2017, IEEE IMAGE PROC, P1087, DOI 10.1109/ICIP.2017.8296449
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang XQ, 2018, COMPUT INTEL NEUROSC, V2018, DOI 10.1155/2018/7208794
   Wang Y, 2019, INT CONF ACOUST SPEE, P31, DOI 10.1109/ICASSP.2019.8682847
   Wilkie D., 2019, IEEE T AFF COMP, P1
   Wollenberg J., 2019, IEEE T PATTERN ANAL, P1
   Wu C., 2015, MULTI INSTANCE HIDDE
   Yang Liu, 2011, ACMM
   Zhang Cha, 2007, NIPS
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang Qi, 2002, ICML
   Zhang Y., 2018, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2018.00262
   Zhang Y, 2018, PROC CVPR IEEE, P2314, DOI 10.1109/CVPR.2018.00246
   Zhao Q., 2016, ICB
   Zhao R, 2016, PROC CVPR IEEE, P3466, DOI 10.1109/CVPR.2016.377
   Zhao ZQ, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhou J, 2016, IEEE COMPUT SOC CONF, P1535, DOI 10.1109/CVPRW.2016.191
   Zhou YZ, 2017, IEEE INT CONF COMP V, P318, DOI 10.1109/ICCVW.2017.46
   Zhou ZH, 2018, NATL SCI REV, V5, P44, DOI 10.1093/nsr/nwx106
NR 51
TC 6
Z9 6
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104167
DI 10.1016/j.imavis.2021.104167
EA APR 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700012
DA 2024-07-18
ER

PT J
AU Yasin, H
   Hayat, S
AF Yasin, Hashim
   Hayat, Saqib
TI DeepSegment: Segmentation of motion capture data using deep
   convolutional neural network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Motion capture data; Segementation; Convolutional neural network;
   Alexnet; Kd-tree
ID RECOGNITION
AB In this paper, we propose a novel framework to segment 3D human motion capture data into distinct behaviors. First, in preprocessing, we build a normalized pose space by eliminating translation and orientation from the 3D poses. We then transform these normalized 3D poses into 2D RGB images, and as a result, we simplify the task of motion segmentation as image classification and recognition. Furthermore, we identify the most significant joints of the skeleton that contribute substantially to executing a motion and get benefits from them by assigning them more weights. The weight allocation to the specific joint has been done purely based on its deviation capability. Finally, each motion is encoded into compact visual representation by exploiting RGB images with weighted joints. We adopt a transfer learning approach to extract a fixed-size feature vector using off-the-shelf deep Convolutional Neural Network (CNN), Alexnet, after fine-tuning. We develop a Kd-tree on these highly descriptive feature vectors to retrieve the nearest neighbors. Based on a similarity measure, we classify the motion segments and ultimately place the cuts on the ongoing motion sequences. We perform extensive experiments to evaluate our proposed approach on popular Motion Capture (MoCap) datasets, CMU and HDM05. Our approach almost outperforms all other state-of-the-art methods, and the results highlight the capabilities of our proposed scheme for effective segmentation.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Yasin, Hashim; Hayat, Saqib] Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad 44000, Pakistan.
RP Yasin, H (corresponding author), Natl Univ Comp & Emerging Sci, Dept Comp Sci, Islamabad 44000, Pakistan.
EM hashim.yasin@nu.edu.pk; saqib.hayat@nu.edu.pk
CR [Anonymous], 2018, IEEE C COMP VIS PATT
   [Anonymous], 2010, SCA'10: proceedings of the 2010 ACM SIGGRAPH/Eurographics symposium on computer animation, DOI [10.2312/SCA/SCA10/001-010, DOI 10.2312/SCA/SCA10/001-010]
   [Anonymous], 2015, 2015 8 INT C ADV PAT
   [Anonymous], 2014, P 2014 ACM SIGGRAPHE
   [Anonymous], 2007, Computer Graphics Technical Report CG-2007-2
   [Anonymous], 2014, 2014 INT C COMP GRAP
   [Anonymous], 2015, PROC IEEE C COMPUT V
   Arn RT, 2019, IEEE T PATTERN ANAL, V41, P2919, DOI 10.1109/TPAMI.2018.2869741
   Barbic J, 2004, PROC GRAPH INTERF, P185
   Cai ML, 2014, MULTIMED TOOLS APPL, V70, P1333, DOI 10.1007/s11042-013-1749-5
   Cheema N., 2019, 40 ANN C EUR ASS COM, P69
   Cho K, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 2, P122
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Donahue J, 2014, PR MACH LEARN RES, V32
   Du Y, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P579, DOI 10.1109/ACPR.2015.7486569
   Du Y, 2015, PROC CVPR IEEE, P1110, DOI 10.1109/CVPR.2015.7298714
   Elias P, 2017, IEEE INT SYM MULTIM, P154, DOI 10.1109/ISM.2017.29
   Elias P, 2015, LECT NOTES COMPUT SC, V9371, P250, DOI 10.1007/978-3-319-25087-8_24
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Kadu H, 2014, IEEE T MULTIMEDIA, V16, P2191, DOI 10.1109/TMM.2014.2360793
   Ke Q, 2017, PROC CVPR IEEE, P4570, DOI 10.1109/CVPR.2017.486
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Krüger B, 2017, IEEE T MULTIMEDIA, V19, P797, DOI 10.1109/TMM.2016.2635030
   Laraba S, 2017, COMPUT ANIMAT VIRT W, V28, DOI 10.1002/cav.1782
   Li B., 2012, 2012 IEEE C COMP VIS
   Liu J., 2019, P IEEE CVF C COMP VI
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Perepichka M., 2019, INTERACTION GAMES
   Sedmidubsky J, 2018, MULTIMED TOOLS APPL, V77, P12073, DOI 10.1007/s11042-017-4859-7
   Sedmidubsky J, 2013, LECT NOTES COMPUT SC, V8192, P669, DOI 10.1007/978-3-319-02895-8_60
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tits M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0199744
   Veeriah V, 2015, IEEE I CONF COMP VIS, P4041, DOI 10.1109/ICCV.2015.460
   Vemulapalli R., 2016, P IEEE C COMP VIS PA
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang H., 2017, P IEEE C COMP VIS PA
   Wang JY, 2009, 2009 WRI WORLD CONGRESS ON SOFTWARE ENGINEERING, VOL 1, PROCEEDINGS, P234, DOI 10.1109/WCSE.2009.354
   Wang LM, 2015, PROC CVPR IEEE, P4305, DOI 10.1109/CVPR.2015.7299059
   Wu S., 2009, P 16 ACM S VIRTUAL R, P207
   Wu SY, 2009, VISUAL COMPUT, V25, P499, DOI 10.1007/s00371-009-0345-1
   Xia GY, 2018, IEEE T IMAGE PROCESS, V27, P3011, DOI 10.1109/TIP.2018.2812100
   Yasin H, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20082226
   Yasin H, 2016, PROC CVPR IEEE, P4948, DOI 10.1109/CVPR.2016.535
NR 44
TC 3
Z9 3
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104147
DI 10.1016/j.imavis.2021.104147
EA MAR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600008
DA 2024-07-18
ER

PT J
AU Lowe, J
   Derakhshani, R
AF Lowe, Jesse
   Derakhshani, Reza
TI Optokinetic response for mobile device biometric liveness assessment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Eye movement; Ocular biometrics; Ocular kinetics; Digital
   identity; Mobile device security; Liveness; Behavioral biometrics
ID NYSTAGMUS
AB As a practical pursuit of quantified uniqueness, biometrics explores the parameters that make us who we are and provides the tools we need to secure the integrity of that identity. In our culture of constant connectivity, an in-creasing reliance on biometrically secured mobile devices is transforming them into a target for bad actors. While no system will ever prevent all forms of intrusion, even state of the art biometric methods remain vulnerable to spoof attacks. As these attacks become more sophisticated, liveness based attack detection methods provide a po-tential deterrent. We present a novel optokinetc nystagmus (OKN) based liveness assessment system for mobile applications which leverages phase-locked temporal features of a unique reflexive behavioral response. In this paper we provide proof of concept for eliciting, collecting and extracting the OKN response motion signature on a mobile device. Results of our most successful experimental machine learning classifier are reported for a multi-layer LSTM based model demonstrating a 98.4% single stimulus detection performance for simulated video based attacks.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Lowe, Jesse; Derakhshani, Reza] Univ Missouri, Computat Intelligence & Bioidentificat Technol CI, Kansas City, MO 64110 USA.
C3 University of Missouri System; University of Missouri Kansas City
RP Lowe, J (corresponding author), Univ Missouri, Computat Intelligence & Bioidentificat Technol CI, Kansas City, MO 64110 USA.
EM jmlkvf@mail.umkc.edu
FU EyeVerify, Inc. (dba ZOLOZ) an affiliate of Ant Group Co., Ltd.
FX This research was funded in part by a grant from EyeVerify, Inc. (dba
   ZOLOZ) an affiliate of Ant Group Co., Ltd., and its affiliates. Dr.
   Derakhshani is also a consultant for ZOLOZ.
CR Akhtar Z., 2011, 2011 INT C INF NETW
   Akhtar Z., 2014, INT CARNAHAN C SECUR, P1, DOI DOI 10.1109/CCST.2014.6986982
   Alzubaidi A., 2016, IEEE COMMUN SURV TUT, DOI DOI 10.1109/COMST.2016
   Anderson R., 2019, 18 WORKSH EC INF SEC
   [Anonymous], 2011, RECENT APPL BIOMETRI, DOI DOI 10.5772/17151
   Ayyavoo T, 2018, IET BIOMETRICS, V7, P380, DOI 10.1049/iet-bmt.2016.0092
   Azemin MZC, 2011, IEEE ENG MED BIO, P3971, DOI 10.1109/IEMBS.2011.6090986
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Bednarik R., 2005, IMAGE ANAL PROC, DOI [10.1007/11499145_79, DOI 10.1007/11499145_79]
   Bleau H., 2017, Global fraud and cybercrime forecast
   Buttner Ulrich, 2007, Dev Ophthalmol, V40, P76
   Cantoni V, 2018, PATTERN RECOGN LETT, V113, P54, DOI 10.1016/j.patrec.2016.12.006
   Carroll J.M., 2014, COMPUT HDB, VThird, DOI [10.1201/b16768, DOI 10.1201/B16768]
   Chen T., PROC ACM SIGKDD INT
   Clarke N, 2016, INT J MOB COMPUT MUL, V7, P15, DOI 10.4018/IJMCMC.2016010102
   Cui JY, 2018, INT CONF BIOMETR, P140, DOI 10.1109/ICB2018.2018.00031
   Cybersecurity Ventures, 2019, 2019 CYBERVENTURES C
   Dachuan Liu, 2015, Applied Cryptography and Network Security. 13th International Conference, ACNS 2015. RevisedSelected Papers: LNCS 9092, P457, DOI 10.1007/978-3-319-28166-7_22
   Dai C, 2020, APPL SOFT COMPUT, V86, DOI 10.1016/j.asoc.2019.105820
   Damer N, P INT C BIOM SPEC IN
   Das A, 2016, PATTERN RECOGN LETT, V82, P232, DOI 10.1016/j.patrec.2015.11.016
   Dollar P., 2014, IEEE T PATTERN ANAL, DOI 10.1109/TPAMI.2014
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Duchowski AT, 2002, BEHAV RES METH INS C, V34, P455, DOI 10.3758/BF03195475
   DURSTELER MR, 1988, J NEUROPHYSIOL, V60, P940, DOI 10.1152/jn.1988.60.3.940
   Edmunds T, 2018, IET BIOMETRICS, V7, P27, DOI 10.1049/iet-bmt.2017.0077
   Escalante H.J., ARXIV200410998
   Fantana AL, 2015, INT CARN CONF SECU, P235, DOI 10.1109/CCST.2015.7389688
   Farooq SJ, 2004, BRIT J OPHTHALMOL, V88, P796, DOI 10.1136/bjo.2003.028738
   Fujiwara M, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0173707
   Furman J.M., 2014, ENCY NEUROL SCI, DOI [10.1016/B978-0-12-385157-4.00150-0, DOI 10.1016/B978-0-12-385157-4.00150-0]
   Galterio MG, 2018, COMPUTERS, V7, DOI 10.3390/computers7030037
   Garbutt S, 2003, INVEST OPHTH VIS SCI, V44, P3833, DOI 10.1167/iovs.03-0066
   Gefen D, 2000, OMEGA-INT J MANAGE S, V28, P725, DOI 10.1016/S0305-0483(00)00021-9
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   GOULD SB, 1991, GOV INFORM Q, V8, P404, DOI 10.1016/0740-624X(91)90010-6
   Haak KV, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0037686
   Hanakawa T, 2016, NEUROSCI RES, V104, P56, DOI 10.1016/j.neures.2015.11.003
   Holland Corey, 2011, 2011 INT JOINT C BIO, P1, DOI [DOI 10.1109/IJCB.2011.6117536, 10.1109/IJCB.2011.6117536.]
   Holland CD, 2013, INT CONF BIOMETR
   Holmqvist K, 2013, Eye tracking A comprehensive guide to methods and measures, DOI [10.1017/CBO9781107415324.004, DOI 10.1017/CBO9781107415324.004]
   Jan F, 2017, SIGNAL PROCESS, V133, P192, DOI 10.1016/j.sigpro.2016.11.007
   Jia Sha, 2020, BIOMETRICS PATTERN R, V98, DOI [10.1016/j.patcog.2019, DOI 10.1016/J.PATCOG.2019]
   Kandel E. R., 2012, Principles of Neural Science
   Kasprowski P, 2004, LECT NOTES COMPUT SC, V3087, P248
   Kassner M, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P1151, DOI 10.1145/2638728.2641695
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   King D, 2017, DLIB NET
   Knapp CM, 2013, STRABISMUS, V21, P37, DOI 10.3109/09273972.2012.762532
   Komogortsev O.V., P 2013 INT C BIOMETR, DOI [DOI 10.1109/ICB.2013.6612984, 10.1109/ICB.2013.6612984]
   Komogortsev O.V., 2015 IEEE 7 INT C BI, DOI DOI 10.1109/BTAS.2015.7358750
   Konen CS, 2005, EXP BRAIN RES, V165, P203, DOI 10.1007/s00221-005-2289-7
   Latman NS, 2013, SCI JUSTICE, V53, P98, DOI 10.1016/j.scijus.2012.03.008
   Li A, 2004, J VISION, V4, P860, DOI 10.1167/4.10.3
   M P G S., 2012, INT J COMPUTER APPL, DOI DOI 10.5120/8960-3163
   Mahfouz A., 2017, RESEARCHGATE, DOI [10.1145/3052973, DOI 10.1145/3052973]
   Mayron LM, 2015, IEEE SECUR PRIV, V13, P70, DOI 10.1109/MSP.2015.67
   Mehrasa M., 2017, Innovative Smart Grid Technologies Conference Europe (ISGT-Europe), 2017 IEEE PES, P1, DOI DOI 10.1109/ISGTEUROPE.2017.8260221
   Pinto A, 2015, IEEE T INF FOREN SEC, V10, P1025, DOI 10.1109/TIFS.2015.2395139
   PIZZAMIGLIO L, 1990, CORTEX, V26, P535, DOI 10.1016/S0010-9452(13)80303-6
   Purves D., 2001, NEUROSCIENCE
   Rattani A., 2019, ADV COMPUT VIS PATTE, DOI [10.1007/978-3-030-26972-2_1, DOI 10.1007/978-3-030-26972-2_1]
   Rattani A, 2018, COMPUT ELECTR ENG, V72, P39, DOI 10.1016/j.compeleceng.2018.09.005
   Rattani A, 2017, IMAGE VISION COMPUT, V59, P1, DOI 10.1016/j.imavis.2016.11.019
   Rattani A, 2013, INT CONF BIOMETR
   Rigas I, 2016, ACM T APPL PERCEPT, V13, DOI 10.1145/2842614
   Rigas I, 2014, IEEE T INF FOREN SEC, V9, P1743, DOI 10.1109/TIFS.2014.2350960
   Rodrigues RN, 2009, J VISUAL LANG COMPUT, V20, P169, DOI 10.1016/j.jvlc.2009.01.010
   Saevanee H, 2015, COMPUT SECUR, V53, P234, DOI 10.1016/j.cose.2015.06.001
   Smiatacz M, 2012, METROL MEAS SYST, V19, P257, DOI 10.2478/v10178-012-0022-y
   Song C, 2016, IEEE INFOCOM SER
   Song H., 2014, COMMUN COMPUT INF SC, DOI [10.5772/10413, DOI 10.5772/10413]
   Strupp M, 2014, J NEUROL, V261, pS542, DOI 10.1007/s00415-014-7385-9
   Sundararajan K, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3190618
   Tarnutzer AA, 2018, CURR OPIN NEUROL, V31, P74, DOI 10.1097/WCO.0000000000000517
   Trewin S., Proceedings of the 28th Annual Computer Security Applications Conference (ACSAC '12), P159, DOI DOI 10.1145/2420950.2420976
   Turuwhenua J, 2014, VISION RES, V103, P75, DOI 10.1016/j.visres.2014.07.016
   VANDIE GC, 1986, BRAIN RES, V383, P185, DOI 10.1016/0006-8993(86)90019-3
   Waddington J, 2015, J VISION, V15, DOI 10.1167/15.13.7
   Waddington J, 2012, J VISION, V12, DOI 10.1167/12.12.5
   Wade N. J, 2005, MOVING TABLET EYE OR, DOI [10.1093/acprof:oso/9780198566175.001.0001, DOI 10.1093/ACPROF:OSO/9780198566175.001.0001]
   Wang L, 2018, IEEE ACCESS, V6, P17913, DOI 10.1109/ACCESS.2018.2817253
   Wang YD, 2005, COMPUT HUM BEHAV, V21, P105, DOI 10.1016/j.chb.2003.11.008
   Wechsler H., 2017, MOB BIOMETRICS, P1, DOI [10.1049/pbse003e_ch1, DOI 10.1049/PBSE003E_CH1]
   Xu JL, 2018, HEALTHC TECHNOL LETT, V5, P54, DOI 10.1049/htl.2017.0020
   YO C, 1992, INVEST OPHTH VIS SCI, V33, P2490
   Zhang YM, 2017, IEEE J BIOMED HEALTH, V21, P1360, DOI 10.1109/JBHI.2016.2551862
   Zloteanu M, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0209071
   Zou X, 2007, 2007 FIRST IEEE INTERNATIONAL CONFERENCE ON BIOMETRICS: THEORY, APPLICATIONS AND SYSTEMS, P113
NR 89
TC 2
Z9 3
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104107
DI 10.1016/j.imavis.2021.104107
EA JAN 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA QZ7RZ
UT WOS:000630921400002
DA 2024-07-18
ER

PT J
AU Labati, RD
   Genovese, A
   Piuri, V
   Scotti, F
   Vishwakarma, S
AF Labati, R. Donida
   Genovese, Angelo
   Piuri, Vincenzo
   Scotti, Fabio
   Vishwakarma, Sarvesh
TI I-SOCIAL-DB: A labeled database of images collected from websites and
   social media for Iris recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Iris; Web images
AB People upload daily a huge number of portrait face pictures on websites and social media, which can be processed using biometric systems based on the face characteristics to perform an automatic recognition of the individuals. However, the performance of face recognition approaches can be limited by negative factors as aging, occlusions, rotations, and uncontrolled expressions. Nevertheless, the constantly increasing quality and resolution of the portrait pictures uploaded on websites and social media could permit to overcome these problems and improve the robustness of biometric recognition methods by enabling the analysis of additional traits, like the iris. To point the attention of the research community to the possible use of iris-based recognition techniques for images uploaded on websites and social media, we present a public image dataset called I-SOCIAL-DB (Iris Social Database). This dataset is composed of 3,286 ocular regions, extracted from 1,643 high-resolution face images of 400 individuals, collected from public websites. For each ocular region, a human expert extracted the coordinates of the circles approximating the inner and outer iris boundaries and performed a pixelwise segmentation of the iris contours, occlusions, and reflections. This dataset is the first collection of ocular images from public websites and social media, and one of the biggest collections of manually segmented ocular images in the literature. In this paper, we also present a qualitative analysis of the samples, a set of testing protocols and figures of merit, and benchmark results achieved using publicly available iris segmentation and recognition algorithms. We hope that this initiative can give a new test tool to the biometric research community, aiming to stimulate new studies in this challenging research field. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Labati, R. Donida; Genovese, Angelo; Piuri, Vincenzo; Scotti, Fabio] Univ Milan, Dept Comp Sci, Milan, Italy.
   [Vishwakarma, Sarvesh] Indian Inst Informat Technol, Dept Comp Sci, Allahabad, Uttar Pradesh, India.
C3 University of Milan; Indian Institute of Information Technology
   Allahabad
RP Labati, RD (corresponding author), Univ Milan, Dept Comp Sci, Milan, Italy.
EM ruggero.donida@unimi.it
RI Scotti, Fabio/C-7405-2009; Genovese, Angelo/G-8769-2012
OI Genovese, Angelo/0000-0002-3683-4723; Vishwakarma, Dr.
   Sarvesh/0000-0001-6923-2764; Scotti, Fabio/0000-0002-4277-3701
FU EC [825333]; Italian MIUR under PRIN project HOPE, Universita degli
   Studi di Milano under project "Artificial Intelligence for image
   analysis in Forensic Anthropology and Odontology"; JPMorgan Chase & Co.
   under project "k-Anonymity for Biometric Data"
FX This work was supported in part by the EC under grant agreement 825333
   (MOSAICrOWN), the Italian MIUR under PRIN project HOPE, Universita degli
   Studi di Milano under project "Artificial Intelligence for image
   analysis in Forensic Anthropology and Odontology", and JPMorgan Chase &
   Co. under project "k-Anonymity for Biometric Data". We thank the NVIDIA
   Corporation for the GPU donated within the project "Deep Learning and
   CUDA for advanced and less-constrained biometric systems". We also thank
   the Data Protection Officer and the Ethics Committee of the Universita
   degli Studi diMilano, for the fruitful discussions and valuable
   suggestions towards improving the database in a privacy-preserving way,
   according to the current regulations.
CR Alonso-Fernandez F, 2015, IET BIOMETRICS, V4, P74, DOI 10.1049/iet-bmt.2014.0038
   [Anonymous], 2019, SAMSUNG NEWSROOM
   [Anonymous], 2014, LEARNING FACE REPRES
   [Anonymous], 2013, HDB IRIS RECOGNITION
   [Anonymous], 2007, Technical report
   [Anonymous], 2013, IRIS RECOGNITION SEG
   [Anonymous], 2003, Matlab source code for a biometric identification system based on iris patterns
   [Anonymous], 2007, HDB BIOMETRICS HDB B
   [Anonymous], 2006, Handbook of Multibiometrics
   Bowyer KW, 2012, PATTERN RECOGN LETT, V33, P965, DOI 10.1016/j.patrec.2011.11.024
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Czajka A, 2019, IEEE WINT CONF APPL, P959, DOI 10.1109/WACV.2019.00107
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Daugman J, 2008, IEEE T INF FOREN SEC, V3, P52, DOI 10.1109/TIFS.2007.916009
   Daugman J, 2007, IEEE T SYST MAN CY B, V37, P1167, DOI 10.1109/TSMCB.2007.903540
   Daugman J, 2016, IEEE T INF FOREN SEC, V11, P400, DOI 10.1109/TIFS.2015.2500196
   De Marsico M, 2017, PATTERN RECOGN LETT, V91, P3, DOI 10.1016/j.patrec.2016.12.013
   De Marsico M, 2015, PATTERN RECOGN LETT, V57, P17, DOI 10.1016/j.patrec.2015.02.009
   Di Vimercati SD, 2012, INT J UNCERTAIN FUZZ, V20, P793, DOI 10.1142/S0218488512400247
   Doyle J.S., 2013, EFFECTS MASCARA IRIS, P126
   Gangwar A, 2016, INT CONF BIOMETR
   Guo GD, 2019, COMPUT VIS IMAGE UND, V189, DOI 10.1016/j.cviu.2019.102805
   Hofbauer H, 2014, INT C PATT RECOG, P527, DOI 10.1109/ICPR.2014.101
   Hollingsworth K, 2009, COMPUT VIS IMAGE UND, V113, P150, DOI 10.1016/j.cviu.2008.08.001
   Jang J., 2009, ENCY BIOMETRICS, P1062
   Kassing JW, 2010, ENVIRON COMMUN, V4, P1, DOI 10.1080/17524030903509725
   Kerrigan D, 2019, INT CONF BIOMETR, DOI 10.1109/icb45273.2019.8987299
   Ko JG, 2007, ETRI J, V29, P399, DOI 10.4218/etrij.07.0206.0141
   Kumar A, 2010, PATTERN RECOGN, V43, P1016, DOI 10.1016/j.patcog.2009.08.016
   Labati D., 2019, Selfie Biometrics, P49, DOI 10.1007/978-3-030-26972-2_3
   Labati R.D., 2012, Cross Disciplinary Biometric Systems, P151
   Labati R. Donida, 2009, P 2009 IEEE INT C BI, P1
   Labati RD, 2019, COMPUT VIS IMAGE UND, V188, DOI 10.1016/j.cviu.2019.07.007
   Labati RD, 2010, IMAGE VISION COMPUT, V28, P270, DOI 10.1016/j.imavis.2009.05.004
   Liu X, 2017, INTELL SYST SER, P1, DOI 10.1007/s10064-017-1107-3
   Ma L, 2004, IEEE T IMAGE PROCESS, V13, P739, DOI 10.1109/TIP.2004.827237
   Maio D, 2002, IEEE T PATTERN ANAL, V24, P402, DOI 10.1109/34.990140
   Mayhew S., 2018, DERMALOG IRIS RECOGN
   Meng WZ, 2015, IEEE COMMUN SURV TUT, V17, P1268, DOI 10.1109/COMST.2014.2386915
   Merler M, 2019, ARXIV
   Moschoglou S, 2017, IEEE COMPUT SOC CONF, P1997, DOI 10.1109/CVPRW.2017.250
   Ortiz EG, 2014, COMPUT VIS IMAGE UND, V118, P153, DOI 10.1016/j.cviu.2013.09.004
   Othman N, 2016, PATTERN RECOGN LETT, V82, P124, DOI 10.1016/j.patrec.2015.09.002
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Proença H, 2012, PATTERN RECOGN LETT, V33, P963, DOI 10.1016/j.patrec.2012.03.003
   Proença H, 2012, IEEE T INF FOREN SEC, V7, P798, DOI 10.1109/TIFS.2011.2177659
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Rathgeb C, 2016, ADV COMPUT VIS PATT, P359, DOI 10.1007/978-1-4471-6784-6_16
   Rathgeb C, 2010, LECT NOTES COMPUT SC, V6112, P266, DOI 10.1007/978-3-642-13775-4_27
   Rattani A, 2018, COMPUT ELECTR ENG, V72, P39, DOI 10.1016/j.compeleceng.2018.09.005
   Rattani A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P762, DOI 10.1109/BTAS.2017.8272767
   Rattani A, 2016, IEEE IMAGE PROC, P320, DOI 10.1109/ICIP.2016.7532371
   Ribeiro E, 2019, IET BIOMETRICS, V8, P69, DOI 10.1049/iet-bmt.2018.5146
   Sequeira AF, 2014, PROCEEDINGS OF THE 2014 9TH INTERNATIONAL CONFERENCE ON COMPUTER VISION, THEORY AND APPLICATIONS (VISAPP 2014), VOL 3, P133
   Tabassi E., 2011, REPORT NUMBER 7820
   Wild P, 2015, INT CONF BIOMETR, P31, DOI 10.1109/ICB.2015.7139072
   Zhao ZJ, 2015, IEEE I CONF COMP VIS, P3828, DOI 10.1109/ICCV.2015.436
NR 58
TC 8
Z9 8
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104058
DI 10.1016/j.imavis.2020.104058
EA JAN 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Shen, DH
   Zareapoor, M
   Yang, J
AF Shen, Donghao
   Zareapoor, Masoumeh
   Yang, Jie
TI Multimodal image fusion based on point-wise mutual information
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image fusion; Multimodal; Point-wise mutual information; Markov random
   field model; Gradient domain
ID TRANSFORM
AB Multimodal image fusion aims to generate a fused image from different signals that captured by multimodal sensors. Although the images obtained by multimodal sensors have different appearances, the information included in these images might be redundant and noisy. In the previous studies, the fusion rule and their properties that guiding how to merge the features from multiple images is relatively simple functions such as choose-max or weighted average. However, merging the features with redundant information based on these fusion rules may lead to brightness distortion or extra noises, since these fusion rules ignore the spatial consistency of feature selections. In this paper, we propose a novel multimodal image fusion algorithm that focuses on both the transferring the salient structures and maintaining spatial consistency that we consider as fundamental to build our proposed architecture. The proposed algorithm selects features to be transferred into fusion results by a graph cut algorithm, in which the spatial varying smoothness cost is formulated based on the independence between local features measured by point-wise mutual information (PMI). Experiment results demonstrate that, with the straightforward gradient features, the proposed method can obtain state-of-the-art performance on several publicly available multimodal image databases. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Shen, Donghao; Zareapoor, Masoumeh; Yang, Jie] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Yang, J (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM shendonghao7@gmail.com; mzarea222@gmail.com; jieyang@sjtu.edu.cn
RI Zareapoor, Dr. Masoumeh/AAE-6067-2019; Yang, Jie/JCD-9867-2023
OI Zareapoor, Dr. Masoumeh/0000-0002-3991-0584; Zareapoor,
   Masoumeh/0000-0002-7569-9018
FU NSFC, China [61876107, U1803261]; Committee of Science and Technology,
   Shanghai, China [19510711200]
FX This research is partly supported by NSFC, China (No: 61876107,
   U1803261), Committee of Science and Technology, Shanghai, China (No.
   19510711200).
CR [Anonymous], 2015, International Journal of Signal Processing, Image Processing and Pattern Recognition
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chipman LJ, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pC248
   Cvejic N., 2005, INT J SIGNAL PROCESS, V2, P178
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Donoho DL, 2001, NETWORK-COMP NEURAL, V12, P371, DOI 10.1088/0954-898X/12/3/308
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   He KM, 2010, LECT NOTES COMPUT SC, V6311, P1
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lewis JJ, 2007, INFORM FUSION, V8, P119, DOI 10.1016/j.inffus.2005.09.006
   Li H, 2019, IEEE T IMAGE PROCESS, V28, P2614, DOI 10.1109/TIP.2018.2887342
   Li Lu Lu Qilei, 2019, IEEE SENSORS J
   Li ST, 2013, IEEE T IMAGE PROCESS, V22, P2864, DOI 10.1109/TIP.2013.2244222
   Liu CH, 2017, INFRARED PHYS TECHN, V83, P94, DOI 10.1016/j.infrared.2017.04.018
   Liu Y, 2016, IEEE SIGNAL PROC LET, V23, P1882, DOI 10.1109/LSP.2016.2618776
   Liu Y, 2015, INFORM FUSION, V24, P147, DOI 10.1016/j.inffus.2014.09.004
   Ma JY, 2019, INFORM FUSION, V48, P11, DOI 10.1016/j.inffus.2018.09.004
   Ma JY, 2016, INFORM FUSION, V31, P100, DOI 10.1016/j.inffus.2016.02.001
   Mitianoudis N, 2007, INFORM FUSION, V8, P131, DOI 10.1016/j.inffus.2005.09.001
   Morel JM, 2012, PATTERN RECOGN LETT, V33, P342, DOI 10.1016/j.patrec.2011.10.010
   Naidu VPS, 2011, DEFENCE SCI J, V61, P479, DOI 10.14429/dsj.61.705
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Pajares G, 2004, PATTERN RECOGN, V37, P1855, DOI 10.1016/j.patcog.2004.03.010
   Patil U., 2011, P 2011 INT C IM INF, P1, DOI DOI 10.1109/ICIIP.2011.6108966
   Pérez P, 2003, ACM T GRAPHIC, V22, P313, DOI 10.1145/882262.882269
   Prabhakar K.R., 2017, ICCV, V1, P3
   Shamsolmoali P, 2019, IMAGE VISION COMPUT, V88, P9, DOI 10.1016/j.imavis.2019.03.006
   Shamsolmoali Pourya, 2020, IEEE T GEOSCI REMOTE
   Sheather SJ, 2004, STAT SCI, V19, P588, DOI 10.1214/088342304000000297
   Shen R, 2011, IEEE T IMAGE PROCESS, V20, P3634, DOI 10.1109/TIP.2011.2150235
   Sun J, 2013, INFORM FUSION, V14, P241, DOI 10.1016/j.inffus.2012.07.003
   TOET A, 1989, PATTERN RECOGN LETT, V9, P245, DOI 10.1016/0167-8655(89)90003-2
   Wang J, 2014, INFRARED PHYS TECHN, V67, P477, DOI 10.1016/j.infrared.2014.09.019
   Wang KP, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19070306
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang Z, 2002, IEEE SIGNAL PROC LET, V9, P81, DOI 10.1109/97.995823
   Xing CD, 2019, IMAGE VISION COMPUT, V90, DOI 10.1016/j.imavis.2019.08.010
   Xu H, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3954
   Xu M, 2011, IEEE T GEOSCI REMOTE, V49, P5116, DOI 10.1109/TGRS.2011.2158607
   Yu NN, 2011, IEEE J-STSP, V5, P1074, DOI 10.1109/JSTSP.2011.2112332
   Zhang Q, 2018, INFORM FUSION, V40, P57, DOI 10.1016/j.inffus.2017.05.006
   Zhao Zixiang, 2020, ARXIV200505896
NR 42
TC 7
Z9 8
U1 3
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104047
DI 10.1016/j.imavis.2020.104047
EA JAN 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800007
DA 2024-07-18
ER

PT J
AU Wu, SK
   Li, XP
   Wang, XG
AF Wu, Shengkai
   Li, Xiaoping
   Wang, Xinggang
TI IoU-aware single-stage object detector for accurate localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE IoU prediction; IoU-aware detector; Accurate localization; Single-stage
   object detector
AB Single-stage object detectors have beenwidely applied inmany computer vision applications due to their simpleness and high efficiency. However, the low correlation between the classification score and localization accuracy in detection results severely hurts the average precision of the detection model. To solve this problem, an IoU-aware single-stage object detector is proposed in this paper. Specifically, IoU-aware single-stage object detector predicts the IoU for each detected box. Then the predicted IoU is multiplied by the classification score to compute the final detection confidence, which is more correlated with the localization accuracy. The detection confidence is then used as the input of the subsequent NMS and COCO AP computation, which substantially improves the localization accuracy of model. Sufficient experiments on COCO and PASCOL VOC datasets demonstrate the effectiveness of IoU-aware single-stage object detector on improving model's localization accuracy. Without whistles and bells, the proposed method can substantially improve AP by 1.7%-1.9% and AP75 by 2.2%-2.5% on COCO test-dev. And it can also substantially improve AP by 2.9%-4.4% and AP80, AP90 by 4.6%-10.2% on PASCAL VOC. The source code will be made publicly available. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Wu, Shengkai; Li, Xiaoping] Huazhong Univ Sci & Technol, State Key Lab Digital Mfg Equipment & Technol, Wuhan 430074, Peoples R China.
   [Wang, Xinggang] Huazhong Univ Sci & Technol, Sch EIC, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology; Huazhong University of
   Science & Technology
RP Li, XP (corresponding author), Huazhong Univ Sci & Technol, State Key Lab Digital Mfg Equipment & Technol, Wuhan 430074, Peoples R China.
EM ShengkaiWu@hust.edu.cn; lixiaoping@hust.edu.cn; xgwang@hust.edu.cn
RI Wu, Shengkai/JRX-2574-2023; Wang, Xinggang/W-4374-2019
OI Wang, Xinggang/0000-0001-6732-7823
CR [Anonymous], ARXIV190913226
   [Anonymous], 2015, DENSEBOX UNIFYING LA
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   CAO Y, 2019, ARXIV190404821
   Chen K, 2019, PROC CVPR IEEE, P4969, DOI 10.1109/CVPR.2019.00511
   Chen Y., 2019, ARXIV190801570
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Gidaris S, 2015, IEEE I CONF COMP VIS, P1134, DOI 10.1109/ICCV.2015.135
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Girshick Ross, 2018, Detectron
   Goldman E, 2019, PROC CVPR IEEE, P5222, DOI 10.1109/CVPR.2019.00537
   Goyal Priya, 2017, abs/1706.02677
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Li BY, 2019, AAAI CONF ARTIF INTE, P8577
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Paszke A, 2019, ADV NEUR IN, V32
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, DOI 10.1109/CVPR.2017.690, DOI 10.48550/ARXIV.1804.02767]
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Tychsen-Smith L, 2018, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR.2018.00719
   Tychsen-Smith L, 2017, IEEE I CONF COMP VIS, P428, DOI 10.1109/ICCV.2017.54
   Wu S., 2019, ARXIV190805641
   Zhang S, 2018, PROC CVPR IEEE, P4203, DOI 10.1109/CVPR.2018.00442
   Zhang ZS, 2018, PROC CVPR IEEE, P5813, DOI 10.1109/CVPR.2018.00609
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
NR 36
TC 97
Z9 110
U1 3
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2020
VL 97
AR 103911
DI 10.1016/j.imavis.2020.103911
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LR7TU
UT WOS:000535899900004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lv, JY
   Li, ZY
   Nai, K
   Chen, Y
   Yuan, J
AF Lv, Jingyi
   Li, Zhiyong
   Nai, Ke
   Chen, Ying
   Yuan, Jin
TI Person re-identification with expanded neighborhoods distance reranking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Re-ranking; Expanded neighborhoods distance;
   Two-level neighborhoods
ID OBJECT RETRIEVAL; RE-RANKING; ACCURATE
AB In the person re-identification (re-ID) community, pedestrians often have great changes in appearance, and there are many similar persons, which incurs will degrades the accuracy. Re-ranking is an effective method to solve these problems, this paper proposes an expanded neighborhoods distance (END) to re-rank the re-ID results. We assume that if the two persons in different image are same, their initial ranking lists and two-level neighborhoods will be very similar when they are taken as the query. Our method follows the principle of similarity, and selects expanded neighborhoods in initial ranking list to calculate the END distance. Final distance is calculated as the combination of the END distance and Jaccard distance. Experiments on Market-1501, DukeMTMC-reID and CUHK03 datasets confirm the effectiveness of the novel re-ranking method in this article. Compare with re-ID baseline, the proposed method in this paper increases mAP by 14.2% on Market-1501 and Rank1 by 12.9% on DukeMTMC-reID. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Li, Zhiyong] Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
   Key Lab Embedded & Network Comp, Changsha 410082, Hunan, Peoples R China.
C3 Hunan University
RP Li, ZY (corresponding author), Hunan Univ, Coll Comp Sci & Elect Engn, Changsha 410082, Hunan, Peoples R China.
EM zhiyong.li@hnu.edu.cn
RI Liu, Kai/IST-6808-2023; li, zy/HZM-1892-2023; Liu, Chang/ISV-3950-2023;
   Wang, Zejun/KBB-8454-2024
FU National Key Research and Development Program of China [2018YFB1308604];
   National Natural Science Foundation of China [61672215, 61976086]; Hunan
   Science and Technology Innovation Project [2017XK2102]
FX This work was partially supported by National Key Research and
   Development Program of China (No.2018YFB1308604), National Natural
   Science Foundation of China (No.61672215, No.61976086) and Hunan Science
   and Technology Innovation Project (No.2017XK2102).
CR [Anonymous], 2016, IEEE WINT CONF APPL
   [Anonymous], RANKING OPTIMIZATION
   [Anonymous], VIDEO OBJECT SEGMENT
   [Anonymous], 2012, ICIP
   [Anonymous], 2017, CVPR
   [Anonymous], ARXIV180208122V1CSCV
   [Anonymous], 2007 IEEE 11 INT C C
   [Anonymous], 2013, ICCV
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2015, ICCV
   [Anonymous], ARXIV190105798CSCV
   [Anonymous], 2015, IEEE INT C COMP VIS
   [Anonymous], DENSELY SEMANTICALLY
   [Anonymous], 2017, POSE SENSITIVE EMBED
   [Anonymous], VCIP
   [Anonymous], 2016, ECCV
   [Anonymous], 2017, IEEE INT C COMP VIS
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Bai S, 2016, IEEE T IMAGE PROCESS, V25, P1056, DOI 10.1109/TIP.2016.2514498
   Chan TH, 2015, IEEE T IMAGE PROCESS, V24, P5017, DOI 10.1109/TIP.2015.2475625
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen Y, 2019, J VIS COMMUN IMAGE R, V58, P486, DOI 10.1016/j.jvcir.2018.11.044
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Jegou H, 2007, PROC CVPR IEEE, P9
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li YJ, 2016, PR IEEE I C PROGR IN, P224, DOI 10.1109/PIC.2016.7949499
   Li ZY, 2017, J VIS COMMUN IMAGE R, V44, P1, DOI [10.1016/j.jvcir.2017.01.012, 10.16339/j.cnki.hdxbzkb.2017.11.001]
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Lv JM, 2018, PROC CVPR IEEE, P7948, DOI 10.1109/CVPR.2018.00829
   Martinel N, 2015, IEEE T IMAGE PROCESS, V24, P5645, DOI 10.1109/TIP.2015.2487048
   Qi L, 2019, IEEE I CONF COMP VIS, P8079, DOI 10.1109/ICCV.2019.00817
   Qin DF, 2011, PROC CVPR IEEE, P777, DOI 10.1109/CVPR.2011.5995373
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Schumann A, 2017, IEEE COMPUT SOC CONF, P1435, DOI 10.1109/CVPRW.2017.186
   Shen XH, 2012, PROC CVPR IEEE, P3013, DOI 10.1109/CVPR.2012.6248031
   Shen YJ, 2018, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2018.00092
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Ye MJ, 2017, IEEE T CYBERNETICS, V47, P720, DOI 10.1109/TCYB.2016.2524452
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Zhang L, 2016, PROC CVPR IEEE, P1239, DOI 10.1109/CVPR.2016.139
   Zheng L, 2018, IEEE T PATTERN ANAL, V40, P1224, DOI 10.1109/TPAMI.2017.2709749
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
NR 46
TC 15
Z9 15
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2020
VL 95
AR 103875
DI 10.1016/j.imavis.2020.103875
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA LG1YB
UT WOS:000527904000001
DA 2024-07-18
ER

PT J
AU Tao, HJ
   Lu, XB
AF Tao, Huanjie
   Lu, Xiaobo
TI Smoke vehicle detection based on robust codebook model and robust volume
   local binary count patterns
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Smoke vehicle detection; Codebook model; Volume local binary count
   (VLBC); Non-redundant VLBC; Completed VLBC
ID SPATIAL-TEMPORAL ENERGY; VIDEO; IMAGE; MULTISCALE; FEATURES; MOTION;
   SEGMENTATION; FRAMEWORK; ADABOOST; NETWORK
AB Smoke vehicle detection is still vulnerable to false alarms. To reduce false alarm rates, this paper presents a smoke vehicle detection method based on Robust Codebook (R-Codebook) model and Robust Volume Local Binary Count (R-VLBC) pattern. In detecting suspected smoke blocks, we propose the R-Codebook model, which is robust to illumination changes and camera shaking or leaf shaking in the scene. In recognizing smoke block sequences, firstly, we propose a robust and discriminative descriptor called Non-Redundant VLBC (NR-VLBC). The feature dimension is reduced by half than the VLBC to overcome the issue that the VLBC is sensitive to the relative changes between background and foreground. Secondly, we propose a new Completed VLBC (CVLBC) by combining VLBC-Sign, VLBC-Magnitude, VLBC-Center gray level and VLBC-Difference to characterize spatial-temporal features. Thirdly, two strategies are used to further improve the proposed CVLBC to form R-VLBC. One is to overcome the issue that the CVLBC is sensitive to noise based on using a weighted local threshold (WLT), which is robust to noise and illumination variants and also make a balance between noise resistance and information of individual pixel. The other one is to extract multi-scale information by using a set of radius and sampling points. Extensive experiments show that the proposed method can achieve better performances than existing methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Tao, Huanjie; Lu, Xiaobo] Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
   [Tao, Huanjie; Lu, Xiaobo] Southeast Univ, Minist Educ, Key Lab Measurement & Control Complex Syst Engn, Nanjing 210096, Jiangsu, Peoples R China.
C3 Southeast University - China; Southeast University - China
RP Lu, XB (corresponding author), Southeast Univ, Sch Automat, Nanjing 210096, Jiangsu, Peoples R China.
EM xblu2013@126.com
FU National Natural Science Foundation of China [61871123]; Key Research
   and Development Program in Jiangsu Province [BE2016739]; Priority
   Academic Program Development of Jiangsu Higher Education Institutions;
   Postgraduate Research and Practice Innovation Program of Jiangsu
   Province [KYCX18_0101]; Scientific Research Foundation of Graduate
   School of Southeast University [YBPY1871]
FX This work was supported by the National Natural Science Foundation of
   China (no. 61871123), Key Research and Development Program in Jiangsu
   Province (no. BE2016739), a Project Funded by the Priority Academic
   Program Development of Jiangsu Higher Education Institutions, the
   Postgraduate Research and Practice Innovation Program of Jiangsu
   Province (no. KYCX18_0101), and the Scientific Research Foundation of
   Graduate School of Southeast University (no. YBPY1871).
CR [Anonymous], SIVIP
   [Anonymous], MACH VIS APPL
   [Anonymous], P 10 INT C DIG IM PR
   Appana DK, 2017, INFORM SCIENCES, V418, P91, DOI 10.1016/j.ins.2017.08.001
   Calderara S, 2011, MACH VISION APPL, V22, P705, DOI 10.1007/s00138-010-0272-1
   Dimitropoulos K, 2017, IEEE T CIRC SYST VID, V27, P1143, DOI 10.1109/TCSVT.2016.2527340
   Favorskaya M, 2015, PROCEDIA COMPUT SCI, V60, P671, DOI 10.1016/j.procs.2015.08.205
   Filonenko A, 2018, IEEE T IND INFORM, V14, P725, DOI 10.1109/TII.2017.2757457
   Gubbi J, 2009, FIRE SAFETY J, V44, P1110, DOI 10.1016/j.firesaf.2009.08.003
   Gunay O, 2012, IEEE T IMAGE PROCESS, V21, P2853, DOI 10.1109/TIP.2012.2183141
   Hu YC, 2018, MULTIMED TOOLS APPL, V77, P29283, DOI 10.1007/s11042-018-5978-5
   Jia Y, 2016, FIRE TECHNOL, V52, P1271, DOI 10.1007/s10694-014-0453-y
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Ko B, 2013, IMAGE VISION COMPUT, V31, P786, DOI 10.1016/j.imavis.2013.08.001
   Ko B, 2012, OPT ENG, V51, DOI 10.1117/1.OE.51.1.017208
   Labati RD, 2013, IEEE T SYST MAN CY-S, V43, P1003, DOI 10.1109/TSMCA.2012.2224335
   Lin GH, 2017, KSII T INTERNET INF, V11, P5522
   Long CJ, 2010, LECT NOTES ARTIF INT, V6319, P389, DOI 10.1007/978-3-642-16530-6_46
   Luo S, 2015, FIRE SAFETY J, V75, P23, DOI 10.1016/j.firesaf.2015.04.002
   Luo YM, 2018, MULTIMED TOOLS APPL, V77, P15075, DOI 10.1007/s11042-017-5090-2
   Muhammad K, 2018, IEEE T IND INFORM, V14, P3679, DOI 10.1109/TII.2018.2791944
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojo JA, 2018, J COMPUT SCI TECHNOL, V18, P35, DOI 10.24215/16666038.18.e05
   Pyykönen P, 2016, INT C INTELL COMP CO, P233, DOI 10.1109/ICCP.2016.7737152
   Tao HJ, 2020, J REAL-TIME IMAGE PR, V17, P745, DOI 10.1007/s11554-019-00856-z
   Tao HJ, 2019, IET INTELL TRANSP SY, V13, P252, DOI 10.1049/iet-its.2018.5039
   Tao HJ, 2018, MULTIMED TOOLS APPL, V77, P32153, DOI 10.1007/s11042-018-6248-2
   Tao HJ, 2018, IEEE ACCESS, V6, P57180, DOI 10.1109/ACCESS.2018.2873757
   Tao HJ, 2018, SIGNAL IMAGE VIDEO P, V12, P1061, DOI 10.1007/s11760-018-1254-4
   Tian H, 2011, P IEEE INT WORKSH MU, P1, DOI DOI 10.1109/VETECF.2011.6092963
   Tian HD, 2018, IEEE T IMAGE PROCESS, V27, P1164, DOI 10.1109/TIP.2017.2771499
   Tian HD, 2014, INT J COMPUT VISION, V106, P192, DOI 10.1007/s11263-013-0656-6
   Tung TX, 2011, FIRE SAFETY J, V46, P276, DOI 10.1016/j.firesaf.2011.03.003
   Wang SD, 2017, J INTELL FUZZY SYST, V33, P305, DOI 10.3233/JIFS-161605
   Wang SD, 2014, J INTELL FUZZY SYST, V26, P267, DOI 10.3233/IFS-120735
   Ye W, 2015, FIRE SAFETY J, V73, P91, DOI 10.1016/j.firesaf.2015.03.001
   Yin MX, 2019, MULTIMED TOOLS APPL, V78, P237, DOI 10.1007/s11042-017-5561-5
   Yin ZJ, 2017, IEEE ACCESS, V5, P18429, DOI 10.1109/ACCESS.2017.2747399
   Yu CY, 2010, FIRE TECHNOL, V46, P651, DOI 10.1007/s10694-009-0110-z
   Yuan F, 2008, PATTERN RECOGN LETT, V29, P925, DOI 10.1016/j.patrec.2008.01.013
   Yuan FN, 2019, INT J WAVELETS MULTI, V17, DOI 10.1142/S0219691319400058
   Yuan FN, 2019, COMPUT VIS IMAGE UND, V178, P43, DOI 10.1016/j.cviu.2018.10.008
   Yuan FN, 2018, INFORM SCIENCES, V468, P193, DOI 10.1016/j.ins.2018.08.005
   Yuan FN, 2018, INFORM SCIENCES, V460, P202, DOI 10.1016/j.ins.2018.05.033
   Yuan FN, 2017, IEEE ACCESS, V5, P6833, DOI 10.1109/ACCESS.2017.2697408
   Yuan FN, 2016, INFORM SCIENCES, V372, P225, DOI 10.1016/j.ins.2016.08.040
   Yuan FN, 2016, KSII T INTERNET INF, V10, P1807, DOI 10.3837/tiis.2016.04.019
   Yuan FN, 2015, IET IMAGE PROCESS, V9, P849, DOI 10.1049/iet-ipr.2014.1032
   Yuan FN, 2012, PATTERN RECOGN, V45, P4326, DOI 10.1016/j.patcog.2012.06.008
   Yuan FN, 2011, FIRE SAFETY J, V46, P132, DOI 10.1016/j.firesaf.2011.01.001
   Zhao XC, 2018, IEEE T MULTIMEDIA, V20, P552, DOI 10.1109/TMM.2017.2750415
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
   Zhou ZQ, 2016, FIRE SAFETY J, V85, P50, DOI 10.1016/j.firesaf.2016.08.004
NR 53
TC 8
Z9 10
U1 0
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2019
VL 86
BP 17
EP 27
DI 10.1016/j.imavis.2019.03.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IC8DN
UT WOS:000471206600002
DA 2024-07-18
ER

PT J
AU Kashiani, H
   Shokouhi, SB
AF Kashiani, Hossein
   Shokouhi, Shahriar B.
TI Visual object tracking based on adaptive Siamese and motion estimation
   network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object tracking; Siamese network; Convolutional neural networks; Motion
   estimation
AB Recently, convolutional neural network (CNN) has attracted much attention in different areas of computer vision, due to its powerful abstract feature representation. Visual object tracking is one of the interesting and important areas in computer vision that achieves remarkable improvements in recent years. In this work, we aim to improve both the motion and observation models in visual object tracking by leveraging representation power of CNNs. To this end, a motion estimation network (named MEN) is utilized to seek the most likely locations of the target and prepare a further clue in addition to the previous target position. Hence the motion estimation would be enhanced by generating a small number of candidates near two plausible positions. The generated candidates are then fed into a trained Siamese network to detect the most probable candidate. Each candidate is compared to an adaptable buffer, which is updated under a predefined condition. To take into account the target appearance changes, a weighting CNN (called WCNN) adaptively assigns weights to the final similarity scores of the Siamese network using sequence-specific information. Evaluation results on well-known benchmark datasets (OTB100, OTB50 and OTB2013) prove that the proposed tracker outperforms the state-of-the-art competitors. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Kashiani, Hossein; Shokouhi, Shahriar B.] Iran Univ Sci & Technol, Sch Elect Engn, Tehran, Iran.
C3 Iran University Science & Technology
RP Kashiani, H (corresponding author), Iran Univ Sci & Technol, Sch Elect Engn, Tehran, Iran.
EM hossein_kashiyani@alumni.iust.ac.ir; bshokouhi@iust.ac.ir
RI Shokouhi, shahriar Baradaran/T-5578-2018; Kashiani,
   Hossein/ABF-6491-2020
OI Kashiani, Hossein/0000-0001-8338-9987
CR [Anonymous], 2016, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2016.465
   Bertinetto L, 2016, PROC CVPR IEEE, P1401, DOI 10.1109/CVPR.2016.156
   Bertinetto L, 2016, LECT NOTES COMPUT SC, V9914, P850, DOI 10.1007/978-3-319-48881-3_56
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Chen K, 2018, IEEE T CIRC SYST VID, V28, P3377, DOI 10.1109/TCSVT.2017.2757061
   Choi J, 2017, PROC CVPR IEEE, P4828, DOI 10.1109/CVPR.2017.513
   Chopra S, 2005, PROC CVPR IEEE, P539, DOI 10.1109/cvpr.2005.202
   Danelljan M, 2015, IEEE I CONF COMP VIS, P4310, DOI 10.1109/ICCV.2015.490
   Fan H, 2017, IEEE COMPUT SOC CONF, P2217, DOI 10.1109/CVPRW.2017.275
   Girshick R., 2014, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2014.81, 10.1109/CVPR.2014.81]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Guo J, 2017, IEEE SIGNAL PROC LET, V24, P1562, DOI 10.1109/LSP.2017.2749458
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   Han B, 2017, PROC CVPR IEEE, P521, DOI 10.1109/CVPR.2017.63
   He AF, 2018, PROC CVPR IEEE, P4834, DOI 10.1109/CVPR.2018.00508
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hongyi Su, 2015, Intelligent Computing Theories and Methodologies. 11th International Conference, ICIC 2015. Proceedings: LNCS 9225, P1, DOI 10.1007/978-3-319-22180-9_1
   Jiang CR, 2018, NEUROCOMPUTING, V275, P2892, DOI 10.1016/j.neucom.2017.10.043
   Leal-Taixé L, 2016, IEEE COMPUT SOC CONF, P418, DOI 10.1109/CVPRW.2016.59
   Li PX, 2018, PATTERN RECOGN, V76, P323, DOI 10.1016/j.patcog.2017.11.007
   Lin T.Y., 2017, P IEEE C COMPUTER VI, P2117, DOI [10.1109/CVPR.2017.106, DOI 10.1109/CVPR.2017.106]
   Ma C, 2019, IEEE T PATTERN ANAL, V41, P2709, DOI [10.1109/TPAMI.2018.2865311, 10.1109/INTMAG.2018.8508195]
   Ma C, 2015, IEEE I CONF COMP VIS, P3074, DOI 10.1109/ICCV.2015.352
   Ma C, 2015, PROC CVPR IEEE, P5388, DOI 10.1109/CVPR.2015.7299177
   Park E, 2018, LECT NOTES COMPUT SC, V11207, P587, DOI 10.1007/978-3-030-01219-9_35
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Pflugfelder R, 2017, ARXIV170700569
   Qi YK, 2018, IEEE T IMAGE PROCESS, V27, P3857, DOI 10.1109/TIP.2018.2797482
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh B, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P364, DOI 10.1109/ICMLA.2015.113
   Smeulders AWM, 2014, IEEE T PATTERN ANAL, V36, P1442, DOI 10.1109/TPAMI.2013.230
   Song YB, 2018, PROC CVPR IEEE, P8990, DOI 10.1109/CVPR.2018.00937
   Song YB, 2017, IEEE I CONF COMP VIS, P2574, DOI 10.1109/ICCV.2017.279
   Tao R, 2016, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2016.158
   Valmadre J, 2017, PROC CVPR IEEE, P5000, DOI 10.1109/CVPR.2017.531
   Wang LJ, 2016, PROC CVPR IEEE, P1373, DOI 10.1109/CVPR.2016.153
   Wang LJ, 2015, IEEE I CONF COMP VIS, P3119, DOI 10.1109/ICCV.2015.357
   Wu Y, 2015, IEEE T PATTERN ANAL, V37, P1834, DOI 10.1109/TPAMI.2014.2388226
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang LX, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1309, DOI 10.1145/3123266.3123381
   Yun S, 2017, PROC CVPR IEEE, P1349, DOI 10.1109/CVPR.2017.148
   Yunhua Zhang, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11213), P355, DOI 10.1007/978-3-030-01240-3_22
   Zhang H, 2018, NEUROCOMPUTING, V275, P2645, DOI 10.1016/j.neucom.2017.11.050
   Zhang KH, 2016, IEEE T IMAGE PROCESS, V25, P1779, DOI 10.1109/TIP.2016.2531283
   2016, IEEE T IMAGE PROCESS, V25, P3814, DOI DOI 10.1109/TIP.2016.2580463
NR 46
TC 12
Z9 13
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR-APR
PY 2019
VL 83-84
BP 17
EP 28
DI 10.1016/j.imavis.2019.02.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HW6TR
UT WOS:000466824000002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Franc, V
   Cech, J
AF Franc, Vojtech
   Cech, Jan
TI Learning CNNs from weakly annotated facial images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Convolution neural networks; EM algorithm; Face recognition; Age and
   gender prediction; Weak annotations
AB Learning of convolutional neural networks (CNNs) to perform a face recognition task requires a large set of facial images each annotated with a label to be predicted. In this paper we propose a method for learning CNNs from weakly annotated images. The weak annotation in our setting means that a pair of an attribute label and a person identity label is assigned to a set of faces automatically detected in the image. The challenge is to link the annotation with the correct face. The weakly annotated images of this type can be collected by an automated process not requiring a human labor. We formulate learning from weakly annotated images as a maximum likelihood (ML) estimation of a parametric distribution describing the weakly annotated images. The ML problem is solved by an instance of the EM algorithm which in its inner loop learns a CNN to predict attribute label from facial images. Experiments on age and gender estimation problem show that the proposed algorithm significantly outperforms the existing heuristic approach for dealing with this type of data. A practical outcome of our paper is a new annotation of the IMDB database [26] containing 300 k faces each one annotated by biological age, gender and identity labels. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Franc, Vojtech; Cech, Jan] Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Prague, Czech Republic.
C3 Czech Technical University Prague
RP Franc, V (corresponding author), Czech Tech Univ, Fac Elect Engn, Dept Cybernet, Prague, Czech Republic.
EM xfrancv@cmp.felk.cvut.cz; cechj@cmp.felk.cvut.cz
RI Franc, Vojtěch/JAC-6432-2023
OI Franc, Vojtěch/0000-0001-7189-1224
FU Czech Science Foundation [16-05872S, P103/12/G084]
FX The authors were supported by Czech Science Foundation grants 16-05872S
   and P103/12/G084.
CR Agustsson E., 2017, 12 IEEE INT C WORKSH
   [Anonymous], 2015, ICCV CHALEARN LOOK P
   [Anonymous], INT C BIOM ICB
   [Anonymous], CVPR WORKSH
   Antoniuk K, 2016, MACH LEARN, V103, P261, DOI 10.1007/s10994-015-5541-9
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen YC, 2014, IEEE T INF FOREN SEC, V9, P2076, DOI 10.1109/TIFS.2014.2359642
   Cour T, 2011, J MACH LEARN RES, V12, P1501
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Franc V, 2017, IEEE INT CONF AUTOMA, P933, DOI 10.1109/FG.2017.115
   Ganchev K, 2010, J MACH LEARN RES, V11, P2001
   Geng X, 2007, IEEE T PATTERN ANAL, V29, P2234, DOI 10.1109/TPAMI.2007.70733
   Geng X, 2010, AAAI CONF ARTIF INTE, P451
   Hinton G., 2002, P 15 INT C NEUR INF
   HOEFFDING W, 1963, J AM STAT ASSOC, V58, P13, DOI 10.2307/2282952
   Jie L, 2010, ADV NEURAL INFORM PR, V23, P1504
   Jim R., 2002, P NIPS
   Kai-Yueh Chang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2129, DOI 10.1109/CVPR.2011.5995415
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lapuschkin S., 2017, P ICCV 17 WORKSH AN
   NOCEDAL J, 1980, MATH COMPUT, V35, P773, DOI 10.1090/S0025-5718-1980-0572855-7
   Panis G., 2016, IET BIOM, V5
   Parkhi O. M., 2015, BRIT MED VIS C
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Schlesinger M., 1968, Kibernetika, V2, P81
   Shrivastava A, 2015, INT J COMPUT VISION, V114, P288, DOI 10.1007/s11263-015-0831-z
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Yan SC, 2008, IEEE T INF FOREN SEC, V3, P698, DOI 10.1109/TIFS.2008.2006585
   Zeng Z., 2013, P INT C COMP VIS PAT
   Zhang ML, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P4048
   Zhang N., 2007, Tech. Rep. 07-49, P7
NR 32
TC 4
Z9 4
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2018
VL 77
BP 10
EP 20
DI 10.1016/j.imavis.2018.06.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV7DT
UT WOS:000446282900002
DA 2024-07-18
ER

PT J
AU Kaya, H
   Gürpinar, F
   Salah, AA
AF Kaya, Heysem
   Gurpinar, Furkan
   Salah, Albert Ali
TI Video-based emotion recognition in the wild using deep transfer learning
   and score fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE EmotiW; Emotion recognition in the wild; Multimodal fusion;
   Convolutional neural networks; Kernel extreme learning machine; Partial
   least squares
ID MACHINE; SCALE
AB Multimodal recognition of affective states is a difficult problem, unless the recording conditions are carefully controlled. For recognition "in the wild", large variances in face pose and illumination, cluttered backgrounds, occlusions, audio and video noise, as well as issues with subtle cues of expression are some of the issues to target. In this paper, we describe a multimodal approach for video-based emotion recognition in the wild. We propose using summarizing functionals of complementary visual descriptors for video modeling. These features include deep convolutional neural network (CNN) based features obtained via transfer learning, for which we illustrate the importance of flexible registration and fine-tuning. Our approach combines audio and visual features with least squares regression based classifiers and weighted score level fusion. We report state-of-the-art results on the EmotiW Challenge for "in the wild" facial expression recognition. Our approach scales to other problems, and ranked top in the ChaLearn-LAP First Impressions Challenge 2016 from video clips collected in the wild. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Kaya, Heysem] Namik Kemal Univ, Corlu Fac Engn, Dept Comp Engn, TR-59860 Corlu, Tekirdag, Turkey.
   [Gurpinar, Furkan; Salah, Albert Ali] Bogazici Univ, Dept Comp Engn, TR-34342 Istanbul, Turkey.
C3 Namik Kemal University; Bogazici University
RP Kaya, H (corresponding author), Namik Kemal Univ, Corlu Fac Engn, Dept Comp Engn, TR-59860 Corlu, Tekirdag, Turkey.
EM hkaya@nku.edu.tr; furkan.gurpinar@boun.edu.tr; salah@boun.edu.tr
RI KAYA, Heysem/V-4493-2019; Salah, Albert Ali/E-5820-2013; Salah, Albert
   Ali/ABH-5561-2020
OI KAYA, Heysem/0000-0001-7947-5508; Salah, Albert Ali/0000-0001-6342-428X;
   Gurpinar, Furkan/0000-0001-8270-9969
CR Almaev TR, 2013, INT CONF AFFECT, P356, DOI 10.1109/ACII.2013.65
   [Anonymous], P AVEC 16 COL ACM MM
   [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], ICPR CONT P
   [Anonymous], P IEEE CVPR WORKSH
   [Anonymous], 2014, P 16 INT C MULT INT
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], 2014, P 4 INT WORKSHOP AUD
   [Anonymous], 2013, P EMOSPACE 2013 HELD
   [Anonymous], 2010, PROC 3 INT WORKSHOP
   [Anonymous], P ICPR
   [Anonymous], P 18 ACM INT C MULT
   [Anonymous], IEEE T PATTERN ANAL
   Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416
   Chatfield K., 2014, P BRIT MACH VIS C 20
   D'Mello S, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P31
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dhall A., 2014, PROC ICMI, P461, DOI DOI 10.1145/2663204.2666275
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P509, DOI 10.1145/2522848.2531739
   Dhall A, 2012, IEEE MULTIMEDIA, V19, P34, DOI 10.1109/MMUL.2012.26
   Dibeklioglu H, 2012, LECT NOTES COMPUT SC, V7574, P525, DOI 10.1007/978-3-642-33712-3_38
   Eyben Florian, 2010, P 18 ACM INT C MULT, P1459
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Goodfellow IJ, 2015, NEURAL NETWORKS, V64, P59, DOI 10.1016/j.neunet.2014.09.005
   Heikkila J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P818, DOI 10.1109/ICPR.2010.206
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Jiang BH, 2014, IEEE T CYBERNETICS, V44, P161, DOI 10.1109/TCYB.2013.2249063
   Kahou SE, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P467, DOI 10.1145/2818346.2830596
   Kahou SE, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P543, DOI 10.1145/2522848.2531745
   Kaya H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P909
   Kaya H, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P459, DOI 10.1145/2818346.2830588
   Kaya H, 2016, J MULTIMODAL USER IN, V10, P139, DOI 10.1007/s12193-015-0175-6
   Kim BK, 2016, J MULTIMODAL USER IN, V10, P173, DOI 10.1007/s12193-015-0209-0
   Krumhuber E, 2007, EMOTION, V7, P730, DOI 10.1037/1528-3542.7.4.730
   Liu MY, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P525, DOI 10.1145/2522848.2531738
   Liu MY, 2016, J MULTIMODAL USER IN, V10, P113, DOI 10.1007/s12193-015-0204-5
   Liu MY, 2015, LECT NOTES COMPUT SC, V9006, P143, DOI 10.1007/978-3-319-16817-3_10
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Perronnin F., 2007, P IEEE CVPR, P1
   Rao C.R., 1971, Generalized inverse of matrices and its applications, V7
   Rifkin R., 2003, Computer and Systems Sciences, V190, P131
   Rothe R, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P252, DOI 10.1109/ICCVW.2015.41
   Schuller B, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 3 AND 4, P2798
   Sikka K, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P517, DOI 10.1145/2522848.2531741
   Sivic J, 2009, IEEE T PATTERN ANAL, V31, P591, DOI 10.1109/TPAMI.2008.111
   Sun Bo., 2014, Proceedings of the 16th International Conference on Multimodal Interaction. ACM, P481
   Suykens JAK, 1999, NEURAL PROCESS LETT, V9, P293, DOI 10.1023/A:1018628609742
   Valstar M., 2013, P 3 ACM INT WORKSHOP, DOI [10.1145/2512530.2512533, DOI 10.1145/2512530.2512533]
   Wang ZH, 2013, PROC CVPR IEEE, P3422, DOI 10.1109/CVPR.2013.439
   Wold H, 1985, ENCY STAT SCI, P581, DOI DOI 10.1002/0471667196.ESS1914.PUB2
   Wu CH, 2014, APSIPA TRANS SIGNAL, V3, DOI 10.1017/ATSIP.2014.11
   Yao AB, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P451, DOI 10.1145/2818346.2830585
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zafeiriou S., 2016, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, P36
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 62
TC 131
Z9 141
U1 1
U2 70
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2017
VL 65
SI SI
BP 66
EP 75
DI 10.1016/j.imavis.2017.01.012
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FJ3GM
UT WOS:000412618500008
DA 2024-07-18
ER

PT J
AU Chen, J
   Patel, VM
   Liu, L
   Kellokumpu, V
   Zhao, GY
   Pietikäinen, M
   Chellappa, R
AF Chen, Jie
   Patel, Vishal M.
   Liu, Li
   Kellokumpu, Vili
   Zhao, Guoying
   Pietikainen, Matti
   Chellappa, Rama
TI Robust local features for remote face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Robust local feature; Remote face recognition
ID BINARY PATTERNS; DIMENSIONALITY; SCALE
AB In this paper, we propose a robust local descriptor for face recognition. It consists of two components, one based on a shearlet-decomposition and the other on local binary pattern (LBP). Shearlets can completely analyze the singular structures of piecewise smooth images, which is useful since singularities and irregular structures carry useful information in an underlying image. Furthermore, LBP is effective for describing the edges extracted by shearlets even when the images contain high level of noise. Experimental results using the Face Recognition Grand Challenge dataset show that the proposed local descriptor significantly outperforms many widely used features (e.g., Gabor and deep learning-based features) when the images are corrupted by random noise, demonstrating robustness to noise. In addition, experimental results show promising results for two challenging datasets which have poor image quality, i.e., a remote face dataset and the Point and Shoot Face Recognition Challenge dataset. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Chen, Jie; Liu, Li; Kellokumpu, Vili; Zhao, Guoying; Pietikainen, Matti] Univ Oulu, Ctr Machine Vis & Signal Anal, Oulu, Finland.
   [Patel, Vishal M.] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ USA.
   [Chellappa, Rama] Univ Maryland, Dept Elect & Comp Engn, College Pk, MD 20742 USA.
   [Liu, Li] Natl Univ Def Technol, Coll Informat Syst & Management, Changsha, Hunan, Peoples R China.
C3 University of Oulu; Rutgers University System; Rutgers University New
   Brunswick; University System of Maryland; University of Maryland College
   Park; National University of Defense Technology - China
RP Liu, L (corresponding author), Natl Univ Def Technol, Coll Informat Syst & Management, Changsha, Hunan, Peoples R China.
EM jiechen@ee.oulu.fi; vishal.m.patel@rutgers.edu; lili@ee.oulu.fi;
   kello@ee.oulu.fi; gyzhao@ee.oulu.fi; mkp@ee.oulu.fi; rama@umiacs.umd.edu
RI Zhao, Guoying/ABE-7716-2020; Chellappa, Rama/AAV-8690-2020; Chellappa,
   Rama/B-6573-2012
OI Zhao, Guoying/0000-0003-3694-206X; Kellokumpu, Vili/0000-0002-5247-9311
FU Academy of Finland [277395]; Tekes Fidipro Program [1849/31/2015];
   Infotech Oulu; US Office of Naval Research (ONR) [YIP N00014-16-1-3134];
   Academy of Finland (AKA) [277395] Funding Source: Academy of Finland
   (AKA)
FX This work was supported by Academy of Finland 277395, Tekes Fidipro
   Program 1849/31/2015 and Infotech Oulu. VMP was supported by US Office
   of Naval Research (ONR) Grant YIP N00014-16-1-3134.
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], 2008, P INT C MACH LEARN
   [Anonymous], P INT C PATT REC
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], 1990, Introduction to statistical pattern classification, DOI DOI 10.1016/B978-0-08-047865-4.50007-7
   [Anonymous], P AS C COMP VIS
   [Anonymous], P IEEE INT C COMP VI
   Beveridge J.R., 2013, IEEE 6 INT C BIOM TH
   Beveridge J.R., 2015, 11 IEEE INT C AUT FA
   Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199
   Chellappa R, 2012, PATTERN RECOGN LETT, V33, P1849, DOI 10.1016/j.patrec.2011.11.020
   Chen D., 2013, P IEEE INT C COMP VI
   Chen J., 2009, P IEEE INT C COMP VI
   Chen J, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.122
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   da Cunha AL, 2006, IEEE T IMAGE PROCESS, V15, P3089, DOI 10.1109/TIP.2006.877507
   Danti A., 2012, 7 IEEE INT C IND INF
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Ding CX, 2016, IEEE T PATTERN ANAL, V38, P518, DOI 10.1109/TPAMI.2015.2462338
   Dong Y., 2013, IEEE T CYBERNETICS, V45, P358
   DONOHO DL, 1995, IEEE T INFORM THEORY, V41, P613, DOI 10.1109/18.382009
   Easley G.R., 2012, J MATH IMAGING VIS, V48, P13
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Grgic M, 2011, MULTIMED TOOLS APPL, V51, P863, DOI 10.1007/s11042-009-0417-2
   Guo KH, 2009, APPL COMPUT HARMON A, V27, P24, DOI 10.1016/j.acha.2008.10.004
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Hauser S., 2014, ARXIV12021773V2
   He JP, 2013, IEEE SIGNAL PROC LET, V20, P905, DOI 10.1109/LSP.2013.2267730
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Huang G.B., 2008, PROC WORKSHOP FACES
   Hwang W., 2006, P IEEE INT C COMP VI
   Jain A. K., 2011, HDB FACE RECOGNITION
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lei Z, 2014, IEEE T PATTERN ANAL, V36, P289, DOI 10.1109/TPAMI.2013.112
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Lim WQ, 2013, IEEE T IMAGE PROCESS, V22, P2056, DOI 10.1109/TIP.2013.2244223
   Lim WQ, 2010, IEEE T IMAGE PROCESS, V19, P1166, DOI 10.1109/TIP.2010.2041410
   Liu CJ, 2006, IEEE T PATTERN ANAL, V28, P725, DOI 10.1109/TPAMI.2006.90
   Liu L, 2017, PATTERN RECOGN, V62, P135, DOI 10.1016/j.patcog.2016.08.032
   Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Marcus Gary., 2012, The New Yorker
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moreels P, 2007, INT J COMPUT VISION, V73, P263, DOI 10.1007/s11263-006-9967-1
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Rahtu E, 2012, IMAGE VISION COMPUT, V30, P501, DOI 10.1016/j.imavis.2012.04.001
   Struc V, 2015, I W BIOMETRIC FORENS
   SU Y, 2007, P IEEE INT C COMP VI
   Sun Y., 2014, P IEEE INT C COMP VI
   TAN X, 2007, IEEE INT WORKSH AN M
   Toshev A., 2014, P IEEE INT C COMP VI
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Zeng Z., 2013, 5 INT C INT NETW COL
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang X, 2012, IEEE T MULTIMEDIA, V14, P995, DOI 10.1109/TMM.2012.2186121
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 60
TC 36
Z9 36
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2017
VL 64
BP 34
EP 46
DI 10.1016/j.imavis.2017.05.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FH0ZW
UT WOS:000410870200004
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Sahin, C
   Kouskouridas, R
   Kim, TK
AF Sahin, Caner
   Kouskouridas, Rigas
   Kim, Tae-Kyun
TI A learning-based variable size part extraction architecture for 6D
   object pose recovery in depth images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object registration; 6 DoF pose estimation; Scale-variant HoCP feature;
   One class training; Random forest; Iterative refinement
ID REGISTRATION
AB State-of-the-art techniques for 6D object pose recovery depend on occlusion-free point clouds to accurately register objects in 3D space. To deal with this shortcoming, we introduce a novel architecture called Iterative Hough Forest with Histogram of Control Points that is capable of estimating the 6D pose of an occluded and cluttered object, given a candidate 2D bounding box. Our Iterative Hough Forest (IHF) is learnt using parts extracted only from the positive samples. These parts are represented with Histogram of Control Points (HoCP), a "scale-variant" implicit volumetric description, which we derive from recently introduced Implicit B-Splines (IBS). The rich discriminative information provided by the scale-variant HoCP features is leveraged during inference. An automatic variable size part extraction framework iteratively refines the object's roughly aligned initial pose due to the extraction of coarsest parts, the ones occupying the largest area in image pixels. The iterative refinement is accomplished based on finer (smaller) parts, which are represented with more discriminative control point descriptors by using our Iterative Hough Forest. Experiments conducted on a publicly available dataset report that our approach shows better registration performance than the state-of-the-art methods. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Sahin, Caner; Kim, Tae-Kyun] Imperial Coll London, Imperial Comp Vis & Learning Lab ICVL, Elect & Elect Engn Dept, London SW7 2AZ, England.
   [Kouskouridas, Rigas] Wirewax, London W1T 2RB, England.
C3 Imperial College London
RP Sahin, C (corresponding author), Imperial Coll London, Imperial Comp Vis & Learning Lab ICVL, Elect & Elect Engn Dept, London SW7 2AZ, England.
EM c.sahinl4@imperial.ac.uk; rkouskou@gmail.com; tk.kim@imperial.ac.uk
RI Kim, Tae-Kyun/HTL-2208-2023; Sahin, Caner/ABS-0159-2022
OI Kim, Tae-Kyun/0000-0002-7587-6053; Sahin, Caner/0000-0002-4591-7168;
   Kouskouridas, Rigas/0000-0002-4866-520X
FU Turkish Ministry of National Education
FX Caner Sahin is funded by the Turkish Ministry of National Education.
CR [Anonymous], 2012, ACCV
   [Anonymous], 2009, IEEE INT C ROB AUT
   [Anonymous], 2014, BMVC
   Bariya P, 2010, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2010.5539774
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Blane M. M., 2000, PAMI
   Bo Zheng, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563058
   Bonde Ujwal., 2014, ECCV
   Brachmann E, 2014, LECT NOTES COMPUT SC, V8690, P536, DOI 10.1007/978-3-319-10605-2_35
   Budiu M., 2011, NIPS
   Choi C, 2012, IEEE INT C INT ROBOT, P3342, DOI 10.1109/IROS.2012.6386067
   Doumanoglou A., 2016, CVPR
   Drost B., 2010, CVPR
   Fanelli G., 2013, INT J COMPUT VIS, V101
   Fanelli G, 2011, PROC CVPR IEEE, P617, DOI 10.1109/CVPR.2011.5995458
   Hara K, 2014, LECT NOTES COMPUT SC, V8690, P552, DOI 10.1007/978-3-319-10605-2_36
   Jüttler B, 2002, ADV COMPUT MATH, V17, P135, DOI 10.1023/A:1015200504295
   Kim E, 2011, IEEE INT C INT ROBOT, P3800, DOI 10.1109/IROS.2011.6048203
   Kouskouridas R., 2016, ARXIV160201464
   Kroon D.J., 2011, THESIS, P69
   Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33
   Papazov C., 2010, P AS C COMP VIS
   Pauwels K., 2015, IROS
   Pauwels K., 2016, ICRA
   Rogez G., 2014, COMP VIS ECCV 2014 W
   Rouhani M., 2011, CORRES FREE REGISTRA
   Rouhani M, 2015, IEEE T IMAGE PROCESS, V24, P22, DOI 10.1109/TIP.2014.2366374
   Rusu R. B., 2008, IROS
   Sahin C., 2016, IROS
   Shotton J., 2013, COMMUN ACM
   Tejani A, 2014, LECT NOTES COMPUT SC, V8694, P462, DOI 10.1007/978-3-319-10599-4_30
   Uenohara M., 1995, VIRTUAL REALITY ROBO
   Unel M., 2010, PATTERN ANAL APPL
   Yang JL, 2013, IEEE I CONF COMP VIS, P1457, DOI 10.1109/ICCV.2013.184
   Zach C, 2015, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.2015.7298615
   Zhao XW, 2014, PROC CVPR IEEE, P1765, DOI 10.1109/CVPR.2014.228
   Zheng B, 2013, COMPUT VIS IMAGE UND, V117, P1647, DOI 10.1016/j.cviu.2013.01.015
NR 37
TC 6
Z9 6
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2017
VL 63
BP 38
EP 50
DI 10.1016/j.imavis.2017.05.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EY9IN
UT WOS:000404312400004
DA 2024-07-18
ER

PT J
AU Al-Tayyan, A
   Assaleh, K
   Shanableh, T
AF Al-Tayyan, Amer
   Assaleh, Khaled
   Shanableh, Tamer
TI Decision-level fusion for single-view gait recognition with various
   carrying and clothing conditions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biometrics; Gait recognition; Decision-level fusion; Accumulated
   prediction image; Accumulated flow image; Edge-masked active energy
   image; Multilinear subspace learning
ID ENERGY IMAGE; INFORMATION; REPRESENTATION
AB Gait recognition is one of the latest and attractive biometric techniques, due to its potential in identification of individuals at a distance, unobtrusively and even using low resolution images. In this paper we focus on single lateral view gait recognition with various carrying and clothing conditions. Such a system is needed in access control applications whereby a single view is imposed by the system setup. The gait data is firstly processed using three gait representation methods as the features sources; Accumulated Prediction Image (API) and two new gait representations namely; Accumulated Flow Image (AFI) and Edge-Masked Active Energy Image (EMAEI). Secondly, each of these methods is tested using three matching classification schemes; image projection with Linear Discriminant Functions (LDF), Multilinear Principal ComponentAnalysis (MPCA) with K-Nearest Neighbor (KNN) classifier and the third method: MPCA plus Linear Discriminant Analysis (MPCA + LDA) with KNN classifier. Gait samples are fed into the MPCA and MPCALDA algorithms using a novel tensor-based form of the gait images. This arrangement results into nine recognition sub-systems. Decisions from the nine classifiers are fused using decision-level (majority voting) scheme. A comparison between unweighted and weighted voting schemes is also presented. The methods are evaluated on CASIA B Dataset using four different experimental setups, and on OU-ISIR Dataset B using two different setups. The experimental results show that the classification accuracy of the proposed methods is encouraging and outperforms several state-of-the-art gait recognition approaches reported in the literature. (C) 2017 Elsevier B.V. All rights reserved.
EM amer.altayyan@wspgroup.ae; kassaleh@aus.edu; tshanableh@aus.edu
RI Shanableh, Tamer/AAC-7893-2021
OI Shanableh, Tamer/0000-0002-7651-3094; Assaleh,
   Khaled/0000-0002-0942-0453
CR Arora P, 2015, PATTERN RECOGN LETT, V68, P336, DOI 10.1016/j.patrec.2015.05.016
   BenAbdelkader C, 2001, LECT NOTES COMPUT SC, V2091, P284
   BenAbdelkader C, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P372, DOI 10.1109/AFGR.2002.1004182
   Bobick AF, 2001, PROC CVPR IEEE, P423
   Boyd JE, 2005, LECT NOTES COMPUT SC, V3161, P19
   Chellappa R., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Chen CH, 2009, PATTERN RECOGN LETT, V30, P977, DOI 10.1016/j.patrec.2009.04.012
   Choudhury S.D., 2016, ELSEVIER PATTERN REC, V48, P798
   Connie T, 2016, NEUROCOMPUTING, V216, P534, DOI 10.1016/j.neucom.2016.08.002
   Cunado D, 1997, LECT NOTES COMPUT SC, V1206, P95
   Das Choudhury S, 2016, PATTERN RECOGN LETT, V80, P1, DOI 10.1016/j.patrec.2016.05.009
   Deng MQ, 2016, PATTERN RECOGN LETT, V78, P56, DOI 10.1016/j.patrec.2016.04.004
   Dockstader SL, 2003, IEEE T IMAGE PROCESS, V12, P962, DOI 10.1109/TIP.2003.815259
   Dupuis Y, 2013, IMAGE VISION COMPUT, V31, P580, DOI 10.1016/j.imavis.2013.04.001
   Fortuny-Guasch J., 2009, 2009 IEEE 43rd International Carnahan Conference on Security Technology. ICCST 2009, P221, DOI 10.1109/CCST.2009.5335534
   Han J, 2006, IEEE T PATTERN ANAL, V28, P316, DOI 10.1109/TPAMI.2006.38
   Han J, 2004, PROC CVPR IEEE, P842
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hossain E., 2011, 2011 Proceedings of IEEE/IFIP 9th International Conference on Embedded and Ubiquitous Computing (EUC 2011), P332, DOI 10.1109/EUC.2011.52
   Hossain MA, 2010, PATTERN RECOGN, V43, P2281, DOI 10.1016/j.patcog.2009.12.020
   Huang XX, 2012, IEEE T IMAGE PROCESS, V21, P2256, DOI 10.1109/TIP.2011.2180914
   Jeevan M, 2013, IEEE IMAGE PROC, P4195, DOI 10.1109/ICIP.2013.6738864
   Kastaniotis D, 2016, PATTERN RECOGN LETT, V84, P245, DOI 10.1016/j.patrec.2016.10.012
   Kusakunniran W, 2013, IEEE T INF FOREN SEC, V8, P1642, DOI 10.1109/TIFS.2013.2252342
   Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255
   Lam THW, 2011, PATTERN RECOGN, V44, P973, DOI 10.1016/j.patcog.2010.10.011
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   Little J., 1998, J COMPUTER VISION RE, V1, P1
   Liu ZY, 2004, INT C PATT RECOG, P211, DOI 10.1109/ICPR.2004.1333741
   López-Fernández D, 2016, J VIS COMMUN IMAGE R, V38, P396, DOI 10.1016/j.jvcir.2016.03.020
   Lu HP, 2008, IEEE T NEURAL NETWOR, V19, P18, DOI 10.1109/TNN.2007.901277
   Luo J, 2016, PATTERN RECOGN, V60, P361, DOI 10.1016/j.patcog.2016.05.030
   Ma GK, 2017, NEUROCOMPUTING, V224, P119, DOI 10.1016/j.neucom.2016.10.047
   MACLIN R, 1995, P 14 INT JOINT C ART
   Makihara Yasushi, 2012, IPSJ Transactions on Computer Vision and Applications, V4, P42, DOI 10.2197/ipsjtcva.4.53
   Marin-Jiménez MJ, 2015, PATTERN RECOGN LETT, V68, P103, DOI 10.1016/j.patrec.2015.08.025
   Nandy A, 2016, NEUROCOMPUTING, V191, P117, DOI 10.1016/j.neucom.2016.01.002
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   O'Donovan P., 2005, OPTICAL FLOW TECHNIQ
   Rogova G., 1996, P 6 IEEE DUAL US TEC
   Rogova G., 1998, P FUSION 98 1 INT C
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Sathish R, 2013, INT C TREND COMPUT C, P1, DOI 10.1109/ICE-CCN.2013.6528465
   Shanableh T, 2009, IEEE INT SYMP SIGNAL, P544, DOI 10.1109/ISSPIT.2009.5407511
   Tanawongsuwan R, 2001, PROC CVPR IEEE, P726
   von Tscharner V, 2003, J ELECTROMYOGR KINES, V13, P253, DOI 10.1016/S1050-6411(02)00111-6
   Wang C, 2012, IEEE T PATTERN ANAL, V34, P2164, DOI 10.1109/TPAMI.2011.260
   Wang L, 2004, IEEE T CIRC SYST VID, V14, P149, DOI 10.1109/TCSVT.2003.821972
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   Xu WJ, 2017, NEUROCOMPUTING, V224, P37, DOI 10.1016/j.neucom.2016.10.054
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
   Yogarajah P, 2015, INFORM SCIENCES, V308, P3, DOI 10.1016/j.ins.2015.01.031
   Yoo J., 2003, P INT SOC BIOM 19 C
   Zeng W, 2014, PATTERN RECOGN, V47, P3568, DOI 10.1016/j.patcog.2014.04.014
   Zhang E, 2010, SIGNAL PROCESS, V90, P2295, DOI 10.1016/j.sigpro.2010.01.024
   Zhang R., 2004, Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPRW'04), June 2004, P18
   Zhang YY, 2013, IEEE INT WORKSH MULT, P189, DOI 10.1109/MMSP.2013.6659286
   Zheng S, 2012, PATTERN RECOGN, V45, P3603, DOI 10.1016/j.patcog.2012.03.008
NR 59
TC 21
Z9 23
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2017
VL 61
BP 54
EP 69
DI 10.1016/j.imavis.2017.02.004
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EU7HK
UT WOS:000401205700005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Joshi, A
   Monnier, C
   Betke, M
   Sclaroff, S
AF Joshi, Ajjen
   Monnier, Camille
   Betke, Margrit
   Sclaroff, Stan
TI Comparing random forest approaches to segmenting and classifying
   gestures
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gesture spotting; Gesture classification; Random forest classifier
ID RECOGNITION
AB A complete gesture recognition system should localize and classify each gesture from a given gesture vocabulary, within a continuous video stream. In this work, we compare two approaches: a method that performs the tasks of temporal segmentation and classification simultaneously with another that performs the tasks sequentially. The first method trains a single random forest model to recognize gestures from a given vocabulary, as presented in a training dataset of video plus 3D body joint locations, as well as out-of-vocabulary (non-gesture) instances. The second method employs a cascaded approach, training a binary random forest model to distinguish gestures from background and a multi-class random forest model to classify segmented gestures. Given a test input video stream, both frameworks are applied using sliding windows at multiple temporal scales. We evaluated our formulation in segmenting and recognizing gestures from two different benchmark datasets: the NATOPS dataset of 9600 gesture instances from a vocabulary of 24 aircraft handling signals, and the ChaLearn dataset of 7754 gesture instances from a vocabulary of 20 Italian communication gestures. The performance of our method compares favorably with state-of-the-art methods that employ Hidden Markov Models or Hidden Conditional Random Fields on the NATOPS dataset. We conclude with a discussion of the advantages of using our model for the task of gesture recognition and segmentation, and outline weaknesses which need to be addressed in the future. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Joshi, Ajjen; Betke, Margrit; Sclaroff, Stan] Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.
   [Monnier, Camille] Charles River Analyt, Cambridge, MA 02138 USA.
C3 Boston University; Charles River Analytics Inc
RP Joshi, A (corresponding author), Boston Univ, Dept Comp Sci, 111 Cummington St, Boston, MA 02215 USA.
EM ajjendj@bu.edu
FU National Science Foundation [IIS-0910908, MRI-1337866]; US Navy
   [N0001413-P-1152]; Direct For Computer & Info Scie & Enginr; Div Of
   Information & Intelligent Systems [1551572] Funding Source: National
   Science Foundation; Division Of Computer and Network Systems; Direct For
   Computer & Info Scie & Enginr [1337866, 1059218] Funding Source:
   National Science Foundation
FX This work was supported in part by National Science Foundation grants
   IIS-0910908 and MRI-1337866 and US Navy contract N0001413-P-1152.
CR Alon Jonathan., 2005, Seventh IEEE Workshops on Application of Computer Vision, V2, P254
   [Anonymous], 2011, COMPUTER ANIMATION A
   [Anonymous], ARXIV150601911
   Bosch A, 2007, IEEE I CONF COMP VIS, P1863
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Camgoz NecatiCihan., 2014, COMPUTER VISION ECCV, P579
   Cooper H, 2007, LECT NOTES COMPUT SC, V4796, P88
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Demirdjian David., 2009, Proceedings of the 2009 International Conference on Multimodal Inter-faces, P293
   Escalera S., 2014, P 2014 IEEE EUR C CO
   Escalera S, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2522848.2532595
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   Kuznetsova A, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P83, DOI 10.1109/ICCVW.2013.18
   Lafferty John, 2001, INT C MACH LEARN ICM
   Malassiotis S, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P190, DOI 10.1109/TDPVT.2002.1024061
   Marín J, 2013, IEEE I CONF COMP VIS, P2592, DOI 10.1109/ICCV.2013.322
   Miranda L., 2012, 2012 XXV SIBGRAPI - Conference on Graphics, Patterns and Images (SIBGRAPI 2012), P268, DOI 10.1109/SIBGRAPI.2012.44
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Neverova N., 2015, IEEE Transactions on Pattern Analysis and Machine intelligence
   Neverova N., 2014, P 2014 IEEE EUR C CO
   Quattoni A, 2007, IEEE T PATTERN ANAL, V29, P1848, DOI 10.1109/TPAMI.2007.1124
   Rautaray SS, 2015, ARTIF INTELL REV, V43, P1, DOI 10.1007/s10462-012-9356-9
   Schroff F, 2008, P BRIT MACH VIS C, P1
   Shotton J, 2013, COMMUN ACM, V56, P116, DOI 10.1145/2398356.2398381
   Song Y., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P500, DOI 10.1109/FG.2011.5771448
   Song Y., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P388, DOI 10.1109/FG.2011.5771431
   Song Y, 2012, ACM T INTERACT INTEL, V2, DOI 10.1145/2133366.2133371
   Song Y, 2012, PROC CVPR IEEE, P2120, DOI 10.1109/CVPR.2012.6247918
   Starner T., 1997, MOTION BASED RECOGNI, P227, DOI 10.1007/978-94-015-8935-2_10
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xu L., 2014, P 6 INT C AUT US INT, P1, DOI DOI 10.1016/B978-0-12-391498-9.00009-7
   Yao A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.67
   Yao A, 2014, PROC CVPR IEEE, P1923, DOI 10.1109/CVPR.2014.247
   Yu G, 2011, IEEE T MULTIMEDIA, V13, P507, DOI 10.1109/TMM.2011.2128301
   Yu Tsz-Ho., 2010, Proceedings of the British Machine Vision Conference, V2, P6
NR 35
TC 31
Z9 34
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 86
EP 95
DI 10.1016/j.imavis.2016.06.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700009
OA hybrid
DA 2024-07-18
ER

PT J
AU Queau, Y
   Mecca, R
   Durou, JD
   Descombes, X
AF Queau, Yvain
   Mecca, Roberto
   Durou, Jean-Denis
   Descombes, Xavier
TI Photometric stereo with only two images: A theoretical study and
   numerical resolution
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D-reconstruction; Shape-from-shading; Photometric stereo; PDEs;
   Numerical analysis; Optimization; Graph cut
ID SURFACE RECOVERY; SHAPE; UNIQUENESS; INTEGRABILITY; RESTORATION; SHADOWS
AB This work tackles the problem of two-image photometric stereo. This problem constitutes the intermediate case between conventional photometric stereo with at least three images, which is well-posed, and shape-from-shading, which is ill-posed. We first provide a theoretical study of ambiguities arising iii this intermediate case. Based on this study, we show that when the albedo is known, disambiguation can be formulated as a binary labeling problem, using integrability and a nonstationary Ising model. The resulting optimization problem is solved efficiently by resorting to the graph cut algorithm. These theoretical and numerical contributions are eventually validated in an application to three-image photometric stereo with shadows. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Queau, Yvain; Durou, Jean-Denis] Univ Toulouse, IRIT, Toulouse, France.
   [Queau, Yvain] Tech Univ Munich, Garching, Germany.
   [Mecca, Roberto] Univ Cambridge, Dept Engn, Cambridge, England.
   [Mecca, Roberto] Univ Bologna, Dept Math, Bologna, Italy.
   [Descombes, Xavier] INRIA, Sophia Antipolis, France.
   [Mecca, Roberto] Ist Nazl Alta Matemat, Rome, Italy.
C3 Universite de Toulouse; Universite Toulouse III - Paul Sabatier;
   Universite Federale Toulouse Midi-Pyrenees (ComUE); Institut National
   Polytechnique de Toulouse; Technical University of Munich; University of
   Cambridge; University of Bologna; Inria
RP Queau, Y (corresponding author), Univ Toulouse, IRIT, Toulouse, France.; Queau, Y (corresponding author), Tech Univ Munich, Garching, Germany.
EM yvain.queau@tum.de
CR Abrams A, 2012, LECT NOTES COMPUT SC, V7573, P357, DOI 10.1007/978-3-642-33709-3_26
   Ackermann J, 2013, FOUND TRENDS COMPUT, V9, P149, DOI 10.1561/0600000065
   Ackermann J, 2012, PROC CVPR IEEE, P262, DOI 10.1109/CVPR.2012.6247684
   [Anonymous], P 11 IEEE INT C COMP
   [Anonymous], 1989, Shape from shading
   Barron J. T., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2521, DOI 10.1109/CVPR.2011.5995392
   Barsky S, 2003, IEEE T PATTERN ANAL, V25, P1239, DOI 10.1109/TPAMI.2003.1233898
   Bergmann R, 2016, INVERSE PROBL IMAG, V10, P281, DOI 10.3934/ipi.2016001
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chandraker M., 2007, P IEEE C COMP VIS PA, P1
   Courteille F, 2004, INT C PATT RECOG, P277, DOI 10.1109/ICPR.2004.1334160
   Durou JD, 2008, COMPUT VIS IMAGE UND, V109, P22, DOI 10.1016/j.cviu.2007.09.003
   Durou JD, 2009, LECT NOTES COMPUT SC, V5681, P261, DOI 10.1007/978-3-642-03641-5_20
   FRANKOT RT, 1988, IEEE T PATTERN ANAL, V10, P439, DOI 10.1109/34.3909
   Golub G.H., 2012, MATRIX COMPUTATIONS, P313
   Hernández C, 2008, LECT NOTES COMPUT SC, V5302, P290, DOI 10.1007/978-3-540-88682-2_23
   Hernández C, 2011, IEEE T PATTERN ANAL, V33, P419, DOI 10.1109/TPAMI.2010.181
   HORN BKP, 1986, COMPUT VISION GRAPH, V33, P174, DOI 10.1016/0734-189X(86)90114-3
   Ikeda O, 2003, IEEE IMAGE PROC, P405
   Ikehata S, 2014, IEEE T PATTERN ANAL, V36, P1816, DOI 10.1109/TPAMI.2014.2299798
   IKEUCHI K, 1981, ARTIF INTELL, V17, P141, DOI 10.1016/0004-3702(81)90023-0
   Jung J, 2015, PROC CVPR IEEE, P4521, DOI 10.1109/CVPR.2015.7299082
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   KONTSEVICH LL, 1994, J OPT SOC AM A, V11, P1047, DOI 10.1364/JOSAA.11.001047
   Koppal SJ, 2009, IEEE T PATTERN ANAL, V31, P1375, DOI 10.1109/TPAMI.2008.148
   KOZERA R, 1991, APPL MATH COMPUT, V44, P1, DOI 10.1016/0096-3003(91)90001-4
   Kozera R., 1993, INT J PATTERN RECOGN, V6, P673
   Mecca R, 2013, SIAM J IMAGING SCI, V6, P616, DOI 10.1137/110857258
   Mecca R, 2011, LECT NOTES COMPUT SC, V6978, P286, DOI 10.1007/978-3-642-24085-0_30
   OLIENSIS J, 1991, INT J COMPUT VISION, V6, P75, DOI 10.1007/BF00128151
   ONN R, 1990, INT J COMPUT VISION, V5, P105, DOI 10.1007/BF00056773
   Papadhimitri T, 2013, PROC CVPR IEEE, P1474, DOI 10.1109/CVPR.2013.194
   Prados E., 2004, Shape from Shading: a well-posed problem? Technical report
   Queau Y., 2016, P IEEE C COMP VIS PA, V2, P3707
   Sato Y., 1995, Proceedings of the Workshop on Physics-Based Modeling in Computer Vision (Cat. No.95TB8038), P180, DOI 10.1109/PBMCV.1995.514684
   Shi B., 2016, P IEEE C COMP VIS PA, V1, P4359
   Sun J, 2007, IMAGE VISION COMPUT, V25, P1050, DOI 10.1016/j.imavis.2006.04.025
   Verbiest F., 2008, P IEEE C COMP VIS PA, P1
   Vogel O, 2009, LECT NOTES COMPUT SC, V5748, P191, DOI 10.1007/978-3-642-03798-6_20
   Vogiatzis G., 2010, COMPUTER VISION DETE
   Woo WL, 2014, SIGNAL PROCESS, V103, P258, DOI 10.1016/j.sigpro.2013.12.006
   Woodham R. J., 1978, Proceedings of the Society of Photo-Optical Instrumentation Engineers, vol.155. Image Understanding Systems and Industrial Applications, P136
   WOODHAM RJ, 1980, OPT ENG, V19, P139, DOI 10.1117/12.7972479
   Wu L, 2011, LECT NOTES COMPUT SC, V6494, P703, DOI 10.1007/978-3-642-19318-7_55
   YANG J, 1992, P SOC PHOTO-OPT INS, V1826, P452, DOI 10.1117/12.131622
   Zeisl Bernhard, 2014, 2014 2nd International Conference on 3D Vision (3DV). Proceedings, P601, DOI 10.1109/3DV.2014.92
NR 46
TC 10
Z9 12
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 175
EP 191
DI 10.1016/j.imavis.2016.11.006
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800014
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Kim, EY
   Ko, E
AF Kim, Eun Yi
   Ko, Eunjeong
TI Canonical image selection based on human affects in photographic images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Canonical image selection; Human affects; Probabilistic affective model;
   Ranking model; PLSA learning
AB The selection of canonical images that best represent a scene type is very important for efficiently visualizing search results and re-ranking them. In this paper, we propose the selection of canonical images based on human affects that are hidden in the image. One is a probabilistic affective model (PAM) based probabilistic latent semantic analysis (PLSA) learning to annotate the image by human affects and the other is the cluster ranking algorithm to select the informative summary from vast search results. The PAM first extract the dominant color compositions (CCs) that constitute the image itself, through image segmentation and RAG analysis, then to infer numerical ratings from CCs for affective classes, a PLSA is employed that is well-known method in finding latent semantics from documents. Once converting the images to the affective space using PAM, the clustering is performed. Then to select the images that are representative among the images and are distinctive from each other, we identify three dominant properties such as coverage, affective coherence, and distinctiveness. Based on these, cluster ranking is performed. Finally, the representative images for each cluster are selected, all of which are displayed as canonical images to the user. Experiments were performed on Photo.Net and Google images and compared the results with other existing methods. Then our PAM showed the F-1-scores of 0.667 on averages, which can improve 14% of the existing method. In addition, it is proven that the proposed system is superior to the others in selecting the canonical images, when comparing its performance with two baselines in terms of representative and diverse scores. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Kim, Eun Yi; Ko, Eunjeong] Konkuk Univ, Dept Internet & Multimedia Engn, Visual Informat Proc Lab, 1204 New Millennium Bldg,120 Neungdong Ro, Seoul 05029, South Korea.
C3 Konkuk University
RP Kim, EY (corresponding author), Konkuk Univ, 1204 New Millennium Bldg,120 Neungdong Ro, Seoul 05029, South Korea.
EM eykim@konkuk.ac.kr; goejeong85@gmail.com
RI Kim, Eun Yi/D-9437-2011
OI Kim, Eun Yi/0000-0002-6944-5863
FU MSIP (Ministry of Science, ICT and Future Planning), Korea under the
   University Information Technology Research Center
   [IITP-2016-R2720-16-0004]
FX This research was supported by the MSIP (Ministry of Science, ICT and
   Future Planning), Korea, under the University Information Technology
   Research Center support program (IITP-2016-R2720-16-0004) supervised by
   the IITP (Institute for Information & communications Technology
   Promotion).
CR [Anonymous], P NEUR INF PROC SYST
   [Anonymous], ACM INT C MULT
   [Anonymous], 1992, COLOR IMAGE SCALE
   [Anonymous], 2012, P 20 ACM MULT C MMM
   [Anonymous], IEEE INT C COMP VIS
   Bianchi-Berthouze N, 2003, IEEE MULTIMEDIA, V10, P103, DOI 10.1109/MMUL.2003.1218262
   Bosch A, 2006, LECT NOTES COMPUT SC, V3954, P517
   Cong Y, 2012, IEEE T MULTIMEDIA, V14, P66, DOI 10.1109/TMM.2011.2166951
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   DEERWESTER S, 1990, J AM SOC INFORM SCI, V41, P391, DOI 10.1002/(SICI)1097-4571(199009)41:6<391::AID-ASI1>3.0.CO;2-9
   Dellandrea Emmanuel, 2010, P INT WORKSHOP CONTE, P1
   FLEISS JL, 1971, PSYCHOL BULL, V76, P378, DOI 10.1037/h0031619
   Hofmann T, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P289
   Hsu WinstonH., 2007, ACM MM
   Jaffe A., 2006, MULTIMEDIA INFORM RE, P89
   Jing Y, 2008, IEEE T PATTERN ANAL, V30, P1877, DOI 10.1109/TPAMI.2008.121
   Jing Yushi., 2007, P 6 ACM INT C IMAGE, P280
   Kennedy L.S., 2008, P ACM INT C WORLD WI, P297
   LANDIS JR, 1977, BIOMETRICS, V33, P159, DOI 10.2307/2529310
   Lazebnik S, 2003, PROC CVPR IEEE, P319
   Li CC, 2009, IEEE J-STSP, V3, P236, DOI 10.1109/JSTSP.2009.2015077
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Shah-Hosseini A., 2006, P 14 ACM INT C MULT, P703
   Shin Y, 2010, IMAGE VISION COMPUT, V28, P526, DOI 10.1016/j.imavis.2009.08.009
   Simon I., 2007, IEEE INT C COMPUTER, P1
   Sinha Pinaki., 2011, P 20 INT C COMPANION, P421
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Solli M., 2010, Proceedings of the ACM International Conference on Image and Video Retrieval, P398
   Wang JD, 2011, MULTIMEDIA SYST, V17, P379, DOI 10.1007/s00530-010-0224-7
   Wang S, 2007, CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, VOLS 1 AND 2, P587
   Wei KP, 2008, LECT NOTES ARTIF INT, V5139, P485
   Wu QF, 2005, LECT NOTES COMPUT SC, V3784, P239
   Yang C., 2011, MM, P1145
   Yang CL, 2013, PATTERN RECOGN, V46, P948, DOI 10.1016/j.patcog.2012.07.011
   Yanulevskaya V, 2008, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2008.4711701
   Zhou WG, 2011, PATTERN RECOGN, V44, P2263, DOI 10.1016/j.patcog.2010.08.016
NR 36
TC 1
Z9 1
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2016
VL 54
BP 83
EP 98
DI 10.1016/j.imavis.2016.08.013
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EB6UG
UT WOS:000387520500008
DA 2024-07-18
ER

PT J
AU Orozco, J
   Martinez, B
   Pantic, M
AF Orozco, Javier
   Martinez, Brais
   Pantic, Maja
TI Empirical analysis of cascade deformable models for multi-view face
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-view face detection; Cascade deformable models; FDDB database;
   AFLW database; HPID database; COFW dataset
AB We present a multi-view face detector based on Cascade Deformable Part Models (CDPM). Over the last decade, there have been several attempts to extend the well-established Viola&Jones face detector algorithm to solve the problem of multi-view face detection. Recently a tree structure model for multi-view face detection was proposed. This method is primarily designed for facial landmark detection and consequently a face detection is provided. However, the effort to model inner facial structures by using a detailed facial landmark labelling resulted on a complex and suboptimal system for face detection. Instead, we adopt CDPMs, where the models are learned from partially labelled images using Latent Support Vector Machines (LSVM). Furthermore, LSVM is enhanced with data-mining and bootstrapping procedures to enrich models during the training. Furthermore, a post-optimization procedure is derived to improve the performance. This semi-supervised methodology allows us to build models based on weakly labelled data while incrementally learning latent positive and negative samples. Our results show that the proposed model can deal with highly expressive and partially occluded faces while outperforming the state-of-the-art face detectors by a large margin on challenging benchmarks such as the Face Detection Data Set and Benchmark (FDDB) [1] and the Annotated Facial Landmarks in the Wild (AFLW) [2] databases. In addition, we validate the accuracy of our models under large head pose variation and facial occlusions in the Head Pose Image Database (HPID) [3] and Caltech Occluded Faces in the Wild (COFW) datasets [4], respectively. We also outline the suitability of our models to support facial landmark detection algorithms. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Orozco, Javier; Martinez, Brais; Pantic, Maja] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
   [Pantic, Maja] Univ Twente, EEMCS, Twente, Netherlands.
C3 Imperial College London; University of Twente
RP Orozco, J (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
EM drjo2009@gmail.com
CR [Anonymous], ICMR
   [Anonymous], 2012, The PASCAL voc2012 Results
   [Anonymous], ICCV
   [Anonymous], 2010, UMCS2010009
   [Anonymous], FG IEEE 2013
   [Anonymous], ECCV IEEE 2006
   [Anonymous], TR20003963 MITS EL R
   [Anonymous], 2004, FGNET FACIAL EXPRESS
   Anvar SMH, 2013, IEEE T PATTERN ANAL, V35, P2484, DOI 10.1109/TPAMI.2013.37
   Battocchi A, 2005, LECT NOTES COMPUT SC, V3814, P303, DOI 10.1007/11590323_39
   Bradski G, 2000, DR DOBBS J, V25, P120
   Chen D, 2014, LECT NOTES COMPUT SC, V8694, P109, DOI 10.1007/978-3-319-10599-4_8
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Gourier N., 2004, FG NET WORKSHOP VISU, P1
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Huang C, 2005, IEEE I CONF COMP VIS, P446
   Jain V, 2011, PROC CVPR IEEE, P577, DOI 10.1109/CVPR.2011.5995317
   Jain Vidit., FDDB RESULTS
   Jianguo Li, 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P2183, DOI 10.1109/ICCVW.2011.6130518
   Jun B, 2012, PATTERN RECOGN, V45, P3304, DOI 10.1016/j.patcog.2012.02.031
   Junek W, 2007, J CAN ACAD CHILD ADO, V16, P182
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li H, 2013, INT BHURBAN C APPL S, P1, DOI 10.1109/IBCAST.2013.6512120
   Li JG, 2013, PROC CVPR IEEE, P3468, DOI 10.1109/CVPR.2013.445
   Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297
   Mathias M, 2014, LECT NOTES COMPUT SC, V8692, P720, DOI 10.1007/978-3-319-10593-2_47
   Orozco J, 2013, IMAGE VISION COMPUT, V31, P322, DOI 10.1016/j.imavis.2013.02.001
   Pantic M, 2005, 2005 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO (ICME), VOLS 1 AND 2, P317, DOI 10.1109/ICME.2005.1521424
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Toews M, 2009, IEEE T PATTERN ANAL, V31, P1567, DOI 10.1109/TPAMI.2008.233
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wu B, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P79
   Yan JJ, 2014, IMAGE VISION COMPUT, V32, P790, DOI 10.1016/j.imavis.2013.12.004
   Zhang C, 2010, C ELECT INSUL DIEL P
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 40
TC 15
Z9 16
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2015
VL 42
BP 47
EP 61
DI 10.1016/j.imavis.2015.07.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CT2BV
UT WOS:000362607900005
OA Green Published, Green Submitted
DA 2024-07-18
ER

PT J
AU Sun, XP
   Wang, J
   She, MFH
   Kong, LX
AF Sun, Xiangping
   Wang, Jin
   She, Mary F. H.
   Kong, Lingxue
TI Sparse representation with multi-manifold analysis for texture
   classification from few training images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Texture classification; Sparse representation; Manifold learning;
   Multi-manifold analysis; Few training image
ID FACE RECOGNITION; FEATURES; ROTATION; WAVELET; SCALE
AB Texture classification is one of the most important tasks in computer vision field and it has been extensively investigated in the last several decades. Previous texture classification methods mainly used the template matching based methods such as Support Vector Machine and k-Nearest-Neighbour for classification. Given enough training images the state-of-the-art texture classification methods could achieve very high classification accuracies on some benchmark databases. However, when the number of training images is limited, which usually happens in real-world applications because of the high cost of obtaining labelled data, the classification accuracies of those state-of-the-art methods would deteriorate due to the overfitting effect. In this paper we aim to develop a novel framework that could correctly classify textural images with only a small number of training images. By taking into account the repetition and sparsity property of textures we propose a sparse representation based multi-manifold analysis framework for texture classification from few training images. A set of new training samples are generated from each training image by a scale and spatial pyramid, and then the training samples belonging to each class are modelled by a manifold based on sparse representation. We learn a dictionary of sparse representation and a projection matrix for each class and classify the test images based on the projected reconstruction errors. The framework provides a more compact model than the template matching based texture classification methods, and mitigates the overfitting effect. Experimental results show that the proposed method could achieve reasonably high generalization capability even with as few as 3 training images, and significantly outperforms the state-of-the-art texture classification approaches on three benchmark datasets. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Sun, Xiangping; Wang, Jin] Deakin Univ, Ctr Intelligent Syst Res, Waurn Ponds, Vic 3216, Australia.
   [Sun, Xiangping; Wang, Jin; She, Mary F. H.; Kong, Lingxue] Deakin Univ, Inst Frontier Mat, Waurn Ponds, Vic 3216, Australia.
C3 Deakin University; Deakin University
RP Sun, XP (corresponding author), Deakin Univ, Ctr Intelligent Syst Res, Waurn Ponds, Vic 3216, Australia.
EM xiangping.sun@gmail.com; jay.wangjin@gmail.com; mary.she@deakin.edu.au;
   lingxue.kong@deakin.edu.au
RI Kong, Lingxue/D-8216-2011
OI Kong, Lingxue/0000-0001-6219-3897
CR Afkham HM, 2008, INT C PATT RECOG, P2019
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587652
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Cai D, 2011, IEEE T PATTERN ANAL, V33, P1548, DOI 10.1109/TPAMI.2010.231
   Candès EJ, 2008, IEEE SIGNAL PROC MAG, V25, P21, DOI 10.1109/MSP.2007.914731
   Candes EJ, 2006, IEEE T INFORM THEORY, V52, P5406, DOI 10.1109/TIT.2006.885507
   Chen J, 2009, PATTERN RECOGN, V42, P2828, DOI 10.1016/j.patcog.2009.02.006
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Drbohlav O., 2005, TEXTURE 2005, P31
   Facco P, 2010, CHEMOMETR INTELL LAB, V103, P66, DOI 10.1016/j.chemolab.2010.05.018
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   Gangeh MJ, 2013, IEEE T SIGNAL PROCES, V61, P4753, DOI 10.1109/TSP.2013.2274276
   Gangeh MJ, 2013, I S BIOMED IMAGING, P1372
   Gangeh MJ, 2010, LECT NOTES COMPUT SC, V6363, P595
   GANGEH MJ, 2011, P 8 INT C IM AN RE 1, V6753, P335
   Gao SH, 2013, IEEE T PATTERN ANAL, V35, P92, DOI 10.1109/TPAMI.2012.63
   Guha T, 2012, IEEE T PATTERN ANAL, V34, P1576, DOI 10.1109/TPAMI.2011.253
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   Hayman E, 2004, LECT NOTES COMPUT SC, V2034, P253
   Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174
   Kassner A, 2010, AM J NEURORADIOL, V31, P809, DOI 10.3174/ajnr.A2061
   Kokare M, 2004, IEEE IMAGE PROC, P393
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liu L, 2012, IEEE T PATTERN ANAL, V34, P574, DOI 10.1109/TPAMI.2011.145
   Lu JW, 2013, IEEE T PATTERN ANAL, V35, P39, DOI 10.1109/TPAMI.2012.70
   Mairal J., 2008, Supervised dictionary learning, P1033
   Mairal J., 2009, P 26 ANN INT C MACHI, P689, DOI 10.1145/1553374.1553463
   Mairal J, 2012, IEEE T PATTERN ANAL, V34, P791, DOI 10.1109/TPAMI.2011.156
   Muneeswaran K, 2005, PATTERN RECOGN, V38, P1495, DOI 10.1016/j.patcog.2005.03.021
   Nguyen TT, 2005, IEEE T SIGNAL PROCES, V53, P3895, DOI 10.1109/TSP.2005.855410
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Schmid C, 2001, PROC CVPR IEEE, P39
   Sorensen L, 2010, IEEE T MED IMAGING, V29, P559, DOI 10.1109/TMI.2009.2038575
   Sun X., 2012, 2012 IEEE INT C BIOI, P1
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xie J, 2010, IEEE IMAGE PROC, P2737, DOI 10.1109/ICIP.2010.5651387
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yang M, 2011, IEEE I CONF COMP VIS, P543, DOI 10.1109/ICCV.2011.6126286
   Yang M, 2010, IEEE IMAGE PROC, P1601, DOI 10.1109/ICIP.2010.5652363
   Yang Y, 2008, IEEE IMAGE PROC, P1852, DOI 10.1109/ICIP.2008.4712139
   Zhang HC, 2013, PATTERN RECOGN, V46, P346, DOI 10.1016/j.patcog.2012.07.010
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 47
TC 2
Z9 2
U1 0
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2014
VL 32
IS 11
BP 835
EP 846
DI 10.1016/j.imavis.2014.07.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AS7FP
UT WOS:000344422900002
DA 2024-07-18
ER

PT J
AU Wang, SF
   Liu, ZL
   Wang, J
   Wang, ZY
   Li, YQ
   Chen, XP
   Ji, Q
AF Wang, Shangfei
   Liu, Zhilei
   Wang, Jun
   Wang, Zhaoyu
   Li, Yongqiang
   Chen, Xiaoping
   Ji, Qiang
TI Exploiting multi-expression dependences for implicit multi-emotion video
   tagging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Implicit video tagging; Multi-emotion; Multi-expression
ID CONTENT REPRESENTATION; RECOGNITION; RETRIEVAL; BEHAVIOR; AROUSAL; AUDIO
AB In this paper, a novel approach of implicit multiple emotional video tagging is proposed, which considers the relations between the users' facial expressions and emotions as well as the relations among multiple expressions. First, the audiences' expressions are inferred through a multi-expression recognition model, which consists of an image-driven expression measurement recognition and a Bayesian network representing the co-existence and mutual exclusion relations among multi-expressions. Second, the videos' multi-emotion tags are obtained from the recognized expressions by another Bayesian Network, capturing the relations between expressions and emotions. Results of the experiments conducted on the JAFFE and NVIE databases demonstrate that the performance of expression recognition is improved by considering the relations among multiple expressions. Furthermore, the relations between expressions and emotions help improve emotional tagging, as our approach outperforms the traditional expression-based or image-driven implicit tagging methods. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Wang, Shangfei; Liu, Zhilei; Wang, Jun; Wang, Zhaoyu; Chen, Xiaoping] Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
   [Li, Yongqiang] Harbin Inst Technol, Sch Elect Engn & Automat, Harbin 15000, Hei Longjiang, Peoples R China.
   [Ji, Qiang] Rensselaer Polytech Inst, Dept Elect Comp & Syst Engn, Troy, NY 12180 USA.
C3 Chinese Academy of Sciences; University of Science & Technology of
   China, CAS; Harbin Institute of Technology; Rensselaer Polytechnic
   Institute
RP Wang, SF (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Key Lab Comp & Commun Software Anhui Prov, Hefei 230027, Anhui, Peoples R China.
EM sfwang@ustc.edu.cn; leivo@mail.ustc.edu.cn; junwong@mail.ustc.edu.cn;
   wazhy@mail.ustc.edu.cn; yongqiang.li.hit@gmail.com; xpchen@ustc.edu.cn;
   qji@ecse.rpi.edu
RI Liu, Zhilei/B-3733-2015; wang, zhaoyu/IQT-3451-2023
OI Liu, Zhilei/0000-0003-1447-6256; 
FU National Program 863 [2008AA01Z122]; National Natural Science Foundation
   of China [61175037, 61228304]; US NSF [A40338]; Special Innovation
   Project on Speech of Anhui Province [11010202192]; Anhui Science and
   Technology Agency [1106c0805008]; Fundamental Research Funds for the
   Central Universities
FX This work has been supported by the National Program 863 (2008AA01Z122),
   the National Natural Science Foundation of China (Grant No. 61175037,
   61228304), the US NSF (A40338), Special Innovation Project on Speech of
   Anhui Province (11010202192), project from Anhui Science and Technology
   Agency (1106c0805008) and the Fundamental Research Funds for the Central
   Universities.
CR [Anonymous], JAPANESE FEMALE FACI
   [Anonymous], DECODING AFFECT VIDE
   [Anonymous], 2001, P 9 ACM INT C MULT
   [Anonymous], CONT BAS MULT IND CB
   [Anonymous], AAM TOOLS
   [Anonymous], 1992, PROCESS EMOTIONAL EX
   [Anonymous], FELT EMOTION SOCIAL
   [Anonymous], USING SCRIPTS AFFECT
   [Anonymous], AUT FAC GEST REC WOR
   [Anonymous], SPIE DEFENSE SECURIT
   [Anonymous], 2004 APS ANN CONV
   [Anonymous], AFF COMP INT INT WOR
   Arapakis I, 2009, IEEE INT CON MULTI, P1440, DOI 10.1109/ICME.2009.5202773
   Arifin S., 2007, Proceedings of the 15th International Conference on Multimedia, P68
   Arifin S, 2007, ICSC 2007: INTERNATIONAL CONFERENCE ON SEMANTIC COMPUTING, PROCEEDINGS, P147, DOI 10.1109/ICSC.2007.22
   Arifin S, 2006, IEEE IMAGE PROC, P433, DOI 10.1109/ICIP.2006.312450
   Cacioppo J.T., 1983, SOCIAL PSYCHOPHYSIOL
   Canini L, 2013, IEEE T CIRC SYST VID, V23, P636, DOI 10.1109/TCSVT.2012.2211935
   Chen Xiu Y., 2009, 2009 WRI World Congress on Computer Science and Information Engineering (CSIE 2009), P277, DOI 10.1109/CSIE.2009.982
   Ching Hau Chan, 2005, 13th Annual ACM International Conference on Multimedia, P427, DOI 10.1145/1101149.1101243
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   de Campos CP, 2011, J MACH LEARN RES, V12, P663
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fernandez-Dols JM, 1997, J NONVERBAL BEHAV, V21, P163, DOI 10.1023/A:1024917530100
   Fridlund A. J., 1994, Human Facial Expression: An Evolutionary View
   GROSS JJ, 1995, COGNITION EMOTION, V9, P87, DOI 10.1080/02699939508408966
   Hanjalic A, 2006, IEEE SIGNAL PROC MAG, V23, P90, DOI 10.1109/MSP.2006.1621452
   Hanjalic A, 2005, IEEE T MULTIMEDIA, V7, P143, DOI 10.1109/TMM.2004.840618
   Healey J, 2011, LECT NOTES COMPUT SC, V6974, P107, DOI 10.1007/978-3-642-24600-5_14
   Irie G, 2009, IEEE INT CON MULTI, P522, DOI 10.1109/ICME.2009.5202548
   Joho H, 2011, MULTIMED TOOLS APPL, V51, P505, DOI 10.1007/s11042-010-0632-x
   Kierkels JJM, 2009, IEEE INT CON MULTI, P1436, DOI 10.1109/ICME.2009.5202772
   Koelstra S., 2009, Proceedings of the 3rd International Conference on Affective Computing and Intelligent Interaction, IEEE, New York, NY, P1, DOI 10.1109/ACII.2009.5349482
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Kok-Meng Ong, 2009, Information and Media Technologies, V4, P903
   Lu Zhaoming, 2009, Proceedings of the 2009 Ninth IEEE International Conference on Computer and Information Technology. CIT 2009, P134, DOI 10.1109/CIT.2009.127
   Lv Yanpeng., 2011, Proceedings of the Third International Conference on Internet Multimedia Computing and Service - ICIMCS'11, page, P170, DOI DOI 10.1145/2043674.2043723
   Mauss IB, 2005, EMOTION, V5, P175, DOI 10.1037/1528-3542.5.2.175
   McDuff D., 2013, IEEE C AUTOMATIC FAC, P1
   Money AG, 2010, ACM T MULTIM COMPUT, V6, DOI 10.1145/1823746.1823751
   Money AG, 2008, LECT NOTES COMPUT SC, V4868, P194, DOI 10.1007/978-3-540-85099-1_17
   Money AG, 2009, DISPLAYS, V30, P59, DOI 10.1016/j.displa.2008.12.003
   Pantic M, 2009, IEEE SIGNAL PROC MAG, V26, P173, DOI 10.1109/MSP.2009.934186
   Pearl J., 1988, PROBABILISTIC REASON
   Peng WT, 2011, IEEE T MULTIMEDIA, V13, P539, DOI 10.1109/TMM.2011.2131638
   Peng WT, 2010, IEEE INT CON MULTI, P849, DOI 10.1109/ICME.2010.5582606
   PHILIPPOT P, 1993, COGNITION EMOTION, V7, P171, DOI 10.1080/02699939308409183
   Russell JA, 2003, ANNU REV PSYCHOL, V54, P329, DOI 10.1146/annurev.psych.54.101601.145102
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Smeaton AF, 2009, INT WORK CONTENT MUL, P162, DOI 10.1109/CBMI.2009.21
   Soleymani M., 2009, Affective Computing and Intelligent Interaction and Workshops, P1
   Soleymani M., 2008, P 2 ACM WORKSHOP MUL, P32, DOI DOI 10.1145/1460676.1460684
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Soleymani M, 2008, IEEE INT SYM MULTIM, P228, DOI 10.1109/ISM.2008.14
   Sorower Mohammad S., 2010, A Literature Survey on Algorithms for Multi-Label Learning
   Sun K, 2007, LECT NOTES COMPUT SC, V4738, P594
   Teixeira RMA, 2012, MULTIMED TOOLS APPL, V61, P21, DOI 10.1007/s11042-010-0702-0
   Toyosawa S, 2010, LECT NOTES COMPUT SC, V6297, P260, DOI 10.1007/978-3-642-15702-8_24
   Wang HL, 2006, IEEE T CIRC SYST VID, V16, P689, DOI 10.1109/TCSVT.2006.873781
   Wang SF, 2011, KANSEI ENGINEERING AND SOFT COMPUTING: THEORY AND PRACTICE, P126, DOI 10.4018/978-1-61692-797-4.ch007
   Wang SF, 2010, IEEE T MULTIMEDIA, V12, P682, DOI 10.1109/TMM.2010.2060716
   [王胜 Wang Sheng], 2014, [现代制造工程, Modern Manufacturing Engineering], P1
   Watanapa SC, 2008, IEICE T INF SYST, VE91D, P1562, DOI 10.1093/ietisy/e91-d.5.1562
   Wei CY, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P831, DOI 10.1109/ICME.2004.1394329
   Wu TY, 2010, SPEECH COMMUN, V52, P83, DOI 10.1016/j.specom.2009.08.010
   Xu M., 2012, MULTIMEDIA TOOLS APP, P1
   Xu M., 2008, Proceeding of the 16th ACM International Conference on Multimedia, P677, DOI DOI 10.1145/1459359.1459457
   Xu M, 2013, SIGNAL PROCESS, V93, P2140, DOI 10.1016/j.sigpro.2012.06.026
   Yazdani J.-S. Lee., 2009, Proc. SIGMM Workshop on Social media, P81
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang SL, 2010, IEEE T MULTIMEDIA, V12, P510, DOI 10.1109/TMM.2010.2059634
   Zhang SL, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-4, P1369, DOI 10.1109/ICME.2008.4607698
   Zhao Sicheng, 2011, P 19 ACM INT C MULTI, P1473, DOI [10.1145/2072298.2072043, DOI 10.1145/2072298.2072043]
NR 73
TC 7
Z9 7
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2014
VL 32
IS 10
SI SI
BP 682
EP 691
DI 10.1016/j.imavis.2014.04.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AP7KR
UT WOS:000342256700007
DA 2024-07-18
ER

PT J
AU Jiménez, D
   Pizarro, D
   Mazo, M
   Palazuelos, S
AF Jimenez, David
   Pizarro, Daniel
   Mazo, Manuel
   Palazuelos, Sira
TI Modeling and correction of multipath interference in time of flight
   cameras
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Time of Flight (ToF); Multipath Interference (MpI); Iterative method
ID SHAPE
AB Multipath interference of light is the cause of important errors in Time of Flight (ToF) depth estimation. This paper proposes an algorithm that removes multipath distortion from a single depth map obtained by a ToF camera. Our approach does not require information about the scene, apart from ToF measurements. The method is based on fitting ToF measurements with a radiometric model. Model inputs are depth values free from multipath interference whereas model outputs consist of synthesized ToF measurements. We propose an iterative optimization algorithm that obtains model parameters that best reproduce ToF measurements, recovering the depth of the scene without distortion. We show results with both synthetic and real scenes captured by commercial ToF sensors. In all cases, our algorithm accurately corrects the multipath distortion, obtaining depth maps that are very close to ground truth data. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Jimenez, David; Mazo, Manuel; Palazuelos, Sira] Univ Alcala, Geintra Res Grp, Madrid 28871, Spain.
   [Pizarro, Daniel] Univ Auvergne, ALCoV ISIT, F-63001 Clermont Ferrand, France.
C3 Universidad de Alcala; Universite Clermont Auvergne (UCA)
RP Jiménez, D (corresponding author), Univ Alcala, Geintra Res Grp, Madrid 28871, Spain.
EM david.jimenez@depeca.uah.es; dani.pizarro@gmail.com; mazo@depeca.uah.es;
   sira@depeca.uah.es
RI CAGIGAS, SIRA PALAZUELOS/ABG-7513-2020
OI CAGIGAS, SIRA PALAZUELOS/0000-0002-2311-441X; Pizarro,
   Daniel/0000-0003-0622-4884
FU Spanish Ministry of Science and Innovation under project VISNU
   [TIN2009-08984]; University of Alcala [CCG10-UAH/TIC-5988]; Regional
   Government of Madrid [CCG10-UAH/TIC-5988]
FX This work has been supported by the Spanish Ministry of Science and
   Innovation under project VISNU (ref. TIN2009-08984) and both the
   University of Alcala and Regional Government of Madrid under project
   FUVA (ref. CCG10-UAH/TIC-5988). We also thank Stefan Fuchs, from the
   German Aerospace Center, for his constructive feedback and helpful
   database.
CR Biswas S, 2009, IEEE T PATTERN ANAL, V31, P884, DOI [10.1109/TPAMI.2008.135, 10.1109/TPAMI.2007.12.0830]
   Dorrington AA, 2011, PROC SPIE, V7864, DOI 10.1117/12.876586
   Falie D, 2008, ECCSC 08: 4TH EUROPEAN CONFERENCE ON CIRCUITS AND SYSTEMS FOR COMMUNICATIONS, P197, DOI 10.1109/ECCSC.2008.4611676
   Falie D, 2008, I W IMAG SYST TECHNI, P123, DOI 10.1109/IST.2008.4659954
   Finlayson GD, 2006, IEEE T PATTERN ANAL, V28, P59, DOI 10.1109/TPAMI.2006.18
   Foix S, 2011, IEEE SENS J, V11, P1917, DOI 10.1109/JSEN.2010.2101060
   Fuchs Stefan, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3583, DOI 10.1109/ICPR.2010.874
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Gudmundsson S.Arni., 2007, Int. Symp. on Signals, P1
   Hartley R., 2000, MULTIPLE VIEW GEOMET, V2
   Keller M, 2009, SIMUL MODEL PRACT TH, V17, P967, DOI 10.1016/j.simpat.2009.03.004
   Klasing K, 2009, IEEE INT CONF ROBOT, P2011
   Kolb A., 2011, MICCAI WORKSH OPT TE
   Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448
   Lindner M, 2006, LECT NOTES COMPUT SC, V4292, P524
   May S., 2009, ROBUST 3D MAPPING TI
   Penne J., MED IMAGE COMPUTING, P467
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Redondo-Cabrera C, 2012, PROC CVPR IEEE, P3458, DOI 10.1109/CVPR.2012.6248087
   Wang L, 2012, INT J COMPUT VISION, V97, P104, DOI 10.1007/s11263-011-0471-x
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 22
TC 47
Z9 54
U1 2
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2014
VL 32
IS 1
BP 1
EP 13
DI 10.1016/j.imavis.2013.10.008
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AB0RV
UT WOS:000331500700001
DA 2024-07-18
ER

PT J
AU Krinidis, S
   Krinidis, M
AF Krinidis, Stelios
   Krinidis, Michail
TI Empirical mode decomposition on skeletonization pruning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Empirical mode decomposition; Ensemble empirical mode decomposition;
   Intrinsic mode; Skeleton; Skeletonization; Pruning
ID THINNING ALGORITHM; TIME
AB This paper presents a novel skeleton pruning approach based on a 2D empirical mode like decomposition (EMD-like). The EMD algorithm can decompose any nonlinear and non-stationary data into a number of intrinsic mode functions (IMFs). When the object contour is decomposed by empirical mode like decomposition (EMD-like), the IMFs of the object provide a workspace with very good properties for obtaining the object's skeleton. The theoretical properties and the performed experiments demonstrate that the obtained skeletons match to hand-labeled skeletons provided by human subjects. Even in the presence of significant noise and shape variations, cuts and tears, the resulted skeletons have the same topology as the original skeletons. In particular, the proposed approach produces no spurious branches as many existing skeleton pruning methods and moreover, does not displace the skeleton points, which are all centers of maximal disks. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Krinidis, Stelios; Krinidis, Michail] Technol Inst Kavala, Informat Management Dept, Ag Loukas 65404, Kavala, Greece.
RP Krinidis, S (corresponding author), Technol Inst Kavala, Informat Management Dept, Ag Loukas 65404, Kavala, Greece.
EM stelios.krinidis@mycosmos.gr
RI Krinidis, Stelios/AAU-3619-2021
OI Krinidis, Stelios/0000-0002-9666-7023
CR Aslan C, 2005, IEEE I CONF COMP VIS, P1339
   Bai X, 2007, IEEE T PATTERN ANAL, V29, P449, DOI 10.1109/TPAMI.2007.59
   Ballard D.H., 1982, Computer Vision
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   BRADY M, 1984, INT J ROBOT RES, V3, P36, DOI 10.1177/027836498400300302
   BRANDT JW, 1992, CVGIP-IMAG UNDERSTAN, V55, P329, DOI 10.1016/1049-9660(92)90030-7
   Choi WP, 2003, PATTERN RECOGN, V36, P721, DOI 10.1016/S0031-3203(02)00098-5
   Dimitrov P, 2003, PROC CVPR IEEE, P835
   Dimitrov P., 2000, Proc. IEEE Conf. Computer Vision and Pattern Recognition, P1417
   Flandrin P, 2004, IEEE SIGNAL PROC LET, V11, P112, DOI 10.1109/LSP.2003.821662
   Ge YR, 1996, IEEE T PATTERN ANAL, V18, P1055, DOI 10.1109/34.544075
   Hesselink WH, 2008, IEEE T PATTERN ANAL, V30, P2204, DOI 10.1109/TPAMI.2008.21
   Huang NE, 1998, P ROY SOC A-MATH PHY, V454, P903, DOI 10.1098/rspa.1998.0193
   Jain A., 1989, Fundamental of digital image processing
   Krinidis S, 2009, IEEE T IMAGE PROCESS, V18, P1, DOI 10.1109/TIP.2008.2007351
   Latecki LJ, 2000, IEEE T PATTERN ANAL, V22, P1185, DOI 10.1109/34.879802
   LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013
   Liu TL, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1129, DOI 10.1109/ICCV.1998.710858
   MARTINEZPEREZ MP, 1987, COMPUT VISION GRAPH, V39, P186, DOI 10.1016/S0734-189X(87)80165-2
   OGNIEWICZ RL, 1995, PATTERN RECOGN, V28, P343, DOI 10.1016/0031-3203(94)00105-U
   Pabel R, 2010, ADV DATA SCI ADAPT, V2, P337, DOI 10.1142/S1793536910000513
   Sebastian T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P755, DOI 10.1109/ICCV.2001.937602
   Shaked D, 1998, COMPUT VIS IMAGE UND, V69, P156, DOI 10.1006/cviu.1997.0598
   Shen W, 2011, PATTERN RECOGN, V44, P196, DOI 10.1016/j.patcog.2010.08.021
   Torsello A, 2004, COMPUT VIS IMAGE UND, V95, P1, DOI 10.1016/j.cviu.2004.03.006
   Vasilevskiy A, 2002, IEEE T PATTERN ANAL, V24, P1565, DOI 10.1109/TPAMI.2002.1114849
   Ward AD, 2010, IEEE T PATTERN ANAL, V32, P1084, DOI 10.1109/TPAMI.2009.81
   Wu ZH, 2004, P ROY SOC A-MATH PHY, V460, P1597, DOI 10.1098/rspa.2003.1221
   Wu ZH, 2009, ADV DATA SCI ADAPT, V1, P1, DOI 10.1142/S1793536909000047
   Xie WJ, 2003, PATTERN RECOGN, V36, P1529, DOI 10.1016/S0031-3203(02)00348-5
   ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P465
NR 31
TC 10
Z9 11
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2013
VL 31
IS 8
BP 533
EP 541
DI 10.1016/j.imavis.2013.04.005
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 185TO
UT WOS:000321993400001
DA 2024-07-18
ER

PT J
AU Ukita, N
AF Ukita, Norimichi
TI Simultaneous particle tracking in multi-action motion models with
   synthesized paths
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human pose tracking; Motion prior; Multiple actions; Action transition;
   Transition paths
ID NONLINEAR DIMENSIONALITY REDUCTION
AB This paper proposes human motion models of multiple actions for 3D pose tracking. A training pose sequence of each action, such as walking and jogging, is separately recorded by a motion capture system and modeled independently. This independent modeling of action-specific motions allows us 1) to optimize each model in accordance with only its respective motion and 2) to improve the scalability of the models. Unlike existing approaches with similar motion models (e.g. switching dynamical models), our pose tracking method uses the multiple models simultaneously for coping with ambiguous motions. For robust tracking with the multiple models, particle filtering is employed so that particles are distributed simultaneously in the models. Efficient use of the particles can be achieved by locating many particles in the model corresponding to an action that is currently observed. For transferring the particles among the models in quick response to changes in the action, transition paths are synthesized between the different models in order to virtually prepare inter-action motions. Experimental results demonstrate that the proposed models improve accuracy in pose tracking. (C) 2012 Elsevier B.V. All rights reserved.
C1 Nara Inst Sci & Technol, Nara 6300192, Japan.
C3 Nara Institute of Science & Technology
RP Ukita, N (corresponding author), Nara Inst Sci & Technol, Nara 6300192, Japan.
EM ukita@ieee.org
CR Agarwal A., 2004, CVPR
   [Anonymous], 2006, CVPR
   [Anonymous], 2000, CVPR
   [Anonymous], 2008, ICML
   [Anonymous], INT C MACH LEARN
   [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273619
   [Anonymous], 2004, CVPR
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bitzer S., 2009, IEEE RAS HUMANOIDS
   Brand M., 1999, ICCV
   Chen J., 2009, CVPR
   Cheung G., 2000, CVPR, P2
   del Rincón JM, 2011, IEEE T SYST MAN CY B, V41, P26, DOI 10.1109/TSMCB.2010.2044041
   Ek C., 2007, MLMI
   FATHI A, 2007, ICCV
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Geiger Andreas., 2009, CVPR
   Hirai M., 2009, ICCV
   HOU S, 2007, ICCV
   How N., 1999, NIPS
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Jaeggli T., 2007, 2 WORKSH HUMAN MOTIO
   Kovar L., 2002, SIGGRAPH
   Lawrence N, 2005, J MACH LEARN RES, V6, P1783
   LAWRENCE N, 2006, ICML
   Lawrence N. D., 2009, ICML
   MacCormick J., 1999, ICCV
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Moeslund TB, 2001, COMPUT VIS IMAGE UND, V81, P231, DOI 10.1006/cviu.2000.0897
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Ning HZ, 2004, PATTERN RECOGN, V37, P1423, DOI 10.1016/j.patcog.2004.01.011
   Pavlovic V., 1999, ICCV
   Poppe R, 2007, COMPUT VIS IMAGE UND, V108, P4, DOI 10.1016/j.cviu.2006.10.016
   Reitsma P., 2004, ACM SIGGRAPH EUR S C
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Safonova A., 2004, SIGGRAPH
   Shon A., 2005, NIPS
   Sidenbladh H., 2002, ECCV
   Sigal L., 2006, CS0608 BROWN U
   Sullivan J, 2001, INT J COMPUT VISION, V44, P111, DOI 10.1023/A:1011818912717
   SUN Y, 2006, BMVC
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Ukita N, 2012, COMPUT VIS IMAGE UND, V116, P500, DOI 10.1016/j.cviu.2011.11.005
   Urtasun R, 2006, COMPUT VIS IMAGE UND, V104, P157, DOI 10.1016/j.cviu.2006.08.006
   Vlasic D, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360696
   Vondrak M., 2008, CVPR
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Xiang SM, 2011, IEEE T SYST MAN CY B, V41, P1250, DOI 10.1109/TSMCB.2011.2123886
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
   Zhao LM, 2009, GRAPH MODELS, V71, P139, DOI 10.1016/j.gmod.2009.04.001
   Zhao X., 2007, IEEE WORKSH APPL COM
NR 51
TC 7
Z9 8
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2013
VL 31
IS 6-7
BP 448
EP 459
DI 10.1016/j.imavis.2012.09.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 172UH
UT WOS:000321029900004
DA 2024-07-18
ER

PT J
AU Rahtu, E
   Heikkilä, J
   Ojansivu, V
   Ahonen, T
AF Rahtu, Esa
   Heikkila, Janne
   Ojansivu, Ville
   Ahonen, Timo
TI Local phase quantization for blur-insensitive image analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Feature extraction; Invariant features; Blur invariance; Texture
   recognition; Face recognition
ID INVARIANT TEXTURE CLASSIFICATION; GRAY-SCALE; BINARY PATTERNS; ROTATION;
   RECOGNITION; DECOMPOSITION; HISTOGRAM; FEATURES
AB One of the principal causes for image quality degradation is blur. This frequent phenomenon is usually a result of misfocused optics or camera motion, and it is very difficult to undo. Beyond the impaired visual quality, blurring causes problems to computer vision algorithms. In this paper, we present a simple yet powerful image descriptor, which is robust against the most common image blurs. The proposed method is based on quantizing the phase information of the local Fourier transform and it can be used to characterize the underlying image texture. We show how to construct several variants of our descriptor by varying the technique for local phase estimation and utilizing the proposed data decorrelation scheme. The descriptors are assessed in texture and face recognition experiments, and the results are compared with several state-of-the-art methods. The difference to the baseline is considerable in the case of blurred images, but also with sharp images our method gives a highly competitive performance. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Rahtu, Esa; Heikkila, Janne] Univ Oulu, Ctr Machine Vis Res, Oulu, Finland.
   [Ojansivu, Ville] Univ Helsinki, Inst Mol Med Finland, FIN-00014 Helsinki, Finland.
   [Ahonen, Timo] Nokia Res Ctr, Palo Alto, CA USA.
C3 University of Oulu; University of Helsinki; Nokia Corporation; Nokia
   Bell Labs
RP Rahtu, E (corresponding author), Univ Oulu, Ctr Machine Vis Res, Oulu, Finland.
EM erahtu@ee.oulu.fi
OI Rahtu, Esa/0000-0001-8767-0864
FU Academy of Finland [127702, 128975]; EC [IST-214324 MOBIO]; Academy of
   Finland (AKA) [127702, 128975] Funding Source: Academy of Finland (AKA)
FX This work was supported by the Academy of Finland (grant nos. 127702 and
   128975) and the EC project IST-214324 MOBIO.
CR Ahonen T., 2007, FINN SIGN PROC S
   Ahonen T, 2008, P 19 INT C PATT REC
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Ahonen T, 2009, LECT NOTES COMPUT SC, V5575, P61, DOI 10.1007/978-3-642-02230-2_7
   [Anonymous], 1995, Signal Processing for Computer Vision
   [Anonymous], ACM T GRAPHICS
   [Anonymous], VOEC
   [Anonymous], P IEEE C COMP VIS PA
   Banham MR, 1997, IEEE SIGNAL PROC MAG, V14, P24, DOI 10.1109/79.581363
   Bihan Jiang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P314, DOI 10.1109/FG.2011.5771416
   Boukerroui D, 2004, J MATH IMAGING VIS, V21, P53, DOI 10.1023/B:JMIV.0000026557.50965.09
   Brahnam S., 2010, Proc. International Conference on Bioinformatics and Computational Biology, P159
   CHANG S, 1987, PATTERN RECOGN LETT, V5, P337, DOI 10.1016/0167-8655(87)90075-4
   CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730
   Chetverikov D, 2000, IMAGE VISION COMPUT, V18, P975, DOI 10.1016/S0262-8856(00)00041-X
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Dhall A., 2011, P WORKSH FAC EXPR RE
   Doretto G, 2003, INT J COMPUT VISION, V51, P91, DOI 10.1023/A:1021669406132
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   Fischer S., 1995, Theory and Applications of Image Analysis II. Selected Paper from the 9th Scandinavian Conference on Image Analysis, P101
   Flusser J, 1998, IEEE T PATTERN ANAL, V20, P590, DOI 10.1109/34.683773
   Fountain SR, 1998, PATTERN RECOGN, V31, P1725, DOI 10.1016/S0031-3203(98)00015-6
   Ghanem B., 2010, P EUR C COMP VIS
   Heikkila J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P818, DOI 10.1109/ICPR.2010.206
   Heikkilä J, 2009, LNLA: 2009 INTERNATIONAL WORKSHOP ON LOCAL AND NON-LOCAL APPROXIMATION IN IMAGE PROCESSING, P104, DOI 10.1109/LNLA.2009.5278397
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Manian V, 1998, PATTERN RECOGN, V31, P1937, DOI 10.1016/S0031-3203(98)00053-3
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   Masashi N., 2011, IEEE T PATT IN PRESS
   Mellor M, 2008, IEEE T PATTERN ANAL, V30, P52, DOI 10.1109/TPAMI.2007.1161
   Mirmehdi Majid., 2008, Handbook of Texture Analysis
   Nanni L, 2012, EXPERT SYST APPL, V39, P1968, DOI 10.1016/j.eswa.2011.08.050
   Nanni L, 2010, ARTIF INTELL MED, V49, P117, DOI 10.1016/j.artmed.2010.02.006
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojansivu V., 2008, P 19 INT C PATT REC
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   Ojansivu V, 2007, 14TH INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND PROCESSING, PROCEEDINGS, P583, DOI 10.1109/ICIAP.2007.4362840
   Oliver W., 2010, P IEEE C COMP VIS PA
   Péteri R, 2010, PATTERN RECOGN LETT, V31, P1627, DOI 10.1016/j.patrec.2010.05.009
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Tan X., 2007, P AN MOD FAC GEST
   van de Weijer J, 2006, IEEE IMAGE PROC, P993
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   VARMA M, 2003, P IEEE C COMP VIS PA
   Varma M., 2002, P EUR C COMP VIS
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Wang Z., 2003, NIPS, P786
   Wu WR, 1996, IEEE T IMAGE PROCESS, V5, P1423, DOI 10.1109/83.536891
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang H, 2010, IEEE T IMAGE PROCESS, V19, P596, DOI 10.1109/TIP.2009.2036702
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
   Zhang L, 2010, IEEE IMAGE PROC, P2677, DOI 10.1109/ICIP.2010.5651885
   Zhang WC, 2009, PATTERN ANAL APPL, V12, P301, DOI 10.1007/s10044-008-0123-0
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhen Lei, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P161, DOI 10.1109/FG.2011.5771391
   Zhou F, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P610, DOI 10.1109/ICIP.2001.958567
NR 62
TC 84
Z9 91
U1 0
U2 20
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2012
VL 30
IS 8
BP 501
EP 512
DI 10.1016/j.imavis.2012.04.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007QV
UT WOS:000308904100011
DA 2024-07-18
ER

PT J
AU El-Zehiry, N
   Sahoo, P
   Elmaghraby, A
AF El-Zehiry, Noha
   Sahoo, Prasanna
   Elmaghraby, Adel
TI Combinatorial Optimization of the piecewise constant Mumford-Shah
   functional with application to scalar/vector valued and volumetric image
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active contours; Graph cuts; Image segmentation
ID ACTIVE CONTOURS; MINIMIZATION; ALGORITHMS
AB Front propagation models represent an important category of image segmentation techniques in the current literature. These models are normally formulated in a continuous level sets framework and optimized using gradient descent methods. Such formulations result in very slow algorithms that get easily stuck in local solutions and are highly sensitive to initialization.
   In this paper, we reformulate one of the most influential front propagation models, the Chan-Vese model, in the discrete domain. The graph representability and submodularity of the discrete energy function is established and then max-flow/min-cut approach is applied to perform the optimization of the discrete energy function. Our results show that this formulation is much more robust than the level sets formulation. Our approach is not sensitive to initialization and provides much faster solutions than level sets. The results also depict that our segmentation approach is robust to topology changes, noise and ill-defined edges, i.e., it preserves all the advantages associated with level sets methods. (C) 2010 Elsevier B.V. All rights reserved.
C1 [El-Zehiry, Noha] Siemens Corp Res, Dept Imaging & Visualizat, Princeton, NJ 08540 USA.
   [Sahoo, Prasanna] Univ Louisville, Dept Math, Louisville, KY 40292 USA.
   [Elmaghraby, Adel] Univ Louisville, Dept Comp Sci, Louisville, KY 40292 USA.
C3 Siemens AG; University of Louisville; University of Louisville
RP El-Zehiry, N (corresponding author), Siemens Corp Res, Dept Imaging & Visualizat, Princeton, NJ 08540 USA.
EM noha.el-zehiry@siemens.com; sahoo@louisville.edu; adel@louisville.edu
RI Elmaghraby, Adel S/B-3353-2014; cai, bo/G-1491-2010
OI Elmaghraby, Adel S/0000-0001-5274-8596; 
CR AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681
   [Anonymous], 2001, Interactive graph cuts for optimal boundary & region segmentation of objects in nd images, DOI DOI 10.1109/ICCV.2001.937505
   [Anonymous], POVERTY GENDER MIGRA
   Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Bresson X, 2007, J MATH IMAGING VIS, V28, P151, DOI 10.1007/s10851-007-0002-0
   Bresson X, 2006, INT J COMPUT VISION, V68, P145, DOI 10.1007/s11263-006-6658-x
   Chan T, 2005, PROC CVPR IEEE, P1164
   Chan TE, 2000, J VIS COMMUN IMAGE R, V11, P130, DOI 10.1006/jvci.1999.0442
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chan TF, 2006, SIAM J APPL MATH, V66, P1632, DOI 10.1137/040615286
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Cremers D, 2003, LECT NOTES COMPUT SC, V2695, P388
   Darbon J, 2007, LECT NOTES COMPUT SC, V4418, P283
   El-Zehiry N, 2007, PROCEEDINGS OF THE SEVENTH IASTED INTERNATIONAL CONFERENCE ON VISUALIZATION, IMAGING, AND IMAGE PROCESSING, P182
   Fedkiw SOR., 2002, APPL MATH SCI, V44, P77, DOI [10.1007/ b98879, 10.1007/b98879]
   Fundana K, 2007, IEEE IMAGE PROC, P285
   Goldstein T., 2009, J SCI COMPU IN PRESS
   Grady L, 2009, IEEE T IMAGE PROCESS, V18, P2547, DOI 10.1109/TIP.2009.2028258
   Huang FZ, 2006, INT C PATT RECOG, P56
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kichenassamy S, 1996, ARCH RATION MECH AN, V134, P275, DOI 10.1007/BF00379537
   Kolmogorov V, 2005, IEEE I CONF COMP VIS, P564
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   MALLADI R, 1995, IEEE T PATTERN ANAL, V17, P158, DOI 10.1109/34.368173
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Paraagios N., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P422, DOI 10.1109/CVPR.1999.784715
   RONFARD R, 1994, INT J COMPUT VISION, V13, P229, DOI 10.1007/BF01427153
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   SAMSON C, 1999, 3662 INRIA
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Xu N, 2003, PROC CVPR IEEE, P46
   Yezzi A, 1997, IEEE T MED IMAGING, V16, P199, DOI 10.1109/42.563665
NR 33
TC 12
Z9 17
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2011
VL 29
IS 6
BP 365
EP 381
DI 10.1016/j.imavis.2010.09.002
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 761TD
UT WOS:000290423000001
DA 2024-07-18
ER

PT J
AU Park, CB
   Lee, SW
AF Park, Chang-Beom
   Lee, Seong-Whan
TI Real-time 3D pointing gesture recognition for mobile robots with cascade
   HMM and particle filter
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human-robot interaction; Pointing gesture recognition; Cascade HMM; 3D
   particle filter
AB In this paper we present a real-time 3D pointing gesture recognition algorithm for mobile robots based on a cascade hidden Markov model (HMM) and a particle filter Among the various human gestures the pointing gesture is very useful to human-robot interaction (HRI) In fact it is highly intuitive does not involve a priori assumptions and has no substitute in other modes of interaction A major issue in pointing gesture recognition is the difficultly of accurate estimation of the pointing direction caused by the difficulty of hand tracking and the unreliability of the direction estimation
   The proposed method involves the use of a stereo camera and 3D particle filters for reliable hand tracking and a cascade of two HMMs for a robust estimate of the pointing direction When a subject enters the field of view of the camera his or her face and two hands are located and tracked using particle filters The first stage HMM takes the hand position estimate and maps It to a more accurate position by modeling the kinematic characteristics of finger pointing The resulting 3D coordinates are used as input Into the second stage HMM that discriminates pointing gestures from other types Finally the pointing direction is estimated for the pointing state
   The proposed method can deal with both large and small pointing gestures The experimental results show gesture recognition and target selection rates of better than 89% and 99% respectively during human-robot interaction (C) 2010 Elsevier B V All rights reserved
C1 [Lee, Seong-Whan] Korea Univ, Dept Brain & Cognit Engn, Seoul 136713, South Korea.
   [Park, Chang-Beom; Lee, Seong-Whan] Korea Univ, Dept Comp Sci & Engn, Seoul 136713, South Korea.
C3 Korea University; Korea University
RP Lee, SW (corresponding author), Korea Univ, Dept Brain & Cognit Engn, Seoul 136713, South Korea.
RI Lee, Seong-Whan/C-7928-2012
FU Ministry of Education Science and Technology Republic of Korea
   [R31-2008-000-10008-0]; Ministry of Commerce Industry and Energy of
   Korea
FX This research was supported by World Class University Project funded by
   the Ministry of Education Science and Technology Republic of Korea
   (R31-2008-000-10008-0) This work was also supported by the Intelligent
   Robotics Development Program among the 21st Century Frontier R&D
   Programs funded by the Ministry of Commerce Industry and Energy of Korea
CR Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203
   [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], NIPS
   BOLT RA, 1980, P 7 ANN C COMP GRAPH, P262, DOI [DOI 10.1145/800250.807503, 10.1145/965105.807503, DOI 10.1145/965105.807503]
   CARBINI S, 2004, P INT WORKSH VIS OBS, P27
   DARRELL T, 2004, P IEEE COMP SOC COMP, V2, P398
   Hayashi K, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P681, DOI 10.1109/AFGR.2004.1301613
   Ho MAT, 2005, IEEE T ROBOT, V21, P497, DOI 10.1109/TRO.2004.840912
   Hong Pengyu, 2000, P 4 IEEE INT C AUT F, P410
   Hosoya E, 2004, LECT NOTES COMPUT SC, V3058, P72
   IBI S, 1999, P INT C INT ROB SYST, P851
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   ISARD M, 1998, P EUR C COMP VIS, V1, P767
   Jones MJ, 2002, INT J COMPUT VISION, V46, P81, DOI 10.1023/A:1013200319198
   Kehl R, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P577, DOI 10.1109/AFGR.2004.1301595
   Keskin C., 2003, P INT C ART NEUR NET, P567
   KRUMM J, 2003, P WORKSH LOC AW COMP, P25
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   MOESLUND TB, 2001, IMAGE, V81, P231
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   NAVARATNAM R, 2005, P BRIT MACH VIS C, P949
   Nickel K., 2003, Proceedings of the 5th International Conference on Multimodal Interfaces (ICMI '03), P140, DOI [10.1145/958432.958460, DOI 10.1145/958432.958460]
   Rabiner L.R., 1993, FUNDAMENTALS SPEECH, VVolume 14
   RICHARZ J, 2007, P INT J ADV ROBOTIC, V4, P139
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   STIEFELHAGEN R, 2004, P 2004 IEEE RSJ INT, V3, P2422
   TAYCHER L, 2003, P INT WORKSH STAT CO
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Yamamoto Y, 2004, INT C PATT RECOG, P965, DOI 10.1109/ICPR.2004.1333934
   Yang HD, 2007, IEEE T ROBOT, V23, P256, DOI 10.1109/TRO.2006.889491
NR 31
TC 51
Z9 58
U1 0
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2011
VL 29
IS 1
BP 51
EP 63
DI 10.1016/j.imavis.2010.08.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 679BP
UT WOS:000284134700005
DA 2024-07-18
ER

PT J
AU Pribanic, T
   Mrvos, S
   Salvi, J
AF Pribanic, Tomislav
   Mrvos, Sasa
   Salvi, Joaquim
TI Efficient multiple phase shift patterns for dense 3D acquisition in
   structured light scanning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D acquisition; Structured light; Pattern projection; Multiple phase
   shifting; Phase unwrapping
ID FOURIER-TRANSFORM PROFILOMETRY; SHAPE MEASUREMENT;
   AUTOMATIC-MEASUREMENT; CALIBRATION; OBJECTS
AB Although phase shifts (PS) are frequently used to acquire colored surfaces of static objects, especially when acquisition time is not critical, the periodic nature of relative (wrapped) PS maps makes it necessary to deal with the issue of phase unwrapping. Consequently, multiple phase shifts (MPS) have been widely used as an alternative, but this usually involves a large number of different PS maps to unwrap an absolute (unique) phase. In this paper we propose a new MPS method to unwrap a phase and accurately perform the dense 3D acquisition of neutral and colored objects using only two PS maps. Accuracy is reported including a quantitative and qualitative evaluation of the results. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Pribanic, Tomislav; Mrvos, Sasa] Univ Zagreb, Fac Elect Engn & Comp, HR-10000 Unska 3, Croatia.
   [Salvi, Joaquim] Univ Girona, Inst Informat & Applicat, Girona 17071, Spain.
C3 University of Zagreb; Universitat de Girona
RP Pribanic, T (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, HR-10000 Unska 3, Croatia.
EM tomislav.pribanic@fer.hr; sasa.mrvos@fer.hr; qsalvi@eia.udg.es
RI Salvi, Joaquim/L-2648-2014
OI Salvi, Joaquim/0000-0002-9482-7126
CR Albitar C, 2007, IEEE IMAGE PROC, P3325
   [Anonymous], 1998, ALGORITHMS C
   [Anonymous], 2008, P 2008 IEEE C COMPUT, DOI DOI 10.1109/CVPR.2008.4587702
   [Anonymous], 2002, NUMERICAL RECIPES C
   Burke J, 2002, P SOC PHOTO-OPT INS, V4778, P312, DOI 10.1117/12.473547
   CARRIHILL B, 1985, COMPUT VISION GRAPH, V32, P337, DOI 10.1016/0734-189X(85)90056-8
   Caspi D, 1998, IEEE T PATTERN ANAL, V20, P470, DOI 10.1109/34.682177
   Chan N., 2003, LUND U GIS CENT, P1
   CHAZAN G, 1995, 121 CTR COMM INF TEC, P1
   Chen WJ, 2007, OPT LASER TECHNOL, V39, P821, DOI 10.1016/j.optlastec.2006.02.002
   Coggrave CR, 2000, OPT ENG, V39, P91, DOI 10.1117/1.602340
   Fechteler P, 2009, IET COMPUT VIS, V3, P49, DOI 10.1049/iet-cvi.2008.0058
   Forster F, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P208
   Gorthi SS, 2005, PROC SPIE, V5856, P184, DOI 10.1117/12.612620
   GRIFFIN PM, 1992, PATTERN RECOGN, V25, P609, DOI 10.1016/0031-3203(92)90078-W
   Guan C, 2003, OPT EXPRESS, V11, P406, DOI 10.1364/OE.11.000406
   GUSHOV VI, 1991, OPT LASER ENG, V14, P311, DOI 10.1016/0143-8166(91)90055-X
   Hu EY, 2009, OPT LASER ENG, V47, P57, DOI 10.1016/j.optlaseng.2008.08.003
   Huntley JM, 1997, MEAS SCI TECHNOL, V8, P986, DOI 10.1088/0957-0233/8/9/005
   ITO M, 1995, PATTERN RECOGN, V28, P27, DOI 10.1016/0031-3203(94)E0047-O
   JINDONG T, 2007, OPTOELECTRONICS LETT, V3, P215
   Klette R., 2013, COMPUTER VISION 3 DI
   Koninckx TP, 2006, IEEE T PATTERN ANAL, V28, P432, DOI 10.1109/TPAMI.2006.62
   LI J, 1990, OPT ENG, V29, P1439, DOI 10.1117/12.55746
   Nadeborn W, 1996, OPT LASER ENG, V24, P245, DOI 10.1016/0143-8166(95)00017-8
   Ono N, 2004, SICE 2004 ANNUAL CONFERENCE, VOLS 1-3, P2544
   Pagès J, 2005, IMAGE VISION COMPUT, V23, P707, DOI 10.1016/j.imavis.2005.05.007
   Pribanic T., 2006, Automatika, V47, P141
   Pribanic T, 2007, MACH VISION APPL, V18, P367, DOI 10.1007/s00138-007-0068-0
   Ribenboim P., 1972, Algebraic Numbers
   Saldner HO, 1997, APPL OPTICS, V36, P2770, DOI 10.1364/AO.36.002770
   Salvi J, 2004, PATTERN RECOGN, V37, P827, DOI 10.1016/j.patcog.2003.10.002
   Salvi J, 2002, PATTERN RECOGN, V35, P1617, DOI 10.1016/S0031-3203(01)00126-1
   Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012
   Sansoni G, 2003, REV SCI INSTRUM, V74, P2593, DOI 10.1063/1.1561602
   Sato T, 1999, P SOC PHOTO-OPT INS, V3640, P28, DOI 10.1117/12.341069
   Su XY, 2001, OPT LASER ENG, V35, P263, DOI 10.1016/S0143-8166(01)00023-9
   TAJIMA J, 1990, 10 INT C PATT REC AT, P393
   TAKEDA M, 1983, APPL OPTICS, V22, P3977, DOI 10.1364/AO.22.003977
   TEHRANI M, 2008, 3 INT C INF COMM TEC, P1
   WEI GQ, 1994, IEEE T PATTERN ANAL, V16, P469, DOI 10.1109/34.291450
   Wiora G, 2000, P SOC PHOTO-OPT INS, V4117, P289, DOI 10.1117/12.404832
   Wust C., 1991, Machine Vision and Applications, V4, P193, DOI 10.1007/BF01230201
   Yue HM, 2007, OPT LASER TECHNOL, V39, P1170, DOI 10.1016/j.optlastec.2006.08.014
   Zhang L, 2002, FIRST INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING VISUALIZATION AND TRANSMISSION, P24, DOI 10.1109/TDPVT.2002.1024035
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 46
TC 54
Z9 63
U1 0
U2 30
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1255
EP 1266
DI 10.1016/j.imavis.2010.01.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400008
DA 2024-07-18
ER

PT J
AU Kaliraj, G
   Baskar, S
AF Kaliraj, G.
   Baskar, S.
TI An efficient approach for the removal of impulse noise from the
   corrupted image using neural network based impulse detector
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Neural network; Image filtering; Impulse detector; Impulse noise
ID FILTERS
AB A new efficient approach to detect the impulse noise from the corrupted image using feed forward neural network (FFNN) is presented. A modified version of the arithmetic mean filter is proposed to remove the detected impulse noise. The performance of proposed noise detection approach is analyzed using the performance measures such as False Alarm Ratio (FAR), Missed Noise (MN) pixels and Falsely Detected Noise (FDN) pixels. The simulation results show that these performances are robust even at higher percentage of noise. The filtered result is compared with the other recent approaches in terms of Peak Signal to Noise Ratio (PSNR). The proposed method produces remarkably good results both in quantitative measures and qualitative judgments of image quality. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Kaliraj, G.] Tessolve Serv Pvt Ltd, RF Testing Dept, Madras, Tamil Nadu, India.
   [Baskar, S.] Thiagarajar Coll Engn, Dept Elect & Elect Engn, Madurai, Tamil Nadu, India.
C3 Thiagarajar College of Engineering
RP Kaliraj, G (corresponding author), Tessolve Serv Pvt Ltd, RF Testing Dept, Madras, Tamil Nadu, India.
EM guru_kaliraj@rediffmail.com; sbeee@tce.edu
RI SUBRAMANIAN, BASKAR/C-1286-2009
OI S, BASKAR/0000-0002-2735-0487
CR Abreu E, 1996, IEEE T IMAGE PROCESS, V5, P1012, DOI 10.1109/83.503916
   [Anonymous], Standard Test Images
   APALKOV IV, 2005, P EUROCON 2005 NOV 2
   BROWNRIGG DRK, 1984, COMMUN ACM, V27, P807, DOI 10.1145/358198.358222
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Garnett R, 2005, IEEE T IMAGE PROCESS, V14, P1747, DOI 10.1109/TIP.2005.857261
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   KONG H, 1998, IEEE T CIRC SYST 1, V45
   Lee CS, 1997, FUZZY SET SYST, V89, P157, DOI 10.1016/S0165-0114(96)00075-9
   LEE CS, 2000, FUZZY TECHNIQUES IMA, V52, P172
   LUO WB, 2006, IEEE SIGNAL PROCESS, V13
   RUSSO F, 1995, IEEE T IMAGE PROCESS, V4, P1169, DOI 10.1109/83.403425
   Russo F, 1996, IEEE SIGNAL PROC LET, V3, P168, DOI 10.1109/97.503279
   Russo F, 1999, FUZZY SET SYST, V103, P265, DOI 10.1016/S0165-0114(98)00226-7
   RUSSO F, 2004, MEASUREMENT, V36
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Yüksel ME, 2006, IEEE T IMAGE PROCESS, V15, P928, DOI 10.1109/TIP.2005.863941
   Yüksel ME, 2004, IEEE T FUZZY SYST, V12, P854, DOI 10.1109/TFUZZ.2004.836075
   ZHANG SQ, 2002, IEEE SIGNAL PROCESS, V9
NR 20
TC 47
Z9 52
U1 0
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 458
EP 466
DI 10.1016/j.imavis.2009.07.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300016
DA 2024-07-18
ER

PT J
AU Lu, WL
   Okuma, K
   Little, JJ
AF Lu, Wei-Lwun
   Okuma, Kenji
   Little, James J.
TI Tracking and recognizing actions of multiple hockey players using the
   boosted particle filter
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Tracking; Action recognition; Boosted particle filter
ID ROBUST; TUTORIAL; OBJECTS; MODELS
AB This article presents a system that can automatically track multiple hockey players and simultaneously recognize their actions given a single broadcast video sequence, where detection is complicated by a panning, tilting, and zooming camera. There are three contributions. Firstly, we use the Histograms of Oriented Gradients (HOG) to represent the players, and introduce a probabilistic framework to model the appearance of the players by a mixture of local subspaces. We also employ an efficient off-line learning algorithm to learn the templates from training data, and an efficient online filtering algorithm to update the templates used by the tracker. Secondly, we augment the boosted particle filter (BPF) with a new observation model and a template updater that improves the robustness of the tracking system. Finally, we recognize the players' actions by combining the HOG descriptors with a pure multi-class sparse classifier with a robust motion similarity measure. Experiments on long sequences show promising quantitative and qualitative results. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Lu, Wei-Lwun; Okuma, Kenji; Little, James J.] Univ British Columbia, Dept Comp Sci, Vancouver, BC V6T 1Z4, Canada.
C3 University of British Columbia
RP Lu, WL (corresponding author), Univ British Columbia, Dept Comp Sci, 2366 Main Mall, Vancouver, BC V6T 1Z4, Canada.
EM vailen@cs.ubc.ca; okumak@cs.ubc.ca; little@cs.ubc.ca
CR [Anonymous], THESIS U BRIT COLUMB
   [Anonymous], 1998, 9810 COMP CAMBR RES
   [Anonymous], 3 CAN C COMP ROB VIS
   [Anonymous], 1995, INTRO KALMAN FILTER
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2006, 2006 IEEE COMP SOC C
   [Anonymous], 1981, P 7 INT JOINT C ART
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   CAWLEY G, 2007, ADV NEURAL INFORM PR, V19
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Doucet A., 2005, Sequential Monte Carlo methods in practice
   Doucet A., 2000, Proceedings of the Sixteenth conference on Uncertainty in artificial intelligence, P176
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Freeman W.T., 1995, Orientation histograms for hand gesture recognition
   Freeman WT, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P100, DOI 10.1109/AFGR.1996.557250
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Giebel J, 2004, LECT NOTES COMPUT SC, V2034, P241
   Hu WM, 2004, IEEE T SYST MAN CY C, V34, P334, DOI 10.1109/TSMCC.2004.829274
   Hue C, 2002, IEEE T AERO ELEC SYS, V38, P791, DOI 10.1109/TAES.2002.1039400
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Jain A. K., 1988, Algorithms for Clustering Data, P446
   Khan Z, 2004, PROC CVPR IEEE, P980
   KOLLER D, 1994, EUR C COMP VIS, P186
   Krishnapuram B, 2005, IEEE T PATTERN ANAL, V27, P957, DOI 10.1109/TPAMI.2005.127
   Lim Hwasup., 2006, COMPUTER VISION PATT, V1, P751
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LU WL, 2006, ECCV WORKSH COMP VIS, P49
   MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275
   Matthews I, 2004, IEEE T PATTERN ANAL, V26, P810, DOI 10.1109/TPAMI.2004.16
   Misu T, 2002, INT C PATT RECOG, P556, DOI 10.1109/ICPR.2002.1044792
   MOON K, 2006, IEEE C COMP VIS PATT, V1, P198
   Murphy K, 2001, STAT ENG IN, P499
   Murphy K., KALMAN FILTER TOOLBO
   Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355
   NEEDHAM CJ, 2001, BMVC, P93
   Oh SM, 2005, IEEE I CONF COMP VIS, P1161
   OKURNA K, 2004, EUR C COMP VIS, P28
   Pavlovic V., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P94, DOI 10.1109/ICCV.1999.791203
   PEREZ P, 2002, EUR C COMP VIS, P661
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Rui Y, 2001, PROC CVPR IEEE, P786
   Shevade SK, 2003, BIOINFORMATICS, V19, P2246, DOI 10.1093/bioinformatics/btg308
   Tipping ME, 1999, NEURAL COMPUT, V11, P443, DOI 10.1162/089976699300016728
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Toyama K, 2002, INT J COMPUT VISION, V48, P9, DOI 10.1023/A:1014899027014
   van der Merwe R., 2001, ADV NEURAL INFORM PR, V13
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   WANG Y, 2007, P 2 WORKSH HUM MOT U
   Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
   YANG C, 2005, IEEE C COMP VIS PATT, V1, P212
NR 57
TC 74
Z9 89
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 189
EP 205
DI 10.1016/j.imavis.2008.02.008
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700019
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hu, QM
   Luo, SH
   Qiao, Y
   Qian, GY
AF Hu, Qingmao
   Luo, Suhuai
   Qiao, Yu
   Qian, Guoyu
TI Supervised grayscale thresholding based on transition regions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Grayscale thresholding; Transition region; Supervision; Prior knowledge
ID GRAY-LEVEL; SELECTION; EXTRACTION
AB A new thresholding framework is proposed which is transition region based, and consists of deriving the transition region with the help of supervision and calculating the threshold from the transition region. Four ways of supervision are studied: picking up an object and a background pixel, from other clustering or segmentation results, based on sample statistics, and exploration of background proportions. The approach has been validated both quantitatively and qualitatively. It is found that the proposed approach: (I) is more robust, consistent and reliable than the conventional transition-region-based thresholding methods; and (2) is easier to implement and has wider applicability than existing supervised thresholding methods. The approach is especially useful for segmenting difficult images with multiple objects and/or serious imaging artifacts. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Hu, Qingmao] Chinese Univ Hong Kong, Chinese Acad Sci, Shenzhen Inst Adv Integrat Technol, Hong Kong, Hong Kong, Peoples R China.
   [Hu, Qingmao] Chinese Univ Hong Kong, Chinese Acad Sci, Key Lab Biomed Informat & Hlth Engn, Hong Kong, Hong Kong, Peoples R China.
   [Luo, Suhuai; Qian, Guoyu] Univ Newcastle, Sch Design Commun & Informat Technol, Callaghan, NSW 2308, Australia.
   [Qiao, Yu; Qian, Guoyu] Agcy Sci Technol & Res, Biomed Imaging Lab, Singapore 138671, Singapore.
C3 Chinese University of Hong Kong; Chinese Academy of Sciences; Shenzhen
   Institute of Advanced Technology, CAS; Chinese Academy of Sciences;
   Chinese University of Hong Kong; University of Newcastle; Agency for
   Science Technology & Research (A*STAR)
RP Hu, QM (corresponding author), Chinese Univ Hong Kong, Chinese Acad Sci, Shenzhen Inst Adv Integrat Technol, Hong Kong, Hong Kong, Peoples R China.
EM qm.hu@siat.ac.cn; suhuai.luo@newcastle.edu.au; qiaoyu@alumni.nus.edu.sg;
   qiangy@sbic.a-star.edu.sg
RI QIAO, Yu/F-6108-2010; Liu, Zhe/KEJ-5299-2024
OI Luo, Suhuai/0000-0002-6185-6035
CR Bezdek James C., 1981, PATTERN RECOGN
   Cheng HD, 1998, PATTERN RECOGN, V31, P857, DOI 10.1016/S0031-3203(97)00113-1
   Collins DL, 1998, IEEE T MED IMAGING, V17, P463, DOI 10.1109/42.712135
   Giarratano J., 1994, EXPERT SYSTEMS PRINC, V2nd
   Hu QM, 2006, IEEE T IMAGE PROCESS, V15, P228, DOI 10.1109/TIP.2005.860348
   Hu QM, 2005, MAGN RESON MED, V53, P970, DOI 10.1002/mrm.20424
   KITTLER J, 1986, PATTERN RECOGN, V19, P41, DOI 10.1016/0031-3203(86)90030-0
   LEE JS, 1989, IEEE T SYST MAN CYB, V19, P422, DOI 10.1109/21.31046
   LI CH, 1993, PATTERN RECOGN, V26, P617, DOI 10.1016/0031-3203(93)90115-D
   Nowinski WL, 2002, MED RAD DIA IMG, P79
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PANDA DP, 1978, IEEE T COMPUT, V27, P875, DOI 10.1109/TC.1978.1675208
   PUN T, 1981, COMPUT VISION GRAPH, V16, P210, DOI 10.1016/0146-664X(81)90038-1
   Qiao Y, 2007, PATTERN RECOGN, V40, P596, DOI 10.1016/j.patcog.2006.04.027
   Saha PK, 2001, IEEE T PATTERN ANAL, V23, P689, DOI 10.1109/34.935844
   SEZAN MI, 1989, IEEE T MED IMAGING, V8, P154, DOI 10.1109/42.24863
   Talairach J., 1988, Co-planar stereotactic atlas of the human brain
   WESZKA JS, 1979, IEEE T SYST MAN CYB, V9, P38
   WU V, 1998, P SPIE 98 DOC REC JA, V5, P263
   Yan CX, 2003, PATTERN RECOGN LETT, V24, P2935, DOI 10.1016/S0167-8655(03)00154-5
   ZHANG YJ, 1991, PATTERN RECOGN LETT, V12, P13, DOI 10.1016/0167-8655(91)90023-F
NR 21
TC 10
Z9 10
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1677
EP 1684
DI 10.1016/j.imavis.2008.05.003
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500011
DA 2024-07-18
ER

PT J
AU Bödvarsson, B
   Klim, S
   Morkebjerg, M
   Mortensen, S
   Yoon, CH
   Chen, J
   Maclaren, JR
   Luther, PK
   Squire, JM
   Bones, PJ
   Millane, RP
AF Bodvarsson, B.
   Klim, S.
   Morkebjerg, M.
   Mortensen, S.
   Yoon, C. H.
   Chen, J.
   Maclaren, J. R.
   Luther, P. K.
   Squire, J. M.
   Bones, P. J.
   Millane, R. P.
TI A morphological image processing method for locating myosin filaments in
   muscle electron micrographs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image analysis; morphology; electron micrograph; disorder; myosin;
   muscle
AB A morphological image processing based method for determining the positions of myosin filaments in electron micrographs of muscle cross-sections is described. The filaments are embedded in a noisy and variable background in the images, but lie on a relatively regular lattice. The filament positions are determined by a novel implementation of morphological grayscale reconstruction in which a threshold is optimised by using the lattice regularity of the derived filament markers. This approach leads to a robust algorithm. The method is applied to a number of muscle micrographs. (C) 2008 Published by Elsevier B.V.
C1 [Bodvarsson, B.; Klim, S.; Morkebjerg, M.; Mortensen, S.; Yoon, C. H.; Chen, J.; Maclaren, J. R.; Bones, P. J.; Millane, R. P.] Univ Canterbury, Dept Elect & Comp Engn, Computat Imaging Grp, Christchurch 1, New Zealand.
   [Luther, P. K.] Univ London Imperial Coll Sci Technol & Med, Natl Heart & Lung Inst, London SW7 2AZ, England.
   [Squire, J. M.] Univ Bristol, Dept Physiol, Muscle Contract Grp, Bristol BS8 1TD, Avon, England.
C3 University of Canterbury; Imperial College London; University of Bristol
RP Millane, RP (corresponding author), Univ Canterbury, Dept Elect & Comp Engn, Computat Imaging Grp, Private Bag 4800, Christchurch 1, New Zealand.
EM rick@elec.canterbury.ac.nz
RI Millane, Rick/AAG-2864-2020; Maclaren, Julian/E-6478-2011
OI Luther, Pradeep/0000-0002-8841-4368; Maclaren,
   Julian/0000-0001-7073-2926
CR Bödvarsson B, 2004, P SOC PHOTO-OPT INS, V5562, P97, DOI 10.1117/12.562357
   Dougherty E., 1994, An introduction to nonlinear image processing, VTT16
   Geeves MA, 2005, ADV PROTEIN CHEM, V71, P161, DOI 10.1016/S0065-3233(04)71005-0
   Grimaud M., 1992, Image Algebra and Morphological Image Processing III, V1769, P292
   Luther PK, 1996, J MORPHOL, V229, P325, DOI 10.1002/(SICI)1097-4687(199609)229:3<325::AID-JMOR7>3.0.CO;2-X
   LUTHER PK, 1980, J MOL BIOL, V141, P409, DOI 10.1016/0022-2836(80)90254-5
   Squire JM, 1997, CURR OPIN STRUC BIOL, V7, P247, DOI 10.1016/S0959-440X(97)80033-4
   Squire JM., 1981, STRUCTURAL BASIS MUS
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
   YOON CH, 2004, P IMAGE VISION COMPU, P173
   YOON CH, 2005, DIGITAL IMAGE COMPUT, P551
NR 11
TC 5
Z9 5
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1073
EP 1080
DI 10.1016/j.imavis.2007.11.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300001
DA 2024-07-18
ER

PT J
AU Zhu, LX
   Xia, DS
AF Zhu Lixin
   Xia Deshen
TI Staircase effect alleviation by coupling gradient fidelity term
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image denoising; anisotropic diffusion; partial differential equation;
   gradient fidelity term
ID EDGE-DETECTION; IMAGE; EQUATIONS; SPACE
AB Image denoising with second order nonlinear PDEs often leads to an undesirable staircase effect, namely, the transformation of smooth regions into piecewise constant ones. In this paper, the similarity in gradient between the noisy images and the restored ones is described and preserved by the gradient fidelity term during the noise removal. The introduction of the Euler equation derived from the gradient fidelity term into nonlinear diffusion PDEs helps to alleviate staircase effect efficiently, while preserving sharp discontinuities in images. The gradient fidelity term is integrable in bounded variation function space, which makes our models outperform fourth order nonlinear PDE-based denoising methods in the preservation of edges and textures. In addition, the necessity of introducing spatial regularization into gradient estimation is theoretically analyzed and experimentally emphasized. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Zhu Lixin; Xia Deshen] Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.
C3 Nanjing University of Science & Technology
RP Zhu, LX (corresponding author), Nanjing Univ Sci & Technol, Sch Comp Sci & Technol, Nanjing 210094, Peoples R China.
EM rambozhuzhu@yahoo.com.cn
CR ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   Aubert G, 1997, SIAM J NUMER ANAL, V34, P1948, DOI 10.1137/S003614299529230X
   Buades A, 2006, IEEE T IMAGE PROCESS, V15, P1499, DOI 10.1109/TIP.2006.871137
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   Chambolle A, 1997, NUMER MATH, V76, P167, DOI 10.1007/s002110050258
   Chan T, 2000, SIAM J SCI COMPUT, V22, P503, DOI 10.1137/S1064827598344169
   DIDAS S, 2006, 143 U BREM DEP MATH
   Fattal R., 2002, ACM Transactions on Graphics, V21, P249, DOI 10.1145/566570.566573
   Gilboa G, 2003, IEEE IMAGE PROC, P865
   Greer JB, 2004, DISCRETE CONT DYN-A, V10, P349
   Kim S., Numerical modeling for the recovery of fine structures in pde-based image denoising
   Lysaker M, 2004, IEEE T IMAGE PROCESS, V13, P1345, DOI 10.1109/TIP.2004.834662
   Lysaker M, 2003, IEEE T IMAGE PROCESS, V12, P1579, DOI 10.1109/TIP.2003.819229
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   SAPIRO G, 1993, INT J COMPUT VISION, V11, P25, DOI 10.1007/BF01420591
   SAPIRO G, 2005, IEEE INT C IM PROC, V2, P11
   Tschumperlé D, 2005, IEEE T PATTERN ANAL, V27, P506, DOI 10.1109/TPAMI.2005.87
   Tumblin J, 1999, COMP GRAPH, P83, DOI 10.1145/311535.311544
   Wei GW, 1999, IEEE SIGNAL PROC LET, V6, P165, DOI 10.1109/97.769359
   Weickert J, 1997, LECT NOTES COMPUT SC, V1252, P3
   You YL, 2000, IEEE T IMAGE PROCESS, V9, P1723, DOI 10.1109/83.869184
   YOU YL, 1996, IEEE T IMAGE PROCESS, V5
NR 25
TC 26
Z9 33
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1163
EP 1170
DI 10.1016/j.imavis.2008.01.008
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300010
DA 2024-07-18
ER

PT J
AU Menudet, JF
   Becker, JM
   Fournel, T
   Mennessier, C
AF Menudet, J. F.
   Becker, J. M.
   Fournel, T.
   Mennessier, C.
TI Plane-based camera self-calibration by metric rectification of images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE self-calibration; rectification; homography; similarity; circular
   points; bundle adjustment; optimization; distortion
ID CONSTRAINTS; MOTION
AB Plane-based self-calibration aims at the computation of camera intrinsic parameters from homographies relating multiple views of the same unknown planar scene. This paper proposes a straightforward geometric statement of plane-based self-calibration, through the concept of metric rectification of images. A set of constraints is derived from a decomposition of metric rectification in terms of intrinsic parameters and planar scene orientation. These constraints are then solved using an optimization framework based on the minimization of a geometrically motivated cost function. The link with previous approaches is demonstrated and our method appears to be theoretically equivalent but conceptually simpler. Moreover, a solution dealing with radial distortion is introduced. Experimentally, the method is compared with plane-based calibration and very satisfactory results are obtained. Markerless self-calibration is demonstrated using an intensity-based estimation of the inter-image homographies. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Menudet, J. F.; Becker, J. M.; Fournel, T.; Mennessier, C.] Univ St Etienne, CNRS, Lab Hubert Curien, UMR 5516, F-42000 St Etienne, France.
C3 Centre National de la Recherche Scientifique (CNRS); CNRS - Institute
   for Engineering & Systems Sciences (INSIS); Universite Jean Monnet
RP Menudet, JF (corresponding author), Univ St Etienne, CNRS, Lab Hubert Curien, UMR 5516, 18 Rue Pr Benoit Lauras, F-42000 St Etienne, France.
EM jeanfrancois.menudet@cpe.fr; becker@cpe.fr; fournel@univ-st-etienne.fr;
   mennessier@cpe.fr
CR [Anonymous], 1999, proceedings of Conference on Computer Vision and Pattern Recognition, DOI DOI 10.1109/CVPR.1999.786974
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], P 5 EUR C COMP VERS
   [Anonymous], 2000, LNCS, DOI DOI 10.1007/3-540-44480-7
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   BARAT C, 2006, P INT S VIS COMP LAK, V2, P364
   Bartoli A, 2003, INT J COMPUT VISION, V52, P45, DOI 10.1023/A:1022318524906
   Bartoli A., 2006, P 17 BRIT MACHINE VI, VI, P157
   Bouguet J. Y., 1999, THESIS CALTECH PASAD
   FAUGERAS O, 1992, P EUR C COMP VIS SAN
   Faugeras O. D., 1988, International Journal of Pattern Recognition and Artificial Intelligence, V2, P485, DOI 10.1142/S0218001488000285
   Faugeras O. D., 1986, Proceedings CVPR '86: IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.86CH2290-5), P15
   Felzenszwalb PF, 2005, IEEE T PATTERN ANAL, V27, P208, DOI 10.1109/TPAMI.2005.35
   GILL PE, 1989, PRACTICAL OPTIMIZATI
   Gurdjos P, 2003, PROC CVPR IEEE, P491
   Hartley RI, 2002, LECT NOTES COMPUT SC, V2351, P433
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Huynh DQ, 2005, IMAGE VISION COMPUT, V23, P747, DOI 10.1016/j.imavis.2005.05.003
   Kanatani K, 2000, IEICE T INF SYST, VE83D, P1369
   Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649
   Liebowitz D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P293, DOI 10.1109/ICCV.1999.791233
   LIEBOWITZ D, 2001, THESIS U OXFORD
   Lucchese L, 2005, IMAGE VISION COMPUT, V23, P517, DOI 10.1016/j.imavis.2005.01.001
   Malis E, 2002, IEEE T PATTERN ANAL, V24, P1268, DOI 10.1109/TPAMI.2002.1033217
   Mendonca P. R. S., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P500, DOI 10.1109/CVPR.1999.786984
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   SHUM H.-Y., 2000, INT J COMPUT VISION, V16, P63
   Sturm P, 1997, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.1997.609467
   Tordoff B, 2004, COMPUT VIS IMAGE UND, V96, P17, DOI 10.1016/j.cviu.2004.06.002
   TRIGGS B, 1998, P EUR C COMP VIS FRE
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 33
TC 14
Z9 26
U1 2
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 913
EP 934
DI 10.1016/j.imavis.2007.10.005
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800006
DA 2024-07-18
ER

PT J
AU Tang, H
   Fang, T
   Du, PJ
   Shi, PF
AF Tang, Hong
   Fang, Tao
   Du, Pei-Jun
   Shi, Peng-Fei
TI Intra-dimensional feature diagnosticity in the fuzzy feature contrast
   model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE similarity measures; feature contrast; image retrieval
ID IMAGE RETRIEVAL; RELEVANCE FEEDBACK; STRUCTURAL ALIGNMENT; SIMILARITY
   MEASURE; COLOR; PROXIMITIES; SELECTION
AB Similarity assessment is a basic operation to query images in a large database. Based on fuzzy logic, Santini and Jain extended Tversky's Feature Contrast Model (FCM) to measure image similarity, and developed the Fuzzy Feature Contrast Model (FFCM). In this paper, we analyze the distinction between FCM and FFCM in terms of feature representations, and point out that the intra-dimensional feature diamosticity in the FCM has not been considered in the FFCM. Consequently, similarity measures of the FFCM are positively correlated with visual feature intensities. In order to depress the positive correlation and preserve the original idea of the FCM where possible, we propose an extension of the FFCM called the Diagnostic Fuzzy Feature Contrast Model (DFFCM). Both the feature diagnosticity and feature intensity are employed to measure the image similarity by the DFFCM. The simulated experimental results demonstrated that the impact of the feature intensity on similarity measures of the DFFCM was weaker than that of the FFCM. Experimental results based on synthetic and real-word image databases showed that the DFFCM outperformed the FFCM in terms of image similarity measures. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Tang, Hong] Inst Natl Rech Informat & Automat, Project IMEDIA, F-78153 Le Chesnay, France.
   [Tang, Hong; Fang, Tao; Shi, Peng-Fei] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai 200240, Peoples R China.
   [Du, Pei-Jun] China Univ Min & Technol, Dept RS & GISci, Xuzhou 221008, Peoples R China.
C3 Shanghai Jiao Tong University; China University of Mining & Technology
RP Tang, H (corresponding author), Inst Natl Rech Informat & Automat, Project IMEDIA, F-78153 Le Chesnay, France.
EM Hong.Tang@inria.fr
RI fang, tao/IQU-3074-2023
OI Du, Peijun/0000-0002-2488-2656
CR Aksoy S, 2001, PATTERN RECOGN LETT, V22, P563, DOI 10.1016/S0167-8655(00)00112-4
   ASHBY FG, 1988, PSYCHOL REV, V95, P124, DOI 10.1037/0033-295X.95.1.124
   Chaira T, 2005, FUZZY SET SYST, V150, P545, DOI 10.1016/j.fss.2004.09.003
   Chaira T, 2004, PATTERN RECOGN LETT, V25, P865, DOI 10.1016/j.patrec.2004.01.018
   Chaira T, 2003, PATTERN RECOGN LETT, V24, P1943, DOI 10.1016/S0167-8655(03)00033-3
   Chen YX, 2002, IEEE T PATTERN ANAL, V24, P1252, DOI 10.1109/TPAMI.2002.1033216
   EIDENBERGER H, 2003, P SPIE IS T EL IMAG
   Garner W.R., 1974, PROCESSING INFORM ST
   GATI I, 1984, COGNITIVE PSYCHOL, V16, P341, DOI 10.1016/0010-0285(84)90013-6
   Goldstone RL, 1996, J EXP PSYCHOL LEARN, V22, P988, DOI 10.1037/0278-7393.22.4.988
   GOLDSTONE RL, 1999, ENCY COGNITIVE SCI, P763
   Guo GD, 2002, IEEE T NEURAL NETWOR, V13, P811, DOI 10.1109/TNN.2002.1021882
   Hahn U, 2003, COGNITION, V87, P1, DOI 10.1016/S0010-0277(02)00184-1
   ISHIKAWA Y, 1998, P 24 INT C VER LARG
   *ISO IEC, 2001, N3914 ISOIEC JTC1SC2
   Jia Li, 2000, Proceedings ACM Multimedia 2000, P147
   Jiang W, 2006, IEEE T IMAGE PROCESS, V15, P702, DOI 10.1109/TIP.2005.863105
   Kherfi ML, 2003, J VIS COMMUN IMAGE R, V14, P428, DOI 10.1016/S1047-3203(03)00043-9
   KRUMHANSL CL, 1978, PSYCHOL REV, V85, P445, DOI 10.1037/0033-295X.85.5.445
   Kushki A, 2004, IEEE T CIRC SYST VID, V14, P644, DOI 10.1109/TCSVT.2004.826759
   Manjunath BS, 2001, IEEE T CIRC SYST VID, V11, P703, DOI 10.1109/76.927424
   MARKMAN AB, 1993, COGNITIVE PSYCHOL, V25, P431, DOI 10.1006/cogp.1993.1011
   MARKMAN AB, 1993, J MEM LANG, V32, P517, DOI 10.1006/jmla.1993.1027
   Mojsilovic A, 2004, INT J COMPUT VISION, V56, P79, DOI 10.1023/B:VISI.0000004833.39906.33
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   RUI Y, 2000, P IEEE INT C COMP VI
   Santini S, 1999, IEEE T PATTERN ANAL, V21, P871, DOI 10.1109/34.790428
   SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P125, DOI 10.1007/BF02289630
   SHEPARD RN, 1962, PSYCHOMETRIKA, V27, P219, DOI 10.1007/BF02289621
   SHEPARD RN, 1987, SCIENCE, V237, P1317, DOI 10.1126/science.3629243
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Tang H, 2004, OPT COMMUN, V238, P123, DOI 10.1016/j.optcom.2004.04.030
   Tolias YA, 2001, FUZZY SET SYST, V120, P255, DOI 10.1016/S0165-0114(99)00114-1
   TVERSKY A, 1977, PSYCHOL REV, V84, P327, DOI 10.1037/h0026750
   TVERSKY A, 1982, PSYCHOL REV, V89, P123, DOI 10.1037/0033-295X.89.2.123
   TVERSKY A, 1970, J MATH PSYCHOL, V7, P4
   Yang J, 2004, INT J COMPUT VISION, V56, P47, DOI 10.1023/B:VISI.0000004836.59343.e9
   Zhou XS, 2003, MULTIMEDIA SYST, V8, P536, DOI 10.1007/s00530-002-0070-3
NR 38
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 751
EP 760
DI 10.1016/j.imavis.2007.08.009
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900003
DA 2024-07-18
ER

PT J
AU Wang, L
   Li, YP
   Wang, CB
   Zhang, HZ
AF Wang, Lin
   Li, Yongping
   Wang, Chengbo
   Zhang, Hongzhou
TI 2D Gaborface representation method for face recognition with ensemble
   and multichannel model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face recognition; Gaborface; 2D principal component analysis (PCA);
   (2D)(2) PCA; feature extraction; multichannel; decision level fusion
ID 2-DIMENSIONAL PCA; IMAGES
AB This paper proposes a scheme that is based on linear correlation criterion to select optimized Gabor filter bank. In addition, by using 2D Gaborface matrices rather than transformed 1D feature vectors, a novel Gaborface-based 2DPCA and (2D)(2)PCA classification method is introduced. Two kinds of strategies to use the bank of Gaborfaces are proposed: ensemble Gaborface representation (EGFR) and multichannel Gaborface representation (MGFR). The feasibility of our method is proved with the experimental results on the ORL, Yale and FERET databases. In particular, the MGFR-based (2D)(2)pCA method achieves 100% recognition accuracy for ORL database, and 98.89% accuracy for Yale database with five training samples per class, and 99.5% accuracy for FERET database. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Wang, Lin; Li, Yongping; Wang, Chengbo; Zhang, Hongzhou] Chinese Acad Sci, Shanghai Inst Appl Phys, Ctr Adv Detect & Instrumentat, Shanghai 201800, Peoples R China.
C3 Chinese Academy of Sciences; Shanghai Institute of Applied Physics, CAS
RP Li, YP (corresponding author), Chinese Acad Sci, Shanghai Inst Appl Phys, Ctr Adv Detect & Instrumentat, Shanghai 201800, Peoples R China.
EM ypli@sinap.ac.cn
CR Alterson R, 2004, IMAGE VISION COMPUT, V22, P1007, DOI 10.1016/j.imavis.2004.03.010
   Ayinde O, 2002, PATTERN RECOGN, V35, P1275, DOI 10.1016/S0031-3203(01)00120-0
   BI S, 2006, SPIE, V6057
   BOVIK AC, 1990, IEEE T PATTERN ANAL, V12, P55, DOI 10.1109/34.41384
   Fan W, 2004, INT C PATT RECOG, P330, DOI 10.1109/ICPR.2004.1334119
   FARROKHINA F, 1991, IEEE COMP SOC C COMP, P364
   FIELD DJ, 1987, J OPT SOC AM A, V4, P2379, DOI 10.1364/JOSAA.4.002379
   GINSBURG AP, 1980, P SID, V21, P219
   Hamamoto Y, 1998, PATTERN RECOGN, V31, P395, DOI 10.1016/S0031-3203(97)00057-5
   Kalocsai P, 2000, IMAGE VISION COMPUT, V18, P273, DOI 10.1016/S0262-8856(99)00051-7
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Lee T. S., 1996, IEEE T PAMI, V18
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   LIU CJ, 2004, IEEE T PAMI, V26
   MALLAT SG, 1989, IEEE T ACOUST SPEECH, V37, P2091, DOI 10.1109/29.45554
   PUHUI ZRL, 1996, P 3 INT C SIGN PROC, P1015
   Qin J, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P5144
   RANDEN T, 1994, OPT ENG, V33, P2617, DOI 10.1117/12.177115
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang L, 2006, LECT NOTES COMPUT SC, V4105, P497
   WISKOTT L, 1996, 9608 IRINI RUHR U BO
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Zhang DQ, 2005, NEUROCOMPUTING, V69, P224, DOI 10.1016/j.neucom.2005.06.004
NR 23
TC 19
Z9 27
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 820
EP 828
DI 10.1016/j.imavis.2007.09.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900009
DA 2024-07-18
ER

PT J
AU Lin, HD
AF Lin, Hong-Dar
TI Tiny surface defect inspection of electronic passive components using
   discrete cosine transform decomposition and cumulative sum techniques
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE tiny surface defect inspection; electronic passive components; discrete
   cosine transform decomposition; cumulative sum technique
ID SINGULAR-VALUE DECOMPOSITION; FAST ALGORITHM; DCT DOMAIN; TEXTURES;
   ENHANCEMENT; CHARTS; LEVEL
AB Passive components, owing to their low or no power consumption, are widely used in modern electronic devices. Nevertheless, tiny defects that often appear in the surface of passive components impair not only their appearances but also their functions. This paper proposes a global approach for the automated visual inspection of tiny surface defects in SBL (Surface Barrier Layer) chips, whose random surface texture contains no repetitions of basic texture primitives. The proposed method, taking advantage of the DCT decomposition and the cumulative sum techniques, does not requires textural features, the lack of which often limits the application of feature extraction-based methods. We apply the cumulative sum algorithm to the odd-odd matrix that gathers most power spectra in the decomposed DCT frequency domain, and select the large-magnitude frequency values that represent the background texture of the surface. Then, by reconstructing the frequency matrix without the selected frequency values, we eliminate random texture patterns and retain anomalies in the restored image. Experimental results demonstrate the effectiveness of the proposed method in inspecting tiny defects in random textures. (C) 2007 Elsevier B.V. All rights reserved.
C1 Chaoyang Univ Technol, Dept Ind Engn & Management, Wufong Township 4139, Taichung Cty, Taiwan.
C3 Chaoyang University of Technology
RP Lin, HD (corresponding author), Chaoyang Univ Technol, Dept Ind Engn & Management, 168 Jifong E Rd, Wufong Township 4139, Taichung Cty, Taiwan.
EM hdlin@cyut.edu.tw
OI Lin, Hong-Dar/0000-0003-1875-8779
CR AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   AMET AL, 2002, COMPUT GEOSCI, V28, P763
   [Anonymous], 1996, Techniques and standards for image, video, and audio coding
   Chan YL, 1997, IEEE T IMAGE PROCESS, V6, P758, DOI 10.1109/83.568933
   Chen B, 1999, IMAGE VISION COMPUT, V17, P913, DOI 10.1016/S0262-8856(98)00165-6
   CHO NI, 1991, IEEE T CIRCUITS SYST, V38, P297, DOI 10.1109/31.101322
   GAN FF, 1991, J QUAL TECHNOL, V23, P279, DOI 10.1080/00224065.1991.11979343
   GIRIDHAR M, 1997, J VIS COMMUN IMAG RE, V8, P21
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   Hasan MK, 2004, SIGNAL PROCESS, V84, P151, DOI 10.1016/j.sigpro.2003.10.004
   Huang YM, 1999, IEEE T SIGNAL PROCES, V47, P904, DOI 10.1109/78.747801
   Jiang BC, 2005, INT J PROD RES, V43, P67, DOI 10.1080/00207540412331285832
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Kim TY, 2001, SIGNAL PROCESS, V81, P871, DOI 10.1016/S0165-1684(00)00261-9
   Kok CW, 1997, IEEE T SIGNAL PROCES, V45, P757, DOI 10.1109/78.558495
   Lu CJ, 2005, INT J ADV MANUF TECH, V25, P53, DOI 10.1007/s00170-003-1832-6
   Lu CJ, 2004, INT J PROD RES, V42, P4331, DOI 10.1080/00207540410001716480
   Montgomery D. C., 2019, Introduction to Statistical Quality Control
   PIGNATIELLO JJ, 1990, J QUAL TECHNOL, V22, P173, DOI 10.1080/00224065.1990.11979237
   Pikaz A, 1997, GRAPH MODEL IM PROC, V59, P1, DOI 10.1006/gmip.1996.0410
   Rau H, 2005, INT J ADV MANUF TECH, V25, P940, DOI 10.1007/s00170-004-2299-9
   SARISARRAF JSH, 1998, P COMPUTER VISION PA, P938
   Sezgin M, 2004, J ELECTRON IMAGING, V13, P146, DOI 10.1117/1.1631315
   SIEW LH, 1988, IEEE T PATTERN ANAL, V10, P92, DOI 10.1109/34.3870
   Stubbs D. M., 2000, Microelectronics International, V17, P7, DOI 10.1108/13565360010332372
   Sun MT, 1998, J VIS COMMUN IMAGE R, V9, P163, DOI 10.1006/jvci.1998.0381
   Tico M, 2001, ELECTRON LETT, V37, P21, DOI 10.1049/el:20010031
   Tsai DM, 2003, IMAGE VISION COMPUT, V21, P413, DOI 10.1016/S0262-8856(03)00003-9
   Tsai DM, 2003, IMAGE VISION COMPUT, V21, P307, DOI 10.1016/S0262-8856(03)00007-6
   Tsai DM, 1999, IMAGE VISION COMPUT, V18, P49, DOI 10.1016/S0262-8856(99)00009-8
   Tummala R. R., 2000, Advancing Microelectronics, V27, P13
   WAN Z, 1999, ANAL DIGITAL SIGNAL, V46, P617
   Wu WY, 1996, COMPUT IND, V28, P103, DOI 10.1016/0166-3615(95)00063-1
   Yeh CH, 2003, INT J PROD RES, V41, P4025, DOI 10.1080/0020754031000120096
   Yeh CH, 2003, INT J ADV MANUF TECH, V22, P899, DOI 10.1007/s00170-003-1608-z
   Yeh CH, 2001, INT J ADV MANUF TECH, V17, P412, DOI 10.1007/s001700170159
NR 36
TC 27
Z9 30
U1 1
U2 18
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 603
EP 621
DI 10.1016/j.imavis.2007.07.009
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900001
DA 2024-07-18
ER

PT J
AU Brandt, SS
AF Brandt, Sami S.
TI On the probabilistic epipolar geometry
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE imaging geometry; probabilistic algorithms; stereo; computer vision
ID UNCERTAINTY
AB In this paper, we are going to answer the following question: assuming that we have estimates for the epipolar geometry and its uncertainty between two views, how probable is it that a new, independent point pair will satisfy the true epipolar geometry and be, in this sense, a feasible candidate correspondence pair? If we knew the true fundamental matrix, the answer would be trivial but in reality we do not know it because of estimation errors. So, as an independent point in the first view is given, we will show we may compute the point-probability-density function, termed as the epipolar pdf, for the epipolar line points in the second view that describes the current level of knowledge of the epipolar geometry between the views. This point-point-probability-density relation is a probabilistic form of the epipolar constraint that also approaches the true point-line relation as the number of training correspondences tends to infinity. In this paper, we will also show that the eigenvectors of the epipolar line covariance matrix have certain interpretations on the image plane, of which one is the previously observed, narrowest point of the epipolar envelope. The results of this paper are important since the uncertainty of the epipolar constraint can be now taken into account in a sound way in applications. (c) 2006 Elsevier B.V. All rights reserved.
C1 Helsinki Univ Technol, Lab Computat Engn, FI-02015 Helsinki, Finland.
C3 Aalto University
RP Brandt, SS (corresponding author), Helsinki Univ Technol, Lab Computat Engn, FI-02015 Helsinki, Finland.
EM Sami.Brandt@tkk.fi
OI Brandt, Sami/0000-0003-2141-9815
CR [Anonymous], 2000, LNCS, DOI DOI 10.1007/3-540-44480-7
   BRANDT S, 2002, THESIS HELSINKI U TE
   BRANDT S, 2001, P 8 INT C COMP VIS I, V2, P166
   Brandt SS, 2006, J MATH IMAGING VIS, V25, P25, DOI 10.1007/s10851-005-4386-4
   BRANDT SS, 2004, P BRIT MACH VIS C, V1, P107
   Csurka G, 1997, COMPUT VIS IMAGE UND, V68, P18, DOI 10.1006/cviu.1997.0531
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   KANATANI K, 2000, P 6 S SENS VIA IM IN, P291
   Karr Alan, 1992, PROBABILITY
   MacKay D., 2003, INFORM THEORY INFERE
   TORR P, 1998, P 5 EUR C COMP VIS, P511
   TRIGGS B, 2001, P 8 INT C COMP VIS, V11, P201
   XU G, 1996, COMPUTATIONAL IMAGIN, V6
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
NR 15
TC 5
Z9 7
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 405
EP 414
DI 10.1016/j.imavis.2006.12.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500009
DA 2024-07-18
ER

PT J
AU Leibe, B
   Ettlin, A
   Schiele, B
AF Leibe, Bastian
   Ettlin, Alan
   Schiele, Bernt
TI Learning semantic object parts for object categorization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object recognition; object categorization; part-based representations;
   semantic; Bayesian networks
ID MEAN-SHIFT; RECOGNITION
AB Appearance-based approaches to object recognition mostly rely on measuring the visual similarity of objects based on global or local descriptors. They have shown great success in object identification but often do not generalize to the more challenging case of object categorization, where category membership is often decided not only on a level of appearances, but also on a semantic level.
   It has been argued that model-based approaches are better suited to this problem, since they allow to inject high-level knowledge, for example about the constituting object parts and possible configurations. Postulating a set of object parts is problematic, though, since it is not guaranteed that those parts can be reliably extracted from real-world images. There is a need for a middle layer, forming an interface between the visual information readily available from the image and the higher-level semantic information that can be used by reasoning processes.
   In this work, we investigate how such an interface can be learned. As the appearance of object parts may vary considerably, this cannot be achieved by relying on visual similarity alone. Rather, this paper proposes to also use co-location and co-activation, together with weak top-down constraints, such as alignment, as guiding principles for learning the appearance of local object parts. The learned structures generalize beyond the appearance of single objects and often correspond to semantically plausible object parts, such as wheels, trunks, or windshields of cars. In a later stage, a Bayesian network of those extracted structures is used to verify object hypotheses successfully in difficult scenes. (c) 2007 Elsevier B.V. All rights reserved.
C1 ETH, Comp Vis Lab, Zurich, Switzerland.
   Tech Univ Darmstadt, Dept Comp Sci, Darmstadt, Germany.
C3 Swiss Federal Institutes of Technology Domain; ETH Zurich; Technical
   University of Darmstadt
RP Leibe, B (corresponding author), ETH, Comp Vis Lab, Zurich, Switzerland.
EM leibe@vision.ee.ethz.ch; aettlin@hta.fhz.ch;
   schiele@informatik.tu-darmstadt.de
RI ; Leibe, Bastian/E-5499-2017
OI Schiele, Bernt/0000-0001-9683-5237; Leibe, Bastian/0000-0003-4225-0051
CR Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2004, Semantic Cognition: A Parallel Distributed Processing Approach
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   BART E, 2004, 8 EUR C COMP VIS ECC, P152
   BART E, 2004, WORKSH IM VID REG WI
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   BURL MC, 1998, 5 EUR C COMP VIS ECC
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 1999, PATTERN ANAL APPL, V2, P22, DOI 10.1007/s100440050011
   EDELMAN S, 2001, NEURAL INFORM PROCES
   Forsyth DA, 1997, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.1997.609399
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Ioffe S., 2001, IEEE C COMP VIS PATT
   Kittler J, 1998, IEEE T PATTERN ANAL, V20, P226, DOI 10.1109/34.667881
   Leibe B, 2004, LECT NOTES COMPUT SC, V3175, P145
   LEIBE B, 2004, ECCV 04
   Leibe Bastian., 2003, In British Machine Vison Conference (BMVC'03), P759
   LOWE DG, 1999, 7 INT C COMP VIS ICC
   Marcus G.F., 2001, ALGEBRAIC MIND INTEG
   Marr D., 1982, Vision
   Mohan A, 2001, IEEE T PATTERN ANAL, V23, P349, DOI 10.1109/34.917571
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Murphy Gregory L, 2002, The Big Book of Concepts (Bradford Books)
   Nelson RC, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P614, DOI 10.1109/ICCV.1998.710781
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   PETERNEL M, 2004, 9 COMP VIS WINT WORK
   Pham TV, 2002, PATTERN RECOGN LETT, V23, P451, DOI 10.1016/S0167-8655(01)00177-5
   RIMEY RD, 1994, INT J COMPUT VISION, V12, P173, DOI 10.1007/BF01421202
   ROSCH E, 1976, COGNITIVE PSYCHOL, V8, P382, DOI 10.1016/0010-0285(76)90013-X
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   SCHMID C, 1996, IEEE C COMP VIS PATT
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   SIVIC J, 2004, ECCV04
   WEBER M, 2000, 6 EUR C COMP VIS ECC
   Yow KC, 1997, IMAGE VISION COMPUT, V15, P713, DOI 10.1016/S0262-8856(97)00003-6
NR 39
TC 19
Z9 24
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2008
VL 26
IS 1
SI SI
BP 15
EP 26
DI 10.1016/j.imavis.2007.08.012
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 236JL
UT WOS:000251299100003
DA 2024-07-18
ER

PT J
AU Willis, A
   Speicher, J
   Cooper, DB
AF Willis, Andrew
   Speicher, Jasper
   Cooper, David B.
TI Rapid prototyping 3D objects from scanned measurement data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE rapid prototyping; 3D scanning; 3D deformable models; 3D probabilistic
   models and estimation; 3D virtual surface sculpting
AB It has become increasingly important to be able to generate free-form 3D shapes in commercial applications using rapid prototyping technologies. In many cases, the shapes of interest are taken from real-world objects that do not have pre-existing computer models. Constructing an accurate model for these objects by hand is extremely time consuming and difficult with even the latest 3D software packages. To aid in the modeling process, 3D scanners are used to capture the object shape and generate a high resolution model of the object. However, these models built from scans often have irregularities that prevent the construction of a useful prototype. This paper proposes a method for generating 3D models suitable for rapid prototyping from measurements of real-world objects taken by a 3D scanner. This is accomplished by taking a cloud of 3D point data as input and fitting a closed 3D surface to the data in such a way as to ensure accuracy in the representation of the object surface and compatibility with a rapid prototyping machine. We treat surface modeling and adaptation to the data in a new framework as 3D stochastic surface estimation. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ N Carolina, Dept Elect & Comp Engn, Charlotte, NC 28223 USA.
   Brown Univ, Providence, RI 02912 USA.
C3 University of North Carolina; University of North Carolina Charlotte;
   Brown University
RP Willis, A (corresponding author), Univ N Carolina, Dept Elect & Comp Engn, 9201 Univ City Blvd, Charlotte, NC 28223 USA.
EM arwillis@uncc.edu; jasper@mingar.com; cooper@lems.brown.edu
CR Amenta N, 2001, COMP GEOM-THEOR APPL, V19, P127, DOI 10.1016/S0925-7721(01)00017-7
   [Anonymous], 2001, COMP SCI W
   ASHLEY S, RAPID PROTOTYPING CO
   Bernardini F, 1999, IEEE T VIS COMPUT GR, V5, P349, DOI 10.1109/2945.817351
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Besse F, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.132
   BOLLE R, 1986, PAMI, V8, P619
   Brand M, 2004, PROC CVPR IEEE, P30
   Bærentzen JA, 2002, SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P175, DOI 10.1109/SMI.2002.1003543
   CARR J, 2003, P INT C COMP GRAPH I, P31
   Cipolla R., 2000, VISUAL MOTION CURVES
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   *D SYST INC, THERM 3D INK JET RP
   *D VIS WORKS, D SCULPTOR 2 URL
   DAVIS J, 2002, 1 INT S 3D DAT PROC, P200
   DU H, COMPUTER GRAPHICS FO, V19
   *EXT HON CORP, 3D INK JET RP MACH U
   *EYETRONICS, SHAPECAM
   *FAR TECHN INC, SCANARM
   GRIFFITH M, RAPID PROTOTYPING TE
   HARALICK RM, 1989, IEEE T SYST MAN CYB, V19, P1426, DOI 10.1109/21.44063
   HOPPE H, 1994, THESIS U WASHINGTON
   *IMM CORP, MICROSCRIBE 3D DIG
   Joukowsky Martha., 1980, A Complete Manual of Field Archaeology: Tools and Techniques of Field Work for Archaeologists
   JOUKOWSKY MS, 1999, BROWN U EXCAVATIONS, V1
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   LEE Y, 2004, COMPUTER IND, P125
   Levoy M, 2000, COMP GRAPH, P131, DOI 10.1145/344779.344849
   Lorensen William E., 1987, COMPUT GRAPH, P163, DOI DOI 10.1145/37402.37422
   MALLADI R, 1995, PAMI, V17, P15
   Ohtake Y, 2004, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, P31, DOI 10.1109/SMI.2004.1314491
   Pollefeys M, 2002, J VISUAL COMP ANIMAT, V13, P199, DOI 10.1002/vis.289
   QIN H, 2001, P S SOL MOD APPL, P47
   Rusinkiewicz S, 2002, ACM T GRAPHIC, V21, P438, DOI 10.1145/566570.566600
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   *SHAP INC, URL
   *STRATASYS FDM 300, FDM RP MACH US ABS P
   TAUBIN G, 1991, IEEE T PATTERN ANAL, V13, P1115, DOI 10.1109/34.103273
   Turk G., 1994, Computer Graphics Proceedings. Annual Conference Series 1994. SIGGRAPH 94 Conference Proceedings, P311, DOI 10.1145/192161.192241
   WELCH W, 1994, SIGGRAPH 94 P, V28, P247
   Williams CA, 2004, J AM MED INFORM ASSN, V11, P249, DOI 10.1197/jamia.M1527
   WILLIS A, 2004, THESIS BROWN U
   Wood Z, 2004, ACM T GRAPHIC, V23, P190, DOI 10.1145/990002.990007
   *Z CORP, 3D INK JET RP US STA
   Zwicker M, 2002, ACM T GRAPHIC, V21, P322, DOI 10.1145/566570.566584
   KONICA MINOLTA VIVID
NR 46
TC 18
Z9 20
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2007
VL 25
IS 7
BP 1174
EP 1184
DI 10.1016/j.imavis.2006.06.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 179MZ
UT WOS:000247295300014
DA 2024-07-18
ER

PT J
AU Chen, GY
   Xie, WF
AF Chen, G. Y.
   Xie, W. F.
TI Pattern recognition with SVM and dual-tree complex wavelets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE twavelets; dual-tree complex wavelets; pattern recognition; SVM
ID AFFINE-INVARIANT REPRESENTATION; SUPPORT VECTOR MACHINE;
   FEATURE-EXTRACTION; MULTIRESOLUTION RECOGNITION; TRANSFORM; DESCRIPTORS;
   NETWORKS
AB A novel descriptor for pattern recognition is proposed by using dual-tree complex wavelet features and SVM. The approximate shiftinvariant property of the dual-tree complex wavelet and its good directional selectivity in 2D make it a very appealing choice for pattern recognition. Recently, SVM has been shown to be very successful in pattern recognition. By combining these two tools we find that better recognition results are obtained. We achieve the highest rates when we use the dual-tree complex wavelet features with the Gaussian radial basis function kernel and the wavelet kernel for recognizing similar handwritten numerals, and when we use the Gaussian radial basis function for palmprint classification. Our findings are that the dual-tree complex wavelets are always better than the scalar wavelet for pattern recognition when SVM is used. Also, among many frequently used SVM kernels, the Gaussian radial basis function kernel and the wavelet kernel are the best for pattern recognition applications. (C) 2006 Elsevier B.V. All rights reserved.
C1 Concordia Univ, Dept Mech & Ind Engn, Montreal, PQ H3G 1M8, Canada.
C3 Concordia University - Canada
RP Chen, GY (corresponding author), 7167 Boyer, Montreal, PQ H2R 2R6, Canada.
EM guangyi_chen@hotmail.com; wfxie@me.concordia.ca
RI Xie, Wen-Fang/AFM-0704-2022
CR [Anonymous], P EUSIPCO 98 RHOD SE
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], P IEEE ICIP VANC SEP
   [Anonymous], Polyu palmprint dataset
   Bui TD, 2001, INT J PATTERN RECOGN, V15, P1213, DOI 10.1142/S0218001401001465
   CHEN G, 2005, P 2 CAN C COMP ROB V
   Chen GY, 2006, PATTERN ANAL APPL, V9, P83, DOI 10.1007/s10044-006-0028-8
   Chen GY, 2005, PATTERN RECOGN, V38, P2314, DOI 10.1016/j.patcog.2005.02.008
   Chen GY, 2003, PATTERN RECOGN, V36, P1597, DOI 10.1016/S0031-3203(02)00252-2
   Chen GY, 1999, PATTERN RECOGN, V32, P1083, DOI 10.1016/S0031-3203(98)00148-4
   CHEN GY, 2005, P IEEE CAN C EL COMP
   CHEN GY, 2006, P IEEE ICIP ATL GA U
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dong KF, 2004, LECT NOTES COMPUT SC, V3338, P639
   Gunn S. R., 1998, SUPPORT VECTOR MACHI
   JOACHIMS T, 2000, P 17 INT C MACH LEAR
   Kearns M., 1997, Proceedings of the Tenth Annual Conference on Computational Learning Theory, P152, DOI 10.1145/267460.267491
   Khalil MI, 2000, PATTERN RECOGN LETT, V21, P863, DOI 10.1016/S0167-8655(00)00046-5
   KINGSBURY NG, 1999, P IEEE ICASSP 99 PHO
   Lee SW, 1996, PATTERN RECOGN, V29, P1953, DOI 10.1016/S0031-3203(96)00053-2
   ROMBERG J, 2000, P IEEE ICIP VANCOUVE, P11
   Shen DG, 1999, PATTERN RECOGN, V32, P151, DOI 10.1016/S0031-3203(98)00137-X
   Smola AJ, 1998, NEURAL NETWORKS, V11, P637, DOI 10.1016/S0893-6080(98)00032-X
   Song Q, 2002, IEEE T SYST MAN CY C, V32, P440, DOI 10.1109/TSMCC.2002.807277
   Tao Y, 2001, PATTERN RECOGN LETT, V22, P271, DOI 10.1016/S0167-8655(01)00003-4
   Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P846, DOI 10.1109/34.608288
   Tieng QM, 1995, PATTERN RECOGN LETT, V16, P1287, DOI 10.1016/0167-8655(95)00079-1
   Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P910, DOI 10.1109/34.608294
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   Vapnik V., 1999, NATURE STAT LEARNING
   WUNSCH P, 1995, PATTERN RECOGN, V28, P1237, DOI 10.1016/0031-3203(95)00001-G
   You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5
   Zhang D., 2000, AUTOMATED BIOMETRICS
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
   Zhang L, 2004, IEEE T SYST MAN CY B, V34, P34, DOI 10.1109/TSMCB.2003.811113
NR 35
TC 83
Z9 87
U1 0
U2 12
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 960
EP 966
DI 10.1016/j.imavis.2006.07.009
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600017
DA 2024-07-18
ER

PT J
AU Roterman, Y
   Porat, M
AF Roterman, Yalon
   Porat, Moshe
TI Color image coding using regional correlation of primary colors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE compression; color; correlation; coding; localized
AB Most color compression systems reduce the redundancies between the RGB color components by transforming the color primaries into a decorrelated color space, such as YIQ or YUV. In this paper a different compression approach is proposed. Since the high correlation of the RGB color channels implicitly suggests a localized functional relation between the components, it is used here in an alternative framework, by approximating subordinate colors as functions of a base color allowing that only a reduced number of parameters is required for coding the color information. Furthermore, since this correlation is particularly high locally, the image is first sub-divided into regions and for each region the correlation is analyzed and exploited separately. The size of the encoded regions is gradually reduced to allow progressively a more refined description of the transmitted image. Compression results of this progressive approach, which could be useful for slower communication channelsi are presented and compared with JPEG as a typical example of the decorrelation approach. Our conclusion is that the proposed new approach to progressive image coding could be superior to presently available compression techniques. (c) 2006 Elsevier B.V. All rights reserved.
C1 Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
C3 Technion Israel Institute of Technology
RP Porat, M (corresponding author), Technion Israel Inst Technol, Dept Elect Engn, IL-32000 Haifa, Israel.
EM mp@ee.technion.ac.il
CR Bennett J, 1998, IEEE T PATTERN ANAL, V20, P327, DOI 10.1109/34.667889
   Bhaskaran Vasudev, 1997, Image and video compression standards: algorithms and architectures
   BRICE CR, 1970, ARTIF INTELL, V1, P205, DOI 10.1016/0004-3702(70)90008-1
   CEDERBERG RLT, 1979, COMPUT VISION GRAPH, V10, P224, DOI 10.1016/0146-664X(79)90002-9
   DURST MJ, 1993, VIRTUAL WORLDS MULTI, P57
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   GOFFMAN L, 2002, IEEE INT C IM PROC I
   GU C, 1994, VIS COMM IM PROC VCI
   HUFFMAN DA, 1952, P IRE, V40, P1098, DOI 10.1109/JRPROC.1952.273898
   *ISO IEC JTCI SC29, N390R ISOIECJTCISC29
   Jahne B., 1995, Digital image processing
   Jain A. K., 1989, Fundamentals of Digital Image Processing
   KOTERA H, 1990, J IMAGING TECHNOL, V16, P142
   KUNT M, 1985, P IEEE, V73, P549, DOI 10.1109/PROC.1985.13184
   LIMB JO, 1971, IEEE T COMMUN, V20, P890
   NAMANE A, 1990, IEEE T PATTERN ANAL, V12, P600, DOI 10.1109/34.56197
   PORAT M, 1988, IEEE T PATTERN ANAL, V10, P452, DOI 10.1109/34.3910
   PRATT W.K., 1991, DIGITAL IMAGE PROCES, V2
   Rao K.R, 2014, DISCRETE COSINE TRAN
   ROTEMANN Y, 2004, 512 CCIT
   SAKATNOTO T, 1998, IEEE T CONSUMER ELEC, V44
   Urieli S, 1998, IEEE T IMAGE PROCESS, V7, P838, DOI 10.1109/83.679428
   Wang D.C.C., 1981, COMPUT GRAPH IMAGE P, V15
   Wang HJ, 1998, INT CONF ACOUST SPEE, P3721, DOI 10.1109/ICASSP.1998.679692
   YAMAGUCHI H, 1984, IEEE T COMMUN, V32, P1201, DOI 10.1109/TCOM.1984.1095992
NR 25
TC 18
Z9 21
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 637
EP 651
DI 10.1016/j.imavis.2006.05.007
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200010
DA 2024-07-18
ER

PT J
AU Guderlei, R
   Klenk, S
   Mayer, J
   Schmidt, V
   Spodarev, E
AF Guderlei, R.
   Klenk, S.
   Mayer, J.
   Schmidt, V.
   Spodarev, E.
TI Algorithms for the computation of the Minkowski functionals of
   deterministic and random polyconvex sets
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE binary image; intrinsic volume; querma beta integral; Minkowski
   functional; area; boundary length; Euler-Poincare characteristic;
   stationary random closed set; random field; volume fraction; Steiner
   formula; principal kinematic formula; parallel set
AB We give algorithms for the simultaneous computation of the area, boundary length and connectivity (the so-called Minkowski functionals) of binary images. It is assumed that a binary image is a discretization of a two-dimensional polyconuex set which is a union of convex components. Edge-corrected versions of these algorithms are used for the estimation of specific intrinsic volumes of a stationary random closed set from a single realization given by a binary image. Performance and exactness of the algorithms in two dimensions are discussed on numerical examples. Comparison to other known methods is provided. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Ulm, Abt Stochast, D-89069 Ulm, Germany.
   Univ Ulm, Abt Angew Informationsverarbeitung, D-89069 Ulm, Germany.
C3 Ulm University; Ulm University
RP Spodarev, E (corresponding author), Univ Ulm, Abt Stochast, D-89069 Ulm, Germany.
EM ralph.guderlei@uni-ulm.de; klenk@uni-ulm.de; johannes.mayer@uni-ulm.de;
   volker.schmidt@uni-ulm.de; evgueni.spodarev@uni-ulm.de
CR [Anonymous], 1976, Integral geometry and geometric probability
   [Anonymous], 1997, LEZIONI LINCEE
   Baddeley AJ, 1999, MG STAT PRO, V80, P37
   Freeman H., 1974, Computing Surveys, V6, P57, DOI 10.1145/356625.356627
   Jernot JP, 2004, J MICROSC-OXFORD, V215, P40, DOI 10.1111/j.0022-2720.2004.01336.x
   Klenk S, 2006, COMP GEOM-THEOR APPL, V34, P127, DOI 10.1016/j.comgeo.2006.02.002
   Martinez V. J., 2002, STAT GALAXY DISTRIBU
   Matheron G., 1975, Random sets and integral geometry
   Mattfeldt T, 2003, PATHOL RES PRACT, V199, P773, DOI 10.1078/0344-0338-00496
   Mayer J., 2004, Image Analysis & Stereology, V23, P177, DOI 10.5566/ias.v23.p177-183
   MECKE K, 2000, LECTO NOTES PHYS, V554
   Mecke K.R., 2002, LECT NOTES PHYS, V600
   MRKVICKA T, 2005, MATHMU20051
   Muller W.G., 2001, COLLECTING SPATIAL D
   Nagel W, 2000, J MICROSC-OXFORD, V198, P54, DOI 10.1046/j.1365-2818.2000.00668.x
   Ochs M, 2004, AM J RESP CRIT CARE, V169, P120, DOI 10.1164/rccm.200308-1107OC
   Ohser J, 2002, LECT NOTES PHYS, V600, P275
   Ohser J., 2003, IMAGE ANAL STEREOL, V22, P11
   Ohser J., 2000, Statistical Analysis of Microstructures in Materials Science
   Pantle U, 2006, ADV APPL PROBAB, V38, P76, DOI 10.1239/aap/1143936141
   RATAJ J, 2006, IN PRESS REND CIRC M
   Robins V, 2002, LECT NOTES PHYS, V600, P261
   Schmidt V, 2005, STOCH PROC APPL, V115, P959, DOI 10.1016/j.spa.2004.12.007
   Schneider R., 2000, Stochastische Geometrie
   Schneider R., 1993, Convex bodies: the BrunnMinkowski theory
   Schneider Rolf., 1992, Integralgeometrie, V1
   Serra J., 1983, IMAGE ANAL MATH MORP
   SPODAREV E, 2005, P 7 INT S MATH MORPH, P343
   Stoyan D., 1995, Stochastic Geometry and Its Applications, V2
   Tabor Z, 2004, BONE, V34, P170, DOI 10.1016/j.bone.2003.10.002
   Vogel HJ, 1997, ACTA STEREOL, V16, P97
   WEIL W, 1984, ADV APPL PROBAB, V16, P324, DOI 10.2307/1427072
NR 32
TC 15
Z9 17
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 464
EP 474
DI 10.1016/j.imavis.2006.07.019
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600009
DA 2024-07-18
ER

PT J
AU Barcelos, CAZ
   Batista, MA
AF Barcelos, Celia A. Zorzo
   Batista, Marcos Aurelio
TI Image restoration using digital inpainting and noise removal
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE inpaint; image processing; noise removal; edge detection; diffusion
   equation; transport equation
ID EDGE-DETECTION; EQUATION
AB Inpainting and denoising are two important tasks in the field of image processing with broad applications in image and vision analysis. In this paper. we present a new approach for image restoration. Our method simultaneously fills in missing, corrupted, or undesirable information while it removes noise. The denoising is performed by the smoothing equation working inside and outside of the inpainting domain but in completely different ways. Inside the inpainting domain, the smoothing is carried out by the Mean Curvature Flow, while the smoothing of the outside of the inpainting domain is carried out in a way as to encourage smoothing within a region and discourage smoothing across boundaries. Besides smoothing, the approach here presented permits the transportation of available information from the outside towards the inside of the inpainting domain. This combination permits the simultaneous use of filling-in and differentiated smoothing of different regions of an image. The experimental results show the effective performance of the combination of these two procedures in restoring scratched photos, disocclusion (or removal of entire objects from the image) in vision analysis and text removal from images. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Fed Goias, Dept Comp, BR-75704020 Catalao, Go, Brazil.
   Univ Fed Uberlandia, Fac Math, BR-38400902 Uberlandia, MG, Brazil.
C3 Universidade Federal de Goias; Universidade Federal de Uberlandia
RP Batista, MA (corresponding author), Univ Fed Goias, Dept Comp, Campus Catalao,Caixa Postal 56, BR-75704020 Catalao, Go, Brazil.
EM celiazb@ufu.br; marcos.4d@uol.com.br
RI Batista, Marcos A./E-1817-2013
CR ALVAREZ A, 1994, ACTA NUMER, P1
   ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   [Anonymous], 1979, Organization in vision
   Barcelos CAZ, 2003, IEEE T IMAGE PROCESS, V12, P751, DOI 10.1109/TIP.2003.814242
   BARCELOS CAZ, IN PRESS B SBMAC
   Barcelos CAZ, 2005, COMPUT APPL MATH, V24, P131, DOI 10.1590/S1807-03022005000100008
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   BERTALMIO M, 2001, THESIS U MINNESOTA
   Chan TF, 2003, SIAM J APPL MATH, V63, P564
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   Masnou S, 2002, IEEE T IMAGE PROCESS, V11, P68, DOI 10.1109/83.982815
   Masnou S, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 3, P259, DOI 10.1109/ICIP.1998.999016
   NORDSTROM KN, 1990, IMAGE VISION COMPUT, V8, P318, DOI 10.1016/0262-8856(90)80008-H
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
NR 16
TC 16
Z9 20
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 61
EP 69
DI 10.1016/j.imavis.2005.12.008
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600008
DA 2024-07-18
ER

PT J
AU Cord, M
   Gosselin, PH
   Philipp-Foliguet, S
AF Cord, Matthieu
   Gosselin, Philippe H.
   Philipp-Foliguet, Sylvie
TI Stochastic exploration and active learning for image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 16th Brazilian Symposium on Computer Graphics and Image Processing
CY OCT 12-15, 2003
CL SAO CARLOS, BRAZIL
SP Brazilian Comp Soc, Univ Sao Paulo, Brazilian Natl Res Council, Brazilian Commiss Higher Educ, Sao Paulo Res Fdn, European Assoc Comp Graph, IEEE
DE image processing; content-based image retrieval; exploration of image
   database; classification; active learning
AB This paper deals with content-based image retrieval. When the user is looking for large categories, statistical classification techniques are efficient as soon as the training set is large enough.
   We introduce a two-step-exploration, classification-interactive strategy designed for category retrieval. The first step aims at getting a useful initial training set for the classification step. A stochastic image selection process is used instead of the usual strategy based on a similarity score ranking. This process is dedicated to explore the database in order to collect examples as various as possible of the searched category. The second step aims at providing the best classification between relevant and irrelevant images. Based on SVM, the classification applies an active learning strategy through user interaction. A quality assessment is carried out on the ANN and COREL databases in order to compare and validate our approach. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Cergy Pontoise, ETIS, CNRS UMR 8051, F-95014 Cergy Pontoise, France.
C3 CY Cergy Paris Universite
RP Cord, M (corresponding author), Univ Cergy Pontoise, ETIS, CNRS UMR 8051, 6 AV Ponceau, F-95014 Cergy Pontoise, France.
EM cord@ensea.fr; gosselin@ensea.fr; philipp@ensea.fr
RI cai, bo/G-1491-2010
CR [Anonymous], 2001, The Element of Statistical Learning
   [Anonymous], 2003, ICML 2003 WORKSH CON
   [Anonymous], 2001, Active learning: theory and applications
   [Anonymous], 1998, STAT LEARNING THEORY
   Brunelli R, 2001, PATTERN RECOGN, V34, P1625, DOI 10.1016/S0031-3203(00)00054-6
   Caenen G, 2000, LECT NOTES COMPUT SC, V1929, P257
   CHANG E, 2003, IEEE INT C IM PROC B
   CHAPELLE O, 1999, IEEE T NEURAL NETWOR, V9
   Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295
   CORD M, 2003, IEEE 15 SIBGR S COMP
   Cox IJ, 2000, IEEE T IMAGE PROCESS, V9, P20, DOI 10.1109/83.817596
   Eakins JP, 2002, PATTERN RECOGN, V35, P3, DOI 10.1016/S0031-3203(01)00038-3
   Fournier J, 2001, PATTERN ANAL APPL, V4, P153, DOI 10.1007/PL00014576
   FOURNIER J, 2002, IEEE INT C IM PROC I
   GEMAN D, 2000, RFIA 2000 PAR FRANC, V3, P173
   GOSSELIN P, 2004, INT WORKSH COMP VIS, P51
   GOSSELIN P, 2004, IEEE ADV CONCEPTS IN
   ISHIKAWA Y, 1998, 24 INT C VER LARG DA, P218
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   LEWIS D, 1994, INT C MACH LEARN
   Mojsilovic A, 2001, IEEE IMAGE PROC, P18, DOI 10.1109/ICIP.2001.958942
   NAJJAR N, 2003, IEEE ICIP BARC SPAIN
   PARK J, 2000, IEEE NEURAL NETWORKS
   Patané G, 2001, NEURAL NETWORKS, V14, P1219, DOI 10.1016/S0893-6080(01)00104-6
   ROY N, 2001, INT C MACH LEARN
   Rui Y, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P82, DOI 10.1109/IVL.1997.629724
   RUI Y, 2000, C COMP VIS PATT REC, V1, P236
   Santini S, 2001, IEEE T KNOWL DATA EN, V13, P337, DOI 10.1109/69.929893
   Schmid C, 2004, INT J COMPUT VISION, V56, P7, DOI 10.1023/B:VISI.0000004829.38247.b0
   Scholkopf B., 1999, Estimating the Support of a High-Dimensional Distribution
   Smola A.J., 2002, LEARNING KERNELS
   TONG S, 2001, ACM MULTIMEDIA
   TRAN L, 2001, INT C IM PROC ICIP 0, V2, P697
   TUYTELAARS T, 1999, 3 INT C VIS INF SYST, V99, P493
   Vasconcelos N, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P6, DOI 10.1109/ICIP.2001.958037
   VASCONCELOS N, 2000, THESIS MIT
   VELTAMP R, 2002, CONTENT BASED IMAGE
   WANG L, 2003, IEEE INT C IM PROC B
NR 38
TC 22
Z9 26
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2007
VL 25
IS 1
BP 14
EP 23
DI 10.1016/j.imavis.2006.01.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 109OJ
UT WOS:000242317600003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Schiele, B
AF Schiele, Bernt
TI Model-free tracking of cars and people based on color regions
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Performance Evaluation of Tracking and Surveillance (PETS)
CY DEC   09, 2001
CL Kauai, HI
SP IEEE
DE tracking; wearable computing; model-free tracking; wearable cameras
ID RECOGNITION
AB This paper exploits a simple but general technique to extract object models from arbitrary image sequences. Such object models can be used to structure and index the image sequence. The algorithm extracts and tracks homogenous regions, which may correspond to objects or object parts. By grouping similar moving regions, the algorithm constructs models of potential objects. As such, the approach is model-free in the sense that it does not use a priori models to detect, track, and segment objects. On the contrary, the ultimate goal of the approach is to build such models automatically from image sequences.
   In this paper, the approach is applied to an image sequence taken by a static camera overlooking a parking lot. Due to the general formulation of the approach it can be used to extract any object from image sequences including cars and people. Tracking results for cars and people are reported. For evaluation purposes all participants of the PETS 2000 workshop(1) were given the same image sequences. (c) 2005 Elsevier B.V. All rights reserved.
C1 Tech Univ Darmstadt, Dept Comp Sci, D-64287 Darmstadt, Germany.
C3 Technical University of Darmstadt
RP Schiele, B (corresponding author), Tech Univ Darmstadt, Dept Comp Sci, D-64287 Darmstadt, Germany.
EM schiele@informatik.tu-darmstadt.de
OI Schiele, Bernt/0000-0001-9683-5237
CR Duda R. O., 1973, PATTERN CLASSIFICATI, V3
   HEISELE B, 1997, MOV OBJ BAS COL CLUS, P257
   HULL R, 1997, IEEE ISWC
   MAO JC, 1992, PATTERN RECOGN, V25, P173, DOI 10.1016/0031-3203(92)90099-5
   PASCOE J, 1998, IEEE ISWC
   SAKOE H, 1978, IEEE T ACOUST SPEECH, V26, P43, DOI 10.1109/TASSP.1978.1163055
   Schiele B, 2000, INT J COMPUT VISION, V36, P31, DOI 10.1023/A:1008120406972
   SCHIELE B, 1999, 500 MIT MED LAB VIS
   SCHIELE B, 1999, ICVS, P51
   Starner T, 1998, SECOND INTERNATIONAL SYMPOSIUM ON WEARABLE COMPUTERS - DIGEST OF PAPERS, P50, DOI 10.1109/ISWC.1998.729529
   STARNER T, 1997, WEARABLE COMPUTER BA
NR 11
TC 15
Z9 16
U1 1
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2006
VL 24
IS 11
BP 1172
EP 1178
DI 10.1016/j.imavis.2005.06.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 101CJ
UT WOS:000241716200003
DA 2024-07-18
ER

PT J
AU Littlewort, G
   Bartlett, MS
   Fasel, I
   Susskind, J
   Movellan, J
AF Littlewort, Gwen
   Bartlett, Marian Stewart
   Fasel, Ian
   Susskind, Joshua
   Movellan, Javier
TI Dynamics of facial expression extracted automatically from video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE facial action coding; support vector machines; facial expression;
   Adaboost
AB We present a systematic comparison of machine learning methods applied to the problem of fully automatic recognition of facial expressions, including AdaBoost, support vector machines, and linear discriminant analysis. Each video-frame is first scanned in real-time to detect approximately upright-frontal faces. The faces found are scaled into image patches of equal size, convolved with a bank of Gabor energy filters, and then passed to a recognition engine that codes facial expressions into 7 dimensions in real time: neutral. anger. disgust, fear. joy, sadness, surprise. We report results on a series of experiments comparing spatial frequency ranges, feature selection techniques, and recognition engines. Best results were obtained by selecting a Subset of Gabor filters using AdaBoost and then training Support Vector Machines on the outputs of the filters selected by AdaBoost. The generalization performance to new Subjects for a 7-way forced choice was 93% or more correct on two publicly available datasets, the best performance reported so far oil these datasets. The Outputs Of the classifier change smoothly as a function of time and thus can be used for unobtrusive expression dynamics capture. We developed an end-to-end system that provides facial expression codes at 24 frames per second and animates a computer-generated character. In real-time this expression mirror operates down to resolutions of 16 pixels front eye to eye. We also applied the system to fully automated facial action coding. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA.
C3 University of California System; University of California San Diego
RP Littlewort, G (corresponding author), Univ Calif San Diego, Inst Neural Computat, La Jolla, CA 92093 USA.
EM gwen@mplab.ucsd.edu
CR [Anonymous], 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389
   [Anonymous], AUTOMATIC ANAL SPONT
   [Anonymous], 1976, Pictures of facial affect
   BARTLETT MS, 2001, KLUWER INT SERIES EN, V612
   Cohen  I., 2003, COMPUTER VISION PATT
   Dailey MN, 2002, J COGNITIVE NEUROSCI, V14, P1158, DOI 10.1162/089892902760807177
   DATCU D, 2004, P IEEE C SYST MAN CY
   DEKEL O, 2003, ADV NEURAL INFORMATI, V15
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Ekman P, 1978, FACIAL ACTION CODING
   FASEL IR, IN PRESS COMPUTER VI
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Friedman J., 1998, ADDITIVE LOGISTIC RE
   HARPELED S, 2003, ADV NEURAL INFORMATI, V15
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   KAPOOR A, 2003, IEEE INT WORKSH AN M
   Kressel UHG, 1999, ADVANCES IN KERNEL METHODS, P255
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   LITTLEWORT G, ADV NEURAL INFORMATI, V16
   Lyons M. J., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P202, DOI 10.1109/AFGR.2000.840635
   MA JY, 2002, P ICSLP 2002
   MARKS TK, CVPR04 WORKSH GEN MO
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Platt JC, 2000, ADV NEUR IN, V12, P547
   Roth D, 2002, NEURAL COMPUT, V14, P1071, DOI 10.1162/089976602753633394
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Vapnik V., 1999, NATURE STAT LEARNING
   VIOLA P, 2001, 2000101 CRL
   WILHELM T, 2004, P IEEE C SYST MAN CY
NR 29
TC 201
Z9 224
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2006
VL 24
IS 6
BP 615
EP 625
DI 10.1016/j.imavis.2005.09.011
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 061NB
UT WOS:000238878200008
DA 2024-07-18
ER

PT J
AU Yörük, E
   Dutagaci, H
   Sankur, B
AF Yoeruek, Erdem
   Dutagaci, Helin
   Sankur, Buelent
TI Hand biometrics
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE biometry; identification and verification; principal component analysis
   and independent component analysis; registration for deformable shapes;
   distance transform
AB The potential of hand shape and hand texture-based biometry is investigated and algorithms are developed. Feature extraction stage is preceded by meticulous registration of the deformable shape of the hand. Alternative features addressing hand shape and hand texture are compared. Independent component analysis features prove to be the best performing in the identification and verification tasks. It is shown that hand biometric devices can be built that perform reliably for a population of at least 1000. (C) 2006 Elsevier B.V. All rights reserved.
C1 Bogazici Univ, Dept Elect & Elect Engn, Istanbul, Turkey.
C3 Bogazici University
RP Sankur, B (corresponding author), Bogazici Univ, Dept Elect & Elect Engn, Istanbul, Turkey.
EM yoruk.erdem@gmail.com; dutagach@boun.edu.tr; bulent.sankur@boun.edu.tr
RI Sankur, Bulent/N-4663-2017; Dutagaci, Helin/KFR-3162-2024
CR [Anonymous], P 4 INT C AUD VID BA
   [Anonymous], 1999, Morphological Image Analysis: Principles and Applications
   [Anonymous], 2000, STAT MODELS APPEARAN
   Bober M, 2001, IEEE T CIRC SYST VID, V11, P716, DOI 10.1109/76.927426
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   BULATOV Y, 2004, P 1 INT C BIOM AUTH
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Draper BA, 2003, COMPUT VIS IMAGE UND, V91, P115, DOI 10.1016/S1077-3142(03)00077-8
   Duta N, 2002, PATTERN RECOGN LETT, V23, P477, DOI 10.1016/S0167-8655(01)00179-9
   Ekenel HK, 2004, PATTERN RECOGN LETT, V25, P1377, DOI 10.1016/j.patrec.2004.05.013
   Funkhouser T, 2003, ACM T GRAPHIC, V22, P83, DOI 10.1145/588272.588279
   Han CC, 2003, PATTERN RECOGN, V36, P371, DOI 10.1016/S0031-3203(02)00037-7
   Hyvärinen A, 2000, NEURAL NETWORKS, V13, P411, DOI 10.1016/S0893-6080(00)00026-5
   Jain A. K., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P857, DOI 10.1109/ICIP.1999.823019
   Jain A.K., 1999, Proceedings of Second International Conference on Audio and Video-Based Biometric Person Authentication (AVBPA), P166
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   JEANNIN S, 2001, 55 MPEG M PIS IT JAN
   Kimia BB, 2003, INT J COMPUT VISION, V54, P157, DOI 10.1023/A:1023713602895
   Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Lin J., 2000, P WORKSH HUM MOT HUM
   Oden C, 2003, PATTERN RECOGN LETT, V24, P2145, DOI 10.1016/S0167-8655(03)00087-4
   Sanchez-Reillo R, 2000, IEEE T PATTERN ANAL, V22, P1168, DOI 10.1109/34.879796
   Weeks A. R, 1996, FUNDAMENTALS ELECT I, P466
   YORUK E, 2006, IN PRESS IEEE IMAGE
   You J, 2002, PATTERN RECOGN, V35, P847, DOI 10.1016/S0031-3203(01)00100-5
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang DP, 1999, PATTERN RECOGN, V32, P691, DOI 10.1016/S0031-3203(98)00117-4
   ZUNKEL RL, 1999, BIOMETRICS, P87
NR 28
TC 58
Z9 62
U1 2
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 483
EP 497
DI 10.1016/j.imavis.2006.01.020
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600008
DA 2024-07-18
ER

PT J
AU Shutler, JD
   Nixon, MS
AF Shutler, J. D.
   Nixon, M. S.
TI Zernike velocity moments for sequence-based description of moving
   features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE statistical moments; Zernike moments; motion; velocity moments; gait
ID AUTOMATIC GAIT RECOGNITION; REPRESENTATION; COMPUTATION
AB The increasing interest in processing sequences of images motivates development of techniques for sequence-based object analysis and description. Accordingly, new velocity moments have been developed to allow a statistical description of both shape and associated motion through an image sequence. Through a generic framework motion information is determined using the established centralised moments, enabling statistical moments to be applied to motion based time series analysis. The translation invariant Cartesian velocity moments suffer from highly correlated descriptions due to their non-orthogonality. The new Zernike velocity moments overcome this by using orthogonal spatial descriptions through the proven orthogonal Zernike basis. Further, they are translation and scale invariant. To illustrate their benefits and application the Zernike velocity moments have been applied to gait recognition-an emergent biometric. Good recognition results have been achieved on multiple datasets using relatively few spatial and/or motion features and basic feature selection and classification techniques. The prime aim of this new technique is to allow the generation of statistical features which encode shape and motion information, with generic application capability. Applied performance analyses illustrate the properties of the Zernike velocity moments which exploit temporal correlation to improve a shape's description. It is demonstrated how the temporal correlation improves the performance of the descriptor under more generalised application scenarios, including reduced resolution imagery and occlusion. (c) 2006 Elsevier B.V. All rights reserved.
C1 Plymouth Marine Lab, Remote Sensing Grp, Plymouth PL1 3DH, Devon, England.
   Univ Southampton, Dept Elect & Comp Sci, Southampton SO17 1BJ, Hants, England.
C3 Plymouth Marine Laboratory; University of Southampton
RP Shutler, JD (corresponding author), Plymouth Marine Lab, Remote Sensing Grp, Prospect Pl, Plymouth PL1 3DH, Devon, England.
EM jams@pml.ac.uk; jamie@zepler.org
RI Nixon, Mark S/F-7406-2014
OI Nixon, Mark/0000-0002-9174-5934
CR Aggarwal JK, 1999, COMPUT VIS IMAGE UND, V73, P428, DOI 10.1006/cviu.1998.0744
   [Anonymous], 2001, CMU MOTION BODY MOBO
   BENABDELKADER C, 2001, P INT C AUD VID BAS, P284
   BHATIA AB, 1954, P CAMB PHILOS SOC, V50, P40, DOI 10.1017/S0305004100029066
   BULTHOFF H, 1989, NATURE, V337, P549, DOI 10.1038/337549a0
   Clarke GM, 1998, BASIC COURSE STAT, P520
   COHEN PR, 1995, EMPIRICAL METHODS AR, P185
   CUNADO D, 1999, P AUT IEEE WORKSH AU, P27
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Foster JP, 2003, PATTERN RECOGN LETT, V24, P2489, DOI 10.1016/S0167-8655(03)00094-1
   Grant MG, 2002, PATTERN RECOGN, V35, P1099, DOI 10.1016/S0031-3203(01)00078-4
   Hayfron-Acquah JB, 2003, PATTERN RECOGN LETT, V24, P2175, DOI 10.1016/S0167-8655(03)00086-2
   Hoey J, 2000, PROC CVPR IEEE, P752, DOI 10.1109/CVPR.2000.855896
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   HUANG PS, 1999, ARTIF INTELL, V13, P93
   HUANG PS, 1998, P 9 BRIT MACH VIS C, V2, P639
   JOHANSSON G, 1976, SC AM, V232
   JOHNSON A, 2001, P 3 INT C AUD VID BA, P301
   Kale A, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P336, DOI 10.1109/AFGR.2002.1004176
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Lee L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P155, DOI 10.1109/AFGR.2002.1004148
   LI BC, 1993, PATTERN RECOGN, V26, P109, DOI 10.1016/0031-3203(93)90092-B
   Little J., 1998, VIDERE, V1, P1
   Mukundan R., 1998, Moment Functions in Image Analysis: Theory and Applications
   Nash JM, 1997, PATTERN RECOGN LETT, V18, P1035, DOI 10.1016/S0167-8655(97)00128-1
   NIYOGI SA, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P469, DOI 10.1109/CVPR.1994.323868
   PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U
   Rosales R., 1998, Recognition of human action using moment-based
   SADJADI FA, 1980, IEEE T PATTERN ANAL, V2, P127, DOI 10.1109/TPAMI.1980.4766990
   Sarkar S, 2005, IEEE T PATTERN ANAL, V27, P162, DOI 10.1109/TPAMI.2005.39
   Shutler J.D., 2002, 4th International Conference on Recent Advances in Soft Computing, P66
   Shutler JD., 2001, P BMVC, P705
   SHUTLER JD, 2000, P INT SOC PHOT REM S, P720
   SHUTLER JD, 2002, THESIS U SOUTHAMPTON
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   THOMPSON D, 1992, OXFORD DICT CURRENT
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Yam CY, 2004, PATTERN RECOGN, V37, P1057, DOI 10.1016/j.patcog.2003.09.012
NR 39
TC 33
Z9 40
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2006
VL 24
IS 4
BP 343
EP 356
DI 10.1016/j.imavis.2005.12.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 049US
UT WOS:000238043500003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Gross, R
   Matthews, I
   Baker, S
AF Gross, R
   Matthews, I
   Baker, S
TI Generic vs. person specific active appearance models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face tracking; active appearance models; face modelling
ID FACE-RECOGNITION
AB Active Appearance Models (AAMs) are generative parametric models that have been successfully used in the past to model faces. Anecdotal evidence, however, suggests that the performance of an AAM built to model the variation in appearance of a single person across pose, illumination, and expression (a Person Specific AAM) is substantially better than the performance of an AAM built to model the variation in appearance of many faces, including unseen subjects not in the training set (a Generic AAM). In this paper, we present an empirical evaluation that shows that Person Specific AAMs are, as expected, both easier to build and more robust to fit than Generic AAMs. Moreover, we show that: (1) building a generic shape model is far easier than building a generic appearance model, and (2) the shape component is the main cause of the reduced fitting robustness of Generic AAMs. We then proceed to describe two refinements to Generic AAMs to improve their performance: (1) a refitting procedure to improve the quality of the ground-truth data used to build the AAM and (2) a new fitting algorithm. For both refinements we demonstrate dramatically improved fitting performance. Finally, we evaluate the effect of these improvements on a combined model construction and fitting task. (c) 2005 Elsevier Ltd. All rights reserved.
C1 Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
C3 Carnegie Mellon University
RP Carnegie Mellon Univ, Inst Robot, Pittsburgh, PA 15213 USA.
EM rgross@cs.cmu.edu; iainm@cs.cmu.edu; simonb@cs.cmu.edu
CR [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], CMURITR0335
   Baker S, 2004, IEEE T PATTERN ANAL, V26, P1380, DOI 10.1109/TPAMI.2004.77
   BAKER S, 2004, CMURITR0414
   Cootes TF, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P748, DOI 10.1109/ICCV.2001.937601
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Lee KC, 2001, PROC CVPR IEEE, P519
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Xiao J, 2004, PROC CVPR IEEE, P668
NR 12
TC 188
Z9 219
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2005
VL 23
IS 12
BP 1080
EP 1093
DI 10.1016/j.imavis.2005.07.009
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 971ZK
UT WOS:000232423400005
DA 2024-07-18
ER

PT J
AU Karabernou, SM
   Terranti, F
AF Karabernou, SM
   Terranti, F
TI Real-time FPGA implementation of hough transform using gradient and
   CORDIC algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CORDIC; FPGA; Hough; real-time
AB This article describes a real-time architecture for Hough Transform based on CORDIC algorithm and gradient for straight lines detection. The CORDIC algorithm allows the use of simple operators, such as adders and shift registers, whereas the use of gradients reduces considerably the computation quantity. The proposed real-time architecture can be easily fitted into Field Programmable Gate Array (FPGA) reconfigurable devices, since the present performance increase of this technology allows the implementation of complex applications while real-time constraints in Hough Transform for lines detection are respected for most of the video transmission standards. This approach can be easily applied for other shapes detection. (c) 2005 Elsevier B.V. All rights reserved.
C1 UCP, ENSEA, ETIS, UMR 8051,CNRS, F-95014 Cergy Pontoise, France.
C3 Centre National de la Recherche Scientifique (CNRS)
RP Karabernou, SM (corresponding author), UCP, ENSEA, ETIS, UMR 8051,CNRS, 6,Ave Ponceau, F-95014 Cergy Pontoise, France.
EM karabernou@ensea.fr
CR Albanesi MG, 2000, REAL-TIME IMAGING, V6, P155, DOI 10.1006/rtim.1999.0180
   ANDRAK R, P 1998 ACM SIGDA 6 I
   DEMIGNY D, 1998, GDR PRC ISIS JAN
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   *FPGA BAS, APSX84 VHDL FPGA SYN
   HANAHARA K, 1988, IEEE T PATTERN ANAL, V10, P124
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   HOUZET D, 1993, UNPUB JUL 15 1993
   HU YH, 1992, IEEE T SIGNAL PROCES, V40, P834, DOI 10.1109/78.127956
   KOSHIMIZU H, 1991, IEICE T E, V74
   LINDBAUER N, 1999, THESIS LANDSHUT U GE
   *LSI LOG, 1989, L64250 HIST HOUGH TR
   MAITRE H, 1985, PANORAMA TRANSFORMEE, V2
   Meribout M, 1999, REAL-TIME IMAGING, V5, P279, DOI 10.1006/rtim.1998.0150
   OGORMAN F, 1976, IEEE T COMPUT, V25, P449, DOI 10.1109/TC.1976.1674627
   WALTHER JS, 1971, AFIPS C P, V38, P379
   ZHOU F, 1995, DSP95 C LIM CHYPR JU
   1959, IRE T ELECT COMPUTER, V8, P330
NR 18
TC 26
Z9 27
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2005
VL 23
IS 11
BP 1009
EP 1017
DI 10.1016/j.imavis.2005.07.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 973KF
UT WOS:000232520600007
DA 2024-07-18
ER

PT J
AU Yu, LJ
   Niu, XM
   Sun, SH
AF Yu, LJ
   Niu, XM
   Sun, SH
TI Print-and-scan model and the watermarking countermeasure
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE print-and-scan; geometric distortion; halftone
ID IMAGES
AB With multimedia developing rapidly, copyright protection and authentication is more and more important. Digital watermark is one of the most efficient methods to protect multimedia products. Print and scan attack is a challenging problem for most of digital watermarks. In this paper, the geometric distortion and halftone in print-and-scan process is analyzed for the sake of presenting a model of print-and-scan. A digital watermarking countermeasure is proposed. Experiment results verify the efficiency of the proposed watermarking countermeasure. The proposed work is promising in application of copyright protection and anti-forgery for paper media. (c) 2005 Elsevier B.V. All rights reserved.
C1 Harbin Inst Technol, Inst Info Countermeasure Tech, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Yu, LJ (corresponding author), Harbin Inst Technol, Inst Info Countermeasure Tech, POB 339, Harbin 150001, Peoples R China.
EM longjiang_yu@yahoo.com.cn
CR Alghoniemy M, 2000, PROC SPIE, V3971, P82, DOI 10.1117/12.385011
   Castleman K.R., 1995, DIGITAL IMAGE PROCES
   Koch E., 1995, PROC WORKSHOP NONLIN, P452
   Kutter M., 1998, Proceedings of SPIE, V3628, P423
   Lin CY, 2000, PROC SPIE, V3971, P90, DOI 10.1117/12.385012
   LIN CY, 1999, INT S MULTIMEDIA INF
   PEREIRA S, 1999, LECT NOTES COMPUTER, V1768, P200
   PETITCOLAS FA, 1998, LECT NOTES COMPUTER
   SCHMUCKER M, 2003, COMPUTER GRAPHIK TOP
   ULICHNEY R, 1987, DIGITALHALFTONING
   VOLOSHYNOVSKIY S, 2004, P SPIE PHOT W EL IM
   Wolfgang RB, 1999, P IEEE, V87, P1108, DOI 10.1109/5.771067
NR 12
TC 37
Z9 42
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2005
VL 23
IS 9
BP 807
EP 814
DI 10.1016/j.imavis.2005.05.014
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VF
UT WOS:000231400700005
DA 2024-07-18
ER

PT J
AU Remy, E
   Thiel, E
AF Remy, E
   Thiel, E
TI Exact medial axis with euclidean distance
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE medial axis; centres of maximal disks; look-up tables; Squared Euclidean
   Distance Transform; digital shape representation
ID LOOK-UP TABLES; TRANSFORMATION; REPRESENTATION; SKELETONS; ALGORITHM;
   PICTURE; TIME; MAPS; SET
AB Medial Axis (MA), also known as Centres of Maximal Disks, is a useful representation of a shape for image description and analysis. MA can be computed on a distance transform, where each point is labelled to its distance to the background. Recent algorithms allow one to compute Squared Euclidean Distance Transform (SEDT) in linear time in any dimension. While these algorithms provide exact measures, the only known method to characterise MA on SEDT, using local tests and Look-Up Tables (LUT), is limited to 2D and small distance values [Borgefors, et al., Seventh Scandinavian Conference on Image Analysis, 1991]. We have proposed [Remy, et al., Pat. Rec. Lett. 23 (2002) 649] an algorithm which computes the LUT and the neighbourhood to be tested in the case of chamfer distances. In this article, we adapt our algorithm for SEDT in arbitrary dimension and show that results have completely different properties. (C) 2004 Elsevier B.V. All rights reserved.
C1 ESIL, CNRS, UMR 6168, LSIS, F-13288 Marseille 9, France.
   CNRS, UMR 6166, LIF, F-13288 Marseille 9, France.
C3 Aix-Marseille Universite; Centre National de la Recherche Scientifique
   (CNRS); Centre National de la Recherche Scientifique (CNRS)
RP ESIL, CNRS, UMR 6168, LSIS, Case 925,163 Av Luminy, F-13288 Marseille 9, France.
EM eric.remy@up.univ-mrs.fr; edouard.thiel@lim.univ-mrs.fr
OI THIEL, Edouard/0000-0002-1057-9912
CR ARCELLI C, 1988, COMPUT VISION GRAPH, V43, P361, DOI 10.1016/0734-189X(88)90089-8
   Blum H., 1967, MODELS PERCEPTION SP, P362, DOI DOI 10.1142/S0218654308001154
   Borgefors G, 1997, PATTERN RECOGN LETT, V18, P465, DOI 10.1016/S0167-8655(97)00027-5
   BORGEFORS G, 1993, 8 SCAND C IM AN TROM, P105
   BORGEFORS G, 1991, 7 SCAND C IM AN AALB, V2, P974
   Coeurjolly D, 2003, LECT NOTES COMPUT SC, V2886, P327
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   diBaja GS, 1996, IMAGE VISION COMPUT, V14, P47, DOI 10.1016/0262-8856(95)01039-4
   HARDY GH, 1978, INTRO THEORY NUMBERS
   Hirata T, 1996, INFORM PROCESS LETT, V58, P129, DOI 10.1016/0020-0190(96)00049-X
   Meijster A, 2000, COMP IMAG VIS, V18, P331
   Nilsson F, 1997, GRAPH MODEL IM PROC, V59, P55, DOI 10.1006/gmip.1996.0412
   PFALTZ JL, 1967, COMMUN ACM, V10, P119, DOI 10.1145/363067.363120
   RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4
   Remy E, 2003, LECT NOTES COMPUT SC, V2886, P224
   Remy E, 2002, PATTERN RECOGN LETT, V23, P649, DOI 10.1016/S0167-8655(01)00141-6
   REMY E, 2001, THESIS U MEDITERRANE
   ROSENFEL.A, 1966, J ACM, V13, P471
   SAITO T, 1994, IEICE T INF SYST, VE77D, P1005
   SAITO T, 1994, PATTERN RECOGN, V27, P1551, DOI 10.1016/0031-3203(94)90133-3
   THIEL E, 2001, GEOMETRIE DISTANCES
   WEISSTEIN EW, LANDAU RAMANUJAN CON
NR 22
TC 37
Z9 43
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 167
EP 175
DI 10.1016/j.imavis.2004.06.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800008
DA 2024-07-18
ER

PT J
AU Vakali, A
   Hacid, MS
   Elmagarmid, A
AF Vakali, A
   Hacid, MS
   Elmagarmid, A
TI MPEG-7 based description schemes for multi-level video content
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE MPEG-7; description schemes; XML schema; video classification
ID SEGMENTATION; TRACKING
AB MPEG-7 has emerged as the standard for multimedia data content description for efficiently describing multimedia content. In this context, its primary goal is to provide flexible and effective searching and retrieval of multimedia resources. Most of the earlier work on MPEG-7 description schemes (DSs) and descriptors (Ds) focuses on the description of a single multimedia document, whereas MPEG-7 can be further exploited to support more advances implementations under multimedia database systems. Therefore, it is important to reconsider issues related to high level multimedia modeling and representation, in the light of the MPEG-7 perspective. In this paper, we propose a high level multimedia representation and description scheme based on multi-level video modeling and semantic video classification. The proposed multi-level multimedia representation and DSs are expected to support more effective video content indexing and accessing operations. The presented DSs and Ds are further described by using the XML Schema language, which has been adopted as the basis of the Description Definition Language (DDL) of the MPEG-7 standard. (C) 2003 Elsevier B.V. All rights reserved.
C1 Aristotle Univ, Dept Informat, Thessaloniki 54006, Greece.
   Lab Ingn Syst Informat, Lyon, France.
   Purdue Univ, Dept Comp Sci, W Lafayette, IN 47907 USA.
C3 Aristotle University of Thessaloniki; Purdue University System; Purdue
   University
RP Vakali, A (corresponding author), Aristotle Univ, Dept Informat, Thessaloniki 54006, Greece.
EM avakali@csd.auth.gr
RI Vakali, Athina/D-8432-2016
OI Vakali, Athina/0000-0002-0666-6984
CR BEIGI M, 1998, P SPIE C STOR RETR I, P3312
   Benitez AB, 2000, SIGNAL PROCESS-IMAGE, V16, P235, DOI 10.1016/S0923-5965(00)00030-8
   Chang SF, 1998, IEEE T CIRC SYST VID, V8, P602, DOI 10.1109/76.718507
   CHANG SF, 1997, CNRI DIGITAL LIB FEB
   FAN J, 2001, J ELECT IMAGING
   FAN J, 2001, MULTIMEDIA TOOLS APP
   Fan J., 2001, IEEE T IMAGE PROCESS
   FAN J, 2001, P SPIE STOR RETR IM
   Fan JP, 2000, J ELECTRON IMAGING, V9, P521, DOI 10.1117/1.1287534
   Gu C, 1998, IEEE T CIRC SYST VID, V8, P572, DOI 10.1109/76.718504
   Günsel B, 1998, J ELECTRON IMAGING, V7, P592, DOI 10.1117/1.482613
   HUANG Q, 1999, JTCISC29WG11 ISOIEC
   MARTINEZ JM, 2002, ISOIECJTC1SC29WG11NG
   Ohm JR, 2000, SIGNAL PROCESS-IMAGE, V16, P157, DOI 10.1016/S0923-5965(00)00023-0
   PAEK S, 1999, PROPOSAL MPEG 7 IMAG
   PAEK S, 1999, IST SPIE 99
   PAEK S, 1998, 199803 ADVENT
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Rui Y, 1999, MULTIMEDIA SYST, V7, P359, DOI 10.1007/s005300050138
   Salembier P, 2000, SIGNAL PROCESS-IMAGE, V16, P211, DOI 10.1016/S0923-5965(00)00026-6
   SATOH S, 1997, NAME IT ASS FACE NAM
   TERZI E, 2001, P 7 INT C DIST MULT
   YEUNG M, 1996, P IEEE C MULT COMP S
NR 23
TC 8
Z9 8
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2004
VL 22
IS 5
BP 367
EP 378
DI 10.1016/S0262-8856(03)00098-2
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 806GN
UT WOS:000220422500002
DA 2024-07-18
ER

PT J
AU Liu, LF
   Sclaroff, S
AF Liu, LF
   Sclaroff, S
TI Deformable model-guided region split and merge of image regions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE deformable templates; region segmentation; statistical shape models;
   object recognition; part decomposition
ID SHAPE; RECOGNITION; COMPONENTS; EXTRACTION
AB The incorporation of model-based splitting operations produces an improved algorithm for image segmentation with deformable templates. Image regions are merged together and/or split apart, based on agreement with a statistical shape model, as well as local shape properties of the region bounding contours. Experiments indicate that the new split/merge strategy yields a significant improvement over the previous template-based segmentation method that used merging alone. (C) 2003 Elsevier B.V. All rights reserved.
C1 Boston Univ, Dept Comp Sci, Boston, MA 02215 USA.
C3 Boston University
RP Boston Univ, Dept Comp Sci, Boston, MA 02215 USA.
EM liu@bwh.harvard.edu; sclaroff@cs.bu.edu
RI Pan, Chong/B-2996-2012
CR [Anonymous], 1971, IEEE C SYST CONTR
   [Anonymous], 1991, Hands: A Pattern Theoretic Study of Biological Shapes
   Belyaev A. G., 1999, International Journal of Shape Modeling, V5, P195, DOI 10.1142/S0218654399000174
   BEVERIDGE JR, 1989, INT J COMPUT VISION, V2, P311, DOI 10.1007/BF00158168
   BIEDERMAN I, 1987, PSYCHOL REV, V94, P115, DOI 10.1037/0033-295X.94.2.115
   CHOU PB, 1990, INT J COMPUT VISION, V4, P185, DOI 10.1007/BF00054995
   Comaniciu D, 1997, PROC CVPR IEEE, P750, DOI 10.1109/CVPR.1997.609410
   COOTES TF, 1994, IMAGE VISION COMPUT, V12, P355, DOI 10.1016/0262-8856(94)90060-4
   Dimitrov P, 2000, PROC CVPR IEEE, P417, DOI 10.1109/CVPR.2000.855849
   DUTA N, 1999, P IEEE C COMP VIS PA, V2, P8
   Ge YR, 1996, IEEE T PATTERN ANAL, V18, P1055, DOI 10.1109/34.544075
   Golland P, 2000, PROC CVPR IEEE, P10, DOI 10.1109/CVPR.2000.855792
   Hoffman DD, 1997, COGNITION, V63, P29, DOI 10.1016/S0010-0277(96)00791-3
   HOFFMAN DD, 1984, COGNITION, V18, P65, DOI 10.1016/0010-0277(84)90022-2
   HOROWITZ SL, 1978, COMPUT VISION GRAPH, V7, P282, DOI 10.1016/0146-664X(78)90118-1
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   Latecki LJ, 1999, COMPUT VIS IMAGE UND, V73, P441, DOI 10.1006/cviu.1998.0738
   LIU L, 1999, P 1999 IEEE C COMP V, V2, P21
   LUNDERVOLD A, 1999, P IEEE C COMP VIS PA, V1, P231
   Mardia KV, 1997, IEEE T PATTERN ANAL, V19, P1035, DOI 10.1109/34.615452
   MARR D, 1977, PROC R SOC SER B-BIO, V197, P441, DOI 10.1098/rspb.1977.0080
   PENTLAND AP, 1990, INT J COMPUT VISION, V4, P107, DOI 10.1007/BF00127812
   RICHARDS W, 1986, J OPT SOC AM A, V3, P1483, DOI 10.1364/JOSAA.3.001483
   Rosin PL, 2000, IEEE T SYST MAN CY A, V30, P202, DOI 10.1109/3468.833102
   Russ J.C., 1992, The Image Processing Handbook
   Sclaroff S, 2001, IEEE T PATTERN ANAL, V23, P475, DOI 10.1109/34.922706
   Singh M, 1999, PERCEPT PSYCHOPHYS, V61, P636, DOI 10.3758/BF03205536
   Singh M, 1998, BEHAV BRAIN SCI, V21, P36, DOI 10.1017/S0140525X98470109
   VAINA LM, 1990, BIOL CYBERN, V62, P225, DOI 10.1007/BF00198097
   Xu C., 2000, HDB MEDICAL IMAGING, P129
   YUILLE AL, 1992, INT J COMPUT VISION, V8, P99, DOI 10.1007/BF00127169
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 34
TC 17
Z9 19
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2004
VL 22
IS 4
BP 343
EP 354
DI 10.1016/j.imavis.2003.11.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 778FW
UT WOS:000189229700007
DA 2024-07-18
ER

PT J
AU Bromiley, PA
   Thacker, NA
   Scott, MLJ
   Pokric, M
   Lacey, AJ
   Cootes, TF
AF Bromiley, PA
   Thacker, NA
   Scott, MLJ
   Pokric, M
   Lacey, AJ
   Cootes, TF
TI Bayesian and non-Bayesian probabilistic models for medical image
   analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Symposium on Probabilistic Models in Computer Vision
CY MAY, 2001
CL ENGLAND
SP British Mach Vis, Royal Stat Soc
DE Bayesian and non-Bayesian probabilistic models; magnetic resonance image
   analysis; expectation maximisation algorithm
ID VOLUME; CLASSIFICATION
AB Bayesian approaches to data analysis are popular in machine vision, and yet the main advantage of Bayes theory, the ability to incorporate prior knowledge in the form of the prior probabilities, may lead to problems in some quantitative tasks. In this paper we demonstrate examples of Bayesian and non-Bayesian techniques from the area of magnetic resonance image (MRI) analysis. Issues raised by these examples are used to illustrate difficulties in Bayesian methods and to motivate an approach based on frequentist methods. We believe this approach to be more suited to quantitative data analysis, and provide a general theory for the use of these methods in learning (Bayes risk) systems and for data fusion. Proofs are given for the more novel aspects of the theory. We conclude with a discussion of the strengths and weaknesses, and the fundamental suitability, of Bayesian and non-Bayesian approaches for MRI analysis in particular, and for machine vision systems in general. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Manchester, Sch Med, Imaging Sci & Biomed Engn Div, Manchester M13 9PT, Lancs, England.
C3 University of Manchester
RP Univ Manchester, Sch Med, Imaging Sci & Biomed Engn Div, Stopford Bldg,Oxford Rd, Manchester M13 9PT, Lancs, England.
EM paul.bromiley@man.ac.uk; thacker@man.ac.uk
OI Bromiley, Paul/0000-0003-4901-107X; Cootes, Timothy/0000-0002-2695-9063
CR Aherne FJ, 1998, KYBERNETIKA, V34, P363
   [Anonymous], 1986, Encyclopedia of Statistical Sciences, DOI DOI 10.1002/0471667196.ESS2064.PUB2
   BAHN MM, 1995, MAGNET RESON MED, V33, P309, DOI 10.1002/mrm.1910330305
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Bromiley PA, 2002, IMAGE VISION COMPUT, V20, P609, DOI 10.1016/S0262-8856(02)00050-1
   BROMILEY PA, 2002, P MIUA 2002 PORTSM, P117
   BROMILEY PA, 2000, P BMVC 2000 BRIST, P795
   BROMILEY PA, 2001, P MIUA 2001 BIRM, P105
   BUSKULIC D, 1993, PHYS LETT B, V313, P535, DOI 10.1016/0370-2693(93)90028-G
   Courtney P., 2001, IMAGING VISION SYSTE
   Feldman GJ, 1998, PHYS REV D, V57, P3873, DOI 10.1103/PhysRevD.57.3873
   Friston K., 1994, Human Brain Mapping, V1, P153
   Friston KJ, 1996, NEUROIMAGE, V4, P223, DOI 10.1006/nimg.1996.0074
   FUKENAGA K, 1990, INTRO STAT PATTERN R
   Guillemaud R, 1997, IEEE T MED IMAGING, V16, P238, DOI 10.1109/42.585758
   HARALICK RM, 1994, CVGIP-IMAG UNDERSTAN, V60, P245, DOI 10.1006/cviu.1994.1055
   Jackson A, 2002, OTOL NEUROTOL, V23, P111, DOI 10.1097/00129492-200203000-00001
   JAMES F, 2000, P WORKSH CONF LIM CE
   Jeffreys H., 1939, THEORY PROBABILITY
   Laidlaw DH, 1998, IEEE T MED IMAGING, V17, P74, DOI 10.1109/42.668696
   Neyman J., 1937, Phil Trans R Soc Lond a, V236, P333, DOI [DOI 10.1098/RSTA.1937.0005, 10.1098/rsta.1937.0005]
   POKRIC M, 2001, P MIUA 2001 BIRM, P77
   POOLE I, 1990, OPTIMAL PROBABILISTI
   REMPP KA, 1994, RADIOLOGY, V193, P637, DOI 10.1148/radiology.193.3.7972800
   Thacker NA, 2002, RADIOLOGY, V224, P278, DOI 10.1148/radiol.2241010419
   THACKER NA, 2000, P MIUA LOND, P61
   THACKER NA, 2002, P SOC PHOTO-OPT INS, V4877, P1
   Vokurka EA, 2002, AM J NEURORADIOL, V23, P459
   Wolansky L J, 1994, J Neuroimaging, V4, P141
   Xu L, 1996, NEURAL COMPUT, V8, P129, DOI 10.1162/neco.1996.8.1.129
NR 30
TC 15
Z9 18
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2003
VL 21
IS 10
BP 851
EP 864
DI 10.1016/S0262-8856(03)00072-6
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 723KU
UT WOS:000185432200003
DA 2024-07-18
ER

PT J
AU Cheng, YC
   Chen, SY
AF Cheng, YC
   Chen, SY
TI Image classification using color, texture and regions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE content-based retrieval; image classification; histogram; color texture
   segmentation; dissimilarity measure; k-NN rule; homogeneous region;
   local edge pattern
ID SEGMENTATION
AB A new classification method using color, texture and regions is proposed in this study. Image-based features related to color and local edge patterns are used to prune irrelevant database images for each query image. The proposed region matching is then applied to find the match to the query image from among the set of candidate images in the database. The dissimilarity of each pair of images can be calculated on the basis of the matching results. Finally, all the database images in the candidate set can be sorted by ascending dissimilarity values. To achieve the classification goal, the k-NN rule is used to assign a class label to the query image. Note that the main contribution of this paper is to select proper features for representing color, texture and region, which, in turn, are used to achieve effective classification results. More important, all features used in the proposed method, no matter color or texture, are presented in the simple form of histogram, yet leading to effective results. Even in the stage of region matching, color and texture features in histograms are also used to obtain homogeneous regions and to measure dissimilarity. In addition, the proposed classification method can be applied to all kinds of color image databases rather than specific databases. The number of classes can be as versatile as required by the application. The effectiveness and practicability of the proposed method has been demonstrated by various experiments. (C) 2003 Elsevier B.V. All rights reserved.
C1 Yuan Ze Univ, Dept Comp Sci & Engn, Taoyuan 32026, Taiwan.
C3 Yuan Ze University
RP Yuan Ze Univ, Dept Comp Sci & Engn, 135 Yuan Tung Rd, Taoyuan 32026, Taiwan.
EM cschen@saturn.yzu.edu.tw
CR Bach JR, 1996, P SOC PHOTO-OPT INS, V2670, P76, DOI 10.1117/12.234785
   Carson C, 1997, IEEE WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO LIBRARIES, PROCEEDINGS, P42, DOI 10.1109/IVL.1997.629719
   Chen KM, 2002, PATTERN RECOGN LETT, V23, P755, DOI 10.1016/S0167-8655(01)00150-7
   FLICKNER M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.410146
   Fuh CS, 2000, IEEE T IMAGE PROCESS, V9, P156, DOI 10.1109/83.817608
   LO CH, 2003, IN PRESS INT J PATTE, P2003
   Ma WY, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL I, P568, DOI 10.1109/ICIP.1997.647976
   Ojala T, 1999, PATTERN RECOGN, V32, P477, DOI 10.1016/S0031-3203(98)00038-7
   Park IK, 1999, IMAGE VISION COMPUT, V17, P465, DOI 10.1016/S0262-8856(98)00139-5
   Pass G., 1996, Proceeding. Third IEEE Workshop on Applications of Computer Vision. WACV'96 (Cat. No.96TB100084), P96, DOI 10.1109/ACV.1996.572008
   Pentland A, 1996, INT J COMPUT VISION, V18, P233, DOI 10.1007/BF00123143
   Rui Y, 1998, IEEE T CIRC SYST VID, V8, P644, DOI 10.1109/76.718510
   Smith J. R., 1996, Proceedings ACM Multimedia 96, P87, DOI 10.1145/244130.244151
   Smith JR, 1999, COMPUT VIS IMAGE UND, V75, P165, DOI 10.1006/cviu.1999.0771
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Szummer M, 1998, 1998 IEEE INTERNATIONAL WORKSHOP ON CONTENT-BASED ACCESS OF IMAGE AND VIDEO DATABASE, PROCEEDINGS, P42, DOI 10.1109/CAIVD.1998.646032
   Vailaya A, 2001, IEEE T IMAGE PROCESS, V10, P117, DOI 10.1109/83.892448
   Vailaya A, 1998, PATTERN RECOGN, V31, P1921, DOI 10.1016/S0031-3203(98)00079-X
NR 18
TC 38
Z9 45
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2003
VL 21
IS 9
BP 759
EP 776
DI 10.1016/S0262-8856(03)00069-6
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 711QX
UT WOS:000184753500001
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Zuo, X
   Zheng, XX
   Gao, XY
   Wang, B
   Hu, WM
AF Zhang, Yu
   Zuo, Xin
   Zheng, Xuxu
   Gao, Xiaoyong
   Wang, Bo
   Hu, Weiming
TI Improving metric-based few-shot learning with dynamically scaled softmax
   loss
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Few-shot learning; Metric-based learning framework; Softmax loss
   improvement
ID ALIGNMENT
AB The metric-based learning framework has been widely used in data-scarce few-shot visual classification. However, the current loss function limits the effectiveness of metric learning. One issue is that the nearest neighbor classification technique used greatly narrows the value range of similarity between the query and class prototypes, which limits the guiding ability of the loss function. The other issue is that the episode-based training setting randomizes the class combination in each iteration, which reduces the perception of the traditional softmax losses for effective learning from episodes with various data distributions.To solve these problems, we first review some variants of the softmax loss from a unified perspective, and then propose a novel DynamicallyScaled Softmax Loss (DSSL). By adding a probability regulator (for scaling probabilities) and a loss regulator (for scaling losses), the loss function can adaptively adjust the prediction distribution and the training weights of the samples, which forces the model to focus on more informative samples. Finally, we found the proposed DSSL strategy for few-shot classifiers can achieve competitive results on four generic benchmarks and a fine-grained benchmark, demonstrating the effectiveness of improving the distinguishability (for base classes) and generalizability (for novel classes) of the learned feature space.
C1 [Zhang, Yu; Zuo, Xin; Gao, Xiaoyong] China Univ Petr, Beijing 102249, Peoples R China.
   [Zheng, Xuxu] Chinese Acad Sci, Data Intelligence Syst Res Ctr, Inst Comp Technol, Beijing 100190, Peoples R China.
   [Wang, Bo; Hu, Weiming] Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100190, Peoples R China.
   [Wang, Bo] Peking Univ, Sch Software & Microelect, Beijing 100871, Peoples R China.
   [Hu, Weiming] Univ Chinese Acad Sci, Sch Artificial Intelligence, Beijing 100190, Peoples R China.
   [Hu, Weiming] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
   [Wang, Bo] Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
C3 China University of Petroleum; Chinese Academy of Sciences; Institute of
   Computing Technology, CAS; Chinese Academy of Sciences; Institute of
   Automation, CAS; Peking University; Chinese Academy of Sciences;
   University of Chinese Academy of Sciences, CAS; ShanghaiTech University;
   Chinese Academy of Sciences; Institute of Automation, CAS
RP Wang, B (corresponding author), Chinese Acad Sci, Natl Lab Pattern Recognit, Inst Automat, 95 Zhongguancun East Rd, Beijing 100190, Peoples R China.
EM zuox@cup.edu.cn; gao@cup.edu.cn; wangbo@ia.ac.cn; wmhu@nlpr.ia.ac.cn
FU Beijing Natural Science Foundation [62036011, 62192782, 61721004,
   U2033210]; Major Projects of Guangdong Edu-cation Department for
   Foundation Research and Applied Research [L223003]; Guangdong Provincial
   University Innovation Team Project [2017KZDXM081, 2018KZDXM066]; 
   [2020KCXTD045]
FX This work is supported by Beijing Natural Science Foundation (4234086) ,
   the National key R&D program of China (No. 2020AAAA0106800) , the
   Natural Science Foundation of China (Grant No. 62036011, 62192782,
   61721004, U2033210) , and Beijing Natural Science Foundation (L223003) ,
   The Major Projects of Guangdong Education Department for Foundation
   Research and Applied Research (Grant: 2017KZDXM081, 2018KZDXM066) ,
   Guangdong Provincial University Innovation Team Project (Project No.:
   2020KCXTD045) .r No. 62036011, 62192782, 61721004, U2033210) , and
   Beijing Natural Science Foundation (L223003) , The Major Projects of
   Guangdong Edu-cation Department for Foundation Research and Applied
   Research (Grant: 2017KZDXM081, 2018KZDXM066) , Guangdong Provincial
   University Innovation Team Project (Project No.: 2020KCXTD045) .
CR Afrasiyabi Arman, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P18, DOI 10.1007/978-3-030-58558-7_2
   Antoniou A., 2019, 7 INT C LEARNING REP
   Aoxue Li, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12573, DOI 10.1109/CVPR42600.2020.01259
   Baik S, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9445, DOI 10.1109/ICCV48922.2021.00933
   Bao W, 2021, IEEE ACCESS, V9, P90805, DOI 10.1109/ACCESS.2021.3091704
   Bateni Peyman, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14481, DOI 10.1109/CVPR42600.2020.01450
   Bertinetto Luca, 2019, PROC INT C LEARN REP
   Bin Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P438, DOI 10.1007/978-3-030-58548-8_26
   Chen HX, 2022, INT C PATT RECOG, P4765, DOI 10.1109/ICPR56361.2022.9955637
   Chen JX, 2020, AAAI CONF ARTIF INTE, V34, P3478
   Chen W., 2019, 7 INT C LEARNING REP
   Chen YB, 2021, Arxiv, DOI [arXiv:2003.04390, 10.48550/arXiv.2003.04390]
   Chen ZT, 2019, IEEE T IMAGE PROCESS, V28, P4594, DOI 10.1109/TIP.2019.2910052
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Cui ZY, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104574
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Doersch C., 2020, NEURIPS, V33, P21981
   Finn C, 2017, PR MACH LEARN RES, V70
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   Hao FS, 2022, IEEE T CIRC SYST VID, V32, P4351, DOI 10.1109/TCSVT.2021.3132912
   He J, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1236, DOI 10.1145/3394171.3413811
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, COMPUT SCI, V2
   Hou RB, 2019, ADV NEUR IN, V32
   Hu WM, 2023, IEEE T PATTERN ANAL, V45, P3072, DOI 10.1109/TPAMI.2022.3172932
   Huang HX, 2022, IEEE T CIRC SYST VID, V32, P853, DOI 10.1109/TCSVT.2021.3065693
   Khrulkov V, 2020, PROC CVPR IEEE, P6417, DOI 10.1109/CVPR42600.2020.00645
   Kim J., 2020, EUR C COMP VIS, P599, DOI DOI 10.1007/978-3-030-58452-8_35
   Koch G., 2015, ICML DEEP LEARNING W, V2
   Krizhevsky A., 2009, Tech. Rep.
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Cat Phuoc, 2022, 10 INT C LEARN REPR
   Le DH, 2021, ADV NEUR IN, V34
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Lei SZ, 2022, COMPUT ELECTR ENG, V99, DOI 10.1016/j.compeleceng.2022.107848
   Li WB, 2019, PROC CVPR IEEE, P7253, DOI 10.1109/CVPR.2019.00743
   Li WB, 2019, AAAI CONF ARTIF INTE, P8642
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu C, 2021, AAAI CONF ARTIF INTE, V35, P8635
   Liu G, 2021, IMAGE VISION COMPUT, V110, DOI 10.1016/j.imavis.2021.104164
   Liu WY, 2016, PR MACH LEARN RES, V48
   Liu Y, 2022, AAAI CONF ARTIF INTE, P1828
   Liu Y, 2022, PROC CVPR IEEE, P14391, DOI 10.1109/CVPR52688.2022.01401
   Lu S, 2021, AAAI CONF ARTIF INTE, V35, P8776
   Ma RK, 2022, AAAI CONF ARTIF INTE, P1926
   Mangla P, 2020, IEEE WINT CONF APPL, P2207, DOI [10.1109/wacv45572.2020.9093338, 10.1109/WACV45572.2020.9093338]
   Mazumder P, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104006
   Mensink T, 2012, LECT NOTES COMPUT SC, V7573, P488, DOI 10.1007/978-3-642-33709-3_35
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Oreshkin BN, 2018, ADV NEUR IN, V31
   Qiao LM, 2019, IEEE I CONF COMP VIS, P3602, DOI 10.1109/ICCV.2019.00370
   Ravi S., 2016, INT C LEARNING REPRE
   Ravichandran A, 2019, IEEE I CONF COMP VIS, P331, DOI 10.1109/ICCV.2019.00042
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rusu A. A., 2019, INT C LEARN REPR
   Schwartz E, 2018, ADV NEUR IN, V31
   Shen ZQ, 2021, AAAI CONF ARTIF INTE, V35, P9594
   Simon C, 2020, PROC CVPR IEEE, P4135, DOI 10.1109/CVPR42600.2020.00419
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wah C., 2011, CALTECH UCSD BIRDS 2
   Wang B, 2021, IEEE T IMAGE PROCESS, V30, P6050, DOI 10.1109/TIP.2021.3091833
   Wang F, 2021, PROC CVPR IEEE, P2495, DOI 10.1109/CVPR46437.2021.00252
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wang HX, 2021, PR MACH LEARN RES, V139
   Wang Yan, 2019, CoRR
   Wang YQ, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3386252
   Wang Yong, 2018, WORKSH MET METALEARN
   Wertheimer D, 2021, PROC CVPR IEEE, P8008, DOI 10.1109/CVPR46437.2021.00792
   Xu CM, 2021, PROC CVPR IEEE, P5178, DOI 10.1109/CVPR46437.2021.00514
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Zhang BQ, 2022, AAAI CONF ARTIF INTE, P9014
   Zhang RX, 2018, ADV NEUR IN, V31
   Zhang X, 2018, Arxiv, DOI arXiv:1809.04157
   Zhu W, 2021, PATTERN RECOGN, V112, DOI 10.1016/j.patcog.2020.107797
NR 81
TC 1
Z9 1
U1 5
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104860
DI 10.1016/j.imavis.2023.104860
EA NOV 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Z2EA9
UT WOS:001110250500001
DA 2024-07-18
ER

PT J
AU Zhu, SD
   Zhang, YZ
   Feng, Y
AF Zhu, Shangdong
   Zhang, Yunzhou
   Feng, Yu
TI GW-net: An efficient grad-CAM consistency neural network with weakening
   of random erasing features for semi-supervised person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semi-supervised person re-identification; Grad-CAM consistency
   regularization module; Weakening of random erasing features module; Data
   augmentation
AB Person re-identification (Re-ID) subject to loss of detailed information (sacrificing certain intricate body details) in samples caused by conventional regularization algorithms and degraded cross-domain performance due to limited generalization capacity is a challenging task. The majority of the existing research efforts address this problem either for attention regularization or cross-domain task, but neglect to explore a powerful framework to consider solving both cases simultaneously. To overcome this limitation, this paper develops an efficient semi-supervised person Re-ID network with Grad-CAM consistency regularization and weakening of random erasing features (GW-Net) to explore rich features and expect non-degraded performance in cross-domain con-dition. Specifically, a Grad-CAM consistency regularization (GCCR) module is designed to capture detailed in-formation by using Grad-CAM for consistency regularization, thereby enhancing the capacity of intra-class feature mining. Secondly, a weakening of random erasing features (WREF) module is presented to reduce the impact of erased regions on texture features, thereby maintaining the performance on the general source domain while preventing performance degradation in the target domain. Thirdly, a Grad-CAM consistency regularization loss is introduced to enable our model to maintain consistency between Grad-CAM results of the unlabeled and its augmented images. Meanwhile, a feature consistency loss is reported to keep consistency between features of unlabeled samples. Finally, sufficient experiments are carried out on three representative datasets, which vali-date the efficacy and meliority of our presented approach over state-of-the-art methods.
C1 [Zhu, Shangdong] Northeastern Univ, Fac Robot Sci & Engn, Shenyang 110819, Peoples R China.
   [Zhang, Yunzhou; Feng, Yu] Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
C3 Northeastern University - China; Northeastern University - China
RP Zhang, YZ (corresponding author), Northeastern Univ, Coll Informat Sci & Engn, Shenyang 110819, Peoples R China.
EM zhangyunzhou@mail.neu.edu.cn
OI Zhu, Shangdong/0000-0003-4701-2028
FU National Natural Science Foundation of China [61471110,
   2021JH1/10400049]; Major Science and Technology Projects of Liaoning
   Province [6142002200301]; Fundation of Key Laboratory of Aerospace
   System Simulation [2019KD0AD01/006]; Fundation of Key Laboratory of
   Equipment Reliability; Open Research Projects of Zhejiang Lab
   [2019JZZY010128]; Major Science and Technology Innovation Engineering
   Projects of Shandong Province [WD2C20205500306]
FX The research is supported by National Natural Science Foundation of
   China (No. 61973066, 61471110), Major Science and Technology Projects of
   Liaoning Province (No. 2021JH1/10400049), Fundation of Key Laboratory of
   Aerospace System Simulation (No. 6142002200301), Fundation of Key
   Laboratory of Equipment Reliability (No. WD2C20205500306), Open Research
   Projects of Zhejiang Lab (No. 2019KD0AD01/006) and Major Science and
   Technology Innovation Engineering Projects of Shandong Province (No.
   2019JZZY010128).
CR Berthelot D, 2019, ADV NEUR IN, V32
   Cai HH, 2022, MULTIMED TOOLS APPL, V81, P1787, DOI 10.1007/s11042-021-11420-y
   Chang XY, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107569
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen XL, 2021, PROC CVPR IEEE, P15745, DOI 10.1109/CVPR46437.2021.01549
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Cubuk ED, 2019, Arxiv, DOI arXiv:1805.09501
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   DeVries T, 2017, Arxiv, DOI [arXiv:1708.04552, DOI 10.48550/ARXIV.1708.04552]
   Ding GD, 2019, IEEE T MULTIMEDIA, V21, P2891, DOI 10.1109/TMM.2019.2916456
   Figueira D, 2013, 2013 10TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS 2013), P111, DOI 10.1109/AVSS.2013.6636625
   Gong X, 2022, IEEE T MULTIMEDIA, V24, P217, DOI 10.1109/TMM.2021.3050082
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Han JL, 2022, Arxiv, DOI arXiv:2201.12078
   Hao G., 2020, P AS C COMP VIS, P21
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong PX, 2021, INT C PATT RECOG, P6471, DOI 10.1109/ICPR48806.2021.9412561
   Huang Y, 2019, IEEE T IMAGE PROCESS, V28, P1391, DOI 10.1109/TIP.2018.2874715
   Ji HXY, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P3641, DOI 10.1109/ICCV48922.2021.00364
   Jia JR, 2020, PATTERN RECOGN, V108, DOI 10.1016/j.patcog.2020.107568
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J., 2021, PREPRINT
   Li JW, 2018, INT J COMPUT VISION, V126, P855, DOI 10.1007/s11263-018-1075-5
   Liu J., 2022, Applied Intelligence, P1
   Liu SP, 2022, IEEE T MULTIMEDIA, V24, P2392, DOI 10.1109/TMM.2021.3080076
   Liu X, 2014, PROC CVPR IEEE, P3550, DOI 10.1109/CVPR.2014.454
   Liu XH, 2021, PROC CVPR IEEE, P13329, DOI 10.1109/CVPR46437.2021.01313
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Lv JY, 2020, IMAGE VISION COMPUT, V95, DOI 10.1016/j.imavis.2020.103875
   Mallapragada PK, 2009, IEEE T PATTERN ANAL, V31, P2000, DOI 10.1109/TPAMI.2008.235
   Ming ZQ, 2022, IMAGE VISION COMPUT, V119, DOI 10.1016/j.imavis.2022.104394
   Miyato T, 2019, IEEE T PATTERN ANAL, V41, P1979, DOI 10.1109/TPAMI.2018.2858821
   Moskvyak O, 2021, Arxiv, DOI arXiv:2107.11566
   Oliver A, 2018, ADV NEUR IN, V31
   Qi L, 2020, IEEE T CIRC SYST VID, V30, P2815, DOI 10.1109/TCSVT.2020.2983600
   Quispe R, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.07.009
   Sajjadi M, 2016, ADV NEUR IN, V29
   Samuli L., 2017, ICLR, P1
   Shen D, 2021, IEEE T IMAGE PROCESS, V30, P1676, DOI 10.1109/TIP.2020.3046904
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sun YF, 2021, IEEE T PATTERN ANAL, V43, P902, DOI 10.1109/TPAMI.2019.2938523
   Tan H., 2022, IEEE Trans. Neural Netw. Learn. Syst., P1
   Tarvainen A, 2017, ADV NEUR IN, V30
   Wang HR, 2022, IEEE T NEUR NET LEAR, V33, P145, DOI 10.1109/TNNLS.2020.3027589
   Wang YQ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12006, DOI 10.1109/ICCV48922.2021.01181
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Xin XM, 2019, IEEE IMAGE PROC, P2631, DOI [10.1109/icip.2019.8803290, 10.1109/ICIP.2019.8803290]
   Xin XM, 2019, PATTERN RECOGN, V88, P285, DOI 10.1016/j.patcog.2018.11.025
   Yang FX, 2021, PROC CVPR IEEE, P4853, DOI 10.1109/CVPR46437.2021.00482
   Yang QZ, 2019, IEEE INT CON MULTI, P1096, DOI 10.1109/ICME.2019.00192
   Yang XL, 2023, IEEE T KNOWL DATA EN, V35, P8934, DOI 10.1109/TKDE.2022.3220219
   Yang X, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3089249
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang AG, 2021, PROC CVPR IEEE, P598, DOI 10.1109/CVPR46437.2021.00066
   Zhang H., 2018, PROF 6 INT C LEARN R, P1
   Zhang L, 2021, IEEE T CIRC SYST VID, V31, P1490, DOI 10.1109/TCSVT.2020.3002956
   Zhang Z, 2021, PROC CVPR IEEE, P12131, DOI 10.1109/CVPR46437.2021.01196
   Zhao JJ, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P205, DOI 10.1109/ICCV48922.2021.00027
   Zhao JN, 2021, PROC CVPR IEEE, P2225, DOI 10.1109/CVPR46437.2021.00226
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhou SP, 2022, IEEE T NEUR NET LEAR, V33, P4826, DOI 10.1109/TNNLS.2021.3061164
   Zhou SP, 2019, IEEE I CONF COMP VIS, P8039, DOI 10.1109/ICCV.2019.00813
   Zhu H, 2022, MULTIMED TOOLS APPL, V81, P18671, DOI 10.1007/s11042-022-12581-0
   Zhu SD, 2021, MACH VISION APPL, V32, DOI 10.1007/s00138-021-01239-w
NR 70
TC 2
Z9 2
U1 2
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104790
DI 10.1016/j.imavis.2023.104790
EA AUG 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA R3SB3
UT WOS:001063571900001
DA 2024-07-18
ER

PT J
AU Ji, JY
   Pan, F
   Wang, XY
   Tang, JX
   Liu, ZA
   Pu, B
AF Ji, Jiayu
   Pan, Feng
   Wang, Xuanyin
   Tang, Jixiang
   Liu, Ze 'an
   Pu, Bin
TI An end-to-end anti-shaking multi-focus image fusion approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Depth -of -focus; Mis-registration; Deformable convolution
AB In this paper, an end-to-end multi-focus fusion network is proposed to solve the mis-registration problem of the captured images. This paper takes the shaking and camera breathing effects that usually exist when acquiring multiple partially focused images into account. The new network consists of a homography pre-correction module, a deformable convolutional fine-correction module, an attention based fusion module and a reconstruction module. The homography pre-correction module is proposed to achieve a coarse correction for multifocus images. The deformable convolution fine-correction module enables the fusion algorithm to achieve an effective fine alignment for small shaking in multi-focus images. The attention based fusion module and the image reconstruction module are proposed to achieve high definition fusion results. This paper produces a dedicated shaking dataset for training and testing. The algorithm's superior performance in depth-of-field extension and generalisation to different scenes can be seen through sufficient experiments on test datasets, real scenes and image sequences. The ablation experiments also demonstrate the necessity of each module in the algorithm.
C1 [Ji, Jiayu; Wang, Xuanyin; Tang, Jixiang; Liu, Ze 'an; Pu, Bin] Zhejiang Univ, Hangzhou 310058, Peoples R China.
   [Pan, Feng] Zhejiang Sunny Opt Intelligence Technol Co Ltd, Hangzhou 310052, Peoples R China.
C3 Zhejiang University
RP Wang, XY (corresponding author), Zhejiang Univ, Hangzhou 310058, Peoples R China.
EM 11625039@zju.edu.cn; 13760173@qq.com; xywang@zju.edu.cn;
   tangjx@zju.edu.cn; 12025014@zju.edu.cn; binpu@zju.edu.cn
FU National Natural Science Foundation of China [52075483]
FX This project is supported by National Natural Science Foundation of
   China (Grant No. 52075483) .
CR Amin-Naji M, 2019, INFORM FUSION, V51, P201, DOI 10.1016/j.inffus.2019.02.003
   [Anonymous], 2003, THRITY 7 ASILOMAR C
   Chen J, 2022, IEEE T MULTIMEDIA, V24, P655, DOI 10.1109/TMM.2021.3057493
   Eskicioglu AM, 1995, IEEE T COMMUN, V43, P2959, DOI 10.1109/26.477498
   Jiang Q, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2022.3169571
   Liang YX, 2019, SIGNAL PROCESS, V161, P111, DOI 10.1016/j.sigpro.2019.03.020
   Liu SQ, 2022, FRONT NEUROROBOTICS, V16, DOI 10.3389/fnbot.2022.1024742
   Liu SQ, 2022, SIGNAL PROCESS-IMAGE, V100, DOI 10.1016/j.image.2021.116533
   Liu Y, 2022, INFORM FUSION, V86-87, P1, DOI 10.1016/j.inffus.2022.06.001
   Liu Y, 2020, INFORM FUSION, V64, P71, DOI 10.1016/j.inffus.2020.06.013
   Liu Y, 2017, INFORM FUSION, V36, P191, DOI 10.1016/j.inffus.2016.12.001
   Liu Y, 2015, INFORM FUSION, V23, P139, DOI 10.1016/j.inffus.2014.05.004
   Ma BY, 2021, NEURAL COMPUT APPL, V33, P5793, DOI 10.1007/s00521-020-05358-9
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Mustafa HT, 2019, IMAGE VISION COMPUT, V85, P26, DOI 10.1016/j.imavis.2019.03.001
   Rajalingam B., 2018, Hybrid multimodality medical image fusion technique for feature enhancement in medical diagnosis
   Suwajanakorn S, 2015, PROC CVPR IEEE, P3497, DOI 10.1109/CVPR.2015.7298972
   Tang H., 2018, Inf. Sci.
   Nguyen T, 2018, IEEE ROBOT AUTOM LET, V3, P2346, DOI 10.1109/LRA.2018.2809549
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wang XT, 2019, IEEE COMPUT SOC CONF, P1954, DOI 10.1109/CVPRW.2019.00247
   Wang XT, 2018, PROC CVPR IEEE, P606, DOI 10.1109/CVPR.2018.00070
   Wang Z., 2023, International Journal of Computer Vision, P1
   Wang ZY, 2022, IEEE T IMAGE PROCESS, V31, P4527, DOI 10.1109/TIP.2022.3184250
   Xiaopeng Rencan, Fully convolutional network-based multifocus image fusion
   Xu H, 2022, IEEE T PATTERN ANAL, V44, P502, DOI 10.1109/TPAMI.2020.3012548
   Zang YS, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2021.3072124
   Zhang Y, 2020, INFORM FUSION, V54, P99, DOI 10.1016/j.inffus.2019.07.011
   Zhao H, 2008, IMAGE VISION COMPUT, V26, P1285, DOI 10.1016/j.imavis.2008.03.007
   Zhao W., 2018, IEEE Trans. Circuits Syst. Video Technol., P1
   Zhou Z, 2014, INFORM FUSION, V20, P60, DOI 10.1016/j.inffus.2013.11.005
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
NR 33
TC 1
Z9 1
U1 8
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104788
DI 10.1016/j.imavis.2023.104788
EA AUG 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FU4Q1
UT WOS:001148359300001
DA 2024-07-18
ER

PT J
AU Shabbir, N
   Rout, RK
AF Shabbir, Nazir
   Rout, Ranjeet Kumar
TI FgbCNN: A unified bilinear architecture for learning a fine-grained
   feature representation in facial expression recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fine-grained; Facial expression; Convolutional neural networks; Bi
   -linear pooling; Fine tuning; Matrix normalization
AB A facial expression recognition system has been proposed in this paper. The challenges of the facial expression recognition system lie due to low intra-class variance within a class of negative emotions, such as anger, disgust, and fear. A conventional Convolution Neural Network (CNN) model may extract discriminative features and has shown outstanding performance in various computer vision tasks. However, it is unable to extract the secondorder feature information that demonstrates the interaction between features in the image of wildenvironment datasets. This paper presents a novel method to solve the facial expression recognition problem by addressing several limitations concerning emotion recognition problems. A deep learning-based bilinear convolutional neural network framework has been proposed, termed an Fine-Grained Bilinear CNN (FgbCNN) model that consists of two branches with optimized CNN along with a normalization layer composed of batchnormalization, square-root normalization, L2-normalization, and drop-out layers. Here, local and holistic features have been aggregated using a dot-product layer to extract more discriminant features. Finally, experimenting with two wild-environments (SFEW 1.0 and SFEW 2.0) and two lab-controlled datasets (KDEF and CK+), it has been observed that the proposed model can minimize the intra-class variances and has attained outstanding performance compared to other state-of-the-art methods.
C1 [Shabbir, Nazir; Rout, Ranjeet Kumar] Natl Inst Technol Srinagar, Dept Comp Sci & Engn, Hazratbal, J&K, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Srinagar
RP Rout, RK (corresponding author), Natl Inst Technol Srinagar, Dept Comp Sci & Engn, Hazratbal, J&K, India.
EM nazirshabbir89@gmail.com; ranjeetkumarrout@nitsri.net
RI Rout, Ranjeet kumar/AAT-3763-2020
CR Barra P, 2023, MULTIMED TOOLS APPL, V82, P11321, DOI 10.1007/s11042-022-13361-6
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Berthelot D., 2020, Remixmatch: Semi-supervised learning with distribution matching and augmentation anchoring
   Berthelot D, 2019, ADV NEUR IN, V32
   Biele Cezary, 2022, HUMAN MOVEMENTS HUMA, V996
   Bisogni C, 2022, IEEE T IND INFORM, V18, P5619, DOI 10.1109/TII.2022.3141400
   Calvo MG, 2008, BEHAV RES METHODS, V40, P109, DOI 10.3758/BRM.40.1.109
   Cao CS, 2015, IEEE I CONF COMP VIS, P2956, DOI 10.1109/ICCV.2015.338
   Dhall A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Dhall A, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P423, DOI 10.1145/2818346.2829994
   Dhall A, 2013, ICMI'13: PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P509, DOI 10.1145/2522848.2531739
   Ding H., 2013, 2013 10th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   EKMAN P, 1971, J PERS SOC PSYCHOL, V17, P124, DOI 10.1037/h0030377
   Fei Zixiang, 2019, 2019 25 INT C AUTOMA, P1
   Gao Y, 2016, PROC CVPR IEEE, P317, DOI 10.1109/CVPR.2016.41
   Gu WF, 2012, PATTERN RECOGN, V45, P80, DOI 10.1016/j.patcog.2011.05.006
   Gutta S, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P194, DOI 10.1109/AFGR.1998.670948
   Hossain S, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11199174
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Jaimes A, 2007, COMPUT VIS IMAGE UND, V108, P116, DOI 10.1016/j.cviu.2006.10.019
   Jayalekshmi J, 2017, 2017 INTERNATIONAL CONFERENCE ON NETWORKS & ADVANCES IN COMPUTATIONAL TECHNOLOGIES (NETACT), P1, DOI 10.1109/NETACT.2017.8076732
   Jiabei Zeng, 2018, Computer Vision - ECCV 2018. 15th European Conference. Proceedings: Lecture Notes in Computer Science (LNCS 11217), P227, DOI 10.1007/978-3-030-01261-8_14
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Li S., 2020, IEEE T AFFECT COMPUT
   Li S, 2018, INT C PATT RECOG, P3092, DOI 10.1109/ICPR.2018.8545284
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu MY, 2013, IEEE INT CONF AUTOMA
   Liu NA, 2018, PROC CVPR IEEE, P3089, DOI 10.1109/CVPR.2018.00326
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Otberdout N, 2022, IEEE T PATTERN ANAL, V44, P848, DOI 10.1109/TPAMI.2020.3002500
   Liang PP, 2018, Arxiv, DOI arXiv:1808.03920
   Rao QY, 2015, INT CONF AFFECT, P630, DOI 10.1109/ACII.2015.7344635
   RHODES G, 1988, PERCEPTION, V17, P43, DOI 10.1068/p170043
   Rose N, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P346
   Rosenberg Erika L., 2020, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Ruan DL, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P2833, DOI 10.1145/3394171.3413907
   Saxena S, 2016, ADV NEUR IN, V29
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Siqueira H, 2020, AAAI CONF ARTIF INTE, V34, P5800
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Umer S, 2022, J AMB INTEL HUM COMP, V13, P721, DOI 10.1007/s12652-020-02845-8
   Umer S, 2020, NEURAL NETWORKS, V122, P407, DOI 10.1016/j.neunet.2019.11.009
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vo TH, 2020, IEEE ACCESS, V8, P131988, DOI 10.1109/ACCESS.2020.3010018
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wei XS, 2016, Arxiv, DOI arXiv:1605.06878
   Xiao TJ, 2015, PROC CVPR IEEE, P842, DOI 10.1109/CVPR.2015.7298685
   Xie Q., 2020, ADV NEURAL INFORM PR, V33, P6256, DOI DOI 10.48550/ARXIV.1904.12848
   Yang HY, 2018, PROC CVPR IEEE, P2168, DOI 10.1109/CVPR.2018.00231
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Zavarez MV, 2017, SIBGRAPI, P405, DOI 10.1109/SIBGRAPI.2017.60
   Zhang B., 2021, Proc. Adv. Neural Inf. Process. Syst., P18408
   Zhang HF, 2021, IEEE T COGN DEV SYST, V13, P898, DOI 10.1109/TCDS.2020.3034807
   Zhang N, 2014, LECT NOTES COMPUT SC, V8689, P834, DOI 10.1007/978-3-319-10590-1_54
   Zhang YL, 2018, PROC CVPR IEEE, P2472, DOI 10.1109/CVPR.2018.00262
   Zhang ZP, 2018, INT J COMPUT VISION, V126, P550, DOI 10.1007/s11263-017-1055-1
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhou HS, 2019, ICMI'19: PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P562, DOI 10.1145/3340555.3355713
NR 66
TC 2
Z9 2
U1 3
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104770
DI 10.1016/j.imavis.2023.104770
EA JUL 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P2GX9
UT WOS:001048887200001
DA 2024-07-18
ER

PT J
AU Sirenden, BH
   Mursanto, P
   Wijonarko, S
AF Sirenden, Bernadus Herdi
   Mursanto, Petrus
   Wijonarko, Sensus
TI Dynamic texture analysis using Temporal Gray scale Pattern Image for
   water surface velocity measurement
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Water surface velocity; Image based measurement; Dynamic texture
   analysis; Temporal gray-scale pattern image
ID EFFICIENT
AB Water surface velocity (WSV) is one of the critical parameters in hydrology. The development of non-intrusive measurement of this parameter using cameras is increasing. Traditionally, measuring WSV using a camera utilizes tracking of moving objects on the water surfaces. Recently, another method has emerged that utilizes the movement of water ripples to estimate the WSV. This paper proposes a novel method for estimating WSV based on camera measurements. The authors call this method Temporal Gray-scale Pattern Image (TGPI) since it extracts Gray-scale patterns of pixels of water flow video in the temporal domain using the XOR operator and create new image. The new image pattern formed is then used to predict WSV using predictor. There are four predictors being compared, namely Multiple Input Linear Regression (MILR), Multiple Input Logistic Regression (MILgR), Convolutional Neural Network Regression (CNN-R), and Convolutional Neural Network Classification (CNN-K). CNN-R and CNN-K predict WSV directly from the results of TGPI. Meanwhile, MILR and MILgR predict WSV from five TGPI features. The five features are the Mean and Median of the Histogram, Mean and Median of the Histogram of Oriented Gradient (HOG), and the Maximum Mid-Value of the Fast Fourier Transform (FFT). MILR and CNN-R are predictors for regression problems, so the testing metrics for them are Trend-Line equation and R2 from the predicted WSV and actual values graph. Meanwhile, for MILgR and CNN-K, which are predictors for classification problems, the testing metrics are Confusion Matrix (CM), Accuracy, Precision, Recall, and F1-Score. To test the four methods without distinguishing their predictor types, a 2-dimensional histogram graph is used. The data-set used for training and testing is video footage of water flow with known WSV. The WSV measurement points used in this study are 1.7 m/s, 3.1 m/s, and 4.2 m/s. The video dataset and these three points are generated by the Mini Open Channel Water Flow Simulator (MOCWFS) developed by the author in this study. From the comparison results, it can be seen that the classification type predictor is superior to the regression type. For the regression type predictor, MILR is better than CNN-R. Meanwhile, for the classification type, CNN-K is superior to MILgR. The best accuracy produced by CNN-K is 98.4%. Although there are shortcomings, the TGPI method is quite feasible for predict Water Surface Velocity.
C1 [Sirenden, Bernadus Herdi; Mursanto, Petrus] Univ Indonesia, Fac Comp Sci, Depok, Indonesia.
   [Sirenden, Bernadus Herdi] Natl Res & Innovat Agcy BRIN, Res Ctr Elect, Jakarta, Indonesia.
   [Wijonarko, Sensus] Natl Res & Innovat Agcy BRIN, Res Ctr Photon, Jakarta, Indonesia.
C3 University of Indonesia; National Research & Innovation Agency of
   Indonesia (BRIN); National Research & Innovation Agency of Indonesia
   (BRIN)
RP Mursanto, P (corresponding author), Univ Indonesia, Fac Comp Sci, Depok, Indonesia.
EM santo@cs.ui.ac.id
OI Wijonarko, Sensus/0000-0003-1869-8737
FU "Degree By Research" Scholarship Program of 489 Indonesia National
   Research and Innovation Agency (BRIN)
FX The authors would like to thanks "Degree By Research" Scholarship
   Program of 489 Indonesia National Research and Innovation Agency (BRIN)
   for the support.
CR Argues SR, 2018, FLOW MEAS INSTRUM, V64, P213, DOI 10.1016/j.flowmeasinst.2018.10.022
   Bernd J., 1999, HDB COMPUTER VISION, V2
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Eltner A., 2021, Int. Arch. Photogramm. Remote Sens. Spat. Inf. Sci, VXLIII-B2-2021, P717, DOI DOI 10.5194/ISPRS-ARCHIVES-XLIII-B2-2021-717-2021
   Fujita I, 2019, ENVIRON FLUID MECH, V19, P1363, DOI 10.1007/s10652-018-9651-3
   Fujita I, 2017, WATER-SUI, V9, DOI 10.3390/w9040269
   Fujita I, 2007, INT J RIVER BASIN MA, V5, P105, DOI 10.1080/15715124.2007.9635310
   Fulton JW, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12081296
   Genç O, 2015, FLOW MEAS INSTRUM, V41, P115, DOI 10.1016/j.flowmeasinst.2014.10.013
   Gleason CJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12071107
   Han XL, 2021, FRONT EARTH SC-SWITZ, V9, DOI 10.3389/feart.2021.686636
   Hodges B, 2019, HYDROL EARTH SYST SC, V23, P1281, DOI 10.5194/hess-23-1281-2019
   Juefei-Xu F, 2017, PROC CVPR IEEE, P4284, DOI 10.1109/CVPR.2017.456
   Legleiter CJ, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12081282
   Livoroi AH, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11157027
   Naves J, 2021, HYDROL EARTH SYST SC, V25, P885, DOI 10.5194/hess-25-885-2021
   Pearce S, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12020232
   Rozos E, 2020, HYDROLOGY-BASEL, V7, DOI 10.3390/hydrology7030065
   Shivashankar S., 2018, International Journal of Image, Graphics and Signal Processing, V10, P56, DOI 10.5815/ijigsp.2018.09.07
   Shivashankar S., 2018, INT J APPL ENG RES, V13, P13460
   Sima J., 2018, INT J NEW TECHNOL RE, V4
   Sirenden BH, 2023, MULTIMED TOOLS APPL, V82, P12167, DOI 10.1007/s11042-022-13627-z
   Sirenden BH, 2020, 2020 INTERNATIONAL CONFERENCE ON RADAR, ANTENNA, MICROWAVE, ELECTRONICS, AND TELECOMMUNICATIONS (ICRAMET), P51, DOI [10.1109/icramet51080.2020.9298601, 10.1109/ICRAMET51080.2020.9298601]
   Strelnikova D, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12030384
   Tauro F, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10122010
   Trieu H, 2021, WATER-SUI, V13, DOI 10.3390/w13121675
   Tsubaki R, 2017, WATER RESOUR RES, V53, P10908, DOI 10.1002/2017WR021913
   Tsuji I, 2018, E3S WEB CONF, V40, DOI 10.1051/e3sconf/20184006011
   Watanabe K, 2021, WATER-SUI, V13, DOI 10.3390/w13152079
   Wei XP, 2019, EUR J REMOTE SENS, V52, P448, DOI 10.1080/22797254.2019.1634980
   Wu H, 2019, WATER-SUI, V11, DOI 10.3390/w11112320
   Yunqian Ma, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P38, DOI 10.1109/CVPR.2009.5204204
   Zhao HY, 2021, FLOW MEAS INSTRUM, V77, DOI 10.1016/j.flowmeasinst.2020.101864
   Zhao XC, 2018, IEEE T MULTIMEDIA, V20, P552, DOI 10.1109/TMM.2017.2750415
NR 34
TC 0
Z9 0
U1 6
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104749
DI 10.1016/j.imavis.2023.104749
EA JUL 2023
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N9QN8
UT WOS:001040274400001
DA 2024-07-18
ER

PT J
AU Dwivedi, P
   Chakraborty, S
AF Dwivedi, Pulkit
   Chakraborty, Soumendu
TI Single image dehazing using extended local dark channel prior
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Single image dehazing; Image enhancement; Uniform transmission estimate;
   Dark channel prior; Channel-wise dark channel estimation
ID QUALITY ASSESSMENT; VISION; VISIBILITY
AB Image dehazing is an important technique aimed at eliminating the haze in the atmosphere to enhance the image's visual quality. There are many applications where it has been used as a prepossessing step, such as in event detection. In recent years, the dark channel prior methodology has been recognised as an effective approach for eliminating haze from hazy images. However, the main drawback of the existing dark channel prior methodology is that it only considers a single colour channel of the RGB image with pixels having minimum intensity values. This non-uniform selection of the dark channel from a single channel eradicates the effect of the transmission across the different channels of the hazy image. Hence, the haze cannot be removed to a great extent using the existing method. Thus, to address the problem of non-uniform estimation of the dark channel by the existing dark channel prior method, we propose an approach where the dark channel will be computed from all three channels of an image by selecting the minimum intensity. The main advantage of using the proposed prior-based methodology for image dehazing over deep neural network-based models such as CNN or GANs is that training deep models requires a large amount of training data, thus resulting in a longer training time. Experimental outcomes exhibit that the proposed technique outperforms state-of-the-art methods on synthetic datasets as well as real-world hazy images. The findings demonstrate that the proposed technique obtains better accuracy as compared to the state-of-the-art methods and recent deep learning-based models over the D-HAZY, IHAZE, O-HAZE and Middlebury databases.
C1 [Dwivedi, Pulkit; Chakraborty, Soumendu] Indian Inst Informat Technol, Dept Comp Sci, Lucknow, India.
RP Dwivedi, P (corresponding author), Indian Inst Informat Technol, Dept Comp Sci, Lucknow, India.
EM pdwivedi1990@gmail.com; soum.uit@gmail.com
CR Ancuti CO, 2018, IEEE COMPUT SOC CONF, P867, DOI 10.1109/CVPRW.2018.00119
   Ancuti CO, 2013, IEEE T IMAGE PROCESS, V22, P3271, DOI 10.1109/TIP.2013.2262284
   Ancuti C, 2016, IEEE IMAGE PROC, P2226, DOI 10.1109/ICIP.2016.7532754
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chakrabarti A., 2009, BRIT MACH VIS C, V1, P4
   CHAVEZ PS, 1988, REMOTE SENS ENVIRON, V24, P459, DOI 10.1016/0034-4257(88)90019-3
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen TY, 2021, IEEE COMPUT SOC CONF, P487, DOI 10.1109/CVPRW53098.2021.00060
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deniz E., 2018, COMPUTER VISION PATT
   Dong H, 2020, PROC CVPR IEEE, P2154, DOI 10.1109/CVPR42600.2020.00223
   Dudhane A., 2016, PROC EUROPEAN C COMP
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Fu MH, 2021, IEEE COMPUT SOC CONF, P203, DOI 10.1109/CVPRW53098.2021.00029
   Gao SH, 2021, IEEE T PATTERN ANAL, V43, P652, DOI 10.1109/TPAMI.2019.2938758
   Gao Y, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103868
   Garg K, 2007, INT J COMPUT VISION, V75, P3, DOI 10.1007/s11263-006-0028-6
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hore Alain, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2366, DOI 10.1109/ICPR.2010.579
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Ju MY, 2021, IEEE T IMAGE PROCESS, V30, P9043, DOI 10.1109/TIP.2021.3122088
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Li SY, 2021, INT J COMPUT VISION, V129, P1301, DOI 10.1007/s11263-020-01416-w
   Liu J, 2020, IEEE COMPUT SOC CONF, P1732, DOI 10.1109/CVPRW50498.2020.00223
   Liu W, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.10.001
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   McCartney J, 1976, Optics of the Atmosphere: Scattering by Molecules and Particles
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Mittal A, 2012, IEEE T IMAGE PROCESS, V21, P4695, DOI 10.1109/TIP.2012.2214050
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Ancuti CO, 2018, Arxiv, DOI arXiv:1804.05091
   Pierre F, 2017, J MATH IMAGING VIS, V57, P99, DOI 10.1007/s10851-016-0670-8
   Qasim M, 2022, IEEE ACCESS, V10, P120296, DOI 10.1109/ACCESS.2022.3221992
   Qin X, 2019, Arxiv, DOI arXiv:1911.07559
   Rahman Ziaur, 2019, International Journal of Computers and Applications, V41, P207, DOI 10.1080/1206212X.2017.1422358
   Rahman Z, 2020, IEEE ACCESS, V8, P109038, DOI 10.1109/ACCESS.2020.3001206
   Rahman Z, 2021, VISUAL COMPUT, V37, P865, DOI 10.1007/s00371-020-01838-0
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Santra S, 2018, IEEE T IMAGE PROCESS, V27, P4598, DOI 10.1109/TIP.2018.2841198
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Sharma T, 2020, IEEE TETCI
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wu HY, 2020, IEEE COMPUT SOC CONF, P1975, DOI 10.1109/CVPRW50498.2020.00247
   Ying ZQ, 2017, Arxiv, DOI arXiv:1711.00591
   Zhang H, 2018, PROC CVPR IEEE, P3194, DOI 10.1109/CVPR.2018.00337
   Zhang YF, 2020, IEEE T CIRC SYST VID, V30, P3544, DOI 10.1109/TCSVT.2019.2939853
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 54
TC 5
Z9 5
U1 10
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104747
DI 10.1016/j.imavis.2023.104747
EA JUL 2023
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA N4NY4
UT WOS:001036810700001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Dou, ZW
   Ye, D
   Wang, BY
AF Dou, Ziwen
   Ye, Dong
   Wang, Boya
TI AutoSegEdge: Searching for the edge device real-time semantic
   segmentation based on multi-task learning
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Semantic segmentation; Multi -task -learning; Hardware -aware neural
   architecture search; Edge; Real-time
AB Real-time semantic segmentation is a challenging task for resource-constrained edge devices. We propose AutoSegEdge, based on Neural Architecture Search (NAS), a semantic segmentation approach that runs on edge devices in real-time. Besides accuracy, we employ FLOPs and latency on the target edge devices as search constraints. Our work is probably one of the first attempts to translate multi-objectives NAS into Multi-Task Learning. Be inspired by Multi-Task Learning, we regard the sub-objective in multi-objective NAS as a learning task in Multi-Task Learning. The total loss function of the multi-objective NAS is deconstructed into the weighted sum of the sub-objective loss function. However, the conflict among the sub-objective will cause the searched networks to "architecture collapse." To avoid the multi-objectives NAS falls into "architecture collapse." Based on uncertainty, this paper proposes a method to learn the weights of sub-objective loss functions automatically. AutoSegEdge was discovered from an efficient cell-level search space that integrates multi-resolution branches. Additionally, AutoSegEdge employs knowledge distillation to further boost accuracy. Finally, we accelerated AutoSegEdge using NVIDIA's TensorRT and deployed it on the Nvidia Jetson NX. Experiments demonstrate that multi-objectives NAS only requires 1.5 GPU days to obtain the best result on a single Nvidia Tesla V100 GPU. On the Cityscapes dataset, AutoSegEdge achieved an mIoU of 70.3% with 16.6 FPS on the Nvidia Jetson NX (and 194.54 FPS on an Nvidia Tesla V100 GPU) at the original resolution (1024 x 2048) using TensorRT. Our method is 2-3x faster than existing state-of-the-art real-time methods while maintaining competitive accuracy. We also conducted robustness experiments to analyze our method and modules. The code is available: https://github.com/douziwenhit/AutoSeg_edge.git. & COPY; 2023 Published by Elsevier B.V.
C1 [Dou, Ziwen; Ye, Dong; Wang, Boya] Harbin Inst Technol, Sch Instrumentat Sci & Engn, Harbin 150001, Peoples R China.
C3 Harbin Institute of Technology
RP Ye, D (corresponding author), Harbin Inst Technol, Sch Instrumentat Sci & Engn, Harbin 150001, Peoples R China.
EM 20B901041@stu.hit.edu.cn; 19B901034@stu.hit.edu.cn
CR Bender G, 2018, PR MACH LEARN RES, V80
   Brock A, 2017, Arxiv, DOI arXiv:1708.05344
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chen WY, 2020, Arxiv, DOI arXiv:1912.10917
   Chen WY, 2019, PROC CVPR IEEE, P8916, DOI 10.1109/CVPR.2019.00913
   Cheng ACE, 2020, AAAI CONF ARTIF INTE, V34, P3577
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Dai X., P IEEE CVF C COMP VI, P11398
   Dai X, 2020, ARXIV
   Ding MY, 2021, PROC CVPR IEEE, P2981, DOI 10.1109/CVPR46437.2021.00300
   Fang Q, 2020, CHIN AUTOM CONGR, P2587, DOI 10.1109/CAC51589.2020.9327332
   Fu Y., 2023, AUTOGAN DISTILLER SE
   Howard AG, 2017, Arxiv, DOI arXiv:1704.04861
   Gong XY, 2019, IEEE I CONF COMP VIS, P3223, DOI 10.1109/ICCV.2019.00332
   Guo YW, 2016, Arxiv, DOI arXiv:1608.04493
   Hao SJ, 2020, NEUROCOMPUTING, V406, P302, DOI 10.1016/j.neucom.2019.11.118
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He T, 2019, PROC CVPR IEEE, P578, DOI 10.1109/CVPR.2019.00067
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Li G, 2019, Arxiv, DOI arXiv:1907.11357
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li X, 2019, PROC CVPR IEEE, P9137, DOI 10.1109/CVPR.2019.00936
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu HX, 2019, Arxiv, DOI [arXiv:1806.09055, DOI 10.48550/ARXIV.1806.09055]
   Liu HT, 2021, IEEE INT CONF ROBOT, P9579, DOI 10.1109/ICRA48506.2021.9561858
   Liu RP, 2023, Arxiv, DOI arXiv:2202.13393
   Liu Y, 2023, STRUCTURED KNOWLEDGE
   Liu Y, 2021, Arxiv, DOI [arXiv:2101.06175, DOI 10.48550/ARXIV.2101.06175]
   Loni M, 2022, DES AUT TEST EUROPE, P1115, DOI 10.23919/DATE54114.2022.9774615
   Loni M, 2022, IEEE T SYST MAN CY-S, V52, P5222, DOI 10.1109/TSMC.2021.3123136
   Loni M, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2020.102989
   Lu Y.-H., 2023, LOW POWER COMPUTER V
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mehta S., P IEEE CVF C COMP VI, P9190
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Nekrasov V., 2023, FAST NEURAL ARCHITEC
   Nvidia tensorrt, 2020, US
   Poudel R. P. K., 2019, arXiv
   Ronneberger O., 2015, PATTERN RECOGN, V2015, p1505.04597, DOI 10.1007/978-3-319-24574-4_28
   Safavi F, 2023, arXiv
   Safavi F, 2021, IEEE INT CONF BIG DA, P4199, DOI 10.1109/BigData52589.2021.9671314
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tan MX, 2021, PR MACH LEARN RES, V139, P7102
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Wan Alvin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12962, DOI 10.1109/CVPR42600.2020.01298
   Wan Q, 2023, INT C LEARNING REPRE
   Wang J., 2023, IEEE T PATTERN ANAL
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xiao CJ, 2022, IMAGE VISION COMPUT, V123, DOI 10.1016/j.imavis.2022.104470
   Xie E., 2023, SEGFORMER SIMPLE EFF
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zhang J., 2023, TRANS4TRANS EFFICIEN
   Zhang WW, 2021, NEUROCOMPUTING, V428, P65, DOI 10.1016/j.neucom.2020.11.024
   Zhang X, P MACHINE LEARNING S, P216
   Zhang X, 2021, PROC CVPR IEEE, P13951, DOI 10.1109/CVPR46437.2021.01374
   Zhang Y., P IEEE CVF C COMP VI, P11641
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zoljodi A, 2022, LECT NOTES COMPUT SC, V13529, P404, DOI 10.1007/978-3-031-15919-0_34
   Zoph B, 2017, Arxiv, DOI [arXiv:1611.01578, DOI 10.48550/ARXIV.1611.01578]
NR 65
TC 2
Z9 2
U1 6
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2023
VL 136
AR 104719
DI 10.1016/j.imavis.2023.104719
EA JUN 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA M4CK9
UT WOS:001029689100001
DA 2024-07-18
ER

PT J
AU Wang, X
   He, N
   Hong, C
   Wang, Q
   Chen, M
AF Wang, Xin
   He, Ning
   Hong, Chen
   Wang, Qi
   Chen, Ming
TI Improved YOLOX-X based UAV aerial photography object detection algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE UAV aerial photography; Object detection; YOLOX; Small objects
ID NETWORK
AB Unmanned Aerial Vehicle (UAV) aerial photography object detection has high research significance in the fields of disaster rescue, ecological environmental protection, and military reconnaissance. The larger width of UAV photography introduces background interference into the detection task, whereas the relatively high imaging height of the UAV results in mostly small objects in the aerial images. YOLOX-X operated fast and achieved ad-vanced results on MS COCO of natural scene images, so YOLOX-X was used as the baseline network in this paper. A UAV aerial photography object detection algorithm YOLOX_w with improved YOLOX-X is proposed to handle the characteristics of complex backgrounds and the large number of small objects in UAV aerial photog-raphy images. The model's performance in detecting small objects is first improved by preprocessing the training set with the slicing aided hyper inference (SAHI) algorithm and by data augmentation. Then, a shallow feature map with rich spatial information is introduced into the path aggregation network (PAN), and a detection head is added to detect small objects. Next, the ultra-lightweight subspace attention module (ULSAM) is added to the PAN stage to highlight the target features and weaken the background features, which improves the detection accuracy of the network. Finally, the loss function of the bounding box regression is optimized to further improve network prediction accuracy. Experimental results on the VisDrone dataset demonstrate that the detection accuracy of the proposed YOLOX_w algorithm improved by 8% when compared with the baseline YOLOX-X. Moreover, migration experiments on the DIOR dataset verify the effectiveness and robustness of the improved method.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Wang, Xin; He, Ning] Beijing Union Univ, Coll Smart City, Beijing 100101, Peoples R China.
   [Hong, Chen; Wang, Qi; Chen, Ming] Beijing Union Univ, Coll Robot, Beijing 100101, Peoples R China.
C3 Beijing Union University; Beijing Union University
RP He, N (corresponding author), Beijing Union Univ, Coll Smart City, Beijing 100101, Peoples R China.
EM wang_xin_nihao@163.com; xxthening@buu.edu.cn; hchchina@sina.com;
   wangqi981124@163.com; 53192877@qq.com
RI Hong, Chen/HZH-3706-2023; Wang, Qi/AAF-1252-2020
OI Wang, Qi/0000-0002-1328-8571
FU National Natural Science Foundation of China [62272049, 61972375,
   62172045]; Key Project of Beijing Municipal Commission of Education
   [KZ201911417048]; National Key Ramp;D Program of China [2018AAA0100804];
   Premium Funding Project for Academic Human Resources Development in
   Beijing Union University [BPHR2020AZ01, BPH2020EZ01]; Science and
   Technology Project of Beijing Municipal Commission of Education
   [KM202111417009, KM201811417005]
FX This work is supported by the National Natural Science Foundation of
   China (62272049, 61972375, 62172045) , the Key Project of Beijing
   Municipal Commission of Education (KZ201911417048) , the National Key
   R&D Program of China (No. 2018AAA0100804) , Premium Funding Project for
   Academic Human Resources Development in Beijing Union University
   (BPHR2020AZ01, BPH2020EZ01) , the Science and Technology Project of
   Beijing Municipal Commission of Education (KM202111417009,
   KM201811417005) .
CR Ajmal A., 2018 INT C IM VIS CO, P1
   Akyon FC, 2022, Arxiv, DOI [arXiv:2202.06934, DOI 10.48550/ARXIV.2202.06934, 10.48550/arXiv.2202.06934, 10.48550/arxiv.2202.06934arXiv.org, DOI 10.48550/ARXIV.2202.06934ARXIV.ORG]
   Albaba BM, 2021, INT C PATT RECOG, P10227, DOI 10.1109/ICPR48806.2021.9412847
   Bai Y., P EUR C COMP VIS ECC, P206
   Bochkovskiy A, 2020, Arxiv, DOI arXiv:2004.10934
   Chaoxu Guo, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12592, DOI 10.1109/CVPR42600.2020.01261
   CHARBONNIER P, 1994, IEEE IMAGE PROC, P168
   Chen CR, 2019, IEEE INT CONF COMP V, P100, DOI 10.1109/ICCVW.2019.00018
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Deng CF, 2022, IEEE T MULTIMEDIA, V24, P1968, DOI 10.1109/TMM.2021.3074273
   DeVries T, 2017, Arxiv, DOI [arXiv:1708.04552, DOI 10.48550/ARXIV.1708.04552]
   Du DW, 2019, IEEE INT CONF COMP V, P213, DOI 10.1109/ICCVW.2019.00030
   Fu C.-Y., 2017, arXiv
   Ge Z, 2021, Arxiv, DOI arXiv:2107.08430
   Gevorgyan Z, 2022, Arxiv, DOI [arXiv:2205.12740, 10.48550/arXiv.2205.12740]
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE T PATTERN ANAL, V37, P1904, DOI 10.1109/TPAMI.2015.2389824
   Hong MB, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3103069
   Huang T. S., 2016, P 24 ACM INT C MULT, P516, DOI 10.1145/2964284.2967274
   Jiang B., 2021, Acta Aeronaut. Astronaut. Sin, V42, P137
   Jocher G., 2023, YOLOv8 by ultralytics
   Jocher G., 2020, Yolov5 by ultralytics
   Kisantal M, 2019, Arxiv, DOI arXiv:1902.07296
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li ZX, 2024, Arxiv, DOI arXiv:1712.00960
   Lim JS, 2021, 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (IEEE ICAIIC 2021), P181, DOI 10.1109/ICAIIC51459.2021.9415217
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu Y, 2024, Arxiv, DOI [arXiv:2111.11057, 10.48550/arXiv.2111.11057]
   Pang JM, 2019, IEEE T GEOSCI REMOTE, V57, P5512, DOI 10.1109/TGRS.2019.2899955
   Rabbi J, 2020, REMOTE SENS-BASEL, V12, DOI 10.3390/rs12091432
   Redmon J., P IEEE C COMPUTER VI, P7263
   Redmon J., 2018, arXiv, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saini R., P IEEE CVF WINT C AP, P1627
   Samyal A.S., 2022, ARXIV
   Tian GY, 2021, NEUROCOMPUTING, V443, P292, DOI 10.1016/j.neucom.2021.03.016
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Van Etten A, 2018, Arxiv, DOI [arXiv:1805.09512, 10.48550/arXiv.1805.09512]
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang CY, 2020, IEEE COMPUT SOC CONF, P1571, DOI 10.1109/CVPRW50498.2020.00203
   Wang X., P EUR C COMP VIS ECC
   Yang C., P IEEE CVF C COMP VI, P13668
   Yang X, 2021, PR MACH LEARN RES, V139
   Yang X, 2019, IEEE I CONF COMP VIS, P8231, DOI 10.1109/ICCV.2019.00832
   Yang Xue, 2021, ADV NEURAL INFORM PR, V34
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yuanzhu Liu, 2020, ICIT 2020: Proceedings of the 8th International Conference on Information Technology: IoT and Smart City, P125, DOI 10.1145/3446999.3447023
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang HY, 2018, Arxiv, DOI [arXiv:1710.09412, DOI 10.48550/ARXIV.1710.09412]
   Zhang X., P IEEE CVF INT C COM, P0
   Zoph Barret, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12372), P566, DOI 10.1007/978-3-030-58583-9_34
NR 59
TC 11
Z9 12
U1 26
U2 88
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104697
DI 10.1016/j.imavis.2023.104697
EA MAY 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA J7QN5
UT WOS:001011531900001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Amin, J
   Anjum, MA
   Ibrar, K
   Sharif, M
   Kadry, S
   Crespo, RG
AF Amin, Javaria
   Anjum, Muhammad Almas
   Ibrar, Kainat
   Sharif, Muhammad
   Kadry, Seifedine
   Crespo, Ruben Gonzalez
TI Detection of anomaly in surveillance videos using quantum convolutional
   neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Anomalous; UNI-crime; Videos; Surveillance; Robbery; Quantum
ID EVENT DETECTION; FRAMEWORK; RECOGNITION
AB Anomalous behavior identification is the process of detecting behavior that differs from its normal. These inci-dents will vary from violence to war, road crashes to kidnapping, and so on in a surveillance model. Video anom-aly detection from video surveillance is a difficult research activity due to the frequency of anomalous cases. Since certain devices need manual evaluation for the detection of violent or criminal situations at the same time video monitoring of security cameras is also a challenging task and is unreliable. When the data or model dimension is sufficiently large, convolutional neural networks have the limitation of learning inefficiently. Quantum Convolutional Neural Network (QCNN) is the name given to a technology that combines CNN and quantum com-puting. Quantum computation and CNN are combined to create a more efficient and outperforming solution for solving complicated machine-learning problems. To analyze the anomalies in a sequence of video frames, two models are proposed in this research. In this research 07 layers of Javeria deep convolutional neural network (DCNN) are proposed on the selected hyperparameters named J. DCNN which is also different from the existing models to analyze the abnormal behavior in a video segment. Furthermore, for a comprehensive analysis of the abnormal video frames a model is proposed which is the combination of Javeria quantum and convolutional neu-ral networks (J. QCNN). In this model 04-qubit quantum neural network is used with five layers and an optimal loss rate named J. QCNN. The proposed J. QCNN model is different from the existing deep learning architectures. The proposed models are trained from the scratch for the detection of anomalous from top challenging publicly available video surveillance datasets such as UNI-Crime and UCF Crime. The proposed J. QCNN model classifies the number of violent robberies such as armed thefts containing handguns or knives, and robberies displaying varying levels of viciousness with 0.99 accuracy while J. DCNN model gives 0.97 accuracy. The obtained results are superior in comparison with recent existing cutting-edge published work for real-time anomaly detection in video CCTV.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Amin, Javaria] Univ Wah, Dept Comp Sci, Wah Cantt, Pakistan.
   [Anjum, Muhammad Almas] Natl Univ Technol NUTECH, Islamabad, Pakistan.
   [Ibrar, Kainat] COMSATS Univ Islamabad, Dept Comp Sci, Islamabad, Pakistan.
   [Sharif, Muhammad] COMSATS Univ Islamabad, Dept Comp Sci, Wah Cantt, Pakistan.
   [Kadry, Seifedine] Noroff Univ Coll, Dept Appl Data Sci, Kristiansand, Norway.
   [Kadry, Seifedine] Ajman Univ, AIRC, Ajman 346, U Arab Emirates.
   [Kadry, Seifedine] Lebanese Amer Univ, Dept Elect & Comp Engn, Byblos, Lebanon.
   [Crespo, Ruben Gonzalez] Univ Int La Rioja, Dept Comp Sci, La Rioja, Spain.
C3 COMSATS University Islamabad (CUI); COMSATS University Islamabad (CUI);
   Ajman University; Lebanese American University; Universidad
   Internacional de La Rioja (UNIR)
RP Kadry, S (corresponding author), Noroff Univ Coll, Dept Appl Data Sci, Kristiansand, Norway.
EM Javeria.amin@uow.edu.pk; sharif@ciitwah.edu.pk;
   seifedine.kadry@noroff.no; ruben.gonzalez@unir.net
RI Kadry, Seifedine/C-7437-2011; Sharif, Muhammad/JPA-2267-2023; Gonzalez
   Crespo, Ruben/P-8601-2018; Sharif, Muhammad/ACD-2598-2022; AMIN,
   JAVARIA/IAQ-1843-2023
OI Kadry, Seifedine/0000-0002-1939-4842; Gonzalez Crespo,
   Ruben/0000-0001-5541-6319; Sharif, Muhammad/0000-0002-7258-8400; 
CR Adam A, 2008, IEEE T PATTERN ANAL, V30, P555, DOI 10.1109/TPAMI.2007.70825
   Adimoolam M., 2022, NOVEL TECHNIQUE DETE
   Amin J., 2022, INTELLIG DECIS TECHN, P1
   Amin J., 2022, MALARIA PARASITE DET
   Amin J, 2023, IEEE LAT AM T, V21, P557, DOI 10.1109/TLA.2023.10128927
   Amin J, 2022, KNOWL-BASED SYST, V249, DOI 10.1016/j.knosys.2022.108881
   Amin J, 2022, DIAGNOSTICS, V12, DOI 10.3390/diagnostics12040823
   Amin J, 2022, MICROSC RES TECHNIQ, V85, P1926, DOI 10.1002/jemt.24054
   Amin J, 2022, COGN COMPUT, V14, P1677, DOI 10.1007/s12559-021-09926-6
   Amin J, 2021, CMC-COMPUT MATER CON, V68, P2693, DOI 10.32604/cmc.2021.016871
   [Anonymous], 2006, Unusual crowd activity dataset of university of minnesota
   Anoopa S., 2022, MATER TODAY-PROC
   Baumgartner P., 2022, ARXIV
   Belhadi A, 2022, IEEE T INTELL TRANSP, V23, P9346, DOI 10.1109/TITS.2021.3114064
   Belhadi A, 2020, ACM TRANS MANAG INF, V11, DOI 10.1145/3399631
   Nievas EB, 2011, LECT NOTES COMPUT SC, V6855, P332, DOI 10.1007/978-3-642-23678-5_39
   Brito AD, 2021, J VIS COMMUN IMAGE R, V77, DOI 10.1016/j.jvcir.2021.103112
   Carletti M, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105730
   Chandrakala S, 2022, EXPERT SYST APPL, V190, DOI 10.1016/j.eswa.2021.116168
   Chen H., 2023, IMAGE VISION COMPUT, V131, P1
   Copiaco A, 2023, ENG APPL ARTIF INTEL, V119, DOI 10.1016/j.engappai.2022.105775
   Dhiman C, 2019, ENG APPL ARTIF INTEL, V77, P21, DOI 10.1016/j.engappai.2018.08.014
   Doshi K, 2020, IEEE COMPUT SOC CONF, P1025, DOI 10.1109/CVPRW50498.2020.00135
   Doshi K, 2020, IEEE COMPUT SOC CONF, P2658, DOI 10.1109/CVPRW50498.2020.00320
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Feng JC, 2021, PROC CVPR IEEE, P14004, DOI 10.1109/CVPR46437.2021.01379
   Goyal A, 2024, IEEE T COMPUT SOC SY, V11, P207, DOI 10.1109/TCSS.2022.3230262
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Henderson M, 2020, QUANT MACH INTELL, V2, DOI 10.1007/s42484-020-00012-y
   Hu XY, 2022, STRESS HEALTH, V38, P927, DOI 10.1002/smi.3146
   Joshi RC, 2019, INT J INTERACT MULTI, V5, P28, DOI 10.9781/ijimai.2019.01.001
   Koren O, 2023, ENG APPL ARTIF INTEL, V117, DOI 10.1016/j.engappai.2022.105503
   Li Q, 2022, KNOWL-BASED SYST, V252, DOI 10.1016/j.knosys.2022.109348
   Li S., 2022, P AAAI VIRT, V24
   Li SW, 2022, NEUROL SCI, V43, P4049, DOI [10.1007/s12274-022-5081-0, 10.1007/s10072-022-06024-9]
   Li WX, 2014, IEEE T PATTERN ANAL, V36, P18, DOI 10.1109/TPAMI.2013.111
   Liang YY, 2021, NEURAL NETWORKS, V143, P133, DOI 10.1016/j.neunet.2021.05.028
   Lin SH, 2019, 2019 16TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), DOI 10.1109/avss.2019.8909882
   Liu Y, 2022, INT CONF ACOUST SPEE, P2190, DOI 10.1109/ICASSP43922.2022.9746822
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Mahima K., 2020, ASIAN J CONVERG TECH, V6, P32
   Malik S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10183291
   Morales G., 2019, Artificial Intelligence Applications and Innovations, V559, P282, DOI DOI 10.1007/978-3-030-19823-7_23
   Mu HY, 2022, INFORM PROCESS MANAG, V59, DOI 10.1016/j.ipm.2022.102983
   Murugesan M, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103303
   Nandi A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207277
   Nasaruddin N, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00365-y
   Potempa Rafal, 2022, Progress in Image Processing, Pattern Recognition and Communication Systems: Proceedings of the Conference (CORES, IP&C, ACS). Lecture Notes in Networks and Systems (255), P61, DOI 10.1007/978-3-030-81523-3_6
   Ravichandran Akshaya, 2021, Applications of Artificial Intelligence and Machine Learning: Select Proceedings of ICAAAIML 2020. Lecture Notes in Electrical Engineering (778), P263, DOI 10.1007/978-981-16-3067-5_20
   Sharif M, 2020, NEURAL COMPUT APPL, V32, P15975, DOI 10.1007/s00521-019-04679-8
   Sharma Preeti, 2022, 2022 9th International Conference on Computing for Sustainable Global Development (INDIACom), P231, DOI 10.23919/INDIACom54597.2022.9763189
   Sikdar A, 2020, NEUROCOMPUTING, V415, P317, DOI 10.1016/j.neucom.2020.07.058
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun J, 2018, J SENSORS, V2018, DOI 10.1155/2018/8580959
   Thakare K. V., 2022, Expert Syst. Appl., V201
   Ul Amin S, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10091555
   Ullah W, 2022, FUTURE GENER COMP SY, V129, P286, DOI 10.1016/j.future.2021.10.033
   Ullah W, 2021, MULTIMED TOOLS APPL, V80, P16979, DOI 10.1007/s11042-020-09406-3
   Vrskova R, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22082946
   Wang L, 2023, PATTERN RECOGN, V138, DOI 10.1016/j.patcog.2023.109335
   Wang T, 2014, IEEE T INF FOREN SEC, V9, P988, DOI 10.1109/TIFS.2014.2315971
   Wang XH, 2018, IEEE T MULTIMEDIA, V20, P634, DOI 10.1109/TMM.2017.2749159
   Weng ZJ, 2021, Arxiv, DOI arXiv:2104.09760
   Xia X, 2022, NEUROCOMPUTING, V493, P497, DOI 10.1016/j.neucom.2021.12.093
   Xu LJ, 2023, ENTROPY-SWITZ, V25, DOI 10.3390/e25020180
   Yan S, 2023, ROBOT CIM-INT MANUF, V79, DOI 10.1016/j.rcim.2022.102441
   Yao Danfeng, 2017, Synthesis Lectures on Information Security, Privacy, and Trust, V9, P1
   Zafar M, 2023, MATHEMATICS-BASEL, V11, DOI 10.3390/math11020364
   Zaheer MZ, 2021, Arxiv, DOI arXiv:2104.14770
   Zaheer MZ, 2020, IEEE SIGNAL PROC LET, V27, P1705, DOI 10.1109/LSP.2020.3025688
   Zahid Y, 2020, IEEE ACCESS, V8, P220620, DOI 10.1109/ACCESS.2020.3042222
   Zeng XL, 2021, Arxiv, DOI arXiv:2112.04294
   Zhao YX, 2022, J SUPERCOMPUT, V78, P3940, DOI 10.1007/s11227-021-04007-9
   Zhong YH, 2022, PATTERN RECOGN, V122, DOI 10.1016/j.patcog.2021.108336
NR 75
TC 9
Z9 9
U1 6
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104710
DI 10.1016/j.imavis.2023.104710
EA MAY 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA J9ER8
UT WOS:001012589500001
DA 2024-07-18
ER

PT J
AU Hussain, A
   Li, HC
   Ali, D
   Ali, M
   Abbas, F
   Hussain, M
AF Hussain, Abid
   Li, Heng-Chao
   Ali, Danish
   Ali, Muqadar
   Abbas, Fakhar
   Hussain, Mehboob
TI An optimized deep supervised hashing model for fast image retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Knowledge distillation; Deep supervised hashing; Quantization; Network
   pruning; Image retrieval
ID NEURAL-NETWORK; FRAMEWORK
AB As multimedia data grows exponentially, searching for and retrieving a relevant image is becoming a challenge for researchers. Hashing is a widely adopted method because of its high performance in image retrieval with deep neural networks and multiple convolutional layers. Even so, most hashing methods ignore the computa-tional cost and memory storage consumption. When the deep hashing model size is large, it leads to a slowdown in the response time of the model compared to the small model. Addressing these issues, a novel optimized deep supervised hashing based on a teacher-student approach for swift and precise image retrieval is proposed in this paper. In this work, the small student model is trained using the knowledge distillation from the large teacher model and the information from the one-hot labels. Therefore, a weight allocation loss function based on the teacher and student models is defined. Meanwhile, we apply model pruning to decrease the amount of the student model further to increase the response time. Therefore, knowledge distillation is performed on the pruned model. After that, the remaining weights are quantized to reach the smaller size of the model. Extensive experimental outcomes on two widely used datasets prove the outstanding efficiency of our proposed method. (c) 2023 Elsevier B.V. All rights reserved.
C1 [Hussain, Abid; Li, Heng-Chao; Ali, Muqadar; Hussain, Mehboob] Southwest Jiao Tong Univ, Sch Informat & Comp Sci, Chengdu 611731, Peoples R China.
   [Ali, Danish] Dalian Univ Technol, Dept Math, Dalian, Peoples R China.
   [Abbas, Fakhar] Natl Univ Singapore, Ctr Trusted Internet & Community, Singapore, Singapore.
C3 Southwest Jiaotong University; Dalian University of Technology; National
   University of Singapore
RP Hussain, A; Li, HC (corresponding author), Southwest Jiao Tong Univ, Sch Informat & Comp Sci, Chengdu 611731, Peoples R China.
EM abidhussain@my.swjtu.edu.cn; hcli@home.swjtu.edu.cn
RI yang, li/JGM-1009-2023; wang, xi/JNT-5162-2023; wang,
   wang/JQW-3034-2023; xu, chen/JNE-5010-2023; Liu, qi/JZT-5038-2024; yang,
   peng/JEZ-8452-2023; wang, xiaoqiang/JMT-2783-2023; chen,
   xu/JNT-3068-2023; LI, YUN/JTV-7108-2023; li, xiang/JCN-9316-2023; zhang,
   chen/JES-0371-2023; zhang, xinyu/JKI-8403-2023; Abbas,
   Fakhar/AAD-5005-2019; wang, KiKi/JFZ-3334-2023; Li, Wei/JLL-4365-2023;
   zhang, hao/JOJ-7093-2023; xiao, wei/KCK-6954-2024; Liu,
   Jie/JCP-1070-2023; Zhang, Yun/JCN-7026-2023; Zhang, Wei/JKI-3565-2023;
   zhou, yang/JED-3951-2023; chen, gang/JRX-1197-2023; li,
   Li/JPA-0218-2023; Yang, Fan/JMA-9594-2023; zhang, yan/JGL-8022-2023;
   Yang, Jie/JDM-6213-2023; Wang, Zejun/KBB-8454-2024; wu, p/JDW-5015-2023;
   chen, Chen/JKJ-2122-2023; Lin, Lin/JTU-1595-2023; Zhou,
   heng/JCN-6493-2023; liu, yang/JMB-9083-2023; Li, Lei/JPE-6543-2023; liu,
   xiao/JLL-2119-2023; feng, feng/KBR-1814-2024; yuan, lin/JDW-7387-2023;
   Chen, Xiao/KBD-1464-2024; Wang, He/JCO-3900-2023; Hussain,
   Abid/GVT-3681-2022; Zhang, Shiwei/JIY-4344-2023; Chen, Yu/JLL-0171-2023;
   li, wenjing/JMP-7498-2023; li, mengyang/JWO-9551-2024; WANG,
   YING/JLM-9219-2023; Li, Yao/JJC-2927-2023; li, rui/JVM-8999-2024; Yang,
   Jing/JFK-4046-2023
OI Abbas, Fakhar/0000-0002-6850-5713; Yang, Jie/0000-0002-3941-0053;
   Hussain, Abid/0000-0003-1879-6994; Yang, Jing/0009-0004-8274-9863; ALI,
   DANISH/0000-0003-4154-4701
FU Natural Science Foundation of Sichuan Province [23NSFSC0058]
FX Funding This work was supported by the Natural Science Foundation of
   Sichuan Province under Grant No. 23NSFSC0058.
CR Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bai C, 2018, NEUROCOMPUTING, V303, P60, DOI 10.1016/j.neucom.2018.04.034
   Cao Y, 2016, AAAI CONF ARTIF INTE, P3457
   Choudhary T, 2020, ARTIF INTELL REV, V53, P5113, DOI 10.1007/s10462-020-09816-7
   Chua T.-S., 2009, CIVR, P1, DOI 10.1145/1646396.1646452
   Feng H, 2021, NEUROCOMPUTING, V423, P274, DOI 10.1016/j.neucom.2020.10.028
   Gao M., 12 INT C GRAPH IM PR, P762
   Ghimire D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11060945
   Han  S., 2015, ARXIV151000149
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   Hu D, 2019, IEEE T IMAGE PROCESS, V28, P1080, DOI 10.1109/TIP.2018.2875312
   Hu HY, 2016, Arxiv, DOI arXiv:1607.03250
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu WJ, 2021, NEUROCOMPUTING, V448, P94, DOI 10.1016/j.neucom.2021.03.093
   Hussain A, 2022, ENTROPY-SWITZ, V24, DOI 10.3390/e24101425
   Jayaraman U, 2020, NEUROCOMPUTING, V408, P231, DOI 10.1016/j.neucom.2019.08.110
   Jiang QY, 2018, AAAI CONF ARTIF INTE, P3342
   Jin L, 2019, IEEE T NEUR NET LEAR, V30, P1429, DOI 10.1109/TNNLS.2018.2869601
   Jose A, 2017, IEEE IMAGE PROC, P2916, DOI 10.1109/ICIP.2017.8296816
   Lee H.J., INT C MULT MOD, P493
   Li P, 2020, IEEE T GEOSCI REMOTE, V58, P7331, DOI 10.1109/TGRS.2020.2981997
   Li Q, 2020, INT J COMPUT VISION, V128, P2204, DOI 10.1007/s11263-020-01327-w
   Li Q, 2017, ADV NEUR IN, V30
   Li WC, 2015, AIP ADV, V5, DOI 10.1063/1.4923194
   Li XJ, 2020, Arxiv, DOI arXiv:1901.09229
   Liang TL, 2021, NEUROCOMPUTING, V461, P370, DOI 10.1016/j.neucom.2021.07.045
   Liu D., 2021, ARXIV210710998, V1, P1
   Liu HM, 2016, PROC CVPR IEEE, P2064, DOI 10.1109/CVPR.2016.227
   Luciano L, 2019, COMPUT GRAPH-UK, V79, P14, DOI 10.1016/j.cag.2018.12.003
   Phan MH, 2022, NEUROCOMPUTING, V504, P189, DOI 10.1016/j.neucom.2022.06.095
   Ojha U., 2022, ARXIV220516004, V2, P1
   Qayyum A, 2017, NEUROCOMPUTING, V266, P8, DOI 10.1016/j.neucom.2017.05.025
   Romero A., 2015, ICLR, P1, DOI DOI 10.48550/ARXIV.1412.6550
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shen YM, 2020, INFORM SCIENCES, V539, P145, DOI 10.1016/j.ins.2020.05.114
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Tulbure AA, 2022, J ADV RES, V35, P33, DOI 10.1016/j.jare.2021.03.015
   Tzelepi M, 2018, NEUROCOMPUTING, V275, P2467, DOI 10.1016/j.neucom.2017.11.022
   Wang WW, 2021, INFORM SCIENCES, V547, P622, DOI 10.1016/j.ins.2020.08.092
   Wei SK, 2019, IEEE T IMAGE PROCESS, V28, P4580, DOI 10.1109/TIP.2019.2913513
   Weng ZY, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107151
   Wu D., P IEEE CVF C COMP VI, P9069
   Wu LJ, 2021, IEEE INTERNET THINGS, V8, P11357, DOI 10.1109/JIOT.2021.3052105
   Xu J., 2022, 2022 CHI C HUMAN FAC, P01
   Xu K, 2021, NEUROCOMPUTING, V451, P81, DOI 10.1016/j.neucom.2021.04.022
   Yim J, 2017, PROC CVPR IEEE, P7130, DOI 10.1109/CVPR.2017.754
   Yuan C., 2021, ARXIV
   Zeng Y., AS C MACH LEARN 2021, P331
   Zhai HJ, 2021, IEEE T CIRC SYST VID, V31, P742, DOI 10.1109/TCSVT.2020.2991171
   Zhao M, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071066
   Zhu H, 2016, AAAI CONF ARTIF INTE, P2415
NR 52
TC 1
Z9 1
U1 4
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2023
VL 133
AR 104668
DI 10.1016/j.imavis.2023.104668
EA APR 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA G5QJ5
UT WOS:000989697100001
DA 2024-07-18
ER

PT J
AU Xiao, CJ
   Hao, XJ
   Li, HB
   Li, YQ
   Zhang, WM
AF Xiao, Cunjun
   Hao, Xingjun
   Li, Haibin
   Li, Yaqian
   Zhang, Wenming
TI Real-time semantic segmentation with local spatial pixel adjustment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic segmentation; Real-time; Local spatial adjustment; Dual-branch
   decoding
ID NETWORK
AB The research of semantic segmentation networks has achieved a significant breakthrough recently. However, most part of methods have difficulty in utilizing information generated at each stage, which resulting in pixel value dislocation and blurred boundaries for small-scale objects. To overcome these challenges, a local spatial pixel adjustment network (LSPANet) is proposed in this paper, which mainly consists of a dual-branch decoding fusion (DDF) module and a spatial pixel cross-correlation (SPCC) block. Specifically, the DDF module takes the high-level and low-level feature maps with different stages as the input, and gradually eliminates the discrepancy in the information of the feature map to fuse a variety of information extracted in the encoder stage. The SPCC block adopts the horizontal spatial pixel adjustment (HSPA) module and the vertical spatial pixel adjustment (VSPA) module to capture the relationship of each pixel value in the local horizontal and vertical space respectively, and then assign the importance to all values based on this relationship. LSPANet is evaluated on Cityscapes and Camvid datasets. The experimental results show that our network achieves 77.1% mIoU with 2 M parameters on the challenging Cityscapes dataset and the inference speed exceeds 30 FPS in a single GTX 2080 Ti GPU.(c) 2022 Published by Elsevier B.V.
C1 [Xiao, Cunjun; Hao, Xingjun; Li, Haibin; Li, Yaqian; Zhang, Wenming] Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University
RP Li, HB (corresponding author), Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM hbili@ysu.edu.cn
RI li, haibin/A-1012-2012
FU National Natural Science Founda-tion of Chain [62106214]; Natural
   Science Founda-tion of Hebei Province [F201920311]
FX Acknowledgments This work was supported by the National Natural Science
   Founda-tion of Chain under grant 62106214, and the Natural Science
   Founda-tion of Hebei Province under grant F201920311.
CR Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Das A., 2019, ARXIV, V1901
   Dong GS, 2021, IEEE T INTELL TRANSP, V22, P3258, DOI 10.1109/TITS.2020.2980426
   Gao GW, 2022, IEEE T INTELL TRANSP, V23, P25489, DOI 10.1109/TITS.2021.3098355
   Gao Roland, ARXIV
   Hao SJ, 2020, IEEE ACCESS, V8, P55230, DOI 10.1109/ACCESS.2020.2981842
   Hao XC, 2021, IMAGE VISION COMPUT, V114, DOI 10.1016/j.imavis.2021.104269
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, PREPRINT
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu P, 2021, IEEE ROBOT AUTOM LET, V6, P263, DOI 10.1109/LRA.2020.3039744
   Hu X, 2022, APPL INTELL, V52, P4041, DOI 10.1007/s10489-021-02644-4
   Hu XG, 2020, IEEE ACCESS, V8, P70913, DOI 10.1109/ACCESS.2020.2987080
   Huang ST, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P2129, DOI 10.1145/3357384.3358132
   Jiang W, 2020, CONSUM COMM NETWORK, DOI 10.1109/ccnc46108.2020.9045219
   Lee J, 2019, PROC CVPR IEEE, P2273, DOI 10.1109/CVPR.2019.00238
   Li G, 2020, IEEE ACCESS, V8, P27495, DOI 10.1109/ACCESS.2020.2971760
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Liu M., 2019, ARXIV, V1909
   Lo SY, 2019, IEEE INT WORKSH MULT, DOI 10.1109/mmsp.2019.8901686
   Ma MY, 2019, IEEE ANN INT CONF CY, P659, DOI 10.1109/CYBER46603.2019.9066620
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Orsic M, 2019, PROC CVPR IEEE, P12599, DOI 10.1109/CVPR.2019.01289
   Paszke A., 2016, ARXIV160602147
   Poudel R.P.K., 2019, ARXIV190204502, P289
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Tang XY, 2021, INFORM SCIENCES, V565, P326, DOI 10.1016/j.ins.2021.02.004
   Wang F, 2021, CHINESE J AERONAUT, V34, P47, DOI 10.1016/j.cja.2020.10.032
   Wang JW, 2020, APPL INTELL, V50, P1045, DOI 10.1007/s10489-019-01587-1
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu M, 2021, I S BIOMED IMAGING, P827, DOI 10.1109/ISBI48211.2021.9433899
   Yang QH, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P2315, DOI 10.1109/ICASSP39728.2021.9413767
   Yang ZG, 2021, IEEE T INTELL TRANSP, V22, P5508, DOI 10.1109/TITS.2020.2987816
   Zhang BX, 2020, NEUROCOMPUTING, V393, P54, DOI 10.1016/j.neucom.2020.02.019
   Zhang C, 2019, PROC CVPR IEEE, P5212, DOI 10.1109/CVPR.2019.00536
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Q, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106682
   Zhu WC, 2021, IEEE T IMAGE PROCESS, V30, P948, DOI 10.1109/TIP.2020.3039886
NR 45
TC 11
Z9 11
U1 6
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104470
DI 10.1016/j.imavis.2022.104470
EA MAY 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1W0YE
UT WOS:000806506500003
DA 2024-07-18
ER

PT J
AU Caglayan, A
   Imamoglu, N
   Nakamura, R
AF Caglayan, Ali
   Imamoglu, Nevrez
   Nakamura, Ryosuke
TI MMSNet: Multi-modal scene recognition using multi-scale encoded features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE RGB-D scene recognition; Multi -modal learning; Multi-scale feature
   fusion
ID OBJECT; NETWORK
AB Utilizing multi-level features has been proven to improve RGB-D scene recognition performance. However, simply fusing features after conducting RGB and depth data separately may not satisfy multi-modal integrity. In this work, we propose an effective multi-modal RGB-D scene recognition model that integrates global or local multiscale/multi-semantic features. The proposed approach is built on two key components. In the first stage, multiple random recursive neural networks (RNNs) are employed on a baseline CNN model to obtain multi-scale encoded features from multi-level feature hierarchy. In the second stage, multi-layer perceptrons (MLPs) learn global/ local features at multiple levels while encouraging the correlation of multi-modal mutual features. Our learning design is based on the insight that correlated multi-modal features provide the complementary relation between the two modalities that promotes better performance of RGB-D scene recognition. In addition, the network is trained using a decisive fusion based on modality prediction confidence weights to yield RGB-D multi-modal recognition. Experiments on three RGB-D scene datasets verify the effectiveness of the proposed approach by achieving superior or highly competitive results compared to other state-of-the-art counterpart methods. Evaluation code and models are available at https://github.com/acaglayan/MMSNet. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Caglayan, Ali; Imamoglu, Nevrez; Nakamura, Ryosuke] Natl Inst Adv Ind Sci & Technologhy AIST, Digital Architecture Res Ctr DigiARC, Tokyo, Japan.
RP Caglayan, A; Imamoglu, N (corresponding author), Natl Inst Adv Ind Sci & Technologhy AIST, Digital Architecture Res Ctr DigiARC, Tokyo, Japan.
EM ali.caglayan@aist.go.jp; nevrez.imamoglu@aist.go.jp
RI Caglayan, Ali/AAF-1688-2020; Imamoglu, Nevrez/B-1746-2017
OI Caglayan, Ali/0000-0002-3408-8659; Imamoglu, Nevrez/0000-0002-2661-599X
FU New Energy and Industrial Technol-ogy Development Organization (NEDO)
   [JPNP18010]
FX Acknowledgment This paper is based on the results obtained from a
   project, JPNP18010, commissioned by the New Energy and Industrial
   Technol-ogy Development Organization (NEDO) .
CR Asif U, 2018, IEEE T PATTERN ANAL, V40, P2051, DOI 10.1109/TPAMI.2017.2747134
   Ayub Ali, 2020, BRIT MACH VIS C BMVC
   Caglayan A, 2022, COMPUT VIS IMAGE UND, V217, DOI 10.1016/j.cviu.2022.103373
   Cai ZY, 2019, COGN COMPUT, V11, P825, DOI 10.1007/s12559-018-9580-y
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Droste Richard, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P419, DOI 10.1007/978-3-030-58558-7_25
   Du DP, 2019, PROC CVPR IEEE, P11828, DOI 10.1109/CVPR.2019.01211
   Du Dapeng, 2021, INT J COMPUT VISION, P1
   Girdhar Rohit, 2022, P I C COMP VI PATT R
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gupta S, 2015, INT J COMPUT VISION, V112, P133, DOI 10.1007/s11263-014-0777-6
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Janoch A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Jia Sen, 2019, ARXIV PREPRINT ARXIV
   Jin YM, 2020, MED IMAGE ANAL, V59, DOI 10.1016/j.media.2019.101572
   Kay W., 2017, CORR ABS170506950
   Li YB, 2019, PATTERN RECOGN, V90, P436, DOI 10.1016/j.patcog.2019.02.005
   Li Yabei, 2018, 32 AAAI C ARTIFICIAL
   Liao YY, 2016, IEEE INT CONF ROBOT, P2318, DOI 10.1109/ICRA.2016.7487381
   Liu Z, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9992, DOI 10.1109/ICCV48922.2021.00986
   Mosella-Montoro A, 2021, INFORM FUSION, V76, P46, DOI 10.1016/j.inffus.2021.05.002
   Mosella-Montoro A, 2019, IEEE INT CONF COMP V, P4123, DOI 10.1109/ICCVW.2019.00507
   Mozos OM, 2019, INT J ROBOT RES, V38, P507, DOI 10.1177/0278364919835603
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Paszke A, 2019, ADV NEUR IN, V32
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Song XH, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4523
   Song XH, 2020, IEEE T IMAGE PROCESS, V29, P525, DOI 10.1109/TIP.2019.2933728
   Song XH, 2019, IEEE T IMAGE PROCESS, V28, P980, DOI 10.1109/TIP.2018.2872629
   Song XH, 2017, AAAI CONF ARTIF INTE, P4271
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Wang A, 2016, PROC CVPR IEEE, P5995, DOI 10.1109/CVPR.2016.645
   Wang AR, 2015, IEEE I CONF COMP VIS, P1125, DOI 10.1109/ICCV.2015.134
   Wang AR, 2015, IEEE T MULTIMEDIA, V17, P1887, DOI 10.1109/TMM.2015.2476655
   Xiong ZT, 2021, IEEE T IMAGE PROCESS, V30, P2722, DOI 10.1109/TIP.2021.3053459
   Xiong ZT, 2020, NEUROCOMPUTING, V373, P81, DOI 10.1016/j.neucom.2019.09.066
   Yuan Y, 2019, AAAI CONF ARTIF INTE, P9176
   Zaki HFM, 2019, AUTON ROBOT, V43, P1005, DOI 10.1007/s10514-018-9776-8
   Zaki HFM, 2017, ROBOT AUTON SYST, V92, P41, DOI 10.1016/j.robot.2017.02.008
   Zheng Y, 2017, MULTIMED TOOLS APPL, V76, P4427, DOI 10.1007/s11042-016-3423-1
   Zhou BL, 2014, ADV NEUR IN, V27
   Zhu HY, 2016, PROC CVPR IEEE, P2969, DOI 10.1109/CVPR.2016.324
NR 46
TC 2
Z9 2
U1 2
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2022
VL 122
AR 104453
DI 10.1016/j.imavis.2022.104453
EA APR 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L0BW
UT WOS:000798959000002
DA 2024-07-18
ER

PT J
AU He, LQ
   Xia, L
   Luo, JJ
   Zhang, K
   Sun, YY
   Qiao, N
   Kuo, CH
   Todorovic, S
AF He, Liqiang
   Xia, Lu
   Luo, Jiajia
   Zhang, Ke
   Sun, Yuyin
   Qiao, Nan
   Kuo, Cheng-Hao
   Todorovic, Sinisa
TI A polar-edge context-aware (PECA) network for mirror segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
AB This paper presents Polar-Edge Contrast-Aware Network (PECA) for mirror instance segmentation in images of indoor scenes. General instance segmentation methods typically rely on the surface appearance of the object to identify the foreground from background. However, these approaches do not directly apply to mirrors as the mirror surfaces are less reliable due to reflections of the surroundings. On the other hand, the existing saliency-based mirror segmentation methods are prone to predict false positives in images with no mirrors, especially for the indoor scenes that have mirror-shape objects, such as doors and windows. In this work, we propose a novel boundary-based mirror localization method PECA that achieves both high segmentation accuracy on mirrors and low false positive rate on negative samples. PECA uses a context-aware module to extract features along the instance contour and in this way incorporates boundary information for improving mirror detection. The predicted mirror candidates are further refined with a local contrast module for the final mirror instance segmentation. PECA achieves IoU 80.29% on the benchmark Mirror Segmentation dataset (MSD), outperforming the state-of-the-art method MirrorNet (IoU = 78.95%) by 1.34%. It also produces a significantly smaller false positive rate (43.37%) than existing methods (91.39%) on our challenging Negative Mirror Dataset (NMD) without retraining. After training on both MSD and NMD training sets, our model further reduces the false positive rate to 0.08% on NMD testing set, while keeping IoU of 73.07% on MSD, enabling realistic real-world applications. (c) 2022 Elsevier B.V. All rights reserved.
C1 [He, Liqiang; Todorovic, Sinisa] Oregon State Univ, Corvallis, OR 97331 USA.
   [Xia, Lu; Luo, Jiajia; Zhang, Ke; Sun, Yuyin; Qiao, Nan; Kuo, Cheng-Hao] Amazon Com, Seattle, WA USA.
C3 Oregon State University; Amazon.com
RP He, LQ (corresponding author), Oregon State Univ, Corvallis, OR 97331 USA.
EM heli@oregonstate.edu
RI xu, lingzhi/JVZ-8748-2024; Zhang, Yihao/JGM-3514-2023; Zhang,
   Ke/ACQ-4947-2022; Wang, Jiacheng/ABE-5948-2020; Cheng,
   Yuan/JKJ-0794-2023; Liu, Song/KCX-6842-2024; Wang, Peilin/JWP-6008-2024
OI Zhang, Ke/0000-0002-7892-3919; Wang, Jiacheng/0000-0003-4327-1508; 
CR Bochkovskiy A., 2020, ARXIV PREPRINT ARXIV
   Chen K., ARXIV PREPRINT ARXIV
   DelPozo Andrey., 2007, CVPR
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Enze Xie, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12190, DOI 10.1109/CVPR42600.2020.01221
   Hao Chen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8570, DOI 10.1109/CVPR42600.2020.00860
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Janoch A, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Lee Y, 2020, P IEEE CVF C COMP VI
   Lin J., P IEEE CVF C COMP VI, P3697
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Qiu H., 2020, ARXIV PREPRINT ARXIV
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Savarese S, 2005, INT J COMPUT VISION, V64, P31, DOI 10.1007/s11263-005-1086-x
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vu T., ADV NEURAL INFORM PR, V2019, P1432
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang X., 2020, INT SOC THROMBOSIS H
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Xue Yang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P677, DOI 10.1007/978-3-030-58598-3_40
   Yang X., 2019, ARXIV190805612, P3163
   Yang X, 2019, IEEE I CONF COMP VIS, P8808, DOI 10.1109/ICCV.2019.00890
   Yang Z., ARXIV PREPRINT ARXIV
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
NR 28
TC 4
Z9 4
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104402
DI 10.1016/j.imavis.2022.104402
EA MAR 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0N8RO
UT WOS:000783099100002
DA 2024-07-18
ER

PT J
AU Zhang, J
   Liang, QW
   Guo, QQ
   Yang, JY
   Zhang, Q
   Shi, YJ
AF Zhang, Jin
   Liang, Qiuwei
   Guo, Qianqian
   Yang, Jinyu
   Zhang, Qing
   Shi, Yanjiao
TI R<SUP>2</SUP>Net: Residual refinement network for salient object
   detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Salient object detection; Multi-scale feature; Feature
   fusion
ID MODEL
AB The multi-scale features and the fusion strategy of contextual features are the keys to salient object detection task. Previous multi-scale-based works often overlooked the completeness of features when acquiring multi scale features. Moreover, the decoders were hard to accurately capture the salient object and refine the object's boundaries simultaneously when in a complex environment, which leads to unsatisfactory saliency maps. To address the above problems, we present a Residual Refinement Network (R(2)Net), which is composed of the Residual Pyramid Module (RPM), the Residual Fusion Module (RFM) and the Feature Optimize Module (FOM), for salient object detection. RPM integrates different feature information through different receptive fields, can not only obtain multi-scale information but also retain the local details information of features. RFM can better locate salient objects and refine the boundaries through the interweaving and fusion of multi-layer features. And FOM is designed to further refine the fused features. Furthermore, we propose a Structural Polishing (SP) loss, which better guides the network through pixel-level supervision, global supervision and boundary supervision to generate high-quality saliency maps with fine boundaries. Experimental results on 6 benchmark datasets demonstrate that the proposed method has superior performance compared with 18 state-of-the-art methods. The code and results of our method are available at https://github.com/zhangjin12138/R(2)Net (c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhang, Jin; Guo, Qianqian; Yang, Jinyu; Zhang, Qing; Shi, Yanjiao] Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
   [Liang, Qiuwei] Wenzhou Med Univ, Sch Ophthalmol & Optometry, Sch Biomed Engn, Wenzhou 325027, Peoples R China.
   [Liang, Qiuwei] Wenzhou Med Univ, Hosp Eye, Wenzhou 325027, Peoples R China.
C3 Shanghai Institute of Technology; Wenzhou Medical University; Wenzhou
   Medical University
RP Shi, YJ (corresponding author), Shanghai Inst Technol, Sch Comp Sci & Informat Engn, Shanghai 201418, Peoples R China.
EM shiyanjiao616@163.com
FU National Natural Science Foundation of China [61806126, 61903256,
   61976140, 61973307, 62062040]; Natural Science Foundation of Shanghai
   [19ZR1455300, 21ZR1462600]
FX Acknowledgements This work was supported by the National Natural Science
   Foundation of China (61806126, 61903256, 61976140, 61973307, 62062040)
   and Natural Science Foundation of Shanghai (19ZR1455300, 21ZR1462600) .
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   Bokhovkin A, 2019, LECT NOTES COMPUT SC, V11555, P388, DOI 10.1007/978-3-030-22808-8_38
   Chen SH, 2018, LECT NOTES COMPUT SC, V11213, P236, DOI 10.1007/978-3-030-01240-3_15
   Chen ZY, 2020, AAAI CONF ARTIF INTE, V34, P10599
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Deng ZJ, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P684
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, LECT NOTES COMPUT SC, V11219, P196, DOI 10.1007/978-3-030-01267-0_12
   Feng MY, 2019, PROC CVPR IEEE, P1623, DOI 10.1109/CVPR.2019.00172
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He SF, 2015, INT J COMPUT VISION, V115, P330, DOI 10.1007/s11263-015-0822-0
   Hou QB, 2017, PROC CVPR IEEE, P5300, DOI 10.1109/CVPR.2017.563
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang L., P IEEE CVF C COMP VI, P16509
   Jun Wei, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13022, DOI 10.1109/CVPR42600.2020.01304
   Li GB, 2015, PROC CVPR IEEE, P5455, DOI 10.1109/CVPR.2015.7299184
   Li J, 2021, IEEE T IMAGE PROCESS, V30, P6855, DOI 10.1109/TIP.2021.3099405
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu JJ, 2020, IEEE T IMAGE PROCESS, V29, P8652, DOI 10.1109/TIP.2020.3017352
   Liu N., 2022, ARXIV PREPRINT ARXIV
   Liu Y., IEEE T CYBERNETICS
   Ma MC, 2021, AAAI CONF ARTIF INTE, V35, P2311
   Margolin R, 2014, PROC CVPR IEEE, P248, DOI 10.1109/CVPR.2014.39
   Miao Z., 2021, ACM MULT C 2021, V2021
   Mohammadi S, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107303
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Qin X., 2022, ARXIV PREPRINT ARXIV
   Qin XB, 2019, PROC CVPR IEEE, P7471, DOI 10.1109/CVPR.2019.00766
   Shimoda W, 2020, COMPUT VIS IMAGE UND, V191, DOI 10.1016/j.cviu.2018.08.006
   Simonyan K., 2015, P 3 INT C LEARN REPR
   Soleymani R, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107146
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang B, 2020, AAAI CONF ARTIF INTE, V34, P12128
   Wang HX, 2020, PATTERN RECOGN LETT, V130, P64, DOI 10.1016/j.patrec.2018.08.010
   Wang LJ, 2017, PROC CVPR IEEE, P3796, DOI 10.1109/CVPR.2017.404
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu R., P IEEE CVF C COMPUTE, P8150
   Wu Z, 2019, IEEE I CONF COMP VIS, P7263, DOI 10.1109/ICCV.2019.00736
   Wu Z, 2019, PROC CVPR IEEE, P3902, DOI 10.1109/CVPR.2019.00403
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yao YZ, 2021, PROC CVPR IEEE, P2623, DOI 10.1109/CVPR46437.2021.00265
   Youwei Pang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9410, DOI 10.1109/CVPR42600.2020.00943
   Zhang J, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104337
   Zhang JX, 2014, IEEE IMAGE PROC, P1175, DOI 10.1109/ICIP.2014.7025234
   Zhang L, 2018, PROC CVPR IEEE, P1741, DOI 10.1109/CVPR.2018.00187
   Zhang P, 2017, NEUROCOMPUTING, V257, P115, DOI 10.1016/j.neucom.2016.10.073
   Zhang PP, 2020, PATTERN RECOGN, V100, DOI 10.1016/j.patcog.2019.107130
   Zhang XN, 2018, PROC CVPR IEEE, P714, DOI 10.1109/CVPR.2018.00081
   Zhao T, 2019, PROC CVPR IEEE, P3080, DOI 10.1109/CVPR.2019.00320
   Zhao X., 2020, P EUR C COMP VIS, P35, DOI 10.1007/ 978-3-030-58536-5_3
   Zhao ZR, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4967, DOI 10.1145/3474085.3475494
   Zhou H., 2020, P IEEE C COMP VIS PA, P9141, DOI 10.1109/CVPR42600.2020.00916
NR 57
TC 8
Z9 9
U1 0
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104423
DI 10.1016/j.imavis.2022.104423
EA MAR 2022
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0M9DZ
UT WOS:000782449300002
DA 2024-07-18
ER

PT J
AU Narwaria, M
AF Narwaria, Manish
TI Does explainable machine learning uncover the black box in vision
   applications?
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Explainable machine learning; Deep learning; Vision; Signal processing
AB Machine learning (ML) in general and deep learning (DL) in particular has become an extremely popular tool in several vision applications (like object detection, super resolution, segmentation, object tracking etc.). Almost in parallel, the issue of explainability in ML (i.e. the ability to explain/elaborate the way a trained ML model arrived at its decision) in vision has also received fairly significant attention from various quarters. However, we argue that the current philosophy behind explainable ML suffers from certain limitations, and the resulting explanations may not meaningfully uncover black box ML models. To elaborate our assertion, we first raise a few fundamental questions which have not been adequately discussed in the corresponding literature. We also provide perspectives on how explainablity in ML can benefit by relying on more rigorous principles in the related areas.(c) 2021 Elsevier B.V. All rights reserved.
C1 [Narwaria, Manish] Indian Inst Technol Jodhpur, Dept Elect Engn, NH 62,Surpura Bypass Rd, Karwar 342037, Rajasthan, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Jodhpur
RP Narwaria, M (corresponding author), Indian Inst Technol Jodhpur, Dept Elect Engn, NH 62,Surpura Bypass Rd, Karwar 342037, Rajasthan, India.
EM narwaria@iitj.ac.in
FU SERB [MTR/2020/000335]
FX The author acknowledges funding from SERB vide grant no.
   MTR/2020/000335.
CR Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Beckh K., 2021, EXPLAINABLE MACHINE
   Buhrmester V., 2019, ARXIVABS191112116
   Carrasco M, 2011, VISION RES, V51, P1484, DOI 10.1016/j.visres.2011.04.012
   Chalmers A, 2017, SIGNAL PROCESS-IMAGE, V54, P49, DOI 10.1016/j.image.2017.02.003
   Chellappa R, 2016, IMAGE VISION COMPUT, V55, P3, DOI 10.1016/j.imavis.2016.04.005
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Engel Jesse H., 2020, DDSP DIFFERENTIABLE
   Guionnet Thomas, 2020, SMPTE Motion Imaging Journal, V129, P26
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kellman M., 2020, THESIS U CALIFORNIA
   Marr D., 1982, Vision. A computational investigation into the human representation and processing of visual information
   Narwaria M, 2021, IEEE SIGNAL PROC MAG, V38, P163, DOI 10.1109/MSP.2021.3050996
   Petsiuk V., 2018, RISE RANDOMIZED INPU
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Thuerey N. etal, 2021, Physics-based Deep Learning
   Tseng A., 2020, P 34 INT C NEUR INF, V33, P1913
   Watson Andrew B., 2013, Motion Imaging Journal, V122, P18
   Xie N., 2020, ARXIVABS200414545
NR 20
TC 10
Z9 10
U1 2
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2022
VL 118
AR 104353
DI 10.1016/j.imavis.2021.104353
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0F3OZ
UT WOS:000777273700009
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hao, XC
   Hao, XJ
   Zhang, YR
   Li, YY
   Wu, C
AF Hao, Xiaochen
   Hao, Xingjun
   Zhang, Yaru
   Li, Yuanyuan
   Wu, Chao
TI Real-time semantic segmentation with weighted factorized-depthwise
   convolution
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semantic segmentation; Real-time; Pyramid fusion; Continuous separation
ID NETWORK; CONVNET
AB Semantic segmentation has achieved great success with the popularity of convolutional neural networks (CNNs). However, the huge computational burden restricts the application of most existing networks on edge devices with strict inference time constraints. To solve this problem, a weighted factorized-depthwise convolution net-work (WFDCNet) is presented in this paper, which contains full-dimensional continuous separation convolution (FCS) modules anda lateral asymmetric pyramid fusion (LAPF) module, aiming to obtain high accuracy without damaging inference speed. Specifically, the FCS module enables the calculation of each dimension to be com-pleted independently in a continuous separation process and uses simplified SE (SSE) attention layer to adjust the channels, achieving the extensive extraction of feature information. The LAPF module is able to eliminate se-mantic divergence and fuse feature maps of three different scales to realize the combination of multiple informa-tion from the front-end and the back-end network. WFDCNet shows superior performance on Cityscapes, Camvid, Mapillary Vistas and COCO-Stuff datasets. Especially, the experimental results demonstrate that our net-work achieves 73.7% mIoU on Cityscapes dataset, with the inference speed of 102.6FPS on a single RTX 2080 Ti GPU, and 17.2FPS on Jetson TX2. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Hao, Xiaochen; Hao, Xingjun; Li, Yuanyuan] Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
   [Zhang, Yaru; Wu, Chao] Yanshan Univ, Sch Informat Sci & Engn, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Yanshan University; Yanshan University
RP Hao, XC (corresponding author), Yanshan Univ, Sch Elect Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM haoxj_new@163.com
RI li, yuanyuan/GZA-4435-2022; Zhang, Yaru/JEP-7689-2023
FU Natural Science Foundation of Hebei Province [F2019203320]
FX This work is supported by the Natural Science Foundation of Hebei
   Province (No. F2019203320)
CR Alonso I, 2020, IEEE T ROBOT, V36, P1340, DOI 10.1109/TRO.2020.2974099
   [Anonymous], 2016, ENET DEEP NEURAL NET
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Dong GS, 2021, IEEE T INTELL TRANSP, V22, P3258, DOI 10.1109/TITS.2020.2980426
   Han H., 2020, IEEE COMMUNICATIONS, P1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, arXiv
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu P, 2021, IEEE ROBOT AUTOM LET, V6, P263, DOI 10.1109/LRA.2020.3039744
   Hu XG, 2020, IEEE ACCESS, V8, P70913, DOI 10.1109/ACCESS.2020.2987080
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   JIANG W, 2020, INORG NANOMETAL CHEM
   Kim J, 2019, IEEE ACCESS, V7, P154239, DOI 10.1109/ACCESS.2019.2949076
   Li G., 2019, DABNet: Depth-wise Asymmetric Bottleneck for Real-time Semantic Segmentation
   Li HC, 2019, PROC CVPR IEEE, P9514, DOI 10.1109/CVPR.2019.00975
   Li X., EUR C COMP VIS 2020, P775
   Li X, 2019, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2019.00060
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin J, 2020, J PHYS CONF SER, V1518, DOI 10.1088/1742-6596/1518/1/012052
   Lin N, 2019, PR IEEE COMP DESIGN, P626, DOI 10.1109/ICCD46524.2019.00090
   Liu M., 2019, FEATURE PYRAMID ENCO
   Lo S. Y., 2019, P ACM MULTIMEDIA ASI, P1, DOI DOI 10.1145/3338533.3366558
   Ma MY, 2019, IEEE ANN INT CONF CY, P659, DOI 10.1109/CYBER46603.2019.9066620
   Mehta S, 2019, PROC CVPR IEEE, P9182, DOI 10.1109/CVPR.2019.00941
   Mehta S, 2018, LECT NOTES COMPUT SC, V11214, P561, DOI 10.1007/978-3-030-01249-6_34
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Romera E, 2018, IEEE T INTELL TRANSP, V19, P263, DOI 10.1109/TITS.2017.2750080
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Siam M, 2018, IEEE IMAGE PROC, P1603, DOI 10.1109/ICIP.2018.8451495
   Wang JW, 2020, APPL INTELL, V50, P1045, DOI 10.1007/s10489-019-01587-1
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang WF, 2020, IEEE ACCESS, V8, P36776, DOI 10.1109/ACCESS.2020.2975640
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Wu TY, 2021, IEEE T IMAGE PROCESS, V30, P1169, DOI 10.1109/TIP.2020.3042065
   Xiang W, 2019, IEEE WINT CONF APPL, P1789, DOI 10.1109/WACV.2019.00195
   Yang ZG, 2020, IEEE T IMAGE PROCESS, V29, P5175, DOI 10.1109/TIP.2020.2976856
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zhou Q, 2020, APPL SOFT COMPUT, V96, DOI 10.1016/j.asoc.2020.106682
   Zhou Q, 2019, WORLD WIDE WEB, V22, P555, DOI 10.1007/s11280-018-0556-3
NR 44
TC 12
Z9 12
U1 1
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2021
VL 114
AR 104269
DI 10.1016/j.imavis.2021.104269
EA AUG 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UR9HP
UT WOS:000697051200004
DA 2024-07-18
ER

PT J
AU Zhang, C
   Cao, M
   Yang, DM
   Jiang, J
   Zou, YX
AF Zhang, Can
   Cao, Meng
   Yang, Dongming
   Jiang, Ji
   Zou, Yuexian
TI Synergic learning for noise-insensitive webly-supervised temporal action
   localization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Temporal action localization; Web supervision; Spatio-temporal
   representation
AB Webly-supervised temporal action localization (WebTAL) leverages web videos to train localization models without requiring manual temporal annotations. WebTAL is extremely challenging since video-level labels on the web are always noisy, seriously damaging the overall performance. Most state-of-the-art methods filter out noise before training, which will inevitably reduce the training samples. In contrast, we propose a preprocessing-free WebTAL framework along with a new synergic learning paradigm to alleviate the noise interference. Specifically, we introduce a synergic task called Spatio-Temporal Order Prediction (STOP) for spatiotemporal representation learning. This task requires a network to arrange permuted spatial crops and temporal clips, thereby learning the inherent spatial semantics and temporal interactions in videos. Instead of pre extracting features with the well-trained STOP, we design a novel synergic learning paradigm called Warm-up Synergic Training (WST) to iteratively generate better spatio-temporal representations and improve action localization results. In this synergic fashion, experimental results show that the interference caused by label noise will be largely mitigated. We demonstrate that our method outperforms all other WebTAL methods on two public benchmarks, THUMOS'14 and ActivityNet v1.2. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Zhang, Can; Cao, Meng; Yang, Dongming; Jiang, Ji; Zou, Yuexian] Peking Univ, Sch ECE, ADSPLAB, Shenzhen, Peoples R China.
   [Zou, Yuexian] Pengcheng Lab, Shenzhen, Peoples R China.
C3 Peking University
RP Zou, YX (corresponding author), Peking Univ, Sch ECE, ADSPLAB, Shenzhen, Peoples R China.
EM zhangcan@pku.edu.cn; mengcao@pku.edu.cn; yangdongming@pku.edu.cn;
   zouyx@pku.edu.cn
OI Zhang, Can/0000-0001-9530-5218
FU IER foundation [HT-JD-CXY-201904]; Shenzhen Municipal Development and
   Reform Commission (Disciplinary Development Program for Data Science and
   Intelligent Computing)
FX This paper was partially supported by the IER foundation (No.
   HT-JD-CXY-201904) and Shenzhen Municipal Development and Reform
   Commission (Disciplinary Development Program for Data Science and
   Intelligent Computing) . Special acknowledgements are given to
   Aoto-PKUSZ Joint Lab for its support.
CR Ahsan U, 2019, IEEE WINT CONF APPL, P179, DOI 10.1109/WACV.2019.00025
   [Anonymous], 2016, IJCAI
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chao YW, 2018, PROC CVPR IEEE, P1130, DOI 10.1109/CVPR.2018.00124
   Chen XL, 2015, IEEE I CONF COMP VIS, P1431, DOI 10.1109/ICCV.2015.168
   Divvala SK, 2014, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2014.412
   Duan H., P EUR C COMP VIS ECC, P670
   Feichtenhofer C, 2019, IEEE I CONF COMP VIS, P6201, DOI 10.1109/ICCV.2019.00630
   Fernando B, 2017, PROC CVPR IEEE, P5729, DOI 10.1109/CVPR.2017.607
   Gan C, 2016, PROC CVPR IEEE, P923, DOI 10.1109/CVPR.2016.106
   Gan C, 2016, LECT NOTES COMPUT SC, V9907, P849, DOI 10.1007/978-3-319-46487-9_52
   Ghadiyaram D, 2019, PROC CVPR IEEE, P12038, DOI 10.1109/CVPR.2019.01232
   Gidaris S., 2018, P 6 INT C LEARNING R
   Guo S, 2018, LECT NOTES COMPUT SC, V11214, P139, DOI 10.1007/978-3-030-01249-6_9
   Idrees H, 2017, COMPUT VIS IMAGE UND, V155, P1, DOI 10.1016/j.cviu.2016.10.018
   Jain M, 2020, PROC CVPR IEEE, P1168, DOI 10.1109/CVPR42600.2020.00125
   Kim D, 2019, AAAI CONF ARTIF INTE, P8545
   Larsson G, 2017, PROC CVPR IEEE, P840, DOI 10.1109/CVPR.2017.96
   Lee HY, 2017, IEEE I CONF COMP VIS, P667, DOI 10.1109/ICCV.2017.79
   Lee KH, 2018, PROC CVPR IEEE, P5447, DOI 10.1109/CVPR.2018.00571
   Lee P, 2020, AAAI CONF ARTIF INTE, V34, P11320
   Lee YJ, 2012, PROC CVPR IEEE, P1346, DOI 10.1109/CVPR.2012.6247820
   Liu DC, 2019, PROC CVPR IEEE, P1298, DOI 10.1109/CVPR.2019.00139
   Liu ZY, 2019, IEEE I CONF COMP VIS, P3898, DOI 10.1109/ICCV.2019.00400
   Ma SG, 2017, PATTERN RECOGN, V68, P334, DOI 10.1016/j.patcog.2017.01.027
   Ma YF, 2005, IEEE T MULTIMEDIA, V7, P907, DOI 10.1109/TMM.2005.854410
   Mahajan D, 2018, LECT NOTES COMPUT SC, V11206, P185, DOI 10.1007/978-3-030-01216-8_12
   McInnes L, 2020, Arxiv, DOI [arXiv:1802.03426, DOI 10.48550/ARXIV.1802.03426, 10.21105/joss.00861]
   Min Kyle, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P283, DOI 10.1007/978-3-030-58568-6_17
   Misra I, 2016, LECT NOTES COMPUT SC, V9905, P527, DOI 10.1007/978-3-319-46448-0_32
   Narayan S, 2019, IEEE I CONF COMP VIS, P8678, DOI 10.1109/ICCV.2019.00877
   Noroozi M, 2016, LECT NOTES COMPUT SC, V9910, P69, DOI 10.1007/978-3-319-46466-4_5
   Pathak D, 2016, PROC CVPR IEEE, P2536, DOI 10.1109/CVPR.2016.278
   Paul S, 2018, LECT NOTES COMPUT SC, V11208, P588, DOI 10.1007/978-3-030-01225-0_35
   Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706
   Nguyen PX, 2019, IEEE I CONF COMP VIS, P5501, DOI 10.1109/ICCV.2019.00560
   Rupprecht C, 2018, COMPUT VIS IMAGE UND, V173, P24, DOI 10.1016/j.cviu.2017.08.006
   Sánchez J, 2013, IMAGE PROCESS ON LIN, V3, P137, DOI 10.5201/ipol.2013.26
   Shi BF, 2020, PROC CVPR IEEE, P1006, DOI 10.1109/CVPR42600.2020.00109
   Sultani W, 2016, PROC CVPR IEEE, P1077, DOI 10.1109/CVPR.2016.122
   Sun C, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P371, DOI 10.1145/2733373.2806226
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Xu DJ, 2019, PROC CVPR IEEE, P10326, DOI 10.1109/CVPR.2019.01058
   Xu HJ, 2017, IEEE I CONF COMP VIS, P5794, DOI 10.1109/ICCV.2017.617
   Xu M., 2020, CVPR, P10156
   Yang JF, 2018, IEEE T IMAGE PROCESS, V27, P5303, DOI 10.1109/TIP.2018.2855449
   Ye GG, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P471, DOI 10.1145/2733373.2806221
   Yeung S., P IEEE C COMP VIS PA, P5154
   Yu T, 2019, IEEE I CONF COMP VIS, P5521, DOI 10.1109/ICCV.2019.00562
   Yuanhao Zhai, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12351), P37, DOI 10.1007/978-3-030-58539-6_3
   Zeng RH, 2019, IEEE I CONF COMP VIS, P7093, DOI 10.1109/ICCV.2019.00719
   Zhang Hongyi, 2018, MIXUP EMPIRICAL RISK, DOI DOI 10.48550/ARXIV.1710.09412
   Zhao Y, 2017, IEEE I CONF COMP VIS, P2933, DOI 10.1109/ICCV.2017.317
   Zhekun Luo, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12374), P729, DOI 10.1007/978-3-030-58526-6_43
NR 56
TC 2
Z9 2
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2021
VL 113
AR 104247
DI 10.1016/j.imavis.2021.104247
EA JUL 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UA3CM
UT WOS:000685039900003
DA 2024-07-18
ER

PT J
AU Xu, L
   Song, YK
   Zhang, WS
   An, YY
   Wang, Y
   Ning, HS
AF Xu, Liang
   Song, Yongkang
   Zhang, Weishan
   An, Yunyun
   Wang, Ye
   Ning, Huansheng
TI An efficient foreign objects detection network for power substation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Power substation; Deep learning; Foreign objects detection; FODN4PS
ID DCGAN; RECOGNITION; VIBE
AB A power substation is susceptible to intrusions of foreign objects. The intrusions can likely result in failures of power supplies. Therefore, recognizing foreign objects becomes important to ensure constant and stable power supplies. However, existing object recognition methods fail to achieve acceptable accuracy and perfor-mance. In this paper, we propose an efficient Foreign Objects Detection Network for Power Substation (FODN4PS) to improve the recognition accuracy with less time. FODN4PS consists of a Moving Object Region Ex-traction Network (MORE Net) and a classification network, where the MORE Net can get the position of foreign objects, and the classification network can recognize the category of foreign objects. Experimental results show that FODN4PS is faster and more accurate in object recognition than the Fast R-CNN and Mask R-CNN.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Xu, Liang; Ning, Huansheng] Beijing Univ Sci & Technol, Coll Comp & Commun Engn, Beijing, Peoples R China.
   [Song, Yongkang; Zhang, Weishan] China Univ Petr, Coll Comp Sci & Technol, Qingdao, Peoples R China.
   [An, Yunyun] Huangdao Dist Power Supply Co, State Grid, Shandong Elect Power Co Qingdao, Qingdao, Peoples R China.
   [Wang, Ye] PLA 9144, Beijing, Peoples R China.
C3 University of Science & Technology Beijing; China University of
   Petroleum; State Grid Corporation of China
RP Zhang, WS (corresponding author), China Univ Petr, Coll Comp Sci & Technol, Qingdao, Peoples R China.
EM zhangws@upc.edu.cn; ninghuansheng@ustb.edu.cn
RI Zhang, Weishan/AAC-4520-2022; song, song/AAQ-4498-2021; Xu,
   Liang/KLC-7829-2024
OI Zhang, Weishan/0000-0001-9800-1068; 
FU National Natural Science Foundation of China [62072469]; National Key RD
   Program [2018yfe0116700]; Shandong Natural Science Foundation
   [ZR2019MF049]; basic research fund of Central University [2015020031];
   West Coast artificial intelligence technology innovation center
   [2019-1-5, 2019-1-6]; Opening Project of Shanghai Trusted Industrial
   Control Platform [TICPSH202003015-ZC]
FX The research is supported by the National Natural Science Foundation of
   China (62072469), National Key R&D Program (2018yfe0116700), Shandong
   Natural Science Foundation (ZR2019MF049, parallel data-driven fault
   prediction under online and offline combined cloud computing
   environment), basic research fund of Central University (2015020031),
   West Coast artificial intelligence technology innovation center
   (2019-1-5, 2019-1-6), and the Opening Project of Shanghai Trusted
   Industrial Control Platform (TICPSH202003015-ZC).
CR ALPARONE L, 1994, SIGNAL PROCESS, V39, P33, DOI 10.1016/0165-1684(94)90121-X
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Barnich O, 2009, INT CONF ACOUST SPEE, P945, DOI 10.1109/ICASSP.2009.4959741
   Bochkovskiy A., 2020, ARXIV200410934
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Cheng FC, 2011, IEEE T BROADCAST, V57, P794, DOI 10.1109/TBC.2011.2160106
   Choi SH, 2019, INT J FUZZY LOG INTE, V19, P40, DOI 10.5391/IJFIS.2019.19.1.40
   DENG G, 1993, NUCLEAR SCIENCE SYMPOSIUM & MEDICAL IMAGING CONFERENCE, VOLS 1-3, P1615, DOI 10.1109/NSSMIC.1993.373563
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Eggert C, 2017, IEEE INT CON MULTI, P421, DOI 10.1109/ICME.2017.8019550
   El-Harbawi M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63354-4
   Fang W, 2019, IEEE ACCESS, V7, P28230, DOI 10.1109/ACCESS.2019.2901930
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   HARALICK RM, 1987, IEEE T PATTERN ANAL, V9, P532, DOI 10.1109/TPAMI.1987.4767941
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Huang L., 2015, Comput. Sci.
   Jayaraj V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/690218
   Jintao S., 2019, PROC IEEE PES ASIA P, P1
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kong T, 2016, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.2016.98
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Law H., 2018, PROC EUR C COMPUT VI, P734
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Monnet A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1305
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Radford A., 2018, ARXIV151106434
   Redmon J., 2018, COMPUTER VISION PATT
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Saracin C. G., 2014, ELECTROTEHNICA ELECT, V62, P54
   Shreyamsha Kumar BK, 2013, SIGNAL IMAGE VIDEO P, V7, P1159, DOI 10.1007/s11760-012-0372-7
   Sun W, 2020, INT J EMBED SYST, V12, P371
   Wan SH, 2020, IEEE T MULTIMEDIA, V22, P1756, DOI 10.1109/TMM.2020.2976573
   Wang J., 2020, 2019 IEEE CVF C COMP
   Wang K, 2020, IEEE ACCESS, V8, P193168, DOI 10.1109/ACCESS.2020.3032981
   Wu QF, 2020, IEEE ACCESS, V8, P98716, DOI 10.1109/ACCESS.2020.2997001
   Xia X., 2019, J PHYS C SERIES, V1302, P022080
   Zhang S., 2020, 2020 IEEE CVF C COMP
   Zhang WS, 2019, PROCEDIA COMPUT SCI, V147, P331, DOI 10.1016/j.procs.2019.01.232
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
   Zhengchong M., 2019, LASER OPTOELECTRON P, V55, P111501
   Zhou DX, 2005, IEEE SYS MAN CYBERN, P2224
NR 52
TC 13
Z9 13
U1 6
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2021
VL 109
AR 104159
DI 10.1016/j.imavis.2021.104159
EA MAR 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RZ9BE
UT WOS:000648892600011
DA 2024-07-18
ER

PT J
AU Kumar, D
   Kumar, C
   Shao, M
AF Kumar, Deepak
   Kumar, Chetan
   Shao, Ming
TI Collaborative knowledge distillation for incomplete multi-view action
   prediction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-view; Action prediction; Knowledge distillation; Graph attention
AB Predicting future actions is a key in visual understanding, surveillance, and human behavior analysis. Current methods for video-based prediction are primarily using single-view data, while in the real world multiple cameras and produced videos are readily available, which may potentially benefit the action prediction tasks. However, it may bring up a new challenge: subjects in the videos are more likely to be occluded by objects when captured from different angles, or suffer from signal jittering in transmission. To that end, in this paper we propose a novel student network called Collaborative Knowledge Distillation (CKD) to predict human actions with missing information under a multi-view setting, i.e., incomplete multi-view action prediction. First, we create a graph attention based teacher model capable of fusing multi-view video features for prediction task. Second, we construct a corruption pattern bank (CPB) to simulate various missing segments in multi-view video, and each student model will manage one pattern through privileged information and knowledge distillation. Third, to account for arbitrary missing video segments in real-world, the ensemble of student models will be developed to make a joint prediction. The proposed framework has been extensively evaluated on popular multi-view visual action datasets, including PKU-MMD and NTU-RGB to validate the effectiveness of our approach and to the best of our knowledge action prediction has not yet been explored in the multi-view setting.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Kumar, Deepak; Kumar, Chetan; Shao, Ming] Univ Massachusetts, 285 Old Westport Rd, Dartmouth, MA 02747 USA.
C3 University of Massachusetts System; University Massachusetts Dartmouth
RP Kumar, D (corresponding author), Univ Massachusetts, 285 Old Westport Rd, Dartmouth, MA 02747 USA.
EM dkumar2@umassd.edu
RI Kumar, Deepak/AAC-8168-2021
OI Kumar, Deepak/0000-0002-2650-9636
FU UMass Dartmouth College of Engineering faculty start-up fund, UMass
   Dartmouth's Marine and Undersea Technology (MUST) Research Program -
   Office of Naval Research (ONR) [N00014-20-1-2170]
FX This work is supported in part by the UMass Dartmouth College of
   Engineering faculty start-up fund, UMass Dartmouth's Marine and Undersea
   Technology (MUST) Research Program funded by the Office of Naval
   Research (ONR) under Grant No. N00014-20-1-2170.
CR Aliakbarian MS, 2017, IEEE I CONF COMP VIS, P280, DOI 10.1109/ICCV.2017.39
   Andrew G., 2013, P ICML, P1247
   [Anonymous], 2019, ICLR
   Barsoum E, 2018, IEEE COMPUT SOC CONF, P1499, DOI 10.1109/CVPRW.2018.00191
   Bengio Y., 2014, TECHNICAL REPORT
   Bhattacharyya A, 2018, PROC CVPR IEEE, P4194, DOI 10.1109/CVPR.2018.00441
   Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chowdhury S., 2019, ARXIV PREPRINT ARXIV
   Davenport MA, 2016, IEEE J-STSP, V10, P608, DOI 10.1109/JSTSP.2016.2539100
   Dean J, 2015, ARXIV PREPRINT ARXIV
   Denton E., 2018, ARXIV PREPRINT ARXIV
   Ding Z., 2019, ARXIV ABS 190913123
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Fan ZX, 2019, IEEE T MULTIMEDIA, V21, P363, DOI 10.1109/TMM.2018.2859620
   Farhadi A, 2008, LECT NOTES COMPUT SC, V5302, P154, DOI 10.1007/978-3-540-88682-2_13
   Garcia NC, 2020, IEEE T PATTERN ANAL, V42, P2581, DOI 10.1109/TPAMI.2019.2929038
   Girdhar R, 2017, PROC CVPR IEEE, P3165, DOI 10.1109/CVPR.2017.337
   Hao T, 2017, J VIS COMMUN IMAGE R, V48, P453, DOI 10.1016/j.jvcir.2017.01.019
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Hu WM, 2007, IEEE T IMAGE PROCESS, V16, P1168, DOI 10.1109/TIP.2006.891352
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   King DB, 2015, ACS SYM SER, V1214, P1
   Kitani KM, 2012, LECT NOTES COMPUT SC, V7575, P201, DOI 10.1007/978-3-642-33765-9_15
   Komodakis N., 2016, PROC INT C LEARN REP
   Kong Y., 2018, ARXIV180611230
   Kong Y, 2017, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2017.390
   Kong Y, 2017, IEEE T IMAGE PROCESS, V26, P3028, DOI 10.1109/TIP.2017.2696786
   Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Kumar D, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P3829, DOI 10.1145/3394171.3413531
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Li LH, 2017, AAAI CONF ARTIF INTE, P4133
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li XP, 2019, AAAI CONF ARTIF INTE, P8658
   Li YM, 2019, IEEE T KNOWL DATA EN, V31, P1863, DOI 10.1109/TKDE.2018.2872063
   Liang JW, 2019, IEEE T PATTERN ANAL, V41, P1893, DOI 10.1109/TPAMI.2018.2890628
   Liu C., 2017, ARXIV PREPRINT ARXIV
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu YF, 2019, PROC CVPR IEEE, P7099, DOI [10.1109/CVPR.2019.00726, 10.1109/CVPR.2019.00372]
   Lopez-Paz D., 2015, ARXIV PREPRINT ARXIV
   Luo ZL, 2018, LECT NOTES COMPUT SC, V11218, P174, DOI 10.1007/978-3-030-01264-9_11
   Luong M.-T., 2015, P 2015 C EMP METH NA
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Hoai M, 2014, INT J COMPUT VISION, V107, P191, DOI 10.1007/s11263-013-0683-3
   Mirzadeh S. -I., 2019, ARXIV PREPRINT ARXIV
   Mun J, 2017, AAAI CONF ARTIF INTE, P4233
   Nie FP, 2017, AAAI CONF ARTIF INTE, P2408
   Qadir O, 2011, IEEE C EVOL COMPUTAT, P208
   Rahmani H, 2018, IEEE T PATTERN ANAL, V40, P667, DOI 10.1109/TPAMI.2017.2691768
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Shahroudy A., 2016, IEEE C COMPUTER VISI
   Singh Sanchit, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P48, DOI 10.1109/AVSS.2010.63
   Song SJ, 2017, AAAI CONF ARTIF INTE, P4263
   Sun SL, 2013, NEURAL COMPUT APPL, V23, P2031, DOI 10.1007/s00521-013-1362-6
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Thompson B, 2005, ENCY STAT BEHAV SCI, V42, P2684
   Vapnik V, 2015, J MACH LEARN RES, V16, P2023
   Villegas R., 2017, International Conference on Machine Learning, P3560
   Wang Dongang, 2018, ECCV
   Wang LC, 2019, IEEE I CONF COMP VIS, P6221, DOI 10.1109/ICCV.2019.00631
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang Q, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1828, DOI 10.1145/3394486.3403234
   Wang XH, 2019, PROC CVPR IEEE, P3551, DOI 10.1109/CVPR.2019.00367
   Weinland D, 2006, COMPUT VIS IMAGE UND, V104, P249, DOI 10.1016/j.cviu.2006.07.013
   Xie D, 2018, IEEE T PATTERN ANAL, V40, P1639, DOI 10.1109/TPAMI.2017.2728788
   Xiong W, 2018, PROC CVPR IEEE, P2364, DOI 10.1109/CVPR.2018.00251
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Yuan Y, 2018, IEEE DATA MINING, P717, DOI 10.1109/ICDM.2018.00087
   Zhang C., 2018, ARXIV PREPRINT ARXIV
   Zheng JJ, 2016, IEEE T IMAGE PROCESS, V25, P2542, DOI 10.1109/TIP.2016.2548242
   Zheng JJ, 2013, IEEE I CONF COMP VIS, P3176, DOI 10.1109/ICCV.2013.394
NR 76
TC 5
Z9 5
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2021
VL 107
AR 104111
DI 10.1016/j.imavis.2021.104111
EA FEB 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA RD1DC
UT WOS:000633227000010
OA Bronze
DA 2024-07-18
ER

PT J
AU Happy, SL
   Dantcheva, A
   Bremond, F
AF Happy, S. L.
   Dantcheva, Antitza
   Bremond, Francois
TI Expression recognition with deep features extracted from holistic and
   part-based models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Convolutional neural networks; Part-based
   face representation; Data augmentation
ID REPRESENTATION; NETWORKS; DATABASE; IMAGE
AB Facial expression recognition aims to accurately interpret facial muscle movements in affective states (emotions). Previous studies have proposed holistic analysis of the face, as well as the extraction of features pertained only to specific facial regions towards expression recognition. While classically the latter have shown better performances, we here explore this in the context of deep learning. In particular, this work provides a performance comparison of holistic and part-based deep learning models for expression recognition. In addition, we showcase the effectiveness of skip connections, which allow a network to infer from both low and high-level feature maps. Our results suggest that holistic models outperform part-based models, in the absence of skip connections. Finally, based on our findings, we propose a data augmentation scheme, which we incorporate in a part-based model. The proposed multi-face multi-part (MFMP) model leverages the wide information from part-based data augmentation, where we train the network using the facial parts extracted from different face samples of the same expression class. Extensive experiments on publicly available datasets show a significant improvement of facial expression classification with the proposed MFMP framework. (C) 2020 Published by Elsevier B.V.
C1 [Happy, S. L.; Dantcheva, Antitza; Bremond, Francois] INRIA, Sophia Antipolis, France.
C3 Inria
RP Happy, SL (corresponding author), INRIA, Sophia Antipolis, France.
EM s-l.happy@inria.fr; antitza.dantcheva@inria.fr;
   francois.bremond@inria.fr
FU French Government National Research Agency (ANR) [ANR-17-CE39-0002,
   ANR-19-P3IA-0002]; Agence Nationale de la Recherche (ANR)
   [ANR-19-P3IA-0002, ANR-17-CE39-0002] Funding Source: Agence Nationale de
   la Recherche (ANR)
FX The work of was supported by the French Government National Research
   Agency (ANR) under the Grants ANR-17-CE39-0002 and ANR-19-P3IA-0002.
CR Acharya D, 2018, IEEE COMPUT SOC CONF, P480, DOI 10.1109/CVPRW.2018.00077
   Albanie S., 2016, Proceedings of the 9th ACM International Conference on PErvasive Technologies Related to Assistive Environments
   Alharbi S, 2017, IEEE IPCCC, DOI 10.1109/TCYB.2017.2662199
   [Anonymous], 2014, PROCEDIA IEEE COMPUT, DOI DOI 10.1109/CVPR.2014.233
   [Anonymous], Environmental Psychology & Nonverbal Behavior
   [Anonymous], 2005, Handbook of nonverbal behavior research methods in the affective sciences
   Azzakhnini S, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3152125
   Carcagnì P, 2015, SPRINGERPLUS, V4, DOI 10.1186/s40064-015-1427-3
   Chang FJ, 2018, IEEE INT CONF AUTOMA, P122, DOI 10.1109/FG.2018.00027
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Dhall Abhinav, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P878, DOI 10.1109/FG.2011.5771366
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Ebner NC, 2010, BEHAV RES METHODS, V42, P351, DOI 10.3758/BRM.42.1.351
   Ekman Paul, 1997, What the Face Reveals: Basic and Applied Studies of Spontaneous Expression using the Facial Action Coding System (FACS)
   Fan B, 2018, INT SYM MED INFORM, P227
   Fan XJ, 2017, PATTERN RECOGN, V64, P399, DOI 10.1016/j.patcog.2016.12.002
   Fu JL, 2017, PROC CVPR IEEE, P4476, DOI 10.1109/CVPR.2017.476
   Gao SH, 2015, INT J COMPUT VISION, V111, P365, DOI 10.1007/s11263-014-0750-4
   Gonzalez-Garcia A, 2018, INT J COMPUT VISION, V126, P476, DOI 10.1007/s11263-017-1048-0
   Guo GD, 2013, IEEE T AFFECT COMPUT, V4, P291, DOI 10.1109/T-AFFC.2013.13
   Guo YM, 2016, IEEE T IMAGE PROCESS, V25, P1977, DOI 10.1109/TIP.2016.2537215
   Happy SL, 2015, 2015 EIGHTH INTERNATIONAL CONFERENCE ON ADVANCES IN PATTERN RECOGNITION (ICAPR), P67
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Happy S.L., 2012, Proceedings of the 4th international conference on intelligent human computer interaction (IHCI), P1, DOI [10.1109/ihci.2012.6481802, DOI 10.1109/IHCI.2012.6481802]
   Ng HW, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P443, DOI 10.1145/2818346.2830593
   Huang SL, 2016, PROC CVPR IEEE, P1173, DOI 10.1109/CVPR.2016.132
   Huang XH, 2012, IEEE SIGNAL PROC LET, V19, P243, DOI 10.1109/LSP.2012.2188890
   Jaiswal M., 2016, APPL COMP VIS WACV 2, P1, DOI DOI 10.1109/WACV.2016.7477625
   Jiang B, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.1.013022
   Jung H, 2015, IEEE I CONF COMP VIS, P2983, DOI 10.1109/ICCV.2015.341
   Kervadec Corentin, 2018, BMVC WORKSH
   Kung HW, 2015, IEEE T INF FOREN SEC, V10, P626, DOI 10.1109/TIFS.2015.2390138
   Langner O, 2010, COGNITION EMOTION, V24, P1377, DOI 10.1080/02699930903485076
   Lee SH, 2014, IEEE T AFFECT COMPUT, V5, P340, DOI 10.1109/TAFFC.2014.2346515
   Li HX, 2015, PROC CVPR IEEE, P5325, DOI 10.1109/CVPR.2015.7299170
   Li S, 2017, PROC CVPR IEEE, P2584, DOI 10.1109/CVPR.2017.277
   Li W, 2018, IEEE T PATTERN ANAL, V40, P2583, DOI 10.1109/TPAMI.2018.2791608
   Li Y, 2018, INT C PATT RECOG, P2209, DOI 10.1109/ICPR.2018.8545853
   Lin D, 2015, PROC CVPR IEEE, P1666, DOI 10.1109/CVPR.2015.7298775
   Liu MY, 2014, PROC CVPR IEEE, P1749, DOI 10.1109/CVPR.2014.226
   Liu YY, 2018, PATTERN RECOGN, V84, P251, DOI 10.1016/j.patcog.2018.07.016
   Lopes AT, 2017, PATTERN RECOGN, V61, P610, DOI 10.1016/j.patcog.2016.07.026
   Lou ZY, 2018, IEEE T PATTERN ANAL, V40, P365, DOI 10.1109/TPAMI.2017.2679739
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   M'Sadeq SA, 2015, ANIM NUTR, V1, P1, DOI 10.1016/j.aninu.2015.02.004
   Mao QR, 2017, IEEE T MULTIMEDIA, V19, P861, DOI 10.1109/TMM.2016.2629282
   Meng ZB, 2017, IEEE INT CONF AUTOMA, P558, DOI 10.1109/FG.2017.140
   Minear M, 2004, BEHAV RES METH INS C, V36, P630, DOI 10.3758/BF03206543
   Mollahosseini A, 2016, IEEE WINT CONF APPL
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Moore S, 2011, COMPUT VIS IMAGE UND, V115, P541, DOI 10.1016/j.cviu.2010.12.001
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Peng YX, 2018, IEEE T IMAGE PROCESS, V27, P1487, DOI 10.1109/TIP.2017.2774041
   Pons G, 2018, IEEE T AFFECT COMPUT, V9, P343, DOI 10.1109/TAFFC.2017.2753235
   Ryu B, 2017, IEEE T IMAGE PROCESS, V26, P6006, DOI 10.1109/TIP.2017.2726010
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Shao J, 2017, IEEE T CIRC SYST VID, V27, P613, DOI 10.1109/TCSVT.2016.2593647
   Sikka K, 2016, PROC CVPR IEEE, P5580, DOI 10.1109/CVPR.2016.602
   Sun T, 2017, IMAGE VISION COMPUT, V64, P47, DOI 10.1016/j.imavis.2017.06.003
   Sun WY, 2017, NEUROCOMPUTING, V267, P385, DOI 10.1016/j.neucom.2017.06.050
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Vielzeuf V, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P589, DOI 10.1145/3242969.3264980
   Walecki R, 2017, PROC CVPR IEEE, P5709, DOI 10.1109/CVPR.2017.605
   Wu BF, 2018, IEEE ACCESS, V6, P12451, DOI 10.1109/ACCESS.2018.2805861
   Xie GS, 2017, PATTERN RECOGN, V71, P118, DOI 10.1016/j.patcog.2017.06.002
   Yu ZD, 2015, ICMI'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P435
   Zavan FHD, 2019, PATTERN RECOGN LETT, V123, P104, DOI 10.1016/j.patrec.2018.09.023
   Zhang H, 2016, PROC CVPR IEEE, P1143, DOI 10.1109/CVPR.2016.129
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zhao XY, 2016, LECT NOTES COMPUT SC, V9906, P425, DOI 10.1007/978-3-319-46475-6_27
   Zhong L, 2015, IEEE T CYBERNETICS, V45, P1499, DOI 10.1109/TCYB.2014.2354351
   Zhou YQ, 2017, IEEE IJCNN, P2031
NR 73
TC 7
Z9 7
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104038
DI 10.1016/j.imavis.2020.104038
EA JAN 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Behera, SS
   Mishra, SS
   Mandal, B
   Puhan, NB
AF Behera, Sushree S.
   Mishra, Sapna S.
   Mandal, Bappaditya
   Puhan, Niladri B.
TI Variance-guided attention-based twin deep network for cross-spectral
   periocular recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Attention; Cross-spectral; Convolutional neural network; Heterogeneous;
   Periocular
ID IRIS
AB Periocular region is considered as an important biometric trait due to its ease of collectability and high acceptability in our society. Recent advancements in surveillance applications require infra-red (IR) sensing equipments to be deployed in order to capture the activities occurring in low-light conditions. This gives rise to the problem of matching periocular images in heterogeneous environments as it is difficult to avail large enrollment datasets in IR modality within a short span of time. Although a number of approaches have studied cross-spectral matching of periocular images where a probe IR image is matched against enrolled dataset images in visible (VIS) domain and vice versa, significant amount of challenges still exists for such matching. In this paper, we propose an attention-based twin deep convolutional neural network (CNN) with shared parameters in order to match the periocular images in heterogeneous modality. We introduce a novel variance-guided objective function in conjunction with the attention module in order to guide the network to focus more into the relevant regions of the periocular images. The weights of the twin model based on the new objective function are learned so as to reduce the intra-class variance and to increase the inter-class variance of the cross-spectral image pairs. Ablation studies and experimental results on three publicly available cross-spectral periocular datasets containing images from VIS, near-infrared (NIR), and night vision domains show that the proposed deep network achieves the stateof-the-art recognition performances on all three datasets. (c) 2020 Elsevier B.V. All rights reserved.
C1 [Behera, Sushree S.; Mishra, Sapna S.; Puhan, Niladri B.] Indian Inst Technol Bhubaneswar, Sch Elect Sci, Bhubaneswar, India.
   [Mandal, Bappaditya] Keele Univ, Sch Comp & Mathamat, Keele, Staffs, England.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Bhubaneswar; Keele University
RP Behera, SS (corresponding author), Indian Inst Technol Bhubaneswar, Sch Elect Sci, Bhubaneswar, India.
EM ssb11@iitbbs.ac.in
RI Behera, Sushree/KGL-1587-2024; Mandal, Bappaditya/IAN-4420-2023
OI Mandal, Bappaditya/0000-0001-8417-1410; Mishra,
   Sapna/0000-0002-5304-7131
CR Abaza A, 2013, IMAGE VISION COMPUT, V31, P640, DOI 10.1016/j.imavis.2013.06.001
   Ahuja K, 2017, PATTERN RECOGN LETT, V91, P17, DOI 10.1016/j.patrec.2017.04.002
   Alonso-Fernandez F, 2015, I W BIOMETRIC FORENS
   Alonso-Fernandez F, 2015, IET BIOMETRICS, V4, P74, DOI 10.1049/iet-bmt.2014.0038
   Anderson P, 2018, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2018.00387
   [Anonymous], 2011, P 25 AAAI C ART INT
   [Anonymous], 2015, PROCIEEE CONFCOMPUT
   [Anonymous], PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2018.00745, DOI 10.1109/TPAMI.2019.2913372]
   Behera SS, 2019, LECT NOTES ELECTR EN, V545, P731, DOI 10.1007/978-981-13-5802-9_64
   Behera SS, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P681, DOI 10.1109/BTAS.2017.8272757
   Bharadwaj Samarth., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Blanco-Gonzalo R, 2014, IET BIOMETRICS, V3, P139, DOI 10.1049/iet-bmt.2013.0044
   Bromley J., 1993, International Journal of Pattern Recognition and Artificial Intelligence, V7, P669, DOI 10.1142/S0218001493000339
   Cao Z., 2014, Open Transactions on Information Processing, V1, P20
   Cao ZC, 2016, PATTERN RECOGN LETT, V82, P170, DOI 10.1016/j.patrec.2015.10.018
   Cao ZCX, 2014, IEEE IMAGE PROC, P4967, DOI 10.1109/ICIP.2014.7026006
   Chang L, 2018, FATIGUE FRACT ENG M, V41, P2024, DOI 10.1111/ffe.12839
   Chen JS, 2010, IMAGE VISION COMPUT, V28, P343, DOI 10.1016/j.imavis.2009.06.004
   Garg Rahul Kumar, 2018, 2018 8th International Conference on Communication Systems and Network Technologies (CSNT), P1, DOI 10.1109/CSNT.2018.8820273
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   He R, 2019, IEEE T PATTERN ANAL, V41, P1761, DOI 10.1109/TPAMI.2018.2842770
   Jain A., 2004, T CIRCUITS SYST VIDE, V14
   Jetley S., 2018, P INT C LEARN REPR
   Kumar KK, 2017, 2017 8TH IEEE ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P204, DOI 10.1109/IEMCON.2017.8117193
   Lee MB, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17122933
   Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720
   Li SZ, 2013, IEEE COMPUT SOC CONF, P348, DOI 10.1109/CVPRW.2013.59
   Liu Juncheng., 2017, P IEEE C COMPUTER VI, P792, DOI DOI 10.1109/CVPR.2017.391
   Mnih V, 2014, ADV NEUR IN, V27
   Nalla PR, 2017, IEEE T IMAGE PROCESS, V26, DOI 10.1109/TIP.2016.2616281
   Nanni L, 2017, PATTERN RECOGN, V71, P158, DOI 10.1016/j.patcog.2017.05.025
   PARK M, 2009, P IEEE VEH TECHN C A, P1
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Pillai JK, 2011, IEEE T PATTERN ANAL, V33, P1877, DOI 10.1109/TPAMI.2011.34
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Proença H, 2014, IET BIOMETRICS, V3, P167, DOI 10.1049/iet-bmt.2013.0039
   Raja KB, 2016, IEEE CONF IMAGING SY, P227, DOI 10.1109/IST.2016.7738228
   Rajaram K, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER, COMMUNICATION AND SIGNAL PROCESSING (ICCCSP), P65
   Ramaiah N.P., 2016, International Conference on Biometrics Theory, Applications and Systems (BTAS), P1, DOI [10.1007/s12572-015-0159-5, DOI 10.1007/S12572-015-0159-5)]
   Ren MY, 2017, PROC CVPR IEEE, P293, DOI 10.1109/CVPR.2017.39
   Sequeira A, 2016, 2016 INT C BIOM SPEC, V260, P1, DOI DOI 10.1109/BIOSIG.2016.7736915
   Sequeira A., 2016, CROSSEYED READING CR
   Sequeira AF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P725, DOI 10.1109/BTAS.2017.8272762
   Sharma A, 2014, IEEE IMAGE PROC, P5007, DOI 10.1109/ICIP.2014.7026014
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang F, 2017, PROC CVPR IEEE, P6450, DOI 10.1109/CVPR.2017.683
   Wang K, 2019, PATTERN RECOGN, V86, P85, DOI 10.1016/j.patcog.2018.08.010
   Xu JP, 2010, MANAG SCI ENG MANAG, P1
   Zanlorensi LA, 2020, IET BIOMETRICS, V9, P68, DOI 10.1049/iet-bmt.2019.0116
   Zhang R, 2007, IMAGE VISION COMPUT, V25, P321, DOI 10.1016/j.imavis.2005.10.007
   Zhao ZJ, 2018, IEEE T INF FOREN SEC, V13, P2937, DOI 10.1109/TIFS.2018.2833018
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
NR 54
TC 12
Z9 12
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2020
VL 104
AR 104016
DI 10.1016/j.imavis.2020.104016
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PB2MR
UT WOS:000596161800003
DA 2024-07-18
ER

PT J
AU Zhang, Y
   Wang, NB
   Cai, SB
AF Zhang, Yun
   Wang, Nianbin
   Cai, Shaobin
TI Adversarial sliced Wasserstein domain adaptation networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Transfer learning; Domain adaptation; Image classification; Adversarial
   learning
AB Domain adaptation has become a resounding success in learning a domain agnostic model that performs well on target dataset by leveraging source dataset which has related data distribution. Most of existing works aim at learning domain-invariant features across different domains, but they ignore the discriminability of learned features although it is import to improve the model's performance. This paper proposes a novel adversarial sliced Wasserstein domain adaptation network (AWDAN) that uses a shared encoder and classifier along with a domain classifier to enhance the discriminability of the domain-invariant features. AWDAN utilizes adversarial learning to learn domain-invariant features in feature space and simultaneously minimizes sliced Wasserstein distance in label space to enforce the generated features to be discriminative that guarantees the transfer performance. Meanwhile, we propose to fix the weights of the pre-trained CNN backbone to guarantee its adaptability. We provide theoretical analysis to demonstrate the efficacy of AWDAN. Experimental results show that the proposed AWDAN significantly outperforms existing domain adaptation methods on three visual domain adaptation tasks. Feature visualizations verify that AWDAN learns both domain-invariant and discriminative features, and can achieve domain agnostic feature learning. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zhang, Yun; Wang, Nianbin] Harbin Engn Univ, Coll Comp Sci & Technol, Harbin, Peoples R China.
   [Cai, Shaobin] Foshan Univ, Sch Elect Informat Engn, Foshan, Peoples R China.
C3 Harbin Engineering University; Foshan University
RP Zhang, Y; Wang, NB (corresponding author), Harbin Engn Univ, Coll Comp Sci & Technol, Harbin, Peoples R China.
EM zhangy@hrbeu.edu.cn; wangnianbin@hrbeu.edu.cn
FU National Natural Science Foundation of China [61772152]; National Key
   Research and Development Program of China [2018YFC0806800]; Technical
   Basic Research Project [JSQB2017206C002]; Fundamental Research Funds for
   the Central Universities [3072020CF0605]
FX This work was supported by the National Natural Science Foundation of
   China under Grant (No. 61772152), and National Key Research and
   Development Program of China (No. 2018YFC0806800), and the Technical
   Basic Research Project (No. JSQB2017206C002), and the Fundamental
   Research Funds for the Central Universities under Grant (No.
   3072020CF0605).
CR [Anonymous], 2014, ABS14123474 CORR
   [Anonymous], 2015, INT C MACHINE LEARNI
   [Anonymous], 2005, ADV NEURAL INFORM PR
   Ben-David S, 2010, MACH LEARN, V79, P151, DOI 10.1007/s10994-009-5152-4
   Bonneel N, 2015, J MATH IMAGING VIS, V51, P22, DOI 10.1007/s10851-014-0506-3
   Chen C., 2019, ARXIV191211976
   Chen XY, 2019, PR MACH LEARN RES, V97
   Damodaran BB, 2018, LECT NOTES COMPUT SC, V11208, P467, DOI 10.1007/978-3-030-01225-0_28
   Deng ZJ, 2019, IEEE I CONF COMP VIS, P9943, DOI 10.1109/ICCV.2019.01004
   Deshpande I, 2018, PROC CVPR IEEE, P3483, DOI 10.1109/CVPR.2018.00367
   Gabourie AJ, 2019, ANN ALLERTON CONF, P352, DOI [10.1109/ALLERTON.2019.8919960, 10.1109/allerton.2019.8919960]
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Gretton A, 2012, J MACH LEARN RES, V13, P723
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Gulrajani I, 2017, ADV NEUR IN, V30
   Kolouri S., 2019, INT C LEARN REPR ICL, P1
   Kolouri S, 2016, IEEE T IMAGE PROCESS, V25, P920, DOI 10.1109/TIP.2015.2509419
   Lee CY, 2019, PROC CVPR IEEE, P10277, DOI 10.1109/CVPR.2019.01053
   Liu H, 2019, PR MACH LEARN RES, V97
   Long M., 2016, Advances in neural information processing systems, V29
   Long M., 2017, Proc Mach Learn Res, V70, P2208
   Long MS, 2018, ADV NEUR IN, V31
   Morerio Pietro, 2018, INT C LEARN REPR
   Paszke A, 2019, ADV NEUR IN, V32
   Pei ZY, 2018, AAAI CONF ARTIF INTE, P3934
   Saito K, 2018, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR.2018.00392
   Shen Jian, 2018, 32 AAAI C ART INT
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wu JQ, 2018, LECT NOTES COMPUT SC, V11209, P673, DOI 10.1007/978-3-030-01228-1_40
   Xie S., 2018, P 35 INT C MACHINE L, P5423
   Zellinger Werner, 2017, 5 INT C LEARN REPR I, P2
NR 34
TC 9
Z9 11
U1 2
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103974
DI 10.1016/j.imavis.2020.103974
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700006
DA 2024-07-18
ER

PT J
AU Gupta, A
   Muthiah, SB
AF Gupta, Arpan
   Muthiah, Sakthi Balan
TI Viewpoint constrained and unconstrained Cricket <i>stroke</i>
   localization from untrimmed videos
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Cricket stroke; Action localization; TIoU; C3D; RNN; GRU
ID RECOGNITION
AB In this work, we create two new video datasets for the task of temporal Cricket stroke extraction. The two datasets, namely, the Highlights dataset (with approx. 117K frames) and the Generic dataset (with approx. 1.93M frames), comprise of Cricket telecast videos collected from available online sources and down-sampled to 360x640 at 25FPS. These untrimmed videos have been manually annotated with temporal Cricket strokes considering viewpoint invariance assumption.
   We construct two learning based localization pipelines which are dependent (Constrained) and independent (Unconstrained) of our viewpoint labeling assumption. The Unconstrained pipeline finetunes a pretrained C3D model with GRU training in disconnected and connected modes, while our Constrained pipeline uses boundary detection with first frame classification for generating the temporal localizations. Two post-processing steps, of filtering and boundary correction, are also discussed which help in improving the overall accuracy values.
   A modified evaluation metric, Weighted Mean TIoU, for single category temporal localization problem is also presented and compared with the evaluations of the standard rnAP metric (threshold >= 0.5) on the created dataset. The best weighted mean TIoU of our method was 0.9376 and 0.7145 on the Highlights and Generic test partitions, respectively.
   Moreover, we compare our baseline method with 3D Segment CNNs and Temporal Recurrent Networks (TRNs) which have state of art results on THUMOS 2014 dataset. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Gupta, Arpan; Muthiah, Sakthi Balan] LNM Inst Informat Technol, Dept Comp Sci & Engn, Jaipur 302031, Rajasthan, India.
C3 LNM Institute of Information Technology
RP Gupta, A (corresponding author), LNM Inst Informat Technol, Dept Comp Sci & Engn, Jaipur 302031, Rajasthan, India.
EM arpan@lnmiit.ac.in; sakthi.balan@lnmiit.ac.in
RI Gupta, Arpan/AGS-4594-2022
OI Gupta, Arpan/0000-0002-9417-3169; Muthiah, Sakthi/0000-0003-1817-7173
CR [Anonymous], 2011, 2011 NAT C COMM NCC
   [Anonymous], 2018, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2017.2712608
   [Anonymous], ABS12120402 CORR
   [Anonymous], 2014, ADV COMPUT VIS PATTE, DOI 10.1007/978-3-319-09396-3_9
   Bahdanau D., ABS14090473 CORR
   Baraldi L, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1199, DOI 10.1145/2733373.2806316
   Heilbron FC, 2015, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2015.7298698
   Cho K., ABS14091259 CORR
   Chung J., ABS14123555 CORR
   D'Orazio T, 2010, PATTERN RECOGN, V43, P2911, DOI 10.1016/j.patcog.2010.03.009
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   DeCampos T.E., 2013, MACHINE LEARNING COG
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Ekin A, 2003, IEEE T IMAGE PROCESS, V12, P796, DOI 10.1109/TIP.2003.812758
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gaidon A, 2013, IEEE T PATTERN ANAL, V35, P2782, DOI 10.1109/TPAMI.2013.65
   Gorban A., 2015, THUMOS challenge: Action recognition with a large number of classes
   Graves A., ABS14105401 CORR
   Gupta A, 2020, COMPUTER VISION IMAG, P509, DOI DOI 10.1007/978-981-15-4018-9_45
   Gupta A, 2018, ELEVENTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS AND IMAGE PROCESSING (ICVGIP 2018), DOI 10.1145/3293353.3293415
   Herath S, 2017, IMAGE VISION COMPUT, V60, P4, DOI 10.1016/j.imavis.2017.01.010
   Idrees H., ABS160406182 CORR
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Kay W., ABS170506950 CORR
   King DB, 2015, ACS SYM SER, V1214, P1
   Kolekar MH, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P382, DOI 10.1109/ICVGIP.2008.102
   Kolekar MH, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P1617, DOI 10.1109/ICME.2006.262856
   Kolekar MH, 2011, MULTIMED TOOLS APPL, V54, P27, DOI 10.1007/s11042-010-0544-9
   Kolekar MH, 2010, MULTIMED TOOLS APPL, V47, P545, DOI 10.1007/s11042-009-0337-1
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Kumar A, 2014, INT IM PROC APPL SYS, P1, DOI [10.1109/IPAS.2014.7043264, DOI 10.1109/IPAS.2014.7043264, 10.1080/11263504.2013.845268]
   Kumar Y. S., 2011, 2011 IEEE 15th International Symposium on Consumer Electronics, P222, DOI 10.1109/ISCE.2011.5973819
   Lazarescu M, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P809, DOI 10.1109/ICME.2002.1035905
   Lennon N.J., 2020, BIORXIV, DOI 10.1101/2020.07.20.20157792
   Li WX, 2017, INT J COMPUT VISION, V122, P334, DOI 10.1007/s11263-016-0918-1
   Najafzadeh N, 2015, 2015 INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P310, DOI 10.1109/AISP.2015.7123503
   Nguyen P., ABS171205080 CORR
   Ni BB, 2016, PROC CVPR IEEE, P1020, DOI 10.1109/CVPR.2016.116
   Oneata D., 2014, The lear submission at thumos
   Piergiovanni A., 2018, CVPR
   Sharma R. A., ABS151107607 CORR
   Shou Z, 2016, PROC CVPR IEEE, P1049, DOI 10.1109/CVPR.2016.119
   Simonyan K., 2014, ARXIV14062199, P1
   Teachabarikiti K, 2010, I C CONT AUTOMAT ROB, P2491, DOI 10.1109/ICARCV.2010.5707906
   Thomas G, 2017, COMPUT VIS IMAGE UND, V159, P3, DOI 10.1016/j.cviu.2017.04.011
   Wang J.R., 2003, SURVEY SPORTS VIDEO
   Xu MZ, 2019, IEEE I CONF COMP VIS, P5531, DOI 10.1109/ICCV.2019.00563
   Yuan Z., ABS170404671 CORR
NR 49
TC 5
Z9 5
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2020
VL 100
AR 103944
DI 10.1016/j.imavis.2020.103944
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA MY9GX
UT WOS:000558728800006
DA 2024-07-18
ER

PT J
AU Alemu, LT
   Pelillo, M
AF Alemu, Leulseged Tesfaye
   Pelillo, Marcello
TI Multi-feature fusion for image retrieval using constrained dominant sets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image retrieval; Multi-feature fusion; Diffusion process
ID DESCRIPTORS; DIFFUSION
AB Aggregating different image features for image retrieval has recently shown its effectiveness. While highly effective, though, the question of how to uplift the impact of the best features for a specific query image persists as an open computer vision problem. in this paper, we propose a computationally efficient approach to fuse several hand-crafted and deep features, based on the probabilistic distribution of a given membership score of a constrained cluster in an unsupervised manner. First, we introduce an incremental nearest neighbor (NN) selection method, whereby we dynamically select k-NN to the query. We then build several graphs from the obtained NN sets and employ constrained dominant sets (CDS) on each graph G to assign edge weights which consider the intrinsic manifold structure of the graph, and detect false matches to the query. Finally, we elaborate the computation of feature positive-impact weight (PIW) based on the dispersive degree of the characteristics vector. To this end, we exploit the entropy of a cluster membership-score distribution. In addition, the final NN set bypasses a heuristic voting scheme. Experiments on several retrieval benchmark datasets show that our method can improve the state-of-the-art result. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Alemu, Leulseged Tesfaye; Pelillo, Marcello] Ca Foscari Univ Venice, DAIS, Via Torino 155, Venice, Italy.
   [Pelillo, Marcello] ECLT, S Marco 2940, I-30124 Venice, Italy.
C3 Universita Ca Foscari Venezia
RP Alemu, LT (corresponding author), Ca Foscari Univ Venice, DAIS, Via Torino 155, Venice, Italy.
EM leulseged.alemu@unive.it
CR Alemu LT, 2019, IEEE I CONF COMP VIS, P9854, DOI 10.1109/ICCV.2019.00995
   [Anonymous], 2007, 2007 IEEE COMP SOC C
   Arandjelovic R., 2016, 2016 IEEE C COMP VIS
   Arandjelovic R, 2012, PROC CVPR IEEE, P2911, DOI 10.1109/CVPR.2012.6248018
   Avrithis Y.S., 2012, COMP VIS ECCV 2012 3
   Babenko A, 2014, LECT NOTES COMPUT SC, V8689, P584, DOI 10.1007/978-3-319-10590-1_38
   Bulò SR, 2011, COMPUT VIS IMAGE UND, V115, P984, DOI 10.1016/j.cviu.2010.12.004
   Chehreghani MH, 2016, MACH LEARN, V104, P271, DOI 10.1007/s10994-016-5573-9
   Chum O, 2011, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2011.5995601
   Deng C, 2013, IEEE I CONF COMP VIS, P2600, DOI 10.1109/ICCV.2013.323
   Deselaers T., 2006, 7 WORKH CROSS LANG E, P725
   Gordo A, 2016, LECT NOTES COMPUT SC, V9910, P241, DOI 10.1007/978-3-319-46466-4_15
   Iscen A, 2017, PROC CVPR IEEE, P926, DOI 10.1109/CVPR.2017.105
   Jain R, 2012, HANDBOOK OF ENVIRONMENTAL ENGINEERING ASSESSMENT: STRATEGY, PLANNING, AND MANAGEMENT, P19
   Jegou H, 2008, LECT NOTES COMPUT SC, V5302, P304, DOI 10.1007/978-3-540-88682-2_24
   Jégou H, 2012, IEEE T PATTERN ANAL, V34, P1704, DOI 10.1109/TPAMI.2011.235
   Jégou H, 2014, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2014.417
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Kalantidis Yannis, 2016, Computer Vision - ECCV 2016. 14th European Conference: Workshops. Proceedings: LNCS 9913, P685, DOI 10.1007/978-3-319-46604-0_48
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma L, 2015, IEEE I CONF COMP VIS, P3128, DOI 10.1109/ICCV.2015.358
   Mequanint EZ, 2019, IEEE T PATTERN ANAL, V41, P2438, DOI 10.1109/TPAMI.2018.2858243
   Mopuri Konda Reddy, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P62, DOI 10.1109/CVPRW.2015.7301273
   Nister David, 2006, CVPR
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   Philbin J., 2008, 2008 IEEE COMP SOC C
   Philbin James, 2007, 2007 IEEE COMP SOC C
   Qin D., 2011, 2011 IEEE COMP SOC C
   Radenovic F, 2016, LECT NOTES COMPUT SC, V9905, P3, DOI 10.1007/978-3-319-46448-0_1
   Shen YT, 2018, PROC CVPR IEEE, P2265, DOI 10.1109/CVPR.2018.00241
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Song Bai, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P774, DOI 10.1109/ICCV.2017.90
   Sznitman R, 2013, PROC CVPR IEEE, P3270, DOI 10.1109/CVPR.2013.420
   Tesfaye A.L., 2016, THESIS
   Do TT, 2015, PROC CVPR IEEE, P3556, DOI 10.1109/CVPR.2015.7298978
   Tolias G, 2014, PATTERN RECOGN, V47, P3466, DOI 10.1016/j.patcog.2014.04.007
   Xu J., 2017, ABSI170501247 CORR
   Yang F, 2015, IEEE WINT CONF APPL, P572, DOI 10.1109/WACV.2015.82
   Yang XW, 2009, PROC CVPR IEEE, P357, DOI 10.1109/CVPRW.2009.5206844
   Yang Y, 2012, IEEE T PATTERN ANAL, V34, P723, DOI 10.1109/TPAMI.2011.170
   Zemene E, 2016, INT C PATT RECOG, P2568, DOI 10.1109/ICPR.2016.7900022
   Zemene E, 2016, LECT NOTES COMPUT SC, V9912, P278, DOI 10.1007/978-3-319-46484-8_17
   Zhang ST, 2015, IEEE T PATTERN ANAL, V37, P803, DOI 10.1109/TPAMI.2014.2346201
   Zhang SL, 2013, IEEE I CONF COMP VIS, P1673, DOI 10.1109/ICCV.2013.210
   ZHENG L, 2015, PROC CVPR IEEE, P1741, DOI DOI 10.1109/CVPR.2015.7298783
   Zheng L, 2014, PROC CVPR IEEE, P1947, DOI 10.1109/CVPR.2014.250
   Zheng L, 2013, PROC CVPR IEEE, P1626, DOI 10.1109/CVPR.2013.213
NR 48
TC 9
Z9 9
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103862
DI 10.1016/j.imavis.2019.103862
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Khan, Z
   Yang, J
AF Khan, Zubair
   Yang, Jie
TI Bottom-up unsupervised image segmentation using FC-Dense u-net based
   deep representation clustering and multidimensional feature fusion based
   region merging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Unsupervised image segmentation; Deep learning; Feature fusion; Region
   merging; Image processing
ID SUPERPIXELS
AB Recent advances in system resources provide ease in the applicability of deep learning approaches in computer vision. In this paper, we propose a deep learning-based unsupervised image segmentation approach for natural image segmentation. Image segmentation aims to transform an image into regions, representing various objects in the image. Our method consists of a fully convolutional dense network-based unsupervised deep representation oriented clustering, followed by shallow features based high-dimensional region merging to produce the final segmented image. We evaluate our proposed approach on the BSD300 database and perform a comparison with several classical and some recent deep learning-based unsupervised segmentation methods. The experimental results represent that the proposed method is comparable and confirm the efficacy of the proposed approach.
C1 [Khan, Zubair; Yang, Jie] Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
C3 Shanghai Jiao Tong University
RP Khan, Z; Yang, J (corresponding author), Shanghai Jiao Tong Univ, Inst Image Proc & Pattern Recognit, Shanghai, Peoples R China.
EM zubairkhan@sjtu.edu.cn; jieyang@sjtu.edu.cn
RI Khan, Zubair/X-7459-2019; Yang, Jie/JCD-9867-2023
OI Khan, Zubair/0000-0002-9651-5767; 
FU NSFC, China [61876107, U1803261]; Committee of Science and Technology,
   Shanghai, China [:19510711200]
FX This research is partly supported by NSFC, China (No: 61876107,
   U1803261) and Committee of Science and Technology, Shanghai, China
   (No:19510711200).
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Alcantarilla PF, 2012, LECT NOTES COMPUT SC, V7577, P214, DOI 10.1007/978-3-642-33783-3_16
   [Anonymous], MULTIMED TOOLS APPL
   [Anonymous], 2014, INT C LEARN REPR
   [Anonymous], 2016, ENET DEEP NEURAL NET
   [Anonymous], HUMAN COLOR VISION O
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bearman A, 2016, LECT NOTES COMPUT SC, V9911, P549, DOI 10.1007/978-3-319-46478-7_34
   Chaurasia A, 2017, 2017 IEEE VISUAL COMMUNICATIONS AND IMAGE PROCESSING (VCIP)
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dai JF, 2015, IEEE I CONF COMP VIS, P1635, DOI 10.1109/ICCV.2015.191
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Hasnat MA, 2016, IEEE T PATTERN ANAL, V38, P2255, DOI 10.1109/TPAMI.2015.2513407
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Imamoglu N, 2019, INT CONF ACOUST SPEE, P2192, DOI 10.1109/ICASSP.2019.8682522
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Jégou S, 2017, IEEE COMPUT SOC CONF, P1175, DOI 10.1109/CVPRW.2017.156
   Kanezaki A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1543, DOI 10.1109/ICASSP.2018.8462533
   Kervadec H, 2019, MED IMAGE ANAL, V54, P88, DOI 10.1016/j.media.2019.02.009
   Khan Z, 2019, IET IMAGE PROCESS, V13, P1763, DOI 10.1049/iet-ipr.2018.5976
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/CVPR.2012.6247750, 10.1109/ISRA.2012.6219309]
   Lin D, 2016, PROC CVPR IEEE, P3159, DOI 10.1109/CVPR.2016.344
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Nock R, 2004, IEEE T PATTERN ANAL, V26, P1452, DOI 10.1109/TPAMI.2004.110
   Peng B, 2011, IEEE T IMAGE PROCESS, V20, P3592, DOI 10.1109/TIP.2011.2157512
   Pinheiro PO, 2015, PROC CVPR IEEE, P1713, DOI 10.1109/CVPR.2015.7298780
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shah S., 2018, Stacked U-Nets: A No-Frills Approach to Natural Image Segmentation
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sima HF, 2018, IEEE T SYST MAN CY-S, V48, P354, DOI 10.1109/TSMC.2016.2608831
   Tang M, 2018, PROC CVPR IEEE, P1818, DOI 10.1109/CVPR.2018.00195
   Trémeau A, 2000, IEEE T IMAGE PROCESS, V9, P735, DOI 10.1109/83.841950
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Wei YC, 2017, IEEE T PATTERN ANAL, V39, P2314, DOI 10.1109/TPAMI.2016.2636150
   Xia Xide, 2017, W-net: A deep model for fully unsupervised image segmentation
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Yang J, 2007, LECT NOTES COMPUT SC, V4663, P197
   Yu HS, 2018, NEUROCOMPUTING, V304, P82, DOI 10.1016/j.neucom.2018.03.037
   Zhu HY, 2016, J VIS COMMUN IMAGE R, V34, P12, DOI 10.1016/j.jvcir.2015.10.012
NR 47
TC 17
Z9 21
U1 6
U2 40
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103871
DI 10.1016/j.imavis.2020.103871
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900012
DA 2024-07-18
ER

PT J
AU Shifa, A
   Imtiaz, MB
   Asghar, MN
   Fleury, M
AF Shifa, Amna
   Imtiaz, Muhammad Babar
   Asghar, Mamoona Naveed
   Fleury, Martin
TI Skin detection and lightweight encryption for privacy protection in
   real-time surveillance applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Color-spaces; Human skin detection; Parallel processing; Privacy
   protection; Segmentation; Skin pixel encryption; Selective encryption
ID FACE DETECTION; ADAPTIVE APPROACH; SEGMENTATION; SECURITY; RECOGNITION;
   MODEL
AB An individual's privacy is a significant concern in surveillance videos. Existing research work into the location of individuals on the basis of detecting their skin is focused either on different techniques for detecting human skin on protecting individuals from the consequences of applying such techniques. This paper considers both lines of research and proposes a hybrid scheme for human skin detection and subsequent privacy protection by utilizing color information in dynamically varying illumination and environmental conditions. For those purposes, dynamic and explicit skin-detection approaches are implemented, simultaneously considering multiple colorspaces, i.e. RGB, perceptual (HSV) and orthogonal (YCbCr) color-spaces, and then detecting the human skin by the proposed Combined Threshold Rule (CTR)-based segmentation. Comparative qualitative and quantitative detection results with an average 93.73% accuracy, imply that the proposed scheme achieves considerable accuracy without incurring a training cost. Once skin detection has been performed, the detected skin pixels (including false positives) are encrypted, when standard AES-CFB encryption of skin pixels is shown to be preferable compared to selective encryption of a whole video frame. The scheme preserves the behavior of the subjects within the video. Hence, subsequent image processing and behavior analysis, if required, can be performed by an authorized user. The experimental results are encouraging, as they show that the average encryption time is 8.268 s and the Encryption Space Ratio (ESR) is an average 7.25% for a high definition video (1280 x 720 pixels/frame). A performance comparison in terms of Correct Detection Rate (CDR) showed an average 91.5% for CTB-based segmentation compared to using only one color space for segmentation, such as using RGB with 85.86%, HSV with 80.93% and YCbCr with an average 84.8%, which implies that the proposed method of combining color-space skin identifications has a higher ability to detect skin accurately. Security analysis confirmed that the proposed scheme could be a suitable choice for real-time surveillance applications operating on resource-constrained devices. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Shifa, Amna; Asghar, Mamoona Naveed] Islamia Univ Bahawalpur, Punjab, Pakistan.
   [Imtiaz, Muhammad Babar; Asghar, Mamoona Naveed] Athlone Inst Technol, Software Res Inst, Athlone, Ireland.
   [Fleury, Martin] Univ Suffolk, Sch EAST, Ipswich, Suffolk, England.
C3 Islamia University of Bahawalpur; Technological University of the
   Shannon: Midlands Midwest; University of Suffolk
RP Fleury, M (corresponding author), Univ Suffolk, Sch EAST, Ipswich, Suffolk, England.
EM b.imtiaz@research.ait.ie; masghar@ait.ie; fleum@essex.ac.uk
RI Imtiaz, Muhammad Babar/AAG-2692-2021; Imtiaz, Muhammad
   Babar/JXL-1570-2024
OI Imtiaz, Muhammad Babar/0000-0003-4775-9033; Shifa,
   Amna/0000-0003-0872-6474; Asghar, Mamoona/0000-0001-7460-266X
FU National Research Program for Universities (NRPU-2016)
   [6282/Punjab/NRPU/RD/HEC/2016]; Higher Education Commission (HEC) of
   Pakistan
FX This research paper is produced as part of a government-funded project
   (National Research Program for Universities (NRPU-2016)) with no:
   6282/Punjab/NRPU/R&D/HEC/2016. We appreciate the support of the Higher
   Education Commission (HEC) of Pakistan for this project.
CR Abdelhedi S., 2015, 2 INT AFR EUR C IND, DOI [10.1007/978-3-319-29504-6_2., DOI 10.1007/978-3-319-29504-6_2]
   Agrawal P, 2011, IEEE T CIRC SYST VID, V21, P299, DOI 10.1109/TCSVT.2011.2105551
   Announcing ADVANCED ENCRYPTION STANDARD (AES), 2001, FEDERAL INFORM PROCE
   [Anonymous], 2012, INT J APPL INF SYST
   Asghar MN, 2015, MULTIMED TOOLS APPL, V74, P10215, DOI 10.1007/s11042-014-2160-6
   Asghar MN, 2014, J VIS COMMUN IMAGE R, V25, P487, DOI 10.1016/j.jvcir.2013.12.015
   Auer S, 2013, INT J DIGIT CRIME FO, V5, P1, DOI 10.4018/jdcf.2013070101
   Ban Y, 2014, PATTERN RECOGN, V47, P1573, DOI 10.1016/j.patcog.2013.11.005
   Basilio Jorge Alberto Marcial, 2011, Applications of Mathematics and Computer Engineering. American Conference on Applied Mathematics (AMERICAN-MATH'11). 5th WSEAS International Conference on Computer Engineering and Applications (CEA'11), P123
   Berger A. M., 1998, U.S. Patent, Patent No. [6,067,599, 6067599]
   Bhardwaj S, 2012, PROC TECH, V4, P220, DOI 10.1016/j.protcy.2012.05.033
   Bianco S, 2015, IEEE T IMAGE PROCESS, V24, P4756, DOI 10.1109/TIP.2015.2467209
   Bilal S, 2015, J REAL-TIME IMAGE PR, V10, P371, DOI 10.1007/s11554-012-0305-2
   Brancati N, 2017, COMPUT VIS IMAGE UND, V155, P33, DOI 10.1016/j.cviu.2016.12.001
   Chai D, 1999, IEEE T CIRC SYST VID, V9, P551, DOI 10.1109/76.767122
   Chattopadhyay A, 2007, 2007 IEEE Conference on Computer Vision and Pattern Recognition, P1, DOI [10.1109/CVPR.2007.383413, DOI 10.1109/CVPR.2007.383413]
   Chawla D, 2018, LECT NOTE DATA ENG, V4, P127, DOI 10.1007/978-981-10-4600-1_12
   Cheddad A, 2009, SIGNAL PROCESS, V89, P2465, DOI 10.1016/j.sigpro.2009.04.022
   Cheung SCS, 2008, IEEE IMAGE PROC, P1676, DOI 10.1109/ICIP.2008.4712095
   Çiftçi S, 2018, IEEE T MULTIMEDIA, V20, P68, DOI 10.1109/TMM.2017.2728479
   Cosar S, 2017, IEEE T CIRC SYST VID, V27, P683, DOI 10.1109/TCSVT.2016.2589859
   Dadgostar F, 2006, PATTERN RECOGN LETT, V27, P1342, DOI 10.1016/j.patrec.2006.01.007
   De Dios J.J., 2003, P INT C IM PROC
   Dufaux F, 2010, IEEE INT CON MULTI, P66, DOI 10.1109/ICME.2010.5583552
   Erdélyi A, 2018, MULTIMED TOOLS APPL, V77, P2285, DOI 10.1007/s11042-016-4337-7
   Gonzalez R, 2009, DIGITAL IMAGE PROCES
   Guo Jie, 2014, Journal of Shanghai Jiaotong University (Science), V19, P385, DOI 10.1007/s12204-014-1513-7
   Gupta A., 2016, Pattern Recognition and Image Analysis, V26, P61
   Hoo WL, 2015, INT CONF SYST SIGNAL, P269, DOI 10.1109/IWSSIP.2015.7314228
   Jairath S, 2016, ADV INTELL SYST, V390, P131, DOI 10.1007/978-81-322-2625-3_12
   Jayasinghe D, 2014, PR IEEE COMP DESIGN, P166
   Kakumanu P, 2007, PATTERN RECOGN, V40, P1106, DOI 10.1016/j.patcog.2006.06.010
   Khan JS, 2019, MULTIDIM SYST SIGN P, V30, P943, DOI 10.1007/s11045-018-0589-x
   Kong SG, 2005, COMPUT VIS IMAGE UND, V97, P103, DOI 10.1016/j.cviu.2004.04.001
   Korshunov P, 2014, IEEE IMAGE PROC, P6051, DOI 10.1109/ICIP.2014.7026221
   Luo Y, 2018, INT J INF SECUR, V17, P261, DOI 10.1007/s10207-017-0380-2
   Luo Y, 2017, IET COMPUT VIS, V11, P550, DOI 10.1049/iet-cvi.2016.0295
   Ma XJ, 2017, IEEE T CLOUD COMPUT, V5, P510, DOI 10.1109/TCC.2015.2469651
   Mahmoodi MR, 2017, MULTIMED TOOLS APPL, V76, P9785, DOI 10.1007/s11042-016-3579-8
   Melle A, 2014, IEEE IMAGE PROC, P6046, DOI 10.1109/ICIP.2014.7026220
   Naji SA, 2012, DIGIT SIGNAL PROCESS, V22, P933, DOI 10.1016/j.dsp.2012.05.004
   Pan ZH, 2003, IEEE T PATTERN ANAL, V25, P1552, DOI 10.1109/TPAMI.2003.1251148
   Prasad Sushil K, 2015, TOPICS PARALLEL DIST
   Pujol FA, 2017, ENTROPY-SWITZ, V19, DOI 10.3390/e19010026
   Qureshi F.Z., 2013, INTELL MULTIMED SURV, P67, DOI [10.1007/978-3-642-41512-8_4, DOI 10.1007/978-3-642-41512-8_4]
   Rahman SMM, 2016, FUTURE GENER COMP SY, V55, P344, DOI 10.1016/j.future.2014.10.019
   Padilla-López JR, 2015, EXPERT SYST APPL, V42, P4177, DOI 10.1016/j.eswa.2015.01.041
   Rashwan HA, 2016, INT J INF SECUR, V15, P225, DOI 10.1007/s10207-015-0286-9
   Rescorla E., 1999, 2361 RFC
   Saini M, 2012, ADV MULTIMED, V2012, DOI 10.1155/2012/639649
   Saini M, 2014, MULTIMED TOOLS APPL, V68, P135, DOI 10.1007/s11042-012-1207-9
   Saini M, 2010, IEEE INT CON MULTI, P60, DOI 10.1109/ICME.2010.5583334
   Shaik KB, 2015, PROCEDIA COMPUT SCI, V57, P41, DOI 10.1016/j.procs.2015.07.362
   Shifa A, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051228
   Song W, 2017, MULTIMED TOOLS APPL, V76, P11199, DOI 10.1007/s11042-015-3201-5
   Tan WR, 2012, IEEE T IND INFORM, V8, P138, DOI 10.1109/TII.2011.2172451
   Thorpe C, 2013, IEEE T PATTERN ANAL, V35, P3066, DOI 10.1109/TPAMI.2013.161
   Tripathi V, 2019, J REAL-TIME IMAGE PR, V16, P535, DOI 10.1007/s11554-016-0573-3
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Yan C, 2017, INT CONF SYST INFORM, P165, DOI 10.1109/ICSAI.2017.8248283
   Yogarajah P, 2010, IEEE IMAGE PROC, P2225, DOI 10.1109/ICIP.2010.5652798
   Zafeiriou S, 2015, COMPUT VIS IMAGE UND, V138, P1, DOI 10.1016/j.cviu.2015.03.015
   Zhang DX, 2018, OPTOELECTRON LETT, V14, DOI 10.1007/s11801-018-7199-6
   Zhu Q, 2004, IEEE IMAGE PROC, P1189
   Zuo HQ, 2017, IEEE SIGNAL PROC LET, V24, P289, DOI 10.1109/LSP.2017.2654803
NR 66
TC 18
Z9 18
U1 2
U2 22
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103859
DI 10.1016/j.imavis.2019.103859
PG 25
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900004
DA 2024-07-18
ER

PT J
AU Jia, S
   Guo, GD
   Xu, ZQ
   Wang, QC
AF Jia, Shan
   Guo, Guodong
   Xu, Zhengquan
   Wang, Qiangchang
TI Face presentation attack detection in mobile scenarios: A comprehensive
   evaluation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face presentation attack; Face recognition; Performance evaluation;
   Biometrics
AB The vulnerability of face recognition systems to different presentation attacks has aroused increasing concern in the biometric community. Face presentation detection (PAD) techniques, which aim to distinguish real face samples from spoof artifacts, are the efficient countermeasure. In recent years, various methods have been proposed to address 2D type face presentation attacks, including photo print attack and video replay attack. However, it is difficult to tell which methods perform better for these attacks, especially in practical mobile authentication scenarios, since there is no systematic evaluation or benchmark of the state-of-the-art methods on a common ground (i.e., using the same databases and protocols). Therefore, this paper presents a comprehensive evaluation of several representative face PAD methods (30 in total) on three public mobile spoofing datasets to quantitatively compare the detection performance. Furthermore, the generalization ability of existing methods is tested under cross-database testing scenarios to show the possible database bias. We also summarize meaningful observations and give some insights that will help promote both academic research and practical applications. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Jia, Shan; Xu, Zhengquan] Wuhan Univ, State Key Lab Informat Engn Surveying Mapping & R, Wuhan 430079, Peoples R China.
   [Guo, Guodong; Wang, Qiangchang] West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
C3 Wuhan University; West Virginia University
RP Guo, GD (corresponding author), West Virginia Univ, Lane Dept Comp Sci & Elect Engn, Morgantown, WV 26506 USA.
EM jias@whu.edu.cn; guodong.guo@mail.wvu.edu; xuzq@whu.edu.cn;
   qw0007@mix.wvu.edu
RI Wang, Qiangchang/ABG-7648-2021; Jia, Shan/AAC-6331-2020
OI Wang, Qiangchang/0000-0003-3707-1761; Jia, Shan/0000-0001-7503-8378
FU NSF-CITeR project; Applied Basic Research Program of Wuhan
   [2017010201010114]
FX The authors would like to thank the CMVS at the University of Oulu, the
   Idiap Research Institute, and MSU's PRIP Lab for providing the datasets
   for our evaluation. This work is partly supported by an NSF-CITeR
   project, and Applied Basic Research Program of Wuhan (no.
   2017010201010114).
CR Agarwal A., 2016, INT CONF BIOMETR THE, P1
   Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   Anjos Andre, 2011, P INT JOINT C BIOM I, P1, DOI DOI 10.1109/IJCB.2011.6117503
   [Anonymous], 2015, 2015 13 INT C ENG MO
   [Anonymous], 2016, CMU SCH COMPUT SCI
   [Anonymous], 3010732017 ISOIEC FD
   [Anonymous], 2011, 2011 INT JOINT C BIO
   [Anonymous], IJCB
   [Anonymous], 2014, ABS14085601 CORR
   [Anonymous], 2017, T MACHINE LEARNING A
   [Anonymous], 2016, ARXIV160207360
   [Anonymous], 2017, 2017 5 INT WORKSH BI
   [Anonymous], P 1 INT C AUT CONTR
   Bao W, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON IMAGE ANALYSIS AND SIGNAL PROCESSING, P233
   Bayram S, 2006, J ELECTRON IMAGING, V15, DOI 10.1117/1.2401138
   Bharadwaj S, 2013, IEEE COMPUT SOC CONF, P105, DOI 10.1109/CVPRW.2013.23
   Boulkenafet Z, 2018, IMAGE VISION COMPUT, V77, P1, DOI 10.1016/j.imavis.2018.04.007
   Boulkenafet Z, 2017, IEEE SIGNAL PROC LET, V24, P141, DOI 10.1109/LSP.2016.2630740
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Chingovska I, 2013, INT CONF BIOMETR
   Chingovska I, 2012, P 11 INT C BIOM SPEC
   de Freitas Pereira Tiago, 2013, Computer Vision - ACCV 2012 Workshops. ACCV 2012 International Workshops. Revised Selected Papers, P121, DOI 10.1007/978-3-642-37410-4_11
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   Erdogmus N, 2013, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG 2013)
   Galbally J, 2014, IEEE ACCESS, V2, P1530, DOI 10.1109/ACCESS.2014.2381273
   Galbally J, 2014, INT C PATT RECOG, P1173, DOI 10.1109/ICPR.2014.211
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Jia S, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107032
   Kim I, 2016, IEEE SYS MAN CYBERN, P4299, DOI 10.1109/SMC.2016.7844907
   Komulainen J, 2013, INT CONF BIOMETR
   Komulainen Jukka, 2013, 2013 IEEE 6 INT C BI
   Kose N, 2012, 2012 INTERNATIONAL CONFERENCE ON INFORMATICS, ELECTRONICS & VISION (ICIEV), P1027, DOI 10.1109/ICIEV.2012.6317336
   Lucena O, 2017, LECT NOTES COMPUT SC, V10317, P27, DOI 10.1007/978-3-319-59876-5_4
   Määttä J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Mei X, 2015, 2015 INTERNATIONAL CONFERENCE ON SOCIOLOGY AND PSYCHOLOGY (ICSP 2015), P135
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Nanni L, 2012, EXPERT SYST APPL, V39, P3634, DOI 10.1016/j.eswa.2011.09.054
   Patel K, 2016, IEEE T INF FOREN SEC, V11, P2268, DOI 10.1109/TIFS.2016.2578288
   Patel K, 2015, INT CONF BIOMETR, P98, DOI 10.1109/ICB.2015.7139082
   Peng F, 2019, MULTIMED TOOLS APPL, V78, P26885, DOI 10.1007/s11042-017-4362-1
   Pinto A, 2015, IEEE T INF FOREN SEC, V10, P1025, DOI 10.1109/TIFS.2015.2395139
   Phan QT, 2016, IEEE IMAGE PROC, P404, DOI 10.1109/ICIP.2016.7532388
   Raghavendra R, 2014, EUR SIGNAL PR CONF, P1387
   Ramachandra R, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3038924
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shan Jia, 2019, New Trends in Image Analysis and Processing - ICIAP 2019. ICIAP International Workshops BioFor, PatReCH, e-BADLE, DeepRetail, and Industrial Session. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11808), P39, DOI 10.1007/978-3-030-30754-7_5
   Souza L, 2018, ENG APPL ARTIF INTEL, V72, P368, DOI 10.1016/j.engappai.2018.04.013
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tu XK, 2017, LECT NOTES COMPUT SC, V10635, P686, DOI 10.1007/978-3-319-70096-0_70
   Wang DY, 2014, IEEE T PATTERN ANAL, V36, P550, DOI 10.1109/TPAMI.2013.145
   Wang QC, 2018, IEEE J BIOMED HEALTH, V22, P184, DOI 10.1109/JBHI.2017.2685586
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Yang JW, 2015, IEEE T INF FOREN SEC, V10, P797, DOI 10.1109/TIFS.2015.2403306
   Yang JS, 2013, IEEE GLOB COMM CONF, P1, DOI 10.1109/GLOCOM.2013.6831038
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
NR 58
TC 16
Z9 16
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103826
DI 10.1016/j.imavis.2019.11.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000013
DA 2024-07-18
ER

PT J
AU Yang, JX
   Fang, X
   Zhang, LH
   Lu, HC
   Wei, GH
AF Yang, Jiaxing
   Fang, Xiang
   Zhang, Lihe
   Lu, Huchuan
   Wei, Guohua
TI Salient object detection via double random walks with dual restarts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Salient object detection; Double random walks; Propagation distance;
   Dual restarts
ID REGION DETECTION; ATTENTION; MODEL
AB In this paper, we propose a novel saliency model based on double random walks with dual restarts. Two agents (also known as walkers) respectively representing the foreground and background properties simultaneously walk on a graph to explore saliency distribution. First, we propose the propagation distance measure and use it to calculate the initial distributions of the two agents instead of using geodesic distance. Second, the two agents traverse the graph starting from their own initial distribution, and then interact with each other to correct their travel routes by the restart mechanism, which enforces the agents to return to some specific nodes with a certain probability after every movement. We define the dual restarts to take into account interaction between and weighting of two agents. Extensive evaluations demonstrate that the proposed algorithm performs favorably against other state-of-the-art methods on four benchmark datasets. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Yang, Jiaxing; Fang, Xiang; Zhang, Lihe; Lu, Huchuan] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116023, Peoples R China.
   [Wei, Guohua] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
C3 Dalian University of Technology; Beijing Institute of Technology
RP Zhang, LH (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116023, Peoples R China.
EM zhanglihe@dlut.edu.cn
RI Yang, Jiaxing/HMO-6544-2023; LU, Jia-Hong/X-1395-2019; Xiang,
   Feixiang/AAD-5020-2019
OI Yang, Jiaxing/0000-0003-4760-383X; LU, Jia-Hong/0000-0002-1147-125X;
   Xiang, Feixiang/0000-0001-7881-6032
FU Natural Science Foundation of China (NSFC) [61876202/61829102]; Shanghai
   Aerospace Science and Technology Innovation Foundation [SAST2018-001];
   Dalian Science and Technology Innovation Foundation [2019J12GX039]
FX This work was supported by the Natural Science Foundation of China
   (NSFC) under Grants 61876202/61829102, Shanghai Aerospace Science and
   Technology Innovation Foundation SAST2018-001 and Dalian Science and
   Technology Innovation Foundation 2019J12GX039.
CR Achanta R., 2010, EPFL Technical Report 149300, V6, P15
   [Anonymous], 2018, CoRR
   Borji A., 2012, CVPR, DOI DOI 10.1109/CVPR.2012.6247706
   Borji A, 2012, LECT NOTES COMPUT SC, V7573, P414, DOI 10.1007/978-3-642-33709-3_30
   Borji A, 2012, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2012.6247711
   Chang KY, 2011, IEEE I CONF COMP VIS, P914, DOI 10.1109/ICCV.2011.6126333
   Chen TC, 2009, PROC EUR SOLID-STATE, P1
   Cheng MM, 2013, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2013.193
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cong R., 2018, IEEE TCSVT
   Cong RM, 2016, IEEE SIGNAL PROC LET, V23, DOI 10.1109/LSP.2016.2557347
   Cong RM, 2019, IEEE T CYBERNETICS, V49, P233, DOI 10.1109/TCYB.2017.2771488
   Cong RM, 2018, IEEE T IMAGE PROCESS, V27, P568, DOI 10.1109/TIP.2017.2763819
   Cornia M., 2016, DEEP MULTILEVEL NETW
   Gastal ESL, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964964
   Goferman S, 2010, PROC CVPR IEEE, P2376, DOI DOI 10.1109/CVPR.2010.5539929
   Gong C, 2015, PROC CVPR IEEE, P2531, DOI 10.1109/CVPR.2015.7298868
   Gopalakrishnan V, 2010, IEEE T IMAGE PROCESS, V19, P3232, DOI 10.1109/TIP.2010.2053940
   Hou X., 2007, IEEE C COMP VIS PATT, V1, P1, DOI DOI 10.1109/CVPR.2007.383267
   Huang F, 2017, IEEE T IMAGE PROCESS, V26, P1911, DOI 10.1109/TIP.2017.2669878
   Itti L, 2004, IEEE T IMAGE PROCESS, V13, P1304, DOI 10.1109/TIP.2004.834657
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jiang BW, 2013, IEEE I CONF COMP VIS, P1665, DOI 10.1109/ICCV.2013.209
   Jiang H., 2013, SALIENT OBJECT DETEC
   Jiang HZ, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.110
   Jiang P, 2013, IEEE I CONF COMP VIS, P1976, DOI 10.1109/ICCV.2013.248
   Judd T, 2009, IEEE I CONF COMP VIS, P2106, DOI 10.1109/ICCV.2009.5459462
   Kim J, 2014, PROC CVPR IEEE, P883, DOI 10.1109/CVPR.2014.118
   Kim JS, 2014, IEEE T CIRC SYST VID, V24, P198, DOI 10.1109/TCSVT.2013.2270366
   Kuen J, 2016, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2016.399
   Lee GY, 2016, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2016.78
   Li CY, 2015, PROC CVPR IEEE, P2710, DOI 10.1109/CVPR.2015.7298887
   Li GB, 2016, PROC CVPR IEEE, P478, DOI 10.1109/CVPR.2016.58
   Li X, 2013, IEEE I CONF COMP VIS, P3328, DOI 10.1109/ICCV.2013.413
   Li Y, 2014, PROC CVPR IEEE, P280, DOI 10.1109/CVPR.2014.43
   Liang H.-J., 2019, SALIENTDSO BRINGING
   Liu NA, 2016, PROC CVPR IEEE, P678, DOI 10.1109/CVPR.2016.80
   Liu T, 2011, IEEE T PATTERN ANAL, V33, P353, DOI 10.1109/TPAMI.2010.70
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu Y, 2012, PROC CVPR IEEE, P1067, DOI 10.1109/CVPR.2012.6247785
   Lu Y, 2011, IEEE I CONF COMP VIS, P233, DOI 10.1109/ICCV.2011.6126247
   Ma Y.F., 2003, P 11 ACM INT C MULT, P374, DOI DOI 10.1145/957013.957094
   Mahadevan V., 2012, IEEE COMP SOC C COMP
   Margolin R, 2013, PROC CVPR IEEE, P1139, DOI 10.1109/CVPR.2013.151
   Min Chen, 2011, IEEE INFOCOM 2011 - IEEE Conference on Computer Communications. Workshops, P409, DOI 10.1109/INFCOMW.2011.5928847
   Pan J., 2017, PROC IEEE C COMPUT V
   Pan JT, 2016, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2016.71
   Peng HW, 2017, IEEE T PATTERN ANAL, V39, P818, DOI 10.1109/TPAMI.2016.2562626
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Pingping Zhang, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P202, DOI 10.1109/ICCV.2017.31
   Qin Y, 2015, PROC CVPR IEEE, P110, DOI 10.1109/CVPR.2015.7298606
   Rutishauser U., 2004, P IEEE COMP SOC C CO, DOI DOI 10.1109/CVPR.2004.1315142
   Tong N, 2015, PROC CVPR IEEE, P1884, DOI 10.1109/CVPR.2015.7298798
   Tu WC, 2016, PROC CVPR IEEE, P2334, DOI 10.1109/CVPR.2016.256
   Wang LJ, 2015, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR.2015.7298938
   Wang QS, 2016, PROC CVPR IEEE, P535, DOI 10.1109/CVPR.2016.64
   Wang TT, 2018, PROC CVPR IEEE, P3127, DOI 10.1109/CVPR.2018.00330
   Wang TT, 2016, LECT NOTES COMPUT SC, V9912, P450, DOI 10.1007/978-3-319-46484-8_27
   Wang W, 2010, PROC CVPR IEEE, P2368, DOI 10.1109/CVPR.2010.5539927
   Wei Y., 2012, GEODESIC SALIENCY US
   XU WP, 2015, CVPR, P100
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang C, 2013, PROC CVPR IEEE, P3166, DOI 10.1109/CVPR.2013.407
   Yang C, 2013, IEEE SIGNAL PROC LET, V20, P637, DOI 10.1109/LSP.2013.2260737
   Yuan Y, 2018, IEEE T SYST MAN CY-S, V48, P1885, DOI 10.1109/TSMC.2017.2704278
   Zhang JM, 2015, IEEE I CONF COMP VIS, P1404, DOI 10.1109/ICCV.2015.165
   Zhang LH, 2018, IEEE T IMAGE PROCESS, V27, P987, DOI 10.1109/TIP.2017.2766787
   Zhao R, 2015, PROC CVPR IEEE, P1265, DOI 10.1109/CVPR.2015.7298731
   Zhu WJ, 2014, PROC CVPR IEEE, P2814, DOI 10.1109/CVPR.2014.360
NR 69
TC 6
Z9 6
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103822
DI 10.1016/j.imavis.2019.10.008
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000009
DA 2024-07-18
ER

PT J
AU Quispe, R
   Pedrini, H
AF Quispe, Rodolfo
   Pedrini, Helio
TI Improved person re-identification based on saliency and semantic parsing
   with deep neural network models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Deep learning; Multi-clue guided learning;
   Human semantic parsing; Saliency detection; Convolutional neural
   networks
AB Given a video or an image of a person acquired from a camera, person re-identification is the process of retrieving all instances of the same person from videos or images taken from a different camera with non-overlapping view. This task has applications in various fields, such as surveillance, forensics, robotics, multimedia. In this paper, we present a novel framework, named Saliency-Semantic Parsing Re-Identification (SSP-RelD), for taking advantage of the capabilities of both clues: saliency and semantic parsing maps, to guide a backbone convolutional neural network (CNN) to learn complementary representations that improves the results over the original backbones. The insight of fusing multiple clues is based on specific scenarios in which one response is better than another, thus favoring the combination of them to increase performance. Due to its definition, our framework can be easily applied to a wide variety of networks and, in contrast to other competitive methods, our training process follows simple and standard protocols. We present extensive evaluation of our approach through five backbones and three benchmarks. Experimental results demonstrate the effectiveness of our person re-identification framework. In addition, we combine our framework with re-ranking techniques and compare it against state-of-the-art approaches, achieving competitive results. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Quispe, Rodolfo; Pedrini, Helio] Univ Estadual Campinas, Inst Comp, BR-13083852 Campinas, SP, Brazil.
C3 Universidade Estadual de Campinas
RP Pedrini, H (corresponding author), Univ Estadual Campinas, Inst Comp, BR-13083852 Campinas, SP, Brazil.
EM helio@ic.unicamp.br
FU FAPESP [2017/12646-3]; CNPq [305169/2015-7]
FX The authors are thankful to FAPESP (grant #2017/12646-3) and CNPq (grant
   #305169/2015-7) for their financial support.
CR Borji Ali, 2019, [Computational Visual Media, 计算可视媒体], V5, P117
   Chang XB, 2018, PROC CVPR IEEE, P2109, DOI 10.1109/CVPR.2018.00225
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Goferman S, 2012, IEEE T PATTERN ANAL, V34, P1915, DOI 10.1109/TPAMI.2011.272
   Gong K, 2017, PROC CVPR IEEE, P6757, DOI 10.1109/CVPR.2017.715
   Gong S., 2018, CVPR, P2285, DOI DOI 10.1109/CVPR.2018.00243
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   Hermans Alexander, 2017, ARXIV170307737
   HUANG G, 2017, PROC CVPR IEEE, P2261, DOI DOI 10.1109/CVPR.2017.243
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li X, 2016, IEEE T IMAGE PROCESS, V25, P3919, DOI 10.1109/TIP.2016.2579306
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Lin TY, 2015, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2015.170
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu Z, 2015, J VIS COMMUN IMAGE R, V32, P10, DOI 10.1016/j.jvcir.2015.06.013
   Qian XL, 2017, IEEE I CONF COMP VIS, P5409, DOI 10.1109/ICCV.2017.577
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarfraz MS, 2018, PROC CVPR IEEE, P420, DOI 10.1109/CVPR.2018.00051
   Si JL, 2018, PROC CVPR IEEE, P5363, DOI 10.1109/CVPR.2018.00562
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun Y., 2017, CORR, DOI DOI 10.1002/EP.10350
   Szegedy C., 2017, AAAI, V4, P12
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2016, P IEEE C COMP VIS PA, DOI DOI 10.1109/CVPR.2016.308
   Wang Wenguan, 2017, ARXIV170200871
   Wang Y, 2018, PROC CVPR IEEE, P8042, DOI [10.1109/CVPR.2018.00839, 10.1109/CVPR.2018.00736]
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z., 2017, P IEEE CVF C COMP VI, P1318, DOI [10.1109/CVPR.2017.389, DOI 10.1109/CVPR.2017.389]
   Zhou Q-Y, 2018, ARXIV
NR 35
TC 35
Z9 38
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2019
VL 92
AR 103809
DI 10.1016/j.imavis.2019.07.009
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JW2JO
UT WOS:000502884200004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Benligiray, B
   Topal, C
   Akinlar, C
AF Benligiray, Burak
   Topal, Cihan
   Akinlar, Cuneyt
TI STag: A stable fiducial marker system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fiducial markers; Pose estimation stability; Geometric calibration;
   Mixed reality
ID GENERATION
AB Fiducial markers provide better-defined features than the ones naturally available in the scene. For this reason, they are widely utilized in computer vision applications where reliable pose estimation is required. Factors such as imaging noise and subtle changes in illumination induce jitter on the estimated pose. Jitter impairs robustness in vision and robotics applications, and deteriorates the sense of presence and immersion in AR/VR applications. In this paper, we propose STag, a fiducial marker system that provides stable pose estimation. STag is designed to be robust against jitter factors, thus sustains pose stability better than the existing solutions. This is achieved by utilizing geometric features that can be localized more repeatably. The outer square border of the marker is used for detection and homography estimation. This is followed by a novel homography refinement step using the inner circular border. After refinement, the pose can be estimated stably and robustly across viewing conditions. These features are demonstrated with a comprehensive set of experiments, including comparisons with the state of the art fiducial marker systems. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Benligiray, Burak; Topal, Cihan] Eskisehir Tech Univ, Dept Elect & Elect Engn, Eskisehir, Turkey.
   [Akinlar, Cuneyt] Eskisehir Osmangazi Univ, Dept Comp Engn, Eskisehir, Turkey.
C3 Eskisehir Technical University; Eskisehir Osmangazi University
RP Benligiray, B (corresponding author), Eskisehir Tech Univ, Dept Elect & Elect Engn, Eskisehir, Turkey.
EM bbenligiray@gmail.com
RI TOPAL, CIHAN/ABC-9414-2021
OI TOPAL, CIHAN/0000-0002-6329-5251; AKINLAR, CUNEYT/0000-0002-0961-7790
CR Akinlar C, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412550026
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   *AM, 2016, AM PRIM AIRS 1 CUST
   [Anonymous], MAKE MAGAZINE
   [Anonymous], 2006, BMVC
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE ACM INT S MIX
   [Anonymous], ATL NEXT GEN
   [Anonymous], 2007, COMP VIS WINT WORKSH
   Anqi Xu, 2011, 2011 Canadian Conference on Computer and Robot Vision (CRV), P40, DOI 10.1109/CRV.2011.13
   Bergamasco F, 2016, IEEE T PATTERN ANAL, V38, P2359, DOI 10.1109/TPAMI.2016.2519024
   Bergamasco F, 2011, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2011.5995544
   Calvet L, 2016, PROC CVPR IEEE, P562, DOI 10.1109/CVPR.2016.67
   CONWAY JH, 1986, IEEE T INFORM THEORY, V32, P337, DOI 10.1109/TIT.1986.1057187
   Fiala M, 2005, PROC CVPR IEEE, P590
   Fiala M, 2010, IEEE T PATTERN ANAL, V32, P1317, DOI 10.1109/TPAMI.2009.146
   Fitzgibbon A, 1999, IEEE T PATTERN ANAL, V21, P476, DOI 10.1109/34.765658
   Garrido-Jurado S, 2016, PATTERN RECOGN, V51, P481, DOI 10.1016/j.patcog.2015.09.023
   Garrido-Jurado S, 2014, PATTERN RECOGN, V47, P2280, DOI 10.1016/j.patcog.2014.01.005
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1998, INT J COMPUT VISION, V26, P41, DOI 10.1023/A:1007984508483
   Kato H, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P111, DOI 10.1109/ISAR.2000.880934
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   López-De-Ipiña D, 2002, PERS UBIQUIT COMPUT, V6, P206, DOI 10.1007/s007790200020
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Olson E, 2011, IEEE INT CONF ROBOT
   Ozsen O., 2012, 2012 IEEE International Conference on Emerging Signal Processing Applications, P79, DOI 10.1109/ESPA.2012.6152450
   Quattoni A, 2009, PROC CVPR IEEE, P413, DOI 10.1109/CVPRW.2009.5206537
   Rekimoto J, 1998, 3RD ASIA PACIFIC COMPUTER HUMAN INTERACTION, PROCEEDINGS, P63, DOI 10.1109/APCHI.1998.704151
   Sattar J, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P165, DOI 10.1109/CRV.2007.34
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   SPARR G, 1992, IMAGE VISION COMPUT, V10, P683, DOI 10.1016/0262-8856(92)90013-S
   Uchiyama H, 2011, P IEEE VIRT REAL ANN, P35, DOI 10.1109/VR.2011.5759433
   Zhang X, 2002, INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P97, DOI 10.1109/ISMAR.2002.1115078
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 36
TC 29
Z9 36
U1 3
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 158
EP 169
DI 10.1016/j.imavis.2019.06.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hashemi, M
   Hall, M
AF Hashemi, Mandi
   Hall, Margeret
TI Detecting and classifying online dark visual propaganda
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dark Web; Image classification; Convolutional neural networks; Machine
   learning; Deep learning; Violent extremist organizations
ID WEB PAGES
AB The staggering increase in the amount of information on the World Wide Web (referred to as Web) has made Web page classification essential to retrieve useful information while filtering out unwanted, futile, or harmful contents. This massive information-sharing platform is occasionally abused for propagating extreme and radical ideologies and posing threats to national security and citizens. Detecting the so called dark material has gained more impetus following the recent outbreak of extremist groups and radical ideologies across the Web. The goal of this project, being the first of its own, is to surveil online social networks (OSN) and Web for real-time detection of visual propaganda by violent extremist organizations (VEOs). This is valuable not only for flagging and removing such content from OSN and Web, but also to provide military insight and narrative context inside VEOs. Visual propaganda by VEOs are not only detected, but also further classified based on the type of VEO and focus or intent of the image into hard propaganda, soft propaganda, symbolic propaganda, landscape, and organizational communications. Over 1.2 million images were automatically collected from suspicious OSN accounts and Web pages over a course of four years. Out of which, 120,000 images were manually classified to provide the training data for a convolutional neural network. An overall generalization accuracy of 97,02% and F1of 97.89% were achieved for a binary classification or mere detection of visual VEO propaganda and an overall generalization accuracy of 86,08% and (F1) over bar of 85.76% for an eight-way classification based on the intent of the image. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Hashemi, Mandi] George Mason Univ, Dept Informat Sci & Technol, 4400 Patriot Cir, Fairfax, VA 22030 USA.
   [Hall, Margeret] Univ Nebraska, Coll Informat Sci & Technol, 1110 S 67th St, Omaha, NE 68182 USA.
C3 George Mason University; University of Nebraska System
RP Hashemi, M (corresponding author), George Mason Univ, Dept Informat Sci & Technol, 4400 Patriot Cir, Fairfax, VA 22030 USA.
EM mhashem2@gmu.edu
RI Hall, Margeret/AAI-4181-2020; Hashemi/AAH-8526-2020
OI Hall, Margeret/0000-0003-1049-3040; Hashemi/0000-0003-0212-0228
CR Abbasi A, 2009, COMPUTER, V42, P78, DOI 10.1109/MC.2009.306
   Ahmadi A, 2011, APPL SOFT COMPUT, V11, P1638, DOI 10.1016/j.asoc.2010.05.003
   Al-Rowaily K, 2015, DIGIT INVEST, V14, P53, DOI 10.1016/j.diin.2015.07.006
   Alvari Hamidreza, 2017, Security Informatics, V6, DOI 10.1186/s13388-017-0029-8
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Glenn C., 2019, Timeline: The rise, spread, and fall of the Islamic State
   Hall M, 2018, INT J HUM-COMPUT INT, V34, P895, DOI 10.1080/10447318.2018.1471575
   Hashemi M, 2018, IEEE ACCESS, V6, P70164, DOI 10.1109/ACCESS.2018.2879056
   Hashemi M, 2018, LECT NOTES COMPUT SC, V10923, P594, DOI 10.1007/978-3-319-91716-0_47
   Hinton G. E., 2012, 12070580 ARXIV
   Hu WM, 2007, IEEE T PATTERN ANAL, V29, P1019, DOI 10.1109/TPAMI.2007.1133
   Hu WM, 2011, ACM T MULTIM COMPUT, V7, DOI 10.1145/2037676.2037685
   Kingma D. P., 2014, arXiv
   Kramer S., 2010, ACM SIGKDD WORKSH IN
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Maas A. L., 2013, 27 INT C MACH LEARN, V30
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Nelson RichardAlan., 1996, CHRONOLOGY GLOSSARY
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang M, 2015, IEEE T KNOWL DATA EN, V27, P2564, DOI 10.1109/TKDE.2015.2415497
   Wendlandt Laura., 2017, INT C SOC INF, P323
   Yang C. C., 2010, ACM SIGKDD WORKSH IN
   Yu J, 2012, IEEE T IMAGE PROCESS, V21, P3262, DOI 10.1109/TIP.2012.2190083
   Zeiler M.D., 2013, ARXIV201313013557, P1
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang HJ, 2011, IEEE T NEURAL NETWOR, V22, P1532, DOI 10.1109/TNN.2011.2161999
NR 27
TC 22
Z9 23
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 95
EP 105
DI 10.1016/j.imavis.2019.06.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900009
DA 2024-07-18
ER

PT J
AU Oh, SI
   Kang, HB
AF Oh, Sang-Il
   Kang, Hang-Bong
TI Development and utilization of a disgusting image dataset to understand
   and predict visual disgust
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual disgust; Image dataset; Visual perception; Subjective assessment;
   Machine learning
ID SENSITIVITY
AB When viewers search for images on the internet, they may unexpectedly encounter disgusting or explicit images. As such images may result in mental suffering or trauma, predicting whether images will induce disgust in order to avoid such issues is desirable. However, formal definitions or insights as to what constitutes disgust-inducing visual factors do not exist. Consequently, eliminating disgusting images from retrieval results is still a challenge. In this paper, we collect a large-scale disgust-inducing image dataset containing approximately 60,000 images, each labeled with disgust scores and divided into image categories. Subsequently, using our dataset, we explore various attributes of disgust-inducing images, such as score distributions, categories of disgusting images, and relationships with other visual attributes. Then, we develop a new Convolutional Neural Network (CNN), called DiNet, that uses more than two pre-trained convolutional layers to consider local to global features for image representation. Experimental results indicate that the developed CNN architecture outperforms both feature-based learning models and state-of-the-art deep learning models with an accuracy of 67.58%. Furthermore, disgust maps extracted using the developed model facilitate an understanding of the disgust-inducing regions of images. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Oh, Sang-Il; Kang, Hang-Bong] Catholic Univ Korea, Dept Digital Media, 43-1,Yeoggok 2 Dong, Bucheon Si, Gyeonggi Do, South Korea.
C3 Catholic University of Korea
RP Kang, HB (corresponding author), Catholic Univ Korea, Dept Digital Media, 43-1,Yeoggok 2 Dong, Bucheon Si, Gyeonggi Do, South Korea.
EM nicolas0@catholic.ac.kr; hbkang@catholic.ac.kr
RI Oh, Sang-Il/B-8508-2016
OI Oh, Sang-Il/0000-0002-3972-5119
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF) - Ministry of Science, ICT and future Planning
   [2015R1A2A1A10056304]; Institute for Information AMP; communications
   Technology Promotion (IITP) - Korea government (MSIP) [2017-0-00819]
FX This research was supported by Basic Science Research Program through
   the National Research Foundation of Korea (NRF) funded by the Ministry
   of Science, ICT and future Planning (No. 2015R1A2A1A10056304) and also
   supported by Institute for Information & communications Technology
   Promotion (IITP) grant funded by the Korea government (MSIP) (No.
   2017-0-00819).
CR [Anonymous], 1998, Tech. rep.
   [Anonymous], SENSORY CHANNEL PRES
   [Anonymous], 2004, P 2004WORKSHOP STAT
   [Anonymous], 2016, ARXIV160400600
   [Anonymous], INT C AC SPEECH SIGN
   [Anonymous], 2013, P INT S INF COMM TEC
   Badrinarayanan V., 2015, SEGNET DEEP CONVOLUT
   Chang HW, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925908
   COHEN J, 1960, EDUC PSYCHOL MEAS, V20, P37, DOI 10.1177/001316446002000104
   Curtis V, 2004, P ROY SOC B-BIOL SCI, V271, pS131, DOI 10.1098/rsbl.2003.0144
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Datta R, 2006, LECT NOTES COMPUT SC, V3953, P288, DOI 10.1007/11744078_23
   Deselaers T., 2008, PATTERN RECOGN, P1
   Deza A, 2015, PROC CVPR IEEE, P1818, DOI 10.1109/CVPR.2015.7298791
   Dhar S, 2011, PROC CVPR IEEE, P1657, DOI 10.1109/CVPR.2011.5995467
   Erdem E, 2013, J VISION, V13, DOI 10.1167/13.4.11
   Feng Jiao, 2001, 2001 International Conferences on Info-Tech and Info-Net. Proceedings (Cat. No.01EX479), P378, DOI 10.1109/ICII.2001.983086
   Gerlach AL, 2006, PSYCHOSOM MED, V68, P331, DOI 10.1097/01.psy.0000203284.53066.4b
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Hassner T., 2012, 2012 IEEE COMP SOC C, P1, DOI [DOI 10.1109/CVPRW.2012.6239348, 10.1109/CVPRW.2012.6239348]
   Isola P, 2011, PROC CVPR IEEE, P145, DOI 10.1109/CVPR.2011.5995721
   Khosla A, 2015, IEEE I CONF COMP VIS, P2390, DOI 10.1109/ICCV.2015.275
   Lang PJ, 2008, INT AFFECTIVE PICTUR
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Lu X, 2015, IEEE I CONF COMP VIS, P990, DOI 10.1109/ICCV.2015.119
   Lu X, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P457, DOI 10.1145/2647868.2654927
   Marchesotti L, 2011, IEEE I CONF COMP VIS, P1784, DOI 10.1109/ICCV.2011.6126444
   Mataix-Cols D, 2008, EUR J NEUROSCI, V27, P3050, DOI 10.1111/j.1460-9568.2008.06311.x
   Mohammadi Sadegh, 2015, ADV VIDEO SIGNAL BAS, P1
   Murray N, 2012, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2012, DOI 10.5244/C.26.110
   Murray N, 2012, PROC CVPR IEEE, P2408, DOI 10.1109/CVPR.2012.6247954
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Ordonez V, 2014, LECT NOTES COMPUT SC, V8694, P494, DOI 10.1007/978-3-319-10599-4_32
   Ries CX, 2014, MULTIMED TOOLS APPL, V69, P661, DOI 10.1007/s11042-012-1132-y
   Schienle A, 2005, NEUROSCI LETT, V388, P1, DOI 10.1016/j.neulet.2005.06.025
   Schirmer A, 2005, NEUROREPORT, V16, P635, DOI 10.1097/00001756-200504250-00024
   Simo-Serra E, 2015, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2015.7298688
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Vedaldi A., 2010, P 18 ACM INT C MULT, P1469, DOI DOI 10.1145/1873951.1874249
   Yang JF, 2004, INT C PATT RECOG, P479, DOI 10.1109/ICPR.2004.1333806
   Zhang YC, 2018, ICMLC 2020: 2020 12TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND COMPUTING, P145, DOI 10.1145/3383972.3383975
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhu SC, 2005, INT J COMPUT VISION, V62, P121, DOI 10.1007/s11263-005-4638-1
NR 45
TC 1
Z9 1
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2018
VL 72
BP 24
EP 38
DI 10.1016/j.imavis.2018.03.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GE4DI
UT WOS:000431164100003
DA 2024-07-18
ER

PT J
AU Campos, V
   Jou, B
   Giro-i-Nieto, X
AF Campos, Victor
   Jou, Brendan
   Giro-i-Nieto, Xavier
TI From pixels to sentiment: Fine-tuning CNNs for visual sentiment
   prediction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sentiment; Convolutional Neural Networks; Social multimedia; Fine-tuning
   strategies
AB Visual multimedia have become an inseparable part of our digital social lives, and they often capture moments tied with deep affections. Automated visual sentiment analysis tools can provide a means of extracting the rich feelings and latent dispositions embedded in these media. In this work, we explore how Convolutional Neural Networks (CNNs), a now de facto computational machine learning tool particularly in the area of Computer Vision, can be specifically applied to the task of visual sentiment prediction. We accomplish this through fine-tuning experiments using a state-of-the-art CNN and via rigorous architecture analysis, we present several modifications that lead to accuracy improvements over prior art on a dataset of images from a popular social media platform. We additionally present visualizations of local patterns that the network learned to associate with image sentiment for insight into how visual positivity (or negativity) is perceived by the model. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Campos, Victor] BSC, Barcelona, Catalonia, Spain.
   [Jou, Brendan] Columbia Univ, New York, NY USA.
   [Giro-i-Nieto, Xavier] UPC, Barcelona, Catalonia, Spain.
C3 Columbia University; Universitat Politecnica de Catalunya
RP Campos, V (corresponding author), BSC, Barcelona, Catalonia, Spain.
EM victor.campos@bsc.es; bjou@caa.columbia.edu; xavier.giro@upc.edu
RI Giró-i-Nieto, Xavier/M-5834-2013
OI Giró-i-Nieto, Xavier/0000-0002-9935-5332
FU Severo Ochoa Program's - Spanish Government [SEV2015-0493]; Spanish
   Ministerio de Economia y Competitividad [TIN2015-65316,
   TEC2013-43935-R]; Generalitat de Catalunya [2014-SGR-1051]; (Generalitat
   de Catalunya) through AGAUR office; NVIDIA Corporation; BSC/UPC NVIDIA
   GPU Center of Excellence; European Regional Development Fund (ERDF)
FX This work has been developed in the framework of the BigGraph
   TEC2013-43935-R project, funded by the Spanish Ministerio de Economia y
   Competitividad and the European Regional Development Fund (ERDF). It has
   been supported by the Severo Ochoa Program's SEV2015-0493 grant awarded
   by the Spanish Government, the TIN2015-65316 project by the Spanish
   Ministerio de Economia y Competitividad and contracts 2014-SGR-1051 by
   Generalitat de Catalunya. The Image Processing Group at the UPC is a
   SGR14 Consolidated Research Group recognized and sponsored by the
   (Generalitat de Catalunya) through its AGAUR office. We gratefully
   acknowledge the support of NVIDIA Corporation with the donation of the
   GeForce GTX Titan Z and X used in this work and the support of BSC/UPC
   NVIDIA GPU Center of Excellence.
CR [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], ACM C MULT MM
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ACM C MULT MM
   [Anonymous], INT WORKSH AFF SENT
   [Anonymous], 2011, IEEE C COMP VIS PATT
   [Anonymous], 1998, P IEEE
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], AAAI C ART INT
   [Anonymous], ACM C MULT MM
   [Anonymous], ACM C MULT MM
   [Anonymous], ACM C MULT MM
   [Anonymous], IT C MACH LEARN WORK
   [Anonymous], DEEPSENTIBANK VISUAL
   [Anonymous], 2014, VISUAL SENTIMENT PRE
   [Anonymous], 2014, PROCEED
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2016, ADAPTIVE COMPUTATION
   [Anonymous], 2014, PROC BRIT MACH VIS C
   [Anonymous], 2014, INT C MACH LEARN ICM
   [Anonymous], 1997, AFFECTIVE COMPUTING
   [Anonymous], 2014, EUROPEAN C COMPUTER
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], PREDICTING AD LIKING
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298965
   [Anonymous], 2009, Construction and Analysis of a Large Scale Image Ontology
   Bo Pang, 2008, Foundations and Trends in Information Retrieval, V2, P1, DOI 10.1561/1500000001
   Cabanac M, 2002, BEHAV PROCESS, V60, P69, DOI 10.1016/S0376-6357(02)00078-5
   Girshick R., 2014, P IEEE C COMP VIS PA, P580
   Huang STY, 2014, PROCEEDINGS OF THE 2014 ACM INTERNATIONAL JOINT CONFERENCE ON PERVASIVE AND UBIQUITOUS COMPUTING (UBICOMP'14 ADJUNCT), P235, DOI 10.1145/2638728.2638784
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Plutchik R., 1980, EMOTION PSYCHOEVOLUT
   Spinoulas L, 2015, IEEE COMPUT SOC CONF
   Szegedy C., 2014, PROC INT C LEARNING
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
NR 38
TC 130
Z9 149
U1 4
U2 48
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2017
VL 65
SI SI
BP 15
EP 22
DI 10.1016/j.imavis.2017.01.011
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FJ3GM
UT WOS:000412618500003
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Sun, JY
   Zhong, GQ
   Dong, JY
AF Zhang, Qin
   Sun, Jianyuan
   Zhong, Guoqiang
   Dong, Junyu
TI Random Multi-Graphs: A semi-supervised learning framework for
   classification of high dimensional data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Semi-supervised learning; Graph; Regularization; Randomness; Anchors
   2010 MSC: 00-01, 99-00
AB Currently, high dimensional data processing confronts two main difficulties: inefficient similarity measure and high computational complexity in both time and memory space. Common methods to deal with these two difficulties are based on dimensionality reduction and feature selection. In this paper, we present a different way to solve high dimensional data problems by combining the ideas of Random Forests and Anchor Graph semi-supervised learning. We randomly select a subset of features and use the Anchor Graph method to construct a graph. This process is repeated many times to obtain multiple graphs, a process which can be implemented in parallel to ensure runtime efficiency. Then the multiple graphs vote to determine the labels for the unlabeled data. We argue that the randomness can be viewed as a kind of regularization. We evaluate the proposed method on eight real-world data sets by comparing it with two traditional graph based methods and one state-of-the-art semi-supervised learning method based on Anchor Graph to show its effectiveness. We also apply the proposed method to the subject of face recognition. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zhang, Qin; Sun, Jianyuan; Zhong, Guoqiang; Dong, Junyu] Ocean Univ China, Dept Comp Sci & Technol, 238 Songling Rd, Qingdao 266100, Peoples R China.
   [Zhang, Qin] Agr Univ Qingdao, Dept Sci & Informat, 700 Changcheng Rd, Qingdao 266109, Peoples R China.
C3 Ocean University of China
RP Dong, JY (corresponding author), Ocean Univ China, Dept Comp Sci & Technol, 238 Songling Rd, Qingdao 266100, Peoples R China.
EM zhang_qin1005@163.com; sunjianyuan11@163.com; gqzhong@ouc.edu.cn;
   dongjunyu@ouc.edu.ch
OI Zhang, Qin/0000-0002-9063-6349
FU National Natural Science Foundation Of China (NSFC) [61271405,
   61403353]; International Science & Technology Cooperation Program of
   China (ISTCP) [2014DFA10410]; Open Project Program of the National
   Laboratory of Pattern Recognition (NLPR); Fundamental Research Funds for
   the Central Universities of China
FX This work was supported by the National Natural Science Foundation Of
   China (NSFC) (Nos. 61271405, 61403353), the International Science &
   Technology Cooperation Program of China (ISTCP) (No. 2014DFA10410), the
   Open Project Program of the National Laboratory of Pattern Recognition
   (NLPR) and the Fundamental Research Funds for the Central Universities
   of China. The Titan X GPU used for this research was donated by the
   NVIDIA Corporation. We thank Leon Bullock very much for his great
   assistance in revising the manuscript.
CR Abbasi M, 2015, 2015 INTERNATIONAL CONFERENCE ON 3D VISION, P518, DOI 10.1109/3DV.2015.64
   [Anonymous], 2001, Proceedings of the 18th International Conference on Machine Learning, ICML '01
   [Anonymous], 2000, Technical Report
   Bache K, 2013, UCI machine learning repository
   Belkin M, 2006, J MACH LEARN RES, V7, P2399
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Chandrashekar G, 2014, COMPUT ELECTR ENG, V40, P16, DOI 10.1016/j.compeleceng.2013.11.024
   Chapelle O., 2006, SEMISUPERVISED LEARN
   Chen C., 2004, USING RANDOM FOREST, V110, P24
   Chung F. R., 1997, Spectral Graph Theory, V92, DOI DOI 10.1090/CBMS/092
   Davis JV, 2006, NIPS 2006 WORKSH LEA, P209
   Delalleau Olivier, 2005, AISTAT
   Erhan D, 2010, J MACH LEARN RES, V11, P625
   Fodor I.K., 2008, NEOPLASIA, V7, P475
   Goldberg A. B., 2006, P 1 WORKSH GRAPH BAS, P45, DOI [DOI 10.5555/1654758, DOI 10.3115/1654758.1654769]
   Guoqiang Zhong, 2011, Proceedings of the 2011 IEEE 11th International Conference on Data Mining (ICDM 2011), P1266, DOI 10.1109/ICDM.2011.95
   Hastie T., 2009, The Elements of Statistical Learning
   Liu, 2010, P 27 INT C MACH LEAR, P679, DOI DOI 10.1007/s11263-007-0090-8
   Liu BB, 2009, IET IMAGE PROCESS, V3, P115, DOI 10.1049/iet-ipr.2008.0112
   Liu R., 2006, IEEE GLOBECOM, P1
   Lu J., 2015, IEEE T CIRCUITS SYST, V26, P1
   Lu JW, 2015, IEEE T PATTERN ANAL, V37, P2041, DOI 10.1109/TPAMI.2015.2408359
   Lu JW, 2015, IEEE T INF FOREN SEC, V10, P1371, DOI 10.1109/TIFS.2015.2408431
   Ma L, 2016, PATTERN RECOGN LETT
   Stikic M, 2009, IEEE INT SYM WRBL CO, P85, DOI 10.1109/ISWC.2009.24
   Sun J., 2016, TECHNICAL REPORT
   Tang JH, 2010, IEEE T MULTIMEDIA, V12, P131, DOI 10.1109/TMM.2009.2037373
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Weinberger KQ, 2009, J MACH LEARN RES, V10, P207
   Wu Mingrui, 2007, International Conference on Artificial Intelligence and Statistics, P628
   Ying Y., 2009, Advances in Neural Information Processing Systems, V22
   Zeng X., ACL IJCNLP, P15
   Zhang Q., 2016, TECHNICAL REPORT
   Zhao Y, 2013, IEEE T POWER ELECTR, V28, P1622, DOI 10.1109/TPEL.2012.2211108
   Zhong GQ, 2015, PATTERN RECOGN, V48, P1211, DOI 10.1016/j.patcog.2014.09.025
   Zhong GQ, 2013, PATTERN RECOGN, V46, P1091, DOI 10.1016/j.patcog.2012.10.015
   Zhou DY, 2004, ADV NEUR IN, V16, P321
   Zhu X., 2009, Synth. Lect. Artif. Intell. Mach. Learn, V3, P1, DOI [10.2200/S00196ED1V01Y200906AIM006, DOI 10.2200/S00196ED1V01Y200906AIM006]
   Zhu X., 2003, P 20 INT C MACH LEAR, V3, P58, DOI DOI 10.1109/18.850663
   Zhu X., 2007, International Conference on Machine Learning ICML
   Zhu X., 2005, P 22 INT C MACH LEAR, P1052, DOI DOI 10.1145/1102351.1102484
NR 41
TC 17
Z9 19
U1 0
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 30
EP 37
DI 10.1016/j.imavis.2016.08.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800004
DA 2024-07-18
ER

PT J
AU Zeppelzauer, M
   Schopfhauser, D
AF Zeppelzauer, Matthias
   Schopfhauser, Daniel
TI Multimodal classification of events in social media
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Social events; Social media retrieval; Event classification; Muldmodal
   retrieval
AB A large amount of social media hosted on platforms like Flickr and Instagram is related to social events. The task of social event classification refers to the distinction of event and non-event-related contents as well as the classification of event types (e.g. sports events and concerts). In this paper, we provide an extensive study of textual, visual, as well as multimodal representations for social event classification. We investigate the strengths and weaknesses of the modalities and study the synergy effects between the modalities. Experimental results obtained with our multimodal representation outperform state-of-the-art methods and provide a new baseline for future research. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zeppelzauer, Matthias] St Polten Univ Appl Sci, Media Comp Grp, Matthias Corvinus Str 15, A-3100 St Polten, Austria.
   [Schopfhauser, Daniel] Vienna Univ Technol, Interact Media Syst Grp, Favoritenstr 9-11, A-1040 Vienna, Austria.
C3 St. Polten University of Applied Sciences; Technische Universitat Wien
RP Zeppelzauer, M (corresponding author), St Polten Univ Appl Sci, Media Comp Grp, Matthias Corvinus Str 15, A-3100 St Polten, Austria.
EM m.zeppelzauer@fhstp.ac.at; schopfhauser@ims.tuwien.acat
OI Zeppelzauer, Matthias/0000-0003-0413-4746
CR Agarwal A., 2010, P 2010 C EMPIRICAL M, P1024
   Aizawa A, 2003, INFORM PROCESS MANAG, V39, P45, DOI 10.1016/S0306-4573(02)00021-3
   [Anonymous], 2009, P 17 ACM INT C MULT, DOI DOI 10.1145/1631272.1631371
   [Anonymous], Mallet: A machine learning for language toolkit
   Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Bossard L, 2013, IEEE I CONF COMP VIS, P1193, DOI 10.1109/ICCV.2013.151
   Del Fabro M, 2012, LECT NOTES COMPUT SC, V7131, P630
   Dou W., IEEE VISWEEK WORKSH, P971
   Egozcue JJ, 2003, MATH GEOL, V35, P279, DOI 10.1023/A:1023818214614
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Gupta I., 2013, P MEDIAEVAL 2013 MUL, V1043
   Jégou H, 2010, PROC CVPR IEEE, P3304, DOI 10.1109/CVPR.2010.5540039
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   LUHN HP, 1957, IBM J RES DEV, V1, P309, DOI 10.1147/rd.14.0309
   Manning Christopher D., 2008, INTRO INFORM RETRIEV
   Mattivi R., 2011, Proceedings of the 2011 joint ACM workshop on Modeling and representing events, P7, DOI DOI 10.1145/2072508.2072511
   Nguyen D. D., 2015, Knowledge and Systems Engineering, P79
   Nguyen T.-V., 2014, P INT WORKSH SOC EV
   Nguyen T.-V., 2013, P MEDIAEVAL 2013 MUL, V1043
   Nurwidyantoro A, 2013, INT CONF ICT SMART S, P307
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Papadopoulos S., 2011, P MEDIAEVAL 2011 MUL, V807
   Petkos G., 2012, P 2 ACM INT C MULT R, P231, DOI 10. 1145/2324796.2324825.
   Petkos G., 2014, P INT WORKSH SOC EV
   Reuter T., 2013, P MEDIAEVAL 2013 MUL, V1043
   Reuter T., P MEDIAEVAL 2013 MUL, P18
   SALTON G, 1988, INFORM PROCESS MANAG, V24, P513, DOI 10.1016/0306-4573(88)90021-0
   Salton G., 1971, SMART RETRIEVAL SYST
   Schinas E., 2013, P MEDIAEVAL 2013 MUL, V1043
   Seiffert C, 2010, IEEE T SYST MAN CY A, V40, P185, DOI 10.1109/TSMCA.2009.2029559
   Sivic J, 2005, IEEE I CONF COMP VIS, P370
   Sutanto T., 2015, P MEDIAEVAL 2013 MUL, V1043
   Wang ZY, 2014, ACM T MULTIM COMPUT, V10, DOI 10.1145/2611388
   Zobel J., 1998, SIGIR Forum, V32, P18, DOI 10.1145/281250.281256
NR 35
TC 13
Z9 15
U1 2
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2016
VL 53
BP 45
EP 56
DI 10.1016/j.imavis.2015.12.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DX4YH
UT WOS:000384386500005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Fan, HQ
   Zhou, EJ
AF Fan, Haoqiang
   Zhou, Erjin
TI Approaching human level facial landmark localization by deep learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial landmark localization; Deep learning; Convolutional neural
   network
ID FACE ALIGNMENT
AB In this paper we present our solution to the 300 Faces in the Wild Facial Landmark Localization Challenge. We demonstrate how to achieve very competitive localization performance with a simple deep learning based system. Human study is conducted to show that the accuracy of our system has been very close to human performance. We discuss how this finding would affect our future direction to improve our system. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Fan, Haoqiang; Zhou, Erjin] Megvii Inc, Beijing, Peoples R China.
RP Fan, HQ (corresponding author), Megvii Inc, Beijing, Peoples R China.
EM fhq@megvii.com; zej@megvii.com
CR [Anonymous], 2012, P BRIT MACH VIS C
   [Anonymous], ARXIV150201852
   [Anonymous], ARXIV14121265
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao XD, 2014, INT J COMPUT VISION, V107, P177, DOI 10.1007/s11263-013-0667-3
   Chandra A., DIVIDING CIRCULAR AR
   Chen D, 2013, PROC CVPR IEEE, P3025, DOI 10.1109/CVPR.2013.389
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fan HQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P933, DOI 10.1145/2647868.2654960
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   KAZEMI V, 2014, PROC CVPR IEEE, P1867, DOI [DOI 10.1109/CVPR.2014.241, 10.1109/CVPR.2014.241]
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang Zhiqiang., 2015, 2015 IEEE 12 INT C W, P1, DOI [10.1109/BSN.2015.7299409, DOI 10.1109/FUZZ-IEEE.2015.7337835, DOI 10.1109/BSN.2015.7299409]
   Zhou E., ARXIV150104690
   ZHOU EJ, 2013, COMP VIS WORKSH ICCV, P386
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 31
TC 37
Z9 44
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2016
VL 47
BP 27
EP 35
DI 10.1016/j.imavis.2015.11.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO5LL
UT WOS:000377824500004
DA 2024-07-18
ER

PT J
AU Penne, R
   Raposo, C
   Mertens, L
   Ribbens, B
   Araújo, H
AF Penne, Rudi
   Raposo, Carolina
   Mertens, Luc
   Ribbens, Bart
   Araujo, Helder
TI Investigating new calibration methods without feature detection for TOF
   cameras
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Range cameras; Time of flight; Calibration; General camera models
AB We propose to represent a time-of-flight (TOF) camera by the map of "internal radial. distances" (IRD), associating an intrinsic distance to each pixel, as an alternative for the classic pinhole model. This representation is more general than the perspective model and appears to be a natural concept for 3D reconstruction and other applications of TOF cameras. In this new framework, calibrating a ToF camera comes down to the determination of this IRD map. We show how this can be accomplished by images of flat surfaces, without performing any feature detection. We prove deterministic calibration formulas, using one or more plane images. We also offer a numerical optimization method that in principle needs only one image of a flat surface. This paper has been recommended for acceptance by Peter Sturm. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Penne, Rudi; Mertens, Luc; Ribbens, Bart] Univ Antwerp, Fac Appl Engn, B-2660 Hoboken, Belgium.
   [Penne, Rudi] Univ Antwerp, Dept Math, B-2020 Antwerp, Belgium.
   [Ribbens, Bart] VUB, Dept Mech Engn, Brussels, Belgium.
   [Ribbens, Bart] Univ Antwerp, Lab BioMed Phys, Antwerp, Belgium.
   [Raposo, Carolina; Araujo, Helder] Univ Coimbra, Dept Elect & Comp Engn, P-3000 Coimbra, Portugal.
C3 University of Antwerp; Vrije Universiteit Brussel; University of
   Antwerp; Universidade de Coimbra
RP Penne, R (corresponding author), Univ Antwerp, Fac Appl Engn, Salesianenlaan 90, B-2660 Hoboken, Belgium.
EM rudi.penne@uantwerpen.be; carolinasraposo@gmail.com;
   luc.mertens@uantwerpen.be; bart.ribbens@uantwerpen.be; helder@isr.uc.pt
RI Araujo, Helder/B-3554-2008; Raposo, Carolina/AAA-7879-2021
OI Araujo, Helder/0000-0002-9544-424X; Raposo,
   Carolina/0000-0002-2884-5000; Penne, Rudi/0000-0002-0921-1950; Ribbens,
   Bart/0000-0001-5882-2531
CR [Anonymous], P 13 INT C INT AUT S
   Beder Christian, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P285, DOI 10.1504/IJISTA.2008.021291
   Belhedi A, 2012, IEEE IMAGE PROC, P549, DOI 10.1109/ICIP.2012.6466918
   Fuchs S., 2007, P DAGM DYN3D WORKSH
   Fuchs S., 2008, COMPUTER VISION PATT, P1, DOI DOI 10.1109/CVPR.2008.4587828
   Grzegorzek Marcin, 2013, LECT NOTES COMPUTER, V8200
   Hanning T, 2011, INFORM FUSION, V12, P37, DOI 10.1016/j.inffus.2010.01.006
   Hansard M., 2012, Time-of-Flight Cameras: Principles, Methods and Applications
   Hansard M, 2014, COMPUT VIS IMAGE UND, V121, P108, DOI 10.1016/j.cviu.2014.01.007
   Hertzberg Christoph, 2014, Proceedings of the 11th International Conference on Informatics in Control, Automation and Robotics ICINCO 2014, P568
   Kahlmann T., 2006, ISPRS COMMISSION SYM, P136
   Lenzen Frank, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P25, DOI 10.1007/978-3-642-44964-2_2
   Lindner Marvin, 2008, International Journal of Intelligent Systems Technologies and Applications, V5, P344, DOI 10.1504/IJISTA.2008.021297
   Lindner M, 2006, LECT NOTES COMPUT SC, V4292, P524
   Lindner M, 2010, COMPUT VIS IMAGE UND, V114, P1318, DOI 10.1016/j.cviu.2009.11.002
   Mertens L., 2013, TIME FLIGHT CAMERAS, P353
   Pattinson T., 2011, THESIS
   Penne R, 2015, INT J COMPUT VISION, V113, P81, DOI 10.1007/s11263-014-0768-7
   Penne R, 2013, LECT NOTES COMPUT SC, V8192, P286, DOI 10.1007/978-3-319-02895-8_26
   Schiller I., 2008, P 21 ISPRS C
   Zhengyou Zhang, 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P666, DOI 10.1109/ICCV.1999.791289
NR 21
TC 8
Z9 8
U1 1
U2 18
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2015
VL 43
BP 50
EP 62
DI 10.1016/j.imavis.2015.09.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CY0AU
UT WOS:000366069200005
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Aykut, M
   Ekinci, M
AF Aykut, Murat
   Ekinci, Murat
TI Developing a contactless palmprint authentication system by introducing
   a novel ROI extraction method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Contactless palmprint authentication system; Model-based ROI extraction;
   Palm direction estimation by nonlinear regression; Contactless palm
   database; AAM-based palm segmentation
ID PALM PRINT; RECOGNITION; BIOMETRICS
AB In this paper, we propose a novel contactless palmprint authentication system where the system uses a CCD camera to capture the user's hand at a distance without any restrictions and touching the device. Furthermore, a novel and high performance region of interest (ROD extraction method which makes use of nonlinear regression and palm model to extract the ROls with high success is proposed. Comparative results indicate that the proposed ROI extraction method gives superior performance as compared to the previously proposed point-based approaches. To show the performance of the proposed system, a novel contactless database has also been created. This database includes images captured from the users who present their hands with various hand positions and orientations in cluttered backgrounds. Furthermore, experiments show that the proposed system has achieved a recognition rate of 99.488% and equal error rate of 0.277% on the contactless database of 145 people containing 1752 hand images. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Aykut, Murat; Ekinci, Murat] Karadeniz Tech Univ, Comp Vis & Pattern Recognit Lab, TR-61080 Trabzon, Turkey.
C3 Karadeniz Technical University
RP Aykut, M (corresponding author), Karadeniz Tech Univ, Comp Vis & Pattern Recognit Lab, TR-61080 Trabzon, Turkey.
EM murat_aykut@ktu.edu.tr; ekinci@ktu.edu.tr
RI Ekinci, Murat/A-9653-2012; AYKUT, Murat/AAV-9658-2020; AYKUT,
   Murat/JCE-4977-2023
OI Aykut, Murat/0000-0003-0100-6343
FU National Science Foundation [107E212]
FX The work described in this paper has been supported by National Science
   Foundation under Project No. 107E212.
CR [Anonymous], 2006, P 8 INT C SIGN PROC
   [Anonymous], THESIS TU DENMARK LY
   Aykut M., IEEE 19 C SIGN PROC, P303
   Aykut M, 2013, PATTERN RECOGN LETT, V34, P955, DOI 10.1016/j.patrec.2013.02.016
   Badrinath GS, 2012, FUTURE GENER COMP SY, V28, P287, DOI 10.1016/j.future.2010.11.029
   Chen JS, 2010, IMAGE VISION COMPUT, V28, P343, DOI 10.1016/j.imavis.2009.06.004
   Choras M, 2012, PATTERN ANAL APPL, V15, P73, DOI 10.1007/s10044-011-0248-4
   Connie T, 2005, IMAGE VISION COMPUT, V23, P501, DOI 10.1016/j.imavis.2005.01.002
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Doublet J., 2007, First IEEE International Conference on Biometrics: Theory, Applications, and Systems, BTAS 2007, P1, DOI DOI 10.1109/BTAS.2007.4401935
   Ekinci M, 2007, ELECTRON LETT, V43, P1077, DOI 10.1049/el:20071688
   Ekinci M., 2010, 107E212 SCI TECHN RE
   Ekinci M., 2013, TURK J ELEC IN PRESS
   Han YF, 2007, LECT NOTES COMPUT SC, V4844, P1, DOI 10.1109/COINACOFT.2007.4519091
   Kanhangad V, 2011, IEEE T INF FOREN SEC, V6, P1014, DOI 10.1109/TIFS.2011.2121062
   Kanhangad V, 2011, IEEE T IMAGE PROCESS, V20, P1415, DOI 10.1109/TIP.2010.2090888
   Kumar A, 2011, IEEE T SYST MAN CY C, V41, P743, DOI 10.1109/TSMCC.2010.2089516
   Kumar A, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P583, DOI 10.1109/ICVGIP.2008.73
   Leng L, 2014, 2014 11TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY: NEW GENERATIONS (ITNG), P523, DOI 10.1109/ITNG.2014.18
   Li W, 2012, IEEE T SYST MAN CY C, V42, P1491, DOI 10.1109/TSMCC.2012.2195653
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Michael GKO, 2008, IMAGE VISION COMPUT, V26, P1551, DOI 10.1016/j.imavis.2008.06.010
   Michael GKO, 2012, J VIS COMMUN IMAGE R, V23, P1068, DOI 10.1016/j.jvcir.2012.07.004
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Mika S., 2000, NIPS, V13, P591
   Morales A, 2011, IET COMPUT VIS, V5, P407, DOI 10.1049/iet-cvi.2010.0191
   Michael GKO, 2010, PATTERN RECOGN LETT, V31, P1708, DOI 10.1016/j.patrec.2010.05.021
   Poinsot A, 2009, 2009 FOURTH INTERNATIONAL MULTI-CONFERENCE ON COMPUTING IN THE GLOBAL INFORMATION TECHNOLOGY (ICCGI 2009), P118, DOI 10.1109/ICCGI.2009.25
   Sato T., 2 IAPR AS C PATT REC, P542
   Shang L, 2012, LECT NOTES ARTIF INT, V7390, P479, DOI 10.1007/978-3-642-31576-3_61
   Van Gestel T, 2001, IEEE IJCNN, P2445, DOI 10.1109/IJCNN.2001.938750
   Wu XQ, 2014, PATTERN RECOGN, V47, P3314, DOI 10.1016/j.patcog.2014.04.008
   Zhang D, 2003, IEEE T PATTERN ANAL, V25, P1041, DOI 10.1109/TPAMI.2003.1227981
   Zhang D, 2012, ACM COMPUT SURV, V44, DOI 10.1145/2071389.2071391
   Zhang L, 2012, IMAGE VISION COMPUT, V30, P1043, DOI 10.1016/j.imavis.2012.09.003
   Zhang SW, 2013, OPTIK, V124, P3340, DOI 10.1016/j.ijleo.2012.10.048
   Zhu Y, 2000, INT C PATT RECOG, P797, DOI 10.1109/ICPR.2000.906196
NR 37
TC 21
Z9 24
U1 0
U2 30
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2015
VL 40
BP 65
EP 74
DI 10.1016/j.imavis.2015.05.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CO4YD
UT WOS:000359165900006
OA hybrid
DA 2024-07-18
ER

PT J
AU Zhang, Q
   Wang, YB
   Wang, L
AF Zhang, Qiang
   Wang, Yabin
   Wang, Long
TI Registration of images with affine geometric distortion based on
   Maximally Stable Extremal Regions and phase congruency
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image registration; Affine transformation; Maximally Stable Extremal
   Region; Phase congruency; Point set registration
ID REPRESENTATION; FEATURES; FUSION; SCALE
AB This paper proposes a novel method to address the registration of images with affine transformation. Firstly, the Maximally Stable Extremal Region (MSER) detection method is performed on the reference image and the image to be registered, respectively. And the coarse affine transformation matrix between the two images is estimated by the matched MSER pairs. Two circular regions containing roughly the same image content are also obtained by fitting and normalizing the centroids of the matched MSERs from the two images. Secondly, a scale invariant and approximate affine transformation invariant feature point detection algorithm based on the Gabor filter decomposition and phase congruency is performed on the two coarsely aligned regions, and two feature point sets are achieved, respectively. Finally, the affine transformation matrix between the two feature point sets is obtained by using a probabilistic point set registration algorithm, and the final affine transformation matrix between the reference image and the image to be registered is achieved according to the coarse affine transformation matrix and the affine transformation matrix between the two feature point sets. Several sets of experiments demonstrate that our proposed method performs competitively with the classical scale-invariant feature transform (SIFT) method for images with scale changes, and performs better than the traditional MSER and Affine-SIFT (ASIFT) methods for images with affine distortions. Moreover, the proposed method shows higher computation efficiency and robustness to illumination change than some existing area-based or feature-based methods do. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Zhang, Qiang; Wang, Yabin] Xidian Univ, Key Lab Elect Equipment Struct Design, Minist Educ, Xian 710071, Shaanxi, Peoples R China.
   [Zhang, Qiang; Wang, Yabin] Xidian Univ, Ctr Complex Syst, Sch Mechanoelect Engn, Xian 710071, Shaanxi, Peoples R China.
   [Wang, Long] Peking Univ, Coll Engn, Ctr Syst & Control, Beijing 100871, Peoples R China.
C3 Xidian University; Xidian University; Peking University
RP Zhang, Q (corresponding author), Xidian Univ, Dept Automat Control, POB 183,2 South Taibai Rd, Xian 710071, Shaanxi, Peoples R China.
EM qzhang@xidian.edu.cn
RI long, wang/KGM-0871-2024; Gao, Y./GWZ-3665-2022; Wang,
   Yabin/HLG-3966-2023; Wang, Long/A-7798-2010; wang, long/IZE-1764-2023
OI Wang, Yabin/0000-0001-6816-4552; Wang, Long/0000-0001-5600-8157; 
FU National Natural Science. Foundation of China [61104212]; Fundamental
   Research Funds for the Central Universities [K5051304001, NSIY211416];
   China Scholarship Council [201306965005]
FX This work is supported by the National Natural Science. Foundation of
   China under grant no. 61104212, by the Fundamental Research Funds for
   the Central Universities under grant nos. K5051304001 and NSIY211416,
   and by China Scholarship Council under grant no. 201306965005. The image
   data sets used in Sections 7.1 and 7.3 are downloaded from
   www.robots.ox.ac.uk and are kindly provided by the Department of
   Engineering Science, University of Oxford.
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 2003, DICTA, DOI [10.1177/0734242X0302100404, DOI 10.1177/0734242X0302100404]
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Berthilsson R, 1998, INT C PATT RECOG, P1458, DOI 10.1109/ICPR.1998.711979
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cole-Rhodes AA, 2003, IEEE T IMAGE PROCESS, V12, P1495, DOI 10.1109/TIP.2003.819237
   Cordón O, 2006, IMAGE VISION COMPUT, V24, P525, DOI 10.1016/j.imavis.2006.02.002
   Dai XL, 1999, IEEE T GEOSCI REMOTE, V37, P2351, DOI 10.1109/36.789634
   DANIEL PM, 1961, J PHYSIOL-LONDON, V159, P203, DOI 10.1113/jphysiol.1961.sp006803
   Dengke Fan, 2011, 2011 International Conference on Image Analysis and Signal Processing (IASP 2011), P326, DOI 10.1109/IASP.2011.6109056
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FLUSSER J, 1994, IEEE T GEOSCI REMOTE, V32, P382, DOI 10.1109/36.295052
   GOSHTASBY A, 1986, IEEE T GEOSCI REMOTE, V24, P390, DOI 10.1109/TGRS.1986.289597
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Heather J.P., 2005, 7 INT C INF FUS, P1
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   Hui Lin, 2010, Proceedings of the 2010 3rd International Congress on Image and Signal Processing (CISP 2010), P2184, DOI 10.1109/CISP.2010.5647722
   Ke Y, 2004, PROC CVPR IEEE, P506
   Kim T, 2003, IEEE T GEOSCI REMOTE, V41, P1111, DOI 10.1109/TGRS.2003.811994
   Kimmel R, 2011, IEEE T PATTERN ANAL, V33, P2316, DOI 10.1109/TPAMI.2011.133
   Kovesi P., 1999, Videre, V1
   Kratochvil BE, 2010, J MICROSC-OXFORD, V237, P122, DOI 10.1111/j.1365-2818.2009.03313.x
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu XS, 2008, COMPUT MED IMAG GRAP, V32, P202, DOI 10.1016/j.compmedimag.2007.12.001
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2002, LECT NOTES COMPUT SC, V2350, P128, DOI 10.1007/3-540-47969-4_9
   Morel JM, 2009, SIAM J IMAGING SCI, V2, P438, DOI 10.1137/080732730
   Myronenko A, 2010, IEEE T PATTERN ANAL, V32, P2262, DOI 10.1109/TPAMI.2010.46
   NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Song TC, 2013, IEEE SIGNAL PROC LET, V20, P59, DOI 10.1109/LSP.2012.2229273
   Wang Y.-X., 2014, POWER ENERGY ENG C A, P1, DOI DOI 10.1016/J.BI0CEL.2014.04.001
   Wong A, 2008, PATTERN RECOGN LETT, V29, P173, DOI 10.1016/j.patrec.2007.08.018
   Wong A, 2009, J SIGNAL PROCESS SYS, V54, P89, DOI 10.1007/s11265-008-0202-x
   Xiaoxiang Wang, 2005, Image Analysis & Stereology, V24, P1, DOI 10.5566/ias.v24.p1-7
   [徐婉莹 Xu Wanying], 2011, [中国图象图形学报, Journal of Image and Graphics], V16, P72
   Yang ZW, 1999, IEEE T IMAGE PROCESS, V8, P934, DOI 10.1109/83.772236
   Zhang Q, 2011, PATTERN RECOGN LETT, V32, P1544, DOI 10.1016/j.patrec.2011.06.002
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 49
TC 22
Z9 24
U1 0
U2 36
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2015
VL 36
BP 23
EP 39
DI 10.1016/j.imavis.2015.01.008
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CG2GV
UT WOS:000353093800003
DA 2024-07-18
ER

PT J
AU Zhang, LB
   Qiu, BC
   Yu, XC
   Xu, JD
AF Zhang, Libao
   Qiu, Bingchang
   Yu, Xianchuan
   Xu, Jindong
TI Multi-scale hybrid saliency analysis for region of interest detection in
   very high resolution remote sensing images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Remote sensing image processing; Region of interest;
   Visual attention; Saliency analysis
ID VISUAL-ATTENTION; TOP-DOWN; MODEL
AB Researchers have recently been performing region of interest detection in such applications as object recognition, object segmentation, and adaptive coding. In this paper, a novel region of interest detection model that is based on visually salient regions is introduced by utilizing the frequency and space domain features in very high resolution remote sensing images. First, the frequency domain features that are based on a multi-scale spectrum residual algorithm are extracted to yield intensity features. Next, we extract the color and orientation features by generating space dynamic pyramids. Then, spectral features are obtained by analyzing spectral information content. In addition, a multi-scale feature fusion method is proposed to generate a saliency map. Finally, the detected visual saliency regions are described using adaptive threshold segmentation. Compared with existing models, our model eliminates the background information effectively and highlights the salient detected results with well-defined boundaries and shapes. Moreover, an experimental evaluation indicates promising results from our model with respect to the accuracy of detection results. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Zhang, Libao; Qiu, Bingchang; Yu, Xianchuan; Xu, Jindong] Beijing Normal Univ, Coll Informat Sci & Technol, Beijing 100875, Peoples R China.
C3 Beijing Normal University
RP Zhang, LB (corresponding author), Beijing Normal Univ, Coll Informat Sci & Technol, 19 Xinjiekouwai St, Beijing 100875, Peoples R China.
EM libaozhang@bnu.edu.cn
FU National Natural Science Foundation of China [60602035, 61071103];
   Fundamental Research Funds for the Central Universities [2012LYB50]
FX This work was sponsored by the National Natural Science Foundation of
   China (nos. 60602035 and 61071103) and the Fundamental Research Funds
   for the Central Universities (2012LYB50).
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   [Anonymous], P 5 INT C COMP VIS S
   [Anonymous], 1987, Shifts in selective visual attention: Towards the underlying neural circuitry. matters of intelligence
   [Anonymous], 2007, PROC IEEE C COMPUT V, DOI 10.1109/CVPR.2007.383267
   Baluja S, 1997, ROBOT AUTON SYST, V22, P329, DOI 10.1016/S0921-8890(97)00046-8
   Blaschke T, 2010, ISPRS J PHOTOGRAMM, V65, P2, DOI 10.1016/j.isprsjprs.2009.06.004
   Bruzzone L., 2008, GEOSC REM SENS S 200, V2, P7
   Das S, 2011, IEEE T GEOSCI REMOTE, V49, P3906, DOI 10.1109/TGRS.2011.2136381
   Guo CL, 2010, IEEE T IMAGE PROCESS, V19, P185, DOI 10.1109/TIP.2009.2030969
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hu XY, 2013, IEEE GEOSCI REMOTE S, V10, P466, DOI 10.1109/LGRS.2012.2210188
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L., 1999, SPIE human vision and electronic imaging IV (HVEIaAZ99), V3644, P373
   Itti L, 2000, MODELS BOTTOM TOP VI
   Khan JF, 2009, APPL OPTICS, V48, P464, DOI 10.1364/AO.48.000464
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Liu ZG, 2012, IEEE T GEOSCI REMOTE, V50, P1955, DOI 10.1109/TGRS.2011.2169075
   MILANESE R, 1995, OPT ENG, V34, P2428, DOI 10.1117/12.205668
   Oliva A, 2003, IEEE IMAGE PROC, P253, DOI 10.1109/icip.2003.1246946
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Persello C, 2010, IEEE T GEOSCI REMOTE, V48, P1232, DOI 10.1109/TGRS.2009.2029570
   Sedaghat A, 2011, IEEE T GEOSCI REMOTE, V49, P4516, DOI 10.1109/TGRS.2011.2144607
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   Sun J., 2010, PROG FISH SCI, P1
   Tian MH, 2008, IEEE IJCNN, P321, DOI 10.1109/IJCNN.2008.4633811
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wolfe JM, 2003, J EXP PSYCHOL HUMAN, V29, P483, DOI 10.1037/0096-1523.29.2.483
   Wu D, 2012, APPL OPTICS, V51, P1742, DOI 10.1364/AO.51.001742
   Yi L, 2012, IEEE T GEOSCI REMOTE, V50, P4062, DOI 10.1109/TGRS.2012.2187789
   Zhang LB, 2013, GISCI REMOTE SENS, V50, P112, DOI 10.1080/15481603.2013.778553
NR 32
TC 23
Z9 26
U1 0
U2 20
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2015
VL 35
BP 1
EP 13
DI 10.1016/j.imavis.2014.12.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CE4JD
UT WOS:000351796000001
DA 2024-07-18
ER

PT J
AU Miraldo, P
   Araujo, H
AF Miraldo, Pedro
   Araujo, Helder
TI Generalized essential matrix: Properties of the singular value
   decomposition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Generalized epipolar geometry; Relative pose; Singular value
   decomposition; Rigid transformation of lines
AB When considering non-central imaging devices, the computation of the relative pose requires the estimation of the rotation and translation that transform the 3D lines from one coordinate system to the second. In most of the state-of-the-art methods, this transformation is estimated by the computing a 6 x 6 matrix, known as the generalized essential matrix. To allow a better understanding of this matrix, we derive some properties associated with its singular value decomposition. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Miraldo, Pedro] Univ Coimbra, Inst Syst & Robot, P-3000 Coimbra, Portugal.
   Univ Coimbra, Dept Elect & Comp Engn, P-3000 Coimbra, Portugal.
C3 Universidade de Coimbra; Universidade de Coimbra
RP Miraldo, P (corresponding author), Univ Coimbra, Inst Syst & Robot, P-3000 Coimbra, Portugal.
EM miraldo@isr.uc.pt; helder@isr.uc.pt
RI Miraldo, Pedro/C-2929-2016; Araujo, Helder/B-3554-2008; Miraldo,
   Pedro/JCD-8915-2023
OI Miraldo, Pedro/0000-0002-8551-2448; Araujo, Helder/0000-0002-9544-424X; 
FU project A "Surgery and Diagnosis Assisted by Computer Using Images," -
   QREN Programme "Mais Centro"; European Fund for Regional Development
   (FEDER) [SCT 2011 02 027 4824]; Portuguese Science Foundation through
   PIDDAC; FEDER through COMPETE Operational Programme Competitive Factors
   [FCT/PTDC/EIAEIA/122454/2010]
FX This work was supported in part by the project A "Surgery and Diagnosis
   Assisted by Computer Using Images," funded by the QREN Programme "Mais
   Centro" with financing from the European Fund for Regional Development
   (FEDER), under Grant SCT 2011 02 027 4824 and in part by the Portuguese
   Science Foundation through PIDDAC and FEDER through COMPETE Operational
   Programme Competitive Factors under Project FCT/PTDC/EIAEIA/122454/2010.
CR [Anonymous], 2004, An invitation to 3-D vision
   Faugeras O. D., INT J COMPUTER VISIO
   Fischler M. A., COMM ACM
   Grossberg D., INT J COMPUTER VISIO
   Hartley R.I., 2007, IEEE T PATTERN ANAL
   Horn B. K. P., INT J COMPUTER VISIO
   Huang T., 1989, IEEE Trans. Pattern Analysis and Machine Intelligence
   Kim J.-S., J MATH IMAGING VIS J
   Kruppa E., SITZUNGSBERICHTE MAT
   Kukelova Z., IEEE T PATTERN ANAL
   Lhuillier M., IEEE P INT C PATT RE
   Li H., IEEE P COMP VIS PATT
   Nister D., IEEE P COMP VIS PATT
   Nister D., 2004, IEEE Trans. Pattern Analysis and Machine Intelligence
   Nister D., IEEE P INT C COMP VI
   Philip J., PHOTOGRAMMETRIC RECO
   Pless R., IEEE P COMP VIS PATT
   Schweighofer G., P BRIT MACH VIS C BM
   Stewenius H., IMAGE VISION COMPUTI
   Sturm P., IEEE P COMP VIS PATT
   Van Loan C.F., 1996, J HOPKINS STUDIES MA
   Wallner J., 2001, MATH VISUAL
NR 22
TC 4
Z9 4
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2015
VL 34
BP 45
EP 50
DI 10.1016/j.imavis.2014.11.003
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA5OB
UT WOS:000348956600005
DA 2024-07-18
ER

PT J
AU Terzakis, G
   Culverhouse, PF
   Bugmann, G
   Sutton, R
AF Terzakis, George
   Culverhouse, Phil F.
   Bugmann, Guido
   Sutton, Robert
TI Fitting multiple projective models using clustering-based Markov chain
   Monte Carlo inference
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multiple model fitting; Clustering; Markov chain Monte Carlo; Two-view
   geometry; Markov random field
ID ALGORITHMS
AB An algorithm for fitting multiple models that characterize the projective relationships between point-matches in pairs of (or single) images is proposed herein. Specifically, the problem of estimating multiple algebraic varieties that relate the projections of 3 dimensional (3D) points in one or more views is predominantly turned into a problem of inference over a Markov random field (MRF) using labels that include outliers and a set of candidate models estimated from subsets of the point matches. Thus, not only the MRF can trivially incorporate the errors of fit in singleton factors, but the sheer benefit of this approach is the ability to consider the interactions between data points. The proposed method (CSAMMFIT) refines the outlier posterior over the course of consecutive inference sweeps, until the process settles at a local minimum. The inference "engine" employed is a Markov Chain Monte Carlo (MCMC) method which samples new labels from clusters of data points. The advantage of this technique pertains to the fact that cluster formation can be manipulated to favor common label assignments between points related to each other by image based criteria. Moreover, although CSAMMFIT uses a Potts-like pairwise factor, the inference algorithm allows for arbitrary prior formulations, thereby accommodating the needs for more elaborate feature based constraints. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Terzakis, George; Culverhouse, Phil F.; Bugmann, Guido] Univ Plymouth, Ctr Robot & Neural Syst, Plymouth PL4 8AA, Devon, England.
   [Sutton, Robert] Univ Plymouth, Sch Marine Sci & Engn, Plymouth PL4 8AA, Devon, England.
C3 University of Plymouth; University of Plymouth
RP Terzakis, G (corresponding author), Univ Plymouth, Room B106,Portland Sq, Plymouth PL4 8AA, Devon, England.
EM Georgios.Terzakis@plymouth.ac.uk; P.Culverhouse@plymouth.ac.uk;
   G.Bugmann@plymouth.ac.uk; R.Sutton@plymouth.ac.uk
OI Culverhouse, Phil/0000-0002-7586-6496
FU EPSRC [EP/I012923/1] Funding Source: UKRI
CR Aharon M., 2005, PROC SPARS, V5, P9, DOI DOI 10.1109/TSP.2006.881199
   [Anonymous], 2007, ISPRS WORKSHOP LASER
   [Anonymous], 2007, C-J CARBON RES
   Auvinen H., 2009, SCALE INVARIANT FEAT
   Ayvaci Alper., 2010, Advances_in_neural_information_processing systems, P100
   Barbu A, 2005, IEEE T PATTERN ANAL, V27, P1239, DOI 10.1109/TPAMI.2005.161
   BELL BM, 1993, IEEE T AUTOMAT CONTR, V38, P294, DOI 10.1109/9.250476
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Black M.J., 1998, FRAMEWORK MODELING A, P660
   BOUFAMA B, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P1030, DOI 10.1109/ICCV.1995.466821
   Chum O, 2005, PROC CVPR IEEE, P772
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hartley R., 2003, Multiple View Geometry in Computer Vision, V2
   Hartley RI, 1997, INT J COMPUT VISION, V22, P125, DOI 10.1023/A:1007936012022
   Isack H, 2012, INT J COMPUT VISION, V97, P123, DOI 10.1007/s11263-011-0474-7
   LEE DT, 1980, INT J COMPUT INF SCI, V9, P219, DOI 10.1007/BF00977785
   Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818
   Ma Y., 2004, INVITATION 3D VISION
   SEMPLE JG, 1952, ALGEBRAIC PROJECTIVE
   Toldo R, 2008, LECT NOTES COMPUT SC, V5302, P537, DOI 10.1007/978-3-540-88682-2_41
   Tong WS, 2004, IEEE T PATTERN ANAL, V26, P1167, DOI 10.1109/TPAMI.2004.72
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   Zuliani M., 2005, IM PROC 2005 ICIP 20
NR 23
TC 0
Z9 1
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2015
VL 33
BP 15
EP 25
DI 10.1016/j.imavis.2014.10.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AZ5KY
UT WOS:000348261100002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Redondo-Cabrera, C
   López-Sastre, RJ
   Acevedo-Rodríguez, J
   Maldonado-Bascón, S
AF Redondo-Cabrera, Carolina
   Lopez-Sastre, Roberto J.
   Acevedo-Rodriguez, Javier
   Maldonado-Bascon, Saturnino
TI Recognizing in the depth: Selective 3D Spatial Pyramid Matching Kernel
   for object and scene categorization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D Spatial Pyramid Matching Kernel; Object recognition; Scene
   classification; Point clouds; Depth images
ID CLASSIFICATION; MODEL; SHAPE
AB This paper proposes a novel approach to recognize object and scene categories in depth images. We introduce a Bag of Words (BoW) representation in 3D, the Selective 3D Spatial Pyramid Matching Kernel (3DSPMK). It starts quantizing 3D local descriptors, computed from point clouds, to build a vocabulary of 3D visual words. This codebook is used to build the 3DSPMK, which starts partitioning a working volume into fine sub-volumes, and computing a hierarchical weighted sum of histogram intersections of visual words at each level of the 3D pyramid structure. With the aim of increasing both the classification accuracy and the computational efficiency of the kernel, we propose two selective hierarchical volume decomposition strategies, based on representative and discriminative sub-volume selection processes, which drastically reduce the pyramid to consider. Results on different RGBD datasets show that our approaches obtain state-of-the-art results for both object recognition and scene categorization. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Redondo-Cabrera, Carolina; Lopez-Sastre, Roberto J.; Acevedo-Rodriguez, Javier; Maldonado-Bascon, Saturnino] Univ Alcala de Henares, Dept Signal Theory & Commun, GRAM, Alcala De Henares 28805, Spain.
C3 Universidad de Alcala
RP Redondo-Cabrera, C (corresponding author), Univ Alcala de Henares, Polytech Sch, Off S201, Alcala De Henares 28805, Spain.
EM carolina.redondo.cabrera@gmail.com
RI Sastre, Roberto Lopez/AAA-2180-2019; Maldonado-Bascon,
   Saturnino/AAR-4127-2020
OI Sastre, Roberto Lopez/0000-0002-2477-0152; Maldonado-Bascon,
   Saturnino/0000-0001-6472-5359
FU [CCG2013/EXP-047];  [IPT-2012-0808-370000];  [TIN2010-20845-C03-03]; 
   [UAH2011/EXP-030];  [IPT-2011-1366-390000]
FX This work was partially supported by projects CCG2013/EXP-047,
   IPT-2012-0808-370000, TIN2010-20845-C03-03, UAH2011/EXP-030 and
   IPT-2011-1366-390000.
CR [Anonymous], ICCV
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bosch A., 2007, P 6 ACM INT C IMAGE, P401, DOI DOI 10.1145/1282280.1282340
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chatzichristofis S.A., 2012, IEEE T SYST MAN CY B, V99, P1
   Csurka G., 2004, Workshop on Statistical Learning in Computer Vision, ECCV, P59
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fei-Fei L, 2005, PROC CVPR IEEE, P524
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Grauman K, 2005, IEEE I CONF COMP VIS, P1458
   Gupta Paritosh., 2009, ICCV
   Hsu CW, 2002, IEEE T NEURAL NETWOR, V13, P415, DOI 10.1109/72.991427
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Knopp J, 2010, LECT NOTES COMPUT SC, V6311, P748, DOI 10.1007/978-3-642-15549-9_54
   Lai K, 2011, IEEE INT CONF ROBOT, P1817
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Marton Z.C., 2009, ICRA
   Mian A., IEEE T PATTERN ANAL, V28
   Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33
   Oliva A, 2001, INT J COMPUT VISION, V42, P145, DOI 10.1023/A:1011139631724
   Osada R, 2002, ACM T GRAPHIC, V21, P807, DOI 10.1145/571647.571648
   Redondo-Cabrera C., 2012, IEEE CVPR
   Saupe D., 2001, DAGM S PATT REC
   Silberman N., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P601, DOI 10.1109/ICCVW.2011.6130298
   Sivic J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1470, DOI 10.1109/iccv.2003.1238663
   Steder B., 2010, WORKSH DEF SOLV REAL
   Su Y., 2011, ICCV
   Toldo R., 2009, MIRAGE 09 P 4 INT C
   van de Sande KEA, 2010, IEEE T PATTERN ANAL, V32, P1582, DOI 10.1109/TPAMI.2009.154
   Xiao JX, 2010, PROC CVPR IEEE, P3485, DOI 10.1109/CVPR.2010.5539970
   Xiao JX, 2012, PROC CVPR IEEE, P2695, DOI 10.1109/CVPR.2012.6247991
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 34
TC 7
Z9 7
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 965
EP 978
DI 10.1016/j.imavis.2014.08.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600001
DA 2024-07-18
ER

PT J
AU Calore, E
   Frosio, I
AF Calore, Enrico
   Frosio, Iuri
TI Accelerometer-based correction of skewed horizon and keystone distortion
   in digital photography
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Accelerometer; Perspective correction; Keystone; Horizon; Digital
   photography; Sensor fusion; Noise propagation
ID CAMERA CALIBRATION; MEMS ACCELEROMETERS; VISION; SENSORS; IMAGES
AB Improper camera orientation produces convergent vertical lines (keystone distortion) and skewed horizon lines (horizon distortion) in digital pictures; an a-posteriori processing is then necessary to obtain appealing pictures. We show here that, after accurate calibration, the camera on-board accelerometer can be used to automatically generate an alternative perspective view from a virtual camera, leading to images with residual keystone and horizon distortions that are essentially imperceptible at visual inspection. Furthermore, we describe the uncertainty on the position of each pixel in the corrected image with respect to the accelerometer noise. Experimental results show a similar accuracy for a smartphone and for a digital reflex camera. The method can find application in customer imaging devices as well as in the computer vision field, especially when reference vertical and horizontal features are not easily detectable in the image. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Calore, Enrico; Frosio, Iuri] Univ Milan, Dept Comp Sci, I-20135 Milan, Italy.
   [Frosio, Iuri] NVIDIA Res, Santa Clara, CA 95050 USA.
C3 University of Milan
RP Frosio, I (corresponding author), NVIDIA Res, 2701 San Tomas Expressway, Santa Clara, CA 95050 USA.
EM ifrosio@nvidia.com
RI Calore, Enrico/A-5874-2012; frosio, iuri/G-8917-2012
OI Calore, Enrico/0000-0002-2301-3838; frosio, iuri/0000-0002-7230-4287
CR [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   Bouguet J., CAMERA CALIBRATION T
   Calore E, 2012, IEEE IMTC P, P205
   Chemichenko D. A., 2010, Patent, Patent No. [US 7737967, 7737967]
   Chen J. H.-P., 2011, Patent Application, Patent No. [US 2010054667, 2010054667]
   Corke P, 2007, INT J ROBOT RES, V26, P519, DOI 10.1177/0278364907079279
   Dance CR, 2002, P SOC PHOTO-OPT INS, V4670, P244
   Fleps M, 2011, IEEE INT C INT ROBOT, P3297, DOI 10.1109/IROS.2011.6048797
   Fraser CS, 2006, PHOTOGRAMM ENG REM S, V72, P1017, DOI 10.14358/PERS.72.9.1017
   Frosio I, 2012, IEEE SENS J, V12, P2100, DOI 10.1109/JSEN.2012.2182991
   Frosio I, 2009, IEEE T INSTRUM MEAS, V58, P2034, DOI 10.1109/TIM.2008.2006137
   Hol JD, 2010, INT J ROBOT RES, V29, P231, DOI 10.1177/0278364909356812
   Kanatani K, 2005, IEICE T INF SYST, VE88D, P2260, DOI 10.1093/ietisy/e88-d.10.2260
   Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649
   Lobo J, 2003, IEEE T PATTERN ANAL, V25, P1597, DOI 10.1109/TPAMI.2003.1251152
   Lobo J, 2007, INT J ROBOT RES, V26, P561, DOI 10.1177/0278364907079276
   Lopez M. Bordallo, 2011, MULTIMODAL SENSING B
   Luczak S, 2006, IEEE SENS J, V6, P1669, DOI 10.1109/JSEN.2006.881433
   Mellis D., 2007, EA CHI 07
   Mirzaei FM, 2008, IEEE T ROBOT, V24, P1143, DOI 10.1109/TRO.2008.2004486
   Molgaard C., 2011, Patent Application, Patent No. [uS 2011/0205377, 20110205377]
   Randeniya DIB, 2008, TRANSPORT RES C-EMER, V16, P255, DOI 10.1016/j.trc.2007.08.003
   Skoczewski M., 2010, COMP INF SCI ICIS 20, V2010, P209
   Sun XB, 2004, PROC SPIE, V5302, P79, DOI 10.1117/12.526972
   Varesano F., 2013, P 7 INT C TANG EMB E, P415
   Varesano F., IMU OPEN HARDWARE FR
   Xu Y., 2013, P CVPR 2013
NR 28
TC 2
Z9 2
U1 0
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2014
VL 32
IS 9
BP 606
EP 615
DI 10.1016/j.imavis.2014.06.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AO6QY
UT WOS:000341477800005
DA 2024-07-18
ER

PT J
AU Vu, NS
   Nguyen, TP
   Garcia, C
AF Ngoc-Son Vu
   Thanh Phuong Nguyen
   Garcia, Christophe
TI Improving texture categorization with biologically-inspired filtering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Texture classification; Retina filtering; DoG; Rotation invariant
   preprocessing; Completed LBP; LBC; WLD; SIFT
ID LOCAL BINARY PATTERNS; FACE RECOGNITION; CLASSIFICATION; MAGNITUDES;
   FEATURES
AB Within the domain of texture classification, a lot of effort has been spent on local descriptors, leading to many powerful algorithms. However, preprocessing techniques have received much less attention despite their important potential for improving the overall classification performance. We address this question by proposing a novel, simple, yet very powerful biologically-inspired filtering (BF) which simulates the performance of human retina. In the proposed approach, given a texture image, after applying a difference of Gaussian (DOG) filter to detect the edges, we first split the filtered image into two maps alongside the sides of its edges. The feature extraction step is then carried out on the two maps instead of the input image. Our algorithm has several advantages such as simplicity, robustness to illumination and noise, and discriminative power. Experimental results on three large texture databases show that with an extremely low computational cost, the proposed method improves significantly the performance of many texture classification systems, notably in noisy environments. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Ngoc-Son Vu] CNRS, UCP, ETIS ENSEA, Cergy, France.
   [Thanh Phuong Nguyen] U2IS ENSTA Paristech, Palaiseau, France.
   [Garcia, Christophe] Univ Lyon, CNRS, INSA Lyon, LIRIS, Lyon, France.
C3 Centre National de la Recherche Scientifique (CNRS); Institut
   Polytechnique de Paris; ENSTA Paris; Institut National des Sciences
   Appliquees de Lyon - INSA Lyon; Centre National de la Recherche
   Scientifique (CNRS)
RP Vu, NS (corresponding author), CNRS, UCP, ETIS ENSEA, Cergy, France.
EM son.vu@ensea.fr
RI Nguyen, Thanh Phuong/AAA-2769-2019
OI Nguyen, Thanh Phuong/0000-0002-5646-8505
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], IM PROC ICIP 2009 16
   Aptoula E, 2007, PATTERN RECOGN, V40, P2914, DOI 10.1016/j.patcog.2007.02.004
   Aptoula E, 2009, IMAGE VISION COMPUT, V27, P1394, DOI 10.1016/j.imavis.2008.12.007
   BENOIT A, 2005, ICIP, V3, P425
   Caputo B, 2010, IMAGE VISION COMPUT, V28, P150, DOI 10.1016/j.imavis.2009.05.005
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   Crosier M, 2010, INT J COMPUT VISION, V88, P447, DOI 10.1007/s11263-009-0315-0
   Cula OG, 2001, PROC CVPR IEEE, P1041
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   Daubechies I., 1992, 10 LECT WAVELETS
   Davis LS., PATTERN RECOGN, P219
   DUVERNOY J, 1984, APPL OPTICS, V23, P828, DOI 10.1364/AO.23.000828
   Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003
   Guo ZH, 2010, IEEE T IMAGE PROCESS, V19, P1657, DOI 10.1109/TIP.2010.2044957
   Guo ZH, 2010, PATTERN RECOGN, V43, P706, DOI 10.1016/j.patcog.2009.08.017
   Hanbury A, 2005, COMPUT IMAGING VIS, V30, P377
   Heikkilä M, 2009, PATTERN RECOGN, V42, P425, DOI 10.1016/j.patcog.2008.08.014
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Liao S, 2009, IEEE T IMAGE PROCESS, V18, P1107, DOI 10.1109/TIP.2009.2015682
   Liu L, 2012, IMAGE VISION COMPUT, V30, P86, DOI 10.1016/j.imavis.2012.01.001
   Liu L, 2012, PATTERN RECOGN, V45, P2405, DOI 10.1016/j.patcog.2011.10.027
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Vu NS, 2012, IEEE T IMAGE PROCESS, V21, P1352, DOI 10.1109/TIP.2011.2166974
   Ojala T, 2002, INT C PATT RECOG, P701, DOI 10.1109/ICPR.2002.1044854
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   Puig D, 2010, PATTERN RECOGN, V43, P3282, DOI 10.1016/j.patcog.2010.05.005
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Varma M, 2005, INT J COMPUT VISION, V62, P61, DOI 10.1007/s11263-005-4635-4
   Varma M, 2009, IEEE T PATTERN ANAL, V31, P2032, DOI 10.1109/TPAMI.2008.182
   Vu NS, 2013, IEEE T INF FOREN SEC, V8, P295, DOI 10.1109/TIFS.2012.2224866
   Vu NS, 2012, PATTERN RECOGN, V45, P2478, DOI 10.1016/j.patcog.2011.12.021
   Vu NS, 2010, LECT NOTES COMPUT SC, V6311, P313
   Zhao GY, 2012, IEEE T IMAGE PROCESS, V21, P1465, DOI 10.1109/TIP.2011.2175739
   Zhao Y, 2012, IEEE T IMAGE PROCESS, V21, P4492, DOI 10.1109/TIP.2012.2204271
NR 41
TC 18
Z9 18
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2014
VL 32
IS 6-7
BP 424
EP 436
DI 10.1016/j.imavis.2014.04.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AJ4QM
UT WOS:000337660900005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Pinto, AM
   Correia, MV
   Moreira, AP
   Costa, PG
AF Pinto, Andry Maykol
   Correia, Miguel V.
   Paulo Moreira, A.
   Costa, Paulo G.
TI Unsupervised flow-based motion analysis for an autonomous moving system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Motion segmentation; Optical flow; Moving observer; Active surveillance;
   Mobile robot
ID OPTICAL-FLOW; SEGMENTATION; SURVEILLANCE; SUBTRACTION
AB This article discusses the motion analysis based on dense optical flow fields and for a new generation of robotic moving systems with real-time constraints. It focuses on a surveillance scenario where an especially designed autonomous mobile robot uses a monocular camera for perceiving motion in the environment.
   The computational resources and the processing-time are two of the most critical aspects in robotics and therefore, two non-parametric techniques are proposed, namely, the Hybrid Hierarchical Optical Flow Segmentation and the Hybrid Density-Based Optical Flow Segmentation. Both methods are able to extract the moving objects by performing two consecutive operations: refining and collecting. During the refining phase, the flow field is decomposed in a set of clusters and based on descriptive motion properties. These properties are used in the collecting stage by a hierarchical or density-based scheme to merge the set of clusters that represent different motion models. In addition, a model selection method is introduced. This novel method analyzes the flow field and estimates the number of distinct moving objects using a Bayesian formulation.
   The research evaluates the performance achieved by the methods in a realistic surveillance situation. The experiments conducted proved that the proposed methods extract reliable motion information in real-time and without using specialized computers. Moreover, the resulting segmentation is less computationally demanding compared to other recent methods and therefore, they are suitable for most of the robotic or surveillance applications. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Pinto, Andry Maykol; Correia, Miguel V.; Paulo Moreira, A.; Costa, Paulo G.] Univ Porto, Fac Engn, INESC Technol & Sci, P-4200465 Oporto, Portugal.
C3 INESC TEC; Universidade do Porto
RP Pinto, AM (corresponding author), Univ Porto, Fac Engn, Dept Electrotecnia, Rua Dr Roberto Frias S-N, P-4200465 Oporto, Portugal.
EM andry.pinto@fe.up.pt
RI Moreira, António Paulo/AAD-9179-2022; Costa, Pedro G./L-4108-2014;
   Correia, Miguel Velhote/N-1059-2013; Moreira, Antonio Paulo/B-1842-2013
OI Costa, Pedro G./0000-0002-0435-8419; Correia, Miguel
   Velhote/0000-0001-6065-9358; Pinto, Andry Maykol
   Gomes/0000-0003-2465-5813; Costa, Paulo/0000-0002-4846-271X; Moreira,
   Antonio Paulo/0000-0001-8573-3147
FU Portuguese Government through the FCT - Foundation for Science and
   Technology [SFRH-BD-70752-2010]; Fundação para a Ciência e a Tecnologia
   [SFRH/BD/70752/2010] Funding Source: FCT
FX This work was partially funded by the Portuguese Government through the
   FCT - Foundation for Science and Technology, SFRH-BD-70752-2010.
CR AKAIKE H, 1974, IEEE T AUTOMAT CONTR, VAC19, P716, DOI 10.1109/TAC.1974.1100705
   Alexiadis DS, 2009, COMPUT VIS IMAGE UND, V113, P212, DOI 10.1016/j.cviu.2008.08.013
   Ankerst M, 1999, SIGMOD RECORD, VOL 28, NO 2 - JUNE 1999, P49
   Berrabah SA, 2006, IEEE IMAGE PROC, P1125, DOI 10.1109/ICIP.2006.312754
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Caballero F, 2009, J INTELL ROBOT SYST, V55, P323, DOI 10.1007/s10846-008-9305-7
   Cesetti A., 2010, Journal of Intelligent & Robotic Systems, V57, P233, DOI 10.1007/s10846-009-9373-3
   Edla DR, 2012, PROC TECH, V1, P485, DOI 10.1016/j.protcy.2012.10.058
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Fernández-Caballero A, 2010, ROBOT AUTON SYST, V58, P1273, DOI 10.1016/j.robot.2010.06.002
   Gao J, 2004, IEEE IMAGE PROC, P381
   Georgiadis G, 2012, PROC CVPR IEEE, P646, DOI 10.1109/CVPR.2012.6247732
   Gheissari N, 2006, COMPUT VIS IMAGE UND, V102, P214, DOI 10.1016/j.cviu.2006.02.002
   Guzel Mehmet Serdar, 2010, 2010 IEEE Conference on Robotics, Automation and Mechatronics (RAM 2010), P545, DOI 10.1109/RAMECH.2010.5513134
   HANNAN EJ, 1979, J ROY STAT SOC B MET, V41, P190
   Helble H, 2007, ROBOT AUTON SYST, V55, P661, DOI 10.1016/j.robot.2007.05.010
   Jay Hyuk Choi, 2011, 2011 5th International Conference on Automation, Robotics and Applications (ICARA 2011), P384, DOI 10.1109/ICARA.2011.6144914
   Jiang H, 2011, EXPERT SYST APPL, V38, P9373, DOI 10.1016/j.eswa.2011.01.135
   Kai-Kuang Ma, 2002, 2002 7th International Conference on Control, Automation, Robotics and Vision (IEEE Cat. No.02EX649), P1216
   Kim IS, 2010, INT J CONTROL AUTOM, V8, P926, DOI 10.1007/s12555-010-0501-4
   Kim J, 2010, IEEE IMAGE PROC, P4669, DOI 10.1109/ICIP.2010.5652848
   Maimon O., 2005, The data mining and knowledge discovery handbook (1315-1329)
   Martín JL, 2005, COMPUT VIS IMAGE UND, V98, P462, DOI 10.1016/j.cviu.2004.10.002
   Meng HY, 2009, PATTERN RECOGN LETT, V30, P1049, DOI 10.1016/j.patrec.2009.03.003
   Ohnishi N, 2008, LECT NOTES COMPUT SC, V4931, P412
   Ohnishi N, 2006, PATTERN RECOGN LETT, V27, P1009, DOI 10.1016/j.patrec.2005.11.012
   Pinto A.M., 2013, J INTELLIGENT ROBOTI, P1, DOI [10.1007/s10846-013-9999-z, DOI 10.1007/S10846-013-9999-Z]
   Pinto AM, 2014, SIGNAL PROCESS-IMAGE, V29, P80, DOI 10.1016/j.image.2013.11.003
   Pinto AM, 2013, ROBOT CIM-INT MANUF, V29, P12, DOI 10.1016/j.rcim.2012.06.002
   Qian Yu, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563096
   Schulter Samuel., 2013, Proceedings of the British Machine Vision Conference (BMVC), P1
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Spagnolo P, 2006, IMAGE VISION COMPUT, V24, P411, DOI 10.1016/j.imavis.2006.01.001
   Tagliasacchi M, 2007, IMAGE VISION COMPUT, V25, P141, DOI 10.1016/j.imavis.2006.01.021
   Ververidis D, 2009, IEEE T PATTERN ANAL, V31, P2275, DOI 10.1109/TPAMI.2009.84
NR 35
TC 11
Z9 15
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2014
VL 32
IS 6-7
BP 391
EP 404
DI 10.1016/j.imavis.2014.04.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AJ4QM
UT WOS:000337660900002
DA 2024-07-18
ER

PT J
AU Yang, Y
   Guo, L
   Wang, TJ
   Tao, WB
   Shao, GP
   Feng, Q
AF Yang, Yong
   Guo, Ling
   Wang, Tianjiang
   Tao, Wenbing
   Shao, Guangpu
   Feng, Qi
TI Unsupervised multiphase color-texture image segmentation based on
   variational formulation and multilayer graph
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Variational formulation; Multiphase successive active contour model
   (MSACM); Unsupervised color texture image segmentation; Multilayer graph
ID GEODESIC ACTIVE CONTOURS; ENERGY MINIMIZATION; PIECEWISE-CONSTANT;
   REGION; FRAMEWORK; CUTS; OPTIMIZATION; EFFICIENT; SNAKES; MODEL
AB This paper proposes an unsupervised variational segmentation approach of color-texture images. To improve the description ability, the compact multi-scale structure tensor, total variation flow, and color information are integrated to extract color-texture information. Since heterogeneous image object and nonlinear variation exist in color-texture image, it is not appropriate to use one single/multiple constant in the Chan and Vese (CV) model to describe each phase [1,2]. Therefore, a multiphase successive active contour model (MSACM) based on the multivariable Gaussian distribution is presented to describe each phase. As geodesic active contour (GAC) has a stronger ability in capturing boundary. To inherit the advantages of edge-based model and region-based model, we incorporate the GAC into the MSACM to enhance the detection ability for concave edge. Although multiphase optimization of our proposed MSACM is a NP hard problem, we can discretely and approximately solve it by a multilayer graph method. In addition, to segment the color-texture image automatically, an adaptive iteration convergence criterion is designed by incorporating the local Kullback-Leibler distance and global phase label, so that we can control the segmentation process converges. Comparing to state-of-the-art unsupervised segmentation methods on a substantial of color texture images, our approach achieves a significantly better performance on capture ability of homogeneous region/smooth boundary and accuracy. Crown Copyright (C) 2014 Published by Elsevier B.V. All rights reserved.
C1 [Yang, Yong; Guo, Ling] Huang He Sci & Technol Coll, Sch Informat Engn, Zhengzhou 450063, Peoples R China.
   [Yang, Yong; Wang, Tianjiang; Shao, Guangpu; Feng, Qi] Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
   [Guo, Ling] China Three Gorges Univ, Coll Sci, Yi Chang 443002, Peoples R China.
   [Tao, Wenbing] Huazhong Univ Sci & Technol, Inst Pattern Recognit & Artificial Intelligence, Natl Key Lab Sci & Technol Multispectral Informat, Wuhan 430074, Hubei, Peoples R China.
C3 Huazhong University of Science & Technology; China Three Gorges
   University; Huazhong University of Science & Technology
RP Wang, TJ (corresponding author), Huazhong Univ Sci & Technol, Sch Comp Sci & Technol, Wuhan 430074, Peoples R China.
EM tjwang@hust.edu.cn
FU National Natural Science Foundation of China [61073094]; science
   research program of education department and technology department in
   Henan province [14A520054, 20130704]; Key Laboratory program of
   technology department of Zhengzhou city, in China
FX The research has been supported by the National Natural Science
   Foundation of China (Grant 61073094), the science research program of
   education department and technology department in Henan province (Grant
   14A520054, 20130704), and the Key Laboratory program of technology
   department of Zhengzhou city, in China. In addition, the author would
   like to thank D. Luo for providing the meaningful discussion on the
   paper.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Appleton B, 2005, J MATH IMAGING VIS, V23, P67, DOI 10.1007/s10851-005-4968-1
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Bae E., 2008, 0836 UCLA CAM
   Boykov Y, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P26
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Brendel William., 2010, NIPS
   Brox T, 2004, LECT NOTES COMPUT SC, V3022, P578
   Brox T, 2010, IMAGE VISION COMPUT, V28, P376, DOI 10.1016/j.imavis.2009.06.009
   Cardoso JS, 2005, IEEE T IMAGE PROCESS, V14, P1773, DOI 10.1109/TIP.2005.854491
   Carmo Do., 1976, DIFFERENTIAL GEOMETR
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   CASELLES V, 1993, NUMER MATH, V66, P1, DOI 10.1007/BF01385685
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen SF, 2010, IEEE T IMAGE PROCESS, V19, P2254, DOI 10.1109/TIP.2010.2047164
   Cheng MM, 2011, PROC CVPR IEEE, P409, DOI 10.1109/CVPR.2011.5995344
   Cohen LD, 1997, INT J COMPUT VISION, V24, P57, DOI 10.1023/A:1007922224810
   Cremers D, 2007, INT J COMPUT VISION, V72, P195, DOI 10.1007/s11263-006-8711-1
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   El-Zehiry N, 2011, IMAGE VISION COMPUT, V29, P365, DOI 10.1016/j.imavis.2010.09.002
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Freixenet J, 2002, LECT NOTES COMPUT SC, V2352, P408, DOI 10.1007/3-540-47977-5_27
   Fulkerson D., 1962, FLOW IN NETWORKS
   Ge F, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2762250
   GERIG G, 1992, IEEE T MED IMAGING, V11, P221, DOI 10.1109/42.141646
   Han SD, 2009, IEEE T IMAGE PROCESS, V18, P2289, DOI 10.1109/TIP.2009.2025560
   Ishikawa H, 2003, IEEE T PATTERN ANAL, V25, P1333, DOI 10.1109/TPAMI.2003.1233908
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Khan JF, 2009, IMAGE VISION COMPUT, V27, P489, DOI 10.1016/j.imavis.2008.07.001
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lankton S, 2008, IEEE T IMAGE PROCESS, V17, P2029, DOI 10.1109/TIP.2008.2004611
   Lenglet C, 2006, IEEE T MED IMAGING, V25, P685, DOI 10.1109/TMI.2006.873299
   Li CM, 2005, PROC CVPR IEEE, P430
   Li ZG, 2012, PROC CVPR IEEE, P789, DOI [10.1109/CVPR.2012.6247750, 10.1109/ISRA.2012.6219309]
   Liu LM, 2011, PATTERN RECOGN, V44, P2819, DOI 10.1016/j.patcog.2011.04.031
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Meila M., 2005, P 22 INT C MACHINE L, P577
   Morel J.-M., 1994, VARIATIONAL METHODS
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Paragios N., 1999, P IEEE INT C COMP VI, V2
   POTTS RB, 1952, P CAMB PHILOS SOC, V48, P106, DOI 10.1017/S0305004100027419
   SANTALO LA, 1979, INTEGRAL GEOMETRY GE
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Tao WB, 2012, IEEE T IMAGE PROCESS, V21, P284, DOI 10.1109/TIP.2011.2160955
   Tao WB, 2011, IMAGE VISION COMPUT, V29, P499, DOI 10.1016/j.imavis.2011.03.002
   Tao WB, 2010, PATTERN RECOGN, V43, P3208, DOI 10.1016/j.patcog.2010.04.014
   Unnikrishnan R, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P394
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   Vese LA, 2002, INT J COMPUT VISION, V50, P271, DOI 10.1023/A:1020874308076
   Wall M. E., 2003, PRACTICAL APPROACH M, P91, DOI [10.1007/0-306-47815-35, DOI 10.1007/0-306-47815-3_5]
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
   Yang Y, 2013, PATTERN RECOGN, V46, P1101, DOI 10.1016/j.patcog.2012.09.024
   Ye Qi-Xiang, 2004, Journal of Software, V15, P522
   Zhang T, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1056, DOI 10.1109/ICCV.2003.1238466
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 61
TC 6
Z9 8
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2014
VL 32
IS 2
BP 87
EP 106
DI 10.1016/j.imavis.2013.12.006
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AD0DS
UT WOS:000332905300001
DA 2024-07-18
ER

PT J
AU Liu, JL
   Feng, DZ
AF Liu, Jian-Lei
   Feng, Da-Zheng
TI Two-dimensional multi-pixel anisotropic Gaussian filter for edge-line
   segment (ELS) detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Edge detection; Continuity; Elongation; Anisotropy; Edge-line segment;
   Multi-pixel anisotropic Gaussian filter
ID RETINAL IMAGES; BLOOD-VESSELS; DESIGN; RECOGNITION; CONTOURS
AB In order to further improve the performance of the existing anisotropic Gaussian filters and more fully take advantage of structural information of a boundary, we heuristically develop a new multi-pixel anisotropic Gaussian filter to detect edges or edge-line segments directly from low signal-to-noise ratio images. To significantly increase computational efficiency, the classical isotropic Gaussian filters are first used for quickly estimating an approximate direction along an edge; then our filter is applied to more accurately search edge-line segment direction by a few directional filter masks only near such approximate direction. By comparing the proposed filter with the isotropic Gaussian filters, we analyze two improvement factors associated with the localization and SNR of the proposed filter. Experimental results show that the proposed detector can achieve better performance than several existing edge-detection methods in the sense of noise reduction, good localization, and high edge continuity. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Liu, Jian-Lei; Feng, Da-Zheng] Xidian Univ, Natl Lab Signal Proc, Xian 710071, Shaanxi, Peoples R China.
   [Liu, Jian-Lei] Xidian Univ, Sch Comp Sci, Xian 710071, Shaanxi, Peoples R China.
C3 Xidian University; Xidian University
RP Feng, DZ (corresponding author), Xidian Univ, Natl Lab Signal Proc, Xian 710071, Shaanxi, Peoples R China.
FU Natural Science Foundation of China [61271293]
FX The authors would like to thank the two anonymous reviewers very much
   for their valuable comments and suggestions that have significantly
   improved the manuscript. This work was supported by the Natural Science
   Foundation of China (no. 61271293).
CR Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   [Anonymous], 1982, Digital Picture Processing
   Bao P, 2005, IEEE T PATTERN ANAL, V27, P1485, DOI 10.1109/TPAMI.2005.173
   Basu M, 2002, IEEE T SYST MAN CY C, V32, P252, DOI 10.1109/TSMCC.2002.804448
   BEZDEK JC, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P894, DOI 10.1109/FUZZY.1994.343855
   Bezdek JC, 1998, IEEE T FUZZY SYST, V6, P52, DOI 10.1109/91.660808
   Bowyer K, 2001, COMPUT VIS IMAGE UND, V84, P77, DOI 10.1006/cviu.2001.0931
   BURNS JB, 1986, IEEE T PATTERN ANAL, V8, P425, DOI 10.1109/TPAMI.1986.4767808
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   CHAUDHURI S, 1989, IEEE T MED IMAGING, V8, P263, DOI 10.1109/42.34715
   Demigny D, 2002, IEEE T IMAGE PROCESS, V11, P728, DOI 10.1109/TIP.2002.800887
   DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   Elder JH, 1998, IEEE T PATTERN ANAL, V20, P699, DOI 10.1109/34.689301
   Faugeras O. D., 1992, International Journal of Pattern Recognition and Artificial Intelligence, V6, P353, DOI 10.1142/S0218001492000229
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Geusebroek JM, 2003, IEEE T IMAGE PROCESS, V12, P938, DOI 10.1109/TIP.2003.812429
   Hoover A, 2000, IEEE T MED IMAGING, V19, P203, DOI 10.1109/42.845178
   Jacob M, 2004, IEEE T PATTERN ANAL, V26, P1007, DOI 10.1109/TPAMI.2004.44
   Jiang W, 2009, IEEE T SYST MAN CY B, V39, P1036, DOI 10.1109/TSMCB.2008.2011646
   Kamarainen JK, 2006, IEEE T IMAGE PROCESS, V15, P1088, DOI 10.1109/TIP.2005.864174
   Kim DS, 2004, PATTERN RECOGN LETT, V25, P101, DOI 10.1016/j.patrec.2003.09.010
   Kong WK, 2003, PATTERN RECOGN, V36, P2339, DOI 10.1016/S0031-3203(03)00121-3
   Lakshmanan V, 2004, IEEE GEOSCI REMOTE S, V1, P192, DOI 10.1109/LGRS.2004.828178
   Law T, 1996, IEEE T PATTERN ANAL, V18, P481, DOI 10.1109/34.494638
   LU SW, 1993, PATTERN RECOGN, V26, P1149, DOI 10.1016/0031-3203(93)90201-7
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   MALLAT S, 1991, IEEE T INFORM THEORY, V37, P1019, DOI 10.1109/18.86995
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   MEER P, 1989, PATTERN RECOGN, V22, P491, DOI 10.1016/0031-3203(89)90019-8
   Moon H, 2002, IEEE T IMAGE PROCESS, V11, P1209, DOI 10.1109/TIP.2002.800896
   NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852
   Nan Wu., 2006, IEEE GEOSCI REMOTE S, V1, P192
   Papari G, 2008, IEEE T IMAGE PROCESS, V17, P1950, DOI 10.1109/TIP.2008.2002306
   Papari G, 2012, IEEE T IMAGE PROCESS, V21, P2931, DOI 10.1109/TIP.2011.2179060
   Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009
   Perona Pietro, 1992, IMAGE VIS COMPUT, V10
   PETROU M, 1991, IEEE T PATTERN ANAL, V13, P483, DOI 10.1109/34.134047
   RAO KR, 1994, IEEE T PATTERN ANAL, V16, P1169, DOI 10.1109/34.387490
   Reisert M, 2008, IEEE T IMAGE PROCESS, V17, P2265, DOI 10.1109/TIP.2008.2006601
   RUSSO F, 1994, PROCEEDINGS OF THE THIRD IEEE CONFERENCE ON FUZZY SYSTEMS - IEEE WORLD CONGRESS ON COMPUTATIONAL INTELLIGENCE, VOLS I-III, P249, DOI 10.1109/FUZZY.1994.343744
   Sanchez-Avila C, 2005, PATTERN RECOGN, V38, P231, DOI 10.1016/j.patcog.2004.07.004
   TAN HL, 1989, IEEE T SYST MAN CYB, V19, P1337, DOI 10.1109/21.44058
   TAN HL, 1992, IEEE T PATTERN ANAL, V14, P3, DOI 10.1109/34.107010
   TAO CW, 1993, SECOND IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2, P1356, DOI 10.1109/FUZZY.1993.327590
   Tieng QM, 1997, IEEE T PATTERN ANAL, V19, P910, DOI 10.1109/34.608294
   TORRE V, 1986, IEEE T PATTERN ANAL, V8, P147, DOI 10.1109/TPAMI.1986.4767769
   TSAI CT, 1993, PATTERN RECOGN, V26, P1057, DOI 10.1016/0031-3203(93)90007-J
   Tu CL, 2005, IEEE T INFORM THEORY, V51, P1049, DOI 10.1109/TIT.2004.842706
   TYAN CY, 1993, SECOND IEEE INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS, VOLS 1 AND 2, P600, DOI 10.1109/FUZZY.1993.327420
   von Gioi RG, 2008, J MATH IMAGING VIS, V32, P313, DOI 10.1007/s10851-008-0102-5
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Wang ZQ, 1996, IEEE T PATTERN ANAL, V18, P1092, DOI 10.1109/34.544078
   Weldon TP, 1996, PATTERN RECOGN, V29, P2005, DOI 10.1016/S0031-3203(96)00047-7
   Woods K, 1997, IEEE T MED IMAGING, V16, P329, DOI 10.1109/42.585767
   Yi S, 2009, IEEE T IMAGE PROCESS, V18, P929, DOI 10.1109/TIP.2009.2013082
   YOUNG IT, 1995, SIGNAL PROCESS, V44, P139, DOI 10.1016/0165-1684(95)00020-E
   Yu JH, 2008, PATTERN RECOGN LETT, V29, P1496, DOI 10.1016/j.patrec.2008.03.002
   Zhang L, 2002, INT C PATT RECOG, P501, DOI 10.1109/ICPR.2002.1047986
NR 60
TC 15
Z9 21
U1 0
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2014
VL 32
IS 1
BP 37
EP 53
DI 10.1016/j.imavis.2013.12.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AB0RV
UT WOS:000331500700004
DA 2024-07-18
ER

PT J
AU Emami, M
   Hoberock, LL
AF Emami, Mohsen
   Hoberock, Lawrence L.
TI Selection of a best metric and evaluation of bottom-up visual saliency
   models
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Bottom-up saliency mechanism; Best comparison metric; Computer vision;
   Human visual system
ID ATTENTION; COMBINATION; COMPUTATION; ALLOCATION; SEARCH; SHIFTS; OVERT
AB There are many "machine vision" models of the visual saliency mechanism, which controls the process of selecting and allocating attention to the most "prominent" locations in the scene and helps humans interact with the visual environment efficiently (Itti and C. Koch, 2001; Gao et al., 2000). It is important to know which models perform the best in mimicking the saliency mechanism of the human visual system. There are several metrics to compare saliency models; however, results from different metrics vary widely in evaluating models. In this paper, a procedure is proposed for evaluating metrics for comparing saliency maps using a database of human fixations on approximately 1000 images. This procedure is then employed to identify the best metric. This best metric is then used to evaluate ten published bottom-up saliency models. An optimized level of the blurriness and center-bias is found for each visual saliency model. Performance of the models is also analyzed on a dataset of 54 synthetic images. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Emami, Mohsen; Hoberock, Lawrence L.] Oklahoma State Univ, Sch Mech & Aerosp Engn, Stillwater, OK 74078 USA.
C3 Oklahoma State University System; Oklahoma State University - Stillwater
RP Emami, M (corresponding author), Oklahoma State Univ, Sch Mech & Aerosp Engn, 218 Engn North, Stillwater, OK 74078 USA.
EM emami@okstate.edu; larry.hoberock@okstate.edu
CR [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], 2012, CSAIL TECHNICAL REPO
   [Anonymous], 2007, APPL STAT USING SPSS
   [Anonymous], 2007, IEEE C COMP VIS PATT
   [Anonymous], 2009, INT C COMP VIS
   Borji A., 2012, IEEE T PATTERN ANAL
   Borji A, 2013, IEEE T IMAGE PROCESS, V22, P55, DOI 10.1109/TIP.2012.2210727
   Bruce N., 2006, P ADV NEUR INF PROC, P155
   Bruce NDB, 2009, J VISION, V9, DOI 10.1167/9.3.5
   Bur A, 2007, LECT NOTES COMPUT SC, V4528, P109
   Chenlei G., 2008, IEEE C COMP VIS PATT
   Duong T.H., 2011, 4 IEEE INT C MACH LE
   Emami M., 2013, THESIS OKLAHOMA STAT
   Gao D., 2008, DISCRIMINANT HYPOTHE
   Gao D, 2008, J VISION, V8, DOI 10.1167/8.7.13
   Garcia-Diaz A, 2009, LECT NOTES COMPUT SC, V5702, P261, DOI 10.1007/978-3-642-03767-2_32
   Goferman S., 2010, IEEE C COMP VIS PATT
   Grossberg S, 1999, SPATIAL VISION, V12, P163, DOI 10.1163/156856899X00102
   Harel J, 2006, Advances in Neural Information Processing Systems, V19
   Hou XD, 2012, IEEE T PATTERN ANAL, V34, P194, DOI 10.1109/TPAMI.2011.146
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Itti L, 2001, NAT REV NEUROSCI, V2, P194, DOI 10.1038/35058500
   Itti L, 2000, VISION RES, V40, P1489, DOI 10.1016/S0042-6989(99)00163-7
   Itti L, 2009, VISION RES, V49, P1295, DOI 10.1016/j.visres.2008.09.007
   Johnson R.A., 2001, Statistics principles and methods
   KOCH C, 1985, HUM NEUROBIOL, V4, P219
   Le Meur O, 2006, IEEE T PATTERN ANAL, V28, P802, DOI 10.1109/TPAMI.2006.86
   Lin YW, 2010, AAAI CONF ARTIF INTE, P967
   Mahadevan V, 2010, IEEE T PATTERN ANAL, V32, P171, DOI 10.1109/TPAMI.2009.112
   Ouerhani N., 2004, ELECT LETT COMPUTER, V3, P13, DOI [10.5565/rev/elcvia.66, DOI 10.5565/REV/ELCVIA.66]
   Ouerhani N, 2006, LECT NOTES COMPUT SC, V4174, P314
   Parkhurst D, 2002, VISION RES, V42, P107, DOI 10.1016/S0042-6989(01)00250-4
   Peters RJ, 2005, VISION RES, V45, P2397, DOI 10.1016/j.visres.2005.03.019
   Rajashekar U., 2005, STAT ANAL SELECTION
   Rosenholtz R., 2007, J VIS
   Tatler BW, 2005, VISION RES, V45, P643, DOI 10.1016/j.visres.2004.09.017
   TREISMAN AM, 1980, COGNITIVE PSYCHOL, V12, P97, DOI 10.1016/0010-0285(80)90005-5
   Wolfe JM, 2004, NAT REV NEUROSCI, V5, P495, DOI 10.1038/nrn1411
   Yarbus A.L., 1967, EYE MOVEMENT VISION
   Zhang LY, 2008, J VISION, V8, DOI 10.1167/8.7.32
NR 40
TC 12
Z9 13
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2013
VL 31
IS 10
BP 796
EP 808
DI 10.1016/j.imavis.2013.08.004
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 242BH
UT WOS:000326211900010
DA 2024-07-18
ER

PT J
AU Mahalingam, G
   Kambhamettu, C
AF Mahalingam, Gayathri
   Kambhamettu, Chandra
TI Face verification of age separated images under the influence of
   internal and external factors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Age progression; Face recognition; Face verification; AdaBoost; Local
   binary patterns
ID SUPPORT VECTOR MACHINES; LOCAL BINARY PATTERN; RECOGNITION;
   CLASSIFICATION
AB In this paper we study the task of face verification of age-separated images with the presence of various internal and external factors. We propose a hierarchical local binary pattern (HLBP) feature descriptor for robust face representation across age. The effective representation by HLBP across minimal age, illumination, and expression variations combined with its hierarchical computation provides a discriminative representation of the face image. The proposed face descriptor is combined with an AdaBoost classification framework to model the face verification task as a two-class problem. Experimental results on the FG-NET and MORPH aging datasets indicate that the performance of the proposed framework is robust with respect to images of both adults and children. A detailed empirical analysis on the effects of internal (age gap, gender, and ethnicity) and external (pose, expressions, facial hair, and glasses) factors in the face verification performance is also studied. The results indicate that the verification accuracy reduces as the age gap between the image pair increases. A quantitative comparison on the effects of gender on verification performance by both humans and the proposed machine learning approach is provided. The analysis indicate that the cues aid humans in verifying image pairs with large age gaps, while it aids machines for all age gaps. However, the cues mislead humans in the case of images of children and extra-personal pairs with large age gaps. Our analyses indicate that the pose and expression variations affect the performance, despite training with such variations, while facial hair and glasses act as discriminative cues. A study on the effects of ethnicity indicate that non-linear algorithms have insignificant effect in performance with the use of both generalized and individual ethnicity models when compared with linear algorithms. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Mahalingam, Gayathri; Kambhamettu, Chandra] Univ Delaware, Dept Comp & Informat Sci, Video Image Modeling & Synth Lab, Newark, DE 19716 USA.
C3 University of Delaware
RP Mahalingam, G (corresponding author), Univ Delaware, Dept Comp & Informat Sci, Video Image Modeling & Synth Lab, Newark, DE 19716 USA.
EM mahaling@udel.edu; chandrak@udel.edu
CR Ahonen T, 2004, LECT NOTES COMPUT SC, V3021, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   ALVAREZ L, 1993, ARCH RATION MECH AN, V123, P199, DOI 10.1007/BF00375127
   [Anonymous], 2001, HIERARCHICAL LINEAR
   Bekios-Calfa J, 2011, IEEE T PATTERN ANAL, V33, P858, DOI 10.1109/TPAMI.2010.208
   Bruce V., 2000, In the Eye of the Beholder: The Science of Face Perception
   Chen X, 2009, IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI), V32, P385, DOI DOI 10.1109/TPAMI.2009.39
   Face gesture recognition working group, 2002, FG NET AG DAT
   Freund Y., 1999, Journal of Japanese Society for Artificial Intelligence, V14, P771
   Freund Y., 1996, Proceedings of the Ninth Annual Conference on Computational Learning Theory, P324
   Guodong Guo, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3392, DOI 10.1109/ICPR.2010.828
   Hammond D.K., 2005, Nonlinear Image representation via local multi scale orientation
   He YG, 2011, LECT NOTES COMPUT SC, V6494, P133, DOI 10.1007/978-3-642-19318-7_11
   Jonsson K, 2002, IMAGE VISION COMPUT, V20, P369, DOI 10.1016/S0262-8856(02)00009-4
   Kumar N, 2011, IEEE T PATTERN ANAL, V33, P1962, DOI 10.1109/TPAMI.2011.48
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Lanitis A, 2010, INT J BIOMETRICS, V2, P34, DOI 10.1504/IJBM.2010.030415
   Li ZF, 2011, IEEE T INF FOREN SEC, V6, P1028, DOI 10.1109/TIFS.2011.2156787
   Liao SC, 2007, LECT NOTES COMPUT SC, V4642, P828
   Ling HB, 2010, IEEE T INF FOREN SEC, V5, P82, DOI 10.1109/TIFS.2009.2038751
   Mäenpää T, 2003, LECT NOTES COMPUT SC, V2749, P885
   Meissner CA, 2001, PSYCHOL PUBLIC POL L, V7, P3, DOI 10.1037//1076-8971.7.1.3
   Moghaddam B., 1998, EIGENFACES PROBABILI, P30
   Ojala T, 1996, PATTERN RECOGN, V29, P51, DOI 10.1016/0031-3203(95)00067-4
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ojala T., 2001, Advances in Pattern Recognition - ICAPR 2001. Second International Conference. Proceedings (Lecture Notes in Computer Science Vol.2013), P397
   Park U., 2008, Proc. Automatic Face and Gesture Recognition, P1
   Phillips PJ, 1999, ADV NEUR IN, V11, P803
   Ramanathan N., 2006, 2006 IEEE COMP SOC C, V1, P387
   Ramanathan N, 2006, IEEE T IMAGE PROCESS, V15, P3349, DOI 10.1109/TIP.2006.881993
   Ramanathan N, 2009, J VISUAL LANG COMPUT, V20, P131, DOI 10.1016/j.jvlc.2009.01.011
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Singh R, 2007, LECT NOTES COMPUT SC, V4815, P576
   Suo J., 2007, COMPUT VIS PATTERN R, P17
   Suo JL, 2009, IEEE I CONF COMP VIS, P622, DOI 10.1109/ICCV.2009.5459181
   Tiddeman M., 2001, COMPUT GRAPH APPL, P42
   Wang XG, 2009, PROC CVPR IEEE, P142, DOI 10.1109/CVPRW.2009.5206736
   Weifeng Li, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P77, DOI 10.1109/FG.2011.5771345
   Zeng J., 2012, ISRN MACHINE VISION
   Zhang GC, 2004, LECT NOTES COMPUT SC, V3338, P179
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 41
TC 9
Z9 9
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2012
VL 30
IS 12
BP 1052
EP 1061
DI 10.1016/j.imavis.2012.10.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057PP
UT WOS:000312575800012
DA 2024-07-18
ER

PT J
AU Bai, XZ
   Zhou, FG
   Xue, BD
AF Bai, Xiangzhi
   Zhou, Fugen
   Xue, Bindang
TI Edge preserved image fusion based on multiscale toggle contrast operator
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Toggle contrast operator; Multiscale; Image fusion; Edge preserving;
   Mathematical morphology
AB An edge preserved image fusion algorithm based on multiscale toggle contrast operator is proposed in this paper. First, the multiscale toggle contrast operator using multiscale structuring elements with the same shape and increasing sizes is discussed. Then, the multiscale dilation and erosion features which represent the edge information of the original images are extracted by using the multiscale toggle contrast operator. After the final dilation and erosion fusion features are constructed from the extracted multiscale dilation and erosion features, the final fusion image is formed by combining the final dilation and erosion fusion features into a base image calculated from the original image. Because the multiscale dilation and erosion features which represent the edge information are effectively extracted and combined into the final fusion image, clear and well preserved edge features of the final fusion image are obtained. Experimental results show that, the proposed image fusion algorithm is efficient for edge preserving and performs well. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Bai, Xiangzhi; Zhou, Fugen; Xue, Bindang] Beijing Univ Aeronaut & Astronaut, Image Proc Ctr, Beijing 100191, Peoples R China.
C3 Beihang University
RP Bai, XZ (corresponding author), Beijing Univ Aeronaut & Astronaut, Image Proc Ctr, Beijing 100191, Peoples R China.
EM jackybxz163@163.com
RI cai, bo/G-1491-2010
FU National Natural Science Foundation of China [60902056, 60832011];
   Innovation Foundation of AVIC [CXY2010BH02]; Weishi Foundation of BUAA
   [YWF-11-03-Q-065]
FX We thank the anonymous reviewers and editor for their very constructive
   comments. This work is partly supported by the National Natural Science
   Foundation of China (60902056, 60832011), Innovation Foundation of AVIC
   (CXY2010BH02), and Weishi Foundation of BUAA (YWF-11-03-Q-065). The
   authors are grateful to Dr. Yan Li at Peking University, Beijing, China,
   for many helpful discussions and comments.
CR Amolins K, 2007, ISPRS J PHOTOGRAMM, V62, P249, DOI 10.1016/j.isprsjprs.2007.05.009
   [Anonymous], IMAGE PROCESSING ANA
   Aslantas V, 2009, OPT COMMUN, V282, P3231, DOI 10.1016/j.optcom.2009.05.021
   Cvejic N, 2007, IEEE SENS J, V7, P743, DOI 10.1109/JSEN.2007.894926
   De I, 2006, SIGNAL PROCESS, V86, P924, DOI 10.1016/j.sigpro.2005.06.015
   De I, 2006, IMAGE VISION COMPUT, V24, P1278, DOI 10.1016/j.imavis.2006.04.005
   Dorini L. B., 2007, P 8 INT S MATH MORPH, P101
   Dorini LB, 2007, SIBGRAPI, P294, DOI 10.1109/SIBGRAPI.2007.33
   González F, 2002, MICROELECTR J, V33, P1115, DOI 10.1016/S0026-2692(02)00117-9
   González-Audícana M, 2004, IEEE T GEOSCI REMOTE, V42, P1291, DOI 10.1109/TGRS.2004.825593
   Jalba AC, 2004, PATTERN RECOGN, V37, P901, DOI 10.1016/j.patcog.2003.09.009
   KRAMER HP, 1975, PATTERN RECOGN, V7, P53, DOI 10.1016/0031-3203(75)90013-8
   LESTER JM, 1980, COMPUT VISION GRAPH, V13, P17, DOI 10.1016/0146-664X(80)90114-8
   Maragos P, 2005, HANDBOOK OF IMAGE AND VIDEO PROCESSING, 2ND EDITION, P135, DOI 10.1016/B978-012119792-6/50072-3
   MEYER F, 1989, SIGNAL PROCESS, V16, P303, DOI 10.1016/0165-1684(89)90028-5
   Mukhopadhyay S, 2001, PATTERN RECOGN, V34, P1939, DOI 10.1016/S0031-3203(00)00123-0
   Nencini F, 2007, INFORM FUSION, V8, P143, DOI 10.1016/j.inffus.2006.02.001
   Oliveira MA, 2008, PATTERN RECOGN, V41, P367, DOI 10.1016/j.patcog.2007.05.019
   PARK HC, 1995, IEEE T PATTERN ANAL, V17, P2, DOI 10.1109/34.368156
   Schavemaker JGM, 2000, PATTERN RECOGN, V33, P997, DOI 10.1016/S0031-3203(99)00160-0
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Toet A, 2010, INFORM FUSION, V11, P95, DOI 10.1016/j.inffus.2009.06.008
   VanDroogenbroeck M, 1996, PATTERN RECOGN LETT, V17, P1451, DOI 10.1016/S0167-8655(96)00113-4
   [WANG Chao 王超], 2007, [自动化学报, Acta Automatica Sinica], V33, P132, DOI 10.1360/aas-007-0132
   WANG WJ, 2001, J IMAGE GRAPHICS, V6, P1130
   Wang ZB, 2010, PATTERN RECOGN, V43, P2003, DOI 10.1016/j.patcog.2010.01.011
NR 26
TC 53
Z9 58
U1 2
U2 24
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2011
VL 29
IS 12
BP 829
EP 839
DI 10.1016/j.imavis.2011.09.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 873TJ
UT WOS:000298905600003
DA 2024-07-18
ER

PT J
AU Wu, W
   Liu, Z
   He, XH
AF Wu, Wei
   Liu, Zheng
   He, Xiaohai
TI Learning-based super resolution using kernel partial least squares
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Learning-based super resolution; High resolution image; Kernel partial
   least squares; Residual image
ID SUPERRESOLUTION; RECONSTRUCTION; FACE
AB In this paper, we propose a learning-based super resolution approach consisting of two steps. The first step uses the kernel partial least squares (KPLS) method to implement the regression between the low-resolution (LR) and high-resolution (HR) images in the training set. With the built KPLS regression model, a primitive super-resolved image can be obtained. However, this primitive HR image loses some detailed information and does not guarantee the compatibility with the LR one. Therefore, the second step compensates the primitive HR image with a residual HR image, which is the subtraction of the original and primitive HR images. Similarly, the residual LR image is obtained from the down-sampled version of the primitive HR and original LR image. The relation of the residual LR and HR images is again modeled with KPLS. Integration of the primitive and the residual HR image will achieve the final super-resolved image. The experiments with face, vehicle plate, and natural scene images demonstrate the effectiveness of the proposed approach in terms of visual quality and selected image quality metrics. Crown Copyright (C) 2011 Published by Elsevier B.V. All rights reserved.
C1 [Liu, Zheng] Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
   [Wu, Wei; He, Xiaohai] Sichuan Univ, Sch Elect & Informat Engn, Chengdu 610064, Peoples R China.
C3 University of Ottawa; Sichuan University
RP Liu, Z (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, Ottawa, ON K1N 6N5, Canada.
EM zheng.liu@ieee.org
RI Liu, Zheng/D-8678-2016
OI Liu, Zheng/0000-0002-7241-3483; Wu, Wei/0000-0001-5769-9340
FU National Natural Science Foundation of China [61071161]
FX This work is supported by the National Natural Science Foundation of
   China (project number: 61071161).
CR Baker S, 2002, IEEE T PATTERN ANAL, V24, P1167, DOI 10.1109/TPAMI.2002.1033210
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   Capel D, 2003, IEEE SIGNAL PROC MAG, V20, P75, DOI 10.1109/MSP.2003.1203211
   Dong H., 2001, ASIAN FACE IMAGE DAT
   Freeman WT, 2000, INT J COMPUT VISION, V40, P25, DOI 10.1023/A:1026501619075
   Freeman WT, 2002, IEEE COMPUT GRAPH, V22, P56, DOI 10.1109/38.988747
   IRANI M, 1991, CVGIP-GRAPH MODEL IM, V53, P231, DOI 10.1016/1049-9652(91)90045-L
   Jiji CV, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/73767
   Jiji CV, 2004, INT J IMAG SYST TECH, V14, P105, DOI 10.1002/ima.20013
   Kim SP, 1993, IEEE T IMAGE PROCESS, V2, P534, DOI 10.1109/83.242363
   Kumar KV, 2008, PATTERN RECOGN, V41, P1398, DOI 10.1016/j.patcog.2007.08.006
   LINDGREN F, 1993, J CHEMOMETR, V7, P45, DOI 10.1002/cem.1180070104
   Liu C, 2007, INT J COMPUT VISION, V75, P115, DOI 10.1007/s11263-006-0029-5
   Liu W, 2005, IEEE IMAGE PROC, P81
   Ni KS, 2007, IEEE T IMAGE PROCESS, V16, P1596, DOI 10.1109/TIP.2007.896644
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park SC, 2003, IEEE SIGNAL PROC MAG, V20, P21, DOI 10.1109/MSP.2003.1203207
   Qin FQ, 2009, J ELECTRON IMAGING, V18, DOI 10.1117/1.3091936
   ROMAN R, 2001, J MACHINE LEARNING R, V2, P97
   ROSIPAL R, 2003, NEURAL NETW WORLD, V13, P1
   Rosipal R, 2006, LECT NOTES COMPUT SC, V3940, P34, DOI 10.1007/11752790_2
   Su CY, 2005, PATTERN RECOGN, V38, P813, DOI 10.1016/j.patcog.2004.11.007
   TRIER OD, 1995, IEEE T PATTERN ANAL, V17, P1191, DOI 10.1109/34.476511
   van Ouwerkerk JD, 2006, IMAGE VISION COMPUT, V24, P1039, DOI 10.1016/j.imavis.2006.02.026
   Wang XG, 2005, IEEE T SYST MAN CY C, V35, P425, DOI 10.1109/TSMCC.2005.848171
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang YW, 2010, IEEE T IND INFORM, V6, P3, DOI 10.1109/TII.2009.2033181
   Zhuang YT, 2007, PATTERN RECOGN, V40, P3178, DOI 10.1016/j.patcog.2007.03.011
NR 28
TC 51
Z9 63
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2011
VL 29
IS 6
BP 394
EP 406
DI 10.1016/j.imavis.2011.02.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 761TD
UT WOS:000290423000003
DA 2024-07-18
ER

PT J
AU Fourie, J
   Mills, S
   Green, R
AF Fourie, Jaco
   Mills, Steven
   Green, Richard
TI Harmony filter: A robust visual tracking system using the improved
   harmony search algorithm
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Harmony search algorithm; Soft computing; Evolutionary
   algorithm 2000 MSC: 68T45
ID ENGINEERING OPTIMIZATION
AB In this article a novel approach to visual tracking called the harmony filter is presented. It is based on the Harmony Search algorithm, a derivative free meta-heuristic optimisation algorithm inspired by the way musicians improvise new harmonies. The harmony filter models the target as a colour histogram and searches for the best estimated target location using the Bhattacharyya coefficient as a fitness metric. Experimental results show that the harmony filter can robustly track an arbitrary target in challenging conditions. We compare the speed and accuracy of the harmony filter with other popular tracking algorithms including the particle filter and the unscented Kalman filter. Experimental results show the harmony filter to be faster and more accurate than both the particle filter and the unscented Kalman filter. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Fourie, Jaco; Green, Richard] Univ Canterbury, Christchurch 1, New Zealand.
   [Fourie, Jaco; Mills, Steven] Geospatial Res Ctr NZ Ltd, Christchurch, New Zealand.
C3 University of Canterbury
RP Fourie, J (corresponding author), Univ Canterbury, Christchurch 1, New Zealand.
EM jaco.fourie@grcnz.com
RI Fourie, Jaco/K-5147-2019
OI Fourie, Jaco/0000-0002-7734-8262; Mills, Steven/0000-0002-4933-7777
CR ALIA O, 2009, SIGN PROC INF TECHN, P538, DOI DOI 10.1109/ISSPIT.2009.5407590
   [Anonymous], INT J INTELLIGENT TE
   [Anonymous], INT C IM VIS COMP NZ
   BUE AD, 2002, SMART CAMERAS REAL T, P429
   Chen T.M., 1999, 25 ANN C IEEE IND EL, V3, P1336
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   FERRARI V, 2001, CVPR 2001, V2, P226
   Fesanghary M, 2008, COMPUT METHOD APPL M, V197, P3080, DOI 10.1016/j.cma.2008.02.006
   FOURIE J, 2009, DIRECTED CORRES SEAR
   Geem Z.W., 2005, AM J APPL SCI, V2, P1552, DOI DOI 10.3844/AJASSP.2005.1552
   Geem ZW, 2006, LECT NOTES ARTIF INT, V4251, P86
   Geem ZW, 2010, STUD COMPUT INTELL, V270, P1
   Geem ZW, 2009, ENG OPTIMIZ, V41, P297, DOI 10.1080/03052150802449227
   Geem ZW, 2001, SIMULATION, V76, P60, DOI 10.1177/003754970107600201
   GUTMAN PO, 1990, IEEE T AERO ELEC SYS, V26, P691, DOI 10.1109/7.102704
   GUYEN H, 2004, SPIE P, V569, pR17
   Handmann U, 2000, IMAGE VISION COMPUT, V18, P367, DOI 10.1016/S0262-8856(99)00032-3
   HONGQI L, 2008, INT J HYBRID INFORM, V1, P57
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Lee KS, 2005, COMPUT METHOD APPL M, V194, P3902, DOI 10.1016/j.cma.2004.09.007
   Li PH, 2004, IMAGE VISION COMPUT, V22, P157, DOI 10.1016/j.imavis.2003.07.004
   Mahdavi M, 2007, APPL MATH COMPUT, V188, P1567, DOI 10.1016/j.amc.2006.11.033
   Minami M, 1999, IND ROBOT, V26, P278, DOI 10.1108/01439919910277549
   MORSLY Y, IAENG INT J COMPUTER, P35
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Omran MGH, 2008, APPL MATH COMPUT, V198, P643, DOI 10.1016/j.amc.2007.09.004
   SATTAR J, 2005, THESIS MCGILL U MONT
   Sulistijono IA, 2007, J ADV COMPUT INTELL, V11, P681, DOI 10.20965/jaciii.2007.p0681
   Swain D., 1990, 3 INT C COMPUTER VIS, P390, DOI [DOI 10.1109/ICCV.1990.139558, 10.1109/ICCV.1990.139558]
   Zhang XQ, 2008, PROC CVPR IEEE, P1317, DOI 10.1109/CVPR.2008.4587512
   2008, EC FUNDED CAVIAR PRO
NR 32
TC 46
Z9 50
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1702
EP 1716
DI 10.1016/j.imavis.2010.05.006
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300011
DA 2024-07-18
ER

PT J
AU Allène, C
   Audibert, JY
   Couprie, M
   Keriven, R
AF Allene, Cedric
   Audibert, Jean-Yves
   Couprie, Michel
   Keriven, Renaud
TI Some links between extremum spanning forests, watersheds and min-cuts
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 8th International Symposium on Mathematical Morphology
CY OCT 10-13, 2007
CL Rio de Janeiro, BRAZIL
DE Min-cuts; Extremum spanning forests; Watersheds; Segmentation
ID ALGORITHM
AB Minimum cuts, extremum spanning forests and watersheds have been used as the basis for powerful image segmentation procedures. In this paper, we present some results about the links which exist between these different approaches. Especially, we show that extremum spanning forests are particular cases of watersheds from arbitrary markers and that min-cuts coincide with extremum spanning forests for some particular weight functions. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Allene, Cedric; Audibert, Jean-Yves; Keriven, Renaud] Univ Paris Est, CERTIS, Ecole Ponts ParisTech, F-77420 Champs Sur Marne, France.
   [Allene, Cedric; Couprie, Michel] Univ Paris Est, Lab Informat Gaspard Monge, Equipe A3SI, ESIEE Paris, F-77420 Champs Sur Marne, France.
C3 Universite Gustave-Eiffel; Ecole des Ponts ParisTech; Universite
   Gustave-Eiffel; ESIEE Paris
RP Allène, C (corresponding author), Univ Paris Est, CERTIS, Ecole Ponts ParisTech, F-77420 Champs Sur Marne, France.
EM allene@certis.enpc.fr; audibert@certis.enpc.fr; m.couprie@esiee.fr;
   keriven@certis.enpc.fr
CR Allene C., 2007, MATH MORPHOLOGY ITS, P253
   [Anonymous], 2011, Combinatorial Optimization
   Bertrand G, 2005, J MATH IMAGING VIS, V22, P217, DOI 10.1007/s10851-005-4891-5
   Beucher S., 1979, Use of watersheds in contour detection
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y., 1999, IEEE International Workshop on Energy Minimization Methods in Computer Vision, P205
   Chazelle B, 2000, J ACM, V47, P1028, DOI 10.1145/355541.355562
   Cormen Thomas H., 2001, INTRO ALGORITHMS
   COUSTY J, 2007, P ISMM, P301
   Cousty J, 2009, IEEE T PATTERN ANAL, V31, P1362, DOI 10.1109/TPAMI.2008.173
   Dahlhaus E., 1992, Proceedings of the Twenty-Fourth Annual ACM Symposium on the Theory of Computing, P241, DOI 10.1145/129712.129736
   DIESTEL R., 1997, GRADUATE TEXTS MATH
   Ford LR., 1956, CAN J MATH, V8, P399, DOI [10.4153/CJM-1956-045-5, DOI 10.4153/CJM-1956-045-5.12R]
   Meyer F, 1994, COMP IMAG VIS, V2, P77
   Meyer F., 1990, Journal of Visual Communication and Image Representation, V1, P21, DOI 10.1016/1047-3203(90)90014-M
   MEYER F, 2008, MORPHOLOGIE MATH, V1, P201
   Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254
   SERRA J, 2008, MORPHOLOGIE MATH, V1, P173
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
NR 20
TC 42
Z9 43
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2010
VL 28
IS 10
SI SI
BP 1460
EP 1471
DI 10.1016/j.imavis.2009.06.017
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 638YK
UT WOS:000280936300005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Nalpantidis, L
   Gasteratos, A
AF Nalpantidis, Lazaros
   Gasteratos, Antonios
TI Stereo vision for robotic applications in the presence of non-ideal
   lighting conditions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo vision; Disparity map; Gestalt laws; HSL color space; Luminosity
   non-uniformity compensation
ID ADAPTIVE SUPPORT-WEIGHT; MAPS
AB Many robotic and machine-vision applications rely on the accurate results of stereo correspondence algorithms. However, difficult environmental conditions, such as differentiations in illumination depending on the viewpoint, heavily affect the stereo algorithms' performance. This work proposes a new illumination-invariant dissimilarity measure in order to substitute the established intensity-based ones. The proposed measure can be adopted by almost any of the existing stereo algorithms, enhancing it with its robust features. The performance of the dissimilarity measure is validated through experimentation with a new adaptive support weight (ASW) stereo correspondence algorithm. Experimental results for a variety of lighting conditions are gathered and compared to those of intensity-based algorithms. The algorithm using the proposed dissimilarity measure outperforms all the other examined algorithms, exhibiting tolerance to illumination differentiations and robust behavior. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Nalpantidis, Lazaros; Gasteratos, Antonios] Democritus Univ Thrace, Robot & Automat Lab, Prod & Management Engn Dept, GR-67100 Xanthi, Greece.
C3 Democritus University of Thrace
RP Nalpantidis, L (corresponding author), Democritus Univ Thrace, Robot & Automat Lab, Prod & Management Engn Dept, Univ Campus, GR-67100 Xanthi, Greece.
EM lanalpa@pme.duth.gr; agaster@pme.duth.gr
RI Gasteratos, Antonios/AAI-4740-2021; Nalpantidis, Lazaros/J-1803-2012;
   Gasteratos, Antonios/B-7796-2012; Nalpantidis, Lazaros/AAV-9414-2021
OI Gasteratos, Antonios/0000-0002-5421-0332; Nalpantidis,
   Lazaros/0000-0002-3620-4123; Nalpantidis, Lazaros/0000-0002-3620-4123
FU E.C. [FP6-IST-2005-045541]
FX This work was supported by the E.C. funded research project for vision
   and chemiresistor equipped web-connected finding robots, "View-Finder",
   FP6-IST-2005-045541.
CR [Anonymous], 1992, R. woods digital image processing
   Binaghi E, 2004, PATTERN RECOGN LETT, V25, P1743, DOI 10.1016/j.patrec.2004.07.001
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cheng L., 2006, 2006 IEEE COMP SOC C, P2378, DOI DOI 10.1109/CVPR.2006.251
   Corke PI, 2005, IEEE ROBOT AUTOM MAG, V12, P16, DOI 10.1109/MRA.2005.1577021
   Di Stefano L, 2004, IMAGE VISION COMPUT, V22, P983, DOI 10.1016/j.imavis.2004.03.009
   Gu Z, 2008, PATTERN RECOGN LETT, V29, P1230, DOI 10.1016/j.patrec.2008.01.032
   Hogue A, 2007, IEEE SYS MAN CYBERN, P540
   Jain R., 1995, MACHINE VISION
   Jobson DJ, 1997, IEEE T IMAGE PROCESS, V6, P965, DOI 10.1109/83.597272
   Klancar G, 2004, ROBOT AUTON SYST, V46, P125, DOI 10.1016/j.robot.2003.11.001
   Klaus A, 2006, INT C PATT RECOG, P15
   Leung C, 2008, IMAGE VISION COMPUT, V26, P1371, DOI 10.1016/j.imavis.2007.11.013
   MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482
   Mordohai P, 2006, IEEE T PATTERN ANAL, V28, P968, DOI 10.1109/TPAMI.2006.129
   Muñoz-Salinas R, 2007, IMAGE VISION COMPUT, V25, P995, DOI 10.1016/j.imavis.2006.07.012
   Murray D, 2000, AUTON ROBOT, V8, P161, DOI 10.1023/A:1008987612352
   Murray D, 1997, IEEE INT CONF ROBOT, P1694, DOI 10.1109/ROBOT.1997.614387
   Nalpantidis L, 2008, INT J OPTOMECHATRONI, V2, P435, DOI 10.1080/15599610802438680
   Ogale AS, 2007, INT J COMPUT VISION, V72, P9, DOI 10.1007/s11263-006-8890-9
   Ogale AS, 2005, IEEE INT CONF ROBOT, P819
   Ogale AS, 2005, INT J COMPUT VISION, V65, P147, DOI 10.1007/s11263-005-3672-3
   OGALE AS, 2009, STEREO MATCHING CODE
   Pollefeys M, 2008, INT J COMPUT VISION, V78, P143, DOI 10.1007/s11263-007-0086-4
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Scharstein D, 2003, PROC CVPR IEEE, P195
   Sim R, 2009, IMAGE VISION COMPUT, V27, P167, DOI 10.1016/j.imavis.2008.04.003
   SUN C, 2003, IEEE T SMC B, V34, P760
   Vineet V., 2008, IEEE COMP SOC C COMP, P1, DOI DOI 10.1109/CVPRW.2008.4563095
   Vonikakis V, 2008, IET IMAGE PROCESS, V2, P19, DOI 10.1049/iet-ipr:20070012
   VONIKAKIS V, 2009, PHOTOENHANCER 2 4
   Yang QX, 2009, IEEE T PATTERN ANAL, V31, P492, DOI 10.1109/TPAMI.2008.99
   Yoon KJ, 2006, LECT NOTES COMPUT SC, V3852, P761
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
   YOON KJ, 2006, IEEE C COMP VIS PATT, V2, P2371
   Yoon S, 2005, PATTERN RECOGN LETT, V26, P2221, DOI 10.1016/j.patrec.2005.03.037
   Zach C., 2004, P INT C CENTR EUR CO, P275
   2008, MIDDLEBURY STEREO VI
NR 39
TC 50
Z9 68
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 940
EP 951
DI 10.1016/j.imavis.2009.11.011
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200009
DA 2024-07-18
ER

PT J
AU Tsai, DM
   Chang, CC
   Chao, SM
AF Tsai, Du-Ming
   Chang, Chih-Chieh
   Chao, Shin-Min
TI Micro-crack inspection in heterogeneously textured solar wafers using
   anisotropic diffusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Defect detection; Heterogeneous texture; Anisotropic diffusion;
   Micro-crack; Solar wafer
ID AUTOMATED SURFACE INSPECTION; DEFECT DETECTION; GABOR FILTERS;
   CLASSIFICATION; SEGMENTATION; RESOLUTION; FEATURES; SPACE
AB This paper proposes a machine vision scheme for detecting micro-crack defects in solar wafer manufacturing. The surface of a polycrystalline silicon wafer shows heterogeneous textures, and the shape of a micro-crack is similar to the multi-grain background. They make the automated visual inspection task extremely difficult.
   The low gray-level and high gradient are two main characteristics of a micro-crack in the sensed image with front-light illumination. An anisotropic diffusion scheme is proposed to detect the subtle defects. The proposed diffusion model takes both gray-level and gradient as features to adjust the diffusion coefficients. It acts as an adaptive smoothing process. Only the pixels with both low gray-levels and high gradients will generate high diffusion coefficients. It then smoothes the suspected defect region and preserves the original gray-levels of the faultless background. By subtracting the diffused image from the original image, the micro-crack can be distinctly enhanced in the difference image. A simple binary thresholding, followed by morphological operations, can then easily segment the micro-crack. The proposed method has shown its effectiveness and efficiency for a test set of more than 100 wafer images. It has also achieved a fast computation of 0.09 s for a 640 x 480 image. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Tsai, Du-Ming; Chang, Chih-Chieh; Chao, Shin-Min] Yuan Ze Univ, Dept Ind Engn & Management, Tao Yuan, Taiwan.
C3 Yuan Ze University
RP Tsai, DM (corresponding author), Yuan Ze Univ, Dept Ind Engn & Management, 135 Yuan Tung Rd, Tao Yuan, Taiwan.
EM iedmtsai@saturn.yzu.edu.tw
CR Azencott R, 1997, IEEE T PATTERN ANAL, V19, P148, DOI 10.1109/34.574796
   Bakalexis SA, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1203, DOI 10.1109/ICDSP.2002.1028309
   Bodnarova A, 2000, INT CONF ACOUST SPEE, P3606, DOI 10.1109/ICASSP.2000.860182
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chao SM, 2008, IMAGE VISION COMPUT, V26, P187, DOI 10.1016/j.imavis.2007.03.003
   Chen S., 1993, Pure and Applied Optics, V2, P429, DOI 10.1088/0963-9659/2/5/004
   CLARK M, 1987, PATTERN RECOGN LETT, V6, P261, DOI 10.1016/0167-8655(87)90086-9
   Clausi DA, 2000, PATTERN RECOGN, V33, P1835, DOI 10.1016/S0031-3203(99)00181-8
   COHEN FS, 1992, CVGIP-GRAPH MODEL IM, V54, P239, DOI 10.1016/1049-9652(92)90054-2
   CONNERS RW, 1983, IEEE T PATTERN ANAL, V5, P573, DOI 10.1109/TPAMI.1983.4767446
   DAUGMAN JG, 1985, J OPT SOC AM A, V2, P1160, DOI 10.1364/JOSAA.2.001160
   Deng H., 2000, INT S MULT INF PROC, P62
   Escofet J, 1998, P SOC PHOTO-OPT INS, V3490, P207, DOI 10.1117/12.308923
   Fu Z, 2004, 2004 INTERNATIONAL CONFERENCE ON THE BUSINESS OF ELECTRONIC PRODUCT RELIABILITY AND LIABILITY, PROCEEDINGS, P77, DOI 10.1109/BEPRL.2004.1308153
   HARALICK RM, 1973, IEEE T SYST MAN CYB, VSMC3, P610, DOI 10.1109/TSMC.1973.4309314
   KHALAJ BH, 1994, MACH VISION APPL, V7, P178, DOI 10.1007/BF01211662
   Lambert G, 1997, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL III, P201, DOI 10.1109/ICIP.1997.632054
   LINNETT LM, 1995, IEE P-VIS IMAGE SIGN, V142, P1, DOI 10.1049/ip-vis:19951678
   LIU SS, 1990, COMPUT VISION GRAPH, V49, P52, DOI 10.1016/0734-189X(90)90162-O
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Maruo K, 1999, IEICE T ELECTRON, VE82C, P1003
   Niessen WJ, 1997, COMPUT VIS IMAGE UND, V66, P233, DOI 10.1006/cviu.1997.0614
   OHSHIGE T, 1991, ELEVENTH IEEE/CHMT INTERNATIONAL ELECTRONICS MANUFACTURING TECHNOLOGY SYMPOSIUM : THE KEY TO MANUFACTURING IN THE 1990S, P192, DOI 10.1109/IEMT.1991.279775
   Ordaz MA, 2000, P SOC PHOTO-OPT INS, V3966, P238, DOI 10.1117/12.380078
   Paschos G, 2000, PATTERN RECOGN LETT, V21, P837, DOI 10.1016/S0167-8655(00)00043-X
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Pilla M, 2002, P SOC PHOTO-OPT INS, V4710, P699, DOI 10.1117/12.459624
   Pölzleitner W, 1999, P SOC PHOTO-OPT INS, V3837, P220, DOI 10.1117/12.360301
   Ramana KV, 1996, PATTERN RECOGN, V29, P1447, DOI 10.1016/0031-3203(96)00008-8
   Sari-Sarraf H, 1998, PROC CVPR IEEE, P938, DOI 10.1109/CVPR.1998.698717
   SIEW LH, 1988, IEEE T PATTERN ANAL, V10, P92, DOI 10.1109/34.3870
   Tsai DM, 2005, IMAGE VISION COMPUT, V23, P325, DOI 10.1016/j.imavis.2004.09.003
   Tsai DM, 2003, IMAGE VISION COMPUT, V21, P413, DOI 10.1016/S0262-8856(03)00003-9
   Tsai DM, 2003, IMAGE VISION COMPUT, V21, P307, DOI 10.1016/S0262-8856(03)00007-6
   Tsai DM, 1999, IMAGE VISION COMPUT, V18, P49, DOI 10.1016/S0262-8856(99)00009-8
   Tsai DM, 2001, PATTERN RECOGN, V34, P1285, DOI 10.1016/S0031-3203(00)00071-6
   VANHULLE MM, 1993, NEURAL NETWORKS, V6, P7, DOI 10.1016/S0893-6080(05)80070-X
   Wiltschi K, 2000, MACH VISION APPL, V12, P113, DOI 10.1007/s001380050130
NR 38
TC 73
Z9 87
U1 6
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 491
EP 501
DI 10.1016/j.imavis.2009.08.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300019
DA 2024-07-18
ER

PT J
AU Zheng, Y
   Li, GY
   Sun, XH
   Zhou, XM
AF Zheng Ying
   Li Guangyao
   Sun Xiehua
   Zhou Xinmin
TI A geometric active contour model without re-initialization for color
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Squared local contrast; Deviation penalization term; The GACV model;
   Geometric active contour
ID EDGE-DETECTION; LEVEL SET; SEGMENTATION; DIFFUSION; OBJECTS; REGION
AB A geometric active contour model without re-initialization for color images is proposed in this paper. It combines directional information about edge location based on local squared contrast as a part of driving force, together with the improved geodesic active contour containing Bayes error based statistical region information as well as an extra term that penalizes deviation of the level set function from a signed distance function. All these measures are integrated in a unified frame thus the costly re-initialization procedure can be completely eliminated. Experimental results on real color images have shown that our model can extract contours of objects in images precisely and its performance is much better than the Geodesic-Aided C-V (GACV) model. Crown Copyright (C) 2009 Published by Elsevier B.V. All rights reserved.
C1 [Zheng Ying; Li Guangyao; Zhou Xinmin] Tongji Univ, Coll Elect & Informat, Shanghai 201804, Peoples R China.
   [Sun Xiehua] China Liliang Univ, Coll Informat Engn, Hangzhou 310018, Zhejiang, Peoples R China.
C3 Tongji University
RP Zheng, Y (corresponding author), Tongji Univ, Coll Elect & Informat, Shanghai 201804, Peoples R China.
EM zy1482@yahoo.com.cn
FU National Science Foundation of China [60771065]
FX This work is supported by the National Science Foundation of China (NO.
   60771065). We are grateful to anonymous referees for useful comments and
   suggestions.
CR [Anonymous], 2002, SURFACES
   [Anonymous], P 34 AS C SIGN SYST
   BROOK A, 2001, P 3 INT C SCAL SPAC, V2106, P362
   Brox T, 2004, LECT NOTES COMPUT SC, V3175, P415
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   Chan T. F., 2000, J VISIONAL COMMUNICA, V11, P30
   Chan TF, 2001, IEEE T IMAGE PROCESS, V10, P266, DOI 10.1109/83.902291
   Chen L, 2006, PATTERN RECOGN, V39, P1391, DOI 10.1016/j.patcog.2006.01.017
   CUMANI A, 1991, CVGIP-GRAPH MODEL IM, V53, P40, DOI 10.1016/1049-9652(91)90018-F
   DIBOS F, 1997, ACT 16 C GRETSI GREN, V9, P367
   Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533
   HUA XX, 2004, IEEE T IMAGE PROCESS, V5, P640
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   KICHENASSAMY S, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P810, DOI 10.1109/ICCV.1995.466855
   KIMMEL R, 2003, FAST EDGE INTEGRATIO
   KOEPFLER G, 1994, SIAM J NUMER ANAL, V31, P282, DOI 10.1137/0731015
   Koschan A., 1995, Proceedings of the 2nd Asian Conference on Computer Vision, V3, P574
   Li CM, 2005, PROC CVPR IEEE, P430
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Naik SK, 2006, IEEE T IMAGE PROCESS, V15, P2588, DOI 10.1109/TIP.2006.877408
   Olver PJ, 1999, ACTA APPL MATH, V59, P45, DOI 10.1023/A:1006295328209
   OSHER S, 1988, J COMPUT PHYS, V79, P12, DOI 10.1016/0021-9991(88)90002-2
   Paragios N, 2004, IEEE T PATTERN ANAL, V26, P402, DOI 10.1109/TPAMI.2004.1262337
   PARAGIOS N, 1998, 3440 INRIA
   PARK HK, 2001, P INT C ADV ROB, V8, P229
   Pi L, 2007, IMAGE VISION COMPUT, V25, P1414, DOI 10.1016/j.imavis.2006.12.013
   Pi L, 2007, J MATH IMAGING VIS, V27, P51, DOI 10.1007/s10851-006-9797-3
   Rousson M, 2004, LECT NOTES COMPUT SC, V3117, P123
   Sapiro G, 1997, COMPUT VIS IMAGE UND, V68, P247, DOI 10.1006/cviu.1997.0562
   Sapiro G, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P817, DOI 10.1109/ICIP.1996.559624
   Shah J, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL I, P461, DOI 10.1109/ICIP.1996.559533
   SMEREKA P, 1997, J COMPUT PHYS, V135, P8
   Vasilevskiy A, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P149, DOI 10.1109/ICCV.2001.937511
   XIE XH, 2003, P IEEE 10 INT C IM P, V2, P153
   Xu CY, 1998, IEEE T IMAGE PROCESS, V7, P359, DOI 10.1109/83.661186
   Yu SY, 2007, LECT NOTES COMPUT SC, V4577, P286
   Z LC, 2007, P 4 INT C FUZZ SYST, V1, P135
   ZENZO SD, 1986, COMPUTER VISION GRAP, V33, P211
   ZHU SC, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P416, DOI 10.1109/ICCV.1995.466909
   Zhu SY, 1999, OPT ENG, V38, P612, DOI 10.1117/1.602105
NR 40
TC 15
Z9 19
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1411
EP 1417
DI 10.1016/j.imavis.2009.01.001
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200017
DA 2024-07-18
ER

PT J
AU Soukup, D
   Bodenhofer, U
   Mittendorfer-Holzer, M
   Mayer, K
AF Soukup, Daniel
   Bodenhofer, Ulrich
   Mittendorfer-Holzer, Markus
   Mayer, Konrad
TI Semi-automatic identification of print layers from a sequence of sample
   images: A case study from banknote print inspection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Block matching; Local correlation; Print inspection; Separation of print
   layers
ID POINT CORRESPONDENCE; MOTION; REGISTRATION; AGGREGATION; ALGORITHMS;
   OPERATORS
AB This article presents an approach for finding displacements of print layers from sequences of sample images semi-automatically with the aim to simplify and shorten the setup of inspection systems for printing processes in which the perfect alignment of print layers cannot be guaranteed. The basic idea behind the proposed approach is to identify pixels which are likely to have the same displacements for a given pair of images. This relatively coarse information is computed for several pairs of sample images and aggregated in order to identify regions that tend to have the same displacement over a large proportion of image pair comparisons. This idea is motivated and justified in detail. The test cases considered in this study are data from banknote print inspection. We use these data to illustrate the steps of the algorithm. The examples demonstrate the method's capability to sensibly identify print layers, even if they overlap partially. Although the paper concentrates on a particular case study, the method can be used in any print inspection process with similar characteristics. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Bodenhofer, Ulrich] Johannes Kepler Univ Linz, Inst Bioinformat, A-4040 Linz, Austria.
   [Soukup, Daniel; Mayer, Konrad] Austrian Res Ctr, ARC Smart Syst Div, A-2444 Seibersdorf, Austria.
   [Mittendorfer-Holzer, Markus] COMNEON Elect Technol, A-4040 Linz, Austria.
C3 Johannes Kepler University Linz; Austrian Institute of Technology (AIT)
RP Bodenhofer, U (corresponding author), Johannes Kepler Univ Linz, Inst Bioinformat, A-4040 Linz, Austria.
EM daniel.soukup@arcs.ac.at; bodenhofer@bioinf.jku.at;
   Markus.Mittendorfer-Holzer@comneon.com; konrad.mayer@arcs.ac.at
RI Bodenhofer, Ulrich/B-7030-2008
OI Bodenhofer, Ulrich/0000-0001-6859-8828
CR AGGARWAL JK, 1988, P IEEE, V76, P917, DOI 10.1109/5.5965
   Anderberg M.R., 1973, Probability and Mathematical Statistics
   [Anonymous], 1987, PROC ISPRS INTERCOMM
   BALLARD DH, 1982, BROWN COMPUTER VISIO
   BARNARD ST, 1980, IEEE T PATTERN ANAL, V2, P333, DOI 10.1109/TPAMI.1980.4767032
   Boixader D, 2000, HDB FUZZ SET SER, V7, P261
   Chang SH, 1997, PATTERN RECOGN, V30, P311, DOI 10.1016/S0031-3203(96)00076-3
   Coldani G, 2000, 5TH INTERNATIONAL WORKSHOP ON COMPUTER ARCHITECTURES FOR MACHINE PERCEPTION, PROCEEDINGS, P163, DOI 10.1109/CAMP.2000.875974
   Davis C. Q., 1995, Proceedings International Symposium on Computer Vision (Cat. No.95TB100006), P7, DOI 10.1109/ISCV.1995.476969
   De Baets B., 1997, J. Fuzzy Math., V5, P471
   Forstner W., 1986, International Archives of the Photogrammetry, V26, P150
   GHAVARI H, 1990, IEEE T CIRCUITS SYST, V37, P649
   Gottwald S., 1993, Fuzzy Sets and Fuzzy Logic
   HARALICK RM, 1993, COMPUT ROBOT VIS, V2
   HARALICK RM, 1992, COMPUT ROBOT VIS, V1
   HARDIN W, 2008, VISION SYSTEMS DESIG, V13
   Harris C., 1988, Proc. of the 4th Alvey Vision Conference, P189
   HOHLE U, 1993, P 1 EUR C FUZZ INT T, V1, P358
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Huber-Moerk R, 2007, PATTERN RECOGN LETT, V28, P2037, DOI 10.1016/j.patrec.2007.06.008
   Jahne B., 1997, DIGITAL IMAGE PROCES
   KOMAREK T, 1989, IEEE T CIRCUITS SYST, V36, P1301, DOI 10.1109/31.44346
   KRATTENTHALER W, 1994, P IEEE INT C IM PROC, V1, P208
   MICHALSKI RS, 1992, ENCY ARTIFICIAL INTE, P168
   Pless R, 2000, IEEE T PATTERN ANAL, V22, P768, DOI 10.1109/34.868679
   Pradera A, 2002, STUD FUZZ SOFT COMP, V90, P125
   RANGARAJAN K, 1991, CVGIP-IMAG UNDERSTAN, V54, P56, DOI 10.1016/1049-9660(91)90075-Z
   SALARI V, 1990, IEEE T PATTERN ANAL, V12, P87, DOI 10.1109/34.41387
   Saminger S, 2002, INT J UNCERTAIN FUZZ, V10, P11, DOI 10.1142/S0218488502001806
   Serra J., 1983, IMAGE ANAL MATH MORP
   Serra J., 1994, MATH MORPHOLOGY ITS
   SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872
   Shafique K, 2005, IEEE T PATTERN ANAL, V27, P51, DOI 10.1109/TPAMI.2005.1
   SOJKA E, 2003, P IEEE INT C IM PROC, V2, P445
   SOUKUP D, 2004, THESIS J KEPLER U LI
   TIAN Q, 1986, COMPUT VISION GRAPH, V35, P220, DOI 10.1016/0734-189X(86)90028-9
   Ullman Shimon, 1979, INTERPRETATION VISUA, DOI [DOI 10.7551/MITPRESS/3877.001.0001, DOI 10.1016/0013-4694(80)90055-3]
   VALVERDE L, 1985, FUZZY SET SYST, V17, P313, DOI 10.1016/0165-0114(85)90096-X
   WARD JH, 1963, J AM STAT ASSOC, V58, P236, DOI 10.2307/2282967
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 40
TC 3
Z9 4
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 989
EP 998
DI 10.1016/j.imavis.2008.08.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000001
DA 2024-07-18
ER

PT J
AU Gnanaprakasam, P
   Parker, JM
   Ganapathiraman, S
   Hou, Z
AF Gnanaprakasam, Pradeep
   Parker, Johne M.
   Ganapathiraman, Subburengan
   Hou, Zhen
TI Efficient 3D characterization of raised topological defects in smooth
   specular coatings
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Surface reflectance model; Surface quality of specular coatings; Defect
   characterization; Camera calibration
ID SYSTEM
AB Many smooth, highly specular coatings, such as automotive paints and appliance coatings, are subjected to considerable performance demands and manufacturers spend significant sums each year to monitor and repair coating surface quality. Additionally, changing product specifications and environmental regulations will continue to affect the processing parameters that influence surface appearance and quality. Therefore, it is vital to develop robust methods to monitor surface quality on-line and continuously examine the processes that significantly affect surface appearance in real-time. As a critical step, this paper presents a cost-effective machine vision system design that utilizes surface reflectance models as a rational basis. Experimental and numerical investigations of diffuse angle images of specular coated surfaces confirm that these images yield a three-dimensional characterization of surface defects, efficiently, from a single image. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Parker, Johne M.; Ganapathiraman, Subburengan; Hou, Zhen] Univ Kentucky, Dept Mech Engn, Lexington, KY 40506 USA.
   [Gnanaprakasam, Pradeep] SMC Inc, Lexington, KY 40511 USA.
C3 University of Kentucky
RP Parker, JM (corresponding author), Univ Kentucky, Dept Mech Engn, 151 Ralph G Anderson, Lexington, KY 40506 USA.
EM jparker@engr.uky.edu
FU National Science Foundation; Toyota Motor Manufacturing North America; 
   [DMI-9984867];  [DMI-0074976]
FX This material is based upon work supported by the National Science
   Foundation, Division of Design, Manufacture and Industrial Innovation,
   under Grants DMI-9984867 and DMI-0074976, and Toyota Motor Manufacturing
   North America. The authors gratefully acknowledge undergraduate
   researcher James Casalino for his work in obtaining Eq. (7) and
   programming this equation on-board the DVT 530 to facilitate preliminary
   real-time studies.
CR Alman DavidH., 1987, Proceedings of the ISCC Williamsburg Conference on Appearance, P53
   Beckmann P., 1987, The Scattering of Electromagnetic Waves from Rough Surfaces
   BLAKE A, 1990, NATURE, V343, P165, DOI 10.1038/343165a0
   Boukouvalas C, 1998, J MATER PROCESS TECH, V82, P179, DOI 10.1016/S0924-0136(98)00044-2
   CHEN CH, 1991, IEEE WORKSH DIR AUT
   CHEONG YL, 2004, THESIS U KENTUCKY LE
   COULOT C, 1997, P IEEE ASME INT C AD
   COWAN C, 1991, IEEE WORKSH DES AUT
   FINNEY GB, 1994, SPIE, V2183, P145
   Gagalowicz A., 1990, SCI VISUALIZATION GR, P233
   GANAPATHIRAMAN S, 2005, THESIS U KENTUCKY LE
   GNANAPRAKASAM P, 2004, THESIS U KENTUCKY LE
   Goral C. M., 1984, Computers & Graphics, V18, P213
   Grynberg A., 1989, 1575 LBID LAWR BERK
   HAROLD R, 2000, NIST WORKSH MET MOD
   Horn B.K.P, 1986, Robot Vision
   HUNTER R.S., 1975, MEASUREMENT APPEARAN
   ISTRE J, 2003, CD ROM P 2004 NSF DE
   ISTRE J, 2004, THESIS U KENTUCKY LE
   JAIN AK, 1990, TEXTURE ANAL AUTOMOT
   Kajiya J. T., 1986, SIGGRAPH, P143, DOI 10.1145/15886.15902
   Kaplan H, 1997, PHOTON SPECTRA, V31, P98
   LAI T, 1999, THESIS U KENTUCKY LE
   LAI T, 2000, MECHATRONICS MACHINE, P83
   Lambourne R., 1987, PAINT SURFACE COATIN
   LEE KM, 1991, INT J PROD ECON, V25, P141, DOI 10.1016/0925-5273(91)90140-O
   LEE KM, 1994, J ENG IND-T ASME, V116, P421, DOI 10.1115/1.2902123
   LEX K, 1997, Patent No. 5596412
   McCamy CS, 1996, COLOR RES APPL, V21, P292, DOI 10.1002/(SICI)1520-6378(199608)21:4<292::AID-COL4>3.3.CO;2-7
   MCKNIGHT ME, 1998, PROGR ORGANIC COATIN, P1
   MELAM CSN, 1999, THESIS U KENTUCKY LE
   MEYER GW, 1986, ACM T GRAPHIC, V5, P30, DOI 10.1145/7529.7920
   NAYAR SK, 1991, IEEE T PATTERN ANAL, V13, P611, DOI 10.1109/34.85654
   Nishita T., 1985, Computer Graphics, V19, P23, DOI 10.1145/325165.325169
   PARKER J, 2005, 2005 IEEE ASME INT C
   PARKER JB, 1992, Patent No. 5078496
   Parker JM, 2002, P I MECH ENG B-J ENG, V216, P1073, DOI 10.1243/09544050260174274
   Parker JM, 1999, J MANUF SCI E-T ASME, V121, P763, DOI 10.1115/1.2833139
   PARKER JM, 2002, P IEEE INT C ROB AUT
   RUSHMEIER HE, 1992, SME APPL MACH VIS C
   SAFIRI H, 1995, COMPUT ELECTR ENG, V21, P433, DOI 10.1016/0045-7906(95)00022-M
   SILLION FX, 1991, COMP GRAPH, V25, P187, DOI 10.1145/127719.122739
   STEENHOEK LE, 1987, INT SOC COL COUNC WI, P71
   TORRANCE KE, 1966, J HEAT TRANSF, V88, P223, DOI 10.1115/1.3691519
   Tsai R., 1987, IEEE Journal on Robotics and Automation, V3, p323,344
   VENABLE WH, 1987, Patent No. 4711580
   Venable WilliamH., 1987, Proceedings of the ISCC Williamsburg Conference on Appearance, P57
   Ward G. J., 1988, Computer Graphics, V22, P85, DOI 10.1145/378456.378490
   Ward G. J., 1994, P 21 ANN C COMP GRAP, P459, DOI [DOI 10.1145/192161.192286, 10.1145/192161.192286]
   Wu C. K., 1990, International Journal of Modelling and Simulation, V10, P67
   ZWINKELS JC, 1995, SURFACE COATINGS INT, V12, P512
NR 51
TC 4
Z9 5
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 319
EP 330
DI 10.1016/j.imavis.2008.03.008
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600002
DA 2024-07-18
ER

PT J
AU Ecker, A
   Ullman, S
AF Ecker, Ady
   Ullman, Shimon
TI A hierarchical non-parametric method for capturing non-rigid
   deformations
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Image similarity; Non-rigid deformations; Relative dynamic programming;
   Overlapping patches
ID REPRESENTATION
AB We present a novel approach for measuring image similarity based on the composition of parts. The measure identifies common sub-regions between the images at multiple sizes, and evaluates the amount of deformation required to align the common regions. The scheme allows complex, non-rigid deformation of the images, and penalizes irregular deformations more than coherent shifts of larger sub-parts. The measure is implemented by an algorithm which is a variant of dynamic programming, extended to multi-dimensions, and is using scores measured on a relative scale. The similarity measure is shown to be robust to non-rigid deformations of parts at various positions and scales, and to capture basic characteristics of human similarity judgments. (C) 2008 Published by Elsevier B.V.
C1 [Ecker, Ady] Univ Toronto, Toronto, ON M5S 1A1, Canada.
   [Ullman, Shimon] Weizmann Inst Sci, IL-76100 Rehovot, Israel.
C3 University of Toronto; Weizmann Institute of Science
RP Ecker, A (corresponding author), Univ Toronto, Toronto, ON M5S 1A1, Canada.
EM adyecker@cs.toronto.edu; shimon.ullman@weizmann.ac.il
CR [Anonymous], 1997, Pattern matching algorithms
   [Anonymous], 1977, TECHNIQUES AUTOMATIC
   [Anonymous], 2006, COMPUTER VISION PATT
   Basri R, 1998, VISION RES, V38, P2365, DOI 10.1016/S0042-6989(98)00043-1
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Ecker A, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P50, DOI 10.1109/CRV.2005.6
   ECKER A, 2002, THESIS WEIZMANN I SC
   Efros A. A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1033, DOI 10.1109/ICCV.1999.790383
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Felzenszwalb PF, 2005, IEEE T PATTERN ANAL, V27, P208, DOI 10.1109/TPAMI.2005.35
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Klein P, 2000, PROCEEDINGS OF THE ELEVENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P696
   Leibe B., 2004, ECCV 04 WORKSH STAT
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Milios E, 2000, IEEE T IMAGE PROCESS, V9, P141, DOI 10.1109/83.817606
   Nelson RC, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P614, DOI 10.1109/ICCV.1998.710781
   PALMER SE, 1978, MEM COGNITION, V6, P91, DOI 10.3758/BF03197433
   Ratan AL, 1998, PROC CVPR IEEE, P634, DOI 10.1109/CVPR.1998.698671
   SALI E, 1999, P BRIT MACH VIS C, P203
NR 19
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 87
EP 98
DI 10.1016/j.imavis.2006.10.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Hamarneh, G
   Li, XX
AF Hamarneh, Ghassan
   Li, Xiaoxing
TI Watershed segmentation using prior shape and appearance knowledge
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Watershed transformation; Prior shape knowledge; Segmentation; k-Means
   clustering
ID IMAGE; TRANSFORM
AB Watershed transformation is a common technique for image segmentation. However, its use for automatic medical image segmentation has been limited particularly due to oversegmentation and sensitivity to noise. Employing prior shape knowledge has demonstrated robust improvements to medical image segmentation algorithms. We propose a novel method for enhancing watershed segmentation by utilizing prior shape and appearance knowledge. Our method iteratively aligns a shape histogram with the result of an improved k-means clustering algorithm of the watershed segments. Quantitative validation of magnetic resonance imaging segmentation results supports the robust nature of our method. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Hamarneh, Ghassan; Li, Xiaoxing] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Hamarneh, G (corresponding author), Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
EM hamarneh@cs.sfu.ca; xlil@cs.sfu.ca
RI Hamarneh, Ghassan/AAE-6673-2021; Hamarneh, Ghassan/B-1063-2009
OI Hamarneh, Ghassan/0000-0001-5040-7448; 
CR Agarwal PK, 1998, ACM COMPUT SURV, V30, P412, DOI 10.1145/299917.299918
   Beucher S, 1994, COMP IMAG VIS, V2, P69
   Beucher S., 1979, P INT WORKSH IM PROC, V132
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   BREU H, 1995, IEEE T PATTERN ANAL, V17, P529, DOI 10.1109/34.391389
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Grau V, 2004, IEEE T MED IMAGING, V23, P447, DOI 10.1109/TMI.2004.824224
   Hamarneh G, 2000, IEEE SYS MAN CYBERN, P2458, DOI 10.1109/ICSMC.2000.884361
   Hamarneh G, 2000, IEEE SYS MAN CYBERN, P1610, DOI 10.1109/ICSMC.2000.886252
   HAMARNEH G, 2001, LNCS, V2208, P66
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Leventon ME, 2000, PROC CVPR IEEE, P316, DOI 10.1109/CVPR.2000.855835
   Li XX, 2005, 2ND CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P27
   LOBREGT S, 1995, IEEE T MED IMAGING, V14, P12, DOI 10.1109/42.370398
   McInerney T, 2002, MED IMAGE ANAL, V6, P251, DOI 10.1016/S1361-8415(02)00083-X
   Moga AN, 1997, IEEE T PATTERN ANAL, V19, P441, DOI 10.1109/34.589204
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   SHENTON ME, 1992, NEW ENGL J MED, V327, P604, DOI 10.1056/NEJM199208273270905
   STEGMANN MB, 2001, P 12 SCAND C IM AN S, V1, P90
   STEGMANN MB, 2002, ANNOTATED DATASET 14
   Szekely G, 1996, Med Image Anal, V1, P19, DOI 10.1016/S1361-8415(01)80003-7
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Vincent L, 1993, IEEE T IMAGE PROCESS, V2, P176, DOI 10.1109/83.217222
NR 24
TC 91
Z9 110
U1 3
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 59
EP 68
DI 10.1016/j.imavis.2006.10.009
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700007
DA 2024-07-18
ER

PT J
AU Duan, W
   Kuester, F
   Gaudiot, JL
   Hammami, O
AF Duan, Weisheng
   Kuester, Falko
   Gaudiot, Jean-Luc
   Hammami, Omar
TI Automatic object and image alignment using Fourier Descriptors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image alignment; edge detection; Fourier Descriptors; correspondence;
   transformation; iterative closest point
ID COMPUTATIONAL APPROACH; REGISTRATION
AB This paper presents a new edge-based technique for image alignment, combining Fourier Descriptors (FD) and the Iterative Closest Point (ICP) computation into an accurate and robust processing pipeline. Once edges are identified in the reference and target images, Fourier Descriptors are used to simultaneously determine edge correspondence and estimate the transformation parameters. Subsequently, an ICP computation is applied to further improve the alignment results. Using Fourier Descriptors in combination with a reliable distance matrix, corresponding edge pairs can be reliably detected for all identified edges. (C) 2008 Published by Elsevier B.V.
C1 [Kuester, Falko] Univ Calif San Diego, Dept Struct Engn, La Jolla, CA 92093 USA.
   [Duan, Weisheng] Ion Beam Applicat SA, B-1348 Louvain, Belgium.
   [Gaudiot, Jean-Luc] Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92697 USA.
   [Hammami, Omar] Ecole Natl Super Tech Avancees, F-75739 Paris 15, France.
C3 University of California System; University of California San Diego;
   University of California System; University of California Irvine;
   Institut Polytechnique de Paris; ENSTA Paris
RP Kuester, F (corresponding author), Univ Calif San Diego, Dept Struct Engn, La Jolla, CA 92093 USA.
EM wduan@iba.be; fkuester@ucsd.edu; gaudiot@uci.edu; hammami@ensta.fr
RI cai, bo/G-1491-2010
CR ADALSTEINSSON D, 1995, J COMPUT PHYS, V118, P269, DOI 10.1006/jcph.1995.1098
   [Anonymous], 1998, Image processing, analysis, and machine vision
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   BESL PJ, 1992, IEEE T PATTERN ANAL, V14, P239, DOI 10.1109/34.121791
   Bhattacharya D, 1997, PATTERN RECOGN, V30, P1373, DOI 10.1016/S0031-3203(96)00177-X
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Caselles V, 1997, INT J COMPUT VISION, V22, P61, DOI 10.1023/A:1007979827043
   FITZGIBBON AW, 2001, P 11 BRIT MACH VIS C
   FOLKERS A, 2002, P INT C PATT REC ICP, V3, P269
   Ghita O, 2002, J ELECTRON IMAGING, V11, P479, DOI 10.1117/1.1501574
   Goldenberg R, 2001, IEEE T IMAGE PROCESS, V10, P1467, DOI 10.1109/83.951533
   GOSHTASBY A, 1986, IEEE T GEOSCI REMOTE, V24, P390, DOI 10.1109/TGRS.1986.289597
   Govindu V, 1998, INT C PATT RECOG, P37, DOI 10.1109/ICPR.1998.711074
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   LI H, 1995, IEEE T IMAGE PROCESS, V4, P320, DOI 10.1109/83.366480
   Likar B, 1999, MED PHYS, V26, P1678, DOI 10.1118/1.598660
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   ROHR K, 2001, COMPUTATIONAL IMAGIN, V21
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   Weickert J, 1998, IEEE T IMAGE PROCESS, V7, P398, DOI 10.1109/83.661190
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 23
TC 17
Z9 21
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1196
EP 1206
DI 10.1016/j.imavis.2008.01.009
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300002
DA 2024-07-18
ER

PT J
AU Suau, P
   Escolano, F
AF Suau, P.
   Escolano, F.
TI Bayesian optimization of the scale saliency filter
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE scale saliency detector; information theory
AB The scale saliency feature extraction algorithm by Kadir and Brady has been widely used in many computer vision applications. However, when compared to other feature extractors, its computational cost is high. In this paper, we analyze how saliency evolves through scale space, demonstrating an intuitive idea: if an image region is homogeneous at higher scales, it will probably also be homogeneous at lower scales. From the results of this analysis we propose a Bayesian filter based on Information Theory, that given some statistical knowledge about the images being considered, discards pixels from an image before applying the scale saliency detector. Experiments show that if our filter is used, the efficiency of the original algorithm increases with low localization and detection error. (C) 2008 Published by Elsevier B.V.
C1 [Suau, P.; Escolano, F.] Univ Alicante, Dpto Ciencia Computac & Inteligencia Artificial, E-03080 Alicante, Spain.
C3 Universitat d'Alacant
RP Suau, P (corresponding author), Univ Alicante, Dpto Ciencia Computac & Inteligencia Artificial, E-03080 Alicante, Spain.
EM pablo@dccia.ua.es; sco@dccia.ua.es
CR BHAT P, 2006, IEEE C COMP VIS PATT, P2491
   Carneiro G, 2005, PROC CVPR IEEE, P296
   Cazorla MA, 2003, IEEE T IMAGE PROCESS, V12, P317, DOI 10.1109/TIP.2002.806242
   Cover T. M., 1991, ELEMENTS INFORM THEO
   EKVALL S, 2006, IEEE RSJ INT C ROB A
   Escolano F, 2007, 2007 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-9, P1721
   Fergus R, 2003, PROC CVPR IEEE, P264
   Gilles S., 1998, PhD thesis
   Kadir T, 2001, INT J COMPUT VISION, V45, P83, DOI 10.1023/A:1012460413855
   KADIR T, 2004, EUR C COMP VIS PRAG, P391
   Konishi S, 2003, IEEE T PATTERN ANAL, V25, P57, DOI 10.1109/TPAMI.2003.1159946
   Laptev I, 2005, INT J COMPUT VISION, V64, P107, DOI 10.1007/s11263-005-1838-7
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Matas J, 2004, IMAGE VISION COMPUT, V22, P761, DOI 10.1016/j.imavis.2004.02.006
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Newman P, 2006, IEEE INT CONF ROBOT, P1180, DOI 10.1109/ROBOT.2006.1641869
   OIKONOMOPOULOS A, 2006, IEEE C COMP VIS PATT, P151
   Park SJ, 2002, LECT NOTES COMPUT SC, V2525, P418
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   UNNIKRISHNAN R, 2006, P 17 BRIT MACH VIS C, V2, P499
   van de Weijer J, 2005, PROC CVPR IEEE, P365
NR 22
TC 6
Z9 6
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1207
EP 1218
DI 10.1016/j.imavis.2008.01.010
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300003
DA 2024-07-18
ER

PT J
AU Tong, XJ
   Cui, M
AF Tong, Xiaojun
   Cui, Minggen
TI Image encryption with compound chaotic sequence cipher shifting
   dynamically
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE compound chaos; stream cipher; image encryption
ID RANDOM NUMBER GENERATORS; MAPS
AB We design a new two-dimensional chaotic function using two one-dimensional chaotic functions, and then prove the chaotic properties to a new function based on a strict Devaney definition. And we propose a new encrypting image scheme using the new compound chaotic function by choosing one of the two one-dimensional chaotic functions randomly. We give statistical analysis, sequence random analysis, and sensitivity analysis to plaintext and key on the proposed scheme. The experimental results show that the new scheme has a very fast encryption speed and the key space is expanded and it can resist all kinds of cryptanalytic, statistical and brute-force attacks, and especially, our new method can be also used to solve the problem that is easily exposed to chosen plaintext attack and low digitization of one-dimensional chaotic function. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Tong, Xiaojun] Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
   [Cui, Minggen] Harbin Inst Technol, Coll Sci, Weihai 264209, Peoples R China.
C3 Harbin Institute of Technology; Harbin Institute of Technology
RP Tong, XJ (corresponding author), Harbin Inst Technol, Sch Comp Sci & Technol, Weihai 264209, Peoples R China.
EM tong_xiaojun@163.com
CR ALFRED J, 1996, HDB APPL CRYPTOGRAPH, P181
   Alvarez E, 1999, PHYS LETT A, V263, P373, DOI 10.1016/S0375-9601(99)00747-1
   BIHAM E, 1991, LECT NOTES COMPUT SC, V547, P532
   Chen GR, 2004, CHAOS SOLITON FRACT, V21, P749, DOI 10.1016/j.chaos.2003.12.022
   Chuang T. J., 1999, Pattern Recognition and Image Analysis, V9, P431
   FRIDRICH J, 1997, COMPUTATIONAL CYBERN, V2, P1105
   GTZ M, 1997, IEEE T CIRCUITS SYST, V44, P963
   HUANG FJ, 2005, INFORM SECURITY RES
   Jakimoski G, 2001, IEEE T CIRCUITS-I, V48, P163, DOI 10.1109/81.904880
   Li SJ, 2002, 2002 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P925
   LU K, 1990, CHAOTIC DYNAMICS, P48
   MINCHELL DW, 1990, CRYPTOGRAPHY, V14, P350
   Neto LG, 1996, OPT ENG, V35, P2459, DOI 10.1117/1.600848
   NIE HY, 2006, RES ENCRYPTION TECHN
   SCHNEIER B, 2000, APPL CRYPTOGRAPHY PR, P106
   SHORT KM, 1994, INT J BIFURCAT CHAOS, V4, P959, DOI 10.1142/S021812749400068X
   Stojanovski T, 2001, IEEE T CIRCUITS-I, V48, P382, DOI 10.1109/81.915396
   Stojanovski T, 2001, IEEE T CIRCUITS-I, V48, P281, DOI 10.1109/81.915385
   Wheeler D. D., 1991, Cryptologia, V15, P140, DOI 10.1080/0161-119191865821
   YANG H, 2002, STUDY CHAOS DYNAMIC
NR 20
TC 118
Z9 127
U1 0
U2 31
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 843
EP 850
DI 10.1016/j.imavis.2007.09.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900011
DA 2024-07-18
ER

PT J
AU Xu, K
   Chia, KW
   Cheok, AD
AF Xu, Ke
   Chia, Kar Wee
   Cheok, Adrian David
TI Real-time camera tracking for marker-less and unprepared augmented
   reality environments
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE vision based tracking; optical flow; fundamental matrix; homography;
   augmented reality
ID POSE
AB For three-dimensional video-based augmented reality applications, accurate measurements of the 6DOF camera pose relative to the real world are required for proper registration of the virtual objects. This paper presents an accurate and robust system for real-time 6DOF camera pose tracking based on natural features in an arbitrary scene. Crucially, the calculation is based on pre-captured reference images. This prevents a gradual increase in the camera position error. Point features in the current image frame are first matched to two spatially separated reference images. This wide baseline correspondence problem is overcome by constructing (1) a global homography between current and previous image frame and (2) local affine transforms derived from known matches between previous frame and reference images. Chaining these two mappings constrains the search for potential matches in the reference images and allows the warping of corner intensity neighborhoods so that a viewpoint invariant similarity measure for assessing potential point matches can be defined. We then minimize deviations from the two-view and three-view constraints between the reference images and current frame as a function of the camera motion parameters to obtain an estimate of the current camera pose relative to the reference images. This calculation is stabilized using a recursive form of temporal regularization similar in spirit to the Kalman filter. We can track camera pose reliably over hundreds of image frames and realistically integrate three-dimensional virtual objects with only slight jitter. This paper also tries to simplify the above described algorithm and present a real-time, robust tracking system based on computing homographies. Homography can exactly describe the image motion between two frames when the camera motion is pure rotation, or it is viewing a planar scene. For outdoor registration applications, the system is robust under small translations as long as the majority of the scene contents are distant. (C) 2008 Published by Elsevier B.V.
C1 [Xu, Ke; Chia, Kar Wee; Cheok, Adrian David] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
C3 National University of Singapore
RP Cheok, AD (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117576, Singapore.
EM adriancheok@nus.edu.sg
RI Cheok, Adrian David/AAT-6141-2021
OI Cheok, Adrian David/0000-0001-6316-2339
CR [Anonymous], P EUR C COMP VIS ECC
   [Anonymous], MSRTR0154
   AVIDAN S, 1998, P EUR C COMP VIS U F, P124
   BAUMBERG A, 2000, CVPR JUN
   BROIDA TJ, 1990, IEEE T AERO ELEC SYS, V26, P639, DOI 10.1109/7.55557
   CORNELIS K, 2000, KULESATPSI0002
   Davison AJ, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1403
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   Eberly D., ROTATION REPRESENTAT
   FAUGERAS OD, 1992, LECT NOTES COMPUT SC, V588, P564
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Kato H., 1999, Proceedings 2nd IEEE and ACM International Workshop on Augmented Reality (IWAR'99), P85, DOI 10.1109/IWAR.1999.803809
   NEUMANN U, 1996, P ACM VIRT REAL SOFT, P109
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Prince SJD, 2002, IEEE COMPUT GRAPH, V22, P39, DOI 10.1109/MCG.2002.1046627
   Pritchett P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P754, DOI 10.1109/ICCV.1998.710802
   Simon G, 2000, IEEE AND ACM INTERNATIONAL SYMPOSIUM ON AUGMENTED REALITY, PROCEEDING, P120, DOI 10.1109/ISAR.2000.880935
   Triggs B., 2000, Vision Algorithms: Theory and Practice. International Workshop on Vision Algorithms. Proceedings (Lecture Notes in Computer Science Vol. 1883), P298
   UENOHARA M, 1995, COMPUT BIOL MED, V25, P249, DOI 10.1016/0010-4825(94)00045-R
   Zhang Z., 1994, ROBUST TECHNIQUE MAT
   Zhang Zhengyou, 1995, PARAMETER ESTIMATION
NR 23
TC 25
Z9 25
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 673
EP 689
DI 10.1016/j.imavis.2007.08.015
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900008
DA 2024-07-18
ER

PT J
AU Cootes, TF
   Twining, CJ
   Babalola, KO
   Taylor, CJ
AF Cootes, T. F.
   Twining, C. J.
   Babalola, K. O.
   Taylor, C. J.
TI Diffeomorphic statistical shape models
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE deformable model; statistical shape model; image registration
AB We describe a method of constructing parametric statistical models of shape variation which can generate continuous diffeomorphic (non-folding) deformation fields. Traditional statistical shape models are constructed by analysis of the positions of a set of landmark points. Here, we describe an algorithm which models parameters of continuous warp fields, constructed by composing simple parametric diffeomorphic warps. The warps are composed in such a way that the deformations are always defined in a reference frame. This allows the parameters controlling the deformations to be meaningfully compared from one example to another. A linear model is learnt to represent the variations in the warp parameters across the training set. This model can then be used to generalise the deformations. Models can be built either from sets of annotated points, or from unlabelled images. In the latter case, we use techniques from non-rigid registration to construct the warp fields deforming a reference image into each example. We describe the technique in detail and give examples of the resulting models. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Cootes, T. F.; Twining, C. J.; Babalola, K. O.; Taylor, C. J.] Univ Manchester, Manchester M13 9PT, Lancs, England.
C3 University of Manchester
RP Cootes, TF (corresponding author), Univ Manchester, Manchester M13 9PT, Lancs, England.
EM t.cootes@manchester.ac.uk
RI Twining, Carole J/F-7423-2012; Taylor, Chris/A-3909-2009
OI Taylor, Chris/0000-0001-7867-9533; Babalola, Kola/0000-0003-1384-8433;
   Cootes, Timothy/0000-0002-2695-9063
CR [Anonymous], 1998, STAT SHAPE ANAL
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Choi Y, 2000, GRAPH MODELS, V62, P411, DOI 10.1006/gmod.2000.0531
   Christine D, 2006, PEDIATR ANESTH, V16, P224, DOI 10.1111/j.1460-9592.2005.01809.x
   COOTES T, 2004, 8 EUR C COMP VIS, V4, P316
   Cootes T., 1998, Proc. ECCV, V2, P484
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   FLETCHER P, 2003, 18 C INF PROC MED IM, P450
   Marsland S, 2003, LECT NOTES COMPUT SC, V2717, P50
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Pizer SM, 2003, INT J COMPUT VISION, V55, P85, DOI 10.1023/A:1026313132218
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   RUECKERT D, 2001, MICCAI, P77
   TWINING C, 2002, 13 BRIT MACH VIS C, V2, P847
   Vaillant M, 2004, NEUROIMAGE, V23, pS161, DOI 10.1016/j.neuroimage.2004.07.023
NR 15
TC 30
Z9 43
U1 1
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 326
EP 332
DI 10.1016/j.imavis.2006.12.005
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500002
DA 2024-07-18
ER

PT J
AU Balázs, P
AF Balazs, Peter
TI A decomposition technique for reconstructing discrete sets from four
   projections
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th International Conference on Discrete Geometry for Computer Imagery
CY APR 13-15, 2005
CL Poitiers, FRANCE
SP Int Assoc Pattern Recognit, Univ Poitiers, Signal, Image, Commun Lab, CNRS
DE discrete tomography; reconstruction algorithm; decomposable discrete
   set; Q-convexity; h nu-convexity
ID Q-CONVEX SETS; ORTHOGONAL PROJECTIONS; POLYOMINOES; VECTORS
AB The reconstruction of discrete sets from four projections is in general an NP-hard problem. In this paper we study the class of decomposable discrete sets and give an efficient reconstruction algorithm for this class using four projections. It is also shown that an arbitrary discrete set which is Q-convex along the horizontal and vertical directions and consists of several components is decomposable. As a consequence of decomposability we get that in a subclass of hv-convex discrete sets the reconstruction from four projections can also be solved in polynomial time. Possible extensions of our method are also discussed. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Szeged, Dept Comp Algorithms & Artificial Intelligence, H-6720 Szeged, Hungary.
C3 Szeged University
RP Balázs, P (corresponding author), Univ Szeged, Dept Comp Algorithms & Artificial Intelligence, Arpad Ter 2, H-6720 Szeged, Hungary.
EM pbalazs@inf.u-szeged.hu
RI Balázs, Péter/M-4393-2018
CR [Anonymous], 2003, ELECT NOTES DISCRETE
   Balázs N, 2005, LECT NOTES COMPUT SC, V3429, P104
   Balázs P, 2005, DISCRETE APPL MATH, V147, P149, DOI 10.1016/j.dam.2004.09.009
   BALAZS P, 2005, ELECT NOTES DISCR MA, V20, P329
   Balogh E, 2001, LINEAR ALGEBRA APPL, V339, P23, DOI 10.1016/S0024-3795(01)00430-X
   Barcucci E, 1996, THEOR COMPUT SCI, V155, P321, DOI 10.1016/0304-3975(94)00293-2
   Batenburg KJ, 2005, DISCRETE APPL MATH, V151, P36, DOI 10.1016/j.dam.2005.02.021
   BRUALDI RA, 1980, LINEAR ALGEBRA APPL, V33, P159, DOI 10.1016/0024-3795(80)90105-6
   Brunetti S, 2005, THEOR COMPUT SCI, V347, P393, DOI 10.1016/j.tcs.2005.06.033
   BRUNETTI S, 2000, P 7 INT WORKSH COMB, P241
   Chrobak M, 1999, INFORM PROCESS LETT, V69, P283, DOI 10.1016/S0020-0190(99)00025-3
   Daurat A, 2005, THEOR COMPUT SCI, V332, P19, DOI 10.1016/j.tcs.2004.10.001
   DelLungo A, 1996, DISCRETE MATH, V157, P65, DOI 10.1016/S0012-365X(96)83007-X
   DELLUNGO A, 1994, THEOR COMPUT SCI, V127, P187, DOI 10.1016/0304-3975(94)90107-4
   GARDNER RJ, UNIQUENESS COMPLEXIT, P85
   GOLOMB S, 1965, POLYOMINOES
   Herman G.T., 1999, Discrete Tomography: Foundations, Algorithms, and Applications
   Kuba A, 2002, THEOR COMPUT SCI, V283, P223, DOI 10.1016/S0304-3975(01)00080-9
   Kuba A, 1999, LECT NOTES COMPUT SC, V1568, P153
   KUBA A, 1984, COMPUT VISION GRAPH, V27, P249, DOI 10.1016/0734-189X(84)90031-8
   Ryser H.J., 1957, CAN J MATH, V9, P371, DOI DOI 10.4153/CJM-1957-044-3
   Woeginger GJ, 2001, INFORM PROCESS LETT, V77, P225, DOI 10.1016/S0020-0190(00)00162-9
NR 22
TC 3
Z9 3
U1 0
U2 5
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2007
VL 25
IS 10
BP 1609
EP 1619
DI 10.1016/j.imavis.2006.06.015
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 204ME
UT WOS:000249047200009
DA 2024-07-18
ER

PT J
AU Averbuch, A
   Liron, G
   Bobrovsky, BZ
AF Averbuch, Amir
   Liron, Gabi
   Bobrovsky, Ben Zion
TI Scene based non-uniformity correction in thermal images using Kalman
   filter
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE focal-plane array; thermal picture; detection and correction of
   non-uniformities; Kalman filter
ID FOCAL-PLANE ARRAYS; REGISTRATION; SENSORS; CORRECTABILITY; ALGORITHM;
   ANALOG
AB Thermal array detectors, also known as focal-plane arrays (FPA), are a rapidly developing technology and are used in a variety of civil, medical and military applications. The detectors, which are sensitive to radiation in the infrared band, output a high resolution low noise thermal picture. The existence of non-uniformities in the responsitivity of the element array is a severe problem typical to FPA. These non-uniformities result in a fixed pattern "curtain"-like feature that appear in the image. One of the most common methods to correct non-uniformity is the use of a uniform reference target. This type of non-uniformity correction has a number of disadvantages. The work presented in this paper proposes a new method to calibrate a thermal detector. The proposed correction method is scene based, relying only on the camera's captured video sequence. The algorithm utilizes redundant information achieved from the thermal camera's high sample rate, combined with the camera's motion. The proposed correction algorithm contains two steps: (1) Application of frame registration that compensates for the camera motion. The registration process matches two consecutive frames and produces a residual (difference) frame. Here, we use well-known techniques. (2) Definition of the calibration parameters as a system of linear equations that is solved with the use of a Kalman filter. The Kalman filter tracks the value of each element specific responsitivity value (unknown) through time. Extensive experimental results demonstrate the success of the proposed scheme. The proposed algorithm necessitates modest computational power (ran on a PC with a Pentium III 550 MHz processor) due to the sparsity of the involved matrices. (C) 2006 Elsevier B.V. All rights reserved.
C1 Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel.
   Intel Corp, Haifa, Israel.
   Tel Aviv Univ, Fac Engn, Sch Elect Engn, Dept Elect Engn Syst, IL-69978 Tel Aviv, Israel.
C3 Tel Aviv University; Intel Corporation; Tel Aviv University
RP Averbuch, A (corresponding author), Tel Aviv Univ, Sch Comp Sci, IL-69978 Tel Aviv, Israel.
EM amir@math.tau.ac.il
CR ARTHUR G, 1999, APPL OPTIMAL ESTIMAT
   AVERBUCH A, IN PRESS IEEE T IMAG
   Chiang YM, 1997, ANALOG INTEGR CIRC S, V12, P231, DOI 10.1023/A:1008297408871
   DECASTRO E, 1987, IEEE T PATTERN ANAL, V9, P700, DOI 10.1109/TPAMI.1987.4767966
   Dierickx B, 1998, P SOC PHOTO-OPT INS, V3410, P200, DOI 10.1117/12.324015
   Golub G. H., 1983, MATRIX COMPUTATIONS
   Gross W, 1998, P SOC PHOTO-OPT INS, V3436, P203, DOI 10.1117/12.328016
   Hardie RC, 2000, APPL OPTICS, V39, P1241, DOI 10.1364/AO.39.001241
   Harris JG, 1997, P SOC PHOTO-OPT INS, V3061, P895, DOI 10.1117/12.280308
   Harris JG, 1998, P SOC PHOTO-OPT INS, V3377, P106, DOI 10.1117/12.319364
   HEPFER KC, 1994, Patent No. 5276319
   Keller Y, 2003, IEEE T CIRC SYST VID, V13, P300, DOI 10.1109/TCSVT.2003.811360
   LIRON G, 2000, THESIS TEL AVIV U IS
   ONEIL W, 1996, Patent No. 5514865
   Ratliff BM, 2003, J OPT SOC AM A, V20, P1890, DOI 10.1364/JOSAA.20.001890
   Ratliff BM, 2002, J OPT SOC AM A, V19, P1737, DOI 10.1364/JOSAA.19.001737
   Reddy BS, 1996, IEEE T IMAGE PROCESS, V5, P1266, DOI 10.1109/83.506761
   SCHULZ M, 1995, P SOC PHOTO-OPT INS, V2470, P200, DOI 10.1117/12.210050
   SCRIBNER DA, 1990, P SPIE, V1308
   SCRIBNER DA, 1991, SPIE, V1541
   SOPHIA T, 1998, SPIE, V3436, P172
   Torres SN, 2003, J OPT SOC AM A, V20, P470, DOI 10.1364/JOSAA.20.000470
   Venkateswarlu R, 1997, P SOC PHOTO-OPT INS, V3061, P915, DOI 10.1117/12.280310
NR 23
TC 37
Z9 40
U1 0
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 833
EP 851
DI 10.1016/j.imavis.2006.05.019
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600006
DA 2024-07-18
ER

PT J
AU Frucci, M
   Ramella, G
   di Baja, GS
AF Frucci, Maria
   Ramella, Giuliana
   di Baja, Gabriella Sanniti
TI Using resolution pyramids for watershed image segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE segmentation; watershed transformation; resolution pyramid
ID OVERSEGMENTATION REDUCTION; REPRESENTATION; ALGORITHMS
AB In this paper we build a shape preserving resolution pyramid and use it in the framework of image segmentation via watershed transformation. Our method is based on the assumption that the most significant image components perceived at high resolution will also be perceived at lower resolution. Thus, we detect the seeds for the watershed transformation at a low resolution, and use them to distinguish significant and non-significant seeds at any selected higher resolution. In this way, the watershed partition obtained at the selected pyramid level will include only the most significant components, and over-segmentation will be considerably reduced. Segmentations of the image at different scales will be available. Moreover, since the seeds can be detected at different pyramid levels, alternative segmentations of the image at a given resolution can be obtained, each characterized by a different level of detail. (C) 2006 Elsevier B.V. All rights reserved.
C1 CNR, Inst Cybernet E Caianiello, I-80078 Pozzuoli, Naples, Italy.
C3 Consiglio Nazionale delle Ricerche (CNR); Istituto di Cibernetica
   "Eduardo Caianiello" (ICIB-CNR)
RP Frucci, M (corresponding author), CNR, Inst Cybernet E Caianiello, Via Campi Flegri 34, I-80078 Pozzuoli, Naples, Italy.
EM m.frucci@cib.na.cnr.it; g.ramella@cib.na.cnr.it;
   g.sannitidibaja@cib.na.cnr.it
RI Ramella, Giuliana/AAN-7025-2021; Frucci, Maria/B-7908-2015
OI Frucci, Maria/0000-0003-1432-931X; Sanniti di Baja,
   Gabriella/0000-0003-2218-0412; RAMELLA, Giuliana/0000-0001-6044-5237
CR BEUCHER S, 1979, P INT C IM PROC REAL
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   BISTER M, 1990, PATTERN RECOGN LETT, V11, P605, DOI 10.1016/0167-8655(90)90013-R
   Borgefors G, 2001, PATTERN RECOGN LETT, V22, P741, DOI 10.1016/S0167-8655(01)00002-2
   BURT PJ, 1981, IEEE T SYST MAN CYB, V11, P802, DOI 10.1109/TSMC.1981.4308619
   CHEN PC, 1980, COMPUT VISION GRAPH, V12, P153, DOI 10.1016/0146-664X(80)90009-X
   Frucci M, 2005, LECT NOTES COMPUT SC, V3773, P989
   Frucci M, 2006, INT J PATTERN RECOGN, V20, P15, DOI 10.1142/S0218001406004533
   KHAN GN, 1992, IMAGE VISION COMPUT, V10, P77, DOI 10.1016/0262-8856(92)90002-K
   Kim JB, 2003, PATTERN RECOGN LETT, V24, P473, DOI 10.1016/S0167-8655(02)00270-2
   Marfil R, 2006, PATTERN RECOGN, V39, P1430, DOI 10.1016/j.patcog.2006.02.017
   MEER P, 1990, IEEE T PATTERN ANAL, V12, P363, DOI 10.1109/34.50622
   MONTANVERT A, 1991, IEEE T PATTERN ANAL, V13, P307, DOI 10.1109/34.88566
   NACKEN PFM, 1995, PATTERN RECOGN, V28, P907, DOI 10.1016/0031-3203(94)00172-I
   Prewer D, 2001, PATTERN RECOGN LETT, V22, P123, DOI 10.1016/S0167-8655(00)00063-5
   Ramella G, 2004, LECT NOTES COMPUT SC, V3287, P574
   Rodríguez JA, 2002, PATTERN RECOGN LETT, V23, P1761, DOI 10.1016/S0167-8655(02)00150-2
   Rosenfeld A, 1998, INFORM SCIENCES, V107, P127, DOI 10.1016/S0020-0255(97)10021-4
   Rosenfeld A., 1984, MULTIRESOLUTION IMAG
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   STANNARD E, 1999, P IEE COLL APPL STAT, V12, P1
   TAN CL, 1993, PATTERN RECOGN, V26, P127, DOI 10.1016/0031-3203(93)90094-D
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   YACOUB SB, 1995, P IEEE C VIS IM SIGN, V142, P7
NR 24
TC 19
Z9 21
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 1021
EP 1031
DI 10.1016/j.imavis.2006.07.014
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600022
DA 2024-07-18
ER

PT J
AU Gao, XT
   Sattar, F
   Quddus, A
   Venkateswarlu, R
AF Gao, Xinting
   Sattar, Farook
   Quddus, Azhar
   Venkateswarlu, Ronda
TI Multiscale contour corner detection based on local natural scale and
   wavelet transform
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE corner detection; dyadic wavelet transform; local natural scale
ID PLANAR CURVES
AB A new corner detection method for contour images is proposed based on dyadic wavelet transform (WT) at local natural scales. The points corresponding to wavelet transform modulus maxima (WTMM) at different scales are taken as corner candidates. For each candidate, the scale at which the maximum value of the normalized WTMM exists is defined as its "local natural scale", and the corresponding modulus is taken as its significance measure. This approach achieves more accurate estimation of the natural scale of each candidate than the existing global natural scale based methods. Furthermore, the proposed algorithm is suitable for both long contours and short contours. The simulation and the objective evaluation results reveal better performance of the proposed algorithm compared to the existing methods. (C) 2006 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
   Univ Waterloo, Waterloo, ON N2L 3G1, Canada.
   Inst Infocomm Res, Singapore 119613, Singapore.
C3 Nanyang Technological University; University of Waterloo; Agency for
   Science Technology & Research (A*STAR); A*STAR - Institute for Infocomm
   Research (I2R)
RP Gao, XT (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Nanyang Ave, Singapore 639798, Singapore.
EM xtgao@pmail.ntu.edu.sg; efsattar@ntu.edu.sg; azhar.quddus@gmail.com;
   vronda@i2r.a-star.edu.sg
RI Sattar, Farook/AAA-3308-2019; Sattar, Farook/KFQ-6650-2024
OI Sattar, Farook/0000-0001-6272-3982; 
CR Antoine JP, 1997, SIGNAL PROCESS, V62, P265, DOI 10.1016/S0165-1684(97)00129-1
   ATTNEAVE F, 1954, PSYCHOL REV, V61, P183, DOI 10.1037/h0054663
   Chuang GCH, 1996, IEEE T IMAGE PROCESS, V5, P56, DOI 10.1109/83.481671
   HUA J, 2000, 5 INT C SIGN PROC P, V1, P341
   LEE JS, 1995, IEEE T IMAGE PROCESS, V4, P100, DOI 10.1109/83.350810
   Lindeberg T., 1994, SCALE SPACE THEORY C
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   PEREZ JC, 1994, PATTERN RECOGN LETT, V15, P743, DOI 10.1016/0167-8655(94)90002-7
   Quddus A, 2002, PATTERN RECOGN LETT, V23, P215, DOI 10.1016/S0167-8655(01)00090-3
   Quddus A, 1999, ELECTRON LETT, V35, P287, DOI 10.1049/el:19990121
   RATTARANGSI A, 1992, IEEE T PATTERN ANAL, V14, P430, DOI 10.1109/34.126805
   Rosin PL, 1997, IEEE T PATTERN ANAL, V19, P659, DOI 10.1109/34.601253
   TEH CH, 1989, IEEE T PATTERN ANAL, V11, P859, DOI 10.1109/34.31447
NR 13
TC 24
Z9 32
U1 1
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 890
EP 898
DI 10.1016/j.imavis.2006.07.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600011
DA 2024-07-18
ER

PT J
AU Thomaz, CE
   Boardman, JP
   Counsell, S
   Hill, DLG
   Hajnal, JV
   Edwards, AD
   Rutherford, MA
   Gillies, DF
   Rueckert, D
AF Thomaz, C. E.
   Boardman, J. P.
   Counsell, S.
   Hill, D. L. G.
   Hajnal, J. V.
   Edwards, A. D.
   Rutherford, M. A.
   Gillies, D. F.
   Rueckert, D.
TI A multivariate statistical analysis of the developing human brain in
   preterm infants
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multivariate statistics; small sample size; brain images; preterm
   infants
ID REGISTRATION; CHILDREN; DEFORMATIONS; MORPHOMETRY; OUTCOMES; ATLAS
AB Preterm delivery accounts for 5% of all deliveries and its consequences contribute to significant individual, medical, and social problems. The neuroanatomical substrates of these disorders are not known, but are essential for understanding mechanisms of causation, and developing strategies for intervention. In the recent years, multivariate pattern recognition methods that analyse all voxels simultaneously have been proposed to characterise the neuroanatomical differences between a reference group of magnetic resonance (MR) images and the population under investigation. Most of these techniques have overcome the difficulty of dealing with the inherent high dimensionality of 3D MR brain image data by using pre-processed segmented images or a small number of specific features. However, an intuitive way of mapping the classification results back into the original image domain for further interpretation remains challenging. In this paper, we propose the idea of using Principal Components Analysis (PCA) plus the maximum uncertainty Linear Discriminant Analysis (MLDA) approach to classify and analyse MR brain images that have been aligned with either affine or non-rigid registration techniques. This approach avoids the computation costs intrinsic to commonly used covariance-based optimisation processes for solving small sample size problems, resulting in a simple and efficient implementation for the maximisation and interpretation of the Fisher's classification results. In order to demonstrate the effectiveness of the approach, we have used a neonatal MR brain data set that contains images of 93 preterm infants at term equivalent age and 20 term controls. Our results indicate that the two-stage linear framework makes clear the statistical differences between the control and preterm samples, showing a classification accuracy of 95.0% and 97.8% for the controls and preterms samples, respectively, using the leave-one-out method. Moreover, it provides a simple and intuitive method of visually analysing the differences between preterm infants at term equivalent age and the control group, such as differences in cerebrospinal fluid spaces, structure of the corpus callosum, and subtle differences in myelination. (C) 2006 Elsevier B.V. All rights reserved.
C1 Ctr Univ FEI, Dept Elect Engn, Sao Paulo, Brazil.
   Univ London Imperial Coll Sci Technol & Med, Dept Sci Imaging, London, England.
   Univ London Imperial Coll Sci Technol & Med, Ctr Med Image Comp, London, England.
   Univ London Imperial Coll Sci Technol & Med, Div Pediat Obstet & Gynaecol, London, England.
   Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
C3 Centro Universitario da FEI; Imperial College London; Imperial College
   London; University of London; University College London; Imperial
   College London; Imperial College London
RP Thomaz, CE (corresponding author), Ctr Univ FEI, Dept Elect Engn, Sao Paulo, Brazil.
EM cet@fei.edu.br
RI Boardman, James P/K-5472-2015; Thomaz, Carlos/AAF-1878-2019; Rueckert,
   Daniel/C-4393-2008
OI Thomaz, Carlos/0000-0001-5566-1963; Rueckert,
   Daniel/0000-0002-5683-5889; Hill, Derek/0000-0003-1970-1432; Boardman,
   James/0000-0003-3904-8960
FU MRC [MC_U120081323, MC_U120061309] Funding Source: UKRI
CR Ashburner J, 2000, NEUROIMAGE, V11, P805, DOI 10.1006/nimg.2000.0582
   Ashburner J, 1998, HUM BRAIN MAPP, V6, P348, DOI 10.1002/(SICI)1097-0193(1998)6:5/6<348::AID-HBM4>3.3.CO;2-G
   BAJESY R, 1989, COMPUT VIS GRAPH IMA, V46, P1
   Bhutta AT, 2002, JAMA-J AM MED ASSOC, V288, P728, DOI 10.1001/jama.288.6.728
   Boardman JP, 2003, LECT NOTES COMPUT SC, V2878, P697
   Botting N, 1997, J CHILD PSYCHOL PSYC, V38, P931, DOI 10.1111/j.1469-7610.1997.tb01612.x
   BroNielsen M, 1996, LECT NOTES COMPUT SC, V1131, P267
   CAMPBELL NA, 1980, APPL STATIST, V29, P5
   Christensen GE, 2001, IEEE T MED IMAGING, V20, P568, DOI 10.1109/42.932742
   CHRISTENSEN GE, 1995, COMPUTER ASSISTED RADIOLOGY, P146
   COLLINS DL, 1994, J COMPUT ASSIST TOMO, V18, P192, DOI 10.1097/00004728-199403000-00005
   Davatzikos C, 1997, COMPUT VIS IMAGE UND, V66, P207, DOI 10.1006/cviu.1997.0605
   Davatzikos C, 1996, J COMPUT ASSIST TOMO, V20, P88, DOI 10.1097/00004728-199601000-00017
   Davies RH, 2003, LECT NOTES COMPUT SC, V2732, P38
   DEVIJVER PA, 1982, STAT APPROACH
   DIPILLO PJ, 1979, COMMUN STAT A-THEOR, V8, P1447, DOI 10.1080/03610927908827842
   DUBB A, 2003, P MICCAI, P457
   Freeborough PA, 1998, J COMPUT ASSIST TOMO, V22, P838, DOI 10.1097/00004728-199809000-00031
   FRIEDMAN JH, 1989, J AM STAT ASSOC, V84, P165, DOI 10.2307/2289860
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   GEE JC, 1993, J COMPUT ASSIST TOMO, V17, P225, DOI 10.1097/00004728-199303000-00011
   Gerig G., 2001, PROC MICCAI, P24
   GOLLAND P, 2000, P MICCAI, P72
   GOLLAND P, 2002, P MICCAI, P508
   GREENE T, 1991, COMPUTATIONAL STAT D, V11, P17
   Hellier P, 1999, LECT NOTES COMPUT SC, V1679, P680
   Johnson A.R., 1998, Applied multivariate statistical analysis
   Lao ZQ, 2004, NEUROIMAGE, V21, P46, DOI 10.1016/j.neuroimage.2003.09.027
   MARLOW N, 1993, ARCH DIS CHILD-FETAL, V68, P286, DOI 10.1136/adc.68.3_Spec_No.286
   Marple SL., 1987, Digital spectral analysis with applications
   Ment LR, 1999, PEDIATRICS, V104, P243, DOI 10.1542/peds.104.2.243
   MILLER MI, 1993, P NATL ACAD SCI USA, V90, P11944, DOI 10.1073/pnas.90.24.11944
   PECK R, 1982, IEEE T PATTERN ANAL, V4, P530, DOI 10.1109/TPAMI.1982.4767298
   Rayens W.S., 1990, J CHEMOMETR, V4, P159
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   SHEN D, 2002, IEEE T MED IMAGING
   Sowell ER, 1999, NEUROIMAGE, V9, P587, DOI 10.1006/nimg.1999.0436
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   TADJUDIN S, 1998, THESIS PURDUE U
   Thirion J P, 1998, Med Image Anal, V2, P243, DOI 10.1016/S1361-8415(98)80022-4
   Thomaz CE, 2004, IEEE T CIRC SYST VID, V14, P214, DOI 10.1109/TCSVT.2003.821984
   THOMAZ CE, 2004, THESIS IMPERIAL COLL
   THOMAZ CE, 2004, TR200401 IMP COLL DE
   Thompson PM, 1997, J COMPUT ASSIST TOMO, V21, P567, DOI 10.1097/00004728-199707000-00008
   Wang YM, 2000, MED IMAGE ANAL, V4, P7, DOI 10.1016/S1361-8415(00)00004-9
   Wood NS, 2000, NEW ENGL J MED, V343, P378, DOI 10.1056/NEJM200008103430601
   YUSHKEVICH P, 2003, INF PROCESS MED IMAG
NR 48
TC 24
Z9 25
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 981
EP 994
DI 10.1016/j.imavis.2006.07.011
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600019
DA 2024-07-18
ER

PT J
AU Izo, T
   Grimson, WEL
AF Izo, Tomas
   Grimson, W. Eric L.
TI Simultaneous pose recovery and camera registration from multiple views
   of a walking person
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE post-estimation; exemplar-based motion modelling; automatic camera
   calibration; model-based motion segmentation
AB We present an algorithm to estimate the body pose of a walking person given synchronized video input from multiple uncalibrated cameras. We construct an appearance model of human walking motion by generating examples from the space of body poses and camera locations, and clustering them using expectation-maximization. Given a segmented input video sequence, we find the closest matching appearance cluster for each silhouette and use the sequence of matched clusters to extrapolate the position of the camera with respect to the person's direction of motion. For each frame, the matching cluster also provides an estimate of the walking phase. We combine these estimates from all views and find the most likely sequence of walking poses using a cyclical, feed-forward hidden Markov model. Our algorithm requires no manual initialization and no prior knowledge about the locations of the cameras. (c) 2007 Elsevier B.V. All rights reserved.
C1 MIT, Comp Sci & Artificial Intelligence Lab, Cambridge, MA 02139 USA.
C3 Massachusetts Institute of Technology (MIT)
RP Izo, T (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM tomas@csail.mit.edu; welg@csail.mit.edu
CR [Anonymous], 1999, P IEEE C COMPUTER VI
   [Anonymous], 1998, GENTLE TUTORIAL ALGO
   BERGLER C, 1998, P IEEE C COMP VIS PA
   CHAM T, 1999, P IEEE C COMP VIS PA
   COHEN I, 2001, 5 WORLD MULT SYST CY
   Duda R.O., 2001, PATTERN CLASSIFICATI, P544
   GRAUMAN K, 2003, INT C COMP VIS NIC F
   HOWE N, 1999, NEURAL INFORMATION P
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   LEE L, 2003, INT C COMP VIS NIC F
   MIGDAL J, 2003, THESIS MIT
   MIKIC I, 2001, P IEEE C COMP VIS PA
   MORRIS D, 1998, P IEEE C COMP VIS PA
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   ROSALES R, 2000, P IEEE C COMP VIS PA
   Rosales R, 2000, IEEE WORKSH HUM MOT
   VITERBI AJ, 1967, IEEE T INFORM THEORY, V13, P260, DOI 10.1109/TIT.1967.1054010
   ZHAO T, 2001, P IEEE C COMP VIS PA
NR 18
TC 3
Z9 4
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2007
VL 25
IS 3
BP 342
EP 351
DI 10.1016/j.imavis.2005.10.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 125NY
UT WOS:000243450100010
DA 2024-07-18
ER

PT J
AU Yi, HR
   Rajan, D
   Chia, LT
AF Yi, HR
   Rajan, D
   Chia, LT
TI A motion-based scene tree for compressed video content management
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE shot boundary detection; video indexing; video browsing; video
   similarity; video retrieval
ID SEGMENTATION; EXTRACTION; RETRIEVAL
AB This paper describes a fully automatic content-based approach for browsing and retrieval of MPEG-2 compressed video. The first step of the approach is (lie detection of shot boundaries based on motion vectors available front the compressed video stream. The next step involves the construction of a scene tree from the shots obtained earlier. The scene tree is shown to Capture some semantic information as well as provide a construct for hierarchical browsing, of compressed videos. Finally, we build a new model for video similarity based on global as well as local motion associated with each node in the scene tree. To this end, we propose new approaches to camera motion and object motion estimation. The experimental results demonstrate that the integration of the above techniques results in in efficient framework for browsing and searching large video databases. (c) 2005 Elsevier B.V. All rights reserved.
C1 Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Rajan, D (corresponding author), Nanyang Technol Univ, Sch Comp Engn, Ctr Multimedia & Network Technol, Singapore 639798, Singapore.
EM pg03763623@ntu.edu.sg; asdrajan@ntu.edu.sg; asltchia@ntu.edu.sg
RI Chia, Liang-Tien/A-9874-2008; Rajan, Deepu/A-3666-2011
CR [Anonymous], ACM MULTIMEDIA
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   DANIEL A, 1976, GRAMMAR FILM LANGUAG
   Divakaran A, 2001, J ELECTRON IMAGING, V10, P909, DOI 10.1117/1.1406507
   Doulamis AD, 2004, IEEE T CIRC SYST VID, V14, P757, DOI 10.1109/TCSVT.2004.828348
   Feng J., 1996, P IEEE INT C IM PROC, V1, P821
   Gunturk BK, 2004, IEEE T IMAGE PROCESS, V13, P33, DOI 10.1109/TIP.2003.819221
   Hanjalic A, 1999, IEEE T CIRC SYST VID, V9, P580, DOI 10.1109/76.767124
   Haskell B.G., 1997, DIGITAL VIDEO INTRO
   *ISO, 2001, N4031 ISOIECJTC1SC29
   *ISO, 2001, JTC1SC29WG11N4318 IS
   *ITU T, 1998, H263 ITUT
   *ITU T, 2002, H264 ITUT
   KATZ E, 1995, FILM ENCY
   Kender JR, 1998, PROC CVPR IEEE, P367, DOI 10.1109/CVPR.1998.698632
   Lienhart R, 1998, PROC SPIE, V3656, P290, DOI 10.1117/12.333848
   MENG J, 1995, P SPIE C MULTIMEDIA, V2417, P180
   NAM J, 1997, P IEEE INT C AC SPEE, V4, P2665
   OH J, 2000, P 2000 ACM SIGMOD IN, P415
   RASHEED Z, 2003, P IEEE INT C COMP VI
   Robertson MA, 2001, P SOC PHOTO-OPT INS, V4310, P21
   SARACENO C, 1998, P INT C IM PROC CHIC, P358
   Schonfeld D, 2000, J VIS COMMUN IMAGE R, V11, P154, DOI 10.1006/jvci.1999.0432
   Sethi I. K., 1995, Proceedings of the SPIE - The International Society for Optical Engineering, V2420, P329, DOI 10.1117/12.205299
   Truong BT, 2003, IEEE T CIRC SYST VID, V13, P5, DOI 10.1109/TCSVT.2002.808084
   WANG H, 2003, J VISUAL COMMUNICATI, V14, P50
   Yeo BL, 1995, IEEE T CIRC SYST VID, V5, P533, DOI 10.1109/76.475896
   Yeo BL, 1995, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOLS I-III, pB260
   YI H, 2003, P IEEE INT C IM PROC
   ZABIH R, 1995, P ACM MULT 95 SAN FR, V1, P10
NR 30
TC 4
Z9 5
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2006
VL 24
IS 2
BP 131
EP 142
DI 10.1016/j.imavis.2005.09.019
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 017GA
UT WOS:000235680900003
DA 2024-07-18
ER

PT J
AU Mardia, KV
   Angulo, JM
   Goitía, A
AF Mardia, KV
   Angulo, JM
   Goitía, A
TI Synthesis of image deformation strategies
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE deformation; entropy; image warping; information theory;
   Kullback-Leibler divergence; landmarks; registration; regularization;
   texture models
AB Warping is one of the key areas of image analysis but there has been no understanding of the effects of different non-linear deformations in literature. This paper addresses the problem of the distortion effect produced by different types of non-linear deformation strategies on textured images. The images are modelled by a Gaussian random field. We first give various examples to illustrate that the model generates realistic images. We consider two types of deformations-a deterministic deformation and a landmark based deformation. The latter includes various radial basis type deformations including the thin-plate splines based deformation. The effects of deformations are assessed through Kullback-Leibler divergence measure. The measure is estimated by statistical sampling techniques. It is found empirically that this divergence measure is approximately distributed as a lognormal distribution under various different deformations. Thus a coefficient of variation based on log-divergence provides a natural criterion to compare different types of deformations. It is found that the thin-plate splines deformation is almost optimal over the wider class of the radial type deformations. (C) 2005 Elsevier B.V. All rights reserved.
C1 Univ Granada, Dept Estadist & IO, E-18071 Granada, Spain.
   Univ Leeds, Dept Stat, Leeds LS2 9JT, W Yorkshire, England.
   Univ Los Andes, Inst Estadist, Merida 5101, Venezuela.
C3 University of Granada; University of Leeds; University of Los Andes
   Venezuela
RP Angulo, JM (corresponding author), Univ Granada, Dept Estadist & IO, E-18071 Granada, Spain.
EM jmangulo@ugr.es
RI cai, bo/G-1491-2010; Angulo, José/I-5066-2015
OI Angulo, José/0000-0002-6863-7847
CR [Anonymous], 1998, Statistical shape analysis: Wiley series in probability and statistics". In
   [Anonymous], 1995, RANDOM FIELDS NETWOR
   [Anonymous], 2001, Medical image registration
   ARAD N, 1994, CVGIP-GRAPH MODEL IM, V56, P161, DOI 10.1006/cgip.1994.1015
   BESAG J, 1974, J ROY STAT SOC B MET, V36, P192
   BOOKSTEIN FL, 1989, IEEE T PATTERN ANAL, V11, P567, DOI 10.1109/34.24792
   Brodatz P., 1966, TEXTURES PHOTOGRAPHI
   Brown L.G., 1992, ACM COMPUT SURV, V24, P325, DOI DOI 10.1145/146370.146374
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   COHEN FS, 1993, MARKOV RANDOM FIELDS, P307
   Faugeras O., 2001, The geometry of multiple images: the laws that govern the formation of multiple images of a scene and some of their applications
   Gimel'farb G., 1999, IMAGE TEXTURES GIBBS
   Glasbey CA, 2001, J ROY STAT SOC B, V63, P465, DOI 10.1111/1467-9868.00295
   Glasbey CA, 1998, J APPL STAT, V25, P155, DOI 10.1080/02664769823151
   Grenander U., 1970, ADV COMPUT, V10, P175
   GUYON X, 1990, ACTA CIEN VENEZ SOC, V1
   HAINDL M, 1991, TEXTURE SYNTHESIS, P305
   Heikkila J, 1997, SCIA '97 - PROCEEDINGS OF THE 10TH SCANDINAVIAN CONFERENCE ON IMAGE ANALYSIS, VOLS 1 AND 2, P847
   Mardia KV, 2005, ANN STAT, V33, P1666, DOI 10.1214/009053605000000273
   MARDIA KV, 1993, ADV APPL STAT, P257
   MARDIA KV, 2001, FUNCTIONAL SPATIAL D, P46
   MARTIN RJ, 1979, BIOMETRIKA, V66, P209
   TANG YY, 1993, IEEE T SYST MAN CYB, V23, P155, DOI 10.1109/21.214774
NR 23
TC 7
Z9 9
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 1
EP 12
DI 10.1016/j.imavis.2005.09.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200001
DA 2024-07-18
ER

PT J
AU Zhong, HX
   Pang, YJ
   Feng, YP
AF Zhong, HX
   Pang, YJ
   Feng, YP
TI A new approach to estimating fundamental matrix
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE fundamental matrix; epipolar geometry; generalized eigenvalue problem
ID EPIPOLAR GEOMETRY; COMPUTER VISION
AB A new linear approach to estimating the fundamental matrix is proposed in this paper. The approach is based on the orthogonal least-squares technique for estimating the fundamental matrix. Using eigenvectors corresponding to the two smallest eigenvalues achieved by the technique mentioned above, we construct a 3x3 generalized eigenvalue problem. The solutions to the problem give not only the fundamental matrix but also the corresponding epipoles. The performance of the new approach is compared with several existing linear methods. It is shown that the approach achieves the higher accuracy. (C) 2005 Elsevier B.V. All rights reserved.
C1 Jilin Univ, Coll Comp Sci & Technol, Changchun 130012, Peoples R China.
C3 Jilin University
RP Zhong, HX (corresponding author), Dept Comp Sci, 10 Qianwei Rd, Changchun 130012, Peoples R China.
EM zhonghuixiang@yahoo.com
RI Zhong, Huixiang/G-4125-2019
OI Zhong, Huixiang/0000-0001-7671-6994
CR [Anonymous], 1998, Image processing, analysis, and machine vision
   Armangué X, 2003, IMAGE VISION COMPUT, V21, P205, DOI 10.1016/S0262-8856(02)00154-3
   Chojnacki W, 2004, IMAGE VISION COMPUT, V22, P85, DOI 10.1016/S0262-8856(03)00140-9
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley R. I., 1995, Proceedings. Fifth International Conference on Computer Vision (Cat. No.95CB35744), P1064, DOI 10.1109/ICCV.1995.466816
   Leedan Y, 2000, INT J COMPUT VISION, V37, P127, DOI 10.1023/A:1008185619375
   Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818
   Torr P. H. S., 2003, P BRIT MACH VIS C, P83
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 12
TC 2
Z9 3
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 56
EP 60
DI 10.1016/j.imavis.2005.09.021
PG 5
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200005
DA 2024-07-18
ER

PT J
AU Lu, SJ
   Chen, BM
   Ko, CC
AF Lu, SJ
   Chen, BM
   Ko, CC
TI Perspective rectification of document images using fuzzy set and
   morphological operations
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE document image analysis; document image rectification; optical character
   recognition; morphological image processing; fuzzy sets
ID BINARIZATION; ALGORITHM
AB In this paper, we deal with the problem of document image rectification from image captured by digital cameras. The improvement on the resolution of digital camera sensors has brought more and more applications for non-contact text capture. Unfortunately, perspective distortion in the resulting image makes it hard to properly identify the contents of the captured text using traditional optical character recognition (OCR) systems. We propose in this work a new technique, which is capable of removing perspective distortion and recovering the fronto-parallel view of text with a single image. Different from reported approaches in the literature, the image rectification is carried out using character stroke boundaries and tip points (SBTP), which are extracted from character strokes based on multiple fuzzy sets and morphological operators. The algorithm needs neither high-contrast document boundary (HDB) nor paragraph formatting (PF) information. Experimental results show that our rectification process is fast and robust. (c) 2005 Elsevier B.V. All rights reserved.
C1 Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
C3 National University of Singapore
RP Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 119260, Singapore.
EM bmchen@nus.edu.sg
RI Chen, Ben M./L-8791-2019; Lu, Shijian/AAU-4831-2021
OI Chen, Ben M./0000-0002-3839-5787; Lu, Shijian/0000-0002-6766-2506
CR Clark P, 2003, PATTERN RECOGN, V36, P2673, DOI 10.1016/S0031-3203(03)00132-8
   Clark P., 2002, International Journal on Document Analysis and Recognition, V4, P243, DOI 10.1007/s10032-001-0072-2
   Dance CR, 2002, P SOC PHOTO-OPT INS, V4670, P244
   Haralick R. M., 1989, Proceedings CVPR '89 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.89CH2752-4), P370, DOI 10.1109/CVPR.1989.37874
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   IRVING WB, 1974, APPL STAT METHODS
   Jain R., 1995, MACHINE VISION
   Kavallieratou E, 2002, IMAGE VISION COMPUT, V20, P813, DOI 10.1016/S0262-8856(02)00091-4
   Kwag HK, 2002, IMAGE VISION COMPUT, V20, P25, DOI 10.1016/S0262-8856(01)00071-3
   Liu Y, 1997, IEEE T PATTERN ANAL, V19, P540, DOI 10.1109/34.589217
   OGORMAN L, 1994, CVGIP-GRAPH MODEL IM, V56, P494, DOI 10.1006/cgip.1994.1044
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Pilu M, 2001, PROC CVPR IEEE, P363
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   Yang YB, 2000, PATTERN RECOGN, V33, P787, DOI 10.1016/S0031-3203(99)00094-1
   Yu B, 1996, PATTERN RECOGN, V29, P1599, DOI 10.1016/0031-3203(96)00020-9
   Zadeh L.A., 1975, CALCULUS FUZZY RESTR
   ZIMMERMANN HJ, 1980, FUZZY SET SYST, V4, P37, DOI 10.1016/0165-0114(80)90062-7
NR 19
TC 66
Z9 83
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2005
VL 23
IS 5
BP 541
EP 553
DI 10.1016/j.imavis.2005.01.003
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 917XA
UT WOS:000228501300007
DA 2024-07-18
ER

PT J
AU Tissainayagam, P
   Suter, D
AF Tissainayagam, P
   Suter, D
TI Assessing the performance of corner detectors for point feature tracking
   applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE point features; corner detector; point feature tracking; feature
   extraction; corner matching
ID COMPUTATIONAL APPROACH; MODEL
AB In this paper we assess the performance of a variety of corner (point) detecting algorithms for feature tracking applications. We analyze four different types of corner extractors, which have been widely used for a variety of applications (they are described later in the paper). We use corner stability and corner localization properties as measures to evaluate the quality of the features extracted by the four detectors. For effective assessment of the corner detectors, first, we employed image sequences with no motion (simply static image sequences), so that the appearance and disappearance of corners in each frame is purely due to image plane noise and illumination conditions. The second stage included experiments on sequences with small motion. The experiments were devised to make the testing environment ideal to analyze the stability and localization properties of the corners extracted. The corners detected from the initial frame are then matched through the sequence using a corner matching strategy. We employed two different types of matchers, namely the GVM (Gradient Vector Matcher) and the Product Moment Coefficient Matcher (PMCM). Each of the corner detectors was tested with each of the matching algorithms to evaluate their performance in tracking (matching) the features. The experiments were carried out on a variety of image sequences with and without motion. (C) 2004 Elsevier B.V. All rights reserved.
C1 NEC Australia Pty, Transmiss Syst Div, Dept Broadband Syst, Mulgrave, Vic 3170, Australia.
   Monash Univ, Dept Elect & Comp Syst Engn, Clayton, Vic 3800, Australia.
C3 Monash University
RP NEC Australia Pty, Transmiss Syst Div, Dept Broadband Syst, Mulgrave, Vic 3170, Australia.
EM raj@ms.nec.com.au; d.suter@eng.monash.edu.au
OI Suter, David/0000-0001-6306-3023
CR [Anonymous], 1992, ACTIVE VISION
   [Anonymous], 1991, CMUCS91132 CARN MELL
   BAUMBERG AM, 1995, THESIS U LEEDS
   BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1
   Blake A., 1992, Active Vision
   Blake A., 1998, ACTIVE CONTOURS
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539
   DERICHE R, 1993, INT J COMPUT VISION, V10, P101, DOI 10.1007/BF01420733
   DRESCHLER L, 1982, COMPUT VISION GRAPH, V20, P199, DOI 10.1016/0146-664X(82)90081-8
   DRESCHLER L, 1982, INT C PATT REC, P542
   Etoh M., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P192, DOI 10.1109/ICCV.1993.378220
   GONZLES R, 1987, DITITAL IMAGE PROCES, pR40
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kitchen L, 1982, PATTERN RECOGN LETT, V1, P95, DOI 10.1016/0167-8655(82)90020-4
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   MEYER F, 1992, LECT NOTES COMPUT SC, V588, P476
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Mokhtarian F, 1998, IEEE T PATTERN ANAL, V20, P1376, DOI 10.1109/34.735812
   NOBLE JA, 1988, IMAGE VISION COMPUT, V6, P121, DOI 10.1016/0262-8856(88)90007-8
   RISSAINAYAGAM P, 1998, 14 INT C PATT REC IC, V1, P289
   ROBERTS JM, 1994, THESIS U SOUTHAMPTON
   Rosin PL, 1996, GRAPH MODEL IM PROC, V58, P286, DOI 10.1006/gmip.1996.0023
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Shapiro LS., 1995, AFFINE ANAL IMAGE SE
   SHAPIRO LS, 1992, 3 BRIT MACH VIS C, P306
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   SMITH SM, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P237, DOI 10.1109/ICCV.1995.466780
   Tissainayagam P, 2001, COMPUT VIS IMAGE UND, V84, P104, DOI 10.1006/cviu.2001.0939
   Tissainayagam P, 2001, PATTERN RECOGN, V34, P641, DOI 10.1016/S0031-3203(00)00019-4
   TISSAINAYAGAM P, 1997, P INT WORKSH IM AN I, P171
   TSUJI S, 1980, IEEE T PATTERN ANAL, V2, P516, DOI 10.1109/TPAMI.1980.6447698
NR 36
TC 79
Z9 114
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2004
VL 22
IS 8
BP 663
EP 679
DI 10.1016/j.imavis.2004.02.001
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RV
UT WOS:000221481200007
DA 2024-07-18
ER

PT J
AU Pang, SN
   Kim, HC
   Kim, D
   Bang, SY
AF Pang, SN
   Kim, HC
   Kim, D
   Bang, SY
TI Prediction of the suitability for image-matching based on
   self-similarity of vision contents
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE matching prediction; vision content description for matching; intuition
   level-wise critical matching; self-similarity; critical filter;
   multi-resolution
ID INVARIANT; SEGMENTATION; RECOGNITION; OBJECTS; MODELS; SCALE
AB This paper is concerned with predicting the suitability for image matching to measure the extent to which a specific area in the input image is difficult for image matching. First, we describe a new reinforced anti-noise image matching technique, which is composed of Vision Content Description for Matching (VCDM) and Intuition Level-wise Critical Matching (ILCM), because we also must perform the image matching in order to predict it's suitability. Next, we construct a prediction model for measuring the suitability for image-matching based on local and global self-similarities of vision contents and the analysis of mismatching elements. Prediction results are represented in two different formats: bitmap and contour map. From various experiments on block template matching, we found that (1) our proposed image matching technique results in both a high degree of accuracy and robustness against noise and (2) the suitability measure for image matching is consistent with the valuable contents in the input image. From these results, it is believed that the predicted suitability measure can successfully serve as a guide for a further process in object matching. (C) 2003 Elsevier B.V. All rights reserved.
C1 POSTECH, Dept Comp Sci & Engn, Pohang 790784, South Korea.
C3 Pohang University of Science & Technology (POSTECH)
RP POSTECH, Dept Comp Sci & Engn, San 31 Hyoja Dong, Pohang 790784, South Korea.
EM pshaoning@yahoo.com
CR [Anonymous], 1982, Digital Picture Processing
   Beveridge JR, 1997, IEEE T PATTERN ANAL, V19, P564, DOI 10.1109/34.601245
   BONINSEGNA M, 1994, PATTERN RECOGN LETT, V15, P1255, DOI 10.1016/0167-8655(94)90116-3
   Cheng FH, 1996, PATTERN RECOGN LETT, V17, P1429, DOI 10.1016/S0167-8655(96)00115-8
   daSilva EAB, 1996, IEEE T IMAGE PROCESS, V5, P299, DOI 10.1109/83.480765
   DELANEY AH, 1995, IEEE T IMAGE PROCESS, V4, P774
   FLUSSER J, 1995, PATTERN RECOGN, V28, P1723, DOI 10.1016/0031-3203(95)00034-W
   Fosgate CH, 1997, IEEE T IMAGE PROCESS, V6, P7, DOI 10.1109/83.552077
   KAPLAN LM, 1995, IEEE T PATTERN ANAL, V17, P1043, DOI 10.1109/34.473230
   KIM NH, 1988, PATTERN RECOGN, V21, P515
   Krishnamachari S, 1997, IEEE T IMAGE PROCESS, V6, P251, DOI 10.1109/83.551696
   LEE SH, 1994, PATTERN RECOGN, V27, P961, DOI 10.1016/0031-3203(94)90138-4
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lindeberg T., 1994, SCALE SPACE THEORY C
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   Nayar S.K., 1996, Early visual learning
   PARK DJ, 1995, PATTERN RECOGN, V28, P211, DOI 10.1016/0031-3203(94)00097-6
   PELG S, 1997, IEEE P CVPR, P338
   RAVELA S, 1997, P SIGIR PHIL
   RAVELA S, 2001, MULTISCALE DIFFERENT
   Rucklidge WJ, 1997, INT J COMPUT VISION, V24, P251, DOI 10.1023/A:1007975324482
   Shen XQ, 2000, IEEE T PATTERN ANAL, V22, P1381, DOI 10.1109/34.895973
   Shinagawa Y, 1998, IEEE T PATTERN ANAL, V20, P994, DOI 10.1109/34.713364
   SPIRKOVSKA L, 1992, PATTERN RECOGN, V25, P975, DOI 10.1016/0031-3203(92)90062-N
NR 24
TC 7
Z9 13
U1 2
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2004
VL 22
IS 5
BP 355
EP 365
DI 10.1016/S0262-8856(03)00032-5
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 806GN
UT WOS:000220422500001
DA 2024-07-18
ER

PT J
AU Theobald, BJ
   Kruse, SM
   Bangham, JA
   Cawley, GC
AF Theobald, BJ
   Kruse, SM
   Bangham, JA
   Cawley, GC
TI Towards a low bandwidth talking face using appearance models
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE talking faces; shape and appearance models; principal component analysis
AB This paper is motivated by the need to develop low bandwidth virtual humans capable of delivering audio-visual speech and sign language at a quality comparable to high bandwidth video. Using an appearance model combined with parameter compression significantly reduces the number of bits required for animating the face of a virtual human. A perceptual method is used to evaluate the quality of the synthesised sequences and it appears that 3.6 kb s(-1) can yield acceptable quality. (C) 2003 Published by Elsevier B.V.
C1 Univ E Anglia, Sch Informat Syst, Norwich NR4 7TJ, Norfolk, England.
C3 University of East Anglia
RP Theobald, BJ (corresponding author), Univ E Anglia, Sch Informat Syst, Norwich NR4 7TJ, Norfolk, England.
OI Cawley, Gavin/0000-0002-4118-9095
CR ABDI H, 1997, BRAIN BEHAV SCI, V21, P175
   [Anonymous], P BRIT MACH VIS C BM, DOI DOI 10.1007/978-1-4471-3201-1_2
   Bregler C., 1997, P 24 ANN C COMP GRAP, V31, P353, DOI DOI 10.1145/258734.258880
   BROOKE NM, 1998, P AUD VIS SPEECH PRO, P213
   *BUC DEAF STUD, 10 BUC DEAF STUD
   COOTES T, 1998, P BRIT MACH VIS C, V2, P680
   Cootes T., 1998, Proc. ECCV, V2, P484
   EDWARDS G, 1997, P BRIT MACH VIS C, P130
   Essa IA, 1997, IEEE T PATTERN ANAL, V19, P757, DOI 10.1109/34.598232
   EZZAT T, 1999, 1658 MIT
   Gregory S., 1995, DEAF YOUNG PEOPLE TH
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   *ITU R, BT50010 ITUR
   Johnston RD, 1996, BT TECHNOL J, V14, P100
   Koufakis I, 1999, IMAGE VISION COMPUT, V17, P1031, DOI 10.1016/S0262-8856(99)00005-0
   Matthews I., 1998, THESIS U E ANGLIA NO
   MATTHEWS I, 1998, P AUD VIS SPEECH PRO, P73
   MATTHEWS I, 1998, EUROPEAN C COMPUTER, P514
   MAX J, 1960, IRE T INFORM THEOR, V6, P7, DOI 10.1109/TIT.1960.1057548
   OTOOLE AJ, 1993, J OPT SOC AM A, V10, P405, DOI 10.1364/JOSAA.10.000405
   PARKE F, 1974, THESIS U UTAH SALTLA
   PARKE F, 1996, COMPUTER FACIAL
   PEARSON DE, 1995, P IEEE, V83, P892, DOI 10.1109/5.387091
   PIGHIN F, 1998, P SIGGRAPH
   THEOBALD B, 2003, IN PRESS P BRIT MACH
   Tian YI, 2001, IEEE T PATTERN ANAL, V23, P97, DOI 10.1109/34.908962
   Waters K., 1987, ACM SIGGRAPH Comput. Graph., V21, P17
   [No title captured]
NR 28
TC 2
Z9 2
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1117
EP 1124
DI 10.1016/j.imavis.2003.08.015
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100006
DA 2024-07-18
ER

PT J
AU Yang, H
   Yang, JY
   Frangi, AF
AF Yang, H
   Yang, JY
   Frangi, AF
TI Combined Fisherfaces framework
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fisher linear discriminant analysis; Principal Component Analysis;
   Kernel based methods; Fisherfaces; Eigenfaces; feature extraction; face
   recognition
ID FACE; EIGENFACES
AB In this paper, a Complex LDA based combined Fisherfaces framework, coined Complex Fisherfaces, is developed for face feature extraction and recognition. In this framework, Principal Component Analysis (PCA) and Kernel PCA (KPCA) are first used for feature extraction. Then, the resulting PCA-based linear features and KPCA-based nonlinear features are integrated by complex vectors and, Complex LDA is further employed for feature fusion. The proposed method is tested on a subset of FERET database. The experimental results demonstrate that Complex Fisherfaces outperforms Fisherfaces and Kernel Fisherfaces. Also, the complex vector based parallel feature fusion strategy is demonstrated to be much more effective and robust than the super-vector based serial feature fusion strategy for face recognition. (C) 2003 Elsevier B.V. All rights reserved.
C1 Nanjing Univ Sci & Technol, Dept Comp Sci, Nanjing 210094, Peoples R China.
   Univ Zaragoza, Aragon Inst Engn Res, Comp Vis Grp, E-50018 Zaragoza, Spain.
C3 Nanjing University of Science & Technology; University of Zaragoza
RP Univ Zaragoza, Aragon Inst Engn Res, Comp Vis Grp, E-50018 Zaragoza, Spain.
EM jyang@unizar.es; yangjy@mail.njust.edu; afrangi@unizar.es
RI Frangi, Alejandro F/C-6500-2008
OI Frangi, Alejandro F/0000-0002-2675-528X
CR Baudat G, 2000, NEURAL COMPUT, V12, P2385, DOI 10.1162/089976600300014980
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Jin Z, 2001, PATTERN RECOGN, V34, P1405, DOI 10.1016/S0031-3203(00)00084-4
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Liu CJ, 2001, IEEE T IMAGE PROCESS, V10, P598, DOI 10.1109/83.913594
   Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604
   Mika S, 2003, IEEE T PATTERN ANAL, V25, P623, DOI 10.1109/TPAMI.2003.1195996
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   Phillips P.J., FACIAL RECOGNITION T
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Yang H, 2003, PATTERN RECOGN, V36, P563, DOI 10.1016/S0031-3203(02)00048-1
   Yang J, 2003, PATTERN RECOGN, V36, P1369, DOI 10.1016/S0031-3203(02)00262-5
   Yang J, 2001, PROC SPIE, V4572, P438, DOI 10.1117/12.444212
   Yang J, 2002, PATTERN RECOGN, V35, P2665, DOI 10.1016/S0031-3203(02)00071-7
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
NR 22
TC 58
Z9 63
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2003
VL 21
IS 12
BP 1037
EP 1044
DI 10.1016/j.imavis.2003.07.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 737UW
UT WOS:000186251000003
DA 2024-07-18
ER

PT J
AU Eveland, CK
   Socolinsky, DA
   Wolff, LB
AF Eveland, CK
   Socolinsky, DA
   Wolff, LB
TI Tracking human faces in infrared video
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT IEEE Workshop in Computer Vision Beyond the Visible Spectrum
CY DEC 14, 2001
CL KAUAI, HI
SP IEEE
DE object detection and tracking; segmentation
AB Detection and tracking of face regions in image sequences has applications to important problems such as face recognition, human-computer interaction, and video surveillance. Visible sensors have inherent limitations in solving this task, such as the need for sufficient and specific lighting conditions, as well as sensitivity to variations in skin color. Thermal infrared (IR) imaging sensors image emitted light, not reflected light. and therefore do not have these limitations, providing a 24-h, 365-day capability while also being more robust to variations in the appearance of individuals.
   In this paper, we present a system for tracking human heads that has three components. First, a method for modeling thermal emission from human skin that can be used for the purpose of segmenting and detecting faces and other exposed skin regions in IR imagery is presented. Second. the segmentation model is applied to the CONDENSATION algorithm for tracking the head regions over time. This includes a new observation density that is motivated by the segmentation results. Finally, we examine how to use the tracking results to refine the segmentation estimate. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Equinox Corp, Baltimore, MD 21201 USA.
RP Equinox Corp, 207 E Redwood St,Suite 205, Baltimore, MD 21201 USA.
EM eveland@equinoxsensors.com
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Anbar M, 1998, DENTOMAXILLOFAC RAD, V27, P61, DOI 10.1038/sj.dmfr.4600314
   ANBAR M, 1991, THERMOLOGY, V3
   [Anonymous], 1998, STAT LEARNING THEORY
   BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1
   EVELAND CK, 1998, CVPR
   FOUAD M, 2000, P INT FOR GRAD YOUNG
   Gaussorgues G., 1994, INFRARED THERMOGRAPH, V5
   HEALEY GE, 1992, COLOR PHYSICS BASED
   Hero AO, 1999, IEEE T INFORM THEORY, V45, P1921, DOI 10.1109/18.782114
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   ISARD M, 2001, P 8 INT C COMP VIS
   ISARD M, 1996, P ECCV
   LIONS JL, 1981, NUMERICAL ANAL VARIA
   MACCORMICK J., 2000, THESIS OXFORD U
   Menser B, 1999, IEE CONF PUBL, P620, DOI 10.1049/cp:19990397
   PAVLIDIS I, 2000, P IEEE COMP SOC WORK
   PHILLIPS PJ, 1999, 6264 NISTIR
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   SOCOLINSKY D, 2001, COMPUTER VISION PATT, V1, P527
   STAUFFER C, 1998, CVPR, V2
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Terrillon JC, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P112, DOI 10.1109/AFGR.1998.670934
   Wilder J, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P182, DOI 10.1109/AFGR.1996.557262
   Wolff L. B., 2001, P CVPR WORKSH COMP V
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
NR 26
TC 41
Z9 48
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2003
VL 21
IS 7
BP 579
EP 590
DI 10.1016/S0262-8856(03)00056-8
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 706FR
UT WOS:000184443400003
DA 2024-07-18
ER

PT J
AU Li, PH
   Zhang, TW
   Pece, AEC
AF Li, PH
   Zhang, TW
   Pece, AEC
TI Visual contour tracking based on particle filters
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE visual tracking; active contour; particle filter; Kalman filter;
   unscented Kalman filter
ID MONTE-CARLO METHODS
AB The Condensation algorithm, developed for visual tracking, is a variant of particle filter. In the sampling stage of Condensation; no use is made of the information from the current frame in the image sequence. As a consequence, the algorithm requires a large number of particles and is computationally expensive. In this paper, a Kalman particle filter (KPF) and an unscented particle filter (UPF) are applied to contour tracking to try to overcome the problem. These. algorithms use. the Kalman filter or unscented Kalman filter to incorporate, information from the current frame. This sampling strategy can effectively steer the set of particles towards regions with high likelihood, and therefore can considerably reduce the number of particles needed for tracking. Performance comparisons show that the KPF is an improvement over Condensation, while the UPF has a much higher computational cost for equal: tracking. error: (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Harbin Inst Technol, Dept Comp Sci & Engn, Harbin 150001, Hei Long Jiang, Peoples R China.
   Univ Copenhagen, Dept Comp Sci, DK-2100 Copenhagen, Denmark.
C3 Harbin Institute of Technology; University of Copenhagen
RP Harbin Inst Technol, Dept Comp Sci & Engn, POB 321, Harbin 150001, Hei Long Jiang, Peoples R China.
EM peihualj@hotmail.com; aecp@diku.dk
CR [Anonymous], 1998, LNCS, DOI DOI 10.1007/BFB0055711
   [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], 2000, NIPS 00 P 13 INT C N
   BLAKE A, 1995, ARTIF INTELL, V78, P179, DOI 10.1016/0004-3702(95)00032-1
   BLAKE A, 1993, INT J COMPUT VISION, V11, P127, DOI 10.1007/BF01469225
   Blake A., 1998, ACTIVE CONTOURS
   CHEN Y, 2002, P INT C IM PROC
   de Freitas JFG, 2000, NEURAL COMPUT, V12, P955, DOI 10.1162/089976600300015664
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Doucet A, 2001, IEEE T SIGNAL PROCES, V49, P613, DOI 10.1109/78.905890
   GORDON NJ, 1993, IEE PROC-F, V140, P107, DOI 10.1049/ip-f-2.1993.0015
   GRENANDER V, 1992, HANDS PATTERN THEORE
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P343, DOI 10.1007/BFb0015549
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797
   JULIER SJ, SCALED UNSENTED TRAN
   Kitagawa G., 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750
   LI P, 2002, P GEN MOD BAS VIS CO, P61
   Liu JS, 1998, J AM STAT ASSOC, V93, P1032, DOI 10.2307/2669847
   MacCormick J, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P390, DOI 10.1109/ICCV.1998.710748
   MacCormick J., 2000, THESIS U OXFORD
   MacCormick J., 2000, IEEE European Conference on Computer Vision, P3, DOI DOI 10.1007/3-540-45053-X1
   METAXAS D, 1993, IEEE T PATTERN ANAL, V15, P580, DOI 10.1109/34.216727
   Pece AV, 2002, LECT NOTES COMPUT SC, V2350, P3
   Peihua Li, 2002, Proceedings of the Statistical Methods in Video Processing Workshop, P13
   Peterfreund N, 1999, IEEE T PATTERN ANAL, V21, P564, DOI 10.1109/34.771328
   Pitt MK, 1999, J AM STAT ASSOC, V94, P590, DOI 10.2307/2670179
   Rui Y, 2001, PROC CVPR IEEE, P786
   Stenger B, 2001, PROC CVPR IEEE, P310
   Sullivan J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1068, DOI 10.1109/ICCV.1999.790391
   Terzopoulos D., 1992, Active Vision, P3
   Tissainayagam P., 2002, INT J IMAGE GRAPHICS, V2, P343
   Wan EA, 2000, IEEE 2000 ADAPTIVE SYSTEMS FOR SIGNAL PROCESSING, COMMUNICATIONS, AND CONTROL SYMPOSIUM - PROCEEDINGS, P153, DOI 10.1109/ASSPCC.2000.882463
NR 33
TC 97
Z9 132
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 111
EP 123
AR PII S0262-8856(02)00133-6
DI 10.1016/S0262-8856(02)00133-6
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800012
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Xu, HX
   Lai, SN
   Li, XY
   Yang, Y
AF Xu, Haoxuan
   Lai, Songning
   Li, Xianyang
   Yang, Yang
TI Cross-domain car detection model with integrated convolutional block
   attention mechanism
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image transformation; Domain adaptation; Attention mechanism; Object
   detection
AB Car detection, especially through camera vision, has become a major focus in the field of computer vision and has gained widespread adoption. While current car detection systems are capable of achieving good detection performance, reliable detection can still be challenging due to factors such as car proximity, varying light conditions, and environmental visibility. To address these issues, we propose Cross-Domain Car Detection Model with in-tegrated convolutional block Attention mechanism(CDCDMA) that is specifically designed for car recognition in autonomous driving and related domains. CDCDMA includes several novelties: 1)Building a complete cross-domain target detection framework. 2)Developing an unpaired target domain picture generation module with an integrated convolutional attention mechanism which specifically emphasizes the car headlights feature. 3) Adopting Generalized Intersection over Union (GIOU) as the loss function of the target detection framework. 4) Designing an object detection model integrated with two-headed Convolutional Block Attention Module(CBAM). To evaluate the model's effectiveness, we performed experiments on the SODA 10 M and BDD100K datasets by applying a reduced resolution process to the data, which served as our benchmark dataset for the task. The experimental results demonstrate that the performance of the cross-domain car target detection model improves by 40% compared to the model without our CDCDMA framework. Moreover, our improvements have a significant impact on cross-domain car recognition, surpassing the performance of most advanced cross-domain models.
C1 [Xu, Haoxuan; Lai, Songning; Yang, Yang] Shandong Univ, Sch Informat Sci & Engn, Qingdao 266100, Peoples R China.
   [Li, Xianyang] Ocean Univ China, Sch Econ, Qingdao 266237, Peoples R China.
C3 Shandong University; Ocean University of China
RP Yang, Y (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Qingdao 266100, Peoples R China.
EM 202020120237@mail.sdu.edu.cn; sonly@mail.sdu.edu.cn;
   lxy6688@stu.ouc.edu.cn; yyang@sdu.edu.cn
RI li, xianyang/AIC-5649-2022
CR Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen Y, 2018, PROC CVPR IEEE, P3339, DOI 10.1109/CVPR.2018.00352
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Deng JH, 2021, PROC CVPR IEEE, P4089, DOI 10.1109/CVPR46437.2021.00408
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han JH, 2021, Arxiv, DOI [arXiv:2106.11118, DOI 10.48550/ARXIV.2106.11118]
   He MM, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201365
   He ZW, 2019, IEEE I CONF COMP VIS, P6667, DOI 10.1109/ICCV.2019.00677
   Inoue N, 2018, PROC CVPR IEEE, P5001, DOI 10.1109/CVPR.2018.00525
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jiale Cao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P1, DOI 10.1007/978-3-030-58568-6_1
   Jiang BR, 2018, LECT NOTES COMPUT SC, V11218, P816, DOI 10.1007/978-3-030-01264-9_48
   Khandelwal S, 2021, PROC CVPR IEEE, P5947, DOI 10.1109/CVPR46437.2021.00589
   Kim J, 2020, Arxiv, DOI [arXiv:1907.10830, DOI 10.48550/ARXIV.1907.10830]
   Law H, 2020, INT J COMPUT VISION, V128, P642, DOI 10.1007/s11263-019-01204-1
   Li JL, 2023, IEEE WINT CONF APPL, P612, DOI 10.1109/WACV56688.2023.00068
   Li YJ, 2022, PROC CVPR IEEE, P7571, DOI 10.1109/CVPR52688.2022.00743
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Minghao Xu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12352, DOI 10.1109/CVPR42600.2020.01237
   Mirza M, 2014, Arxiv, DOI [arXiv:1411.1784, DOI 10.48550/ARXIV.1411.1784]
   Nurhadiyatna A, 2013, IEEE SYS MAN CYBERN, P4006, DOI 10.1109/SMC.2013.684
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Schwartz E, 2019, IEEE T IMAGE PROCESS, V28, P912, DOI 10.1109/TIP.2018.2872858
   Soydaner D, 2022, NEURAL COMPUT APPL, V34, P13371, DOI 10.1007/s00521-022-07366-3
   Tan M., 2020, P IEEECVF C COMPUTER, P10781, DOI [10.48550/arXiv.1911.09070, DOI 10.1109/CVPR42600.2020.01079]
   Vu TH, 2019, PROC CVPR IEEE, P2512, DOI 10.1109/CVPR.2019.00262
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   Wang CY, 2023, PROC CVPR IEEE, P7464, DOI 10.1109/CVPR52729.2023.00721
   Wang M, 2018, NEUROCOMPUTING, V312, P135, DOI 10.1016/j.neucom.2018.05.083
   Wang Q, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4889, DOI 10.1109/ICASSP.2018.8461423
   Wang TC, 2018, PROC CVPR IEEE, P8798, DOI 10.1109/CVPR.2018.00917
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yu F, 2020, PROC CVPR IEEE, P2633, DOI 10.1109/CVPR42600.2020.00271
   Yu FX, 2021, Arxiv, DOI arXiv:1911.07158
   Yu J., 2016, P 24 ACM INT C MULT, P516, DOI DOI 10.1145/2964284.2967274
   Zhang ZL, 2018, ADV NEUR IN, V31
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu XK, 2021, IEEE INT CONF COMP V, P2778, DOI 10.1109/ICCVW54120.2021.00312
   Zhu XZ, 2021, Arxiv, DOI arXiv:2010.04159
NR 46
TC 1
Z9 1
U1 14
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104834
DI 10.1016/j.imavis.2023.104834
EA OCT 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AZ4E4
UT WOS:001122246800001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Haider, U
   Hanif, M
   Rashid, A
   Hussain, SF
AF Haider, Usman
   Hanif, Muhammad
   Rashid, Ahmar
   Hussain, Syed Fawad
TI Dictionary-enabled efficient training of ConvNets for image
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sparse representation; Convolution neural networks; Deep learning;
   Dictionary learning; Image classification
ID SPARSE; REPRESENTATION; NETWORKS
AB Convolutional networks (ConvNets) are computationally expensive but well known for their performance on image data. One way to reduce their complexity is to explore inherited data sparsity. However, since the gradi-ents involved in ConvNets require dynamic updates, applying data sparsity in the training step is not straightfor-ward. Dictionary-based learning methods can be useful since they encode the original data in a sparse form. This paper proposes a new dictionary-based training paradigm for ConvNets by exploiting redundancy in the training data while keeping the distinctive features intact. The ConvNet is then trained on the reduced, sparse dataset. The new approach significantly reduces the training time without compromising accuracy. To the best of our knowledge, this is the first implementation of ConvNet on dictionary-based sparse training data. The proposed method is validated on three publicly available datasets aeuro"MNIST, USPS, and MNIST FASHION. The experimental results show a significant reduction of 4.5 times in the overall computational burden of vanilla ConvNet for all the datasets. Whereas the accuracy is intact at 97.21% for MNIST, 96.81% for USPS, and 88.4% for FASHION datasets. These results are comparable to state-of-the-art algorithms, such as ResNet-{18,34,50}, trained on the full training dataset.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Haider, Usman; Hanif, Muhammad; Rashid, Ahmar; Hussain, Syed Fawad] Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi, Pakistan.
   [Haider, Usman; Hanif, Muhammad; Rashid, Ahmar] Ghulam Ishaq Khan Inst Engn Sci & Technol, Aerial Robot & Vis Lab, Topi, Pakistan.
   [Hussain, Syed Fawad] Univ Birmingham, Sch Comp Sci, Birmingham, England.
C3 GIK Institute Engineering Science & Technology; GIK Institute
   Engineering Science & Technology; University of Birmingham
RP Haider, U (corresponding author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Fac Comp Sci & Engn, Topi, Pakistan.; Haider, U (corresponding author), Ghulam Ishaq Khan Inst Engn Sci & Technol, Aerial Robot & Vis Lab, Topi, Pakistan.
EM usman.haider@giki.edu.pk; muhammad.hanif@giki.edu.pk;
   ahmar.rashid@giki.edu.pk; s.f.hussain@bham.ac.uk
OI Hanif, Muhammad/0000-0002-9236-5263
CR Abdi A, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107634
   Adelman M, 2021, ADV NEUR IN, V34
   Anthimopoulos M, 2016, IEEE T MED IMAGING, V35, P1207, DOI 10.1109/TMI.2016.2535865
   Bagherinezhad H, 2017, PROC CVPR IEEE, P860, DOI 10.1109/CVPR.2017.98
   Cheng H, 2013, SIGNAL PROCESS, V93, P1408, DOI 10.1016/j.sigpro.2012.09.011
   Cheng J, 2018, FRONT INFORM TECH EL, V19, P64, DOI 10.1631/FITEE.1700789
   Elad M, 2012, IEEE SIGNAL PROC LET, V19, P922, DOI 10.1109/LSP.2012.2224655
   Elad M, 2010, SPARSE AND REDUNDANT REPRESENTATIONS, P3, DOI 10.1007/978-1-4419-7011-4_1
   Farfade SS, 2015, ICMR'15: PROCEEDINGS OF THE 2015 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL, P643, DOI 10.1145/2671188.2749408
   Gou JP, 2022, IEEE T INTELL TRANSP, V23, P25308, DOI 10.1109/TITS.2022.3177647
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P5966, DOI 10.1109/TGRS.2020.3015157
   Hong DF, 2021, IEEE T GEOSCI REMOTE, V59, P4340, DOI 10.1109/TGRS.2020.3016820
   Gangeh MJ, 2015, Arxiv, DOI arXiv:1502.05928
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Katharopoulos A, 2017, Arxiv, DOI arXiv:1706.00043
   Kingma D. P., 2014, arXiv
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Li S, 2018, IEEE T PATTERN ANAL, V40, P2963, DOI 10.1109/TPAMI.2017.2764893
   Mamalet Franck, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. 22nd International Conference on Artificial Neural Networks, P58, DOI 10.1007/978-3-642-33266-1_8
   Meyes R, 2019, Arxiv, DOI [arXiv:1901.08644, DOI 10.48550/ARXIV.1901.08644]
   Müller T, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3341156
   Ning L, 2019, PROC INT CONF DATA, P1538, DOI 10.1109/ICDE.2019.00138
   Pan H, 2018, IEEE T CYBERNETICS, V48, P2875, DOI 10.1109/TCYB.2017.2751585
   Rubinstein R, 2010, P IEEE, V98, P1045, DOI 10.1109/JPROC.2010.2040551
   Shi Shaohuai, 2017, arXiv, DOI DOI 10.48550/ARXIV.1704.07724
   Spring R, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P445, DOI 10.1145/3097983.3098035
   Sun J, 2016, INT J COMPUT VISION, V120, P111, DOI 10.1007/s11263-016-0899-0
   Sun X, 2017, PR MACH LEARN RES, V70
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Takase T, 2018, NEURAL NETWORKS, V101, P68, DOI 10.1016/j.neunet.2018.01.016
   Tang H, 2021, IEEE T NEUR NET LEAR, V32, P2129, DOI 10.1109/TNNLS.2020.2997289
   Tosic I, 2011, IEEE SIGNAL PROC MAG, V28, P27, DOI 10.1109/MSP.2010.939537
   Vente CD, 2020, Arxiv, DOI arXiv:2009.09725
   Wang J., 2013, P 21 ACM INT C MULTI, P769
   Wu X, 2023, IEEE T IMAGE PROCESS, V32, P364, DOI 10.1109/TIP.2022.3228497
   Xucheng Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12370), P322, DOI 10.1007/978-3-030-58595-2_20
   Yang N, 2020, IEEE ACCESS, V8, P142393, DOI 10.1109/ACCESS.2020.3013621
   Yang WX, 2016, PATTERN RECOGN, V58, P190, DOI 10.1016/j.patcog.2016.04.007
   You Y, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225069
NR 42
TC 2
Z9 2
U1 1
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104718
DI 10.1016/j.imavis.2023.104718
EA JUN 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA K8QV9
UT WOS:001019037500001
DA 2024-07-18
ER

PT J
AU Kolf, JN
   Elliesen, J
   Boutros, F
   Proenca, H
   Damer, N
AF Kolf, Jan Niklas
   Elliesen, Jurek
   Boutros, Fadi
   Proenca, Hugo
   Damer, Naser
TI SyPer: Synthetic periocular data for quantized light-weight recognition
   in the NIR and visible domains
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Quantization; Synthetic data; Biometrics; Periocular
AB Deep-learning based periocular recognition systems typically use overparameterized deep neural networks asso-ciated with high computational costs and memory requirements. This is especially problematic for mobile and embedded devices in shared resource environments. To perform model quantization for lightweight periocular recognition in a privacy-aware manner, we propose and release SyPer, a synthetic dataset and generation model of periocular images. To enable this, we propose to perform the knowledge transfer in the quantization process on the embedding level and thus not identity-labeled data. This does not only allow the use of synthetic data for quantization, but it also successfully allows to perform the quantization on different domains to addition-ally boost the performance in new domains. In a variety of experiments on a diverse set of model backbones, we demonstrate the ability to build compact and accurate models through an embedding-level knowledge transfer using synthetic data. We also demonstrate very successfully the use of embedding-level knowledge transfer for near-infrared quantized models towards accurate and efficient periocular recognition on near-infrared images. The SyPer dataset, together with the evaluation protocol, the training code, and model checkpoints are made publicly available at https://github.com/jankolf/SyPer.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Kolf, Jan Niklas; Elliesen, Jurek; Boutros, Fadi; Damer, Naser] Fraunhofer IGD, Fraunhoferstr 5,Hessia, D-64283 Darmstadt, Germany.
   [Kolf, Jan Niklas; Damer, Naser] Tech Univ Darmstadt, Karolinenpl 5,Hessia, D-64289 Darmstadt, Germany.
   [Proenca, Hugo] Univ Beira Intenor, IT Inst Telecomunicacoes, Covilha, Portugal.
C3 Technical University of Darmstadt
RP Kolf, JN (corresponding author), Fraunhofer IGD, Fraunhoferstr 5,Hessia, D-64283 Darmstadt, Germany.
EM jan.niklas.kolf@igd.fraunhofer.de
RI Proença, Hugo/F-9499-2010
OI Proença, Hugo/0000-0003-2551-8570
FU German Federal Ministry of Education and Research; Hessian Ministry of
   Higher Education, Research, Science; Arts within their joint support of
   the National Research Center for Applied Cybersecurity ATHENE;
   FCT/MCTES; EU [UIDB/EEA/50008/2020]
FX This research work has been funded by the German Federal Ministry of
   Education and Research and the Hessian Ministry of Higher Education,
   Research, Science and the Arts within their joint support of the
   National Research Center for Applied Cybersecurity ATHENE. The
   contributions due to Hugo Proenca in this work were funded by FCT/MCTES
   through national funds and co-funded EU funds under the project
   UIDB/EEA/50008/2020.
CR Ahuja K, 2016, IEEE IMAGE PROC, P335, DOI 10.1109/ICIP.2016.7532374
   Almadan A, 2021, 2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2021), DOI 10.1109/SSCI50451.2021.9660033
   Alonso-Fernandez F, 2023, Arxiv, DOI [arXiv:2212.13792, 10.48550/arXiv.2212.13792abs/2212.13792]
   Alonso-Fernandez F, 2022, INFORM FUSION, V83-84, P110, DOI 10.1016/j.inffus.2022.03.008
   Alonso-Fernandez F, 2016, INT C PATT RECOG, P1455, DOI 10.1109/ICPR.2016.7899842
   Alonso-Fernandez F, 2014, IEEE IMAGE PROC, P4987, DOI 10.1109/ICIP.2014.7026010
   [Anonymous], 2019, 2019 IEEE CVF INT C
   Banner R, 2019, ADV NEUR IN, V32
   Bengio Y, 2013, Arxiv, DOI arXiv:1308.3432
   Boutros Fadi, 2023, 2023 IEEE 17th International Conference on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG57933.2023.10042627
   Boutros F., 2021, 26 INT C PATTERN REC
   Boutros F, 2022, 2022 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), DOI 10.1109/IJCB54206.2022.10007961
   Boutros F, 2022, IEEE COMPUT SOC CONF, P1577, DOI 10.1109/CVPRW56347.2022.00164
   Boutros F, 2022, IEEE ACCESS, V10, P46823, DOI 10.1109/ACCESS.2022.3170561
   Boutros F, 2021, 2021 INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2021), DOI [10.1109/IJCB52358.2021.9484374, 10.4018/IJCINI.290308]
   Boutros F, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22051921
   Boutros F, 2021, 2021 INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB 2021), DOI 10.1109/IJCB52358.2021.9484337
   Boutros F, 2020, IMAGE VISION COMPUT, V104, DOI 10.1016/j.imavis.2020.104007
   Boutros F, 2020, I W BIOMETRIC FORENS, DOI 10.1109/iwbf49977.2020.9107939
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen S, 2018, LECT NOTES COMPUT SC, V10996, P428, DOI 10.1007/978-3-319-97909-0_46
   Choi Y, 2020, IEEE COMPUT SOC CONF, P3047, DOI 10.1109/CVPRW50498.2020.00363
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Damer N, 2021, IET BIOMETRICS, V10, P548, DOI 10.1049/bme2.12044
   Damer N, 2019, IEEE INT CONF COMP V, P3677, DOI 10.1109/ICCVW.2019.00454
   DAUGMAN JG, 1993, IEEE T PATTERN ANAL, V15, P1148, DOI 10.1109/34.244676
   Deng JK, 2019, PROC CVPR IEEE, P4685, DOI 10.1109/CVPR.2019.00482
   Deng JK, 2019, IEEE INT CONF COMP V, P2638, DOI 10.1109/ICCVW.2019.00322
   Dong RP, 2022, PR MACH LEARN RES
   Fang M., 2021, FG, P1, DOI [DOI 10.1109/FG52635.2021.9667051, 10.1109/FG52635.2021.9667051]
   Fang ML, 2022, PATTERN RECOGN, V123, DOI 10.1016/j.patcog.2021.108398
   Fei W, 2022, IEEE T NEUR NET LEAR, V33, P5253, DOI 10.1109/TNNLS.2021.3069886
   GholamReza A, 2022, APPL GEOMAT, V14, P181, DOI 10.1007/s12518-021-00366-3
   Gong J, 2018, 1ST ACM REQUEST WORKSHOP/TOURNAMENT ON REPRODUCIBLE SOFTWARE/HARDWARE CO-DESIGN OF PARETO-EFFICIENT DEEP LEARNING, DOI 10.1145/3229762.3229763
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Guo Y., 2018, ARXIV180804752, P1
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jain AK, 2004, IEEE T CIRC SYST VID, V14, P4, DOI 10.1109/TCSVT.2003.818349
   Jin Q., 2022, INT C LEARNING REPRE
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Kolf JN, 2022, 2022 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), DOI 10.1109/IJCB54206.2022.10007980
   Kortylewski A, 2018, Arxiv, DOI arXiv:1802.05891
   Kortylewski A, 2019, IEEE COMPUT SOC CONF, P2261, DOI 10.1109/CVPRW.2019.00279
   Krishnamoorthi R., 2018, ARXIV PREPRINT ARXIV, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumari P, 2022, J KING SAUD UNIV-COM, V34, P1086, DOI 10.1016/j.jksuci.2019.06.003
   Lehtinen J., 2020, Advances in Neural Information Processing Systems (NeurIPS), V33, P12104
   Li HC, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20216114
   Li X, 2019, IEEE I CONF COMP VIS, P9166, DOI 10.1109/ICCV.2019.00926
   Liu J., 2022, LECT NOTES COMPUTER, V13672
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma YJ, 2021, AM J ROENTGENOL, V217, P1242, DOI 10.2214/AJR.21.26239
   Mansfield A., 2006, Information technology-biometric performance testing and reporting-part 1: Principles and framework, P19795
   Martínez-Díaz Y, 2021, INT C PATT RECOG, P5421, DOI 10.1109/ICPR48806.2021.9412280
   Martínez-Díaz Y, 2021, ARTIF INTELL REV, V54, P6201, DOI 10.1007/s10462-021-09974-2
   Martínez-Díaz Y, 2019, IEEE INT CONF COMP V, P2721, DOI 10.1109/ICCVW.2019.00333
   Nie L, 2014, INT C PATT RECOG, P399, DOI 10.1109/ICPR.2014.77
   Park U., 2009, 2009 IEEE 3 INT C BI, P1
   Parkhi OM, 2015, DEEP FACE RECOGNITIO
   Paszke A, 2019, ADV NEUR IN, V32
   Qijing Huang, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P206, DOI 10.1145/3431920.3439295
   Qiu HB, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P10860, DOI 10.1109/ICCV48922.2021.01070
   Raja KB, 2014, 2014 INTERNATIONAL CONFERENCE OF THE BIOMETRICS SPECIAL INTEREST GROUP (BIOSIG)
   Raja KB, 2016, IEEE IMAGE PROC, P330, DOI 10.1109/ICIP.2016.7532373
   Reddy, 2018, 2018 IEEE INT S TECH, P1
   Reddy N, 2019, INT CONF BIOMETR THE, DOI 10.1109/btas46853.2019.9185993
   Rezende M., 2015, PROJETOS DISSERTA ES, V4
   Ross Arun, 2012, Proceedings of the IEEE 5th International Conference on Biometrics, pag, P446
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma R, 2023, COMPUT VIS IMAGE UND, V226, DOI 10.1016/j.cviu.2022.103583
   Shoukai Xu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P1, DOI 10.1007/978-3-030-58610-2_1
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spolaor R, 2016, PSYCHNOLOGY J, V14, P87
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tan CW, 2012, INT C PATT RECOG, P553
   Tomasevic D, 2022, 2022 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), DOI 10.1109/IJCB54206.2022.10007982
   Uzair M, 2013, IEEE WORK APP COMP, P246, DOI 10.1109/WACV.2013.6475025
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Yaohui Cai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13166, DOI 10.1109/CVPR42600.2020.01318
   Zanlorensi L. A., 2022, SCI REP-UK, V12, P1
   Zanlorensi LA, 2020, IEEE IMAGE PROC, P1361, DOI [10.1109/icip40778.2020.9191251, 10.1109/ICIP40778.2020.9191251]
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhang P, 2022, IEEE ACCESS, V10, P31740, DOI 10.1109/ACCESS.2022.3150862
   Zhang Q, 2018, IEEE T INF FOREN SEC, V13, P2897, DOI 10.1109/TIFS.2018.2833033
   Zhao ZJ, 2017, IEEE T INF FOREN SEC, V12, P1017, DOI 10.1109/TIFS.2016.2636093
   Zhuang BH, 2018, PROC CVPR IEEE, P7920, DOI 10.1109/CVPR.2018.00826
   Zuras D., 2008, IEEE Std, V2008, P1
NR 92
TC 6
Z9 6
U1 1
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2023
VL 135
AR 104692
DI 10.1016/j.imavis.2023.104692
EA MAY 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA H9OA8
UT WOS:000999158900001
DA 2024-07-18
ER

PT J
AU Jabbooree, AI
   Khanli, LM
   Salehpour, P
   Pourbahrami, S
AF Jabbooree, Abbas Issa
   Khanli, Leyli Mohammad
   Salehpour, Pedram
   Pourbahrami, Shahin
TI A novel facial expression recognition algorithm using geometry
   β-skeleton in fusion based on deep CNN
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Data fusion; beta-Skeleton; Geometry features; Deep learning; CNN
ID NETWORKS
AB Facial expression recognition (FER) methods based on single-source facial data often suffer from reduced accuracy or unpredictability due to facial occlusion or illumination changes. To address this, a new technique called Fusion-CNN is proposed. It improves accuracy by extracting hybrid features using a beta-skeleton undirected graph and an ellipse with parameters trained using a 1D-CNN. In addition, a 2D-CNN is trained on the same image. The outputs fromthese two subnetworks are fused, and their features are concatenated to create a feature vector for classification in a deep neural network. The proposed method is evaluated on four public face datasets: the extended Cohn-Kanade (CK+) dataset, the Japanese Female Facial Expression (JAFFE) dataset, Karolinska Directed Emotional Faces (KDEF), and Oulu-CASIA. The experimental results show that Fusion-CNN outperforms other algorithms, achieving recognition accuracy of 98.22%, 93.07%, 90.30%, and 90.13% for the CK+, JAFFE, KDEF, and Oulu-CASIA datasets, respectively. (C) 2023 Elsevier B.V. All rights reserved.
C1 [Jabbooree, Abbas Issa; Khanli, Leyli Mohammad; Salehpour, Pedram] Univ Tabriz, Fac Elect & Comp Engn, Dept Comp Engn, Tabriz, Iran.
   [Pourbahrami, Shahin] Tech & Vocat Univ TVU, Dept Comp Engn, Tehran, Iran.
   [Salehpour, Pedram] Univ Tabriz, Bisto Noh Bahman Bulvar, Tabriz 5166616471, Iran.
C3 University of Tabriz; University of Tabriz
RP Salehpour, P (corresponding author), Univ Tabriz, Bisto Noh Bahman Bulvar, Tabriz 5166616471, Iran.
EM l-khanli@tabrizu.ac.ir; psalehpoor@tabrizu.ac.ir;
   sh.porbahrami@tabrizu.ac.ir
CR Agrawal A, 2020, VISUAL COMPUT, V36, P405, DOI 10.1007/s00371-019-01630-9
   Al Machot F, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19071659
   Alay N, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20195523
   Albiero V, 2021, PROC CVPR IEEE, P7613, DOI 10.1109/CVPR46437.2021.00753
   Allamy S, 2021, 2021 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2021), DOI 10.1109/SSCI50451.2021.9659979
   Barman A, 2021, PATTERN RECOGN LETT, V145, P254, DOI 10.1016/j.patrec.2017.06.018
   Beh KX, 2019, 2019 IEEE 15TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2019), P192, DOI [10.1109/CSPA.2019.8696059, 10.1109/cspa.2019.8696059]
   Boughida A, 2022, EVOL SYST-GER, V13, P331, DOI 10.1007/s12530-021-09393-2
   Chen A, 2020, IEEE ACCESS, V8, P49741, DOI 10.1109/ACCESS.2020.2980060
   Ding H, 2017, IEEE INT CONF AUTOMA, P118, DOI 10.1109/FG.2017.23
   Do LN, 2021, J SUPERCOMPUT, V77, P10773, DOI 10.1007/s11227-021-03690-y
   Eng S. K., 2019, IOP Conference Series: Materials Science and Engineering, V705, DOI 10.1088/1757-899X/705/1/012031
   Gabdulkhakova A, 2018, INT C PATT RECOG, P3025, DOI 10.1109/ICPR.2018.8546138
   Gera D, 2021, PATTERN RECOGN LETT, V145, P58, DOI 10.1016/j.patrec.2021.01.029
   Goeleven E, 2008, COGNITION EMOTION, V22, P1094, DOI 10.1080/02699930701626582
   Gonzalez-Lozoya SM, 2020, MULTIMED TOOLS APPL, V79, P13987, DOI 10.1007/s11042-020-08681-4
   Han Y., 2021, RES FACIAL EXPRESSIO
   Huang J., 2019, EURASIP J IMAGE VIDE, V1, P2019
   Hyun J, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401114
   Joseph A, 2020, VISUAL COMPUT, V36, P529, DOI 10.1007/s00371-019-01628-3
   Kola DGR, 2021, MULTIMED TOOLS APPL, V80, P2243, DOI 10.1007/s11042-020-09663-2
   Lagias AE, 2018, IEEE WIREL COMMUN LE, V7, P392, DOI 10.1109/LWC.2017.2779507
   Li F, 2019, EURASIP J ADV SIG PR, V2019, DOI 10.1186/s13634-019-0651-3
   Liu C, 2021, IEEE ACCESS, V9, P18876, DOI 10.1109/ACCESS.2021.3054332
   Liu TT, 2021, INFRARED PHYS TECHN, V112, DOI 10.1016/j.infrared.2020.103594
   Liu X, 2021, IEEE SENS J, V21, P11532, DOI 10.1109/JSEN.2020.3028075
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Minaee S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093046
   Mitiche I, 2020, IET GENER TRANSM DIS, V14, P5766, DOI 10.1049/iet-gtd.2020.0773
   Murugappan M, 2021, PLOS ONE, V16, DOI 10.1371/journal.pone.0247131
   Nan YH, 2022, ALEX ENG J, V61, P4435, DOI 10.1016/j.aej.2021.09.066
   Niu B, 2021, COMPUT INTEL NEUROSC, V2021, DOI 10.1155/2021/8828245
   Ozcan T., 2019, BALK J ELECT COMPUT, V7, P195
   Ozcan T, 2020, MULTIMED TOOLS APPL, V79, P26587, DOI 10.1007/s11042-020-09268-9
   Park S.J., 2021, SENSORS-BASEL, V21, P1
   Pócsová J, 2018, 2018 19TH INTERNATIONAL CARPATHIAN CONTROL CONFERENCE (ICCC), P532, DOI 10.1109/CarpathianCC.2018.8399688
   Porcu S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9111892
   Pourbahrami S., 2020, IRAN J COMPUTER SCI, V3, P59
   Pourbahrami S, 2020, IRAN CONF ELECTR ENG, P94
   Pourbahrami S, 2019, EXPERT SYST APPL, V115, P57, DOI 10.1016/j.eswa.2018.07.066
   Ngoc QT, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050764
   Rizwan SA, 2020, INT CONF ADV COMP SC, DOI 10.1109/icacs47775.2020.9055954
   Rodrigues F, 2019, INFORM FUSION, V49, P120, DOI 10.1016/j.inffus.2018.07.007
   Sajjad M, 2020, MOBILE NETW APPL, V25, P1611, DOI 10.1007/s11036-019-01366-9
   Samara A, 2019, J AMB INTEL HUM COMP, V10, P2175, DOI 10.1007/s12652-017-0636-8
   Shahsavarifar R., 2018, COMPUTING PLANAR BET, P1
   Shan K, 2017, 2017 IEEE/ACIS 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING RESEARCH, MANAGEMENT AND APPLICATIONS (SERA), P123, DOI 10.1109/SERA.2017.7965717
   Sikka K, 2016, PROC CVPR IEEE, P5580, DOI 10.1109/CVPR.2016.602
   Sukhavasi S.B., 2022, INT J ENV RES PUB HE, V19
   Suraiya M.R.I., 2020, SENSOE MDPI, V20
   Taini M, 2008, INT C PATT RECOG, P1438
   Tang Y, 2021, IEEE T IMAGE PROCESS, V30, P444, DOI 10.1109/TIP.2020.3037467
   Teja BSM, 2021, MATER TODAY-PROC, V37, P2578, DOI 10.1016/j.matpr.2020.08.501
   Tuama S.A., 2020, IRAQI COMMIS COMP, V1
   Wang M., 2020, J PHYS C SER, V1601
   Wang RS, 2022, IEEE WINT CONF APPL, P2533, DOI 10.1109/WACV51458.2022.00259
   Yan K., 2022, DIGIT COMMUN NETW
   Yang Y, 2016, PATTERN RECOGN LETT, V71, P78, DOI 10.1016/j.patrec.2015.11.027
   Yu ZB, 2018, VISUAL COMPUT, V34, P1691, DOI 10.1007/s00371-017-1443-0
   Zhang HL, 2019, IEEE ACCESS, V7, P159081, DOI 10.1109/ACCESS.2019.2949741
   Zhou YQ, 2017, IEEE IJCNN, P2031
   Zhu JP, 2020, IEEE INT SYMP CIRC S
   Zhu X., 2021, SENSORS-BASEL, V21, P1
NR 64
TC 4
Z9 4
U1 2
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2023
VL 134
AR 104677
DI 10.1016/j.imavis.2023.104677
EA APR 2023
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA F9LP5
UT WOS:000985492900001
DA 2024-07-18
ER

PT J
AU Jain, DK
   Dutta, AK
   Verdú, E
   Alsubai, S
   Sait, ARW
AF Jain, Deepak Kumar
   Dutta, Ashit Kumar
   Verdu, Elena
   Alsubai, Shtwai
   Sait, Abdul Rahaman Wahab
TI An automated hyperparameter tuned deep learning model enabled facial
   emotion recognition for autonomous vehicle drivers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Autonomous driving systems; Emotion recognition; Deep learning; Facial
   expressions; Object detection; Metaheuristics
AB The progress of autonomous driving cars is a difficult movement that causes problems regarding safety, ethics, social acceptance, and cybersecurity. Currently, the automotive industry is utilizing these technologies to assist drivers with advanced driver assistance systems. This system helps different functions to careful driving and predict drivers' ability of stable driving behavior and road safety. A great number of researches have shown that the driver's emotion is the major factor that handles the emotions, resulting in serious vehicle collisions. As a result, continuous monitoring of drivers' behavior could assist to evaluate their behavior to prevent accidents. The study proposes a new Squirrel Search Optimization with Deep Learning Enabled Facial Emotion Recognition (SSO-DLFER) technique for Autonomous Vehicle Drivers. The proposed SSO-DLFER technique fo-cuses mainly on the identification of driver facial emotions in the AVs. The proposed SSO-DLFER technique fol-lows two major processes namely face detection and emotion recognition. The RetinaNet model is employed at the initial phase of the face detection process. For emotion recognition, the SSO-DLFER technique applied the Neural Architectural Search (NASNet) Large feature extractor with a gated recurrent unit (GRU) model as a classifier. For improving the emotion recognition performance, the SSO-based hyperparameter tuning procedure is performed. The simulation analysis of the SSO-DLFER technique is tested under benchmark datasets and the experimental outcome was investigated under various aspects. The comparative analysis reported the enhanced performance of the SSO-DLFER algorithm on recent approaches. & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Jain, Deepak Kumar] Dalian Univ Technol, Key Lab Intelligent Control & Optimizat Ind Equipm, Minist Educ, Dalian 116024, Peoples R China.
   [Jain, Deepak Kumar] Sch Artificial Intelligence, Dalian, Peoples R China.
   [Jain, Deepak Kumar] Symbiosis Int Univ, Symbiosis Inst Technol, Pune, India.
   [Dutta, Ashit Kumar] AlMaarefa Univ, Coll Appl Sci, Dept Comp Sci & Informat Syst, Riyadh, Saudi Arabia.
   [Verdu, Elena] Univ Int Rioja, Escuela Super Ingn & Tecnol, Logrono, La Rioja, Spain.
   [Alsubai, Shtwai] Prince Sattam bin Abdulaziz Univ, Coll Comp Engn & Sci Al Kharj, Dept Comp Sci, Al Kharj 151, Saudi Arabia.
   [Sait, Abdul Rahaman Wahab] King Faisal Univ, Ctr Documents & Adm Commun, Dept Documents & Arch, Al Hufuf 31982, Saudi Arabia.
C3 Dalian University of Technology; Symbiosis International University;
   Symbiosis Institute of Technology (SIT); Almaarefa University;
   Universidad Internacional de La Rioja (UNIR); Prince Sattam Bin
   Abdulaziz University; King Faisal University
RP Verdú, E (corresponding author), Univ Int Rioja, Escuela Super Ingn & Tecnol, Logrono, La Rioja, Spain.
EM elena.verdu@unir.net
RI Sait, Abdul/AFT-9562-2022; Alsubai, Shtwai/ABW-9013-2022; Verdu,
   Elena/A-5021-2019
OI Sait, Abdul/0000-0001-5445-7899; Alsubai, Shtwai/0000-0002-6584-7400;
   Verdu, Elena/0000-0002-3040-7077; DUTTA, ASHIT KUMAR/0000-0002-1208-2678
FU Deanship of Scienti fic Research, Vice Presidency for Graduate Studies
   and Scienti fic Research, King Faisal University, Saudi Arabia [2714]
FX This work was supported by the Deanship of Scienti fic Research, Vice
   Presidency for Graduate Studies and Scienti fic Research, King Faisal
   University, Saudi Arabia [Grant No. 2714] .
CR Alcaide A, 2022, INT J INTERACT MULTI, V7, P121, DOI 10.9781/ijimai.2021.11.003
   Arefnezhad S, 2022, ENERGIES, V15, DOI 10.3390/en15020480
   Benamara NK, 2022, INT J INTERACT MULTI, V7, P132, DOI 10.9781/ijimai.2021.12.003
   Chauhan S., 2021 IEEE 2 INT C EL, P1
   Chen L, 2021, IEEE T INTELL TRANSP, V22, P3234, DOI 10.1109/TITS.2020.2993926
   Garg M, 2023, MULTIMED TOOLS APPL, V82, P6271, DOI 10.1007/s11042-022-13596-3
   Hu HP, 2019, IEEE ACCESS, V7, P105652, DOI 10.1109/ACCESS.2019.2932198
   Izquierdo-Reyes J, 2018, INT J INTERACT DES M, V12, P1447, DOI 10.1007/s12008-018-0473-9
   Jeong M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124270
   Kandeel Amany A., 2021, Pattern Recognition. ICPR International Workshops and Challenges. Proceedings. Lecture Notes in Computer Science (LNCS 12666), P699, DOI 10.1007/978-3-030-68780-9_53
   Lee KH, 2020, I C INF COMM TECH CO, P1332, DOI 10.1109/ICTC49870.2020.9289227
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lorente MPS, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11083321
   Lu HM, 2019, IEEE NETWORK, V33, P65, DOI 10.1109/MNET.2019.1800339
   Lundqvist D., 1998, The Karolinska Directed Emotional Faces-KDEF
   Meshram H.A., 2020, 2020 IEEE INT C INNO, P1
   Naz S, 2019, INT J INTERACT MULTI, V5, P86, DOI 10.9781/ijimai.2017.10.002
   Ouyang H, 2020, PROCESSES, V8, DOI 10.3390/pr8040391
   Radhika K., 2020, Nature inspired computing for data science, P57
   Shafaei S, 2019, LECT NOTES COMPUT SC, V11367, P386, DOI 10.1007/978-3-030-21074-8_32
   Sini J, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9030518
   Sukhavasi SB, 2022, INT J ENV RES PUB HE, V19, DOI 10.3390/ijerph19053085
   Xiao HF, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12020807
   Xing Y, 2020, IEEE SYS MAN CYBERN, P4410, DOI [10.1109/smc42975.2020.9283004, 10.1109/SMC42975.2020.9283004]
   Yaman SO, 2023, INT J DIABETES DEV C, V43, P125, DOI 10.1007/s13410-022-01095-y
   Yuan Y., 2019, Adv. Neural Inf. Process. Syst, P1
   Zepf S, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3388790
NR 27
TC 9
Z9 9
U1 11
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2023
VL 133
AR 104659
DI 10.1016/j.imavis.2023.104659
EA MAR 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA L9DO3
UT WOS:001026198500001
DA 2024-07-18
ER

PT J
AU Chen, Y
   Yang, YZ
   Liu, WF
   Huang, YW
   Li, JM
AF Chen, Ying
   Yang, Yuzhen
   Liu, Wenfeng
   Huang, Yuwen
   Li, Jinming
TI Pose-guided counterfactual inference for occluded person
   re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Occluded person re-identification; Attention mechanism; Counterfactual
   inference; Counterfactual intervention
AB Occluded person re-identification (ReID) isa challenging task as the body is partially occluded by obstacles in crowd scenarios. Many previous studies employed an attention mechanism to focus on fine-grained local infor-mation with conventional likelihood while ignoring the inherent causality between the final prediction results and attention, especially occluded person always possesses biased clues. To address this problem, we propose a Pose-Guided Multi-Attention Network (PGMA-Net) for occluded person ReID in an end-to-end manner. PGMA-Net contains two main novel components: Pose-Guided Counterfactual Inference Branch (PGCIB) and Striped-and Patched-Attention Module (SPAM). The PGCIB jointly explores the causality between the predicted identities and input clues to alleviate the negative effects brought by occluded bias. Specifically, the counterfac-tual inference can directly guide the attention learning process via the counterfactual intervention. The SPAM generates a set of attention vectors for storing part prototypes over multiple rounds of attention. We empirically demonstrate that PGMA-Net can improve the recognition in both occluded and non-occluded ReID. With the above designs, our framework achieves 52.2% in mAP and 62.0% in top-1 on the Occluded-DukeMTMC dataset, surpassing the baseline by a large margin. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Chen, Ying; Yang, Yuzhen; Liu, Wenfeng; Huang, Yuwen; Li, Jinming] Heze Univ, Sch Comp Sci & Technol, Comp Informat Proc Lab, Heze 274015, Shandong, Peoples R China.
C3 Heze University
RP Li, JM (corresponding author), Heze Univ, Sch Comp Sci & Technol, Comp Informat Proc Lab, Heze 274015, Shandong, Peoples R China.
EM ljmgw@163.com
FU Heze University Doctoral Foundation [XY22BS18]; Shandong Provincial
   Natural Science Foundation of China [ZR2016FQ25]; Shandong Social
   Science Planning Fund Program [20CDCJ01]; Shandong Province Social
   Science Popularization and Application Research Project [2020-SKZZ-51];
   Heze University Doctoral Research and Development Fund [XY20BS19];
   NSFC-Xinjiang Joint Fund [U1903127]; Natural Science Foundation of
   Shandong Province [ZR2020MF052]
FX This work was supported by the Heze University Doctoral Foundation
   (No.XY22BS18), and the Shandong Provincial Natural Science Foundation of
   China (No. ZR2016FQ25), and the Shandong Social Science Planning Fund
   Program (No. 20CDCJ01) ; this work was supported in part by the Shandong
   Province Social Science Popularization and Application Research Project
   (No. 2020-SKZZ-51) , and the Heze University Doctoral Research and
   Development Fund (No. XY20BS19) , and the NSFC-Xinjiang Joint Fund (No.
   U1903127) , and the Natural Science Foundation of Shandong Province (No.
   ZR2020MF052) .
CR Cai H., 2019, IEEE CVF C COMP VIS, P1
   Chen G., 2021, P OF THE IEEE INT C, P1
   Chen G., 2021, ICCV, P9824
   Deng J., 2009, J ALLOY COMPD, P248, DOI DOI 10.1016/j.jallcom.2006.10.076
   Fan X, 2019, LECT NOTES COMPUT SC, V11362, P19, DOI 10.1007/978-3-030-20890-5_2
   Fang M., 2020, IMAGE VIS COMPUT, P1
   He L., 2018, ARXIV, V14
   He LX, 2019, IEEE I CONF COMP VIS, P8449, DOI 10.1109/ICCV.2019.00854
   He LX, 2018, PROC CVPR IEEE, P7073, DOI 10.1109/CVPR.2018.00739
   Huang H., 2020, IEEE INT CON MULTI, P1, DOI DOI 10.1109/ICME46284.2020.9102789
   Huo LJ, 2021, INT C PATT RECOG, P3652, DOI 10.1109/ICPR48806.2021.9412527
   Kiran M, 2023, Arxiv, DOI arXiv:2104.06524
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Lingxiao He, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P357, DOI 10.1007/978-3-030-58604-1_22
   Lopez-Paz D, 2017, PROC CVPR IEEE, P58, DOI 10.1109/CVPR.2017.14
   Luo H., 2019, P IEEE CVF C COMP VI
   Ma ZX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P1487, DOI 10.1145/3474085.3475283
   Mahendran Thomas A., 2020, NEURAL INFORM PROCES, P1
   Miao JX, 2022, IEEE T NEUR NET LEAR, V33, P4624, DOI 10.1109/TNNLS.2021.3059515
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Pan XG, 2018, LECT NOTES COMPUT SC, V11208, P484, DOI 10.1007/978-3-030-01225-0_29
   Park J., 2018, BRIT MACH VIS C BMVC
   Park S, 2019, AAAI CONF ARTIF INTE, P6883
   Pearl Judea, 2010, Causality: objectives and assessment, P39
   Rao Yongming, 2021, P IEEE CVF INT C COM, P1025
   Shang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11741, DOI 10.1109/CVPR42600.2020.01176
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tang KH, 2020, PROC CVPR IEEE, P3713, DOI 10.1109/CVPR42600.2020.00377
   Vaswani A, 2017, ADV NEUR IN, V30
   Vig J., 2020, arXiv
   Wang GA, 2020, PROC CVPR IEEE, P6448, DOI 10.1109/CVPR42600.2020.00648
   Wang H.X., 2021, IMAGE VISION COMPUT, V111, P1
   Wang T., 2020, P IEEE CVF C COMP VI, P378
   Wood-Doughty Z., 2018, EMP METH NAT LANG PR, P4586
   Xu YJ, 2021, KNOWL-BASED SYST, V212, DOI 10.1016/j.knosys.2020.106554
   Yang K, 2021, ARXIV
   Yujian F, 2021, IEEE SIGNAL PROC LET, V28, P1425, DOI 10.1109/LSP.2021.3093865
   Zhang XK, 2021, IEEE T CIRC SYST VID, V31, P2764, DOI 10.1109/TCSVT.2020.3033165
   Zhang X, 2018, Arxiv, DOI arXiv:1711.08184
   Zhang Y.-F., 2021, arXiv
   Zheng KC, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4537, DOI 10.1145/3474085.3475610
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng WS, 2015, IEEE I CONF COMP VIS, P4678, DOI 10.1109/ICCV.2015.531
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhuo JX, 2018, IEEE INT CON MULTI
NR 48
TC 8
Z9 8
U1 1
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2022
VL 128
AR 104587
DI 10.1016/j.imavis.2022.104587
EA NOV 2022
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 6Q9BU
UT WOS:000891904500003
DA 2024-07-18
ER

PT J
AU Song, BY
   Hu, XG
   Xiao, J
   Zhang, GF
   Chen, TY
AF Song, Boyang
   Hu, Xiaoguang
   Xiao, Jin
   Zhang, Guofeng
   Chen, Tianyou
TI Implicit neural refinement based multi-view stereo network with adaptive
   correlation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi -view stereo; Implicit neural representation; Adaptive
   aggregation; Feature pyramid; Coarse -to -fine
AB In this paper, we propose ACINR-MVSNet, an end-to-end trainable framework with adaptive group-wise corre-lation and implicit neural depth refinement for multi-view stereo (MVS). Previous learning-based MVS methods have demonstrated their outstanding performance, and most of them estimate depth maps in a coarse-to-fine manner. However, in a commonly used multi-stage cascaded framework, the previous wrong estimation might lead to error propagation. In contrast, we focus on another coarse-to-fine structure, i.e., one-stage MVS ar-chitecture followed by refinement modules. Inspired by implicit neural representation, we propose an implicit neural refinement module to refine the coarse depth map. Guided by the corresponding reference image, it can better recover finer details, especially those in boundary areas. To solve the visibility problem in complex sce-narios while maintaining efficiency, we propose an adaptive group-wise correlation similarity measure for cost volume construction. Besides, we present a pyramid-based feature extraction network with a repeated top -down and bottom-up structure to gather more context-aware information, which can better meet the challenges in ill-posed regions. This novel feature extractor is also utilized to construct an enhanced Gauss-Newton refine-ment module for further upsampling and optimizing. Extensive experiments on the DTU, the Tanks & Temples and the BlendedMVS datasets demonstrate the effectiveness and generalization of our approach, which can achieve better or competitive results compared to state-of-the-art methods. The code will be available at https://github.com/BoyangSONG/ACINR-MVSNet.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Song, Boyang; Hu, Xiaoguang; Xiao, Jin; Zhang, Guofeng; Chen, Tianyou] Beihang Univ, 37 Xueyuan Rd, Beijing, Peoples R China.
C3 Beihang University
RP Xiao, J (corresponding author), Beihang Univ, 37 Xueyuan Rd, Beijing, Peoples R China.
EM buaasong96@buaa.edu.cn; xiaoguang@buaa.edu.cn; xiaojin@buaa.edu.cn;
   gfzhang@buaa.edu.cn; chentianyou@buaa.edu.cn
RI Chen, Tianyou/ABE-7836-2021; Guofeng, Zhang/J-9769-2016
OI Guofeng, Zhang/0000-0003-1180-4170; Song, Boyang/0009-0005-6985-7285;
   xiao, jin/0000-0003-2462-4996; Chen, Tianyou/0000-0002-7107-1004
FU National Natural Science Founda-tion of China [51807003]
FX Acknowledgment This work was supported by the National Natural Science
   Founda-tion of China (under Grant 51807003) .
CR Aanæs H, 2016, INT J COMPUT VISION, V120, P153, DOI 10.1007/s11263-016-0902-9
   Bi S., 2020, European Conference on Computer Vision (ECCV), P294
   Bi S, 2020, Arxiv, DOI [arXiv:2008.03824, 10.48550/arXiv.2008.03824, DOI 10.48550/ARXIV.2008.03824]
   Campbell NDF, 2008, LECT NOTES COMPUT SC, V5302, P766, DOI 10.1007/978-3-540-88682-2_58
   Chang D., ARXIV PREPR, DOI [10.48550/arXiv.2203.03949, DOI 10.48550/ARXIV.2203.03949]
   Chen A., PROC IEEECVF INT C C, P14124
   Chen R, 2021, IEEE T PATTERN ANAL, V43, P3695, DOI 10.1109/TPAMI.2020.2988729
   Chen R, 2019, IEEE I CONF COMP VIS, P1538, DOI 10.1109/ICCV.2019.00162
   Chen Y, PROC IEEECVF C COMPU, P8628
   Cheng S, 2020, PROC CVPR IEEE, P2521, DOI 10.1109/CVPR42600.2020.00260
   Furukawa Y, 2010, IEEE T PATTERN ANAL, V32, P1362, DOI 10.1109/TPAMI.2009.161
   Galliani S, 2015, IEEE I CONF COMP VIS, P873, DOI 10.1109/ICCV.2015.106
   Genova K, 2020, PROC CVPR IEEE, P4856, DOI 10.1109/CVPR42600.2020.00491
   Gu XD, 2020, PROC CVPR IEEE, P2492, DOI 10.1109/CVPR42600.2020.00257
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hongwei Yi, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P766, DOI 10.1007/978-3-030-58545-7_44
   Ji MQ, 2017, IEEE I CONF COMP VIS, P2326, DOI 10.1109/ICCV.2017.253
   Kar A, 2017, ADV NEUR IN, V30
   Knapitsch A, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073599
   Li ZQ, 2021, PROC CVPR IEEE, P6494, DOI 10.1109/CVPR46437.2021.00643
   Lim B, 2017, IEEE COMPUT SOC CONF, P1132, DOI 10.1109/CVPRW.2017.151
   Lombardi S, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323020
   Martin-Brualla R, PROC IEEECVF C COMPU, P7210
   Masson JEN, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104369
   Mildenhall Ben, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P405, DOI 10.1007/978-3-030-58452-8_24
   Park K, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P5845, DOI 10.1109/ICCV48922.2021.00581
   Pumarola A, 2021, PROC CVPR IEEE, P10313, DOI 10.1109/CVPR46437.2021.01018
   Rebain D., PROC IEEECVF C COMPU, P14153
   Saito S, 2019, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2019.00239
   Schönberger JL, 2016, LECT NOTES COMPUT SC, V9907, P501, DOI 10.1007/978-3-319-46487-9_31
   Sitzmann V, 2019, ADV NEUR IN, V32
   Tang JX, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4390, DOI 10.1145/3474085.3475584
   Thies J, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3323035
   Tola E, 2012, MACH VISION APPL, V23, P903, DOI 10.1007/s00138-011-0346-8
   Wang Fangjinhua, 2021, PATCHMATCHNET LEARNE
   Wei Zizhuang, 2021, P IEEE CVF INT C COM, P6187
   Xian W, PROC IEEECVF C COMPU, P9421
   Xiang Fanbo., 2021, ARXIV PREPRINT ARXIV
   Xu QS, 2020, AAAI CONF ARTIF INTE, V34, P12508
   Xu QS, 2019, PROC CVPR IEEE, P5478, DOI 10.1109/CVPR.2019.00563
   Yan J., EUR C COMPUT VIS 202, P674
   Yang JY, 2020, PROC CVPR IEEE, P4876, DOI 10.1109/CVPR42600.2020.00493
   Yao Y, PROC EUR C COMPUT VI, P767
   Yao Y., PROC IEEECVF C COMPU, P1790
   Yao Y, 2019, PROC CVPR IEEE, P5520, DOI 10.1109/CVPR.2019.00567
   YiWei Shaohui Liu, 2021, P IEEE CVF INT C COM, P5610
   Yu A, 2021, PROC CVPR IEEE, P4576, DOI 10.1109/CVPR46437.2021.00455
   Yu AZ, 2021, ISPRS J PHOTOGRAMM, V175, P448, DOI 10.1016/j.isprsjprs.2021.03.010
   Yu Z, PROC IEEECVF C COMPU, P1949
   Zhang J., 2020, BR MACH VIS C
   Zhang K, 2020, Arxiv, DOI arXiv:2010.07492
   Zhou TH, 2018, ACM T GRAPHIC, V37, DOI 10.1145/3197517.3201323
NR 52
TC 1
Z9 2
U1 3
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104511
DI 10.1016/j.imavis.2022.104511
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3F6VI
UT WOS:000830804100007
DA 2024-07-18
ER

PT J
AU Ye, XQ
   Yan, BB
   Liu, BY
   Wang, HC
   Qi, S
   Chen, D
   Wang, P
   Wang, KR
   Sang, XZ
AF Ye, Xiaoqian
   Yan, Binbin
   Liu, Boyang
   Wang, Huachun
   Qi, Shuai
   Chen, Duo
   Wang, Peng
   Wang, Kuiru
   Sang, Xinzhu
TI Improved real-time three-dimensional stereo matching with local
   consistency
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image matching; Disparity refinement; Localconsistency; Real-time
AB Existing stereo matching algorithms are unable to meet the real-time and high-performance dual requirements in practical applications. To address this problem, a novel stereo network is proposed, which utilizes the prior of local disparity consistency to improve the performance of real-time disparity estimation. Based on the initial disparity estimation by the light-weight pyramid matching network, novel spatial consistency refinement (SCR) module and time consistency refinement (TCR) module are designed for further disparity refinement. SCR module propagates the neighborhood high-confidence predictions of sparse sampling to unreliable regions for disparity refinement. A single-layer Dynamic Local Filter (DLF) is designed to realize the content-adaptive propagation, which effectively improves the disparity quality without significantly increasing the burden of com-putation and memory. For real-time disparity estimation of consecutive frames, novel TCR module is further proposed to refine the disparity estimation based on the time local consistency of disparity. The proposed method is evaluated on the Scene Flow and KITTI 2015 datasets with comprehensive experiments. Experimental results demonstrated that our method can achieve high-accuracy disparity estimation and real-time running speed of over 40 FPS, which significantly outperforms the compared networks with similar runtimes.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Ye, Xiaoqian; Yan, Binbin; Liu, Boyang; Wang, Huachun; Qi, Shuai; Chen, Duo; Wang, Peng; Wang, Kuiru; Sang, Xinzhu] Beijing Univ Posts & Telecommun, State Key Lab Informat Photon & Opt Commun, Beijing, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Yan, BB; Sang, XZ (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Informat Photon & Opt Commun, Beijing, Peoples R China.
EM yanbinbin@bupt.edu.cn; xzsang@bupt.edu.cn
RI qi, shuai/HDM-0369-2022; Wang, Huachun/AAO-3889-2021; Qi,
   Shuai/HDM-0320-2022
OI qi, shuai/0000-0002-4200-2472; Qi, Shuai/0000-0002-4200-2472
FU National Natural Science Foundation of China [61905020, 62175017,
   62075016, 61905017]
FX Acknowledgements This work was supported in part by the National Natural
   Science Foundation of China under Grants 61905020, 62175017, 62075016,
   61905017.
CR Adhyapak SA, 2007, J ELECTRON IMAGING, V16, DOI 10.1117/1.2711817
   [Anonymous], ECCV
   Badki Abhishek., Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, P1600
   Bascle B., 1993, [1993] Proceedings Fourth International Conference on Computer Vision, P421, DOI 10.1109/ICCV.1993.378185
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Cheng XJ, 2020, IEEE T PATTERN ANAL, V42, P2361, DOI 10.1109/TPAMI.2019.2947374
   Cox I. J., 1995, Proceedings. International Conference on Image Processing (Cat. No.95CB35819), P366, DOI 10.1109/ICIP.1995.537491
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dovesi Pier Luigi, 2020, 2020 IEEE International Conference on Robotics and Automation (ICRA), P10780, DOI 10.1109/ICRA40945.2020.9196784
   Duggal S, 2019, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2019.00448
   Gerrits Mark., 2006, The 3rd Canadian Conference on Computer and Robot Vision (CRV'06), P66
   Guo X., P IEEECVF C COMPUTER, P3273
   Guo XY, 2019, PROC CVPR IEEE, P3268, DOI 10.1109/CVPR.2019.00339
   Gupta RK, 2012, NEURAL COMPUT APPL, V21, P1585, DOI 10.1007/s00521-012-0831-7
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Jia X., 2016, Advances in Neural Information Processing Systems, V29, P667
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Kingma D. P., 2014, arXiv
   Lee H, 2019, IEEE IMAGE PROC, P4280, DOI [10.1109/ICIP.2019.8803514, 10.1109/icip.2019.8803514]
   Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614
   MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   Orts-Escolano S, 2016, UIST 2016: PROCEEDINGS OF THE 29TH ANNUAL SYMPOSIUM ON USER INTERFACE SOFTWARE AND TECHNOLOGY, P741, DOI 10.1145/2984511.2984517
   Paszke A, 2019, ADV NEUR IN, V32
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   SCHARSTEIN D, 1994, INT C PATT RECOG, P572, DOI 10.1109/ICPR.1994.576363
   Seki A., P IEEE C COMPUTER VI, P231
   Song X., 2020, IJCV
   Sun DQ, 2018, PROC CVPR IEEE, P8934, DOI 10.1109/CVPR.2018.00931
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028
   Wu ZY, 2019, IEEE I CONF COMP VIS, P7483, DOI 10.1109/ICCV.2019.00758
   Ye X., 2021, IEEE T COMPUT IMAG
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zhang C, 2015, IEEE I CONF COMP VIS, P2057, DOI 10.1109/ICCV.2015.238
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
NR 39
TC 3
Z9 3
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2022
VL 124
AR 104509
DI 10.1016/j.imavis.2022.104509
EA JUL 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3F6VI
UT WOS:000830804100002
DA 2024-07-18
ER

PT J
AU Kar, NB
   Babu, KS
   Bakshi, S
AF Kar, Nikunja Bihari
   Babu, Korra Sathya
   Bakshi, Sambit
TI Facial expression recognition system based on variational mode
   decomposition and whale optimized KELM
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; Kernel extreme learning machine;
   Variational mode decomposition; Whale optimization
ID EXTREME LEARNING-MACHINE; EMOTION RECOGNITION; FEATURES
AB In this paper, a methodology for the Facial Expression Recognition (FER) system is proposed using the Variational Mode Decomposition (VMD) and Whale Optimization (WO) with Kernel Extreme Learning Machine (KELM) classifier. A non-stationary, adaptive, and variational signal analysis technique called VMD is adopted in this work, which depends on the signal's frequency information content. The VMD decomposed the input image into four modes, and the 4th mode of the VMD decomposition is considered for feature representation, a high frequency band. This VMD mode preserves the edge and shape features from the face image efficiently. The high-dimensional features are reduced using the Principal Component Analysis + Linear Discriminant Analysis (PCA + LDA) method, which minimizes the feature dimension and retains the high variance among emotion classes. A hybrid classifier with better scalability and faster learning speed than SVM and Least Squares SVM (LS-SVM), namely WO-KELM, is proposed to discriminate facial expressions accurately. The WO algorithm is employed for optimal parameter tuning of the KELM with the RBF kernel. The performance of the proposed framework are compared with state-of-the-art methods. Extensive experiments are assessed on the two benchmark datasets, namely Japanese Female Facial Expression (JAFFE) and the Extended Cohn-Kanade (CK+). Experimental results founded on 5-fold Stratified Cross-Validation (SCV) test reveal the superiority of the proposed method over state-of-the-art systems. (C) 2022 Published by Elsevier B.V.
C1 [Kar, Nikunja Bihari] Siksha O Anusandhan, Dept Comp Sci & Engn, Bhubaneswar, Orissa, India.
   [Babu, Korra Sathya] Indian Inst Informat Technol Design & Mfg Kurnool, Dept Comp Sci & Engn, Kurnool, India.
   [Kar, Nikunja Bihari; Bakshi, Sambit] Natl Inst Technol, Dept Comp Sci & Engn, Rourkela, Orissa, India.
C3 Siksha 'O' Anusandhan University; National Institute of Technology (NIT
   System); National Institute of Technology Rourkela
RP Bakshi, S (corresponding author), Natl Inst Technol, Dept Comp Sci & Engn, Rourkela, Orissa, India.
EM sambitbaksi@gmail.com
RI Korra, Sathya Babu/R-2218-2017; Korra, Sathya Babu/JBR-9336-2023;
   Bakshi, Sambit/JDC-3355-2023
OI Korra, Sathya Babu/0000-0002-5963-5735; Bakshi,
   Sambit/0000-0002-6107-114X; Kar, Nikunja/0000-0003-0409-2080
FU NITROAA; Department of Biotechnology, Ministry of Science and
   Technology, Government of India; NVIDIA Corporation
FX This research is supported by the following projects: 1. Project titled
   "Deep learning applications for computer vision task" funded by NITROAA
   with support of Lenovo P920 and Dell Inception 7820 workstation and
   NVIDIA Corporation with support of NVIDIA Titan V and Quadro RTX 8000
   GPU. 2. Project titled "Establishment of Bioinformatics and
   Computational Biology Centre: Animal Bioinformatics-BIC at National
   Institute of Technology Rourkela" by Department of Biotechnology,
   Ministry of Science and Technology, Government of India.
CR Aleksic PS, 2006, IEEE T INF FOREN SEC, V1, P3, DOI 10.1109/TIFS.2005.863510
   Ali H, 2015, EXPERT SYST APPL, V42, P1261, DOI 10.1016/j.eswa.2014.08.049
   [Anonymous], 2013, SIN 13, DOI DOI 10.1145/2523514.2523597
   [Anonymous], 2017, P INT C COMPUTER VIS, DOI DOI 10.1007/978-981-10-2107-719
   Bisogni C, 2022, IEEE T IND INFORM, V18, P5619, DOI 10.1109/TII.2022.3141400
   Chen JK, 2018, IEEE T AFFECT COMPUT, V9, P38, DOI 10.1109/TAFFC.2016.2593719
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Dragomiretskiy K, 2014, IEEE T SIGNAL PROCES, V62, P531, DOI 10.1109/TSP.2013.2288675
   Flandrin P, 2004, IEEE SIGNAL PROC LET, V11, P112, DOI 10.1109/LSP.2003.821662
   George A., 2012, 4 INT C INT HUM, P1
   Ghimire D, 2013, SENSORS-BASEL, V13, P7714, DOI 10.3390/s130607714
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Hung-Hsu Tsai, 2010, 2010 International Conference on Machine Learning and Cybernetics (ICMLC 2010), P2697, DOI 10.1109/ICMLC.2010.5580938
   Ilbeygi M, 2012, ENG APPL ARTIF INTEL, V25, P130, DOI 10.1016/j.engappai.2011.07.004
   Kar NB, 2021, IET IMAGE PROCESS, V15, P1471, DOI 10.1049/ipr2.12118
   Kar NB, 2019, MULTIMED TOOLS APPL, V78, P4789, DOI 10.1007/s11042-017-5485-0
   Li S, 2022, IEEE T AFFECT COMPUT, V13, P1195, DOI 10.1109/TAFFC.2020.2981446
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   Maheshwari S, 2017, COMPUT BIOL MED, V88, P142, DOI 10.1016/j.compbiomed.2017.06.017
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Min Guo, 2017, Multimedia Tools and Applications, V76, P2995, DOI 10.1007/s11042-016-3282-9
   Mirjalili S, 2016, ADV ENG SOFTW, V95, P51, DOI 10.1016/j.advengsoft.2016.01.008
   Mlakar U, 2015, SIGNAL IMAGE VIDEO P, V9, P245, DOI 10.1007/s11760-015-0810-4
   Naik Shraddha, 2018, Advances in Machine Learning and Data Science. Recent Achievements and Research Directives. Advances in Intelligent Systems and Computing (AISC 705), P129, DOI 10.1007/978-981-10-8569-7_14
   Nigam S, 2018, MULTIMED TOOLS APPL, V77, P28725, DOI 10.1007/s11042-018-6040-3
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Rahulamathavan Y, 2013, IEEE T AFFECT COMPUT, V4, P83, DOI 10.1109/T-AFFC.2012.33
   Sarkar R, 2012, PROC TECH, V1, P1004, DOI 10.1016/j.protcy.2012.10.122
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Shang YY, 2023, IEEE T AFFECT COMPUT, V14, P2557, DOI 10.1109/TAFFC.2021.3139651
   Shi Dongcheng, 2010, 2010 Proceedings of 3rd International Congress on Image and Signal Processing (CISP 2010), P1970, DOI 10.1109/CISP.2010.5648166
   Siddiqi MH, 2015, IEEE T IMAGE PROCESS, V24, P1386, DOI 10.1109/TIP.2015.2405346
   Suja P, 2014, ADV INTELL SYST COMP, V264, P299, DOI 10.1007/978-3-319-04960-1_27
   Suk M, 2014, IEEE COMPUT SOC CONF, P132, DOI 10.1109/CVPRW.2014.25
   Uçar A, 2016, NEURAL COMPUT APPL, V27, P131, DOI 10.1007/s00521-014-1569-1
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Wang K, 2020, IEEE T IMAGE PROCESS, V29, P4057, DOI 10.1109/TIP.2019.2956143
   Wang SH, 2018, NEUROCOMPUTING, V272, P668, DOI 10.1016/j.neucom.2017.08.015
   Wang XH, 2013, 2013 IEEE/SICE INTERNATIONAL SYMPOSIUM ON SYSTEM INTEGRATION (SII), P227, DOI 10.1109/SII.2013.6776664
   Wei W, 2016, PATTERN RECOGN, V49, P115, DOI 10.1016/j.patcog.2015.08.004
   Xie SY, 2019, IEEE T MULTIMEDIA, V21, P211, DOI 10.1109/TMM.2018.2844085
   Xue F., 2021, P IEEE CVF INT C COM, P3581
   Yang LZ, 2018, INT J EMBED SYST, V10, P181, DOI 10.1504/IJES.2018.091775
   Zhang L, 2016, KNOWL-BASED SYST, V111, P248, DOI 10.1016/j.knosys.2016.08.018
   Zhang LG, 2011, IEEE T AFFECT COMPUT, V2, P219, DOI 10.1109/T-AFFC.2011.13
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 49
TC 2
Z9 2
U1 3
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104445
DI 10.1016/j.imavis.2022.104445
EA MAY 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1W0YE
UT WOS:000806506500001
DA 2024-07-18
ER

PT J
AU Song, D
   Ling, YT
   Li, TB
   Zhang, T
   Jin, GQ
   Guo, JB
   Li, XY
AF Song, Dan
   Ling, Yuting
   Li, Tianbao
   Zhang, Ting
   Jin, Guoqing
   Guo, Junbo
   Li, Xuanya
TI Gradual adaption with memory mechanism for image-based 3D model
   retrieval
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D model retrieval; Unsupervised learning; Domain adaptation
AB With the development of 3D modeling technology and its wide application in different fields, the number of 3D models increases rapidly, making 3D model retrieval a hot topic in current research. Compared with other 3D model retrieval methods, 2D image-based unsupervised 3D model retrieval takes the 2D images which have rich labels and are easy to obtain as the queries, and also takes into account the difficulties of labeling 3D models. 2D image-based unsupervised 3D model retrieval is a retrieval task involving cross-domain adaptation problem, which main challenge is the excessive domain gap. In this paper, we propose a cross-domain 3D model retrieval method of memory mechanism based on disentangled feature learning. The disentangled feature learning enables to disentangle the twisted original features into the isolated domain-invariant features and domain specific features, where the former is to be aligned to narrow the domain gap. On this basis, the memory mechanism selects feature vectors from class memory modules constructed by class representative features of the opposite domain for every sample, which are used to update the domain-invariant features with gradient weight. The memory mechanism can gradually improve the adaptability of the model to the very different two domains. Experiments are conducted on the public datasets MI3DOR and MI3DOR-2 to verify the feasibility and the superiority of the proposed method. Especially on MI3DOR-2 dataset, our method outperforms the current state-ofthe-art methods with gains of 7.71% for the strictest retrieval metric NN.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Song, Dan; Jin, Guoqing; Guo, Junbo] Peoples Daily Online, State Key Lab Commun Content Cognit, Beijing 100733, Peoples R China.
   [Song, Dan] Hefei Comprehens Natl Sci Ctr, Inst Artificial Intelligence, Hefei 230088, Peoples R China.
   [Song, Dan; Ling, Yuting; Li, Tianbao; Zhang, Ting] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
   [Li, Xuanya] Baidu Inc, Beijing 100105, Peoples R China.
C3 Tianjin University; Baidu
RP Li, TB (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.; Li, XY (corresponding author), Baidu Inc, Beijing 100105, Peoples R China.
EM litianbao@tju.edu.cn; lixuanya@baidu.com
FU National Nature Science Foundation of China [61902277]; State Key
   Laboratory of Communication Content Cognition [A02106]; Open Funding
   Project of the State Key Laboratory of Communication Content Cognition
   [20K04]; Baidu Program
FX This work was supported in part by the National Nature Science
   Foundation of China (61902277) , State Key Laboratory of Communication
   Content Cognition (Grant No. A02106) , the Open Funding Project of the
   State Key Laboratory of Communication Content Cognition (Grant No.
   20K04) and the Baidu Program.
CR [Anonymous], 2018, P EUR C COMP VIS ECC
   Bai S, 2017, IEEE T MULTIMEDIA, V19, P1257, DOI 10.1109/TMM.2017.2652071
   Berthelot D, 2019, ADV NEUR IN, V32
   Caron M., 2020, Advances in neural information processing systems, V33, P9912
   Chang XJ, 2016, IEEE T NEUR NET LEAR, V27, P1502, DOI 10.1109/TNNLS.2015.2441735
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Dai GX, 2017, AAAI CONF ARTIF INTE, P4002
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ganin Y, 2015, PR MACH LEARN RES, V37, P1180
   Garcia-Garcia A, 2016, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2016.7727386
   Grabner A, 2019, INT CONF 3D VISION, P583, DOI 10.1109/3DV.2019.00070
   Grabner A, 2018, PROC CVPR IEEE, P3022, DOI 10.1109/CVPR.2018.00319
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He XW, 2018, PROC CVPR IEEE, P1945, DOI 10.1109/CVPR.2018.00208
   Jiang B, 2019, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR.2019.01157
   Kim SH, 2020, IMAGE VISION COMPUT, V96, DOI 10.1016/j.imavis.2020.103900
   Lepetit Vincent, 2005, Foundations and Trends in Computer Graphics and Vision, V1, P1, DOI 10.1561/0600000001
   Li ZQ, 2019, AAAI CONF ARTIF INTE, P8682
   Li ZH, 2018, IEEE T NEUR NET LEAR, V29, P6323, DOI 10.1109/TNNLS.2018.2829867
   Liu ZG, 2023, IEEE T KNOWL DATA EN, V35, P1296, DOI 10.1109/TKDE.2021.3095196
   Long MS, 2017, PR MACH LEARN RES, V70
   Long MS, 2018, ADV NEUR IN, V31
   Ma Y., 2019, FRONT DATA COMPUT, V1, P105, DOI [DOI 10.11871/JFDC, DOI 10.11871/JFDC.ISSN.2096.742X.2019.01.011]
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mu PP, 2018, FRONT INFORM TECH EL, V19, P1397, DOI 10.1631/FITEE.1601764
   Nguyen-Meidine L, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104096
   Nie Wei-Zhi, 2020, IEEE T CYBERN, V52, P1862
   Nie WZ, 2021, IEEE T IMAGE PROCESS, V30, P4371, DOI 10.1109/TIP.2021.3071687
   PaddlePaddle, PADDL EASY TO US EAS
   Pan SJ, 2011, IEEE T NEURAL NETWOR, V22, P199, DOI 10.1109/TNN.2010.2091281
   Qi CR, 2017, ADV NEUR IN, V30
   Ren PZ, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3447582
   Sedaghat Nima., 2016, CoRR
   Shuhao Cui, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12452, DOI 10.1109/CVPR42600.2020.01247
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Snell J, 2017, ADV NEUR IN, V30
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Sun BC, 2016, AAAI CONF ARTIF INTE, P2058
   Sun BC, 2016, LECT NOTES COMPUT SC, V9915, P443, DOI 10.1007/978-3-319-49409-8_35
   Tzeng E., 2014, ARXIV14123474
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang F, 2015, PROC CVPR IEEE, P1875, DOI 10.1109/CVPR.2015.7298797
   Wang JD, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P402, DOI 10.1145/3240508.3240512
   Wang XP, 2021, IEEE T CIRC SYST VID, V31, P4020, DOI 10.1109/TCSVT.2020.3043444
   Wang XP, 2021, IEEE T IMAGE PROCESS, V30, P3017, DOI 10.1109/TIP.2021.3056223
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie J, 2017, PROC CVPR IEEE, P3615, DOI 10.1109/CVPR.2017.385
   Yue ZS, 2017, IMAGE VISION COMPUT, V60, P38, DOI 10.1016/j.imavis.2016.11.013
   Zhang J, 2017, PROC CVPR IEEE, P5150, DOI 10.1109/CVPR.2017.547
   Zhou H., 2020, P 28 ACM INT C MULT, P925
   Zhou HY, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P839
   Zhou HY, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1667, DOI 10.1145/3343031.3351011
   Zhou Q, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104137
   Zhu F, 2016, AAAI CONF ARTIF INTE, P3683
NR 56
TC 4
Z9 4
U1 8
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104482
DI 10.1016/j.imavis.2022.104482
EA MAY 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1W0YE
UT WOS:000806506500002
DA 2024-07-18
ER

PT J
AU Wu, YQ
   Xiao, WP
   Liu, C
   Gao, JT
   Sun, JC
   Tan, GZ
   Li, XM
AF Wu, Yiqiang
   Xiao, Weiping
   Liu, Chang
   Gao, Jiantao
   Sun, Jiacheng
   Tan, Guozhu
   Li, Xiaomao
TI RE-Det3D: RoI-enhanced 3D object detector
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D object detection; Point -based method; Proposal-shape understanding;
   Tilted sampling; Self-attention; Plug -and -play module
AB This paper proposes a two-stage point-based detector referred to as RoI-enhanced 3D object detector (RE-Det3D), which enhances the RoI-feature extraction ability for two-stage point-based 3D object detectors. The proposed detector is characterized by an RoI shape-aware module (RSAM), RoI keypoints sampling module (RKSM), and RoI self-attention module (RAM). More precisely, the RSAM uses the proposal which possesses ac-curate boundary information as auxiliary supervision, to reinforce the framework to be more aware of the object shape. Simultaneously, RKSM uses the tilted sampling strategy to obtain more representative keypoints from the RoI. Afterwards, the plug-and-play module RAM cascades the set-abstraction and self-attention, exploring the in-teractions of keypoints and aggregating local features, to produce discriminative feature representations for 3D box refinement. Comprehensive experiments are conducted on the widely used KITTI dataset and the latest large-scale dataset (ONCE). The results demonstrate that the RE-Det3D can bolster the baseline by a significant margin and achieve comparable accuracy as several strong voxel-based detectors. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Wu, Yiqiang; Xiao, Weiping; Liu, Chang; Gao, Jiantao; Sun, Jiacheng; Tan, Guozhu; Li, Xiaomao] Shanghai Univ, Shanghai, Peoples R China.
   [Wu, Yiqiang; Xiao, Weiping; Liu, Chang; Gao, Jiantao; Sun, Jiacheng; Tan, Guozhu; Li, Xiaomao] Minist Educ, Engn Res Ctr Unmanned Intelligent Marine Equipment, Shanghai, Peoples R China.
C3 Shanghai University
RP Li, XM (corresponding author), Shanghai Univ, Shanghai, Peoples R China.
EM lixiaomaosia@163.com
RI Liu, Han/HMD-9231-2023; wang, yue/ISA-4119-2023; Zhang,
   Can/JUU-9511-2023; li, yang/IQV-3559-2023; wu, yi/JEP-1581-2023; zhang,
   yuyang/IVV-5089-2023; ZHAO, S/IWV-4219-2023; liu, junyang/IXD-1201-2023;
   XU, nan/KDP-0628-2024; LI, XIAO/IQV-9318-2023; liu,
   junyang/IXD-1252-2023; wu, jun/ISB-8607-2023; fang, yu/KCK-2014-2024;
   zhang, yu/HNS-5948-2023; Zhang, Wenxiao/KCK-3295-2024; Li,
   Li/IAQ-0885-2023; Zhang, Yanchao/JMB-7717-2023; LI,
   Xiang-Yang/JZE-0275-2024; Lu, Xiaomei/IUQ-2139-2023; cheng,
   shu/IZE-4788-2023; liang, YU/IYT-4334-2023
OI Liu, Han/0000-0002-5269-8477; wu, yiqiang/0009-0000-3572-9326; Liu,
   Chang/0000-0001-5012-7921; liang, YU/0009-0007-3922-3454
FU National Key Research and Development Program of China [2020YFC1521700];
   Joint Fund of National Natural Science Foundation of China [U1813217];
   National Natural Science Foundation of China [62073075]
FX This work was supported by the National Key Research and Develop-ment
   Program of China [grant number 2020YFC1521700] , the Joint Fund of
   National Natural Science Foundation of China [grant number U1813217] ,
   and National Natural Science Foundation of China [grant number 62073075]
   .
CR [Anonymous], 2019, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2019.00987
   Bhattacharyya P., ARXIV, DOI [10.1109/ICCVW54120.2021.00337, DOI 10.1109/ICCVW54120.2021.00337]
   Chen JY, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2020.103873
   Chen X., 2017, PROC CVPR IEEE, V1, P3, DOI DOI 10.1109/CVPR.2017.691
   Dai A, 2017, PROC CVPR IEEE, P6545, DOI 10.1109/CVPR.2017.693
   Deng J., ARXIV
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Graham B, 2018, PROC CVPR IEEE, P9224, DOI 10.1109/CVPR.2018.00961
   Heinrich M., ARXIV
   Hong DS, 2020, IMAGE VISION COMPUT, V100, DOI 10.1016/j.imavis.2020.103955
   Kingma D., ARXIV PREPRINT
   Ku J, 2018, IEEE INT C INT ROBOT, P5750, DOI 10.1109/IROS.2018.8594049
   Kuang HW, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030704
   Lang AH, 2019, PROC CVPR IEEE, P12689, DOI 10.1109/CVPR.2019.01298
   Li B, 2017, IEEE INT C INT ROBOT, P1513, DOI 10.1109/IROS.2017.8205955
   Li J., ARXIV
   Li ZC, 2021, PROC CVPR IEEE, P7542, DOI 10.1109/CVPR46437.2021.00746
   Liang M, 2019, PROC CVPR IEEE, P7337, DOI 10.1109/CVPR.2019.00752
   Liang M, 2018, LECT NOTES COMPUT SC, V11220, P663, DOI 10.1007/978-3-030-01270-0_39
   Liu Z, 2020, AAAI CONF ARTIF INTE, V34, P11677
   Loshchilov I., ARXIV
   Mao Jiageng, NEURIPS
   Qi C.R., ARXIV
   Qi CR, 2018, PROC CVPR IEEE, P918, DOI 10.1109/CVPR.2018.00102
   Shaoshuai Shi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10526, DOI 10.1109/CVPR42600.2020.01054
   Shi S., ARXIV
   Shi SS, 2019, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2019.00086
   Shi SS, 2021, IEEE T PATTERN ANAL, V43, P2647, DOI 10.1109/TPAMI.2020.2977026
   Simon M, 2019, LECT NOTES COMPUT SC, V11129, P197, DOI 10.1007/978-3-030-11009-3_11
   Sun P, 2020, PROC CVPR IEEE, P2443, DOI 10.1109/CVPR42600.2020.00252
   Tsung-Yi Lin, 2017, 2017 IEEE International Conference on Computer Vision (ICCV), P2999, DOI 10.1109/ICCV.2017.324
   Yan Y, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18103337
   Yang ZT, 2019, IEEE I CONF COMP VIS, P1951, DOI 10.1109/ICCV.2019.00204
   Zheng W., ARXIV
   Zhou Y, 2018, PROC CVPR IEEE, P4490, DOI 10.1109/CVPR.2018.00472
NR 35
TC 3
Z9 3
U1 1
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104430
DI 10.1016/j.imavis.2022.104430
EA MAR 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0Z8MP
UT WOS:000791325900003
DA 2024-07-18
ER

PT J
AU Du, ZH
   Zuo, Y
   Qiu, JF
   Li, X
   Li, Y
   Guo, HX
   Hong, XB
   Wu, J
AF Du, Zhihua
   Zuo, Yong
   Qiu, Jifang
   Li, Xiang
   Li, Yan
   Guo, Hongxiang
   Hong, Xiaobin
   Wu, Jian
TI MDCS with fully encoding the information of local shape description for
   3D Rigid Data matching
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Local feature description; 3D rigid data matching; Multi-view; Local
   reference frame (LRF)
ID OBJECT RECOGNITION; PAIRWISE REGISTRATION; UNIQUE SIGNATURES; POSE
   ESTIMATION; SURFACE; HISTOGRAMS; GEOMETRY; SETS
AB Local feature description is the fundamental research topic for 3D rigid data matching. However, how to achieve a good balanced performance of the local shape descriptor among descriptiveness, robustness, compactness and efficiency remains a challenging task. For this purpose, we propose a novel feature representation of 3D local surface called multi-view depth and contour signatures (MDCS). Key to MDCS descriptor is multi-view and multi attribute description to provide a comprehensive and effective geometric information. Specifically, we first construct a repeatable Local Reference Frame (LRF) for the local surface to achieve rotation invariance. Then we integrate the depth information characterized in a local coordinate manner and the 2D contour cue derived from 3D-to-2D projection, forming the depth and contour signatures (DCS). Finally, MDCS is generated by concatenating all the DCS descriptors captured from three orthogonal view planes in the LRF into a vector. The performance of the MDCS method is evaluated on several data modalities (i.e., LiDAR, Kinect, and Space Time) with respect to Gaussian noise, varying mesh resolutions, clutter and occlusion. Experimental results and rigorous comparisons with the state-of-the-arts validate that our approach achieves the superior performance in terms of descriptiveness, robustness, compactness and efficiency. Moreover, we further demonstrate the feasibility of MDCS in matching of both LiDAR and Kinect point clouds for 3D vision applications and evaluate the generalization ability of the proposed method on real-world datasets.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Du, Zhihua; Zuo, Yong; Qiu, Jifang; Li, Xiang; Li, Yan; Guo, Hongxiang; Hong, Xiaobin; Wu, Jian] Beijing Univ Post & Telecommun, Sch Elect Engn, Beijing 100876, Peoples R China.
C3 Beijing University of Posts & Telecommunications
RP Zuo, Y (corresponding author), Beijing Univ Post & Telecommun, Sch Elect Engn, Beijing 100876, Peoples R China.
EM yong_zuo@bupt.edu.cn
CR Ao S, 2020, IET COMPUT VIS, V14, P154, DOI 10.1049/iet-cvi.2019.0601
   Ao Sheng, 2020, ARXIV201112149
   As'ari MA, 2014, IMAGE VISION COMPUT, V32, P260, DOI 10.1016/j.imavis.2014.02.002
   Curless B., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P303, DOI 10.1145/237170.237269
   Endres F, 2014, IEEE T ROBOT, V30, P177, DOI 10.1109/TRO.2013.2279412
   Frome A, 2004, LECT NOTES COMPUT SC, V3023, P224
   Gojcic Z, 2019, PROC CVPR IEEE, P5540, DOI 10.1109/CVPR.2019.00569
   Guo YL, 2016, INT J COMPUT VISION, V116, P66, DOI 10.1007/s11263-015-0824-y
   Guo YL, 2015, IEEE T INSTRUM MEAS, V64, P683, DOI 10.1109/TIM.2014.2358131
   Guo YL, 2014, IEEE T PATTERN ANAL, V36, P2270, DOI 10.1109/TPAMI.2014.2316828
   Guo YL, 2013, INT J COMPUT VISION, V105, P63, DOI 10.1007/s11263-013-0627-y
   Guo Yulan., 2013, Proceedings of the International Conference on Computer Graphics Theory and Applications and International Conference on Information Visualization Theory and Applications, V1, P86, DOI [10.5220/0004277600860093, DOI 10.5220/0004277600860093]
   Horache S., 2021, ARXIV210314533
   Johnson AE, 1999, IEEE T PATTERN ANAL, V21, P433, DOI 10.1109/34.765655
   Li Dp, 2019, PATTERN RECOGN LETT, V128, P148, DOI 10.1016/j.patrec.2019.08.016
   Lu M, 2014, SENSORS-BASEL, V14, P24156, DOI 10.3390/s141224156
   Mian A, 2010, INT J COMPUT VISION, V89, P348, DOI 10.1007/s11263-009-0296-z
   Mian AS, 2006, IEEE T PATTERN ANAL, V28, P1584, DOI 10.1109/TPAMI.2006.213
   Novatnack J, 2008, LECT NOTES COMPUT SC, V5304, P440, DOI 10.1007/978-3-540-88690-7_33
   Papazov C, 2012, INT J ROBOT RES, V31, P538, DOI 10.1177/0278364911436019
   Petrelli A, 2016, COMPUT GRAPH FORUM, V35, P59, DOI 10.1111/cgf.12732
   Poiesi F., 2021, CORR
   Pomerleau F, 2012, INT J ROBOT RES, V31, P1705, DOI 10.1177/0278364912458814
   Quan SW, 2018, SIGNAL PROCESS-IMAGE, V65, P67, DOI 10.1016/j.image.2018.03.015
   Rusu RB, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P3384, DOI 10.1109/IROS.2008.4650967
   Rusu RB, 2009, IEEE INT CONF ROBOT, P1848
   Salti S, 2014, COMPUT VIS IMAGE UND, V125, P251, DOI 10.1016/j.cviu.2014.04.011
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Tao WY, 2021, IEEE T GEOSCI REMOTE, V59, P801, DOI 10.1109/TGRS.2020.2998683
   Tombari F., 2010, P ACM WORKSH 3D OBJ, P57, DOI DOI 10.1145/1877808.1877821
   Tombari F, 2013, INT J COMPUT VISION, V102, P198, DOI 10.1007/s11263-012-0545-4
   Tombari F, 2010, LECT NOTES COMPUT SC, V6313, P356, DOI 10.1007/978-3-642-15558-1_26
   Xiong FG, 2020, IEEE ACCESS, V8, P100120, DOI 10.1109/ACCESS.2020.2995369
   Yang JQ, 2020, IEEE T IMAGE PROCESS, V29, P2522, DOI 10.1109/TIP.2019.2959236
   Yang JQ, 2017, COMPUT VIS IMAGE UND, V160, P133, DOI 10.1016/j.cviu.2017.02.004
   Yang JQ, 2017, PATTERN RECOGN, V66, P375, DOI 10.1016/j.patcog.2017.01.017
   Yang JQ, 2017, PATTERN RECOGN, V65, P175, DOI 10.1016/j.patcog.2016.11.019
   Yang JQ, 2016, INFORM SCIENCES, V346, P163, DOI 10.1016/j.ins.2016.01.095
   Zeng A, 2017, PROC CVPR IEEE, P199, DOI 10.1109/CVPR.2017.29
   Zhao B, 2019, INFORM SCIENCES, V483, P363, DOI 10.1016/j.ins.2019.01.045
   Zhao H, 2020, PATTERN RECOGN, V103, DOI 10.1016/j.patcog.2020.107272
NR 41
TC 10
Z9 10
U1 8
U2 46
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104421
DI 10.1016/j.imavis.2022.104421
EA MAR 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0N8RO
UT WOS:000783099100001
DA 2024-07-18
ER

PT J
AU Xu, KL
   Li, ZM
   Zhang, ZJ
   Dong, LZ
   Xu, WH
   Yan, LX
   Zhong, S
   Zou, X
AF Xu, Kunlun
   Li, Zhimin
   Zhang, Zhijun
   Dong, Leizhen
   Xu, Wenhui
   Yan, Luxin
   Zhong, Sheng
   Zou, Xu
TI Effective actor-centric human-object interaction detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human-object interaction detection; Global context utilizing; Pixel-wise
   prediction; Deep learning
AB While Human-Object Interaction (HOI) Detection has achieved tremendous advances in recent, it still remains challenging due to complex interactions with multiple humans and objects occurring in images, which would inevitably lead to ambiguities. Most existing methods either generate all human-object pair candidates and infer their relationships by cropped local features successively in a two-stage manner, or directly predict interaction points in a one-stage procedure. However, the lack of spatial configurations or reasoning steps of two- or onestage methods respectively limits their performance in such complex scenes. To avoid this ambiguity, we propose a novel actor-centric framework. The main ideas are that when inferring interactions: 1) the non-local features of the entire image guided by actor position are obtained to model the relationship between the actor and context, and then 2) we use an object branch to generate pixel-wise interaction area prediction, where the interaction area denotes the object central area. Moreover, we also use an actor branch to get interaction prediction of the actor and propose a novel composition strategy based on center-point indexing to generate the final HOI prediction. Thanks to the usage of the non-local features and the partly-coupled property of the human-objects composition strategy, our proposed framework can detect HOI more accurately especially for complex images. Extensive experimental results show that our method achieves the state-of-the-art on the challenging V-COCO and HICO-DET benchmarks and is more robust especially in multiple persons and/or objects scenes.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Xu, Kunlun; Li, Zhimin; Zhang, Zhijun; Dong, Leizhen; Xu, Wenhui; Yan, Luxin; Zhong, Sheng; Zou, Xu] Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.
C3 Huazhong University of Science & Technology
RP Zou, X (corresponding author), Huazhong Univ Sci & Technol, Sch Artificial Intelligence & Automat, Wuhan 430074, Peoples R China.
EM zoux@hust.edu.cn
RI Zhang, Zhijun/HTN-1545-2023
OI Zhang, Zhijun/0000-0001-6916-2356
FU National Natural Science Foundation of China (NSFC) [62176100]; Central
   Guidance on Local Science and Technology Development Fund of Hubei
   Province [2021BEE056]
FX Acknowledgements This work is supported by the National Natural Science
   Foundation of China (NSFC) grant 62176100, the Central Guidance on Local
   Science and Technology Development Fund of Hubei Province grant
   2021BEE056.
CR Aksoy EE, 2011, INT J ROBOT RES, V30, P1229, DOI 10.1177/0278364911410459
   Argall BD, 2009, ROBOT AUTON SYST, V57, P469, DOI 10.1016/j.robot.2008.10.024
   Bansal A, 2020, AAAI CONF ARTIF INTE, V34, P10460
   Bingjie Xu, 2019, 2019 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P2019, DOI 10.1109/CVPR.2019.00212
   Chao YW, 2018, IEEE WINT CONF APPL, P381, DOI 10.1109/WACV.2018.00048
   Chen C.-Y, 2014, PROC ASIAN C COMPUT, P351
   Chen Gao, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P696, DOI 10.1007/978-3-030-58610-2_41
   Chen K., 2022, ARXIV PREPRINT ARXIV
   Feng W, 2019, AAAI CONF ARTIF INTE, P898
   Gao C., 2022, ARXIV PREPRINT ARXIV
   Gao C, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P165, DOI 10.1145/3394171.3413854
   Gkioxari G, 2018, PROC CVPR IEEE, P8359, DOI 10.1109/CVPR.2018.00872
   Gupta S., 2022, ARXIV PREPRINT ARXIV
   Gupta T, 2019, IEEE I CONF COMP VIS, P9676, DOI 10.1109/ICCV.2019.00977
   Kim B., 2020, ECCV, P498, DOI DOI 10.1007/978-3-030
   Kim B, 2021, PROC CVPR IEEE, P74, DOI 10.1109/CVPR46437.2021.00014
   Kim D.-J., 2022, ARXIV PREPRINT ARXIV
   Kingma D. P., 2014, arXiv
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Li Y.-L., 2022, NEUIPS, P33
   Li Y.-L, P IEEE CVF C COMP VI, P382
   Li YL, 2019, PROC CVPR IEEE, P3580, DOI 10.1109/CVPR.2019.00370
   Li Z., 2022, AAAI, P1509
   Liao Y, 2020, PROC CVPR IEEE, P479, DOI 10.1109/CVPR42600.2020.00056
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu Y, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P4235, DOI 10.1145/3394171.3413600
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Peyre J, 2019, IEEE I CONF COMP VIS, P1981, DOI 10.1109/ICCV.2019.00207
   Qi SY, 2018, LECT NOTES COMPUT SC, V11213, P407, DOI 10.1007/978-3-030-01240-3_25
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Ulutan Oytun, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13614, DOI 10.1109/CVPR42600.2020.01363
   Wan B, 2019, IEEE I CONF COMP VIS, P9468, DOI 10.1109/ICCV.2019.00956
   Wang H., 2022, ARXIV PREPRINT ARXIV
   Wang JQ, 2021, PROC CVPR IEEE, P9690, DOI 10.1109/CVPR46437.2021.00957
   Wang TC, 2020, PROC CVPR IEEE, P4115, DOI 10.1109/CVPR42600.2020.00417
   Wang TC, 2019, IEEE I CONF COMP VIS, P1971, DOI 10.1109/ICCV.2019.00206
   Wörgötter F, 2013, IEEE T AUTON MENT DE, V5, P117, DOI 10.1109/TAMD.2012.2232291
   Yang Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P248, DOI 10.1007/978-3-030-58568-6_15
   Yang YZ, 2013, PROC CVPR IEEE, P2563, DOI 10.1109/CVPR.2013.331
   Yao BP, 2010, PROC CVPR IEEE, P17, DOI 10.1109/CVPR.2010.5540235
   Yu F, 2018, PROC CVPR IEEE, P2403, DOI 10.1109/CVPR.2018.00255
   Zhang A, 2021, 35 C NEUR INF PROC S
   Zhi Hou, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12360), P584, DOI 10.1007/978-3-030-58555-6_35
   Zhong X., 2021, P IEEE CVF C COMPUTE, P13234
   Zhou PH, 2019, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2019.00093
   Zhou TF, 2020, PROC CVPR IEEE, P4262, DOI 10.1109/CVPR42600.2020.00432
   Zou C, 2021, PROC CVPR IEEE, P11820, DOI 10.1109/CVPR46437.2021.01165
NR 50
TC 1
Z9 2
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2022
VL 121
AR 104422
DI 10.1016/j.imavis.2022.104422
EA MAR 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 0N8RO
UT WOS:000783099100006
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Saleem, N
   Gao, JC
   Irfan, M
   Verdu, E
   Fuente, JP
AF Saleem, Nasir
   Gao, Jiechao
   Irfan, Muhammad
   Verdu, Elena
   Fuente, Javier Parra
TI E2E-V2SResNet: Deep residual convolutional neural networks for
   end-to-end video driven speech synthesis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video processing; E2E speech synthesis; ResNet-18; Residual CNN;
   Waveform CRITIC
ID COEFFICIENTS; RECOGNITION
AB Speechreading which infers spoken message from a visually detected articulated facial trend is a challenging task. In this paper, we propose an end-to-end ResNet (E2E-ResNet) model for synthesizing speech signals from the silent video of a speaking individual. The model is the convolutional encoder-decoder framework which captures the frames of video and encodes into a latent space of visual features. The outputs of the decoder are spectrograms which are converted into waveforms corresponding to a speech articulated in the input video. The speech waveforms are then fed to a waveform critic used to decide the real or synthesized speech. The experiments show that the proposed E2E-V2SResNet model is apt to synthesize speech with realism and intelligibility/quality for GRID database. To further demonstrate the potentials of the proposed model, we also conduct experiments on the TCD-TIMIT database. We examine the synthesized speech in unseen speakers using three objective metrics use to measure the intelligibility, quality, and word error rate (WER) of the synthesized speech. We show that E2E-V2SResNet model outscores the competing approaches in most metrics on the GRID and TCD-TIMIT databases. By comparing with the baseline, the proposed model achieved 3.077% improvement in speech quality and 2.593% improvement in speech intelligibility. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Saleem, Nasir] Gomal Univ, Dept Elect Engn, FET, Dera Ismail Khan, Pakistan.
   [Gao, Jiechao] Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
   [Irfan, Muhammad] UET, Dept Elect Engn, Peshawar, Pakistan.
   [Verdu, Elena; Fuente, Javier Parra] Univ Int La Rioja, Logrono, Spain.
C3 Gomal University; University of Virginia; Universidad Internacional de
   La Rioja (UNIR)
RP Saleem, N (corresponding author), Gomal Univ, Dept Elect Engn, FET, Dera Ismail Khan, Pakistan.
EM nasirsaleem@gu.edu.pk; jg5ycn@virginia.edu;
   m.i.khattak@uetpeshawar.edu.pk; elena.verdu@unir.net
RI Gao, Jiechao/AAV-1830-2021; Irfan, Muhammad/KLZ-6004-2024; Saleem,
   Nasir/AAG-9197-2019; Saleem, Nasir/Y-4557-2018; Verdu, Elena/A-5021-2019
OI Gao, Jiechao/0000-0003-0628-1416; Saleem, Nasir/0000-0003-0010-0629;
   Verdu, Elena/0000-0002-3040-7077; Parra-Fuente,
   Javier/0000-0003-0098-7741
CR Akbari H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2516, DOI 10.1109/ICASSP.2018.8461856
   [Anonymous], 2018, ARXIV180205521
   Assael Y.M., 2016, ARXIV161101599, V2
   Assael Yannis M, 2016, ARXIV161101599
   Bengio Y., 2019, ARXIV191006711
   Chazan D, 2000, INT CONF ACOUST SPEE, P1299, DOI 10.1109/ICASSP.2000.861816
   Choi H, 2019, INT CONF ACOUST SPEE, P6950, DOI 10.1109/ICASSP.2019.8683682
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Cooke M, 2006, J ACOUST SOC AM, V120, P2421, DOI 10.1121/1.2229005
   Donahue C., 2018, Adversarial audio synthesis
   Donahue Jeff, 2020, ARXIV200603575
   Engel J, 2017, PR MACH LEARN RES, V70
   Ephrat A, 2017, IEEE INT CONF COMP V, P455, DOI 10.1109/ICCVW.2017.61
   Ephrat A, 2017, INT CONF ACOUST SPEE, P5095, DOI 10.1109/ICASSP.2017.7953127
   Feichtenhofer C, 2016, PROC CVPR IEEE, P1933, DOI 10.1109/CVPR.2016.213
   Gurban M, 2009, IEEE T SIGNAL PROCES, V57, P4765, DOI 10.1109/TSP.2009.2026513
   Harte N, 2015, IEEE T MULTIMEDIA, V17, P603, DOI 10.1109/TMM.2015.2407694
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsieh TA, 2020, IEEE SIGNAL PROC LET, V27, P2149, DOI 10.1109/LSP.2020.3040693
   ITAKURA F, 1975, J ACOUST SOC AM, V57, pS35, DOI 10.1121/1.1995189
   Jampani V, 2017, PROC CVPR IEEE, P3154, DOI 10.1109/CVPR.2017.336
   KUBICHEK RF, 1993, IEEE PACIF, P125, DOI 10.1109/PACRIM.1993.407206
   Kumar K, 2007, INT CONF ACOUST SPEE, P429
   Le Cornu T, 2017, IEEE-ACM T AUDIO SPE, V25, P1447, DOI 10.1109/TASLP.2017.2716178
   Le Cornu T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3355
   Li J, 2019, INTERSPEECH, P71, DOI 10.21437/Interspeech.2019-1819
   Liu C., 2009, Beyond pixels: Exploring new representations and applications for motion analysis
   Loizou PC, 2011, STUD COMPUT INTELL, V346, P623
   Lu YY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081599
   Ma P., 2019, ARXIV190602112
   Maas AL, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P22
   Michelsanti D, 2020, INTERSPEECH, P3530, DOI 10.21437/Interspeech.2020-1026
   Milner B., 2015, INTERSPEECH 2015
   Mira R., 2021, ARXIV210413332
   Morise M, 2016, IEICE T INF SYST, VE99D, P1877, DOI 10.1587/transinf.2015EDP7457
   Oord A., 2016, ARXIV160903499
   Pathak D, 2017, PROC CVPR IEEE, P6024, DOI 10.1109/CVPR.2017.638
   Perraudin N, 2013, IEEE WORK APPL SIG
   Petridis S., 2017, ARXIV170900443
   Petridis S, 2020, PATTERN RECOGN LETT, V131, P421, DOI 10.1016/j.patrec.2020.01.022
   Petridis S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P6548, DOI 10.1109/ICASSP.2018.8461326
   Petridis S, 2017, INT CONF ACOUST SPEE, P2592, DOI 10.1109/ICASSP.2017.7952625
   Prajwal K.R., P IEEE CVF C COMP VI, P13796
   Rix AW, 2001, INT CONF ACOUST SPEE, P749, DOI 10.1109/ICASSP.2001.941023
   Sarhan AM, 2021, CMC-COMPUT MATER CON, V68, P1531, DOI 10.32604/cmc.2021.016509
   Shen J, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P4779, DOI 10.1109/ICASSP.2018.8461368
   Shillingford B., 2018, ARXIV180705162
   Simonyan K, 2014, ADV NEUR IN, V27
   Srivastava RK, 2015, ARXIV150500387
   Stafylakis T, 2017, INTERSPEECH, P3652, DOI 10.21437/Interspeech.2017-85
   Stewart D, 2014, IEEE T CYBERNETICS, V44, P175, DOI 10.1109/TCYB.2013.2250954
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Taal CH, 2010, INT CONF ACOUST SPEE, P4214, DOI 10.1109/ICASSP.2010.5495701
   Tao F, 2021, IEEE T MULTIMEDIA, V23, P1, DOI 10.1109/TMM.2020.2975922
   van den Oord A, 2018, PR MACH LEARN RES, V80, DOI arXiv:1711.10433
   Vougioukas K, 2019, INTERSPEECH, P4125, DOI 10.21437/Interspeech.2019-1445
   Vougioukas Konstantinos, 2018, PROC BRIT MACH VIS C
   Wang YX, 2017, INTERSPEECH, P4006, DOI 10.21437/Interspeech.2017-1452
   Yamamoto R, 2020, INT CONF ACOUST SPEE, P6199, DOI [10.1109/ICASSP40776.2020.9053795, 10.1109/icassp40776.2020.9053795]
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhou H, 2019, IEEE I CONF COMP VIS, P283, DOI 10.1109/ICCV.2019.00037
   Zhu XL, 2007, IEEE T AUDIO SPEECH, V15, P1645, DOI 10.1109/TASL.2007.899236
NR 64
TC 8
Z9 8
U1 1
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104389
DI 10.1016/j.imavis.2022.104389
EA FEB 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400002
DA 2024-07-18
ER

PT J
AU Zhou, Y
   Song, YX
   Chen, L
   Chen, Y
   Ben, XY
   Cao, YW
AF Zhou, Ying
   Song, Yanxin
   Chen, Lei
   Chen, Yang
   Ben, Xianye
   Cao, Yewen
TI A novel micro-expression detection algorithm based on BERT and 3DCNN
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Micro-expression detection; 3DCNN; BERT
ID OPTICAL-FLOW; RECOGNITION
AB As a special type of facial expressions, the spontaneous micro-expressions can reveal the genuine emotions that people attempt to hide, therefore can provide potential information in criminal detection, lie detection, etc. Compared to ordinary facial expressions, micro-expressions are involuntary, transient and of low intensity. Consequently, micro-expression detection is difficult and overly dependent on expert experiences. Thus, we propose a novel micro-expression detection method based on the Bidirectional Encoder Representation from Transformers (BERT) network, namely R3D_BERT + Group, which includes the candidate segment generation module, spatio-temporal feature extraction module and grouping module. Specifically, the candidate segments are generated by the candidate segment generation module, then each candidate segment is divided into smaller time slots by the spatio-temporal feature extraction module, where spatio-temporal features are extracted through 3DCNN and BERT network. Finally, consecutive segments are merged and overlapping segments are suppressed by the grouping module to locate the position of the onset and offset frames of the micro-expression more accurately. Comprehensive experiments on CASME 2 and SDU_spotting databases firmly demonstrate the effectiveness of our method over other state-of-the-art detection methods.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhou, Ying; Song, Yanxin; Chen, Lei; Ben, Xianye; Cao, Yewen] Shandong Univ, Sch Informat Sci & Engn, Qingdao, Peoples R China.
   [Chen, Yang] Univ Michigan, Ann Arbor, MI 48109 USA.
C3 Shandong University; University of Michigan System; University of
   Michigan
RP Ben, XY; Cao, YW (corresponding author), Shandong Univ, Sch Informat Sci & Engn, Qingdao, Peoples R China.
EM benxianye@gmail.com; ycao@sdu.edu.cn
RI cao, yewen/JWA-0421-2024
FU National Key R&D Program of China [2020YFC0833201]; Natural Science
   Foundation of China [61971468, 62001267, 61571275]; Shandong Provincial
   Key Research and Development Program (Major Scientific and Technological
   Innovation Project) [2019JZZY010119]; Natural Science Foundation of
   Shandong Province [ZR2020MF004]
FX This work was supported in part by the National Key R&D Program of China
   under Grant 2020YFC0833201, in part by the Natural Science Foundation of
   China under Grants 61971468, 62001267 and 61571275, in part by the
   Shandong Provincial Key Research and Development Program (Major
   Scientific and Technological Innovation Project) under Grant
   2019JZZY010119, and in part by the Natural Science Foundation of
   Shandong Province under Grant ZR2020MF004.
CR Ben XY, 2022, IEEE T PATTERN ANAL, V44, P5826, DOI 10.1109/TPAMI.2021.3067464
   Ben XY, 2018, PATTERN RECOGN LETT, V107, P50, DOI 10.1016/j.patrec.2017.07.010
   Ben XY, 2016, NEURAL COMPUT APPL, V27, P2629, DOI 10.1007/s00521-015-2031-8
   Bhushan B., 2015, Understanding Facial Expressions in Communication, P265, DOI [DOI 10.1007/978-81-322-1934-7_13, 10.1007/978-81-322-1934-7%2013, DOI 10.1007/978-81-322-1934-713]
   Chaudhry R, 2009, PROC CVPR IEEE, P1932, DOI 10.1109/CVPRW.2009.5206821
   Davison AK, 2015, IEEE SYS MAN CYBERN, P1864, DOI 10.1109/SMC.2015.326
   Devlin J., 2018, BERT PRE TRAINING DE
   EKMAN P, 1969, PSYCHIATR, V32, P88, DOI 10.1080/00332747.1969.11023575
   Ekman P., 2007, MICROEXPRESSION TRAI, V2
   Endres J, 2009, BMC MED EDUC, V9, DOI 10.1186/1472-6920-9-47
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo YF, 2021, IEEE MULTIMEDIA, V28, P29, DOI 10.1109/MMUL.2021.3058017
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D., 2016, ARXIV160608415
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Huang TH, 2019, IEEE ACCESS, V7, P120670, DOI 10.1109/ACCESS.2019.2932784
   Jain DK, 2019, PATTERN RECOGN LETT, V120, P69, DOI 10.1016/j.patrec.2019.01.008
   Jia XT, 2018, J COMPUT SCI-NETH, V25, P289, DOI 10.1016/j.jocs.2017.03.016
   King DB, 2015, ACS SYM SER, V1214, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liong ST, 2017, LECT NOTES COMPUT SC, V10117, P345, DOI 10.1007/978-3-319-54427-4_26
   Liong ST, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P665, DOI 10.1109/ACPR.2015.7486586
   Ma HY, 2017, I S INTELL SIG PROC, P281, DOI 10.1109/ISPACS.2017.8266489
   Moilanen A, 2014, INT C PATT RECOG, P1722, DOI 10.1109/ICPR.2014.303
   Oh YH, 2018, FRONT PSYCHOL, V9, DOI 10.3389/fpsyg.2018.01128
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Shen XB, 2012, J ZHEJIANG UNIV-SC B, V13, P221, DOI 10.1631/jzus.B1100063
   Shen XB, 2016, FRONT PSYCHOL, V7, DOI 10.3389/fpsyg.2016.01346
   Vaswani A, 2017, ADV NEUR IN, V30
   Verburg M, 2019, IEEE INT CONF AUTOMA, P652
   Xiong Y., 2017, CoRR
   Xue L, 2014, ROCK MECH ROCK ENG, V47, P1183, DOI 10.1007/s00603-013-0479-3
   Yan WJ, 2018, J COMPUT SCI-NETH, V25, P318, DOI 10.1016/j.jocs.2017.02.012
   Yan WJ, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0086041
   Yan WJ, 2013, J NONVERBAL BEHAV, V37, P217, DOI 10.1007/s10919-013-0159-8
   Yap CH, 2020, IEEE INT CONF AUTOMA, P771, DOI 10.1109/FG47880.2020.00029
   Zhang ZH, 2018, IEEE ACCESS, V6, P71143, DOI 10.1109/ACCESS.2018.2879485
   Zhu XN, 2018, MULTIMED TOOLS APPL, V77, P3105, DOI 10.1007/s11042-017-4943-z
NR 40
TC 6
Z9 7
U1 3
U2 56
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104378
DI 10.1016/j.imavis.2022.104378
EA FEB 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400004
DA 2024-07-18
ER

PT J
AU Ming, ZQ
   Zhu, M
   Wang, XK
   Zhu, JM
   Cheng, JL
   Gao, CR
   Yang, Y
   Wei, XY
AF Ming, Zhangqiang
   Zhu, Min
   Wang, Xiangkun
   Zhu, Jiamin
   Cheng, Junlong
   Gao, Chengrui
   Yang, Yong
   Wei, Xiaoyong
TI Deep learning-based person re-identification methods: A survey and
   outlook of recent works
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Deep metric learning; Local feature learning;
   Generative adversarial learning; Sequence feature learning
ID NEURAL-NETWORK; ATTENTION; BIOMETRICS
AB In recent years, with the increasing demand for public safety and the rapid development of intelligent surveil-lance networks, person re-identification (Re-ID) has become one of the hot research topics in the computer vi-sion field. The main research goal of person Re-ID is to retrieve persons with the same identity from different cameras. However, traditional person Re-ID methods require manual marking of person targets, which consumes a lot of labor cost. With the widespread application of deep neural networks, many deep learning-based person Re-ID methods have emerged. Therefore, this paper is to facilitate researchers to understand the latest research results and the future trends in the field. Firstly, we summarize the studies of several recently published person Re-ID surveys and complement the latest research methods to systematically classify deep learning-based person Re-ID methods. Secondly, we propose a multi-dimensional taxonomy that classifies current deep learning-based person Re-ID methods into four categories according to metric and representation learning, including methods for deep metric learning, local feature learning, generative adversarial learning and sequence feature learning. Furthermore, we subdivide the above four categories according to their methodologies and motivations, discussing the advantages and limitations of part subcategories. Finally, we discuss some challenges and possible research directions for person Re-ID.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Ming, Zhangqiang; Zhu, Min; Wang, Xiangkun; Zhu, Jiamin; Cheng, Junlong; Gao, Chengrui; Yang, Yong; Wei, Xiaoyong] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP Zhu, M (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
EM zhumin@scu.edu.cn
RI 0, 0/KEE-7704-2024; Cheng, Junlong/ABP-8353-2022; Wei,
   Xiao-Yong/GLU-7097-2022; GAO, CHENGRUI/JQJ-6841-2023
OI Cheng, Junlong/0000-0002-6849-9093; 
FU Na-tional Key Research and Development Project of China [61872256];
   National Natural Science Foundation of China
FX Acknowledgement The authors wish to thank Jizhuo Li, Xiao Pang, Jiamin
   Zhu, Fuqiu Chen, Yi Zhou and Cheng Zhang. This work was supported by the
   Na-tional Key Research and Development Project of China (No. JG2018190)
   , and in part by the National Natural Science Foundation of China (No.
   61872256) .
CR An L, 2017, MULTIMED TOOLS APPL, V76, P12117, DOI 10.1007/s11042-016-4070-2
   [Anonymous], 2017, ICCV
   [Anonymous], 2016, PERSONNET PERSON RE
   [Anonymous], 2018, REVISITING TEMPORAL
   Bai Z., P IEEE CVF C COMP VI, P12914
   Bak S, 2018, LECT NOTES COMPUT SC, V11217, P193, DOI 10.1007/978-3-030-01261-8_12
   Bedagkar-Gala A, 2014, IMAGE VISION COMPUT, V32, P270, DOI 10.1016/j.imavis.2014.02.001
   Bedogni L., 2021, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies, P1
   Behera NKS, 2021, PATTERN RECOGN LETT, V151, P163, DOI 10.1016/j.patrec.2021.08.007
   Behera NKS, 2020, PATTERN RECOGN LETT, V138, P282, DOI 10.1016/j.patrec.2020.07.030
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chahar H, 2017, LECT NOTES COMPUT SC, V10597, P543, DOI 10.1007/978-3-319-69900-4_69
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen DP, 2018, PROC CVPR IEEE, pCP1, DOI 10.1109/CVPR.2018.00128
   Chen GY, 2019, IEEE I CONF COMP VIS, P9636, DOI 10.1109/ICCV.2019.00973
   Chen H, 2021, PROC CVPR IEEE, P2004, DOI 10.1109/CVPR46437.2021.00204
   Chen HT, 2019, IEEE T CONTR SYST T, V27, P2766, DOI 10.1109/TCST.2018.2866976
   Chen JX, 2017, PROC CVPR IEEE, P5330, DOI 10.1109/CVPR.2017.566
   Chen JX, 2021, PROC CVPR IEEE, P8142, DOI 10.1109/CVPR46437.2021.00805
   Chen TL, 2019, IEEE I CONF COMP VIS, P8350, DOI 10.1109/ICCV.2019.00844
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen XS, 2020, PROC CVPR IEEE, P3297, DOI 10.1109/CVPR42600.2020.00336
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Chen YB, 2017, IEEE INT CONF COMP V, P2590, DOI 10.1109/ICCVW.2017.304
   Chen YC, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P3402
   Chen YC, 2019, AAAI CONF ARTIF INTE, P8215
   Choi Y, 2018, PROC CVPR IEEE, P8789, DOI 10.1109/CVPR.2018.00916
   Chung D, 2017, IEEE I CONF COMP VIS, P1992, DOI 10.1109/ICCV.2017.218
   [戴臣超 Dai Chenchao], 2019, [计算机研究与发展, Journal of Computer Research and Development], V56, P1632
   Dehghan A, 2015, PROC CVPR IEEE, P4091, DOI 10.1109/CVPR.2015.7299036
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Dikmen M, 2011, LECT NOTES COMPUT SC, V6495, P501, DOI 10.1007/978-3-642-19282-1_40
   Dollár P, 2014, IEEE T PATTERN ANAL, V36, P1532, DOI 10.1109/TPAMI.2014.2300479
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Duan YQ, 2018, IEEE T CIRC SYST VID, V28, P2644, DOI 10.1109/TCSVT.2017.2711015
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8287
   Fu Y, 2019, AAAI CONF ARTIF INTE, P8295
   Ge Y., 2018, FD GAN POSE GUIDED F
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gray D., 2007, P IEEE INT WORKSH PE, V3, P41
   Guan'an Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12353), P275, DOI 10.1007/978-3-030-58598-3_17
   Guo JY, 2019, IEEE I CONF COMP VIS, P3641, DOI 10.1109/ICCV.2019.00374
   Hermans Alexander, 2017, ARXIV170307737
   Hirzer M, 2011, LECT NOTES COMPUT SC, V6688, P91, DOI 10.1007/978-3-642-21227-7_9
   Hou RB, 2021, PROC CVPR IEEE, P2014, DOI 10.1109/CVPR46437.2021.00205
   Hou RB, 2019, PROC CVPR IEEE, P7176, DOI 10.1109/CVPR.2019.00735
   Hou Y., LOCALITY AWARE APPEA
   Hu HM, 2017, MULTIMED TOOLS APPL, V76, P26633, DOI 10.1007/s11042-016-4188-2
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Huang HJ, 2018, PROC CVPR IEEE, P5098, DOI 10.1109/CVPR.2018.00535
   Huang Y., 2020, P IEEE CVF C COMP VI, P14084
   Huang Y, 2019, IEEE T IMAGE PROCESS, V28, P1391, DOI 10.1109/TIP.2018.2874715
   Islam K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103970
   Kalayeh MM, 2018, PROC CVPR IEEE, P1062, DOI 10.1109/CVPR.2018.00117
   Karanam S, 2019, IEEE T PATTERN ANAL, V41, P523, DOI 10.1109/TPAMI.2018.2807450
   Kipf Thomas N., 2017, 5 INT C LEARN REPRES
   Lavi B., SURVEY RELIABLE DEEP
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li DW, 2017, PROC CVPR IEEE, P7398, DOI 10.1109/CVPR.2017.782
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Li HJ, 2021, PROC CVPR IEEE, P6725, DOI 10.1109/CVPR46437.2021.00666
   Li JN, 2019, IEEE I CONF COMP VIS, P3957, DOI 10.1109/ICCV.2019.00406
   Li JN, 2019, AAAI CONF ARTIF INTE, P8618
   Li S, 2018, PROC CVPR IEEE, P369, DOI 10.1109/CVPR.2018.00046
   Li W, 2018, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2018.00243
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li W, 2013, PROC CVPR IEEE, P3594, DOI 10.1109/CVPR.2013.461
   Li Wei, 2012, AS C COMP VIS ACCV 2, P31
   Li YJ, 2019, IEEE I CONF COMP VIS, P8089, DOI 10.1109/ICCV.2019.00818
   Li YL, 2021, PROC CVPR IEEE, P2897, DOI 10.1109/CVPR46437.2021.00292
   Liang W., 2018, M2M GAN MANY TO MANY
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Liao X., 2019, P AS C COMP VIS, P620
   Lin YT, 2020, PROC CVPR IEEE, P3387, DOI 10.1109/CVPR42600.2020.00345
   Liu C., P IEEE C COMP VIS PA, P6887
   Liu H, 2018, IEEE T CIRC SYST VID, V28, P2788, DOI 10.1109/TCSVT.2017.2715499
   Liu J., 2021, Computer Vision Foundation, P4370
   Liu JM, 2019, IEEE COMPUT SOC CONF, P2070, DOI 10.1109/CVPRW.2019.00259
   Liu JW, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P665, DOI 10.1145/3343031.3350991
   Liu JW, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P737, DOI 10.1145/3240508.3240585
   Liu Jiawei, 2016, P 24 ACM INT C MULT, P192
   Liu JX, 2018, PROC CVPR IEEE, P4099, DOI 10.1109/CVPR.2018.00431
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu XH, 2017, IEEE I CONF COMP VIS, P350, DOI 10.1109/ICCV.2017.46
   Liu ZM, 2019, IEEE I CONF COMP VIS, P6121, DOI 10.1109/ICCV.2019.00622
   Luo CC, 2019, IEEE I CONF COMP VIS, P4975, DOI 10.1109/ICCV.2019.00508
   [罗浩 Luo Hao], 2019, [自动化学报, Acta Automatica Sinica], V45, P2032
   Ma LQ, 2018, PROC CVPR IEEE, P99, DOI 10.1109/CVPR.2018.00018
   Mao SN, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P883
   Martinel N, 2015, LECT NOTES COMPUT SC, V8927, P191, DOI 10.1007/978-3-319-16199-0_14
   Mathur Neha, 2020, 2020 3rd International Conference on Emerging Technologies in Computer Engineering: Machine Learning and Internet of Things (ICETCE). Proceedings, P129, DOI 10.1109/ICETCE48199.2020.9091747
   McLaughlin N, 2016, PROC CVPR IEEE, P1325, DOI 10.1109/CVPR.2016.148
   Miao JX, 2019, IEEE I CONF COMP VIS, P542, DOI 10.1109/ICCV.2019.00063
   Ming Y., GLOBAL LOCAL DYNAMIC
   Mishchuk A., 2017, P ADV NEURAL INFORM, P4826
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Ngo C.W., 2005, TRECVID WORKSHOP PAR
   Ngo C.W., 2008, TRECVID WORKSHOP PAR
   Ning X, 2021, IEEE T CIRC SYST VID, V31, P3391, DOI 10.1109/TCSVT.2020.3043026
   Ning X, 2021, NEUROCOMPUTING, V453, P801, DOI 10.1016/j.neucom.2020.05.106
   Niu K, 2020, IEEE T IMAGE PROCESS, V29, P5542, DOI 10.1109/TIP.2020.2984883
   Peng PX, 2016, PROC CVPR IEEE, P1306, DOI 10.1109/CVPR.2016.146
   [祁磊 Qi Lei], 2020, [软件学报, Journal of Software], V31, P2883
   Qi L, 2020, IEEE T CIRC SYST VID, V30, P2815, DOI 10.1109/TCSVT.2020.2983600
   Qian XL, 2018, LECT NOTES COMPUT SC, V11213, P661, DOI 10.1007/978-3-030-01240-3_40
   Redmon J., 2018, P IEEE C COMP VIS PA
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Ristani E, 2016, LECT NOTES COMPUT SC, V9914, P17, DOI 10.1007/978-3-319-48881-3_2
   Seokeon Choi, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10254, DOI 10.1109/CVPR42600.2020.01027
   Shen Y., 2018, P EUR C COMP VIS, P486
   Shi HL, 2016, LECT NOTES COMPUT SC, V9905, P732, DOI 10.1007/978-3-319-46448-0_44
   Song CF, 2018, PROC CVPR IEEE, P1179, DOI 10.1109/CVPR.2018.00129
   Song GL, 2018, AAAI CONF ARTIF INTE, P7347
   Song HO, 2016, PROC CVPR IEEE, P4004, DOI 10.1109/CVPR.2016.434
   Song JF, 2019, PROC CVPR IEEE, P719, DOI 10.1109/CVPR.2019.00081
   Su C, 2017, IEEE I CONF COMP VIS, P3980, DOI 10.1109/ICCV.2017.427
   Sun S., DECENTRALISED PERSON
   Sun YF, 2019, PROC CVPR IEEE, P393, DOI 10.1109/CVPR.2019.00048
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Tang HT, 2019, IEEE COMPUT SOC CONF, P1536, DOI 10.1109/CVPRW.2019.00195
   Tang SY, 2017, PROC CVPR IEEE, P3701, DOI 10.1109/CVPR.2017.394
   Tay CP, 2019, PROC CVPR IEEE, P7127, DOI 10.1109/CVPR.2019.00730
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   Varior RR, 2016, LECT NOTES COMPUT SC, V9911, P135, DOI 10.1007/978-3-319-46478-7_9
   Varior RR, 2016, LECT NOTES COMPUT SC, V9912, P791, DOI 10.1007/978-3-319-46484-8_48
   Wang FQ, 2016, PROC CVPR IEEE, P1288, DOI 10.1109/CVPR.2016.144
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang KJ, 2018, CAAI T INTELL TECHNO, V3, P219, DOI 10.1049/trit.2018.1001
   Wang TQ, 2014, LECT NOTES COMPUT SC, V8692, P688, DOI 10.1007/978-3-319-10593-2_45
   Wang XG, 2013, PATTERN RECOGN LETT, V34, P3, DOI 10.1016/j.patrec.2012.07.005
   Wang XJ, 2016, IEEE T CIRC SYST VID, V26, P1447, DOI 10.1109/TCSVT.2015.2450331
   Wang Y., 2021, ARTI INTELL CHINA, P153
   Wang YC, 2018, PROC CVPR IEEE, P1470, DOI 10.1109/CVPR.2018.00159
   Wang Z., INTRAMODALITY SURVEY
   Wang ZX, 2019, PROC CVPR IEEE, P618, DOI 10.1109/CVPR.2019.00071
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wei LH, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P420, DOI 10.1145/3123266.3123279
   Wei X.-Y., 2012, Proceedings of the 20th ACM International Conference on Multimedia, MM, P639, DOI [DOI 10.1145/2393347.2393436, 10.1145/2393347.2393436]
   Wu D, 2019, NEUROCOMPUTING, V337, P354, DOI 10.1016/j.neucom.2019.01.079
   Wu G., DECENTRALISED LEARNI
   Wu GL, 2020, AAAI CONF ARTIF INTE, V34, P12362
   Wu Q., P IEEE C COMPUTER VI, P4330
   Wu WY, 2021, PATTERN RECOGN, V110, DOI 10.1016/j.patcog.2020.107424
   Wu YM, 2020, IEEE T IMAGE PROCESS, V29, P8821, DOI 10.1109/TIP.2020.3001693
   Wu Y, 2018, PROC CVPR IEEE, P5177, DOI 10.1109/CVPR.2018.00543
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xin XM, 2019, PATTERN RECOGN, V88, P285, DOI 10.1016/j.patcog.2018.11.025
   Xu SJ, 2017, IEEE I CONF COMP VIS, P4743, DOI 10.1109/ICCV.2017.507
   Yaghoubi E, 2021, PATTERN RECOGN LETT, V143, P50, DOI 10.1016/j.patrec.2020.12.017
   Yan C., 2021, IEEE T MULTIMED
   Yan YC, 2020, PROC CVPR IEEE, P2896, DOI 10.1109/CVPR42600.2020.00297
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Yan YC, 2016, LECT NOTES COMPUT SC, V9910, P701, DOI 10.1007/978-3-319-46466-4_42
   Yang C., INT C COMP DAT SCI, P161
   Yang JR, 2020, PROC CVPR IEEE, P3286, DOI 10.1109/CVPR42600.2020.00335
   Yang QZ, 2019, PROC CVPR IEEE, P3628, DOI 10.1109/CVPR.2019.00375
   [杨婉香 Yang Wanxiang], 2020, [软件学报, Journal of Software], V31, P1943
   Yang WJ, 2019, PROC CVPR IEEE, P1389, DOI 10.1109/CVPR.2019.00148
   Yao HT, 2019, IEEE T IMAGE PROCESS, V28, P2860, DOI 10.1109/TIP.2019.2891888
   Ye M., P EUR C COMP VIS, P229
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2017, IEEE I CONF COMP VIS, P5152, DOI 10.1109/ICCV.2017.550
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yunpeng Zhai, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9018, DOI 10.1109/CVPR42600.2020.00904
   Zha ZJ, 2020, IEEE T MULTIMEDIA, V22, P1836, DOI 10.1109/TMM.2020.2972168
   Zhang XY, 2019, IEEE I CONF COMP VIS, P8221, DOI 10.1109/ICCV.2019.00831
   Zhang ZZ, 2020, INT CONF CONDIT MON, P404, DOI 10.1109/CVPR42600.2020.01042
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhang Z, 2021, PROC CVPR IEEE, P12131, DOI 10.1109/CVPR46437.2021.01196
   Zhao CR, 2021, IEEE T IMAGE PROCESS, V30, P7776, DOI 10.1109/TIP.2021.3109508
   Zhao HY, 2017, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2017.103
   Zhao LM, 2017, IEEE I CONF COMP VIS, P3239, DOI 10.1109/ICCV.2017.349
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng F, 2019, PROC CVPR IEEE, P8506, DOI 10.1109/CVPR.2019.00871
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2016, LECT NOTES COMPUT SC, V9910, P868, DOI 10.1007/978-3-319-46466-4_52
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng Liang., 2016, Person re-identification: Past, present and future
   Zheng M, 2019, PROC CVPR IEEE, P5728, DOI 10.1109/CVPR.2019.00588
   Zheng Z., PARAMETER EFCIENT PE
   Zheng ZD, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3159171
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2018, LECT NOTES COMPUT SC, V11217, P176, DOI 10.1007/978-3-030-01261-8_11
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhong Z, 2018, PROC CVPR IEEE, pCP99, DOI 10.1109/CVPR.2018.00541
   Zhou K., Domain generalization: A survey
   Zhou K, 2021, INT J ADV MANUF TECH, V115, P1005, DOI 10.1007/s00170-021-07253-6
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zhou SP, 2019, IEEE I CONF COMP VIS, P8039, DOI 10.1109/ICCV.2019.00813
   Zhou Z, 2017, PROC CVPR IEEE, P6776, DOI 10.1109/CVPR.2017.717
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu Z, 2019, PROC CVPR IEEE, P2342, DOI 10.1109/CVPR.2019.00245
   Zhuang WM, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P955, DOI 10.1145/3394171.3413814
   Zou Y., 2020, P EUR C COMP VIS, P87
NR 203
TC 47
Z9 49
U1 9
U2 74
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104394
DI 10.1016/j.imavis.2022.104394
EA FEB 2022
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Li, Y
   Xu, HH
   Bian, MJ
   Xiao, JS
AF Li, Yang
   Xu, Huahu
   Bian, Minjie
   Xiao, Junsheng
TI Cross-scale global attention feature pyramid network for person search
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person search; Global attention; Feature pyramid network; Multi-scale;
   Fine-grained
AB Person search aims to locate the target person in real unconstrained scene images. It faces many challenges such as multi-scale and fine-grained. To address the challenges, a novel cross-scale global attention feature pyramid network (CSGAFPN) is proposed. Firstly, we design a novel multi-head global attention module (MHGAM), which adopts cosine similarity and sparse query location methods to effectively capture cross-scale long-distance dependence. Then, we design the CSGAFPN, which extends top-down feature pyramid network with bottom-up connections and embeds MHGAMs to the connections. CSGAFPN can capture cross-scale long-distance global correlation from multi-scale feature maps, selectively strengthen important features and restrain less important features. CSGAFPN is applied for both person detection and person re-identification (reID) sub-tasks of person search, it can well handle the multi-scale and fine-grained challenges, and significantly improve person search performance. Furthermore, the output multi-scale feature maps of CSGAFPN are processed by an adaptive feature aggregation with attention (AFAA) layer to further improve the performance. Numerous exper-iments with two public person search datasets, CUHK-SYSU and PRW, show our CSGAFPN based approach ac-quires better performance than other state-of-the-art (SOTA) person search approaches. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Li, Yang] Shanghai Jianqiao Univ, Sch Informat Technol, Shanghai 201306, Peoples R China.
   [Li, Yang; Xu, Huahu; Xiao, Junsheng] Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.
   [Xu, Huahu; Bian, Minjie] Shanghai Univ, Informat Off, Shanghai 200444, Peoples R China.
C3 Shanghai University; Shanghai University
RP Li, Y; Xu, HH (corresponding author), Shanghai Univ, Sch Comp Engn & Sci, Shanghai 200444, Peoples R China.
EM liyang162@shu.edu.cn; huahuxu@staff.shu.edu.cn
FU SJQU research project [SJQ19010]; CERNET innovation project
   [NGII20180617]
FX This work is supported partially by SJQU research project (SJQ19010) and
   the CERNET innovation project (NGII20180617) .
CR Cao Y, 2019, IEEE INT CONF COMP V, P1971, DOI 10.1109/ICCVW.2019.00246
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chang XJ, 2018, LECT NOTES COMPUT SC, V11213, P86, DOI 10.1007/978-3-030-01240-3_6
   Chen BH, 2019, IEEE I CONF COMP VIS, P371, DOI 10.1109/ICCV.2019.00046
   Chen D., P IEEE CVF C COMP VI, P12615
   Chen D, 2020, IEEE T IMAGE PROCESS, V29, P4669, DOI 10.1109/TIP.2020.2973513
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong WK, 2020, PROC CVPR IEEE, P2836, DOI 10.1109/CVPR42600.2020.00291
   Ghiasi G, 2019, PROC CVPR IEEE, P7029, DOI 10.1109/CVPR.2019.00720
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Han CC, 2019, IEEE I CONF COMP VIS, P9813, DOI 10.1109/ICCV.2019.00991
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hu J., P IEEE C COMPUTER VI, P7132
   Hu J, 2018, ADV NEURAL INFORM PR, P9401, DOI DOI 10.5555/3327546.3327612
   Huang ZL, 2019, IEEE I CONF COMP VIS, P603, DOI 10.1109/ICCV.2019.00069
   Islam K, 2020, IMAGE VISION COMPUT, V101, DOI 10.1016/j.imavis.2020.103970
   Kong T, 2018, LECT NOTES COMPUT SC, V11209, P172, DOI 10.1007/978-3-030-01228-1_11
   Lan X, 2018, LECT NOTES COMPUT SC, V11205, P553, DOI 10.1007/978-3-030-01246-5_33
   Leng QM, 2020, IEEE T CIRC SYST VID, V30, P1092, DOI 10.1109/TCSVT.2019.2898940
   Li W, 2020, INT J COMPUT VISION, V128, P1635, DOI 10.1007/s11263-019-01274-1
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Li Z., ARXIV210310148
   Lin D, 2019, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2019.00767
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu H, 2017, IEEE I CONF COMP VIS, P493, DOI 10.1109/ICCV.2017.61
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Munjal B, 2019, PROC CVPR IEEE, P811, DOI 10.1109/CVPR.2019.00090
   Nie J, 2019, IEEE I CONF COMP VIS, P9536, DOI 10.1109/ICCV.2019.00963
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shi XJ, 2015, ADV NEUR IN, V28
   Vaswani Ashish, 2017, Advances in Neural Information Processing Systems (NeurIPS), V17, P6000, DOI DOI 10.48550/ARXIV.1706.03762
   Wang C., P IEEE CVF C COMP VI, P11952
   Wang GS, 2018, PROCEEDINGS OF THE 2018 ACM MULTIMEDIA CONFERENCE (MM'18), P274, DOI 10.1145/3240508.3240552
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Woo SH, 2018, LECT NOTES COMPUT SC, V11211, P3, DOI 10.1007/978-3-030-01234-2_1
   Xiao JM, 2019, PATTERN RECOGN, V87, P332, DOI 10.1016/j.patcog.2018.10.028
   Xiao T., 2016, ARXIV160401850, V2, P4
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xu YL, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P937, DOI 10.1145/2647868.2654965
   Yan Y., ARXIV210311617
   Yan YC, 2019, PROC CVPR IEEE, P2153, DOI 10.1109/CVPR.2019.00226
   Zhang ZL, 2018, LECT NOTES COMPUT SC, V11214, P273, DOI 10.1007/978-3-030-01249-6_17
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zhu Z, 2019, IEEE I CONF COMP VIS, P593, DOI 10.1109/ICCV.2019.00068
NR 47
TC 3
Z9 3
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104332
DI 10.1016/j.imavis.2021.104332
EA NOV 2021
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WZ2LF
UT WOS:000719802700003
DA 2024-07-18
ER

PT J
AU Jiang, TL
   Shao, HL
   Tian, X
   Ji, Y
   Liu, CP
AF Jiang, Tianling
   Shao, Hailin
   Tian, Xin
   Ji, Yi
   Liu, Chunping
TI Aligning vision-language for graph inference in visual dialog
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual dialog; Alignment; Graph inference; Scene graph
AB As a cross-media intelligence task, visual dialog calls for answering a sequence of questions based on an image, using the dialog history as context. To acquire correct answers, the exploration of the semantic dependencies among potential visual and textual contents becomes vital. Prior works usually ignored the underlying knowledge hidden in internal and external textual-visual relationships, which resulted in unreasonable inferring. In this paper, we propose an Aligning Vision-Language for Graph Inference (AVLGI) in visual dialog by combining the internal context-aware information and the external scene graph knowledge. Compared with other approaches, it makes up the lack of structural inference in visual dialog. So the whole system consists of three modules, Inter-Modalities Alignment (IMA), Visual Graph Attended by Text (VGAT) and Combining Scene Graph and Textual Contents(CSGTC). Specifically, the IMA module aims at representing an image with a set of integrated visual regions and corresponding textual concepts, reflecting certain semantics. And the VGAT module views the visual features with semantic information as observed nodes and measures the weight of importance between each two nodes in visual graph. The CSGTC supplements various relationships between visual objects by introducing additional information of the scene graph. We also qualitatively and quantitatively evaluate the model on VisDial v1.0 dataset, showing our AVLGI outperforms previous state-of-the-art models. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Jiang, Tianling; Shao, Hailin; Tian, Xin; Ji, Yi; Liu, Chunping] Soochow Univ, Sch Comp Sci & Technol, Suzhou, Jiangsu, Peoples R China.
C3 Soochow University - China
RP Ji, Y (corresponding author), Soochow Univ, Sch Comp Sci & Technol, Suzhou, Jiangsu, Peoples R China.
EM jiyi@suda.edu.cn
OI JI, Yi/0000-0001-6965-4158
FU Postgraduate Research & Practice Innovation Program of Jiangsu Province
   [SJCX21_1341]; National Natural Science Foundation of China (NSFC)
   [61773272, 61272258, 61301299, 61572085, 61170124, 61272005]; Provincial
   Natural Science Foundation of Jiangsu [BK20151254, BK20151260]; Science
   and Education Innovation based Cloud Data fusion Foundation of Science
   and Technology Development Center of Education Ministry [2017B03112];
   Six talent peaks Project in Jiangsu Province [DZXX-027]; Key Laboratory
   of Symbolic Computation and Knowledge Engineering of Ministry of
   Education, Jilin University [93K172016K08]; Collaborative Innovation
   Center of Novel Software Technology and Industrialization - Priority
   Academic Program Development of Jiangsu Higher Education Institutions
FX Thisworkwas partially supported by Postgraduate Research & Practice
   Innovation Program of Jiangsu Province (SJCX21_1341), National Natural
   Science Foundation of China (NSFC Grant No. 61773272, 61272258,
   61301299, 61572085, 61170124, 61272005), Provincial Natural Science
   Foundation of Jiangsu (Grant No. BK20151254, BK20151260), Science and
   Education Innovation based Cloud Data fusion Foundation of Science and
   Technology Development Center of EducationMinistry (2017B03112), Six
   talent peaks Project in Jiangsu Province (DZXX-027), Key Laboratory of
   Symbolic Computation and Knowledge Engineering of Ministry of Education,
   Jilin University (Grant No. 93K172016K08), and Collaborative Innovation
   Center of Novel Software Technology and Industrialization, Project
   Funded by the Priority Academic Program Development of Jiangsu Higher
   Education Institutions.
CR Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Das A, 2017, PROC CVPR IEEE, P1080, DOI 10.1109/CVPR.2017.121
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Nguyen DK, 2018, PROC CVPR IEEE, P6087, DOI 10.1109/CVPR.2018.00637
   Gu JX, 2019, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2019.00207
   Guo DL, 2019, PROC CVPR IEEE, P10426, DOI 10.1109/CVPR.2019.01068
   Guo Dan, P IEEE CVF C COMP VI, P10055
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Hudson DA, 2019, PROC CVPR IEEE, P6693, DOI 10.1109/CVPR.2019.00686
   Jiang XZ, 2020, MM '20: PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, P1265, DOI 10.1145/3394171.3413826
   Johnson J, 2018, PROC CVPR IEEE, P1219, DOI 10.1109/CVPR.2018.00133
   Johnson J, 2015, PROC CVPR IEEE, P3668, DOI 10.1109/CVPR.2015.7298990
   Kang GC, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P2024
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kim H, 2020, AAAI CONF ARTIF INTE, V34, P8091
   Kim JH, 2018, ADV NEUR IN, V31
   Kottur S, 2018, LECT NOTES COMPUT SC, V11219, P160, DOI 10.1007/978-3-030-01267-0_10
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li MS, 2019, PROC CVPR IEEE, P3590, DOI 10.1109/CVPR.2019.00371
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu Y, 2018, PROC CVPR IEEE, P6985, DOI 10.1109/CVPR.2018.00730
   Lu JS, 2017, ADV NEUR IN, V30
   Lu JS, 2016, ADV NEUR IN, V29
   Nam H, 2017, PROC CVPR IEEE, P2156, DOI 10.1109/CVPR.2017.232
   Niu YL, 2019, PROC CVPR IEEE, P6672, DOI 10.1109/CVPR.2019.00684
   Peng YQ, 2019, IMAGE VISION COMPUT, V86, P38, DOI 10.1016/j.imavis.2019.03.003
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Ren S, 2015, FASTER R CNN REAL TI, P91
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schwartz I, 2019, PROC CVPR IEEE, P2039, DOI 10.1109/CVPR.2019.00214
   Seo PH, 2017, ADV NEUR IN, V30
   Shimizu Nobuyuki, P 27 INT C COMP LING, P1918
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JB, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107075
   Wang P, 2019, PROC CVPR IEEE, P1960, DOI 10.1109/CVPR.2019.00206
   WenguanWang Siyuan, P IEEE C COMP VIS PA, P6669
   Wu H, 2019, PROC CVPR IEEE, P6602, DOI 10.1109/CVPR.2019.00677
   Wu Q, 2016, PROC CVPR IEEE, P203, DOI 10.1109/CVPR.2016.29
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Xu K, 2015, PR MACH LEARN RES, V37, P2048
   Yang TH, 2019, IEEE I CONF COMP VIS, P2561, DOI 10.1109/ICCV.2019.00265
   Yao T, 2018, LECT NOTES COMPUT SC, V11218, P711, DOI 10.1007/978-3-030-01264-9_42
NR 44
TC 6
Z9 6
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104316
DI 10.1016/j.imavis.2021.104316
EA OCT 2021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WU6KE
UT WOS:000716651500002
DA 2024-07-18
ER

PT J
AU He, FJ
   Wang, YX
   Miao, XL
   Sun, X
AF He, Feijuan
   Wang, Yaxian
   Miao, Xianglin
   Sun, Xia
TI Interpretable visual reasoning: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Visual question answering; Visual reasoning; Interpretability; Datasets;
   Survey
ID ATTENTION
AB Visual reasoning refers to the process of solving questions about visual information. At present, most visual reasoning models are mainly based on deep learning and end-to-end architecture. Although these models have achieved good performance, they are usually black boxes for users, and it is difficult to understand the basic rationales of the reasoning process. In recent years, the academic community has realized the importance of interpretability in visual reasoning and has developed a series of Interpretable Visual Reasoning (IVR) models. In this paper, we review these models. First, we have established a taxonomy based on four explanation forms of vision, text, graph and symbol used in current visual reasoning. Secondly, we explore the typical IVR models of each category and analyze their pros and cons. Thirdly, we elaborate on the current mainstream datasets about visual reasoning and VQA, and analyze how these datasets promote IVR research from different perspectives. Finally, we summarize the challenges for IVR and point out potential research directions. (c) 2021 Elsevier B.V. All rights reserved.
C1 [He, Feijuan; Miao, Xianglin] Xi An Jiao Tong Univ City Coll, Dept Comp Sci, Xian, Peoples R China.
   [Wang, Yaxian] Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian, Peoples R China.
   [Sun, Xia] Northwest Univ, Sch Informat Sci & Technol, Xian, Peoples R China.
C3 Xi'an Jiaotong University; Northwest University Xi'an
RP Wang, YX (corresponding author), Xi An Jiao Tong Univ, Dept Comp Sci & Technol, Xian, Peoples R China.
EM hfj@mail.xjtu.edu.cn; wyx1566@stu.xjtu.edu.cn; miaoxianglin@126.com;
   raindy@nwu.edu.cn
RI Sun, Xia/GSN-0795-2022
FU Natural Science Basic Research Program of Shaanxi [2020JM-711]; National
   Natural Science Foundation of China [61877050]; National Social Science
   Fund of China [18XXW005]; National Statistical Science Research Project
   [2020LY103]; Humanities and Social Sciences Fund of the Ministry of
   Education [17YJA860028]; Shaanxi Provincial Education Science
   Regulations "Thirteenth Five-Year Plan" Project [SGH20Y1397]
FX This work was supported in part by the Natural Science Basic Research
   Program of Shaanxi (2020JM-711), the National Natural Science Foundation
   of China (61877050), National Social Science Fund of China (18XXW005),
   National Statistical Science Research Project (2020LY103), the
   Humanities and Social Sciences Fund of the Ministry of Education
   (17YJA860028), Shaanxi Provincial Education Science Regulations
   "Thirteenth Five-Year Plan" Project (SGH20Y1397).
CR Agarwal Vedika, 2020, P IEEE CVF C COMP VI, P9690
   Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Agrawal R., 1994, P INT VLDB C VLDB 94, P487, DOI DOI 10.5555/645920.672836
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Andreas J, 2016, PROC CVPR IEEE, P39, DOI 10.1109/CVPR.2016.12
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Auer S, 2007, LECT NOTES COMPUT SC, V4825, P722, DOI 10.1007/978-3-540-76298-0_52
   Bach S., 2017, J MACH LEARN RES, V18, P1
   Banerjee S, 2005, ACL WORKSHOP INTRINS, P65
   Baral Chitta, 2018, P AAAI C ART INT, V32
   Basu K, 2020, LECT NOTES COMPUT SC, V12007, P57, DOI 10.1007/978-3-030-39197-3_4
   Ben-younes H, 2017, IEEE I CONF COMP VIS, P2631, DOI 10.1109/ICCV.2017.285
   Bidoit Nicole, 2014, QUERY BASED WHY NOT
   Binder A, 2016, LECT NOTES COMPUT SC, V9887, P63, DOI 10.1007/978-3-319-44781-0_8
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Cao QX, 2018, PROC CVPR IEEE, P7249, DOI 10.1109/CVPR.2018.00757
   Cao Qingxing, 2019, ARXIV PREPRINT ARXIV
   Cao Qingxing, 2019, IEEE T PATTERN ANAL, V43
   Cao Qingxing, 2020, ARXIV PREPRINT ARXIV
   Das A, 2017, COMPUT VIS IMAGE UND, V163, P90, DOI 10.1016/j.cviu.2017.10.001
   Das Abhishek, 2018, C ROB LEARN PMLR, P53
   Fong RC, 2017, IEEE I CONF COMP VIS, P3449, DOI 10.1109/ICCV.2017.371
   Gao P, 2019, IEEE I CONF COMP VIS, P5824, DOI 10.1109/ICCV.2019.00592
   Gokhale Tejas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P379, DOI 10.1007/978-3-030-58589-1_23
   Goyal Y, 2017, PROC CVPR IEEE, P6325, DOI 10.1109/CVPR.2017.670
   Guo Dalu, 2019, ARXIV PREPRINT ARXIV
   Halbe S, 2020, PROCEEDINGS OF THE SECOND GRAND CHALLENGE AND WORKSHOP ON MULTIMODAL LANGUAGE (CHALLENGE-HML), VOL 1, P64
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendricks LA, 2016, LECT NOTES COMPUT SC, V9908, P3, DOI 10.1007/978-3-319-46493-0_1
   Hong J, 2019, NEUROCOMPUTING, V351, P187, DOI 10.1016/j.neucom.2019.03.035
   Hu RH, 2017, IEEE I CONF COMP VIS, P804, DOI 10.1109/ICCV.2017.93
   Hudson D. A., 2019, 2019 IEEE CVF C COMP, P6700, DOI DOI 10.48550/ARXIV.1902.09506
   Hudson Drew A., 2018, ARXIV PREPRINT ARXIV
   Ilievski Ilija, P 31 INT C NEUR INF, P551
   JialinWu Raymond J., 2019, BLACKB WORKSH AN, P103
   Jiang Lu, 2017, ARXIV PREPRINT ARXIV
   Johnson J, 2017, IEEE I CONF COMP VIS, P3008, DOI 10.1109/ICCV.2017.325
   Johnson J, 2017, PROC CVPR IEEE, P1988, DOI 10.1109/CVPR.2017.215
   Johnson J, 2016, PROC CVPR IEEE, P4565, DOI 10.1109/CVPR.2016.494
   Kafle K, 2017, IEEE I CONF COMP VIS, P1983, DOI 10.1109/ICCV.2017.217
   Kafle K, 2017, COMPUT VIS IMAGE UND, V163, P3, DOI 10.1016/j.cviu.2017.06.005
   Kim Wonjae, 2019, STAT, V1050, P28
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Li H, 2019, PROC CVPR IEEE, P6312, DOI 10.1109/CVPR.2019.00648
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li Q., 2018, P EUR C COMP VIS ECC, P552
   Li Q., 2018, C EMP METH NAT LANG, P1338
   Li W, 2020, PATTERN RECOGN LETT, V133, P334, DOI 10.1016/j.patrec.2020.02.031
   Liang JW, 2019, IEEE T PATTERN ANAL, V41, P1893, DOI 10.1109/TPAMI.2018.2890628
   Liang Peng, 2020, IEEE T PATTERN ANAL
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu H, 2004, BT TECHNOL J, V22, P211, DOI 10.1023/B:BTTJ.0000047600.45421.6d
   Liu RT, 2019, PROC CVPR IEEE, P4180, DOI 10.1109/CVPR.2019.00431
   Lu JS, 2016, ADV NEUR IN, V29
   Manjunatha V, 2019, PROC CVPR IEEE, P9554, DOI 10.1109/CVPR.2019.00979
   Mascharka D, 2018, PROC CVPR IEEE, P4942, DOI 10.1109/CVPR.2018.00519
   Molnar C., 2020, Interpretable machine learning.
   Narasimhan M, 2018, LECT NOTES COMPUT SC, V11212, P460, DOI 10.1007/978-3-030-01237-3_28
   Norcliffe-Brown W, 2018, ADV NEUR IN, V31
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park DH, 2018, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2018.00915
   Perez E, 2018, AAAI CONF ARTIF INTE, P3942
   Redmon J., 2018, COMPUTER VISION PATT
   Riley H, 2019, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00125
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Robnik-Sikonja M, 2018, HUM-COMPUT INT-SPRIN, P159, DOI 10.1007/978-3-319-90403-0_9
   Rohrbach A, 2017, INT J COMPUT VISION, V123, P94, DOI 10.1007/s11263-016-0987-1
   Schoenmackers Stefan., 2010, Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP '10, P1088
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shah S, 2019, AAAI CONF ARTIF INTE, P8876
   Shetty Rakshith, 2018, INT CONFNEURAL INF P, P7717
   Shi Jiaxin, 2019, PROC CVPR IEEE, P8376, DOI DOI 10.1109/CVPR.2019.00857
   Singh A, 2019, PROC CVPR IEEE, P8309, DOI 10.1109/CVPR.2019.00851
   Suarez Joseph, 2018, ARXIV PREPRINT ARXIV
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   Tapaswi M, 2016, PROC CVPR IEEE, P4631, DOI 10.1109/CVPR.2016.501
   Vatashsky Ben-Zion, 2020, PROC IEEE C COMPUT V, P10376
   Vedantam R., 2019, PR MACH LEARN RES, P6428
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Wang M, 2019, KNOWL INF SYST, V58, P169, DOI 10.1007/s10115-018-1155-4
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wu Jialin, 2020, ARXIV PREPRINT ARXIV
   Wu Q, 2017, COMPUT VIS IMAGE UND, V163, P21, DOI 10.1016/j.cviu.2017.05.001
   Xu HJ, 2016, LECT NOTES COMPUT SC, V9911, P451, DOI 10.1007/978-3-319-46478-7_28
   Yang C, 2019, IEEE ACCESS, V7, P40771, DOI 10.1109/ACCESS.2019.2908035
   Yang LJ, 2017, PROC CVPR IEEE, P1978, DOI 10.1109/CVPR.2017.214
   Yi Kexin, P 32 INT C NEUR INF, P1039
   Yu Wang, 2018, 2 CONV AI WORKSH NEU
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Zellers R, 2019, PROC CVPR IEEE, P6713, DOI 10.1109/CVPR.2019.00688
   Zellers R, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P93
   Zhang Wen, 2020, IEEE T CIRC SYST VID
   Zhou YY, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P681, DOI 10.1145/3123266.3123335
NR 96
TC 6
Z9 6
U1 9
U2 44
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2021
VL 112
AR 104194
DI 10.1016/j.imavis.2021.104194
EA JUN 2021
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA TH5WM
UT WOS:000672160100014
DA 2024-07-18
ER

PT J
AU Liu, Y
AF Liu, Yuan
TI Improved generative adversarial network and its application in image oil
   painting style transfer
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Generative adversarial network; Wasserstein distance; Gradient penalty;
   Total variance loss; Migration and reconstruction of oil painting style
ID GAN
AB In view of the difficulty in training the algorithm of image oil painting style migration and reconstruction based on the generative adversarial network, and the loss gradient of generator and discriminator disappears, this paper proposes an improved generative adversarial network based on gradient penalty, and constructs the total variance loss function to carry out the research of image oil painting style migration and reconstruction. Firstly, the Wasserstein distance (WGAN) is added to the loss function of the generative adversarial network to improve the stability of the alternative iterative training; secondly, the gradient penalty (WGAN-GP) is added to the loss function to deal with the problem of gradient disappearance in the training; finally, the LBP texture feature and total variation of the prototype are introduced based on the CycleGAN Loss noise constraint is used to improve the edge and texture strength of the image after migration of oil painting style. The experimental results show that the WGAN-GP algorithm constructed in this study has the ability of stable gradient and alternating iterative convergence, and the total variation loss noise constraint can provide good edge and texture details for the migration process of image oil painting style. Compared with the existing mainstream algorithm, the algorithm proposed in this study has better performance of image oil painting style migration and reconstruction, and better effect of image oil painting style migration and reconstruction. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Liu, Yuan] Lanzhou City Univ, Coll Fine Arts & Design, Lanzhou 730070, Peoples R China.
C3 Lanzhou City University
RP Liu, Y (corresponding author), Lanzhou City Univ, Coll Fine Arts & Design, Lanzhou 730070, Peoples R China.
EM liuyuan_x@163.com
CR Andreini P, 2020, COMPUT METH PROG BIO, V184, DOI 10.1016/j.cmpb.2019.105268
   Atapour-Abarghouei A, 2018, PROC CVPR IEEE, P2800, DOI 10.1109/CVPR.2018.00296
   Azadil S, 2018, PROC CVPR IEEE, P7564, DOI 10.1109/CVPR.2018.00789
   Chen XY, 2019, IEEE T IMAGE PROCESS, V28, P546, DOI 10.1109/TIP.2018.2869695
   Chi YC, 2018, IEEE ENG MED BIO, P2591, DOI 10.1109/EMBC.2018.8512842
   Deng X, 2018, IEEE SIGNAL PROC LET, V25, P571, DOI 10.1109/LSP.2018.2805809
   Gatys LA, 2016, PROC CVPR IEEE, P2414, DOI 10.1109/CVPR.2016.265
   Hiasa Y, 2018, LECT NOTES COMPUT SC, V11037, P31, DOI 10.1007/978-3-030-00536-8_4
   Hu Z., 2020, P 28 ACM INT C MULTI, P3320
   Huang X, 2017, IEEE I CONF COMP VIS, P1510, DOI 10.1109/ICCV.2017.167
   Iqbal T, 2018, J MED SYST, V42, DOI 10.1007/s10916-018-1072-9
   Karras T, 2019, PROC CVPR IEEE, P4396, DOI 10.1109/CVPR.2019.00453
   Li PF, 2019, IEEE INT CON MULTI, P910, DOI 10.1109/ICME.2019.00161
   Liu HW, 2018, INT C PATT RECOG, P79, DOI 10.1109/ICPR.2018.8546172
   Luan FJ, 2017, PROC CVPR IEEE, P6997, DOI 10.1109/CVPR.2017.740
   Palsson S, 2018, IEEE COMPUT SOC CONF, P2165, DOI 10.1109/CVPRW.2018.00282
   Shen CG, 2020, JAMA-J AM MED ASSOC, V323, P1582, DOI 10.1001/jama.2020.4783
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Yang S, 2019, IEEE I CONF COMP VIS, P4441, DOI 10.1109/ICCV.2019.00454
   Yang S, 2019, AAAI CONF ARTIF INTE, P1238
   Zhang LM, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P506, DOI 10.1109/ACPR.2017.61
   Zhou ZY, 2019, 2019 53RD ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/ciss.2019.8692884
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, P2223, DOI DOI 10.1109/ICCV.2017.244
NR 23
TC 19
Z9 19
U1 5
U2 40
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104087
DI 10.1016/j.imavis.2020.104087
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800005
DA 2024-07-18
ER

PT J
AU Mesbah, A
   Berrahou, A
   Hammouchi, H
   Berbia, H
   Qjidaa, H
   Daoudi, M
AF Mesbah, Abderrahim
   Berrahou, Aissam
   Hammouchi, Hicham
   Berbia, Hassan
   Qjidaa, Hassan
   Daoudi, Mohamed
TI Lip reading with Hahn Convolutional Neural Networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual speech recognition; Lipreading; Laryngectomy; Hahn moments;
   Convolutional Neural Networks
AB Lipreading or Visual speech recognition is the process of decoding speech from speaker's mouth movements. It is used for people with hearing impairment, to understand patients attained with laryngeal cancer, people with vocal cord paralysis and in noisy environment. In this paper we aim to develop a visual-only speech recognition system based only on video. Our main targeted application is in the medical field for the assistance to laryngectomized persons. To that end, we propose Hahn Convolutional Neural Network (HCNN), a novel architecture based on Hahn moments as first layer in the Convolutional Neural Network (CNN) architecture. We show that HCNN helps in reducing the dimensionality of video images, in gaining training time. HCNN model is trained to classify letters, digits or words given as video images. We evaluated the proposed method on three datasets, AVLetters, OuluVS2 and BBC LRW, and we show that it achieves significant results in comparison with other works in the literature. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Mesbah, Abderrahim; Hammouchi, Hicham; Qjidaa, Hassan] Sidi Mohammed Ben Abdellah Univ, Fes, Morocco.
   [Berrahou, Aissam; Hammouchi, Hicham; Berbia, Hassan] Mohammed V Univ, Rabat, Morocco.
   [Daoudi, Mohamed] Univ Lille, IMT Lille Douai, CNRS, UMR 9189,CRIStAL, Lille, France.
C3 Sidi Mohamed Ben Abdellah University of Fez; Mohammed V University in
   Rabat; Centre National de la Recherche Scientifique (CNRS); Universite
   de Lille; IMT - Institut Mines-Telecom; IMT Nord Europe; Centrale Lille
RP Mesbah, A (corresponding author), Sidi Mohammed Ben Abdellah Univ, Fes, Morocco.
EM abderrahim.mesbah@usmba.ac.ma
RI ; Daoudi, Mohammed/H-5935-2013
OI HAMMOUCHI, Hicham/0000-0002-0572-218X; Daoudi,
   Mohammed/0000-0003-4219-7860; berrahou, aissam/0000-0003-2787-3138;
   Hassan, qjidaa/0000-0003-4505-5243; Berbia, Hassan/0000-0003-2615-2638
CR Anina Iryna, 2015, 2015 11th IEEE International Conference and Workshops on Automatic Face and Gesture Recognition (FG), P1, DOI 10.1109/FG.2015.7163155
   [Anonymous], 2009, P AVSP
   Bakry A., 2016, ARXIV160105861CSCV
   Chung J. S., 2017, LECT NOTES COMPUTER, V10117
   Chung J. S., 2016, LIP READING WILD
   Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367
   Cootes T. F., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P484, DOI 10.1007/BFb0054760
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   FISHER CG, 1968, J SPEECH HEAR RES, V11, P796, DOI 10.1044/jshr.1104.796
   Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900
   Mesbah A, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.6.061621
   Petridis S, 2016, INT CONF ACOUST SPEE, P2304, DOI 10.1109/ICASSP.2016.7472088
   Saitoh T., 2017, LECT NOTES COMPUTER, V10117
   Stafylakis T., ABS171011201 CORR
   Stafylakis T, 2017, INTERSPEECH, P3652, DOI 10.21437/Interspeech.2017-85
   Tian C., 2017, ARXIV170104224V2
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhou J., 2005, LECT NOTES COMPUTER, V3656
NR 18
TC 22
Z9 25
U1 2
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 76
EP 83
DI 10.1016/j.imavis.2019.04.010
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400008
DA 2024-07-18
ER

PT J
AU Ouyang, Y
AF Ouyang, Yi
TI Total variation constraint GAN for dynamic scene deblurring
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Total variation; Deblur; GAN; Convolution neural network
AB Recovering the sharp image solely from the blurry image in dynamic scene is challenging due to the ill-defined nature of the problem. Through Wasserstein distance and L-1 norm of total variation combined regularization, we propose a novel TV-DRGAN optimization framework to obtain a latent sharp image from some observed blurry images. Our method benefits from two aspects: one is the improved object total variation energy to constrain the blurry image, and the other is the generator model combining (UPR)-Blocks and D-Blocks. An (UPR)-Block is composed of one upsampling layer and 3 convolution layers. Consisting of an average-pooling layer and multiple convolution layers, a D-Block comes with different kernel sizes that capture global, and local spatial information of the raw image, separately. By analyzing the information of gradient, we obtain a TV-based based on minimum lower bound of loss function of the generator. Our experiments show that the proposed method outperforms the state-of-the-art conventional algorithms significantly. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Ouyang, Yi] Zhejiang Gongshang Univ, Sch Management & E Business, Hangzhou, Zhejiang, Peoples R China.
C3 Zhejiang Gongshang University
RP Ouyang, Y (corresponding author), Zhejiang Gongshang Univ, Sch Management & E Business, Hangzhou, Zhejiang, Peoples R China.
EM oyy@mail.zjgsu.edu.cn
CR [Anonymous], P C COMP VIS PATT RE
   [Anonymous], P IEEE WORKSH COL PH
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], 171107064 ARXIV
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COMP VI
   [Anonymous], P IEEE INT C COM VIS
   [Anonymous], 2016, ADV NEURAL INFORM PR
   [Anonymous], 2017, SAIGAN VISUAL SALIEN
   [Anonymous], 2016, P IEEE C COMP VIS PA
   [Anonymous], P IEEE INT C COMP VI
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Boracchi G, 2012, IEEE T IMAGE PROCESS, V21, P3502, DOI 10.1109/TIP.2012.2192126
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Kingma Diederik P, 2014, INT C LEARN REPR ICL, Patent No. [1312.6114, 13126114]
   Krishnan D., 2009, P ADV NEURAL INFORM, V22, P1033
   Levin A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2657, DOI 10.1109/CVPR.2011.5995308
   Nah Seungjun, 2017, P C COMP VIS PATT RE
   Perrone D, 2014, PROC CVPR IEEE, P2909, DOI 10.1109/CVPR.2014.372
   Schuler CJ, 2016, IEEE T PATTERN ANAL, V38, DOI 10.1109/TPAMI.2015.2481418
   Simons KA, 2014, ADV ACC EDUC-TEACH, V15, P1, DOI 10.1108/S1085-462220140000015001
   Son H, 2017, IEEE INT CONF COMPUT, P23
   Sun J, 2015, PROC CVPR IEEE, P769, DOI 10.1109/CVPR.2015.7298677
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Williams C.K.I., PASCAL VISUAL OBJECT
   Xu L, 2013, PROC CVPR IEEE, P1107, DOI 10.1109/CVPR.2013.147
   Xu Li, 2014, P ANN C NEUR INF PRO, P1790
   Zhang L, 2011, IEEE T IMAGE PROCESS, V20, P2378, DOI 10.1109/TIP.2011.2109730
   Zhang XX, 2015, IEEE IMAGE PROC, P138, DOI 10.1109/ICIP.2015.7350775
   Zhao J., 2017, P INT C LEARNING REP
   Zhu J.-Y., 2017, IEEE I CONF COMP VIS, P2223, DOI DOI 10.1109/ICCV.2017.244
   Zoran D, 2011, IEEE I CONF COMP VIS, P479, DOI 10.1109/ICCV.2011.6126278
NR 32
TC 7
Z9 8
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 113
EP 119
DI 10.1016/j.imavis.2019.05.007
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400011
DA 2024-07-18
ER

PT J
AU Perez-Yus, A
   Lopez-Nicolas, G
   Guerrero, JJ
AF Perez-Yus, Alejandro
   Lopez-Nicolas, Gonzalo
   Guerrero, Jose J.
TI Scaled layout recovery with wide field of view RGB-D
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D layout estimation; RGB-D; Omnidirectional cameras; Multi-camera
   systems
ID OMNIDIRECTIONAL CAMERAS; CALIBRATION; SCENE
AB In this work, we propose a method that integrates depth and fisheye cameras to obtain a wide 3D scene reconstruction with scale in one single shot. The motivation of such integration is to overcome the narrow field of view in consumer RGB-D cameras and lack of depth and scale information in fisheye cameras. The hybrid camera system we use is easy to build and calibrate, and currently consumer devices with similar configuration are already available in the market. With this system, we have a portion of the scene with shared field of view that provides simultaneously color and depth. In the rest of the color image we estimate the depth by recovering the structural information of the scene. Our method finds and ranks corners in the scene combining the extraction of lines in the color image and the depth information. These corners are used to generate plausible layout hypotheses, which have real-world scale due to the usage of depth. The wide angle camera captures more information from the environment (e.g. the ceiling), which helps to overcome severe occlusions. After an automatic evaluation of the hypotheses, we obtain a scaled 3D model expanding the original depth information with the wide scene reconstruction. We show in our experiments with real images from both home-made and commercial systems that our method achieves high success ratio in different scenarios and that our hybrid camera system outperforms the single color camera set-up while additionally providing scale in one single shot. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Perez-Yus, Alejandro; Lopez-Nicolas, Gonzalo; Guerrero, Jose J.] Univ Zaragoza, I3A, Zaragoza, Spain.
C3 University of Zaragoza
RP Perez-Yus, A (corresponding author), Univ Zaragoza, I3A, Zaragoza, Spain.
EM alperez@unizar.es; gonlopez@unizar.es; josechu.guerrero@unizar.es
RI Guerrero, Jose J./K-5435-2014
OI Guerrero, Jose J./0000-0001-5209-2267; Perez-Yus,
   Alejandro/0000-0002-8949-2632
FU MINECO/FEDER, UE [DPI2014-61792-EXP, DPI2015-65962-R]; MINECO
   [BES-2013-065834]
FX This work was supported by Projects DPI2014-61792-EXP and
   DPI2015-65962-R (MINECO/FEDER, UE) and grant BES-2013-065834 (MINECO).
CR [Anonymous], 2010, NIPS
   [Anonymous], IEEE C COMP VIS PATT
   Bazin JC, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P346, DOI 10.1109/IROS.2008.4650795
   Bermudez-Cameo J, 2015, INT J COMPUT VISION, V114, P16, DOI 10.1007/s11263-014-0792-7
   Cabral R, 2014, PROC CVPR IEEE, P628, DOI 10.1109/CVPR.2014.546
   Chang HC, 2015, IEEE IMAGE PROC, P4723, DOI 10.1109/ICIP.2015.7351703
   Coughlan J. M., 1999, P IEEE INT C COMPUTE, DOI DOI 10.1109/ICCV.1999.790349
   Dasgupta S, 2016, PROC CVPR IEEE, P616, DOI 10.1109/CVPR.2016.73
   Del Pero L., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2009, DOI 10.1109/CVPR.2011.5995737
   Del Pero L, 2012, PROC CVPR IEEE, P2719, DOI 10.1109/CVPR.2012.6247994
   Delage Erick, 2006, 2006 IEEE COMP SOC C, P2418
   Eigen D, 2015, IEEE I CONF COMP VIS, P2650, DOI 10.1109/ICCV.2015.304
   Endres F, 2014, IEEE INT C INT ROBOT, P466, DOI 10.1109/IROS.2014.6942600
   Fernandez-Labrador C, 2018, IEEE ROBOT AUTOM LET, V3, P3153, DOI 10.1109/LRA.2018.2850532
   Fernández-Moral E, 2014, IEEE INT C INT ROBOT, P429, DOI 10.1109/IROS.2014.6942595
   Flint A, 2011, IEEE I CONF COMP VIS, P2228, DOI 10.1109/ICCV.2011.6126501
   Fukano K, 2016, INT C PATT RECOG, P1768, DOI 10.1109/ICPR.2016.7899892
   Furlan A., 2013, BRIT MACH VIS C BMVC
   Geiger A, 2012, IEEE INT CONF ROBOT, P3936, DOI 10.1109/ICRA.2012.6224570
   Hedau V, 2010, LECT NOTES COMPUT SC, V6316, P224, DOI 10.1007/978-3-642-15567-3_17
   Hedau V, 2009, IEEE I CONF COMP VIS, P1849, DOI 10.1109/ICCV.2009.5459411
   Herrera CD, 2012, IEEE T PATTERN ANAL, V34, P2058, DOI 10.1109/TPAMI.2012.125
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Iglesias J, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P2506, DOI 10.1109/IROS.2016.7759390
   Jia HC, 2015, IEEE INT CONF ROBOT, P4851, DOI 10.1109/ICRA.2015.7139873
   Jia HC, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P818, DOI 10.1109/ACPR.2013.148
   Lee CY, 2017, IEEE I CONF COMP VIS, P4875, DOI 10.1109/ICCV.2017.521
   Lee DC, 2009, PROC CVPR IEEE, P2136, DOI 10.1109/CVPRW.2009.5206872
   López-Nicolás G, 2014, ROBOT AUTON SYST, V62, P1271, DOI 10.1016/j.robot.2014.03.018
   Mallya A, 2015, IEEE I CONF COMP VIS, P936, DOI 10.1109/ICCV.2015.113
   Perez-Yus A, 2016, INT C PATT RECOG, P2789, DOI 10.1109/ICPR.2016.7900058
   Perez-Yus A, 2017, COMPUT VIS IMAGE UND, V154, P192, DOI 10.1016/j.cviu.2016.04.007
   Perez-Yus A, 2018, IEEE ROBOT AUTOM LET, V3, P273, DOI 10.1109/LRA.2017.2739104
   Perez-Yus A, 2016, LECT NOTES COMPUT SC, V9912, P396, DOI 10.1007/978-3-319-46484-8_24
   Puig L, 2012, COMPUT VIS IMAGE UND, V116, P120, DOI 10.1016/j.cviu.2011.08.003
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Ramalingam S, 2013, PROC CVPR IEEE, P3065, DOI 10.1109/CVPR.2013.394
   Savarese S., 2017, Joint 2d-3d-semantic data for indoor scene understanding
   Scaramuzza Davide, 2007, 2007 IEEE/RSJ International Conference on Intelligent Robots and Systems, P4164, DOI 10.1109/IROS.2007.4399276
   Scaramuzza D, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P5695, DOI 10.1109/IROS.2006.282372
   Schwing AG, 2013, IEEE I CONF COMP VIS, P353, DOI 10.1109/ICCV.2013.51
   Schwing AG, 2012, PROC CVPR IEEE, P2815, DOI 10.1109/CVPR.2012.6248006
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Tomari R, 2012, LECT NOTES COMPUT SC, V7432, P526, DOI 10.1007/978-3-642-33191-6_52
   von Gioi RG, 2010, IEEE T PATTERN ANAL, V32, P722, DOI 10.1109/TPAMI.2008.300
   Walton DR, 2017, PROCEEDINGS OF THE 2017 IEEE INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY (ISMAR), P72, DOI 10.1109/ISMAR.2017.24
   Xu J, 2017, IEEE WINT CONF APPL, P354, DOI 10.1109/WACV.2017.46
   Yang H, 2016, PROC CVPR IEEE, P5422, DOI 10.1109/CVPR.2016.585
   Zhang Q. L., 2004, 2004 IEEERSJ INT C I, P2301
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang WD, 2017, IEEE T MULTIMEDIA, V19, P935, DOI 10.1109/TMM.2016.2642780
   Zhang Y., 2015, COMP VIS PATT REC WO
   Zhang YD, 2014, LECT NOTES COMPUT SC, V8694, P668, DOI 10.1007/978-3-319-10599-4_43
NR 53
TC 1
Z9 1
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2019
VL 87
BP 76
EP 96
DI 10.1016/j.imavis.2019.04.008
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IF3NV
UT WOS:000472988400008
DA 2024-07-18
ER

PT J
AU Lin, WA
   Chen, JC
   Ranjan, R
   Bansal, A
   Sankaranarayanan, S
   Castillo, CD
   Chellappa, R
AF Lin, Wei-An
   Chen, Jun-Cheng
   Ranjan, Rajeev
   Bansal, Ankan
   Sankaranarayanan, Swami
   Castillo, Carlos D.
   Chellappa, Rama
TI Proximity-Aware Hierarchical Clustering of unconstrained faces
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th IEEE International Conference on Automatic Face and Gesture
   Recognition (FG)
CY MAY 30-JUN 03, 2017
CL Washington, DC
SP IEEE, Baidu, Mitsubishi Elect Res Labs Inc, 3dMD, DI4D, Syst & Technol Res, ObjectVideo Labs, MUKH Technologies, IEEE Comp Soc
DE Face recognition; Clustering
ID ALGORITHM
AB In this paper, we propose an unsupervised face clustering algorithm called "Proximity-Aware Hierarchical Clustering" (PAHC) that exploits the local structure of deep representations. In the proposed method, a similarity measure between deep features is computed by evaluating linear SVM margins, which are learned using nearest neighbors of sample data. Clusters are then formed by applying agglomerative hierarchical clustering (AHC). We evaluate the clustering performance using four unconstrained face datasets, including Celebrity in Frontal-Profile (CFP), Labeled Faces in the Wild (LFW), IARPA JANUS Benchmark A (IJB-A), and IARPA JANUS Benchmark B (IJB-B) datasets. Experimental results demonstrate that the proposed approach can achieve improved performance over state-of-the-art methods. Moreover, we show the proposed clustering algorithm has the potential to be applied to actively learn robust deep face representations by first harvesting sufficient number of unseen face images through curation of large-scale dataset, e.g. the MS-Celeb-1 M dataset. By training DCNNs on the curated MS-Celeb-1 M dataset which contains over three million face images, improved representation for face images are learned. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Lin, Wei-An; Chen, Jun-Cheng; Ranjan, Rajeev; Bansal, Ankan; Sankaranarayanan, Swami; Castillo, Carlos D.; Chellappa, Rama] Univ Maryland, College Pk, MD 20742 USA.
C3 University System of Maryland; University of Maryland College Park
RP Lin, WA (corresponding author), Univ Maryland, College Pk, MD 20742 USA.
EM walin@umd.edu; pullpull@cs.umd.edu; rranjan1@umd.edu;
   ankan@umiacs.umd.edu; swamiviv@umiacs.umd.edu; carlos@umiacs.umd.edu;
   rama@umiacs.umd.edu
RI Chen, Jun-Cheng/ABC-4218-2020; Castillo-Araiza, Carlos O./M-6725-2017;
   Chellappa, Rama/AAV-8690-2020; Chellappa, Rama/B-6573-2012;
   Sankaranarayanan, Swami/AFP-9228-2022
OI Chen, Jun-Cheng/0000-0002-0209-8932; Castillo,
   Carlos/0000-0001-5308-4824
FU Office of the Director of National Intelligence (ODNI), Intelligence
   Advanced Research Projects Activity (IARPA), via IARPA RD
   [2014-14071600012]
FX This research is based upon work supported by the Office of the Director
   of National Intelligence (ODNI), Intelligence Advanced Research Projects
   Activity (IARPA), via IARPA R&D Contract No. 2014-14071600012. The views
   and conclusions contained herein are those of the authors and should not
   be interpreted as necessarily representing the official policies or
   endorsements, either expressed or implied, of the ODNI, IARPA, or the
   U.S. Government. The U.S. Government is authorized to reproduce and
   distribute reprints for Governmental purposes notwithstanding any
   copyright annotation thereon.
CR Amigó E, 2009, INFORM RETRIEVAL, V12, P461, DOI 10.1007/s10791-008-9066-8
   [Anonymous], 2017, DENSELY CONNECTED CO
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], 2016, IEEE WINT C APPL COM
   [Anonymous], 2008, LABELED FACES WILD D
   [Anonymous], 2014, IEEE C COMP VIS PATT
   [Anonymous], 2017, COMMUN ACM, DOI DOI 10.1145/3065386
   [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], 2009, IEEE C COMP VIS PATT
   [Anonymous], 2015, P IEEE C COMP VIS PA
   [Anonymous], 2017, IEEE Transactions on Pattern Analysis and Machine Intelligence
   [Anonymous], OPEN SET DOMAIN ADAP
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ARXIV170605067
   [Anonymous], 2017, ADVERSARIAL DISCRIMI
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], 2014, LEARNING FACE REPRES
   [Anonymous], 2015, UNSUPERVISED DOMAIN
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], 2016, IEEE C COMP VIS PATT
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Fanti C, 2004, ADV NEUR IN, V16, P1603
   GOWDA KC, 1978, PATTERN RECOGN, V10, P105
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   James M., 1967, PROC BERKELEY S MATH, V1, P281, DOI DOI 10.1007/S11665-016-2173-6
   Kasabov N, 2016, 2016 IEEE 8TH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS (IS), P15, DOI 10.1109/IS.2016.7737434
   KURITA T, 1991, PATTERN RECOGN, V24, P205, DOI 10.1016/0031-3203(91)90062-A
   Lin WA, 2017, IEEE INT CONF AUTOMA, P294, DOI 10.1109/FG.2017.134
   Liu GC, 2011, IEEE I CONF COMP VIS, P1615, DOI 10.1109/ICCV.2011.6126422
   Long M., 2017, DEEP TRANSFER LEARNI
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Patel VM, 2015, IEEE J-STSP, V9, P691, DOI 10.1109/JSTSP.2015.2402643
   Ranjan R, 2017, IEEE INT CONF AUTOMA, P17, DOI 10.1109/FG.2017.137
   Ranjan Rajeev, 2017, L2-constrained softmax loss for discriminative face verification
   Sankaranarayanan Swami., 2017, CoRR
   Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Simonyan K., 2014, Very Deep Convolutional Networks for Large-Scale Image Recognition
   Vidal R, 2014, PATTERN RECOGN LETT, V43, P47, DOI 10.1016/j.patrec.2013.08.006
   Zhi CH, 2011, PROC CVPR IEEE, P481, DOI 10.1109/CVPR.2011.5995680
NR 41
TC 2
Z9 3
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2018
VL 77
BP 33
EP 44
DI 10.1016/j.imavis.2018.06.007
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA GV7DT
UT WOS:000446282900004
DA 2024-07-18
ER

PT J
AU Koringa, PA
   Mitra, SK
AF Koringa, Purvi A.
   Mitra, Suman K.
TI ONPPn: Orthogonal Neighborhood Preserving Projection with Normalization
   and its applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dimensionality reduction; Orthogonality; Normalization; Neighborhood
   preserving projection
ID DIMENSIONALITY REDUCTION; DISCRIMINANT-ANALYSIS; FACE RECOGNITION
AB Subspace analysis or dimensionality reduction techniques are becoming very popular for many computer vision tasks such as image recognition. Most of such techniques deal with optimizing a cost function based on some criteria imposed on either projections of data or on the basis of projection space. NPP and ONPP are such linear methods that preserve local linear relationship within the neighborhood, with two different constraints, normalized projection and orthogonal basis of subspace respectively. This article proposes a method, ONPPn, that finds a subspace which satisfies two constraints namely, normalization and orthogonality. The article also provides two-dimensional variant of ONPPn. Experiments show that ONPPn outperforms its NPP and ONPP versions in image recognition tasks, whereas 2D-ONPPn outperforms 2D-ONPP by huge margin but does not perform as good as 2D-NPP. 2D-NPP as well as 2D-ONPP are not suitable for reconstruction task, but the proposed method 2D-ONPPn overcomes drawbacks of existing methods and is best suited for image reconstruction, too. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Koringa, Purvi A.; Mitra, Suman K.] Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar, India.
C3 Dhirubhai Ambani Institute of Information & Communication Technology
RP Koringa, PA (corresponding author), Dhirubhai Ambani Inst Informat & Commun Technol, Gandhinagar, India.
EM 201321010@daiict.ac.in
RI Koringa, Purvi/ABB-6960-2021
OI Koringa, Purvi/0000-0003-4350-5378
CR [Anonymous], 2003, Advances in Neural Informaiton Processing Systems
   [Anonymous], 2004, INDEPENDENT COMPONEN
   Battacharya U, 2005, PROC INT CONF DOC, P789
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   DUCHENE J, 1988, IEEE T PATTERN ANAL, V10, P978, DOI 10.1109/34.9121
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Graham Daniel B, 1998, CHARACTERISING VIRTU, P446
   Gui J, 2014, IEEE T IMAGE PROCESS, V23, P3126, DOI 10.1109/TIP.2014.2326001
   Gui J, 2014, IEEE T CIRC SYST VID, V24, P211, DOI 10.1109/TCSVT.2013.2273652
   Gui J, 2012, PATTERN RECOGN, V45, P2884, DOI 10.1016/j.patcog.2012.02.005
   Gui J, 2010, ARTIF INTELL MED, V50, P181, DOI 10.1016/j.artmed.2010.05.004
   Gui J, 2010, NEUROCOMPUTING, V73, P2696, DOI 10.1016/j.neucom.2010.04.017
   He XF, 2005, IEEE I CONF COMP VIS, P1208
   He XF, 2004, ADV NEUR IN, V16, P153
   Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131
   Kong H, 2005, NEURAL NETWORKS, V18, P585, DOI 10.1016/j.neunet.2005.06.041
   Koringa Purvi, 2015, Pattern Recognition and Machine Intelligence. 6th International Conference, PReMI 2015. Proceedings: LNCS 9124, P225, DOI 10.1007/978-3-319-19941-2_22
   Koringa PA, 2017, ICPRAM: PROCEEDINGS OF THE 6TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P165, DOI 10.5220/0006196101650172
   LeCun Y., 1998, MNIST DATABASE HANDW
   Li M, 2005, PATTERN RECOGN LETT, V26, P527, DOI 10.1016/j.patrec.2004.09.007
   Liu HY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2308
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P195, DOI 10.1109/TNN.2002.806647
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Nagar R, 2015, P 8 INT C ADV PATT R, P1, DOI [10.1109/ICAPR.2015.7050654, DOI 10.1109/ICAPR.2015.7050654]
   Nie FP, 2009, PATTERN RECOGN, V42, P105, DOI 10.1016/j.patcog.2008.03.012
   Nie FP, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P977, DOI 10.1145/2623330.2623726
   Nie FP, 2010, IEEE T IMAGE PROCESS, V19, P1921, DOI 10.1109/TIP.2010.2044958
   Nie FP, 2009, OPT ENG, V48, DOI 10.1117/1.3067869
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Sacha D, 2016, IEEE T VIS COMPUT GR, V22, P240, DOI 10.1109/TVCG.2015.2467591
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Saul LK, 2004, J MACH LEARN RES, V4, P119, DOI 10.1162/153244304322972667
   Shikkenawis G., 2016, THESIS
   Shikkenawis G, 2016, IEEE T IMAGE PROCESS, V25, P262, DOI 10.1109/TIP.2015.2501753
   Shikkenawis G, 2016, NEUROCOMPUTING, V173, P196, DOI 10.1016/j.neucom.2015.01.100
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang H, 2014, PR MACH LEARN RES, V32, P1836
   Zhang HJ, 2012, PATTERN RECOGN, V45, P1866, DOI 10.1016/j.patcog.2011.11.002
   Zhang TH, 2010, IEEE T SYST MAN CY B, V40, P253, DOI 10.1109/TSMCB.2009.2027473
NR 40
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2018
VL 76
BP 64
EP 75
DI 10.1016/j.imavis.2018.06.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GR1TB
UT WOS:000442333500006
DA 2024-07-18
ER

PT J
AU Cristina, S
   Camilleri, KP
AF Cristina, Stefania
   Camilleri, Kenneth P.
TI Unobtrusive and pervasive video-based eye-gaze tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Review; Eye-gaze tracking; Pervasive; Unobtrusive; Passive
ID LOCALIZATION; CALIBRATION; ALGORITHM; FEATURES; SYSTEM
AB Eye-gaze tracking has long been considered a desktop technology that finds its use inside the traditional office setting, where the operating conditions may be controlled. Nonetheless, recent advancements in mobile technology and a growing interest in capturing natural human behaviour have motivated an emerging interest in tracking eye movements within unconstrained real-life conditions, referred to as pervasive eye-gaze tracking. This critical review focuses on emerging passive and unobtrusive video-based eye-gaze tracking methods in recent literature, with the aim to identify different research avenues that are being followed in response to the challenges of pervasive eye-gaze tracking. Different eye-gaze tracking approaches are discussed in order to bring out their strengths and weaknesses, and to identify any limitations, within the context of pervasive eye-gaze tracking, that have yet to be considered by the computer vision community. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Cristina, Stefania; Camilleri, Kenneth P.] Univ Malta, Dept Syst & Control Engn, MSD-2080 Msida, Malta.
C3 University of Malta
RP Cristina, S (corresponding author), Univ Malta, Dept Syst & Control Engn, MSD-2080 Msida, Malta.
EM stefania.cristina@um.edu.mt; kenneth.camilleri@um.edu.mt
RI Camilleri, Kenneth P./AAJ-1468-2020
OI Camilleri, Kenneth P./0000-0003-0436-6408; Cristina,
   Stefania/0000-0003-4617-7998
FU WildEye by the Malta Council for Science and Technology through FUSION:
   The R&I Technology Development Programme [RI-2016-010-V]
FX This work forms part of the project R&I-2016-010-V WildEye financed by
   the Malta Council for Science and Technology through FUSION: The R&I
   Technology Development Programme 2016.
CR Abdel-Kader RF, 2014, ENG APPL ARTIF INTEL, V31, P90, DOI 10.1016/j.engappai.2013.06.017
   Akashi T., 2007, Journal of Systemics, Cybernetics and Informatics, V5, P72
   Al-Rahayfeh A., 2014, IEEE LONG ISL SYST A, P1
   Alnajar F, 2013, IEEE I CONF COMP VIS, P137, DOI 10.1109/ICCV.2013.24
   [Anonymous], SEM DEV RES S 2009 I
   [Anonymous], 2014, P ACM INT JOINT C PE, DOI DOI 10.1145/2638728.2641694
   [Anonymous], 2012, J VISUAL EXPT
   [Anonymous], 2010, P 2010 S EYE TRACK R
   [Anonymous], P INT C ADV COMP EL
   [Anonymous], 2011, CALIBRATION GAMES MA, DOI DOI 10.1145/2047196.2047248
   Asteriadis S., 2009, P INT WORKSH AFF AW
   Asteriadis S, 2014, INT J COMPUT VISION, V107, P293, DOI 10.1007/s11263-013-0691-3
   Baek SJ, 2013, IEEE T CONSUM ELECTR, V59, P415, DOI 10.1109/TCE.2013.6531125
   Barea R, 2002, IEEE T NEUR SYS REH, V10, P209, DOI 10.1109/TNSRE.2002.806829
   Bhoi N., 2010, INT J COMPUTER APPL, V12, P15, DOI [10.5120/1676-2262, DOI 10.5120/1676-2262]
   Bong David B. L., 2009, International Journal of Intelligent Information Technology Application, V2, P121
   Bulling A., 2011, 1 INT WORKSH PERV EY, P627
   Cai H, 2012, VIRTUAL REAL-LONDON, V16, P25, DOI 10.1007/s10055-010-0171-9
   Camus TA, 2002, INT C PATT RECOG, P389, DOI 10.1109/ICPR.2002.1044732
   Chen BC, 2015, IEEE IMAGE PROC, P715, DOI 10.1109/ICIP.2015.7350892
   Chen JX, 2015, IEEE T IMAGE PROCESS, V24, P1076, DOI 10.1109/TIP.2014.2383326
   Chen JX, 2011, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.2011.5995675
   Chen Jixu, 2008, 2008 19 INT C PATT R, P1
   Cristina S., 2015, J ADV SOFTW, V8, P327
   Cristina S., 2014, 8 INT C ADV ENG COMP, P126
   Cristina S, 2016, MACH VISION APPL, V27, P1229, DOI 10.1007/s00138-016-0791-5
   Cristina S, 2016, COMPUT VIS IMAGE UND, V149, P157, DOI 10.1016/j.cviu.2016.02.012
   Czuprynski B, 2014, LECT NOTES COMPUT SC, V8610, P407, DOI 10.1007/978-3-319-09912-5_34
   D'Orazio T, 2004, INT C PATT RECOG, P278, DOI 10.1109/ICPR.2004.1334521
   Dehkordi E. G., 2013, INT J COMPUT SCI ISS, V10, P107
   Demjén E, 2011, PHYSIOL RES, V60, P841, DOI 10.33549/physiolres.932117
   Egger B, 2014, LECT NOTES COMPUT SC, V8753, P317, DOI 10.1007/978-3-319-11752-2_25
   Evans KM, 2012, J EYE MOVEMENT RES, V5
   Fard PJM, 2007, IFMBE PROC, V14, P2407
   Funes Mora KennethAlberto., 2012, Computer Vision and Pattern Recognition Workshops (CVPRW), 2012 IEEE Computer Society Conference on, P25, DOI DOI 10.1109/CVPRW.2012.6239182
   Galdi Chiara, 2013, Pattern Recognition. 5th Mexican Conference, MCPR 2013. Proceedings: LNCS 7914, P136, DOI 10.1007/978-3-642-38989-4_14
   Galdi C, 2016, PATTERN RECOGN LETT, V84, P272, DOI 10.1016/j.patrec.2016.11.002
   Gentry L., 2007, J INT MANAGEMENT AUG, P60
   George A., 2016, 2016 IEEE High Performance Extreme Computing Conference (HPEC), P1, DOI DOI 10.1109/HPEC.2016.7761639
   Hammal Z, 2004, 6th IEEE Southwest Symposium on Image Analysis and Interpretation, P138, DOI 10.1109/IAI.2004.1300961
   Hammal Z, 2005, LECT NOTES COMPUT SC, V3687, P236
   Hansen DW, 2010, IEEE T PATTERN ANAL, V32, P478, DOI 10.1109/TPAMI.2009.30
   Heinzmann J., 1997, 3 IEEE INT C AUT FAC, P142
   Holland C., 2012, P S EYE TRACKING RES, P277
   Huang MX, 2016, 34TH ANNUAL CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, CHI 2016, P5169, DOI 10.1145/2858036.2858404
   Huang MX, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1017, DOI 10.1145/2647868.2655031
   Huang Q., 2016, ARXIV150801244V3CSCV
   Ince IF, 2011, EURASIP J ADV SIG PR, DOI 10.1186/1687-6180-2011-40
   Ishikawa T., 2004, 11 WORD C ITS NAG, P100
   Jacob R. J. K., 1990, SIGCHI Bulletin, P11
   Janko Zsolt, 2012, 2012 IEEE 3rd International Conference on Cognitive Infocommunications (CogInfoCom 2012), P155
   Jeni LA, 2016, IEEE COMPUT SOC CONF, P792, DOI 10.1109/CVPRW.2016.104
   Kar A, 2016, IEEE SYS MAN CYBERN, P2061, DOI 10.1109/SMC.2016.7844543
   Khamis M., 2017, 30 ANN ACM S US INT, P1
   Khan MI, 2008, LECT NOTES COMPUT SC, V5112, P729, DOI 10.1007/978-3-540-69812-8_72
   Kim S, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2683, DOI 10.1109/IJCNN.2011.6033570
   Klefenz F, 2010, INT CONF ACOUST SPEE, P762, DOI 10.1109/ICASSP.2010.5495004
   Ko J. G., 2000, P INT C CIRC SYST CO, P415
   Kohlbecher S., 2012, P GAZ HUM ROB INT WO
   Kohlbecher S, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P135, DOI 10.1145/1344471.1344506
   Kothari R, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P519, DOI 10.1109/ICIP.1996.560546
   Koutras P, 2015, IEEE IMAGE PROC, P2424, DOI 10.1109/ICIP.2015.7351237
   Krafka K, 2016, PROC CVPR IEEE, P2176, DOI 10.1109/CVPR.2016.239
   Kunze K., 2013, P 2013 ACM C PERVASI, P283
   Kyung-Nam Kim, 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P324, DOI 10.1109/ICSMC.1999.825279
   Lai CC, 2014, INT C PATT RECOG, P1869, DOI 10.1109/ICPR.2014.327
   Lee JW, 2013, SENSORS-BASEL, V13, P10802, DOI 10.3390/s130810802
   Lee SJ, 2011, IEEE T INTELL TRANSP, V12, P254, DOI 10.1109/TITS.2010.2091503
   Leimberg D., 2005, P SVENSK S BILD
   Levine J. L., 1981, RC8857 TJ WATS RES C
   Li-Qun Xu, 1998, BMVC 98. Proceedings of the Ninth British Machine Vision Conference, P428
   Liang K., 2013, P 2013 C EYE TRACK S, P17
   Lin YT, 2013, MULTIMED TOOLS APPL, V65, P543, DOI 10.1007/s11042-012-1202-1
   Liu Y, 2017, PROCEEDINGS OF THE FIFTEENTH IAPR INTERNATIONAL CONFERENCE ON MACHINE VISION APPLICATIONS - MVA2017, P219, DOI 10.23919/MVA.2017.7986840
   Lu F, 2017, IEEE T IMAGE PROCESS, V26, P1543, DOI 10.1109/TIP.2017.2657880
   Lu F, 2016, IEEE T MULTIMEDIA, V18, P1772, DOI 10.1109/TMM.2016.2576284
   Lu F, 2016, NEUROCOMPUTING, V182, P10, DOI 10.1016/j.neucom.2015.07.125
   Lu F, 2014, IEEE T PATTERN ANAL, V36, P2033, DOI 10.1109/TPAMI.2014.2313123
   Lu F, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.126
   Lu F, 2011, IEEE I CONF COMP VIS, P153, DOI 10.1109/ICCV.2011.6126237
   Mansanet J, 2013, LECT NOTES COMPUT SC, V7887, P881
   Markus N, 2014, PATTERN RECOGN, V47, P578, DOI 10.1016/j.patcog.2013.08.008
   Martinez F, 2012, IEEE IMAGE PROC, P1961, DOI 10.1109/ICIP.2012.6467271
   Matsumoto Y., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P499, DOI 10.1109/AFGR.2000.840680
   Merad D, 2006, ICINCO 2006: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS, P326
   Model D, 2010, IEEE T BIO-MED ENG, V57, P1031, DOI 10.1109/TBME.2009.2039351
   Moore D., 2011, Disabled students in education: Technology, transition, and inclusivity
   Mora K. A. F., 2014, IEEE C COMP VIS PATT, P4321
   Mora KAF, 2014, PROC CVPR IEEE, P1773, DOI 10.1109/CVPR.2014.229
   Mora KAF, 2013, IEEE IMAGE PROC, P2787, DOI 10.1109/ICIP.2013.6738574
   Moriyama T, 2006, IEEE T PATTERN ANAL, V28, P738, DOI 10.1109/TPAMI.2006.98
   Motwani M. C., 2004, P GSPX, V27, P27
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Nagamatsu T., 2013, INT WORKSH PERV EYE, P125
   Nguyen B.L., 2010, Proceedings of the 2010 Symposium on Information and Communication Technology, New York, NY, USA, P108, DOI DOI 10.1145/1852611.1852632
   Cuong NH, 2010, I C CONT AUTOMAT ROB, P2507, DOI 10.1109/ICARCV.2010.5707319
   Nitschke C, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P298, DOI 10.1109/ACPR.2013.84
   Noris B, 2008, VISAPP 2008: PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P611
   Ohtera R, 2007, LECT NOTES COMPUT SC, V4843, P708
   Papoutsaki A., 2016, P 25 INT JOINT C ART, P3839
   Pfeuffer K., 2013, P 26 ANN ACM S US IN, P261, DOI [DOI 10.1145/2501988.2501998, 10.1145/2501988.2501998]
   Pino C, 2012, FED CONF COMPUT SCI, P1199
   Piratla NM, 2002, J NETW COMPUT APPL, V25, P179, DOI 10.1006/jnca.2002.0142
   Pogalin E, 2007, THIRD INTERNATIONAL SYMPOSIUM ON 3D DATA PROCESSING, VISUALIZATION, AND TRANSMISSION, PROCEEDINGS, P57
   Rajpathak T., 2009, PROC FLORIDA C RECEN, P1
   Reale M., 2010, P IEEE COMP SOC C CO, P24
   Reale MJ, 2011, IEEE T MULTIMEDIA, V13, P474, DOI 10.1109/TMM.2011.2120600
   REMMEL RS, 1984, IEEE T BIO-MED ENG, V31, P388, DOI 10.1109/TBME.1984.325352
   Rigas I, 2017, IMAGE VISION COMPUT, V58, P129, DOI 10.1016/j.imavis.2016.03.014
   Rigas I, 2016, INFORM FUSION, V32, P13, DOI 10.1016/j.inffus.2015.08.003
   Ronsse R, 2007, J NEUROSCI METH, V159, P158, DOI 10.1016/j.jneumeth.2006.06.016
   Schneider T, 2014, INT C PATT RECOG, P1167, DOI 10.1109/ICPR.2014.210
   Sewell W., 2010, CHI 10 EXTENDED ABST, P3739, DOI DOI 10.1145/1753846.1754048
   SHAHID M, 2013, LIFE SCI J, V10, P1571
   Singh H., 2011, IND INT C POW EL 201, DOI [10.1109/IICPE.2011.5728062, DOI 10.1109/IICPE.2011.5728062]
   Smith P, 2000, INT C PATT RECOG, P636, DOI 10.1109/ICPR.2000.902999
   Stiefelhagen R, 1997, INT CONF ACOUST SPEE, P2617, DOI 10.1109/ICASSP.1997.595325
   Stiefelhagen R., 1997, Proceedings of the Workshop on Perceptual User Interfaces (PUI97), P98
   Sugano Y, 2015, IEEE T HUM-MACH SYST, V45, P750, DOI 10.1109/THMS.2015.2400434
   Sugano Y, 2014, PROC CVPR IEEE, P1821, DOI 10.1109/CVPR.2014.235
   Sugano Y, 2010, PROC CVPR IEEE, P2667, DOI 10.1109/CVPR.2010.5539984
   Szeliski R., 2011, COMPUTER VISION ALGO
   Takemura K., 2014, PROC 2014 S EYE TRAC, P251
   Tan KH, 2002, SIXTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P191, DOI 10.1109/ACV.2002.1182180
   Huynh TH, 2013, IEEE SYM COMP INT CO, P24, DOI 10.1109/CICA.2013.6611659
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Toennies K., 2002, PATT REC 2002 P 16 I, V2, P1053
   Urano R, 2014, IEEE ASME INT C ADV, P1157, DOI 10.1109/AIM.2014.6878237
   Utsumi A., 2012, SOURC EYE TRACK RES, P273, DOI DOI 10.1145/2168556.2168614
   Valenti Roberto, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3870, DOI 10.1109/ICPR.2010.1160
   Valenti R, 2012, INT J COMPUT VISION, V98, P324, DOI 10.1007/s11263-011-0511-6
   Valenti R, 2012, IEEE T IMAGE PROCESS, V21, P802, DOI 10.1109/TIP.2011.2162740
   Valenti R, 2009, LECT NOTES COMPUT SC, V5716, P662, DOI 10.1007/978-3-642-04146-4_71
   Valenti Roberto., 2008, 2008 IEEE Conference on Computer Vision and Pattern Recognition, P1
   Vezhnevets V., 2003, P GRAPHICON, P81
   Wang HB, 2010, LECT NOTES COMPUT SC, V5995, P120
   Wang HG, 2005, COMPUT VIS IMAGE UND, V98, P83, DOI 10.1016/j.cviu.2004.07.008
   Wang HG, 2001, IMAGE VISION COMPUT, V19, P891, DOI 10.1016/S0262-8856(01)00051-8
   Weidenbacher U, 2006, LECT NOTES ARTIF INT, V4021, P9
   Wibirama Sunu, 2009, 2009 6th International Conference on Electrical Engineering/Electronics, Computer, Telecommunications and Information Technology (ECTI-CON), P1054, DOI 10.1109/ECTICON.2009.5137226
   Wibirama S., 2008, 3 INT S BIOM ENG, P84
   Wojciechowski A, 2015, B POL ACAD SCI-TECH, V63, P879, DOI 10.1515/bpasts-2015-0100
   Wojke N., 2016, Pattern Recognition and Image Analysis, V26, P248, DOI 10.1134/S1054661816010296
   Wood E., 2014, P S EYE TRACK RES AP, P207, DOI DOI 10.1145/2578153.2578185
   Wood E, 2016, 2016 ACM SYMPOSIUM ON EYE TRACKING RESEARCH & APPLICATIONS (ETRA 2016), P131, DOI 10.1145/2857491.2857492
   Wood E, 2016, LECT NOTES COMPUT SC, V9905, P297, DOI 10.1007/978-3-319-46448-0_18
   Wood E, 2015, IEEE I CONF COMP VIS, P3756, DOI 10.1109/ICCV.2015.428
   Wu HY, 2007, LECT NOTES COMPUT SC, V4843, P688
   Xiong CS, 2014, INT C PATT RECOG, P1156, DOI 10.1109/ICPR.2014.208
   Yamazoe H, 2008, PROCEEDINGS OF THE EYE TRACKING RESEARCH AND APPLICATIONS SYMPOSIUM (ETRA 2008), P245, DOI 10.1145/1344471.1344527
   Zhang Y., 2012, PHOTODIODES FROM FUN, P261
   Zhang YX, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL WORKING CONFERENCE ON ADVANCED VISUAL INTERFACES, AVI 2014, P129, DOI 10.1145/2598153.2598186
   Zhang YX, 2015, PERS UBIQUIT COMPUT, V19, P967, DOI 10.1007/s00779-015-0866-8
   Zhang Yanxia., 2013, P SIGCHI C HUMAN FAC, P851, DOI DOI 10.1145/2470654.2470775
   Zhu DJ, 1999, COMPUT METH PROG BIO, V59, P145, DOI 10.1016/S0169-2607(98)00105-9
   Zhu J, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P131, DOI 10.1109/AFGR.2002.1004144
NR 156
TC 19
Z9 23
U1 14
U2 94
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2018
VL 74
BP 21
EP 40
DI 10.1016/j.imavis.2018.04.002
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GJ9UE
UT WOS:000435749600003
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Cordts, M
   Rehfeld, T
   Schneider, L
   Pfeiffer, D
   Enzweiler, M
   Roth, S
   Pollefeys, M
   Franke, U
AF Cordts, Marius
   Rehfeld, Timo
   Schneider, Lukas
   Pfeiffer, David
   Enzweiler, Markus
   Roth, Stefan
   Pollefeys, Marc
   Franke, Uwe
TI The Stixel World: A medium-level representation of traffic scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Stereo-vision; Automotive vision; Intelligent vehicles; Scene
   understanding
AB Recent progress in advanced driver assistance systems and the race towards autonomous vehicles is mainly driven by two factors: (1) increasingly sophisticated algorithms that interpret the environment around the vehicle and react accordingly, and (2) the continuous improvements of sensor technology itself. In terms of cameras, these improvements typically include higher spatial resolution, which as a consequence requires more data to be processed. The trend to add multiple cameras to cover the entire surrounding of the vehicle is not conducive in that matter. At the same time, an increasing number of special purpose algorithms need access to the sensor input data to correctly interpret the various complex situations that can occur, particularly in urban traffic.
   By observing those trends, it becomes clear that a key challenge for vision architectures in intelligent vehicles is to share computational resources. We believe this challenge should be faced by introducing a representation of the sensory data that provides compressed and structured access to all relevant visual content of the scene. The Stixel World discussed in this paper is such a representation. It is a medium-level model of the environment that is specifically designed to compress information about obstacles by leveraging the typical layout of outdoor traffic scenes. It has proven useful for a multitude of automotive vision applications, including object detection, tracking, segmentation, and mapping.
   In this paper, we summarize the ideas behind the model and generalize it to take into account multiple dense input streams: the image itself, stereo depth maps, and semantic class probability maps that can be generated, e.g., by deep convolutional neural networks. Our generalization is embedded into a novel mathematical formulation for the Stixel model. We further sketch how the free parameters of the model can be learned using structured SVMs. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Cordts, Marius; Schneider, Lukas; Pfeiffer, David; Enzweiler, Markus; Franke, Uwe] Daimler AG, R&D, Dept Environm Percept, Sindelfingen, Germany.
   [Rehfeld, Timo] Mercedes Benz R&D North Amer, Sunnyvale, CA USA.
   [Cordts, Marius; Rehfeld, Timo; Roth, Stefan] Tech Univ Darmstadt, Dept Visual Inference, Darmstadt, Germany.
   [Pollefeys, Marc] Microsoft HoloLens, Seattle, WA USA.
   [Schneider, Lukas; Pollefeys, Marc] Swiss Fed Inst Technol, lnst Visual Comp, Zurich, Switzerland.
C3 Daimler AG; Technical University of Darmstadt; Swiss Federal Institutes
   of Technology Domain; ETH Zurich
RP Cordts, M (corresponding author), Daimler AG, R&D, Dept Environm Percept, Sindelfingen, Germany.
EM marius.cordts@daimler.com
RI Pollefeys, Marc/I-7607-2013
OI Pollefeys, Marc/0000-0003-2448-2318; Roth, Stefan/0000-0001-9002-9832
CR Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   [Anonymous], IEEE INT VEH S GOLD
   [Anonymous], IEEE INT VEH S GOLD
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], FDN TRENDS COMPUT GR
   [Anonymous], DAGM S
   [Anonymous], ARXIV150401013V2CSCV
   [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], THESIS
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INT VEH S GOLD
   [Anonymous], 2015, ARXIV151102680V1CSCV
   [Anonymous], BRIT MACH VIS C
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2016, IEEE C COMP VIS PATT
   [Anonymous], GERM C PATT REC
   [Anonymous], 2015, INT C COMP VIS
   [Anonymous], INT C COMP VIS WORKS
   [Anonymous], 2010, IEEE C COMP VIS PATT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], CVVT WORKSH ECCV
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], BRIT MACH VIS C
   [Anonymous], EUR C COMP VIS
   [Anonymous], 2014, INT J COMPUT VIS
   [Anonymous], IEEE INT VEH S GOLD
   [Anonymous], INT C COMP VIS SYST
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], IEEE INTELL TRANSP S
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], BRIT MACH VIS C
   [Anonymous], 2013, INT J COMPUT VIS
   [Anonymous], CAN C COMP ROB VIS
   [Anonymous], IEEE INT C INF FUS
   [Anonymous], IEEE C INT TRANSP SY
   [Anonymous], LAYERED INTERPRETATI
   [Anonymous], IEEE INT VEH S GOLD
   [Anonymous], 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298965
   [Anonymous], 2015, INT C COMP VIS
   Carreira J, 2012, IEEE T PATTERN ANAL, V34, P1312, DOI 10.1109/TPAMI.2011.231
   Chen L, 2015, 3 INT C LEARNING REP
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Dhiman V, 2014, IEEE INT CONF ROBOT, P2037, DOI 10.1109/ICRA.2014.6907129
   Felzenszwalb PF, 2004, INT J COMPUT VISION, V59, P167, DOI 10.1023/B:VISI.0000022288.19776.77
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Girshick R., 2014, P IEEE C COMP VIS PA, P580
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI 10.1109/TPAMl.2007.1166
   Hoiem D, 2007, INT J COMPUT VISION, V75, P151, DOI 10.1007/s11263-006-0031-y
   Levinshtein A, 2009, IEEE T PATTERN ANAL, V31, P2290, DOI 10.1109/TPAMI.2009.96
   Sengupta S, 2013, IEEE INT CONF ROBOT, P580, DOI 10.1109/ICRA.2013.6630632
   Thrun S., 2002, Robotic mapping: A survey
NR 56
TC 18
Z9 22
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2017
VL 68
SI SI
BP 40
EP 52
DI 10.1016/j.imavis.2017.01.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FR9UP
UT WOS:000419418900005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chum, O
AF Chum, Ondrej
TI Optimizing explicit feature maps on intervals
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Explicit feature maps; Shift-invariant kernels; Homogeneous kernels;
   Linear programming
AB Approximating non-linear kernels by finite-dimensional feature maps is a popular approach for accelerating training and evaluation of support vector machines or to encode information into efficient match kernels. We propose a novel method of data independent construction of low-dimensional feature maps. The problem is formulated as a linear program that jointly considers two competing objectives: the quality of the approximation and the dimensionality of the feature map.
   For both shift-invariant and homogeneous kernels the proposed method achieves better approximation at the same dimensionality or comparable approximations at lower dimensionality of the feature map compared with state-of-the-art methods. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Chum, Ondrej] Czech Tech Univ, Fac Elect Engn, Visual Recognit Grp, Prague, Czech Republic.
C3 Czech Technical University Prague
RP Chum, O (corresponding author), Czech Tech Univ, Fac Elect Engn, Visual Recognit Grp, Prague, Czech Republic.
EM chum@cmp.felk.cvut.cz
RI Chum, Ondrej/F-5262-2015
FU  [MSMT LL1303 ERC-CZ]
FX would like to thank Tomag Werner for his valuable opinions and
   interesting discussions. This work was supported by MSMT LL1303 ERC-CZ
   grant.
CR [Anonymous], 2009, Advances in neural information processing systems
   [Anonymous], TPAMI
   [Anonymous], 2006, P ACMSIGKDD INT C KN
   [Anonymous], 2010, ADV NEUR INF PROC SY
   [Anonymous], 2008, OPEN PORTABLE LIB CO
   Bursuc A., 2015, KERNEL LOCAL DESCRIP
   Chum O., IMPLEMENTATION LOW D
   Chum O., 2015, LOW DIMENSIONAL EXPL
   Franc V, 2012, OPTIMIZATION FOR MACHINE LEARNING, P185
   Jegou H., 2010, Aggregating local descriptors into a compact image representation
   KELLEY JE, 1960, J SOC IND APPL MATH, V8, P703, DOI 10.1137/0108053
   Le Q.V., 2013, Fastfood: Approximating Kernel Expansions in Loglinear Time
   Li F., RANDFEAT RANDOM FOUR, V1
   Li F., 2010, RANDOM FOURIER APPRO
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Maji S, 2009, IEEE I CONF COMP VIS, P40, DOI 10.1109/ICCV.2009.5459203
   Perronnin F., 2010, LARGE SCALE IMAGE RE
   Rahimi A., 2007, NIPS, P1177
   Scholkopf B., 2002, Encyclopedia of Biostatistics
   Tolias G., 2014, ORIENTATION COVARIAN
   Vanderbei R.J., 1996, LINEAR PROGRAMMING F
   Vedaldi A., 2012, SPARSE KERNEL APPROX
NR 22
TC 2
Z9 2
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2017
VL 66
BP 36
EP 47
DI 10.1016/j.imavis.2017.07.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FJ9AO
UT WOS:000413060000004
DA 2024-07-18
ER

PT J
AU Lee, HH
   Hong, KS
AF Lee, Hyo-Haeng
   Hong, Kwang-Seok
TI Automatic recognition of flower species in the natural environment
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Flower image; Automatic recognition; Mobile; Natural environment; Random
   Forests
AB In this study, we propose a method for the recognition and retrieval of a flower species in the natural environment based on a multi-layer technique, and we also suggest novel applications. First, the study suggests how to capture a flower object that is blooming in the natural environment, as well as the corresponding background. Secondly, an experimental analysis is conducted for the purpose of improving the optimal method of feature extraction for color, texture, and shape. Thirdly, the study developed a flower-image automatic-recognition technology that can be utilized in a mobile environment. We performed experiments on 29,463 images of 300 species of blooming flowers that were collected in South Korea between 2011 and 2014. We found image recognition to be 91.26% for the 1st-ranking recognition of the flower image and 97.40% for the 6th-ranking recognition. These results show that the color-texture-shape features of the flower pictures are the most effective; furthermore, the effectiveness and validity of this suggested method for demonstration services are verified in this paper. (C) 2017 Elsevier B.V. All rights reserved.
EM hyohaeng@skku.edu
FU Ministry of Science, ICT and Future Planning (MSIP), Korea, under the
   G-ITRC support program [IITP-2016-R6812-16-0001]; Basic Science Research
   Program through the National Research Foundation of Korea (NRF) -
   Ministry of Education [NRF-2010-0020210]
FX This work was supported by the Ministry of Science, ICT and Future
   Planning (MSIP), Korea, under the G-ITRC support program [grant number
   IITP-2016-R6812-16-0001] supervised by the IITP; Basic Science Research
   Program through the National Research Foundation of Korea (NRF) funded
   by the Ministry of Education [grant number NRF-2010-0020210]. The
   sponsors had no role in study design; in the collection, analysis and
   interpretation of data; in the writing of the report; and in the
   decision to submit the article for publication.
CR [Anonymous], 2014, P LIFECLEF
   Beucher S., IMAGE SEGMENTATION M
   Breiman L., Random Forests
   Chen Yanjuan, 2011, International Journal of Contents, V7, P24
   Hall-Beyer M., THE GLCM TUTORIAL
   Hong AX, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P589
   Hsieh IS, 2000, INT C PATT RECOG, P1023, DOI 10.1109/ICPR.2000.905645
   Khoshgoftaar TM, 2007, PROC INT C TOOLS ART, P310, DOI 10.1109/ICTAI.2007.46
   Korea National Park Service, 2011, PUKH WILDFL
   Krishnan N, 2007, ICCIMA 2007: INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND MULTIMEDIA APPLICATIONS, VOL III, PROCEEDINGS, P190, DOI 10.1109/ICCIMA.2007.64
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Ladicky L, 2010, LECT NOTES COMPUT SC, V6315, P239, DOI 10.1007/978-3-642-15555-0_18
   Mancas-Thillou C., 2007, THESIS, P1
   Mortensen E., 2005, P 22 ANN C COMP GRAP, P191
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Park J, 2010, PATTERN RECOGN LETT, V31, P1728, DOI 10.1016/j.patrec.2010.05.024
   Pornpanomchai C., 2010, INT C MEN EL INF ENG, P123
   Saitoh T, 2004, INT C PATT RECOG, P27, DOI 10.1109/ICPR.2004.1333997
   Saitoh T, 2003, LECT NOTES COMPUT SC, V2749, P1130
   Saitoh T, 2000, INT C PATT RECOG, P507, DOI 10.1109/ICPR.2000.906123
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
   Yang C. C., 1999, IEEE SMC'99 Conference Proceedings. 1999 IEEE International Conference on Systems, Man, and Cybernetics (Cat. No.99CH37028), P922, DOI 10.1109/ICSMC.1999.812533
   Zhang W, 2010, IEEE T INF FOREN SEC, V5, P544, DOI 10.1109/TIFS.2010.2051666
   Zhenjiang M., 2002, P INT C SIGN PROC, P1087
   Zou J, 2004, INT C PATT RECOG, P311, DOI 10.1109/ICPR.2004.1334185
NR 25
TC 14
Z9 14
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2017
VL 61
BP 98
EP 114
DI 10.1016/j.imavis.2017.01.013
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EU7HK
UT WOS:000401205700008
DA 2024-07-18
ER

PT J
AU Moeini, A
   Faez, K
   Moeini, H
   Safai, AM
AF Moeini, Ali
   Faez, Karim
   Moeini, Hossein
   Safai, Armon Matthew
TI Open-set face recognition across look-alike faces in real-world
   scenarios
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Open-set face recognition; Look-alike face; Facial plastic surgery;
   Sparse representation; Collaborative representation; Real-world
   scenarios
ID PLASTIC-SURGERY; SPARSE REPRESENTATION; CLASSIFICATION; SCALE; MODEL
AB The open-set problem is among the problems that have significantly changed the performance of face recognition algorithms in real-world scenarios. Open-set operates under the supposition that not all the probes have a pair in the gallery. Most face recognition systems in real-world scenarios focus on handling pose, expression and illumination problems on face recognition. In addition to these challenges, when the number of subjects is increased for face recognition, these problems are intensified by look-alike faces for which there are two subjects with lower intra-class variations. In such challenges, the inter-cldss similarity is higher than the intra-class variation for these two subjects. In fact, these look-alike faces can be created as intrinsic, situation-based and also by facial plastic surgery. This work introduces three real-world open-set face recognition methods across facial plastic surgery changes and a look-alike face by 3D face reconstruction and sparse representation. Since some real world databases for face recognition do not have multiple images per person in the gallery, With just one image per subject in the gallery, this paper proposes a novel idea to overcome this challenge by 3D modeling from gallery images and synthesizing them for generating several images. Accordingly, a 3D model is initially reconstructed from frontal face images in a real-world gallery. Then, each 3D reconstructed face in the gallery is synthesized to several possible views and a sparse dictionary is generated based on the synthesized face image for each person. Also, a likeness dictionary is defined and its optimization problem is solved by the proposed method. Finally, the face recognition is performed for open-set face recognition using three proposed representation classifications. Promising results are achieved for face recognition across plastic surgery and look-alike faces on three databases including the plastic surgery face, look-alike face and LFW databases compared to several state-of-the-art methods. Also, several real-world and open-set scenarios are performed to evaluate the proposed method on these databases in real-world scenarios. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Moeini, Ali; Faez, Karim] Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
   [Moeini, Hossein] Semnan Univ, Dept Elect Engn, Semnan, Iran.
   [Safai, Armon Matthew] Univ Calif San Diego, Comp Sci & Engn Dept, San Diego, CA 92103 USA.
C3 Amirkabir University of Technology; Semnan University; University of
   California System; University of California San Diego
RP Moeini, A (corresponding author), Amirkabir Univ Technol, Dept Elect Engn, Tehran, Iran.
EM ali.moeini1989@gmail.com
RI faez, karim/K-5117-2019
OI faez, karim/0000-0002-1159-4866
CR Aharon M, 2006, IEEE T SIGNAL PROCES, V54, P4311, DOI 10.1109/TSP.2006.881199
   [Anonymous], BRIT MACH VIS C
   [Anonymous], P INT JOINT C BIOM I
   [Anonymous], P BRIT MACH VIS C
   [Anonymous], 2015, IEEE C COMP VIS PATT
   [Anonymous], WACV
   [Anonymous], P CVPR
   [Anonymous], P WORKSH APPL COMP V
   [Anonymous], J ELECT IMAGING
   [Anonymous], 2015, IEEE GLOB COMM CONF, DOI DOI 10.1109/GLOCOM.2015.7417362
   [Anonymous], 2008, REAL LIF IM WORKSH E
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], P ACCV
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bhatt HS, 2013, IEEE T INF FOREN SEC, V8, P89, DOI 10.1109/TIFS.2012.2223684
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   De Marsico M, 2015, PATTERN RECOGN, V48, P1261, DOI 10.1016/j.patcog.2014.10.004
   De Marsico M, 2011, LECT NOTES COMPUT SC, V6754, P191, DOI 10.1007/978-3-642-21596-4_20
   Etemad K, 1997, J OPT SOC AM A, V14, P1724, DOI 10.1364/JOSAA.14.001724
   He R, 2013, IEEE T NEUR NET LEAR, V24, P35, DOI 10.1109/TNNLS.2012.2226471
   Heo J, 2012, IEEE T INF FOREN SEC, V7, P563, DOI 10.1109/TIFS.2012.2184755
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang ZH, 2015, IMAGE VISION COMPUT, V37, P12, DOI 10.1016/j.imavis.2014.12.005
   Kosmerlj M, 2006, LECT NOTES COMPUT SC, V3832, P33
   Kumar N, 2009, IEEE I CONF COMP VIS, P365, DOI 10.1109/ICCV.2009.5459250
   Li F, 2005, IEEE T PATTERN ANAL, V27, P1686, DOI 10.1109/TPAMI.2005.224
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Moeini A, 2015, IEEE T INF FOREN SEC, V10, P969, DOI 10.1109/TIFS.2015.2393553
   Moeini A, 2015, IMAGE VISION COMPUT, V36, P9, DOI 10.1016/j.imavis.2015.01.007
   Narang N, 2015, IMAGE VISION COMPUT, V33, P26, DOI 10.1016/j.imavis.2014.10.005
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Penev PS, 1996, NETWORK-COMP NEURAL, V7, P477, DOI 10.1088/0954-898X/7/3/002
   Phillips P. J., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P185, DOI 10.1109/FG.2011.5771395
   Sariyanidi E, 2015, IEEE T PATTERN ANAL, V37, P1113, DOI 10.1109/TPAMI.2014.2366127
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Scheirer WJ, 2013, IEEE T PATTERN ANAL, V35, P1757, DOI 10.1109/TPAMI.2012.256
   Schroff F, 2011, IEEE I CONF COMP VIS, P2494, DOI 10.1109/ICCV.2011.6126535
   Singh R, 2010, IEEE T INF FOREN SEC, V5, P441, DOI 10.1109/TIFS.2010.2054083
   Singh R, 2009, IMAGE VISION COMPUT, V27, P245, DOI 10.1016/j.imavis.2007.06.010
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang DH, 2013, IMAGE VISION COMPUT, V31, P895, DOI 10.1016/j.imavis.2013.10.002
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Xu Y, 2014, IEEE T CYBERNETICS, V44, P1950, DOI 10.1109/TCYB.2014.2300175
   Yang M, 2013, IEEE T NEUR NET LEAR, V24, P900, DOI 10.1109/TNNLS.2013.2245340
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zhang WC, 2005, IEEE I CONF COMP VIS, P786
   Zhu ZF, 2014, IMAGE VISION COMPUT, V32, P180, DOI 10.1016/j.imavis.2013.12.015
NR 48
TC 19
Z9 19
U1 2
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2017
VL 57
BP 1
EP 14
DI 10.1016/j.imavis.2016.11.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EJ5NU
UT WOS:000393265800001
DA 2024-07-18
ER

PT J
AU Liu, Z
   Zhang, CY
   Tian, YL
AF Liu, Zhi
   Zhang, Chenyang
   Tian, Yingli
TI 3D-based Deep Convolutional Neural Network for action recognition with
   depth sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Deep learning; Convolutional neural network; Depth
   sequences; 3D convolution
ID REPRESENTATION; POSE
AB Traditional algorithms to design hand-crafted features for action recognition have been a hot research area in the last decade. Compared to RGB video, depth sequence is more insensitive to lighting changes and more discriminative due to its capability to catch geometric information of object. Unlike many existing methods for action recognition which depend on well-designed features, this paper studies deep learning based action recognition using depth sequences and the corresponding skeleton joint information. Firstly, we construct a 3D-based Deep Convolutional Neural Network (3D(2)CNN) to directly learn spatio-temporal features from raw depth sequences, then compute a joint based feature vector named JointVector for each sequence by taking into account the simple position and angle information between skeleton joints. Finally, support vector machine (SVM) classification results from 3D(2)CNN learned features and JointVector are fused to take action recognition. Experimental results demonstrate that our method can learn feature representation which is time-invariant and viewpoint-invariant from depth sequences. The proposed method achieves comparable results to the state-of-the-art methods on the UTKinect-Action3D dataset and achieves superior performance in comparison to baseline methods on the MSR-Action3D dataset. We further investigate the generalization of the trained model by transferring the learned features from one dataset (MSR-Action3D) to another dataset (UTKinect-Action3D) without retraining and obtain very promising classification accuracy. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Liu, Zhi] Chongqing Univ Technol, Coll Comp Sci & Engn, Chongqing 400050, Peoples R China.
   [Zhang, Chenyang; Tian, Yingli] CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
C3 Chongqing University of Technology; City University of New York (CUNY)
   System; City College of New York (CUNY)
RP Tian, YL (corresponding author), CUNY City Coll, Dept Elect Engn, New York, NY 10031 USA.
EM liuzhi@cqut.edu.cn; czhang10@ccny.cuny.edu; ytian@ccny.cuny.edu
RI liu, zhi/M-4315-2015; TIAN, YI/KHU-9704-2024
OI Tian, Yingli/0000-0003-4458-360X
FU NSF [EFRI-1137172, IIS-1400802]; Scientific and Technological Research
   Program of Chongqing Municipal Education Commission [KJ1400926];
   Chongqing National Science Foundation [cstc2013jcyjA40038]; Div Of
   Information & Intelligent Systems; Direct For Computer & Info Scie &
   Enginr [1400802] Funding Source: National Science Foundation; Emerging
   Frontiers & Multidisciplinary Activities; Directorate For Engineering
   [1137172] Funding Source: National Science Foundation
FX This work was supported in part by NSF grants EFRI-1137172 and
   IIS-1400802, Scientific and Technological Research Program of Chongqing
   Municipal Education Commission (KJ1400926), and Chongqing National
   Science Foundation (cstc2013jcyjA40038).
CR Valle EA, 2013, 2013 10TH INTERNATIONAL CONFERENCE ON ELECTRICAL ENGINEERING, COMPUTING SCIENCE AND AUTOMATIC CONTROL (CCE), P239, DOI 10.1109/ICEEE.2013.6676005
   [Anonymous], 2011, PROC CVPR IEEE, DOI [DOI 10.1109/CVPR.2011.5995316, 10.1109/CVPR.2011.5995316]
   [Anonymous], ARXIV13101531
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Burger H., 2012, CVPR
   Chrungoo A, 2014, LECT NOTES ARTIF INT, V8755, P84, DOI 10.1007/978-3-319-11973-1_9
   Collobert R, 2011, BIGLEARN NIPS WORKSH, P1
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   Devanne M, 2013, LECT NOTES COMPUT SC, V8158, P456, DOI 10.1007/978-3-642-41190-8_49
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Han JG, 2013, IEEE T CYBERNETICS, V43, P1318, DOI 10.1109/TCYB.2013.2265378
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Hunter D, 2012, IEEE T IND INFORM, V8, P228, DOI 10.1109/TII.2012.2187914
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Jin L, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM), P311, DOI 10.1109/ISM.2014.56
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu L., 2013, 23 INT JOINT C ART I
   LIU L, IEEE T CYBERN
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Mao Ye, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P149, DOI 10.1007/978-3-642-44964-2_8
   Molchanov Pavlo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P1, DOI 10.1109/CVPRW.2015.7301342
   Murray R. M., 1994, MATH INTRO ROBOTIC M
   Ni BB, 2013, IEEE T CYBERNETICS, V43, P1383, DOI 10.1109/TCYB.2013.2276433
   O'Hara S, 2012, IMAGE VISION COMPUT, V30, P206, DOI 10.1016/j.imavis.2011.11.001
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Peng XJ, 2014, IMAGE VISION COMPUT, V32, P616, DOI 10.1016/j.imavis.2014.06.011
   Roshtkhari MJ, 2013, IMAGE VISION COMPUT, V31, P864, DOI 10.1016/j.imavis.2013.08.005
   Sermanet P, 2013, PROC CVPR IEEE, P3626, DOI 10.1109/CVPR.2013.465
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Sun L, 2014, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2014.336
   Thi TH, 2012, IMAGE VISION COMPUT, V30, P1, DOI 10.1016/j.imavis.2011.12.006
   Vemulapalli R, 2014, PROC CVPR IEEE, P588, DOI 10.1109/CVPR.2014.82
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2012, LECT NOTES COMPUT SC, V7573, P872, DOI 10.1007/978-3-642-33709-3_62
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Wu D, 2014, PROC CVPR IEEE, P724, DOI 10.1109/CVPR.2014.98
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yang XD, 2014, PROC CVPR IEEE, P804, DOI 10.1109/CVPR.2014.108
   Ye GZ, 2013, IEEE T CYBERNETICS, V43, P1370, DOI 10.1109/TCYB.2013.2272321
   Yu M., IEEE T PATTERN ANAL
   Zanfir M, 2013, IEEE I CONF COMP VIS, P2752, DOI 10.1109/ICCV.2013.342
   Zhang CY, 2013, IEEE COMPUT SOC CONF, P500, DOI 10.1109/CVPRW.2013.80
   Zhu Y, 2014, IMAGE VISION COMPUT, V32, P453, DOI 10.1016/j.imavis.2014.04.005
NR 53
TC 99
Z9 101
U1 0
U2 50
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 93
EP 100
DI 10.1016/j.imavis.2016.04.004
PN 2
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300007
OA Bronze
DA 2024-07-18
ER

PT J
AU Spratling, MW
AF Spratling, M. W.
TI A neural implementation of the Hough transform and the advantages of
   explaining away
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hough transform; Generalised Hough transform; Implicit shape model;
   Feature extraction; Object detection; Explaining away; Neural networks
ID LINE SEGMENT EXTRACTION; CODING MODEL; INHIBITION; SPARSE; RECOGNITION;
   ACCURATE; ENTROPY
AB The Hough transform (HT) is widely used for feature extraction and object detection. However, during the HT individual image elements vote for many possible parameter values. This results in a dense accumulator array and problems identifying the parameter values that correspond to image features. This article proposes a new method for implementing the voting process in the HT. This method employs a competitive neural network algorithm to perform a form of probabilistic inference known as "explaining away". This results in a sparse accumulator array in which the parameter values of image features can be more accurately identified. The proposed method is initially demonstrated using the simple, prototypical, task of straight line detection in synthetic images. In this task it is shown to more accurately identify straight lines, and the parameter of those lines, compared to the standard Hough voting process. The proposed method is further assessed using a version of the implicit shape model (ISM) algorithm applied to car detection in natural images. In this application it is shown to more accurately identify cars, compared to using the standard Hough voting process in the same algorithm, and compared to the original ISM algorithm. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Spratling, M. W.] Kings Coll London, Dept Informat, London WC2R 2LS, England.
C3 University of London; King's College London
RP Spratling, MW (corresponding author), Kings Coll London, Dept Informat, London WC2R 2LS, England.
EM michael.spratling@kcl.ac.uk
RI Spratling, Michael/G-7689-2011
OI Spratling, Michael/0000-0001-9531-2813
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113
   [Anonymous], 2006, COMPUTER VISION PATT
   [Anonymous], P IEEE COMP SOC C CO
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Barinova O, 2012, IEEE T PATTERN ANAL, V34, P1773, DOI 10.1109/TPAMI.2012.79
   Beinglass A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P461, DOI 10.1109/CVPR.1991.139736
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   DAVIES ER, 1988, IEE PROC-E, V135, P49, DOI 10.1049/ip-e.1988.0006
   DUDA RO, 1972, COMMUN ACM, V15, P11, DOI 10.1145/361237.361242
   Furukawa Y, 2003, COMPUT VIS IMAGE UND, V92, P1, DOI 10.1016/j.cviu.2003.07.002
   Gall J., 2009, P IEEE COMP SOC C 3
   Gall J, 2011, IEEE T PATTERN ANAL, V33, P2188, DOI 10.1109/TPAMI.2011.70
   GEORGOPOULOS AP, 1986, SCIENCE, V233, P1416, DOI 10.1126/science.3749885
   Gerig G., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P112
   Harpur G. F., 1994, 1994 International Symposium on Artificial Neural Networks. ISANN '94. Proceedings, P412
   Harpur GF, 1996, NETWORK-COMP NEURAL, V7, P277, DOI 10.1088/0954-898X/7/2/007
   Hart PE, 2009, IEEE SIGNAL PROC MAG, V26, P18, DOI 10.1109/MSP.2009.934181
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964
   Ji JH, 2011, PATTERN RECOGN LETT, V32, P1503, DOI 10.1016/j.patrec.2011.04.011
   Karlinsky L., 2010, P IEEE COMP SOC C 3
   Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005
   Lehmann A, 2011, INT J COMPUT VISION, V94, P175, DOI 10.1007/s11263-010-0342-x
   Leibe B., 2004, EUR C COMP VIS WORKS
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Lin YM, 2014, MATH PROBL ENG, V2014, DOI 10.1155/2014/513283
   Lochmann T, 2012, J NEUROSCI, V32, P4179, DOI 10.1523/JNEUROSCI.0817-11.2012
   Lochmann T, 2011, CURR OPIN NEUROBIOL, V21, P774, DOI 10.1016/j.conb.2011.05.018
   Maji S., 2009, P IEEE COMP SOC C 3
   Okada R, 2009, IEEE I CONF COMP VIS, P2000, DOI 10.1109/ICCV.2009.5459441
   Rao R.P.N., NAT NEUROSCI, V2
   Razavi N, 2011, PROC CVPR IEEE, P1505, DOI 10.1109/CVPR.2011.5995441
   Samal A, 1997, PATTERN RECOGN LETT, V18, P473, DOI 10.1016/S0167-8655(97)00023-8
   Spratling MW, 2008, VISION RES, V48, P1391, DOI 10.1016/j.visres.2008.03.009
   Spratling MW, 2014, J COMPUT NEUROSCI, V36, P97, DOI 10.1007/s10827-013-0471-7
   Spratling MW, 2014, BIOL CYBERN, V108, P61, DOI 10.1007/s00422-013-0579-x
   Spratling MW, 2012, NEURAL NETWORKS, V26, P7, DOI 10.1016/j.neunet.2011.10.002
   Spratling MW, 2012, NEURAL COMPUT, V24, P60, DOI 10.1162/NECO_a_00222
   Spratling M W, 2009, Comput Intell Neurosci, P381457, DOI 10.1155/2009/381457
   Spratling MW, 2013, IEEE T IMAGE PROCESS, V22, P1629, DOI 10.1109/TIP.2012.2235850
   Spratling MW, 2010, J NEUROSCI, V30, P3531, DOI 10.1523/JNEUROSCI.4911-09.2010
   Spratling MW, 1999, NETWORK-COMP NEURAL, V10, P285, DOI 10.1088/0954-898X/10/4/301
   Spratling MW, 2003, NEUROCOMPUTING, V52-4, P389, DOI 10.1016/S0925-2-112(02)00847-0
   Spratling MW, 2002, NEURAL COMPUT, V14, P2157, DOI 10.1162/089976602320264033
   Woodford OJ, 2014, INT J COMPUT VISION, V106, P332, DOI 10.1007/s11263-013-0623-2
   Xu ZZ, 2015, IEEE T IMAGE PROCESS, V24, P813, DOI 10.1109/TIP.2014.2387020
   Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883
NR 48
TC 8
Z9 9
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 15
EP 24
DI 10.1016/j.imavis.2016.05.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Naruniec, J
AF Naruniec, Jacek
TI Discrete area filters in accurate detection of faces and facial features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face detection; Facial features detection; Discrete area filers; mLDA
   cascade
ID RECOGNITION; LOCALIZATION
AB This paper introduces a new method for detection of faces and facial features. Proposed algorithm denies the thesis that bottom-up solutions can't work at reasonable speed. It introduces fast detection - about 9 frames per second for a 384 x 256 image - while preserving accurate details of the detection. Main experiments focus on the detection of the eye centers - crucial in many computer vision systems such as face recognition, eye movement detection or iris recognition, however algorithm is tuned to detect 15 fiducial face points. Models were trained on nearly frontal faces. Bottom-up approach allows to detect objects under partial occlusion - particularly two out of four face parts (left eye, right eye, nose, mouth) must be localized. Precision of the trained model is verified on the Feret dataset. Robustness of the face detection is evaluated on the BioID, LFPW, Feret, GT, Valid and Helen databases in comparison to the state of the art detectors. (C) 2014 Elsevier B.V. All rights reserved.
C1 Warsaw Univ Technol, Inst Radioelect, Fac Elect & Informat Technol, PL-00665 Warsaw, Poland.
C3 Warsaw University of Technology
RP Naruniec, J (corresponding author), Warsaw Univ Technol, Inst Radioelect, Fac Elect & Informat Technol, Ul Nowowiejska 15-19, PL-00665 Warsaw, Poland.
OI Naruniec, Jacek/0000-0002-2315-5166
CR Al Haj M., 2008, ICPR 2008, P1
   Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   [Anonymous], 24 IEEE C COMP VIS P
   [Anonymous], IEEE INT C COMP VIS
   Antonini G, 2003, LECT NOTES COMPUT SC, V2688, P111
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Beigzadeh M, 2008, CAIR INT BIOM ENG C, P1
   Belhumeur P.N., 1997, EIGENFACES VS FISHER
   Bober M, 2003, LECT NOTES COMPUT SC, V2756, P638
   Bober M., 2002, JTC1SC29WG11N4749
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Celiktutan O., 2008, AUT FAC GEST REC 200, P1
   Cootes T.F., 1998, LECT NOTES COMPUT SC, V1407
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Craw I., 1992, finding face features
   Ding LY, 2010, IEEE T PATTERN ANAL, V32, P2022, DOI 10.1109/TPAMI.2010.28
   Donato G, 1999, IEEE T PATTERN ANAL, V21, P974, DOI 10.1109/34.799905
   Duffner S, 2005, ISPA 2005: PROCEEDINGS OF THE 4TH INTERNATIONAL SYMPOSIUM ON IMAGE AND SIGNAL PROCESSING AND ANALYSIS, P316, DOI 10.1109/ISPA.2005.195430
   Fasel I., AUT FAC GEST REC IEE, V02002, P0242
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   FOX NA, 2005, P 5 INT C AUD VID BA
   Fröba B, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P342, DOI 10.1109/AFGR.2002.1004177
   Fukunaga K., 1992, INTRO STAT PATTERN R, V2nd
   GOLDSTEI.AA, 1972, AT&T TECH J, V51, P399, DOI 10.1002/j.1538-7305.1972.tb01927.x
   Hamouz M, 2005, IEEE T PATTERN ANAL, V27, P1490, DOI 10.1109/TPAMI.2005.179
   Hotta K, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P70, DOI 10.1109/AFGR.1998.670927
   Jahanbin S, 2008, 2008 IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS & INTERPRETATION, P25, DOI 10.1109/SSIAI.2008.4512276
   Jee H, 2004, PROCEEDINGS OF THE 2004 INTELLIGENT SENSORS, SENSOR NETWORKS & INFORMATION PROCESSING CONFERENCE, P577, DOI 10.1109/ISSNIP.2004.1417525
   Kim T., 2002, COMPONENT BASED IDA
   KUCHARSKI K, 2006, THESIS WARSAW U TECH
   LADES M, 1993, IEEE T COMPUT, V42, P300, DOI 10.1109/12.210173
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Leibe B, 2008, INT J COMPUT VISION, V77, P259, DOI 10.1007/s11263-007-0095-3
   Leutenegger S, 2011, P IEEE INT C COMP VI
   Lienhart R, 2003, LECT NOTES COMPUT SC, V2781, P297
   Matas J., 2002, P AS C COMP VIS
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Naruniec J, 2007, LECT NOTES ARTIF INT, V4481, P187
   NGUYEN MH, 2008, 8 IEEE INT C AUT FAC
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Reinders M., 1997, 2nd International Conference on Automatic Face and Gesture Recognition, P230
   REISFELD D, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL I, P117, DOI 10.1109/ICPR.1992.201521
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Sobottka K, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL III, P483, DOI 10.1109/ICIP.1996.560536
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Viola P, 2002, ADV NEUR IN, V14, P1311
   Vukadinovic D., 2005, P IEEE ICSMS
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu ZW, 2005, COMPUT VIS IMAGE UND, V98, P124, DOI 10.1016/j.cviu.2004.07.012
NR 55
TC 5
Z9 6
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 979
EP 993
DI 10.1016/j.imavis.2014.09.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600002
DA 2024-07-18
ER

PT J
AU Hoang, TV
   Tabbone, S
AF Hoang, Thai V.
   Tabbone, Salvatore
TI Generic polar harmonic transforms for invariant image representation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Polar harmonic transforms; Harmonic kemels; Rotation invariance;
   Orthogonal moments
ID JACOBI-FOURIER MOMENTS; ZERNIKE MOMENTS; PATTERN-RECOGNITION; ORTHOGONAL
   MOMENTS
AB This paper introduces four classes of rotation-invariant orthogonal moments by generalizing four existing moments that use harmonic functions in their radial kernels. Members of these classes share beneficial properties for image representation and pattern recognition like orthogonality and rotation-invariance. The kernel sets of these generic harmonic function-based moments are complete in the Hilbert space of square-integrable continuous complex-valued functions. Due to their resemble definition, the computation of these kernels maintains the simplicity and numerical stability of existing harmonic function-based moments. In addition, each member of one of these classes has distinctive properties that depend on the value of a parameter, making it more suitable for some particular applications. Comparison with existing orthogonal moments defined based on Jacobi polynomials and eigenfunctions has been carried out and experimental results show the effectiveness of these classes of moments in terms of representation capability and discrimination power. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Hoang, Thai V.] Inria Nancy Grand Est, F-54600 Villers Les Nancy, France.
   [Tabbone, Salvatore] Univ Lorraine, LORIA, F-54506 Vandoeuvre Les Nancy, France.
C3 Universite de Lorraine; Universite de Lorraine
RP Hoang, TV (corresponding author), Inria Nancy Grand Est, F-54600 Villers Les Nancy, France.
EM vanthai.hoang@inria.fr
CR ABUMOSTAFA YS, 1984, IEEE T PATTERN ANAL, V6, P698, DOI 10.1109/TPAMI.1984.4767594
   Amu G, 2004, APPL OPTICS, V43, P2093, DOI 10.1364/AO.43.002093
   BHATIA AB, 1954, P CAMB PHILOS SOC, V50, P40, DOI 10.1017/S0305004100029066
   Bober M., 2002, INTRO MPEG 7 MULTIME, P231
   Bowman F., 1958, Introduction to Bessel Function
   FEFFERMAN C, 1971, B AM MATH SOC, V77, P744, DOI 10.1090/S0002-9904-1971-12793-3
   Flusser J., 2009, Moments and Moment Invariants in Pattern Recognition
   Guan SG, 2001, PHYSICA D, V151, P83, DOI 10.1016/S0167-2789(01)00223-8
   Hoang T. V., 2011, P 18 IEEE INT C IM P, P845
   Hoang T. V., 2012, PROC INT CONF PATT R, P3160
   Hoang T. V., 2011, THESIS U NANCY
   Hoang TV, 2013, PATTERN RECOGN, V46, P3148, DOI 10.1016/j.patcog.2013.04.011
   Hoang TV, 2012, PATTERN RECOGN, V45, P2145, DOI 10.1016/j.patcog.2011.11.007
   KHOTANZAD A, 1990, IEEE T PATTERN ANAL, V12, P489, DOI 10.1109/34.55109
   Koornwinder T.H., 2010, NIST Handbook of Mathematical Functions. Ed. by
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   Papakostas GA, 2006, IMAGE VISION COMPUT, V24, P960, DOI 10.1016/j.imavis.2006.02.015
   Ping ZL, 2007, PATTERN RECOGN, V40, P1245, DOI 10.1016/j.patcog.2006.07.016
   Ping ZL, 2002, J OPT SOC AM A, V19, P1748, DOI 10.1364/JOSAA.19.001748
   Ren HP, 2003, J OPT SOC AM A, V20, P631, DOI 10.1364/JOSAA.20.000631
   SHENG YL, 1994, J OPT SOC AM A, V11, P1748, DOI 10.1364/JOSAA.11.001748
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   TEH CH, 1986, COMPUT VISION GRAPH, V33, P318, DOI 10.1016/0734-189X(86)90180-5
   Verrall SC, 1998, J OPT SOC AM A, V15, P389, DOI 10.1364/JOSAA.15.000389
   Wang JZ, 2001, IEEE T PATTERN ANAL, V23, P947, DOI 10.1109/34.955109
   Wang Q, 2009, IEEE T PATTERN ANAL, V31, P1715, DOI 10.1109/TPAMI.2009.29
   Xiao B, 2010, PATTERN RECOGN, V43, P2620, DOI 10.1016/j.patcog.2010.03.013
   Yap PT, 2010, IEEE T PATTERN ANAL, V32, P1259, DOI 10.1109/TPAMI.2009.119
   Yip P., 2010, TRANSFORMS APPL HDB
   Zernike F, 1934, PHYSICA, V1, P689
   Zhang DS, 2002, SIGNAL PROCESS-IMAGE, V17, P825, DOI 10.1016/S0923-5965(02)00084-X
NR 33
TC 19
Z9 20
U1 0
U2 17
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2014
VL 32
IS 8
BP 497
EP 509
DI 10.1016/j.imavis.2014.04.016
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AL3PB
UT WOS:000339039600005
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Fergie, M
   Galata, A
AF Fergie, Martin
   Galata, Aphrodite
TI Mixtures of Gaussian process models for human pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Computer vision; Gaussian processes; Human pose estimation; Mixture of
   experts
AB Discriminative human pose estimation is the problem of inferring the 3D articulated pose of a human directly from an image feature. This is a challenging problem due to the highly non-linear and multi-modal mapping from the image feature space to the pose space. To address this problem, we propose a model employing a mixture of Gaussian processes where each Gaussian process models a local region of the pose space. By employing the models in this way we are able to overcome the limitations of Gaussian processes applied to human pose estimation their O(N-3) time complexity and their uni-modal predictive distribution. Our model is able to give a multi-modal predictive distribution where each mode is represented by a different Gaussian process prediction. A logistic regression model is used to give a prior over each expert prediction in a similar fashion to previous mixture of expert models. We show that this technique outperforms existing state of the art regression techniques on human pose estimation data sets for ballet dancing, sign language and the HumanEva data set. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Fergie, Martin; Galata, Aphrodite] Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England.
C3 University of Manchester
RP Fergie, M (corresponding author), Univ Manchester, Sch Comp Sci, Manchester M13 9PL, Lancs, England.
EM mfergie@cs.man.ac.uk; agalata@cs.man.ac.uk
OI Fergie, Martin/0000-0002-9531-6109; Galata,
   Aphrodite/0000-0002-9229-7811
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   [Anonymous], 8 IEEE INT C COMP VI
   [Anonymous], 2008 INT S WORLD WIR
   [Anonymous], 2007, ICCV
   [Anonymous], P UAI 03 P 19 C UNC
   [Anonymous], 2006, HUMANEVA SYNCHRONIZ
   [Anonymous], COMPUTER VISION ECCV
   [Anonymous], 2010, INT J COMPUT VISION, DOI DOI 10.1007/s11263-008-0204-y
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], 2008, P 19 BRIT MACHINE VI
   [Anonymous], 2007, MACHINE LEARNING MUL, DOI DOI 10.1007/978-3-540-78155-4
   Bishop C, 2007, RECOGNITION PATTERN
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Jixu Chen, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2655, DOI 10.1109/CVPRW.2009.5206580
   JORDAN MI, 1994, NEURAL COMPUT, V6, P181, DOI 10.1162/neco.1994.6.2.181
   Kanaujia A., 2007, Computer Vision and Pattern Recognition CVPR, P1
   Kanaujia A., 2008, COMPUTER VISION PATT, P1
   Lowe D. G., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1150, DOI 10.1109/ICCV.1999.790410
   Memisevic R, 2012, IEEE T PATTERN ANAL, V34, P778, DOI 10.1109/TPAMI.2011.154
   Ning H., 2008, COMPUTER VISION PATT, P1
   Rasmussen CE, 2002, ADV NEUR IN, V14, P881
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Rogez G., 2008, IEEE C COMPUTER VISI, P1
   Serre T, 2005, PROC CVPR IEEE, P994
   Sminchisescu C, 2005, PROC CVPR IEEE, P390
   Sminchisescu C., 2006, COMPUTER VISION PATT, V2, P1743
   Tresp V, 2001, ADV NEUR IN, V13, P654
   Urtasun R., 2008, COMPUTER VISION PATT, P1
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Zhao X, 2011, IEEE T IMAGE PROCESS, V20, P1141, DOI 10.1109/TIP.2010.2076820
NR 30
TC 7
Z9 7
U1 1
U2 28
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2013
VL 31
IS 12
BP 949
EP 957
DI 10.1016/j.imavis.2013.09.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 282DU
UT WOS:000329151300005
DA 2024-07-18
ER

PT J
AU Yu, ZW
   Wong, HS
   Wen, GH
AF Yu, Zhiwen
   Wong, Hau-San
   Wen, Guihua
TI A modified support vector machine and its application to image
   segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Support vector machine; Image segmentation; Classification
ID ALGORITHM
AB Recently researchers are focusing more on the study of support vector machine (SVM) due to its useful applications in a number of areas such as pattern recognition multimedia image processing and bioinformatics One of the main research issues is how to improve the efficiency of the original SVM model while preventing any deterioration of the classification performance of the model In this paper we propose a modified SVM based on the properties of support vectors and a pruning strategy to preserve support vectors while eliminating redundant training vectors at the same time The experiments on real images show that (1) our proposed approach can reduce the number of Input training vectors while preserving the support vectors which leads to a significant reduction in the computational cost while attaining similar levels of accuracy (2)The approach also works well when applied to image segmentation (C) 2010 Elsevier B V All rights reserved
C1 [Yu, Zhiwen; Wen, Guihua] S China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
   [Wong, Hau-San] City Univ Hong Kong, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 South China University of Technology; City University of Hong Kong
RP Yu, ZW (corresponding author), S China Univ Technol, Sch Comp Sci & Engn, Guangzhou, Guangdong, Peoples R China.
RI cai, bo/G-1491-2010
OI WONG, Hau-San/0000-0002-1530-7529
FU National Natural Science Foundation of China [61003174, 60973083];
   Natural Science Foundation of Guangdong Province China
   [10451064101004233]; Fundamental Research Funds for the Central
   Universities [2009ZM0255]; Research Grants Council of Hong Kong Special
   Administrative Region China [CityU 121607]; City University of Hong Kong
   [7002374]
FX The work described in this paper was partially supported by grants from
   National Natural Science Foundation of China (Project No 61003174 and
   60973083) a grant from Natural Science Foundation of Guangdong Province
   China (Project No 10451064101004233) a grant from the Fundamental
   Research Funds for the Central Universities (Project No 2009ZM0255) a
   grant from the Research Grants Council of Hong Kong Special
   Administrative Region China (Project No CityU 121607) and a grant from
   the City University of Hong Kong (Project No 7002374)
CR Akaike H., 1985, CELEBRATION STAT ISI
   [Anonymous], 1998, STAT LEARNING THEORY
   [Anonymous], FINDING GROUPS DATA
   [Anonymous], 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389
   Bennett K.P., 2000, ICML, P57
   Brox T, 2006, IEEE T IMAGE PROCESS, V15, P3213, DOI 10.1109/TIP.2006.877481
   Carson C, 2002, IEEE T PATTERN ANAL, V24, P1026, DOI 10.1109/TPAMI.2002.1023800
   Chang CC, 2001, NEURAL COMPUT, V13, P2119, DOI 10.1162/089976601750399335
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   DAVIES DL, 1979, IEEE T PATTERN ANAL, V1, P224, DOI 10.1109/TPAMI.1979.4766909
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dong JX, 2005, IEEE T PATTERN ANAL, V27, P603, DOI 10.1109/TPAMI.2005.77
   Drucker H, 1997, ADV NEUR IN, V9, P155
   Duda R. O., 2000, PATTERN CLASSIFICATI
   Dunn J. C., 1974, Journal of Cybernetics, V4, P95, DOI 10.1080/01969727408546059
   Franc V, 2003, PATTERN RECOGN, V36, P1985, DOI 10.1016/S0031-3203(03)00060-8
   FRIESS TT, 1998, 752 ACSE TR U SHEFF
   Gao S, 2005, IEEE T IMAGE PROCESS, V14, P1537, DOI 10.1109/TIP.2005.852200
   GAZIT MH, 2006, IEEE T IMAGE PROCESS, V15, P354
   Joachims T., 2000, International Conference on Machine Learning, P431
   Joachims Thorsten, 2005, P 22 INT C MACH LEAR, P377, DOI DOI 10.1145/1102351.1102399
   Keerthi SS, 2000, IEEE T NEURAL NETWOR, V11, P124, DOI 10.1109/72.822516
   KEERTHI SS, 1999, 9903 TR ISL IISC BAN
   Kohonen T., 1997, Self-Organizing Maps
   Li J, 2003, IEEE T PATTERN ANAL, V25, P1075, DOI 10.1109/TPAMI.2003.1227984
   Lie J, 2006, IEEE T IMAGE PROCESS, V15, P1171, DOI 10.1109/TIP.2005.863956
   Luo QM, 2006, IEEE T IMAGE PROCESS, V15, P2755, DOI 10.1109/TIP.2006.877342
   Mavroforakis ME, 2006, INT C PATT RECOG, P564
   Mavroforakis ME, 2006, IEEE T NEURAL NETWOR, V17, P671, DOI 10.1109/TNN.2006.873281
   Mukherjee DP, 2004, IEEE T IMAGE PROCESS, V13, P562, DOI 10.1109/TIP.2003.819858
   Platt J. C., 1998, NIPS, V11, P557
   RISSANEN J, 1978, AUTOMATICA, V14, P465, DOI 10.1016/0005-1098(78)90005-5
   Schlesinger M. I., 2002, 10 LECT STAT STRUCT
   Schlkopf B., 1997, P 10 INT C NEUR INF, P640
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Smola AJ, 1999, ADV NEUR IN, V11, P585
   THEODONDIS S, 2006, PATTERN RECOGNITION
   Xiang C, 2006, IEEE T IMAGE PROCESS, V15, P2097, DOI 10.1109/TIP.2006.875225
   Zhu SC, 1996, IEEE T PATTERN ANAL, V18, P884, DOI 10.1109/34.537343
NR 39
TC 36
Z9 48
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2011
VL 29
IS 1
BP 29
EP 40
DI 10.1016/j.imavis.2010.08.003
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 679BP
UT WOS:000284134700003
DA 2024-07-18
ER

PT J
AU Lladó, X
   Del Bue, A
   Agapito, L
AF Llado, Xavier
   Del Bue, Alessio
   Agapito, Lourdes
TI Non-rigid metric reconstruction from perspective cameras
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Non-rigid structure from motion; Motion segmentation; Self-calibration;
   Non-linear optimization; Deformable model
ID STRUCTURE-FROM-MOTION; EUCLIDEAN RECONSTRUCTION; PROJECTIVE STRUCTURE;
   FACTORIZATION METHOD; IMAGE; SHAPE; TRACKING; OBJECTS
AB The metric reconstruction of a non-rigid object viewed by a generic camera poses new challenges since current approaches for Structure from Motion assume the rigidity constraint of a shape as an essential condition. In this work, we focus on the estimation of the 3-D Euclidean shape and motion of a non-rigid shape observed by a perspective camera. In such case deformation and perspective effects are difficult to decouple - the parametrization of the 3-D non-rigid body may mistakenly account for the perspective distortion. Our method relies on the fact that it is often a reasonable assumption that some of the points on the object's surface are deforming throughout the sequence while others remain rigid. Thus, relying on the rigidity constraints of a subset of rigid points, we estimate the perspective to metric upgrade transformation. First, we use an automatic segmentation algorithm to identify the set of rigid points. These are then used to estimate the internal camera calibration parameters and the overall rigid motion. Finally, we formulate the problem of non-rigid shape and motion estimation as a non-linear optimization where the objective function to be minimized is the image reprojection error. The prior information that some of the points in the object are rigid can also be added as a constraint to the non-linear minimization scheme in order to avoid ambiguous configurations. We perform experiments on different synthetic and real data sets which show that even when using a minimal set of rigid points and when varying the intrinsic camera parameters it is possible to obtain reliable metric information. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Llado, Xavier] Univ Girona, Inst Informat & Applicat, Girona 17071, Spain.
   [Del Bue, Alessio] Ist Italiano Tecnol, I-16163 Genoa, Italy.
   [Agapito, Lourdes] Queen Mary Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.
C3 Universitat de Girona; Istituto Italiano di Tecnologia - IIT; University
   of London; Queen Mary University London
RP Lladó, X (corresponding author), Univ Girona, Inst Informat & Applicat, Campus Montilivi, Girona 17071, Spain.
EM llado@eia.udg.edu; alessio.delbue@iit.it; lourdes@dcs.qmul.ac.uk
RI Llado, Xavier/L-1141-2014
OI Llado, Xavier/0000-0003-2777-3479; Del Bue, Alessio/0000-0002-2262-4872;
   Agapito, Lourdes/0000-0002-6947-1092
FU MEC [DPI2007-66796-C03-02]; EPSRC [GR/S61539/01]; FCT
   [PTDC/EEA-ACR/72201/2006]; Fundação para a Ciência e a Tecnologia
   [PTDC/EEA-ACR/72201/2006] Funding Source: FCT
FX This work has been supported by MEC Grant DPI2007-66796-C03-02, EPSRC
   Grant GR/S61539/01, and by FCT through the POS_Conhecimento Program and
   Grant PTDC/EEA-ACR/72201/2006. We would like to thank Dr. J. Xiao and
   Prof. T. Kanade for sharing their code.
CR Aans H., 2002, WORKSH VIS MOD DYN S
   [Anonymous], P ECCV
   [Anonymous], P AUSTR JAP ADV WORK
   [Anonymous], MEM FAC ENG OKAYAMA
   [Anonymous], ADV NEURAL INFORM PR
   BARTOLI A, 2008, P IEEE C COMP VIS PA
   BARTOLI A, 2006, P WORKSH DYN VIS BEI, P257
   Brand M, 2005, PROC CVPR IEEE, P122
   Brand M, 2001, PROC CVPR IEEE, P456
   Bregler C, 2000, PROC CVPR IEEE, P690, DOI 10.1109/CVPR.2000.854941
   Chen HF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P878, DOI 10.1109/ICCV.2003.1238441
   Christy S, 1996, IEEE T PATTERN ANAL, V18, P1098, DOI 10.1109/34.544079
   Costeira JP, 1998, INT J COMPUT VISION, V29, P159, DOI 10.1023/A:1008000628999
   Del Bue A, 2007, IMAGE VISION COMPUT, V25, P297, DOI 10.1016/j.imavis.2005.10.004
   Del Bue A, 2005, LECT NOTES COMPUT SC, V3723, P97
   Del Bue A., 2006, PROC IEEE C COMPUTER, V1, P1191
   Del Bue A, 2008, P IEEE C COMP VIS PA
   Fan LX, 2008, LECT NOTES COMPUT SC, V5304, P182
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Han M, 2000, PROC CVPR IEEE, P542, DOI 10.1109/CVPR.2000.854908
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   HARTLEY R, 2008, P 10 EUR C COMP VIS
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Heyden A, 1999, IMAGE VISION COMPUT, V17, P981, DOI 10.1016/S0262-8856(99)00002-5
   Heyden A, 1997, PROC CVPR IEEE, P438, DOI 10.1109/CVPR.1997.609362
   Kanatani K., 2002, INT J IMAGE GRAPH, V2, P179
   KIM T, 2004, P AS C COMP VIS JEJ
   Lladó X, 2006, INT C PATT RECOG, P139
   Mahamud S, 2000, PROC CVPR IEEE, P430, DOI 10.1109/CVPR.2000.854872
   Oliensis J, 2007, IEEE T PATTERN ANAL, V29, P2217, DOI 10.1109/TPAMI.2007.1132
   OLSEN S, 2007, P 18 BRIT MACH VIS C
   Paladini Marco, 2009, P IEEE C COMP VIS PA
   Poelman C.J., 1994, PROC 3 EUROPEAN C CO, P97
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   Pollefeys M., 1999, Ph.D. Thesis
   Tang W. K., 2002, Pattern Recognition. 24th DAGM Symposium. Proceedings (Lecture Notes in Computr Science Vol.2449), P387
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Tordoff BJ, 2005, IEEE T PATTERN ANAL, V27, P1523, DOI 10.1109/TPAMI.2005.199
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Torr PHS, 1999, INT J COMPUT VISION, V32, P27, DOI 10.1023/A:1008140928553
   Torresani L, 2001, PROC CVPR IEEE, P493
   Torresani L, 2008, IEEE T PATTERN ANAL, V30, P878, DOI 10.1109/TPAMI.2007.70752
   Triggs B, 1996, PROC CVPR IEEE, P845, DOI 10.1109/CVPR.1996.517170
   UESHIBA T, 1998, P 5 ECCV, V1, P296
   Vidal R, 2004, PROC CVPR IEEE, P310
   VIDAL R, 2006, P 9 EUR C COMP VIS G, V2, P205
   Wang GH, 2008, IEEE T SYST MAN CY B, V38, P90, DOI 10.1109/TSMCB.2007.910534
   Wang G, 2008, PATTERN RECOGN LETT, V29, P72, DOI 10.1016/j.patrec.2007.09.004
   Wang GH, 2007, PATTERN RECOGN LETT, V28, P507, DOI 10.1016/j.patrec.2006.09.006
   Wang HZ, 2004, IEEE T PATTERN ANAL, V26, P1459, DOI 10.1109/TPAMI.2004.109
   Xiao J, 2005, IEEE I CONF COMP VIS, P1075
   Xiao J, 2004, LECT NOTES COMPUT SC, V2034, P573
   Yan JY, 2006, LECT NOTES COMPUT SC, V3954, P94
NR 53
TC 11
Z9 14
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2010
VL 28
IS 9
BP 1339
EP 1353
DI 10.1016/j.imavis.2010.01.014
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 620NN
UT WOS:000279506700002
DA 2024-07-18
ER

PT J
AU Kim, DW
   Choi, YG
   Kim, HS
   Yoo, JS
   Choi, HJ
   Seo, YH
AF Kim, Dong-Wook
   Choi, Young-Geun
   Kim, Hwa-Sung
   Yoo, Ji-Sang
   Choi, Hyun-Jun
   Seo, Young-Ho
TI The problems in digital watermarking into intra-frames of H.264/AVC
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE H.264/AVC; Digital watermarking; Intra picture; Intra-prediction
ID VIDEO
AB Differently from other image/video compression techniques, it is not easy to find a successful watermarking scheme for H.264/AVC. Thus we, as the researchers on digital watermarking, intend to find the reason(s) of the hardness in this paper. Among the various techniques in H.264/AVC we only concern the intra-prediction in this paper, which is the main technique to form an intra picture. We closely examine the properties of intra-prediction in the aspect of digital watermarking.
   We consider three watermarking schemes: (1) a blind scheme by fixing the watermark positions without using any information from encoding process, (2) a semi-blind scheme which selects watermark positions with a threshold value of the cost function to determine the prediction mode, and (3) a blind scheme selecting only the blocks predicted by 16 x 16 mode as the one to be watermarked. These three schemes are getting more restricted in selecting the watermarking positions. The experiments showed that none of the three schemes were satisfactory. Even the error rates of the extracted watermark data were getting lower.
   After examining the data, we found the followings. The intra-prediction of H.264/AVC itself is not reversible. That is, the re-engineering of the intra pictures, which is necessary to extract the embedded watermark, does not guarantee the same results as before re-engineering. The intra-prediction modes in many blocks and the coefficient values are changed in re-engineering. In addition, watermarking and attacks further change the prediction modes and coefficient values, which make the watermarking useless.
   The reason of changing the prediction modes and the coefficient values, we concluded, is heuristics of the technique. That means the intra-prediction includes many heuristic schemes that cannot recover the data exactly. Consequently a new watermarking method rather than the conventional ones is necessary to find. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Kim, Dong-Wook; Choi, Young-Geun; Kim, Hwa-Sung; Yoo, Ji-Sang; Choi, Hyun-Jun; Seo, Young-Ho] Kwangwoon Univ, Seoul 139701, South Korea.
C3 Kwangwoon University
RP Kim, DW (corresponding author), Kwangwoon Univ, 447-1 Welgye Dong, Seoul 139701, South Korea.
EM dwkim@kw.ac.kr; hjchoi@kw.ac.kr
FU MKE/IITA [2009-F- 028-01]
FX This work was supported by the IT R&D program of MKE/IITA, [2009-F-
   028-01, Signal Processing Elements and their SoC Developments to Realize
   the Integrated Service System for Interactive Digital Holograms].
CR Cox I. J., 2002, Digital Watermarking
   *ISO IEC, 2005, ISO IEC JTC1 SC29 WG
   LU TT, 2006, CAN C EL COMP ENG MA, P2353
   NOORKAMI M, 2005, IEEE INT C IM PROC I, V2, P2353
   Noorkami M, 2007, IEEE T INF FOREN SEC, V2, P14, DOI 10.1109/TIFS.2006.890306
   QIU G, 2006, P 17 INT C PATT REC, V4, P2353
   Richardson I.E.G., 2002, Video Codec Design: Developing Image and Video Compression Systems
   RICHARDSON IEG, 2003, H 264 AVC MPEG 4 VID
   Sakazawa S, 2006, IEEE INT SYMP CIRC S, P1439
NR 9
TC 18
Z9 30
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2010
VL 28
IS 8
BP 1220
EP 1228
DI 10.1016/j.imavis.2009.12.006
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 616BJ
UT WOS:000279182400005
DA 2024-07-18
ER

PT J
AU Nilsback, ME
   Zisserman, A
AF Nilsback, Maria-Elena
   Zisserman, Andrew
TI Delving deeper into the whorl of flower segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Spatial model
AB We describe an algorithm for automatically segmenting flowers in colour photographs. This is a challenging problem because of the sheer variety of flower classes, the variability within a class and within a particular flower, and the variability of the imaging conditions - lighting, pose, foreshortening, etc.
   The method couples two models - a colour model for foreground and background, and a light generic shape model for the petal structure. This shape model is tolerant to viewpoint changes and petal deformations, and applicable across many different flower classes. The segmentations are produced using a MRF cost function optimized using graph cuts.
   We show how the components of the algorithm can be tuned to overcome common segmentation errors, and how performance can be optimized by learning parameters on a training set.
   The algorithm is evaluated on 13 flower classes and more than 750 examples. Performance is assessed against ground truth trimap segmentations. The algorithms is also compared to several previous approaches for flower segmentation. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Nilsback, Maria-Elena; Zisserman, Andrew] Univ Oxford, Dept Engn Sci, Visual Geometry Grp, Oxford OX1 3PJ, England.
C3 University of Oxford
RP Nilsback, ME (corresponding author), Univ Oxford, Dept Engn Sci, Visual Geometry Grp, 3 Parks Rd, Oxford OX1 3PJ, England.
EM men@robots.ox.ac.uk; az@robots.ox.ac.uk
CR [Anonymous], P COMP GRAPH SIGGRAP, DOI DOI 10.1145/218380.218442
   [Anonymous], 2007, P BMVC
   BORENSTEIN E, 2002, P EUR C COMP VIS, P109
   Boykov Y., 2001, International Conference on Computer Vision, V1, P105, DOI DOI 10.1109/ICCV.2001.937505
   Das M, 1999, IEEE INTELL SYST APP, V14, P24, DOI 10.1109/5254.796084
   Kumar MP, 2005, PROC CVPR IEEE, P18
   Lamdan Y., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P335, DOI 10.1109/CVPR.1988.196257
   LEIBE B, 2003, P BRIT MACH VIS C, V2, P264
   LEVIN A, 2006, P EUR C COMP VIS, V4, P581
   Manning C.D., 1999, FDN STAT NATURAL LAN
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Saitoh T, 2004, INT C PATT RECOG, P27, DOI 10.1109/ICPR.2004.1333997
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Tuytelaars T, 2003, IEEE T PATTERN ANAL, V25, P418, DOI 10.1109/TPAMI.2003.1190569
   Winn J, 2005, IEEE I CONF COMP VIS, P756
NR 16
TC 57
Z9 64
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 1049
EP 1062
DI 10.1016/j.imavis.2009.10.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200018
DA 2024-07-18
ER

PT J
AU Wang, QG
   Li, JW
   Wang, XC
AF Wang Qinggang
   Li Jianwei
   Wang Xuchu
TI Distinguishing variance embedding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Manifold learning; Dimensionality reduction; Maximum variance unfolding;
   Laplacian eigenmaps; Variance analysis
ID NONLINEAR DIMENSIONALITY REDUCTION; MANIFOLDS
AB Nonlinear dimensionality reduction is a challenging problem encountered in a variety of high dimensional data analysis. Based on the different geometric intuitions of manifolds, maximum variance unfolding (MVU) and Laplacian eigenmaps are designed for detecting the different aspects of data set. In this paper, combining the ideas of MVU and Laplacian eigenmaps, we propose a new nonlinear dimensionality reduction method called distinguishing variance embedding (DVE), which unfolds the data manifold by maximizing the global variance subject to the proximity relation preservation constraint originated in Laplacian eigenmaps. We illustrate the algorithm on easily visualized examples of curves and surfaces, as well as on actual images of faces, handwritten digits, and rotating objects. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Wang Qinggang; Li Jianwei; Wang Xuchu] Chongqing Univ, Key Lab Optoelect Technol & Syst, Minist Educ, Chongqing 400044, Peoples R China.
C3 Chongqing University
RP Wang, QG (corresponding author), Chongqing Univ, Key Lab Optoelect Technol & Syst, Minist Educ, Chongqing 400044, Peoples R China.
EM ygest@hotmail.com
CR [Anonymous], 1994, Multidimensional Scaling
   [Anonymous], 2003, Advances in Neural Information Processing Systems 15, DOI DOI 10.1109/34.682189
   Belkin M, 2002, ADV NEUR IN, V14, P585
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Burges CJC, 2005, DATA MINING AND KNOWLEDGE DISCOVERY HANDBOOK, P59, DOI 10.1007/0-387-25465-X_4
   De Silva Vin., 2002, NIPS, P705
   Diamantaras K., 1996, Principal component neural networks: theory and applications
   Duda R., 1973, Pattern Classification and Scene Analysis
   ELGAMMAL A, 2004, P 2004 IEEE COMP SOC, V1
   Golub Gene H, 2012, MATRIX COMPUTATIONS
   HULL JJ, 1994, IEEE T PATTERN ANAL, V16, P550, DOI 10.1109/34.291440
   Jolliffe I.T., 1986, Principal component analysis, DOI DOI 10.1016/0169-7439(87)80084-9
   Manor LZ., 2005, Proceedings of the Advances in Neural Information Processing Systems, V27, P1601
   Nene S. A., 1996, Tech. Rep. CUCS-005-96
   PLESS R, 2004, COMP VIS PATT REC WO, P10
   Roweis S, 2002, ADV NEUR IN, V14, P889
   Roweis SamT., 2003, J MACHINE LEARNING R, V4, P119
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Saul L.K., 2006, Semi-supervised learning, V3
   Seung HS, 2000, SCIENCE, V290, P2268, DOI 10.1126/science.290.5500.2268
   Sun J, 2006, SIAM REV, V48, P681, DOI 10.1137/S0036144504443821
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   Vlachos M., 2002, INT C KNOWLEDGE DISC, P645
   Weinberger K.Q., 2006, AAAI
   Weinberger KQ, 2006, INT J COMPUT VISION, V70, P77, DOI 10.1007/s11263-005-4939-z
   WEINBERGER KQ, 2004, P 2004 IEEE COMP SOC, V2
   Ye J., 2004, P 10 ACM SIGKDD INT, P354, DOI DOI 10.1145/1014052.1014092
   Zhang ZY, 2004, SIAM J SCI COMPUT, V26, P313, DOI 10.1137/S1064827502419154
NR 28
TC 4
Z9 4
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 872
EP 880
DI 10.1016/j.imavis.2009.11.003
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200003
DA 2024-07-18
ER

PT J
AU Delac, K
   Grgic, M
   Grgic, S
AF Delac, Kresimir
   Grgic, Mislav
   Grgic, Sonja
TI Face recognition in JPEG and JPEG2000 compressed domain
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face Recognition; Compressed Domain; JPEG; JPEG2000; DCT; DWT
ID IMAGE; EIGENFACES; COMPONENT; PCA
AB In this paper we investigate the potential of performing face recognition in JPEG and JPEG2000 compressed domain. This is achieved by avoiding full decompression and using transform coefficients as input to face recognition algorithms. We propose a new comparison methodology and by employing it show that face recognition can efficiently be implemented directly into compressed domain. In the first part of our experiment we use all the available transform coefficients and show that recognition rates are comparable and in some cases even higher than recognition rates obtained by using pixels from uncompressed images (standard face recognition approach). In the second part, we propose an effective coefficient preselection method (applicable both in JPEG and JPEG2000 compressed domain). Our results show that by using the proposed method, recognition rates can be significantly improved while additionally reducing computational time. Finally, we propose what a hypothetical compressed domain face recognition system should look like. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Delac, Kresimir; Grgic, Mislav; Grgic, Sonja] Univ Zagreb, Fac Elect Engn & Comp, Dept Wireless Commun, HR-10000 Zagreb, Croatia.
C3 University of Zagreb
RP Grgic, M (corresponding author), Univ Zagreb, Fac Elect Engn & Comp, Dept Wireless Commun, Unska 3-12, HR-10000 Zagreb, Croatia.
EM kdelac@ieee.org; mgrgic@ieee.org; sgrgic@ieee.org
RI Grgic, Mislav/B-6128-2008
OI Grgic, Mislav/0000-0001-6230-3734; Grgic, Sonja/0000-0002-0802-3288
FU Ministry of Science, Education and Sports of the Republic of Croatia
   [036-0982560-1643]
FX The work described in this paper was conducted under the research
   project: "Intelligent Image Features Extraction in Knowledge Discovery
   Systems" (036-0982560-1643), supported by the Ministry of Science,
   Education and Sports of the Republic of Croatia.
CR [Anonymous], FRVT 2000 EVALUATION
   [Anonymous], P 2 INT C INF TECHN
   [Anonymous], FACE RECOGNITION
   *ANSI INCITS, 2004, 3852004 ANSI INCITS
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Beveridge JR, 2001, PROC CVPR IEEE, P535
   BEVERIDGE JR, 2001, IEEE 3 WORKSH EMP EV
   Chen WL, 2005, PATTERN RECOGN LETT, V26, P2474, DOI 10.1016/j.patrec.2005.05.004
   Chien JT, 2002, IEEE T PATTERN ANAL, V24, P1644, DOI 10.1109/TPAMI.2002.1114855
   Delac K, 2005, INT J IMAG SYST TECH, V15, P252, DOI 10.1002/ima.20059
   Delac K, 2005, LECT NOTES COMPUT SC, V3687, P136
   Delac K, 2004, PROCEEDINGS ELMAR-2004: 46TH INTERNATIONAL SYMPOSIUM ELECTRONICS IN MARINE, P184
   DELAC K, 2007, FACE RECOGNITION, P75
   Delac K., 2007, P 14 INT WORKSH SYST, P155
   Eickeler S, 2000, IMAGE VISION COMPUT, V18, P279, DOI 10.1016/S0262-8856(99)00055-4
   EICKELER S, 1999, P 1999 INT C IM PROC, V1, P672
   Ekenel HK, 2005, IMAGE VISION COMPUT, V23, P469, DOI 10.1016/j.imavis.2004.09.002
   Elad M, 2007, IEEE T IMAGE PROCESS, V16, P2379, DOI 10.1109/TIP.2007.903259
   Feng GC, 2000, J ELECTRON IMAGING, V9, P226, DOI 10.1117/1.482742
   FONSECA P, 2004, ICIP 2004, V3, P2015
   Funk W, 2005, Proceedings from the Sixth Annual IEEE Systems, Man and Cybernetics Information Assurance Workshop, P72, DOI 10.1109/IAW.2005.1495936
   Garcia C, 2000, IMAGE VISION COMPUT, V18, P289, DOI 10.1016/S0262-8856(99)00056-6
   Hafed ZM, 2001, INT J COMPUT VISION, V43, P167, DOI 10.1023/A:1011183429707
   Huitao Luo, 2000, Proceedings ACM Multimedia 2000, P285
   *ISO IEC, 2004, JTC1 ISOIEC
   Li B, 2002, KNOWL-BASED SYST, V15, P343, DOI 10.1016/S0950-7051(01)00172-1
   Li S.Z., 2005, Handbook of Face Recognition
   Mandal MK, 1999, IMAGE VISION COMPUT, V17, P513, DOI 10.1016/S0262-8856(98)00143-7
   MASCHERKAMPFER A, 2007, P SPIE, V6508
   Matschitsch S, 2007, LECT NOTES COMPUT SC, V4642, P232
   McGarry DP, 2004, P SOC PHOTO-OPT INS, V5404, P362, DOI 10.1117/12.543054
   McNemar Q, 1947, PSYCHOMETRIKA, V12, P153, DOI 10.1007/BF02295996
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Rakshit S, 2007, IEEE T INF FOREN SEC, V2, P605, DOI 10.1109/TIFS.2007.902401
   SABHARWAL CL, 1997, SMART ENG SYSTEMS, V7, P555
   Seales WB, 1998, IMAGE VISION COMPUT, V16, P337, DOI 10.1016/S0262-8856(97)00072-3
   Shneier M, 1996, IEEE T PATTERN ANAL, V18, P849, DOI 10.1109/34.531805
   Skodras A, 2001, IEEE SIGNAL PROC MAG, V18, P36, DOI 10.1109/79.952804
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Zhang BL, 2004, IEEE T NEURAL NETWOR, V15, P166, DOI 10.1109/TNN.2003.820673
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 43
TC 21
Z9 21
U1 1
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1108
EP 1120
DI 10.1016/j.imavis.2008.10.007
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000012
DA 2024-07-18
ER

PT J
AU Wu, HHP
   Lee, MT
   Weng, PK
   Chen, SL
AF Wu, Hsien-Huang P.
   Lee, Meng-Tu
   Weng, Ping-Kuo
   Chen, Soon-Lin
TI Epipolar geometry of catadioptric stereo systems with planar mirrors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Catadioptric stereo system; Affine epipolar geometry; Fundamental
   matrix; Reflection transformation
ID FUNDAMENTAL MATRIX; MOTION
AB In order to simplify the design and implementation of a stereo vision system, catadioptric instruments have been used to capture stereo images with a single camera. These catadioptric stereo systems not only provide radiometric advantages over traditional two-camera stereo, but also reduce the complexity and cost of acquiring stereoscopic video. Although much research has been done on the design of the catadioptric stereo system, little attention has been paid to analyze the planar catadioptric stereo (PCS) system based on the epipolar geometry. in this paper, we investigated characteristics of a selected PCS system and proved that it can be approximated by affine epipolar geometry. This affine model reduces the number of parameters in the fundamental matrix from seven in the conventional stereo system to only four in the PCS system. Experimental results verify that estimation of the fundamental matrix for a PCS system can be more robust, precise, and much easier to implement with the affine model. Furthermore, rectification of the image pair based on the affine fundamental matrix can achieve better performance with much less geometric distortion. These significant advantages confirm the usefulness of an affine fundamental matrix model for the selected PCS system. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Wu, Hsien-Huang P.; Lee, Meng-Tu] Natl Yunlin Univ Sci & Technol, Grad Sch Engn Sci & Technol, Touliu 640, Taiwan.
   [Lee, Meng-Tu] Nan Kai Inst Technol, Dept Comp Sci & Informat Engn, Tianjin, Peoples R China.
   [Weng, Ping-Kuo; Chen, Soon-Lin] Chung Shan Inst Sci & Technol, Mat RD Ctr, Solid State Devices Mat Sect, Tao Yuan 325, Taiwan.
C3 National Yunlin University Science & Technology; Chung-Shan Institute of
   Science & Technology
RP Wu, HHP (corresponding author), Natl Yunlin Univ Sci & Technol, Grad Sch Engn Sci & Technol, 123 Univ Rd,Sect 3 Yunlin, Touliu 640, Taiwan.
EM wuhp@yuntech.edu.tw
FU National Science Council [NSC 93-2211E-224-009]; CSIST [BV95GO9P]
FX The authors gratefully acknowledge the helpful suggestions made by the
   anonymous reviewers for improving the paper from its earlier draft. They
   also wish to express their appreciation for the supports of the National
   Science Council under NSC 93-2211E-224-009 and the CSIST under BV95GO9P.
   The Matlab codes for camera calibration and F matrix estimation offered
   by Refs. [29] and [25], respectively, are greatly appreciated.
CR [Anonymous], CAMERA CALIBRATION T
   Armangué X, 2003, IMAGE VISION COMPUT, V21, P205, DOI 10.1016/S0262-8856(02)00154-3
   Cabral ELL, 2004, INT C PATT RECOG, P1, DOI 10.1109/ICPR.2004.1333989
   Chesi G, 2002, IEEE T PATTERN ANAL, V24, P397, DOI 10.1109/34.990139
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   Geyer C, 2001, INT J COMPUT VISION, V45, P223, DOI 10.1023/A:1013610201135
   Gluckman J, 2001, INT J COMPUT VISION, V44, P65, DOI 10.1023/A:1011172403203
   GLUCKMAN J, 1998, P 1998 DARPA IM UND, P309
   GOSHTASBY A, 1993, PATTERN RECOGN, V26, P923, DOI 10.1016/0031-3203(93)90058-5
   Harris C., 1998, ALVEY VISION C, P147
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley RI, 1999, INT J COMPUT VISION, V35, P115, DOI 10.1023/A:1008115206617
   Hecht E., 1997, OPTICS
   INABA M, 1993, P INT C ROB SYST, V3, P26
   Kang SB, 2000, PROC CVPR IEEE, P201, DOI 10.1109/CVPR.2000.855820
   Lehmann S, 2007, IEEE T PATTERN ANAL, V29, P82, DOI 10.1109/TPAMI.2007.250601
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   Luong QT, 1996, INT J COMPUT VISION, V17, P43, DOI 10.1007/BF00127818
   MITSUMOTO H, 1992, IEEE T PATTERN ANAL, V14, P941, DOI 10.1109/34.161352
   Mundy J., 1992, GEOMETRIC INVARIANCE
   Quan L, 1997, IEEE T PATTERN ANAL, V19, P834, DOI 10.1109/34.608285
   SHAPIRO LS, 1995, INT J COMPUT VISION, V16, P147, DOI 10.1007/BF01539553
   Southwell D., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P378, DOI 10.1109/ICPR.1996.546053
   Svoboda T, 2002, INT J COMPUT VISION, V49, P23, DOI 10.1023/A:1019869530073
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhang ZY, 1997, INT JOINT CONF ARTIF, P1502
   ZHANG ZY, 1998, P INT C PATTERN RECO, V2, P16
NR 30
TC 11
Z9 16
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1047
EP 1061
DI 10.1016/j.imavis.2008.09.007
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000007
DA 2024-07-18
ER

PT J
AU Deruyver, A
   Hodé, Y
AF Deruyver, Aline
   Hode, Yann
TI Qualitative spatial relationships for image interpretation by using a
   conceptual graph
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Image interpretation; Spatial relationships; Conceptual graph;
   Arc-consistency analysis
ID CONSISTENCY; ARC
AB In this paper, a new way to express complex spatial relations is proposed in order to integrate them in a Constraint Satisfaction Problem with bilevel constraints (CSPBC). The two levels of constraint were introduced to deal with the non bijective matching between segmented regions of an image and the nodes of a conceptual graph describing the semantic content of the image. This new system of spatial relations allows to build conceptual graphs describing more precisely the spatial relations between subparts of a composite object that we look for in an image. For example, it allows to express complex spatial relations such as "is surrounded by". This approach can be applied to image interpretation and some examples on real images are presented. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Deruyver, Aline] CNRS ULP, UMR 7005, LSIIT, F-67000 Strasbourg, France.
   [Hode, Yann] Ctr Hosp, G08, F-68250 Rouffach, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universites de
   Strasbourg Etablissements Associes; Universite de Strasbourg
RP Deruyver, A (corresponding author), CNRS ULP, UMR 7005, LSIIT, F-67000 Strasbourg, France.
EM aline.deruyver@libertysurf.fr
CR Bauckhage C, 2004, INT J PATTERN RECOGN, V18, P497, DOI 10.1142/S0218001404003198
   BERTOLINO P, 1996, P IEEE ICIP96 LAUS S, P357
   BESSIERE C, 1994, ARTIF INTELL, V65, P179, DOI 10.1016/0004-3702(94)90041-8
   Bloch I, 2005, IMAGE VISION COMPUT, V23, P89, DOI 10.1016/j.imavis.2004.06.013
   Bookstein F., 1997, MORPHOMETRIC TOOLS L
   Cohn AnthonyG., 1997, Spatial and Temporal Reasoning, P97
   Conte D, 2004, INT J PATTERN RECOGN, V18, P265, DOI 10.1142/S0218001404003228
   Deruyver A, 1997, ARTIF INTELL, V93, P321, DOI 10.1016/S0004-3702(97)00022-2
   DERUYVER A, 2001, P GBR 2001 ISCH IT, P137
   DERUYVER A, P RFIA C 2006 CD
   Hudelot C, 2008, FUZZY SET SYST, V159, P1929, DOI 10.1016/j.fss.2008.02.011
   Hunter J., 2001, First International Semantic Web Working Symposium (SWWS'01), P261
   HUNTER J, 2003, IEEE T CIRCUITS SYST, V12, P19
   Jolion JM, 2003, PATTERN RECOGN LETT, V24, P1035, DOI 10.1016/S0167-8655(02)00249-0
   Keselman Y, 2005, IEEE T PATTERN ANAL, V27, P1141, DOI 10.1109/TPAMI.2005.139
   Laemmer E, 2002, IEEE IMAGE PROC, P789
   MOHR R, 1986, ARTIF INTELL, V28, P225, DOI 10.1016/0004-3702(86)90083-4
   Skiadopoulos S, 2004, ARTIF INTELL, V152, P143, DOI 10.1016/S0004-3702(03)00137-1
   Sun HB, 2005, PROCEEDINGS OF 2005 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-9, P1851
   Tu ZW, 2005, INT J COMPUT VISION, V63, P113, DOI 10.1007/s11263-005-6642-x
   VANHENTENRYCK P, 1992, ARTIF INTELL, V57, P291, DOI 10.1016/0004-3702(92)90020-X
NR 21
TC 11
Z9 11
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 876
EP 886
DI 10.1016/j.imavis.2008.10.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300006
DA 2024-07-18
ER

PT J
AU Prieto, MS
   Allen, AR
AF Prieto, Miguel S.
   Allen, Alastair R.
TI Using self-organising maps in the detection and recognition of road
   signs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Road sign detection; Road sign recognition; Self-organising map
ID CLASSIFICATION; CLASSIFIERS
AB Road sign recognition is a part of driver support systems. Its main aim is the increase of traffic safety by calling the driver's attention to the presence of key traffic signs. Additionally, a vision-based system able to detect and classify traffic signs from road images in real-time would also be useful as a support tool for guidance and navigation of intelligent vehicles. This paper proposes a new method for the detection and recognition of traffic signs using self-organising maps (SOM). This method first detects potential road signs by analysing the distribution of red pixels within the image, and then identifies these road signs from the distribution of dark pixels in their pictograms. Additionally, a novel hybrid system combining programmable hardware and artificial neural networks for embedded machine vision is introduced, and a prototype of this system is used in the implementation of the application. The experiments indicate a good performance of the new approach using SOM in both speed and classification accuracy. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Prieto, Miguel S.; Allen, Alastair R.] Univ Aberdeen, Sch Engn, Aberdeen AB24 3UE, Scotland.
C3 University of Aberdeen
RP Allen, AR (corresponding author), Univ Aberdeen, Sch Engn, Fraser Noble Bldg, Aberdeen AB24 3UE, Scotland.
EM a.allen@abdn.ac.uk
RI Allen, Alastair R/B-3605-2012
FU AXEON Limited
FX The authors gratefully acknowledge the support of AXEON Limited for this
   work.
CR BENALLAL M, 2003, P IEEE CAN C EL COMP
   Cyganek B, 2007, INTEGR COMPUT-AID E, V14, P323
   de la Escalera A, 2003, IMAGE VISION COMPUT, V21, P247, DOI 10.1016/S0262-8856(02)00156-7
   delaEscalera A, 1997, IEEE T IND ELECTRON, V44, P848, DOI 10.1109/41.649946
   Dickmanns ED, 1999, VEHICLE SYST DYN, V31, P325, DOI 10.1076/vesd.31.5.325.8359
   Douville P, 2000, REAL-TIME IMAGING, V6, P185, DOI 10.1006/rtim.1998.0142
   ESTABLE S, 1994, P INT VEH 94 S
   Fang CY, 2004, COMPUT VIS IMAGE UND, V96, P237, DOI 10.1016/j.cviu.2004.02.007
   Ford A., 1998, COLOUR SPACE CONVERS
   Fu L., 1994, NEURAL NETWORKS COMP
   Gavrila D.M., 1999, COMPUTER VISION, V1, P87, DOI DOI 10.1109/ICCV.1999.791202
   GAVRILA DM, 1999, P 21 DAGM S MUST, P86
   Ghica R, 1994, P CAN C EL COMP ENG
   Hsu SH, 2001, IMAGE VISION COMPUT, V19, P119, DOI 10.1016/S0262-8856(00)00050-0
   *INF COMM THEOR GR, INF COMM THEOR GROUP
   International Telecommunications Union, BT601 ITUR
   Johansson B., 2002, ROAD SIGN RECOGNITIO
   Kehtarnavaz N., 1993, Machine Vision and Applications, V6, P206, DOI 10.1007/BF01212298
   Kim E., 2002, P INT C INF TECHN AP
   KOHONEN T, 1982, BIOL CYBERN, V44, P135, DOI 10.1007/BF00317973
   Koncar A, 2007, PATTERN RECOGN LETT, V28, P260, DOI 10.1016/j.patrec.2006.07.012
   Krumbiegel D., 1992, Proceedings of the Fifth IFAC/IFIP/IFORS/IEA Symposium on Analysis, Design and Evaluation of Man-Machine Systems, P201
   Lalonde M., 1995, ROAD SIGN RECOGNITIO
   Liu YS, 2007, INT J IMAG SYST TECH, V17, P28, DOI 10.1002/ima.20095
   Nguwi YY, 2008, NEURAL COMPUT APPL, V17, P265, DOI 10.1007/s00521-007-0120-z
   Paclík P, 2000, PATTERN RECOGN LETT, V21, P1165, DOI 10.1016/S0167-8655(00)00078-7
   PACLIK P, 1998, THESIS CZECH TECHNIC
   PACLIK P, 2000, ASCI 2000
   Piccioli G, 1996, IMAGE VISION COMPUT, V14, P209, DOI 10.1016/0262-8856(95)01057-2
   Priese L., 1994, Proceedings of the Intelligent Vehicles '94 Symposium (Cat. No.94TH8011), P249, DOI 10.1109/IVS.1994.639514
   PRIETO MS, 2008, MACHINE VISION APPL, V19
   REHRMANN V, 1998, ACCV, V1, P598
   RITTER W, 1995, MATH COMPUT MODEL, V22, P149, DOI 10.1016/0895-7177(95)00131-K
   SUETENS P, 1992, ACM COMPUT SURV, V24, P5
   Zadeh M., 1998, Proceedings of the SPIE intelligent system and automated manufacturing, P272
NR 35
TC 62
Z9 63
U1 0
U2 19
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 673
EP 683
DI 10.1016/j.imavis.2008.07.006
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000008
DA 2024-07-18
ER

PT J
AU Gracias, N
   Mahoor, M
   Negahdaripour, S
   Gleason, A
AF Gracias, Nuno
   Mahoor, Mohammad
   Negahdaripour, Shahriar
   Gleason, Arthur
TI Fast image blending using watersheds and graph cuts
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 17th Annual British Machine Vision Conference
CY SEP, 2006
CL British Machine Vis Assoc, Edinburgh, SCOTLAND
HO British Machine Vis Assoc
DE Image mosaicing; Watershed segmentation; Graph cuts; 3-D texture
   blending
AB This paper presents a novel approach for combining a set of registered images into a composite mosaic with no visible seams and minimal texture distortion. To promote execution speed in building large area mosaics, the mosaic space is divided into disjoint regions of image intersection based on a geometric criterion. Pair-wise image blending is performed independently in each region by means of watershed segmentation and graph cut optimization. A contribution of this work - use of watershed segmentation on image differences to find possible Cuts over areas of low photometric difference - allows for searching over a much smaller set of watershed segments, instead of over the entire set of pixels in the intersection zone. Watershed transform seeks areas of low difference when creating boundaries of each segment. Constraining the overall cutting lines to be a sequence of watershed segment boundaries results in significant reduction of search space. The solution is found efficiently via graph cut, using a photometric criterion. The proposed method presents several advantages. The use of graph Cuts over image pairs guarantees the globally optimal solution for each intersection region. The independence of such regions makes the algorithm suitable for parallel implementation. The separated use of the geometric and photometric criteria leads to reduced memory requirements and a compact storage of the input data. Finally, it allows the efficient creation of large mosaics, without user intervention. We illustrate the performance of the approach on image sequences with prominent 3-D content and moving objects. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Gracias, Nuno] Univ Girona, EIA Dept, PIV, Girona 17003, Spain.
   [Mahoor, Mohammad; Negahdaripour, Shahriar] Univ Miami, ECE Dept, Coral Gables, FL 33124 USA.
   [Gleason, Arthur] Univ Miami, RSMAS MGG, Miami, FL 33149 USA.
C3 Universitat de Girona; University of Miami; University of Miami
RP Gracias, N (corresponding author), Univ Girona, EIA Dept, PIV, Girona 17003, Spain.
EM ngracias@isr.ist.utl.pt
RI cai, bo/G-1491-2010; Gracias, Nuno/N-1396-2019
OI Gracias, Nuno/0000-0002-4675-9595; Mahoor, Mohammad/0000-0001-8923-4660
CR Agarwala A., 2004, P SIGGRAPH04 AUG
   [Anonymous], 2003, ACM T GRAPHICS
   ARAUJO F, 1996, P 8 EUR SIGN PROC C, P181
   BAUMBERG A, 2002, P BRIT MACH VIS C CA
   Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   BURT PJ, 1983, ACM T GRAPHIC, V2, P217, DOI 10.1145/245.247
   DAVIS J, 1998, P C COMP VIS PATT RE
   Efros AA, 2001, COMP GRAPH, P341, DOI 10.1145/383259.383296
   Gracias N, 2003, J OCEAN ENG, V28
   GREIG DM, 1989, J ROY STAT SOC B MET, V51, P271, DOI 10.1111/j.2517-6161.1989.tb01764.x
   GU F, 2006, P IEEE MTS OCEANS 20
   ISHIKAWA H, 1998, EUR C COMP VIS, P232
   Janko Z., 2005, Machine Graphics & Vision, V14, P379
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Li Y, 2004, ACM T GRAPHIC, V23, P303, DOI 10.1145/1015706.1015719
   LIN MH, 2002, THESIS STANFORD U
   Lirman D, 2007, ENVIRON MONIT ASSESS, V125, P59, DOI 10.1007/s10661-006-9239-0
   Najman L, 1996, IEEE T PATTERN ANAL, V18, P1163, DOI 10.1109/34.546254
   Nguyen HT, 2003, IEEE T PATTERN ANAL, V25, P330, DOI 10.1109/TPAMI.2003.1182096
   PELEGA S, 2004, P EUR C COMP VIS ECC
   Roerdink J. B. T. M., 2000, Fundamenta Informaticae, V41, P187
   Roy S., 1999, Int. Journ. Comput. Vision, V1, P1
   Roy Sebastien, 1998, INT C COMP VIS
   Soille P, 2006, IEEE T PATTERN ANAL, V28, P673, DOI 10.1109/TPAMI.2006.99
   Su MS, 2004, IEEE T IMAGE PROCESS, V13, P952, DOI 10.1109/TIP.2004.828416
   Szeliski R, 2006, LECT NOTES COMPUT SC, V3952, P16
   Uyttendaele M, 2001, PROC CVPR IEEE, P509
   VINCENT L, 1991, IEEE T PATTERN ANAL, V13, P583, DOI 10.1109/34.87344
NR 31
TC 90
Z9 141
U1 0
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 2
PY 2009
VL 27
IS 5
SI SI
BP 597
EP 607
DI 10.1016/j.imavis.2008.04.014
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 437WD
UT WOS:000265516700010
DA 2024-07-18
ER

PT J
AU Xiong, WH
   Funt, B
AF Xiong, Weihua
   Funt, Brian
TI Stereo retinex
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
ID COLOR CONSTANCY; LIGHTNESS; ALGORITHM
AB The retinex algorithm for lightness and color constancy is extended to include 3-dimensional spatial information reconstructed from a stereo image. A key aspect of traditional retinex is that, within each color channel, it makes local spatial comparisons of intensity. In particular, intensity ratios are computed between neighboring spatial locations, retinex assumes that a large ratio indicates a change in surface reflectance, not a change in incident illumination; however, this assumption is often violated in 3-dimensional scenes, where an abrupt change in surface orientation can lead to a significant change in illumination. In this paper, retinex is modified to use the 3-dimensional edge information derived from stereo images. The edge map is used so that spatial comparisons are only made between locations lying on approximately the same plane in 3-dimensions. Experiments on real images show this method works well, however, they also reveal that it can lead to isolated regions, which, as a result of being isolated, are incorrectly determined to be grey. To overcome this problem, stereo retinex is extended to allow information that is orthogonal to the space of possible illuminants to propagate across changes in surface orientation. This is accomplished by transforming the original RGB image data into a color space based on coordinates of luminance, illumination and reflectance. This coordinate system allows stereo retinex to propagate reflectance information across changes in surface orientation, while at the same time inhibiting the propagation of potentially invalid illumination information. The stereo retinex algorithm builds upon the multi-resolution implementation of retinex known as McCann99. Experiments on synthetic and real images show that stereo retinex performs significantly better than unmodified McCann99 retinex when evaluated in terms of the accuracy with which correct surface object colors are estimated. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Xiong, Weihua; Funt, Brian] Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
C3 Simon Fraser University
RP Funt, B (corresponding author), Simon Fraser Univ, Sch Comp Sci, 8888 Univ Dr, Burnaby, BC V5A 1S6, Canada.
EM funt@sfu.ca
CR [Anonymous], 2000, NEW COGNITIVE NEUROS
   Barnard K, 2002, IEEE T IMAGE PROCESS, V11, P985, DOI 10.1109/TIP.2002.802529
   Barnard K, 2002, COLOR RES APPL, V27, P147, DOI 10.1002/col.10049
   BARNARD K, 2000, P 6 EUR C COMP VIS, P275
   Berthold KP, 1974, Comput. Graph. Image Process., V3, P277, DOI [DOI 10.1016/0146-664X(74)90022-7, 10.1016/0146-664X(74)90022-7]
   BLOJ MG, 1999, NATURE, V42, P23
   Boyaci H, 2003, J VISION, V3, P541, DOI 10.1167/3.8.2
   Cardei VC, 2002, J OPT SOC AM A, V19, P2374, DOI 10.1364/JOSAA.19.002374
   Finayson GD, 2001, IEEE T PATTERN ANAL, V23, P1209, DOI 10.1109/34.969113
   Finlayson GD, 2001, J OPT SOC AM A, V18, P253, DOI 10.1364/JOSAA.18.000253
   FINLAYSON GD, 1997, P AIC INT COL ASS CO, V2, P527
   FORSYTH DA, 1990, INT J COMPUT VISION, V5, P5, DOI 10.1007/BF00056770
   Frankle J. A., 1983, US Patent, Patent No. [4 384 336, 4384336, US, 4384336]
   Funt B, 2004, 12TH COLOR IMAGING CONFERENCE: COLOR SCIENCE AND ENGINEERING SYSTEMS, TECHNOLOGIES, APPLICATIONS, P47
   Funt B, 2004, J ELECTRON IMAGING, V13, P48, DOI 10.1117/1.1636761
   GELAUTZ M, P 2 INT S 3D DAT PRO, P774
   GILCHRIST AL, 1977, SCIENCE, V195, P185, DOI 10.1126/science.831266
   Hordley SD, 2006, J OPT SOC AM A, V23, P1008, DOI 10.1364/JOSAA.23.001008
   Kimmel R, 2003, INT J COMPUT VISION, V52, P7, DOI 10.1023/A:1022314423998
   LAND EH, 1971, J OPT SOC AM, V61, P1, DOI 10.1364/JOSA.61.000001
   LAND EH, 1986, VISION RES, V26, P7, DOI 10.1016/0042-6989(86)90067-2
   Rosenberg C, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P239, DOI 10.1109/ICCV.2001.937524
   Sapiro G, 1999, IEEE T PATTERN ANAL, V21, P1210, DOI 10.1109/34.809114
   Sun CM, 2002, INT J COMPUT VISION, V47, P99, DOI 10.1023/A:1014585622703
   Yamauchi Y, 2005, J VISION, V5, P515, DOI 10.1167/5.6.3
   Yang JN, 2001, VISION RES, V41, P2581, DOI 10.1016/S0042-6989(01)00143-2
   Yang JN, 2002, VISION RES, V42, P1979, DOI 10.1016/S0042-6989(02)00098-6
NR 27
TC 6
Z9 10
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 178
EP 188
DI 10.1016/j.imavis.2007.11.012
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700018
DA 2024-07-18
ER

PT J
AU Dong, JY
   Sun, GM
   Chen, GJ
AF Dong, Junyu
   Sun, Guimei
   Chen, Guojiang
TI Conversions between three methods for representing 3D surface textures
   under arbitrary illumination directions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gradient; Polynomial texture map; Eigen; Relighting; Conversion methods
ID REFLECTANCE; IMAGES
AB Representing the appearances of surfaces illuminated from different directions has long been an active research topic. While many representation methods have been proposed, the relationships and conversion between different representations have been less well researched. These relationships are important, as they provide (a) an insight as to the different capabilities of the surface representations, and (b) a means by which they may be converted to common formats for computer graphic applications. In this paper, we introduce a single mathematical framework and use it to express three commonly used surface texture relighting representations: surface gradients (Gradient), Polynomial Texture Maps (PTM) and eigen base images (Eigen). The framework explicitly reveals the relations between the three methods, and from this we propose a set of conversion methods. We use 26 rough surface textures illuminated from 36 directions for our experiments and perform both quantitative and qualitative assessments to evaluate the conversion methods. The quantitative assessment uses a normalized root-mean-squared error as metric to compare the original images and those produced by proposed representation methods. The qualitative assessment is based on psychophysical experiments and non-parametric statistics. The results from the two assessments are consistent and show that the original Eigen representation produces the best performance. The second best performances are achieved by the original PTM representation and the conversion between Polynomial Texture Maps (PTM) and eigen base images (Eigen), while the performances of other representations are not significantly different. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Dong, Junyu; Sun, Guimei] Ocean Univ China, Dept Comp Sci, Qingdao 266100, Shandong, Peoples R China.
   [Chen, Guojiang] Qingdao Univ, Coll Teachers, Qingdao 266071, Peoples R China.
C3 Ocean University of China; Qingdao University
RP Dong, JY (corresponding author), Ocean Univ China, Dept Comp Sci, 23 E Hong Kong Rd, Qingdao 266100, Shandong, Peoples R China.
EM dongjunyu@ouc.edu.cn; chenguojiang@public.qd.sd.cn
OI Dong, Junyu/0000-0001-7012-2087
FU National Science Foundation of China [60702014]
FX This work was supported by the National Science Foundation of China (No.
   60702014).
CR [Anonymous], 1987, MULTIPLE COMP PROCED, DOI DOI 10.1002/9780470316672
   [Anonymous], 1977, NATL BUREAU STANDARD
   [Anonymous], P EUR C COMP VIS
   Ashikhmin M, 2002, ACM T GRAPHIC, V21, P1, DOI 10.1145/504789.504790
   Basri R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P383, DOI 10.1109/ICCV.2001.937651
   CHANTLER MJ, 1995, IEE P-VIS IMAGE SIGN, V142, P199, DOI 10.1049/ip-vis:19952065
   Copeland A.C., 2001, OPTICAL ENG, V40, P26
   Dana KJ, 1999, ACM T GRAPHIC, V18, P1, DOI 10.1145/300776.300778
   DANA KJ, 1999, P IEEE WORKSH INT AP, P46
   Daniel W. W., 1990, 2001 P AAZV AAWV ARA, V2nd
   DONG J, 2003, THESIS HERIOTWATT U
   Dong JY, 2005, INT J COMPUT VISION, V62, P177, DOI 10.1007/s11263-005-4641-6
   Epstein J., 1995, The family school connection: Theory, research, and practice, P108
   Georghiades AS, 1999, IEEE WORKSHOP ON MULTI-VIEW MODELING & ANALYSIS OF VISUAL SCENES (MVIEW'99). PROCEEDINGS, P47, DOI 10.1109/MVIEW.1999.781082
   GULL C, 2002, THESIS HERIOTWATT U
   Holly E., 1997, P EUROGRAPHICS WORKS, P35
   HUANG TS, 1984, IMAGE RECONSTRUCTION
   Koenderink JJ, 1999, INT J COMPUT VISION, V31, P129, DOI 10.1023/A:1008061730969
   KOUDELKA ML, 2003, P 3 INT WORKSH TEXT, P59
   Lalonde P, 1997, IEEE T VIS COMPUT GR, V3, P329, DOI 10.1109/2945.646236
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Malzbender T, 2001, COMP GRAPH, P519, DOI 10.1145/383259.383320
   MCALLISTER D, 2002, EUR WORKSH GRAPH HAR, P79
   PHONG BT, 1975, COMMUN ACM, V18, P311, DOI 10.1145/360825.360839
   Ramamoorthi R, 2001, COMP GRAPH, P117, DOI 10.1145/383259.383271
   Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204
   Robb M., 2003, P VIS VID GRAPH 2003, P79
   TORRANCE KE, 1967, J OPT SOC AM, V57, P1105, DOI 10.1364/JOSA.57.001105
   WOODHAM RJ, 1981, ARTIF INTELL, V17, P117, DOI 10.1016/0004-3702(81)90022-9
   Zhang ZY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1041, DOI 10.1109/ICCV.1998.710845
NR 30
TC 4
Z9 4
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1561
EP 1573
DI 10.1016/j.imavis.2008.02.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500002
DA 2024-07-18
ER

PT J
AU Min, JH
   Kasturi, R
   Camps, O
AF Min, Junghye
   Kasturi, Rangachar
   Camps, Octavia
TI Extraction and temporal segmentation of multiple motion trajectories in
   human motion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Activity recognition; Motion trajectories; Motion tracking; Motion
   segmentation; Motion detection; Temporal segmentation
ID OPTICAL-FLOW; TRACKING; ALGORITHM; REPRESENTATION; RECOGNITION
AB A new method for extraction and temporal segmentation of multiple motion trajectories in human motion is presented. The proposed method extracts motion trajectories generated by body parts without any initialization or any assumption on color distribution. Motion trajectories are very compact and representative features for activity recognition. Tracking human body parts (hands and feet) is inherently difficult because the body parts which generate most of the motion trajectories are relatively small compared to the human body. This problem is overcome by using a new motion segmentation method: at every frame, candidate motion locations are detected and set as significant motion points (SMPs). The motion trajectories are obtained by combining these SMPs and the color-optical flow based tracker results. These motion trajectories are inturn used as features for temporal segmentation of specific activities from continuous video sequences. The proposed approach is tested on actual ballet step sequences. Experimental results show that the proposed method can successfully extract and temporally segment multiple motion trajectories from human motion. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Min, Junghye] Samsung Elect, Digital Media R&D Ctr, Suwon, South Korea.
   [Kasturi, Rangachar] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.
   [Camps, Octavia] Penn State Univ, Dept Elect Engn, University Pk, PA 16802 USA.
   [Camps, Octavia] Northeastern Univ, Dept Elect & Comp Engn, Boston, MA 02115 USA.
C3 Samsung; Samsung Electronics; State University System of Florida;
   University of South Florida; Pennsylvania Commonwealth System of Higher
   Education (PCSHE); Pennsylvania State University; Pennsylvania State
   University - University Park; Northeastern University
RP Min, JH (corresponding author), Samsung Elect, Digital Media R&D Ctr, Suwon, South Korea.
CR ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   Bab-Hadiashar A, 1998, INT J COMPUT VISION, V29, P59, DOI 10.1023/A:1008090730467
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Bobick AF, 1997, IEEE T PATTERN ANAL, V19, P1325, DOI 10.1109/34.643892
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cox IJ, 1996, IEEE T PATTERN ANAL, V18, P138, DOI 10.1109/34.481539
   Cox IJ, 1997, IEEE T AERO ELEC SYS, V33, P295, DOI 10.1109/7.570789
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Mansouri AR, 2003, IEEE T IMAGE PROCESS, V12, P201, DOI 10.1109/TIP.2002.807582
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   RANGARAJAN K, 1991, CVGIP-IMAG UNDERSTAN, V54, P56, DOI 10.1016/1049-9660(91)90075-Z
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Rasmussen C, 2001, IEEE T PATTERN ANAL, V23, P560, DOI 10.1109/34.927458
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   SHAH M, 1993, IEEE T SYST MAN CYB, V23, P1138, DOI 10.1109/21.247894
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946
   Wilson AD, 1999, IEEE T PATTERN ANAL, V21, P884, DOI 10.1109/34.790429
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P1061, DOI 10.1109/TPAMI.2002.1023803
   Ye M, 2003, IEEE T PATTERN ANAL, V25, P1625, DOI 10.1109/TPAMI.2003.1251156
NR 24
TC 8
Z9 10
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2008
VL 26
IS 12
BP 1621
EP 1635
DI 10.1016/j.imavis.2008.03.006
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 369RL
UT WOS:000260711500006
DA 2024-07-18
ER

PT J
AU Gupta, L
   Mangai, UG
   Das, S
AF Gupta, Lalit
   Mangai, Utthara Gosa
   Das, Sukhendu
TI Integrating region and edge information for texture segmentation using a
   modified constraint satisfaction neural network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE constraint satisfaction neural networks (CSNN); segmentation; texture
   edge detection; fuzzy-C means (FCM); dynamic window
ID IMAGE SEGMENTATION; CLASSIFICATION; FEATURES
AB In this paper, we propose an approach for texture segmentation by integrating region and edge information. The algorithm uses a constraint satisfaction neural network for texture segmentation with additional edge constraints. Initial class probabilities and edge maps are computed using multi-channel, multi-resolution filters to obtain image segmented map and edge map. The complementary information of the segmented map and the edge map are iteratively updated using a modified CSNN to satisfy a set of constraints to obtain superior segmentation results. The proposed methodology is tested on simulated as well as natural textures and it produces satisfactory results. The proposed methodology is also tested on a synthetic aperture radar (SAR) image. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Gupta, Lalit; Mangai, Utthara Gosa; Das, Sukhendu] Indian Inst Technol, Dept Comp Sci & Engn, Visualizat & Percept Lab, Madras 600036, Tamil Nadu, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Madras
RP Das, S (corresponding author), Indian Inst Technol, Dept Comp Sci & Engn, Visualizat & Percept Lab, Madras 600036, Tamil Nadu, India.
EM lalitemails@yahoo.com; utthara@cse.iitm.ernet.in; sdas@iitm.ac.in
RI Sahlen, Martin/C-6308-2008; Das, Sukhendu/AAP-8630-2020; Das,
   Sukhendu/F-3672-2010
OI Das, Sukhendu/0000-0002-2823-9211; 
CR Berthod M, 1996, IMAGE VISION COMPUT, V14, P285, DOI 10.1016/0262-8856(95)01072-6
   Bhattacharya U, 1997, IMAGE VISION COMPUT, V15, P937, DOI 10.1016/S0262-8856(97)00035-8
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chakraborty A, 1996, IEEE T MED IMAGING, V15, P859, DOI 10.1109/42.544503
   Chakraborty A, 1999, IEEE T PATTERN ANAL, V21, P12, DOI 10.1109/34.745730
   Chan TF, 2001, IEEE WORKSHOP ON VARIATIONAL AND LEVEL SET METHODS IN COMPUTER VISION, PROCEEDINGS, P161, DOI 10.1109/VLSM.2001.938895
   Charalampidis D, 2002, IEEE T IMAGE PROCESS, V11, P825, DOI 10.1109/TIP.2002.801117
   CHU CC, 1990, THIRD INTERNATIONAL CONFERENCE ON COMPUTER VISION, P117
   DUNN D, 1994, IEEE T PATTERN ANAL, V16, P130, DOI 10.1109/34.273736
   Ecabert O, 2002, INT C PATT RECOG, P885, DOI 10.1109/ICPR.2002.1048445
   FORSYTH P, 2003, COMPUTER VISION
   GUPTA L, 2006, 18 IEEE INT C PATT R
   Gupta L, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/94298
   HADDON JF, 1990, IEEE T PATTERN ANAL, V12, P929, DOI 10.1109/34.58867
   KOHONEN T, 1990, P IEEE, V78, P1464, DOI 10.1109/5.58325
   KURUGOLLU F, 1999, INT C IM PROC, P236
   Li CT, 2003, IMAGE VISION COMPUT, V21, P955, DOI 10.1016/S0262-8856(03)00120-3
   LIN WC, 1992, PATTERN RECOGN, V25, P679, DOI 10.1016/0031-3203(92)90132-3
   Liu JC, 1999, INT CONF ACOUST SPEE, P1105, DOI 10.1109/ICASSP.1999.759937
   Lu CS, 1997, PATTERN RECOGN, V30, P729, DOI 10.1016/S0031-3203(96)00116-1
   MAXWELL BA, 2003, P BRIT MACH VIS C, P101
   Mueller M, 2004, PATTERN RECOGN, V37, P1619, DOI 10.1016/j.patcog.2004.03.001
   Muñoz X, 2003, PATTERN RECOGN LETT, V24, P375, DOI 10.1016/S0167-8655(02)00262-3
   MUNOZ X, 2002, 2 INT WORKSH TEXT AN, P95
   MUNOZ X, 2003, IEEE INT C IM PROC, V3, P453
   Paragios N, 2002, INT J COMPUT VISION, V46, P223, DOI 10.1023/A:1014080923068
   Raghu PP, 1996, IEEE T IMAGE PROCESS, V5, P1625, DOI 10.1109/83.544570
   RAO SG, 2004, IND C COMP VIS GRAPH, P370
   Saber E, 1998, J ELECTRON IMAGING, V7, P684, DOI 10.1117/1.482605
   Sagiv C, 2006, IEEE T IMAGE PROCESS, V15, P1633, DOI 10.1109/TIP.2006.871133
   Salari E, 1995, PATTERN RECOGN, V28, P1819, DOI 10.1016/0031-3203(95)00054-2
   SALOTTI M, 1992, 11TH IAPR INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION, PROCEEDINGS, VOL III, P611, DOI 10.1109/ICPR.1992.202061
   WANG W, 2006, AS C COMP VIS HYD IN, P226
   Wu Q., 2003, Proc. DICTA, P957
   YEGNANARAYANA B, 1998, IND C COMP VIS GRAPH, P231
NR 35
TC 4
Z9 5
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1106
EP 1117
DI 10.1016/j.imavis.2007.12.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300004
DA 2024-07-18
ER

PT J
AU Gan, T
   He, Y
   Zhu, W
AF Gan, Tao
   He, Yanmin
   Zhu, Weile
TI Efficient embedded wavelet codec based on list structure
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE embedded; morphological representation; quadtree partitioning; list
   structure
ID IMAGE COMPRESSION
AB A new efficient image codec called embedded wavelet coding based on list structure (EWCBL) is proposed in this paper. By combining the techniques of morphological representation and quadtree partitioning, EWCBL effectively exploits both within-subband clustering and cross-subband similarity of wavelet coefficients. Based on the list structure, a fine fractional bit-plane coding is employed to achieve excellent rate-distortion performance. The patterned morphological dilation is introduced to greatly reduce the redundant test operations. Experimental results show that the proposed EWCBL outperforms state-of-the-art embedded codecs for both lossy and lossless compression. Moreover, the good performance and features of embeddedness and scalability are achieved with relatively low complexity. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Gan, Tao; He, Yanmin; Zhu, Weile] Univ Elect Sci & Technol China, Sch Elect Engn, Chengdu 610054, Si Chuan, Peoples R China.
C3 University of Electronic Science & Technology of China
RP Gan, T (corresponding author), Univ Elect Sci & Technol China, Sch Elect Engn, JianShe N Rd 4,Block 2, Chengdu 610054, Si Chuan, Peoples R China.
EM garrete@infomedia.net.cn
CR Chai BB, 1999, IEEE T IMAGE PROCESS, V8, P774, DOI 10.1109/83.766856
   Islam A, 1998, P SOC PHOTO-OPT INS, V3653, P294, DOI 10.1117/12.334677
   Munteanu A, 1999, INT J IMAG SYST TECH, V10, P76, DOI 10.1002/(SICI)1098-1098(1999)10:1<76::AID-IMA9>3.0.CO;2-0
   Pearlman WA, 2004, IEEE T CIRC SYST VID, V14, P1219, DOI 10.1109/TCSVT.2004.835150
   Peng KW, 2004, IEEE T IMAGE PROCESS, V13, P1011, DOI 10.1109/TIP.2004.828441
   Said A, 1996, IEEE T CIRC SYST VID, V6, P243, DOI 10.1109/76.499834
   Schelkens P, 2003, IEEE T MED IMAGING, V22, P441, DOI 10.1109/TMI.2003.809582
   Servetto SD, 1999, IEEE T IMAGE PROCESS, V8, P1161, DOI 10.1109/83.784429
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Taubman D, 2000, IEEE T IMAGE PROCESS, V9, P1158, DOI 10.1109/83.847830
   Zhong JM, 2000, IEE P-VIS IMAGE SIGN, V147, P564, DOI 10.1049/ip-vis:20000752
NR 11
TC 3
Z9 3
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2008
VL 26
IS 7
BP 898
EP 904
DI 10.1016/j.imavis.2007.10.009
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 306PR
UT WOS:000256260800004
DA 2024-07-18
ER

PT J
AU Broumandnia, A
   Shanbehzadeh, J
   Varnoosfaderani, MR
AF Broumandnia, A.
   Shanbehzadeh, J.
   Varnoosfaderani, M. Rezakhah
TI Persian/arabic handwritten word recognition using M-band packet wavelet
   transform
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE holistic word recognition; Farsi handwritings; M-band packet wavelet;
   row shift invariant
ID INVARIANT TEXTURE CLASSIFICATION; HIDDEN MARKOV MODEL;
   TRANSLATION-INVARIANT; PATTERN-RECOGNITION; SCALE; ROTATION; FEATURES;
   REPRESENTATION; DECOMPOSITION; SEGMENTATION
AB The extraction of rotation and scale invariant features is an essential problem in document image analysis. This paper proposes an effective rotation and scale invariant holistic handwritten word recognition scheme. This approach utilizes M-band packet wavelet transform to extract feature vector of Farsi word image. The global and local features extracted are exploited in recognition of limited-size lexicon of handwritten words. The rotation and scale invariant feature of a word image involves applying a polar transform to eliminate rotation and scale effects, but this produces M-row shifted polar image, which is passed to a row shift invariant M-band wavelet packet transform to eliminate the row shift effects. The output wavelet coefficients are rotation and scale invariant. For each subband of these wavelet coefficients a set of local energy features are computed and we extract feature vectors from the subbands of wavelet coefficients. The proposed polar M-band wavelet features have been tested by employing Mahalanobis algorithm to classify a set of distinct natural handwriting Farsi words. We compared the proposed scheme with two well-known rotation invariant methods; Fourier-wavelet and Zernike moments. The experimental results show that the proposed algorithm improves the recognition rate about 12 percents. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Broumandnia, A.] Islamic Azad Univ, S Tehran Branch, Dept Comp, Tehran, Iran.
   [Shanbehzadeh, J.] Tarbiat Moallem Univ, Tehran, Iran.
   [Varnoosfaderani, M. Rezakhah] Amir Kabir Univ Technol, Biomed Engn Fac, Tehran, Iran.
C3 Islamic Azad University; Kharazmi University; Amirkabir University of
   Technology
RP Broumandnia, A (corresponding author), Islamic Azad Univ, S Tehran Branch, Dept Comp, Tehran, Iran.
EM Broumandnia@azad.ac.ir; Shanbehzadeh@gmail.com; mrezakhah@aut.ac.ir
RI Broumandnia, Ali/I-6383-2018
OI Broumandnia, Ali/0000-0001-5145-2013
CR Acharyya M, 2003, IEEE T PATTERN ANAL, V25, P1639, DOI 10.1109/TPAMI.2003.1251158
   Acharyya M, 2002, IEEE T CIRC SYST VID, V12, P1117, DOI 10.1109/TCSVT.2002.806812
   ALKIN O, 1995, IEEE T SIGNAL PROCES, V43, P1579, DOI 10.1109/78.398719
   Chang JP, 1996, BIOL SIGNAL, V5, P70
   Chen GY, 1999, PATTERN RECOGN, V32, P1083, DOI 10.1016/S0031-3203(98)00148-4
   CHEN JL, 1994, IEEE T PATTERN ANAL, V16, P208, DOI 10.1109/34.273730
   COHEN FS, 1991, IEEE T PATTERN ANAL, V13, P192, DOI 10.1109/34.67648
   Cohen I, 1997, SIGNAL PROCESS, V57, P251, DOI 10.1016/S0165-1684(97)00007-8
   COIFMAN RR, 1992, IEEE T INFORM THEORY, V38, P713, DOI 10.1109/18.119732
   Coifman RR., 1995, WAVELETS STAT, P125, DOI DOI 10.1007/978-1-4612-2544-7_9
   Kan C, 2002, PATTERN RECOGN, V35, P143, DOI 10.1016/S0031-3203(00)00179-5
   KHOTANZAD A, 1990, PATTERN RECOGN, V23, P1089, DOI 10.1016/0031-3203(90)90005-6
   KHOTANZAD A, 1990, IEEE T ACOUST SPEECH, V38, P1028, DOI 10.1109/29.56063
   Krzanowski Wojtek J, 2000, PRINCIPLES MULTIVARI
   Kundu MK, 2003, INT J WAVELETS MULTI, V1, P115, DOI DOI 10.1142/S0219691303000074
   LEUNG M, 1991, P INT C AC SPEECH SI, P461
   Liang J, 1996, IEEE T SIGNAL PROCES, V44, P225, DOI 10.1109/78.485919
   Mallat S.A., 1999, WAVELET TOUR SIGNAL
   Mitchell PE, 2004, IMAGE VISION COMPUT, V22, P307, DOI 10.1016/j.imavis.2003.11.001
   Pesquet JC, 1996, IEEE T SIGNAL PROCES, V44, P1964, DOI 10.1109/78.533717
   Primer A., 1998, INTRO WAVELETS WAVEL
   PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U
   Pun CM, 2004, IEEE T PATTERN ANAL, V26, P1228, DOI 10.1109/TPAMI.2004.67
   Pun CM, 2003, IEEE T PATTERN ANAL, V25, P590, DOI 10.1109/TPAMI.2003.1195993
   RASHKOVSKIY O, 1994, P SOC PHOTO-OPT INS, V2237, P390, DOI 10.1117/12.169445
   Seber G A., 2009, Multivariate observations, DOI DOI 10.1002/9780470316641
   STEFFEN P, 1993, IEEE T SIGNAL PROCES, V41, P3497, DOI 10.1109/78.258088
   Steinherz T., 1999, International Journal on Document Analysis and Recognition, V2, P90, DOI 10.1007/s100320050040
   Tang Y.Y., 1999, Wavelet Theory and Its Application to Pattern Recognition
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
   WANG SS, 1994, PATTERN RECOGN, V27, P1735, DOI 10.1016/0031-3203(94)90090-6
   Wu WR, 1996, IEEE T IMAGE PROCESS, V5, P1423, DOI 10.1109/83.536891
   WUNSCH P, 1995, PATTERN RECOGN, V28, P1237, DOI 10.1016/0031-3203(95)00001-G
   Xiong HL, 2000, IEEE T IMAGE PROCESS, V9, P2100, DOI 10.1109/83.887977
   YOU J, 1993, PATTERN RECOGN, V26, P245, DOI 10.1016/0031-3203(93)90033-S
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 43
TC 28
Z9 29
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 2
PY 2008
VL 26
IS 6
BP 829
EP 842
DI 10.1016/j.imavis.2007.09.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 301HV
UT WOS:000255887900010
DA 2024-07-18
ER

PT J
AU Vincent, E
   Laganière, R
AF Vincent, Etienne
   Laganiere, Robert
TI Models from image triplets using epipolar gradient features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE feature based matching; 3D reconstruction; trinocular geometry; epipolar
   gradient; edge transfer
ID UNCALIBRATED IMAGES
AB In an application where sparse matching of feature points is used towards fast scene reconstruction, the choice of the type of features to be matched has an important impact on the quality of the resulting model. In this work, a method is presented for quickly and reliably selecting and matching points from three views of a scene. The selected points are based on epipolar gradients, and consist of stable image features relevant to reconstruction. Then, the selected points are matched using edge transfer, a measure of geometric consistency for point triplets and the edges on which they lie. This matching scheme is tolerant to image deformations due to changes in viewpoint. Models drawn from matches obtained by the proposed technique are shown to demonstrate its usefulness. (c) 2007 Elsevier B.V. All rights reserved.
C1 Univ Ottawa, Sch Informat Technol & Engn, VIVA Lab, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Laganière, R (corresponding author), Univ Ottawa, Sch Informat Technol & Engn, VIVA Lab, Ottawa, ON K1N 6N5, Canada.
EM laganier@site.uottawa.ca
RI Laganiere, Robert/H-9138-2013
CR Baumberg A, 2000, PROC CVPR IEEE, P774, DOI 10.1109/CVPR.2000.855899
   DERICHE R, 1994, LECT NOTES COMPUTER, V800, P567
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P133, DOI 10.1109/34.574792
   HORAUD R, 1995, VISION ORDINATEUR OU
   LACEY A, 2001, P BRIT MACH VIS C, P203
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Mokhtarian F, 2006, COMPUT VIS IMAGE UND, V102, P81, DOI 10.1016/j.cviu.2005.11.001
   Montesinos P, 2000, IMAGE VISION COMPUT, V18, P659, DOI 10.1016/S0262-8856(99)00070-0
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   ROTH G, 2000, P VIS INT, P225
   Schmid C, 2000, INT J COMPUT VISION, V37, P151, DOI 10.1023/A:1008199403446
   Schmid C, 1997, IEEE T PATTERN ANAL, V19, P530, DOI 10.1109/34.589215
   Schmid C, 2001, PROC CVPR IEEE, P39
   SHASHUA A, 1994, LECT NOTES COMPUTER, V800, P479
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Torr P, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P727, DOI 10.1109/ICCV.1998.710798
   Tuytelaars T, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1601, DOI 10.1109/ROBOT.1999.772588
   Vincent E., 2001, Machine Graphics & Vision, V10, P237
   VINCENT E, 2002, P 1 INT WORKSH HAPT, P13
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 25
TC 2
Z9 4
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1699
EP 1708
DI 10.1016/j.imavis.2006.12.021
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900001
DA 2024-07-18
ER

PT J
AU Xiao, Y
   Lim, KB
AF Xiao, Yong
   Lim, Kah Bin
TI A prism-based single-lens stereovision system: From trinocular to
   multi-ocular
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE stereovision; trinocular; multi-ocular; prism; stereo vision
ID CAMERA SYSTEM; VISION; CALIBRATION
AB This paper investigates a passive stereovision system which employs one single CCD camera and one pyramid-like glass prism. Its trinocular variety is first presented: each image captured by this system can be split into three sub-images and these sub-images are taken as the images simultaneously captured by three virtual cameras which are generated by the prism. Two different approaches are developed to model this system: one bases on a conventional camera calibration technique and the other bases on geometrical analysis of ray sketching. The second approach is a relatively simpler but is sufficiently accurate as compared to the calibration based approach. Then the knowledge on this trinocular system is extended to build a single-lens multi-ocular stereovision system. Experiments are conducted to validate this system. The ideas presented in this paper are believed novel. (c) 2007 Elsevier B.V. All rights reserved.
C1 Natl Univ Singapore, Dept Mech Engn, Control & Mechatron Lab, EA 04-06,10 Kent Ridge Crescent, Singapore 119260, Singapore.
C3 National University of Singapore
RP Xiao, Y (corresponding author), Natl Univ Singapore, Dept Mech Engn, Control & Mechatron Lab, EA 04-06,10 Kent Ridge Crescent, Singapore 119260, Singapore.
EM engp1821@nus.edu.sg
OI Lim, Kah Bin/0000-0002-2118-0966
CR Abbasi S, 2000, INT C PATT RECOG, P13, DOI 10.1109/ICPR.2000.905266
   ADELSON EH, 1992, IEEE T PATTERN ANAL, V14, P99, DOI 10.1109/34.121783
   Agrawal M, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P3, DOI 10.1109/SMBV.2001.988757
   AYACHE N, 1991, IEEE T PATTERN ANAL, V13, P73, DOI 10.1109/34.67633
   Black J, 2002, MEASUREMENT, V32, P61, DOI 10.1016/S0263-2241(01)00050-1
   CARDILLO J, 1990, P MIDW S CIRC SYST, V1, P325
   CHIOU RN, 1995, IEEE T SYST MAN CYB, V25, P1207, DOI 10.1109/21.398682
   DHOND UR, 1990, P IEEE INT C ROB AUT, V3, P2045
   FAUGERAS O, 1993, 3 DIMENSIONAL COMPUT, P211
   François ARJ, 2003, IMAGE VISION COMPUT, V21, P137, DOI 10.1016/S0262-8856(02)00149-X
   GOSHTASBY A, 1993, PATTERN RECOGN, V26, P923, DOI 10.1016/0031-3203(93)90058-5
   Goshtasby AA, 1998, PATTERN RECOGN, V31, P1705, DOI 10.1016/S0031-3203(98)00047-8
   Grammalidis N, 1998, IEEE T CIRC SYST VID, V8, P328, DOI 10.1109/76.678630
   HANSEN C, 1988, P 2 INT C COMP VIS, P129
   HARTLEY R, 2000, MULTIPLE VIEW GEOMET, P353
   INABA M, 1993, IROS 93 : PROCEEDINGS OF THE 1993 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOL 1-3, P1857, DOI 10.1109/IROS.1993.583888
   KURADA S, 1995, OPT LASER TECHNOL, V27, P75, DOI 10.1016/0030-3992(95)93618-2
   Lee D, 2000, IEEE T ROBOTIC AUTOM, V16, P528, DOI 10.1109/70.880803
   LeGrand R, 1996, IEEE INT CONF ROBOT, P1714, DOI 10.1109/ROBOT.1996.506959
   Lerasle F, 1999, COMPUT VIS IMAGE UND, V75, P229, DOI 10.1006/cviu.1999.0759
   Lim KB, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.2137654
   Lim KB, 2004, PROC SPIE, V5302, P41, DOI 10.1117/12.524703
   Maas HG, 1999, ISPRS J PHOTOGRAMM, V54, P352, DOI 10.1016/S0924-2716(99)00029-5
   MOORE D, 1997, P C RECORD 30 AS C S, V1, P125
   Mulligan J, 2000, INT C PATT RECOG, P567, DOI 10.1109/ICPR.2000.905401
   Nakazawa Y, 1996, INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, PROCEEDINGS - VOL II, P293, DOI 10.1109/ICIP.1996.560812
   Nene SA, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1087, DOI 10.1109/ICCV.1998.710852
   Nishimoto Y., 1987, Proceedings of the International Workshop on Industrial Applications of Machine Vision and Machine Intelligence. Seiken Symposium (Cat. no. 87TH0166-9), P192
   Park JH, 2004, APPL OPTICS, V43, P4882, DOI 10.1364/AO.43.004882
   Pedersini F, 1999, SIGNAL PROCESS, V77, P309, DOI 10.1016/S0165-1684(99)00042-0
   Ploskas N, 2003, SIGNAL PROCESS-IMAGE, V18, P185, DOI 10.1016/S0923-5965(02)00131-5
   Ramsgaard BK, 2000, INT C PATT RECOG, P499, DOI 10.1109/ICPR.2000.902966
   Rodriguez J. J., 1988, Proceedings CVPR '88: The Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.88CH2605-4), P153, DOI 10.1109/CVPR.1988.196229
   Segen J., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P479, DOI 10.1109/CVPR.1999.786981
   Shen J, 1996, PATTERN RECOGN, V29, P1661, DOI 10.1016/0031-3203(96)00025-8
   STEWART C, 1988, P 2 INT C COMP VIS, P129
   Teoh W., 1984, International Conference on Robotics, P186
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   Xiao Y, 2004, 2004 IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS, VOLS 1 AND 2, P396
   Xiao Y, 2006, 12TH INTERNATIONAL MULTI-MEDIA MODELLING CONFERENCE PROCEEDINGS, P469
   YACHIDA M, 1986, P ICPR, P1041
   Zelnik-Manor L, 2002, IEEE T PATTERN ANAL, V24, P214, DOI 10.1109/34.982901
   Zhang ZY, 1998, INT C PATT RECOG, P1174, DOI 10.1109/ICPR.1998.711905
NR 43
TC 34
Z9 39
U1 2
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1725
EP 1736
DI 10.1016/j.imavis.2007.01.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900003
DA 2024-07-18
ER

PT J
AU du Buf, JMH
AF du Buf, J. M. H.
TI Improved grating and bar cell models in cortical area V1 and texture
   coding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE cortical cells; groupings; computational models; diatoms; texture
   analysis; symmetry order
ID NEURAL CONTOUR MECHANISMS; SIMULATION; ATTENTION; RESPONSES
AB This paper presents improved models of cortical neurons in VI that act like grating and bar detectors. Both models use the same frontend, which consists of a contrast normalisation in combination with isotropic DOG filtering, followed by anisotropic Gabor filtering together with a response sharpening. Different grouping processes of ON and OFF responses lead to a very selective detection of bar width and grating frequency, with a good localisation. Furthermore, outputs of grating cells can be grouped over combinations of orientations for coding nonlinear textures. It is shown that these models, apart from being used in the modelling of the visual cortex, can be employed in pattern-recognition applications. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Algarve, Dept Elect & Comp Sci, Vis Lab, P-8000810 Faro, Portugal.
C3 Universidade do Algarve
RP du Buf, JMH (corresponding author), Univ Algarve, Dept Elect & Comp Sci, Vis Lab, Campus Gambelas,FCT, P-8000810 Faro, Portugal.
EM dubuf@ualg.pt
RI du Buf, Hans/M-5125-2013
OI du Buf, Hans/0000-0002-4345-1237
CR ALLMAN J, 1990, COLD SPRING HARB SYM, V55, P979
   [Anonymous], 1995, Signal Processing for Computer Vision
   BARBER HG, 1994, FRESHWATER BIOL ASS, P29
   Berson DM, 2003, TRENDS NEUROSCI, V26, P314, DOI 10.1016/S0166-2236(03)00130-9
   BIGUN J, 1994, IEEE T PATTERN ANAL, V16, P80, DOI 10.1109/34.273714
   DAUGMAN JG, 1980, VISION RES, V20, P847, DOI 10.1016/0042-6989(80)90065-6
   Deco G, 2004, VISION RES, V44, P621, DOI 10.1016/j.visres.2003.09.037
   Du Buf J. M. H., 1992, Spatial Vision, V6, P221, DOI 10.1163/156856892X00109
   DUBUF JMH, 1993, BIOL CYBERN, V68, P321, DOI 10.1007/BF00201857
   DUBUF JMH, 2002, MACH PERCEPTION ARTI, V51
   DUBUF JMH, 1994, PROGR IMAGE ANAL, V3, P669
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Grossberg S, 1999, SPATIAL VISION, V12, P163, DOI 10.1163/156856899X00102
   Heitger F, 1998, IMAGE VISION COMPUT, V16, P407, DOI 10.1016/S0262-8856(97)00083-8
   HEITGER F, 1992, VISION RES, V32, P963, DOI 10.1016/0042-6989(92)90039-L
   Johnson D. H., 1993, ARRAY SIGNAL PROCESS
   JONES JP, 1987, J NEUROPHYSIOL, V58, P1233, DOI 10.1152/jn.1987.58.6.1233
   Kastner S, 2005, PERCEPTION, V34, P36
   Kruizinga P, 2000, BIOL CYBERN, V83, P313, DOI 10.1007/s004220000153
   MARCELJA S, 1980, J OPT SOC AM, V70, P1297, DOI 10.1364/JOSA.70.001297
   Mingolla E, 1999, NEURAL NETWORKS, V12, P499, DOI 10.1016/S0893-6080(98)00144-0
   Petkov N, 1997, BIOL CYBERN, V76, P83, DOI 10.1007/s004220050323
   Rensink RA, 2000, VIS COGN, V7, P17, DOI 10.1080/135062800394667
   Rodrigues J, 2004, LECT NOTES COMPUT SC, V3211, P664, DOI 10.1109/TIA.2004.824508
   Rodrigues J, 2006, BIOSYSTEMS, V86, P75, DOI 10.1016/j.biosystems.2006.02.019
   Santos LM, 2002, LECT NOTES COMPUT SC, V2525, P90
   SCHILLER PH, 1986, NATURE, V322, P824, DOI 10.1038/322824a0
   Van Deemter JH, 2000, INT J PATTERN RECOGN, V14, P757, DOI 10.1142/S0218001400000465
   VONDERHEYDT R, 1992, J NEUROSCI, V12, P1416
   Wässle H, 2004, NAT REV NEUROSCI, V5, P747, DOI 10.1038/nrn1497
NR 30
TC 9
Z9 10
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2007
VL 25
IS 6
BP 873
EP 882
DI 10.1016/j.imavis.2006.06.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 168QH
UT WOS:000246538600009
DA 2024-07-18
ER

PT J
AU Gabarda, S
   Cristóbal, G
AF Gabarda, Salvador
   Cristobal, Gabriel
TI Cloud covering denoising through image fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Wigner distribution; image fusion; image enhancement
ID FREQUENCY SIGNAL ANALYSIS; WIGNER DISTRIBUTION; TOOL
AB This paper presents a solution to the cloud removal problem, based in a recently developed image fusion methodology consisting in applying a I-D pseudo-Wigner distribution (PWD) transformation to the source images and on the use of a pixel-wise cloud model. Both features could also be interpreted as a denoising method centered in a pixel-level measure. Such procedure is able to process sequences of multi-temporal registered images affected with spatial-variant noise. The goal consists in providing a 2-D clean image, after removing the spatial-variant noise disturbing the set of multi-temporal registered source images. This is achieved by taking as reference a statistically parameterized model of a cloud prototype. Using this model, a pixel-wise measure of the noise degree of the source images can be calculated through their PWDs. This denoising procedure enables to choose the noise-free pixels from the set of given source images. The applicability of the method to the cloud removal paradigm is illustrated with different sets of artificial and natural cloudy or foggy images, partially occluded by clouds in different regions. Another advantage of the present approach is its reduced computational cost, once the I-D case has been preferred instead of a full 2-D implementation of the PWD. (c) 2006 Elsevier B.V. All rights reserved.
C1 CSIC, Inst Opt Daza Valdes, E-28006 Madrid, Spain.
C3 Consejo Superior de Investigaciones Cientificas (CSIC); CSIC - Instituto
   de Optica (Daza de Valdes)
RP Cristóbal, G (corresponding author), CSIC, Inst Opt Daza Valdes, Serrano 121, E-28006 Madrid, Spain.
RI Cristobal, Gabriel/B-7216-2012
OI Cristobal, Gabriel/0000-0001-6408-2269
CR BRENNER KH, 1983, P EURASIP SIGN PROC, V2, P307
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P372
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P217
   CLAASEN TACM, 1980, PHILIPS J RES, V35, P276
   Gabarda S, 2005, OPT ENG, V44, DOI 10.1117/1.1881412
   GABARDA S, 2004, APPL COMP VIS WORKSH
   GALLEANI L, SPIE SEATTL WASH US
   GONZALO C, 1989, APPL OPTICS, V28, P730, DOI 10.1364/AO.28.000730
   GONZALO C, 1989, THESIS I OPTICA MADR
   GUILLORY AR, 1998, 9 C SAT MET OC PAR F, P374
   Haralick R. M., 1992, COMPUTER ROBOT VISIO, V1
   JACOBSON LD, 1988, SIGNAL PROCESS, V14, P37, DOI 10.1016/0165-1684(88)90043-6
   JEDLOVEC GJ, 2001, 11 C SAT MET OC MAD, P412
   Kundur D, 1996, IEEE SIGNAL PROC MAG, V13, P43, DOI 10.1109/79.489268
   Kundur D, 1997, P SOC PHOTO-OPT INS, V3067, P83, DOI 10.1117/12.276116
   Lagendijk R.L., 2000, APS COMM NETW MULTIM, P125
   LI M, P 20 ISPRS C 12 13 J
   ONEILL JC, 1998, TIME FREQUENCY S MAR
   Rajagopalan AN, 1997, COMPUT VIS IMAGE UND, V68, P309, DOI 10.1006/cviu.1997.0534
   SALEH BEA, 1985, IEEE T ACOUST SPEECH, V33, P1479, DOI 10.1109/TASSP.1985.1164753
   Warner JX, 2001, APPL OPTICS, V40, P1269, DOI 10.1364/AO.40.001269
   Wigner E, 1932, PHYS REV, V40, P0749, DOI 10.1103/PhysRev.40.749
   WISETPHANICHKIJ S, 1999, P 20 AS C REM SENS H
   Zhang Z, 1999, P IEEE, V87, P1315, DOI 10.1109/5.775414
NR 24
TC 31
Z9 43
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 523
EP 530
DI 10.1016/j.imavis.2006.03.007
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200001
DA 2024-07-18
ER

PT J
AU Suresh, RM
   Arumugam, S
AF Suresh, R. M.
   Arumugam, S.
TI Fuzzy technique based recognition of handwritten characters
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE fuzzy logic; fuzzy context-free grammar; preprocessing; polygonal
   approximation; segmentation; labeling; handwritten numerals; modified
   parsing algorithm
ID NUMERAL RECOGNITION; LANGUAGE; PATTERNS; TEXT
AB The different methods for automatic pattern recognition are motivated by the way in which pattern classes are characterized and defined. In this paper, the handwritten characters (numerals) are preprocessed and segmented into primitives. These primitives are measured and labeled using fuzzy logic. Strings of a character are formed from these labeled primitives. To recognize the handwritten characters, conventional string matching is performed. However, the problem in this string matching has been avoided using the membership value of the string. This result is being compared with the Modified Parser generated from the Error-free fuzzy context-free grammar. (c) 2006 Elsevier B.V. All rights reserved.
C1 RSM Nagar, RMK Engn Coll, Dept Comp Sci & Engn, Kavaraipettai 601206, Tamil Nadu, India.
   Arulmigu Kalasalingam Coll Engn, Kirshnankoil 626190, Tamil Nadu, India.
C3 R.M.K. Engineering College; Kalasalingam Academy of Research & Education
RP Suresh, RM (corresponding author), RSM Nagar, RMK Engn Coll, Dept Comp Sci & Engn, Kavaraipettai 601206, Tamil Nadu, India.
EM rmsuresh@hotmail.com
OI Arumugam, Subramanian/0000-0002-4477-9453
CR ABHUHAIBA ISI, 1993, PATTERN RECOGN, V26, P1335
   Cai JH, 1999, IEEE T PATTERN ANAL, V21, P263, DOI 10.1109/34.754622
   CAO J, 1995, PATTERN RECOGN, V28, P153, DOI 10.1016/0031-3203(94)00094-3
   CASACUBERTA F, 1988, SYNTACTIC STRUCTURAL
   CHI ZR, 1995, PATTERN RECOGN, V28, P59, DOI 10.1016/0031-3203(94)00085-Z
   CHINNUSWAMY P, 1980, PATTERN RECOGN, V12, P141, DOI 10.1016/0031-3203(80)90038-2
   DOWNTON AC, 1996, PROGR HANDWRITING RE
   Fu K.S., 1982, SYNTACTIC PATTERN RE, Vsecond
   GOLD EM, 1967, INFORM CONTROL, V10, P447, DOI 10.1016/S0019-9958(67)91165-5
   GOVINDAN VK, 1988, THESIS IISC BANGALOR
   HORNINGS JJ, 1969, 139 CSE DEPT STANF U
   Jain AK, 1997, IEEE T PATTERN ANAL, V19, P1386, DOI 10.1109/34.643899
   JAMSHIDI M, 1993, FUZZY LOGIC CONTROL, P112
   LEE ET, 1969, INFORM SCIENCES, V1, P421, DOI 10.1016/0020-0255(69)90025-5
   Malaviya A, 1997, PATTERN RECOGN, V30, P1591, DOI 10.1016/S0031-3203(97)00003-4
   Malaviya A, 2000, PATTERN RECOGN, V33, P119, DOI 10.1016/S0031-3203(99)00034-5
   MIZUMOTO M, 1969, J COMPUT SYST SCI, V3, P409, DOI DOI 10.1016/S0022-0000(69)80029-2
   PAO TWL, 1969, 7019 U PENNS DEP EL
   Parizeau M., 1995, IEEE Transaction on Pattern Analysis and Machine Intelligence, V17, P707
   PEDRYCZ W, 1990, PATTERN RECOGN, V23, P121, DOI 10.1016/0031-3203(90)90054-O
   RAJASEKARAN SNS, 1977, COMPUTER GRAPHICS IM, V6, P335
   SHAW AC, 1969, INFORM CONTROL, V14, P9, DOI 10.1016/S0019-9958(69)90017-5
   SINHA RMK, 1988, COMPUT VISION GRAPH, V43, P98, DOI 10.1016/0734-189X(88)90046-1
   SINHA RMK, 1993, IEEE T PATTERN ANAL, V15, P915, DOI 10.1109/34.232077
   SIY P, 1971, IEEE SMC, V1, P61
   SRIHARI SN, 1993, PATTERN RECOGN LETT, V14, P291, DOI 10.1016/0167-8655(93)90095-U
   SURESH RM, 2000, THESIS MS U
   WAKAHARA T, 1993, PATTERN RECOGN LETT, V14, P345, DOI 10.1016/0167-8655(93)90100-R
   ZADEH L, 1996, 5 FUZZ IEEE LOUS, P1
NR 29
TC 15
Z9 25
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 230
EP 239
DI 10.1016/j.imavis.2006.01.029
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700012
DA 2024-07-18
ER

PT J
AU Black, J
   Ellis, T
AF Black, James
   Ellis, Tim
TI Multi camera image tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Performance Evaluation of Tracking and Surveillance (PETS)
CY DEC09, 2001
CL Kauai, HI
SP IEEE
AB This paper presents a method for multi-camera image tracking in the context of image surveillance. The approach differs from most methods in that we exploit multiple camera views to resolve object occlusion. Moving objects are detected by using background subtraction. Viewpoint correspondence between the detected objects is then established by using the ground plane homography constraint. The Kalman Filter is then used to facilitate the tracking of objects in 3D. Tracking in 3D offers benefits in terms of allowing multiple views to be combined to generate a network field of view (FOV), i.e. the FOV of all the cameras combined. In addition, tracking the objects location in 3D allows us to use the Linear Kalman Filter, which is less cumbersome to implement than the Extended Kalman Filter (EKF). The current system is capable of tracking moving objects within three camera views (c) 2005 Elsevier B.V. All rights reserved.
C1 Kingston Univ, Digital Imaging Res Ctr, Kingston upon Thames KT1 2EE, Surrey, England.
C3 Kingston University
RP Black, J (corresponding author), Kingston Univ, Digital Imaging Res Ctr, Penrhyn Rd, Kingston upon Thames KT1 2EE, Surrey, England.
EM j.k.black@computer.org; t.ellis@kingston.ac.uk
CR CRIMINISI A, 1997, PLANE MEASURING DEVI, P699
   DELLAERT F, 1997, ROB CAR TRACK US KAL
   Faugeras O., 1993, Three-dimensional computer vision: a geometric viewpoint
   KHAN S, 2000, TRACK PEOPL PRES OCC
   LEE R, 2000, IEEE T PAMI, V22, P117
   MIKIC I, 1998, VIDEO INTEGRATION MU
   ROSALES R, 1998, IEEE C CVPR WORKSH I, P117
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   TEIN G, 1998, DARPA IU WORKSH, P1037
   TSAI RY, 1986, IEEE C CVPR, P323
   Xu M., 2001, P BRIT MACHINE VISIO, P163
NR 11
TC 61
Z9 76
U1 1
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2006
VL 24
IS 11
BP 1256
EP 1267
DI 10.1016/j.imavis.2005.06.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 101CJ
UT WOS:000241716200010
DA 2024-07-18
ER

PT J
AU Bergboer, NH
   Postma, EO
   van den Herik, HJ
AF Bergboer, N. H.
   Postma, E. O.
   van den Herik, H. J.
TI Context-based object detection in still images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE computer vision; machine learning; object recognition
ID FACE DETECTION; ATTENTION; STATISTICS; SYSTEM; FIELD; MODEL; END
AB We present a novel dual-stage object-detection method. In the first stage, an object detector based on appropriate visual features is used to find object candidates. In the second stage, the object candidates are assigned a confidence value based on local-contextual information. Our context-based method is called COBA, for COntext BAsed object detection. At a given detection rate COBA is able to lower the false-detection rate. Experiments in which frontal human faces are to be detected show that the number of false positives is lowered by a factor 8.7 at a detection rate of 80% when compared to the current high-performance object detectors. Moreover, COBA is capable of flexibly using other new object-detection algorithms as 'plug-ins' in the second stage. Hence, object detection can be straightforwardly improved by our method a soon as new insights emerge and are available in algorithmic form. (c) 2006 Elsevier B.V. All rights reserved.
C1 Maastricht Univ, Dept Comp Sci, NL-6200 MD Maastricht, Netherlands.
C3 Maastricht University
RP Bergboer, NH (corresponding author), Maastricht Univ, Dept Comp Sci, Minderbroedersberg 6A,POB 616, NL-6200 MD Maastricht, Netherlands.
EM n.bergboer@cs.unimaas.nl
CR [Anonymous], 2001, P 2 INT WORKSH STAT
   BIEDERMAN L, 1981, PERCEPTUAL ORG
   Cawley G.C., 2000, MATLAB SUPPORT VECTO
   ERIKSEN CW, 1985, J EXP PSYCHOL HUMAN, V11, P583, DOI 10.1037/0096-1523.11.5.583
   ERIKSEN CW, 1986, PERCEPT PSYCHOPHYS, V40, P225, DOI 10.3758/BF03211502
   Freund Y., 1996, INT C MACHINE LEARNI, P148
   Gershenfeld N.A., 1999, The Nature of Mathematical Modeling
   Hjelmås E, 2001, COMPUT VIS IMAGE UND, V83, P236, DOI 10.1006/cviu.2001.0921
   HUMPHREYS GW, 1989, VISUAL COGNITION COM, pCH5
   KOCH C, 1985, HUMAN NEUROBIOLOGY, V4, P35
   Kruppa H., 2003, P JOINT IEEE INT WOR
   Lewis MB, 2003, PERCEPTION, V32, P903, DOI 10.1068/p5007
   LIENHART R, 2002, EXTENDED SET HAARLIK
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   MARTINEZ AM, 1998, 24 CVC PURD U EL COM
   Montgomery D. C., 2010, Applied Statistics and Probability for Engineers
   Palmer S., 1999, VISION SCI PHOTONS P
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Pham TV, 2002, PATTERN RECOGN LETT, V23, P451, DOI 10.1016/S0167-8655(01)00177-5
   POSNER MI, 1990, ANNU REV NEUROSCI, V13, P25, DOI 10.1146/annurev.ne.13.030190.000325
   Postma EO, 1997, NEURAL NETWORKS, V10, P993, DOI 10.1016/S0893-6080(97)00034-8
   POSTMA FO, 1994, THESIS RIJKSUNIVERSI
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   RIFKIN B, 2001, SVMFU FAST FLEXIBLE
   Romeny BMT, 2000, LECT NOTES COMPUT SC, V1811, P297
   Schneiderman H, 2004, INT J COMPUT VISION, V56, P151, DOI 10.1023/B:VISI.0000011202.85607.00
   Schneiderman H., 2000, IEEE C COMP VIS PATT
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Sung KK, 1998, IEEE T PATTERN ANAL, V20, P39, DOI 10.1109/34.655648
   Torralba A, 2003, NETWORK-COMP NEURAL, V14, P391, DOI 10.1088/0954-898X/14/3/302
   Torralba A, 2002, IEEE T PATTERN ANAL, V24, P1226, DOI 10.1109/TPAMI.2002.1033214
   TORRALBA A, 2002, ADV NEURAL INFORM PR, V14
   Verbeek JJ, 2003, NEURAL COMPUT, V15, P469, DOI 10.1162/089976603762553004
   Vinette C, 2004, COGNITIVE SCI, V28, P289, DOI 10.1016/j.cogsci.2004.01.002
   Yarbus A. L., 1967, Eye Movements and Vision
NR 36
TC 3
Z9 3
U1 0
U2 10
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2006
VL 24
IS 9
BP 987
EP 1000
DI 10.1016/j.imavis.2006.02.024
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 085BD
UT WOS:000240577200008
DA 2024-07-18
ER

PT J
AU Calvetti, D
   Sgallari, F
   Somersalo, E
AF Calvetti, Daniela
   Sgallari, Fiorella
   Somersalo, Erkki
TI Image inpainting with structural bootstrap priors
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE inpainting; statistical inversion; structural priors; boundary
   conditions
ID SCALE-SPACE; REGULARIZATION
AB In this article, we consider the following inpainting problem arising in image restoration: part of an image has been removed, and we want to restore the image from the remaining, possibly noisy, portion. We show that if the true image contains no sharp edges, the inpainting can be done rather satisfactorily by means of an isotropic smoothness prior assumption. If, on the other hand, we have information concerning discontinuities in the image, we can input this information into the restoration algorithm using an anisotropic smoothness prior. Based on these observations, we propose an inpainting method based on a bootstrapping procedure that consists of the following steps: first, we smooth out the incomplete image and calculate the gradient field. Since this field is smooth, it can be inpainted satisfactorily. By using the inpainted gradient field, we then construct an anisotropic smoothness prior that pilots the inpainting of the original non-smooth image. The calculations are based on the Bayesian interpretation of the inpainting problem as a statistical inverse problem. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Bologna, Dept Math, CIRAM, Fac Engn, I-40123 Bologna, Italy.
   Case Western Reserve Univ, Dept Math, Cleveland, OH 44106 USA.
   Aalto Univ, Inst Math, FIN-02015 Helsinki, Finland.
C3 University of Bologna; University System of Ohio; Case Western Reserve
   University; Aalto University
RP Sgallari, F (corresponding author), Univ Bologna, Dept Math, CIRAM, Fac Engn, Via Saragozza 8, I-40123 Bologna, Italy.
EM dxc57@po.cwru.edu; sgallari@dm.unibo.it; erkki.somersalo@hut.fi
OI Somersalo, Erkki/0000-0001-5099-3512; SGALLARI,
   Fiorella/0000-0002-9166-8879; Calvetti, Daniela/0000-0001-5696-718X
CR [Anonymous], 2003, Geometric Level Set Methods in Imaging, Vision, and Graphics
   Ballester C, 2001, IEEE T IMAGE PROCESS, V10, P1200, DOI 10.1109/83.935036
   Bertalmio M, 2003, IEEE T IMAGE PROCESS, V12, P882, DOI 10.1109/TIP.2003.815261
   Bertalmio M, 2000, COMP GRAPH, P417, DOI 10.1145/344779.344972
   BERTALMIO M, 2001, P IEEE COMP VIS PATT
   CALVETTI D, 2006, INT J MATH COMPUT SC, P1
   Chan TF, 2003, SIAM J APPL MATH, V63, P564
   Chan TF, 2001, J VIS COMMUN IMAGE R, V12, P436, DOI 10.1006/jvci.2001.0487
   Chan TF, 2002, SIAM J APPL MATH, V62, P1019, DOI 10.1137/S0036139900368844
   CHAN TF, 2004, CAM0445
   CHAN TF, 2004, 0472 CAM
   Esedoglu S, 2002, EUR J APPL MATH, V13, P353, DOI 10.1017/S0956792501004904
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Kaipio J., 2004, COMPUTATIONAL STAT I
   Kaipio JP, 1999, INVERSE PROBL, V15, P713, DOI 10.1088/0266-5611/15/3/306
   KLASSEN E, 2005, IEEE T PATTERN ANAL, P26
   KOKARAM AC, 1995, IEEE T IMAGE PROCESS, V4, P1509, DOI 10.1109/83.469932
   MIO W, 2004, P 8 EUR C COMP VIS E
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Peterson I., 2002, SCI NEWS, P161
   Radmoser E, 2000, J VIS COMMUN IMAGE R, V11, P96, DOI 10.1006/jvci.1999.0437
   SAPIRO G, 2002, SIAM NEWS, P35
   Scherzer O, 2000, J MATH IMAGING VIS, V12, P43, DOI 10.1023/A:1008344608808
   SHEN J, 2003, SIAM NEWS, P36
   Voci F, 2004, IEEE SIGNAL PROC MAG, V21, P39, DOI 10.1109/MSP.2004.1296541
   Weickert J, 2002, J VIS COMMUN IMAGE R, V13, P103, DOI 10.1006/jvci.2001.0495
NR 26
TC 20
Z9 23
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 782
EP 793
DI 10.1016/j.imavis.2006.01.015
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400011
DA 2024-07-18
ER

PT J
AU Vestri, C
AF Vestri, Christophe
TI Using range data in automatic modeling of buildings
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE building modeling; DEM; robust estimation; planar patch segmentation;
   polygonalization; orthogonalization; aerial images
ID DIGITAL ELEVATION MODELS; PARAMETER-ESTIMATION; EXTRACTION
AB We present a system for modeling buildings from a single correlation-based digital elevation model (DEM). The model is constructed in two stages. The first stage segments the DEM into planar surface patches that describe the building. The second stage generates the final polygonal model of the building using weak geometric constraints. We use robust estimation methods at different stages of our modeling process to obtain an efficient and noise-insensitive modeling system. The proposed system is fully automatic and does not use any a priori information about the shape of the buildings. We present results on isolated buildings and on a large area of the city of Berlin. Finally, we propose an evaluation with the intended application. (c) 2006 Published by Elsevier B.V.
C1 Univ So Calif, Inst Robot & Intelligent Syst, Los Angeles, CA 90089 USA.
   ISTAR, F-06905 Sophia Antipolis, France.
C3 University of Southern California
RP Vestri, C (corresponding author), Univ So Calif, Inst Robot & Intelligent Syst, Powell Hall 226, Los Angeles, CA 90089 USA.
EM vestri@iris.usc.edu
RI Devernay, Frederic/B-4629-2009
OI Devernay, Frederic/0000-0002-7061-4898
CR AMERI B, 1999, ISPRS C AUT EXTR GIS, P15
   Baillard C, 1998, ISPRS J PHOTOGRAMM, V53, P130, DOI 10.1016/S0924-2716(97)00036-1
   BIGNONE F, 1996, P ECCV, P85
   COLLINS R, 1996, RADIUS IMAGE UNDERST, P209
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   FRADKIN M, 1999, ISPRS C AUT EXTR GIS
   Gabet L, 1997, ISPRS J PHOTOGRAMM, V52, P33, DOI 10.1016/S0924-2716(96)00030-5
   Hata Masaharu, 1980, IEEE T VEHICULAR TEC, V29
   LEONARDIS A, 1994, PERFORMANCE VERSUS M, P78
   Mayer H, 1999, COMPUT VIS IMAGE UND, V74, P138, DOI 10.1006/cviu.1999.0750
   MOONS T, 1998, LECT NOTES COMPUTER, P410
   NEVATIA R, 1998, P ARPA IM UND WORKSH
   PAVLIDIS T, 1974, IEEE T COMPUT, VC 23, P860, DOI 10.1109/T-C.1974.224041
   Rousseeuw P.J., 1987, ROBUST REGRESSION OU
   Stewart CV, 1999, SIAM REV, V41, P513, DOI 10.1137/S0036144598345802
   STRICKER M, 1995, BIWITR159 ETH
   TON PHS, 1999, MSRTR9916
   VESTRI C, 2000, THESIS U NICE SOPHIA
   VESTRI C, 2000, P INT C COMP VIS PAT
   WEIDNER U, 1995, ISPRS J PHOTOGRAMM, V50, P38, DOI 10.1016/0924-2716(95)98236-S
   Zhang ZY, 1997, IMAGE VISION COMPUT, V15, P59, DOI 10.1016/S0262-8856(96)01112-2
NR 21
TC 5
Z9 5
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 709
EP 719
DI 10.1016/j.imavis.2005.12.015
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400006
DA 2024-07-18
ER

PT J
AU Leemans, V
   Destain, MF
AF Leemans, V
   Destain, MF
TI Line cluster detection using a variant of the Hough transform for
   culture row localisation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hough transform; line cluster; guidance; crop rows
ID IMAGE-ANALYSIS; SEGMENTATION; GUIDANCE; VEHICLE
AB An adaptation of the Hough transform was proposed for the detection of line clusters of known geometry. This method was applied in agriculture for the detection of sowing furrows created by a driller and of chicory plant rows during harvesting process.
   The sowing rows were revealed by a background correction, the background being obtained thanks to a median rank filter. The method was found efficient in eliminating the shadows. For the crop rows, a neural network was used to localise the plants. While the petiole and the leaves were easily separated from the soil, the chicory root and the soil having about the same colour and the lighting condition varying widely, it was more difficult to obtain a good contrast between those parts, which leaves place for some improvements. The adapted Hough transform consisted in computing one transform for each line in the cluster with, for reference, the position and direction of the theoretical position of the row. The different transforms were then added. It was found effective for both the sowing rows and the chicory rows. Results remained good even in very noisy conditions, when the rows were incomplete or when artefacts would lead its classical counter part to show several alignments other than the expected ones. The culture rows were localised with a precision of a few centimetres, which was compatible with the proposed applications. (C) 2006 Elsevier B.V. All rights reserved.
C1 Gembloux Agr Univ, Unite Mecan & Construct, B-5030 Gembloux, Belgium.
C3 University of Liege
RP Leemans, V (corresponding author), Gembloux Agr Univ, Unite Mecan & Construct, Passage Deportes 2, B-5030 Gembloux, Belgium.
EM leemans.v@fsagx.ac.de
CR Marchant JA, 1996, COMPUT ELECTRON AGR, V15, P161, DOI 10.1016/0168-1699(96)00014-2
   Onyango CM, 2001, IMAGE VISION COMPUT, V19, P523, DOI 10.1016/S0262-8856(00)00097-4
   Pilarski T, 2002, AUTON ROBOT, V13, P9, DOI 10.1023/A:1015622020131
   Pla F, 1997, IMAGE VISION COMPUT, V15, P465, DOI 10.1016/S0262-8856(96)01147-X
   Rovira-Más F, 2005, P I MECH ENG D-J AUT, V219, P999, DOI 10.1243/095440705X34667
   Sogaard HT, 2003, COMPUT ELECTRON AGR, V38, P141, DOI 10.1016/S0168-1699(02)00140-0
   Tillett ND, 1999, J AGR ENG RES, V74, P225, DOI 10.1006/jaer.1999.0458
   Tillett ND, 2002, COMPUT ELECTRON AGR, V33, P163, DOI 10.1016/S0168-1699(02)00005-4
   van der Heijden F., 1994, IMAGE BASED MEASUREM
NR 9
TC 41
Z9 54
U1 0
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 541
EP 550
DI 10.1016/j.imavis.2006.02.004
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600013
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, J
   Chen, SC
AF Liu, J
   Chen, SC
TI Discriminant common vectors versus neighbourhood components analysis and
   Laplacianfaces: A comparative study in small sample size problem
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Principal component analysis (PCA); linear discriminant analysis (LDA);
   discriminant common vectors (DCV); neighbourhood components analysis
   (NCA); Laplacianfaces (LAP); small sample size (SSS); face recognition
ID RECOGNITION
AB Discriminant common vectors (DCV), neighbourhood components analysis (NCA) and Laplacianfaces (LAP) are three recently proposed methods which can effectively learn linear projection matrices for dimensionality reduction in face recognition. where the dimension of the sample space is typically larger than the number of samples in the training set and consequently the so-called small sample size (SSS) problem exists. The three methods obtained their respective projection matrices based on different objective functions and all claimed to be superior to such methods as Principal component analysis (PCA) and PCA plus Linear discriminant analysis (PCA + LDA) in terms of classification accuracy. However, in literature, no comparative study is carried out among them. In this paper, we carry out a comparative study among them in face recognition (or generally in the SSS problem), and argue that the projection matrix yielded by DCV is the optimal solution to both NCA and LAP in terms of their respective objective functions, whereas neither NCA nor LAP may get their own optimal solutions. In addition, we show that DCV is more efficient than both NCA and LAP for both linear dimensionality reduction and subsequent classification in SSS problem. Finally, experiments are conducted on ORL, AR and YALE face databases to verify out-arguments and to present some insights for future study. (c) 2005 Elsevier B.V. All rights reserved.
C1 Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, Nanjing 210016, Jiangsu, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Nanjing Univ Aeronaut & Astronaut, Dept Comp Sci & Engn, 29 Yudao St, Nanjing 210016, Jiangsu, Peoples R China.
EM j.liu@nuaa.edu.cn; s.chen@nuaa.edu.cn
CR [Anonymous], P C ADV NEUR INF PRO
   [Anonymous], 2003, NIPS
   [Anonymous], 1991, P 1991 IEEE COMP SOC, DOI DOI 10.1109/CVPR.1991.139758
   [Anonymous], 2004, KERNEL METHODS PATTE
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Cevikalp H, 2004, INT C PATT RECOG, P326, DOI 10.1109/ICPR.2004.1334118
   Cevikalp H, 2005, IEEE T PATTERN ANAL, V27, P4, DOI 10.1109/TPAMI.2005.9
   Chang Y., 2003, P IEEE INT WORKSH AN
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   GOLDBERGER J, 2004, P C ADV NEUR INF PRO
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Gulmezoglu M.B., 2001, IEEE T SPEECH AUDIO, V9
   Gulmezoglu M. B., 1999, IEEE T SPEECH AUDIO, V7
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang R, 2002, INT C PATT RECOG, P29, DOI 10.1109/ICPR.2002.1047787
   Liu CJ, 2000, IEEE T IMAGE PROCESS, V9, P132, DOI 10.1109/83.817604
   LIU J, UNPUB EQUIVALENCES A
   Martinez A., 1998, AR FACE DATABASE
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   ROWEISS ST, 2000, SCIENCE, V290
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   Vapnik V., 1999, NATURE STAT LEARNING
   Yang J, 2003, PATTERN ANAL APPL, V6, P47, DOI 10.1007/s10044-002-0177-3
   Ye JP, 2005, IEEE T PATTERN ANAL, V27, P929, DOI 10.1109/TPAMI.2005.110
NR 27
TC 27
Z9 35
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2006
VL 24
IS 3
BP 249
EP 262
DI 10.1016/j.imavis.2005.11.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 031PI
UT WOS:000236716100004
DA 2024-07-18
ER

PT J
AU Vörös, J
AF Vörös, J
TI Quadtree-based representations of grid-oriented data
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image representation; quadtrees; robotics; potentials; Voronoi diagram;
   octrees; rapid prototyping
ID IMAGE COMPRESSION; BINARY IMAGES; INTEGRATION; OPERATIONS; STRATEGY;
   TIME
AB Two modifications of quadtrees are described for representations of grid-oriented data. First. the extended forms of quadtree are presented. which allow homogeneous coverage of the relevant parts (or even the whole) of pictures with equal sized blocks of required dimensions being equivalent with a grid. Then a special form of quadtree is introduced enabling the storage of multi-valued data. These hierarchical forms enable multiresolution approaches when dealing with such grid-oriented data as terrain information. potentials. approximate Voronoi diagrarns, but also spatial object models, etc. The data are stored directly into the matrix representation of the Corresponding quadtree. More examples of application are included. (c) 2006 Elsevier B.V. All rights reserved.
C1 Slovak Univ Technol Bratislava, Fac Elect Engn & Informat Technol, Dept Automat & Control, Bratislava 81219, Slovakia.
C3 Slovak University of Technology Bratislava
RP Slovak Univ Technol Bratislava, Fac Elect Engn & Informat Technol, Dept Automat & Control, Ilkovicova 3, Bratislava 81219, Slovakia.
EM jvoros@elf.stuba.sk
CR Aizawa K, 1999, PATTERN RECOGN, V32, P277, DOI 10.1016/S0031-3203(98)00071-5
   Allerton DJ, 2000, J NAVIGATION, V53, P483, DOI 10.1017/S037346330000103X
   [Anonymous], 1990, The design and analysis of spatial data structures
   [Anonymous], 2012, Robot Motion Planning
   Aurenhammer F., 1991, ACM Computing Surveys, V23, P345, DOI DOI 10.1145/116873.116880
   BERGER L, 1992, PATTERN RECOGN LETT, V13, P425, DOI 10.1016/0167-8655(92)90049-6
   GARGANTINI I, 1982, COMMUN ACM, V25, P905, DOI 10.1145/358728.358741
   Gáspár C, 2000, ENG ANAL BOUND ELEM, V24, P559, DOI 10.1016/S0955-7997(00)00036-9
   Greaves DM, 1999, INT J NUMER METH ENG, V45, P447, DOI 10.1002/(SICI)1097-0207(19990610)45:4<447::AID-NME592>3.0.CO;2-#
   Hulko G., 1998, MODELING CONTROL DES
   HUNTER GM, 1979, IEEE T PATTERN ANAL, V1, P145, DOI 10.1109/TPAMI.1979.4766900
   Jackson DJ, 1997, IMAGE VISION COMPUT, V15, P759, DOI 10.1016/S0262-8856(97)00020-6
   Lam TW, 1998, INT J ADV MANUF TECH, V14, P631, DOI 10.1007/BF01192282
   Lam TW, 1997, J MATER PROCESS TECH, V63, P784, DOI 10.1016/S0924-0136(96)02724-0
   Lay YL, 2000, OPT LASER TECHNOL, V32, P1, DOI 10.1016/S0030-3992(99)00105-X
   Nardelli E, 1997, INFORM SYST, V22, P25, DOI 10.1016/S0306-4379(97)00002-1
   Pieper WM, 1997, INT J NUMER METH ENG, V40, P1923, DOI 10.1002/(SICI)1097-0207(19970530)40:10<1923::AID-NME151>3.0.CO;2-2
   Pieper WM, 1999, COMMUN NUMER METH EN, V15, P77, DOI 10.1002/(SICI)1099-0887(199902)15:2<77::AID-CNM223>3.0.CO;2-J
   Sarkar D, 1997, PATTERN RECOGN LETT, V18, P455, DOI 10.1016/S0167-8655(97)00033-0
   Sarkar D, 1996, PATTERN RECOGN LETT, V17, P839, DOI 10.1016/0167-8655(96)00045-1
   Sridharan AK, 2001, J MANUF SYST, V19, P355, DOI 10.1016/S0278-6125(01)80007-8
   Tayeb J, 1998, COMPUT J, V41, P185, DOI 10.1093/comjnl/41.3.185
   Teuhola J, 1998, REAL-TIME IMAGING, V4, P299, DOI 10.1006/rtim.1997.9999
   Vörös J, 2000, IMAGE VISION COMPUT, V18, P1085, DOI 10.1016/S0262-8856(00)00049-4
   Voros J, 1997, PATTERN RECOGN LETT, V18, P955, DOI 10.1016/S0167-8655(97)80001-3
   Vörös J, 2001, ROBOT CIM-INT MANUF, V17, P447, DOI 10.1016/S0736-5845(01)00018-7
   VOROS J, 2002, P 11 INT WORKSH ROB, P373
   Voros J., 1998, P 7 WORKSH ROB ALP A, P451
   VOROS J, 2001, P 10 WORKSH ROB ALP
   Wise DS, 1999, SCI COMPUT PROGRAM, V33, P29, DOI 10.1016/S0167-6423(98)00005-7
NR 30
TC 3
Z9 5
U1 0
U2 7
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 1
PY 2006
VL 24
IS 3
BP 263
EP 270
DI 10.1016/j.imavis.2005.11.009
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 031PI
UT WOS:000236716100005
DA 2024-07-18
ER

PT J
AU Zhu, ZG
   Xu, GY
   Riseman, EM
   Hanson, AR
AF Zhu, ZG
   Xu, GY
   Riseman, EM
   Hanson, AR
TI Fast construction of dynamic and multi-resolution 360° panoramas from
   video sequences
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE panoramic representation; video mosaicing; multi-resolution; moving
   object extraction
AB This paper presents a unified approach to automatically build dynamic and multi-resolution 360 degrees panoramic (DMP) representations from image sequences captured by hand-held cameras mainly undertaking rotation and zooming for natural scenes with moving targets. A simple (yet stable) rigid motion model and a closed-loop-based mosaicing algorithm are proposed to generate cylindrical mosaics automatically. Multi-resolution representations are built for interesting areas by separating zooming sub-sequences from a pan/zoom sequence. Moving objects are detected and separated from images based on motion information, and then more accurate contours are extracted using a modified active contour algorithm. The DMP construction method is fast, robust, and automatic, achieving five frames per second for image sequences with 384x288 color images on a Pentium III 800 MHz PC. The construction of the DMP representation can be used in virtual reality, video surveillance, and very low bit-rate video coding, (C) 2005 Elsevier B.V. All rights reserved.
C1 CUNY City Coll, Dept Comp Sci, New York, NY 10031 USA.
   Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   Univ Massachusetts, Dept Comp Sci, Amherst, MA 01003 USA.
C3 City University of New York (CUNY) System; City College of New York
   (CUNY); Tsinghua University; University of Massachusetts System;
   University of Massachusetts Amherst
RP CUNY City Coll, Dept Comp Sci, Convent Ave & 138th St, New York, NY 10031 USA.
EM zhu@cs.ccny.cuny.edu
OI Zhu, Zhigang/0000-0002-9990-1137
CR AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681
   Bartoli A, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P201, DOI 10.1109/MOTION.2002.1182237
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Chen S. E., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P29, DOI 10.1145/218380.218395
   Dufournaud YE, 2004, COMPUT VIS IMAGE UND, V93, P175, DOI 10.1016/j.cviu.2003.07.003
   Greguss P., 1986, US Patent, Patent No. 4566763
   IRANI M, IEEE P ICCV 95, P605
   Kang SB, 1997, PROC CVPR IEEE, P103, DOI 10.1109/CVPR.1997.609306
   Kass M., 1987, Proceedings of the First International Conference on Computer Vision (Cat. No.87CH2465-3), P259, DOI 10.1007/BF00133570
   LAI KF, 1995, IEEE T PATTERN ANAL, V17, P1084, DOI 10.1109/34.473235
   Li Y, 2004, IEEE T PATTERN ANAL, V26, P45, DOI 10.1109/TPAMI.2004.1261078
   Mann S., 1995, 338 MIT MED LAB PERC
   Mikolajczyk K, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P525, DOI 10.1109/ICCV.2001.937561
   Nayar S., 1997, P DARPA IM UND WORKS, P235
   Peleg S, 1997, PROC CVPR IEEE, P338, DOI 10.1109/CVPR.1997.609346
   Peleg S, 2001, IEEE T PATTERN ANAL, V23, P279, DOI 10.1109/34.910880
   Peri V., 1997, P DARPA IM UND WORKS, P243
   POWELL L, 1994, APPL OPTICS, V33, P7356, DOI 10.1364/AO.33.007356
   Seitz S.M., 1997, PROC IMAGE UNDERSTAN, P881
   Shum H.-Y., 1997, MSRTR9723
   Sun CM, 2004, IEEE T SYST MAN CY B, V34, P760, DOI 10.1109/TSMCB.2003.816997
   Williams L, 2001, FILM QUART, V55, P14, DOI 10.1525/fq.2001.55.2.14
   Xiong YL, 1997, PROC CVPR IEEE, P237, DOI 10.1109/CVPR.1997.609326
   ZHU Z, 2005, MACHINE VISION APPL
   ZHU Z, 1999, P IEEE C COMP VIS PA, V2, P531
   Zhu ZG, 2005, INT J COMPUT VISION, V61, P233
   Zhu ZG, 2004, IEEE T PATTERN ANAL, V26, P226, DOI 10.1109/TPAMI.2004.1262190
   Zhu ZG, 2004, COMPUT VIS IMAGE UND, V96, P294, DOI 10.1016/j.cviu.2004.03.011
   Zhu ZG, 2000, IEEE WORKSHOP ON OMNIDIRECTIONAL VISION, PROCEEDINGS, P29, DOI 10.1109/OMNVIS.2000.853800
   Zhu ZG, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P400, DOI 10.1109/MMCS.1999.779237
   ZHU ZG, 1998, IEEE INT C INT VEH O
NR 31
TC 14
Z9 19
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2006
VL 24
IS 1
BP 13
EP 26
DI 10.1016/j.imavis.2005.09.006
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 007GQ
UT WOS:000234957200002
DA 2024-07-18
ER

PT J
AU Wang, GH
   Hu, ZY
   Wu, FC
   Tsui, HT
AF Wang, GH
   Hu, ZY
   Wu, FC
   Tsui, HT
TI Single view metrology from scene constraints
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE computer vision; single view metrology; projective matrix; metric
   measurement; geometrical constraints
ID VANISHING POINT DETECTION; 3D RECONSTRUCTION
AB The problem of how to retrieve Euclidean entities of a 3D scene from a single uncalibrated image is studied in this paper. We first present two methods to compute the camera projection matrix through the homography of a reference space plane and its vertical vanishing point. Then, we show how to use the projection matrix and some available scene constraints to retrieve geometrical entities of the scene, such as height of an object on the reference plane, measurements on a vertical or arbitrary plane with respect to the reference plane, distance from a point to a line, etc. In particular, the method is further employed to compute the volume and surface area of some regular and symmetric objects from a single image, the undertaking seems no similar report in the literature to our knowledge. In addition, all the algorithms are formulated in an explicit and linear geometric framework, and the involved computation is linear. Finally, extensive experiments on simulated data and real images as well as a comparative test with a closely related method in the literature validate our proposed methods. (c) 2005 Elsevier B.V. All rights reserved.
C1 Aviat Univ Airforce, Dept Control Engn, Changchun 130022, Peoples R China.
   Chinese Acad Sci, Inst Automat, Natl Lab Pattern Recognit, Beijing 100080, Peoples R China.
   Chinese Univ Hong Kong, Dept Elect Engn, Shatin, Hong Kong, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS; Chinese
   University of Hong Kong
RP Aviat Univ Airforce, Dept Control Engn, Changchun 130022, Peoples R China.
EM ghwang@ee.cuhk.edu.hk
RI Wang, Guanghui/B-1080-2008; Hu, Zhanying/AAE-8790-2019
CR Almansa A, 2003, IEEE T PATTERN ANAL, V25, P502, DOI 10.1109/TPAMI.2003.1190575
   Criminisi A, 1999, IMAGE VISION COMPUT, V17, P625, DOI 10.1016/S0262-8856(98)00183-8
   Criminisi A., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P434, DOI 10.1109/ICCV.1999.791253
   Criminisi A., 2001, DISTINGUISHED DISSER
   Gurdjos P, 2000, INT C PATT RECOG, P358, DOI 10.1109/ICPR.2000.905352
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Kim T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P721, DOI 10.1109/ICCV.1998.710797
   Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649
   LIEBOWITZ D, 1999, P EUR, P39
   MCLEAN GF, 1995, IEEE T PATTERN ANAL, V17, P1090, DOI 10.1109/34.473236
   Reid I., 1996, Computer Vision - ECCV '96. 4th Eurpean Conference on Computer Proceedings, P647
   van den Heuvel FA, 1998, ISPRS J PHOTOGRAMM, V53, P354, DOI 10.1016/S0924-2716(98)00019-7
   Wang GH, 2005, IMAGE VISION COMPUT, V23, P311, DOI 10.1016/j.imavis.2004.07.008
   Wang GH, 2004, J COMPUT SCI TECH-CH, V19, P374, DOI 10.1007/BF02944907
   Wang ST, 2002, INT ORTHOP, V26, P207, DOI 10.1007/s00264-002-0346-4
   Wilczkowiak M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P142, DOI 10.1109/ICCV.2001.937510
NR 16
TC 38
Z9 54
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2005
VL 23
IS 9
BP 831
EP 840
DI 10.1016/j.imavis.2005.04.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 957VF
UT WOS:000231400700007
DA 2024-07-18
ER

PT J
AU Qu, YD
   Cui, CS
   Chen, SB
   Li, JQ
AF Qu, YD
   Cui, CS
   Chen, SB
   Li, JQ
TI A fast subpixel edge detection method using <i>Sobel-Zernike moments</i>
   operator
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE edge detection; subpixel edge detection; Sobel operator; Zernike moments
   operator
ID IMAGE-ANALYSIS
AB In this paper, a new edge detection approach combining Zernike moments operator with Sobel operator is proposed. This detection consists of two steps: Firstly, all probable edge points are detected using Sobel operator; Secondly, Zernike moments operator is used to relocate the edge precisely from the points detected by Sobel operator. In the second step, two masks (one real and one complex) are deduced based on Zernike moments theory, and a new criterion for edge point, i.e. magnitude of the complex mask, has been established. Testing of this new detection approach demonstrates the advantage of high precision in subpixel as Zernike moments operator and short run time 79% more efficient than Zernike moments operator. (C) 2004 Elsevier B.V. All rights reserved.
C1 Harbin Inst Technol, Sch Mat Sci & Engn, Harbin 150001, Peoples R China.
   Shanghai Jiao Tong Univ, Sch Mat Sci & Engn, Shanghai 200030, Peoples R China.
C3 Harbin Institute of Technology; Shanghai Jiao Tong University
RP Harbin Inst Technol, Sch Mat Sci & Engn, Harbin 150001, Peoples R China.
EM quyingdong@163.com
RI Liu, Yixuan/JFJ-2820-2023
CR CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Edward P L, 1995, IEEE T PATTERN ANAL, V11, P1293
   GHOSAL S, 1993, PATTERN RECOGN, V26, P295, DOI 10.1016/0031-3203(93)90038-X
   GHOSAL S, 1994, IEEE T IMAGE PROCESS, V3, P14, DOI 10.1109/83.265977
   Ghosal S, 1997, IEEE T IMAGE PROCESS, V6, P781, DOI 10.1109/83.585230
   HUECKEL MH, 1971, J ACM, V18, P113, DOI 10.1145/321623.321635
   Kris J., 1995, IEEE T IMAGE PROCESS, V4, P285
   Liao SX, 1996, IEEE T PATTERN ANAL, V18, P254, DOI 10.1109/34.485554
   Liao SX, 1998, IEEE T PATTERN ANAL, V20, P1358, DOI 10.1109/34.735809
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   ROSENFEL A, 1989, IEEE T BIOMEDICAL EN, V36, P83
   SOBEL I, 1978, COMPUT VISION GRAPH, V8, P127, DOI 10.1016/S0146-664X(78)80020-3
   WHELAN PJM, 1981, P SPIE INT SOC OPT E, V281, P211
   Zernike F, 1934, PHYSICA, V1, P689
   ZHENG NN, 1998, COMPUTER VISION PATT, P69
NR 15
TC 167
Z9 205
U1 4
U2 94
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2005
VL 23
IS 1
BP 11
EP 17
DI 10.1016/j.imavis.2004.07.003
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 882BO
UT WOS:000225913700002
DA 2024-07-18
ER

PT J
AU Ha, DM
   Lee, JM
   Kim, YD
AF Ha, DM
   Lee, JM
   Kim, YD
TI Neural-edge-based vehicle detection and traffic parameter extraction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE vehicle detection; vehicle classification; background extraction; neural
   network; traffic monitoring
AB Vehicle detection is a fundamental component of image-based traffic monitoring system. In this paper, we propose a neural-edge-based vehicle detection method to improve the accuracy of vehicle detection and classification. In this method, the feature information is extracted by the seed-filling-based method and is presented to the input of neural network for vehicle detection and classification. The neural-edge-based vehicle detection method is effective and the correct rate of vehicle detection is higher than 96%, independent of environmental conditions. Also, traffic parameters, such as vehicle count, vehicle class, and vehicle speed, are extracted via vehicle tracking method (C) 2004 Elsevier B.V. All rights reserved.
C1 Ajou Univ, Dept Elect Engn, Suwon 442749, South Korea.
C3 Ajou University
RP Ajou Univ, Dept Elect Engn, And 5,Wonchon Dong, Suwon 442749, South Korea.
EM chaboom@ajou.ac.kr
CR [Anonymous], TRAFFIC ENG CONTR
   Burger P., 1989, Interactive Computer Graphics
   FATHY M, 1995, IEE P-VIS IMAGE SIGN, V142, P297, DOI 10.1049/ip-vis:19952064
   Fathy M, 1998, IEEE T VEH TECHNOL, V47, P1342, DOI 10.1109/25.728525
   Gupte S, 2002, IEEE T INTELL TRANSP, V3, P37, DOI 10.1109/6979.994794
   Hashimoto N., 1988, SUMITOMO ELECT TECH, P133
   Hoose N., 1991, COMPUTER IMAGE PROCE
   INDIO RM, 1989, IEEE T VEH TECHNOL, V38, P112
   MICHALOPOULOS PG, 1991, IEEE T VEH TECHNOL, V40, P21, DOI 10.1109/25.69968
   PANDYA AS, 1995, PATTERN RECOGN, P73
   Rourke A., 1988, P SEM TRANSP PLANN M
   YEN JC, 1995, IEEE T IMAGE PROCESS, V4, P370, DOI 10.1109/83.366472
   ZHANG H, 1994, 3 INT C AUT ROB COMP, P1990
NR 13
TC 52
Z9 60
U1 5
U2 44
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 20
PY 2004
VL 22
IS 11
BP 899
EP 907
DI 10.1016/j.imavis.2004.05.006
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 847MJ
UT WOS:000223396600004
DA 2024-07-18
ER

PT J
AU Heikkilä, J
   Silvén, I
AF Heikkilä, J
   Silvén, I
TI A real-time system for monitoring of cyclists and pedestrians
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE human tracking; traffic counting; target classification
AB Camera based systems are routinely used for monitoring highway traffic, supplementing inductive loops and microwave sensors employed for counting purposes. These techniques achieve very good counting accuracy and are capable of discriminating trucks and cars. However, pedestrians and cyclists are mostly counted manually. In this paper, we describe a new camera based automatic system that utilizes Kalman filtering in tracking and Learning Vector Quantization for classifying the observations to pedestrians and cyclists. Both the requirements for such systems and the algorithms used are described. The tests performed show that the system achieves around 80-90% accuracy in counting and classification. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Oulu, Infotec Oulu, Machine Vis Grp, FIN-90014 Oulu, Finland.
   Univ Oulu, Dept Elect & Informat Engn, FIN-90014 Oulu, Finland.
C3 University of Oulu; University of Oulu
RP Univ Oulu, Infotec Oulu, Machine Vis Grp, POB 4500, FIN-90014 Oulu, Finland.
EM jth@ee.oulu.fi; olli@ee.oulu.fi
OI Silven, Olli/0000-0002-2661-804X
CR BAUMBERG A, 1994, IEEE WORKSH MOT NONR, P194
   BOGAERT M, 1996, IEEE INT C IM PROC L, V3, P675
   Bregler C, 1997, PROC CVPR IEEE, P568, DOI 10.1109/CVPR.1997.609382
   COMANICIU D, IEEE C COMP VIS PATT, P142
   GAVRILA D, 1999, ICCV, P87
   HARITAOGLU I, 1998, W4 WHO WHAT REAL TIM, P22
   Isard M., 1996, ECCV, P343
   Kohonen T., 1995, SELF ORGANIZING MAPS
   Nadler M., 1993, Pattern Recognition Engineering
   Papageorgiou C., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P1223, DOI 10.1109/ICCV.1999.790420
   ROHR K, 1993, IEEE C COMPUTER VISI, P8
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 12
TC 39
Z9 47
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2004
VL 22
IS 7
BP 563
EP 570
DI 10.1016/j.imavis.2003.09.010
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RT
UT WOS:000221481000005
DA 2024-07-18
ER

PT J
AU Hamarneh, G
   Gustavsson, T
AF Hamarneh, G
   Gustavsson, T
TI Deformable spatio-temporal shape models: extending active shape models
   to 2D+time
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE deformable models; segmentation; active shape models; spatio-temporal
   shapes; dynamic programming; echocardiography
ID TRACKING; IMAGES
AB This paper extends 2D active shape models to 2D + time by presenting a method for modeling and segmenting spatio-temporal shapes (ST-shapes). The modeling part consists of constructing a statistical model of ST-shape parameters. This model describes the principal modes of variation of the ST-shape in addition to constraints on the allowed variations. An active approach is used in segmentation where an initial ST-shape is deformed to better fit the data and the optimal proposed deformation is calculated using dynamic programming. Segmentation results on both synthetic and real data are presented. (C) 2003 Elsevier B.V. All rights reserved.
C1 Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
   Chalmers Univ Technol, Dept Signals & Syst, SE-41296 Gothenburg, Sweden.
C3 Simon Fraser University; Chalmers University of Technology
RP Simon Fraser Univ, Sch Comp Sci, Burnaby, BC V5A 1S6, Canada.
EM hamarneh@cs.sfu.ca; gustavsson@s2.chalmers.se
RI Hamarneh, Ghassan/B-1063-2009; Hamarneh, Ghassan/AAE-6673-2021
OI Hamarneh, Ghassan/0000-0001-5040-7448
CR AMINI AA, 1990, IEEE T PATTERN ANAL, V12, P855, DOI 10.1109/34.57681
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   Bonciu C, 1998, BIOIMAGING, V6, P111, DOI 10.1002/1361-6374(199809)6:3<111::AID-BIO1>3.0.CO;2-3
   COHEN LD, 1991, CVGIP-IMAG UNDERSTAN, V53, P211, DOI 10.1016/1049-9660(91)90028-N
   Cootes T., 1994, BMVC, V1, P327
   Cootes T., 1998, Proc. ECCV, V2, P484
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Grzeszczuk RP, 1997, IEEE T PATTERN ANAL, V19, P1100, DOI 10.1109/34.625111
   Herlin I. L., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P534, DOI 10.1109/CVPR.1992.223139
   HILL A, 1994, BMVC94 - PROCEEDINGS OF THE 5TH BRITISH MACHINE VISION CONFERENCE, VOLS 1 AND 2, P429
   Hill A., 1993, fth British Machine Vision Conference, P1, DOI DOI 10.5244/C.7.34
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lelieveldt B. P. F., 2001, Information Processing in Medical Imaging. 17th International Conference, IPMI 2001. Proceedings (Lecture Notes in Computer Science Vol.2082), P446
   LEYMARIE F, 1993, IEEE T PATTERN ANAL, V15, P617, DOI 10.1109/34.216733
   LOBREGT S, 1995, IEEE T MED IMAGING, V14, P12, DOI 10.1109/42.370398
   MCINERNEY T, 1995, COMPUT MED IMAG GRAP, V19, P69, DOI 10.1016/0895-6111(94)00040-9
   MCINERNEY T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P840, DOI 10.1109/ICCV.1995.466850
   NIESSEN W, 1995, SPIE MED IMAGING, P250
   Sclaroff S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P1146, DOI 10.1109/ICCV.1998.710860
   SIGNH A, 1993, SPIE P BIOM IM PROC, V1905, P8
   Singh A., 1998, DEFORMABLE MODELS ME
   STAIB LH, 1992, IEEE T PATTERN ANAL, V14, P1061, DOI 10.1109/34.166621
   STARK S, 1996, P INT C PATT REC, P905
   Terzopoulos D., 1992, Active Vision, P3
NR 24
TC 33
Z9 34
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 1
PY 2004
VL 22
IS 6
BP 461
EP 470
DI 10.1016/j.imavis.2003.11.009
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 817HB
UT WOS:000221167500003
DA 2024-07-18
ER

PT J
AU Deschênes, F
   Ziou, D
   Fuchs, P
AF Deschênes, F
   Ziou, D
   Fuchs, P
TI An unified approach for a simultaneous and cooperative estimation of
   defocus blur and spatial shifts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE three-dimensional computer vision; unified model; feature extraction;
   depth from defocus; blur; disparity; motion; zoom; moment expansion;
   S-transform
ID DEPTH; STEREO; MOTION; VISION; FLOW; CALIBRATION; ALGORITHM; VERGENCE;
   IMAGES; DOMAIN
AB This paper presents an algorithm for a cooperative and simultaneous estimation of depth cues: defocus blur and spatial shifts (stereo disparities, two-dimensional (2D) motion, and/or zooming disparities). These cues are estimated from two images of the same scene acquired by a camera evolving in time and/or space and for which the intrinsic parameters are known. This algorithm is based on generalized moment expansion. We show that the more blurred image may be expressed as a function of the partial derivatives of the two images, the blur difference and the horizontal and vertical shifts. Hence, these depth cues can be computed by resolving a system of equations. The behavior of the algorithm is studied for constant and linear images, step edges, lines and junctions. The rules governing the choice of its parameters are then discussed. The proposed algorithm is tested using synthetic and real images. The results obtained are accurate and dense. They confirm that defocus blurs and spatial shifts (stereo disparities, 2D motion, and/or zooming disparities) can be simultaneously computed without using the epipolar geometry. They thus implicitly show that the unified approach allows: (1) blur estimation even if the spatial locations of corresponding pixels do not match perfectly; (2) spatial shift estimation even if some of the intrinsic parameters of the camera have been modified during the capture. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Sherbrooke, Fac Sci, Dept Math & Informat, Sherbrooke, PQ J1K 2R1, Canada.
   Ecole Mines, Ctr Robot, F-75272 Paris 06, France.
C3 University of Sherbrooke; Universite PSL; MINES ParisTech
RP Univ Sherbrooke, Fac Sci, Dept Math & Informat, 2500 Blvd Univ, Sherbrooke, PQ J1K 2R1, Canada.
EM francois.deschenes@dmi.usherb.ca; djemel.ziou@dmi.usherb.ca;
   philippe.fuchs@caor.ensmp.fr
CR AHUJA N, 1993, IEEE T PATTERN ANAL, V15, P1007, DOI 10.1109/34.254059
   ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   [Anonymous], 1981, P 7 INT JOINT C ART
   DAS S, 1995, IEEE T PATTERN ANAL, V17, P1213, DOI 10.1109/34.476513
   DESCHENES F, 2001, 261 DMI U SHERBR
   DESCHENES F, 2000, 256 DMI U SHERBR
   ENCISO R, 1995, P 4 INT C INT REAL V, P103
   GRIMSON WEL, 1985, IEEE T PATTERN ANAL, V7, P17, DOI 10.1109/TPAMI.1985.4767615
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   JULESZ B, 1960, AT&T TECH J, V39, P1125, DOI 10.1002/j.1538-7305.1960.tb03954.x
   Krotkov E.P., 1989, Active Computer Vision by co-operative Focus and Stereo
   LARVEST JM, 1993, IEEE T ROBOTIC AUTOM, V9, P196
   Lavest JM, 1997, COMPUT VIS IMAGE UND, V66, P301, DOI 10.1006/cviu.1996.0511
   LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781
   MA J, 1990, J OPT SOC AM A, V7, P1883, DOI 10.1364/JOSAA.7.001883
   MANMATHA R, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P141, DOI 10.1109/CVPR.1994.323821
   Myles Z, 1998, IEEE T PATTERN ANAL, V20, P652, DOI 10.1109/34.683782
   Olsen RA, 1997, J BEHAV DECIS MAKING, V10, P65, DOI 10.1002/(SICI)1099-0771(199703)10:1<65::AID-BDM246>3.0.CO;2-S
   PAHLAVAN K, 1992, P 2 EUR C COMP VIS S, P526
   PENTLAND AP, 1987, IEEE T PATTERN ANAL, V9, P523, DOI 10.1109/TPAMI.1987.4767940
   Press W. H., 1988, Numerical Recipes
   Rajagopalan AN, 1997, COMPUT VIS IMAGE UND, V68, P309, DOI 10.1006/cviu.1997.0534
   RICHARDS W, 1985, J OPT SOC AM A, V2, P343, DOI 10.1364/JOSAA.2.000343
   Roy S, 1999, INT J COMPUT VISION, V34, P147, DOI 10.1023/A:1008192004934
   STEWART CV, 1989, HUMAN MACHINE STRATE, V1198, P102
   SUBBARAO M, 1994, INT J COMPUT VISION, V13, P271, DOI 10.1007/BF02028349
   SUDHIR G, 1995, J OPT SOC AM A, V12, P2564, DOI 10.1364/JOSAA.12.002564
   Super BJ, 1997, IEEE T PATTERN ANAL, V19, P247, DOI 10.1109/34.584102
   Trucco E., 1998, INTRO TECHNIQUES 3D
   VIEVILLE T, 1995, ROBOT AUTON SYST, V14, P1, DOI 10.1016/0921-8890(94)00019-X
   WAXMAN AM, 1986, IEEE T PATTERN ANAL, V8, P715, DOI 10.1109/TPAMI.1986.4767853
   Willson R. C., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P670, DOI 10.1109/CVPR.1993.341035
   XU G, 1996, EPIPLOAR GEOMETRY ST
   ZHANG Y, 2000, P 15 INT C PATT REC, P881
   Zhang YN, 2000, PATTERN RECOGN LETT, V21, P425, DOI 10.1016/S0167-8655(00)00014-3
   Ziou D, 2001, COMPUT VIS IMAGE UND, V81, P143, DOI 10.1006/cviu.2000.0899
NR 36
TC 24
Z9 30
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2004
VL 22
IS 1
BP 35
EP 57
DI 10.1016/j.imavis.2003.08.003
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 763BB
UT WOS:000188048400005
DA 2024-07-18
ER

PT J
AU Porter, S
   Mirmehdi, M
   Thomas, B
AF Porter, S
   Mirmehdi, M
   Thomas, B
TI Temporal video segmentation and classification of edit effects
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 12th Annual British Machine Vision Conference
CY SEP, 2001
CL UNIV MANCHESTER, MANCHESTER, ENGLAND
SP British Machine Vis Assoc
HO UNIV MANCHESTER
DE shot transitions; shot break detection; shot classification; video
   segmentation
ID SHOT-BOUNDARY DETECTION
AB The process of shot break detection is a fundamental component in automatic video indexing, editing and archiving. This paper introduces a novel approach to the detection and classification of shot transitions in video sequences including cuts, fades and dissolves. It uses the average inter-frame correlation coefficient and block-based motion estimation to track image blocks through the video sequence and to distinguish changes caused by shot transitions from those caused by camera and object motion. We present a number of experiments in which we achieve better results compared with two established techniques. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.
C3 University of Bristol
RP Univ Bristol, Dept Comp Sci, Bristol BS8 1UB, Avon, England.
EM porter@cs.bris.ac.uk
OI Mirmehdi, Majid/0000-0002-6478-1403
CR AKUTSU A, 1992, SPIE P VISUAL COMMUN, V1818, P1522
   ALATTAR AM, 1993, 1993 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS : PROCEEDINGS, VOLS 1-4 ( ISCAS 93 ), P13
   [Anonymous], 2001, International Journal of Image and Graphics (IJIG), Vol, DOI DOI 10.1142/S021946780100027X
   [Anonymous], 1993, Multimedia Systems, DOI DOI 10.1007/BF01210504
   Boreczky JS, 1996, P SOC PHOTO-OPT INS, V2670, P170, DOI 10.1117/12.234794
   Calway A. D., 1992, BMVC92. Proceedings of the British Machine Vision Conference, P227
   Fernando W. A. C., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P299, DOI 10.1109/ICIP.1999.817121
   Hampapur A., 1994, Proceedings ACM Multimedia '94, P357, DOI 10.1145/192593.192699
   Hanjalic A, 2002, IEEE T CIRC SYST VID, V12, P90, DOI 10.1109/76.988656
   JONES C, 1994, ENCY ED TECHNOLOGY
   KASTURI R, 1991, COMPUTER VISION PRIN
   KRUGER S, 1998, THESIS U BRISTOL
   LIENHART R, 1999, SPIE C STORAGE RETRI, V356, P290
   Lupatini G, 1998, EIGHTH INTERNATIONAL WORKSHOP ON RESEARCH ISSUES IN DATA ENGINEERING - CONTINUOUS-MEDIA DATABASES AND APPLICATIONS, PROCEEDINGS, P34, DOI 10.1109/RIDE.1998.658276
   NAGASAKA A, 1992, IFIP TRANS A, V7, P113
   SHAHRARAY B, 1995, P SOC PHOTO-OPT INS, V2419, P2, DOI 10.1117/12.206348
   Yusoff Y, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 2, P700, DOI 10.1109/MMCS.1999.778569
   YUSOFF Y, 1998, 3 EUR C MULT APPL SE, P177
   Zabih R, 1999, MULTIMEDIA SYST, V7, P119, DOI 10.1007/s005300050115
   ZABIH R, 1995, ACM MULTIMEDIA 95 P
   Ziegel ER, 1995, MATH STAT DATA ANAL, V37, P127
NR 21
TC 34
Z9 35
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2003
VL 21
IS 13-14
BP 1097
EP 1106
DI 10.1016/j.imavis.2003.08.014
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 758JN
UT WOS:000187631100004
DA 2024-07-18
ER

PT J
AU Shamim, A
   Robinson, JA
AF Shamim, A
   Robinson, JA
TI Asymmetric binary tree coding for contour images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE hierarchical coding; contour coding
ID DATA-COMPRESSION
AB We consider the coding of featured contours, i.e. texture, object or motion boundaries in images. The MPEG-4 and MPEG-7 video coding standards provide for a content-based representation of video information, so efficient coding of boundaries can play an important role. We propose a new coding scheme that uses an asymmetric binary tree. We show that the new scheme outperforms conventional quadtree, binary tree, contour and READ coding algorithms applied to typical boundary images and also offers competitive performance for general-purpose two-level image coding. (C) 2003 Elsevier B.V. All rights reserved.
C1 Mem Univ Newfoundland, Fac Engn & Appl Sci, St Johns, NF A1B 3X5, Canada.
C3 Memorial University Newfoundland
RP Robinson, JA (corresponding author), Univ York, Dept Elect, York YO10 5EE, N Yorkshire, England.
CR [Anonymous], 1992, R. woods digital image processing
   BODSON D, 1985, P IEEE, V73, P731, DOI 10.1109/PROC.1985.13196
   COHEN Y, 1985, IEEE T PATTERN ANAL, V7, P284, DOI 10.1109/TPAMI.1985.4767657
   Freeman H., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P701
   Freeman H., 1961, IRE T ELECTRON COMPU, V10, P260, DOI [DOI 10.1109/TEC.1961.5219197, 10.1109/TEC.1961.5219197]
   GOLOMB SW, 1966, IEEE T INFORM THEORY, V12, P399, DOI 10.1109/TIT.1966.1053907
   KNOWLTON K, 1980, P IEEE, V68, P885, DOI 10.1109/PROC.1980.11754
   ROBINSON JA, 1986, IEE PROC-F, V133, P236, DOI 10.1049/ip-f-1.1986.0041
   Samet H., 1980, Proceedings of the 5th International Conference on Pattern Recognition, P815
   SHAMIM A, 2002, IEEE T CIRCUITS SYST, V12
NR 10
TC 1
Z9 1
U1 0
U2 0
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2003
VL 21
IS 9
BP 797
EP 807
DI 10.1016/S0262-8856(03)00093-3
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 711QX
UT WOS:000184753500004
DA 2024-07-18
ER

PT J
AU Nummiaro, K
   Koller-Meier, E
   Van Gool, L
AF Nummiaro, K
   Koller-Meier, E
   Van Gool, L
TI An adaptive color-based particle filter
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 1st International Workshop on Generative-Model-Based Vision
CY JUN 02, 2002
CL COPENHAGEN, DENMARK
DE particle filtering; condensation algorithm; color distribution;
   bhattacharyya coefficient; mean shift tracker
ID TRACKING
AB Robust real-time tracking of non-rigid objects is a challenging task. Particle filtering has proven very successful for non-linear and non-Gaussian estimation problems. The article presents the integration of color distributions into particle filtering, which has typically been used in combination with edge-based image features. Color distributions are applied, as they are robust to partial occlusion, are rotation and scale invariant and computationally efficient. As the color of an object can vary over time dependent on the illumination, the visual angle and the camera parameters, the target model is adapted during temporally stable image observations. An initialization based on an appearance condition is introduced since tracked objects may disappear and reappear. Comparisons with the mean shift tracker and a combination between the mean shift tracker and Kalman filtering show the advantages and limitations of the new approach. (C) 2002 Elsevier Science B.V. All rights reserved.
C1 Katholieke Univ Leuven, VISICS, PSI, ESAT, B-3001 Heverlee, Belgium.
   Swiss Fed Inst Technol, Swiss Fed Inst Technol, D ITET, BIWI, CH-8092 Zurich, Switzerland.
C3 KU Leuven; Swiss Federal Institutes of Technology Domain; ETH Zurich
RP Katholieke Univ Leuven, VISICS, PSI, ESAT, Kasteelpk Arenberg 10, B-3001 Heverlee, Belgium.
EM knummiar@esat.kuleuven.ac.be
CR Aherne F., 1997, KYBERNETIKA, V32, P1
   Beymer D, 1997, PROC CVPR IEEE, P495, DOI 10.1109/CVPR.1997.609371
   Black M.J., 1998, P EUROPEAN C COMPUTE, V1, P909
   BURGES C.J., 1998, A Tutorial on Support Vector Machines for Pattern, P121
   Comaniciu D, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P70, DOI 10.1109/ICIP.2000.899297
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   Friedman N., 1997, PROC UNCERTAINTY ART, P175
   GORDON N, 1995, J GUID CONTROL DYNAM, V18, P1434, DOI 10.2514/3.21565
   Greiffenhagen M, 2000, PROC CVPR IEEE, P335, DOI 10.1109/CVPR.2000.854840
   Halevy G, 1999, MACH VISION APPL, V11, P122, DOI 10.1007/s001380050096
   Heap T, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P344, DOI 10.1109/ICCV.1998.710741
   Isard M, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P107, DOI 10.1109/ICCV.1998.710707
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P34, DOI 10.1109/ICCV.2001.937594
   Isard M., 1996, ECCV, P343
   Jepson AD, 2001, PROC CVPR IEEE, P415
   KAILATH T, 1967, IEEE T COMMUN TECHN, VCO15, P52, DOI 10.1109/TCOM.1967.1089532
   Kitagawa G., 1996, J COMPUT GRAPH STAT, V5, P1, DOI DOI 10.2307/1390750
   KOLLER D, 1994, EUR C COMP VIS, P189
   MacCormick J., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P572, DOI 10.1109/ICCV.1999.791275
   McKenna SJ, 1999, IMAGE VISION COMPUT, V17, P225, DOI 10.1016/S0262-8856(98)00104-8
   Menser B, 2000, CONF REC ASILOMAR C, P49, DOI 10.1109/ACSSC.2000.910916
   Nummiaro K., 2002, Proceedings of International Workshop on Generative-Model-Based Vision, V2002/01, P53
   NUMMIARO K, 2002, S PATT REC DAGM, P353
   PEREZ P, 2002, EUR C COMP VIS, P661
   Raja Y, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P228, DOI 10.1109/AFGR.1998.670953
   Segen J., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P63, DOI 10.1109/ICPR.1996.546795
   YILMAZ A, 2001, COMPUTER VISION VISI, P54
NR 28
TC 813
Z9 1041
U1 2
U2 123
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 10
PY 2003
VL 21
IS 1
BP 99
EP 110
AR PII S0262-8856(02)00129-4
DI 10.1016/S0262-8856(02)00129-4
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 645KM
UT WOS:000180974800011
DA 2024-07-18
ER

PT J
AU Jaisurya, RS
   Mukherjee, S
AF Jaisurya, R. S.
   Mukherjee, Snehasis
TI AGLC-GAN: Attention-based global-local cycle-consistent generative
   adversarial networks for unpaired single image dehazing
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image Dehazing; CycleGAN; Attention; Unpaired
AB Image dehazing is a critical image pre-processing task to estimate the haze-free images corresponding to the input hazy images. Despite the recent advances, the task of image dehazing remains challenging, especially in the unsupervised scenario. Several efforts can be found in the literature to dehaze images in a supervised set-up, where a huge number of paired (clear and hazy images) images are required for training. The supervised approaches often become biased towards the nature of haze present in the training hazy images, and produce less realistic images for query hazy images. We propose an Attention-based Global-Local Cycle-consistent Generative Adversarial Network (AGLC-GAN) for Unpaired Single Image Dehazing. The proposed CycleGAN-based AGLCGAN model contains a dehazing generator encapsulating an autoencoder-like network with an attention mechanism comprising channel attention and pixel attention to deal with uneven haze intensity across the image. We use a global-local consistent discriminator to identify spatially varying haze and improve the stability of the discriminator. We adopt cyclic perceptual consistency loss to maintain consistency in the feature space. A dynamic feature enhancement module and an adaptive mix-up module are included in the proposed generator to dynamically obtain more spatially structured features and hence, adaptively preserve the flow of shallow features. Furthermore, we extensively experiment with the proposed model on multiple benchmark datasets for evaluating the efficacy of removing haze. The results of the experiments conducted in the study, demonstrate a significant quantitative and qualitative improvement over the existing methods for unpaired image dehazing. 1
C1 [Jaisurya, R. S.; Mukherjee, Snehasis] Shiv Nadar Inst Eminence, Delhi, India.
RP Mukherjee, S (corresponding author), Shiv Nadar Inst Eminence, Delhi, India.
EM snehasis.mukherjee@snu.edu.in
CR Ancuti CO, 2019, IEEE COMPUT SOC CONF, P2241, DOI 10.1109/CVPRW.2019.00277
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P1798, DOI 10.1109/CVPRW50498.2020.00230
   Ancuti CO, 2020, IEEE COMPUT SOC CONF, P2029, DOI 10.1109/CVPRW50498.2020.00253
   Ancuti CO, 2019, IEEE IMAGE PROC, P1014, DOI [10.1109/icip.2019.8803046, 10.1109/ICIP.2019.8803046]
   Anvari Z., 2008, arXiv
   Babu GH, 2020, J VIS COMMUN IMAGE R, V72, DOI 10.1016/j.jveir.2020.102912
   Borkar K, 2020, NEUROCOMPUTING, V400, P294, DOI 10.1016/j.neucom.2020.03.027
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chaitanya BSNV, 2021, J VIS COMMUN IMAGE R, V74, DOI 10.1016/j.jvcir.2020.103014
   Chen DD, 2019, IEEE WINT CONF APPL, P1375, DOI 10.1109/WACV.2019.00151
   Chen Xuesong, 2022, ECCV, V6
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Engin D, 2018, IEEE COMPUT SOC CONF, P938, DOI 10.1109/CVPRW.2018.00127
   Fattal R, 2014, ACM T GRAPHIC, V34, DOI 10.1145/2651362
   Fu MH, 2021, IEEE COMPUT SOC CONF, P203, DOI 10.1109/CVPRW53098.2021.00029
   Gao Y, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103868
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gui J, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3576918
   Gui Jie, 2021, IJCAI
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Iizuka S, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073659
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Jaisurya R.S., 2022, IEEE IJCNN
   Jiang YF, 2021, IEEE T IMAGE PROCESS, V30, P2340, DOI 10.1109/TIP.2021.3051462
   Kaplan NH, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103720
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li BY, 2017, IEEE I CONF COMP VIS, P4780, DOI 10.1109/ICCV.2017.511
   Liu J, 2020, IEEE COMPUT SOC CONF, P1732, DOI 10.1109/CVPRW50498.2020.00223
   Liu W, 2019, IMAGE VISION COMPUT, V92, DOI 10.1016/j.imavis.2019.10.001
   Liu XH, 2019, IEEE I CONF COMP VIS, P7313, DOI 10.1109/ICCV.2019.00741
   Qin X, 2020, AAAI CONF ARTIF INTE, V34, P11908
   Qu YY, 2019, PROC CVPR IEEE, P8152, DOI 10.1109/CVPR.2019.00835
   Ren WQ, 2016, LECT NOTES COMPUT SC, V9906, P154, DOI 10.1007/978-3-319-46475-6_10
   Shao YJ, 2020, PROC CVPR IEEE, P2805, DOI 10.1109/CVPR42600.2020.00288
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Su Z, 2023, J VIS COMMUN IMAGE R, V90, DOI 10.1016/j.jvcir.2022.103706
   Wu HY, 2021, PROC CVPR IEEE, P10546, DOI 10.1109/CVPR46437.2021.01041
   Yang XT, 2018, AAAI CONF ARTIF INTE, P7485
   Yang Y, 2022, PROC CVPR IEEE, P2027, DOI 10.1109/CVPR52688.2022.00208
   Yu F., 2015, ARXIV
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu QS, 2015, IEEE T IMAGE PROCESS, V24, P3522, DOI 10.1109/TIP.2015.2446191
NR 42
TC 3
Z9 3
U1 21
U2 26
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2023
VL 140
AR 104859
DI 10.1016/j.imavis.2023.104859
EA OCT 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA Y7RX6
UT WOS:001107207100001
DA 2024-07-18
ER

PT J
AU Zhu, JQ
   Wu, HX
   Zhao, QQ
   Zeng, HQ
   Zhu, XB
   Huang, JC
   Cai, CH
AF Zhu, Jianqing
   Wu, Hanxiao
   Zhao, Qianqian
   Zeng, Huanqiang
   Zhu, Xiaobin
   Huang, Jingchang
   Cai, Canhui
TI Visible-infrared person re-identification using high utilization
   mismatch amending triplet loss
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE negative intra-modal; function that; modal or intra-modal. But; pairs
   are more important loss to cross
AB Visible-infrared person re-identification (VIPR) is a task of retrieving a specific pedestrian monitored by cameras in different spectra. A dilemma of VIPR is how to reasonably use intra-modal pairs. Fully discarding intra-modal pairs causes a low utilization of training data, while using intra-modal pairs brings a danger of distracting a VIPR model's concentration on handling cross-modal pairs, harming the cross-modal similarity metric learning. For that, a high utilization mismatch amending (HUMA) triplet loss function is proposed for VIPR. The key of HUMA is the multi-modal matching regularization (MMMR), which restricts variations of distance matrices calculated from cross- and intra-modal pairs to cohere cross-and intra-modal similarity metrics, allowing for a high utilization of training data and amending the adverse distractions of intra-modal pairs. In addition, to avoid the risk of harming feature discrimination caused by MMMR preferring coherence in similarity metrics, a novel separated loss function assignment (SLFA) strategy is designed to arrange MMMR well. Experimental results show that the proposed method is superior to state-of-the-art approaches.
C1 [Zhu, Jianqing; Zeng, Huanqiang; Zhu, Xiaobin; Cai, Canhui] Huaqiao Univ, Coll Engn, 269 Chenghua North Rd, Quanzhou 362021, Fujian, Peoples R China.
   [Zhao, Qianqian] Huaqiao Univ, Coll Informat Sci & Engn, 668 Jimei Ave, Xiamen 361021, Fujian, Peoples R China.
   [Zhu, Xiaobin] Univ Sci & Technol Beijing, Sch Comp & Commun Engn, 30 Xueyuan Rd, Beijing 100083, Peoples R China.
   [Huang, Jingchang] Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, 865 Changning Rd, Shanghai 200050, Peoples R China.
C3 Huaqiao University; Huaqiao University; University of Science &
   Technology Beijing; Chinese Academy of Sciences; Shanghai Institute of
   Microsystem & Information Technology, CAS
RP Zhu, JQ (corresponding author), Huaqiao Univ, Coll Engn, 269 Chenghua North Rd, Quanzhou 362021, Fujian, Peoples R China.
EM jqzhu@hqu.edu.cn
RI Zeng, Huanqiang/U-2017-2018
CR Cai X, 2021, KNOWL-BASED SYST, V215, DOI 10.1016/j.knosys.2021.106772
   Can Zhang, 2020, 2020 25th International Conference on Pattern Recognition (ICPR), P8679, DOI 10.1109/ICPR48806.2021.9412576
   Chen KX, 2020, IEEE T NEUR NET LEAR, V31, P1747, DOI 10.1109/TNNLS.2019.2927224
   Chen Y, 2022, IMAGE VISION COMPUT, V128, DOI 10.1016/j.imavis.2022.104587
   Dai PY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P677
   Feng YJ, 2021, IEEE SIGNAL PROC LET, V28, P1789, DOI 10.1109/LSP.2021.3107209
   Feng ZX, 2020, IEEE T IMAGE PROCESS, V29, P579, DOI 10.1109/TIP.2019.2928126
   Hao X, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P16383, DOI 10.1109/ICCV48922.2021.01609
   Hao Y, 2019, AAAI CONF ARTIF INTE, P8385
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans A, 2017, Arxiv, DOI [arXiv:1703.07737, DOI 10.48550/ARXIV.1703.07737]
   Hu B., 2021, INT C MULT EXP, P1
   Hu WP, 2022, IEEE T CIRC SYST VID, V32, P5095, DOI 10.1109/TCSVT.2022.3147813
   Huang Y, 2022, IEEE T MULTIMEDIA, V24, P1570, DOI 10.1109/TMM.2021.3067760
   Kerim A, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104187
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li DG, 2020, AAAI CONF ARTIF INTE, V34, P4610
   Li WK, 2021, IEEE IJCNN, DOI 10.1109/IJCNN52387.2021.9533325
   Li XL, 2022, LECT NOTES COMPUT SC, V13686, P381, DOI 10.1007/978-3-031-19809-0_22
   Liu HJ, 2021, IEEE T MULTIMEDIA, V23, P4414, DOI 10.1109/TMM.2020.3042080
   Liu HJ, 2023, IEEE T NEUR NET LEAR, V34, P1958, DOI 10.1109/TNNLS.2021.3105702
   Liu JC, 2022, APPL INTELL, V52, P2423, DOI 10.1007/s10489-021-02548-3
   Liu JL, 2022, PROC CVPR IEEE, P19344, DOI 10.1109/CVPR52688.2022.01876
   Liu S, 2021, IEEE INTERNET THINGS, V8, P15170, DOI 10.1109/JIOT.2020.3038794
   Liu XL, 2021, IEEE T CIRC SYST VID, V31, P2133, DOI 10.1109/TCSVT.2020.3021409
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Mang Ye, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12362), P229, DOI 10.1007/978-3-030-58520-4_14
   Miao Z, 2021, PROC JCAI, P916
   Nguyen DT, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030605
   Paszke A, 2019, ADV NEUR IN, V32
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seokeon C., 2020, INT C COMP VIS PATT, P10254
   Shen F, 2022, IEEE T INTELL TRANSP, V23, P8793, DOI 10.1109/TITS.2021.3086142
   Shi W, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104335
   Sun ZH, 2021, IEEE T CIRC SYST VID, V31, P1819, DOI 10.1109/TCSVT.2020.3009717
   Tao DP, 2018, IEEE T CIRC SYST VID, V28, P2657, DOI 10.1109/TCSVT.2017.2726580
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang GA, 2020, AAAI CONF ARTIF INTE, V34, P12144
   Wang GA, 2019, IEEE I CONF COMP VIS, P3622, DOI 10.1109/ICCV.2019.00372
   Wang JB, 2020, PROCEEDINGS OF 2020 5TH INTERNATIONAL CONFERENCE ON MULTIMEDIA AND IMAGE PROCESSING (ICMIP 2020), P28, DOI 10.1145/3381271.3381285
   Wang PY, 2021, IEEE T IMAGE PROCESS, V30, P2908, DOI 10.1109/TIP.2021.3055952
   Wang RP, 2021, IMAGE VISION COMPUT, V107, DOI 10.1016/j.imavis.2021.104110
   Wei ZY, 2022, IEEE T NEUR NET LEAR, V33, P4676, DOI 10.1109/TNNLS.2021.3059713
   Wu AC, 2017, IEEE I CONF COMP VIS, P5390, DOI 10.1109/ICCV.2017.575
   Wu Q, 2021, PROC CVPR IEEE, P4328, DOI 10.1109/CVPR46437.2021.00431
   Xiao CJ, 2021, IEEE INTERNET THINGS, V8, P5669, DOI 10.1109/JIOT.2020.3033173
   Xiaojiang Hu, 2020, Pattern Recognition and Computer Vision. Third Chinese Conference, PRCV 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12306), P557, DOI 10.1007/978-3-030-60639-8_46
   Yan Lu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13376, DOI 10.1109/CVPR42600.2020.01339
   Yang MX, 2022, PROC CVPR IEEE, P14288, DOI 10.1109/CVPR52688.2022.01391
   Ye M, 2022, IEEE T INF FOREN SEC, V17, P386, DOI 10.1109/TIFS.2021.3139224
   Ye M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1092
   Ye M, 2022, IEEE T PATTERN ANAL, V44, P2872, DOI 10.1109/TPAMI.2021.3054775
   Ye M, 2021, IEEE T INF FOREN SEC, V16, P728, DOI 10.1109/TIFS.2020.3001665
   Ye M, 2020, IEEE T IMAGE PROCESS, V29, P9387, DOI 10.1109/TIP.2020.2998275
   Ye M, 2020, IEEE T INF FOREN SEC, V15, P407, DOI 10.1109/TIFS.2019.2921454
   Ye M, 2018, AAAI CONF ARTIF INTE, P7501
   Zhu YX, 2020, NEUROCOMPUTING, V386, P97, DOI 10.1016/j.neucom.2019.12.100
   Zeng ZL, 2020, IEEE T MULTIMEDIA, V22, P3064, DOI 10.1109/TMM.2020.2969782
   Zhang DM, 2022, IEEE T CIRC SYST VID, V32, P5361, DOI 10.1109/TCSVT.2022.3144775
   Zhang LY, 2021, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2021.3085978
   Zhang P, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104118
   Zhang Q, 2022, PROC CVPR IEEE, P7339, DOI 10.1109/CVPR52688.2022.00720
   Zhang YK, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P788, DOI 10.1145/3474085.3475250
   Zhao Jiaqi, 2022, IEEE Transactions on Multimedia
   Zhao YB, 2019, IET IMAGE PROCESS, V13, P2897, DOI 10.1049/iet-ipr.2019.0699
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong X, 2022, IEEE T CIRC SYST VID, V32, P1418, DOI 10.1109/TCSVT.2021.3072171
   Zhu JQ, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-3004-7
   Zhu JQ, 2020, IEEE T INTELL TRANSP, V21, P410, DOI 10.1109/TITS.2019.2901312
   Zhu JQ, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9639-7
   Zhu JQ, 2018, IEEE T CIRC SYST VID, V28, P3183, DOI 10.1109/TCSVT.2017.2734740
NR 73
TC 1
Z9 1
U1 6
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104797
DI 10.1016/j.imavis.2023.104797
EA AUG 2023
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA S2CY1
UT WOS:001069311900001
DA 2024-07-18
ER

PT J
AU Nemani, P
   Krishna, GS
   Supriya, K
   Kumar, S
AF Nemani, Praneeth
   Krishna, Ghanta Sai
   Supriya, Kundrapu
   Kumar, Santosh
TI Speaker independent VSR: A systematic review and futuristic applications
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE VSR; Speaker-independence; Lip-reading; Feature extraction;
   Spatio-temporal
ID VISUAL SPEECH RECOGNITION; FACE; EXTRACTION; MACHINE; NORMALIZATION;
   SEGMENTATION; CLASSIFIER; PHONEMES; FEATURES; MODELS
AB Speaker-independent visual speech recognition (VSR) is a complex task that involves identifying spoken words or phrases from video recordings of a speaker's facial movements. Decoding the intricate visual dynamics of a speaker's mouth in a high-dimensional space is a significant challenge in this field. To address this challenge, researchers have employed advanced techniques that enable machines to recognize human speech through visual cues automatically. Over the years, there has been a considerable amount of research in the field of VSR involving different algorithms and datasets to evaluate system performance. These efforts have resulted in significant progress in developing effective VSR models, creating new opportunities for further research in this area. This survey provides a detailed examination of the progression of VSR over the past three decades, with a particular emphasis on the transition from speaker-dependent to speaker-independent systems. We also provide a comprehensive overview of the various datasets used in VSR research and the preprocessing techniques employed to achieve speaker independence. The survey covers the works published from 1990 to 2023, thor-oughly analyzing each work and comparing them on various parameters. This survey provides an in-depth analysis of speaker-independent VSR systems evolution from 1990 to 2023. It outlines the development of VSR systems over time and highlights the need to develop end-to-end pipelines for speaker-independent VSR. The pictorial representation offers a clear and concise overview of the techniques used in speaker-independent VSR, thereby aiding in the comprehension and analysis of the various methodologies. The survey also highlights the strengths and limitations of each technique and provides insights into developing novel approaches for analyzing visual speech cues. Overall, This comprehensive review provides insights into the current state-of-the-art speaker-independent VSR and highlights potential areas for future research.
C1 [Nemani, Praneeth; Supriya, Kundrapu; Kumar, Santosh] IIIT Naya Raipur, Dept Comp Sci & Engn, Raipur 493661, Chhattisgarh, India.
   [Krishna, Ghanta Sai] IIIT Naya Raipur, Dept Data Sci & AI, Chattisgarh 493661, India.
RP Kumar, S (corresponding author), IIIT Naya Raipur, Dept Comp Sci & Engn, Raipur 493661, Chhattisgarh, India.
EM praneeth19100@iiitnr.edu.in; ghanta20102@iiitnr.edu.in;
   kundrapu20100@iiitnr.edu.in; santosh@iiitnr.edu.in
OI Nemani, Praneeth/0000-0002-5439-213X
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Abrar MA, 2019, IEEE REG 10 HUMANIT, P40, DOI 10.1109/R10-HTC47129.2019.9042439
   Afouras T, 2018, Arxiv, DOI arXiv:1809.00496
   AHMED N, 1974, IEEE T COMPUT, VC 23, P90, DOI 10.1109/T-C.1974.223784
   Alajlan NN, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13060851
   Alqahtani H, 2021, ARCH COMPUT METHOD E, V28, P525, DOI 10.1007/s11831-019-09388-y
   Altieri NA, 2011, J ACOUST SOC AM, V130, P1, DOI 10.1121/1.3593376
   Amit A., 2016, Lip reading using cnn and lstm
   [Anonymous], 2001, ADAPT LEARN SYST SIG, DOI 10.1002/047084535X
   Anwar M., 2003, Revised Selected and Invited Papers, V1, P164
   Baldwin J.F., 1999, AVSP 99 INT C AUDITO
   Bear HL, 2016, INT CONF ACOUST SPEE, P2009, DOI 10.1109/ICASSP.2016.7472029
   Bear HL, 2014, IEEE IMAGE PROC, P1371, DOI 10.1109/ICIP.2014.7025274
   Bertelson P., 1997, AUDIO VISUAL SPEECH
   Bisong E., 2019, Building Machine Learning and Deep Learning Models on Google Cloud Platform, P401, DOI DOI 10.1007/978-1-4842-4470-8_31
   BREGLER C, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P494, DOI 10.1109/ICCV.1995.466899
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Lipton ZC, 2015, Arxiv, DOI [arXiv:1506.00019, DOI 10.48550/ARXIV.1506.00019]
   Cao KY, 2020, IEEE ACCESS, V8, P85714, DOI 10.1109/ACCESS.2020.2991734
   Cappelletta L, 2011, EUR SIGNAL PR CONF, P2109
   Chalamala SR, 2015, I SYMP CONSUM ELECTR, P459, DOI 10.1109/ICCE.2015.7066486
   Chan T, 1999, LECT NOTES COMPUT SC, V1682, P141
   Chen C., Cn-cvs: A mandarin audio-visual dataset for large vocabulary continuous visual to speech synthesis
   Chin SW, 2012, IEEE T CIRC SYST VID, V22, P869, DOI 10.1109/TCSVT.2011.2180771
   Chiou GI, 1997, IEEE T IMAGE PROCESS, V6, P1192, DOI 10.1109/83.605417
   Chitu AG, 2010, LECT NOTES ARTIF INT, V6231, P259, DOI 10.1007/978-3-642-15760-8_33
   Choras M, 2010, PATTERN ANAL APPL, V13, P105, DOI 10.1007/s10044-008-0144-8
   Chowdhury DP, 2022, MULTIMED TOOLS APPL, V81, P3831, DOI 10.1007/s11042-021-11613-5
   Chung J., 2014, NIPS 2014 WORKSH DEE
   Chung JS, 2017, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2017.367
   Chung JS, 2017, LECT NOTES COMPUT SC, V10112, P87, DOI 10.1007/978-3-319-54184-6_6
   Cootes T.F., 1998, COMPUTER VISION ECCV, V1407, P484, DOI [DOI 10.1007/BFB0054760, DOI 10.1109/34.927467]
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cortés E, 2021, IEEE LAT AM T, V19, P944, DOI 10.1109/TLA.2021.9451239
   Cox S., 2008, INT C AUDITORY VISUA
   Damien P., 2011, 2011 International Symposium on Humanities, Science and Engineering Research (SHUSER 2011), P50, DOI 10.1109/SHUSER.2011.6008499
   Das S.K., 2017, 2017 14 IEEE INDIA C, P1, DOI [10.1109/INDICON.2017.8487538, DOI 10.1109/INDICON.2017.8487538]
   de Gelder B., 1991, European Journal of Cognitive Psychology, V3, P69
   Edwards T., 1991, Discrete wavelet transforms: theory and implementation, P28
   Foo SW, 2004, IEEE T CIRC SYST VID, V14, P693, DOI 10.1109/TCSVT.2004.826773
   Foo SW, 2003, INT CONF ACOUST SPEE, P285
   Fox NA, 2007, IEEE T MULTIMEDIA, V9, P701, DOI 10.1109/TMM.2007.893339
   Gaikwad S., 2010, INT J COMPUT APPL, V10, P16
   Gordan M, 2002, LECT NOTES ARTIF INT, V2308, P355
   Gordan M, 2002, EURASIP J APPL SIG P, V2002, P1248, DOI 10.1155/S1110865702207039
   Gordan M, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1093, DOI 10.1109/ICDSP.2002.1028281
   Graves A, 2013, 2013 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P273, DOI 10.1109/ASRU.2013.6707742
   Guan C, 2020, IEEE T FUZZY SYST, V28, P1242, DOI 10.1109/TFUZZ.2019.2957708
   Hashmi SN, 2018, INT CONF CONTEMP, P252
   He ZX, 2019, IEEE INT CONF MOB DA, P226, DOI 10.1109/MDM.2019.00-53
   Hu D, 2016, PROC CVPR IEEE, P3574, DOI 10.1109/CVPR.2016.389
   Ivanko D, 2022, LREC 2022: THIRTEEN INTERNATIONAL CONFERENCE ON LANGUAGE RESOURCES AND EVALUATION, P1555
   Ivanko D, 2022, EUR SIGNAL PR CONF, P1131
   Jiang JT, 2002, EURASIP J APPL SIG P, V2002, P1174, DOI 10.1155/S1110865702206046
   Jignesh Chowdary G., 2020, Big Data Analytics. 8th International Conference, BDA 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12581), P81, DOI 10.1007/978-3-030-66665-1_6
   Lee JS, 2006, IEEE SYS MAN CYBERN, P198, DOI 10.1109/ICSMC.2006.384382
   Juhui W., 2010, 2010 INT C COMPUTER, V9, DOI 10.1109/ICCASM.2010.5623095
   Kim M, 2023, Arxiv, DOI arXiv:2302.08102
   Kim TK, 2001, ROBOT AND HUMAN COMMUNICATION, PROCEEDINGS, P74, DOI 10.1109/ROMAN.2001.981881
   Kittler J, 1997, PATTERN RECOGN LETT, V18, P845, DOI 10.1016/S0167-8655(97)00062-7
   Koonce B., 2021, Convolutional Neural Networks with Swift for Tensorflow: Image Recognition and Dataset Categorization, P35
   Koumparoulis A, 2022, INT CONF ACOUST SPEE, P8467, DOI 10.1109/ICASSP43922.2022.9747729
   Krishnan M.R., 2012, 2012 INT C COMPUTING, P1, DOI DOI 10.1109/ICCCA.2012.6179154
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar L.A., 2022, International Journal of Cognitive Computing in Engineering, V3, P24, DOI DOI 10.1016/J.IJCCE.2022.01.003
   Kun Lu, 2010, Proceedings 2010 IEEE Youth Conference on Information, Computing and Telecommunications (YC-ICT 2010), P154, DOI 10.1109/YCICT.2010.5713068
   Lambora Annu, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P380, DOI 10.1109/COMITCon.2019.8862255
   Leung SH, 2004, IEEE T IMAGE PROCESS, V13, P51, DOI 10.1109/TIP.2003.818116
   Li CL, 2020, IEEE ACCESS, V8, P95512, DOI 10.1109/ACCESS.2020.2995549
   Li YJ, 2007, IEEE T PATTERN ANAL, V29, P1091, DOI 10.1109/TPAMI.2007.1070
   Liew AWC, 2003, IEEE T FUZZY SYST, V11, P542, DOI 10.1109/TFUZZ.2003.814843
   Liu SY, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P730, DOI 10.1109/ACPR.2015.7486599
   Lu YY, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9081599
   Luettin J, 1996, INT CONF ACOUST SPEE, P817, DOI 10.1109/ICASSP.1996.543246
   Luettin J., 1996, 1996 8 EUROPEAN SIGN, P1
   Luettin J., 1997, P EUROPEAN C SPEECH, P1991
   Assael YM, 2016, Arxiv, DOI arXiv:1611.01599
   Ma PC, 2022, NAT MACH INTELL, V4, P930, DOI 10.1038/s42256-022-00550-z
   Ma PC, 2022, INT CONF ACOUST SPEE, P8472, DOI 10.1109/ICASSP43922.2022.9746706
   Ma XJ, 2016, CHIN CONTR CONF, P6928, DOI 10.1109/ChiCC.2016.7554449
   MARASSA LK, 1995, J SPEECH HEAR RES, V38, P1387, DOI 10.1044/jshr.3806.1387
   Matthews I, 2002, IEEE T PATTERN ANAL, V24, P198, DOI 10.1109/34.982900
   Mavroforakis ME, 2006, IEEE T NEURAL NETWOR, V17, P671, DOI 10.1109/TNN.2006.873281
   McShane P, 2017, INT CONF INTERNET, P405, DOI 10.23919/ICITST.2017.8356433
   Mehnert A, 1997, PATTERN RECOGN LETT, V18, P1065, DOI 10.1016/S0167-8655(97)00131-1
   MINES MA, 1978, LANG SPEECH, V21, P221, DOI 10.1177/002383097802100302
   Mirjalili S, 2019, STUD COMPUT INTELL, V780, P1, DOI 10.1007/978-3-319-93025-1
   Miyamoto S, 2008, Algorithms for Fuzzy Clustering: Methods in c-Means Clustering with Applications, V10
   Movellan J. R., 1995, Advances in Neural Information Processing Systems 7, P851
   Movellan J.R, 1999, AVSP 99 INT C AUDITO
   Movellan J.R., 1996, Speechreading by humans and machines: Models, systems, and applications, P473
   Mudaliar N.K., 2020, 2020 5 INT C COMMUNI, P1218, DOI 10.1109/ICCES48766.2020.9137926
   Nankaku Y, 2000, 2000 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL III, PROCEEDINGS, P234, DOI 10.1109/ICIP.2000.899338
   Nankaku Y, 1999, 6 EUROPEAN C SPEECH
   Nemani P., 2022, IEEE Transactions on, Artif. Intell.
   Pan ZQ, 2019, IEEE ACCESS, V7, P36322, DOI 10.1109/ACCESS.2019.2905015
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Parekh D, 2019, 2019 IEEE 5TH INTERNATIONAL CONFERENCE FOR CONVERGENCE IN TECHNOLOGY (I2CT)
   Park J., 2023, OLKAVS: an open largescale Korean audiovisual speech dataset
   Pass A, 2010, IEEE IMAGE PROC, P93, DOI 10.1109/ICIP.2010.5652630
   Petridis S, 2016, INT CONF ACOUST SPEE, P2304, DOI 10.1109/ICASSP.2016.7472088
   Rabi G, 1997, 1997 CANADIAN CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING, CONFERENCE PROCEEDINGS, VOLS I AND II, P55, DOI 10.1109/CCECE.1997.614788
   Rajavel R., 2009, P 1 INT C INT HUM CO, P184
   REDDY DR, 1976, P IEEE, V64, P501, DOI 10.1109/PROC.1976.10158
   Rekik A, 2014, LECT NOTES COMPUT SC, V8815, P21, DOI 10.1007/978-3-319-11755-3-3
   Ryumin D, 2023, SENSORS-BASEL, V23, DOI 10.3390/s23042284
   Saenko K, 2005, IEEE I CONF COMP VIS, P1424, DOI 10.1109/ICCV.2005.251
   Sagheer A, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY (ISSPIT), VOLS 1 AND 2, P761
   Saha P, 2015, PROCEDIA COMPUT SCI, V46, P1739, DOI 10.1016/j.procs.2015.02.123
   Sainath TN, 2012, INT CONF ACOUST SPEE, P4153, DOI 10.1109/ICASSP.2012.6288833
   Santos TI, 2021, IEEE W SP LANG TECH, P613, DOI 10.1109/SLT48900.2021.9383540
   Saxena D, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3446374
   Schadt EE, 2001, J CELL BIOCHEM, V84, P120, DOI 10.1002/jcb.10073
   Schapire Robert E, 2013, EMPIRICAL INFERENCE, P37, DOI [DOI 10.1007/978-3-642-41136-65, DOI 10.1007/978-3-642-41136-6_5]
   Schwiebert G, 2022, Arxiv, DOI arXiv:2202.13403
   Sengupta A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00095
   Shaikh AA, 2011, INT J COMPUT INTELL, V10, P167, DOI 10.1142/S1469026811003045
   Shemshaki M., 2011, 2011 7 IR C MACH VIS, P1, DOI [10.1109/IranianMVIP.2011.6121606, DOI 10.1109/IRANIANMVIP.2011.6121606]
   Shenggui Ling, 2020, 2020 IEEE 6th International Conference on Computer and Communications (ICCC), P1433, DOI 10.1109/ICCC51575.2020.9344868
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   SILSBEE PL, 1993, P SOC PHOTO-OPT INS, V2094, P84, DOI 10.1117/12.157855
   Sindhura PV, 2018, 2018 3RD INTERNATIONAL CONFERENCE ON ELECTRICAL, ELECTRONICS, COMMUNICATION, COMPUTER, AND OPTIMIZATION TECHNIQUES (ICEECCOT - 2018), P929, DOI 10.1109/ICEECCOT43722.2018.9001505
   Chung JS, 2017, Arxiv, DOI arXiv:1611.05358
   Soundarya B., 2021, IOP Conference Series: Materials Science and Engineering, V1084, DOI 10.1088/1757-899X/1084/1/012020
   Steinwart Ingo, 2008, SUPPORT VECTOR MACHI
   Sun XH, 2009, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2009.5204255
   Tammina S, 2019, Int. J. Sci. Res. Publ, V9, P143, DOI DOI 10.29322/IJSRP.9.10.2019.P9420
   Tanaka J.W., 2003, PERCEPTION FACES OBJ, P53, DOI 10.1093/acprof:oso/9780195313659.003.0003
   Tatulli E, 2017, INT CONF ACOUST SPEE, P2971, DOI 10.1109/ICASSP.2017.7952701
   Taud H., 2018, Geomatic approaches for modeling land change scenarios, DOI [DOI 10.1007/978-3-319-60801-3_27, DOI 10.1007/978-3-319-60801-327]
   Trager GL, 1941, LANGUAGE, V17, P223, DOI 10.2307/409203
   Vanegas O, 2000, IEICE T INF SYST, VE83D, P1969
   Varcheie PDZ, 2010, INT CONF ACOUST SPEE, P1162, DOI 10.1109/ICASSP.2010.5495373
   Varghese B, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P20, DOI 10.1109/SmartCloud.2016.18
   WALDEN BE, 1993, J SPEECH HEAR RES, V36, P431, DOI 10.1044/jshr.3602.431
   Wang C, 2019, IEEE ACCESS, V7, P146533, DOI 10.1109/ACCESS.2019.2946000
   Wang KF, 2017, IEEE-CAA J AUTOMATIC, V4, P588, DOI 10.1109/JAS.2017.7510583
   Wang SL, 2006, INT C PATT RECOG, P881
   Wang X, 2008, ICNC 2008: FOURTH INTERNATIONAL CONFERENCE ON NATURAL COMPUTATION, VOL 2, PROCEEDINGS, P543, DOI 10.1109/ICNC.2008.550
   Wang Y, 2000, IEEE SIGNAL PROC MAG, V17, P12, DOI 10.1109/79.888862
   Wang Y, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030319
   WenJuan Y., 2010, 2010 3 INT C ADV COM, V6, pV6, DOI 10.1109/ICACTE.2010.5579830
   Werda S, 2013, Arxiv, DOI arXiv:1301.4558
   Whitehill J, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P97
   Wibowo ME, 2021, IEEE IND ELEC, DOI 10.1109/IECON48115.2021.9589577
   WILSON P.I., 2006, J COMPUT SMALL COLL, V21, P127
   Wu GY, 2008, IEEE IMAGE PROC, P1328, DOI 10.1109/ICIP.2008.4712008
   Wu Z., 2008, 2008 6 INT S CHINESE, P1, DOI [10.1109/CHINSL.2008.ECP.104, DOI 10.1109/CHINSL.2008.ECP.104]
   Xia XL, 2017, 2017 2ND INTERNATIONAL CONFERENCE ON IMAGE, VISION AND COMPUTING (ICIVC 2017), P783, DOI 10.1109/ICIVC.2017.7984661
   Xiaoping Wang, 2008, 2008 International Conference on Neural Networks and Signal Processing, P178, DOI 10.1109/ICNNSP.2008.4590335
   XIE XLL, 1991, IEEE T PATTERN ANAL, V13, P841, DOI 10.1109/34.85677
   Xin Liu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4332, DOI 10.1109/ICPR.2010.1053
   Xu HZY, 2021, INT J REMOTE SENS, V42, P6155, DOI 10.1080/01431161.2021.1934912
   Xu K, 2019, PROC CVPR IEEE, P1379, DOI 10.1109/CVPR.2019.00147
   Xue F., 2023, arXiv
   Yang CJ, 2014, 2014 5TH IEEE INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING AND SERVICE SCIENCE (ICSESS), P597, DOI 10.1109/ICSESS.2014.6933639
   Yang CZ, 2020, IEEE IMAGE PROC, P2181, DOI [10.1109/ICIP40778.2020.9190780, 10.1109/icip40778.2020.9190780]
   YANG MS, 1993, MATH COMPUT MODEL, V18, P1, DOI 10.1016/0895-7177(93)90202-A
   Yao HX, 2003, LECT NOTES COMPUT SC, V2688, P251
   Yau W., 2006, P INT C COMP GRAPH I, P194
   Yingdi Guo, 2015, WSEAS Transactions on Computers, V14, P369
   Yu D, 2007, LECT NOTES COMPUT SC, V4673, P374
   Yu D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P244
   Yu K., 1997, Computer Analysis of Images and Patterns. 7th International Conference, CAIP '97. Proceedings, P472, DOI 10.1007/3-540-63460-6_152
   Zali-Vargahan B., 2013, 2013 21 IRANIAN C EL, P1, DOI [10.1109/IranianCEE.2013.6599705, DOI 10.1109/IRANIANCEE.2013.6599705]
   Zhang JX, 2022, PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, ICMI 2022, P368, DOI 10.1145/3536221.3556571
   Zhang Q, 2021, IEEE IMAGE PROC, P2493, DOI 10.1109/ICIP42928.2021.9506396
   Zhang ZF, 2015, EURASIP J AUDIO SPEE, DOI 10.1186/s13636-015-0056-7
   Zhao GY, 2009, IEEE T MULTIMEDIA, V11, P1254, DOI 10.1109/TMM.2009.2030637
   Zhao Y, 2020, IEEE T COGN DEV SYST, V12, P451, DOI 10.1109/TCDS.2019.2916916
   Zhou JiangJu Zhou JiangJu, 2011, China Condiment, P98
   Zhu J, 2009, STAT INTERFACE, V2, P349
NR 172
TC 0
Z9 0
U1 5
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104787
DI 10.1016/j.imavis.2023.104787
EA AUG 2023
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA R5SR2
UT WOS:001064954400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Tong, K
   Wu, YQ
AF Tong, Kang
   Wu, Yiquan
TI Deep learning-based detection from the perspective of small or tiny
   objects: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Object detection; Small or tiny objects; Deep learning; Datasets;
   Convolutional neural networks
ID CONTEXT; NETWORKS; IMAGES
AB Detecting small or tiny objects is always a difficult and challenging issue in computer vision. In this paper, we provide a latest and comprehensive survey of deep learning-based detection approaches from the perspective of small or tiny objects. Our survey is featured by thorough and exhaustive analysis of small or tiny object detection. We comprehensively introduce 30 existing datasets about small or tiny objects, and summarize different defini-tions of small or tiny objects based on different application scenarios, such as pedestrian detection, traffic signs detection, face detection, remote sensing target detection and object detection in common life. Then small or tiny object detection techniques are overviewed systematically from seven aspects, including super-resolution techniques, context-based information, multi-scale representation learning, anchor mechanism, training strategy, data augmentation, and schemes based on loss function. Finally, the detection performance of small or tiny objects on 12 popular datasets is analyzed in depth. Based on performance analysis, we also discuss the promising research directions in the future. We hope this survey could provide researchers guidance to catalyze understanding of small or tiny object detection and further facilitate research on small or tiny object detection systems.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Tong, Kang; Wu, Yiquan] Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Wu, YQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing, Peoples R China.
EM tkangcv@nuaa.edu.cn; nuaavision@163.com
FU National Natural Science Foundation of China [61573183]; Open Project
   Pro-gram of the National Laboratory of Pattern Recognition (NLPR)
   [201900029]
FX Acknowledgments This work was supported in part by the National Natural
   Science Foundation of China under Grant 61573183 and the Open Project
   Pro-gram of the National Laboratory of Pattern Recognition (NLPR) under
   Grant 201900029.
CR [Anonymous], 2009, P BRIT MACH VIS C
   Bai YL, 2018, LECT NOTES COMPUT SC, V11216, P21, DOI 10.1007/978-3-030-01258-8_2
   Behrendt Karsten, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1370, DOI 10.1109/ICRA.2017.7989163
   Bochkovskiy A., 2020, ARXIV E PRINTS
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Bosquet B., 2018, P 29 BRIT MACH VIS C
   Bosquet B., 2020, DROPPED REF
   Bosquet B, 2021, PATTERN RECOGN, V116, DOI 10.1016/j.patcog.2021.107929
   Bosquet B, 2020, ENG APPL ARTIF INTEL, V91, DOI 10.1016/j.engappai.2020.103615
   Braun M, 2018, ARXIV180507193V2
   Cao CQ, 2019, IEEE ACCESS, V7, P106838, DOI 10.1109/ACCESS.2019.2932731
   Cao GM, 2018, PROC SPIE, V10615, DOI 10.1117/12.2304811
   Cao JL, 2017, IEEE T IMAGE PROCESS, V26, P3210, DOI 10.1109/TIP.2017.2694224
   Chen CR, 2019, IEEE INT CONF COMP V, P100, DOI 10.1109/ICCVW.2019.00018
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Chen G, 2022, IEEE T SYST MAN CY-S, V52, P936, DOI 10.1109/TSMC.2020.3005231
   Chen K, 2019, ARXIV190607155, DOI [DOI 10.48550/ARXIV.1906.07155, 10.48550/arXiv.1906.07155]
   Chen KA, 2019, PROC CVPR IEEE, P5114, DOI 10.1109/CVPR.2019.00526
   Chen P.-Y., 2020, PRESENTED IEEE C COM
   Chen WH, 2017, PROC CVPR IEEE, P1320, DOI 10.1109/CVPR.2017.145
   Chen Y., 2020, COMPUT RES REPOSIT
   Chen Y., 2021, ARXIV200412432V2
   Chen YP, 2017, ADV NEUR IN, V30
   Cheng Gao, 2020, Proceedings of the 16th European Conference on Computer Vision (ECCV 2020) Workshops. Lecture Notes in Computer Science (LNCS 12539), P331, DOI 10.1007/978-3-030-68238-5_25
   Cheng G, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2022.3149780
   Cheng G, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3104112
   Cheng G, 2021, J REMOTE SENS-PRC, V2021, DOI 10.34133/2021/9805389
   Cheng G, 2021, IEEE GEOSCI REMOTE S, V18, P431, DOI 10.1109/LGRS.2020.2975541
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Cui LS, 2020, SCI CHINA INFORM SCI, V63, DOI 10.1007/s11432-019-2723-1
   Cui LS, 2022, IEEE T CYBERNETICS, V52, P2300, DOI 10.1109/TCYB.2020.3004636
   Dai J, 2016, PROCEEDINGS 2016 IEEE INTERNATIONAL CONFERENCE ON INDUSTRIAL TECHNOLOGY (ICIT), P1796, DOI 10.1109/ICIT.2016.7475036
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Du DW, 2019, IEEE INT CONF COMP V, P213, DOI 10.1109/ICCVW.2019.00030
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Duan KW, 2020, IEEE T CIRC SYST VID, V30, P1639, DOI 10.1109/TCSVT.2019.2906246
   Eggert C, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P172, DOI 10.1145/3078971.3078990
   Eggert C, 2017, IEEE INT CON MULTI, P421, DOI 10.1109/ICME.2017.8019550
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fang LJ, 2019, MULTIMED TOOLS APPL, V78, P13227, DOI 10.1007/s11042-018-6227-7
   Fu K., 2020, ARXIV200900833V1
   Geiger A, 2012, PROC CVPR IEEE, P3354, DOI 10.1109/CVPR.2012.6248074
   Gong YQ, 2021, IEEE WINT CONF APPL, P1159, DOI 10.1109/WACV48630.2021.00120
   Goodfellow I.J., 2014, NEUR INF PROC SYST M
   Gu Y., 2020, INT C PATTERN RECOG
   Guan LT, 2018, INT J COMPUT INT SYS, V11, P951
   Han B, 2020, IEEE T INTELL TRANSP, V21, P3046, DOI 10.1109/TITS.2019.2923752
   Han S., 2019, INT C VIS IM SIGN PR
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He YH, 2019, PROC CVPR IEEE, P2883, DOI 10.1109/CVPR.2019.00300
   Hong MB, 2022, IEEE GEOSCI REMOTE S, V19, DOI 10.1109/LGRS.2021.3103069
   Houben S, 2013, IEEE IJCNN
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Ji H., 2020, INT C PATTERN RECOGN
   Ji Z, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1349, DOI 10.1145/3343031.3351064
   Jiang N., 2021, IEEE INT C ACOUSTICS
   Kaur P., 2021, PRESENTED IEEE INT M
   Kim YY, 2018, LECT NOTES COMPUT SC, V11209, P328, DOI 10.1007/978-3-030-01228-1_20
   Kisantal M., 2019, P 9 INT C ADV COMP I, DOI 10.5121/csit.2019.91713
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Krishna H, 2017, PROCEEDINGS 2017 4TH IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR), P340, DOI 10.1109/ACPR.2017.149
   Law H., 2020, ARXIV190408900
   Law H, 2018, LECT NOTES COMPUT SC, V11218, P765, DOI 10.1007/978-3-030-01264-9_45
   Ledig C, 2017, PROC CVPR IEEE, P105, DOI 10.1109/CVPR.2017.19
   Lee G, 2021, IEEE SIGNAL PROC LET, V28, P1026, DOI 10.1109/LSP.2021.3081041
   Leng JX, 2021, NEUROCOMPUTING, V433, P287, DOI 10.1016/j.neucom.2020.12.093
   Levi H., 2019, ARXIV PREPRINT ARXIV
   Li JA, 2017, PROC CVPR IEEE, P1951, DOI 10.1109/CVPR.2017.211
   Li K, 2020, ISPRS J PHOTOGRAMM, V159, P296, DOI 10.1016/j.isprsjprs.2019.11.023
   Li X, 2020, ADV NEURAL INFORMA T
   Li X, 2021, PROC CVPR IEEE, P11627, DOI 10.1109/CVPR46437.2021.01146
   Li YH, 2019, IEEE I CONF COMP VIS, P6053, DOI 10.1109/ICCV.2019.00615
   Li YY, 2021, IEEE J-STARS, V14, P2148, DOI 10.1109/JSTARS.2020.3046482
   Li YJ, 2020, IEEE ACCESS, V8, P227288, DOI 10.1109/ACCESS.2020.3046515
   Li Z., 2019, ARXIV190400386V1
   Liang X, 2020, IEEE T CIRC SYST VID, V30, P1758, DOI 10.1109/TCSVT.2019.2905881
   Liang Z., 2018, PRESENTED PACIFIC RI
   Lim JS, 2021, 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE IN INFORMATION AND COMMUNICATION (IEEE ICAIIC 2021), P181, DOI 10.1109/ICAIIC51459.2021.9415217
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu D., 2020, INT C INTELLIGENT CO
   Liu G, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104197
   Liu J, 2019, IEEE ACCESS, V7, P128339, DOI 10.1109/ACCESS.2019.2939488
   Liu JW, 2021, IEEE ACCESS, V9, P62946, DOI 10.1109/ACCESS.2021.3074790
   Liu K, 2015, IEEE GEOSCI REMOTE S, V12, P1938, DOI 10.1109/LGRS.2015.2439517
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu LR, 2020, IEEE J-STARS, V13, P2096, DOI 10.1109/JSTARS.2020.2966543
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu ST, 2018, LECT NOTES COMPUT SC, V11215, P404, DOI 10.1007/978-3-030-01252-6_24
   Liu Y, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114602
   Liu YJ, 2020, IEEE ACCESS, V8, P145740, DOI 10.1109/ACCESS.2020.3014910
   Liu Z., 2021, 2021 IEEE INT C MULT, P1
   Liu ZG, 2020, APPL INTELL, V50, P1, DOI 10.1007/s10489-019-01511-7
   Liu ZM, 2020, IEEE COMPUT SOC CONF, P4422, DOI 10.1109/CVPRW50498.2020.00521
   Lu X, 2019, PROC CVPR IEEE, P7355, DOI 10.1109/CVPR.2019.00754
   Luo S, 2019, IEEE ACCESS, V7, P171609, DOI 10.1109/ACCESS.2019.2955757
   Menikdiwela M, 2017, INT CONF IMAG VIS
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Mudassar B.A., 2019, P BRIT MACH VIS C BM
   Najibi M, 2017, IEEE I CONF COMP VIS, P4885, DOI 10.1109/ICCV.2017.522
   Nguyen ND, 2020, J ELECTR COMPUT ENG, V2020, DOI 10.1155/2020/3189691
   Noh J, 2019, IEEE I CONF COMP VIS, P9724, DOI 10.1109/ICCV.2019.00982
   Oksuz K, 2021, IEEE T PATTERN ANAL, V43, P3388, DOI 10.1109/TPAMI.2020.2981890
   Oliva A, 2007, TRENDS COGN SCI, V11, P520, DOI 10.1016/j.tics.2007.09.009
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Pang JM, 2019, IEEE T GEOSCI REMOTE, V57, P5512, DOI 10.1109/TGRS.2019.2899955
   Pang YW, 2019, IEEE T INF FOREN SEC, V14, P3322, DOI 10.1109/TIFS.2019.2916592
   Pengcheng Fang, 2018, 2018 IEEE 4th International Conference on Computer and Communications (ICCC). Proceedings, P1537, DOI 10.1109/CompComm.2018.8780579
   Pham P, 2017, LECT NOTES COMPUT SC, V10636, P516, DOI 10.1007/978-3-319-70090-8_53
   Pinggera P, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P1099, DOI 10.1109/IROS.2016.7759186
   Qi Qian, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12161, DOI 10.1109/CVPR42600.2020.01218
   Qu JS, 2020, IEEE ACCESS, V8, P82832, DOI 10.1109/ACCESS.2020.2991439
   Razaak M., 2019, PRESENTED IN TERNATI
   Redmon J., 2018, ARXIV 180402767V1
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Robicquet A, 2016, LECT NOTES COMPUT SC, V9912, P549, DOI 10.1007/978-3-319-46484-8_33
   Samangouei P, 2018, IEEE WINT CONF APPL, P122, DOI 10.1109/WACV.2018.00020
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Song T, 2018, LECT NOTES COMPUT SC, V11211, P554, DOI 10.1007/978-3-030-01234-2_33
   Sun C, 2021, APPL INTELL, V51, P3311, DOI 10.1007/s10489-020-01949-0
   Sun W, 2020, SOFT COMPUT, V24, P5897, DOI 10.1007/s00500-019-04404-6
   Tang X., 2018, PRESENTED EUROPEAN C
   Tian Z., 2019, PRESENTED IEEE INT C
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Tuggener L, 2018, INT C PATT RECOG, P3704, DOI 10.1109/ICPR.2018.8545307
   Tychsen-Smith L, 2018, PROC CVPR IEEE, P6877, DOI 10.1109/CVPR.2018.00719
   Ünel FÖ, 2019, IEEE COMPUT SOC CONF, P582, DOI 10.1109/CVPRW.2019.00084
   Wang GT, 2018, IEEE INT CON MULTI
   Wang J., ARXIV211013389V1, P2021
   Wang J., 2020, INT C PATTERN RECOGN
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang Z., 2019, 10 INT C IMAGE GRAPH
   Wang ZZ, 2021, IEEE ACCESS, V9, P56416, DOI 10.1109/ACCESS.2021.3072211
   Wolpert A, 2020, 31 BRIT MACH VIS C B
   Wu BC, 2017, IEEE COMPUT SOC CONF, P446, DOI 10.1109/CVPRW.2017.60
   Wu J., 2020, ACM INT C MULT SEATT
   Wu XW, 2020, NEUROCOMPUTING, V396, P39, DOI 10.1016/j.neucom.2020.01.085
   Xi Y, 2020, PATTERN RECOGN LETT, V137, P53, DOI 10.1016/j.patrec.2019.03.009
   Xi Y, 2018, IEEE IMAGE PROC, P1907, DOI 10.1109/ICIP.2018.8451426
   Xia GS, 2018, PROC CVPR IEEE, P3974, DOI 10.1109/CVPR.2018.00418
   Xiao JX, 2016, INT J COMPUT VISION, V119, P3, DOI 10.1007/s11263-014-0748-y
   Xu DL, 2020, IEEE SIGNAL PROC LET, V27, P1435, DOI 10.1109/LSP.2020.3013160
   Yan JJ, 2014, IMAGE VISION COMPUT, V32, P790, DOI 10.1016/j.imavis.2013.12.004
   Yan ZW, 2021, NEURAL PROCESS LETT, V53, P1921, DOI 10.1007/s11063-021-10493-y
   Yang C., 2021, ARXIV210309136V1
   Yang S., 2020, CHIN C PATT REC COMP
   YANG S, 2016, PROC CVPR IEEE, P5525, DOI DOI 10.1109/CVPR.2016.596
   Yang T., 2018, PRESENTED ADV NEURAL
   Yang X, 2019, IEEE I CONF COMP VIS, P8231, DOI 10.1109/ICCV.2019.00832
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yang ZX, 2019, IEEE IMAGE PROC, P86, DOI [10.1109/ICIP.2019.8802612, 10.1109/icip.2019.8802612]
   Yao XW, 2021, IEEE T GEOSCI REMOTE, V59, P675, DOI 10.1109/TGRS.2020.2991407
   Yu J., 2016, ACM C MULT C AMST NE
   Yu X., 2020, 1 TINY OBJECT UNPUB
   Yu XH, 2020, IEEE WINT CONF APPL, P1246, DOI 10.1109/WACV45572.2020.9093394
   Yuan Feng, 2020, Proceedings of the 16th European Conference on Computer Vision (ECCV 2020) Workshops. Lecture Notes in Computer Science (LNCS 12539), P324, DOI 10.1007/978-3-030-68238-5_24
   Yun S, 2019, IEEE I CONF COMP VIS, P6022, DOI 10.1109/ICCV.2019.00612
   Zhang C., 2018, PATTERN RECOGN
   Zhang Canlin, 2019, IEEE INT JOINT C NEU
   Zhang H., 2019, BRIT MACHINE VISION
   Zhang S, 2020, NEUROCOMPUTING, V409, P12, DOI 10.1016/j.neucom.2020.05.019
   Zhang SF, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P1, DOI 10.1109/BTAS.2017.8272675
   Zhang SF, 2017, IEEE I CONF COMP VIS, P192, DOI 10.1109/ICCV.2017.30
   Zhang W, 2018, INT GEOSCI REMOTE SE, P2483, DOI 10.1109/IGARSS.2018.8517436
   Zhang XD, 2019, IEEE INT CONF COMP V, P118, DOI 10.1109/ICCVW.2019.00020
   Zhang Y., 2020, ACM INT C COMPUTING
   Zhang YQ, 2020, INT J COMPUT VISION, V128, P1810, DOI 10.1007/s11263-020-01301-6
   Zhang ZS, 2020, IEEE WINT CONF APPL, P1350, DOI [10.1109/wacv45572.2020.9093445, 10.1109/WACV45572.2020.9093445]
   Zhao Zhong-Qiu, 2019, IEEE Trans Neural Netw Learn Syst, V30, P3212, DOI 10.1109/TNNLS.2018.2876865
   Zhaowei Cai, 2018, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Proceedings, P6154, DOI 10.1109/CVPR.2018.00644
   Zhen Yang, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1673, DOI 10.1109/ICCT46805.2019.8947158
   Zheng QY, 2021, IMAGE VISION COMPUT, V108, DOI 10.1016/j.imavis.2021.104128
   Zheng QY, 2021, MULTIMED TOOLS APPL, V80, P20283, DOI 10.1007/s11042-021-10718-1
   Zheng ZH, 2020, AAAI CONF ARTIF INTE, V34, P12993
   Zhou D., 2020, EUR CCOMP VIS GLASG
   Zhou K, 2016, DESTECH TRANS COMP
   Zhou X., 2019, ABS190407850 ARXIV
   Zhou XQ, 2017, IEEE IMAGE PROC, P425, DOI 10.1109/ICIP.2017.8296316
   Zhou XY, 2019, PROC CVPR IEEE, P850, DOI 10.1109/CVPR.2019.00094
   Zhu CC, 2018, PROC CVPR IEEE, P5127, DOI 10.1109/CVPR.2018.00538
   Zhu P., 2020, ARXIV 200106303V2
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
   Zoph B, 2020, EUROPEAN C COMPUTER
   Zou Z., 2019, ARXIV PREPRINT ARXIV
NR 188
TC 52
Z9 56
U1 138
U2 663
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104471
DI 10.1016/j.imavis.2022.104471
EA MAY 2022
PG 26
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1W0YE
UT WOS:000806506500004
DA 2024-07-18
ER

PT J
AU Xi, X
   Wu, YQ
   Xia, CM
   He, SH
AF Xi, Xing
   Wu, Yuanqing
   Xia, Canming
   He, Shenghuang
TI Feature fusion for object detection at one map
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Object detection; Multi-scale fusion; COCO
AB The scale feature plays a crucial role in the detector, and existing methods adopt the feature pyramid based on multiple maps. This paper focuses on a single map and proposes an encoder called SFMF which can employ multi-scale feature fusion on a map. One of the crucial techniques underlying SFMF is a fine-grained weighting method that is used to fast discard unneeded pixel channels during the fusion process. YOLOF (you only look one-level feature) with SFMF (single feature map fusion) achieve 38.5 mAP in the ResNet50 and 40.3 mAP in the ResNet101, which improves 0.8 and 0.5 mAP than the baseline, respectively. Meta-ACON is used to auto learn activate the neurons or not in the backbone. With the Meta-ACON and SFMF, YOLOF can achieve 39.1 and 40.4 mAP, surpassing the baseline by 1.4 and 0.6 mAP on COCO val-dev. In addition, YOLOF with SFMF achieves 54.8 mAP, improving the performance by an absolute 4.9 mAP on the aircraft detection dataset, with a slight sacrificing efficiency (1 FPS) in inference. (c) 2022 Published by Elsevier B.V.
C1 [Xi, Xing; Wu, Yuanqing; Xia, Canming] Guangdong Univ Technol, Guangzhou 510006, Peoples R China.
   [He, Shenghuang] Shanghai Jiao Tong Univ, Shanghai, Peoples R China.
   [He, Shenghuang] Shanghai Jiao Tong Univ, NingBo Artificial Intelligent Inst, Shanghai, Peoples R China.
C3 Guangdong University of Technology; Shanghai Jiao Tong University;
   Shanghai Jiao Tong University
RP Wu, YQ (corresponding author), Guangdong Univ Technol, Guangzhou 510006, Peoples R China.
EM yqwuzju@163.com; shhesjtu@sjtu.edu.cn
RI xi, xing/GZN-1321-2022
CR Aksoy T., ARXIV220213115
   Baker B., ARXIV161102167
   Bodla N, 2017, IEEE I CONF COMP VIS, P5562, DOI 10.1109/ICCV.2017.593
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Chiasi G., P IEEE COMPUTER VISI, P7029
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Fu C.-Y., ARXIV PREPRINT ARXIV
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang ZJ, 2019, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2019.00657
   Kong T, 2020, IEEE T IMAGE PROCESS, V29, P7389, DOI 10.1109/TIP.2020.3002345
   Li BY, 2019, AAAI CONF ARTIF INTE, P8577
   Li W., ARXIV1901 00148
   Liang T., ARXIV PREPRINT ARXIV
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu Sheng, ARXIV PREPRINT ARXIV
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Ma N., 2021, P IEEE CVF C COMP VI
   Pang JM, 2019, PROC CVPR IEEE, P821, DOI 10.1109/CVPR.2019.00091
   Qiao SY, 2021, PROC CVPR IEEE, P10208, DOI 10.1109/CVPR46437.2021.01008
   Qin Z, 2019, IEEE I CONF COMP VIS, P6717, DOI 10.1109/ICCV.2019.00682
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren S., ARXIV PREPRINT ARXIV
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Singh B, 2018, PROC CVPR IEEE, P3578, DOI 10.1109/CVPR.2018.00377
   Sukthankar R., ARXIV PREPRINT ARXIV
   Sun PZ, 2021, PROC CVPR IEEE, P14449, DOI 10.1109/CVPR46437.2021.01422
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang JQ, 2019, PROC CVPR IEEE, P2960, DOI 10.1109/CVPR.2019.00308
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang XY, 2013, IEEE I CONF COMP VIS, P17, DOI 10.1109/ICCV.2013.10
   Wu Y., 2019, DETECTRON2
   Yang Z, 2019, IEEE I CONF COMP VIS, P9656, DOI 10.1109/ICCV.2019.00975
   Yu F., ARXIV PREPRINT ARXIV
   Yue Wu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10183, DOI 10.1109/CVPR42600.2020.01020
   Zhang XS, 2019, ADV NEUR IN, V32
   Zhao QJ, 2019, AAAI CONF ARTIF INTE, P9259
   Zhu YS, 2017, IEEE I CONF COMP VIS, P4146, DOI 10.1109/ICCV.2017.444
   Zoph B, ARXIV PREPRINT ARXIV
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 49
TC 5
Z9 5
U1 2
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104466
DI 10.1016/j.imavis.2022.104466
EA MAY 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L9ND
UT WOS:000799606300002
DA 2024-07-18
ER

PT J
AU Chen, YY
   Fan, ZY
   Chen, SN
AF Chen, Yiyu
   Fan, Zheyi
   Chen, Shuni
TI Consistent camera-invariant and noise-tolerant learning for unsupervised
   person re-identification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Person re-identification; Meta learning; Noise pseudo label; Camera
   variations
AB Unsupervised person re-identification (re-ID) is still a challenging task. Existing methods usually utilize an alternative manner of generating pseudo labels by clustering and optimizing the model based on pseudo labels. Although these methods achieve great accuracy, there remain two problems unsolved: (1) Noise labels caused by camera variations and other factors. (2) The training of the model is inconsistent or unstable. In this paper, we propose a cluster memory-based meta learning (CMML) strategy with a cluster memory-based additive margin (CMAM) loss to deal with noise labels caused by camera variations and the model training problem, and a cluster memory-based noise-tolerant (CMNT) loss to tackle the rest noise labels. Extensive experimental results on three re-ID datasets (i.e., DukeMTMC-reID, Market1501 and MSMT17) validate the effectiveness of our proposed method. Our method achieves 70.3%, 81.8%, and 39.2% mAP on these three datasets, yielding comparable performance against the state-of-the-art purely unsupervised re-ID methods.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Chen, Yiyu; Fan, Zheyi; Chen, Shuni] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Fan, ZY (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
EM funye@bit.edu.cn
FU Natural Science Foundation of Beijing Municipality [L192036]
FX Acknowledgments This work was supported by the Natural Science
   Foundation of Beijing Municipality under Grant L192036.
CR Biggio Battista, AS C MACH LEARN PMLR, P97
   Chen H, 2021, PROC CVPR IEEE, P2004, DOI 10.1109/CVPR46437.2021.00204
   Chen Hao, P IEEECVF INT C COMP, P14960
   Chen YB, 2019, IEEE I CONF COMP VIS, P232, DOI 10.1109/ICCV.2019.00032
   Chen YF, 2022, PATTERN RECOGN, V126, DOI 10.1016/j.patcog.2022.108567
   Chen Y, 2022, PATTERN RECOGN LETT, V157, P90, DOI 10.1016/j.patrec.2022.03.020
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng WJ, 2018, PROC CVPR IEEE, P994, DOI 10.1109/CVPR.2018.00110
   Ding YH, 2020, ACM T MULTIM COMPUT, V16, DOI 10.1145/3369393
   Dongkai Wang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P10978, DOI 10.1109/CVPR42600.2020.01099
   Ester M., 1996, KDD 96, P226, DOI DOI 10.5555/3001460.3001507
   Fan HH, 2018, ACM T MULTIM COMPUT, V14, DOI 10.1145/3243316
   Fang Zhao, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12356), P526, DOI 10.1007/978-3-030-58621-8_31
   Finn C, 2017, PR MACH LEARN RES, V70
   Fu Y, 2019, IEEE I CONF COMP VIS, P6111, DOI 10.1109/ICCV.2019.00621
   Ge Y., 2020, P NIPS, V33, P11309
   Ghosh A, 2017, AAAI CONF ARTIF INTE, P1919
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hermans Alexander, 2017, ARXIV170307737
   Hou HP, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104191
   Hsu K., 2018, ABS181002334 CORR
   Jianing Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12369), P483, DOI 10.1007/978-3-030-58586-0_29
   Kaiwei Zeng, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13654, DOI 10.1109/CVPR42600.2020.01367
   Khardon Roni, 2007, J. Mach. Learn. Res, V8
   Li D, 2018, AAAI CONF ARTIF INTE, P3490
   Lin YT, 2019, AAAI CONF ARTIF INTE, P8738
   Luo H, 2020, IEEE T MULTIMEDIA, V22, P2597, DOI 10.1109/TMM.2019.2958756
   Munkhdalai T, 2017, PR MACH LEARN RES, V70
   Ning MN, 2020, PATTERN RECOGN LETT, V135, P237, DOI 10.1016/j.patrec.2020.04.039
   Rajeswaran A, 2019, ADV NEUR IN, V32
   Reed S.E., 2015, INT C LEARNING REPRE
   Santoro A, 2016, PR MACH LEARN RES, V48
   Snell J, 2017, ADV NEUR IN, V30
   Sun YF, 2018, LECT NOTES COMPUT SC, V11208, P501, DOI 10.1007/978-3-030-01225-0_30
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Tay CP, 2021, IMAGE VISION COMPUT, V115, DOI 10.1016/j.imavis.2021.104298
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang Menglin, 2021, arXiv preprint arXiv:2109.08472, V2, P4
   Wang YS, 2019, IEEE I CONF COMP VIS, P322, DOI 10.1109/ICCV.2019.00041
   Wang Zhongdao, EUR C COMP VIS, P72
   Wei LH, 2018, PROC CVPR IEEE, P79, DOI 10.1109/CVPR.2018.00016
   Wu JL, 2019, IEEE I CONF COMP VIS, P8320, DOI 10.1109/ICCV.2019.00841
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xiao T, 2015, PROC CVPR IEEE, P2691, DOI 10.1109/CVPR.2015.7298885
   Xuan S., 2021, PROC CVPR IEEE, P11926, DOI DOI 10.1109/CVPR46437.2021.01175
   Yang FX, 2021, PROC CVPR IEEE, P4853, DOI 10.1109/CVPR46437.2021.00482
   Yu HX, 2019, PROC CVPR IEEE, P2143, DOI 10.1109/CVPR.2019.00225
   Yunpeng Zhai, P IEEECVF C COMPUTER, P9021
   Zhang ZZ, 2020, PROC CVPR IEEE, P3183, DOI 10.1109/CVPR42600.2020.00325
   Zhao Y, 2020, IMAGE VISION COMPUT, V103, DOI 10.1016/j.imavis.2020.104000
   Zheng DY, 2022, PATTERN RECOGN, V127, DOI 10.1016/j.patcog.2022.108615
   Zheng L, 2017, PROC CVPR IEEE, P3346, DOI 10.1109/CVPR.2017.357
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2019, PROC CVPR IEEE, P2133, DOI 10.1109/CVPR.2019.00224
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
   Zhong Z, 2020, AAAI CONF ARTIF INTE, V34, P13001
   Zhong Z, 2017, PROC CVPR IEEE, P3652, DOI 10.1109/CVPR.2017.389
   Zhong Z, 2019, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2019.00069
   Zhou KY, 2019, IEEE I CONF COMP VIS, P3701, DOI 10.1109/ICCV.2019.00380
   Zilong Ji, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12373), P20, DOI 10.1007/978-3-030-58604-1_2
NR 60
TC 2
Z9 2
U1 0
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104462
DI 10.1016/j.imavis.2022.104462
EA APR 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L9ND
UT WOS:000799606300003
DA 2024-07-18
ER

PT J
AU Amudhan, AN
   Sudheer, AP
AF Amudhan, A. N.
   Sudheer, A. P.
TI Lightweight and computationally faster Hypermetropic Convolutional
   Neural Network for small size object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Small-size object detection; Real-time; YOLO; Robotic vision; Faster
   RCNN; Light-weight models
ID DEEP; VEHICLE; IMAGES
AB Object detection has been an active area of research over the past two decades. The complexity of detecting an object increases with the increase in object speed and decrease in object size. Similar scenarios are observed in sports video analysis, vision systems of robots, driverless cars and much more. This led to the need for an efficient neural network that can detect small size objects. Further, most of the real-time applications use single board computers such as Jetson Nano, TX2, Xavier, Raspberry Pi and the like. The state-of-the-art of Deep Learning models such as YOLOv4, v3, YOLOR, YOLOX and SSD show poor run-time performance on these devices. Their lighter versions YOLOv3-tiny, YOLOv4-tiny and YOLOX-nano run nearly at 24 frames per second (fps) on Jetson Nano; however, their detection accuracy on small-sized objects is unsatisfactory. This paper focuses on developing a computationally lighter Convolutional Neural network(CNN) to detect small-sized objects efficiently. A novel hypermetropic CNN was developed to meet the above requirements. The improvement in detection is made by extracting more features from the shallow layers and transferring low-level features to the deeper layers. The network is hypermetropic because it performs well on distant objects and lags on nearby objects. The proposed model's performance is compared with the state-of-the-art models on various public datasets such as the VEDAI dataset, Visdrone dataset, and a few classes from the MS COCO and OID dataset. The proposed model shows impressive improvements in detecting small-size objects, and a 32% increase in the fps is observed on Jetson Nano.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Amudhan, A. N.; Sudheer, A. P.] Natl Inst Technol Calicut, Dept Mech Engn, Robot Lab, Calicut, Kerala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Calicut
RP Sudheer, AP (corresponding author), Natl Inst Technol Calicut, Dept Mech Engn, Robot Lab, Calicut, Kerala, India.
EM apsudheer@nitc.ac.in
FU Technical Education Quality Improvement Program (TEQIP-III);
   coordinators of TEQIP-III; Dean of Research and consultancy at National
   Institute of Technology Calicut
FX The authors would like to thank the Government of India for the
   Technical Education Quality Improvement Program (TEQIP-III) ,
   coordinators of TEQIP-III and Dean of Research and consultancy at
   National Institute of Technology Calicut for providing financial aid to
   procure Baumer High-speed cameras and GPU-workstation. The authors also
   thank the Centre for Computational Modelling and Simulation (CCMS) at
   NITC for the NVIDIA DGX facility.
CR Abbas Q, 2017, INT J ADV COMPUT SC, V8, P41
   Bochkovskiy A., 2020, PREPRINT
   Cao CQ, 2019, IEEE ACCESS, V7, P106838, DOI 10.1109/ACCESS.2019.2932731
   Chen CY, 2017, LECT NOTES COMPUT SC, V10115, P214, DOI 10.1007/978-3-319-54193-8_14
   Chen XZ, 2018, IEEE T PATTERN ANAL, V40, P1259, DOI 10.1109/TPAMI.2017.2706685
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dijkstra K, 2021, NEUROCOMPUTING, V423, P490, DOI 10.1016/j.neucom.2020.10.075
   Forczmanski P, 2016, COMM COM INF SC, V640, P293, DOI 10.1007/978-3-319-49646-7_25
   Ge Z., 2021, YOLOX: Exceeding YOLO Series in 2021, P1
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Han C, 2019, MULTIMED TOOLS APPL, V78, P13263, DOI 10.1007/s11042-018-6428-0
   Han-Wu Luo, 2019, 2019 International Conference on Machine Learning, Big Data and Business Intelligence (MLBDBI), P134, DOI 10.1109/MLBDBI48998.2019.00032
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu PY, 2017, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2017.166
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang XY, 2021, IEEE ICC, DOI [10.1109/ICC42927.2021.9500846, 10.1109/iWEM53379.2021.9790658]
   Huang ZC, 2020, INFORM SCIENCES, V522, P241, DOI 10.1016/j.ins.2020.02.067
   Jamiya SS, 2021, OPTIK, V225, DOI 10.1016/j.ijleo.2020.165818
   John V, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2286, DOI 10.1109/ITSC.2014.6958056
   Jordan AA, 2021, IEEE EMBED SYST LETT, V13, P130, DOI 10.1109/LES.2020.3029313
   Kang Dongyeon Daniel, 2018, 2018 IEEE Photonics Conference (IPC), DOI 10.1109/IPCon.2018.8527218
   Kim S. G., 2017, Electronics Letters, V53, P1034, DOI 10.1049/el.2017.1373
   Kim Y, 2016, IEEE GEOSCI REMOTE S, V13, P8, DOI 10.1109/LGRS.2015.2491329
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar A, 2021, OPTIK, V239, DOI 10.1016/j.ijleo.2021.166744
   Lee Y, 2020, P IEEE CVF C COMP VI
   Liang ZW, 2018, LECT NOTES COMPUT SC, V11166, P554, DOI 10.1007/978-3-030-00764-5_51
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WC, 2018, IEEE GEOSCI REMOTE S, V15, P937, DOI 10.1109/LGRS.2018.2813094
   Liu Y, 2021, EXPERT SYST APPL, V172, DOI 10.1016/j.eswa.2021.114602
   Loey Mohamed, 2021, Sustain Cities Soc, V65, P102600, DOI 10.1016/j.scs.2020.102600
   Long K, 2021, NEUROCOMPUTING, V422, P345, DOI 10.1016/j.neucom.2020.10.022
   Lu X, 2019, PROC CVPR IEEE, P7355, DOI 10.1109/CVPR.2019.00754
   Mao QC, 2019, IEEE ACCESS, V7, P133529, DOI 10.1109/ACCESS.2019.2941547
   Mery D, 2020, J NONDESTRUCT EVAL, V39, DOI 10.1007/s10921-020-0655-9
   Nguyen N., 2020, EVALUATION DEEP LEAR
   Rao Q, 2018, PROCEEDINGS 2018 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON SOFTWARE ENGINEERING FOR AI IN AUTONOMOUS SYSTEMS (SEFAIAS), P35, DOI 10.1145/3194085.3194087
   Razakarivony S, 2016, J VIS COMMUN IMAGE R, V34, P187, DOI 10.1016/j.jvcir.2015.11.002
   Redmon J., 2018, P IEEE C COMP VIS PA
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   Said YF, 2019, INT J COMPUT SCI NET, V19, P9
   Sharjeel A, 2021, J CHIN INST ENG, V44, P128, DOI 10.1080/02533839.2020.1856725
   Sun XD, 2018, NEUROCOMPUTING, V299, P42, DOI 10.1016/j.neucom.2018.03.030
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan M., 2019, 36 INT C MACH LEARN, P10691
   Tong K, 2020, IMAGE VISION COMPUT, V97, DOI 10.1016/j.imavis.2020.103910
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Wang C-Y, 2021, You Only Learn One Representation: Unified Network for Multiple Tasks, P1
   Wu J, 2021, APPL INTELL, V51, P4945, DOI 10.1007/s10489-020-02084-6
   Yi Zhang, 2019, Optik, V183, P17, DOI 10.1016/j.ijleo.2019.02.038
   Yin YH, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102756
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
   Zheng Z, 2020, Enhancing geometric factors in model learning and inference for object detection and instance segmentation
   Zhu P., IEEE T PATTERN ANAL
   Zhu Z, 2016, PROC CVPR IEEE, P2110, DOI 10.1109/CVPR.2016.232
NR 60
TC 17
Z9 18
U1 11
U2 183
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104396
DI 10.1016/j.imavis.2022.104396
EA FEB 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400008
DA 2024-07-18
ER

PT J
AU Liu, ZG
   Yin, ZY
   Wu, Y
AF Liu, Zhigang
   Yin, Ziyang
   Wu, Yin
TI MLRMV: Multi-layer representation for multi-view action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-layer representation; Multi-view action recognition; Motion atom;
   Motion phrase
ID JOINT; SEGMENTATION; TEMPLATES
AB Daily action recognition has gained much interest in computer vision. However, viewpoint changes will lead to sizable intra-class differences in the same action. To deal with this problem, we propose a novel multi-view daily action recognition approach based on the multi-layer representation. In use of motion atoms and motion phrases, we construct the middle-level feature representations in multi-view daily actions. A multi-view unsupervised discriminative clustering method is proposed for constructing motion atoms, and the classification accuracy of motion atoms is improved by jointly learning atom dictionaries and the classifier. Moreover, we present discontinuous temporal scale motion phrases and a grading mechanism of motion phrases to strengthen the representative ability of motion phrases and the final recognition accuracy. Finally, the experimental results based on the WVU dataset, the NTU RGB-D dataset, and N-UCLA dataset show that the proposed methods have the state-of-the-art performance, compared with the classic methods such as IDT, MoFAP, JLMF, and so on. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, Zhigang; Yin, Ziyang; Wu, Yin] Northeastern Univ, Sch Comp & Commun Engn, Qinhuangdao 066004, Hebei, Peoples R China.
C3 Northeastern University - China
RP Liu, ZG (corresponding author), Northeastern Univ, Sch Comp & Commun Engn, Qinhuangdao 066004, Hebei, Peoples R China.
EM zliu@neuq.edu.cn
OI Liu, Zhigang/0000-0003-2399-248X
FU National Natural Science Foun-dation of China [61973069, 61901099]
FX This work was supported by the National Natural Science Foun-dation of
   China under Grant 61973069 and Grant 61901099.
CR Abdelbaky A, 2020, NEURAL COMPUT APPL, V32, P12561, DOI 10.1007/s00521-020-04712-1
   Amer MR, 2012, LECT NOTES COMPUT SC, V7575, P187, DOI 10.1007/978-3-642-33765-9_14
   [Anonymous], 2016, WVU MULTIVIEW ACTION
   Anwaar-ul-Haq, 2013, IEEE T CIRC SYST VID, V23, P203, DOI 10.1109/TCSVT.2012.2203213
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Chen YL, 2021, IEEE T PARALL DISTR, V32, P1465, DOI 10.1109/TPDS.2021.3051011
   Duan H., 2021, ARXIV PREPRINT ARXIV
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Gao Z, 2019, IEEE INTERNET THINGS, V6, P9280, DOI 10.1109/JIOT.2019.2911669
   Ghodsi S, 2018, J VIS COMMUN IMAGE R, V55, P729, DOI 10.1016/j.jvcir.2018.08.001
   Hashemi SM, 2016, MULTIMED TOOLS APPL, V75, P6755, DOI 10.1007/s11042-015-2606-5
   Hu SZ, 2020, INFORM SCIENCES, V524, P148, DOI 10.1016/j.ins.2020.03.029
   Iosifidis A, 2013, SIGNAL PROCESS, V93, P1445, DOI 10.1016/j.sigpro.2012.08.015
   Khan M. Q., 2021, ARAB J SCI ENG, P1, DOI DOI 10.1007/s13369-021-05881-4
   Li BL, 2012, PROC CVPR IEEE, P1362, DOI 10.1109/CVPR.2012.6247822
   Li RM, 2019, IEEE ACCESS, V7, P169782, DOI 10.1109/ACCESS.2019.2954744
   Liu CW, 2018, MULTIMED TOOLS APPL, V77, P31627, DOI 10.1007/s11042-018-6189-9
   Liu F, 2020, NEUROCOMPUTING, V380, P236, DOI 10.1016/j.neucom.2019.11.020
   Liu F, 2016, IEEE T IMAGE PROCESS, V25, P949, DOI 10.1109/TIP.2015.2512107
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P2684, DOI 10.1109/TPAMI.2019.2916873
   Liu Y, 2019, IEEE T CIRC SYST VID, V29, P2416, DOI 10.1109/TCSVT.2018.2868123
   Liu Y, 2021, J SENSORS, V2021, DOI 10.1155/2021/8864870
   Luo G, 2020, IEEE T IMAGE PROCESS, V29, P3052, DOI 10.1109/TIP.2019.2955561
   Shahroudy A, 2016, PROC CVPR IEEE, P1010, DOI 10.1109/CVPR.2016.115
   Si ZZ, 2013, IEEE T PATTERN ANAL, V35, P2189, DOI 10.1109/TPAMI.2013.35
   Su B, 2017, IEEE T IMAGE PROCESS, V26, P5784, DOI 10.1109/TIP.2017.2745212
   Sui WC, 2016, NEUROCOMPUTING, V191, P286, DOI 10.1016/j.neucom.2016.01.051
   Vyas S., 2020, COMPUTER VISION ECCV, P427
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang J, 2014, PROC CVPR IEEE, P2649, DOI 10.1109/CVPR.2014.339
   Wang KZ, 2020, IEEE T PATTERN ANAL, V42, P1069, DOI 10.1109/TPAMI.2019.2892452
   Wang LM, 2016, INT J COMPUT VISION, V119, P254, DOI 10.1007/s11263-015-0859-0
   Wang LM, 2013, IEEE I CONF COMP VIS, P2680, DOI 10.1109/ICCV.2013.333
   Wang QY, 2018, IEEE ACCESS, V6, P20174, DOI 10.1109/ACCESS.2018.2791578
   Wang RS, 2020, CHIN CONT DECIS CONF, P4858, DOI 10.1109/CCDC49329.2020.9164815
   Wang TW, 2018, NEUROCOMPUTING, V273, P111, DOI 10.1016/j.neucom.2017.07.057
   Wei P, 2019, IEEE T MULTIMEDIA, V21, P2195, DOI 10.1109/TMM.2019.2897902
   Wei P, 2017, IEEE T PATTERN ANAL, V39, P1165, DOI 10.1109/TPAMI.2016.2574712
   Zheng JJ, 2016, IEEE T IMAGE PROCESS, V25, P2542, DOI 10.1109/TIP.2016.2548242
NR 39
TC 3
Z9 3
U1 1
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2021
VL 116
AR 104333
DI 10.1016/j.imavis.2021.104333
EA NOV 2021
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WZ2LF
UT WOS:000719802700005
DA 2024-07-18
ER

PT J
AU Huang, X
   Qiao, H
   Li, H
   Jiang, ZH
AF Huang, Xiao
   Qiao, Hong
   Li, Hui
   Jiang, Zhihong
TI A bioinspired retinal neural network for accurately extracting
   small-target motion information in cluttered backgrounds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Bioinspiration; Small-target motion detector; Robotic visual perception;
   Spatiotemporal energy model
ID BIPOLAR CELLS; OBJECT DETECTION; GANGLION-CELLS; DIRECTION; NEURONS
AB Robust and accurate detection of small moving targets in cluttered moving backgrounds is a significant and challenging problem for robotic visual systems to perform search and tracking tasks. Inspired by the neural circuitry of elementary motion vision in the mammalian retina, this paper proposes a bioinspired retinal neural network based on a new neurodynamics-based temporal filtering and multiform 2-D spatial Gabor filtering. This model can estimate motion direction accurately via only two perpendicular spatiotemporal filtering signals, and respond to small targets of different sizes and velocities through adjusting the dendrite field size of spatial filter. Meanwhile, an algorithm of directionally selective inhibition is proposed to suppress the target-like features in the moving background, which can reduce the influence of background motion effectively. Extensive synthetic and real-data experiments show that the proposed model works stably for small targets of a wider size and velocity range, and has better detection performance than other bioinspired models. Additionally, it can also extract the information of motion direction and motion energy accurately and rapidly. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Huang, Xiao; Li, Hui; Jiang, Zhihong] Beijing Inst Technol, Adv Innovat Ctr Intelligent Robots & Syst, Key Lab Biomimet Robots & Syst, Chinese Minist Educ,Sch Mechatron Engn, Beijing 100081, Peoples R China.
   [Qiao, Hong] Chinese Acad Sci, Inst Automat, State Key Lab Management & Control Complex Syst, Beijing 100190, Peoples R China.
C3 Beijing Institute of Technology; Chinese Academy of Sciences; Institute
   of Automation, CAS
RP Li, H; Jiang, ZH (corresponding author), Beijing Inst Technol, Adv Innovat Ctr Intelligent Robots & Syst, Key Lab Biomimet Robots & Syst, Chinese Minist Educ,Sch Mechatron Engn, Beijing 100081, Peoples R China.
EM lihui2011@bit.edu.cn; jiangzhihong@bit.edu.cn
FU National Key Research and Development Program of China [2018YFB1305300];
   China Postdoctoral Science Foundation [2020TQ0039]; National Natural
   Science Foundation of China [61733001, U2013602, 61873039, U1913211,
   U1713215]
FX This work is supported in part by the National Key Research and
   Development Program of China under 2018YFB1305300, the China
   Postdoctoral Science Foundation under Grant 2020TQ0039, the National
   Natural Science Foundation of China under Grant 61733001, U2013602,
   61873039, U1913211 and U1713215.
CR ADELSON EH, 1985, J OPT SOC AM A, V2, P284, DOI 10.1364/JOSAA.2.000284
   [Anonymous], 2018, YOLOV3 INCREMENTAL I
   Bagheri ZM, 2017, J NEURAL ENG, V14, DOI 10.1088/1741-2552/aa776c
   Bagheri ZM, 2017, BIOINSPIR BIOMIM, V12, DOI 10.1088/1748-3190/aa5b48
   Bagheri ZM, 2015, J R SOC INTERFACE, V12, DOI 10.1098/rsif.2015.0083
   Bai XZ, 2018, IEEE T GEOSCI REMOTE, V56, P2452, DOI 10.1109/TGRS.2017.2781143
   Barnett PD, 2007, CURR BIOL, V17, P569, DOI 10.1016/j.cub.2007.02.039
   BIALEK W, 1990, BIOPHYS J, V58, P1227, DOI 10.1016/S0006-3495(90)82463-2
   Borst A, 2015, NAT NEUROSCI, V18, P1067, DOI 10.1038/nn.4050
   Boström JE, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0151099
   Browning NA, 2009, NEURAL NETWORKS, V22, P1383, DOI 10.1016/j.neunet.2009.05.007
   Browning NA, 2009, COGNITIVE PSYCHOL, V59, P320, DOI 10.1016/j.cogpsych.2009.07.002
   Burkhardt DA, 2007, VISUAL NEUROSCI, V24, P765, DOI 10.1017/S0952523807070630
   Caves EM, 2018, TRENDS ECOL EVOL, V33, P358, DOI 10.1016/j.tree.2018.03.001
   Clark DA, 2016, CURR BIOL, V26, pR1062, DOI 10.1016/j.cub.2016.08.003
   Dhande OS, 2015, ANNU REV VIS SCI, V1, P291, DOI 10.1146/annurev-vision-082114-035502
   Ester M., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P226
   Euler T, 2014, NAT REV NEUROSCI, V15, P507, DOI 10.1038/nrn3783
   Fortun Denis, 2015, Computer Vision and Image Understanding, V134, P1, DOI 10.1016/j.cviu.2015.02.008
   Gao CQ, 2013, IEEE T IMAGE PROCESS, V22, P4996, DOI 10.1109/TIP.2013.2281420
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   HEEGER DJ, 1987, INT J COMPUT VISION, V1, P279, DOI 10.1007/BF00133568
   Hoggarth A, 2015, NEURON, V86, P276, DOI 10.1016/j.neuron.2015.02.035
   Huang SC, 2014, IEEE T CYBERNETICS, V44, P114, DOI 10.1109/TCYB.2013.2248057
   Jessell TM., 2000, PRINCIPLES NEURAL SC
   Li ZF, 2016, IEEE GEOSCI REMOTE S, V13, P1512, DOI 10.1109/LGRS.2016.2594299
   Liu G, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104197
   Masland RH, 2001, NAT NEUROSCI, V4, P877, DOI 10.1038/nn0901-877
   Mazinan AH, 2012, ISA T, V51, P485, DOI 10.1016/j.isatra.2012.02.002
   Nordstrom K, 2006, P ROY SOC B-BIOL SCI, V273, P1211, DOI 10.1098/rspb.2005.3424
   Ran T, 2021, ISA T, V109, P389, DOI 10.1016/j.isatra.2020.10.023
   Redmon J., 2017, P IEEE C COMP VIS PA, P7263
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Schubert E, 2017, ACM T DATABASE SYST, V42, DOI 10.1145/3068335
   Wang FL, 2015, INFORM SCIENCES, V301, P215, DOI 10.1016/j.ins.2014.12.022
   Wang HX, 2020, IEEE T NEUR NET LEAR, V31, P839, DOI 10.1109/TNNLS.2019.2910418
   Wang HX, 2020, IEEE T CYBERNETICS, V50, P1541, DOI 10.1109/TCYB.2018.2869384
   Wang XY, 2017, IMAGE VISION COMPUT, V63, P1, DOI 10.1016/j.imavis.2017.04.002
   Wei SG, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.650
   Wei SG, 2009, PROCEEDINGS OF THE SECOND INTERNATIONAL SYMPOSIUM ON ELECTRONIC COMMERCE AND SECURITY, VOL II, P85, DOI 10.1109/ISECS.2009.62
   Werner R., 1961, SENSORY COMMUNICATIO
   Wiederman SD, 2008, PLOS ONE, V3, DOI 10.1371/journal.pone.0002784
   Woo H, 2010, IEEE T IMAGE PROCESS, V19, P2838, DOI 10.1109/TIP.2010.2050644
   WYATT HJ, 1975, J NEUROPHYSIOL, V38, P613, DOI 10.1152/jn.1975.38.3.613
   Yong HW, 2018, IEEE T PATTERN ANAL, V40, P1726, DOI 10.1109/TPAMI.2017.2732350
   Zhu J.C., 1965, ''Symmetry, V12
NR 46
TC 2
Z9 2
U1 3
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2021
VL 114
AR 104266
DI 10.1016/j.imavis.2021.104266
EA AUG 2021
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UR9HP
UT WOS:000697051200010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Zioulis, N
   Alvarez, F
   Zarpalas, D
   Daras, P
AF Zioulis, Nikolaos
   Alvarez, Federico
   Zarpalas, Dimitrios
   Daras, Petros
TI Single-shot cuboids: Geodesics-based end-to-end Manhattan aligned layout
   estimation from spherical panoramas
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Panoramic scene understanding; Indoor 3D reconstruction; Layout
   estimation; Spherical panoramas; Omnidirectional vision
ID RECONSTRUCTION; GEOMETRY; IMAGES
AB It has been shown that global scene understanding tasks like layout estimation can benefit from wider field of views, and specifically spherical panoramas. While much progress has been made recently, all previous approaches rely on intermediate representations and postprocessing to produce Manhattan-aligned estimates. In this work we show how to estimate full room layouts in a single-shot, eliminating the need for postprocessing. Our work is the first to directly infer Manhattan-aligned outputs. To achieve this, our data-driven model exploits direct coordinate regression and is supervised end-to-end. As a result, we can explicitly add quasi-Manhattan constraints, which set the necessary conditions for a homography-based Manhattan alignment module. Finally, we introduce the geodesic heatmaps and loss and a boundary-aware center of mass calculation that facilitate higher quality keypoint estimation in the spherical domain. Our models and code are publicly available at https://github.com/VCL3D/SingleShotCuboids.
   (c) 2021 The Author(s). Published by Elsevier B.V. This is an open access article under the CC BY license (http:// creativecommons.org/licenses/by/4.0/).
C1 [Zioulis, Nikolaos; Zarpalas, Dimitrios; Daras, Petros] Ctr Res & Technol Hellas CERTH, Informat Technol Inst ITI, Visual Comp Lab VCL, 6Km Charilaou Thermi Rd, Thessaloniki, Greece.
   [Zioulis, Nikolaos; Alvarez, Federico] Univ Politecn Madrid UPM, Signals Syst & Radiocommun Dept SSRD, Madrid, Spain.
C3 Centre for Research & Technology Hellas; Universidad Politecnica de
   Madrid
RP Zioulis, N (corresponding author), Ctr Res & Technol Hellas CERTH, Informat Technol Inst ITI, Visual Comp Lab VCL, 6Km Charilaou Thermi Rd, Thessaloniki, Greece.
EM nzioulis@iti.gr; fag@gatv.ssr.upm.es; zarpalas@iti.gr; daras@iti.gr
RI Daras, Petros/F-5284-2012; Alvarez, Federico/AAA-7628-2019
OI Daras, Petros/0000-0003-3814-6710; Alvarez,
   Federico/0000-0001-7400-9591; ZIOULIS, NIKOLAOS/0000-0002-7898-9344
FU European Commission H2020 [GA 951900]
FX This work was supported by the European Commission H2020 funded project
   ATLANTIS (http://atlantis-ar.eu/) [GA 951900]. We also thanks the
   anonymous reviewers for their insightful comments.
CR [Anonymous], 2012, 3D GEOMETRY PANORAMA
   Armeni Iro, 2017, arXiv
   Buslaev A, 2020, INFORMATION, V11, DOI 10.3390/info11020125
   Chang A, 2017, INT CONF 3D VISION, P667, DOI 10.1109/3DV.2017.00081
   Cheng HT, 2018, PROC CVPR IEEE, P1420, DOI 10.1109/CVPR.2018.00154
   Cohen T.S., 2018, P 6 INT C LEARN REPR, P1
   Coors B, 2018, LECT NOTES COMPUT SC, V11213, P525, DOI 10.1007/978-3-030-01240-3_32
   da Silveira TLT, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P9, DOI [10.1109/VR.2019.8798281, 10.1109/vr.2019.8798281]
   Daniilidis K., 2018, **DROPPED REF**
   Defferrard M, 2019, ICLR WORKSH REPR LEA
   Eigen D, 2014, ADV NEUR IN, V27
   Esteves C, 2018, LECT NOTES COMPUT SC, V11217, P54, DOI 10.1007/978-3-030-01261-8_4
   Falcon W., 2019, PYTORCH LIGHTNING
   Feng ZH, 2018, PROC CVPR IEEE, P2235, DOI 10.1109/CVPR.2018.00238
   Fernandez-Labrador C., 2018, ARXIV180809879, P1
   Fernandez-Labrador C, 2020, IEEE ROBOT AUTOM LET, V5, P1255, DOI 10.1109/LRA.2020.2967274
   Fernandez-Labrador C, 2018, IEEE ROBOT AUTOM LET, V3, P3153, DOI 10.1109/LRA.2018.2850532
   Fukano K, 2016, INT C PATT RECOG, P1768, DOI 10.1109/ICPR.2016.7899892
   Giovanni Pintore, 2020, EUR C COMP VIS SPRIN, P432
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Jia Zheng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P519, DOI 10.1007/978-3-030-58545-7_30
   Jin L, 2020, PROC CVPR IEEE, P886, DOI 10.1109/CVPR42600.2020.00097
   Jung J, 2017, VISUAL COMPUT, V33, P737, DOI 10.1007/s00371-017-1368-7
   Jung R, 2019, 2019 26TH IEEE CONFERENCE ON VIRTUAL REALITY AND 3D USER INTERFACES (VR), P1, DOI [10.1109/VR.2019.8798326, 10.1109/vr.2019.8798326]
   Kaiming He, 2015, 2015 IEEE International Conference on Computer Vision (ICCV). Proceedings, P1026, DOI 10.1109/ICCV.2015.123
   Khasanova R, 2017, IEEE INT CONF COMP V, P860, DOI 10.1109/ICCVW.2017.106
   Kingma D. P., 2014, arXiv
   Lee CY, 2017, IEEE I CONF COMP VIS, P4875, DOI 10.1109/ICCV.2017.521
   Li MY, 2019, IEEE IJCNN
   Liu NT, 2018, ADV APPL CLIFFORD AL, V28, DOI 10.1007/s00006-018-0880-9
   Liu R, 2018, ADV NEUR IN, V31
   Luvizon DC, 2019, COMPUT GRAPH-UK, V85, P15, DOI 10.1016/j.cag.2019.09.002
   Monroy R, 2018, SIGNAL PROCESS-IMAGE, V69, P26, DOI 10.1016/j.image.2018.05.005
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Nibali A., ARXIV180107372
   Paszke A., 2017, AUTOMATIC DIFFERENTI
   Pintore Giovanni, 2018, Computational Visual Media, V4, P367, DOI 10.1007/s41095-018-0125-9
   Pintore G., 2016, 2016 IEEE WINT C APP, P1, DOI DOI 10.1109/WACV.2016.7477631
   Pintore G, 2020, COMPUT GRAPH FORUM, V39, P667, DOI 10.1111/cgf.14021
   Pintore G, 2019, COMPUT GRAPH FORUM, V38, P347, DOI 10.1111/cgf.13842
   Pintore G, 2018, COMPUT GRAPH-UK, V77, P16, DOI 10.1016/j.cag.2018.09.013
   SCHONEMA.PH, 1966, PSYCHOMETRIKA, V31, P1, DOI 10.1007/BF02289451
   Song SR, 2019, PROC CVPR IEEE, P6911, DOI 10.1109/CVPR.2019.00708
   Song SR, 2018, PROC CVPR IEEE, P3847, DOI 10.1109/CVPR.2018.00405
   Su Y.-C., 2017, ADV NEURAL INFORM PR, P529
   Su YC, 2019, PROC CVPR IEEE, P9434, DOI 10.1109/CVPR.2019.00967
   Sun C, 2021, PROC CVPR IEEE, P2573, DOI 10.1109/CVPR46437.2021.00260
   Sun C, 2019, PROC CVPR IEEE, P1047, DOI 10.1109/CVPR.2019.00114
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Sun YL, 2017, IEEE SIGNAL PROC LET, V24, P1408, DOI 10.1109/LSP.2017.2720693
   Taira H, 2018, PROC CVPR IEEE, P7199, DOI 10.1109/CVPR.2018.00752
   Tateno K, 2018, LECT NOTES COMPUT SC, V11220, P732, DOI 10.1007/978-3-030-01270-0_43
   Tensmeyer C, 2019, PROC INT CONF DOC, P1, DOI 10.1109/ICDARW.2019.40072
   von Gioi RG, 2012, IMAGE PROCESS ON LIN, V2, P35, DOI 10.5201/ipol.2012.gjmr-lsd
   Wang TH, 2018, IEEE INT CONF ROBOT, P2341
   Xia F, 2018, PROC CVPR IEEE, P9068, DOI 10.1109/CVPR.2018.00945
   Xiao JX, 2012, PROC CVPR IEEE, P2695, DOI 10.1109/CVPR.2012.6247991
   Xu J, 2017, IEEE WINT CONF APPL, P354, DOI 10.1109/WACV.2017.46
   Yang H, 2016, PROC CVPR IEEE, P5422, DOI 10.1109/CVPR.2016.585
   Yang ST, 2019, PROC CVPR IEEE, P3358, DOI 10.1109/CVPR.2019.00348
   Yang Y, 2018, PROC CVPR IEEE, P3926, DOI 10.1109/CVPR.2018.00413
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
   Zhang R, 2019, PR MACH LEARN RES, V97
   Zhang YD, 2014, LECT NOTES COMPUT SC, V8694, P668, DOI 10.1007/978-3-319-10599-4_43
   Zioulis N, 2019, INT CONF 3D VISION, P690, DOI 10.1109/3DV.2019.00081
   Zioulis N, 2018, LECT NOTES COMPUT SC, V11210, P453, DOI 10.1007/978-3-030-01231-1_28
   Zou CH, 2021, INT J COMPUT VISION, V129, P1410, DOI 10.1007/s11263-020-01426-8
   Zou CH, 2018, PROC CVPR IEEE, P2051, DOI 10.1109/CVPR.2018.00219
NR 71
TC 7
Z9 7
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104160
DI 10.1016/j.imavis.2021.104160
EA APR 2021
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700008
OA hybrid, Green Submitted
DA 2024-07-18
ER

PT J
AU Zhang, YF
   Sidibé, D
   Morel, O
   Mériaudeau, F
AF Zhang, Yifei
   Sidibe, Desire
   Morel, Olivier
   Meriaudeau, Fabrice
TI Deep multimodal fusion for semantic image segmentation: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Image fusion; Multi-modal; Deep learning; Semantic segmentation
ID NEURAL-NETWORKS; RGB-D; POLARIZATION; RECOGNITION; VISION
AB Recent advances in deep learning have shown excellent performance in various scene understanding tasks. However, in some complex environments or under challenging conditions, it is necessary to employ multiple modalities that provide complementary information on the same scene. A variety of studies have demonstrated that deep multimodal fusion for semantic image segmentation achieves significant performance improvement. These fusion approaches take the benefits of multiple information sources and generate an optimal joint prediction automatically. This paper describes the essential background concepts of deep multimodal fusion and the relevant applications in computer vision. In particular, we provide a systematic survey of multimodal fusion methodologies, multimodal segmentation datasets, and quantitative evaluations on the benchmark datasets. Existing fusion methods are summarized according to a common taxonomy: early fusion, late fusion, and hybrid fusion. Based on their performance, we analyze the strengths and weaknesses of different fusion strategies. Current challenges and design choices are discussed, aiming to provide the reader with a comprehensive and heuristic view of deep multimodal image segmentation. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zhang, Yifei; Morel, Olivier; Meriaudeau, Fabrice] Univ Bourgogne Franche Comte, ImViA, VIBOT ERL CNRS 6000, F-71200 Le Creusot, France.
   [Sidibe, Desire] Univ Paris Saclay, Univ Evry, IBISC, F-91020 Evry, France.
C3 Universite de Bourgogne; Universite Paris Saclay; Universite Paris Cite
RP Zhang, YF (corresponding author), Univ Bourgogne Franche Comte, ImViA, VIBOT ERL CNRS 6000, F-71200 Le Creusot, France.
EM Yifei.Zhang@u-bourgogne.fr
RI MOREL, Olivier/AAK-3190-2020; Zhang, Yifei/GRO-3001-2022; SIDIBE,
   DESIRE/AFQ-8070-2022
OI MOREL, Olivier/0000-0001-5768-2821; SIDIBE, DESIRE/0000-0002-5843-7139
CR [Anonymous], 2018, ARXIV180601054
   [Anonymous], 2016, ENET DEEP NEURAL NET
   [Anonymous], 2014, 2 INT C LEARN REPR I
   [Anonymous], 2018, ARXIV180100868
   [Anonymous], 2019, P IEEE C COMP VIS PA
   [Anonymous], 2017, BRIT MACH VIS C BMVC
   [Anonymous], 2016, ICLR
   [Anonymous], 2010, INT J COMPUT VISION, DOI [DOI 10.1007/s11263-009-0275-4, 10.1007/s11263-009-0275-4]
   [Anonymous], 2017, IEEE I CONF COMP VIS, DOI DOI 10.1109/ICCV.2017.147
   [Anonymous], 2019, P 14 INT JOINT C, DOI DOI 10.5220/0007360203280335
   [Anonymous], 2019, ARRAY, DOI DOI 10.1145/3342775.3342785
   [Anonymous], 2017, COMPUTER VISION AUTO
   [Anonymous], 2015, INT C LEARN REPR
   Guerrero JA, 2017, 2017 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P16
   Arvin AM, 2009, LIVE VARIOLA VIRUS: CONSIDERATIONS FOR CONTINUING RESEARCH, P9
   Asvadi A, 2018, PATTERN RECOGN LETT, V115, P20, DOI 10.1016/j.patrec.2017.09.038
   Atrey PK, 2010, MULTIMEDIA SYST, V16, P345, DOI 10.1007/s00530-010-0182-0
   Audebert N, 2018, ISPRS J PHOTOGRAMM, V140, P20, DOI 10.1016/j.isprsjprs.2017.11.011
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Baltrusaitis T, 2019, IEEE T PATTERN ANAL, V41, P423, DOI 10.1109/TPAMI.2018.2798607
   Bansal X. Chen, 2016, ARXIV160906694
   Benezeth Y., 2014, BACKGROUND SUBTRACTI
   Bijelic M., 2019, ARXIV190208913
   Blum H, 2018, IEEE INT C INT ROBOT, P3670, DOI 10.1109/IROS.2018.8593786
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Caesar H., 2018, REALLY AWESOME SEMAN
   Chen H, 2018, PROC CVPR IEEE, P3051, DOI 10.1109/CVPR.2018.00322
   Chen LCE, 2018, LECT NOTES COMPUT SC, V11211, P833, DOI 10.1007/978-3-030-01234-2_49
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen LC, 2016, PROC CVPR IEEE, P3640, DOI 10.1109/CVPR.2016.396
   Chen Liang-Chieh, 2014, Comput Sci, DOI DOI 10.48550/ARXIV.1412.7062
   Chen LB, 2017, IEEE INT SYMP NANO, P1, DOI 10.1109/NANOARCH.2017.8053709
   Chen XJ, 2014, PROC CVPR IEEE, P1979, DOI 10.1109/CVPR.2014.254
   Chen XZ, 2017, PROC CVPR IEEE, P6526, DOI 10.1109/CVPR.2017.691
   Cheng B., 2019, ARXIV191110194
   Cheng YH, 2017, PROC CVPR IEEE, P1475, DOI 10.1109/CVPR.2017.161
   Choe G, 2018, IEEE ROBOT AUTOM LET, V3, P1808, DOI 10.1109/LRA.2018.2801390
   Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533
   Connor P, 2018, COMPUT VIS IMAGE UND, V167, P1, DOI 10.1016/j.cviu.2018.01.007
   Cordts M, 2016, PROC CVPR IEEE, P3213, DOI 10.1109/CVPR.2016.350
   Couprie C., 2013, P 1 INT C LEARN REPR, P1
   Dai A, 2017, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2017.261
   Deng L., 2019, ARXIV190700135
   Dumbgen F., 2018, Electron. Imaging, V30, P321, DOI 10.2352/
   Edelman S., 1989, OPT NEWS, V15, P8
   Eitel A, 2015, IEEE INT C INT ROBOT, P681, DOI 10.1109/IROS.2015.7353446
   Erzin E, 2006, IEEE MULTIMEDIA, V13, P18, DOI 10.1109/MMUL.2006.37
   Etgen D., 2013, ARXIV13124314
   Fan L, 2018, IEEE ACCESS, V6, P71566, DOI 10.1109/ACCESS.2018.2880877
   Farokhi S, 2016, COMPUT SCI REV, V21, P1, DOI 10.1016/j.cosrev.2016.05.003
   Feng D., 2019, ARXIV190207830
   Fernandez-Moral E, 2018, IEEE INT VEH SYM, P1051, DOI 10.1109/IVS.2018.8500497
   Fierrez-Aguilar J, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P5
   Fooladgar F., 2019, MULTIMED TOOLS APPL, P1
   Frischholz RW, 2000, COMPUTER, V33, P64, DOI 10.1109/2.820041
   Gade R, 2014, MACH VISION APPL, V25, P245, DOI 10.1007/s00138-013-0570-5
   Gal Y, 2016, PR MACH LEARN RES, V48
   Garcia-Garcia A., 2017, ARXIV170406857
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Ghosh S., 2019, ARXIV190706119
   González A, 2017, IEEE T CYBERNETICS, V47, P3980, DOI 10.1109/TCYB.2016.2593940
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Guan DY, 2019, INFORM FUSION, V50, P148, DOI 10.1016/j.inffus.2018.11.017
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Ha Q, 2017, IEEE INT C INT ROBOT, P5108, DOI 10.1109/IROS.2017.8206396
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   Hazirbas C, 2017, LECT NOTES COMPUT SC, V10111, P213, DOI 10.1007/978-3-319-54181-5_14
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Holliday A, 2017, COMPUT VIS IMAGE UND, V164, P16, DOI 10.1016/j.cviu.2017.05.004
   Hu X., 2019, ARXIV190510089
   Huang J, 2017, PROC CVPR IEEE, P3296, DOI 10.1109/CVPR.2017.351
   Hung S.-W., 2018, ARXIV180909077
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   Jang DW, 2017, IET IMAGE PROCESS, V11, P587, DOI 10.1049/iet-ipr.2017.0192
   Jiang JD, 2017, INT CONF SOFTW ENG, P525, DOI 10.1109/ICSESS.2017.8342970
   Jin X, 2017, INFRARED PHYS TECHN, V85, P478, DOI 10.1016/j.infrared.2017.07.010
   Karasawa T, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P35, DOI 10.1145/3126686.3126727
   Khaleghi B, 2013, INFORM FUSION, V14, P28, DOI 10.1016/j.inffus.2011.08.001
   Kirsanov P., 2019, ARXIV190912146
   Kuncheva L.I., 2014, COMBINING PATTERN CL
   Lahat D, 2015, P IEEE, V103, P1449, DOI 10.1109/JPROC.2015.2460697
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li CY, 2019, PATTERN RECOGN, V85, P161, DOI 10.1016/j.patcog.2018.08.005
   Li X., 2019, ARXIV190907229
   Li X., 2019, ARXIV190401803
   Li Y., 2018, ABS181203904 CORR
   Li YB, 2017, IEEE IMAGE PROC, P1262, DOI 10.1109/ICIP.2017.8296484
   Li Z, 2016, LECT NOTES COMPUT SC, V9906, P541, DOI 10.1007/978-3-319-46475-6_34
   Lin GS, 2017, PROC CVPR IEEE, P5168, DOI 10.1109/CVPR.2017.549
   Lin GS, 2018, IEEE T PATTERN ANAL, V40, P1352, DOI 10.1109/TPAMI.2017.2708714
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lipton ZC, 2015, ARXIV PREPRINT ARXIV
   Litjens G, 2017, MED IMAGE ANAL, V42, P60, DOI 10.1016/j.media.2017.07.005
   Liu J., 2016, BRIT MACH VIS C 2016
   Liu K., 2018, CORR, V1730
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Liu Y, 2017, 2017 20TH INTERNATIONAL CONFERENCE ON INFORMATION FUSION (FUSION), P1070
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma LN, 2017, IEEE INT C INT ROBOT, P598, DOI 10.1109/IROS.2017.8202213
   McMahon S, 2018, IEEE ROBOT AUTOM LET, V3, P1, DOI 10.1109/LRA.2017.2719763
   Mees O, 2016, 2016 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS (IROS 2016), P151, DOI 10.1109/IROS.2016.7759048
   Moeskops Pim, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P478, DOI 10.1007/978-3-319-46723-8_55
   Mottaghi R, 2014, PROC CVPR IEEE, P891, DOI 10.1109/CVPR.2014.119
   Mroueh Y, 2015, INT CONF ACOUST SPEE, P2130, DOI 10.1109/ICASSP.2015.7178347
   Naseer M, 2019, IEEE ACCESS, V7, P1859, DOI 10.1109/ACCESS.2018.2886133
   Neuhold G, 2017, IEEE I CONF COMP VIS, P5000, DOI 10.1109/ICCV.2017.534
   Noh H, 2015, IEEE I CONF COMP VIS, P1520, DOI 10.1109/ICCV.2015.178
   Ohta Y., 1978, Proceedings of the 4th International Joint Conference on Pattern Recognition, P752
   Park SJ, 2017, IEEE I CONF COMP VIS, P4990, DOI 10.1109/ICCV.2017.533
   Patel N, 2017, IEEE INT C INT ROBOT, P1531, DOI 10.1109/IROS.2017.8205958
   Peng C, 2017, PROC CVPR IEEE, P1743, DOI 10.1109/CVPR.2017.189
   Pfeuffer A., 2018, 2018 21 INT C INF FU, P1, DOI DOI 10.23919/ICIF.2018.8455757
   Pfeuffer A., 2019, ARXIV190510117
   Piasco N, 2019, IEEE INT CONF ROBOT, P9094, DOI [10.1109/icra.2019.8794221, 10.1109/ICRA.2019.8794221]
   Qiu S., 2019, POLARIZATION DEMOSAI
   Ramachandram D, 2017, IEEE SIGNAL PROC MAG, V34, P96, DOI 10.1109/MSP.2017.2738401
   Rastgoo M, 2018, IEEE INT C INT ROBOT, P8397, DOI 10.1109/IROS.2018.8593575
   Ren M., 2016, ABS160509410 CORR
   Richter SR, 2016, LECT NOTES COMPUT SC, V9906, P102, DOI 10.1007/978-3-319-46475-6_7
   Abid MR, 2016, 2016 IEEE 4TH INTERNATIONAL CONFERENCE ON FUTURE INTERNET OF THINGS AND CLOUD WORKSHOPS (FICLOUDW), P109, DOI 10.1109/W-FiCloud.2016.35
   Romera E, 2017, IEEE INT VEH SYM, P1789, DOI 10.1109/IVS.2017.7995966
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ros G, 2016, PROC CVPR IEEE, P3234, DOI 10.1109/CVPR.2016.352
   Rubin NA, 2019, SCIENCE, V365, P43, DOI 10.1126/science.aax1839
   Sakaridis C, 2018, LECT NOTES COMPUT SC, V11217, P707, DOI 10.1007/978-3-030-01261-8_42
   Schechner YY, 2001, PROC CVPR IEEE, P325
   Schneider L, 2017, LECT NOTES COMPUT SC, V10269, P98, DOI 10.1007/978-3-319-59126-1_9
   Schwarz M, 2015, IEEE INT CONF ROBOT, P1329, DOI 10.1109/ICRA.2015.7139363
   Shivakumar Shreyas S, 2019, ARXIV190910980
   Shotton J, 2006, LECT NOTES COMPUT SC, V3951, P1
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Sokolova M, 2009, INFORM PROCESS MANAG, V45, P427, DOI 10.1016/j.ipm.2009.03.002
   Soleymani S, 2018, INT C PATT RECOG, P3469, DOI 10.1109/ICPR.2018.8545061
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Sun D., 2019, INT SOC OPTICS PHOTO, V11166
   Sun L, 2019, PROC SPIE, V11169, DOI 10.1117/12.2532477
   Sun YX, 2019, IEEE ROBOT AUTOM LET, V4, P2576, DOI 10.1109/LRA.2019.2904733
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Taghanaki S.A., 2019, ARXIV191007655
   Treible W., 2019, CVPR WORKSHOPS
   Valada Abhinav, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P4644, DOI 10.1109/ICRA.2017.7989540
   Valada A, 2020, INT J COMPUT VISION, V128, P1239, DOI 10.1007/s11263-019-01188-y
   Valada A, 2017, SPR PROC ADV ROBOT, V1, P465, DOI 10.1007/978-3-319-50115-4_41
   Vaswani A, 2017, ADV NEUR IN, V30
   Velte Maurice, 2015, THESIS
   Visin F, 2016, IEEE COMPUT SOC CONF, P426, DOI 10.1109/CVPRW.2016.60
   Wagner J., 2016, EUR S ART NEUR NETW
   Wang JH, 2016, LECT NOTES COMPUT SC, V9909, P664, DOI 10.1007/978-3-319-46454-1_40
   Wang N, 2019, ARXIV190101369
   Wang PQ, 2018, IEEE WINT CONF APPL, P1451, DOI 10.1109/WACV.2018.00163
   Wang PC, 2018, COMPUT VIS IMAGE UND, V171, P118, DOI 10.1016/j.cviu.2018.04.007
   WOLFF LB, 1991, IEEE T PATTERN ANAL, V13, P635, DOI 10.1109/34.85655
   Wolff LB, 1997, IMAGE VISION COMPUT, V15, P81, DOI 10.1016/S0262-8856(96)01123-7
   Xiao Y., 2019, ARXIV190603199
   Xu DF, 2018, PROC CVPR IEEE, P244, DOI 10.1109/CVPR.2018.00033
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   Xu XY, 2017, PATTERN RECOGN, V72, P300, DOI 10.1016/j.patcog.2017.07.026
   Yang KL, 2018, IEEE-RAS INT C HUMAN, P96, DOI 10.1109/HUMANOIDS.2018.8625005
   Yang LQ, 2003, INT CONF ACOUST SPEE, P121
   Yin H, 2017, IEEE INT C INTELL TR, DOI 10.1109/ITSC.2017.8317828
   Ying Yang M, 2019, Multimodal scene understanding: Algorithms, applications and deep learning, Vfirst
   Yu HS, 2018, NEUROCOMPUTING, V304, P82, DOI 10.1016/j.neucom.2018.03.037
   Zendel O, 2018, LECT NOTES COMPUT SC, V11210, P407, DOI 10.1007/978-3-030-01231-1_25
   Zendel O, 2019, IEEE COMPUT SOC CONF, P1221, DOI 10.1109/CVPRW.2019.00161
   Zhang R, 2015, IEEE INT CONF ROBOT, P1850, DOI 10.1109/ICRA.2015.7139439
   Zhang WK, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10010052
   Zhang YF, 2019, PROCEEDINGS OF THE 14TH INTERNATIONAL JOINT CONFERENCE ON COMPUTER VISION, IMAGING AND COMPUTER GRAPHICS THEORY AND APPLICATIONS (VISAPP), VOL 5, P336, DOI 10.5220/0007360403360343
   Zhang ZY, 2018, SUSTAIN CIV INFRASTR, P269, DOI 10.1007/978-3-319-61612-4_22
   Zhao HS, 2018, LECT NOTES COMPUT SC, V11207, P418, DOI 10.1007/978-3-030-01219-9_25
   Zhao HS, 2017, PROC CVPR IEEE, P6230, DOI 10.1109/CVPR.2017.660
   Zheng S, 2015, IEEE I CONF COMP VIS, P1529, DOI 10.1109/ICCV.2015.179
   Zhou BL, 2017, PROC CVPR IEEE, P5122, DOI 10.1109/CVPR.2017.544
   Zhu D., 2019, COMPUTER VISION PATT
   Zhu Y., 2018, ARXIV181109855
NR 177
TC 90
Z9 95
U1 29
U2 193
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2021
VL 105
AR 104042
DI 10.1016/j.imavis.2020.104042
EA JAN 2021
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA PY3ZH
UT WOS:000611984800004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Raja, K
   Ramachandra, R
   Busch, C
AF Raja, Kiran
   Ramachandra, Raghavendra
   Busch, Christoph
TI Collaborative representation of blur invariant deep sparse features for
   periocular recognition from smartphones
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Periocular recognition; Visible Spectrum; Smartphone; Biometrics; Deep
   sparse filtering
ID IRIS RECOGNITION; FACE; PHASE
AB The periocular region is used for authentication in the recent days under unconstrained acquisition in biometrics. This work presents two new feature extraction techniques to achieve robust and blur invariant biometric verification using periocular images captured using smartphones (1) Deep Sparse Features (DSF) and (2) Deep Sparse Time Frequency Features (DeSTiFF). Both the approaches are based on extracting features via convolution of periocular images with a set of filters also referred as Deep Sparse Filters. The filters are learnt using natural image patches and sparse filtering approach. The DSF is obtained through convolution via Deep Sparse Filters. Further, convoluted responses are analyzed using Short Term Fourier Transform (STFT) to obtain time and frequency features of the images referred as DeSTIFF. The features obtained from the newly proposed feature extraction techniques are further represented in a collaborative subspace to achieve better verification performance. Both of the proposed feature extraction schemes are evaluated on two publicly available smartphone periocular databases and a new database (Visible Spectrum Periocular Image (VISPI) database) released with this article. The robustness of the proposed feature extraction is exemplified by comparing it with state-of-art approaches along with multiple deep networks where the improvement is evidently seen on large scale database with an average verification accuracy of Genuine Match Rate approximate to 98% at False Match Rate = 0.01%. We further support reproducible research by making the code and the database available for the academic research. (C) 2020 The Author(s). Published by Elsevier B.V.
C1 [Raja, Kiran; Ramachandra, Raghavendra; Busch, Christoph] Norwegian Univ Sci & Technol, Trondheim, Norway.
C3 Norwegian University of Science & Technology (NTNU)
RP Raja, K (corresponding author), Norwegian Univ Sci & Technol, Trondheim, Norway.
EM kiran.raja@ntnu.no; raghavendra.ramachandra@ntnu.no;
   christoph.busch@ntnu.no
RI Busch, Christoph/AAF-8176-2019
OI Busch, Christoph/0000-0002-9159-2923
CR Alonso-Fernandez F, 2016, PATTERN RECOGN LETT, V82, P92, DOI 10.1016/j.patrec.2015.08.026
   [Anonymous], 2015, IEEE INT C BIOM ICB
   [Anonymous], 2016, PROBABILISTIC COLLAB
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bharadwaj Samarth., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Bradski D., 2008, Learning OpenCV, V1st
   Brown M, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1218
   Chan CH, 2013, IEEE T PATTERN ANAL, V35, P1164, DOI 10.1109/TPAMI.2012.199
   De Marsico M, 2015, PATTERN RECOGN LETT, V57, P17, DOI 10.1016/j.patrec.2015.02.009
   De Marsico M, 2014, IMAGE VISION COMPUT, V32, P1161, DOI 10.1016/j.imavis.2013.12.014
   Gao XF, 2007, LECT NOTES COMPUT SC, V4642, P242
   Gottemukkula V, 2012, 2012 IEEE INTERNATIONAL CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, P150, DOI 10.1109/THS.2012.6459841
   He K., 2016, PROC CVPR IEEE, P770, DOI [10.1109/CVPR.2016.90, DOI 10.1109/CVPR.2016.90]
   HESS R., 2010, P INT C MULTIMEDIA, P1493, DOI DOI 10.1145/1873951.1874256
   Hyvärinen A, 2009, COMPUT IMAGING VIS, V39, P1
   Kannala J, 2012, INT C PATT RECOG, P1363
   Kiran N, 2016, IEEE I C NETW INFRAS, P6, DOI 10.1109/ICNIDC.2016.7974526
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Narvekar ND, 2011, IEEE T IMAGE PROCESS, V20, P2678, DOI 10.1109/TIP.2011.2131660
   Ngiam J., 2011, Advances in Neural Information Processing Systems, V24
   Ojansivu V, 2008, LECT NOTES COMPUT SC, V5099, P236, DOI 10.1007/978-3-540-69905-7_27
   OPPENHEIM AV, 1981, P IEEE, V69, P529, DOI 10.1109/PROC.1981.12022
   Padole C. N., 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P439, DOI 10.1109/ICB.2012.6199790
   Park M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICUWB 2009), P1, DOI 10.1109/ICUWB.2009.5288737
   Park U, 2011, IEEE T INF FOREN SEC, V6, P96, DOI 10.1109/TIFS.2010.2096810
   Pietikinen M., 2015, Advances in Independent Component Analysis and Learning Machines, P175
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Proença H, 2018, IEEE T INF FOREN SEC, V13, P888, DOI 10.1109/TIFS.2017.2771230
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1529, DOI 10.1109/TPAMI.2009.66
   Raghavendra R, 2016, IEEE CONF IMAGING SY, P201, DOI 10.1109/IST.2016.7738223
   Raghavendra R, 2013, 2013 SECOND IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION (ACPR 2013), P155, DOI 10.1109/ACPR.2013.22
   Raja KB, 2017, PATTERN RECOGN LETT, V91, P27, DOI 10.1016/j.patrec.2016.12.025
   Raja KB, 2015, PATTERN RECOGN LETT, V57, P33, DOI 10.1016/j.patrec.2014.09.006
   Raja KB, 2014, 2014 IEEE WORKSHOP ON BIOMETRIC MEASUREMENTS AND SYSTEMS FOR SECURITY AND MEDICAL APPLICATIONS (BIOMS) PROCEEDINGS, P15, DOI 10.1109/BIOMS.2014.6951530
   Rattani A, 2017, IMAGE VISION COMPUT, V59, P1, DOI 10.1016/j.imavis.2016.11.019
   Rattani A, 2016, IEEE IMAGE PROC, P320, DOI 10.1109/ICIP.2016.7532371
   Santos G, 2015, PATTERN RECOGN LETT, V57, P52, DOI 10.1016/j.patrec.2014.09.012
   Shirvaikar MV, 2004, SE SYM SYS THRY, P472
   Sun Y, 2013, IEEE I CONF COMP VIS, P1489, DOI 10.1109/ICCV.2013.188
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Tan CW, 2012, INT C PATT RECOG, P553
   Tapia J., 2019, SELFIE BIOMETRICS, P227, DOI DOI 10.1007/978-3-030-26972-2_11
   Tapia J., 2019, ARXIV190500372
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wasnik P, 2017, I W BIOMETRIC FORENS
   Woodard Damon L., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P201, DOI 10.1109/ICPR.2010.58
   Zhang L, 2011, IEEE I CONF COMP VIS, P471, DOI 10.1109/ICCV.2011.6126277
   Zohra FT, 2017, 2017 IEEE 16TH INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS & COGNITIVE COMPUTING (ICCI*CC), P130, DOI 10.1109/ICCI-CC.2017.8109741
NR 52
TC 14
Z9 14
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2020
VL 101
AR 103979
DI 10.1016/j.imavis.2020.103979
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NP4HG
UT WOS:000570137900009
OA hybrid
DA 2024-07-18
ER

PT J
AU Riquelme, F
   De Goyeneche, A
   Zhang, YD
   Niebles, JC
   Soto, A
AF Riquelme, Felipe
   De Goyeneche, Alfredo
   Zhang, Yundong
   Niebles, Juan Carlos
   Soto, Alvaro
TI Explaining VQA predictions using visual grounding and a knowledge base
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep Learning; Attention; Supervision; Knowledge Base; Interpretability;
   Explainability
ID ATTENTION
AB In this work, we focus on the Visual Question Answering (VQA) task, where a model must answer a question based on an image, and the VQA-Explanations task, where an explanation is produced to support the answer. We introduce an interpretable model capable of pointing out and consuming information from a novel Knowledge Base (KB) composed of real-world relationships between objects, along with labels mined from available region descriptions and object annotations. Furthermore, this model provides a visual and textual explanations to complement the KB visualization. The use of a KB brings two important consequences: enhance predictions and improve interpretability. We achieve this by introducing a mechanism that can extract relevant information from this KB, and can point out the relations better suited for predicting the answer. A supervised attention map is generated over the KB to select the relevant relationships from it for each question-image pair. Moreover, we add image attention supervision on the explanations module to generate better visual and textual explanations. We quantitatively show that the predicted answers improve when using the KB; similarly, explanations improve with this and when adding image attention supervision. Also, we qualitatively show that the KB attention helps to improve interpretability and enhance explanations. Overall, the results support the benefits of having multiple tasks to enhance the interpretability and performance of the model. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Riquelme, Felipe; De Goyeneche, Alfredo; Soto, Alvaro] Pontificia Univ Catolica Chile, Santiago, Chile.
   [Zhang, Yundong; Niebles, Juan Carlos] Stanford Univ, Stanford, CA 94305 USA.
C3 Pontificia Universidad Catolica de Chile; Stanford University
RP Riquelme, F; De Goyeneche, A (corresponding author), Pontificia Univ Catolica Chile, Santiago, Chile.
EM fariquelme@uc.cl; asdegoyeneche@uc.cl
RI Niebles, Juan Carlos/AAT-5882-2021; Soto, Alvaro M/D-1406-2014
OI Niebles, Juan Carlos/0000-0001-8225-9793; De Goyeneche Macaya,
   Alfredo/0000-0002-1550-280X
FU Fondecyt Grant, Chile [1181739]; Millennium Institute for Foundational
   Research on Data, Chile
FX This work was partially funded by Fondecyt Grant 1181739, Chile and
   Millennium Institute for Foundational Research on Data, Chile.
CR Anderson P, 2016, LECT NOTES COMPUT SC, V9909, P382, DOI 10.1007/978-3-319-46454-1_24
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bahdanau Dzmitry, 2015, 3 INT C LEARN REP IC
   Bird S., 2004, NLTK: The Natural Language Toolkit, P214
   Biswas P, 2005, I CONF VLSI DESIGN, P651
   Das A, 2017, COMPUT VIS IMAGE UND, V163, P90, DOI 10.1016/j.cviu.2017.10.001
   Fukui Akira, 2016, P C EMP METH NAT LAN
   Gan C, 2017, IEEE I CONF COMP VIS, P1829, DOI 10.1109/ICCV.2017.201
   Goodman B, 2017, AI MAG, V38, P50, DOI 10.1609/aimag.v38i3.2741
   Goyal Y, 2019, INT J COMPUT VISION, V127, P398, DOI 10.1007/s11263-018-1116-0
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Jin Xin, 2010, ENCY MACHINE LEARNIN, P563, DOI [10.1007/978-0-387-30164-8_425, DOI 10.1007/978-0-387-30164-8_425]
   Kim J, 2018, LECT NOTES COMPUT SC, V11206, P577, DOI 10.1007/978-3-030-01216-8_35
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Lin CY, 2004, ROUGE: A Package for Automatic Evaluation of Summaries, P74, DOI DOI 10.1253/JCJ.34.1213
   Lu JS, 2016, ADV NEUR IN, V29
   Miller A., 2016, P 2016 C EMP METH NA, P1400, DOI DOI 10.18653/V1/D16-1147
   MILLER GA, 1995, COMMUN ACM, V38, P39, DOI 10.1145/219717.219748
   Narasimhan M, 2018, LECT NOTES COMPUT SC, V11212, P460, DOI 10.1007/978-3-030-01237-3_28
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   Park DH, 2018, PROC CVPR IEEE, P8779, DOI 10.1109/CVPR.2018.00915
   Pennington J., 2014, P 2014 C EMP METH NA, P1532
   Qiao TT, 2018, AAAI CONF ARTIF INTE, P7300
   Redmon J., 2018, P IEEE C COMP VIS PA
   Rubner Y, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P59, DOI 10.1109/ICCV.1998.710701
   Shrivastava A, 2016, PROCEEDINGS OF THE 10TH INDIACOM - 2016 3RD INTERNATIONAL CONFERENCE ON COMPUTING FOR SUSTAINABLE GLOBAL DEVELOPMENT, P2378
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Su Z, 2018, PROC CVPR IEEE, P7736, DOI 10.1109/CVPR.2018.00807
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Vedantam R, 2015, PROC CVPR IEEE, P4566, DOI 10.1109/CVPR.2015.7299087
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wu Q, 2016, PROC CVPR IEEE, P4622, DOI 10.1109/CVPR.2016.500
   Yadav D., 2019, ABS190203570 CORR
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu Z, 2018, IEEE T NEUR NET LEAR, V29, P5947, DOI 10.1109/TNNLS.2018.2817340
   Yu Z, 2017, IEEE I CONF COMP VIS, P1839, DOI 10.1109/ICCV.2017.202
   Zhang YD, 2019, IEEE WINT CONF APPL, P349, DOI 10.1109/WACV.2019.00043
NR 37
TC 10
Z9 13
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2020
VL 101
AR 103968
DI 10.1016/j.imavis.2020.103968
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA NP4HG
UT WOS:000570137900006
DA 2024-07-18
ER

PT J
AU Gao, Y
   Li, QM
   Li, J
AF Gao, Yin
   Li, Qiming
   Li, Jun
TI Single image dehazing via a dual-fusion method
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image dehazing; Multi-region fusion; Exposure fusion; New speckle
   reducing anisotropic diffusion model
ID ENHANCEMENT; VISION; VISIBILITY
AB Single image dehazing is a challenging task because of the hue and brightness distortion problems. In this paper, we propose a dual-fusion method for single image dehazing. By a segmentation method creating two divided regions, the sky and non-sky regions can be obtained. To properly optimize the transmission, a multi-region fusion method is proposed for single image smooth. An exposure fusion method is constructed by the brightness transform function to effectively remove the haze from a single image. Experimental results show that this method outperforms state-of-the-art dehazing methods in terms of both efficiency and the dehazing effect. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Gao, Yin; Li, Qiming; Li, Jun] Chinese Acad Sci, Quanzhou Inst Equipment Mfg, Quanzhou, Peoples R China.
C3 Chinese Academy of Sciences
RP Li, J (corresponding author), Chinese Acad Sci, Quanzhou Inst Equipment Mfg, Quanzhou, Peoples R China.
EM junli@fjirsm.ac.cn
RI gao, Yin/D-4589-2019
FU National Key Research and Development Program of China [2016YFC11000502]
FX This work was supported by the National Key Research and Development
   Program of China Grant (no. 2016YFC11000502).
CR Abdullah-Al-Wadud M, 2007, IEEE T CONSUM ELECTR, V53, P593, DOI 10.1109/TCE.2007.381734
   [Anonymous], IEEE INT CONF COMPUT
   [Anonymous], 2015, INT J TECHNOLOGICAL
   Berman D, 2016, PROC CVPR IEEE, P1674, DOI 10.1109/CVPR.2016.185
   Bonde S., 2017, INT J OCEAN OCEAN, V11, P01
   Bui TM, 2018, IEEE T IMAGE PROCESS, V27, P999, DOI 10.1109/TIP.2017.2771158
   Cai BL, 2016, IEEE T IMAGE PROCESS, V25, P5187, DOI 10.1109/TIP.2016.2598681
   Chen C, 2016, LECT NOTES COMPUT SC, V9906, P576, DOI 10.1007/978-3-319-46475-6_36
   Chen XD, 2019, AMBIO, V48, P732, DOI 10.1007/s13280-018-1105-0
   Choi LK, 2015, IEEE T IMAGE PROCESS, V24, P3888, DOI 10.1109/TIP.2015.2456502
   Fattal R, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1360612.1360671
   Gangyi Wang, 2013, Information Technology Journal, V12, P1168, DOI 10.3923/itj.2013.1168.1175
   Guo XJ, 2017, IEEE T IMAGE PROCESS, V26, P982, DOI 10.1109/TIP.2016.2639450
   Hautiere Nicolas, 2008, Image Analysis & Stereology, V27, P87, DOI 10.5566/ias.v27.p87-95
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Huang JB, 2015, PROC CVPR IEEE, P5197, DOI 10.1109/CVPR.2015.7299156
   Kim JH, 2013, J VIS COMMUN IMAGE R, V24, P410, DOI 10.1016/j.jvcir.2013.02.004
   Kopf J, 2008, ACM T GRAPHIC, V27, DOI 10.1145/1409060.1409069
   Li BY, 2019, IEEE T IMAGE PROCESS, V28, P492, DOI 10.1109/TIP.2018.2867951
   Li Y, 2015, IEEE I CONF COMP VIS, P226, DOI 10.1109/ICCV.2015.34
   Liu Y, 2017, IEEE ACCESS, V5, P8890, DOI 10.1109/ACCESS.2017.2710305
   Lu HM, 2013, IEEE IMAGE PROC, P3412, DOI 10.1109/ICIP.2013.6738704
   Meng GF, 2013, IEEE I CONF COMP VIS, P617, DOI 10.1109/ICCV.2013.82
   Mittal A, 2013, IEEE SIGNAL PROC LET, V20, P209, DOI 10.1109/LSP.2012.2227726
   Narasimhan SG, 2002, INT J COMPUT VISION, V48, P233, DOI 10.1023/A:1016328200723
   Narasimhan SG, 2000, PROC CVPR IEEE, P598, DOI 10.1109/CVPR.2000.855874
   Nayar S. K., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P820, DOI 10.1109/ICCV.1999.790306
   Nishino K, 2012, INT J COMPUT VISION, V98, P263, DOI 10.1007/s11263-011-0508-1
   Oakley JP, 1998, IEEE T IMAGE PROCESS, V7, P167, DOI 10.1109/83.660994
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Tan RT, 2008, PROC CVPR IEEE, P2347, DOI 10.1109/cvpr.2008.4587643
   Tarel JP, 2012, IEEE INTEL TRANSP SY, V4, P6, DOI 10.1109/MITS.2012.2189969
   Tarel JP, 2009, IEEE I CONF COMP VIS, P2201, DOI 10.1109/ICCV.2009.5459251
   Xu Y, 2016, IEEE ACCESS, V4, P165, DOI 10.1109/ACCESS.2015.2511558
   Ying Z., 2017, BIOINSPIRED MULTIEXP, V14, P1
   Yu J, 2011, INT CONF ACOUST SPEE, P1245
   Yu YJ, 2002, IEEE T IMAGE PROCESS, V11, P1260, DOI 10.1109/TIP.2002.804279
NR 38
TC 17
Z9 21
U1 1
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103868
DI 10.1016/j.imavis.2019.103868
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900007
DA 2024-07-18
ER

PT J
AU Rehman, YAU
   Po, LM
   Komulainen, J
AF Rehman, Yasar Abbas Ur
   Po, Lai-Man
   Komulainen, Jukka
TI Enhancing deep discriminative feature maps via perturbation for face
   presentation attack detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Spoofing; Presentation attack detection; CNN; Attention; Face-biometrics
ID SPOOFING DETECTION; LIVENESS DETECTION; IMAGE QUALITY; TEXTURE
AB Face presentation attack detection (PAD) in unconstrained conditions is one of the key issues in face biometric-based authentication and security applications. In this paper, we propose a perturbation layer - a learnable preprocessing layer for low-level deep features to enhance the discriminative ability of deep features in face PAD. The perturbation layer takes the deep features - of a candidate layer in Convolutional Neural Network (CNN), the corresponding hand-crafted features of an input image, and produces adaptive convolutional weights for the deep features of the candidate layer. These adaptive convolutional weights determine the importance of the pixels in the deep features of the candidate layer for face PAD. The proposed perturbation layer adds very little overhead to the total trainable parameters in the model. We evaluated the proposed perturbation layer with Local Binary Patterns (LBP), with and without color information, on three publicly available face PAD databases, i.e., CASIA, Idiap Replay-Attack, and OULU-NPU databases. Our experimental results show that the introduction of the proposed perturbation layer in the CNN improved the face PAD performance, in both intra-database and cross-database scenarios. Our results also highlight the attention created by the proposed perturbation layer in the deep features and its effectiveness for face PAD in general. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Rehman, Yasar Abbas Ur; Po, Lai-Man] City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.
   [Komulainen, Jukka] Visidon Ltd, Oulu, Finland.
   [Rehman, Yasar Abbas Ur] TCL Corp Res Hong Kong Co Ltd, Hong Kong Sci Pk, Hong Kong, Peoples R China.
C3 City University of Hong Kong
RP Rehman, YAU (corresponding author), City Univ Hong Kong, Dept Elect Engn, Kowloon, Hong Kong, Peoples R China.
EM yaurehman2-c@my.cityu.edu.hk; eelmpo@my.cityu.edu.hk; yty@iki.fi
RI Komulainen, Jukka/O-6240-2017
OI Komulainen, Jukka/0000-0002-0102-7868; rehman, yasar/0000-0002-2945-7181
FU City University of Hong Kong [7004430]
FX Internal SRC Funding from the City University of Hong Kong substantially
   supported the work described in this paper under Project No. 7004430.
CR Agarwal A., 2016, INT CONF BIOMETR THE, P1
   Anjos A, 2014, IET BIOMETRICS, V3, P147, DOI 10.1049/iet-bmt.2012.0071
   [Anonymous], INT C BIOM ICB 12 IA
   [Anonymous], FACE PRESENTATION AT
   [Anonymous], IEEE T CONSUM ELECT
   [Anonymous], 2014, ABS14085601 CORR
   [Anonymous], 2015, P ICLR
   [Anonymous], LEARNING GEN IDENTIT
   [Anonymous], 1SC37 ISOIECJTC
   Atoum Y, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P319, DOI 10.1109/BTAS.2017.8272713
   Bhogal APS, 2017, 2017 5 INT WORKSH BI, P1
   Boulkenafet Z, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P688, DOI 10.1109/BTAS.2017.8272758
   Boulkenafet Z, 2018, IMAGE VISION COMPUT, V77, P1, DOI 10.1016/j.imavis.2018.04.007
   Boulkenafet Z, 2016, IEEE T INF FOREN SEC, V11, P1818, DOI 10.1109/TIFS.2016.2555286
   Boulkenafet Z, 2015, IEEE IMAGE PROC, P2636, DOI 10.1109/ICIP.2015.7351280
   Boulkenafet Z, 2017, IEEE INT CONF AUTOMA, P612, DOI 10.1109/FG.2017.77
   Chan PPK, 2018, IEEE T INF FOREN SEC, V13, P521, DOI 10.1109/TIFS.2017.2758748
   Chingovska Ivana, 2012, BIOSIG
   Nguyen DT, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18030699
   de Freitas Pereira Tiago, 2013, Biometrics (ICB), 2013 International Conference on, DOI DOI 10.1109/ICB.2013.6612981
   de Souza GB, 2017, IEEE T CIRCUITS-II, V64, P1397, DOI 10.1109/TCSII.2017.2764460
   Duan YQ, 2018, IEEE T PATTERN ANAL, V40, P1139, DOI 10.1109/TPAMI.2017.2710183
   Duan YQ, 2017, IEEE T IMAGE PROCESS, V26, P3636, DOI 10.1109/TIP.2017.2704661
   Feng LT, 2016, J ELECTRON IMAGING, V25, DOI 10.1117/1.JEI.25.4.043014
   Feng LT, 2016, J VIS COMMUN IMAGE R, V38, P451, DOI 10.1016/j.jvcir.2016.03.019
   Galbally J, 2014, IEEE T IMAGE PROCESS, V23, P710, DOI 10.1109/TIP.2013.2292332
   Gragnaniello D, 2015, IEEE T INF FOREN SEC, V10, P849, DOI 10.1109/TIFS.2015.2404294
   Jourabloo A, 2018, LECT NOTES COMPUT SC, V11217, P297, DOI 10.1007/978-3-030-01261-8_18
   Juefei-Xu F, 2018, PROC CVPR IEEE, P3310, DOI 10.1109/CVPR.2018.00349
   Kim W, 2015, IEEE T IMAGE PROCESS, V24, P2456, DOI 10.1109/TIP.2015.2422574
   Kollreider K, 2007, IEEE T INF FOREN SEC, V2, P548, DOI 10.1109/TIFS.2007.902037
   Komulainen J., 2019, Handbook of Biometric Anti-Spoofing: Presentation Attack Detection, P291
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kutyniok G, 2012, APPL NUMER HARMON AN, P1, DOI 10.1007/978-0-8176-8316-0
   Lakshminarayana N.N., 2017, IEEE ISBA, P1
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P2639, DOI 10.1109/TIFS.2018.2825949
   Li HL, 2018, IEEE T INF FOREN SEC, V13, P1794, DOI 10.1109/TIFS.2018.2801312
   Li L, 2018, J VIS COMMUN IMAGE R, V54, P182, DOI 10.1016/j.jvcir.2018.05.009
   Li L, 2017, IEEE IMAGE PROC, P101, DOI 10.1109/ICIP.2017.8296251
   Li L, 2017, CC'17: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON COMPILER CONSTRUCTION, P120, DOI 10.1145/3033019.3033029
   Liu YJ, 2018, PROC CVPR IEEE, P389, DOI 10.1109/CVPR.2018.00048
   Määttä J, 2012, IET BIOMETRICS, V1, P3, DOI 10.1049/iet-bmt.2011.0009
   Maatta J., 2011, 2011 INT JOINT C BIO, P1
   Manjani I, 2017, IEEE T INF FOREN SEC, V12, P1713, DOI 10.1109/TIFS.2017.2676720
   Marcel S., 2019, HDB BIOMETRIC ANTISP, V2nd
   Menotti D, 2015, IEEE T INF FOREN SEC, V10, P864, DOI 10.1109/TIFS.2015.2398817
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Patel K, 2015, INT CONF BIOMETR, P98, DOI 10.1109/ICB.2015.7139082
   Pereira TD, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-2
   Pinto A, 2015, IEEE T IMAGE PROCESS, V24, P4726, DOI 10.1109/TIP.2015.2466088
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Rehman Yasar Abbas Ur, 2020, International Joint Conference: 12th International Conference on Computational Intelligence in Security for Information Systems (CISIS 2019) and 10th International Conference on EUropean Transnational Education (ICEUTE 2019). Proceedings. Advances in Intelligent Systems and Computing (AISC 951), P3, DOI 10.1007/978-3-030-20005-3_1
   Sepas-Moghaddam A, 2018, IEEE T INF FOREN SEC, V13, P1696, DOI 10.1109/TIFS.2018.2799427
   Shao R, 2019, IEEE T INF FOREN SEC, V14, P923, DOI 10.1109/TIFS.2018.2868230
   Siddiqui TA, 2016, INT C PATT RECOG, P1035, DOI 10.1109/ICPR.2016.7899772
   Song X, 2019, PATTERN RECOGN, V85, P220, DOI 10.1016/j.patcog.2018.08.019
   Tian Y., 2016, P INT WORKSH DIG WAT, P16
   Tu XK, 2017, LECT NOTES COMPUT SC, V10635, P686, DOI 10.1007/978-3-319-70096-0_70
   Wen D, 2015, IEEE T INF FOREN SEC, V10, P746, DOI 10.1109/TIFS.2015.2400395
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Xu Y, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P497
   Xu ZQ, 2015, PROCEEDINGS 3RD IAPR ASIAN CONFERENCE ON PATTERN RECOGNITION ACPR 2015, P141, DOI 10.1109/ACPR.2015.7486482
   Yang X, 2019, PROC CVPR IEEE, P3502, DOI 10.1109/CVPR.2019.00362
   Zhiwei Zhang, 2012, 2012 5th IAPR International Conference on Biometrics (ICB), P26, DOI 10.1109/ICB.2012.6199754
   Zhou B, 2016, PROC CVPR IEEE, P2921, DOI 10.1109/CVPR.2016.319
NR 65
TC 9
Z9 9
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103858
DI 10.1016/j.imavis.2019.103858
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900002
DA 2024-07-18
ER

PT J
AU Huang, Q
   Wang, YX
   Yin, Z
AF Huang, Qiang
   Wang, Yongxiong
   Yin, Zhong
TI View-based weight network for 3D object recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE View-based weights layer; 3D object recognition; Extreme learning
   machine; Multi-channel integrated classifier
ID EXTREME LEARNING-MACHINE; NEURAL-NETWORKS
AB Projective methods generally achieve better results in 3D object recognition in recent years. This may be similar to that human visual 3D shapes rely on various 2D observations which are unconscious on retina. Each projection is treated fairly in existing methods. However, we note that different viewpoint images of the same object have different discriminative features, and only some of images are completely significant. We propose a novel View-based Weight Network (VWN) for 3D object recognition where the different view-based weights are assigned to different projections. The trainable view-level weights are incorporated as a pooling layer of the multi-view residual network. The pooling layer contains 7 sub-layers. Meanwhile, we find a simple unsupervised criterion to evaluate the prediction results before they output. To improve the recognition accuracy, a new multi-channel integrated classifier combining Extreme Learning Machine, KNN, SVM and Random Forest is proposed based on the criterion. The multi-channel classifier can make the accuracy of Top1 close to Top2. Experiments on Princeton ModelNet 3D datasets demonstrate our proposed method outperforms the state-of-the-art approaches significantly in recognition accuracy. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Huang, Qiang; Wang, Yongxiong; Yin, Zhong] Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
   [Wang, Yongxiong; Yin, Zhong] Shanghai Engn Res Ctr Assist Devices, Shanghai, Peoples R China.
C3 University of Shanghai for Science & Technology
RP Wang, YX (corresponding author), Univ Shanghai Sci & Technol, Sch Opt Elect & Comp Engn, Shanghai, Peoples R China.
EM wyxiong@usstedu.cn
RI Yuan, Yu/KBQ-0606-2024
FU National Natural Science Foundation of China [61673276]
FX This work was supported by the National Natural Science Foundation of
   China (61673276).
CR [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ASS ADV ART INT C AA
   [Anonymous], BRIT MACH VIS C BMVC
   [Anonymous], 2016, Computer Science
   Biasotti S, 2008, THEOR COMPUT SCI, V392, P5, DOI 10.1016/j.tcs.2007.10.018
   Chen W, 2019, NEUROCOMPUTING, V346, P3, DOI 10.1016/j.neucom.2018.08.088
   Cheraghian A, 2019, IEEE WINT CONF APPL, P1194, DOI 10.1109/WACV.2019.00132
   Dominguez M, 2018, IEEE WINT CONF APPL, P1972, DOI 10.1109/WACV.2018.00218
   Feng YF, 2018, PROC CVPR IEEE, P264, DOI 10.1109/CVPR.2018.00035
   Gao Y, 2010, NEUROCOMPUTING, V73, P1900, DOI 10.1016/j.neucom.2009.11.050
   Han ZZ, 2019, IEEE T IMAGE PROCESS, V28, P3986, DOI 10.1109/TIP.2019.2904460
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jégou H, 2009, PROC CVPR IEEE, P1169, DOI 10.1109/CVPRW.2009.5206609
   Johns E, 2016, PROC CVPR IEEE, P3813, DOI 10.1109/CVPR.2016.414
   Kasaei H, 2019, ARXIV190203057
   Khan SH, 2019, PROC CVPR IEEE, P9731, DOI 10.1109/CVPR.2019.00997
   Klokov R, 2017, IEEE I CONF COMP VIS, P863, DOI 10.1109/ICCV.2017.99
   Kumawat S, 2019, PROC CVPR IEEE, P4898, DOI 10.1109/CVPR.2019.00504
   Liu SK, 2018, INT CONF 3D VISION, P542, DOI 10.1109/3DV.2018.00068
   Liu YC, 2019, PROC CVPR IEEE, P8887, DOI 10.1109/CVPR.2019.00910
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sarkar Kripasindhu, 2018, P EUR C COMP VIS ECC, P71
   Silberman N, 2012, LECT NOTES COMPUT SC, V7576, P746, DOI 10.1007/978-3-642-33715-4_54
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song SR, 2015, PROC CVPR IEEE, P567, DOI 10.1109/CVPR.2015.7298655
   Su H, 2015, IEEE I CONF COMP VIS, P945, DOI 10.1109/ICCV.2015.114
   Tevs A, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2601097.2601220
   Wang YQ, 2016, NEUROCOMPUTING, V174, P988, DOI 10.1016/j.neucom.2015.10.035
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xiao JX, 2013, IEEE I CONF COMP VIS, P1625, DOI 10.1109/ICCV.2013.458
   Xie JW, 2018, PROC CVPR IEEE, P8629, DOI 10.1109/CVPR.2018.00900
   Xie ZG, 2015, COMPUT GRAPH FORUM, V34, P1, DOI 10.1111/cgf.12740
   Yang YQ, 2018, PROC CVPR IEEE, P206, DOI 10.1109/CVPR.2018.00029
   Yu T, 2018, PROC CVPR IEEE, P186, DOI 10.1109/CVPR.2018.00027
   Zaheer Manzil, 2017, P ADV NEURAL INFORM, P3391
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang Kuangen., 2019, ARXIV190410014
NR 40
TC 10
Z9 11
U1 1
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103828
DI 10.1016/j.imavis.2019.11.006
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000015
DA 2024-07-18
ER

PT J
AU Narayan, N
   Sankaran, N
   Setlur, S
   Govindaraju, V
AF Narayan, Neeti
   Sankaran, Nishant
   Setlur, Srirangaraj
   Govindaraju, Venu
TI Learning deep features for online person tracking using non-overlapping
   cameras: A survey
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Online person tracking; Re-identification; Surveillance; Deep features;
   Recurrent neural network
ID NETWORK
AB Target-agnostic person tracking and re-identification across multiple non-overlapping cameras is an open vision problem. It is the task of maintaining the correct identity of people at different time instances and possibly different cameras. This study focuses on existing algorithms that facilitate online person tracking by using discriminative spatio-temporal features from video data, and presents the open issues and future research directions. The initial take on the problem introduces person tracking as a pure association problem, where the influence of human appearance, biometric and location information on re-identification are addressed explicitly. These constraints are modeled and used to understand and associate detections in real world environments. Next, a spatio-temporal model using LSTM networks for propagating associations and recovering from errors by taking advantage of the spatial and temporal information in videos is described. The spatio-temporal context indicates a way for discriminative appearance learning. The novelty of the mentioned approaches is that they do not require to learn target-specific appearance models and collect samples to distinguish different people from each other. The methods are evaluated on large-scale tracking datasets. State-of-the-art performance is achieved using motion metadata such as person bounding box and camera number, and shows better associations for the challenging exit-entry cases. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Narayan, Neeti; Sankaran, Nishant; Setlur, Srirangaraj; Govindaraju, Venu] Univ Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
C3 State University of New York (SUNY) System; State University of New York
   (SUNY) Buffalo
RP Narayan, N (corresponding author), Univ Buffalo, Dept Comp Sci & Engn, Buffalo, NY 14260 USA.
EM neetinar@buffalo.edu
RI Setlur, Srirangaraj/F-9034-2015
OI Setlur, Srirangaraj/0000-0002-7118-9280
FU National Science Foundation [1266183]; Division Of Computer and Network
   Systems; Direct For Computer & Info Scie & Enginr [1266183] Funding
   Source: National Science Foundation
FX This material is based upon work supported by the National Science
   Foundation under Grant IIP #1266183.
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Alahi A, 2016, PROC CVPR IEEE, P961, DOI 10.1109/CVPR.2016.110
   [Anonymous], 2017, AAAI
   [Anonymous], 2017, IEEE C COMP VIS PATT
   [Anonymous], COMPUT VIS PATTERN R
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, ARXIV150406852
   [Anonymous], 2009, BMVC
   [Anonymous], 2012, BRIT MACH VIS C
   [Anonymous], 2009, 12 IEEE INT WORKSH P
   [Anonymous], 2011, P JOINT ACM WORKSH H
   [Anonymous], 2016, ARXIV161106026
   [Anonymous], 2016, EUR C COMP VIS ECCV
   [Anonymous], 2017, INT CONF SEMANT, DOI DOI 10.1109/SKG.2017.00009
   [Anonymous], 2017, ARXIV170907065
   [Anonymous], 2008, EUR C COMP VIS ECCV
   [Anonymous], 2008, EUR C COMP VIS ECCV
   Ardeshir S., 2016, EUR C COMP VIS ECCV, V8, P253
   Barbosa I. B., 2012, EUR C COMP VIS ECCV, V7, P433
   Bialkowski A., 2012, DATABASE PERSON REID
   Cai Q, 2018, GEOTECH LETT, V8, P56, DOI 10.1680/jgele.17.00160
   Cai YS, 2008, CHINA QUART, P24, DOI 10.1017/S0305741008000027
   Chen K. W., 2008, IEEE C COMP VIS PATT, V23, P1
   Chen WH, 2017, IEEE T CIRC SYST VID, V27, P2367, DOI 10.1109/TCSVT.2016.2589619
   Chen XJ, 2015, IEEE SENS J, V15, P2692, DOI 10.1109/JSEN.2015.2392781
   Cheng DS, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.68
   Cho Y.J., 2017, ARXIV171000983, P3
   Das A., 2014, EUR C COMP VIS ECCV, V6, P330
   DEHGHAN A, 2015, PROC CVPR IEEE, P4091, DOI DOI 10.1109/CVPR.2015
   Dicle C, 2013, IEEE I CONF COMP VIS, P2304, DOI 10.1109/ICCV.2013.286
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Fujita T, 2014, PAC J MATH IND, V6, DOI 10.1186/s40736-014-0002-0
   Gilbert A., 2006, EUR C COMP VIS ECCV, V7, P125
   Huang C., 2008, EUR C COMP VIS ECCV, V12, P788
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Khan SM, 2006, LECT NOTES COMPUT SC, V3954, P133
   Kingma DP., 2014, ADAM METHOD STOCHAST
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kuo C. H., 2010, INTERCAMERA ASS MULT, P383
   Li W, 2014, PROC CVPR IEEE, P152, DOI 10.1109/CVPR.2014.27
   Liao SC, 2015, PROC CVPR IEEE, P2197, DOI 10.1109/CVPR.2015.7298832
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Makris D., 2004, 27 P IEEE COMP SOC C, V2, pII
   Mazzon R, 2012, PATTERN RECOGN LETT, V33, P1828, DOI 10.1016/j.patrec.2012.02.014
   Narayan N., 2017, COMP VIS PATT REC WO, V21, P566
   Narayan N., 2018, ARXIV181106582
   Narayan Neeti., 2018, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, P1438
   Per J., 2012, 9 INT C ADV VID SIGN, V18, P64
   Qin Z, 2012, PROC CVPR IEEE, P1972, DOI 10.1109/CVPR.2012.6247899
   Ristani E., 2016, EUR C COMP VIS ECCV, V8, P17
   Ristani E, 2018, PROC CVPR IEEE, P6036, DOI 10.1109/CVPR.2018.00632
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sadeghian A., 2017, INT C COMP VIS ICCV
   Shafique K., 2008, APPL COMPUTER VISION, V7, P1
   Simonyan K., 2014, 14091556 ARXIV
   Song B, 2008, IEEE J-STSP, V2, P582, DOI 10.1109/JSTSP.2008.925992
   Stauffer C., 2005, Proc. IEEE Comp. Soc. Wkshp. Motion and Video Computing, P96
   Sun YF, 2017, IEEE I CONF COMP VIS, P3820, DOI 10.1109/ICCV.2017.410
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Xing JL, 2009, PROC CVPR IEEE, P1200, DOI 10.1109/CVPRW.2009.5206745
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   You JJ, 2016, PROC CVPR IEEE, P1345, DOI 10.1109/CVPR.2016.150
   Zhang S, 2015, IEEE WINT CONF APPL, P365, DOI 10.1109/WACV.2015.55
   ZHAO H, 2017, P IEEE C COMP VIS PA, V1, P1077
   Zhao R, 2013, IEEE I CONF COMP VIS, P2528, DOI 10.1109/ICCV.2013.314
   Zheng L, 2015, IEEE I CONF COMP VIS, P1116, DOI 10.1109/ICCV.2015.133
   Zheng ZD, 2017, IEEE I CONF COMP VIS, P3774, DOI 10.1109/ICCV.2017.405
NR 68
TC 4
Z9 5
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 222
EP 235
DI 10.1016/j.imavis.2019.07.007
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900019
OA Bronze
DA 2024-07-18
ER

PT J
AU Ahmed, M
   Laskar, RH
AF Ahmed, Manir
   Laskar, Rabul Hussain
TI Eye center localization in a facial image based on geometric shapes of
   iris and eyelid under natural variability
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Eye detection; Eye localization; Shape analysis; Image gradients
ID ROBUST
AB The estimation of the human eye centers is one of the important step in several computer vision applications such as driver drowsiness detection, eye tracking, face recognition etc. Most of the existing techniques are able to localize eyes in frontal faces only while they fail to localize eye pairs in complex scenarios such as changes in head pose, scale, and illumination. In this paper, an eye localization method has been proposed that can locate the eye centers more precisely in facial images captured under the above-mentioned complexities. The proposed method consists of three stages: eye candidate detection, eye candidate verification, and post-processing. In eye candidate detection, the possible eye candidates are extracted using two new features namely Semi-Circular Edge Shape (sCES) and Semi-Ellipse Edge Shape (sEES) features. These features take into consideration the semi-circular and semi-ellipse edges of iris and eyelid and hence are able to localize eye centers more precisely. In verification, the extracted eye candidates are verified using a Support Vector Machine (SVM) based classifier. A scale-space framework is also included in the verification stage to handle the scale variations of images. In post-processing, the eye centers are paired using some geometrical constraints and then a modified gradient-based method is proposed to detect the required eye pair. The proposed system is evaluated on different databases to check its robustness to changes in head pose, scale, illumination etc. The experimental results suggest that the proposed method shows better accuracy in challenging environments and also outperforms some state-of-the-art methods. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Ahmed, Manir; Laskar, Rabul Hussain] Natl Inst Technol Silchar, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Silchar
RP Ahmed, M (corresponding author), Natl Inst Technol Silchar, Dept Elect & Commun Engn, Silchar 788010, Assam, India.
EM manirahmed02@gmail.com
RI Laskar, Rabul Hussain/AFU-7180-2022; Ahmed, Manir/V-1775-2019
OI Laskar, Rabul Hussain/0000-0003-3988-394X; Ahmed,
   Manir/0000-0003-2775-7452
FU Visvesvaraya Ph.D. Scheme of MietY, Government of India
FX This research work has been carried out in the SIP Lab, NIT Silchar,
   India, and is supported by Visvesvaraya Ph.D. Scheme of MietY,
   Government of India. Moreover, the author would like to thank Mr.
   Mohammad Azharuddin Laskar of the same lab for his valuable suggestions.
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Alonso-Fernandez F, 2016, PATTERN RECOGN LETT, V82, P92, DOI 10.1016/j.patrec.2015.08.026
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2010, P INT MULT ENG COMP
   [Anonymous], P INT JOINT C BIOM
   [Anonymous], 2006, BMVC
   [Anonymous], 2015, INT J COMPUT APPL
   Baek SJ, 2013, IEEE T CONSUM ELECTR, V59, P415, DOI 10.1109/TCE.2013.6531125
   Borza D, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16071105
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Daugman J, 2009, ESSENTIAL GUIDE TO IMAGE PROCESSING, 2ND EDITION, P715, DOI 10.1016/B978-0-12-374457-9.00025-1
   de Oliveira LS, 2012, IEEE SYS MAN CYBERN, P840, DOI 10.1109/ICSMC.2012.6377832
   Everingham M, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P441
   Farkas LG, 2005, J CRANIOFAC SURG, V16, P615, DOI 10.1097/01.scs.0000171847.58031.9e
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   George A, 2016, IET COMPUT VIS, V10, P660, DOI 10.1049/iet-cvi.2015.0316
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Hamouz M, 2005, IEEE T PATTERN ANAL, V27, P1490, DOI 10.1109/TPAMI.2005.179
   Horng W. B., 2012, WSEAS T INF SCI APPL, V9
   Ito Y, 2012, INT C PATT RECOG, P1795
   Jesorsky O, 2001, LECT NOTES COMPUT SC, V2091, P90
   Jo J, 2014, EXPERT SYST APPL, V41, P1139, DOI 10.1016/j.eswa.2013.07.108
   Jo J, 2011, OPT ENG, V50, DOI 10.1117/1.3657506
   Kim H, 2017, IMAGE VISION COMPUT, V57, P147, DOI 10.1016/j.imavis.2016.10.003
   Kroon B, 2009, COMPUT VIS IMAGE UND, V113, P921, DOI 10.1016/j.cviu.2009.03.013
   Leo M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0102829
   Liang L, 2008, LECT NOTES COMPUT SC, V5303, P72, DOI 10.1007/978-3-540-88688-4_6
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Monzo D, 2011, MACH VISION APPL, V22, P471, DOI 10.1007/s00138-010-0273-0
   Ponz V, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P681
   Ren Y, 2014, IEEE T IMAGE PROCESS, V23, P226, DOI 10.1109/TIP.2013.2287614
   Ross A., 2004, P BIOM CONS C BCC, P1
   Shan SG, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P314
   Shih MY, 2005, IMAGE VISION COMPUT, V23, P441, DOI 10.1016/j.imavis.2004.11.005
   Skodras E, 2015, IMAGE VISION COMPUT, V36, P51, DOI 10.1016/j.imavis.2015.01.006
   Song FY, 2013, PATTERN RECOGN, V46, P3157, DOI 10.1016/j.patcog.2013.05.009
   Tan XY, 2009, PROC CVPR IEEE, P1621, DOI 10.1109/CVPRW.2009.5206818
   Timm F, 2011, VISAPP 2011: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, P125
   Valenti R, 2012, IEEE T PATTERN ANAL, V34, P1785, DOI 10.1109/TPAMI.2011.251
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang JG, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P136
   Xiong F, 2007, LECT NOTES COMPUT SC, V4679, P87
   Ye ZF, 2012, UBICOMP'12: PROCEEDINGS OF THE 2012 ACM INTERNATIONAL CONFERENCE ON UBIQUITOUS COMPUTING, P699
NR 46
TC 11
Z9 11
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 52
EP 66
DI 10.1016/j.imavis.2019.05.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400006
DA 2024-07-18
ER

PT J
AU Raitoharju, J
   Riabchenko, E
   Ahmad, I
   Iosifidis, A
   Gabbouj, M
   Kiranyaz, S
   Tirronen, V
   Arje, J
   Kärkkäinen, S
   Meissner, K
AF Raitoharju, Jenni
   Riabchenko, Ekaterina
   Ahmad, Iftikhar
   Iosifidis, Alexandros
   Gabbouj, Moncef
   Kiranyaz, Serkan
   Tirronen, Ville
   Arje, Johanna
   Karkkainen, Salme
   Meissner, Kristian
TI Benchmark database for fine-grained image classification of benthic
   macroinvertebrates
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biomonitoring; Fine-grained classification; Benthic macroinvertebrates;
   Deep learning; Convolutional Neural Networks
ID WATER; IDENTIFICATION; BIODIVERSITY; MACHINE
AB Managing the water quality of freshwaters is a crucial task worldwide. One of the most used methods to biomonitor water quality is to sample benthic macroinvertebrate communities, in particular to examine the presence and proportion of certain species. This paper presents a benchmark database for automatic visual classification methods to evaluate their ability for distinguishing visually similar categories of aquatic macroinvertebrate taxa. We make publicly available a new database, containing 64 types of freshwater macroinvertebrates, ranging in number of images per category from 7 to 577. The database is divided into three datasets, varying in number of categories (64, 29, and 9 categories). Furthermore, in order to accomplish a baseline evaluation performance, we present the classification results of Convolutional Neural Networks (CNNs) that are widely used for deep learning tasks in large databases. Besides CNNs, we experimented with several other well-known classification methods using deep features extracted from the data. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Raitoharju, Jenni; Riabchenko, Ekaterina; Ahmad, Iftikhar; Iosifidis, Alexandros; Gabbouj, Moncef] Tampere Univ Technol, Lab Signal Proc, Tampere, Finland.
   [Kiranyaz, Serkan] Qatar Univ, Dept Elect Engn, Doha, Qatar.
   [Tirronen, Ville] Univ Jyvaskyla, Fac Informat Technol, Jyvaskyla, Finland.
   [Arje, Johanna; Karkkainen, Salme] Univ Jyvaskyla, Dept Math & Stat, Jyvaskyla, Finland.
   [Meissner, Kristian] Finnish Environm Inst, Freshwater Ctr, Jyvaskyla, Finland.
C3 Tampere University; Qatar University; University of Jyvaskyla;
   University of Jyvaskyla; Finnish Environment Institute
RP Raitoharju, J (corresponding author), Tampere Univ Technol, Lab Signal Proc, Tampere, Finland.
EM jenni.raitoharju@tut.fi
RI Ahmad, Mirza Iftikhar/KHD-2053-2024; Kiranyaz, Serkan/AAK-1416-2021;
   Ahmad, iftikhar/I-6826-2015; Gabbouj, Moncef/G-4293-2014; Iosifidis,
   Alexandros/G-2433-2013; Meissner, Kristian/E-8390-2014
OI Gabbouj, Moncef/0000-0002-9788-2323; Iosifidis,
   Alexandros/0000-0003-4807-1345; Arje, Johanna/0000-0003-0710-9044;
   Meissner, Kristian/0000-0001-6316-8554; Raitoharju,
   Jenni/0000-0003-4631-9298; kiranyaz, serkan/0000-0003-1551-3397
FU Academy of Finland [288584, 289076, 289104]; Academy of Finland (AKA)
   [289104, 288584, 289076] Funding Source: Academy of Finland (AKA)
FX The authors would like to thank the Academy of Finland for the grants
   nos. 288584, 289076, and 289104 funding the DETECT consortium's project
   (Advanced Computational and Statistical Techniques for Biomonitoring and
   Aquatic Ecosystem Service Management).
CR Agarwal S, 2002, LECT NOTES COMPUT SC, V2353, P113
   [Anonymous], 2011, 2IEEE WORKSH APPL CO, DOI DOI 10.1109/WACV.2011.5711522
   Ärje J, 2013, ENVIRONMETRICS, V24, P248, DOI 10.1002/env.2208
   Berg T, 2014, PROC CVPR IEEE, P2019, DOI 10.1109/CVPR.2014.259
   Birk S, 2012, ECOL INDIC, V18, P31, DOI 10.1016/j.ecolind.2011.10.009
   Boser B. E., 1992, Proceedings of the Fifth Annual ACM Workshop on Computational Learning Theory, P144, DOI 10.1145/130385.130401
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Culverhouse PF, 2007, ECOL INFORM, V2, P361, DOI 10.1016/j.ecoinf.2007.07.001
   Culverhouse PF, 2014, MAR BIOL RES, V10, P73, DOI 10.1080/17451000.2013.810762
   Dudgeon D, 2006, BIOL REV, V81, P163, DOI 10.1017/S1464793105006950
   Elbrecht V, 2017, METHODS ECOL EVOL, V8, P1265, DOI 10.1111/2041-210X.12789
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Haase P, 2010, J N AM BENTHOL SOC, V29, P1279, DOI 10.1899/09-183.1
   He HB, 2009, IEEE T KNOWL DATA EN, V21, P1263, DOI 10.1109/TKDE.2008.239
   Hooper DU, 2012, NATURE, V486, P105, DOI 10.1038/nature11118
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Iosifidis A, 2016, IEEE T CYBERNETICS, V46, P311, DOI 10.1109/TCYB.2015.2401973
   Joutsijoki Henry, 2012, Machine Learning and Data Mining in Pattern Recognition. Proceedings 8th International Conference, MLDM 2012, P439, DOI 10.1007/978-3-642-31537-4_35
   Joutsijoki H, 2014, ECOL INFORM, V20, P1, DOI 10.1016/j.ecoinf.2014.01.004
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Kiranyaz S, 2011, COMPUT BIOL MED, V41, P463, DOI 10.1016/j.compbiomed.2011.04.008
   Kiranyaz S, 2010, IEEE IMAGE PROC, P2257, DOI 10.1109/ICIP.2010.5651161
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kumar N, 2012, LECT NOTES COMPUT SC, V7573, P502, DOI 10.1007/978-3-642-33709-3_36
   Lin J., 2011, P 1 WORKSH FIN GRAIN, V1
   Lin YL, 2014, LECT NOTES COMPUT SC, V8692, P466, DOI 10.1007/978-3-319-10593-2_31
   Liu JX, 2012, LECT NOTES COMPUT SC, V7572, P172, DOI 10.1007/978-3-642-33718-5_13
   Lytle DA, 2010, J N AM BENTHOL SOC, V29, P867, DOI 10.1899/09-080.1
   Meissner K., 2017, REPORTS FINNISH ENV
   Millennium Ecosystem Assessment Panel, 2005, ECOSYSTEMS HUMAN WEL, V5
   Nilsback M.E., 2006, IEEE C COMP VIS PATT, P1447, DOI DOI 10.1109/CVPR.2006.42
   Nilsson C, 2005, SCIENCE, V308, P405, DOI 10.1126/science.1107887
   Otsu N., 2007, IEEE T SYS MAN CYBER, V9, P66, DOI [DOI 10.1109/TSMC.1979.4310076, 10.1109/TSMC.1979.4310076]
   Raitoharju J, 2016, 2016 ICPR 2ND WORKSHOP ON COMPUTER VISION FOR ANALYSIS OF UNDERWATER IMAGERY (CVAUI 2016), P43, DOI [10.1109/CVAUI.2016.020, 10.1109/CVAUI.2016.20]
   Riabchenko E., 2016, P INT C PATT C PATT
   Rochatte S., 2012, SYNDEX REPORT EUROPE
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Van Horn G, 2015, PROC CVPR IEEE, P595, DOI 10.1109/CVPR.2015.7298658
   Vedaldi A., 2013, Technical report
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Vedaldi A, 2014, PROC CVPR IEEE, P3622, DOI 10.1109/CVPR.2014.463
   Xenopoulos MA, 2005, GLOBAL CHANGE BIOL, V11, P1557, DOI 10.1111/j.1365-2486.2005.001008.x
NR 44
TC 26
Z9 27
U1 2
U2 24
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2018
VL 78
BP 73
EP 83
DI 10.1016/j.imavis.2018.06.005
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA GV5LO
UT WOS:000446143900006
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Li, F
   Jia, X
   Xiang, C
   Lu, HC
AF Li, Fu
   Jia, Xu
   Xiang, Cheng
   Lu, Huchuan
TI Visual tracking with structured patch-based model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Structural information; Patch-based model; Linear
   programming
AB In this paper, we present a novel structured patch-based visual tracking method, which models the appearance of individual patches and their structural relationships within a unified framework. Specifically, this framework is defined as an optimal patch selection task, and can be further formulated as a linear programming problem, tractable and efficient in tracking scenario. To account for the changing appearance of the target object during tracking process, a pyramid local covariance descriptor is proposed to fuse multiple image characteristics. We compare the proposed method with other competing trackers by the recent large-scale benchmark. Extensive experimental results demonstrate that our tracker performs favorably against the state-of-the-art tracking algorithms. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Li, Fu; Lu, Huchuan] Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116023, Peoples R China.
   [Jia, Xu] Katholieke Univ Leuven, ESAT PSI VISICS, Leuven, Belgium.
   [Xiang, Cheng] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore, Singapore.
C3 Dalian University of Technology; KU Leuven; National University of
   Singapore
RP Lu, HC (corresponding author), Dalian Univ Technol, Sch Informat & Commun Engn, Dalian 116023, Peoples R China.
EM lhchuan@dlut.edu.cn
RI Xiang, Cheng/JSL-4858-2023; LU, Jia-Hong/X-1395-2019
OI Xiang, Cheng/0000-0001-8267-4268; LU, Jia-Hong/0000-0002-1147-125X
CR Amit Y, 2007, INT J COMPUT VISION, V75, P267, DOI 10.1007/s11263-006-0033-9
   [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], 2009, P IEEE INT C COMP VI
   [Anonymous], P IEEE C COMP VIS PA
   Arsigny V, 2007, SIAM J MATRIX ANAL A, V29, P328, DOI 10.1137/050637996
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Cao XC, 2016, NEUROCOMPUTING, V172, P235, DOI 10.1016/j.neucom.2014.12.105
   Crandall D, 2005, PROC CVPR IEEE, P10
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   Fu HZ, 2015, IEEE T IMAGE PROCESS, V24, P3415, DOI 10.1109/TIP.2015.2442915
   Hare S, 2011, IEEE I CONF COMP VIS, P263, DOI 10.1109/ICCV.2011.6126251
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hu JL, 2016, IEEE T CIRC SYST VID, V26, P2056, DOI 10.1109/TCSVT.2015.2477936
   Jiang H., 2007, PROCEEDINGS OF IEEE
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kwon J, 2009, PROC CVPR IEEE, P1208, DOI 10.1109/CVPRW.2009.5206502
   Lazebnik S., 2006, P IEEE CVF C COMP VI, DOI [DOI 10.1109/CVPR.2006.68, 10.1109/CVPR.2006.68]
   Li Y, 2015, PROC CVPR IEEE, P287, DOI 10.1109/CVPR.2015.7298625
   Liu FY, 2016, IMAGE VISION COMPUT, V51, P84, DOI 10.1016/j.imavis.2016.04.008
   Liu T, 2015, PROC CVPR IEEE, P4902, DOI 10.1109/CVPR.2015.7299124
   Ma B, 2016, IEEE T CYBERNETICS, V46, P2411, DOI 10.1109/TCYB.2015.2477879
   Nejhum SMS, 2010, COMPUT VIS IMAGE UND, V114, P901, DOI 10.1016/j.cviu.2010.04.002
   Pa X., 2012, P IEEE C COMP VIS PA
   Peng X, 2017, IEEE T CYBERNETICS, V47, P1053, DOI 10.1109/TCYB.2016.2536752
   Peng X, 2016, IEEE T NEUR NET LEAR, V27, P2499, DOI 10.1109/TNNLS.2015.2490080
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Porikli F., 2006, 2006 IEEE COMPUTER S, V1, P728, DOI [10.1109/CVPR.2006.94, DOI 10.1109/CVPR.2006.94]
   Serre T, 2005, PROC CVPR IEEE, P994
   Sigal L, 2004, P INT WORKSH COMPL M
   Tuzel O, 2006, LECT NOTES COMPUT SC, V3952, P589
   Tuzel O, 2007, PROC CVPR IEEE, P1736
   Wang D., 2013, P IEEE C COMP VIS PA
   Wang D, 2013, IEEE T IMAGE PROCESS, V22, P314, DOI 10.1109/TIP.2012.2202677
   Wang F., 2015, ADV IMAGE GRAPHICS T
   Wang F., P IEEE INT C CONTR A, P2008
   Wang JJ, 2010, PROC CVPR IEEE, P3360, DOI 10.1109/CVPR.2010.5540018
   Wang Xinchao, 2014, P EUR C COMP VIS
   Wang ZL, 2015, IMAGE VISION COMPUT, V38, P24, DOI 10.1016/j.imavis.2015.04.005
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Xu YL, 2016, IEEE SIGNAL PROC LET, V23, P40, DOI 10.1109/LSP.2015.2479360
   Yan S., 2012, P EUR C COMP VIS
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   Yao R, 2017, IEEE T CIRC SYST VID, V27, P1235, DOI 10.1109/TCSVT.2016.2527358
   Yao R, 2013, PROC CVPR IEEE, P2363, DOI 10.1109/CVPR.2013.306
   Zhen LL, 2014, ELECTRON LETT, V50, P942, DOI 10.1049/el.2014.0666
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 47
TC 6
Z9 6
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2017
VL 60
SI SI
BP 124
EP 133
DI 10.1016/j.imavis.2017.01.003
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ES4PS
UT WOS:000399517800013
DA 2024-07-18
ER

PT J
AU Akbari, Y
   Nouri, K
   Sadri, J
   Djeddi, C
   Siddiqi, I
AF Akbari, Younes
   Nouri, Kazem
   Sadri, Javad
   Djeddi, Chawki
   Siddiqi, Imran
TI Wavelet-based gender detection on off-line handwritten documents using
   probabilistic finite state automata
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Off-line handwriting analysis; Gender detection; Texture analysis;
   Wavelet sub-band; Symbolic dynamics; Probabilistic finite state automata
ID WRITER IDENTIFICATION; SEX; PERSONALITY
AB Detection of gender from handwriting of an individual presents an interesting research problem with applications in forensic document examination, writer identification and psychological studies. This paper presents an effective technique to predict the gender of an individual from off-line images of handwriting. The proposed technique relies on a global approach that considers writing images as textures. Each handwritten image is converted into a textured image which is decomposed into a series of wavelet sub-bands at a number of levels, The wavelet sub-bands are then extended into data sequences. Each data sequence is quantized to produce a probabilistic finite state automata (PFSA) that generates feature Vectors. These features are used to train two classifiers, artificial neural network and support vector machine to discriminate between male and female writings. The performance of the proposed system was evaluated on two databases, QUWI and MSHD, within a number of challenging experimental scenarios and realized classification rates of up to 80%. The experimental results show the superiority of the proposed technique over existing techniques in terms of classification rates. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Akbari, Younes; Nouri, Kazem] Semnan Univ, Fac Math Stat & Comp Sci, Dept Math, POB 35195-363, Semnan, Iran.
   [Sadri, Javad] Concordia Univ, Fac Engn & Comp Sci, Dept Comp Sci Software Engn, Montreal, PQ H3G IM8, Canada.
   [Sadri, Javad] Univ Birjand, Fac Elect & Comp Engn, Dept Comp Engn, POB 97175 615, Birjand, Iran.
   [Djeddi, Chawki] Larbi Tebessi Univ, Math & Comp Sci Dept, Tebessa, Algeria.
   [Siddiqi, Imran] Bahria Univ, Islamabad, Pakistan.
C3 Semnan University; Concordia University - Canada; University of Birjand;
   Echahid Cheikh Larbi Tebessi University
RP Sadri, J (corresponding author), Concordia Univ, Fac Engn & Comp Sci, Dept Comp Sci Software Engn, Montreal, PQ H3G IM8, Canada.
EM akbari_younes@semnan.ac.ir; knouri@semnan.ac.ir;
   j_sadri@encs.concordia.ca; c.djeddi@univ-tebessa.dz;
   imran.siddiqi@bahria.edu.pk
RI Nouri, Kazem/HGE-0958-2022; Djeddi, Chawki/AAZ-9378-2021; Nouri,
   Kazem/Z-3815-2019
OI Djeddi, Chawki/0000-0002-8436-827X; Nouri, Kazem/0000-0002-7922-5848;
   Siddiqi, Imran/0000-0002-7203-5195
CR Al Maadeed S, 2014, EURASIP J IMAGE VIDE, DOI 10.1186/1687-5281-2014-10
   Al Maadeed S, 2012, INT CONF FRONT HAND, P746, DOI 10.1109/ICFHR.2012.256
   [Anonymous], 1992, CBMSNSF REGIONAL C S
   Bahrampour S, 2013, PATTERN RECOGN LETT, V34, P2126, DOI 10.1016/j.patrec.2013.06.021
   Bandi KarthikR., 2005, PROC 12 INT GRAPHONO, P133
   Beech JR, 2005, PERS INDIV DIFFER, V39, P459, DOI 10.1016/j.paid.2005.01.024
   Bertolini D, 2013, EXPERT SYST APPL, V40, P2069, DOI 10.1016/j.eswa.2012.10.016
   Bouletreau V, 1998, INT C PATT RECOG, P1758, DOI 10.1109/ICPR.1998.712067
   Burr V, 2002, J SOC PSYCHOL, V142, P691, DOI 10.1080/00224540209603929
   Cha SH, 2001, PROC INT CONF DOC, P1022, DOI 10.1109/ICDAR.2001.953940
   Djeddi C, 2014, INT CONF FRONT HAND, P93, DOI 10.1109/ICFHR.2014.23
   EAMES K, 1990, J SOC PSYCHOL, V130, P831, DOI 10.1080/00224545.1990.9924637
   FURNHAM A, 1987, PERS INDIV DIFFER, V8, P433, DOI 10.1016/0191-8869(87)90045-6
   Garain Utpal, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P991, DOI 10.1109/ICDAR.2009.222
   Gawda B, 2008, PERCEPT MOTOR SKILL, V107, P862, DOI 10.2466/PMS.107.3.862-872
   Ghiasi G, 2013, IMAGE VISION COMPUT, V31, P379, DOI 10.1016/j.imavis.2013.03.002
   Goodenough FL, 1945, J SOC PSYCHOL, V22, P61, DOI 10.1080/00224545.1945.9714182
   Hamid S, 1996, J SOC PSYCHOL, V136, P778, DOI 10.1080/00224545.1996.9712254
   Hanusiak RK, 2012, INT J DOC ANAL RECOG, V15, P213, DOI 10.1007/s10032-011-0166-4
   Hartley J., 1991, British Educational Research Journal, V17, P141, DOI 10.1080/0141192910170204
   Hassaïne A, 2013, PROC INT CONF DOC, P1417, DOI 10.1109/ICDAR.2013.286
   Hayes WN, 1996, PERCEPT MOTOR SKILL, V83, P791, DOI 10.2466/pms.1996.83.3.791
   He ZY, 2008, NEUROCOMPUTING, V71, P1832, DOI 10.1016/j.neucom.2007.10.017
   He ZY, 2010, INTEGR COMPUT-AID E, V17, P157, DOI 10.3233/ICA-2010-0338
   Huber R.A., 1999, HANDWRITING IDENTIFI
   Jin X, 2012, IEEE SENS J, V12, P1709, DOI 10.1109/JSEN.2011.2177257
   KLIMOSKI RJ, 1983, J OCCUP PSYCHOL, V56, P191, DOI 10.1111/j.2044-8325.1983.tb00127.x
   LESTER D, 1982, PERCEPT MOTOR SKILL, V55, P1190, DOI 10.2466/pms.1982.55.3f.1190
   Liwicki M, 2006, LECT NOTES COMPUT SC, V3872, P186
   Liwicki M, 2011, PATTERN ANAL APPL, V14, P87, DOI 10.1007/s10044-010-0178-6
   Mallapragada G, 2012, IEEE T SYST MAN CY B, V42, P647, DOI 10.1109/TSMCB.2011.2172419
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   Mergl R, 1999, J NEUROSCI METH, V90, P157, DOI 10.1016/S0165-0270(99)00080-1
   Morris N., 2000, FORENSIC HANDWRITING
   NETER E, 1989, PERS INDIV DIFFER, V10, P737, DOI 10.1016/0191-8869(89)90120-7
   Rajagopalan V, 2006, SIGNAL PROCESS, V86, P3309, DOI 10.1016/j.sigpro.2006.01.014
   Ray A, 2004, SIGNAL PROCESS, V84, P1115, DOI 10.1016/j.sigpro.2004.03.011
   Said HES, 1998, BMVC, P1, DOI DOI 10.5244/C.12.48
   Siddiqi I, 2015, PATTERN ANAL APPL, V18, P887, DOI 10.1007/s10044-014-0371-0
   Siddiqi I, 2010, PATTERN RECOGN, V43, P3853, DOI 10.1016/j.patcog.2010.05.019
   Simard PY, 2003, PROC INT CONF DOC, P958
   Sokic E, 2012, P INT S TEL, P1, DOI 10.1109/BIHTEL.2012.6412086
   Srihari SN, 2001, PROC INT CONF DOC, P1195, DOI 10.1109/ICDAR.2001.953974
   Srihari SN, 2002, J FORENSIC SCI, V47, P856
   Tett RP, 1997, PERS INDIV DIFFER, V22, P11, DOI 10.1016/S0191-8869(96)00183-3
   Vapnik V., 1999, NATURE STAT LEARNING
   Youssef Amira E, 2013, 5 INT C IM CRIM DET, P1
NR 47
TC 31
Z9 33
U1 1
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2017
VL 59
BP 17
EP 30
DI 10.1016/j.imavis.2016.11.017
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA EP9IS
UT WOS:000397687900002
DA 2024-07-18
ER

PT J
AU Zeng, D
   Zhao, QJ
   Long, SQ
   Li, J
AF Zeng, Dan
   Zhao, Qijun
   Long, Shuqin
   Li, Jing
TI Examplar coherent 3D face reconstruction from forensic mugshot database
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D face reconstruction; Forensic mugshot images; Examplar coherent
ID SHAPE; MODEL
AB Reconstructing 3D face models from 2D face images is usually done by using a single reference 3D face model or some gender/ethnicity specific 3D face models. However, different persons, even those of the same gender or ethnicity, usually have significantly different faces in terms of their overall appearance, which forms the base of person recognition via faces. Consequently, existing 3D reference model based methods have limited capability of reconstructing precise 3D face models for a large variety of persons. In this paper, we propose to explore a reservoir of diverse reference models for 3D face reconstruction from forensic mugshot face images, where facial examplars coherent with the input determine the final shape estimation. Specifically, our 3D face reconstruction is formulated as an energy minimization problem with: 1) shading constraint from multiple input face images, 2) distortion and self-occlusion based color consistency between different views, and 3) depth uncertainty based smoothness constraint on adjacent pixels. The proposed energy is minimized in a coarse to fine way, where the shape refinement step is done by using a multi label segmentation algorithm. Experimental results on challenging datasets demonstrate that the proposed algorithm is capable of recovering high quality 3D face models. We also show that our reconstructed models successfully boost face recognition accuracy. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Zeng, Dan; Zhao, Qijun; Long, Shuqin; Li, Jing] Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
C3 Sichuan University
RP Li, J (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610065, Peoples R China.
EM lijing712@scu.edu.cn
RI Zhao, QiJun/KIH-9623-2024; Zeng, Dan/M-4615-2019
OI Zeng, Dan/0000-0002-9036-7791
FU National Natural Science Foundation of China [61202161]; National Key
   Scientific Instrument and Equipment Development Projects
   [2013YQ49087904]
FX This work is supported by National Natural Science Foundation of China
   61202161, and National Key Scientific Instrument and Equipment
   Development Projects 2013YQ49087904.
CR Ahmed A, 2008, IEEE IMAGE PROC, P201, DOI 10.1109/ICIP.2008.4711726
   [Anonymous], CVPR 2011 WORKSH
   [Anonymous], ADV MULTIMEDIA INFOR
   [Anonymous], 2014, T GRAPH
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Castelán M, 2009, IET COMPUT VIS, V3, P60, DOI 10.1049/iet-cvi.2008.0060
   Castelan M, 2007, IEEE T IMAGE PROCESS, V16, P1139, DOI 10.1109/TIP.2006.891351
   Dovgard R, 2004, LECT NOTES COMPUT SC, V3022, P99
   Gonzalez-Mora J, 2010, IMAGE VISION COMPUT, V28, P1117, DOI 10.1016/j.imavis.2010.01.005
   Hassner T, 2013, IEEE I CONF COMP VIS, P3607, DOI 10.1109/ICCV.2013.448
   Heo J, 2012, IEEE T PATTERN ANAL, V34, P2341, DOI 10.1109/TPAMI.2011.275
   Hu Han, 2012, 2012 IEEE Fifth International Conference On Biometrics: Theory, Applications And Systems (BTAS 2012), P223, DOI 10.1109/BTAS.2012.6374581
   Jeni Laszlo A., 2015, Dense 3D Face Alignment from 2D Videos in Real-Time
   Jiang DL, 2005, PATTERN RECOGN, V38, P787, DOI 10.1016/j.patcog.2004.11.004
   Jongmoo Choi, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3959, DOI 10.1109/ICPR.2010.963
   Kemelmacher I, 2006, LECT NOTES COMPUT SC, V3951, P277
   Kemelmacher-Shlizerman I, 2011, IEEE I CONF COMP VIS, P1746, DOI 10.1109/ICCV.2011.6126439
   Kemelmacher-Shlizerman I, 2011, IEEE T PATTERN ANAL, V33, P394, DOI 10.1109/TPAMI.2010.63
   Lei Z., 2008, COMPUTER VISION PATT, P1
   Lin YP, 2010, PROC CVPR IEEE, P1490, DOI 10.1109/CVPR.2010.5539793
   Park U., 2008, Proc. Automatic Face and Gesture Recognition, P1
   Park U, 2010, IEEE T PATTERN ANAL, V32, P947, DOI 10.1109/TPAMI.2010.14
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Reiter M, 2006, INT C PATT RECOG, P425
   Segundo MP, 2012, IEEE IMAGE PROC, P1797, DOI 10.1109/ICIP.2012.6467230
   Suwajanakorn S, 2014, LECT NOTES COMPUT SC, V8692, P796, DOI 10.1007/978-3-319-10593-2_52
   Zhang R, 1999, IEEE T PATTERN ANAL, V21, P690, DOI 10.1109/34.784284
   Zhang X, 2009, PATTERN RECOGN, V42, P2876, DOI 10.1016/j.patcog.2009.04.017
NR 29
TC 18
Z9 20
U1 2
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 193
EP 203
DI 10.1016/j.imavis.2016.03.001
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700018
DA 2024-07-18
ER

PT J
AU Proeriça, H
   Neves, JC
AF Proerica, Hugo
   Neves, Joao C.
TI Visible-wavelength iris/periocular imaging and recognition surveillance
   environments
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Biometrics Conference
CY OCT, 2015
CL London, ENGLAND
DE Visual surveillance; Non-cooperative recognition; Iris/periocular
   recognition
AB Visual surveillance cameras have been massively deployed in public urban environments over the recent years, as a crime prevention and law enforcement solution. This fact raised the interest in developing automata to infer useful information from such crowded scenes (from abnormal behavior detection to human identification). In order to cover wide outdoor areas, one interesting possibility is to combine wide-angle and pan tilt zoom (PTZ) cameras in a master slave configuration. The use of fish-eye lenses allows the master camera to maximize the coverage area while the PTZ acts as a foveal sensor, providing high resolution images of the interest regions. This paper addresses the feasibility of using this type of data acquisition paradigm for imaging iris/periocular data with enough discriminating power to be used for biometric recognition purposes. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Proerica, Hugo; Neves, Joao C.] Univ Beira Interior, IT, Covilha, Portugal.
C3 Instituto de Telecomunicacoes; Universidade da Beira Interior
RP Proeriça, H (corresponding author), Univ Beira Interior, R Marques DAvila e Bolama, P-6201001 Covilha, Portugal.
EM hugomcp@di.ubi.pt; jcneves@di.ubi.pt
RI Proença, Hugo/F-9499-2010; Neves, João/G-6477-2016
OI Proença, Hugo/0000-0003-2551-8570; Neves, João/0000-0003-0139-2213
CR Barret D., 2014, TELEGRAPH
   Bashir F, 2008, 2008 IEEE CONFERENCE ON TECHNOLOGIES FOR HOMELAND SECURITY, VOLS 1 AND 2, P426, DOI 10.1109/THS.2008.4534490
   Dong Wenbo., 2009, CHINESE C PATTERN RE, P1
   Guo G., 2005, TR2005044 MERL, P1
   Jang-Hee Yoo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P113, DOI 10.1109/CVPRW.2015.7301304
   Kariotoglou N, 2011, IEEE DECIS CONTR P, P1411, DOI 10.1109/CDC.2011.6161228
   Lee G, 2009, OPT ENG, V48, DOI 10.1117/1.3083290
   Matey JR, 2006, P IEEE, V94, P1936, DOI 10.1109/JPROC.2006.884091
   Neves J. C., 2015, IEEE 7 INT C BIOM TH, P1, DOI DOI 10.1109/AVSS.2015.7301790
   Neves J.C., 2015, 12th IEEE International Conference on Advanced Video and Signal based Surveillance (AVSS), P1
   Neves JC, 2015, LECT NOTES COMPUT SC, V9281, P59, DOI 10.1007/978-3-319-23222-5_8
   Wheeler F.W., 2008, 2 IEEE INT C BIOMETR, P1
   Yoon S., 2007, IEEE INT S PERSONAL, P1
NR 13
TC 6
Z9 6
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
BP 22
EP 25
DI 10.1016/j.imavis.2016.03.015
PN 1
PG 4
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA ED8BO
UT WOS:000389097100007
DA 2024-07-18
ER

PT J
AU Nicolle, J
   Bailly, K
   Chetouani, M
AF Nicolle, Jeremie
   Bailly, Kevin
   Chetouani, Mohamed
TI Real-time facial action unit intensity prediction with regularized
   metric learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression; Action Units; FACS; Metric Learning for Kernel
   Regression
ID RECOGNITION; FIELDS
AB The ability to automatically infer emotional states, engagement, depression or pain from nonverbal behavior has recently become of great interest in many research and industrial works. This will result in the emergence of a wide range of applications in robotics, biometrics, marketing and medicine. The Facial Action Coding System (FACS) proposed by Ekman features objective descriptions of facial movements, characterizing activations of facial muscles. Achieving an accurate intensity prediction of Action Units (AUs) has a significant impact on the prediction quality of more high-level information regarding human behavior (e.g. emotional states). Real-time AU intensity prediction, in many image-related machine learning tasks, is a high-dimensional problem. For solving this task, we propose adapting the Metric Learning for Kernel Regression (MLKR) framework focusing on overfitting issues induced in high-dimensional spaces. MLKR aims at estimating the optimal linear subspace for reducing the squared error of a Gaussian kernel regressor. We introduce Iterative Regularized Kernel Regression (IRKR), an iterative nonlinear feature selection method combined with a Lasso-regularized version of the original MLKR formulation that improves on the state-of-the-art results on several AU databases, ranging from prototypical to natural and wild data. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Nicolle, Jeremie; Bailly, Kevin; Chetouani, Mohamed] Univ Paris 06, Sorbonne Univ, CNRS UMR 7222, ISIR, 4 Pl Jussieu, F-75005 Paris, France.
C3 Sorbonne Universite; Centre National de la Recherche Scientifique (CNRS)
RP Nicolle, J (corresponding author), Univ Paris 06, ISIR Inst Syst Intelligents & Robot Pyramide, T55-65 CC 173,4 Pl Jussieu, F-75005 Paris, France.
EM jeremie.nicolle@isir.upmc.fr
RI CHETOUANI, Mohamed/F-5854-2010
FU French National Agency (ANR) [ANR-13-CORD-0004]; Agence Nationale de la
   Recherche (ANR) [ANR-13-CORD-0004] Funding Source: Agence Nationale de
   la Recherche (ANR)
FX This work was partially supported by the French National Agency (ANR) in
   the frame of its technological research CONTINT program (JEMImE, project
   number ANR-13-CORD-0004).
CR [Anonymous], P MACHINE LEARNING R
   [Anonymous], INT J COMPUT THEORY
   [Anonymous], 2015, PROC 11 IEEE INT C W
   [Anonymous], IEEE C COMP VIS PATT
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Baltrusaitis T, 2014, LECT NOTES COMPUT SC, V8692, P593, DOI 10.1007/978-3-319-10593-2_39
   Chang WY, 2007, LECT NOTES COMPUT SC, V4844, P621
   Chuang CF, 2006, PATTERN RECOGN, V39, P1795, DOI 10.1016/j.patcog.2006.03.017
   De La Torre F, 2009, P 2009 3 INT C AFF C, P1, DOI 10.1109/ACII.2009.5349358
   Demsar J, 2006, J MACH LEARN RES, V7, P1
   EKMAN P, 1992, COGNITION EMOTION, V6, P169, DOI 10.1080/02699939208411068
   EKMAN P, 1976, ENVIRON PSYCH NONVER, V1, P56, DOI 10.1007/BF01115465
   el Kaliouby R, 2005, REAL-TIME VISION FOR HUMAN-COMPUTER INTERACTION, P181
   Feng YQ, 2003, 2003 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-5, PROCEEDINGS, P2085, DOI 10.1109/ICMLC.2003.1259848
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Girard J.M., 2014, PATTERN RECOGN LETT
   Gudi A., 2015, 2015 11 IEEE INT C W, V6, P1
   Guyon Isabelle, 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hamm J, 2011, J NEUROSCI METH, V200, P237, DOI 10.1016/j.jneumeth.2011.06.023
   Hoque ME, 2012, IEEE T AFFECT COMPUT, V3, P323, DOI 10.1109/T-AFFC.2012.11
   Jeni L.A., 2013, Proc. 10th IEEE Int. Conf. Workshops Autom. Face Gesture Recognit, P1
   Jeni LA, 2013, INT CONF AFFECT, P245, DOI 10.1109/ACII.2013.47
   Kaltwang S, 2015, PROC CVPR IEEE, P296, DOI 10.1109/CVPR.2015.7298626
   Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Koelstra S., 2008, P IEEE INT C AUT FAC, P1
   Li YQ, 2013, IEEE T AFFECT COMPUT, V4, P127, DOI 10.1109/T-AFFC.2013.5
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P., 2010, IEEE COMP SOC C COMP, P94, DOI 10.1109/CVPRW.2010.5543262
   Mahoor Mohammad H., 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P74, DOI 10.1109/CVPR.2009.5204259
   Mavadati SM, 2013, IEEE T AFFECT COMPUT, V4, P151, DOI 10.1109/T-AFFC.2013.4
   McDuff D, 2013, IEEE COMPUT SOC CONF, P881, DOI 10.1109/CVPRW.2013.130
   Nadaraya E.A., 1964, Theory of Probability and Its Applications, V61, P405, DOI [10.1137/1109020, DOI 10.1137/1109020]
   Nicolle J, 2013, IEEE IMAGE PROC, P2978, DOI 10.1109/ICIP.2013.6738613
   Nicolle J, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P501
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   Rudovic O, 2015, IEEE T PATTERN ANAL, V37, P944, DOI 10.1109/TPAMI.2014.2356192
   Rudovic O, 2012, LECT NOTES COMPUT SC, V7584, P260, DOI 10.1007/978-3-642-33868-7_26
   Sandbach G, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P738, DOI 10.1109/ICCVW.2013.101
   Savran A, 2012, IMAGE VISION COMPUT, V30, P774, DOI 10.1016/j.imavis.2011.11.008
   Savran A, 2008, LECT NOTES COMPUT SC, V5372, P47, DOI 10.1007/978-3-540-89991-4_6
   Schaap M, 2009, LECT NOTES COMPUT SC, V5636, P528, DOI 10.1007/978-3-642-02498-6_44
   Senechal T., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P860, DOI 10.1109/FG.2011.5771363
   Senechal T, 2012, IEEE T SYST MAN CY B, V42, P993, DOI 10.1109/TSMCB.2012.2193567
   SHROUT PE, 1979, PSYCHOL BULL, V86, P420, DOI 10.1037/0033-2909.86.2.420
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Sun YL, 2008, KEY ENG MATER, V359-360, P1, DOI 10.4028/www.scientific.net/KEM.359-360.1
   Takeda H, 2008, IEEE T IMAGE PROCESS, V17, P550, DOI 10.1109/TIP.2007.918028
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Valstar Michel F., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P921, DOI 10.1109/FG.2011.5771374
   Valstar MF, 2012, IEEE T SYST MAN CY B, V42, P28, DOI 10.1109/TSMCB.2011.2163710
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wan S., 2013, PATTERN RECOGN
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang P, 2007, PROC CVPR IEEE, P688
   Zaman B., 2006, Proceedings of the 4th Nordic conference on Human-computer interaction: changing roles, P457
NR 58
TC 8
Z9 11
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 1
EP 14
DI 10.1016/j.imavis.2016.03.004
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Uricár, M
   Franc, V
   Thomas, D
   Sugimoto, A
   Hlavác, V
AF Uricar, Michal
   Franc, Vojtech
   Thomas, Diego
   Sugimoto, Akihiro
   Hlavac, Vaclav
TI Multi-view facial landmark detector learned by the Structured Output SVM
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deformable Part Models; Structured output SVM; Facial landmarks
   detection
ID MODELS
AB We propose a real-time multi-view landmark detector based on Deformable Part Models (DPM). The detector is composed of a mixture of tree based DPMs, each component describing landmark configurations in a specific range of viewing angles. The usage of view specific DPMs allows to capture a large range of poses and to deal with the problem of self-occlusions. Parameters of the detector are learned from annotated examples by the Structured Output Support Vector Machines algorithm. The learning objective is directly related to the performance measure used for detector evaluation. The tree based DPM allows to find a globally optimal landmark configuration by the dynamic programming. We propose a coarse-to-fine search strategy which allows real-time processing by the dynamic programming also on high resolution images. Empirical evaluation on "in the wild" images shows that the proposed detector is competitive with the state-of-the-art methods in terms of speed and accuracy yet it keeps the guarantee of finding a globally optimal estimate in contrast to other methods. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Uricar, Michal; Franc, Vojtech; Hlavac, Vaclav] Czech Tech Univ, Ctr Machine Percept, Prague, Czech Republic.
   [Thomas, Diego; Sugimoto, Akihiro] Natl Inst Informat, Tokyo, Japan.
C3 Czech Technical University Prague; Research Organization of Information
   & Systems (ROIS); National Institute of Informatics (NII) - Japan
RP Uricár, M (corresponding author), Czech Tech Univ, Ctr Machine Percept, Prague, Czech Republic.
EM uricamic@cmp.felk.cvut.cz; xfrancv@cmp.felk.cvut.cz;
   diego_thomas@nii.ac.jp; sugimoto@nii.ac.jp; hlavac@cmp.felk.cvut.cz
RI Hlavac, Vaclav/D-9415-2014; Uřičář, Michal/AAY-9965-2020; Franc,
   Vojtěch/JAC-6432-2023
OI Hlavac, Vaclav/0000-0002-8472-3147; Uřičář, Michal/0000-0002-2606-4470;
   Franc, Vojtěch/0000-0001-7189-1224; Thomas, Diego/0000-0002-8525-7133
FU Grant Agency of the CTU in Prague project [SGS15/201/OHK3/3T/13];
   Ministry of Education, Youth and Sports [ERC-CZ LL1303]; Technology
   Agency of the Czech Republic [TE01020197]
FX MU was supported by The Grant Agency of the CTU in Prague project
   SGS15/201/OHK3/3T/13. VF was supported by the Ministry of Education,
   Youth and Sports under project ERC-CZ LL1303. VH was supported by The
   Technology Agency of the Czech Republic under Project TE01020197 Center
   Applied Cybernetics.
CR [Anonymous], 2006, P BRIT MACH VIS C BM, DOI DOI 10.5244/C.20.92
   [Anonymous], 1998, STATISTICAL LEARNING
   [Anonymous], 2013, P IEEE INT C COMP VI
   [Anonymous], 21 IEEE C COMP VIS P
   [Anonymous], P 11 IEEE INT C AUT
   Asthana A, 2014, PROC CVPR IEEE, P1859, DOI 10.1109/CVPR.2014.240
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Bertsekas D. P., 1999, Nonlinear Program, V2nd
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   Cech J, 2014, INT C PATT RECOG, P2173, DOI 10.1109/ICPR.2014.378
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Cristinacce D, 2008, PATTERN RECOGN, V41, P3054, DOI 10.1016/j.patcog.2008.01.024
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Felzenszwalb PF, 2010, IEEE T PATTERN ANAL, V32, P1627, DOI 10.1109/TPAMI.2009.167
   Felzenszwalb PF, 2005, INT J COMPUT VISION, V61, P55, DOI 10.1023/B:VISI.0000042934.15159.49
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huttenlocher, 2012, THEORY COMPUT, V8, P415, DOI [10.4086/toc.2012.v008a019, DOI 10.4086/TOC.2012.V008A019]
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   Köstinger M, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Martínez AM, 2002, IEEE T PATTERN ANAL, V24, P748, DOI 10.1109/TPAMI.2002.1008382
   Martinez B, 2013, IEEE T PATTERN ANAL, V35, P1149, DOI 10.1109/TPAMI.2012.205
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Sagonas C, 2013, IEEE COMPUT SOC CONF, P896, DOI 10.1109/CVPRW.2013.132
   Saragih J, 2007, IEEE I CONF COMP VIS, P2173
   Saragih J, 2009, PATTERN RECOGN, V42, P2628, DOI 10.1016/j.patcog.2009.04.014
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   SCHLESINGER M.I., 2002, Ten lectures on statistical and structural pattern recognition
   Sochman J, 2005, PROC CVPR IEEE, P150
   Sonnenburg S., 2010, ICML, P999
   Teo CH, 2010, J MACH LEARN RES, V11, P311
   Tsochantaridis I, 2005, J MACH LEARN RES, V6, P1453
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Uricar Michal, 2012, Proceedings of the International Conference on Computer Vision Theory and Applications. VISAPP 2012, P547
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Williams L., 1983, Computer Graphics, V17, P1, DOI 10.1145/964967.801126
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
NR 45
TC 19
Z9 22
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2016
VL 47
BP 45
EP 59
DI 10.1016/j.imavis.2016.02.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DO5LL
UT WOS:000377824500006
DA 2024-07-18
ER

PT J
AU Lee, S
   Shim, H
AF Lee, Seungkyu
   Shim, Hyunjung
TI Skewed stereo time-of-flight camera for translucent object imaging
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Translucent object imaging; ToF depth camera; Three-dimensional image
   processing
AB Time-of-flight (ToF) depth cameras have widely been used in many applications such as 3D imaging, 3D reconstruction, human interaction and robot navigation. However, conventional depth cameras are incapable of imaging a translucent object which occupies a substantial portion of a real world scene. Such a limitation prohibits realistic imaging using depth cameras. In this work, we propose a new skewed stereo ToF camera for detecting and imaging translucent objects under minimal prior of environment We find that the depth calculation of a ToF camera with a translucent object presents a systematic distortion due to the superposed reflected light ray observation from multiple surfaces. We propose to use a stereo ToF camera setup and derive a generalized depth imaging formulation for translucent objects. Distorted depth value is refined using an iterative optimization. Experimental evaluation shows that our proposed method reasonably recovers the depth image of translucent objects. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Lee, Seungkyu] Kyung Hee Univ, Dept Comp Engn, Seoul, South Korea.
   [Shim, Hyunjung] Yonsei Univ, Sch Integrated Technol, Seoul 120749, South Korea.
C3 Kyung Hee University; Yonsei University
RP Lee, S (corresponding author), Kyung Hee Univ, Dept Comp Engn, Seoul, South Korea.
EM seungkyu@khu.ac.kr
RI Shim, Hyunjung/AAS-3610-2021
FU Kyung Hee University [KHU-20130684]; Global Frontier R&D Program on
   "Human-centered Interaction for Coexistence" - National Research
   Foundation of Korea grant - Korean Government (MSIP) [2012M3A6A3057376]
FX This work was supported by Kyung Hee University in 2013 under grant
   KHU-20130684. This work was also supported by the Global Frontier R&D
   Program on "Human-centered Interaction for Coexistence" funded by the
   National Research Foundation of Korea grant funded by the Korean
   Government (MSIP) (2012M3A6A3057376).
CR Albrecht S., 2013, 2 WORKSH ROB CLUTT
   Alt N, 2013, IEEE IMAGE PROC, P4131, DOI 10.1109/ICIP.2013.6738851
   [Anonymous], INT C PATT REC
   [Anonymous], STAR P EUR
   Fritz M., 2009, Advances in Neural Information Processing Systems, V22
   Inoshita C., 2012, P EUR C COMP VIS
   Kadambi A, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2508363.2508428
   Klank U, 2011, IEEE INT CONF ROBOT
   Kompella VR, 2011, IEEE INT CONF ROBOT
   Kutulakos K.N., 2008, INT J COMPUTER VISIO
   Kutulakos K.N., 2005, P IEEE INT C COMP VI
   Lysenkov I., 2012, ROB SCI SYST C
   McHenry K., 2006, IEEE C COMP VIS PATT
   McHenry K., 2005, IEEE COMP SOC C COMP
   Mériaudeau F, 2012, J ELECTRON IMAGING, V21, DOI 10.1117/1.JEI.21.2.021105
   Morris N.J., 2011, IEEE T PATTERN ANAL
   Murase H., 1992, IEEE T PATTERN ANAL
   Murase H., 1990, INT C COMP VIS
   Phillips CJ, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Yang S., 2008, P IEEE INT C ROB AUT
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 21
TC 12
Z9 12
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2015
VL 43
BP 27
EP 38
DI 10.1016/j.imavis.2015.08.001
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CY0AU
UT WOS:000366069200003
DA 2024-07-18
ER

PT J
AU Mitianoudis, N
   Papamarkos, N
AF Mitianoudis, Nikolaos
   Papamarkos, Nikolaos
TI Document image binarization using local features and Gaussian mixture
   modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Binarization; Handwritten documents; Historic documents; Classification;
   Background estimation
AB In this paper, we address the document image binarization problem with a three-stage procedure. First, possible stains and general document background information are removed from the image through a background removal stage. The remaining misclassified background and character pixels are then separated using a Local Co-occurrence Mapping, local contrast and a two-state Gaussian Mixture Model. Finally, some isolated misclassified components are removed by a morphology operator. The proposed scheme offers robust and fast performance, especially for both handwritten and printed documents, which compares favorably with other binarization methods. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Mitianoudis, Nikolaos; Papamarkos, Nikolaos] Democritus Univ Thrace, Dept Elect & Comp Engn, Image Proc & Multimedia Lab, GR-67100 Xanthi, Greece.
C3 Democritus University of Thrace
RP Mitianoudis, N (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Image Proc & Multimedia Lab, GR-67100 Xanthi, Greece.
EM nmitiano@ee.duth.gr
RI Mitianoudis, Nikolaos/E-8184-2012
OI Mitianoudis, Nikolaos/0000-0003-0898-6102
CR [Anonymous], 1927, STUDIES OPTICS
   Badekas E, 2007, IET IMAGE PROCESS, V1, P67, DOI 10.1049/iet-ipr:20050311
   Badekas E, 2007, ENG APPL ARTIF INTEL, V20, P11, DOI 10.1016/j.engappai.2006.04.003
   Badekas E, 2006, INT J IMAG SYST TECH, V16, P262, DOI 10.1002/ima.20092
   Bernsen J., 1986, In: Proceedings of the Eighth International Conference on Pattern Recognition, P1251
   Bilmes J., GENTLE TUTORIAL EM A
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Gatos B, 2006, PATTERN RECOGN, V39, P317, DOI 10.1016/j.patcog.2005.09.010
   Gatos B, 2011, INT J DOC ANAL RECOG, V14, P35, DOI 10.1007/s10032-010-0115-7
   Gatos Basilis, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1375, DOI 10.1109/ICDAR.2009.246
   Gooch AA, 2005, ACM T GRAPHIC, V24, P634, DOI 10.1145/1073204.1073241
   Grundland M., 2005, 649 CAMBR U COMP LAB
   Hedjam R, 2011, PATTERN RECOGN, V44, P2184, DOI 10.1016/j.patcog.2011.02.021
   Howe NR, 2013, INT J DOC ANAL RECOG, V16, P247, DOI 10.1007/s10032-012-0192-x
   Hyvärinen A, 2001, INDEPENDENT COMPONENT ANALYSIS: PRINCIPLES AND PRACTICE, P71
   Kanan C, 2012, PLOS ONE, V7, P133, DOI 10.1371/journal.pone.0029740
   Lelore T, 2013, IEEE T PATTERN ANAL, V35, P2039, DOI 10.1109/TPAMI.2013.63
   Lu SJ, 2010, INT J DOC ANAL RECOG, V13, P303, DOI 10.1007/s10032-010-0130-8
   Makridis M, 2010, INT J PATTERN RECOGN, V24, P245, DOI 10.1142/S0218001410007889
   Min Qiu, 2008, CGIV 2008/MCS'08. 4th European Conference on Colour in Graphics, Imaging and Vision. 10th International Symposium on Multispectral Colour Science, P347
   Moghaddam RF, 2012, PATTERN RECOGN, V45, P2419, DOI 10.1016/j.patcog.2011.12.013
   Moghaddam RF, 2010, PATTERN RECOGN, V43, P2186, DOI 10.1016/j.patcog.2009.12.024
   Niblack W., 1986, An Introduction to Digital Image Processing
   Ntirogiannis K, 2014, PATTERN RECOGN LETT, V35, P3, DOI 10.1016/j.patrec.2012.09.026
   Ntzios K, 2007, INT J DOC ANAL RECOG, V9, P179, DOI 10.1007/s10032-006-0031-z
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Papamarkos N, 2003, NEURAL COMPUT APPL, V12, P190, DOI 10.1007/s00521-003-0382-z
   Papamarkos N., 1994, COMP VISION IMAGE PR, V56, P378
   Pratikakis I., 2010, Proceedings 2010 12th International Conference on Frontiers in Handwriting Recognition (ICFHR 2010), P727, DOI 10.1109/ICFHR.2010.118
   Pratikakis I, 2013, PROC INT CONF DOC, P1471, DOI 10.1109/ICDAR.2013.219
   Pratikakis I, 2012, INT CONF FRONT HAND, P817, DOI 10.1109/ICFHR.2012.216
   Ramírez-Ortegón MA, 2014, INT J DOC ANAL RECOG, V17, P139, DOI 10.1007/s10032-013-0212-5
   Ramírez-Ortegón MA, 2014, PATTERN RECOGN, V47, P2635, DOI 10.1016/j.patcog.2014.02.003
   Ramírez-Ortegón MA, 2013, PATTERN RECOGN LETT, V34, P1299, DOI 10.1016/j.patrec.2013.04.007
   Ramírez-Ortegón MA, 2010, PATTERN RECOGN, V43, P3243, DOI 10.1016/j.patcog.2010.04.028
   Ramírez-Ortegón MA, 2010, PATTERN RECOGN, V43, P1233, DOI 10.1016/j.patcog.2009.11.006
   REDDI SS, 1984, IEEE T SYST MAN CYB, V14, P661, DOI 10.1109/TSMC.1984.6313341
   Sauvola J, 2000, PATTERN RECOGN, V33, P225, DOI 10.1016/S0031-3203(99)00055-2
   Su Bolan, 2010, P INT WORKSH DOC AN, P159
   Valizadeh M, 2012, INT J DOC ANAL RECOG, V15, P57, DOI 10.1007/s10032-010-0142-4
NR 40
TC 40
Z9 42
U1 1
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2015
VL 38
BP 33
EP 51
DI 10.1016/j.imavis.2015.04.003
PG 19
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CK4LX
UT WOS:000356196400004
DA 2024-07-18
ER

PT J
AU Babu, RV
   Parate, P
   Acharya, KÄ
AF Babu, R. Venkatesh
   Parate, Priti
   Acharya, Aniruddha K.
TI Robust tracking with interest points: A sparse representation approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; l(1) minimization; Interest points; Harris corner;
   Sparse representation
ID VISUAL TRACKING; OBJECT TRACKING; IMAGE; RECOGNITION
AB Visual tracking is an important task in various computer vision applications including visual surveillance, human computer interaction, event detection, video indexing and retrieval. Recent state of the art sparse representation (SR) based trackers show better robustness than many of the other existing trackers. One of the issues with these SR trackers is low execution speed. The particle filter framework is one of the major aspects responsible for slow execution, and is common to most of the existing SR trackers. In this paper,(1) we propose a robust interest point based tracker in l(1) minimization framework that runs at real-time with performance comparable to the state of the art trackers. In the proposed tracker, the target dictionary is obtained from the patches around target interest points. Next, the interest points from the candidate window of the current frame are obtained. The correspondence between target and candidate points is obtained via solving the proposed l(1) minimization problem. In order to prune the noisy matches, a robust matching criterion is proposed, where only the reliable candidate points that mutually match with target and candidate dictionary elements are considered for tracking. The object is localized by measuring the displacement of these interest points. The reliable candidate patches are used for updating the target dictionary. The performance and accuracy of the proposed tracker is benchmarked with several complex video sequences. The tracker is found to be considerably fast as compared to the reported state of the art trackers. The proposed tracker is further evaluated for various local patch sizes, number of interest points and regularization parameters. The performance of the tracker for various challenges including illumination change, occlusion, and background clutter has been quantified with a benchmark dataset containing 50 videos. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Babu, R. Venkatesh; Parate, Priti; Acharya, Aniruddha K.] Indian Inst Sci, Supercomp Educ & Res Ctr, Video Analyt Lab, Bangalore 560012, Karnataka, India.
C3 Indian Institute of Science (IISC) - Bangalore
RP Babu, RV (corresponding author), Indian Inst Sci, Supercomp Educ & Res Ctr, Video Analyt Lab, Bangalore 560012, Karnataka, India.
EM venky@serc.iisc.in
OI Radhakrishnan, Venkatesh Babu/0000-0002-1926-1804
CR [Anonymous], 2006, IEEE C COMPUTER VISI, DOI DOI 10.1109/CVPR.2006.256
   [Anonymous], MATLAB and Octave functions for computer vision and image processing
   Babenko B, 2009, PROC CVPR IEEE, P983, DOI 10.1109/CVPRW.2009.5206737
   Babu RV, 2007, IMAGE VISION COMPUT, V25, P1205, DOI 10.1016/j.imavis.2006.07.016
   Bao CL, 2012, PROC CVPR IEEE, P1830, DOI 10.1109/CVPR.2012.6247881
   Bay H, 2006, LECT NOTES COMPUT SC, V3951, P404, DOI 10.1007/11744023_32
   Birchfield S, 1998, PROC CVPR IEEE, P232, DOI 10.1109/CVPR.1998.698614
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Brown M, 2007, INT J COMPUT VISION, V74, P59, DOI 10.1007/s11263-006-0002-3
   Bryt O, 2008, J VIS COMMUN IMAGE R, V19, P270, DOI 10.1016/j.jvcir.2008.03.001
   Cevher V, 2008, LECT NOTES COMPUT SC, V5303, P155, DOI 10.1007/978-3-540-88688-4_12
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Elad M, 2006, IEEE T IMAGE PROCESS, V15, P3736, DOI 10.1109/TIP.2006.881969
   Gabriel R, 2005, AVSS 2005: ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P159
   Grabner H., 2006, BMVC, V1, P61
   Gu I.Y., 2011, OBJECT TRACKING, P89
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Huaping Liu, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1702, DOI 10.1109/ICPR.2010.421
   Jeyakar J, 2008, COMPUT VIS IMAGE UND, V112, P296, DOI 10.1016/j.cviu.2008.05.005
   Jia X, 2012, PROC CVPR IEEE, P1822, DOI 10.1109/CVPR.2012.6247880
   Jurie F., 2002, BMVC, P1
   Kai Guo, 2010, Proceedings 7th IEEE International Conference on Advanced Video and Signal Based Surveillance (AVSS 2010), P188, DOI 10.1109/AVSS.2010.71
   Kalal Z, 2012, IEEE T PATTERN ANAL, V34, P1409, DOI 10.1109/TPAMI.2011.239
   Kloihofer Werner, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3549, DOI 10.1109/ICPR.2010.866
   Li H., 2010, P IEEE INT C IM PROC, P1305
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   Mairal J, 2008, MULTISCALE MODEL SIM, V7, P214, DOI 10.1137/070697653
   Mei X, 2011, PROC CVPR IEEE, P1257
   Mei X, 2011, IEEE T PATTERN ANAL, V33, P2259, DOI 10.1109/TPAMI.2011.66
   Mei X, 2009, IEEE I CONF COMP VIS, P1436, DOI 10.1109/ICCV.2009.5459292
   Noble A., 1989, THESIS OXFORD U
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   Rao S, 2010, IEEE T PATTERN ANAL, V32, P1832, DOI 10.1109/TPAMI.2009.191
   Ross DA, 2008, INT J COMPUT VISION, V77, P125, DOI 10.1007/s11263-007-0075-7
   Sankaranarayanan AC, 2008, P IEEE, V96, P1606, DOI 10.1109/JPROC.2008.928758
   Schweitzer H, 2002, LECT NOTES COMPUT SC, V2353, P358
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   SPAMS, SPAMS
   Wright J, 2009, IEEE T PATTERN ANAL, V31, P210, DOI 10.1109/TPAMI.2008.79
   Wu Y, 2013, PROC CVPR IEEE, P2411, DOI 10.1109/CVPR.2013.312
   Yang JQ, 2008, ITESS: 2008 PROCEEDINGS OF INFORMATION TECHNOLOGY AND ENVIRONMENTAL SYSTEM SCIENCES, PT 1, P1, DOI 10.1109/CVPR.2008.4587647
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Zhang KH, 2012, LECT NOTES COMPUT SC, V7574, P864, DOI 10.1007/978-3-642-33712-3_62
   Zhang L, 2013, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2013.240
   Zhang TZ, 2012, PROC CVPR IEEE, P2042, DOI 10.1109/CVPR.2012.6247908
   Zhong W, 2012, PROC CVPR IEEE, P1838, DOI 10.1109/CVPR.2012.6247882
NR 46
TC 9
Z9 10
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2015
VL 33
BP 44
EP 56
DI 10.1016/j.imavis.2014.10.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AZ5KY
UT WOS:000348261100004
DA 2024-07-18
ER

PT J
AU Narang, N
   Bourlai, T
AF Narang, N.
   Bourlai, T.
TI Face recognition in the SWIR band when using single sensor
   multi-wavelength imaging systems
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Multi-spectral imaging; Weighted score level fusion scheme; Face
   recognition; Classification; Pre-processing; SWIR band
AB In this paper, we study the problem of Face Recognition (FR) when using Single Sensor Multi-Wavelength (SSMW) imaging systems that operate in the Short-Wave Infrared (SWIR) band. The contributions of our work are four fold: First, a SWIR database is collected when using our developed SSMW system under the following scenarios, i.e. Multi-Wavelength (MW) multi-pose images were captured when the camera was focused at either 1150, 1350 or 1550 nm. Second, an automated quality-based score level fusion scheme is proposed for the classification of input MW images. Third, a weighted quality-based score level fusion scheme is proposed for the automated classification of full frontal (FF) vs. nonfrontal (NFF) face images. Fourth, a set of experiments is performed indicating that our proposed algorithms, for the classification of (i) multiwavelength images and (ii) FF vs. NFF face images, are beneficial when designing different steps of multi-spectral face recognition (FR) systems, including face detection, eye detection and face recognition. We also determined that when our SWIR-based system is focused at 1350 nm, the identification performance increases compared to focusing the camera at any of the other SWIR wavelengths available. This outcome is particularly important for unconstrained FR scenarios, where imaging at 1550 nm, at long distances and when operating at night time environments, is preferable over different SWIR wavelengths. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Narang, N.; Bourlai, T.] W Virginia Univ, MILab, Morgantown, WV 26506 USA.
C3 West Virginia University
RP Narang, N (corresponding author), W Virginia Univ, MILab, POB 6201, Morgantown, WV 26506 USA.
EM nneeru@mix.wvu.edu; Thirimachos.Bourlai@mail.wvu.edu
OI Bourlai, Thirimachos/0000-0001-8751-0836
FU Office of Naval Research (ONR) [N00014-09-C-0495]
FX This work was sponsored in part through a grant from the Office of Naval
   Research (ONR), contract N00014-09-C-0495, "Distribution A - Approved or
   Unlimited Distribution". We are also grateful to all faculty and
   students who assisted us with this work as well as the reviewers for the
   kind and constructive feedback. The views expressed in this manuscript
   are those of the authors and do not reflect the official policy or
   position of the Department of Defense, or the U.S. Government
CR [Anonymous], INT ARCH PHOTOGRAMME
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bolme DS, 2003, LECT NOTES COMPUT SC, V2626, P304
   Bourlai T., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1343, DOI 10.1109/ICPR.2010.1115
   Bourlai T., 2011, ASCERTAINING HUMAN I, P471
   Bourlai T., 2012, P SPIE INFRARED TECH, VXXXVIII
   Bourlai T, 2012, PROC SPIE, V8353, DOI 10.1117/12.919392
   Bourlai T, 2011, IEEE T INF FOREN SEC, V6, P371, DOI 10.1109/TIFS.2011.2109951
   Carr JR, 1996, COMPUT GEOSCI, V22, P849, DOI 10.1016/S0098-3004(96)00025-8
   CAVIEDESA J, 2004, SIGNAL PROCESS-IMAGE, V19
   Chang H., P IEEE INT C IM PROC
   Chang H., IEEE MACHINE VISION, V21, P201
   Fairchild M.D., 2001, Spectral and Metameric Color Imaging
   Franc V., 2004, Statistical Pattern Recognition Toolbox for Matlab
   Guillemaut JY, 2006, LECT NOTES COMPUT SC, V4225, P79
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jain AK, 2000, IEEE T PATTERN ANAL, V22, P4, DOI 10.1109/34.824819
   Jégou H, 2010, INT J COMPUT VISION, V87, P316, DOI 10.1007/s11263-009-0285-2
   KIRBY M, 1990, IEEE T PATTERN ANAL, V12, P103, DOI 10.1109/34.41390
   Li S.Z., 2006, NEAR INFRARED IMAGE, P455
   Marras Ioannis, 2011, Journal of Computing and Information Technology - CIT, V19, P255, DOI 10.2498/cit.1002024
   Namin ST, 2012, IEEE INT C INT ROBOT, P1393, DOI 10.1109/IROS.2012.6386074
   NOWAK E, 2006, EUR C COMP VIS
   Ougiaroglou S, 2007, LECT NOTES COMPUT SC, V4690, P66
   Pan ZH, 2004, PROC SPIE, V5425, P520, DOI 10.1117/12.543102
   Ross A, 2003, PATTERN RECOGN LETT, V24, P2115, DOI 10.1016/S0167-8655(03)00079-5
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Sun XH, 2006, INT GEOSCI REMOTE SE, P1103, DOI 10.1109/IGARSS.2006.285
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Vu CT, 2012, IEEE T IMAGE PROCESS, V21, P934, DOI 10.1109/TIP.2011.2169974
   Wang WL, 2012, COMPUT ELECTRON AGR, V80, P126, DOI 10.1016/j.compag.2011.07.012
   Wang Z, 2002, INT CONF ACOUST SPEE, P3313
   Whitelam C., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P209, DOI 10.1109/ICPR.2010.60
   Wu SQ, 2009, J VIS COMMUN IMAGE R, V20, P231, DOI 10.1016/j.jvcir.2009.03.002
NR 34
TC 16
Z9 20
U1 1
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2015
VL 33
BP 26
EP 43
DI 10.1016/j.imavis.2014.10.005
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AZ5KY
UT WOS:000348261100003
DA 2024-07-18
ER

PT J
AU Zagrouba, E
   Ben Gamra, S
   Najjar, A
AF Zagrouba, Ezzeddine
   Ben Gamra, Siwar
   Najjar, Asma
TI Model-based graph-cut method for automatic flower segmentation with
   spatial constraints
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Automatic flower image segmentation; Graph-cut; Spatial prior
ID OPTIMIZATION; EXTRACTION
AB In this paper, we present an accelerated system for segmenting flower images based on graph-cut technique which formulates the segmentation problem as an energy function minimization. The contribution of this paper consists to propose an improvement of the classical used energy function, which is composed of a data-consistent term and a boundary term. For this, we integrate an additional data-consistent term based on the spatial prior and we add gradient information in the boundary term. Then, we propose an automated coarse-to-fine segmentation method composed mainly of two levels: coarse segmentation and fine segmentation. First, the coarse segmentation level is based on minimizing the proposed energy function. Then, the fine segmentation is done by optimizing the energy function through the standard graph-cut technique. Experiments were performed on a subset of Oxford flower database and the obtained results are compared to the reimplemented method of Nilsback et al. [1]. The evaluation shows that our method consumes less CPU time and it has a satisfactory accuracy compared with the mentioned method above [1]. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Zagrouba, Ezzeddine; Ben Gamra, Siwar; Najjar, Asma] Univ Tunis Elmanar, Higher Inst Comp Sci, Team Res SIIVA Lab Riadi, Tunis, Tunisia.
C3 Universite de Tunis-El-Manar
RP Zagrouba, E (corresponding author), Higher Inst Comp Sci ISI, 2 Rue Abourraihan Al Bayrouni, Ariana 2080, Tunisia.
EM ezzeddine.zagrouba@fsm.rnu.tn
RI Zagrouba, Ezzeddine/D-7896-2014
OI Zagrouba, Ezzeddine/0000-0002-2574-9080; BEN GAMRA,
   siwar/0000-0001-5546-5292
CR [Anonymous], 2006, CVPR, DOI DOI 10.1109/CVPR.2006.69
   [Anonymous], IEEE C COMP VIS PATT
   Aydin D, 2011, PROCEDIA COMPUT SCI, V3, DOI 10.1016/j.procs.2010.12.088
   Bo Peng, 2009, Computer Vision - ACCV 2009. 9th Asian Conference on Computer Vision. Revised Selected Papers, P677
   Boykov Y, 2006, HANDBOOK OF MATHEMATICAL MODELS IN COMPUTER VISION, P79, DOI 10.1007/0-387-28831-7_5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Candemir S, 2010, LECT NOTES COMPUT SC, V6111, P117, DOI 10.1007/978-3-642-13772-3_13
   Chai Y., 2010, RECOGNITION LARGE NU
   Chai YN, 2011, IEEE I CONF COMP VIS, P2579, DOI 10.1109/ICCV.2011.6126546
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Das M, 1999, IEEE INTELL SYST APP, V14, P24, DOI 10.1109/5254.796084
   Dorigo M, 2006, IEEE COMPUT INTELL M, V1, P28, DOI 10.1109/MCI.2006.329691
   Fradet M., 2010, CONTRIBUTIONS SEGMEN
   Freedman D, 2005, PROC CVPR IEEE, P755
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Fukuda Keita, 2009, 2009 IEEE 13th International Symposium on Consumer Electronics (ISCE), P36, DOI 10.1109/ISCE.2009.5156907
   Itti L, 1998, IEEE T PATTERN ANAL, V20, P1254, DOI 10.1109/34.730558
   Jugui G., 2004, MULTIRESOLUTION REGI
   Jung C, 2010, IEEE INT CON MULTI, P590, DOI 10.1109/ICME.2010.5582577
   Kolmogorov V, 2005, IEEE I CONF COMP VIS, P564
   Marji M, 2004, LECT NOTES COMPUT SC, V3322, P512
   Mortensen E. N., 1995, Computer Graphics Proceedings. SIGGRAPH 95, P191, DOI 10.1145/218380.218442
   Nilsback M., 2009, FLOWER DATASETS
   Nilsback ME, 2010, IMAGE VISION COMPUT, V28, P1049, DOI 10.1016/j.imavis.2009.10.001
   Peng B, 2011, PATTERN RECOGN, V44, P2527, DOI 10.1016/j.patcog.2011.03.024
   REYNOLDS DA, 1995, SPEECH COMMUN, V17, P91, DOI 10.1016/0167-6393(95)00009-D
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Saitoh T, 2004, INT C PATT RECOG, P27, DOI 10.1109/ICPR.2004.1333997
   Slabaugh G, 2005, IEEE IMAGE PROC, P1973
   Tao WB, 2008, IEEE T SYST MAN CY A, V38, P1181, DOI 10.1109/TSMCA.2008.2001068
   Veksler O, 2008, LECT NOTES COMPUT SC, V5304, P454, DOI 10.1007/978-3-540-88690-7_34
   Yangel Boris, 2011, Energy Minimization Methods in Computer Vision and Pattern Recognition. Proceedings 8th International Conference, EMMCVPR 2011, P247, DOI 10.1007/978-3-642-23094-3_18
   Yining Deng, 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P446, DOI 10.1109/CVPR.1999.784719
NR 33
TC 10
Z9 10
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1007
EP 1020
DI 10.1016/j.imavis.2014.08.012
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600004
DA 2024-07-18
ER

PT J
AU Lee, S
   Kim, JH
AF Lee, SeongHun
   Kim, Jin Hyung
TI Integrating multiple character proposals for robust scene text
   extraction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Scene text extraction; Two-stage CRF models; Multiple image
   segmentations; Component; Character proposal
ID OBJECT DETECTION; COLOR; LOCALIZATION; RECOGNITION
AB Text contained in scene images provides the semantic context of the images. For that reason, robust extraction of text regions is essential for successful scene text understanding. However, separating text pixels from scene images still remains as a challenging issue because of uncontrolled lighting conditions and complex backgrounds. In this paper, we propose a two-stage conditional random field (TCRF) approach to robustly extract text regions from the scene images. The proposed approach models the spatial and hierarchical structures of the scene text, and it finds text regions based on the scene text model. In the first stage, the system generates multiple character proposals for the given image by using multiple image segmentations and a local CRF model. In the second stage, the system selectively integrates the generated character proposals to determine proper character regions by using a holistic CRF model. Through the TCRF approach, we cast the scene text separation problem as a probabilistic labeling problem, which yields the optimal label configuration of pixels that maximizes the conditional probability of the given image. Experimental results indicate that our framework exhibits good performance in the case of the public databases. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Lee, SeongHun; Kim, Jin Hyung] Korea Adv Inst Sci & Technol, Taejon 305701, South Korea.
C3 Korea Advanced Institute of Science & Technology (KAIST)
RP Lee, S (corresponding author), Korea Adv Inst Sci & Technol, 373-1 Guseong Dong, Taejon 305701, South Korea.
EM leesh@ai.kaist.ac.kr; jkim@ai.kaist.ac.kr
RI Kim, Jin Hyung/C-1923-2011
FU Industrial Strategic Technology Development Program [10035348]; Ministry
   of Knowledge Economy (MKE, Korea)
FX This work was supported by the Industrial Strategic Technology
   Development Program (10035348, Development of a Cognitive Planning and
   Learning Model for Mobile Platforms) funded by the Ministry of Knowledge
   Economy (MKE, Korea).
CR [Anonymous], P 21 INT C MACH LEAR
   [Anonymous], 2005, P MULT INF RETR WORK
   [Anonymous], 2001, PROC 18 INT C MACH L
   Berkhin P, 2006, GROUPING MULTIDIMENSIONAL DATA: RECENT ADVANCES IN CLUSTERING, P25
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Davidson I., 2005, P 5 INT C DAT MIN, P138
   Egyul Kim, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P166, DOI 10.1109/ICDAR.2009.21
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Freund Y., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P148
   Gong YH, 1999, MULTIMEDIA SYST, V7, P449, DOI 10.1007/s005300050145
   Hanif S.M., 2008, Pattern Recognition, P1
   Jeong CB, 2007, FOURTH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE DISCOVERY, VOL 4, PROCEEDINGS, P624, DOI 10.1109/FSKD.2007.617
   Jin XB, 2010, PATTERN RECOGN, V43, P2428, DOI 10.1016/j.patcog.2010.01.013
   Kasar T., 2009, P 3 INT WORKSH CAM B
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lan XY, 2006, LECT NOTES COMPUT SC, V3952, P269
   Lee S., 2009, P CHIN C PATT REC, P1
   Li HP, 2000, IEEE T IMAGE PROCESS, V9, P147, DOI 10.1109/83.817607
   Li S. Z., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P361, DOI 10.1007/BFb0028368
   Liu YX, 2006, IEICE T INF SYST, VE89D, P1221, DOI 10.1093/ietisy/e89-d.3.1221
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Mancas-Thillou C, 2007, COMPUT VIS IMAGE UND, V107, P97, DOI 10.1016/j.cviu.2006.11.010
   Murphy KP, 1999, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, PROCEEDINGS, P467
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Neumann L, 2011, PROC INT CONF DOC, P687, DOI 10.1109/ICDAR.2011.144
   Opelt Andreas., 2006, IEEE COMPUTER SOC C, V1, P3
   Pal C., 2006, P 2006 INT C AC SPEE, P5
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Pantofaru C, 2008, LECT NOTES COMPUT SC, V5304, P481, DOI 10.1007/978-3-540-88690-7_36
   Potetz Brian., 2007, Computer Vision and Pattern Recognition, P1
   SeongHun Lee, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3983, DOI 10.1109/ICPR.2010.969
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Smith M., VIDEO SKIMMING QUICK
   Subramanian K, 2007, PROC INT CONF DOC, P33
   Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0
   Yi CC, 2011, IEEE T IMAGE PROCESS, V20, P2594, DOI 10.1109/TIP.2011.2126586
   Zhang HM, 2006, IMAGE VISION COMPUT, V24, P327, DOI 10.1016/j.imavis.2005.11.010
   Zhang Z, 2004, PROC CVPR IEEE, P10
NR 38
TC 22
Z9 25
U1 0
U2 18
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2013
VL 31
IS 11
BP 823
EP 840
DI 10.1016/j.imavis.2013.08.007
PG 18
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 268PX
UT WOS:000328184100001
DA 2024-07-18
ER

PT J
AU Metaxas, D
   Zhang, ST
AF Metaxas, Dimitris
   Zhang, Shaoting
TI A review of motion analysis methods for human Nonverbal Communication
   Computing
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Nonverbal Communication Computing; Motion analysis; Face tracking;
   Facial expression recognition; Gesture recognition; Group activity
   analysis
ID FACIAL EXPRESSION RECOGNITION; ACTIVE APPEARANCE MODELS; DENSITY
   PROPAGATION; DEFORMABLE MODELS; BINARY PATTERNS; EVENT DETECTION; FACE
   TRACKING; OPTICAL-FLOW; SHAPE; ROBUST
AB Human Nonverbal Communication Computing aims to investigate how people exploit nonverbal aspects of their communication to coordinate their activities and social relationships. Nonverbal behavior plays important roles in message production and processing, relational communication, social interaction and networks, deception and impression management, and emotional expression. This is a fundamental yet challenging research topic. To effectively analyze Nonverbal Communication Computing, motion analysis methods have been widely investigated and employed. In this paper, we introduce the concept and applications of Nonverbal Communication Computing and also review some of the motion analysis methods employed in this area. They include face tracking, expression recognition, body reconstruction, and group activity analysis. In addition, we also discuss some open problems and the future directions of this area. (C) 2013 Published by Elsevier B.V.
C1 [Metaxas, Dimitris; Zhang, Shaoting] Rutgers State Univ, Ctr Computat Biomed Imaging & Modeling CBIM, Dept Comp Sci, Piscataway, NJ 08855 USA.
C3 Rutgers University System; Rutgers University New Brunswick
RP Metaxas, D (corresponding author), Rutgers State Univ, Ctr Computat Biomed Imaging & Modeling CBIM, Dept Comp Sci, Piscataway, NJ 08855 USA.
OI Zhang, Shaoting/0000-0002-8719-448X
FU NSF [0964597, 1064965, 1059281, NASA-NSBRI-NBTS01601,
   NASA-NSBRI-NBTS004, ONR-N000140910104]; Direct For Computer & Info Scie
   & Enginr; Division Of Computer and Network Systems [1059281] Funding
   Source: National Science Foundation; Direct For Computer & Info Scie &
   Enginr; Div Of Information & Intelligent Systems [0964597, 1064965]
   Funding Source: National Science Foundation
FX The authors would like to thank all the reviewers for their constructive
   suggestions. We also would like to thank our long time collaborators
   Judee Burgoon (UA), David Dinges (UPENN), and Carol Neidle (BU). Metaxas
   would like to thank his previous PhD students Ioannis Kakadiaris (Univ
   of Houston), Atul Kanaujia (Object Video), Siome Goldenstein (UNICAMP,
   Brazil), Dimitris Samaras (SUNY Stony Brook), Christian Vogler
   (Gallaudet) and Gabriel Tsechpenakis (IUPUI) for their seminal work in
   this area. Finally, we would like to thank our current CBIM students and
   colleagues Fei Yang, Xinyi Cui, Mark Dilsizian, Christophe Restif and
   Qiong Hu for their help and valuable suggestions. This work is supported
   in part by NSF (award numbers 0964597, 1064965, 1059281),
   NASA-NSBRI-NBTS01601, NASA-NSBRI-NBTS004, and ONR-N000140910104.
CR Agarwal A, 2004, PROC CVPR IEEE, P882
   Ali S., 2007, PROC 15 ACM INT C MU, P357
   Ali S, 2008, LECT NOTES COMPUT SC, V5303, P1, DOI 10.1007/978-3-540-88688-4_1
   Ali S, 2010, IEEE T PATTERN ANAL, V32, P288, DOI 10.1109/TPAMI.2008.284
   Alon J, 2009, IEEE T PATTERN ANAL, V31, P1685, DOI 10.1109/TPAMI.2008.203
   Andrade EL, 2006, INT C PATT RECOG, P175
   [Anonymous], 2012, Computer Vision and Pattern Recognition Workshops CVPRW
   [Anonymous], IMAGE VIS COMPUT
   [Anonymous], 2003, P 2003 C COMP VIS PA, DOI DOI 10.1109/CVPRW.2003.10057
   [Anonymous], 2004, 2004 C COMP VIS PATT
   [Anonymous], 2007, IEEE C COMPUTER VISI
   [Anonymous], P IEEE INT C COMP VI, DOI DOI 10.1109/CVPR.2000.854758
   [Anonymous], P 2008 8 IEEE INT C, DOI DOI 10.1109/AFGR.2008.4813324
   Antonini G, 2006, INT J COMPUT VISION, V69, P159, DOI 10.1007/s11263-005-4797-0
   Athitsos Vassilis, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563181
   AZARBAYEJANI A, 1993, IEEE T PATTERN ANAL, V15, P602, DOI 10.1109/34.216730
   AZARBAYEJANI A, 1993, COMP VIS PATT REC 19, P294
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baltrusaitis T, 2012, PROC CVPR IEEE, P2610, DOI 10.1109/CVPR.2012.6247980
   BASSILI JN, 1979, J PERS SOC PSYCHOL, V37, P2049, DOI 10.1037/0022-3514.37.11.2049
   Basso C, 2003, FIRST IEEE INTERNATIONAL WORKSHOP ON HIGHER-LEVEL KNOWLEDGE IN 3D MODELING AND MOTION ANALYSIS, PROCEEDINGS, P3, DOI 10.1109/HLK.2003.1240853
   Black MJ, 1997, INT J COMPUT VISION, V25, P23, DOI 10.1023/A:1007977618277
   BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Blanz V, 2003, COMPUT GRAPH FORUM, V22, P641, DOI 10.1111/1467-8659.t01-1-00712
   Bourdev L, 2009, IEEE I CONF COMP VIS, P1365, DOI 10.1109/ICCV.2009.5459303
   Cai Q, 2010, LECT NOTES COMPUT SC, V6313, P229
   Chang Y, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P28
   Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Cu L, 2008, LECT NOTES COMPUT SC, V5302, P413, DOI 10.1007/978-3-540-88682-2_32
   Cui XY, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1263
   DeCarlo D, 1996, PROC CVPR IEEE, P231, DOI 10.1109/CVPR.1996.517079
   DeCarlo D, 2000, INT J COMPUT VISION, V38, P99, DOI 10.1023/A:1008122917811
   Dibeklioglu H, 2012, LECT NOTES COMPUT SC, V7574, P525, DOI 10.1007/978-3-642-33712-3_38
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Fanelli Gabriele, 2011, Pattern Recognition. Proceedings 33rd DAGM Symposium, P101, DOI 10.1007/978-3-642-23123-0_11
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Fei Yang, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P272, DOI 10.1109/FG.2011.5771410
   Feng X., 2005, Pattern Recognition and Image Analysis, V15, P546
   Ferrari V, 2008, PROC CVPR IEEE, DOI 10.1109/CVPR.2008.4587468
   Friedman N., 1997, PROC UNCERTAINTY ART, P175
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P145, DOI 10.1109/TSMCC.2009.2035631
   Gu HS, 2004, PROC CVPR IEEE, P870
   Hadid A, 2007, LECT NOTES COMPUT SC, V4778, P1
   Haritaoglu I, 2000, IEEE T PATTERN ANAL, V22, P809, DOI 10.1109/34.868683
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hassner T, 2012, PROC CVPR IEEE, P1522, DOI 10.1109/CVPR.2012.6247842
   Helbing D., PHYS REV E
   Howe N., 1999, Neural Information Processing Systems (NIPS 1999), V1999, P1
   Huang JZ, 2011, COMPUT VIS IMAGE UND, V115, P1610, DOI 10.1016/j.cviu.2011.06.011
   Huang JZ, 2010, LECT NOTES COMPUT SC, V6313, P607
   Huang JZ, 2010, ANN STAT, V38, P1978, DOI 10.1214/09-AOS778
   Huang PSS, 2003, OPT ENG, V42, P163, DOI 10.1117/1.1525272
   Huang XH, 2012, IEEE SIGNAL PROC LET, V19, P243, DOI 10.1109/LSP.2012.2188890
   Huang Y, 2007, AM SOC TEST MATER, V1486, P1
   Ikizler N, 2009, IMAGE VISION COMPUT, V27, P1515, DOI 10.1016/j.imavis.2009.02.002
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Kakadiaris I, 2000, IEEE T PATTERN ANAL, V22, P1453, DOI 10.1109/34.895978
   Kanaujia A, 2006, INT C PATT RECOG, P33
   Ke Y, 2005, IEEE I CONF COMP VIS, P166
   Kehl R, 2005, PROC CVPR IEEE, P129
   Kellokumpu V., 2008, P BRIT MACH VIS C BM, P1
   Kellokumpu V, 2011, MACH VISION APPL, V22, P767, DOI 10.1007/s00138-009-0233-8
   Konrad J., 2010, HDB IMAGE VIDEO PROC
   Kumano S, 2009, INT J COMPUT VISION, V83, P178, DOI 10.1007/s11263-008-0185-x
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Laptev I, 2008, PROC CVPR IEEE, P3222, DOI 10.1109/cvpr.2008.4587756
   Lee CS, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO - ICME 2006, VOLS 1-5, PROCEEDINGS, P65, DOI 10.1109/ICME.2006.262551
   Lee CS, 2005, LECT NOTES COMPUT SC, V3723, P17
   Lee M.W., 2004, IEEE COMP SOC C COMP, V2
   Li XB, 2013, IEEE INT CONF AUTOMA, DOI 10.1109/FG.2013.6553717
   Li XL, 2010, INT CONF SIGN PROCES, P1366, DOI 10.1109/ICOSP.2010.5656891
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Liu BY, 2010, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2010.5539823
   Liu J., 2008, INT C COMP VIS PATT, P1
   Liu J., 2013, INT C AUT FAC GEST R
   Liu JE, 2012, COMPUT VIS IMAGE UND, V116, P361, DOI 10.1016/j.cviu.2011.08.010
   Liu JG, 2009, PROC CVPR IEEE, P1996
   Liu JJ, 2013, IEEE INT CONF AUTOMA
   Loy G, 2004, LECT NOTES COMPUT SC, V2034, P442
   Lu S, 2003, PROC CVPR IEEE, P443
   Lu S., 2005, PROC 38 ANN HAWAII I
   Maalej Ahmed, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4129, DOI 10.1109/ICPR.2010.1003
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Matthews I, 2007, INT J COMPUT VISION, V75, P93, DOI 10.1007/s11263-007-0043-2
   Medioni G, 2001, IEEE T PATTERN ANAL, V23, P873, DOI 10.1109/34.946990
   Mehran R, 2009, PROC CVPR IEEE, P935, DOI 10.1109/CVPRW.2009.5206641
   Metaxas D., 2012, INT C LANG RES EV
   Metaxas D., 1997, Physics-based deformable models: applications to computer vision, graphics, and medical imaging, V389
   Michael N., 2011, 18 IAA HUM SPAC S
   Michael N, 2010, LECT NOTES COMPUT SC, V6316, P462, DOI 10.1007/978-3-642-15567-3_34
   Mikolajczyk K, 2005, INT J COMPUT VISION, V65, P43, DOI 10.1007/s11263-005-3848-x
   Mitra S, 2007, IEEE T SYST MAN CY C, V37, P311, DOI 10.1109/TSMCC.2007.893280
   Neidle C., 2012, P 5 WORKSH REPR PROC
   Ni BB, 2009, PROC CVPR IEEE, P1470, DOI 10.1109/CVPRW.2009.5206853
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Nowozin S, 2007, IEEE I CONF COMP VIS, P1727
   Oikonomopoulos A, 2009, IMAGE VISION COMPUT, V27, P1814, DOI 10.1016/j.imavis.2009.05.010
   Pantic M, 2004, IEEE T SYST MAN CY B, V34, P1449, DOI 10.1109/TSMCB.2004.825931
   Pantic M, 2000, IEEE T PATTERN ANAL, V22, P1424, DOI 10.1109/34.895976
   Park D, 2011, IEEE I CONF COMP VIS, P2627, DOI 10.1109/ICCV.2011.6126552
   Pellegrini S, 2009, IEEE I CONF COMP VIS, P261, DOI 10.1109/ICCV.2009.5459260
   Pfister T, 2011, IEEE I CONF COMP VIS, P1449, DOI 10.1109/ICCV.2011.6126401
   Pighin F., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P143, DOI 10.1109/ICCV.1999.791210
   Plänkers R, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P394, DOI 10.1109/ICCV.2001.937545
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Prati A., 2008, 2008 IEEE C COMP VIS, P1
   Proesmans M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P336, DOI 10.1109/ICPR.1996.546966
   Qadir O, 2011, IEEE C EVOL COMPUTAT, P208
   Qian Yu, 2009, 2009 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P2671, DOI 10.1109/CVPRW.2009.5206541
   Rapantzikos K, 2009, PROC CVPR IEEE, P1454, DOI 10.1109/CVPRW.2009.5206525
   Rosales R., 2002, NIPS, V1, P2
   Rudovic O, 2010, LECT NOTES COMPUT SC, V6312, P350, DOI 10.1007/978-3-642-15552-9_26
   Sapp B, 2011, PROC CVPR IEEE, P1281, DOI 10.1109/CVPR.2011.5995607
   Saragih JM, 2011, INT J COMPUT VISION, V91, P200, DOI 10.1007/s11263-010-0380-4
   Saragih JM, 2009, IEEE I CONF COMP VIS, P1034, DOI 10.1109/ICCV.2009.5459377
   Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P, 2009, IEEE I CONF COMP VIS, P381, DOI 10.1109/ICCV.2009.5459224
   Shan C., 2005, IEEE INT C IM PROC I, V2
   Shan C., 2005, BRIT MACH VIS C, V1
   Shreve Matthew, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P51, DOI 10.1109/FG.2011.5771451
   Sigal L., 2004, P IEEE C COMP VIS PA, V1, pI
   Sigal L., 2007, NIPS, V20, P1337
   Simo-Serra E, 2012, PROC CVPR IEEE, P2673, DOI 10.1109/CVPR.2012.6247988
   Singh VK, 2010, LECT NOTES COMPUT SC, V6313, P314
   Sminchisescu C, 2005, PROC CVPR IEEE, P390
   SMITH K., 2006, IEEE Performance Evaluation of Tracking and Surveillance Workshop (PETS), P75
   Souvenir R., 2008, Proc. IEEE Conference on Computer Vision and Pattern Recognition, P1
   Souvenir R, 2009, EURASIP J IMAGE VIDE, DOI 10.1155/2009/738702
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Sun M, 2011, IEEE I CONF COMP VIS, P723, DOI 10.1109/ICCV.2011.6126309
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Sung J, 2008, INT J COMPUT VISION, V80, P260, DOI 10.1007/s11263-007-0125-1
   Swears E., 2009, WORKSH MOT VID COMP, P1
   Tang H, 2008, IEEE INT CONF AUTOMA, P110
   TERZOPOULOS D, 1993, IEEE T PATTERN ANAL, V15, P569, DOI 10.1109/34.216726
   Treuille A, 2006, ACM T GRAPHIC, V25, P1160, DOI 10.1145/1141911.1142008
   Tsalakanidou Filareti, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P4, DOI 10.1109/CVPR.2009.5204281
   Tsechpenakis G, 2006, COMPUT VIS IMAGE UND, V104, P140, DOI 10.1016/j.cviu.2006.07.009
   VALSTAR M., 2005, COMPUTER VISION PATT, P76, DOI DOI 10.1109/CVPR.2005.457
   Vogler C, 2007, IEEE I CONF COMP VIS, P1456
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   Wang Y, 2004, COMPUT GRAPH FORUM, V23, P677, DOI 10.1111/j.1467-8659.2004.00800.x
   Wang Y., 2008, CVPR 2008
   Weise T, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964972
   Whitehill J., 2006, 7 INT C AUT FAC GEST
   Wu J, 2007, PROCEEDINGS OF THE 2007 IEEE INTERNATIONAL CONFERENCE ON SERVICE OPERATIONS AND LOGISTICS, AND INFORMATICS, P7, DOI 10.1109/SOLI.2007.4383891
   Wu Q, 2011, LECT NOTES COMPUT SC, V6975, P152, DOI 10.1007/978-3-642-24571-8_16
   Wu SD, 2010, PROC CVPR IEEE, P2054, DOI 10.1109/CVPR.2010.5539882
   Xiao J, 2004, PROC CVPR IEEE, P535
   Xinyi Cui, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3161, DOI 10.1109/CVPR.2011.5995558
   YACOOB Y, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P70, DOI 10.1109/CVPR.1994.323812
   Yang F, 2012, PROC CVPR IEEE, P861, DOI 10.1109/CVPR.2012.6247759
   Yang F, 2011, ACM T GRAPHIC, V30, DOI 10.1145/1964921.1964955
   Yang P., 2008, P IEEE COMPUTER VISI, P1
   Yang P, 2007, PROC CVPR IEEE, P688
   Yang P, 2009, IEEE I CONF COMP VIS, P1018, DOI 10.1109/ICCV.2009.5459371
   Yang P, 2011, COMPUT VIS IMAGE UND, V115, P456, DOI 10.1016/j.cviu.2010.11.015
   Yang P, 2010, PROC CVPR IEEE, P2638, DOI 10.1109/CVPR.2010.5539978
   Yang P, 2009, PATTERN RECOGN LETT, V30, P132, DOI 10.1016/j.patrec.2008.03.014
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Yu T, 2009, PROC CVPR IEEE, P1462, DOI 10.1109/CVPRW.2009.5206526
   Yu W, 2007, PHYS REV B, V76, DOI 10.1103/PhysRevB.76.020503
   Yu X., 2013, HAW INT C SYST SCI H
   Yuan M., 2006, Journal of the Royal Statistical Society, Series B, V70, P53
   Yuille A., 1993, DEFORMABLE TEMPLATES, P21
   Zafeiriou S, 2012, IMAGE VISION COMPUT, V30, P681, DOI 10.1016/j.imavis.2012.09.001
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhang L, 2004, ACM T GRAPHIC, V23, P548, DOI 10.1145/1015706.1015759
   Zhang ST, 2012, MED IMAGE ANAL, V16, P1385, DOI 10.1016/j.media.2012.07.007
   Zhang ST, 2012, MED IMAGE ANAL, V16, P265, DOI 10.1016/j.media.2011.08.004
   Zhang ST, 2011, PROC CVPR IEEE, P1025, DOI 10.1109/CVPR.2011.5995322
   Zhang ST, 2010, PROC CVPR IEEE, P3312, DOI 10.1109/CVPR.2010.5540036
   Zhang ZY, 2012, IEEE MULTIMEDIA, V19, P4, DOI 10.1109/MMUL.2012.24
   Zhao G., IMAGE VIS COMPUT
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
   Zhao GY, 2009, PATTERN RECOGN LETT, V30, P1117, DOI 10.1016/j.patrec.2009.03.018
   Zhenqing Z., 2008, P INT C ELECT PACKAG, P1
   Zhou MC, 2010, PROC CVPR IEEE, P701, DOI 10.1109/CVPR.2010.5540146
   Zhou XS, 2005, IEEE T PATTERN ANAL, V27, P115, DOI 10.1109/TPAMI.2005.3
   Zhou Y., 2008, 2008 IEEE C COMP VIS, P1
NR 186
TC 33
Z9 39
U1 3
U2 75
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2013
VL 31
IS 6-7
BP 421
EP 433
DI 10.1016/j.imavis.2013.03.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 172UH
UT WOS:000321029900002
DA 2024-07-18
ER

PT J
AU Dagher, I
   Issa, S
AF Dagher, Issam
   Issa, Saad
TI Subband effect of the wavelet fuzzy C-means features in texture
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Texture classification; Wavelet transform; FCM; Subbands; K-nearest
   neighbors
AB The wavelet transform is an important analysis used in the field of texture classification. It decomposes an image into subbands. Some of the subbands contain more significant coefficients than others. Based on this property, we propose a texture analysis and classification approach using a combination of the fuzzy C-means clustering method (FCM) and the wavelet transform. By taking the energy coefficients of two pairs of frequency channels resulting from 2D wavelet transform, and grouping the data into a specific number of clusters, we were able to build a feature list for each texture. The feature list is obtained by applying the FCM on each frequency channel pair. The centers obtained are used as the features for every combination of frequency channel pair: the partition matrix generated from the FCM is used as a method for determining the k-nearest neighbors of an unknown texture. The subband effect of the wavelet FCM features is studied by varying the number of decomposition levels of the wavelet tree. Optimal number of features was obtained by varying the number of clusters and the k-nearest neighbors of the FCM. Experiments show that this method outperformed other methods (linear regression model. Gabor transform). (C) 2012 Elsevier B.V. All rights reserved.
C1 [Dagher, Issam; Issa, Saad] Univ Balamand, Dept Comp Engn, Koura, Lebanon.
C3 University Balamand
RP Dagher, I (corresponding author), Univ Balamand, Dept Comp Engn, Koura, Lebanon.
EM dagheri@balamand.edu.lb
CR Akansu AliN., 1992, Multiresolution Signal Decomposition : Transforms, Subbands, Wavelets
   [Anonymous], 2004, Wiley InterScience electronic collection.
   [Anonymous], 2005, INT ARAB J INFORM TE
   Bezdek James C., 1981, PATTERN RECOGN
   Çarkacioglu A, 2003, PATTERN RECOGN, V36, P2615, DOI 10.1016/S0031-3203(03)00171-7
   Chang T., 1992, ICASSP-92: 1992 IEEE International Conference on Acoustics, Speech and Signal Processing (Cat. No.92CH3103-9), P661, DOI 10.1109/ICASSP.1992.226311
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   CHEN Yan-hua, 1995, NOVEL TECHNIQUES IMA, P1
   Clausi DA, 2005, IEEE T IMAGE PROCESS, V14, P925, DOI 10.1109/TIP.2005.849319
   Epifanio I, 2002, IEEE T IMAGE PROCESS, V11, P859, DOI 10.1109/TIP.2002.801119
   Finch H., 2005, Journal of Data Science, V3, P85
   Huang K, 2006, SIGNAL PROCESS, V86, P1410, DOI 10.1016/j.sigpro.2005.07.032
   Kaymak M.S. Uzay, 2000, J ECON LIT, P2
   Mallat S., 2003, WAVELET TOUR SIGNAL, P220
   Mills P., 2012, INT J REMOTE SENS
   Ojala T, 2004, TEXTURE CLASSIFICATI
   Peleg N., 2002, IEEE INT C SIGNAL PR, V2, P1
   Popovic R, 1999, TELSIKS '99: 4TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS IN MODERN SATELLITE, CABLE AND BROADCASTING SERVICES, PROCEEDINGS, VOLS 1 AND 2, P149, DOI 10.1109/TELSKS.1999.804715
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   SHAPIRO JM, 1993, IEEE T SIGNAL PROCES, V41, P3445, DOI 10.1109/78.258085
   Wang ZZ, 2008, IEEE T IMAGE PROCESS, V17, P1421, DOI 10.1109/TIP.2008.926150
   Zeng XY, 2004, SIGNAL PROCESS, V84, P589, DOI 10.1016/j.sigpro.2003.11.021
NR 22
TC 8
Z9 8
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2012
VL 30
IS 11
BP 896
EP 905
DI 10.1016/j.imavis.2012.07.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 052CW
UT WOS:000312176300008
DA 2024-07-18
ER

PT J
AU Savran, A
   Sankur, B
   Bilge, MT
AF Savran, Arman
   Sankur, Bulent
   Bilge, M. Taha
TI Regression-based intensity estimation of facial action units
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action unit intensity estimation; 3D facial expression recognition;
   Facial Action Coding System; Feature selection; AdaBoost.RT; SVM
   regression
ID RECOGNITION
AB Facial Action Coding System (FACS) is the de facto standard in the analysis of facial expressions. FACS describes expressions in terms of the configuration and strength of atomic units called Action Units: AUs. FACS defines 44 AUs and each AU intensity is defined on a nonlinear scale of five grades. There has been significant progress in the literature on the detection of AUs. However, the companion problem of estimating the AU strengths has not been much investigated. In this work we propose a novel AU intensity estimation scheme applied to 2D luminance and/or 3D surface geometry images. Our scheme is based on regression of selected image features. These features are either non-specific, that is, those inherited from the AU detection algorithm, or are specific in that they are selected for the sole purpose of intensity estimation. For thoroughness, various types of local 3D shape indicators have been considered, such as mean curvature, Gaussian curvature, shape index and curvedness, as well as their fusion. The feature selection from the initial plethora of Gabor moments is instrumented via a regression that optimizes the AU intensity predictions. Our AU intensity estimator is person-independent and when tested on 25 AUs that appear singly or in various combinations, it performs significantly better than the state-of-the-art method which is based on the margins of SVMs designed for AU detection. When evaluated comparatively, one can see that the 2D and 3D modalities have relative merits per upper face and lower face AUs, respectively, and that there is an overall improvement if 2D and 3D intensity estimations are used in fusion. (c) 2011 Elsevier B.V. All rights reserved.
C1 [Savran, Arman; Sankur, Bulent] Bogazici Univ, Elect Elect Engn Dept, Istanbul, Turkey.
   [Bilge, M. Taha] Bogazici Univ, Dept Psychol, Istanbul, Turkey.
C3 Bogazici University; Bogazici University
RP Savran, A (corresponding author), Bogazici Univ, Elect Elect Engn Dept, Istanbul, Turkey.
EM arman.savran@boun.edu.tr
RI Savran, Arman/AAS-6577-2020; Sankur, Bulent/N-4663-2017
OI Savran, Arman/0000-0001-5142-6384; 
FU Bogazici University fund [09HA202D]; TUBITAK project [107E001]; Turkish
   State Planning Organization (DPT) under the TAM Project [2007K120610]
FX This work is supported by the Bogazici University fund 09HA202D, by the
   TUBITAK project 107E001 grants and by the Turkish State Planning
   Organization (DPT) under the TAM Project, number 2007K120610. Part of
   the calculations reported in this paper were performed at TUBITAK
   ULAKBIM, High Performance and Grid Computing Center (TR-Grid
   e-Infrastructure).
CR [Anonymous], INT C IM AN REC ICIA
   [Anonymous], IEEE CVPR WORKSH 3D
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], IEEE C COMP VIS PATT
   Bartlett M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.6.22-35
   Cherkassky V, 1997, IEEE Trans Neural Netw, V8, P1564, DOI 10.1109/TNN.1997.641482
   Cowie R, 2001, IEEE SIGNAL PROC MAG, V18, P32, DOI 10.1109/79.911197
   Doulamis N., 2006, EUR SIGN PROC C EUSI
   Drucker H., 1997, INT C MACH LEARN SAN
   Ekman P, 1978, FACIAL ACTION CODING
   Fasel B, 2003, PATTERN RECOGN, V36, P259, DOI 10.1016/S0031-3203(02)00052-3
   Karpinsky N., 2010, J REAL-TIME IMAGE PR, P1
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   KOENDERINK JJ, 1992, IMAGE VISION COMPUT, V10, P557, DOI 10.1016/0262-8856(92)90076-F
   Lucey S., 2007, Investigating Spontaneous Facial Action Recognition through AAM Representations of the Face
   Mahoor M., 2009, IEEE CVPR WORKSH HUM
   Modrow D., 2008, NOVEL SENSOR SYSTEM
   Mpiperis I., 2008, IEEE INT C ACC SPEEC
   Pantic M, 2000, SEVENTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-2001) / TWELFTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-2000), P1026
   Savran A., 2011, EUR SIGN PROC C EUSI
   Savran A, 2012, PATTERN RECOGN, V45, P767, DOI 10.1016/j.patcog.2011.07.022
   Shrestha DL, 2006, NEURAL COMPUT, V18, P1678, DOI 10.1162/neco.2006.18.7.1678
   Telea A., 2004, Journal of Graphics Tools, V9, P23, DOI 10.1080/10867651.2004.10487596
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009
   Whitehill J, 2009, IEEE T PATTERN ANAL, V31, P2106, DOI 10.1109/TPAMI.2009.42
   Yang P., 2009, INT C COMP VIS ICCV
NR 27
TC 88
Z9 91
U1 1
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2012
VL 30
IS 10
BP 774
EP 784
DI 10.1016/j.imavis.2011.11.008
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 027YD
UT WOS:000310389100009
DA 2024-07-18
ER

PT J
AU Huang, WL
   Yin, HJ
AF Huang, Weilin
   Yin, Hujun
TI On nonlinear dimensionality reduction for face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dimensionality reduction; Nonlinear manifold; Subspace learning;
   Principal component analysis; Feature representation; Face recognition
ID NEURAL-NETWORK; DISCRIMINANT-ANALYSIS; COMPONENT ANALYSIS; PROJECTION;
   EIGENMAPS; FRAMEWORK; POSE
AB The curse of dimensionality has prompted intensive research in effective methods of mapping high dimensional data. Dimensionality reduction and subspace learning have been studied extensively and widely applied to feature extraction and pattern representation in image and vision applications. Although PCA has long been regarded as a simple, efficient linear subspace technique, many nonlinear methods such as kernel PCA, local linear embedding, and self-organizing networks have been proposed recently for dealing with increasingly complex nonlinear data. The intensive research in nonlinear methods often creates an impression that they are highly superior and preferred, though often limited experiments were given and the results not tested on significance. In this paper, we systematically investigate and compare the capabilities of various linear and nonlinear subspace methods for face representation and recognition. The performances of these methods are analyzed and discussed along with statistical significance tests on obtained results. The experiments on a range of data sets show that nonlinear methods do not always outperform linear ones, especially on data sets containing noise and outliers or having discontinuous or multiple submanifolds. Certain nonlinear methods with certain classifiers do yield better performances consistently than others. However, the differences among them are small and in most cases are not significant. A measure is used to quantify the nonlinearity of a data set in a subspace. It explains that good performances are achievable in reduced dimensions of low degree of nonlinearity. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Huang, Weilin; Yin, Hujun] Univ Manchester, Sch Elect & Elect Engn, Manchester M60 1QD, Lancs, England.
C3 University of Manchester
RP Yin, HJ (corresponding author), Univ Manchester, Sch Elect & Elect Engn, Manchester M60 1QD, Lancs, England.
EM weilin.huang@postgrad.manchester.ac.uk; h.yin@manchester.ac.uk
OI Yin, Hujun/0000-0002-9198-5401
CR Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belkin M, 2003, NEURAL COMPUT, V15, P1373, DOI 10.1162/089976603321780317
   Benavente R, 1998, 24 COMP VIS CTR
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen LF, 2000, PATTERN RECOGN, V33, P1713, DOI 10.1016/S0031-3203(99)00139-9
   Demartines P, 1997, IEEE T NEURAL NETWOR, V8, P148, DOI 10.1109/72.554199
   Donoho DL, 2003, P NATL ACAD SCI USA, V100, P5591, DOI 10.1073/pnas.1031596100
   Duda R. O., 2001, PATTERN CLASSIFICATI, P517
   Goldberg Y, 2008, J MACH LEARN RES, V9, P1909
   Han L, 2010, IMAGE VISION COMPUT, V28, P836, DOI 10.1016/j.imavis.2009.08.003
   He X., 2003, ADV NEURAL INFORM PR, P153
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Huang WL, 2009, IEEE IMAGE PROC, P3337, DOI 10.1109/ICIP.2009.5413898
   Huang WL, 2010, IEEE IMAGE PROC, P3785, DOI 10.1109/ICIP.2010.5653495
   Ji SW, 2008, IEEE T NEURAL NETWOR, V19, P1768, DOI 10.1109/TNN.2008.2002078
   Kim MS, 2003, PATTERN RECOGN, V36, P2723, DOI 10.1016/S0031-3203(03)00137-7
   Kohonen T., 1997, Self-Organizing Maps
   Kokiopoulou E, 2011, NUMER LINEAR ALGEBR, V18, P565, DOI 10.1002/nla.743
   Kokiopoulou E, 2007, IEEE T PATTERN ANAL, V29, P2143, DOI 10.1109/TPAMI.2007.1131
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lu JW, 2003, IEEE T NEURAL NETWOR, V14, P117, DOI 10.1109/TNN.2002.806629
   Martìnez AM, 2001, IEEE T PATTERN ANAL, V23, P228, DOI 10.1109/34.908974
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Pang YH, 2008, 2008 INTERNATIONAL SYMPOSIUM ON BIOMETRICS AND SECURITY TECHNOLOGIES, P82
   PENTLAND A, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P84, DOI 10.1109/CVPR.1994.323814
   Roweis ST, 2000, SCIENCE, V290, P2323, DOI 10.1126/science.290.5500.2323
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Scholkopf B, 1998, NEURAL COMPUT, V10, P1299, DOI 10.1162/089976698300017467
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Talukder A, 2001, NEURAL NETWORKS, V14, P1201, DOI 10.1016/S0893-6080(01)00103-4
   Tan XY, 2005, IEEE T NEURAL NETWOR, V16, P875, DOI 10.1109/TNN.2005.849817
   Tenenbaum JB, 2000, SCIENCE, V290, P2319, DOI 10.1126/science.290.5500.2319
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Wang JZ, 2010, IMAGE VISION COMPUT, V28, P1624, DOI 10.1016/j.imavis.2010.05.001
   Weiss Y., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P975, DOI 10.1109/ICCV.1999.790354
   Yan SC, 2007, IEEE T PATTERN ANAL, V29, P40, DOI 10.1109/TPAMI.2007.250598
   Yang J, 2004, IEEE T PATTERN ANAL, V26, P131, DOI 10.1109/TPAMI.2004.1261097
   Yang MH, 2002, EIGHTEENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE (AAAI-02)/FOURTEENTH INNOVATIVE APPLICATIONS OF ARTIFICIAL INTELLIGENCE CONFERENCE (IAAI-02), PROCEEDINGS, P224
   Yang MH, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P215
   Yang MH, 2000, IEEE IMAGE PROC, P37, DOI 10.1109/ICIP.2000.900886
   Yin HJ, 2002, IEEE T NEURAL NETWOR, V13, P237, DOI 10.1109/72.977314
   Yin HJ, 2008, NEURAL NETWORKS, V21, P160, DOI 10.1016/j.neunet.2007.12.027
   Yin HJ, 2010, INFORM SCIENCES, V180, P2649, DOI 10.1016/j.ins.2010.04.004
   Yin HJ, 2007, INT J AUTOM COMPUT, V4, P294, DOI 10.1007/s11633-007-0294-y
   Yu H, 2001, PATTERN RECOGN, V34, P2067, DOI 10.1016/S0031-3203(00)00162-X
NR 48
TC 17
Z9 22
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2012
VL 30
IS 4-5
BP 355
EP 366
DI 10.1016/j.imavis.2012.03.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 964WF
UT WOS:000305726700008
OA Green Published
DA 2024-07-18
ER

PT J
AU Prisacariu, VA
   Reid, I
AF Prisacariu, Victor Adrian
   Reid, Ian
TI 3D hand tracking for human computer interaction
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Hand tracking; Region based tracking; 3d tracking; Real time 3d
   tracking; Accelerometer tracker integration; Pose classification;
   Articulated hand tracking
ID POSE
AB We propose a real-time model-based 3D hand tracker that combines image regions and the signal from an off-the-shelf 3-axis accelerometer placed on the user's hand. The visual regions allow the tracker to cope with occlusions, motion blur and background clutter, while the latter aids with the inherent silhouette-pose ambiguities. The accelerometer and tracker are synchronised by casting the calibration problem as one of principal component analysis. Based on the assumption that, often, the number of possible hand configurations is limited by the activity the hand is engaging in, we use a multiclass pose classifier to distinguish between a number of activity dependent articulated hand configurations. We demonstrate the benefits of our method, both qualitatively and quantitatively, on a variety of video sequences and hand configurations and show a proof-of-concept human computer interface based on our system. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Prisacariu, Victor Adrian; Reid, Ian] Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England.
C3 University of Oxford
RP Prisacariu, VA (corresponding author), Univ Oxford, Dept Engn Sci, Oxford OX1 2JD, England.
EM victor@robots.ox.ac.uk
OI Reid, Ian/0000-0001-7790-6423
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Athitsos V, 2003, PROC CVPR IEEE, P432
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Bibby C, 2008, LECT NOTES COMPUT SC, V5303, P831, DOI 10.1007/978-3-540-88688-4_61
   Boykov Y, 2004, IEEE T PATTERN ANAL, V26, P1124, DOI 10.1109/TPAMI.2004.60
   Bray M, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P675, DOI 10.1109/AFGR.2004.1301612
   Bray M., 2004, PROC INT C ARTIFICIA, P59
   Bretzner L, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P423, DOI 10.1109/AFGR.2002.1004190
   Crammer K., 2001, J. Mach. Learn. Res., V2, P265
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   de Campos T.E., 2006, IEEE C COMPUTER VISI, V1, P782
   de la Gorce M, 2008, PROC CVPR IEEE, P3192
   Delamarre Q, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P585, DOI 10.1109/AFGR.1998.671011
   Farahani S., 2008, ZIGBEE WIRELESS NETW
   Freescale, 2007, AN3461 FREESC
   Giaccone P.R., 1998, BRIT MACH VIS C
   Hol JD, 2010, INT J ROBOT RES, V29, P231, DOI 10.1177/0278364909356812
   Lang P., 2005, WORKSH INT VIS IN SY
   Li CM, 2005, PROC CVPR IEEE, P430
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lu S, 2003, PROC CVPR IEEE, P443
   MacCormick J., 2000, IEEE European Conference on Computer Vision, P3, DOI DOI 10.1007/3-540-45053-X1
   Maes P., 2009, IEEE INT S MIX AUGM, P21
   Pavlovic VI, 1997, IEEE T PATTERN ANAL, V19, P677, DOI 10.1109/34.598226
   Prisacariu V., 2009, fastHOG-a real-time GPU implementation of HOG
   Prisacariu Victor Adrian, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P368, DOI 10.1109/FG.2011.5771427
   Prisacariu V. A., 2011, INT C COMP VIS
   Prisacariu VA, 2012, INT J COMPUT VISION, V98, P335, DOI 10.1007/s11263-011-0514-3
   Rehg J. M., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P16, DOI 10.1109/MNRAO.1994.346260
   Rehg J.M., 1995, THESIS
   Rosenhahn B, 2007, INT J COMPUT VISION, V73, P243, DOI 10.1007/S11263-006-9965-3
   Schweighofer G, 2006, IEEE T PATTERN ANAL, V28, P2024, DOI 10.1109/TPAMI.2006.252
   Sidenbladh H, 2002, LECT NOTES COMPUT SC, V2350, P784
   Stenger B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1063
   Stenger B., 2004, Int. Workshop on Human-Computer Interaction, P102
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Wang R, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531397
   Zhou HN, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1102, DOI 10.1109/ICCV.2003.1238472
NR 39
TC 34
Z9 36
U1 0
U2 31
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 236
EP 250
DI 10.1016/j.imavis.2012.01.003
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000012
DA 2024-07-18
ER

PT J
AU Zhao, XW
   Chai, XJ
   Niu, ZH
   Heng, CK
   Shan, SG
AF Zhao, Xiaowei
   Chai, Xiujuan
   Niu, Zhiheng
   Heng, Cherkeng
   Shan, Shiguang
TI Context modeling for facial landmark detection based on Non-Adjacent
   Rectangle (NAR) Haar-like feature
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 9th IEEE International Conference on Automatic Face and Gesture
   Recognition
CY MAR 21-25, 2011
CL Santa Barbara, CA
SP IEEE
DE Context modeling; Face detection; Facial landmark detection; NAR
   Haar-like feature; Co-occurrence
ID FACE; DATABASE; SCALE
AB Automatically locating facial landmarks in images is an important task in computer vision. This paper proposes a novel context modeling method for facial landmark detection, which integrates context constraints together with local texture model in the cascaded AdaBoost framework The motivation of our method lies in the basic human psychology observation that not only the local texture information but also the global context information is used for human to locate facial landmarks in faces. Therefore, in our solution, a novel type of feature, called Non-Adjacent Rectangle (NAR) Haar-like feature, is proposed to characterize the co-occurrence between facial landmarks and its surroundings, i.e., the context information, in terms of low-level features. For the locating task, traditional Haar-like features (characterizing local texture information) and NAR Haar-like features (characterizing context constraints in global sense) are combined together to form more powerful representations. Through Real AdaBoost learning, the most discriminative feature set is selected automatically and used for facial landmark detection. To verify the effectiveness of the proposed method, we evaluate our facial landmark detection algorithm on BioID and Cohn-Kanade face databases. Experimental results convincingly show that the NAR Haar-like feature is effective to model the context and our proposed algorithm impressively outperforms the published state-of-the-art methods. In addition, the generalization capability of the NAR Haar-like feature is further validated by extended applications to face detection task on FDDB face database. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Zhao, Xiaowei; Chai, Xiujuan; Shan, Shiguang] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Zhao, Xiaowei] Chinese Acad Sci, Grad Univ, Beijing 100049, Peoples R China.
   [Niu, Zhiheng; Heng, Cherkeng] Panason Singapore Labs Pte Ltd PSL, Singapore 534415, Singapore.
C3 Chinese Academy of Sciences; Institute of Computing Technology, CAS;
   Chinese Academy of Sciences; University of Chinese Academy of Sciences,
   CAS
RP Shan, SG (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
EM sgshan@ict.ac.cn
OI Shan, Shiguang/0000-0002-8348-392X
CR [Anonymous], FDDB BENCHMARK FACE
   Bailly-Bailliére E, 2003, LECT NOTES COMPUT SC, V2688, P625
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Chen J, 2010, IEEE T PATTERN ANAL, V32, P1705, DOI 10.1109/TPAMI.2009.155
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   Cristinacce D., 2006, BRIT MACH VIS C, V1, P3
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   FINK M, 2003, P NEUR INF PROC SYST
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Jain V., 2011, P COMP VIS PATT REC
   Jesorsky O., 2001, P AUD VID BAS BIOM P, P91
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Kienzle W., 2005, Advances, V17, P673
   Kinoshita K., 2008, P MIRU
   Kozakaya T, 2010, IMAGE VISION COMPUT, V28, P772, DOI 10.1016/j.imavis.2009.09.008
   Kruppa H., 2003, Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS), P157
   Li SZ, 2004, IEEE T PATTERN ANAL, V26, P1112, DOI 10.1109/TPAMI.2004.68
   Lienhart R, 2002, IEEE IMAGE PROC, P900
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, IEEE T PATTERN ANAL, V18, P837, DOI 10.1109/34.531803
   Martinez A.M., 1998, AR FACE DATABASE CVC
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   Messer K., 1999, 2 INT C AUD VID BAS, V964, P965
   Mikolajczyk K, 2005, IEEE T PATTERN ANAL, V27, P1615, DOI 10.1109/TPAMI.2005.188
   Mikolajczyk K, 2004, LECT NOTES COMPUT SC, V3021, P69
   Milborrow S, 2008, LECT NOTES COMPUT SC, V5305, P504, DOI 10.1007/978-3-540-88693-8_37
   Mita T, 2005, IEEE I CONF COMP VIS, P1619
   Niu ZH, 2006, INT C PATT RECOG, P1216
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sim T, 2003, IEEE T PATTERN ANAL, V25, P1615, DOI 10.1109/TPAMI.2003.1251154
   Subburaman V.B., 2010, P EUR C COMP VIS WOR
   Torralba A, 2010, COMMUN ACM, V53, P107, DOI 10.1145/1666420.1666446
   Tu ZW, 2010, IEEE T PATTERN ANAL, V32, P1744, DOI 10.1109/TPAMI.2009.186
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Vukadinovic D, 2005, IEEE SYS MAN CYBERN, P1692
   WU B., 2004, Sixth IEEE International Conference on Automatic Face and Gesture Recognition (FG'04), P79
   Xiaowei Zhao, 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P673, DOI 10.1109/FG.2011.5771329
   Yan S., 2008, P COMP VIS PATT REC
   Yan S., 2007, P COMP VIS PATT REC
NR 44
TC 14
Z9 17
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2012
VL 30
IS 3
SI SI
BP 136
EP 146
DI 10.1016/j.imavis.2011.12.004
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 944EB
UT WOS:000304181000002
DA 2024-07-18
ER

PT J
AU Hollingsworth, K
   Bowyer, KW
   Flynn, PJ
AF Hollingsworth, Karen
   Bowyer, Kevin W.
   Flynn, Patrick J.
TI Useful features for human verification in near-infrared periocular
   images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Periocular recognition; Ocular biometrics; Near-infrared light
ID IRIS RECOGNITION; FACE RECOGNITION
AB The periocular region is the part of the face immediately surrounding the eye, and researchers have recently begun to investigate how to use the periocular region for recognition. Understanding how humans recognize faces helped computer vision researchers develop algorithms for face recognition. Likewise, understanding how humans analyze periocular images could benefit researchers developing algorithms for periocular recognition. We conducted two experiments to determine how humans analyze periocular images. In these experiments, we presented pairs of images and asked volunteers to determine whether the two images showed eyes from the same subject or from different subjects. In the first experiment, subjects were paired randomly to create different-subject queries. Our volunteers correctly determined the relationship between the two images in 92% of the queries. In the second experiment, we considered multiple factors in forming different-subject pairs: queries were formed from pairs of subjects with the same gender and race, and with similar eye color, makeup, eyelash length, and eye occlusion. In addition, we limited the amount of time volunteers could view a query pair. On this harder experiment, the correct verification rate was 79%. We asked volunteers to describe what features in the images were helpful to them in making their decisions. In both experiments, eyelashes were reported to be the most helpful feature. (C) 2011 Elsevier B.V. All rights reserved.
C1 [Hollingsworth, Karen; Bowyer, Kevin W.; Flynn, Patrick J.] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
C3 University of Notre Dame
RP Hollingsworth, K (corresponding author), Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
EM kholling@nd.edu
RI Flynn, Patrick J/J-3388-2013
OI Bowyer, Kevin/0000-0002-7562-4390
FU Federal Bureau of Investigation; Technical Support Working Group through
   US Army [W91CRB-08-C-0093]; CIA [US-2010-1048708-000]
FX This work is supported by the Federal Bureau of Investigation, the
   Technical Support Working Group through US Army contract
   W91CRB-08-C-0093, and the Intelligence Community Postdoctoral Fellowship
   Program CIA award US-2010-1048708-000. The opinions, findings, and
   conclusions or recommendations expressed in this publication are those
   of the authors and do not necessarily reflect the views of our sponsors.
CR Abiantun R., 2008, IEEE 37th Applied Imagery Pattern Recognition Workshop (AIPR), P1
   Adams J., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P205, DOI 10.1109/ICPR.2010.59
   [Anonymous], 2010, INT C BIOM THEOR APP
   [Anonymous], 2010, P 2010 4 IEEE INT C
   [Anonymous], 2010, P 2010 ACM S APPL CO, DOI DOI 10.1145/1774088.1774408
   Bharadwaj Samarth., 2010, 2010 4 IEEE INT C BI, P1, DOI DOI 10.1109/BTAS.2010.5634498
   Bhat S, 2008, INT CONF ACOUST SPEE, P5228, DOI 10.1109/ICASSP.2008.4518838
   Bowyer KW, 2008, COMPUT VIS IMAGE UND, V110, P281, DOI 10.1016/j.cviu.2007.08.005
   BOWYER KW, 2010, IEEE INT CARN C SEC, P1
   BOWYER KW, NDIRIS0405 U NOTR DA
   Calder A., 2010, HDB FACE PE IN PRESS
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   HOLLINGSWORTH KP, 2011, HUMAN MACHINE PERFOR
   Kang BJ, 2007, PATTERN RECOGN LETT, V28, P1630, DOI 10.1016/j.patrec.2007.04.004
   Li Yanjun, 2008, PLoS One, V3, pe2166, DOI 10.1371/journal.pone.0002166
   Lyle J.R., 2012, Pattern Recognition, V45, P3877, DOI DOI 10.1016/J.PATCOG.2012.04.027
   Miller MA, 2010, P IEEE INT C BIOM TH, P1
   Oyster C.W., 1999, HUMAN EYE STRUCTURE
   Park M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ULTRA-WIDEBAND (ICUWB 2009), P1, DOI 10.1109/ICUWB.2009.5288737
   RYAN WJ, 2008, P IEEE INT C BIOM TH, P1
   Sinha P, 2006, P IEEE, V94, P1948, DOI 10.1109/JPROC.2006.884093
   Wildes RP, 1997, P IEEE, V85, P1348, DOI 10.1109/5.628669
   Woodard Damon L., 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P201, DOI 10.1109/ICPR.2010.58
   Woodard D. L., 2010, IEEE COMPUTER VISION, P162
   Xu JP, 2010, MANAG SCI ENG MANAG, P1
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 26
TC 8
Z9 8
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2011
VL 29
IS 11
BP 707
EP 715
DI 10.1016/j.imavis.2011.09.002
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 864EE
UT WOS:000298219000001
DA 2024-07-18
ER

PT J
AU Karavasilis, V
   Nikou, C
   Likas, A
AF Karavasilis, Vasileios
   Nikou, Christophoros
   Likas, Aristidis
TI Visual tracking using the Earth Mover's Distance between Gaussian
   mixtures and Kalman filtering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual tracking; Gaussian mixture model (GMM); Expectation-Maximization
   (EM) algorithm; Differential Earth Mover's Distance (Differential EMD);
   Kalman filter
ID OBJECT TRACKING
AB In this paper, we demonstrate how the differential Earth Mover's Distance (EMD) may be used for visual tracking in synergy with Gaussian mixtures models (GMM). According to our model, motion between adjacent frames results in variations of the mixing proportions of the Gaussian components representing the object to be tracked. These variations are computed in closed form by minimizing the differential EMD between Gaussian mixtures, yielding a very fast algorithm with high accuracy, without recurring to the EM algorithm in each frame. Moreover, we also propose a framework to handle occlusions, where the prediction for the object's location is forwarded to an adaptive Kalman filter whose parameters are estimated on line by the motion model already observed. Experimental results show significant improvement in tracking performance in the presence of occlusion. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Karavasilis, Vasileios; Nikou, Christophoros; Likas, Aristidis] Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece.
C3 University of Ioannina
RP Nikou, C (corresponding author), Univ Ioannina, Dept Comp Sci, POB 1186, GR-45110 Ioannina, Greece.
EM vkaravas@cs.uoi.gr; cnikou@cs.uoi.gr; arly@cs.uoi.gr
RI Nikou, Christophoros/AAF-4236-2019; Nikou, Christophoros/L-8685-2014
CR [Anonymous], 2007, P ICWSM
   [Anonymous], P INT C COMP VIS ICC
   Argyros AA, 2004, LECT NOTES COMPUT SC, V3023, P368
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Avidan S, 2004, IEEE T PATTERN ANAL, V26, P1064, DOI 10.1109/TPAMI.2004.53
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Black MJ, 1998, INT J COMPUT VISION, V26, P63, DOI 10.1023/A:1007939232436
   Bugeau A, 2008, EURASIP J IMAGE VIDE, DOI 10.1155/2008/317278
   CHONG EKP, 2008, WILEY INTERSCIENCE S
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Cremers D, 2006, IEEE T PATTERN ANAL, V28, P1262, DOI 10.1109/TPAMI.2006.161
   CUEVAS E, 2005, 80512 FREIER U BERL
   Fan ZM, 2007, IEEE T PATTERN ANAL, V29, P1268, DOI 10.1109/TPAMI.2007.1034
   Figueiredo MAT, 2002, IEEE T PATTERN ANAL, V24, P381, DOI 10.1109/34.990138
   Hager GD, 2004, PROC CVPR IEEE, P790
   Han B., 2007, Testbeds and Research Infrastructure for the Development of Networks and 126 Communities, P1
   Isard M, 1998, INT J COMPUT VISION, V29, P5, DOI 10.1023/A:1008078328650
   Isard M., 1998, PROC 5 EUROPEAN C CO, V1, P893
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucas B. D., 1981, P 7 INT JOINT C ART, V81, P674, DOI DOI 10.5555/1623264.1623280
   Mansouri AR, 2002, IEEE T PATTERN ANAL, V24, P947, DOI 10.1109/TPAMI.2002.1017621
   Moreno-Noguer F, 2008, IEEE T PATTERN ANAL, V30, P670, DOI 10.1109/TPAMI.2007.70727
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   Rathi Y, 2005, PROC CVPR IEEE, P2
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Sato K, 2004, COMPUT VIS IMAGE UND, V96, P100, DOI 10.1016/j.cviu.2004.02.003
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Simon D, 2006, OPTIMAL STATE ESTIMA
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Tao H, 2002, IEEE T PATTERN ANAL, V24, P75, DOI 10.1109/34.982885
   Tu JL, 2009, MACH VISION APPL, V20, P163, DOI 10.1007/s00138-007-0115-x
   Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946
   Wang HZ, 2006, LECT NOTES COMPUT SC, V3953, P606, DOI 10.1007/11744078_47
   Wang ZW, 2009, PATTERN RECOGN LETT, V30, P407, DOI 10.1016/j.patrec.2008.10.017
   Wu Y, 2004, INT J COMPUT VISION, V58, P55, DOI 10.1023/B:VISI.0000016147.97880.cd
   Yang C, 2005, PROC CVPR IEEE, P176
   Yang M, 2009, IEEE T PATTERN ANAL, V31, P1195, DOI 10.1109/TPAMI.2008.146
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   ZHAO Q, 2009, IEEE T PATT IN PRESS
   Zhou HY, 2009, COMPUT VIS IMAGE UND, V113, P345, DOI 10.1016/j.cviu.2008.08.006
NR 41
TC 32
Z9 38
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2011
VL 29
IS 5
BP 295
EP 305
DI 10.1016/j.imavis.2010.12.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 751FT
UT WOS:000289603600001
DA 2024-07-18
ER

PT J
AU Lin, SY
   Horng, SJ
   Kao, TW
   Fahn, CS
   Fan, PZ
   Chen, YH
   Khan, MK
   Bourgeois, A
   Terano, T
AF Lin, Shih-Ying
   Horng, Shi-Jinn
   Kao, Tzong-Wann
   Fahn, Chin-Shyurng
   Fan, Pingzhi
   Chen, Yuan-Hsin
   Khan, Muhammad Khurram
   Bourgeois, Anu
   Terano, Takao
TI 3D block-based medial axis transform and chessboard distance transform
   based on dominance
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Parallel algorithm; Image processing; CREW; PRAM model; Block-based
   medial axis transform; Chessboard distance transform; Euclidean distance
   transform
ID O(1) TIME ALGORITHM; LOOK-UP TABLES; FORMAL CLASSIFICATION; PARALLEL
   COMPUTATION; THINNING ALGORITHM; SHAPE; TRANSITIONS; POINTS; MAPS; 2D
AB Traditionally, the block-based medial axis transform (BB-MAT) and the chessboard distance transform (CDT) were usually viewed as two completely different image computation problems, especially for three dimensional (3D) space. In fact, there exist some equivalent properties between them. The relationship between both of them is first derived and proved in this paper. One of the significant properties is that CDT for 3D binary image V is equal to BB-MAT for image V' where it denotes the inverse image of V. In a parallel algorithm, a cost is defined as the product of the time complexity and the number of processors used. The main contribution of this work is to reduce the costs of 3D BB-MAT and 3D CDT problems proposed by Wang [65]. Based on the reverse-dominance technique which is redefined from dominance concept, we achieve the computation of the 3D CDT problem by implementing the 3D BB-MAT algorithm first. For a 3D binary image of size N-3, our parallel algorithm can be run in O(logN) time using N3 processors on the concurrent read exclusive write (CREW) parallel random access machine (PRAM) model to solve both 3D BB-MAT and 3D CDT problems, respectively. The presented results for the cost are reduced in comparison with those of Wang's. To the best of our knowledge, this work is the lowest costs for the 3D BB-MAT and 3D CDT algorithms known. In parallel algorithms, the running time can be divided into computation time and communication time. The experimental results of the running, communication and computation times for the different problem sizes are implemented in an HP Superdome with SMP/CC-NUMA (symmetric multiprocessor/cache coherent non-uniform memory access) architecture. We conclude that the parallel computer (i.e., SMP/CC-NUMA architecture or cluster system) is more suitable for solving problems with a large amount of input size. (C) 2010 Elsevier BM. All rights reserved.
C1 [Lin, Shih-Ying; Horng, Shi-Jinn] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
   [Horng, Shi-Jinn; Fahn, Chin-Shyurng] Natl Taiwan Univ Sci & Technol, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Chen, Yuan-Hsin] Natl United Univ, Dept Elect Engn, Miaoli, Taiwan.
   [Kao, Tzong-Wann] Technol & Sci Inst No Taiwan, Dept Elect Engn, Taipei, Taiwan.
   [Fan, Pingzhi] SW Jiaotong Univ, Inst Mobile Commun, Chengdu 610031, Peoples R China.
   [Khan, Muhammad Khurram] King Saud Univ, Ctr Excellence Informat Assurance, Riyadh 11451, Saudi Arabia.
   [Horng, Shi-Jinn; Bourgeois, Anu] Georgia State Univ, Dept Comp Sci, Atlanta, GA 30302 USA.
   [Terano, Takao] Tokyo Inst Technol, Dept Computat Intelligence & Syst Sci, Tokyo, Japan.
C3 National Taiwan University of Science & Technology; National Taiwan
   University of Science & Technology; National United University;
   Southwest Jiaotong University; King Saud University; University System
   of Georgia; Georgia State University; Tokyo Institute of Technology
RP Horng, SJ (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei, Taiwan.
EM horngsj@yahoo.com.tw
RI Horng, Shi-Jinn/GVU-0488-2022; Chen, H.Y./JSL-7102-2023; Nusa,
   Nuhammad/JXY-5819-2024; Khan, Muhammad/IXN-8470-2023; Bourgeois,
   Anu/ACZ-6301-2022; KHAN, MUHAMMAD KHURRAM/E-4836-2014
OI Chen, H.Y./0009-0009-5542-0460; Bourgeois, Anu/0000-0002-4705-4888;
   KHAN, MUHAMMAD KHURRAM/0000-0001-6636-0533
FU National Science Council [NSC 96-2918-I-011-002, 96-2221-E-011-022-,
   95-2221-E-011-032-MY3]; 111 Project [111-2-14]
FX This work was supported in part by the National Science Council under
   the contract number NSC 96-2918-I-011-002, 96-2221-E-011-022-,
   95-2221-E-011-032-MY3, and it was also partially supported by the 111
   Project under the grant No. 111-2-14.
CR Amenta N, 1999, DISCRETE COMPUT GEOM, V22, P481, DOI 10.1007/PL00009475
   [Anonymous], 1992, An introduction to parallel algorithms
   [Anonymous], 1985, COMPUTATIONAL GEOMET, DOI DOI 10.1007/978-1-4612-1098-6
   ARCELLI C, 1988, COMPUT VISION GRAPH, V43, P361, DOI 10.1016/0734-189X(88)90089-8
   BLUM H, 1967, MODELS PERCEPTION SP, V11, P362
   Bonnassie A, 2003, IEEE T SYST MAN CY B, V33, P700, DOI 10.1109/TSMCB.2003.814298
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Borgefors G., 1991, P 7 SCAND C IM AN, V2, P974
   Bruce J. W., 1992, CURVES SINGULARITIES
   CALABI L, 1968, AM MATH MON, V75, P335, DOI 10.2307/2313409
   CHANDRAN S, 1992, ALGORITHMICA, V7, P25, DOI 10.1007/BF01758750
   CHANDRAN S, 1987, IEEE WORKSH COMP ARC, P44
   CHEN L, 1994, INFORM PROCESS LETT, V51, P25, DOI 10.1016/0020-0190(94)00062-X
   Chen YJ, 1998, AUST COMPUT J, V30, P12
   Culver T, 1999, P 5 ACM S SOL MOD AP, P179, DOI DOI 10.1145/304012.304030
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   Datta A, 1999, IPPS PROC, P431, DOI 10.1109/IPPS.1999.760512
   Dey T.K., 2003, P 8 ACM S SOL MOD AP, P127, DOI DOI 10.1145/781606.781627
   Dey TK, 2004, ALGORITHMICA, V38, P179, DOI 10.1007/s00453-003-1049-y
   Ferreira A, 1999, IEEE T PATTERN ANAL, V21, P277, DOI 10.1109/34.754629
   Ferreira A, 1998, LECT NOTES COMPUT SC, V1470, P875, DOI 10.1007/BFb0057943
   FERREIRA A, 1995, P IEEE INT C IM PROC, V2, P105
   Fujiwara A, 1996, IEICE T INF SYST, VE79D, P1038
   Giblin P, 2004, IEEE T PATTERN ANAL, V26, P238, DOI 10.1109/TPAMI.2004.1262192
   Giblin P, 2000, PROC CVPR IEEE, P566, DOI 10.1109/CVPR.2000.855870
   Giblin PJ, 2009, IEEE T PATTERN ANAL, V31, P900, DOI 10.1109/TPAMI.2008.120
   Giblin PJ, 2003, INT J COMPUT VISION, V54, P143, DOI 10.1023/A:1023761518825
   JENQ JF, 1992, IEEE T PATTERN ANAL, V14, P1218, DOI 10.1109/34.177389
   KIM SK, 1991, SIAM J DISCRETE MATH, V4, P385
   KIMIA BB, 1995, INT J COMPUT VISION, V15, P189, DOI 10.1007/BF01451741
   KOLOUNTZAKIS MN, 1992, INFORM PROCESS LETT, V43, P181, DOI 10.1016/0020-0190(92)90197-4
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   LATECKI LJ, 2007, IM PROC 2007 ICIP 20, V5, P349
   LEE DT, 1982, IEEE T PATTERN ANAL, V4, P363, DOI 10.1109/TPAMI.1982.4767267
   Lee YH, 1999, COMPUT VIS IMAGE UND, V73, P374, DOI 10.1006/cviu.1998.0741
   Lee YH, 1997, INT J COMPUT MATH, V65, P165, DOI 10.1080/00207169708804608
   Lee YH, 1996, 10TH INTERNATIONAL PARALLEL PROCESSING SYMPOSIUM - PROCEEDINGS OF IPPS '96, P424, DOI 10.1109/IPPS.1996.508090
   LEE YH, 2003, THESIS NTUST TAIWAN
   LEYMARIE F, 1992, IEEE T PATTERN ANAL, V14, P56, DOI 10.1109/34.107013
   LEYMARIE FF, 2001, LNCS, V2059, P216
   Leymarie FF, 2007, IEEE T PATTERN ANAL, V29, P313, DOI 10.1109/TPAMI.2007.44
   Lin SY, 2005, PDCAT 2005: SIXTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES, PROCEEDINGS, P603
   LIN SY, 2008, 3D BLOCK BASED MEDIA, P83
   Ma CM, 1996, COMPUT VIS IMAGE UND, V64, P420, DOI 10.1006/cviu.1996.0069
   MATOUSEK J, 1994, ACM COMPUTING SURVEY, V26
   MONTANVERT A, 1986, P 8 INT C PATT REC, P430
   Morrison P, 2005, Third International Conference on Information Technology and Applications, Vol 1, Proceedings, P644
   Palágyi K, 2002, PATTERN RECOGN LETT, V23, P663, DOI 10.1016/S0167-8655(01)00142-8
   Palágyi K, 2008, THEOR COMPUT SCI, V406, P119, DOI 10.1016/j.tcs.2008.06.041
   Peternell M, 2000, GRAPH MODELS, V62, P202, DOI 10.1006/gmod.1999.0521
   PFALTZ JL, 1967, COMMUN ACM, V10, P119, DOI 10.1145/363067.363120
   Ramanathan M, 2005, COMPUT AIDED DESIGN, V37, P1370, DOI 10.1016/j.cad.2005.01.006
   Remy E, 2003, LECT NOTES COMPUT SC, V2886, P224
   Remy E, 2002, PATTERN RECOGN LETT, V23, P649, DOI 10.1016/S0167-8655(01)00141-6
   ROSENFEL.A, 1966, J ACM, V13, P471
   Saúde AV, 2009, IMAGE VISION COMPUT, V27, P354, DOI 10.1016/j.imavis.2008.05.007
   SCHWARZKOPF O, 1991, ALGORITHMICA, V6, P685, DOI 10.1007/BF01759067
   Sherbrooke E. C., 1995, Proceedings. Third Symposium on Solid Modeling and Applications, P187, DOI 10.1145/218013.218059
   SHERBROOKE EC, 1996, IEEE T VISUALIZATION, V2
   Shih F. Y., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P723, DOI 10.1109/ICPR.1990.118203
   Tsai HR, 2002, NINTH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS, PROCEEDINGS, P123, DOI 10.1109/ICPADS.2002.1183388
   VALIANT LG, 1990, COMMUN ACM, V33, P103, DOI 10.1145/79173.79181
   VO K, 1982, J ALGORITHMS, V4, P366
   Wang YR, 2004, IEEE T SYST MAN CY B, V34, P517, DOI 10.1109/TSMCB.2003.817062
   Wang YR, 2003, IEEE T PARALL DISTR, V14, P973, DOI 10.1109/TPDS.2003.1239866
   WANG YR, 2005, P IEEE INT C SYST MA
   Wang YR, 2009, PARALLEL COMPUT, V35, P72, DOI 10.1016/j.parco.2008.10.003
   YAMADA H, 1984, P 7 INT C PATT REC, V1, P69
NR 68
TC 0
Z9 0
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2011
VL 29
IS 4
BP 272
EP 285
DI 10.1016/j.imavis.2010.11.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 727UR
UT WOS:000287828800007
DA 2024-07-18
ER

PT J
AU Swilem, A
AF Swilem, Ahmed
TI A fast vector quantization encoding algorithm based on projection
   pyramid with Hadamard transformation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hadamard transform; Projection pyramid; Vector quantization
ID CODEWORD SEARCH ALGORITHM; DESIGN
AB Vector quantization (VQ) for image compression requires expensive time to find the closest codevector in the encoding process. In this paper, a fast search algorithm is proposed for projection pyramid vector quantization using a lighter modified distortion with Hadamard transform of the vector. The algorithm uses projection pyramids of the vectors and codevectors after applying Hadamard transform and one elimination criterion based on deviation characteristic values in the Hadamard transform domain to eliminate unlikely codevectors. Experimental results are presented on image block data. These results confirm the effectiveness of the proposed algorithm with the same quality of the image as the full search algorithm. (c) 2010 Elsevier B.V. All rights reserved.
EM ahmed200eg@yahoo.com
CR [Anonymous], 2012, VECTOR QUANTIZATION
   Baek S, 1997, IEEE SIGNAL PROC LET, V4, P325, DOI 10.1109/97.650035
   BARLAUD M, 1994, IEEE T IMAGE PROCESS, V3, P367, DOI 10.1109/83.298393
   Bayazit U, 1999, IEEE T IMAGE PROCESS, V8, P321, DOI 10.1109/83.748888
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   Chen TS, 1998, IEEE T IMAGE PROCESS, V7, P1485, DOI 10.1109/83.718488
   Chu SC, 2007, INFORM SCIENCES, V177, P734, DOI 10.1016/j.ins.2006.06.010
   Garcia C, 1999, IEEE T MULTIMEDIA, V1, P264, DOI 10.1109/6046.784465
   Gray R. M., 1984, IEEE ASSP Magazine, V1, P4, DOI 10.1109/MASSP.1984.1162229
   GUAN L, 1992, PATTERN RECOGN LETT, V13, P693, DOI 10.1016/0167-8655(92)90098-K
   Hwang WJ, 1997, ELECTRON LETT, V33, P365, DOI 10.1049/el:19970249
   Jiang SD, 2003, CHINESE J ELECTRON, V12, P373
   LEE CH, 1994, IEE P-VIS IMAGE SIGN, V141, P143, DOI 10.1049/ip-vis:19941140
   LEE CH, 1995, IEEE T COMMUN, V43, P1697, DOI 10.1109/26.380218
   Liao HYM, 2006, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2006.1692634
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   Lu ZM, 2000, ELECTRON LETT, V36, P1364, DOI 10.1049/el:20000972
   Lu ZM, 2003, IEICE T INF SYST, VE86D, P660
   Moureaux JM, 1998, IEEE T COMMUN, V46, P1602, DOI 10.1109/26.737398
   ORCHARD MT, 1991, INT CONF ACOUST SPEE, P2297, DOI 10.1109/ICASSP.1991.150755
   Pan JS, 2000, ELECTRON LETT, V36, P210, DOI 10.1049/el:20000237
   Raffy P, 2000, IEEE T IMAGE PROCESS, V9, P2006, DOI 10.1109/83.887969
   RISKIN EA, 1990, IEEE T MED IMAGING, V9, P290, DOI 10.1109/42.57766
   RISKIN EA, 1991, IEEE T SIGNAL PROCES, V39, P2500, DOI 10.1109/78.98004
   Rose K, 1996, IEEE T IMAGE PROCESS, V5, P393, DOI 10.1109/83.480777
   Song BC, 2002, IEEE T IMAGE PROCESS, V11, P10, DOI 10.1109/83.977878
   Swilem A, 2004, IEICE T FUND ELECTR, VE87A, P732
   Swilem A., 2002, Journal of the Institute of Image Information and Television Engineers, V56, P1513, DOI 10.3169/itej.56.1513
   SWILEM A, 2008, P NFOS
   SWILEM A, 2005, IIEEJ J I IMAGE ELEC, V34, P653
   SWILEM A, 2003, P IEEE INES 2003 7 I, V2, P704
   VOINSON T, 2002, P IEEE INT C IM PROC, P641
   Wu KS, 2000, IEEE T CIRC SYST VID, V10, P59, DOI 10.1109/76.825859
   Zheng J, 2006, IEICE T INF SYST, VE89D, P201, DOI 10.1093/ietisy/e89-d.1.201
NR 34
TC 5
Z9 7
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1637
EP 1644
DI 10.1016/j.imavis.2010.05.002
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300006
DA 2024-07-18
ER

PT J
AU Kannan, K
   Kanna, BR
   Aravindan, C
AF Kannan, K.
   Kanna, B. Rajesh
   Aravindan, C.
TI Root Mean Square filter for noisy images based on hyper graph model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Hypergraph; Image Neighborhood Hypergraph (INHG); Root Mean Square
   approximation; Impulse noise; Gaussian noise
ID MEDIAN FILTERS; REDUCTION; ALGORITHM; REMOVAL; SALT
AB In this paper, we propose a noise removal algorithm for digital images. This algorithm is based on hypergraph model of image, which enables us to distinguish noisy pixels in the image from the noise-free ones. Hence, our algorithm obviates the need for denoising all the pixels, thereby preserving as much image details as possible. The identified noisy pixels are denoised through Root Mean Square (RMS) approximation. The performance of our algorithm, based on peak-signal-to-noise-ratio (PSNR) and mean-absolute-error (MAE), was studied on various benchmark images, and found to be superior to that of other traditional filters and other hypergraph based denoising algorithms. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Kannan, K.] SASTRA Univ, Dept Math, Thanjavur, India.
   [Kanna, B. Rajesh] St Josephs Coll Engn, Dept Comp Applicat, Madras, Tamil Nadu, India.
   [Aravindan, C.] SSN Coll Engn, Dept Comp Sci, Madras, Tamil Nadu, India.
C3 Shanmugha Arts, Science, Technology & Research Academy (SASTRA); St.
   Joseph's College of Engineering, Chennai; SSN College of Engineering
RP Kannan, K (corresponding author), SASTRA Univ, Dept Math, Thanjavur, India.
EM kkannan@maths.sastra.edu; rajesh@stjosephs.ac.in; aravindanc@ssn.edu.in
RI k, k/KFC-0221-2024; Chandrabose, Aravindan/O-6194-2019; su,
   haobo/JPK-2362-2023; k, k/HZK-4476-2023; k, k/KFT-2541-2024;
   Chandrabose, Aravindan/Q-1046-2015; cai, bo/G-1491-2010; Baskaran,
   Rajesh Kanna/Y-6659-2019; K, Kannan/GPK-0744-2022
OI Chandrabose, Aravindan/0000-0002-9025-4009; Chandrabose,
   Aravindan/0000-0002-9025-4009; Baskaran, Rajesh
   Kanna/0000-0001-5970-3702; 
FU Department of Science and Technology, Government of India
FX The first author wishes to acknowledge with thanks the financial grant
   from the Department of Science and Technology, Government of India.
CR [Anonymous], DIGITAL IMAGE PROCES
   ASTOLA J, 1994, IEEE T CIRCUITS-II, V41, P487, DOI 10.1109/82.298384
   Barni M, 1998, SIGNAL PROCESS, V71, P45, DOI 10.1016/S0165-1684(98)00133-9
   BERGE C, 1987, HYPERGRAPHS
   Boukerrou K, 1998, INFORM SCIENCES, V110, P217, DOI 10.1016/S0020-0255(98)00004-8
   Bretto A, 2002, PATTERN RECOGN, V35, P651, DOI 10.1016/S0031-3203(01)00067-X
   Bretto A, 1996, 1996 IEEE DIGITAL SIGNAL PROCESSING WORKSHOP, PROCEEDINGS, P5, DOI 10.1109/DSPWS.1996.555446
   BRETTO A, 1997, GRAPH MODEL IM PROC, V59, P277
   BRETTO A, 1998, SW J PURE APPL MATH, V1, P56
   Chan RH, 2005, IEEE T IMAGE PROCESS, V14, P1479, DOI 10.1109/TIP.2005.852196
   Chen T, 1999, IEEE T IMAGE PROCESS, V8, P1834, DOI 10.1109/83.806630
   Chen T, 2001, IEEE T CIRCUITS-II, V48, P784, DOI 10.1109/82.959870
   Chen T, 2001, IEEE T IMAGE PROCESS, V10, P829, DOI 10.1109/83.923279
   CHEN T, 2007, IEEE SIGNAL PROCESSI, V8, P1
   Frosio I, 2005, BIOLOGICAL AND ARTIFICIAL INTELLIGENCE ENVIRONMENTS, P337, DOI 10.1007/1-4020-3432-6_39
   He QH, 2007, AEU-INT J ELECTRON C, V61, P546, DOI 10.1016/j.aeue.2006.09.008
   HUANG TS, 1979, IEEE T ACOUST SPEECH, V27, P13, DOI 10.1109/TASSP.1979.1163188
   KO SJ, 1991, IEEE T CIRCUITS SYST, V38, P984, DOI 10.1109/31.83870
   KUNDU A, 1984, IEEE T ACOUST SPEECH, V32, P600, DOI 10.1109/TASSP.1984.1164364
   LUO WB, 2007, INT J ELECT COMMUNIC, V8, P551
   LUOP WB, 2007, INT J ELECT COMMUNIC, V61, P551
   Majhi B, 2007, AEU-INT J ELECTRON C, V61, P478, DOI 10.1016/j.aeue.2006.08.007
   MAK CT, 1999, IEEE T IMAGE PROCESS, V8, P1834
   NIEMINEN A, 1987, IEEE T PATTERN ANAL, V9, P74, DOI 10.1109/TPAMI.1987.4767873
   PETERS RA, 1995, IEEE T IMAGE PROCESS, V4, P554, DOI 10.1109/83.382491
   Rioul O, 1996, 1996 IEEE DIGITAL SIGNAL PROCESSING WORKSHOP, PROCEEDINGS, P275, DOI 10.1109/DSPWS.1996.555514
   RITAL S, 2003, 4 EURASIP C FOC VID, P539
   RITAL S, 2002, INT S VID IM PROC MU, P351
   RITAL S, 2001, LECT NOTE COMPUTER S, P34
   SIMON HQ, 2007, FUZZY SETS SYSTEMS, V158, P1036
   SUN T, 1994, PATTERN RECOGN LETT, V15, P341, DOI 10.1016/0167-8655(94)90082-5
   Toprak A, 2007, DIGIT SIGNAL PROCESS, V17, P711, DOI 10.1016/j.dsp.2006.11.008
   YANG RK, 1995, SIGNAL PROCESS, V41, P135, DOI 10.1016/0165-1684(94)00096-I
   YOUNG HC, 1996, P SOC PHOTO-OPT INS, V2727, P1439
   URI TAL IMPULSE NOIS
NR 35
TC 20
Z9 20
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2010
VL 28
IS 9
BP 1329
EP 1338
DI 10.1016/j.imavis.2010.01.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 620NN
UT WOS:000279506700001
DA 2024-07-18
ER

PT J
AU Liu, XM
AF Liu, Xiaoming
TI Video-based face model fitting using Adaptive Active Appearance Model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Active Appearance Model; Model fitting; Subject-specific model; Generic
   model
ID SHAPE
AB Active Appearance Model (AAM) represents the shape and appearance of an object via two low-dimensional subspaces, one for shape and one for appearance. AAM for facial images is currently receiving considerable attention from the computer vision community. However, most existing work focuses on fitting an AAM to a single image. For many applications, effectively fitting an AAM to video sequences is of critical importance and challenging, especially considering the varying quality of real-world video content. This paper proposes an Adaptive Active Appearance Model (AAAM) to address this problem, where both a generic MM component and a subject-specific appearance model component are employed simultaneously in the proposed fitting scheme. While the generic AAM component is held fixed, the subject-specific model component is updated during the fitting process by selecting the frames that can be best explained by the generic model. Experimental results from both indoor and outdoor representative video sequences demonstrate the faster fitting convergence and improved fitting accuracy. (C) 2009 Elsevier B.V. All rights reserved.
C1 Gen Elect Global Res, Visualizat & Comp Vis Lab, Niskayuna, NY 12309 USA.
C3 General Electric
RP Liu, XM (corresponding author), Gen Elect Global Res, Visualizat & Comp Vis Lab, Niskayuna, NY 12309 USA.
EM liux@research.ge.com
OI liu, xiaoming/0000-0003-3215-8753
FU National Institute of Justice, Office of Justice Programs, US Department
   of Justice [2005-IJ-CX-K060, 2006-IJ-CX-K045, 2007-DE-BX-K191]
FX This work was supported by awards #2005-IJ-CX-K060, #2006-IJ-CX-K045,
   and #2007-DE-BX-K191 awarded by the National Institute of Justice,
   Office of Justice Programs, US Department of Justice. The opinions,
   findings, and conclusions or recommendations expressed in this
   publication are those of the authors and do not necessarily reflect the
   views of the Department of Justice.
CR Ahlberg J, 2002, EURASIP J APPL SIG P, V2002, P566, DOI 10.1155/S1110865702203078
   [Anonymous], P 18 BRIT MACH VIS C
   [Anonymous], P 17 BRIT MACH VIS C
   [Anonymous], CMURITR0335
   [Anonymous], 2004, Statistical Models of Appearance for Computer Vision
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker S, 2004, IEEE T PATTERN ANAL, V26, P1380, DOI 10.1109/TPAMI.2004.77
   Batur AU, 2005, IEEE T IMAGE PROCESS, V14, P1707, DOI 10.1109/TIP.2005.854473
   Beichel R, 2005, IEEE T MED IMAGING, V24, P1151, DOI 10.1109/TMI.2005.853237
   Bosch JG, 2002, IEEE T MED IMAGING, V21, P1374, DOI 10.1109/TMI.2002.806427
   Butakoff C, 2006, IEEE T PATTERN ANAL, V28, P1847, DOI 10.1109/TPAMI.2006.215
   CHANG K, 2003, P ACM WORKSH MULT US, P25
   COOTES T, 1991, P 2 BRIT MACH VIS C, P54
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P429
   Dedeoglu G, 2007, IEEE T PATTERN ANAL, V29, P807, DOI 10.1109/TPAMI.2007.1054
   Donner R, 2006, IEEE T PATTERN ANAL, V28, P1690, DOI 10.1109/TPAMI.2006.206
   Gross R, 2005, IMAGE VISION COMPUT, V23, P1080, DOI 10.1016/j.imavis.2005.07.009
   JONES E, 2005, P 10 INT C COMP VIS, V2, P1097
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Koterba S, 2005, IEEE I CONF COMP VIS, P511
   Levy A, 2000, IEEE T IMAGE PROCESS, V9, P1371, DOI 10.1109/83.855432
   Liu XM, 2003, PATTERN RECOGN, V36, P1945, DOI 10.1016/S0031-3203(03)00057-8
   Matthews I, 2004, INT J COMPUT VISION, V60, P135, DOI 10.1023/B:VISI.0000029666.37597.d3
   MATTHEWS I, 2003, P 14 BRIT MACH VIS C
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Rolfe BF, 2001, P I MECH ENG B-J ENG, V215, P1229, DOI 10.1243/0954405011519295
   WHEELER FW, 2007, P IEEE SIGN PROC SOC
   Yan SC, 2003, IMAGE VISION COMPUT, V21, P69, DOI 10.1016/S0262-8856(02)00136-1
NR 29
TC 34
Z9 40
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2010
VL 28
IS 7
SI SI
BP 1162
EP 1172
DI 10.1016/j.imavis.2009.09.016
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 603UP
UT WOS:000278233900010
DA 2024-07-18
ER

PT J
AU Liu, XH
   Chua, CS
AF Liu, Xiao-Hui
   Chua, Chin-Seng
TI Rejection of non-meaningful activities for HMM-based activity
   recognition system
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pattern spotting; Likelihood ratio test; Hidden Markov model; Pairwise
   likelihood ratio test
AB This paper presents a new test to distinguish between meaningful and non-meaningful HMM-modeled activity patterns in human activity recognition systems. Operating as a hypothesis test, alternative models are generated from available classes and the decision is based on a likelihood ratio test (LRT). The proposed test differs from traditional LRTs in two aspects. Firstly, the likelihood ratio, which is called pairwise likelihood ratio (PLR), is based on each pair of HMMs. Models for non-meaningful patterns are not required. Secondly, the distribution of the likelihood ratios, rather than a fixed threshold, is used as the measurement. Multiple measurements from multiple PLR tests are combined to improve the rejection accuracy. The advantage of the proposed test is that the establishment of such a test relies only on the meaningful samples. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Liu, Xiao-Hui; Chua, Chin-Seng] Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
C3 Nanyang Technological University
RP Chua, CS (corresponding author), Nanyang Technol Univ, Sch Elect & Elect Engn, Singapore 639798, Singapore.
EM ecschua@ntu.edu.sg
RI Liu, Xiaohui/B-5046-2013
CR Ben-Arie J, 2002, IEEE T PATTERN ANAL, V24, P1091, DOI 10.1109/TPAMI.2002.1023805
   Bobick AF, 2001, IEEE T PATTERN ANAL, V23, P257, DOI 10.1109/34.910878
   Davis JW, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P169, DOI 10.1109/AVSS.2003.1217918
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Elgammal A, 2003, PROC CVPR IEEE, P571
   Fujiyoshi H, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P15, DOI 10.1109/ACV.1998.732852
   Higgins A., 1991, Digital Signal Processing, V1, P89, DOI 10.1016/1051-2004(91)90098-6
   KANG H, 2004, PATTERN RECOGN, P1701
   Kim D, 2007, PATTERN RECOGN, V40, P3012, DOI 10.1016/j.patcog.2007.02.010
   Lee HK, 1999, IEEE T PATTERN ANAL, V21, P961, DOI 10.1109/34.799904
   Li J, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 3, PROCEEDINGS, P949
   Liu XH, 2006, IMAGE VISION COMPUT, V24, P166, DOI 10.1016/j.imavis.2005.09.024
   Ren Y, 2003, MACH VISION APPL, V13, P332, DOI 10.1007/s00138-002-0091-0
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Richards W., 1996, Perception as Bayesian Inference, P63
   Rose RC, 1994, IEEE T SPEECH AUDI P, V2, P245, DOI 10.1109/89.279273
   ROSE RC, 1990, INT CONF ACOUST SPEE, P129, DOI 10.1109/ICASSP.1990.115555
   ROSE RC, 1992, P IEEE INT C AC SPEE, P105
   Rosenberg AE, 1996, INT CONF ACOUST SPEE, P81, DOI 10.1109/ICASSP.1996.540295
   Siohan O, 1999, INT CONF ACOUST SPEE, P825, DOI 10.1109/ICASSP.1999.759798
   Starner T, 1998, IEEE T PATTERN ANAL, V20, P1371, DOI 10.1109/34.735811
   WILCOX LD, 1992, P IEEE INT C AC SPEE, P97
   WILPON JG, 1990, IEEE T ACOUST SPEECH, V38, P1870, DOI 10.1109/29.103088
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
NR 24
TC 5
Z9 5
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2010
VL 28
IS 6
BP 865
EP 871
DI 10.1016/j.imavis.2009.11.001
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 585WO
UT WOS:000276861200002
DA 2024-07-18
ER

PT J
AU Morency, LP
   Whitehill, J
   Movellan, J
AF Morency, Louis-Philippe
   Whitehill, Jacob
   Movellan, Javier
TI Monocular head pose estimation using generalized adaptive view-based
   appearance model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Head pose estimation; View-based appearance model; Keyframe tracking;
   Differential tracking; Rigid body tracking; Kalman filter update;
   Bounded drift
ID TRACKING
AB Accurately estimating the person's head position and orientation is an important task for a wide range of applications such as driver awareness, meeting analysis and human-robot interaction. Over the past two decades, many approaches have been suggested to solve this problem, each with its own advantages and disadvantages. In this paper, we present a probabilistic framework called Generalized Adaptive View-based Appearance Model (GAVAM) which integrates the advantages from three of these approaches: (1) the automatic initialization and stability of static head pose estimation, (2) the relative precision and user-independence of differential registration, and (3) the robustness and bounded drift of keyframe tracking. In our experiments, we show how the GAVAM model can be used to estimate head position and orientation in real-time using a simple monocular camera. Our experiments on two previously published datasets show that the GAVAM framework can accurately track for a long period of time with an average accuracy of 3.5 degrees and 0.75 in. when compared with an inertial sensor and a 3D magnetic sensor. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Morency, Louis-Philippe] USC Inst Creat Technol, Marina Del Rey, CA 90292 USA.
   [Whitehill, Jacob; Movellan, Javier] Univ Calif San Diego, Machine Percept Lab, La Jolla, CA 92093 USA.
C3 University of California System; University of California San Diego
RP Morency, LP (corresponding author), USC Inst Creat Technol, Marina Del Rey, CA 90292 USA.
EM morency@ict.usc.edu; jake@mplab.ucsd.edu; movellan@mplab.ucsd.edu
RI Morency, Louis-Philippe/B-2006-2008
FU US Army Research, Development, and Engineering Command (RDECOM); US
   Naval Research Laboratory [NRL 55-05-03]
FX This work was sponsored by the US Army Research, Development, and
   Engineering Command (RDECOM) and the US Naval Research Laboratory under
   grant # NRL 55-05-03. The content does not necessarily reflect the
   position or the policy of the Government, and no official endorsement
   should be inferred.
CR [Anonymous], P IEEE INT C AUT FAC
   [Anonymous], 2000, CVPR
   BAKER S, 2004, P 11 WORLD C INT TRA
   Balasubramanian VN, 2008, EURASIP J ADV SIG PR, DOI 10.1155/2008/283540
   BASU S, 1996, P INT C PATT REC
   BLACK MJ, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P374, DOI 10.1109/ICCV.1995.466915
   Blanz V, 1999, COMP GRAPH, P187, DOI 10.1145/311535.311556
   Brand M., 2001, CVPR
   Cootes TF, 2002, IMAGE VISION COMPUT, V20, P657, DOI 10.1016/S0262-8856(02)00055-0
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   DESIGN V, 2000, MEGA D MEGAPIXEL DIG
   Eckhardt M, 2009, INT J PATTERN RECOGN, V23, P379, DOI 10.1142/S0218001409007247
   FU Y, 2007, IEEE WORKSH APPL COM, P30
   Fu Y, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P3
   Gourier N, 2007, LECT NOTES COMPUT SC, V4122, P270
   Hanson RJ., 1974, SOLVING LEAST SQUARE
   Huang C, 2007, IEEE T PATTERN ANAL, V29, P671, DOI 10.1109/TPAMI.2007.1011
   Huang J, 1998, INT C PATT RECOG, P154, DOI 10.1109/ICPR.1998.711102
   HUANG K, 2004, ICPR
   Kjeldsen R., 2001, P 2 INT WORKSH REC A, P62
   La Cascia M, 2000, IEEE T PATTERN ANAL, V22, P322, DOI 10.1109/34.845375
   LANITIS A, 1995, FG, P98
   Morency LP, 2003, PROC CVPR IEEE, P803
   Murphy-Chutorian E., 2007, Intelligent Transportation Systems
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   SCHODL A, 1998, PUI98
   Sherrah J, 2001, PATTERN RECOGN, V34, P1565, DOI 10.1016/S0031-3203(00)00091-1
   Torresani L., 2004, ECCV
   VACCHETTI L, 2003, CVPR
   Vedula S., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P722, DOI 10.1109/ICCV.1999.790293
   VIOLA P, 2001, ICCV
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   WU J, 2005, INT WORKSH AN MOD FA
NR 33
TC 25
Z9 31
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2010
VL 28
IS 5
SI SI
BP 754
EP 761
DI 10.1016/j.imavis.2009.08.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 572RG
UT WOS:000275849900004
DA 2024-07-18
ER

PT J
AU Dickinson, P
   Hunter, A
   Appiah, K
AF Dickinson, Patrick
   Hunter, Andrew
   Appiah, Kofi
TI A spatially distributed model for foreground segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Foreground segmentation; Background model; Spatial coherence; Mixture of
   Gaussians
ID TRACKING
AB Foreground segmentation is a fundamental first processing stage for vision systems which monitor real-world activity. In this paper, we consider the problem of achieving robust segmentation in scenes where the appearance of the background varies unpredictably over time. Variations may be caused by processes such as moving water, or foliage moved by wind, and typically degrade the performance of standard per-pixel background models.
   Our proposed approach addresses this problem by modeling homogeneous regions of scene pixels as an adaptive mixture of Gaussians in color and space. Model components are used to represent both the scene background and moving foreground objects. Newly observed pixel values are probabilistically classified, such that the spatial variance of the model components supports correct classification even when the background appearance is significantly distorted. We evaluate our method over several challenging video sequences, and compare our results with both per-pixel and Markov Random Field based models. Our results show the effectiveness of our approach in reducing incorrect classifications. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Dickinson, Patrick; Hunter, Andrew; Appiah, Kofi] Lincoln Univ, Ctr Visual Surveillance & Machine Percept, Lincoln, England.
C3 University of Lincoln
RP Dickinson, P (corresponding author), Lincoln Univ, Ctr Visual Surveillance & Machine Percept, Lincoln, England.
EM pdickinson@lincoln.ac.uk
RI Hunter, Andrew/E-3880-2015
OI Hunter, Andrew/0000-0003-3786-4008
FU EPSRC [GP-P04329-01]
FX The work presented in this article was supported by an EPSRC CASE
   studentship (Reference GP-P04329-01), in conjunction with Nectar
   Electronics Ltd. UK. The authors would like to thank Ray Broadbridge of
   Nectar Electronics for contributions in supporting this work.
CR [Anonymous], P IEEE INT C COMP VI
   Cheng J, 2006, IMAGE VISION COMPUT, V24, P473, DOI 10.1016/j.imavis.2006.01.018
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   Greenspan H, 2004, IEEE T PATTERN ANAL, V26, P384, DOI 10.1109/TPAMI.2004.1262334
   Haritaoglu I, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P222, DOI 10.1109/AFGR.1998.670952
   Harville M, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P3, DOI 10.1109/EVENT.2001.938860
   Heisele B., 2000, P AS C COMP VIS TAIP, P1028
   HUA C, 2006, P INT C PATT REC HON, V1, P739
   KaewTraKulPong P., 2001, P EUR WORKSH ADV VID
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   MIGDAL J, 2005, P IEEE WORKSH MOT VI, V2, P58
   Monnet A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1305
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Paragios N, 2001, PROC CVPR IEEE, P1034
   PECE AEC, 2000, P S INT ROB SYST SIR, P295
   RAJA Y, 1998, P EUR C COMP VIS FRE, V1, P460
   Ren Y, 2003, MACH VISION APPL, V13, P332, DOI 10.1007/s00138-002-0091-0
   Rosin PL, 2003, PATTERN RECOGN LETT, V24, P2345, DOI 10.1016/S0167-8655(03)00060-6
   Schindler K, 2006, LECT NOTES COMPUT SC, V3852, P581
   Seki M, 2003, PROC CVPR IEEE, P65
   Sheikh Y, 2005, IEEE T PATTERN ANAL, V27, P1778, DOI 10.1109/TPAMI.2005.213
   SHIMADA A, 2006, P IEEE INT C VID SIG
   Spagnolo P, 2006, IMAGE VISION COMPUT, V24, P411, DOI 10.1016/j.imavis.2006.01.001
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Tian YL, 2005, PROC CVPR IEEE, P1182
   Wang Y, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P474
   Wang Y, 2006, IEEE T PATTERN ANAL, V28, P279, DOI 10.1109/TPAMI.2006.25
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
NR 28
TC 18
Z9 27
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1326
EP 1335
DI 10.1016/j.imavis.2008.12.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200009
DA 2024-07-18
ER

PT J
AU Gerogiannis, D
   Nikou, C
   Likas, A
AF Gerogiannis, Demetrios
   Nikou, Christophoros
   Likas, Aristidis
TI The mixtures of Student's <i>t</i>-distributions as a robust framework
   for rigid registration
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image registration; Point set registration; Gaussian mixture model;
   Mixtures of Student's t-distribution; Expectation-Maximization (EM)
   algorithm
ID MUTUAL INFORMATION; ALGORITHM; MAXIMIZATION; INTENSITY; IMAGES
AB The problem of registering images or point sets is addressed. At first, a pixel similarity-based algorithm for the rigid registration between single and multimodal images is presented. The images may present dissimilarities due to noise, missing data or outlying measures. The method relies on the partitioning of a reference image by a Student's t-mixture model (SMM). This partition is then projected onto the image to be registered. The main idea is that a t-component in the reference image corresponds to a t-component in the image to be registered. If the images are correctly registered the distances between the corresponding components is minimized. Moreover, the extension of the method to the registration of point clouds is also proposed. The use of SMM components is justified by the property that they have heavier tails than standard Gaussians, thus providing robustness to outliers. Experimental results indicate that, even in the case of low SNR or important amount of dissimilarities due to temporal changes, the proposed algorithm compares favorably to the mutual information method for image registration and to the Iterative Closest Points (ICP) algorithm for the alignment of point sets. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Gerogiannis, Demetrios; Nikou, Christophoros; Likas, Aristidis] Univ Ioannina, Dept Comp Sci, GR-45110 Ioannina, Greece.
C3 University of Ioannina
RP Nikou, C (corresponding author), Univ Ioannina, Dept Comp Sci, POB 1186, GR-45110 Ioannina, Greece.
EM dgerogia@cs.uoi.gr; cnikou@cs.uoi.gr; arly@cs.uoi.gr
RI Nikou, Christophoros/L-8685-2014; Nikou, Christophoros/AAF-4236-2019
OI Gerogiannis, Demetris/0000-0003-0798-6709
CR [Anonymous], 2001, Medical image registration
   Bankman IN, 2000, HDB MED IMAGE PROCES
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Besl PJ., 1998, PATTERN ANAL MACH IN, V14, P239, DOI [10.1109/34.121791, DOI 10.1109/34.121791]
   BISHOP C, 2005, NEUROCOMPUTING, P69
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Brandt SS, 2006, J MATH IMAGING VIS, V25, P25, DOI 10.1007/s10851-005-4386-4
   CHEN S, 2004, P 3 IEEE INT C IM GR
   Chetverikov D, 2005, IMAGE VISION COMPUT, V23, P299, DOI 10.1016/j.imavis.2004.05.007
   CHUI H, 2000, P INT C COMP VIS PAT, V2
   Chui HL, 2003, COMPUT VIS IMAGE UND, V89, P114, DOI 10.1016/S1077-3142(03)00009-2
   Constantinopoulos C, 2006, IEEE T PATTERN ANAL, V28, P1013, DOI 10.1109/TPAMI.2006.111
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Granger S, 2002, LECT NOTES COMPUT SC, V2353, P418
   Guimond A, 2001, IEEE T MED IMAGING, V20, P58, DOI 10.1109/42.906425
   HEITZ F, 1990, IEEE T ACOUST SPEECH, V38, P695, DOI 10.1109/29.52709
   HELLIER P, 2003, P 2003 IEEE INT C IM, V1
   HERBIN M, 1989, COMPUT VISION GRAPH, V47, P77, DOI 10.1016/0734-189X(89)90055-8
   HERMOSILLO G, 2001, P 2001 IEEE C COMP V, V1
   Jensen JohnR., 2004, INTRO DIGITAL IMAGE, V3rd
   Jian B, 2005, IEEE I CONF COMP VIS, P1246
   LEVENTON M, 1998, P MED IM COMP COMP A
   Maes F, 1997, IEEE T MED IMAGING, V16, P187, DOI 10.1109/42.563664
   Maintz J B, 1998, Med Image Anal, V2, P1, DOI 10.1016/S1361-8415(01)80026-8
   MATTES D, 2003, P 2001 SPIE MED IM C, V4322
   McLachlan G., 2000, WILEY SER PROB STAT, DOI 10.1002/0471721182
   Myronenko Andriy., 2006, Advances in Neural Information Processing Systems, V19, P1009
   Nikou C, 1999, PATTERN RECOGN, V32, P1351, DOI 10.1016/S0031-3203(98)00167-8
   Peel D, 2000, STAT COMPUT, V10, P339, DOI 10.1023/A:1008981510081
   PHILLIPS J, 2007, P 6 INT C 3D DIG IM
   Pluim JPW, 2000, COMPUT VIS IMAGE UND, V77, P211, DOI 10.1006/cviu.1999.0816
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   RAJWADE A, 2006, P 2006 IEEE C COMP V
   Rangarajan A., 1999, MED IMAGE ANAL, V4, P1
   RANGARAJAN A, 1997, LECT NOTES COMPUTER, V1230
   Roche A, 2001, IEEE T MED IMAGING, V20, P1038, DOI 10.1109/42.959301
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Taron M, 2009, IEEE T PATTERN ANAL, V31, P99, DOI 10.1109/TPAMI.2008.36
   Thévenaz P, 2000, IEEE T IMAGE PROCESS, V9, P2083, DOI 10.1109/83.887976
   Tu ZW, 2008, COMPUT VIS IMAGE UND, V109, P290, DOI 10.1016/j.cviu.2007.04.004
   Viola P, 1997, INT J COMPUT VISION, V24, P137, DOI 10.1023/A:1007958904918
   WANG F, 2006, P EUR C COMP VIS ECC
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 43
TC 46
Z9 52
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 3
PY 2009
VL 27
IS 9
BP 1285
EP 1294
DI 10.1016/j.imavis.2008.11.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FK
UT WOS:000267723200005
DA 2024-07-18
ER

PT J
AU Daul, C
   Lopez-Hernandez, J
   Wolf, D
   Karcher, G
   Ethévenot, G
AF Daul, Christian
   Lopez-Hernandez, Juan
   Wolf, Didier
   Karcher, Gilles
   Ethevenot, Gerard
TI 3-D multimodal cardiac data superimposition using 2-D image registration
   and 3-D reconstruction from multiple views
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Coronary angiography; Tomoscintygraphy; Active contours; Distance map;
   Cardiac data segmentation; 3-D reconstruction; 3-D data superimposition;
   Multimodal data registration
ID CORONARY ARTERIAL TREE
AB Tomoscintigraphy (3-D data representing the myocardium perfusion) and coronarography (X-ray image sequences acquired from several viewpoints and providing information about the coronary artery tree state) are widespread examinations used standardly for the diagnosis of cardiovascular diseases. Currently, the data of both examinations are separately analyzed by the specialists who are often not able to visually link the information of the two modalities. The aim of this work is to facilitate the diagnosis by providing the specialist with 3-D representations highlighting the relationship between stenoses (artery narrowing, disease cause) and perfusion defaults (muscle necrosis, consequence). In such representations, the structure of a schematic artery tree and the stenosis positions are 3-D reconstructed and set onto the perfusion volume. The reconstruction algorithm starts with the projection of the perfusion volume on planes parallel to the X-ray images. In this way, 2-D tomographic images are generated for each viewpoint of the coronarography. The borders of the myocardium shadow visible in the X-ray images are then segmented with an active contour method. These contours are registered with their homologuous structures from the corresponding 2-D tomographic images. The geometrical transformations obtained for each coronarographic viewpoint are used to place artery points marked by cardiologists in the X-ray images (stenoses, artery beginnings, ends and bifurcations) in their corresponding positions in the tomographic images. Finally, the schematic artery tree is set on the perfusion volume using the homologous points of the different viewpoints and a parallel projection model. The main advantage of this method is that the clinical acquisition protocols remain unchanged, no calibration of the acquisition systems being needed. Results are given for a phantom and a database of patients in order to validate the proposed method. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Daul, Christian; Lopez-Hernandez, Juan; Wolf, Didier] Nancy Univ, CRAN, CNRS, F-54516 Vandoeuvre Les Nancy, France.
   [Karcher, Gilles; Ethevenot, Gerard] CHU Nancy, Lab Insuffisance Cardiaque Mecanismes Physiopatho, EA 2403, F-54511 Vandoeuvre Les Nancy, France.
C3 Centre National de la Recherche Scientifique (CNRS); Universite de
   Lorraine; CHU de Nancy
RP Daul, C (corresponding author), Nancy Univ, CRAN, CNRS, 2 Ave Foret Haye, F-54516 Vandoeuvre Les Nancy, France.
EM christian.daul@ensem.inpl-nancy.fr
RI Lopez-Hernandez, Juan/D-9804-2018; Hu, Hong/A-1693-2011
FU Segami company, 22 rue Sibelle, Paris, France; ANVAR (Agence Nationale
   de Valorisation et d'Aide a la Recherche)
FX This work was partially sponsored by the Segami company, 22 rue Sibelle,
   Paris, France and the ANVAR (Agence Nationale de Valorisation et d'Aide
   a la Recherche).
CR BOLON C, 1995, ANAL IMAGES FILTRAGE
   BORGEFORS G, 1984, P 7 INT C PATT REC M, P1175
   Chen SJ, 2000, IEEE T MED IMAGING, V19, P318, DOI 10.1109/42.848183
   COHEN L, 1991, GRAPH MODEL IM PROC, V53, P211
   COHEN LD, 1993, IEEE T PATTERN ANAL, V15, P1131, DOI 10.1109/34.244675
   COPPINI G, 1991, MED BIOL ENG COMPUT, V29, P535, DOI 10.1007/BF02442327
   DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   FABER TL, 1995, J NUCL MED, V36, P697
   FABER TL, 1996, P COMP CARD 96, P333
   GARREAU M, 1991, IEEE T MED IMAGING, V10, P122, DOI 10.1109/42.79469
   GIRAUDON G, 1987, 5 SCAND C IM AN STOC
   GUGGENHEIM N, 1991, PHYS MED BIOL, V36, P99, DOI 10.1088/0031-9155/36/1/009
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Lenzen MJ, 2005, EUR HEART J, V26, P1169, DOI 10.1093/eurheartj/ehi238
   Maintz J.B., 1998, Medical image analysis, V2
   Mäkelä T, 2002, IEEE T MED IMAGING, V21, P1011, DOI 10.1109/TMI.2002.804441
   Merle AB, 1998, COMPUT CARDIOL, V25, P757, DOI 10.1109/CIC.1998.731984
   Messenger JC, 2000, INT J CARDIAC IMAG, V16, P413, DOI 10.1023/A:1010643426720
   MOKHTARIAN F, 1986, IEEE T PATTERN ANAL, V8, P34, DOI 10.1109/TPAMI.1986.4767750
   NELDER A, 1965, COMPUTER, V5, P308
   Pratt W.K, 1978, DIGITAL IMAGE PROCES
   RUAN S, 1994, IMAGE VISION COMPUT, V12, P683, DOI 10.1016/0262-8856(94)90043-4
   Schindler TH, 2000, INT J CARDIAC IMAG, V16, P1, DOI 10.1023/A:1006216221695
   Schindler TH, 1999, INT J CARDIAC IMAG, V15, P357, DOI 10.1023/A:1006232407637
   Sugimoto N, 1999, P SOC PHOTO-OPT INS, V3661, P848, DOI 10.1117/12.348643
   Tukey J.W., 1977, EXPLORATORY DATA ANA, V2
   VANDENELSEN PA, 1993, IEEE ENG MED BIOL, V12, P26, DOI 10.1109/51.195938
   Windyga P, 1998, MED BIOL ENG COMPUT, V36, P158, DOI 10.1007/BF02510737
NR 28
TC 3
Z9 3
U1 0
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 790
EP 802
DI 10.1016/j.imavis.2008.08.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000018
DA 2024-07-18
ER

PT J
AU Li, Z
   Jiang, PH
   Ma, H
   Yang, J
   Tang, DM
AF Li, Zheng
   Jiang, Pohuang
   Ma, Hong
   Yang, Jian
   Tang, DongMing
TI A model for dynamic object segmentation with kernel density estimation
   based on gradient features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Kernel density estimation; Cast shadow; Reflection image; Gradient
   feature; Dynamic object segmentation
AB The dynamic object segmentation in videos taken from a static camera is a basic technique in many vision surveillance applications. In order to suppress fake objects caused by dynamic cast shadows and reflection images, this paper presents a novel segmentation model with the function of cast shadow and reflection image suppression. This model is a kernel density estimation model based on dynamic gradient features. Unlike the conventional kernel density estimation model which can only suppress cast shadows in color videos, this model Can also Suppress them in intensity videos, and under the circumstance of diffusion it can suppress reflection images effectively. Although this model may cause the increase of the false negative rate, its function of fake object Suppression is remarkable. Furthermore, the false negative rate can be reduced with other convenient methods. Some experimental results by real videos are also presented in this paper to demonstrate the effectiveness of this model. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Li, Zheng; Jiang, Pohuang] Sichuan Univ, Coll Comp Sci, Chengdu 610064, Sichuan, Peoples R China.
   [Ma, Hong] Sichuan Univ, Coll Math, Chengdu 610064, Sichuan, Peoples R China.
   [Yang, Jian; Tang, DongMing] Univ Elect Sci & Technol China, Chengdu 610054, Sichuan, Peoples R China.
C3 Sichuan University; Sichuan University; University of Electronic Science
   & Technology of China
RP Li, Z (corresponding author), Sichuan Univ, Coll Comp Sci, Chengdu 610064, Sichuan, Peoples R China.
EM lizheng@cs.scu.edu.cn; jiangpohuang@gmail.com; mahong@scu.edu.cn;
   yangjiin@uestc.edu.cn
RI Yang, Jian/ABD-9791-2021
OI Yang, Jian/0000-0003-2172-6591
FU science foundation of Sichuan province of Republic of China
   [2006J13-092]
FX We are grateful to the science foundation of Sichuan province
   (2006J13-092) of Republic of China for financial Support.
CR [Anonymous], EUR C COMP VIS ECCV
   [Anonymous], INT C IMAGE PROCESSI
   ECONOMOU G, 2001, ICIP 01, V1, P922
   Elgammal A, 2002, P IEEE, V90, P1151, DOI 10.1109/JPROC.2002.801448
   ELGMMAL A, 2001, CVPR 01, V2, P563
   ELSABAN MA, 2003, ICIP 03, V1
   Friedman N., 1997, PROC UNCERTAINTY ART, P175
   Grimson WEL, 1998, PROC CVPR IEEE, P22, DOI 10.1109/CVPR.1998.698583
   MIGDAL J, 2005, WACV MOTION 05, V2, P58
   Mittal A, 2004, PROC CVPR IEEE, P302
   Salvador E, 2004, COMPUT VIS IMAGE UND, V95, P238, DOI 10.1016/j.cviu.2004.03.008
   SOUVENIR R, 2005, PETS 05
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Yoneyama A, 2003, IEEE CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, PROCEEDINGS, P229, DOI 10.1109/AVSS.2003.1217926
NR 14
TC 9
Z9 12
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 4
PY 2009
VL 27
IS 6
BP 817
EP 823
DI 10.1016/j.imavis.2008.08.004
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 441YR
UT WOS:000265807000020
DA 2024-07-18
ER

PT J
AU Pauwels, K
   Van Hulle, MM
AF Pauwels, Karl
   Van Hulle, Marc M.
TI Optic flow from unstable sequences through local velocity constancy
   maximization
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 17th Annual British Machine Vision Conference
CY SEP, 2006
CL British Machine Vis Assoc, Edinburgh, SCOTLAND
HO British Machine Vis Assoc
DE Multiscale optic flow; Video stabilization; Phase-based techniques
ID VIDEO STABILIZATION; MOTION
AB We introduce a novel video stabilization method that enables the extraction of optic flow from short unstable sequences. Contrary to traditional stabilization techniques that use approximative global motion models to estimate the full camera motion, our method estimates the unstable component of the camera motion only. This allows for the use of simpler global motion models, and at the same time extends the validity to more complex environments, such as close scenes that contain independently moving objects. The unstable component of the camera motion is derived from a maximization of the temporal local velocity constancy over the entire short sequence. The method, embedded within a phase-based optic flow algorithm, is tested on both synthetic and complex real-world sequences. The optic flow obtained using our technique is denser than that extracted directly from the original sequence, and from a sequence stabilized with a more traditional stabilization technique. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Pauwels, Karl; Van Hulle, Marc M.] Katholieke Univ Leuven, Neuro & Psychofysiol Lab, B-3000 Louvain, Belgium.
C3 KU Leuven
RP Pauwels, K (corresponding author), Katholieke Univ Leuven, Neuro & Psychofysiol Lab, Herestr 49,Bus 1021, B-3000 Louvain, Belgium.
EM karl.pauwels@med.kuleuven.be; marc.vanhulle@med.kuleuven.be
RI Pauwels, Karl/B-1074-2013
OI Pauwels, Karl/0000-0003-3731-0582; Van Hulle, Marc/0000-0003-1060-7044
CR Adelson E. H., 1984, RCA engineer, V29, P33, DOI 10.1.1.59.9419.
   ADIV G, 1985, IEEE T PATTERN ANAL, V7, P384, DOI 10.1109/TPAMI.1985.4767678
   [Anonymous], ECCV 92
   [Anonymous], 1996, MULTIPLE COMP THEORY, DOI DOI 10.1201/B15074
   Balakirsky SB, 1996, REAL-TIME IMAGING, V2, P297, DOI 10.1006/rtim.1996.0031
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Bombini P., 2006, P IEEE INT TRANSP SY, P1562
   Duric Z, 2003, MACH VISION APPL, V13, P303, DOI 10.1007/s00138-002-0085-y
   FLEET DJ, 1990, INT J COMPUT VISION, V5, P77, DOI 10.1007/BF00056772
   FLEET DJ, 1991, CVGIP-IMAG UNDERSTAN, V53, P198, DOI 10.1016/1049-9660(91)90027-M
   FREEMAN WT, 1991, IEEE T PATTERN ANAL, V13, P891, DOI 10.1109/34.93808
   Gautama T, 2002, IEEE T NEURAL NETWOR, V13, P1127, DOI 10.1109/TNN.2002.1031944
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   IRANI M, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P454, DOI 10.1109/CVPR.1994.323866
   Liang YM, 2004, IEEE T VEH TECHNOL, V53, P1636, DOI 10.1109/TVT.2004.836923
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Morimoto C, 1996, REAL-TIME IMAGING, V2, P285, DOI 10.1006/rtim.1996.0030
   Morimoto C, 1998, INT CONF ACOUST SPEE, P2789, DOI 10.1109/ICASSP.1998.678102
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Xiang T, 2003, INT J COMPUT VISION, V51, P111, DOI 10.1023/A:1021627622971
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 21
TC 19
Z9 19
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 2
PY 2009
VL 27
IS 5
SI SI
BP 579
EP 587
DI 10.1016/j.imavis.2008.04.010
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 437WD
UT WOS:000265516700008
OA Green Accepted
DA 2024-07-18
ER

PT J
AU Ameer, S
   Basir, O
AF Ameer, Salah
   Basir, Otman
TI Image compression using plane fitting with inter-block prediction
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image compression; Plane fitting; Blocking effects; Progressive
   transmission; Multiplication- and division-free implementations
ID VECTOR QUANTIZER; DESIGN; REPRESENTATION; SEGMENTATION; ALGORITHM;
   SURFACES
AB This paper describes a simple scheme to compress images through plane fitting. The scheme can achieve better than 60:1 compression ratio, while maintaining acceptable image quality. The results are superior to those of JPEG at comparable compression ratios. The scheme does not require any multiplication or division operations, making it a perfect candidate for online and/or progressive compression. The scheme is scalable in the context of computations required to magnify the image. Blocking effects were reduced up to 0.85 dB of PSNR through simple line fitting on block boundaries. The performance of the scheme is further improved by optimizing its predicted model parameters based on previously coded neighbouring blocks. It is found that less than 2 bits (on average) are enough to index the position of the candidate neighbour, making a 100:1 compression ratio possible. The improvement in the compression ratio came at the expense of moderate to small quality degradations. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Ameer, Salah; Basir, Otman] Univ Waterloo, Dept Elect & Comp Engn, Waterloo, ON N2L 3G1, Canada.
C3 University of Waterloo
RP Ameer, S (corresponding author), Univ Waterloo, Dept Elect & Comp Engn, 200 Univ Ave W, Waterloo, ON N2L 3G1, Canada.
EM ameer@pami.uwaterloo.ca; obasir@uwaterloo.ca
RI Basir, Otman/ISU-4477-2023
OI Basir, Otman/0000-0002-6454-0538
CR Ameer S., 2006, INT C COMPUTER VISIO, P101
   Aydinoglu H., 1996, 13 ASILOMAR C SIGNAL, V1, P520
   BASERI R, 1994, P ICIP 94, V3, P866
   BERG A, 1994, P 37 MIDW S CIRC SYS, V2, P943
   Biswas S, 2003, PATTERN RECOGN, V36, P1501, DOI 10.1016/S0031-3203(02)00261-3
   CABRELLI CA, 1990, IEEE T PATTERN ANAL, V12, P1190, DOI 10.1109/34.62608
   Chen Y., 1994, GRAPH MODEL IM PROC, V13, P272
   Chou J, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P377, DOI 10.1109/ICIP.1998.723505
   DELP EJ, 1979, IEEE T COMMUN, V27, P1335, DOI 10.1109/TCOM.1979.1094560
   DENATALE FGB, 1991, ELECTRON LETT, V27, P2035, DOI 10.1049/el:19911260
   EDEN M, 1986, SIGNAL PROCESS, V10, P385, DOI 10.1016/0165-1684(86)90046-0
   Egger O, 1999, P IEEE, V87, P976, DOI 10.1109/5.763312
   HABIBI A, 1977, IEEE T COMMUN, V25, P1275, DOI 10.1109/TCOM.1977.1093760
   Hasegawa M., 2002, Systems and Computers in Japan, V33, P31, DOI 10.1002/scj.10097
   Hemami SS, 1997, IEEE T IMAGE PROCESS, V6, P523, DOI 10.1109/83.563318
   HUANG J, 1994, IEEE INT C AC SPEECH, V5, P333
   Jiang J, 1999, SIGNAL PROCESS-IMAGE, V14, P737, DOI 10.1016/S0923-5965(98)00041-1
   Karczewicz M, 1997, SIGNAL PROCESS-IMAGE, V10, P63, DOI 10.1016/S0923-5965(97)00019-2
   Kieu T, 2001, IEEE REGION 10 INTERNATIONAL CONFERENCE ON ELECTRICAL AND ELECTRONIC TECHNOLOGY, VOLS 1 AND 2, P23, DOI 10.1109/TENCON.2001.949544
   Kim HS, 2002, PATTERN RECOGN LETT, V23, P1239, DOI 10.1016/S0167-8655(02)00059-4
   Laha A, 2004, IEEE T IMAGE PROCESS, V13, P1291, DOI 10.1109/TIP.2004.833107
   Lakhani G, 2004, IEEE SIGNAL PROC LET, V11, P505, DOI 10.1109/LSP.2004.826643
   Lan YJ, 1998, NINTH IEEE INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOLS 1-3, P1071, DOI 10.1109/PIMRC.1998.731340
   LI WP, 1995, P IEEE, V83, P317, DOI 10.1109/5.364459
   LIM YS, 1988, ELECTRON LETT, V24, P1380, DOI 10.1049/el:19880944
   Lin YP, 1996, MULTIDIM SYST SIGN P, V7, P263, DOI 10.1007/BF01826246
   LU T, 2000, P DAT COMPR C, P410
   Nguyen TB, 1997, IEEE T PATTERN ANAL, V19, P84, DOI 10.1109/34.566816
   Sikora T, 2005, P IEEE, V93, P6, DOI 10.1109/JPROC.2004.839601
   SINHA SS, 1992, IEEE T PATTERN ANAL, V14, P36, DOI 10.1109/34.107012
   STROBACH P, 1991, IEEE T SIGNAL PROCES, V39, P1380, DOI 10.1109/78.136544
   Sun HW, 2005, NEURAL COMPUT APPL, V14, P203, DOI 10.1007/s00521-004-0455-7
   Wang SJ, 2005, IEEE T IMAGE PROCESS, V14, P1043, DOI 10.1109/TIP.2005.851693
   Watanabe T, 1997, ELECTRON COMM JPN 1, V80, P55, DOI 10.1002/(SICI)1520-6424(199702)80:2<55::AID-ECJA6>3.0.CO;2-9
   WELLIMEN P, 1991, IEEE T COMMUN, V39, P1845
   Wohlberg B, 1999, IEEE T IMAGE PROCESS, V8, P1716, DOI 10.1109/83.806618
   Wu SH, 2001, IEEE T CIRC SYST VID, V11, P1193, DOI 10.1109/76.964789
   Xu WH, 2005, SIGNAL PROCESS, V85, P1315, DOI 10.1016/j.sigpro.2004.12.012
   Zhang S, 2003, NEUROCOMPUTING, V50, P249, DOI 10.1016/S0925-2312(01)00709-3
NR 39
TC 8
Z9 11
U1 1
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 385
EP 390
DI 10.1016/j.imavis.2008.06.005
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600008
DA 2024-07-18
ER

PT J
AU Feng, Z
   Shang-Qian, L
   Da-Bao, W
   Wei, G
AF Feng, Zhang
   Shang-qian, Liu
   Da-bao, Wang
   Wei, Guan
TI Aircraft recognition in infrared image using wavelet moment invariants
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Wavelet moment invariants; Image recognition; Moment invariants;
   Rotation invariant
AB Automatic Target Recognition (ATR) of infrared object has been taking a great interest to the researchers in recent years. ATR requires invariance of high cognition accuracy in translation, scaling and orientation, but classification of two-dimensional (2D) shapes despite of their position, size and orientation in infrared image remains a difficult problem. In this paper, a feature extraction method is proposed using Wavelet Moment invariants (WMI), The very similar objects can be classified correctly by virtue of the wavelet moment with its multi-resolution properties. Compared with some other geometry moments, the classification rate and the recognition efficiency are improved with wavelet moments. As different wavelet basis will have different impacts to wavelet moment, it affects the efficiency of classification. Some important properties such as orthonomality, Supported length and vanishing moments which affect the performance of wavelet moment are discussed in this paper. Through experimental analysis, a conclusion is obtained that symmetry, compactly supported wavelet has more high-performance, and using wavelet function with proper vanishing moments could effectively improve the efficiency of classification. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Feng, Zhang; Shang-qian, Liu; Da-bao, Wang] Xidian Univ, Sch Tech Phys, Xian 710071, Peoples R China.
   [Wei, Guan] ShuangLiu Airport Swatmb CNS Div, Chengdu 610202, Peoples R China.
C3 Xidian University
RP Feng, Z (corresponding author), Xidian Univ, Sch Tech Phys, Taibai Rd 2, Xian 710071, Peoples R China.
EM cdmavsgprs@hotmail.com
CR Adamek Tomasz., 2003, P 5 ACM SIGMM INT WO, P138
   AZENCOTT R, 1996, P 13 INT C PATT REC, V1, P687
   Bailey RR, 1996, IEEE T PATTERN ANAL, V18, P389, DOI 10.1109/34.491620
   DUDANI SA, 1977, IEEE T COMPUT, V26, P39, DOI 10.1109/TC.1977.5009272
   HU M, 1962, IRE T INFORM THEOR, V8, P179, DOI 10.1109/tit.1962.1057692
   LI YJ, 1992, PATTERN RECOGN, V25, P723, DOI 10.1016/0031-3203(92)90135-6
   MALLAT SG, 1989, IEEE T PATTERN ANAL, V11, P674, DOI 10.1109/34.192463
   Novotni M., 2003, P 8 ACM S SOL MOD AP
   Saupe D., 2001, Pattern Recognition. 23rd DAGM Symposium. Proceedings (Lecture Notes in Computer Science Vol.2191), P392
   Shen DG, 1999, PATTERN RECOGN, V32, P151, DOI 10.1016/S0031-3203(98)00137-X
   TEAGUE MR, 1980, J OPT SOC AM, V70, P920, DOI 10.1364/JOSA.70.000920
   TEH CH, 1988, IEEE T PATTERN ANAL, V10, P496, DOI 10.1109/34.3913
NR 12
TC 42
Z9 57
U1 0
U2 38
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 313
EP 318
DI 10.1016/j.imavis.2008.08.007
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600001
DA 2024-07-18
ER

PT J
AU Carneiro, G
   Vasconcelos, N
AF Carneiro, Gustavo
   Vasconcelos, Nuno
TI Minimum Bayes error features for visual recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 3rd Canadian Conference on Computer and Robot Vision
CY 2006
CL Quebec City, CANADA
SP Int Assoc Pattern Recognit, Canadian Image Proc & Pattern Recognit Soc
DE Visual recognition; Feature selection; Feature extraction; Minimum Bayes
   error; Mixture models; Face recognition; Texture recognition; Object
   recognition
AB The design of optimal feature sets for visual classification problems is still one of the most challenging topics in the area of computer vision. In this work, we propose a new algorithm that computes optimal features, in the minimum Bayes error sense, for visual recognition tasks. The algorithm now proposed combines the fast convergence rate of feature selection (FS) procedures with the ability of feature extraction (FE) methods to uncover optimal features that are not part of the original basis function set. This leads to solutions that are better than those achievable by either FE or FS alone, in a small number of iterations, making the algorithm scalable in the number of classes of the recognition problem. This property is currently only available for feature extraction methods that are either sub-optimal or optimal under restrictive assumptions that do not hold for generic imagery. Experimental results show significant improvements over these methods, either through much greater robustness to local minima or by achieving significantly faster convergence. (C) 2006 Elsevier B.V. All rights reserved.
C1 [Carneiro, Gustavo] Siemens Corp Res, Integrated Data Syst Dept, Princeton, NJ 08540 USA.
   [Vasconcelos, Nuno] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
C3 Siemens AG; University of California System; University of California
   San Diego
RP Carneiro, G (corresponding author), Siemens Corp Res, Integrated Data Syst Dept, 755 Coll Rd E, Princeton, NJ 08540 USA.
EM gustavo.carneiro@siemens.com; nuno@ece.ucsd.edu
OI Vasconcelos, Nuno/0000-0002-9024-4302; Carneiro,
   Gustavo/0000-0002-5571-6220
CR [Anonymous], J ROYAL STAT SOC B
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bishop C. M., 1995, NEURAL NETWORKS PATT
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   Kumar N, 1998, SPEECH COMMUN, V26, P283, DOI 10.1016/S0167-6393(98)00061-2
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   OREN M, 1997, IEEE COMP SOC C COMP
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Roth D, 2002, NEURAL COMPUT, V14, P1071, DOI 10.1162/089976602753633394
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   SAON G, 2000, P NEUR INF P SYST DE
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Vasconcelos N, 2004, IEEE T SIGNAL PROCES, V52, P2322, DOI 10.1109/TSP.2004.831125
   VASCONCELOS N, 2002, NEURAL INFORM PROCES
   VASCONCELOS N, 2003, P IEEE COMP VIS PATT
   VASCONCELOS N, 2002, P EUR C COMP VIS COP
   Viola P, 2001, P 2001 IEEE COMP SOC, pII
   Weber M, 2000, LECT NOTES COMPUT SC, V1842, P18
NR 18
TC 2
Z9 2
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN 1
PY 2009
VL 27
IS 1-2
SI SI
BP 131
EP 140
DI 10.1016/j.imavis.2006.06.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 385NA
UT WOS:000261819700014
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ebrahimnezhad, H
   Ghassemian, H
AF Ebrahimnezhad, Hossein
   Ghassemian, Hassan
TI Robust motion from space curves and 3D reconstruction from multiviews
   using perpendicular double stereo rigs
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D reconstruction; perpendicular double stereo; silhouette; structure
   from motion; space curves; unique points; visual hull
ID SHAPE-FROM-SILHOUETTE; 3-D MOTION; FLOW; GEOMETRY
AB This paper proposes a robust curve based method to reconstruct 3D model of an object from image sequences captured by two perpendicular stereo rigs. First, corresponding points and the geometry of points are computed in stereo images by extracting unique space curves. A new algorithm is proposed to extract unique space curves from plane curves in stereo images based on curvature and torsion consistency. The proposed method provides accurate geometry of the curve points with extremely reduced number of outliers. Contrarily to the standard sparse approaches that need sub-pixel accuracy to compute structure and motion, the proposed curve matching method deals with pixel accuracy information. More importantly, it finds the correspondence based on curve shape and does not use any photometric information. This property makes the matching process very robust against the color and intensity maladjustment of stereo rigs. Second, the recovered space curves are employed to estimate robust motion by minimizing the curve distance in the next sequence of stereo images. An efficient structure of stereo rigs - perpendicular double stereo - is proposed to improve accuracy of motion estimation. We discuss and prove its properties mathematically. Third, a set of calibrated virtual cameras are constructed from estimated motion information to take advantage of the shape-from-silhouette using multiple views and extract the object's visual hull as fine as possible. As a whole, a complete automatic and practical system of three-dimensional modeling from raw images captured by calibrated perpendicular double stereo rigs to surface representation is proposed. Fine motion estimation is the main advantage of the proposed method using perpendicular stereo rigs, which makes use of the space curves in a large base line camera setup. While the previous methods of motion estimation suffer from the statistical bias due to quantization noise, measurement error, and outliers in the input data set, the proposed method overcomes the bias problem even in pixel-level information. Experimental results demonstrate the privileged performance of the proposed method for a variety of object shapes and textures. (c) 2008 Elsevier B.V. All rights reserved.
C1 [Ebrahimnezhad, Hossein; Ghassemian, Hassan] Tarbiat Modares Univ, Dept Elect & Comp Engn, Tehran, Iran.
C3 Tarbiat Modares University
RP Ghassemian, H (corresponding author), Tarbiat Modares Univ, Dept Elect & Comp Engn, POB 14115-143, Tehran, Iran.
EM ebrahimnezhad@sut.ac.ir; ghassemi@modares.ac.ir
RI ebrahimnezhad, hossein/ABC-3865-2021; Ghassemian, Hassan/D-1955-2010
OI ebrahimnezhad, hossein/0000-0003-4071-2750; Ghassemian,
   Hassan/0000-0002-2303-1753
FU Iran Telecommunication Research Center [TMU 85-05-33]
FX This research was supported in part by ITRC, the Iran Telecommunication
   Research Center, under Grant No. TMU 85-05-33.
CR [Anonymous], 2000, LNCS, DOI DOI 10.1007/3-540-44480-7
   Bottino A, 2003, IEEE T PATTERN ANAL, V25, P1484, DOI 10.1109/TPAMI.2003.1240121
   Calway A, 2005, IEEE T PATTERN ANAL, V27, P562, DOI 10.1109/TPAMI.2005.83
   Cheung KM, 2005, INT J COMPUT VISION, V62, P221, DOI 10.1007/s11263-005-4881-5
   CHOWDHURY AKR, 2004, IEEE T IMAGE PROCESS, V14, P1057
   Dornaika F., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P70, DOI 10.1109/CVPR.1999.786919
   Ebrahimnezhad H, 2006, 2006 IEEE WORKSHOP ON MULTIMEDIA SIGNAL PROCESSING, P192, DOI 10.1109/MMSP.2006.285295
   Eisert P, 2000, IEEE T CIRC SYST VID, V10, P261, DOI 10.1109/76.825726
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Furukawa Y, 2006, IEEE T PATTERN ANAL, V28, P302, DOI 10.1109/TPAMI.2006.41
   GRAY A, 1997, MODERN DIFFERENTIAL, P219
   Han JH, 2000, IEEE T PATTERN ANAL, V22, P358, DOI 10.1109/34.845378
   Han YM, 2005, IEEE T CIRC SYST VID, V15, P269, DOI 10.1109/TCSVT.2004.841541
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Ho PK, 2000, IEEE T PATTERN ANAL, V22, P215, DOI 10.1109/34.825760
   JEPSON AD, 1993, SPATIAL VISION IN HUMANS AND ROBOTS, P39
   KAHL F, 2003, INT C COMP VIS, P181
   KANATANI K, 1993, INT J COMPUT VISION, V11, P267, DOI 10.1007/BF01469345
   Lhuillier M, 2005, IEEE T PATTERN ANAL, V27, P418, DOI 10.1109/TPAMI.2005.44
   LI LX, 1993, IEEE T PATTERN ANAL, V15, P657, DOI 10.1109/34.221167
   Mülayim AY, 2003, IEEE T SYST MAN CY B, V33, P582, DOI 10.1109/TSMCB.2003.814303
   Papadimitriou T, 2000, IEEE T CIRC SYST VID, V10, P541, DOI 10.1109/76.844999
   Park SK, 2001, PATTERN RECOGN, V34, P1713, DOI 10.1016/S0031-3203(00)00104-7
   POLLEFEYS M, 1998, P EUR WORKSH 3D STRU, P139
   Robert L., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P57, DOI 10.1109/CVPR.1991.139661
   Schmid C, 2000, INT J COMPUT VISION, V40, P199, DOI 10.1023/A:1008135310502
   Szeliski R., 1994, Journal of Visual Communication and Image Representation, V5, P10, DOI 10.1006/jvci.1994.1002
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   Torr PHS, 2000, COMPUT VIS IMAGE UND, V78, P138, DOI 10.1006/cviu.1999.0832
   WENG JY, 1992, IEEE T ROBOTIC AUTOM, V8, P362, DOI 10.1109/70.143354
   YANG L, 2004, J WSCG, V12
   YOUNG GSJ, 1990, IEEE T PATTERN ANAL, V12, P735, DOI 10.1109/34.57666
   Zhang Y, 2003, IEEE T SYST MAN CY B, V33, P592, DOI 10.1109/TSMCB.2003.814284
   Zhang ZY, 1998, INT J COMPUT VISION, V27, P161, DOI 10.1023/A:1007941100561
NR 34
TC 6
Z9 7
U1 3
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2008
VL 26
IS 10
BP 1397
EP 1420
DI 10.1016/j.imavis.2008.01.002
PG 24
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 350CR
UT WOS:000259330700009
DA 2024-07-18
ER

PT J
AU Chetty, G
   Wagner, M
AF Chetty, Girija
   Wagner, Michael
TI Robust face-voice based speaker identity verification using multilevel
   fusion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE lip; 3D face; voice; biometric; identity verification; robust;
   multilevel fusion
ID SPEECH; MOTION
AB In this paper, we propose a robust multilevel fusion strategy involving cascaded multimodal fusion of audio-lip-face motion, correlation and depth features for biometric person authentication. The proposed approach combines the information from different audio-video based modules, namely: audio-lip motion module, audio-lip correlation module, 2D + 3D motion-depth fusion module, and performs a hybrid cascaded fusion in an automatic, unsupervised and adaptive manner, by adapting to the local performance of each module. This is done by taking the output-score based reliability estimates (confidence measures) of each of the module into account. The module weightings are determined automatically such that the reliability measure of the combined scores is maximised. To test the robustness of the proposed approach, the audio and visual speech (mouth) modalities are degraded to emulate various levels of train/test mismatch; employing additive white Gaussian noise for the audio and JPEG compression for the video signals. The results show improved fusion performance for a range of tested levels of audio and video degradation, compared to the individual module performances. Experiments on a 3D stereovision database AVOZES show that, at severe levels of audio and video mismatch, the audio, mouth, 3D face, and tri-module (audio-lip motion, correlation and depth) fusion EERs were 42.9%, 32%, 15%, and 7.3%, respectively, for biometric person authentication task. Crown copyright (C) 2008 Published by Elsevier B.V. All rights reserved.
C1 [Chetty, Girija; Wagner, Michael] Univ Canberra, Human Comp Commun Lab, Sch Informat Sci & Engn, Bruce, ACT 2601, Australia.
C3 University of Canberra
RP Chetty, G (corresponding author), Univ Canberra, Human Comp Commun Lab, Sch Informat Sci & Engn, LPO Box 340,Bldg 11, Bruce, ACT 2601, Australia.
EM girija.chetty@canberra.edu.au
RI CHETTY, Girija/C-2221-2008
OI CHETTY, Girija/0000-0001-6264-8644
CR [Anonymous], 2002, Discrete-Time Speech Signal Processing: Principles and Practice
   BASU S, 1999, Patent No. 6219640
   Ben-Yacoub S, 1999, IEEE T NEURAL NETWOR, V10, P1065, DOI 10.1109/72.788647
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   BRUNELLI R, 1995, IEEE T PATTERN ANAL, V17, P955, DOI 10.1109/34.464560
   Callan DE, 2003, NEUROREPORT, V14, P2213, DOI 10.1097/00001756-200312020-00016
   Chatzis V, 1999, IEEE T SYST MAN CY A, V29, P674, DOI 10.1109/3468.798073
   CHETTY G, INTERSPEECH 2007 C
   Chetty Girija., 2004, Proc. Image and Vision Computing, P17
   DUTAGACI H, 2006, P SPIE C EL IM SEC S
   GLOTIN H, 2001, P IEEE INT C AC SPEE
   Goecke R., 2005, Proc. of the International Conference on Auditory-Visual Speech Processing (AVSP), P109
   GOECKE R, 1989, P 8 INT C SPOK LANG, V3, P2525
   GOKBERK B, IMAGE VISIO IN PRESS
   Heckmann M, 2002, EURASIP J APPL SIG P, V2002, P1260, DOI 10.1155/S1110865702206150
   Kroos C, 2002, J PHONETICS, V30, P569, DOI 10.1006/jpho.2002.0164
   MEIER U, 1996, P IEEE INT C AC SPEE, V2, P833
   Mermelstein P., 1976, 1976 Joint Workshop on Pattern Recognition and Artificial Intelligence
   ORTEGAGARCIA J, 2003, IEE P VISP, V150
   Pan H, 2004, IEEE T SIGNAL PROCES, V52, P573, DOI 10.1109/TSP.2003.822353
   Pigeon S, 1998, SIGNAL PROCESS, V69, P59, DOI 10.1016/S0165-1684(98)00087-5
   Potamianos G, 2003, P IEEE, V91, P1306, DOI 10.1109/JPROC.2003.817150
   Santi A, 2003, J COGNITIVE NEUROSCI, V15, P800, DOI 10.1162/089892903322370726
   Tamura S, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL I, PROCEEDINGS, P857
   Tan B., 2006, Computer Vision and Pattern Recognition Workshop, P26, DOI DOI 10.1109/CVPRW.2006.120
   Wark T, 2001, DIGIT SIGNAL PROCESS, V11, P169, DOI 10.1006/dspr.2001.0397
   Wark TJ, 1999, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA COMPUTING AND SYSTEMS, PROCEEDINGS VOL 1, P812, DOI 10.1109/MMCS.1999.779305
   Yehia HC, 2002, J PHONETICS, V30, P555, DOI 10.1006/jpho.2002.0165
NR 28
TC 23
Z9 24
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2008
VL 26
IS 9
BP 1249
EP 1260
DI 10.1016/j.imavis.2008.02.009
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 325GF
UT WOS:000257576300007
DA 2024-07-18
ER

PT J
AU Vogiatzis, G
   Torr, PHS
   Seitz, SM
   Cipolla, R
AF Vogiatzis, George
   Torr, Philip H. S.
   Seitz, Steven M.
   Cipolla, Roberto
TI Reconstructing relief surfaces
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE stereo; multi-view; reconstruction; MRF; belief propagation; Volumetric;
   vision
AB This paper generalizes Markov Random Field (MRF) stereo methods to the generation Of Surface relief (height) fields rather than disparity or depth maps. This generalization enables the reconstruction of complete object models using the same algorithms that have been previously used to compute depth maps in binocular stereo. In contrast to traditional dense stereo where the parametrization is image based, here we advocate a parametrization by a height field over any base surface. In practice, the base surface is a coarse approximation to the true geometry, e.g., a bounding box, visual hull or triangulation of sparse correspondences, and is assigned or computed using other means. A dense set of sample points is defined on the base surface, each with a fixed normal direction and unknown height value. The estimation of heights for the sample points is achieved by a belief propagation technique. Our method provides a viewpoint independent smoothness constraint, a more compact parametrization and explicit handling of occlusions. We present experimental results on real scenes as well as a quantitative evaluation on an artificial scene. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Vogiatzis, George; Cipolla, Roberto] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
   [Torr, Philip H. S.] Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England.
   [Seitz, Steven M.] Univ Washington, Dept Comp Sci & Engn, Seattle, WA 98195 USA.
C3 University of Cambridge; Oxford Brookes University; University of
   Washington; University of Washington Seattle
RP Vogiatzis, G (corresponding author), Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
EM gv215@eng.cam.ac.uk; philiptorr@brookes.ac.uk; seitz@cs.washington.edu;
   cipolla@eng.cam.ac.uk
RI Ghanem, Bernard/J-7605-2017; Arandjelović, Ognjen/V-5255-2019
OI Arandjelović, Ognjen/0000-0002-9314-194X; Vogiatzis,
   George/0000-0002-3226-0603; Cipolla, Roberto/0000-0002-8999-2151
CR [Anonymous], 1999, ADV NEURAL INFORM PR
   Boykov Y, 1998, PROC CVPR IEEE, P648, DOI 10.1109/CVPR.1998.698673
   BOYKOV Y, 2001, FAST APPROXIMATE ENE, V23, P1222
   CIPOLLA R, 1993, ICCV, P374
   Cross Geoffrey., 2000, CONFLUENCE COMPUTER, P25
   Debevec P. E., 1996, Computer Graphics Proceedings. SIGGRAPH '96, P11, DOI 10.1145/237170.237191
   Faugeras O, 1998, IEEE T IMAGE PROCESS, V7, P336, DOI 10.1109/83.661183
   FELZENSZWALB PF, IN PRESS P CVPR 2004
   FUA P, 1995, INT J COMPUT VISION, V16, P35, DOI 10.1007/BF01428192
   GEIGER D, P CVPR 1998, P125
   HAILIN J, CVPR 2003, V1, P171
   Hoppe H., 1993, Computer Graphics Proceedings, P19, DOI 10.1145/166117.166119
   Isidoro J, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1335
   Kolmogorov V, 2002, LECT NOTES COMPUT SC, V2352, P82
   Kutulakos KN, 2000, INT J COMPUT VISION, V38, P199, DOI 10.1023/A:1008191222954
   LEE A, COMPUTER GRAPHICS P, P85
   Narayanan PJ, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P3, DOI 10.1109/ICCV.1998.710694
   PARIS S, 2004, P AS C COMP VIS JAN
   ROY IJ, P ICCV 1998, P735
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shade J., 1998, Computer Graphics. Proceedings. SIGGRAPH 98 Conference Proceedings, P231, DOI 10.1145/280814.280882
   Strecha C, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P1194
   Sun J, 2002, LECT NOTES COMPUT SC, V2351, P510
   TAPPEN FM, ICCV 2003, V2, P900
   ZHANG L, 2001, P SOC PHOTO-OPT INS, P51
NR 25
TC 10
Z9 25
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 397
EP 404
DI 10.1016/j.imavis.2007.01.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500008
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Chao, SM
   Tsai, DM
AF Chao, Shin-Min
   Tsai, Du-Ming
TI An anisotropic diffusion-based defect detection for low-contrast glass
   substrates
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE defect detection; surface inspection; anisotropic diffusion;
   low-contrast images; glass substrates
ID EDGE-DETECTION; ENHANCEMENT; SYSTEM
AB In this paper, we propose an anisotropic diffusion scheme to detect defects in low-contrast surface images and, especially, aim at glass substrates used in TFT-LCDs (Thin Film Transistor-Liquid Crystal Displays). In a sensed image of glass substrate, the gray levels of defects and background are hardly distinguishable and result in a low-contrast image. Therefore, thresholding and edge detection techniques cannot be applied to detect subtle defects in the glass substrates surface. Although the traditional diffusion model can effectively smooth noise and irregularity of a faultless background in an image, it can only passively stop the diffusion process to preserve the original low-contrast gray values of defect edges. The proposed diffusion method in this paper can simultaneously carry out the smoothing and sharpening operations so that a simple thresholding can be used to segment the intensified defects in the resulting image. The method adaptively triggers the smoothing process in faultless areas to make the background uniform, and performs the sharpening process in defective areas to enhance anomalies. Experimental results from a number of glass substrate samples including backlight panels and LCD glass substrates have shown the efficacy of the proposed diffusion scheme in low-contrast surface inspection. (c) 2007 Elsevier B.V. All rights reserved.
C1 [Chao, Shin-Min; Tsai, Du-Ming] Yuan Ze Univ, Dept Ind Engn & Management, Tao Yuan, Taiwan.
C3 Yuan Ze University
RP Tsai, DM (corresponding author), Yuan Ze Univ, Dept Ind Engn & Management, 135 Yuan Tung Rd, Tao Yuan, Taiwan.
EM iedmtsai@saturn.yzu.edu.tw
CR ALVAREZ L, 1992, SIAM J NUMER ANAL, V29, P845, DOI 10.1137/0729052
   Bakalexis SA, 2002, DSP 2002: 14TH INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING PROCEEDINGS, VOLS 1 AND 2, P1203, DOI 10.1109/ICDSP.2002.1028309
   Barash D, 2002, IEEE T PATTERN ANAL, V24, P844, DOI 10.1109/TPAMI.2002.1008390
   Brzakovic D, 1996, PATTERN RECOGN, V29, P1401, DOI 10.1016/0031-3203(95)00166-2
   Chen Y, 2001, COMPUT VIS IMAGE UND, V82, P85, DOI 10.1006/cviu.2001.0903
   Deng H., 2000, INT S MULT INF PROC, P62
   FERNANDEZ C, 1993, PROCEEDINGS OF THE IECON 93 - INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, AND INSTRUMENTATION, VOLS 1-3, P1854, DOI 10.1109/IECON.1993.339356
   Gilboa G, 2002, IEEE T IMAGE PROCESS, V11, P689, DOI 10.1109/TIP.2002.800883
   Lee JY, 2004, IEICE T INF SYST, VE87D, P2371
   NGAN YT, 2003, P 32 APPL IM PATT RE, P163
   Niessen WJ, 1997, COMPUT VIS IMAGE UND, V66, P233, DOI 10.1006/cviu.1997.0614
   OLSSON J, 1992, PROCEEDINGS OF THE 1992 INTERNATIONAL CONFERENCE ON INDUSTRIAL ELECTRONICS, CONTROL, INSTRUMENTATION, AND AUTOMATION, VOLS 1-3, P1443, DOI 10.1109/IECON.1992.254389
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   Sapiro G, 1996, IEEE T IMAGE PROCESS, V5, P1582, DOI 10.1109/83.541429
   Solé AF, 2001, COMPUT VIS IMAGE UND, V84, P241, DOI 10.1006/cviu.2001.0945
   Tomasi C, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P839, DOI 10.1109/ICCV.1998.710815
   TorkamaniAzar F, 1996, IEEE T IMAGE PROCESS, V5, P1573, DOI 10.1109/83.541427
   Tsuji H, 2002, IEEE IMAGE PROC, P85
   Wilder J, 1989, MACHINE VISION INSPE, P237
   You YL, 1996, IEEE T IMAGE PROCESS, V5, P1539, DOI 10.1109/83.541424
NR 20
TC 51
Z9 58
U1 2
U2 34
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2008
VL 26
IS 2
BP 187
EP 200
DI 10.1016/j.imavis.2007.03.003
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 244EQ
UT WOS:000251849500004
DA 2024-07-18
ER

PT J
AU Jin, XY
   Davis, CH
AF Jin, Xiaoying
   Davis, Curt H.
TI Vehicle detection from high-resolution satellite imagery using
   morphological shared-weight neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE vehicle detection; high-resolution satellite imagery; neural networks;
   feature extraction; IKONOS
ID SCALE-SPACE
AB High-resolution satellite imagery has recently become a new data source for extraction of small-scale objects such as vehicles. Very little vehicle detection research has been done using high-resolution satellite imagery where panchromatic band resolutions are presently in the range of 0.6-1.0 m. Given the limited spatial resolution, reliable vehicle detection can only be achieved by incorporating contextual information. Here, a GIs road vector map is used to constrain a vehicle detection system to road networks. We used a morphological shared-weight neural network (MSNN) to learn an implicit vehicle model and classify pixels into vehicles and non-vehicles. A vehicle image base library was built by collecting more than 300 cars manually from test images. Strategies to reduce the false alarms and select target centroids were designed. Experimental results indicate that the MSNN performed very well. The detection rate on both training and validation sites exceeded 85% with very few false alarms. By learning the implicit vehicle model through a MSNN, our method outperforms a baseline blob detection method. (C) 2007 Elsevier B.V. All rights reserved.
C1 Univ Missouri, Dept Elect & Comp Engn, Columbia, MO 65211 USA.
C3 University of Missouri System; University of Missouri Columbia
RP Davis, CH (corresponding author), Univ Missouri, Dept Elect & Comp Engn, Columbia, MO 65211 USA.
EM jinxy65201@yahoo.com; DavisCH@missouri.edu
CR Burlina P., 1995, IEEE WORKSH CONT BAS, P38
   BURLINA P, 1997, 1997 IM UND WORKSH P, P577
   DOUGHERTY ER, 1992, INTRO MORPHOLOGICAL
   Haykin S., 1998, NEURAL NETWORKS COMP
   Hinz S, 2005, INT GEOSCI REMOTE SE, P2937
   JIN X, 2004, P SOC PHOTO-OPT INS, P137
   JIN X, 2005, INFORM FUSION, V6, P257, DOI DOI 10.1016/J.INFFUS.2004.06.003
   Jin XY, 2005, EURASIP J APPL SIG P, V2005, P2196, DOI 10.1155/ASP.2005.2196
   Khabou MA, 2000, MACH VISION APPL, V11, P300, DOI 10.1007/s001380050114
   Khabou MA, 1999, OPT ENG, V38, P263, DOI 10.1117/1.602085
   LIN CL, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P694, DOI 10.1109/CVPR.1994.323776
   LINDEBERG T, 1993, INT J COMPUT VISION, V11, P283, DOI 10.1007/BF01469346
   Lindeberg T, 1998, INT J COMPUT VISION, V30, P79, DOI 10.1023/A:1008045108935
   Lindeberg T, 1996, CERN REPORT, V96, P27
   Liu G, 2000, INT C PATT RECOG, P342, DOI 10.1109/ICPR.2000.905348
   Michaelsen E, 2001, IEEE/ISPRS JOINT WORKSHOP ON REMOTE SENSING AND DATA FUSION OVER URBAN AREAS, P25, DOI 10.1109/DFUA.2001.985719
   Moon H, 2002, IMAGE VISION COMPUT, V20, P1, DOI 10.1016/S0262-8856(01)00059-2
   Papageorgiou C, 2000, INT J COMPUT VISION, V38, P15, DOI 10.1023/A:1008162616689
   Ruskone R., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P900, DOI 10.1109/ICPR.1996.547298
   Schlosser C, 2003, 2ND GRSS/ISPRS JOINT WORKSHOP ON REMOTE SENSING AND DATA FUSION OVER URBAN AREAS, P167, DOI 10.1109/DFUA.2003.1219980
   SHARMA G, 2002, THESIS OHIO STATE U
   WON Y, 1995, THESIS U MISSOURI CO
   Won YG, 1997, IEEE T NEURAL NETWOR, V8, P1195, DOI 10.1109/72.623220
   Zhao T, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P710, DOI 10.1109/ICCV.2001.937593
NR 24
TC 66
Z9 83
U1 0
U2 33
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1422
EP 1431
DI 10.1016/j.imavis.2006.12.011
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000005
DA 2024-07-18
ER

PT J
AU Kalmoun, EM
   Köstler, H
   Rüde, U
AF Kalmoun, El Mostafa
   Kostler, Harald
   Rude, Ulrich
TI 3D optical flow computation using a parallel variational multigrid
   scheme with application to cardiac C-arm CT motion
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D optical flow; Horn-Schunck model; multigrid; Galerkin coarsening;
   parallelization; cardiac C-arm CT motion
ID ALGORITHMS; FRAMEWORK; FIELDS
AB Motivated by recent applications to 3D medical motion estimation, we consider the problem of 3D optical flow computation in real time. The 3D optical flow model is derived from a straightforward extension of the 2D Horn-Schunck model and discretized using standard finite differences. We compare memory costs and convergence rates of four numerical schemes: Gauss-Seidel and multigrid with three different strategies of coarse grid operators discretization: direct coarsening, lumping and Galerkin approaches. Experimental results to compute 3D motion from cardiac C-arm CT images demonstrate that our variational multi-grid based on Galerkin discretization outperforms significantly the Gauss-Seidel method. The parallel implementation of the proposed scheme using domain partitioning shows that the algorithm scales well up to 32 processors on a cluster of AMD Opteron CPUs which consists of four-way nodes connected by an Infiniband network. (C) 2007 Published by Elsevier B.V.
C1 Univ Cadi Ayyad, Ecole Natl Sci Appl, Marrakech 40000, Morocco.
   Univ Erlangen Nurnberg, Dept Comp Sci 10, Erlangen, Germany.
C3 Cadi Ayyad University of Marrakech; University of Erlangen Nuremberg
RP Kalmoun, EM (corresponding author), Univ Cadi Ayyad, Ecole Natl Sci Appl, BP 575,Ave Abdelkarim Khatabi Gueliz, Marrakech 40000, Morocco.
EM kalmoun@ensa.ac.ma
RI Koestler, Harald/AAK-9385-2021; Kalmoun, El Mostafa/Q-1321-2015
OI Koestler, Harald/0000-0002-6992-2690; Kalmoun, El
   Mostafa/0000-0002-1434-2541; Ruede, Ulrich/0000-0001-8796-8599
CR ANANDAN P, 1989, INT J COMPUT VISION, V2, P283, DOI 10.1007/BF00158167
   [Anonymous], THESIS SAARLAND U SA
   [Anonymous], 1985, Multi-grid methods and applications
   [Anonymous], 1992, An Introduction to Multigrid Methods
   BATTITI R, 1991, INT J COMPUT VISION, V6, P133, DOI 10.1007/BF00128153
   Beauchemin SS, 1995, ACM COMPUT SURV, V27, P433, DOI 10.1145/212094.212141
   BRANDT A, 1977, MATH COMPUT, V31, P333, DOI 10.1090/S0025-5718-1977-0431719-X
   BRANDT A, 1984, GND STUDIEN, V85
   Bruhn A, 2005, IEEE T IMAGE PROCESS, V14, P608, DOI 10.1109/TIP.2005.846018
   Ciarlet P., 1978, The Finite Element Method for Elliptic Problems
   Cohen I, 1999, INT J COMPUT VISION, V33, P29, DOI 10.1023/A:1008161130332
   DOPICO A, 2004, LECT NOTES COMPUTER, P397
   ENKELMANN W, 1988, COMPUT VISION GRAPH, V43, P150, DOI 10.1016/0734-189X(88)90059-X
   Fleury M, 2001, IMAGE VISION COMPUT, V19, P131, DOI 10.1016/S0262-8856(00)00061-5
   FORMAGGIA L, 2005, LECT NOTES COMPUTATI, V51, P165
   Ghosal S, 1996, IEEE T PATTERN ANAL, V18, P181, DOI 10.1109/34.481542
   GLAZER F, 1984, MULTIRESOLUTION IMAG, P312
   Gropp W., 1999, USING MPI 2
   Hata N, 2000, J COMPUT ASSIST TOMO, V24, P531, DOI 10.1097/00004728-200007000-00004
   HIILSEMANN F, 2005, LECT NOTES COMPUTATI, V51, P165
   HOLZEL A, 2002, THESIS FACH HOCHSCHU
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Hughes TJR., 1987, FINITE ELEMENT METHO
   Kalmoun EM, 2003, VISION, MODELING, AND VISUALIZATION 2003, P577
   KLEIN GJ, 1997, P 1997 IEEE WORKSH M
   Kohlberger T, 2003, LECT NOTES COMPUT SC, V2781, P196
   Lauritsch G, 2006, IEEE T MED IMAGING, V25, P922, DOI 10.1109/TMI.2006.876166
   LIORANTE IM, 1997, IEEE T PARALL DISTR, V8, P562
   Lotzbeyer H, 1997, BIT, V37, P739, DOI 10.1007/BF02510250
   Lucas B. D., 1981, 7 INT JOINT C ART IN, V81, P674
   Nagel H.-H., 1983, P IJCAI, P945
   Negahdaripour S, 1998, IEEE T PATTERN ANAL, V20, P961, DOI 10.1109/34.713362
   ODOBEZ JM, 1995, J VIS COMMUN IMAGE R, V6, P348, DOI 10.1006/jvci.1995.1029
   RIGGS WL, 2000, MULTIGRID TUTORIAL
   Ruge J.W., 1987, Multigrid Methods, P73, DOI DOI 10.1007/S10444-014-9395-7
   SMITH B. F., 1996, DOMAIN DECOMPOSITION
   SONG SM, 1991, IEEE T MED IMAGING, V10, P295, DOI 10.1109/42.97579
   Szeliski R, 1996, IEEE T PATTERN ANAL, V18, P1199, DOI 10.1109/34.546257
   TERZOPOULOS D, 1986, IEEE T PATTERN ANAL, V8, P129, DOI 10.1109/TPAMI.1986.4767767
   Tikhonov A., 1977, Solution of Ill-Posed Problems
   Trottenberg U, 2000, Multigrid
   Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973
   Yang H, 2005, CRYOBIOLOGY, V51, P165, DOI 10.1016/j.cryobiol.2005.06.003
   Zini G, 1997, IEEE T ULTRASON FERR, V44, P297, DOI 10.1109/58.585114
NR 44
TC 17
Z9 20
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2007
VL 25
IS 9
BP 1482
EP 1494
DI 10.1016/j.imavis.2006.12.017
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 190OH
UT WOS:000248068000009
DA 2024-07-18
ER

PT J
AU Amador, JJ
AF Amador, Jose J.
TI Random projection and orthonormality for lossy image compression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE image compression; random projection; transform image coding
ID DISCRETE SINE
AB There exist many lossy image compression techniques, some of which are based on dimensionality reduction. In this paper, a method for lossy image compression is introduced which utilizes the dimensionality reduction technique known as Random Projection. Random Projection has proven itself as an effective technique for reducing the dimensionality of data, particularly when dimensionality d is moderately high (e.g., d < 1500). Image columns or rows are treated as vectors in feature space which are thereby reduced in size to a user specified dimension k where k < d. The condition of orthonormality is utilized thereby establishing a technique applicable to image compression. Although the compression is lossy, experiments indicate that the recovered image is effectively restored. Visual data is shown in the form of comparison between original and recovered image. Quantitative data includes the compression ratio achieved, the peak signal-to-noise ratio, and the root mean square error. Published by Elsevier B.V.
C1 NASA, John F Kennedy Space Ctr, Kennedy Space Ctr, FL 32899 USA.
C3 National Aeronautics & Space Administration (NASA); Kennedy Space Center
RP Amador, JJ (corresponding author), NASA, John F Kennedy Space Ctr, Kennedy Space Ctr, FL 32899 USA.
EM Jose.J.Amador@nasa.gov
CR Achlioptas D., 2001, P 20 ACM SIGMOD SIGA, P274, DOI [DOI 10.1145/375551.375608, 10.1145/375551.375608]
   AGRAWAL M, 2002, PRIMES P
   ANGUH MM, 1995, IEEE T COMMUN, V43, P2103, DOI 10.1109/26.387451
   [Anonymous], 1994, Computational Intelligence, chapter Context Vectors: General Purpose Approximate Meaning Representations Self-Organized from Raw Data
   [Anonymous], 2001, P 7 ACM SIGKDD INT C
   Arriaga R., 1999, PROC 40 IEEE FOCS, P616
   BRACEWELL RN, 1983, J OPT SOC AM, V73, P1832, DOI 10.1364/JOSA.73.001832
   Castleman K. R., 1996, Digital Image Processing
   Chen H, 2002, INT GEOSCI REMOTE SE, P1431, DOI 10.1109/IGARSS.2002.1026139
   Choi E, 2005, INT GEOSCI REMOTE SE, P704
   Cormen T.H., 1997, Introduction to Algorithms
   Crowley J. L., 1999, Proceedings International Workshop on Recognition, Analysis, and Tracking of Faces and Gestures in Real-Time Systems. In Conjunction with ICCV'99 (Cat. No.PR00378), P2, DOI 10.1109/RATFG.1999.799216
   DASGUPTA S, 2000, P UNC ART INT
   Dasgupta S., 1999, Rep. TR-99-006
   DAUBECHIES I, 1988, COMMUN PUR APPL MATH, V41, P909, DOI 10.1002/cpa.3160410705
   FALKOWSKI BJ, 1994, PROCEEDINGS OF THE 37TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1 AND 2, P825, DOI 10.1109/MWSCAS.1994.518941
   FRANKL P, 1988, J COMB THEORY B, V44, P355, DOI 10.1016/0095-8956(88)90043-3
   GARG A, 2002, P 19 INT C MACH LEAR
   Hacihaliloglu I, 2004, IEEE ANTENNAS AND PROPAGATION SOCIETY SYMPOSIUM, VOLS 1-4 2004, DIGEST, P3856, DOI 10.1109/APS.2004.1330190
   Hartley R.V., 1942, Proc. IRE, V30, P144, DOI 10.1109/JRPROC.1942.234333
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   Johnson W.B., 1984, CONTEMP MATH-SINGAP, V26, P189, DOI DOI 10.1090/CONM/026/737400
   Kaiser G., 1998, IEEE Potentials, V17, P34, DOI 10.1109/45.666645
   KASKI S, 1998, P INT JOINT C NEUR N, P413
   Kolda TG, 1998, ACM T INFORM SYST, V16, P322, DOI 10.1145/291128.291131
   MARTUCCI SA, 1994, IEEE T SIGNAL PROCES, V42, P1038, DOI 10.1109/78.295213
   Nacer FZN, 2001, ISSPA 2001: SIXTH INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS, VOLS 1 AND 2, PROCEEDINGS, P545, DOI 10.1109/ISSPA.2001.950201
   NARASIMHA MJ, 1978, IEEE T COMMUN, V26, P934, DOI 10.1109/TCOM.1978.1094144
   Noble B., 1988, APPL LINEAR ALGEBRA
   Press W. H., 1999, NUMERICAL RECIPES C
   Rabbani M., 1991, DIGITAL IMAGE COMPRE
   SAITO N, 2004, POLYHARMONIC LOCAL S
   Sonka M., 2014, Image processing, analysis, and machine vision
   SORENSEN HV, 1985, IEEE T ACOUST SPEECH, V33, P1231, DOI 10.1109/TASSP.1985.1164687
   Tian M, 2005, Proceedings of 2005 International Conference on Machine Learning and Cybernetics, Vols 1-9, P5200
   VEMPALA SS, 2002, RANDOM PROJECTION
   WALDERMAR P, 1997, P IEEE INT C AC SPEE, P2713
   Wu YG, 2001, IEEE T INF TECHNOL B, V5, P236, DOI 10.1109/4233.945294
   YIP P, 1980, IEEE T COMMUN, V28, P304, DOI 10.1109/TCOM.1980.1094656
   Zyto S, 2002, IEEE DATA COMPR CONF, P484, DOI 10.1109/DCC.2002.1000027
NR 40
TC 13
Z9 17
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 754
EP 766
DI 10.1016/j.imavis.2006.05.018
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200020
DA 2024-07-18
ER

PT J
AU Phimoltares, S
   Lursinsap, C
   Chamnongthai, K
AF Phimoltares, S.
   Lursinsap, C.
   Chamnongthai, K.
TI Face detection and facial feature localization without considering the
   appearance of image context
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE face detection; face location; facial feature detection; neural visual
   model; pattern recognition
ID ROBUST; COLOR; SEGMENTATION; EXTRACTION
AB Face and facial feature detection plays an important role in various applications such as human computer interaction, video surveillance, face tracking, and face recognition. Efficient face and facial feature detection algorithms are required for applying to those tasks. This paper presents the algorithms for all types of face images in the presence of several image conditions. There are two main stages. In the first stage, the faces are detected from an original image by using Canny edge detection and our proposed average face templates. Second, a proposed neural visual model (NVM) is used to recognize all possibilities of facial feature positions. Input parameters are obtained from the positions of facial features and the face characteristics that are low sensitive to intensity change. Finally, to improve the results, image dilation is applied for removing some irrelevant regions. Additionally, the algorithms can be extended to rotational invariance problem by using Radon transformation to extract the main angle of the face. With more than 1000 images, the algorithms are successfully tested with various types of faces affected by intensity, occlusion, structural components, facial expression, illumination, noise, and orientation. (c) 2006 Elsevier B.V. All rights reserved.
C1 Chulalongkorn Univ, Dept Math, AVIC, Bangkok 10330, Thailand.
   King Mongkuts Univ Technol Thonburi, Dept Elect & Telecommun Engn, Bangor 10140, Gwynedd, Wales.
C3 Chulalongkorn University
RP Phimoltares, S (corresponding author), Chulalongkorn Univ, Dept Math, AVIC, 254 Phyathai Rd, Bangkok 10330, Thailand.
EM Suphakant.P@Student.chula.ac.th; lchidcha@chula.ac.th;
   kosin.cha@kmutt.ac.th
RI Chamnongthai, Kosin/AEX-9479-2022
OI Chamnongthai, Kosin/0000-0003-1509-5754
CR Anderson K, 2004, COMPUT VIS IMAGE UND, V95, P184, DOI 10.1016/j.cviu.2004.01.001
   Blanz Volker., 1999, P 26 ANN C COMPUTER, P187, DOI DOI 10.1145/311535.311556
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Fleuret F, 2001, INT J COMPUT VISION, V41, P85, DOI 10.1023/A:1011113216584
   Gonzalez R. C., 2007, DIGITAL IMAGE PROCES
   Hsu RL, 2002, IEEE T PATTERN ANAL, V24, P696, DOI 10.1109/34.1000242
   Huang LL, 2003, PATTERN RECOGN, V36, P2501, DOI 10.1016/S0031-3203(03)00130-4
   Li YM, 2004, IMAGE VISION COMPUT, V22, P413, DOI 10.1016/j.imavis.2003.12.005
   Liévin M, 2004, IEEE T IMAGE PROCESS, V13, P63, DOI 10.1109/TIP.2003.818013
   Liu CJ, 2003, IEEE T PATTERN ANAL, V25, P725, DOI 10.1109/TPAMI.2003.1201822
   Liu Z, 2005, SIGNAL PROCESS-IMAGE, V20, P295, DOI 10.1016/j.image.2004.12.005
   Loutas E, 2004, IEEE T CIRC SYST VID, V14, P128, DOI 10.1109/TCSVT.2003.819178
   Martinez A., 1998, AR FACE DATABASE
   Ng J, 2002, IMAGE VISION COMPUT, V20, P359, DOI 10.1016/S0262-8856(02)00008-2
   Phimoltares S, 2002, 2002 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-4, PROCEEDINGS, P1914, DOI 10.1109/ICMLC.2002.1175371
   PHIMOLTARES S, 2002, P 3 INT C INT TECHN, P226
   PHIMOLTARES S, 2003, P IEEE INT S CIRC SY
   Prechelt L, 1998, NEURAL NETWORKS, V11, P761, DOI 10.1016/S0893-6080(98)00010-0
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Schneiderman H, 2000, PROC CVPR IEEE, P746, DOI 10.1109/CVPR.2000.855895
   Shih FY, 2004, INFORM SCIENCES, V158, P117, DOI 10.1016/j.ins.2003.03.002
   Soriano M, 2003, PATTERN RECOGN, V36, P681, DOI 10.1016/S0031-3203(02)00089-4
   Spors S, 2001, INT CONF ACOUST SPEE, P1493, DOI 10.1109/ICASSP.2001.941214
   Tsalakanidou F, 2005, IEEE T IMAGE PROCESS, V14, P152, DOI 10.1109/TIP.2004.840714
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Xiao R, 2004, IEEE T CIRC SYST VID, V14, P31, DOI 10.1109/TCSVT.2003.818351
   Yang MH, 2002, IEEE T PATTERN ANAL, V24, P34, DOI 10.1109/34.982883
   Zhang SC, 2005, PATTERN RECOGN, V38, P273, DOI 10.1016/j.patcog.2004.03.014
NR 28
TC 25
Z9 33
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2007
VL 25
IS 5
BP 741
EP 753
DI 10.1016/j.imavis.2006.05.017
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 149SF
UT WOS:000245166200019
DA 2024-07-18
ER

PT J
AU Motamed, C
AF Motamed, Cina
TI Motion detection and tracking using belief indicators for an automatic
   visual-surveillance system
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Workshop on Performance Evaluation of Tracking and Surveillance (PETS)
CY DEC09, 2001
CL Kauai, HI
SP IEEE
DE video-surveillance; motion detection; tracking; belief indicator; belief
   updating; uncertainty management
AB A motion detection and tracking algorithm for human and car activity surveillance is presented and evaluated by using the Pets' 2000 test sequence. The proposed approach uses a temporal fusion strategy by using the history of events in order to improve instantaneous decisions. Normalized indicators updated at each frame summarize the history of specific events. For the motion detection stage, a fast updating algorithm of the background reference is proposed. The control of the updating at each pixel is based on a stability indicator estimated from inter-frame variations. The tracking algorithm uses a region-based approach. A belief indicator representing the tracking consistency for each object allows solving defined ambiguities at the tracking level. A second specific tracking indicator representing the identity quality of each tracked object is updated by integrating object interaction. Tracking indicators permit to propagate uncertainties on higher levels of the interpretation and are directly useful in the tracking performance evaluation. (c) 2005 Elsevier B.V. All rights reserved.
C1 Univ Littoral Cote dOpale, Lab LASL, F-62228 Calais, France.
C3 Universite du Littoral-Cote-d'Opale
RP Motamed, C (corresponding author), Univ Littoral Cote dOpale, Lab LASL, 50 RF Buissson Bat B, F-62228 Calais, France.
EM motamed@lasl.univ-littoral.fr
CR Aggarwal JK, 1998, COMPUT VIS IMAGE UND, V70, P142, DOI 10.1006/cviu.1997.0620
   Bar-Shalom Y., 1988, MATH SCI ENG, V179
   Betke M, 1996, PROCEEDINGS OF THE 1996 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P351, DOI 10.1109/IVS.1996.566405
   BOBICK A, 1997, P WORKSH KNOWL BAS V
   BREMOND F, 1996, KP WORKSH CONC DESCR
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   DAVIS JW, 1997, P COMPUTER VISION PA
   DUBOIS D, 1994, CONTROL ENG PRACT, V2, P811, DOI 10.1016/0967-0661(94)90346-8
   ELGAMMAL A, 2000, 6 EUR C COMP VIS
   Ferryman JM, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P127
   FORESTI GL, 1994, IEEE INT C IND EL IE
   Isard M., 1996, Proceedings of the European Conference on Computer Vision (ECCV), P343
   KARMAN KP, 1990, TIME VARYING IMAGE P
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   KOLLNIG H, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P569, DOI 10.1109/ICCV.1995.466888
   Liu SC, 1998, IEEE T IMAGE PROCESS, V7, P1258, DOI 10.1109/83.709658
   McKenna SJ, 2000, COMPUT VIS IMAGE UND, V80, P42, DOI 10.1006/cviu.2000.0870
   MEYER FG, 1994, CVGIP-IMAG UNDERSTAN, V60, P119, DOI 10.1006/ciun.1994.1042
   MOTAMED C, 2000, VID IND BAS OBJ MOT, P586
   NGUYEN HT, 2001, P INT C COM VIS
   Paragios N, 2000, IEEE T PATTERN ANAL, V22, P266, DOI 10.1109/34.841758
   PIATER J, 2001, MULTI MODAL TRACKING
   POLANA P, 1994, P IEEE CS WORKSH MOT, P77
   RANGARAJAN K, 1991, CVGIP-IMAG UNDERSTAN, V54, P56, DOI 10.1016/1049-9660(91)90075-Z
   REID DB, 1979, IEEE T AUTOMAT CONTR, V24, P843, DOI 10.1109/TAC.1979.1102177
   SETHI IK, 1987, IEEE T PATTERN ANAL, V9, P56, DOI 10.1109/TPAMI.1987.4767872
   Stauffer C., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P246, DOI 10.1109/CVPR.1999.784637
   Veenman CJ, 2001, IEEE T PATTERN ANAL, V23, P54, DOI 10.1109/34.899946
   Wang LA, 2003, PATTERN RECOGN, V36, P585, DOI 10.1016/S0031-3203(02)00100-0
   WREN CR, 2000, P INT C AUT FAC GEST
NR 31
TC 12
Z9 18
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2006
VL 24
IS 11
BP 1192
EP 1201
DI 10.1016/j.imavis.2005.06.005
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 101CJ
UT WOS:000241716200005
DA 2024-07-18
ER

PT J
AU Yu, YH
   Chang, CC
AF Yu, Yuan-Hui
   Chang, Chin-Chen
TI A new edge detection approach based on image context analysis
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE edge detection; predictive error value; GAP; image context analysis
ID COLOR IMAGES
AB A new adaptive edge detection approach based on image context analysis is presented in this paper. The proposed approach uses the information from predictive error values produced by the GAP predictor to detect edges. The experimental results indicate that both the visual evaluations and objective performance evaluations of the detected image in the proposed approach are superior to the edge detection of Sobel, Canny and the scheme presented by Tsai et al. [P. Tsai, C.C. Chang, Y.C. Hu, An adaptive two-stage edge detection scheme for digital color images, Real-Time Imaging 8 (4) (2002) 329-343]. To meet the needs of users, the flexibility in the threshold selection in the proposed approach is the same as that of the edge detection scheme [P. Tsai, C.C. Chang, Y.C. Hu, An adaptive two-stage edge detection scheme for digital color images, Real-Time Imaging 8 (4) (2002) 329-343]. The proposed approach, which is far more accurate than the detection scheme in [P. Tsai, C.C. Chang, Y.C. Hu, An adaptive two-stage edge detection scheme for digital color images, Real-Time Imaging 8 (4) (2002) 329-343], can precisely locate object contours in the image, especially for complex scenes. This feature, which the edge detection scheme [P. Tsai, C.C. Chang, Y.C. Hu, An adaptive two-stage edge detection scheme for digital color images, Real-Time Imaging 8 (4) (2002) 329-343] lacks, is of extreme importance to some applications such as data hiding, watermarking, morph, and pattern recognition. In addition, the approach can be integrated into a prediction-based lossless image compression scheme to provide both the lossless compression codes and edge maps of objects, which facilitate the image transmission and objects recognition for medical diagnoses and other applications. (c) 2006 Elsevier B.V. All rights reserved.
C1 Feng Chia Univ, Dept Comp Sci & Informat Engn, Taichung 40724, Taiwan.
   So Taiwan Univ Technol, Dept Multimedia & Game Sci, Tainan 710, Taiwan.
C3 Feng Chia University; Southern Taiwan University of Science & Technology
RP Chang, CC (corresponding author), Feng Chia Univ, Dept Comp Sci & Informat Engn, 100 Wenhwa Rd, Taichung 40724, Taiwan.
EM yhyu@mail.stut.edu.tw; ccc@cs.ccu.edu.tw
RI Chang, Ching-Chun/JAN-6210-2023
CR [Anonymous], INT J PATTERN RECOGN
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cheng SC, 2003, IMAGE VISION COMPUT, V21, P809, DOI 10.1016/S0262-8856(03)00095-7
   Heath M, 1998, COMPUT VIS IMAGE UND, V69, P38, DOI 10.1006/cviu.1997.0587
   Hou ZJ, 2002, PATTERN RECOGN, V35, P1559, DOI 10.1016/S0031-3203(01)00147-9
   LEMA MD, 1984, IEEE T COMMUN, V32, P1148, DOI 10.1109/TCOM.1984.1095973
   Li X, 2001, IEEE T IMAGE PROCESS, V10, P813, DOI 10.1109/83.923277
   Pratt W.K, 1978, DIGITAL IMAGE PROCES
   Sun JX, 2004, PATTERN RECOGN, V37, P1315, DOI 10.1016/j.patcog.2003.11.006
   Tsai P, 2002, REAL-TIME IMAGING, V8, P329, DOI 10.1006/rtim.2001.0286
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   Wei GW, 2002, EUROPHYS LETT, V59, P814, DOI 10.1209/epl/i2002-00115-8
   Wongthanavasu S, 2003, J VIS COMMUN IMAGE R, V14, P83, DOI 10.1016/S1047-3203(03)00022-1
   Wu XL, 1997, IEEE T COMMUN, V45, P437, DOI 10.1109/26.585919
   Yen T., 2003, THESIS NEW YORK U
   Zheng S, 2004, PATTERN RECOGN LETT, V25, P1143, DOI 10.1016/j.patrec.2004.03.009
NR 16
TC 27
Z9 35
U1 0
U2 6
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1090
EP 1102
DI 10.1016/j.imavis.2006.03.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300005
DA 2024-07-18
ER

PT J
AU Kopparapu, SK
AF Kopparapu, Sunil Kumar
TI Lighting design for machine vision application
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE lighting design; machine vision; optimal light placement; simulated
   annealing
ID AUTOMATIC SENSOR PLACEMENT
AB Low-level image processing is an essential first step in any machine vision application. Low-level vision processing tasks need good lighting in the work environment for them to function robustly. Hence, good and uniform illumination from external light source is essential for machine vision applications to function. In this paper, we suggest a design procedure to obtain uniform illumination on the scene being imaged using several light sources. We pose the problem of determining the optimal position of the light sources as a minimisation problem. Simulation results show the effectiveness and suitability of the proposed procedure to illuminate the scene uniformly. (c) 2006 Elsevier B.V. All rights reserved.
C1 Tata Consultancy Serv Ltd, Cognit Syst Res Lab, Bombay 400705, Maharashtra, India.
   CSIRO, Queensland Ctr Adv Technol, Kenmore, Qld 4069, Australia.
C3 Tata Sons; Tata Consultancy Services Limited (TCS); Commonwealth
   Scientific & Industrial Research Organisation (CSIRO)
RP Kopparapu, SK (corresponding author), Tata Consultancy Serv Ltd, Cognit Syst Res Lab, Plot 14,Sector 24, Bombay 400705, Maharashtra, India.
EM sunil.kopparapu@tcs.com
RI Kopparapu, Sunil Kumar/D-8160-2012
OI Kopparapu, Sunil Kumar/0000-0002-0502-527X
CR [Anonymous], 1989, Simulated annealing and Boltzmann machines: A stochastic approach to combinatorial optimization and neural computing
   CAMERON A, 1990, INT J ROBOT RES, V9, P70, DOI 10.1177/027836499000900505
   Cowan C. K., 1991, Workshop on Directions in Automated CAD-Based Vision. (Cat. No.91TH0377-2), P22, DOI 10.1109/CADVIS.1991.148754
   COWAN CK, 1992, P SOC PHOTO-OPT INS, V1826, P397, DOI 10.1117/12.131617
   COWAN CK, 1988, IEEE T PATTERN ANAL, V10, P407, DOI 10.1109/34.3905
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   HAGER GD, 1990, ADV SPATIAL REASONIN, V2, pCH4
   HAJEK B, 1989, MATH OPER RES, V134, P311
   Kopparapu S.K., 2001, Bayesian Approach to Image interpretation
   LI S, 1995, COMPUTER VISION IMAG, V61, P122
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   MASON SO, 1995, COMPUT VIS IMAGE UND, V61, P454, DOI 10.1006/cviu.1995.1034
   Mersch S., 1987, Proceedings of the SPIE - The International Society for Optical Engineering, V728, P36, DOI 10.1117/12.937821
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   SIECZKA EJ, 1991, P SOC PHOTO-OPT INS, V1614, P2
   ZHANG H, 1995, IEEE T SYST MAN CYB, V25, P781
NR 16
TC 51
Z9 64
U1 10
U2 77
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2006
VL 24
IS 7
BP 720
EP 726
DI 10.1016/j.imavis.2005.12.016
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 079ZC
UT WOS:000240215400007
DA 2024-07-18
ER

PT J
AU Habed, A
   Boufama, B
AF Habed, Adlane
   Boufama, Boubakeur
TI Camera self-calibration from bivariate polynomial equations and the
   coplanarity constraint
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE three-dimensional Euclidean reconstruction; camera self-calibration;
   modulus constraint
ID KRUPPAS EQUATIONS; AUTOCALIBRATION
AB This paper presents a new approach for self-calibrating a moving camera with constant intrinsic parameters. Unlike existing methods, the proposed method turns the self-calibration problem into one of solving bivariate polynomial equations. In particular, we show that each pair of images partially identifies a pair of 3D points that lie on the plane at infinity. These points are parameterized in terms of the real eigenvalue of the homography of the plane at infinity. A triplet of images identifies six such points on which the coplanarity constraint is enforced leading to a set of quintic and sextic polynomial equations. These equations are solved using a homotopy continuation method. More images allow to isolate the real eigenvalue associated with each motion and thus, to fully identify the points at infinity. The method also presents inequality conditions that allow to eliminate spurious solutions. Degenerate motions, not allowing the calculation of the eigenvalues, are also presented here. Once the 3D points at infinity are localized, both the plane at infinity and the Kruppa's coefficients can be linearly estimated. (C) 2006 Elsevier B.V. All rights reserved.
C1 Univ Windsor, Sch Comp Sci, Windsor, ON N9B 3P4, Canada.
C3 University of Windsor
RP Habed, A (corresponding author), Univ Windsor, Sch Comp Sci, 401 Sunset Ave, Windsor, ON N9B 3P4, Canada.
EM adlane@uwindsor.ca
CR Fusiello A, 2004, IEEE T PATTERN ANAL, V26, P1633, DOI 10.1109/TPAMI.2004.125
   FUSIELLO A, 2001, LECT NOTES COMPUTER, V2124, P717
   Habed A, 2004, INT C PATT RECOG, P116, DOI 10.1109/ICPR.2004.1333719
   HABED A, 2000, P 15 INT C PATT REC, V1, P1415
   Hartley R.I., 1993, Proc. DARPA Image Understanding Workshop, P745
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P133, DOI 10.1109/34.574792
   HEYDEN A, 1996, P 13 INT C PATT REC, V1, P339
   HUANG TS, 1989, IEEE T PATTERN ANAL, V11, P1310, DOI 10.1109/34.41368
   KAHL F, 1999, P C COMP VIS PATT RE, V2, P366
   LEI C, 2002, P 16 INT C PATT REC, V2, P308
   LOURAKIS MI, 2000, P AS C COMP VIS TAIP, V1, P403
   Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991
   MA Y, 2000, P 6 EUR C COMP VIS D, P561
   MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171
   MENDONCA P, 1999, P C COMP VIS PATT RE, V1, P500
   Pollefeys M, 1999, IEEE T PATTERN ANAL, V21, P707, DOI 10.1109/34.784285
   Pollefeys M., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P349, DOI 10.1109/ICPR.1996.546047
   Ronda JI, 2004, INT J COMPUT VISION, V57, P219, DOI 10.1023/B:VISI.0000013095.05991.55
   SCHAFFALITZKY F, 2000, P IND C COMP VIS GRA, P314
   Sturm P, 1997, PROC CVPR IEEE, P1100, DOI 10.1109/CVPR.1997.609467
   Sturm P, 2000, IEEE T PATTERN ANAL, V22, P1199, DOI 10.1109/34.879804
   Triggs B, 1997, PROC CVPR IEEE, P609, DOI 10.1109/CVPR.1997.609388
   UESHIBA T, 1998, P 5 ECCV, V1, P296
   VERSCHELDE J, 1994, SIAM J NUMER ANAL, V31, P915, DOI 10.1137/0731049
   VERSCHELDE J, 1993, ADA BELGIUM NEWSLETT, V2, P23
   VERSCHELDE J, 1996, ADA BELGIUM NEWSLETT, V4, P59
   VERSCHELDE J, 1993, 265 TW KATH U LEUV D
   VERSCHELDE J, 1995, THESIS KATHOLIEKE U
   Whitehead A., 2004, EURASIP J APPL SIGNA, V8
   ZELLER C, 1996, 2793 INR
NR 30
TC 8
Z9 10
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2006
VL 24
IS 5
BP 498
EP 514
DI 10.1016/j.imavis.2006.01.013
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 057WT
UT WOS:000238626600009
DA 2024-07-18
ER

PT J
AU Mor, E
   Aladjem, M
AF Mor, E
   Aladjem, M
TI Boundary refinements for wavelet-domain multiscale texture segmentation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE hidden Markov models; wavelets; boundary refinements; texture
   segmentation
AB We propose a method based on the Hidden Markov Tree (HMT) model for multiscale image segmentation in the wavelet domain. We use the inherent tree structure of the model to segment the image at a range of different scales. We then merge these different scale segmented images using boundary refinement conditions. The final segmented image utilizes the reliability of coarse scale segmented images and the fineness of finer scales segmented images. We demonstrate the performance of the algorithm on synthetic data and aerial photos. (C) 2005 Elsevier Ltd All rights reserved.
C1 Ben Gurion Univ Negev, Dept Elect & Comp Engn, IL-84105 Beer Sheva, Israel.
C3 Ben Gurion University
RP Ben Gurion Univ Negev, Dept Elect & Comp Engn, POB 653, IL-84105 Beer Sheva, Israel.
EM mor_etai@yahoo.com; aladjem@ee.bgu.ac.l
OI Aladjem, Mayer/0000-0003-3846-3417
CR [Anonymous], TOUR SIGNAL PROCESSI
   BOUMAN C, 1991, IEEE T PATTERN ANAL, V13, P99, DOI 10.1109/34.67641
   BOUMAN CA, 1994, IEEE T IMAGE PROCESS, V3, P162, DOI 10.1109/83.277898
   CHARLES F, 2000, INTRO SCI PROGRAMMIN, P289
   Cheng H, 2001, IEEE T IMAGE PROCESS, V10, P511, DOI 10.1109/83.913586
   Cheng H, 1998, 1998 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING - PROCEEDINGS, VOL 1, P610, DOI 10.1109/ICIP.1998.723575
   Chipman HA, 1997, J AM STAT ASSOC, V92, P1413, DOI 10.2307/2965411
   Choi H, 2001, IEEE T IMAGE PROCESS, V10, P1309, DOI 10.1109/83.941855
   Choi H, 1999, P SOC PHOTO-OPT INS, V3816, P306, DOI 10.1117/12.351325
   Crouse MS, 1998, IEEE T SIGNAL PROCES, V46, P886, DOI 10.1109/78.668544
   FAN G, P IEEE INT C IM P 20
   Fan GL, 2001, IEEE T GEOSCI REMOTE, V39, P2680, DOI 10.1109/36.975002
   FAN GL, 2001, P 35 AS C SIGN SYST
   HARALICK RM, 1985, COMPUT VISION GRAPH, V29, P100, DOI 10.1016/S0734-189X(85)90153-7
   MALLAT S, 1992, IEEE T PATTERN ANAL, V14, P710, DOI 10.1109/34.142909
   MALLAT S, 1992, IEEE T INFORM THEORY, V38, P617, DOI 10.1109/18.119727
   ORCHARD MT, 1994, DAT COMPR C 94 SNOWB, P341
   SHAPIRO J, 1998, IEEE T SIGNAL PROCES, V41, P3445
   Ten Daubechies I., 1992, lecture on wavelets
   Vetterli Martin, 1995, Wavelets and Subband Coding
NR 20
TC 11
Z9 14
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 29
PY 2005
VL 23
IS 13
BP 1150
EP 1158
DI 10.1016/j.imavis.2005.07.011
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 985MR
UT WOS:000233382500004
DA 2024-07-18
ER

PT J
AU Ekvall, S
   Kragic, D
   Hoffmann, F
AF Ekvall, S
   Kragic, D
   Hoffmann, F
TI Object recognition and pose estimation using color cooccurrence
   histograms and geometric modeling
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE object recognition; pose estimation; color cooccurrence histograms;
   model based tracking
ID TRACKING
AB Robust techniques for object recognition and pose estimation are essential for robotic manipulation and object grasping. In this paper, a novel approach for object recognition and pose estimation based on color cooccurrence histograms and geometric modelling is presented. The particular problems addressed are: (i) robust recognition of objects in natural scenes, (ii) estimation of partial pose using an appearance based approach, and (iii) complete 6DOF model based pose estimation and tracking using geometric models.
   Our recognition scheme is based on the color cooccurrence histograms embedded in a classical learning framework that facilitates a 'winner-takes-all' strategy across different views and scales. The hypotheses generated in the recognition stage provide the basis for estimating the orientation of the object around the vertical axis. This prior, incomplete pose information is subsequently made precise by a technique that facilitates a geometric model of the object to estimate and continuously track the complete 6DOF pose of the object.
   Major contributions of the proposed system are the ability to automatically initiate an object tracking process, its robustness and invariance towards scaling and translations as well as the computational efficiency since both recognition and pose estimation rely on the same representation of the object. The performance of the system is evaluated in a domestic environment with changing lighting and background conditions on a set of everyday objects. (c) 2005 Elsevier B.V. All rights reserved.
C1 Royal Inst Technol, Ctr Autonomous Syst, Stockholm, Sweden.
   Univ Dortmund, Dortmund, Germany.
C3 Royal Institute of Technology; Dortmund University of Technology
RP Royal Inst Technol, Ctr Autonomous Syst, Stockholm, Sweden.
EM ekvall@nada.kth.se; danik@nada.kth.se;
   hoffmann@esr.e-technik.uni-dortmund.de
CR [Anonymous], 1996, CUCS00696 DEP COMP S
   ARAUJO H, 1996, 641 U ROCH CS DEP
   Bar-Shalom Yaakov., 1993, ESTIMATION TRACKING
   CHANG P, 1999, CVPR 99, P498
   Comport AI, 2003, SECOND IEEE AND ACM INTERNATIONAL SYMPOSIUM ON MIXED AND AUGMENTED REALITY, PROCEEDINGS, P36, DOI 10.1109/ISMAR.2003.1240686
   Craig JJ, 2009, INTRO ROBOTICS MECH
   DEMENTHON DF, 1992, LECT NOTES COMPUT SC, V588, P335, DOI 10.1007/BF01450852
   DICKMANNS ED, 1988, MACH VISION APPL, V1, P223
   DRUMMOND T, 2000, ECCV, V2, P20
   Duda R., 1973, Pattern Classification and Scene Analysis
   FOLEY JD, 2003, COMPUTER GRAPHICS PR
   Gengenbach V, 1996, IEEE INT CONF ROBOT, P1320, DOI 10.1109/ROBOT.1996.506889
   GIORDANA N, 2000, ROBUST VISION VISION, P67
   HU Y, 1999, IEEE ICRA, V3, P3209
   KOLLER D, 1993, INT J COMPUT VISION, V10, P257, DOI 10.1007/BF01539538
   KRAGIC D, 2002, IROS 02
   LINDE O, 2004, ICPR
   Lowe D. G., 1985, Perceptual Organization and Visual Recognition
   LOWE DG, 1991, IEEE T PATTERN ANAL, V13, P441, DOI 10.1109/34.134043
   Nayar SK, 1996, IEEE T ROBOTIC AUTOM, V12, P750, DOI 10.1109/70.538979
   OBDRZALEK S, 2002, BRIT MACH VIS C BMVC, V1, P113
   PETERSSON L, 2002, IEEE INT C ROB AUT I, V3, P2500
   Pontil M, 1998, IEEE T PATTERN ANAL, V20, P637, DOI 10.1109/34.683777
   ROOBAERT D, 2001, THESIS ROYAL I TECHN
   SHCIELE B, 1999, ICCV 99
   Taylor GS, 2003, AUSTR C ROB AUT BRIS, P1
   Vacchetti L, 2004, IEEE T PATTERN ANAL, V26, P1385, DOI 10.1109/TPAMI.2004.92
   VINCZE M, 2001, INT J ROBOTICS
   WUNSCH P, 1979, ICRA 97, V3, P3232
   WUNSCH P, 1997, ICRA 97, V2, P2868
NR 30
TC 32
Z9 36
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2005
VL 23
IS 11
BP 943
EP 955
DI 10.1016/j.imavis.2005.05.006
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 973KF
UT WOS:000232520600002
DA 2024-07-18
ER

PT J
AU Lucchese, L
AF Lucchese, L
TI Geometric calibration of digital cameras through multi-view
   rectification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE CCD and CMOS digital cameras; pinhole camera; 2-D projective
   transformation; 2-D homography; image rectification; camera calibration;
   intrinsic and extrinsic parameters; focal length; pixel aspect ratio;
   lens distortion
ID ZOOM-LENS CAMERA; SELF-CALIBRATION; DISTORTION
AB This paper introduces a new and very effective method for high-precision geometric calibration of digital cameras. The internal and external geometry are estimated: (1) by extracting features with subpixel accuracy from various views of a planar calibration plate; and (2) by mapping these feature sets into the corresponding points of the undistorted and rectified image that would be generated by an ideal pinhole digital camera with the same focal length as the camera to calibrate but devoid of lens distortion and perspective warp. The rectification of the views is formulated as a nonlinear least-squares optimization problem where a quadratic cost function expressing the residual registration error has to be minimized. The views are first prealigned with the reference image by means of a simplified mathematical model. This initialization, together with the closed-form computation of the gradient of the cost function, allows the Levenberg-Marquardt algorithm employed to find its minimum to rapidly converge to the optimal solution. The performance of the new calibration algorithm is tested with a set of real images available on the Internet and discussed in the paper. Also, its accuracy is assessed by means of synthetic versions of the actual images generated with the estimated parameters. (c) 2005 Elsevier B.V. All rights reserved.
C1 Oregon State Univ, Sch Elect Engn & Comp Sci, Corvallis, OR 97331 USA.
C3 Oregon State University
RP Oregon State Univ, Sch Elect Engn & Comp Sci, 313 Owen Hall, Corvallis, OR 97331 USA.
EM luca@eecs.orst.edu
CR Agapito L, 2001, INT J COMPUT VISION, V45, P107, DOI 10.1023/A:1012471930694
   Ahmed M, 2001, 2001 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL II, PROCEEDINGS, P157, DOI 10.1109/ICIP.2001.958448
   Altunbasak Y, 2003, IEEE T IMAGE PROCESS, V12, P395, DOI 10.1109/TIP.2003.809012
   [Anonymous], 1971, American Society of Photogrammetry Symposium on Close-Range Photogrammetry
   [Anonymous], P 5 EUR C COMP VERS
   Bacakoglu H, 1997, IEEE T INSTRUM MEAS, V46, P1165, DOI 10.1109/19.676732
   Bouguet J, 2001, CAMERA CALIBRATION T
   BROWN DC, 1971, PHOTOGRAMM ENG, V37, P855
   Chatterjee C, 2000, MACH VISION APPL, V12, P84, DOI 10.1007/s001380050127
   COLLINS RT, 1999, CMURITR9836
   Devernay F, 2001, MACH VISION APPL, V13, P14, DOI 10.1007/PL00013269
   Du F., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P477, DOI 10.1109/CVPR.1993.341087
   Faugeras O, 2000, IEEE T PATTERN ANAL, V22, P1179, DOI 10.1109/34.879801
   Fitzgibbon AW, 2001, PROC CVPR IEEE, P125
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   Heikkilä J, 2000, IEEE T PATTERN ANAL, V22, P1066, DOI 10.1109/34.879788
   Heikkila J, 1997, PROC CVPR IEEE, P1106, DOI 10.1109/CVPR.1997.609468
   Heikkila J, 1996, P 13 INT C PATT REC, V1, P166
   Kopparapu SK, 1999, ICRA '99: IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS 1-4, PROCEEDINGS, P1281, DOI 10.1109/ROBOT.1999.772537
   LAI JZC, 1993, IMAGE VISION COMPUT, V11, P656, DOI 10.1016/0262-8856(93)90061-K
   LENZ RK, 1988, IEEE T PATTERN ANAL, V10, P713, DOI 10.1109/34.6781
   Li MX, 1996, IEEE T PATTERN ANAL, V18, P1105, DOI 10.1109/34.544080
   Liebowitz D, 1998, PROC CVPR IEEE, P482, DOI 10.1109/CVPR.1998.698649
   Liebowitz D., 1999, Proceedings of the Seventh IEEE International Conference on Computer Vision, P293, DOI 10.1109/ICCV.1999.791233
   Lucchese L., 2003, Proceedings of the Fifth IASTED International Conference on Signal and Image Processing, P201
   LUCCHESE L, 2003, P VIIP 2003 BEN SPAI, V3, P1066
   LUCCHESE L, 2002, P 2002 AS PAC C CIRC
   LUCCHESE L, 2003, P 3 IASTED INT C VIS, V3, P1061
   Luong QT, 1997, INT J COMPUT VISION, V22, P261, DOI 10.1023/A:1007982716991
   Malis E, 2002, IEEE T PATTERN ANAL, V24, P1268, DOI 10.1109/TPAMI.2002.1033217
   MAYBANK SJ, 1992, INT J COMPUT VISION, V8, P123, DOI 10.1007/BF00127171
   Pedersini F, 1999, SIGNAL PROCESS, V77, P309, DOI 10.1016/S0165-1684(99)00042-0
   Pollefeys M, 1999, INT J COMPUT VISION, V32, P7, DOI 10.1023/A:1008109111715
   Ponce J, 2002, COMPUTER VISION MODE, DOI 10.5555/580035
   Prescott B, 1997, GRAPH MODEL IM PROC, V59, P39, DOI 10.1006/gmip.1996.0407
   Press W. H., 2002, Numerical Recipes in C: the Art of Scientific Computing, V2nd ed., DOI DOI 10.1119/1.14981
   Samtaney R., 1999, NAS99003
   Sawhney HS, 1999, IEEE T PATTERN ANAL, V21, P235, DOI 10.1109/34.754589
   Shen TS, 2001, IEEE T ROBOTIC AUTOM, V17, P502, DOI 10.1109/70.954763
   Slama C.C., 1980, MANUAL PHOTOGRAMMETR, Vfourth
   Stein GP, 1997, PROC CVPR IEEE, P602, DOI 10.1109/CVPR.1997.609387
   Sturm P, 1997, IMAGE VISION COMPUT, V15, P583, DOI 10.1016/S0262-8856(97)00015-2
   Sturm PF, 2000, INT C PATT RECOG, P72, DOI 10.1109/ICPR.2000.905278
   STURM PF, 1999, P IEEE C COMP VIS PA, V1, P23
   Swaminathan R, 2000, IEEE T PATTERN ANAL, V22, P1172, DOI 10.1109/34.879797
   TORDOFF BJ, 2002, THESIS MICHAELMAS
   Triggs B., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P89, DOI 10.1007/BFb0055661
   TSAI RY, 1987, IEEE T ROBOTIC AUTOM, V3, P323, DOI 10.1109/JRA.1987.1087109
   WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901
   Wong KYK, 2003, IEEE T PATTERN ANAL, V25, P147, DOI 10.1109/TPAMI.2003.1177148
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 52
TC 45
Z9 61
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2005
VL 23
IS 5
BP 517
EP 539
DI 10.1016/j.imavis.2005.01.001
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 917XA
UT WOS:000228501300006
DA 2024-07-18
ER

PT J
AU Fouard, C
   Malandain, G
AF Fouard, C
   Malandain, G
TI 3-D chamfer distances and norms in anisotropic grids
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 11th International Conference on Discrete Geometry for Computer Imagery
CY NOV 19-21, 2003
CL ITALIAN INST PHILOSOPH STUDIES, NAPLES, ITALY
SP Int Assoc Pattern Recognit
HO ITALIAN INST PHILOSOPH STUDIES
DE chamfer distance; anisotropic lattice; farey triangulation
ID TRANSFORMATIONS; ALGORITHM; PICTURE
AB Chamfer distances are widely used in image analysis and many authors have investigated the computation of optimal chamfer mask coefficients. Unfortunately, these methods are not systematized: calculations have to be conducted manually for every mask size or image anisotropy. Since image acquisition (e.g. medical imaging) can lead to discrete anisotropic, grids with unpredictable anisotropy value, automated calculation of chamfer mask coefficients becomes mandatory for efficient distance map computations. This article presents an automatic construction for chamfer masks of arbitrary sizes. This allows, first, to derive analytically the relative error with respect to the Euclidean distance, in any 3-D anisotropic lattice, and second, to compute optimal chamfer coefficients. In addition, the resulting chamfer map verifies discrete norm conditions. (C) 2004 Elsevier B.V. All rights reserved.
C1 INRIA, Epidaure Res Project, F-06902 Sophia Antipolis, France.
   TGS Europe SA, F-33708 Merignac, France.
   INSERM, U455, Toulouse, France.
C3 Inria; Institut National de la Sante et de la Recherche Medicale
   (Inserm); Universite de Toulouse; Universite Toulouse III - Paul
   Sabatier
RP INRIA, Epidaure Res Project, 2004 Route Lucioles,BP 92, F-06902 Sophia Antipolis, France.
EM celine.fouard@sophia.inria.fr; gregoire.malandain@sophia.inria.fr
RI Fouard, Céline/M-6004-2014; Malandain, Gregoire/J-8115-2015
OI Fouard, Celine/0000-0002-3500-9916; Malandain,
   Gregoire/0000-0002-4559-1575
CR BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   BORGEFORS G, 1984, COMPUT VISION GRAPH, V27, P321, DOI 10.1016/0734-189X(84)90035-5
   Borgefors G, 1996, COMPUT VIS IMAGE UND, V64, P368, DOI 10.1006/cviu.1996.0065
   COEURJOLLY D, 2002, THESIS U LUMIERE LYO
   COQUIN D, 1995, PATTERN RECOGN LETT, V16, P911, DOI 10.1016/0167-8655(95)00033-D
   Cuisenaire O., 1999, DISTANCE TRANSFORMAT
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   DUVERNOY HM, 1981, BRAIN RES BULL, V7, P519, DOI 10.1016/0361-9230(81)90007-1
   Fouard C, 2004, 2004 2ND IEEE INTERNATIONAL SYMPOSIUM ON BIOMEDICAL IMAGING: MACRO TO NANO, VOLS 1 AND 2, P89
   Hardy G.H., 1979, An introduction to the theory of numbers
   HERMAN GT, 1992, IEEE COMPUT GRAPH, V12, P69, DOI 10.1109/38.135915
   Hirata T, 1996, INFORM PROCESS LETT, V58, P129, DOI 10.1016/0020-0190(96)00049-X
   HUANG CT, 1994, IEEE T PATTERN ANAL, V16, P443, DOI 10.1109/34.277600
   MANGIN J, 1994, 7 EUR SIGN PROC C ED, P975
   MONTANARI U, 1968, J ACM, V15, P600, DOI 10.1145/321479.321486
   Pudney C, 1998, COMPUT VIS IMAGE UND, V72, P404, DOI 10.1006/cviu.1998.0680
   RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4
   REMY E, 2000, IWCIA, P39
   REMY E, 2001, THESIS U MEDITERRANE
   ROSENFEL.A, 1966, J ACM, V13, P471
   SAITO T, 1994, PATTERN RECOGN, V27, P1551, DOI 10.1016/0031-3203(94)90133-3
   Shih FYC, 1992, IEEE T IMAGE PROCESS, V1, P197, DOI 10.1109/83.136596
   Sintorn IM, 2004, PATTERN RECOGN LETT, V25, P571, DOI 10.1016/j.patrec.2003.12.006
   THEIL E, 2001, GEOMETRIE DISTANCES
   THIEL E, 1994, THESIS U J FOURIER
   Turner R, 2002, NEUROIMAGE, V16, P1062, DOI 10.1006/nimg.2002.1082
   VERWER B, 1991, THESIS TU
   VERWER BJH, 1991, PATTERN RECOGN LETT, V12, P671, DOI 10.1016/0167-8655(91)90004-6
NR 28
TC 27
Z9 30
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2005
VL 23
IS 2
BP 143
EP 158
DI 10.1016/j.imavis.2004.06.009
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 883OE
UT WOS:000226021800006
DA 2024-07-18
ER

PT J
AU Pujari, AK
   Naidu, CD
   Rao, MS
   Jinaga, BC
AF Pujari, AK
   Naidu, CD
   Rao, MS
   Jinaga, BC
TI An intelligent character recognizer for Telugu scripts using
   multiresolution analysis and associative memory
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT Indian Conference on Vision, Graphics and Image Processing (ICVGIP)
CY DEC 16-18, 2002
CL Ahmedabad, INDIA
DE multi-resolution analysis; optical character recognition; pattern
   recognition
ID CHINESE CHARACTERS; TEXT RECOGNITION; NEURAL NETWORKS; OCR;
   METHODOLOGIES; SEGMENTATION; SYSTEM
AB The present work is an attempt to develop a robust character recognizer for Telugu texts. We aim at designing a recognizer, which exploits the inherent characteristics of the Telugu Script. Our proposed method uses wavelet multi-resolution analysis for the purpose extracting features and associative memory model to accomplish the recognition tasks. Our system learns the style and font from the document itself and then it recognizes the remaining characters in the document. The major contribution of the present study can be outlined as follows. It is a robust OCR system for Telugu printed text. It avoids feature extraction process and it exploits the inherent characteristics of the Telugu character by a clever selection of Wavelet Basis function, which extracts the invariant features of the characters. It has a Hoptield-based Dynamic Neural Network for the purpose of learning and recognition. This is important because it overcomes the inherent difficulties of memory limitation and spurious states in the Hopfield Network. The DNN has been demonstrated to be efficient for associative memory recall. However, though it is normally not suitable for image processing application, the multi-resolution analysis reduces the sizes of the images to make the DNN applicable to the present domain. Our experimental results show extremely promising results. (C) 2004 Elsevier B.V. All rights reserved.
C1 Univ Hyderabad, AI Lab, Hyderabad 500046, Andhra Pradesh, India.
   VJIEY, VNR, Dept ECE, Hyderabad 500072, Andhra Pradesh, India.
   JN Technol Univ, Dept CSE, Hyderabad 500072, Andhra Pradesh, India.
   JN Technol Univ, Dept ECE, Hyderabad 500072, Andhra Pradesh, India.
C3 University of Hyderabad; Jawaharlal Nehru Technological University -
   Hyderabad; Jawaharlal Nehru Technological University - Hyderabad
RP Pujari, AK (corresponding author), Univ Hyderabad, AI Lab, Hyderabad 500046, Andhra Pradesh, India.
EM akpcs@uohyd.ernet.in
RI PUJARI, ARUN K/ABG-9196-2021; C.D., Naidu/O-9351-2015
OI C.D., Naidu/0000-0001-8477-9821
CR [Anonymous], 1973, PATTEN CLASSIFICATIO
   ATUL N, 2001, OCR SYSTEM TELUGU
   BURR DJ, 1988, IEEE T ASSP, V36
   CASEY R, 1966, IEEE TRANS ELECTRON, VEC15, P91, DOI 10.1109/PGEC.1966.264379
   Chaudhuri BB, 1998, PATTERN RECOGN, V31, P531, DOI 10.1016/S0031-3203(97)00078-2
   CHAUDHURI BB, 1991, J IETE, V37, P499
   Cheung A, 2001, PATTERN RECOGN, V34, P215, DOI 10.1016/S0031-3203(99)00227-7
   Devijver P. A., 1982, PATTERN RECOGNITION, V265
   Dunn CE, 1992, P 11 INT C PATT REC, V2, P577
   ELLIMAN DG, 1990, PATTERN RECOGN, V23, P337, DOI 10.1016/0031-3203(90)90021-C
   Fu K.S., 1982, SYNTACTIC PATTERN RE, Vsecond
   Fukunaga K., 1990, Introduction to StatisticalPattern Recognition
   FUKUSHIMA K, 1991, IEEE T NEURAL NETWOR, V2, P355, DOI 10.1109/72.97912
   GOVINDAN VK, 1990, PATTERN RECOGN, V23, P671, DOI 10.1016/0031-3203(90)90091-X
   GROTHER PJ, 1992, P APPL ART NEUR NETW
   GUYON I, 1991, CHARACTER HANDWRITIN
   HUBRIGSCHAUMBUR.S, 1992, IMPEDRITTEN CHARACTE
   IMPEDEVO S, 1991, INT J PATTERN RECOGN
   KIM HY, 2001, PATTERN RECOGN, P34
   KUNIHITO F, 1992, IEEE T NEURAL NETWOR, V2, P355
   LAM L, 1992, IEEE T PATTERN ANAL, V14, P869, DOI 10.1109/34.161346
   LOVELL DR, 1994, THESIS U QUEENSLAND
   MALLAT SG, 1989, T AM MATH SOC, V315, P69, DOI 10.2307/2001373
   MANTAS J, 1986, PATTERN RECOGN, V19, P425, DOI 10.1016/0031-3203(86)90040-3
   MOHIUDDIN KM, 1994, MACH INTELL PATT REC, V16, P437
   MORI S, 1992, P IEEE, V80, P1029, DOI 10.1109/5.156468
   NAGY G, 1992, P IEEE, V80, P1093, DOI 10.1109/5.156472
   PENTLAND A, 1991, P CG 91 C NEWYORK, P5017
   PERANTONIS SJ, 1992, IEEE T NEURAL NETWOR, V3, P241, DOI 10.1109/72.125865
   Rao M S, 1999, Int J Neural Syst, V9, P351, DOI 10.1142/S0129065799000332
   SABOURIN M, 1992, NEURAL NETWORKS, V5, P843, DOI 10.1016/S0893-6080(05)80144-3
   Schwenk H., 1995, Advances in Neural Information Processing Systems 7, P991
   SINHA RMK, 1987, PATTERN RECOGN, V20, P475, DOI 10.1016/0031-3203(87)90075-6
   SINHA RMK, 1979, IEEE T SYST MAN CYB, V9, P435
   *SNS, 1977, COMPUTER GRAPHICS IM, V6, P335
   SUEN CY, 1980, P IEEE, V68, P469, DOI 10.1109/PROC.1980.11675
   SUKHASWAMI MB, 1995, INT J NEURAL SYST, V6, P317, DOI 10.1142/S0129065795000238
   Trier OD, 1996, PATTERN RECOGN, V29, P641, DOI 10.1016/0031-3203(95)00118-2
   ULLMANN JR, 1973, PATTERN RECOGNITION
   Wang AB, 2001, PATTERN RECOGN, V34, P15, DOI 10.1016/S0031-3203(99)00207-1
   Wilson C. L., 1993, Neural Networks for Processing III Proceedings of the 1993 IEEE-SP Workshop, P485, DOI 10.1109/NNSP.1993.471839
NR 41
TC 20
Z9 21
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC 1
PY 2004
VL 22
IS 14
BP 1221
EP 1227
DI 10.1016/j.imavis.2004.03.027
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 882LG
UT WOS:000225939800009
DA 2024-07-18
ER

PT J
AU Torr, PHS
   Criminisi, A
AF Torr, PHS
   Criminisi, A
TI Dense stereo using pivoted dynamic programming
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE dynamic programming; dense stereo; epipolar lines
AB This paper describes an improvement to the dynamic programming approach for dense stereo. Traditionally dense stereo algorithms proceed independently for each pair of epipolar lines, and then a further step is used to smooth the estimated disparities between the epipolar lines. This typically results in a streaky disparity map along depth discontinuities. In order to overcome this problem the information from corner and edge matching algorithms are exploited. Indeed we present a unified dynamic programming/statistical framework that allows the incorporation of any partial knowledge about disparities, such as matched features and known surfaces within the scene. The result is a fully automatic dense stereo system with a faster run time and greater accuracy than the standard dynamic programming method. (C) 2004 Elsevier B.V. All rights reserved.
C1 Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England.
   Microsoft Res Ltd, Cambridge CB3 0FB, England.
C3 Oxford Brookes University; Microsoft
RP Oxford Brookes Univ, Dept Comp, Oxford OX33 1HX, England.
EM philiptorr@brookes.ac.uk; antcrimr@microsoft.com
CR Baker H.M., 1981, PROC 7 INT JOINT C A, P631
   BEARDSLEY PA, 1996, LNCS, V1065, P683
   Belhumeur PN, 1996, INT J COMPUT VISION, V19, P237, DOI 10.1007/BF00055146
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Cox IJ, 1996, COMPUT VIS IMAGE UND, V63, P542, DOI 10.1006/cviu.1996.0040
   FORNEY GD, 1973, P IEEE, V61, P268, DOI 10.1109/PROC.1973.9030
   GEIGER D, 1985, IJCV, V14, P211
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   HENDERSON RL, 1979, SPIE, V1, P240
   Ishikawa H., 1998, Computer Vision - ECCV'98. 5th European Conference on Computer Vision. Proceedings, P232, DOI 10.1007/BFb0055670
   KOCH R, 1998, P 5 EUR C COMP VIS, V1, P55
   MARR D, 1976, SCIENCE, V194, P283, DOI 10.1126/science.968482
   OHTA Y, 1985, IEEE T PATTERN ANAL, V7, P139, DOI 10.1109/TPAMI.1985.4767639
   Roy S, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P492, DOI 10.1109/ICCV.1998.710763
   Schmid C, 1997, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.1997.609397
   SCHMID C, 1998, EUR C COMP VIS, V1, P394
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   TORR PHS, 1993, P SOC PHOTO-OPT INS, V2059, P432, DOI 10.1117/12.150246
   ZHANG Z, 1994, AI J, V78, P87
NR 19
TC 22
Z9 24
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 1
PY 2004
VL 22
IS 10
BP 795
EP 806
DI 10.1016/j.imavis.2004.02.012
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 840VZ
UT WOS:000222889300007
DA 2024-07-18
ER

PT J
AU Jaynes, C
AF Jaynes, C
TI Multi-view calibration from planar motion trajectories
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE surveillance cameras; planar motion trajectories; multi-view calibration
ID IMAGE REGISTRATION; TRACKING; OBJECT
AB We present a technique for the registration of a network of surveillance cameras through the automatic alignment of observed planar motion trajectories. The algorithm addresses the problem of recovering the relative pose of several stationary, networked cameras whose intrinsic parameters are known. Each camera tracks several objects to produce a set of image trajectories. Using temporal and geometric constraints derived from the trajectory and a network synchronization signal, overlapping viewing frustums are determined and corresponding cameras are calibrated. Full calibration is a two stage process. Initially, the relative orientation of each camera to the local ground plane, is computed in order to recover the projective mapping of image points to world trajectories embedded on a nominal plane of correct orientation. Given the relative camera-to-plane orientation, projectively unwarped trajectory curves can then be robustly matched by solving for the similarity transform that brings them into absolute alignment.
   Registration aligns n-cameras with respect to each other in a single camera frame (that of the reference camera). The approach recovers both the epipolar geometry between all cameras and the camera-to-ground rotation for each camera independently. After calibration, points that are known to lie on a world ground plane can be directly back projected into each of the camera frames. These tracked points are known to be in spatial and temporal correspondence, supporting multi-view surveillance and motion understanding tasks. The algorithm is demonstrated for two, three, and five camera scenarios by tracking pedestrians as they move through a surveillance area and matching the resulting trajectories. (C) 2003 Elsevier B.V. All rights reserved.
C1 Univ Kentucky, Dept Comp Sci, Lexington, KY 40502 USA.
C3 University of Kentucky
RP Jaynes, C (corresponding author), Univ Kentucky, Dept Comp Sci, 773 Anderson Hall, Lexington, KY 40502 USA.
EM jaynes@metaverselab.org
CR Amoozegar F, 1998, OPT ENG, V37, P836, DOI 10.1117/1.601917
   ARARBAYEJANI A, 1995, 341 MIT MED LAB
   Besl P.J., 1990, Machine Vision for Three-Dimensional Scenes, P25, DOI [10.1016/B978-0-12-266722-0.50006-3, DOI 10.1016/B978-0-12-266722-0.50006-3]
   BOLDT M, 1994, IEE T SYSTEMS MAN CY
   Bouguet JY, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P43, DOI 10.1109/ICCV.1998.710699
   Brooks RR, 1997, OPT ENG, V36, P767, DOI 10.1117/1.601274
   Brooks RR, 1996, COMPUTER, V29, P53, DOI 10.1109/2.507632
   BROWN LG, 1992, COMPUT SURV, V24, P325, DOI 10.1145/146370.146374
   Buiten HJ, 1997, ISPRS J PHOTOGRAMM, V52, P57, DOI 10.1016/S0924-2716(97)83001-8
   CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K
   Collins R. T., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P240, DOI 10.1109/CVPR.1993.340983
   DAVIS L, 1997, P DARPA IU WORKSH NE, P19
   Fujiyoshi H, 1998, FOURTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION - WACV'98, PROCEEDINGS, P15, DOI 10.1109/ACV.1998.732852
   GRIMSON W, 1998, P DAPRA IU WORKSH MO, P33
   HORN BKP, 1988, J OPT SOC AM A, V5, P1127, DOI 10.1364/JOSAA.5.001127
   Intille SS, 1997, PROC CVPR IEEE, P697, DOI 10.1109/CVPR.1997.609402
   JAYNES C, 1999, P AS C COMP VIS ACCV
   Kanade T., 1998, Proc. of DARPA Image Understanding Workshop, P3
   KATAO H, 1998, P INT C PATT REC
   KISHON E, 1990, P EUR C COMP VIS, P589
   MAGEE MJ, 1984, COMPUT VISION GRAPH, V26, P256, DOI 10.1016/0734-189X(84)90188-9
   MATSUYAMA T, 1998, P IM UND WORKSH, P365
   MICHEALS R, 1999, THESIS LEHIGH U
   Neri A, 1998, SIGNAL PROCESS, V66, P219, DOI 10.1016/S0165-1684(98)00007-3
   Parodi P, 1996, IEEE T PATTERN ANAL, V18, P211, DOI 10.1109/34.481545
   PENTLAND A, 1997, P DARPA IU WORKSH NE, P193
   PUGET P, 1990, IMAGE VISION COMPUT, V8, P341, DOI 10.1016/0262-8856(90)80010-Q
   Stein G. P., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P521, DOI 10.1109/CVPR.1999.786987
   Szeliski R, 1998, INT J COMPUT VISION, V28, P27, DOI 10.1023/A:1008050630628
   THORNTON KB, 1995, P SOC PHOTO-OPT INS, V2486, P37, DOI 10.1117/12.213130
   TRIVEDI HP, 1991, IMAGE VISION COMPUT, V9, P75, DOI 10.1016/0262-8856(91)90015-H
   Trucco E., 1998, Introductory techniques for 3-D computer vision, V201
   Wren CR, 1997, IEEE T PATTERN ANAL, V19, P780, DOI 10.1109/34.598236
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
NR 34
TC 7
Z9 8
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 1
PY 2004
VL 22
IS 7
BP 535
EP 550
DI 10.1016/j.imavis.2003.09.008
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 821RT
UT WOS:000221481000003
DA 2024-07-18
ER

PT J
AU Xiao, Y
   Yan, H
AF Xiao, Y
   Yan, H
TI Location of title and author regions in document images based on the
   Delaunay triangulation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE document image analysis; document image segmentation; connected
   component analysis; location of title and author regions; Delaunay
   triangulation
ID PAGE SEGMENTATION; EXTRACTION
AB Automatic title and author location can be a crucial step in journal document image processing systems. This paper presents a Delaunay triangulation-based method for identification of title and author areas in a technical document image. The positions and alignments of small text line regions are measured by different triangle groups and the character stroke widths are calculated from the constrained Delaunay triangulation. The rules defining spatial features and font attributes of the title and author region are applied to single line text regions to extract the title and author regions. Our experiment results show that the proposed method is effective. (C) 2003 Elsevier B.V. All fights reserved.
C1 Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
   City Univ Hong Kong, Dept Comp Engn & Informat Technol, Kowloon, Hong Kong, Peoples R China.
C3 University of Sydney; City University of Hong Kong
RP Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
EM yix@ee.usyd.edu.au
OI YAN, Hong/0000-0001-9661-3095
CR Antonacopoulos A, 1998, COMPUT VIS IMAGE UND, V70, P350, DOI 10.1006/cviu.1998.0691
   Baird H. S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P820, DOI 10.1109/ICPR.1990.118223
   CHEW LP, 1989, ALGORITHMICA, V4, P97, DOI 10.1007/BF01553881
   FLETCHER LA, 1988, IEEE T PATTERN ANAL, V10, P910, DOI 10.1109/34.9112
   Fukushima S, 1997, IEEE T PATTERN ANAL, V19, P144, DOI 10.1109/34.574795
   Ishitani Y., 1999, Proceedings of the Fifth International Conference on Document Analysis and Recognition. ICDAR '99 (Cat. No.PR00318), P189, DOI 10.1109/ICDAR.1999.791756
   Jain AK, 1998, IEEE T PATTERN ANAL, V20, P294, DOI 10.1109/34.667886
   Kim J, 2001, PROC SPIE, V4307, P111
   Kise K, 1998, COMPUT VIS IMAGE UND, V70, P370, DOI 10.1006/cviu.1998.0684
   Klink S., 2001, International Journal on Document Analysis and Recognition, V4, P18, DOI 10.1007/PL00013570
   MAO S, 2003, SPIE, V5010, P197
   Mitchell PE, 2000, OPT ENG, V39, P724, DOI 10.1117/1.602419
   Mitchell PE, 2002, OPT ENG, V41, P2831, DOI 10.1117/1.1512907
   Nagy G, 2000, IEEE T PATTERN ANAL, V22, P38, DOI 10.1109/34.824820
   NAGY G, 1992, COMPUTER, V25, P10, DOI 10.1109/2.144436
   OGORMAN L, 1993, IEEE T PATTERN ANAL, V15, P1162, DOI 10.1109/34.244677
   OKABE A, 2000, SPATIAL TESSELLATION, P165
   PAVLIDIS T, 1992, CVGIP-GRAPH MODEL IM, V54, P484, DOI 10.1016/1049-9652(92)90068-9
   PRASAD L, 1997, MORPHOLOGICAL SHAPES
   Shewchuk J., 1996, First Workshop on Applied Computational Geometry, P124
   Summers K., 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P462, DOI 10.1109/ICDAR.1995.599036
   Tsujimoto S., 1990, Proceedings. 10th International Conference on Pattern Recognition (Cat. No.90CH2898-5), P551, DOI 10.1109/ICPR.1990.118163
   WAHL FM, 1982, COMPUT VISION GRAPH, V20, P375, DOI 10.1016/0146-664X(82)90059-4
   Xiao Y, 2003, PATTERN RECOGN, V36, P799, DOI 10.1016/S0031-3203(02)00082-1
NR 24
TC 6
Z9 9
U1 0
U2 0
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2004
VL 22
IS 4
BP 319
EP 329
DI 10.1016/j.imavis.2003.11.002
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 778FW
UT WOS:000189229700005
DA 2024-07-18
ER

PT J
AU Masoud, O
   Papanikolopoulos, N
AF Masoud, O
   Papanikolopoulos, N
TI A method for human action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE motion recognition; human tracking; articulated motion
ID TEMPORAL TEMPLATES; BIOLOGICAL MOTION; NONRIGID MOTION; HUMAN MOVEMENT;
   TRACKING; PERCEPTION; MODEL; EIGENFACES; SPACE
AB This article deals with the problem of classification of human activities from video. Our approach uses motion features that are computed very efficiently, and subsequently projected into a lower dimensional space where matching is performed. Each action is represented as a manifold in this lower dimensional space and matching is done by comparing these manifolds. To demonstrate the effectiveness of this approach. it was used on a large data set of similar actions, each performed by many different actors. Classification results were very accurate and show that this approach is robust to challenges such as variations in performers' physical attributes, color of clothing, and style of motion. An important result of this article is that the recovery of the three-dimensional properties of a moving person, or even the two-dimensional tracking of the person's limbs need not precede action recognition. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 Univ Minnesota, Dept Comp Sci & Engn, Minneapolis, MN 55455 USA.
C3 University of Minnesota System; University of Minnesota Twin Cities
RP Univ Minnesota, Dept Comp Sci & Engn, 4-192 EE-CS Bldg,200 Union St SE, Minneapolis, MN 55455 USA.
EM masoud@cs.umn.edu; npapas@cs.umn.edu
RI Papanikolopoulos, Nikos/ITW-0029-2023
OI Papanikolopoulos, Nikos/0000-0002-2177-1870
CR AKITA K, 1984, PATTERN RECOGN, V17, P73, DOI 10.1016/0031-3203(84)90036-0
   AZARBAYEJANI A, 1996, P INT C PATT REC VIE
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   BENABDELKADER C, 2002, 5 INT C AUT FAC GEST
   Bregler C, 1998, PROC CVPR IEEE, P8, DOI 10.1109/CVPR.1998.698581
   BREGLER C, 1997, P IEEE C COMP VIS PA
   Cai Q., 1996, Proceedings of the 13th International Conference on Pattern Recognition, P68, DOI 10.1109/ICPR.1996.546796
   CAMPBELL LW, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P624, DOI 10.1109/ICCV.1995.466880
   CEDRAS C, 1995, IMAGE VISION COMPUT, V13, P129, DOI 10.1016/0262-8856(95)93154-K
   CUTTING JE, 1977, B PSYCHONOMIC SOC, V9, P353, DOI 10.3758/BF03337021
   Davis JW, 1997, PROC CVPR IEEE, P928, DOI 10.1109/CVPR.1997.609439
   DIFRANCO DE, 2001, RECONSTRUCTION 3D FI, V2, P307
   DITTRICH WH, 1993, PERCEPTION, V22, P15, DOI 10.1068/p220015
   Foster J., 2001, P BRIT MACH VIS C 20, P233
   Gavrila DM, 1999, COMPUT VIS IMAGE UND, V73, P82, DOI 10.1006/cviu.1998.0716
   Gavrila DM, 1996, PROC CVPR IEEE, P73, DOI 10.1109/CVPR.1996.517056
   Goddard N. H., 1994, Proceedings of the 1994 IEEE Workshop on Motion of Non-Rigid and Articulated Objects (Cat. No.94TH0671-8), P89, DOI 10.1109/MNRAO.1994.346250
   GUO Y, 1994, INT C PATT RECOG, P325, DOI 10.1109/ICPR.1994.576929
   Halevi G, 1997, PROC CVPR IEEE, P897, DOI 10.1109/CVPR.1997.609434
   HUANG PS, 1999, IEEE P VISP, V14, P93
   JOHANSSON G, 1975, SCI AM, V232, P76, DOI 10.1038/scientificamerican0675-76
   JOHANSSON G, 1973, PERCEPT PSYCHOPHYS, V14, P201, DOI 10.3758/BF03212378
   JU S, 1996, P IEEE INT C AUT FAC, P33
   KOZLOWSKI LT, 1977, PERCEPT PSYCHOPHYS, V21, P575, DOI 10.3758/BF03198740
   Krahnstöver N, 2001, IEEE WORKSHOP ON DETECTION AND RECOGNITION OF EVENTS IN VIDEO, PROCEEDINGS, P47, DOI 10.1109/EVENT.2001.938865
   Masoud O, 2001, IEEE T VEH TECHNOL, V50, P1267, DOI 10.1109/25.950328
   MASOUD O, 2000, THESIS U MINNESOTA
   NAYAR SK, 1996, P IEEE C ROB AUT, V3, P2321
   Pavlovic V, 2000, PROC CVPR IEEE, P788, DOI 10.1109/CVPR.2000.855901
   Polana R, 1997, INT J COMPUT VISION, V23, P261, DOI 10.1023/A:1007975200487
   Polana R., 1994, Journal of Visual Communication and Image Representation, V5, P172, DOI 10.1006/jvci.1994.1016
   RANGARAJAN K, 1993, PATTERN RECOGN, V26, P595, DOI 10.1016/0031-3203(93)90113-B
   Swets DL, 1996, IEEE T PATTERN ANAL, V18, P831, DOI 10.1109/34.531802
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   WANG J, 1991, P 7 SCAND C IM AN AA
   Wren C, 1996, PROCEEDINGS OF THE SECOND INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, P51, DOI 10.1109/AFGR.1996.557243
   Yacoob Y, 1999, COMPUT VIS IMAGE UND, V73, P232, DOI 10.1006/cviu.1998.0726
   Yamato J., 1992, Proceedings. 1992 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.92CH3168-2), P379, DOI 10.1109/CVPR.1992.223161
NR 38
TC 80
Z9 107
U1 0
U2 14
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2003
VL 21
IS 8
BP 729
EP 743
DI 10.1016/S0262-8856(03)00068-4
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 706VM
UT WOS:000184475800005
DA 2024-07-18
ER

PT J
AU Brettle, DS
   Berry, E
   Smith, MA
AF Brettle, DS
   Berry, E
   Smith, MA
TI Synthesis of texture from clinical images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE texture; synthesis; psychophysical
ID OBSERVER PERFORMANCE; CONTRAST SENSITIVITY; VISUAL-PERCEPTION;
   STRUCTURED NOISE; ROC METHODOLOGY; BACKGROUNDS; LESIONS; MODELS
AB Psychophysical tests are a major tool in medical imaging for accessing a persons performance in viewing medical images. Tests that use clinical images are preferred as the results are more representative of the clinical task but these require large numbers of images and accurate definition of the gold standard. In this paper methods for synthesising clinical textures were evaluated. One non-parametric method was found to be more suitable although clinical samples were difficult to synthesise. A modification, based on sample reordering was developed. Results are presented showing the success of this approach for a range of clinical images and modalities. This may help facilitate psychophysical experiments where anatomical background noise is to be considered. (C) 2003 Elsevier Science B.V. All rights reserved.
C1 St James Univ Hosp, Leeds Teaching Hosp NHS Trust, Dept Med Phys & Engn, Leeds LS9 7TF, W Yorkshire, England.
   Univ Leeds, Leeds Gen Infirm, Acad Unit Med Phys, Leeds LS1 3EX, W Yorkshire, England.
   Univ Leeds, Leeds Gen Infirm, Ctr Med Imaging Res, Leeds LS1 3EX, W Yorkshire, England.
C3 University of Leeds; Saint James's University Hospital; Leeds General
   Infirmary; University of Leeds; University of Leeds; Leeds General
   Infirmary
RP St James Univ Hosp, Leeds Teaching Hosp NHS Trust, Dept Med Phys & Engn, Leeds LS9 7TF, W Yorkshire, England.
EM dsb@medphysics.leeds.ac.uk
OI Brettle, David/0000-0001-6963-1757
CR [Anonymous], REPRESENTATION SYNTH
   [Anonymous], 1999, ICCV
   [Anonymous], SIGGRAPH
   Bochud FO, 1999, MED PHYS, V26, P1365, DOI 10.1118/1.598632
   Bochud FO, 1999, OPT EXPRESS, V4, P33, DOI 10.1364/OE.4.000033
   Brodatz P., 1999, Textures: a photographic album for artists and designers
   BURGESS AE, 1995, MED PHYS, V22, P643, DOI 10.1118/1.597576
   Burgess AE, 2001, MED PHYS, V28, P419, DOI 10.1118/1.1355308
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   CAELLI T, 1978, BIOL CYBERN, V28, P167, DOI 10.1007/BF00337138
   CHESTERS MS, 1992, PHYS MED BIOL, V37, P1433, DOI 10.1088/0031-9155/37/7/001
   DEBONET JS, 1997, SIGGRAPH 97, P361, DOI DOI 10.1145/258734.258882
   DELP EJ, 1979, PATTERN RECOGN, V11, P313, DOI 10.1016/0031-3203(79)90041-4
   DENEVE E, ANIMATING REAL TIME
   Ellemberg D, 1998, J OPT SOC AM A, V15, P1733, DOI 10.1364/JOSAA.15.001733
   ELMARAGHI T, IMPLEMENTATION HEEGE
   GIMELFARB G, 2000, COMPUTER ASSISTED RA, P537
   GINSBURG AP, 1983, INVEST OPHTH VIS SCI, V24, P798
   GOODENOUGH DJ, 1972, RADIOLOGY, V105, P199, DOI 10.1148/105.1.199
   GRAY R, SIGNAL DETECTION THE
   HAHN L, 1995, STAIRCASE 2 AFC URL
   HIGGINS KE, 1984, ARCH OPHTHALMOL-CHIC, V102, P1035, DOI 10.1001/archopht.1984.01040030837028
   IVERSEN H, 1994, PATTERN RECOGN LETT, V15, P575, DOI 10.1016/0167-8655(94)90018-3
   JAIN R, 1995, MACHINE VISION, P243
   JULESZ B, 1975, SCI AM, V232, P34, DOI 10.1038/scientificamerican0475-34
   KUNDEL HL, 1985, INVEST RADIOL, V20, P94, DOI 10.1097/00004424-198501000-00023
   LOO LND, 1984, PHYS MED BIOL, V29, P837, DOI 10.1088/0031-9155/29/7/007
   MCKEE SP, 1985, PERCEPT PSYCHOPHYS, V37, P286, DOI 10.3758/BF03211350
   MEANEY TF, 1980, RADIOLOGY, V134, P149, DOI 10.1148/radiology.134.1.7350595
   METZ CE, 1986, INVEST RADIOL, V21, P720, DOI 10.1097/00004424-198609000-00009
   OHARA K, 1989, MED PHYS, V16, P14, DOI 10.1118/1.596391
   Penn AI, 1996, P SOC PHOTO-OPT INS, V2710, P840, DOI 10.1117/12.237990
   Portilla J, 2000, INT J COMPUT VISION, V40, P49, DOI 10.1023/A:1026553619983
   REVESZ G, 1974, INVEST RADIOL, V9, P479, DOI 10.1097/00004424-197411000-00009
   ROLLAND J, 2001, HDB MED IMAGING PHYS, V1, P683
   Rolland JP, 1997, OPT EXPRESS, V1, P414, DOI 10.1364/OE.1.000414
   SALLANS B, TEXTURE SYNTHESIS
   SHERRIER RH, 1985, INVEST RADIOL, V20, P933, DOI 10.1097/00004424-198512000-00008
   Simoncelli E., 1995, IEEE INT C IM PROC I
   SUTTON RN, 1972, IEEE T COMPUT, VC 21, P667, DOI 10.1109/T-C.1972.223572
   Tuceryan M., 1998, HDB PATTERN RECOGNIT, V2nd
   Wei LY, 2000, COMP GRAPH, P479, DOI 10.1145/344779.345009
   WITKIN A, 1991, COMP GRAPH, V25, P299, DOI 10.1145/127719.122750
NR 43
TC 2
Z9 2
U1 0
U2 1
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2003
VL 21
IS 5
BP 433
EP 445
DI 10.1016/S0262-8856(03)00002-7
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 676DA
UT WOS:000182735600003
DA 2024-07-18
ER

PT J
AU Gao, RX
   Su, H
   Prasad, S
   Tang, PS
AF Gao, Ruixuan
   Su, Han
   Prasad, Shitala
   Tang, Peisen
TI Few-shot classification with multisemantic information fusion network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Few-shot learning; Metric-based learning; Feature representation;
   Unsupervised mechanism
AB Metric-based methods aim to predict class labels by computing the similarity between samples using distance functions, which is the mainstream approach to few-shot learning. However, the limited representational space of feature vectors and appearance variations among congenetic samples still present challenges. We propose a Multisemantic Information Fusion Network (MIFN) to address these problems. A Lower-level Feature generator (LF-generator), which is an unsupervised module, adaptively activates high-response regions of objects to introduce discriminative semantic details. Meanwhile, a Higher-level Feature extractor (HF-extractor) learns global semantic information with human cognition to minimise the impact of appearance variations. We integrate the coarse outputs of these two modules, which complement each other to jointly promote more precise predictions. Furthermore, considering the importance of prototypes, we redefine the sampling strategy of the triplet loss and utilise it as an auxiliary loss to sharpen the decision boundary at the prototype level, facilitating subsequent classification. Our experimental results demonstrate the competitiveness of our approach in both general few-shot classification (mini-ImageNet and tiered-ImageNet) and cross-domain problems (CUB, Caltech101, Stanford-dogs, and Stanford-cars) with minimal bells and whistles.
C1 [Gao, Ruixuan; Su, Han; Tang, Peisen] Sichuan Normal Univ, Sch Comp Sci, Chengdu, Peoples R China.
   [Su, Han] Visual Comp & Virtual Real Key Lab Sichuan Prov, Chengdu, Peoples R China.
   [Prasad, Shitala] Indian Inst Technol Goa, Sch Math & Comp Sci, Ponda, Goa, India.
   [Su, Han] Univ Hull, Sch Comp Sci, Kingston Upon Hull, England.
C3 Sichuan Normal University; Indian Institute of Technology System (IIT
   System); Indian Institute of Technology (IIT) Goa; University of Hull
RP Su, H (corresponding author), Sichuan Normal Univ, Sch Comp Sci, Chengdu, Peoples R China.; Su, H (corresponding author), Visual Comp & Virtual Real Key Lab Sichuan Prov, Chengdu, Peoples R China.; Su, H (corresponding author), Univ Hull, Sch Comp Sci, Kingston Upon Hull, England.
EM jkxy_sh@sicnu.edu.cn
FU Returned Overseas Chinese Program of Ministry of Human Resources and
   Social Security; China Scholarship Council; Natural Science Foundation
   of Sichuan Province [2023NSFSC1080, 2023NSFSC0210, 2023YFS0202]; Chengdu
   Science and Technology Program [2022-YF09-00019-SN]; Chengdu Research
   Base of Giant Panda Breeding [2021CPB-B06]
FX The work is supported by Returned Overseas Chinese Program of Ministry
   of Human Resources and Social Security; China Scholarship Council;
   Natural Science Foundation of Sichuan Province, Grant/Award Number:
   2023NSFSC1080, 2023NSFSC0210, 2023YFS0202; Chengdu Science and
   Technology Program, Grant/Award Number: 2022-YF09-00019-SN; Chengdu
   Research Base of Giant Panda Breeding, Grant/Award Number: 2021CPB-B06.
CR Afrasiyabi Arman, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12350), P18, DOI 10.1007/978-3-030-58558-7_2
   Amos B, 2017, PR MACH LEARN RES, V70
   Bin Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12349), P438, DOI 10.1007/978-3-030-58548-8_26
   Chen D, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P1745, DOI 10.1109/ICASSP39728.2021.9413783
   Chen W.-Y., 2019, ARXIV191210917
   Chen Y., 2020, ARXIV200304390
   Chi Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12200, DOI 10.1109/CVPR42600.2020.01222
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding N, 2022, Arxiv, DOI arXiv:2211.05319
   Dvornik N, 2019, IEEE I CONF COMP VIS, P3722, DOI 10.1109/ICCV.2019.00382
   Finn C, 2017, PR MACH LEARN RES, V70
   Gidaris S, 2018, PROC CVPR IEEE, P4367, DOI 10.1109/CVPR.2018.00459
   Han-Jia Ye, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8805, DOI 10.1109/CVPR42600.2020.00883
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Hou RB, 2019, ADV NEUR IN, V32
   Hu YX, 2022, LECT NOTES COMPUT SC, V13680, P20, DOI 10.1007/978-3-031-20044-1_2
   Jamal MA, 2019, PROC CVPR IEEE, P11711, DOI 10.1109/CVPR.2019.01199
   Khosla A., 2011, P CVPR WORKSH FIN GR
   Krause J, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P554, DOI 10.1109/ICCVW.2013.77
   Lee K, 2019, PROC CVPR IEEE, P10649, DOI 10.1109/CVPR.2019.01091
   Li FF, 2007, COMPUT VIS IMAGE UND, V106, P59, DOI 10.1016/j.cviu.2005.09.012
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Li XM, 2020, NEUROCOMPUTING, V406, P49, DOI 10.1016/j.neucom.2020.04.040
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Mangla P, 2020, IEEE WINT CONF APPL, P2207, DOI [10.1109/wacv45572.2020.9093338, 10.1109/WACV45572.2020.9093338]
   Ouali Y, 2021, LECT NOTES ARTIF INT, V12975, P671, DOI 10.1007/978-3-030-86486-6_41
   Ravi S, 2016, PROC INT C LEARN REP
   Ren M., 2018, INT C LEARNING REPRE, DOI DOI 10.1109/IPFA.2018.8452547
   Rubner Y, 2000, INT J COMPUT VISION, V40, P99, DOI 10.1023/A:1026543900054
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shen ZQ, 2021, AAAI CONF ARTIF INTE, V35, P9594
   Simon C, 2020, PROC CVPR IEEE, P4135, DOI 10.1109/CVPR42600.2020.00419
   Snell J, 2017, ADV NEUR IN, V30
   Sun QR, 2019, PROC CVPR IEEE, P403, DOI 10.1109/CVPR.2019.00049
   Sung F, 2018, PROC CVPR IEEE, P1199, DOI 10.1109/CVPR.2018.00131
   Triantafillou E, 2020, Arxiv, DOI arXiv:1903.03096
   Tseng H. Y., 2020, ICLR
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinyals O, 2016, 30 C NEURAL INFORM P, V29
   Wah C, 2011, CALTECH UCSD BIRDS 2
   Wang X, 2023, IEEE T CIRC SYST VID, V33, P5932, DOI 10.1109/TCSVT.2023.3262670
   Wang Y, 2019, Arxiv, DOI arXiv:1911.04623
   Wertheimer D, 2021, PROC CVPR IEEE, P8008, DOI 10.1109/CVPR46437.2021.00792
   Xu J, 2018, AAAI CONF ARTIF INTE, P7436
   Yaoyao Liu, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P404, DOI 10.1007/978-3-030-58517-4_24
   Ye Han-Jia, 2022, IEEE Trans Pattern Anal Mach Intell
   Yonglong Tian, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P266, DOI 10.1007/978-3-030-58568-6_16
   Zhang T, 2024, Arxiv, DOI arXiv:2305.18970
   Zinkevich M., 2010, Advances in neural information processing systems, P23
NR 50
TC 1
Z9 1
U1 3
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2024
VL 141
AR 104869
DI 10.1016/j.imavis.2023.104869
EA DEC 2023
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CX5E3
UT WOS:001128537000001
DA 2024-07-18
ER

PT J
AU Wu, YM
   Cen, LH
   Kan, SC
   Xie, YF
AF Wu, Yuming
   Cen, Lihui
   Kan, Shichao
   Xie, Yongfang
TI Multi-layer capsule network with joint dynamic routing for fire
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fire recognition; Multi-layer capsule network; Joint dynamic routing
   algorithm; Two-step training strategy
ID FLAME DETECTION; SYSTEM
AB Fire recognition has emerged as a critical concern in the field of fire safety. Deep learning techniques, specifically convolutional neural networks (CNNs), have found widespread application in fire recognition tasks. The capsule network, a higher-level variant of CNN, offers distinct advantages in terms of enhanced recognition accuracy, making it suitable for fire recognition applications. However, the capsule network faces challenges in effectively determining the presence or absence of fire objects due to the idiosyncrasies of its dynamic routing algorithm. To address this issue and enable effective fire recognition, we propose a novel approach that involves a multi-layer capsule network. Within this framework, we introduce a joint dynamic routing algorithm that computes output values during forward propagation within the multi-layer capsule network. Additionally, we present a new loss function and a fully connected auxiliary training layer designed to train the multi-layer capsule networks effectively. Comparative evaluations against conventional CNN architectures and recent state-of-the-art fire recognition methods demonstrate that the enhanced multi-layer capsule network achieves higher test accuracy, even with limited training samples and fewer training iterations. Furthermore, owing to its reduced model parameter scale, the multi-layer capsule network exhibits faster recognition speeds compared to the aforementioned methods.
C1 [Wu, Yuming; Cen, Lihui; Xie, Yongfang] Cent South Univ, Sch Automat, Changsha 410083, Hunan, Peoples R China.
   [Kan, Shichao] Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Hunan, Peoples R China.
C3 Central South University; Central South University
RP Kan, SC (corresponding author), Cent South Univ, Sch Comp Sci & Engn, Changsha 410083, Hunan, Peoples R China.
EM yumingwu@csu.edu.cn; lhcen@csu.edu.cn; kanshichao@csu.edu.cn;
   yfxie@csu.edu.cn
FU Key Program of the National Natural Science Foundation of China
   [62233018]; National Natural Science Foundation of China [62202499];
   Key- Area Research and Development Program of Guangdong
   [2021B0101200005]; Natural Science Foundation of Hunan Province, China
   [2021JJ30862, 2022JJ40632]; High Performance Computing Center of Central
   South University
FX This work was supported by the Key Program of the National Natural
   Science Foundation of China under Grants 62233018, the National Natural
   Science Foundation of China under Grants 62202499, the Key- Area
   Research and Development Program of Guangdong under Grant
   2021B0101200005, the Natural Science Foundation of Hunan Province, China
   under Grant 2021JJ30862 and 2022JJ40632. We are grateful to the High
   Performance Computing Center of Central South University for partial
   support of this work.
CR Afshar P, 2020, IEEE ENG MED BIO, P1075, DOI [10.1109/EMBC44109.2020.9175922, 10.1109/embc44109.2020.9175922]
   Ali A.E.A., 2023, J. Image Proc. Intellig. Rem. Sens., V3, P1
   Angayarkkani K, 2009, INT J COMPUT SCI NET, V9, P100
   Anupama M. A., 2019, 2019 International Conference on Communication and Signal Processing (ICCSP), P0143, DOI 10.1109/ICCSP.2019.8698043
   Borges P.V.K., 2008, 2008 16 EUR SIGN PRO, P1
   Celik T, 2007, J VIS COMMUN IMAGE R, V18, P176, DOI 10.1016/j.jvcir.2006.12.003
   Çelik T, 2009, FIRE SAFETY J, V44, P147, DOI 10.1016/j.firesaf.2008.05.005
   Changwoo Ha, 2012, 2012 Sixth International Conference on Complex, Intelligent, and Software Intensive Systems (CISIS), P526, DOI 10.1109/CISIS.2012.25
   Chino DYT, 2015, SIBGRAPI, P95, DOI 10.1109/SIBGRAPI.2015.19
   Dong Z., 2020, 2019 IEEE 4 ADV INF, V1, P1023, DOI [10.1109/IAEAC47372.2019.8997743, DOI 10.1109/IAEAC47372.2019.8997743]
   Farhadi A., 1804, Comp. Vision Patt. Recognit., V2018
   Fatichah C, 2019, 2019 1ST INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND DATA SCIENCES (AIDAS2019), P100, DOI [10.1109/AiDAS47888.2019.8970957, 10.1109/aidas47888.2019.8970957]
   Foo SY, 1996, KNOWL-BASED SYST, V9, P531, DOI 10.1016/S0950-7051(96)00005-6
   Frizzi S, 2016, IEEE IND ELEC, P877, DOI 10.1109/IECON.2016.7793196
   Geng Qing-tian, 2014, Journal of Jilin University (Engineering and Technology Edition), V44, P1787, DOI 10.13229/j.cnki.jdxbgxb201406038
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Habiboglu YH, 2012, MACH VISION APPL, V23, P1103, DOI 10.1007/s00138-011-0369-1
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Healey G., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P605, DOI 10.1109/CVPR.1993.341064
   Ko BC, 2011, IEEE T CIRC SYST VID, V21, P1903, DOI 10.1109/TCSVT.2011.2157190
   Ko BC, 2009, FIRE SAFETY J, V44, P322, DOI 10.1016/j.firesaf.2008.07.006
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li P, 2020, CASE STUD THERM ENG, V19, DOI 10.1016/j.csite.2020.100625
   Li SB, 2020, IEEE T IMAGE PROCESS, V29, P8467, DOI 10.1109/TIP.2020.3016431
   Liu ZG, 2016, SIGNAL IMAGE VIDEO P, V10, P277, DOI 10.1007/s11760-014-0738-0
   Mao WT, 2018, FIRE TECHNOL, V54, P531, DOI 10.1007/s10694-017-0695-6
   [毛文涛 Mao Wentao], 2016, [计算机应用, Journal of Computer Applications], V36, P2907
   Mobiny A, 2020, IEEE T MED IMAGING, V39, P1, DOI 10.1109/TMI.2019.2918181
   Mueller M, 2013, IEEE T IMAGE PROCESS, V22, P2786, DOI 10.1109/TIP.2013.2258353
   Muhammad K, 2020, IEEE NETWORK, V34, P108, DOI 10.1109/MNET.011.1900257
   Muhammad K, 2019, IEEE T IND INFORM, V15, P3113, DOI 10.1109/TII.2019.2897594
   Muhammad K, 2019, IEEE T SYST MAN CY-S, V49, P1419, DOI 10.1109/TSMC.2018.2830099
   Muhammad K, 2018, NEUROCOMPUTING, V288, P30, DOI 10.1016/j.neucom.2017.04.083
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabour S, 2017, ADV NEUR IN, V30
   Shag Liangshan, 2015, Journal of Computer Applications, V35, P1483, DOI 10.11772/j.issn.1001-9081.2015.05.1483
   Shamsoshoara A, 2021, COMPUT NETW, V193, DOI 10.1016/j.comnet.2021.108001
   Sharma J, 2017, COMM COM INF SC, V744, P183, DOI 10.1007/978-3-319-65172-9_16
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PR MACH LEARN RES, V97
   Torabian M, 2019, IRAN CONF ELECTR ENG, P1260, DOI [10.1109/iraniancee.2019.8786704, 10.1109/IranianCEE.2019.8786704]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Wang Z., 2017, International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences, V42, P925, DOI [10.5194/isprs-archives-XLII-2-W7-925-2017, DOI 10.5194/ISPRS-ARCHIVES-XLII-2-W7-925-2017]
   Xi ED, 2017, Arxiv, DOI [arXiv:1712.03480, 10.48550/arXiv.1712.03480]
   Xiang CQ, 2018, IEEE SIGNAL PROC LET, V25, P1850, DOI 10.1109/LSP.2018.2873892
   Xiong Y., 2019, IEEE IJCNN, P1, DOI DOI 10.1109/ijcnn.2019.8852020
NR 51
TC 2
Z9 2
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2023
VL 139
AR 104825
DI 10.1016/j.imavis.2023.104825
EA OCT 2023
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA W0LW7
UT WOS:001088641700001
DA 2024-07-18
ER

PT J
AU Liu, K
   Liang, YQ
AF Liu, Ke
   Liang, Yongquan
TI Enhancement method for non-uniform scattering images of turbid
   underwater based on neural network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual quality enhancement; Underwater optical image; Background light;
   Convolutional neural network; Image enhancement
ID BACKGROUND LIGHT
AB Due to the influence of light absorption and scattering in the water medium, underwater images often appear with different degrees of blur, color distortion, and so on. The physical model-based method needs to establish image degradation processes and improve image quality by assuming and estimating complex parameters, which limits the generalization ability and practical application effect of these methods. To solve the above problems, this paper proposes an image enhancement method of non-uniform scattering in turbid underwater based on neural network. First, the high-frequency and low-frequency components of underwater images were obtained through the difference of gaussian (DOG) and bilateral filtering (BF), respectively. Then, for the high-frequency component, pulse coupled neural networks (PCNN) to improve the edge details of the image. For low-frequency components, it is carried out in two steps: an adaptive automatic white balance and polynomial regression (AAWBPR) algorithm is proposed, which can effectively eliminate the color bias under different color temperatures and improve the brightness of images; the adaptive color and contrast enhancement (ACCE) method is used to further enhance the color and contrast of images. Finally, Decom-Net and the improved U-Net method are used to reduce the errors caused by the non-uniform scattering effect, weaken the noise interference, and enhance the overall effect of images. Extensive experiments show that the proposed method can effectively improve the quality of turbid underwater non-uniform scattering images, enhance the contrast of images, reduce the complexity of parameters, and has good generalization performance and practical application effects.
C1 [Liu, Ke; Liang, Yongquan] Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
C3 Shandong University of Science & Technology
RP Liang, YQ (corresponding author), Shandong Univ Sci & Technol, Coll Comp Sci & Engn, Qingdao 266590, Peoples R China.
EM lyq@sdust.edu.cn
FU National Natural Science Foundation of China [91746100]; National Key
   Research and Development Program of China [2017YFC0804406]
FX This work was supported in part by the National Natural Science
   Foundation of China under Grant 91746100 and in part by the National Key
   Research and Development Program of China under Grant 2017YFC0804406. We
   are very grateful to the teachers and students who provided help and
   support for this paper and to the project funders for their support of
   this paper.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Ancuti C, 2012, PROC CVPR IEEE, P81, DOI 10.1109/CVPR.2012.6247661
   [Anonymous], 2017, INT C INT MULT COMP
   Carlevaris-Bianco N, 2010, OCEANS-IEEE
   Chen RZ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3134762
   Chiang JY, 2012, IEEE T IMAGE PROCESS, V21, P1756, DOI 10.1109/TIP.2011.2179666
   Drews PLJ, 2016, IEEE COMPUT GRAPH, V36, P24, DOI 10.1109/MCG.2016.26
   Eckhorn R, 1990, NEURAL COMPUT, V2, P293, DOI 10.1162/neco.1990.2.3.293
   Fabbri C, 2018, IEEE INT CONF ROBOT, P7159
   Fu XY, 2014, IEEE IMAGE PROC, P4572, DOI 10.1109/ICIP.2014.7025927
   Ge R., 2022, Semiconductor Optoelectron, V43, P377
   Guo YC, 2020, IEEE J OCEANIC ENG, V45, P862, DOI 10.1109/JOE.2019.2911447
   Haoran Xu, 2012, 2012 IEEE International Conference on Information Science and Technology, P663, DOI 10.1109/ICIST.2012.6221729
   He K., 2019, Image Fusion and Enhancement Based on Pulse Coupled Neural Network and Multi-Feature Analysis
   He KM, 2011, IEEE T PATTERN ANAL, V33, P2341, DOI 10.1109/TPAMI.2010.168
   Hou GJ, 2020, IEEE ACCESS, V8, P122078, DOI 10.1109/ACCESS.2020.3006359
   Hu Z., 2022, J. Nankai Univ. (Nat. Sci. Ed.), V55
   Huang DM, 2018, LECT NOTES COMPUT SC, V10704, P453, DOI 10.1007/978-3-319-73603-7_37
   Izonin Ivan, 2015, 2015 Xth International Scientific and Technical Conference - Computer Sciences and Information Technologies (CSIT). Proceedings, P25, DOI 10.1109/STC-CSIT.2015.7325423
   Jin R., 2021, Research on Underwater Image Restoration Algorithm Based on Suppression of Non-uniform Scattering Effect
   JOHNSON JL, 1993, OPT LETT, V18, P1253, DOI 10.1364/OL.18.001253
   Johnson JL, 1999, IEEE T NEURAL NETWOR, V10, P480, DOI 10.1109/72.761706
   Kappeler A, 2016, IEEE T COMPUT IMAG, V2, P109, DOI 10.1109/TCI.2016.2532323
   Lei T, 2019, IEEE T FUZZY SYST, V27, P1753, DOI 10.1109/TFUZZ.2018.2889018
   Li CY, 2021, IEEE T IMAGE PROCESS, V30, P4985, DOI 10.1109/TIP.2021.3076367
   Li CY, 2020, IEEE T IMAGE PROCESS, V29, P4376, DOI 10.1109/TIP.2019.2955241
   Li CY, 2020, PATTERN RECOGN, V98, DOI 10.1016/j.patcog.2019.107038
   Li J, 2018, IEEE ROBOT AUTOM LET, V3, P387, DOI 10.1109/LRA.2017.2730363
   Li X., 2021, Research on Sharpening Enhancement of Underwater Image
   Liang Z, 2021, NEUROCOMPUTING, V425, P160, DOI 10.1016/j.neucom.2020.03.091
   Liu K, 2021, OPT EXPRESS, V29, P28307, DOI 10.1364/OE.428626
   Liu K, 2021, OPT EXPRESS, V29, P10321, DOI 10.1364/OE.413164
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lv XQ, 2021, SIGNAL PROCESS-IMAGE, V99, DOI 10.1016/j.image.2021.116466
   MCCOLLOUGH C, 1955, J EXP PSYCHOL, V49, P141, DOI 10.1037/h0047238
   Panetta K, 2016, IEEE J OCEANIC ENG, V41, P541, DOI 10.1109/JOE.2015.2469915
   Peng YT, 2018, IEEE T IMAGE PROCESS, V27, P2856, DOI 10.1109/TIP.2018.2813092
   Peng YT, 2017, IEEE T IMAGE PROCESS, V26, P1579, DOI 10.1109/TIP.2017.2663846
   Qiu XD, 2018, OPTICA, V5, P208, DOI 10.1364/OPTICA.5.000208
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi MH, 2009, MACH VISION APPL, V20, P131, DOI 10.1007/s00138-007-0113-z
   Song W, 2020, IEEE T BROADCAST, V66, P153, DOI 10.1109/TBC.2019.2960942
   Song W, 2018, LECT NOTES COMPUT SC, V11164, P678, DOI 10.1007/978-3-030-00776-8_62
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Xiao JJ, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3101848
   Xu S, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107822
   Yang M, 2015, IEEE T IMAGE PROCESS, V24, P6062, DOI 10.1109/TIP.2015.2491020
   Yang WH, 2021, IEEE T IMAGE PROCESS, V30, P2072, DOI 10.1109/TIP.2021.3050850
   Yashtini M, 2016, SIAM J IMAGING SCI, V9, P1552, DOI 10.1137/16M1063757
   Yin XY, 2021, LECT NOTES COMPUT SC, V12893, P421, DOI 10.1007/978-3-030-86365-4_34
   Zeng LC, 2021, ENG APPL ARTIF INTEL, V100, DOI 10.1016/j.engappai.2021.104190
   Zhang B, 2008, IEEE T IMAGE PROCESS, V17, P664, DOI 10.1109/TIP.2008.919949
   Zhang H., 2011, Research on Image Denoising and Image Enhancement Method Based on PCNN
   Zhang WD, 2022, IEEE T IMAGE PROCESS, V31, P3997, DOI 10.1109/TIP.2022.3177129
   Zhao SY, 2021, IEEE T IMAGE PROCESS, V30, P3391, DOI 10.1109/TIP.2021.3060873
   Zhou R., 2005, J. Comput. Aid. Des. Comput. Graph., V3, P529
   Zhou ZW, 2020, IEEE T MED IMAGING, V39, P1856, DOI 10.1109/TMI.2019.2959609
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhuang PX, 2022, IEEE T IMAGE PROCESS, V31, P5442, DOI 10.1109/TIP.2022.3196546
NR 60
TC 0
Z9 0
U1 5
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2023
VL 138
AR 104813
DI 10.1016/j.imavis.2023.104813
EA SEP 2023
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA T5TN2
UT WOS:001078613200001
DA 2024-07-18
ER

PT J
AU Borji, A
AF Borji, Ali
TI Qualitative failures of image generation models and their application in
   detecting deepfakes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Generative models; Image and video generation; Qualitative failures;
   Deepfakes; Image forensics; Object and scene recognition; Neural
   networks; Deep learning
ID FORENSICS
AB The remarkable advancement of image and video generation models has led to the creation of exceptionally realistic content, posing challenges in differentiating between genuine and fabricated instances in numerous scenarios. However, despite this progress, a gap remains between the quality of generated images and those found in the real world. To address this, we have reviewed a vast body of literature from both academic publications and social media to identify qualitative shortcomings in image generation models, which we have classified into five categories. By understanding these failures, we can identify areas where these models need improvement, as well as develop strategies for detecting generated images and deepfakes. The prevalence of deepfakes in today's society is a serious concern, and our findings can help mitigate their negative impact. In order to support research in this field, a collection of instances where models have failed is made available at here.
C1 [Borji, Ali] Quintic AI, Los Angeles, CA 90089 USA.
RP Borji, A (corresponding author), Quintic AI, Los Angeles, CA 90089 USA.
EM aliborji@gmail.com
CR Afchar D, 2018, IEEE INT WORKS INFOR
   Assogba Y., 2023, arXiv
   Bohácek M, 2022, P NATL ACAD SCI USA, V119, DOI [10.1073/pnas.2107266119, 10.1073/pnas.2216035119]
   Borji A, 2023, Arxiv, DOI [arXiv:2302.03494, 10.48550/arXiv.2302.03494, DOI 10.48550/ARXIV.2302.03494]
   Borji A, 2022, Arxiv, DOI [arXiv:2210.00586, 10.48550/arXiv.2210.00586]
   Borji A, 2022, COMPUT VIS IMAGE UND, V215, DOI 10.1016/j.cviu.2021.103329
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Chen Yixin, 2005, ADV DIGITAL FORENSIC, V1, P271
   Chesney B, 2019, CALIF LAW REV, V107, P1753, DOI 10.15779/Z38RV0D15J
   Cozzolino D, 2019, Arxiv, DOI arXiv:1812.02510
   Dragar L, 2023, Arxiv, DOI arXiv:2306.05985
   Fridrich J, 2009, IEEE SIGNAL PROC MAG, V26, P26, DOI 10.1109/MSP.2008.931078
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Güera D, 2018, 2018 15TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE (AVSS), P127
   Hensel M, 2017, ADV NEUR IN, V30
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Kee E, 2011, IEEE T INF FOREN SEC, V6, P1066, DOI 10.1109/TIFS.2011.2128309
   Lazer DMJ, 2018, SCIENCE, V359, P1094, DOI 10.1126/science.aao2998
   Li YZ, 2019, Arxiv, DOI arXiv:1811.00656
   Lukás J, 2006, IEEE T INF FOREN SEC, V1, P205, DOI 10.1109/TIFS.2006.873602
   Marcus G., 2022, arXiv, DOI [DOI 10.48550/ARXIV.2204.13807, 10.48550/arXiv.2204.13807]
   Mo HX, 2018, PROCEEDINGS OF THE 6TH ACM WORKSHOP ON INFORMATION HIDING AND MULTIMEDIA SECURITY (IH&MMSEC'18), P43, DOI 10.1145/3206004.3206009
   Nataraj L, 2019, Arxiv, DOI arXiv:1903.06836
   Radford A, 2021, PR MACH LEARN RES, V139
   Ramesh A., 2022, arXiv, DOI 10.48550/arXiv.2204.06125
   Ramesh A, 2021, PR MACH LEARN RES, V139
   Redi JA, 2011, MULTIMED TOOLS APPL, V51, P133, DOI 10.1007/s11042-010-0620-1
   Saharia C., 2022, Advances in Neural Information Processing Systems, V35, P36479
   Sajjadi MSM, 2018, ADV NEUR IN, V31
   Salimans T, 2016, ADV NEUR IN, V29
   Nguyen TT, 2022, COMPUT VIS IMAGE UND, V223, DOI 10.1016/j.cviu.2022.103525
   Verdoliva L, 2020, IEEE J-STSP, V14, P910, DOI 10.1109/JSTSP.2020.3002101
   Wang O., 2020, PROC IEEECVF C COMPU, V7, P8695
   Wang ZJ, 2022, Arxiv, DOI [arXiv:2210.14896, DOI 10.48550/ARXIV.2210.14896]
   Yu JH, 2022, Arxiv, DOI [arXiv:2206.10789, 10.48550/arXiv.2206.10789]
   Zeng Y, 2017, arXiv
NR 36
TC 1
Z9 1
U1 6
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104771
DI 10.1016/j.imavis.2023.104771
EA JUL 2023
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA P6CE7
UT WOS:001051527200001
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Guan, QJ
   Li, ZZ
   Zhang, JY
   Huang, YP
   Zhao, Y
AF Guan, Qingji
   Li, Zhuangzhuang
   Zhang, Jiayu
   Huang, Yaping
   Zhao, Yao
TI Joint representation and classifier learning for long-tailed image
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Long-tailed image classification; Representation learning; Classifier
   learning; Supervised contrastive learning
ID THORAX DISEASE CLASSIFICATION
AB Long-tailed classification with fine-grained appearance, e.g., in chest X-ray images, is very challenging due to the very similar appearance and imbalanced distribution between normal and abnormal samples, which extremely limits the ability of deep networks to learn powerful representations and discriminative classifiers. In this paper, we propose a novel Joint Representation and Classifier Learning (JRCL) framework to achieve the above purposes, simultaneously. In terms of representation learning, we propose a One-to-All supervised contrastive learning strategy to avoid the medium or tail classes mixing in the head classes. For the classifier cleaning, we propose a novel Binary Distribution Consistency (BDC) loss to learn a discriminative classifier that could separate the normal and abnormal samples.The BDC loss measures the binary distribution consistency between the designed multi-class classifier and an auxiliary binary classifier. Consequently, the JRCL framework is optimized with a supervised contrastive learning loss, a binary distribution consistency loss, and a multi-classification loss. We conduct experiments on large-scale, long-tail image datasets, NIH-CXR-LT, MIMIC-CXR-LT, iNaturalist 2018, and Places-LT. Experimental results demonstrate JRCL could improve the discriminate ability of the imbalanced data and thus obtain better classification performance. Compared with the state-of-the-art methods, our proposed JRCL achieves comparable or even better performance. The source codes are available at https://github. com/guanqj932/JRCL.
C1 [Guan, Qingji; Li, Zhuangzhuang; Zhang, Jiayu; Huang, Yaping] Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, 3 Shangyuancun, Beijing 100044, Peoples R China.
   [Zhao, Yao] Beijing Jiaotong Univ, Inst Informat Sci, 3 Shangyuancun, Beijing 100044, Peoples R China.
C3 Beijing Jiaotong University; Beijing Jiaotong University
RP Guan, QJ (corresponding author), Beijing Jiaotong Univ, Beijing Key Lab Traff Data Anal & Min, 3 Shangyuancun, Beijing 100044, Peoples R China.
EM qjguan@bjtu.edu.cn
RI Li, zhuangzhuang/JAD-1371-2023
CR [Anonymous], 2017 INT S BIOM IM I
   Branco P, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2907070
   Cao B, 2021, IEEE T KNOWL DATA EN, V33, P3550, DOI 10.1109/TKDE.2020.2974949
   Cao KD, 2019, ADV NEUR IN, V32
   Chen T, 2020, PR MACH LEARN RES, V119
   Cui Y, 2019, PROC CVPR IEEE, P9260, DOI 10.1109/CVPR.2019.00949
   Eyiokur FI, 2023, IMAGE VISION COMPUT, V130, DOI 10.1016/j.imavis.2022.104610
   Galdran A, 2021, LECT NOTES COMPUT SC, V12905, P323, DOI 10.1007/978-3-030-87240-3_31
   Guan QJ, 2021, IEEE T IMAGE PROCESS, V30, P2476, DOI 10.1109/TIP.2021.3052711
   Guan QJ, 2020, PATTERN RECOGN LETT, V131, P38, DOI 10.1016/j.patrec.2019.11.040
   Guan QJ, 2020, PATTERN RECOGN LETT, V130, P259, DOI 10.1016/j.patrec.2018.10.027
   Guo HX, 2017, EXPERT SYST APPL, V73, P220, DOI 10.1016/j.eswa.2016.12.035
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holste G, 2022, LECT NOTES COMPUT SC, V13567, P22, DOI 10.1007/978-3-031-17027-0_3
   Japkowicz N., 2002, Intelligent Data Analysis, V6, P429
   Johnson AEW, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0322-0
   Ju L, 2021, LECT NOTES COMPUT SC, V12908, P3, DOI 10.1007/978-3-030-87237-3_1
   Kaiming He, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9726, DOI 10.1109/CVPR42600.2020.00975
   Kang Bingyi, 2020, 8 INT C LEARN REPR I
   Khosla P., 2020, ADV NEURAL INF PROCE, V33, P18661
   Kim Y, 2021, PATTERN RECOGN LETT, V151, P33, DOI 10.1016/j.patrec.2021.07.017
   Li J, 2022, PROC CVPR IEEE, P6939, DOI 10.1109/CVPR52688.2022.00682
   Li SH, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P1241
   Li TH, 2022, PROC CVPR IEEE, P6908, DOI 10.1109/CVPR52688.2022.00679
   Lin TY, 2017, IEEE I CONF COMP VIS, P2999, DOI 10.1109/ICCV.2017.324
   Liu MM, 2022, LECT NOTES COMPUT SC, V13432, P109, DOI 10.1007/978-3-031-16434-7_11
   Liu ZW, 2019, PROC CVPR IEEE, P2532, DOI 10.1109/CVPR.2019.00264
   Mehta D, 2022, LECT NOTES COMPUT SC, V13431, P732, DOI 10.1007/978-3-031-16431-6_69
   Read J, 2011, MACH LEARN, V85, P333, DOI 10.1007/s10994-011-5256-5
   Soda P, 2011, PATTERN RECOGN, V44, P1801, DOI 10.1016/j.patcog.2011.01.015
   Tang YX, 2018, LECT NOTES COMPUT SC, V11046, P249, DOI 10.1007/978-3-030-00919-9_29
   Tian CY, 2022, LECT NOTES COMPUT SC, V13685, P73, DOI 10.1007/978-3-031-19806-9_5
   Trokielewicz M, 2020, IMAGE VISION COMPUT, V94, DOI 10.1016/j.imavis.2019.103866
   Van Horn G, 2017, REPTILIA, V32, P1
   Wang P, 2021, PROC CVPR IEEE, P943, DOI 10.1109/CVPR46437.2021.00100
   Wang Xiao, 2022, IEEE T PATTERN ANAL, V2
   Wang XS, 2018, PROC CVPR IEEE, P9049, DOI 10.1109/CVPR.2018.00943
   Wang XS, 2017, PROC CVPR IEEE, P3462, DOI 10.1109/CVPR.2017.369
   Wang Y.X., 2017, Adv. Neural Inf. Process. Syst., V30
   Wu PS, 2022, IMAGE VISION COMPUT, V117, DOI 10.1016/j.imavis.2021.104341
   Yang ZX, 2022, LECT NOTES COMPUT SC, V13438, P173, DOI 10.1007/978-3-031-16452-1_17
   Yao L., 2022, IEEE T MULTIMED
   Yin X, 2019, PROC CVPR IEEE, P5697, DOI 10.1109/CVPR.2019.00585
   Zhang P, 2021, IEEE T MULTIMEDIA, V23, P3562, DOI 10.1109/TMM.2020.3028461
   Zhe L, 2018, PROC CVPR IEEE, P8290, DOI 10.1109/CVPR.2018.00865
   Zhou Q, 2022, LECT NOTES COMPUT SC, V13432, P709, DOI 10.1007/978-3-031-16434-7_68
   Zhu JG, 2022, PROC CVPR IEEE, P6898, DOI 10.1109/CVPR52688.2022.00678
NR 47
TC 2
Z9 2
U1 5
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2023
VL 137
AR 104759
DI 10.1016/j.imavis.2023.104759
EA JUL 2023
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA O1VU0
UT WOS:001041774200001
OA Bronze
DA 2024-07-18
ER

PT J
AU Kolluri, J
   Das, R
AF Kolluri, Johnson
   Das, Ranjita
TI Intelligent multimodal pedestrian detection using hybrid metaheuristic
   optimization with deep learning model
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Pedestrian detection; Metaheuristics; Deep learning; YOLO-v5; Hybrid
   algorithms; Machine learning
ID NETWORK
AB For video surveillance, pedestrian detection assists in providing baseline data for crowd monitoring, people counting, and event detection; for smart transport system, pedestrian detection acts as a vital part in the semantic understanding of the environment. Pedestrian detection is frequently confronted with substantial intra-class variability because human tends to have great variation in human appearance and pose. Currently, the emergence of deep learning (DL) model has received considerable attention in computer vision techniques like object detection and object classification, and this application is based on supervised learning which required labels. Convolution neural networks (CNN) have assisted substantial improvement in pedestrian recognition due to the stronger representative capability of the CNN feature. But it is usually hard to decrease false positives on hard negative samples namely poles, tree leaves, traffic lights, and so on. Therefore, this study develops an intelligent multimodal pedestrian detection and classification using hybrid metaheuristic optimization with deep learning (IPDCHMODL) algorithm. The major aim of the presented IPDC-HMODL model is the recognition and classification of multiple pedestrians exist in the input frames. It follows a three stage process namely multimodal object detection, pedestrian classification, and parameter tuning. At the initial stage, the IPDC-HMODL model uses multimodal object detector using YOLO-v5 and RetinaNet model. In addition, the IPDC-HMODL model applies kernel extreme learning machine (KELM) algorithm for pedestrian classification. Finally, hybrid salp swarm optimization (HSSO) model is used for optimal parameter adjustment. To depict the improvised outcomes of the IPDC-HMODL technique, a wide spread simulation analysis was conducted. The comparison study highlighted the enhanced outcomes of the IPDC-HMODL model over other approaches on multimodal pedestrian detection. & COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Kolluri, Johnson] Natl Inst Technol Mizoram, Dept CSE, Aizwal, Mizoram, India.
   [Das, Ranjita] Natl Inst Technol Agartala, Dept CSE, Agartala, India.
C3 National Institute of Technology (NIT System); National Institute of
   Technology Mizoram; National Institute of Technology (NIT System);
   National Institute of Technology Agartala
RP Kolluri, J (corresponding author), Natl Inst Technol Mizoram, Dept CSE, Aizwal, Mizoram, India.
EM johnson.kolluri12@outlook.com; ranjita.nitm@gmail.com
OI Das, Ranjita/0000-0001-6184-6294
CR [Anonymous], 2014, INT J ELECT COMMUN C
   Brazil G, 2019, PROC CVPR IEEE, P7224, DOI 10.1109/CVPR.2019.00740
   Camara F, 2021, IEEE T INTELL TRANSP, V22, P5453, DOI 10.1109/TITS.2020.3006767
   Chen L, 2022, CITIES, V127, DOI 10.1016/j.cities.2022.103734
   Chen L, 2020, COMPUT ENVIRON URBAN, V81, DOI 10.1016/j.compenvurbsys.2020.101481
   Dasgupta K, 2022, IEEE T INTELL TRANSP, V23, P15940, DOI 10.1109/TITS.2022.3146575
   Elallid B.B, 2022, Computational intelligence in recent communication networks, P135
   Fabbri M., 2021, P IEEE CVF INT C COM, p10 849
   Fang Y, 2021, BIORESOURCES, V16
   Gauerhof Lydia, 2020, Computer Safety, Reliability, and Security. 39th International Conference, SAFECOMP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12234), P197, DOI 10.1007/978-3-030-54549-9_13
   Hasan R, 2022, FUTURE GENER COMP SY, V134, P187, DOI 10.1016/j.future.2022.03.036
   Hou Q, 2020, TRANSPORT RES C-EMER, V119, DOI 10.1016/j.trc.2020.102772
   Jain DK, 2023, J ELECTRON IMAGING, V32, DOI 10.1117/1.JEI.32.1.011211
   Kassaymeh S, 2022, J KING SAUD UNIV-COM, V34, P3365, DOI 10.1016/j.jksuci.2021.01.015
   Kavitha M, 2022, INTELL AUTOM SOFT CO, V34, P1571, DOI 10.32604/iasc.2022.026385
   Khan MA, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2020.106960
   Kumar PM, 2022, COMPUT ELECTR ENG, V100, DOI 10.1016/j.compeleceng.2022.107987
   Le VT, 2023, APPL INTELL, V53, P3240, DOI 10.1007/s10489-022-03613-1
   Liu SY, 2020, NEUROCOMPUTING, V401, P123, DOI 10.1016/j.neucom.2020.02.094
   Neelakandan S, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/2163458
   Neelakandan S, 2022, INTELL AUTOM SOFT CO, V32, P1617, DOI 10.32604/iasc.2022.022209
   Pustokhina IV, 2021, SAFETY SCI, V142, DOI 10.1016/j.ssci.2021.105356
   Razali H, 2021, TRANSPORT RES C-EMER, V130, DOI 10.1016/j.trc.2021.103259
   Reshma G, 2022, INTELL AUTOM SOFT CO, V31, P621, DOI 10.32604/iasc.2022.019117
   Saeidi M, 2022, VISUAL COMPUT, V38, P2223, DOI 10.1007/s00371-021-02280-6
   Sreekala K, 2022, WIREL COMMUN MOB COM, V2022, DOI 10.1155/2022/2086613
   Sunitha G, 2022, IMAGE VISION COMPUT, V121, DOI 10.1016/j.imavis.2022.104404
   Wang W, 2021, EUR J REMOTE SENS, V54, P65, DOI 10.1080/22797254.2020.1755998
   Wang Y, 2022, J INTERCONNECT NETW, V22, DOI 10.1142/S0219265921440047
   Wu CK, 2022, CLUSTER COMPUT, V25, P2715, DOI 10.1007/s10586-021-03439-5
   Xu YY, 2018, PROC CVPR IEEE, P5275, DOI 10.1109/CVPR.2018.00553
   Zhang H, 2021, IEEE WINT CONF APPL, P72, DOI 10.1109/WACV48630.2021.00012
   Zhang L, 2019, INFORM FUSION, V50, P20, DOI 10.1016/j.inffus.2018.09.015
   Zhishuai Zhang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11343, DOI 10.1109/CVPR42600.2020.01136
NR 34
TC 9
Z9 9
U1 8
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2023
VL 131
AR 104628
DI 10.1016/j.imavis.2023.104628
EA JAN 2023
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA L8AS9
UT WOS:001025439000001
DA 2024-07-18
ER

PT J
AU Wang, XZ
   Chen, SW
   Wei, GY
   Liu, JH
AF Wang, Xingzheng
   Chen, Songwei
   Wei, Guoyao
   Liu, Jiehao
TI TENet: Accurate light-field salient object detection with a transformer
   embedding network
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Light-field; Salient object detection; Transformer
AB Current light-field salient object detection methods have difficulty in accurately distinguishing objects from com-plex backgrounds. In this paper, we believe that this problem can be mitigated by optimizing feature fusion and enlarging receptive field, and thus propose a novel transformer embedding network named TENet. The main idea of the network is to (1) selectively aggregate multi-features for fuller feature fusion; (2) integrate the Trans-former for larger receptive field, so as to accurately identify salient objects. For the former, firstly, a multi -modal feature fusion module (MMFF) is designed to mine the different contributions of multi-modal features (i.e., all-in-focus image features and focal stack features). Then, a multi-level feature fusion module (MLFF) is de-veloped to iteratively select and fuse complementary cues from multi-level features. For the latter, we integrate the Transformer for the first time and propose a transformer-based feature enhancement module (TFE), to pro-vide a wider receptive field for each pixel of high-level features. To validate our idea, we comprehensively eval-uate the performance of our TENet on three challenging datasets. Experimental results show that our method outperforms the state-of-the-art method, e.g., the detection accuracy is improved by 28.1%, 20.3%, and 14.9% in MAE metric, respectively.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Wang, Xingzheng; Chen, Songwei; Wei, Guoyao; Liu, Jiehao] Shenzhen Univ, Coll Mechatron & Control Engn, Shenzhen 518060, Peoples R China.
C3 Shenzhen University
RP Wang, XZ (corresponding author), Shenzhen Univ, Coll Mechatron & Control Engn, Shenzhen 518060, Peoples R China.
EM xingzheng.wang@szu.edu.cn
RI Wei, Guoyao/HIA-0397-2022
FU Shenzhen Fundamental Re-search Fund; Natural Science Founda-tion of
   Guangdong Province;  [20200810150441003];  [JCYJ20190808143415801]; 
   [2020A1515011559];  [2021A1515012287]
FX Acknowledgment This work was supported in part by the Shenzhen
   Fundamental Re-search Fund under Grant 20200810150441003 and Grant
   JCYJ20190808143415801, and in part by the Natural Science Founda-tion of
   Guangdong Province under Grant 2020A1515011559 and Grant
   2021A1515012287.
CR Achanta R, 2009, PROC CVPR IEEE, P1597, DOI 10.1109/CVPRW.2009.5206596
   Chen JY, 2021, PROC CVPR IEEE, P12021, DOI 10.1109/CVPR46437.2021.01185
   Cui WZ, 2021, NEUROCOMPUTING, V445, P35, DOI 10.1016/j.neucom.2021.02.061
   Deng-Ping Fan, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12357), P275, DOI 10.1007/978-3-030-58610-2_17
   Fan DP, 2017, IEEE I CONF COMP VIS, P4558, DOI 10.1109/ICCV.2017.487
   Fan DP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P698
   Fu K, 2022, COMPUT VIS MEDIA, V8, P509, DOI 10.1007/s41095-021-0256-2
   Gao W, 2022, IEEE T CIRC SYST VID, V32, P2091, DOI 10.1109/TCSVT.2021.3082939
   Guo YN, 2018, NEUROCOMPUTING, V275, P2179, DOI 10.1016/j.neucom.2017.10.057
   Ji YZ, 2021, INFORM SCIENCES, V546, P835, DOI 10.1016/j.ins.2020.09.003
   Jiayao S., 2022, IEEE T MULTIMEDIA, P1
   Kingma D. P., 2014, arXiv
   Lawrence J, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3478513.3480490
   Lee S, 2021, PROC CVPR IEEE, P5491, DOI 10.1109/CVPR46437.2021.00545
   Lei S, 2022, IEEE T GEOSCI REMOTE, V60, DOI 10.1109/TGRS.2021.3136190
   Li NY, 2017, IEEE T PATTERN ANAL, V39, P1605, DOI 10.1109/TPAMI.2016.2610425
   Li NY, 2015, PROC CVPR IEEE, P5216, DOI 10.1109/CVPR.2015.7299158
   Li NY, 2014, PROC CVPR IEEE, P2806, DOI 10.1109/CVPR.2014.359
   Li XY, 2022, IEEE T COGN DEV SYST, V14, P246, DOI 10.1109/TCDS.2020.3048883
   Li XL, 2020, IEEE T IMAGE PROCESS, V29, P9165, DOI 10.1109/TIP.2020.3023774
   Liang YH, 2022, IMAGE VISION COMPUT, V118, DOI 10.1016/j.imavis.2021.104352
   Liang ZY, 2022, IEEE SIGNAL PROC LET, V29, P563, DOI 10.1109/LSP.2022.3146798
   Liu JJ, 2019, PROC CVPR IEEE, P3912, DOI 10.1109/CVPR.2019.00404
   Liu N, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4702, DOI 10.1109/ICCV48922.2021.00468
   Liu NA, 2020, IEEE T IMAGE PROCESS, V29, P6438, DOI 10.1109/TIP.2020.2988568
   Liu ZY, 2021, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA, MM 2021, P4481, DOI 10.1145/3474085.3475601
   Long J., 2015, P IEEE C COMP VIS PA, P3431, DOI DOI 10.48550/ARXIV.1411.4038
   Luo WF, 2021, PATTERN RECOGN, V115, DOI 10.1016/j.patcog.2021.107858
   Luo WJ, 2016, ADV NEUR IN, V29
   Ma MJ, 2022, APPL INTELL, V52, P10692, DOI 10.1007/s10489-021-03010-0
   Perazzi F, 2012, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2012.6247743
   Piao YR, 2023, IEEE T CYBERNETICS, V53, P379, DOI 10.1109/TCYB.2021.3095512
   Piao YR, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P904
   Piao YR, 2020, AAAI CONF ARTIF INTE, V34, P11865
   Piao YR, 2020, IEEE T IMAGE PROCESS, V29, P1879, DOI 10.1109/TIP.2019.2942434
   Ren QH, 2021, IEEE T MULTIMEDIA, V23, P1442, DOI 10.1109/TMM.2020.2997178
   Seo S, 2021, IEEE T CIRC SYST VID, V31, P2602, DOI 10.1109/TCSVT.2020.3030895
   Shao ZF, 2020, IEEE T CIRC SYST VID, V30, P781, DOI 10.1109/TCSVT.2019.2897980
   Siris A, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P4136, DOI 10.1109/ICCV48922.2021.00412
   Strudel R, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P7242, DOI 10.1109/ICCV48922.2021.00717
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang AZ, 2017, NEURAL PROCESS LETT, V46, P1083, DOI 10.1007/s11063-017-9610-x
   Wang GC, 2021, NEUROCOMPUTING, V458, P416, DOI 10.1016/j.neucom.2021.06.033
   Wang SZ, 2018, PROC CVPR IEEE, P2031, DOI 10.1109/CVPR.2018.00217
   Wang TT, 2019, IEEE I CONF COMP VIS, P8837, DOI 10.1109/ICCV.2019.00893
   Wang WG, 2022, IEEE T PATTERN ANAL, V44, P3239, DOI 10.1109/TPAMI.2021.3051099
   Wang XX, 2023, Arxiv, DOI arXiv:2112.01177
   Wang YH, 2021, IMAGE VISION COMPUT, V112, DOI 10.1016/j.imavis.2021.104216
   Wang ZY, 2022, NEURAL COMPUT APPL, V34, P11789, DOI 10.1007/s00521-022-07069-9
   Wei J, 2020, AAAI CONF ARTIF INTE, V34, P12321
   Wu KJ, 2019, IEEE DATA COMPR CONF, P608, DOI 10.1109/DCC.2019.00120
   Xue H, 2022, NEUROCOMPUTING, V468, P233, DOI 10.1016/j.neucom.2021.10.024
   Yan CG, 2022, IEEE T CIRC SYST VID, V32, P43, DOI 10.1109/TCSVT.2021.3067449
   Yan XY, 2022, IEEE WINT CONF APPL, P3270, DOI 10.1109/WACV51458.2022.00333
   Yang J, 2022, Appl Intell, P1
   Yu Q., 2021, arXiv
   Zhang J, 2020, IEEE T IMAGE PROCESS, V29, P4421, DOI 10.1109/TIP.2020.2970529
   Zhang J, 2017, ACM T MULTIM COMPUT, V13, DOI 10.1145/3107956
   Zhang J, 2015, PROCEEDINGS OF THE TWENTY-FOURTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE (IJCAI), P2212
   Zhang M, 2019, ADV NEUR IN, V32
   Zhang M, 2020, IEEE T IMAGE PROCESS, V29, P6276, DOI 10.1109/TIP.2020.2990341
   Zhang QD, 2021, IEEE T IMAGE PROCESS, V30, P7578, DOI 10.1109/TIP.2021.3108018
   Zhang QD, 2021, IEEE T CIRC SYST VID, V31, P1849, DOI 10.1109/TCSVT.2020.3013119
   Zhang Y., 2021, P BRIT MACHINE VISIO
   Zheng QP, 2022, NEUROCOMPUTING, V467, P465, DOI 10.1016/j.neucom.2021.10.007
   Zhou YE, 2021, IEEE INT CONF COMP V, P3132, DOI 10.1109/ICCVW54120.2021.00350
   Zhou ZK, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P9846, DOI 10.1109/ICCV48922.2021.00972
NR 67
TC 4
Z9 4
U1 4
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104595
DI 10.1016/j.imavis.2022.104595
EA DEC 2022
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7S6FQ
UT WOS:000910848000007
DA 2024-07-18
ER

PT J
AU Zhang, YS
   Zhang, YX
   Fan, LW
   Wang, NN
AF Zhang, Yongsheng
   Zhang, Yongxia
   Fan, Linwei
   Wang, Nannan
TI Fast and accurate superpixel segmentation algorithm with a guidance
   image
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Superpixel; Real-time; Guidance image; Accurate
AB Superpixels are generated by automatically grouping image pixels into lots and lots of compact segments. In com-puter vision, it is widely used as an effective way to reduce the number of image primitives for subsequent tasks and for recognizing objects' contours due to its excellent boundary adhesion. The primary concerns of a superpixel generation algorithm are its efficiency and accuracy. In this document, we aim to propose a fast and precise superpixel segmentation algorithm with a guidance image. Specifically, we introduce a rolling filter that can remove details while well preserving the boundaries to obtain the guidance image. In the meantime, we introduce a robust edge confidence operator to accurately detect image boundaries. From this, we define a distance measurement with adaptive parameters for each image. In this way, we can adapt and accurately group pixels into regions according to the new distance measurement. Furthermore, we adopt a noniterative framework to generate superpixels in real time by processing all pixels once. The experimental results show that the proposed methodology achieves state-of-the-art performance on two sets of reference data while oper-ating in real time.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Zhang, Yongsheng] Changchun Univ Sci & Technol, Sch Artificial Intelligence, Changchun, Peoples R China.
   [Zhang, Yongxia; Fan, Linwei] Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
   [Zhang, Yongxia; Fan, Linwei] Digital Media Technol Key Lab Shandong Prov, Jinan, Peoples R China.
   [Wang, Nannan] Shandong Management Univ, Dept Informat Engn, Jinan, Peoples R China.
C3 Changchun University of Science & Technology; Shandong University of
   Finance & Economics; Shandong Management University
RP Zhang, YS (corresponding author), Changchun Univ Sci & Technol, Sch Artificial Intelligence, Changchun, Peoples R China.; Zhang, YX (corresponding author), Shandong Univ Finance & Econ, Sch Comp Sci & Technol, Jinan, Peoples R China.
EM zys@cust.edu.cn; sdu_zyx@hotmail.com
RI Fan, Linwei/ABG-8736-2021
OI Fan, Linwei/0000-0001-9986-2396
FU Science and Technology Project of Jilin Provincial Department of
   Education; National Natural Science Foundation of China; Natural Science
   Foundation of Shandong Province; Shandong Provincial Science and
   Technology Sup- port Program of Youth Innovation Team in Colleges; 
   [JJKH20200798KJ];  [61802229];  [61873145];  [62002200];  [ZR2018BF007];
    [ZR2020QF012];  [2021KJ069]
FX Acknowledgements This work was supported by the ?Thirteenth Five -Year?
   Science and Technology Project of Jilin Provincial Department of
   Education (No. JJKH20200798KJ) , the National Natural Science Foundation
   of China (Grant Nos. 61802229, 61873145, 62002200) , the Natural Science
   Foundation of Shandong Province (Grant Nos. ZR2018BF007, ZR2020QF012) ,
   and Shandong Provincial Science and Technology Sup- port Program of
   Youth Innovation Team in Colleges (No. 2021KJ069) .
CR Achanta R, 2017, PROC CVPR IEEE, P4895, DOI 10.1109/CVPR.2017.520
   Achanta R, 2012, IEEE T PATTERN ANAL, V34, P2274, DOI 10.1109/TPAMI.2012.120
   Ban ZH, 2018, IEEE T IMAGE PROCESS, V27, P4105, DOI 10.1109/TIP.2018.2836306
   berkeley, PROJECTS VISION GROU
   Chen JS, 2017, IEEE T IMAGE PROCESS, V26, P3317, DOI 10.1109/TIP.2017.2651389
   Choi KS, 2016, COMPUT VIS IMAGE UND, V146, P1, DOI 10.1016/j.cviu.2016.02.018
   Conze PH, 2019, IMAGE VISION COMPUT, V89, P289, DOI 10.1016/j.imavis.2019.06.011
   Dong XP, 2016, IEEE T IMAGE PROCESS, V25, P516, DOI 10.1109/TIP.2015.2505184
   Dong XP, 2015, IEEE T IMAGE PROCESS, V24, P3966, DOI 10.1109/TIP.2015.2456636
   Fengting Yang, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13961, DOI 10.1109/CVPR42600.2020.01398
   Giraud R, 2018, COMPUT VIS IMAGE UND, V170, P1, DOI 10.1016/j.cviu.2018.01.006
   Hariharan B, 2011, IEEE I CONF COMP VIS, P991, DOI 10.1109/ICCV.2011.6126343
   He KM, 2013, IEEE T PATTERN ANAL, V35, P1397, DOI 10.1109/TPAMI.2012.213
   Kou F, 2015, IEEE T IMAGE PROCESS, V24, P4528, DOI 10.1109/TIP.2015.2468183
   Lee SH, 2017, PROC CVPR IEEE, P5863, DOI 10.1109/CVPR.2017.621
   Liang YL, 2016, IEEE T CIRC SYST VID, V26, P928, DOI 10.1109/TCSVT.2015.2406232
   Liu YJ, 2018, IEEE T PATTERN ANAL, V40, P653, DOI 10.1109/TPAMI.2017.2686857
   Liu YJ, 2016, PROC CVPR IEEE, P651, DOI 10.1109/CVPR.2016.77
   Machairas V, 2015, IEEE T IMAGE PROCESS, V24, P3707, DOI 10.1109/TIP.2015.2451011
   Oh KW, 2019, J REAL-TIME IMAGE PR, V16, P945, DOI 10.1007/s11554-016-0583-1
   Peng JT, 2016, IEEE T CIRC SYST VID, V26, P917, DOI 10.1109/TCSVT.2015.2430631
   Ren XF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P10
   Shen JB, 2016, IEEE T IMAGE PROCESS, V25, P5933, DOI 10.1109/TIP.2016.2616302
   Shen JB, 2014, IEEE T IMAGE PROCESS, V23, P1451, DOI 10.1109/TIP.2014.2302892
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Stutz D, 2018, COMPUT VIS IMAGE UND, V166, P1, DOI 10.1016/j.cviu.2017.03.007
   Van den Bergh M, 2012, LECT NOTES COMPUT SC, V7578, P13, DOI 10.1007/978-3-642-33786-4_2
   Wang H, 2020, IEEE T CIRC SYST VID, V30, P822, DOI 10.1109/TCSVT.2019.2896438
   Wang LJ, 2018, IEEE T CYBERNETICS, V48, P1030, DOI 10.1109/TCYB.2017.2675910
   Wang NN, 2021, IMAGE VISION COMPUT, V116, DOI 10.1016/j.imavis.2021.104315
   Wang W, 2018, IEEE T CIRC SYST VID, V28, P1609, DOI 10.1109/TCSVT.2017.2684759
   Wilms C, 2021, IMAGE VISION COMPUT, V114, DOI 10.1016/j.imavis.2021.104263
   Xue TF, 2019, IMAGE VISION COMPUT, V91, DOI 10.1016/j.imavis.2019.05.006
   Yuan Qing, 2021, P PAC RIM INT C ART, P293
   Zhang Q, 2014, LECT NOTES COMPUT SC, V8691, P815, DOI 10.1007/978-3-319-10578-9_53
   Zhang Y, 2022, IEEE T MULTIMEDIA, V24, P440, DOI 10.1109/TMM.2021.3053393
   Zhang YX, 2020, IET IMAGE PROCESS, V14, P4543, DOI 10.1049/iet-ipr.2020.1179
   Zhang YX, 2021, VISUAL COMPUT, V37, P1061, DOI 10.1007/s00371-020-01852-2
   Zhang YX, 2017, IEEE T CIRC SYST VID, V27, P1502, DOI 10.1109/TCSVT.2016.2539839
   Zhou XN, 2019, VISUAL COMPUT, V35, P385, DOI 10.1007/s00371-018-1471-4
   Zhu L, 2021, PROC CVPR IEEE, P1225, DOI 10.1109/CVPR46437.2021.00128
NR 41
TC 1
Z9 1
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2023
VL 129
AR 104596
DI 10.1016/j.imavis.2022.104596
EA NOV 2022
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 7S6FQ
UT WOS:000910848000005
DA 2024-07-18
ER

PT J
AU Yang, JC
   Zhu, Y
   Xiao, S
   Lan, GP
   Li, Y
AF Yang, Jiachen
   Zhu, Yong
   Xiao, Shuai
   Lan, Guipeng
   Li, Yang
TI A controllable face forgery framework to enrich face-privacy-protection
   datasets
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Privacy and security; Explainable arti ficial intelligence; Facial
   forgery; Generative adversarial network; Latent feature analysis and
   manipulation; Data diversity
ID IMAGES
AB Deep learning not only brings convenience to people, but also promotes the development of facial forgery tech-nology. Considering the current personal portrait security issues, the tampering and forgery of facial data has attracted more and more attention. In order to solve the above issues, we try to implement from another novel angle, that is, enrich the face-privacy-protection dataset to improve the detection ability of forgery faces. There-fore, we propose a controllable face forgery framework. In this work, we firstly analyze the identity information in the latent features and construct an identity latent space based on StyleGAN's w+ latent space. Then, we pro-pose an adaptive identity mapping network to edit the latent codes of the image through encoder and realize the identity transform. Finally, we further enhance the authenticity of the image through post-processing. In order to verify the superiority of our proposed method, we design extensive experiments. Experiments show the effec-tiveness of identity latent space and the controllability of our model. At the same time, it also shows that our pro-posed network can generate photo-level results and achieve excellent results in the comparison of other face swapping methods.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yang, Jiachen; Zhu, Yong; Xiao, Shuai; Lan, Guipeng; Li, Yang] Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
C3 Tianjin University
RP Xiao, S (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin, Peoples R China.
EM xs611@tju.edu.cn
RI Li, Yang/ABC-9731-2020
OI Li, Yang/0000-0002-4268-4004; zhu, yong/0000-0002-9806-1965
FU National Natural Science Foundation of China;  [61871283]
FX Acknowledgement This work is supported by National Natural Science
   Foundation of China (No. 61871283) .
CR Alaluf Y., 2021, HyperStyle: styleGAN inversion with HyperNetworks for real image editing
   Chen R, 2019, IEEE I CONF COMP VIS, P1538, DOI 10.1109/ICCV.2019.00162
   Chen XW, 2011, PROC CVPR IEEE, P281, DOI 10.1109/CVPR.2011.5995473
   Deng Y, 2019, IEEE COMPUT SOC CONF, P285, DOI 10.1109/CVPRW.2019.00038
   Denton Emily, 2019, arXiv
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Harkonen E., 2020, Ganspace: Discovering interpretable gan controls
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He ZL, 2019, IEEE T IMAGE PROCESS, V28, P5464, DOI 10.1109/TIP.2019.2916751
   Heusel M., 2017, GANS TRAINED 2 TIME, P6627
   Hudson Drew A., 2021, GENERATIVE ADVERSARI
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Karras Tero, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8107, DOI 10.1109/CVPR42600.2020.00813
   Karras T, 2021, IEEE T PATTERN ANAL, V43, P4217, DOI 10.1109/TPAMI.2020.2970919
   Kingma D. P., 2014, arXiv
   Korshunova I, 2017, IEEE I CONF COMP VIS, P3697, DOI 10.1109/ICCV.2017.397
   Lee CH, 2020, PROC CVPR IEEE, P5548, DOI 10.1109/CVPR42600.2020.00559
   Li LZ, 2020, PROC CVPR IEEE, P5073, DOI 10.1109/CVPR42600.2020.00512
   Li Y., IEEE T IND INFORM
   Li Y, 2022, ICT EXPRESS, V8, P309, DOI 10.1016/j.icte.2022.01.006
   Li Y, 2023, DIGIT COMMUN NETW, V9, P1061, DOI 10.1016/j.dcan.2021.12.001
   Li Y, 2022, FRONT PLANT SCI, V12, DOI 10.3389/fpls.2021.818895
   Li Y, 2021, PLANT METHODS, V17, DOI 10.1186/s13007-021-00770-1
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Ma TX, 2019, ASIAPAC SIGN INFO PR, P1657, DOI [10.1109/APSIPAASC47483.2019.9023328, 10.1109/apsipaasc47483.2019.9023328]
   Machlev R., 2021, IEEE T INDUSTR INF, DOI [10.1109/TII.2021.31261111-1, DOI 10.1109/TII.2021.31261111-1]
   Nirkin Y, 2019, IEEE I CONF COMP VIS, P7183, DOI 10.1109/ICCV.2019.00728
   Patashnik O, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P2065, DOI 10.1109/ICCV48922.2021.00209
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Rössler A, 2019, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2019.00009
   Selvaraju RR, 2020, INT J COMPUT VISION, V128, P336, DOI [10.1007/s11263-019-01228-7, 10.1109/ICCV.2017.74]
   Tjoa E, 2021, IEEE T NEUR NET LEAR, V32, P4793, DOI 10.1109/TNNLS.2020.3027314
   Tov O, 2021, ACM T GRAPHIC, V40, DOI 10.1145/3450626.3459838
   Wang Y., 2021, HIFIFACE 3D SHAPE SE, P1136
   Wiles O, 2018, LECT NOTES COMPUT SC, V11217, P690, DOI 10.1007/978-3-030-01261-8_41
   Wu WN, 2018, LECT NOTES COMPUT SC, V11205, P622, DOI 10.1007/978-3-030-01246-5_37
   Yang CY, 2021, INT J COMPUT VISION, V129, P1451, DOI 10.1007/s11263-020-01429-5
   Yang J., 2022, COMPUT ELECTR ENG, V103
   Yang JC, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22134697
   Yang JC, 2022, IEEE T CIRC SYST VID, V32, P4854, DOI 10.1109/TCSVT.2021.3133859
   Yang JC, 2022, PLANT METHODS, V18, DOI 10.1186/s13007-022-00866-2
   Yang JC, 2021, IEEE T INF FOREN SEC, V16, P4234, DOI 10.1109/TIFS.2021.3102487
   Yang JC, 2021, FUTURE GENER COMP SY, V125, P127, DOI 10.1016/j.future.2021.06.043
   Yu C., 2021, INT J COMPUT VISION, V129, P3051, DOI [DOI 10.1007/s11263-021-01515-2, 10.1007/s11263-021-01515-2]
   Yujun Shen, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9240, DOI 10.1109/CVPR42600.2020.00926
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zeng XF, 2020, AAAI CONF ARTIF INTE, V34, P12757
   Zhengzhe Liu, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P8057, DOI 10.1109/CVPR42600.2020.00808
   Zhou P, 2018, PROC CVPR IEEE, P1053, DOI 10.1109/CVPR.2018.00116
   Zhou Y, 2020, IEEE T NEUR NET LEAR, V31, P2916, DOI 10.1109/TNNLS.2019.2933879
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
   Zhu YH, 2021, PROC CVPR IEEE, P4832, DOI 10.1109/CVPR46437.2021.00480
NR 52
TC 3
Z9 3
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2022
VL 127
AR 104566
DI 10.1016/j.imavis.2022.104566
EA OCT 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 5R6GH
UT WOS:000874606300005
DA 2024-07-18
ER

PT J
AU Li, Z
   Zhang, HB
   Zhang, MH
   Lei, Q
   Du, JX
AF Li, Zhe
   Zhang, Hong -Bo
   Zhang, Miao-Hui
   Lei, Qing
   Du, Ji-Xiang
TI Late feature supplement network for early action prediction*
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Early action prediction; Early clip; Late clip; Feature supplement;
   Observation ratio
ID ACTION RECOGNITION
AB Early action prediction is a new hotspot in the field of computer vision. To improve the accuracy of early action prediction, a new end-to-end late feature supplement-based early action prediction network is proposed in this work. Different from the existing methods that use the model transfer strategy, a feature transfer strategy is defined in this work. Specifically, the features of the late clip are regarded as labels, and a feature transfer model is built to achieve mapping from the features of the early clip to the late features. After feature transfer, the generated late feature is fused into the early feature to form the final video feature. Finally, the final video fea-ture is applied to action classification. The proposed method is evaluated on the action classification task of the early clip. The experimental results show that compared with the existing methods, the proposed method has better performance at different observation ratios. The ablation study verifies that the proposed feature transfer strategy can significantly improve the accuracy of early action prediction.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Li, Zhe; Zhang, Hong -Bo] Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361000, Peoples R China.
   [Lei, Qing] Huaqiao Univ, Fujian Key Lab Big Data Intelligence & Secur, Xiamen 361000, Peoples R China.
   [Du, Ji-Xiang] Huaqiao Univ, Xiamen Key Lab Comp Vis & Pattern Recognit, Xiamen 361000, Peoples R China.
   [Zhang, Miao-Hui] Jiangxi Acad Sci, Inst Energy Res, Nanchang 330012, Peoples R China.
C3 Huaqiao University; Huaqiao University; Huaqiao University; Jiangxi
   Academy of Sciences
RP Zhang, HB (corresponding author), Huaqiao Univ, Sch Comp Sci & Technol, Xiamen 361000, Peoples R China.
EM zhanghongbo@hqu.edu.cn
RI Zhang, Hong-Bo/GWC-9306-2022
CR Arnab A., 2021, arXiv, DOI DOI 10.48550/ARXIV.2103.15691
   Cai YJ, 2019, AAAI CONF ARTIF INTE, P8118
   Cao Y, 2013, PROC CVPR IEEE, P2658, DOI 10.1109/CVPR.2013.343
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Fernando Basura, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P13219, DOI 10.1109/CVPR46437.2021.01302
   Hara K, 2018, Arxiv, DOI arXiv:1711.09577
   Hara K, 2018, PROC CVPR IEEE, P6546, DOI 10.1109/CVPR.2018.00685
   Hu JF, 2019, IEEE T PATTERN ANAL, V41, P2568, DOI 10.1109/TPAMI.2018.2863279
   Kong Y, 2022, Arxiv, DOI [arXiv:1806.11230, DOI 10.1007/S11263-022-01594-9]
   Kong Y, 2018, AAAI CONF ARTIF INTE, P7000
   Kong Y, 2020, IEEE T PATTERN ANAL, V42, P539, DOI 10.1109/TPAMI.2018.2882805
   Kong Y, 2017, PROC CVPR IEEE, P3662, DOI 10.1109/CVPR.2017.390
   Kong Y, 2016, IEEE T PATTERN ANAL, V38, P1844, DOI 10.1109/TPAMI.2015.2491928
   Kong Y, 2014, LECT NOTES COMPUT SC, V8693, P596, DOI 10.1007/978-3-319-10602-1_39
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Lai SF, 2018, IEEE T IMAGE PROCESS, V27, P2272, DOI 10.1109/TIP.2017.2751145
   Lan T, 2014, LECT NOTES COMPUT SC, V8691, P689, DOI 10.1007/978-3-319-10578-9_45
   Pang GL, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P897
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Ryoo MS, 2011, IEEE I CONF COMP VIS, P1036, DOI 10.1109/ICCV.2011.6126349
   Shi QHY, 2022, ACM T MULTIM COMPUT, V18, DOI 10.1145/3485665
   Simonyan K, 2014, Arxiv, DOI arXiv:1406.2199
   Soomro K, 2012, Arxiv, DOI arXiv:1212.0402
   Vaswani A, 2017, ADV NEUR IN, V30
   Than V, 2021, IEEE IMAGE PROC, P2583, DOI 10.1109/ICIP42928.2021.9506507
   Vondrick C, 2016, PROC CVPR IEEE, P98, DOI 10.1109/CVPR.2016.18
   Wang BY, 2020, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR42600.2020.00116
   Wang H., 2009, BMVC
   Wang H, 2013, IEEE I CONF COMP VIS, P3551, DOI 10.1109/ICCV.2013.441
   Wang LM, 2016, LECT NOTES COMPUT SC, V9912, P20, DOI 10.1007/978-3-319-46484-8_2
   Wang XH, 2019, PROC CVPR IEEE, P3551, DOI 10.1109/CVPR.2019.00367
   Wu XX, 2021, INT J COMPUT VISION, V129, P1484, DOI 10.1007/s11263-020-01409-9
   Zhang HB, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051005
NR 34
TC 0
Z9 0
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2022
VL 125
AR 104519
DI 10.1016/j.imavis.2022.104519
EA JUL 2022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 3Y7JW
UT WOS:000843898700001
DA 2024-07-18
ER

PT J
AU Bai, GH
   Luo, YM
   Pan, XL
   Wang, YJ
   Wang, J
   Guo, JM
AF Bai, Guihu
   Luo, Yanmin
   Pan, Xueliang
   Wang, Youjie
   Wang, Jia
   Guo, Jingming
TI Double chain networks for monocular 3D human pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D human pose estimation; Global constraint; Local constraint;
   Equipotential-joints
AB The 2D-3D lifting task for Human Pose Estimation is a highly nonlinear mapping problem, which requires mutual constraints among human joints. In this paper, we mainly discuss how to represent the constraints among the joints by their global and local dependencies, and how to fuse them more effectively. Therefore, we propose a novel end-to-end neural network architecture named Double chain Networks (DCN), for monocular 2D-3D human pose lifting task. The DCN consists of two parts. One is a global constraint module based on full connection layer, which extracts the global dependency information of human body joints; the other is graph convolution based local constraint module, which represents the local dependency information of human body joints. The global and local constraint features are fused by interleaved addition to combine the global and local spatial constraint features of human joints in DCN regression, which outperforms the way of concatenating them. We perform abundant ablation experiments on Human3.6M dataset to verify the advantages of the constraint modules, and compare the performance of the single/double chain networks. Experimental results show that the DCN achieves state-of-the-art performance and exhibits strong generalization ability, and its performance is comparable to the methods based on temporal information. Finally, we apply the DCN to reconstruct 3D skeletons in 3D anime characters. The equipotential-joints connection mode to extract the constraint relationships between the human equipotential-joints; The DCN can effectively extract and combine the global and local constraints of human joints; The DCN achieves state-of-the-art performance and exhibits strong generalization ability; We apply the DCN to the posture construction of 3D virtual characters.
C1 [Bai, Guihu; Luo, Yanmin; Pan, Xueliang; Wang, Youjie; Wang, Jia] Huaqiao Univ, Coll Comp Sci & Technol, 668 Jimei Ave, Xiamen 361021, Fujian, Peoples R China.
   [Bai, Guihu; Luo, Yanmin; Pan, Xueliang; Wang, Youjie; Wang, Jia] Huaqiao Univ, Key Lab Comp Vis & Pattern Recognit, 668 Jimei Ave, Xiamen 361021, Fujian, Peoples R China.
   [Guo, Jingming] Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
C3 Huaqiao University; Huaqiao University; National Taiwan University of
   Science & Technology
RP Luo, YM (corresponding author), Huaqiao Univ, Coll Comp Sci & Technol, 668 Jimei Ave, Xiamen 361021, Fujian, Peoples R China.; Guo, JM (corresponding author), Natl Taiwan Univ Sci & Technol, Dept Elect Engn, Taipei 10607, Taiwan.
EM lym@hqu.edu.cn; jmguo@seed.net.tw
RI Bai, Guihu/GSM-7354-2022; xiao, ming/KHT-1774-2024; Liu,
   Jinyu/JYQ-6274-2024
FU Natural Science Foundation of Fujian Province, China [2020J01082]
FX Acknowledgment This work was supported by Natural Science Foundation of
   Fujian Province, China under grant 2020J01082.
CR Agarwal A, 2004, PROC CVPR IEEE, P882
   Martinez AA, 2017, INT SYMP COMPUT EDUC
   Ailing Zeng, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P507, DOI 10.1007/978-3-030-58568-6_30
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Artacho B., 2021, OMNIPOSE MULTISCALE
   Ben Gamra M, 2021, IMAGE VISION COMPUT, V114, DOI 10.1016/j.imavis.2021.104282
   Bruna J., 2014, ABS13126203 CORR, P1, DOI [10.48550/arXiv.1312.6203, DOI 10.48550/ARXIV.1312.6203]
   Bulat A, 2020, IEEE INT CONF AUTOMA, P8, DOI 10.1109/FG47880.2020.00014
   Cai YJ, 2019, IEEE I CONF COMP VIS, P2272, DOI 10.1109/ICCV.2019.00236
   Chen JT, 2020, PROC CVPR IEEE, P389, DOI 10.1109/CVPR42600.2020.00047
   Chen TL, 2022, IEEE T CIRC SYST VID, V32, P198, DOI 10.1109/TCSVT.2021.3057267
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chen ZM, 2019, PROC CVPR IEEE, P5172, DOI 10.1109/CVPR.2019.00532
   Chiang WL, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P257, DOI 10.1145/3292500.3330925
   Ci H, 2019, IEEE I CONF COMP VIS, P2262, DOI 10.1109/ICCV.2019.00235
   Fang HS, 2018, AAAI CONF ARTIF INTE, P6821
   Hong J, 2020, IEEE ACCESS, V8, P190529, DOI 10.1109/ACCESS.2020.3023423
   Hossain MRI, 2018, LECT NOTES COMPUT SC, V11214, P69, DOI 10.1007/978-3-030-01249-6_5
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/CVPR.2018.00745, 10.1109/TPAMI.2019.2913372]
   Hu W., P 29 ACM INT CONFREN, P602
   Pham HH, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071825
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Kanazawa A, 2018, PROC CVPR IEEE, P7122, DOI 10.1109/CVPR.2018.00744
   Kipf TN, 2016, ARXIV
   Kocabas M, 2020, PROC CVPR IEEE, P5252, DOI 10.1109/CVPR42600.2020.00530
   Kolotouros N, 2019, IEEE I CONF COMP VIS, P2252, DOI 10.1109/ICCV.2019.00234
   Koppula HS, 2016, IEEE T PATTERN ANAL, V38, P14, DOI 10.1109/TPAMI.2015.2430335
   Kumarapu L, 2021, PATTERN RECOGN LETT, V147, P16, DOI 10.1016/j.patrec.2021.03.028
   Lee K., P EUROPEAN C COMPUTE, P119
   Li C, 2019, PROC CVPR IEEE, P9879, DOI 10.1109/CVPR.2019.01012
   Li MS, 2021, IEEE T IMAGE PROCESS, V30, P7760, DOI 10.1109/TIP.2021.3108708
   Li SC, 2020, PROC CVPR IEEE, P6172, DOI 10.1109/CVPR42600.2020.00621
   Li W., 2021, ARXIV PREPRINT ARXIV
   Liu J, 2020, ARXIV PREPRINT ARXIV
   Liu K., EUR C COMP VIS, P318
   Liu RX, 2020, PROC CVPR IEEE, P5063, DOI 10.1109/CVPR42600.2020.00511
   Lo Presti L, 2015, IMAGE VISION COMPUT, V44, P29, DOI 10.1016/j.imavis.2015.09.007
   Luo C., 2018, ARXIV PREPRINT ARXIV
   Luvizon DC, 2018, PROC CVPR IEEE, P5137, DOI 10.1109/CVPR.2018.00539
   Ma X., P IEEECVF C COMPUTER, P6238
   Mehta D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392410
   Mehta D, 2018, INT CONF 3D VISION, P120, DOI 10.1109/3DV.2018.00024
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Newell A, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901343
   Nibali A, 2019, IEEE WINT CONF APPL, P1477, DOI 10.1109/WACV.2019.00162
   Pavlakos G, 2018, PROC CVPR IEEE, P7307, DOI 10.1109/CVPR.2018.00763
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Qiu L., 2020, EUR C COMP VIS, P488, DOI DOI 10.1007/978-3-030-58529-7_29
   Reddy ND, 2021, PROC CVPR IEEE, P15185, DOI 10.1109/CVPR46437.2021.01494
   Schwarz LA, 2012, IMAGE VISION COMPUT, V30, P217, DOI 10.1016/j.imavis.2011.12.001
   Shan W., 2021, P 29 ACM INT C MULT, P3446
   Sharma S, 2019, IEEE I CONF COMP VIS, P2325, DOI 10.1109/ICCV.2019.00241
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun N, 2021, IMAGE VISION COMPUT, V109, DOI 10.1016/j.imavis.2021.104141
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Tekin B, 2017, IEEE I CONF COMP VIS, P3961, DOI 10.1109/ICCV.2017.425
   Wandt B, 2019, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2019.00797
   Wang LY, 2019, IEEE INT CONF COMP V, P4024, DOI 10.1109/ICCVW.2019.00497
   Wehrbein T., P IEEE CVF INT C COM, P11199
   Xu TH, 2021, PROC CVPR IEEE, P16100, DOI 10.1109/CVPR46437.2021.01584
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Zhang ZQ, 2021, IMAGE VISION COMPUT, V111, DOI 10.1016/j.imavis.2021.104198
   Zhao L, 2019, PROC CVPR IEEE, P3420, DOI 10.1109/CVPR.2019.00354
   Zhao X, 2008, INT C PATT RECOG, P2006
   Zheng C., P IEEE CVF INT C COM, P11656
NR 66
TC 4
Z9 4
U1 2
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL
PY 2022
VL 123
AR 104452
DI 10.1016/j.imavis.2022.104452
EA MAY 2022
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 1L9ND
UT WOS:000799606300004
DA 2024-07-18
ER

PT J
AU Yi, SH
   Fan, ZY
   Wu, D
AF Yi, Shuhan
   Fan, Zheyi
   Wu, Di
TI Batch feature standardization network with triplet loss for
   weakly-supervised video anomaly detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video anomaly detection; Batch feature standardization; Triplet loss;
   Feature processing
AB Video anomaly detection refers to detecting anomalies automatically without manual labor, which is of great sig-nificance to intelligent security. With the emergence of weakly-supervised learning, the performance of video anomaly detection has been greatly advanced. However, the abnormal frames and their adjacent normal frames often make slight differences, increasing the difficulty and complexity of video anomaly detection. To address this problem, we propose a batch feature standardization module using a special standardization approach to facili-tate the identification of obscure abnormal events. Meanwhile, we propose a novel strategy to refine the anomaly degree to classify the anomalous videos into two categories, i.e., weak anomalies and strong anomalies. Then the triplet loss is utilized to further improve the discriminative power of the model. Extensive experiments results demonstrate that our method works well on two benchmark datasets, and obtains a frame-level AUC 97.65% on ShanghaiTech and 84.29% on UCF-Crime, achieving comparable performance with the recent state-of-the -art methods.(c) 2022 Elsevier B.V. All rights reserved.
C1 [Yi, Shuhan; Fan, Zheyi; Wu, Di] Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
C3 Beijing Institute of Technology
RP Fan, ZY (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100081, Peoples R China.
EM funye@bit.edu.cn
FU Natural Science Foundation of Bei-jing Municipality [L192036]
FX Acknowledgments This work was supported by the Natural Science
   Foundation of Bei-jing Municipality under Grant L192036.
CR Andrews S., 2002, P C WORKSH NEU INF P
   Babenko B, 2011, IEEE T PATTERN ANAL, V33, P1619, DOI 10.1109/TPAMI.2010.226
   Carbonneau MA, 2018, PATTERN RECOGN, V77, P329, DOI 10.1016/j.patcog.2017.10.009
   Carreira J, 2017, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2017.502
   Chen Q, 2021, PROC CVPR IEEE, P13034, DOI 10.1109/CVPR46437.2021.01284
   Chen YX, 2006, IEEE T PATTERN ANAL, V28, P1931, DOI 10.1109/TPAMI.2006.248
   Feng, P IEEE CVF C COMP VI
   Gong D, 2019, IEEE I CONF COMP VIS, P1705, DOI 10.1109/ICCV.2019.00179
   Hasan M, 2016, PROC CVPR IEEE, P733, DOI 10.1109/CVPR.2016.86
   Ioffe S, 2015, P INT C MACH LEARN, V2015, P1
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Kingma D. P., 2014, arXiv
   Lee D.-H., 2013, WORKSHOP CHALLENGES, V3, P896
   Liu K, 2019, PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA (MM'19), P1490, DOI 10.1145/3343031.3350998
   Liu W., 2019, P INT JOINT C ART IN
   Liu W, 2018, PROC CVPR IEEE, P6536, DOI 10.1109/CVPR.2018.00684
   LIU ZA, 2021, HYBRID VIDEO ANOMALY, P13568, DOI DOI 10.1109/ICCV48922.2021.01333
   Lu CW, 2013, IEEE I CONF COMP VIS, P2720, DOI 10.1109/ICCV.2013.338
   Manju N, 2020, INT J INTERACT MULTI, V6, P117, DOI 10.9781/ijimai.2019.11.002
   Melendez J, 2015, IEEE T MED IMAGING, V34, P179, DOI 10.1109/TMI.2014.2350539
   Nair V., 2010, P 27 INT C MACHINE L, P807
   Park H, 2020, IEEE INT C ELECTR TA, DOI 10.1109/icce-taiwan49838.2020.9258065
   Paszke A, 2019, ADV NEUR IN, V32
   Nguyen P, 2018, PROC CVPR IEEE, P6752, DOI 10.1109/CVPR.2018.00706
   Quellec G, 2012, MED IMAGE ANAL, V16, P1228, DOI 10.1016/j.media.2012.06.003
   Rodrigues R, 2020, IEEE WINT CONF APPL, P2615, DOI [10.1109/WACV45572.2020.9093633, 10.1109/wacv45572.2020.9093633]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sultani W, 2018, PROC CVPR IEEE, P6479, DOI 10.1109/CVPR.2018.00678
   Sun Che, 2020, P 28 ACM INT C MULT
   Tang Y, 2020, PATTERN RECOGN LETT, V129, P123, DOI 10.1016/j.patrec.2019.11.024
   Tong T, 2014, MED IMAGE ANAL, V18, P808, DOI 10.1016/j.media.2014.04.006
   Wan BY, 2020, IEEE INT CON MULTI, DOI 10.1109/icme46284.2020.9102722
   Wang J, 2019, IEEE I CONF COMP VIS, P8200, DOI 10.1109/ICCV.2019.00829
   Wang SL, 2018, PROC CVPR IEEE, P2589, DOI 10.1109/CVPR.2018.00274
   Wang Z., IEEE T NEUR NET LEAR, V2021, P1
   Wu, 2021, IEEE T IMAGE PROCESS
   Wu P., 2020, P EUR C COMP VIS ECC
   Zaheer Muhammad Zaigham, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12367), P358, DOI 10.1007/978-3-030-58542-6_22
   Zhang JG, 2019, IEEE IMAGE PROC, P4030, DOI [10.1109/ICIP.2019.8803657, 10.1109/icip.2019.8803657]
   Zhao YR, 2017, PROCEEDINGS OF THE 2017 ACM MULTIMEDIA CONFERENCE (MM'17), P1933, DOI 10.1145/3123266.3123451
   Zhong JX, 2019, PROC CVPR IEEE, P1237, DOI 10.1109/CVPR.2019.00133
   Zhu JY, 2015, IEEE T PATTERN ANAL, V37, P862, DOI 10.1109/TPAMI.2014.2353617
   Zhu Y., 2019, ARXIV190710211, P1
NR 43
TC 6
Z9 6
U1 4
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2022
VL 120
AR 104397
DI 10.1016/j.imavis.2022.104397
EA FEB 2022
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4CS
UT WOS:000772535500010
DA 2024-07-18
ER

PT J
AU Kumar, S
   Singh, SK
   Mishra, NK
   Dutta, M
AF Kumar, Sumit
   Singh, Satish Kumar
   Mishra, Nayaneesh Kumar
   Dutta, Mainak
TI An encoder-decoder based thermo-visible image translation for disguised
   and undisguised faces
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image translation; Generative Adversarial Networks (GAN); Pix2Pix;
   Cycle-GAN; Encoder-decoder
AB Thermal cameras can capture images even in low light conditions. However, humans cannot recognize human faces in thermal images. Translation of thermal images to visible domain is one solution to the problem of face recognition in thermal images. Most of the research works have proposed Generative Adversarial Networks (GANs) based solutions for thermal to visible image translation. However, GAN is a heavy network that consumes huge amount of resource for thermal to visible image translation. In this paper, we propose an encoder-decoder architecture for thermal to visible image translation of human faces. Since our proposed architecture is not based on GANs, it is lightweight. The proposed method works well for both disguised and non-disguised thermal facial images. Standard comparison parameters such as Peak Signal-to-noise Ratio (PSNR), Structural Similarity Index (SSIM), and Multiscale Structural Similarity Index (MS-SSIM) are used to evaluate the quality of the generated visible images with respect to the ground truth. It has been found that our proposed architecture outperforms the current state-of-the-art image translator architectures namely pix2pix, Cycle-GAN, modified thermal to visible GAN and Dual GAN by a considerable margin for both disguised as well as non-disguised dataset. (c) 2022 Elsevier B.V. All rights reserved.
C1 [Kumar, Sumit; Singh, Satish Kumar; Mishra, Nayaneesh Kumar] Indian Inst Informat Technol, Jhalwa 211012, Prayagraj, India.
   [Dutta, Mainak] Qualcomm, Hyderabad, Telangana, India.
C3 Indian Institute of Information Technology Allahabad; Qualcomm
RP Kumar, S (corresponding author), Indian Inst Informat Technol, Jhalwa 211012, Prayagraj, India.
EM babbusumit@gmail.com
RI kumar, sumit/HDM-6772-2022; Dutta, Mainak/H-3354-2019; Kumar,
   Sumit/HHS-8959-2022; Singh, Dr Satish Kumar/JMP-6186-2023
OI Dutta, Mainak/0000-0003-3977-3230; Singh, Dr Satish
   Kumar/0000-0003-1991-7727; kumar, sumit/0000-0001-5441-1671
CR Aswatha S.M., P 12 IND C COMP VIS, P1
   Borji A, 2019, COMPUT VIS IMAGE UND, V179, P41, DOI 10.1016/j.cviu.2018.10.009
   Clevert D.A, 2015, 4 INT C LEARN REPR I
   Dhamecha TI, 2013, INT CONF BIOMETR
   Dhamecha TI, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0099212
   Dou MS, 2007, LECT NOTES COMPUT SC, V4844, P722
   Dumoulin V., 2016, A guide to convolution arithmetic for deep learning[J
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Kaiming, 2016, P INT C COMP VIS PAT, DOI 10.1109/CVPR.2016.90
   Isola P, 2017, PROC CVPR IEEE, P5967, DOI 10.1109/CVPR.2017.632
   Kuang XD, 2020, INFRARED PHYS TECHN, V107, DOI 10.1016/j.infrared.2020.103338
   Lezama J, 2017, PROC CVPR IEEE, P6807, DOI 10.1109/CVPR.2017.720
   Li J, 2008, IEEE IMAGE PROC, P465, DOI 10.1109/ICIP.2008.4711792
   Liang W, 2021, INFRARED PHYS TECHN, V116, DOI 10.1016/j.infrared.2021.103764
   Liming Jiang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P206, DOI 10.1007/978-3-030-58580-8_13
   Ma Y, 2020, Annals of Data Science, V9, P187, DOI DOI 10.1007/S40745-020-00253-5
   Park Taesung, 2020, EUR C COMP VIS, P319, DOI [DOI 10.1007/978-3-030-58545-719, DOI 10.1007/978-3-030-58545-7_19]
   Qian N, 1988, J MOL BIOL, V202, P865, DOI 10.1016/0022-2836(88)90564-5
   Richardson E, 2021, PROC CVPR IEEE, P2287, DOI 10.1109/CVPR46437.2021.00232
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sarfraz MS, 2017, INT J COMPUT VISION, V122, P426, DOI 10.1007/s11263-016-0933-2
   Wang NN, 2013, PATTERN RECOGN LETT, V34, P77, DOI 10.1016/j.patrec.2012.04.005
   Wang Z, 2003, CONF REC ASILOMAR C, P1398
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wang ZL, 2018, IEEE SIGNAL PROC LET, V25, P1161, DOI 10.1109/LSP.2018.2845692
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Yi Z., P IEEE INT C COMP VI, P2849
   Zhang H, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P100
   Zhang T, 2018, INT CONF BIOMETR, P174, DOI 10.1109/ICB2018.2018.00035
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 31
TC 1
Z9 1
U1 1
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2022
VL 119
AR 104376
DI 10.1016/j.imavis.2022.104376
EA FEB 2022
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY3WS
UT WOS:000772519400009
DA 2024-07-18
ER

PT J
AU Mishra, NK
   Singh, SK
AF Mishra, Nayaneesh Kumar
   Singh, Satish Kumar
TI Regularized Hardmining loss for face recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face Recognition; Hardmining loss; Regularized Hardmining loss
AB For face recognition using deep learning architectures, loss functions have become a topic of research these days. This is because of the fact that when the discriminative ability of the loss function increases, then the face recognition accuracy increases. Hardmining loss is one such generic loss function that can be used with any basic loss function and has the ability to enhance the face recognition accuracy of the given basic loss function. Hardmining loss achieves the improvement by introducing greater penalty for hard examples. However, the problem with Hardmining loss is that the easy examples are allocated loss value near to zero. This limits the contribution of the easy examples specially in the later training stages. We therefore propose an improved Hardmining loss called the Regularized Hardmining loss. The Regularized Hardmining loss allocates a reasonable loss value to the easier examples as well. It thus helps easy examples maintain their contribution in the later training stage while still giving relatively greater penalty for hard examples thus preserving the property of the Hardmining loss. The Regularized Hardmining loss fine-tunes the behavior of Hardmining loss for better performance. The results of Regularized Hardmining loss when applied with Cross Entropy loss show an increased accuracy of face recognition from 93.78% to 95.55% on LFW dataset. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Mishra, Nayaneesh Kumar; Singh, Satish Kumar] Indian Inst Informat Technol, Jhalwa 211012, Prayagraj, India.
C3 Indian Institute of Information Technology Allahabad
RP Mishra, NK (corresponding author), Indian Inst Informat Technol, Jhalwa 211012, Prayagraj, India.
EM nayaneesh@gmail.com
RI Singh, Dr Satish Kumar/JMP-6186-2023
OI Singh, Dr Satish Kumar/0000-0003-1991-7727
CR Boutros F., 2021, ARXIV PREPRINT ARXIV
   Chen KZ, 2018, IEEE IMAGE PROC, P1638, DOI 10.1109/ICIP.2018.8451129
   Deng JK, 2017, IEEE COMPUT SOC CONF, P2006, DOI 10.1109/CVPRW.2017.251
   Felzenszwalb PF, 2010, PROC CVPR IEEE, P2241, DOI 10.1109/CVPR.2010.5539906
   Hadsell R, 2006, IEEE C COMP VIS PATT, P1735, DOI DOI 10.1109/CVPR.2006.100
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang G. B., 2008, WORKSH FAC REAL LIF
   Johnson J, 2016, LECT NOTES COMPUT SC, V9906, P694, DOI 10.1007/978-3-319-46475-6_43
   Liang XZ, 2017, LECT NOTES COMPUT SC, V10635, P413, DOI 10.1007/978-3-319-70096-0_43
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Liu H, 2019, PROC CVPR IEEE, P11939, DOI 10.1109/CVPR.2019.01222
   Liu WY, 2016, PR MACH LEARN RES, V48
   Rowley HA, 1996, ADV NEUR IN, V8, P875
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shrivastava A, 2016, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2016.89
   Smirnov E, 2018, IEEE COMPUT SOC CONF, P37, DOI 10.1109/CVPRW.2018.00013
   Srivastava Y., 2021, ARXIV PREPRINT ARXIV
   Sung K.-K., 2021, LEARNING EXAMPLE SEL
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang F, 2018, IEEE SIGNAL PROC LET, V25, P926, DOI 10.1109/LSP.2018.2822810
   Wang H, 2018, PROC CVPR IEEE, P5265, DOI 10.1109/CVPR.2018.00552
   Wei X, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.107012
   Wen YD, 2016, LECT NOTES COMPUT SC, V9911, P499, DOI 10.1007/978-3-319-46478-7_31
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Xiao Q., 2021, ARXIV PREPRINT ARXIV
   Xu ZS, 2017, 2017 2ND IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (ICCIA), P214, DOI 10.1109/CIAPP.2017.8167210
   Yang S., 2021, IEEE T CIRCUIT SYST, V31
   Yi D., 2021, ARXIV PREPRINT ARXIV
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
NR 29
TC 2
Z9 2
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2022
VL 117
AR 104343
DI 10.1016/j.imavis.2021.104343
PG 6
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ZY4VF
UT WOS:000772585200002
DA 2024-07-18
ER

PT J
AU Liu, AA
   Lu, ZM
   Xu, N
   Nie, WZ
   Li, WH
AF Liu, An-An
   Lu, Zimu
   Xu, Ning
   Nie, Weizhi
   Li, Wenhui
TI Multi-type decision fusion network for visual Q&A
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual question answering; Multi-type question; Scene graph
AB The existing VQA task contains questions of various complexity, which can be divided into the object-level and relation-level categories. The former requires the model to focus on individual objects of images to answer the question, such as "Is a man in the image?", denoted by object-QA, while the latter depends on a better under-standing in the relation of pairwise objects to infer the answer, such as "What is the man doing now?", denoted by relation-QA. However, existing methods indiscriminately rely on the single network to deal with multi-type question categories, which cannot meet the comprehensive nature of VQA task. To this end, we introduce the novel multi-type decision fusion model, which can adaptively leverage object-and relation-level decision net-works to infer the answer. Our approach consists of three key components: 1) the object-QA network designs the attention layer to search for object regions in an image that are associated with the answer. 2) the relation-QA network captures the question aware relation information from the visual scene graph, for the an-swer inference; 3) the proposed balance gate involves the outputs of object-and relation-QA networks to adap-tively predict the final output. Extensive experiments on two benchmarks demonstrate that the proposed method can achieve competing performance against the state-of-the-art methods. Additional ablation studies further validate its effectiveness. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Liu, An-An; Lu, Zimu; Xu, Ning; Nie, Weizhi; Li, Wenhui] Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
C3 Tianjin University
RP Xu, N; Li, WH (corresponding author), Tianjin Univ, Sch Elect & Informat Engn, Tianjin 300072, Peoples R China.
EM ningxu@tju.edu.cn; liwenhui@tju.edu.cn
RI Lu, Wang/JVO-0416-2024; LU, lpp pp/JFJ-9011-2023; Nie,
   Weizhi/ABF-5316-2021; LI, Wenhui/JCD-9947-2023; Zeng, Yun/JFK-6190-2023
OI nie, weizhi/0000-0002-0578-8138
FU National Key Research and Development Program of China [2020YFB1406602];
   National Natural Science Foundation of China [61772359, 62002257];
   Tianjin New Generation Artificial Intelligence Major Program
   [19ZXZNGX00110, 18ZXZNGX00150]; China Postdoctoral Science Foundation
   [2021M692395]
FX This work was supported in part by the National Key Research and
   Development Program of China (2020YFB1406602) , the National Natural
   Science Foundation of China (61772359, 62002257) , the grant of Tianjin
   New Generation Artificial Intelligence Major Program (19ZXZNGX00110,
   18ZXZNGX00150) , the China Postdoctoral Science Foundation (2021M692395)
   .
CR Agarwal Vedika, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9687, DOI 10.1109/CVPR42600.2020.00971
   Agrawal A, 2018, PROC CVPR IEEE, P4971, DOI 10.1109/CVPR.2018.00522
   Anderson P, 2018, PROC CVPR IEEE, P6077, DOI 10.1109/CVPR.2018.00636
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   Bai YL, 2018, LECT NOTES COMPUT SC, V11216, P21, DOI 10.1007/978-3-030-01258-8_2
   Dourado AMB, 2020, APPL SOFT COMPUT, V89, DOI 10.1016/j.asoc.2020.106130
   Cadene R, 2019, PROC CVPR IEEE, P1989, DOI 10.1109/CVPR.2019.00209
   Chen Long, 2020, P IEEE CVF C COMP VI
   Chen TS, 2019, PROC CVPR IEEE, P6156, DOI 10.1109/CVPR.2019.00632
   Cho K., 2014, PROCS C EMPIRICAL ME, P1724, DOI DOI 10.3115/V1/D14-1179
   Clark C, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P4069
   Ding ST, 2020, NEUROCOMPUTING, V398, P520, DOI 10.1016/j.neucom.2019.04.095
   Gao Z, 2020, NEURAL NETWORKS, V125, P290, DOI 10.1016/j.neunet.2020.02.017
   Goyal Y, 2019, INT J COMPUT VISION, V127, P398, DOI 10.1007/s11263-018-1116-0
   Grand G., 2019, ABS190608430 CORR
   Gu JX, 2019, PROC CVPR IEEE, P1969, DOI 10.1109/CVPR.2019.00207
   Hudson Drew A., 2019, ADV NEURAL INFORM PR
   Hwang SJ, 2018, PROC CVPR IEEE, P1014, DOI 10.1109/CVPR.2018.00112
   Kingma D. P., 2014, arXiv
   Krishna R, 2017, INT J COMPUT VISION, V123, P32, DOI 10.1007/s11263-016-0981-7
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li LJ, 2019, IEEE I CONF COMP VIS, P10312, DOI 10.1109/ICCV.2019.01041
   Li YK, 2017, PROC CVPR IEEE, P7244, DOI 10.1109/CVPR.2017.766
   Liang X., P IEEE C COMP VIS PA, P848
   Lin X, 2020, PROC CVPR IEEE, P3743, DOI 10.1109/CVPR42600.2020.00380
   Lu CW, 2016, LECT NOTES COMPUT SC, V9905, P852, DOI 10.1007/978-3-319-46448-0_51
   Lu P, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1880, DOI 10.1145/3219819.3220036
   Malinowski M, 2018, LECT NOTES COMPUT SC, V11210, P3, DOI 10.1007/978-3-030-01231-1_1
   Marino K, 2019, PROC CVPR IEEE, P3190, DOI 10.1109/CVPR.2019.00331
   Murahari V., EMNLP IJCNLP9 ASS, P1449
   Narasimhan M, 2018, LECT NOTES COMPUT SC, V11212, P460, DOI 10.1007/978-3-030-01237-3_28
   Newell A., 2017, P NIPS, P2171
   Peyre J., 2018, ABS181205736 CORR
   Qi M., P IEEE C COMP VIS PA, P3957
   Ramakrishnan S., 2018, INT C NEURAL INF PRO, V31, P1541
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Scanlon V., 2018, ESSENTIALS ANATOMY P
   Shi Y, 2018, LECT NOTES COMPUT SC, V11208, P158, DOI 10.1007/978-3-030-01225-0_10
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Socher R., 2011, PROC INT C MACH LEAR, P129
   Su Z, 2018, PROC CVPR IEEE, P7736, DOI 10.1109/CVPR.2018.00807
   Tang KH, 2019, PROC CVPR IEEE, P6612, DOI 10.1109/CVPR.2019.00678
   Teney D, 2018, PROC CVPR IEEE, P4223, DOI 10.1109/CVPR.2018.00444
   Wang P, 2018, IEEE T PATTERN ANAL, V40, P2413, DOI 10.1109/TPAMI.2017.2754246
   Wu JL, 2019, ADV NEUR IN, V32
   Xi YL, 2020, SIGNAL PROCESS-IMAGE, V80, DOI 10.1016/j.image.2019.115648
   Xu DF, 2017, PROC CVPR IEEE, P3097, DOI 10.1109/CVPR.2017.330
   Yang JW, 2018, LECT NOTES COMPUT SC, V11205, P690, DOI 10.1007/978-3-030-01246-5_41
   Yang ZC, 2016, PROC CVPR IEEE, P21, DOI 10.1109/CVPR.2016.10
   Yu Z, 2019, PROC CVPR IEEE, P6274, DOI 10.1109/CVPR.2019.00644
   Zellers R, 2018, PROC CVPR IEEE, P5831, DOI 10.1109/CVPR.2018.00611
   Zhang HW, 2017, PROC CVPR IEEE, P3107, DOI 10.1109/CVPR.2017.331
   Zhang Y., 2018, 6 INT C LEARN REPR I
   Zhao Y, 2019, IEEE J BIOMED HEALTH, V23, P1363, DOI 10.1109/JBHI.2019.2891526
   Zhu YK, 2016, PROC CVPR IEEE, P4995, DOI 10.1109/CVPR.2016.540
NR 55
TC 5
Z9 5
U1 1
U2 20
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2021
VL 115
AR 104281
DI 10.1016/j.imavis.2021.104281
EA AUG 2021
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA WC6NH
UT WOS:000704372400003
DA 2024-07-18
ER

PT J
AU Ben Gamra, M
   Akhloufi, MA
AF Ben Gamra, Miniar
   Akhloufi, Moulay A.
TI A review of deep learning techniques for 2D and 3D human pose estimation
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE 2D and 3D human pose estimation; Deep learning; CNN; Computer vision;
   Single-person and multi-person pose estimation
AB Inferring human pose from a monocular RGB image remains an interesting field of research in computer vision. It serves as a fundamental key for many real-world applications, including human-computer interaction, anima-tion, and detecting abnormal or illegal human behavior. Despite the considerable progress made in this area dur-ing the last decade, the proposed methods face serious problems due to the huge variations in human appearance, occlusions, noisy backgrounds, viewpoints, and other factors that can change the context of the cap-tured information. In this paper, we introduce a survey of state-of-the-art methods to highlight various research that have been proposed to tackle the 2D and 3D pose estimation tasks. Based on the number of persons in the image, two main pipelines are identified: single-person and multi-person methods. Each of these categories is di-vided into two groups according to the proposed architectures. Also, we provide a brief description of current datasets and the different metrics applied to evaluate the methods performances. Finally, we include a discussion about the advantages and disadvantages of the mentioned strategies. (c) 2021 Elsevier B.V. All rights reserved.
C1 [Ben Gamra, Miniar; Akhloufi, Moulay A.] Univ Moncton, Dept Comp Sci, Percept Robot & Intelligent Machines Res Grp PRIM, Moncton, NB E1A 3E9, Canada.
C3 University of Moncton
RP Ben Gamra, M (corresponding author), Univ Moncton, Dept Comp Sci, Percept Robot & Intelligent Machines Res Grp PRIM, Moncton, NB E1A 3E9, Canada.
EM emb4506@umoncton.ca; moulay.akhloufi@umoncton.ca
FU Natural Sciences and Engineering Research Council of Canada (NSERC)
   [RGPIN-2018-06233]
FX This research was enabled in part by support provided by the Natural
   Sciences and Engineering Research Council of Canada (NSERC), funding
   reference number RGPIN-2018-06233.
CR Andriluka M, 2018, PROC CVPR IEEE, P5167, DOI 10.1109/CVPR.2018.00542
   Andriluka M, 2014, PROC CVPR IEEE, P3686, DOI 10.1109/CVPR.2014.471
   Andriluka M, 2009, PROC CVPR IEEE, P1014, DOI 10.1109/CVPRW.2009.5206754
   [Anonymous], 2010, BMVC
   Antol S, 2014, LECT NOTES COMPUT SC, V8692, P401, DOI 10.1007/978-3-319-10593-2_27
   Artacho B., ABS210310180 ARXIV, P1
   Artacho B, 2020, PROC CVPR IEEE, P7033, DOI 10.1109/CVPR42600.2020.00706
   Belagiannis V, 2014, PROC CVPR IEEE, P1669, DOI 10.1109/CVPR.2014.216
   Benzine A, 2020, PROC CVPR IEEE, P6855, DOI 10.1109/CVPR42600.2020.00689
   Bin YR, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107410
   Bulat A, 2020, IEEE INT CONF AUTOMA, P8, DOI 10.1109/FG47880.2020.00014
   Can Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P242, DOI 10.1007/978-3-030-58580-8_15
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Carreira J, 2016, PROC CVPR IEEE, P4733, DOI 10.1109/CVPR.2016.512
   Charles J, 2014, INT J COMPUT VISION, V110, P70, DOI 10.1007/s11263-013-0672-6
   Chen B, 2019, PROCEEDINGS OF THE 10TH ACM MULTIMEDIA SYSTEMS CONFERENCE (ACM MMSYS'19), P1, DOI [10.1007/s12602-018-9495-7, 10.1145/3304109.3306234]
   Chen YL, 2018, PROC CVPR IEEE, P7103, DOI 10.1109/CVPR.2018.00742
   Chen Y, 2017, IEEE I CONF COMP VIS, P1221, DOI 10.1109/ICCV.2017.137
   Cheng H.-P., 2020, ABS201114584 ARXIV, P1
   Chou CJ, 2018, ASIAPAC SIGN INFO PR, P17, DOI 10.23919/APSIPA.2018.8659538
   Ci H, 2022, IEEE T PATTERN ANAL, V44, P1429, DOI 10.1109/TPAMI.2020.3019139
   Dabral R, 2019, INT CONF 3D VISION, P405, DOI 10.1109/3DV.2019.00052
   Dabral R, 2018, LECT NOTES COMPUT SC, V11213, P679, DOI 10.1007/978-3-030-01240-3_41
   Dang Q, 2019, TSINGHUA SCI TECHNOL, V24, P663, DOI 10.26599/TST.2018.9010100
   Defferrard M, 2016, ADV NEUR IN, V29
   Dong JT, 2019, PROC CVPR IEEE, P7784, DOI 10.1109/CVPR.2019.00798
   Eichner M., 2010, 272 ETH ZUR D ITET B
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Fabbri M, 2020, PROC CVPR IEEE, P7202, DOI 10.1109/CVPR42600.2020.00723
   Fabbri M, 2018, LECT NOTES COMPUT SC, V11208, P450, DOI 10.1007/978-3-030-01225-0_27
   Fang HS, 2017, IEEE I CONF COMP VIS, P2353, DOI 10.1109/ICCV.2017.256
   Geng ZG, 2021, PROC CVPR IEEE, P14671, DOI 10.1109/CVPR46437.2021.01444
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gong K., 2021, PROC CVPR IEEE, P8575, DOI DOI 10.1109/CVPR46437.2021.00847
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   He Chen, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12348), P541, DOI 10.1007/978-3-030-58580-8_32
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A.G., 2017, MOBILENETS EFFICIENT, DOI DOI 10.48550/ARXIV.1704.04861
   Huang JJ, 2020, PROC CVPR IEEE, P5699, DOI 10.1109/CVPR42600.2020.00574
   Insafutdinov E, 2016, LECT NOTES COMPUT SC, V9910, P34, DOI 10.1007/978-3-319-46466-4_3
   Ionescu C, 2014, IEEE T PATTERN ANAL, V36, P1325, DOI 10.1109/TPAMI.2013.248
   Iskakov K, 2019, IEEE I CONF COMP VIS, P7717, DOI 10.1109/ICCV.2019.00781
   Jhuang HH, 2013, IEEE I CONF COMP VIS, P3192, DOI 10.1109/ICCV.2013.396
   Johnson S, 2011, PROC CVPR IEEE, P1465, DOI 10.1109/CVPR.2011.5995318
   Joo H, 2019, IEEE T PATTERN ANAL, V41, P190, DOI 10.1109/TPAMI.2017.2782743
   Ke LP, 2018, LECT NOTES COMPUT SC, V11206, P731, DOI 10.1007/978-3-030-01216-8_44
   Kocabas M, 2019, PROC CVPR IEEE, P1077, DOI 10.1109/CVPR.2019.00117
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Kundu Jogendra Nath, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12358), P35, DOI 10.1007/978-3-030-58601-0_3
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Li SJ, 2015, LECT NOTES COMPUT SC, V9004, P332, DOI 10.1007/978-3-319-16808-1_23
   Li W., 2019, ACM/IEEE ANCS, P1, DOI DOI 10.5114/AOMS.2019.86185
   Li Y, 2019, OVERVIEW 2D MULTIHUM, V9
   Liang XD, 2019, IEEE T PATTERN ANAL, V41, P871, DOI 10.1109/TPAMI.2018.2820063
   Lin MD, 2017, PROC CVPR IEEE, P5543, DOI 10.1109/CVPR.2017.588
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu J, 2020, IEEE T PATTERN ANAL, V42, P494, DOI 10.1109/TPAMI.2019.2894422
   Luo Z., 2020, ABS201215175 ARXIV, P1
   Luvizon DC, 2019, COMPUT GRAPH-UK, V85, P15, DOI 10.1016/j.cag.2019.09.002
   Martinez J, 2017, IEEE I CONF COMP VIS, P2659, DOI 10.1109/ICCV.2017.288
   Mehta D, 2020, ACM T GRAPHIC, V39, DOI 10.1145/3386569.3392410
   Mehta D, 2018, INT CONF 3D VISION, P120, DOI 10.1109/3DV.2018.00024
   Mehta D, 2017, INT CONF 3D VISION, P506, DOI 10.1109/3DV.2017.00064
   Mehta D, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073596
   Moon G, 2019, IEEE I CONF COMP VIS, P10132, DOI 10.1109/ICCV.2019.01023
   Munea TL, 2020, IEEE ACCESS, V8, P133330, DOI 10.1109/ACCESS.2020.3010248
   Newell A, 2016, LECT NOTES COMPUT SC, V9912, P483, DOI 10.1007/978-3-319-46484-8_29
   Nie XC, 2018, PROC CVPR IEEE, P2100, DOI 10.1109/CVPR.2018.00224
   Osokin D, 2019, ICPRAM: PROCEEDINGS OF THE 8TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION APPLICATIONS AND METHODS, P744, DOI 10.5220/0007555407440748
   Papandreou G, 2017, PROC CVPR IEEE, P3711, DOI 10.1109/CVPR.2017.395
   Pavlakos G, 2017, PROC CVPR IEEE, P1253, DOI 10.1109/CVPR.2017.138
   Pavllo D, 2019, PROC CVPR IEEE, P7745, DOI 10.1109/CVPR.2019.00794
   Pfister T, 2015, LECT NOTES COMPUT SC, V9003, P538, DOI 10.1007/978-3-319-16865-4_35
   Pishchulin L, 2016, PROC CVPR IEEE, P4929, DOI 10.1109/CVPR.2016.533
   Remelli E, 2020, PROC CVPR IEEE, P6039, DOI 10.1109/CVPR42600.2020.00608
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rhodin H, 2018, LECT NOTES COMPUT SC, V11214, P765, DOI 10.1007/978-3-030-01249-6_46
   Rogez G, 2020, IEEE T PATTERN ANAL, V42, P1146, DOI 10.1109/TPAMI.2019.2892985
   Sapp B, 2013, PROC CVPR IEEE, P3674, DOI 10.1109/CVPR.2013.471
   Sarafianos N, 2016, COMPUT VIS IMAGE UND, V152, P1, DOI 10.1016/j.cviu.2016.09.002
   Sigal L, 2010, INT J COMPUT VISION, V87, P4, DOI 10.1007/s11263-009-0273-6
   Simonyan K., 2014, 14091556 ARXIV
   Su Z., 2019, arXiv
   Sun K, 2019, PROC CVPR IEEE, P5686, DOI 10.1109/CVPR.2019.00584
   Sun K, 2017, IEEE I CONF COMP VIS, P5600, DOI 10.1109/ICCV.2017.597
   Sun X, 2018, LECT NOTES COMPUT SC, V11210, P536, DOI 10.1007/978-3-030-01231-1_33
   Sun X, 2017, IEEE I CONF COMP VIS, P2621, DOI 10.1109/ICCV.2017.284
   Takahashi K, 2018, IEEE COMPUT SOC CONF, P1856, DOI 10.1109/CVPRW.2018.00230
   Tekin B., 2016, ARXIV PREPRINT, DOI [10.5244/c.30.130, DOI 10.5244/C.30.130]
   Tome D, 2017, PROC CVPR IEEE, P5689, DOI 10.1109/CVPR.2017.603
   Toshev A, 2014, PROC CVPR IEEE, P1653, DOI 10.1109/CVPR.2014.214
   Tu H., 2020, EUR C COMP VIS ECCV, DOI [10.1007/978-3-030-58452-8_12, DOI 10.1007/978-3-030-58452-8_12]
   von Marcard T, 2018, LECT NOTES COMPUT SC, V11214, P614, DOI 10.1007/978-3-030-01249-6_37
   Wandt Bastian, 2021, 2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), P13289, DOI 10.1109/CVPR46437.2021.01309
   Wandt B, 2019, PROC CVPR IEEE, P7774, DOI 10.1109/CVPR.2019.00797
   Wang JH, 2021, PROC CVPR IEEE, P11850, DOI 10.1109/CVPR46437.2021.01168
   Wang M, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P978
   Wei SE, 2016, PROC CVPR IEEE, P4724, DOI 10.1109/CVPR.2016.511
   Wu J., 2017, CoRR abs/1711.06475
   Wu W., 2020, Tech. Rep. 6
   Xia FT, 2017, PROC CVPR IEEE, P6080, DOI 10.1109/CVPR.2017.644
   Xiao B, 2018, LECT NOTES COMPUT SC, V11210, P472, DOI 10.1007/978-3-030-01231-1_29
   Xu JW, 2020, PROC CVPR IEEE, P896, DOI 10.1109/CVPR42600.2020.00098
   Yang W, 2018, PROC CVPR IEEE, P5255, DOI 10.1109/CVPR.2018.00551
   Yang W, 2017, IEEE I CONF COMP VIS, P1290, DOI 10.1109/ICCV.2017.144
   Yang Y, 2011, PROC CVPR IEEE, P1385, DOI 10.1109/CVPR.2011.5995741
   Zhang F, 2020, PROC CVPR IEEE, P7091, DOI 10.1109/CVPR42600.2020.00712
   Zhang WY, 2013, IEEE I CONF COMP VIS, P2248, DOI 10.1109/ICCV.2013.280
   Zhen Jianan, 2020, EUROPEAN C COMPUTER, DOI 10.1007/978-3030-58555-6
   Zhong FJ, 2021, NEUROCOMPUTING, V423, P327, DOI 10.1016/j.neucom.2020.11.003
   Zhou XY, 2017, IEEE I CONF COMP VIS, P398, DOI 10.1109/ICCV.2017.51
NR 113
TC 38
Z9 39
U1 12
U2 118
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2021
VL 114
AR 104282
DI 10.1016/j.imavis.2021.104282
EA AUG 2021
PG 23
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA UR9HP
UT WOS:000697051200005
DA 2024-07-18
ER

PT J
AU Cores, D
   Brea, VM
   Mucientes, M
AF Cores, Daniel
   Brea, Victor M.
   Mucientes, Manuel
TI Short-term anchor linking and long-term self-guided attention for video
   object detection
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video object detection; Spatio-temporal features; Convolutional neural
   networks
AB We present a new network architecture able to take advantage of spatio-temporal information available in videos to boost object detection precision. First, box features are associated and aggregated by linking proposals that come from the same anchor box in the nearby frames. Then, we design a new attention module that aggregates short-term enhanced box features to exploit long-term spatio-temporal information. This module takes advantage of geometrical features in the long-term for the first time in the video object detection domain. Finally, a spatio-temporal double head is fed with both spatial information from the reference frame and the aggregated information that takes into account the shortand long-term temporal context. We have tested our proposal in five video object detection datasets with very different characteristics, in order to prove its robustness in a wide number of scenarios. Non-parametric statistical tests show that our approach outperforms the state-ofthe-art. Our code is available at https://github.com/daniel-cores/SLTnet.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Cores, Daniel; Brea, Victor M.; Mucientes, Manuel] Univ Santiago de Compostela, Ctr Singular Invest Tecnoloxias Intelixentes CiTI, Santiago De Compostela, Spain.
C3 Universidade de Santiago de Compostela
RP Cores, D (corresponding author), Univ Santiago de Compostela, Ctr Singular Invest Tecnoloxias Intelixentes CiTI, Santiago De Compostela, Spain.
EM daniel.cores@usc.es; victor.brea@usc.es; manuel.mucientes@usc.es
RI Cores Costa, Daniel/GRE-6003-2022; Brea, Victor M/N-5165-2014;
   Mucientes, Manuel/L-7100-2014
OI Cores Costa, Daniel/0000-0002-5548-4837; Mucientes,
   Manuel/0000-0003-1735-3585
FU Spanish Ministry of Science, Innovation and Universities
   [TIN2017-84796-C2-1-R, RTI2018097088BC32]; Galician Ministry of
   Education, Culture and Universities [ED431C 2018/29, ED431C 2017/69,
   ED431G/08]; European Regional Development Fund (ERDF/FEDER program)
FX This research was partially funded by the Spanish Ministry of Science,
   Innovation and Universities under grants TIN2017-84796-C2-1-R and
   RTI2018097088BC32, and the Galician Ministry of Education, Culture and
   Universities under grants ED431C 2018/29, ED431C 2017/69 and
   accreditation 2016-2019, ED431G/08. These grants are cofunded by the
   European Regional Development Fund (ERDF/FEDER program) .
CR Bertasius G, 2018, LECT NOTES COMPUT SC, V11216, P342, DOI 10.1007/978-3-030-01258-8_21
   Bosquet B., 2018, P 29 BRIT MACH VIS C
   Bosquet B, 2020, ENG APPL ARTIF INTEL, V91, DOI 10.1016/j.engappai.2020.103615
   Chen Y., 2020, CVPR, P10337
   Cores D, 2020, FRONT ARTIF INTEL AP, V325, P2680, DOI 10.3233/FAIA200406
   Dendorfer P., 2020, Mot20: A benchmark for multi object tracking in crowded scenes
   Deng HM, 2019, IEEE I CONF COMP VIS, P6677, DOI 10.1109/ICCV.2019.00678
   Deng JJ, 2019, IEEE I CONF COMP VIS, P7022, DOI 10.1109/ICCV.2019.00712
   Du DW, 2018, LECT NOTES COMPUT SC, V11214, P375, DOI 10.1007/978-3-030-01249-6_23
   Feichtenhofer C, 2017, IEEE I CONF COMP VIS, P3057, DOI 10.1109/ICCV.2017.330
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Guo CX, 2019, IEEE I CONF COMP VIS, P3908, DOI 10.1109/ICCV.2019.00401
   Hu H, 2018, PROC CVPR IEEE, P3588, DOI 10.1109/CVPR.2018.00378
   Kalogeiton V, 2017, IEEE I CONF COMP VIS, P4415, DOI 10.1109/ICCV.2017.472
   Kang K, 2018, IEEE T CIRC SYST VID, V28, P2896, DOI 10.1109/TCSVT.2017.2736553
   Kang K, 2017, PROC CVPR IEEE, P889, DOI 10.1109/CVPR.2017.101
   Kang K, 2016, PROC CVPR IEEE, P817, DOI 10.1109/CVPR.2016.95
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Lin TY, 2020, IEEE T PATTERN ANAL, V42, P318, DOI 10.1109/TPAMI.2018.2858826
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Ling H., 2018, Vision Meets Drones: A Challenge
   Liu S, 2018, PROC CVPR IEEE, P8759, DOI 10.1109/CVPR.2018.00913
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mhalla A, 2019, IMAGE VISION COMPUT, V88, P120, DOI 10.1016/j.imavis.2019.03.002
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rodríguez-Fdez I, 2015, IEEE INT FUZZY SYST
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Shvets M, 2019, IEEE I CONF COMP VIS, P9755, DOI 10.1109/ICCV.2019.00985
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tang P, 2020, IEEE T PATTERN ANAL, V42, P1272, DOI 10.1109/TPAMI.2019.2910529
   Tian Z, 2019, IEEE I CONF COMP VIS, P9626, DOI 10.1109/ICCV.2019.00972
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang SY, 2018, LECT NOTES COMPUT SC, V11217, P557, DOI 10.1007/978-3-030-01261-8_33
   Wu HP, 2019, IEEE I CONF COMP VIS, P9216, DOI 10.1109/ICCV.2019.00931
   Xiao FY, 2018, LECT NOTES COMPUT SC, V11212, P494, DOI 10.1007/978-3-030-01237-3_30
   Xiao T, 2017, PROC CVPR IEEE, P3376, DOI 10.1109/CVPR.2017.360
   Zhu XZ, 2019, PROC CVPR IEEE, P9300, DOI 10.1109/CVPR.2019.00953
   Zhu XZ, 2017, IEEE I CONF COMP VIS, P408, DOI 10.1109/ICCV.2017.52
NR 40
TC 7
Z9 7
U1 2
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2021
VL 110
AR 104179
DI 10.1016/j.imavis.2021.104179
EA APR 2021
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA SI2OO
UT WOS:000654665700004
OA Green Published, hybrid
DA 2024-07-18
ER

PT J
AU Georgopoulos, M
   Panagakis, Y
   Pantic, M
AF Georgopoulos, Markos
   Panagakis, Yannis
   Pantic, Maja
TI Investigating bias in deep face analysis: The KANFace dataset and
   empirical study
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Dataset bias; Face recognition; Age estimation; Gender recognition;
   Kinship verification
ID KINSHIP; GENDER; AGE
AB Deep learning-based methods have pushed the limits of the state-of-the-art in face analysis. However, despite their success, these models have raised concerns regarding their bias towards certain demographics. This bias is inflicted both by limited diversity across demographics in the training set, as well as the design of the algorithms. In this work, we investigate the demographic bias of deep learning models in face recognition, age estimation, gender recognition and kinship verification. To this end, we introduce the most comprehensive, large-scale dataset of facial images and videos to date. It consists of 40K still images and 44K sequences (14.5M video frames in total) captured in unconstrained, real-world conditions from 1,045 subjects. The data are manually annotated in terms of identity, exact age, gender and kinship. The performance of state-of-the-art models is scrutinized and demographic bias is exposed by conducting a series of experiments. Lastly, a method to debias network embeddings is introduced and tested on the proposed benchmarks. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Georgopoulos, Markos; Pantic, Maja] Imperial Coll London, Dept Comp, London, England.
   [Panagakis, Yannis] Univ Athens, Dept Informat & Telecommun, Athens, Greece.
C3 Imperial College London; National & Kapodistrian University of Athens
RP Georgopoulos, M (corresponding author), Imperial Coll London, Dept Comp, London, England.
EM m.georgopoulos@imperial.ac.uk
RI Panagakis, Yannis/AAZ-8090-2020
OI Panagakis, Ioannis/0000-0003-0153-5210
FU EPSRC [EP/N007743/1]; EPSRC [EP/N007743/1] Funding Source: UKRI
FX The work of M. Georgopoulos is funded by the EPSRC project EP/N007743/1
   (FACER2VM).
CR [Anonymous], 2015, BRIT MACH VIS C
   [Anonymous], 2002, FG NET AGING DATABAS
   [Anonymous], 2016, FAMILY WILD FIW LARG
   Bansal A, 2017, 2017 IEEE INTERNATIONAL JOINT CONFERENCE ON BIOMETRICS (IJCB), P456
   Bansal A, 2017, IEEE INT CONF COMP V, P2545, DOI 10.1109/ICCVW.2017.299
   Baudouin JY, 2002, J EXP PSYCHOL LEARN, V28, P362, DOI 10.1037/0278-7393.28.2.362
   BOTHWELL RK, 1989, PERS SOC PSYCHOL B, V15, P19, DOI 10.1177/0146167289151002
   Buolamwini J., 2018, FACCT, P77
   Cao Q, 2018, IEEE INT CONF AUTOMA, P67, DOI 10.1109/FG.2018.00020
   Chen BC, 2015, IEEE T MULTIMEDIA, V17, P804, DOI 10.1109/TMM.2015.2420374
   Chung JY, 2015, PR MACH LEARN RES, V37, P2067
   Dibeklioglu H, 2012, LECT NOTES COMPUT SC, V7574, P525, DOI 10.1007/978-3-642-33712-3_38
   Eidinger E, 2014, IEEE T INF FOREN SEC, V9, P2170, DOI 10.1109/TIFS.2014.2359646
   Fang RG, 2010, IEEE IMAGE PROC, P1577, DOI 10.1109/ICIP.2010.5652590
   Ganin Y, 2016, J MACH LEARN RES, V17
   Georgopoulos M, 2018, IMAGE VISION COMPUT, V80, P58, DOI 10.1016/j.imavis.2018.05.003
   Guo YD, 2016, LECT NOTES COMPUT SC, V9907, P87, DOI 10.1007/978-3-319-46487-9_6
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heip Carlo H. R., 1998, Oceanis, V24, P61
   Hochreiter S, 1997, NEURAL COMPUT, V9, P1735, DOI [10.1162/neco.1997.9.1.1, 10.1007/978-3-642-24797-2]
   Hoss RA, 2005, PERCEPTION, V34, P1459, DOI 10.1068/p5154
   Huang G.B., 2008, TECH REP
   Kemelmacher-Shlizerman I, 2016, PROC CVPR IEEE, P4873, DOI 10.1109/CVPR.2016.527
   Lanitis A, 2002, IEEE T PATTERN ANAL, V24, P442, DOI 10.1109/34.993553
   Liu L, 2020, INT J COMPUT VISION, V128, P261, DOI 10.1007/s11263-019-01247-4
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   López MB, 2016, IEEE T PATTERN ANAL, V38, P2342, DOI 10.1109/TPAMI.2016.2522416
   Lovén J, 2011, EXP PSYCHOL, V58, P333, DOI 10.1027/1618-3169/a000100
   Lu JW, 2014, IEEE T PATTERN ANAL, V36, P331, DOI 10.1109/TPAMI.2013.134
   Masi I, 2018, SIBGRAPI, P471, DOI 10.1109/SIBGRAPI.2018.00067
   Merler M., ARXIV190110436
   Minaee S., 2020, ARXIV200105566
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ren S., 2017, IEEETransactionsonPatternAnalysisandMachineIntelligence, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Ricanek K, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P341
   Robinson J. P., 2016, P 24 ACM INT C MULT, P242, DOI DOI 10.1145/2964284.2967219
   Rothe R, 2018, INT J COMPUT VISION, V126, P144, DOI 10.1007/s11263-016-0940-3
   Schaich A, 2016, FRONT AGING NEUROSCI, V8, DOI 10.3389/fnagi.2016.00264
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Shao M., 2011, CVPR 2011 WORKSH, P60, DOI DOI 10.1109/CVPRW.2011.5981801
   Siarohin A, 2019, ADV NEUR IN, V32
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tommasi T, 2017, ADV COMPUT VIS PATT, P37, DOI 10.1007/978-3-319-58347-1_2
   Torralba A, 2011, PROC CVPR IEEE, P1521, DOI 10.1109/CVPR.2011.5995347
   TURK MA, 1991, 1991 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, P586
   Tzeng E, 2015, IEEE I CONF COMP VIS, P4068, DOI 10.1109/ICCV.2015.463
   Tzeng E, 2017, PROC CVPR IEEE, P2962, DOI 10.1109/CVPR.2017.316
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Voelkle MC, 2012, PSYCHOL AGING, V27, P265, DOI 10.1037/a0025065
   Vougioukas K, 2020, INT J COMPUT VISION, V128, P1398, DOI 10.1007/s11263-019-01251-8
   Whitelam C, 2017, IEEE COMPUT SOC CONF, P592, DOI 10.1109/CVPRW.2017.87
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Wu X, 2018, IEEE T INF FOREN SEC, V13, P2884, DOI 10.1109/TIFS.2018.2833032
   Xia S., 2011, Proceedings of the 22nd International Joint Conference on Artificial Intelligence, P2539, DOI DOI 10.5591/978-1-57735-516-8/IJCAI11-422
   Yang TY, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1078
   Yi D, 2014, INT C PATT RECOG, P34, DOI 10.1109/ICPR.2014.16
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zou J., 2018, AI can be sexist and racist-it's time to make it fair
NR 59
TC 15
Z9 15
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2020
VL 102
AR 103954
DI 10.1016/j.imavis.2020.103954
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Social Science Citation Index (SSCI)
SC Computer Science; Engineering; Optics
GA NZ0FS
UT WOS:000576766700010
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Perng, JW
   Hsu, YW
   Yang, YZ
   Chen, CY
   Yin, TK
AF Perng, Jau Woei
   Hsu, Ya Wen
   Yang, Ya Zhu
   Chen, Chia Yen
   Yin, Tang Kai
TI Development of an embedded road boundary detection system based on deep
   learning
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Embedded system; Hyperbola model; Lane detection;
   Particle filter
ID VANISHING POINT DETECTION; LANE DETECTION; TRACKING; FILTERS; MODEL
AB The ability to sense the surrounding environment is an important developing technology in the field of automated vehicles. Lane line detection could determine a vehicle's travelable area. An embedded road boundary detection system based on deep learning was developed in this study. The system can detect structured and unstructured roads in a variety of situations. To obtain an image with clear lane markings, a convolution autoencoder with the characteristics of noise reduction and reconstruction was used to remove all objects in the images except lane markings. Then, the feature points of the lane line were extracted, and the lane line was fitted with a hyperbolic model. Finally, a particle filter was used for lane tracking. The road boundary detection system was implemented on the NVIDIA Jetson TX2 platform. Three different situations, day, night, and rainy day were selected to demonstrate the performance of the proposed algorithm. Additionally, to deal with structured roads, some special scenes, such as shadows, tunnels, degenerate lane markings, and blocked lane markings, were considered. According to the experimental results, the accuracy of the proposed lane detection system for structured and unstructured roads was 90.02%. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Perng, Jau Woei; Hsu, Ya Wen; Yang, Ya Zhu] Natl Sun Yat Sen Univ, Dept Mech & Electromech Engn, Kaohsiung, Taiwan.
   [Chen, Chia Yen] Univ Auckland, Dept Comp Sci, Auckland, New Zealand.
   [Yin, Tang Kai] Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.
C3 National Sun Yat Sen University; University of Auckland; National
   University Kaohsiung
RP Yin, TK (corresponding author), Natl Univ Kaohsiung, Dept Comp Sci & Informat Engn, Kaohsiung, Taiwan.
EM tkyin@nuk.edu.tw
RI zhen, wang/KBA-3844-2024
FU NSYSU-NUK JOINT RESEARCH PROJECT through National Sun Yat-sen
   University; National University of Kaohsiung [NSYSUNUK 107-P003]
FX This work was supported by the NSYSU-NUK JOINT RESEARCH PROJECT through
   National Sun Yat-sen University and National University of Kaohsiung
   [grant number #NSYSUNUK 107-P003].
CR Aly M, 2008, IEEE INT VEH SYM, P165, DOI 10.1109/ivs.2008.4621152
   [Anonymous], 2018, ARXIV180205591
   [Anonymous], 2015, 3 INT C LEARNING REP
   [Anonymous], 2012, PARTICLE FILTERING
   Bai L, 2008, KNOWL-BASED SYST, V21, P265, DOI 10.1016/j.knosys.2007.11.012
   Bai L, 2011, COMPUT VIS IMAGE UND, V115, P1463, DOI 10.1016/j.cviu.2011.06.005
   Bai L, 2010, PATTERN ANAL APPL, V13, P251, DOI 10.1007/s10044-010-0175-9
   Cheng HY, 2010, IET COMPUT VIS, V4, P37, DOI 10.1049/iet-cvi.2007.0073
   Deng L, 2010, 2011 INTERNATIONAL CONFERENCE ON COMPUTERS, COMMUNICATIONS, CONTROL AND AUTOMATION (CCCA 2011), VOL III, P27
   Ding WL, 2016, IET COMPUT VIS, V10, P852, DOI 10.1049/iet-cvi.2015.0390
   Ding WL, 2015, IET COMPUT VIS, V9, P549, DOI 10.1049/iet-cvi.2014.0187
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Fan X, 2016, IET COMPUT VIS, V10, P503, DOI 10.1049/iet-cvi.2015.0313
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Han J, 2014, INT J AUTO TECH-KOR, V15, P611, DOI 10.1007/s12239-014-0064-0
   Kim J, 2017, NEURAL NETWORKS, V87, P109, DOI 10.1016/j.neunet.2016.12.002
   LeCun Y., 1990, NeurIPS, P396
   Madrid N., 2015, FUZZY SETS SYST, V92, P319
   Mammeri A, 2016, COMPUT COMMUN, V73, P132, DOI 10.1016/j.comcom.2015.08.010
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Niu JW, 2016, PATTERN RECOGN, V59, P225, DOI 10.1016/j.patcog.2015.12.010
   Pan XG, 2018, AAAI CONF ARTIF INTE, P7276
   Park JM, 2018, IMAGE VISION COMPUT, V79, P11, DOI 10.1016/j.imavis.2018.04.003
   Shi JJ, 2016, IEEE T INTELL TRANSP, V17, P970, DOI 10.1109/TITS.2015.2490556
   Phung SL, 2016, COMPUT VIS IMAGE UND, V149, P186, DOI 10.1016/j.cviu.2016.01.011
   Tian Y, 2018, NEUROCOMPUTING, V280, P46, DOI 10.1016/j.neucom.2017.09.098
   Wang Y, 2008, IEEE T INTELL TRANSP, V9, P570, DOI 10.1109/TITS.2008.2006733
   Wang YF, 2012, SIGNAL PROCESS, V92, P319, DOI 10.1016/j.sigpro.2011.07.019
   Yi SC, 2015, COMPUT ELECTR ENG, V42, P23, DOI 10.1016/j.compeleceng.2015.01.002
   Yim YU, 2003, IEEE T INTELL TRANSP, V4, P219, DOI 10.1109/TITS.2003.821339
   Zhoam K., 2012, P IEEE INT VEH S IV, P3
NR 31
TC 16
Z9 18
U1 6
U2 27
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2020
VL 100
AR 103935
DI 10.1016/j.imavis.2020.103935
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA MY9GX
UT WOS:000558728800005
DA 2024-07-18
ER

PT J
AU Zheng, MT
   Wang, SG
   Xiong, XD
   Zhu, JF
AF Zheng, Maoteng
   Wang, Shiguang
   Xiong, Xiaodong
   Zhu, Junfeng
TI A fast and accurate iterative method for the camera pose estimation
   problem
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Camera pose estimation; Direct relative orientation; Iterative method;
   Parameterization; Gross detection and elimination
ID ALGORITHM; RANSAC; MOTION
AB This paper presents a fast and accurate iterative method for camera pose estimation problem. The dependence on initial values is reduced by replacing unknown angular parameters with three independent non-angular parameters. Image point coordinates are treated as observations with errors and a new model is built using a conditional adjustment with parameters for relative orientation. This model allows for the estimation of the errors in the observations. The estimated observation errors are then used iteratively to detect and eliminate gross errors in the adjustment. A total of 22 synthetic datasets and 10 real datasets are used to compare the proposed method with the traditional iterative method, the 5-point-RANSAC and the state-of-the-art 5-point-USAC methods. Preliminary results show that our proposed method is not only faster than the other methods, but also more accurate and stable. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Zheng, Maoteng; Wang, Shiguang] China Univ Geosci, Natl Engn Res Ctr Geog Informat Syst, Wuhan, Peoples R China.
   [Wang, Shiguang] China Aero Geophys Survey & Remote Sensing Ctr La, Beijing, Peoples R China.
   [Xiong, Xiaodong; Zhu, Junfeng] Beijing Smart Mapping Technol Co Ltd, Beijing, Peoples R China.
C3 China University of Geosciences
RP Zheng, MT (corresponding author), China Univ Geosci, Natl Engn Res Ctr Geog Informat Syst, Wuhan, Peoples R China.
EM tengve@163.com
RI zheng, maoteng/KDN-2048-2024; Wang, Shiguang/A-5476-2018
OI zheng, maoteng/0000-0002-3533-4129
FU National Natural Science Foundation of China, China [41601502]; National
   Key Research and Development Program of China, China [2017YFB0503800];
   Fundamental Research Funds for the Central Universities-China University
   of Geosciences (Wuhan), China [CUG170664]
FX Thanks to the Beijing Smart Mapping Technology Co. Ltd., who provided us
   with real datasets for experiments! This project was funded by the
   National Natural Science Foundation of China under grant (No. 41601502),
   China; The National Key Research and Development Program of China (No.
   2017YFB0503800), China; and the Fundamental Research Funds for the
   Central Universities-China University of Geosciences (Wuhan) under grant
   (No. CUG170664), China.
CR [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], TRITAMAT1998MA13
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 1993, SPRINGER SERIES INFO
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Chum O, 2003, LECT NOTES COMPUT SC, V2781, P236
   Chum O., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P623
   Chum O, 2008, IEEE T PATTERN ANAL, V30, P1472, DOI 10.1109/TPAMI.2007.70787
   FAUGERAS OD, 1990, INT J COMPUT VISION, V4, P225, DOI 10.1007/BF00054997
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hartley RI, 1997, IEEE T PATTERN ANAL, V19, P580, DOI 10.1109/34.601246
   Hartley R, 2012, IEEE T PATTERN ANAL, V34, P2303, DOI 10.1109/TPAMI.2012.43
   Heyden A, 1999, J MATH IMAGING VIS, V10, P123, DOI 10.1023/A:1008370905794
   HORN BKP, 1990, INT J COMPUT VISION, V4, P59, DOI 10.1007/BF00137443
   Huber P., 1981, Robust Statistics
   Kalantari M, 2011, J MATH IMAGING VIS, V39, P259, DOI 10.1007/s10851-010-0234-2
   Li B, 2013, IEEE INT C INT ROBOT, P1595, DOI 10.1109/IROS.2013.6696562
   LONGUETHIGGINS HC, 1981, NATURE, V293, P133, DOI 10.1038/293133a0
   MARONNA RA, 1976, ANN STAT, V4, P51, DOI 10.1214/aos/1176343347
   Matas J, 2005, IEEE I CONF COMP VIS, P1727
   Myatt D. R., 2002, Electronic Proceedings of the 13th British Machine Vision Conference, P458
   NI K, 2009, INT C COMP VIS
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nistér D, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P199
   Palmer T, 2017, PROC CVPR IEEE, P4551, DOI 10.1109/CVPR.2017.484
   PHILIP J, 1996, PHOTOGRAMM REC, V15, P589, DOI DOI 10.1111/0031-868X.00066
   Raguram R, 2008, LECT NOTES COMPUT SC, V5303, P500, DOI 10.1007/978-3-540-88688-4_37
   Raguram R, 2013, IEEE T PATTERN ANAL, V35, P2022, DOI 10.1109/TPAMI.2012.257
   Stewénius H, 2006, ISPRS J PHOTOGRAMM, V60, P284, DOI 10.1016/j.isprsjprs.2006.03.005
   STUELPNA.J, 1964, SIAM REV, V6, P422, DOI 10.1137/1006093
   Thompson E.H., 1959, The Photogrammetric Record, V3, P152
   THOMPSON EH, 1968, PHOTOGRAMMETRIA, V23, P67, DOI 10.1016/0031-8663(68)90028-8
   Torr PHS, 1997, INT J COMPUT VISION, V24, P271, DOI 10.1023/A:1007927408552
   TSAI RY, 1984, IEEE T PATTERN ANAL, V6, P13, DOI 10.1109/TPAMI.1984.4767471
   ZHANG Z, 1996, RR2927 INRIA
   ZHANG ZY, 1995, ARTIF INTELL, V78, P87, DOI 10.1016/0004-3702(95)00022-4
NR 44
TC 1
Z9 1
U1 2
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29a, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2020
VL 94
AR 103860
DI 10.1016/j.imavis.2019.103860
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KU4FH
UT WOS:000519664900003
DA 2024-07-18
ER

PT J
AU Huang, B
   Chen, RW
   Xu, W
   Zhou, QB
AF Huang, Bin
   Chen, Renwen
   Xu, Wang
   Zhou, Qinbang
TI Improving head pose estimation using two-stage ensembles with
   top-<i>k</i> regression
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D head pose estimation; Average top-k regression; Task-dependent
   weights; Two-stage ensembles
AB Conventional head pose estimation methods are regarded as a classification or regression paradigm, individually. The accuracy of classification-based approaches is limited to pose quantized interval and regression-based methods are fragile due to extremely large pose in non-ideal conditions. On the contrary to these methods, this paper introduces a novel head pose estimation method using two-stage ensembles with average top-k regression. The first stage is a binned classification subtask with the optimal pose partition. The second stage achieves average top-k regression based on the former prediction. Then we combine the two subtasks by considering the task-dependent weights instead of setting coefficients by grid search. We conduct several experiments to analyze the optimal pose partition for classification part and to validate the average top-k loss for regression part. Furthermore, we report the performance of proposed method on MW, AFLW2000 and BIWI datasets and results show rather competitive performance in head pose prediction. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Huang, Bin; Chen, Renwen; Xu, Wang; Zhou, Qinbang] Nanjing Univ Aeronaut & Astronaut, State Key Lab Mech & Control Mech Struct, Nanjing 210016, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics
RP Huang, B (corresponding author), Nanjing Univ Aeronaut & Astronaut, State Key Lab Mech & Control Mech Struct, Nanjing 210016, Peoples R China.
EM binhuang@nuaa.edu.cn
FU National Science Foundation of China [51675265]; Priority Academic
   Program Development of Jiangsu Higher Education Institutions (grant
   PAPD)
FX This work was supported National Science Foundation of China (grant
   51675265), and the Priority Academic Program Development of Jiangsu
   Higher Education Institutions (grant PAPD).
CR Ahn B, 2018, ROBOT AUTON SYST, V103, P1, DOI 10.1016/j.robot.2018.01.005
   Ahn B, 2015, LECT NOTES COMPUT SC, V9005, P82, DOI 10.1007/978-3-319-16811-1_6
   [Anonymous], ARXIV150703148
   [Anonymous], 2017, ARXIV170508826
   [Anonymous], P 1 IEEE INT WORKSH
   [Anonymous], 2004, IEEE INT C NETW SENS
   [Anonymous], 2004, FG NET WORKSH VIS OB
   BenAbdelkader C, 2010, LECT NOTES COMPUT SC, V6316, P518, DOI 10.1007/978-3-642-15567-3_38
   Brown LM, 2002, IEEE WORKSHOP ON MOTION AND VIDEO COMPUTING (MOTION 2002), PROCEEDINGS, P125, DOI 10.1109/MOTION.2002.1182224
   Bulat A, 2017, IEEE I CONF COMP VIS, P1021, DOI 10.1109/ICCV.2017.116
   Fanelli G, 2013, INT J COMPUT VISION, V101, P437, DOI 10.1007/s11263-012-0549-0
   Foytik J, 2013, INT J COMPUT VISION, V101, P270, DOI 10.1007/s11263-012-0567-y
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gong B., 2009, Proceedings of the 17th ACM International Conference on Multimedia, P569
   Gourier N, 2007, LECT NOTES COMPUT SC, V4122, P270
   Hao Ji, 2011, 2011 18th IEEE International Conference on Image Processing (ICIP 2011), P3617, DOI 10.1109/ICIP.2011.6116500
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kazemi V, 2014, PROC CVPR IEEE, P1867, DOI 10.1109/CVPR.2014.241
   King DE, 2009, J MACH LEARN RES, V10, P1755
   Kumar A, 2017, IEEE INT CONF AUTOMA, P258, DOI 10.1109/FG.2017.149
   Langton SRH, 2004, PERCEPT PSYCHOPHYS, V66, P752, DOI 10.3758/BF03194970
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Z, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOLS 1-5, P1810
   Murphy-Chutorian E, 2009, IEEE T PATTERN ANAL, V31, P607, DOI 10.1109/TPAMI.2008.106
   Osuna E, 1997, PROC CVPR IEEE, P130, DOI 10.1109/CVPR.1997.609310
   Patacchiola M, 2017, PATTERN RECOGN, V71, P132, DOI 10.1016/j.patcog.2017.06.009
   Ranjan R, 2019, IEEE T PATTERN ANAL, V41, P121, DOI 10.1109/TPAMI.2017.2781233
   Ruiz Nataniel, 2018, IEEE C COMP VIS PATT
   Stiefelhagen R., 2004, Pointing Workshop, P21
   Sundararajan K, 2015, IEEE COMPUT SOC CONF
   Tang X, 2018, NEUROCOMPUTING, V297, P22, DOI 10.1016/j.neucom.2018.01.080
   Tian YL, 2003, IEEE INTERNATIONAL WORKSHOP ON ANALYSIS AND MODELING OF FACE AND GESTURES, P92
   Xu X, 2017, IEEE INT CONF AUTOMA, P642, DOI 10.1109/FG.2017.81
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhang ZQ, 2007, LECT NOTES COMPUT SC, V4122, P299
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 37
TC 32
Z9 32
U1 0
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103827
DI 10.1016/j.imavis.2019.11.005
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000014
DA 2024-07-18
ER

PT J
AU Mahmood, A
   Bennamoun, M
   An, S
   Sohel, F
   Boussaid, F
AF Mahmood, Ammar
   Bennamoun, Mohammed
   An, Senjian
   Sohel, Ferdous
   Boussaid, Farid
TI ResFeats: Residual network based features for underwater image
   classification
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Deep learning; Residual networks; Deep features; Image classification;
   Underwater image classification
AB Oceanographers rely on advanced digital imaging systems to assess the health of marine ecosystems. The majority of the imagery collected by these systems do not get annotated due to lack of resources. Consequently, the expert labeled data is not enough to train dedicated deep networks. Meanwhile, in the deep learning community, much focus is on how to use pre-trained deep networks to classify out-of-domain images and transfer learning. In this paper, we leverage these advances to evaluate how well features extracted from deep neural networks transfer to underwater image classification. We propose new image features (called ResFeats) extracted from the different convolutional layers of a deep residual network pre-trained on ImageNet. We further combine the ResFeats extracted from different layers to obtain compact and powerful deep features. Moreover, we show that ResFeats consistently perform better than their CNN counterparts. Experimental results are provided to show the effectiveness of ResFeats with state-of-the-art classification accuracies on MLC, Benthoz15, EILAT and RSMAS datasets. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Mahmood, Ammar; Bennamoun, Mohammed; An, Senjian; Boussaid, Farid] Univ Western Australia, Nedlands, WA 6009, Australia.
   [Sohel, Ferdous] Murdoch Univ, Murdoch, WA 6150, Australia.
C3 University of Western Australia; Murdoch University
RP Mahmood, A (corresponding author), Univ Western Australia, Nedlands, WA 6009, Australia.
EM ammar.mahmood@research.uwa.edu.au
RI An, Senjian/H-8746-2014; Sohel, Ferdous/C-2428-2013; Bennamoun,
   Mohammed/C-2789-2013
OI Sohel, Ferdous/0000-0003-1557-4907; Bennamoun,
   Mohammed/0000-0002-6603-3257; An, Senjian/0000-0002-1758-6824; BOUSSAID,
   FARID/0000-0001-7250-7407
FU Australian Research Council [DP150104251, DE120102960]; Integrated
   Marine Observing System (IMOS) through the Department of Innovation,
   Industry, Science and Research (DIISR), National Collaborative Research
   Infrastructure Scheme; Australian Research Council [DE120102960] Funding
   Source: Australian Research Council
FX This research was partially supported by Australian Research Council
   grants (DP150104251 and DE120102960) and the Integrated Marine Observing
   System (IMOS) through the Department of Innovation, Industry, Science
   and Research (DIISR), National Collaborative Research Infrastructure
   Scheme. The authors also acknowledge NVIDIA for providing a Titan-X GPU
   for the experiments involved in this research.
CR [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   Azizpour Hossein, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P36, DOI 10.1109/CVPRW.2015.7301270
   Beijbom O, 2012, PROC CVPR IEEE, P1170, DOI 10.1109/CVPR.2012.6247798
   Bewley M, 2015, SCI DATA, V2, DOI 10.1038/sdata.2015.57
   Bo LF, 2013, PROC CVPR IEEE, P660, DOI 10.1109/CVPR.2013.91
   Chatfield K, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.76
   Cimpoi M, 2015, PROC CVPR IEEE, P3828, DOI 10.1109/CVPR.2015.7299007
   Donahue J., 2005, DECAF DEEP CONVOLUTI
   Donggeun Yoo, 2015, 2015 IEEE Conference on Computer Vision and Pattern Recognition Workshops (CVPRW), P71, DOI 10.1109/CVPRW.2015.7301274
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Griffin Gregory, 2007, CALTECH 256 OBJECT C
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2014, LECT NOTES COMPUT SC, V8691, P346, DOI [arXiv:1406.4729, 10.1007/978-3-319-10578-9_23]
   Khan Salman H, 2018, IEEE Trans Neural Netw Learn Syst, V29, P3573, DOI 10.1109/TNNLS.2017.2732482
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Liu LQ, 2015, PROC CVPR IEEE, P4749, DOI 10.1109/CVPR.2015.7299107
   Mahmood A, 2016, IEEE IMAGE PROC, P519, DOI 10.1109/ICIP.2016.7532411
   Mahmood A, 2019, IEEE J OCEANIC ENG, V44, P121, DOI 10.1109/JOE.2017.2786878
   Marcos MSAC, 2005, OPT EXPRESS, V13, P8766, DOI 10.1364/OPEX.13.008766
   Mary NAB, 2017, J VIS COMMUN IMAGE R, V49, P225, DOI 10.1016/j.jvcir.2017.09.008
   Nadeem U., 2019, 2019 DIG IM COMP TEC
   Nilsback ME, 2008, SIXTH INDIAN CONFERENCE ON COMPUTER VISION, GRAPHICS & IMAGE PROCESSING ICVGIP 2008, P722, DOI 10.1109/ICVGIP.2008.47
   Pizarro O, 2008, OCEANS-IEEE, P1863
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Rippel Oren., 2015, ICLR
   Sermanet P., 2 INT C LEARN REPR
   Shihavuddin ASM, 2013, OCEANS-IEEE, DOI 10.1109/OCEANS-Bergen.2013.6608111
   Shihavuddin ASM, 2013, REMOTE SENS-BASEL, V5, P1809, DOI 10.3390/rs5041809
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohn K, 2011, IEEE I CONF COMP VIS, P2643, DOI 10.1109/ICCV.2011.6126554
   Srivastava RK, 2015, ARXIV150500387
   Stokes MD, 2009, LIMNOL OCEANOGR-METH, V7, P157, DOI 10.4319/lom.2009.7.157
   Szegedy Christian, 2015, IEEE C COMP VIS PATT, DOI [10.1109/cvpr.2015.7298594, DOI 10.1109/CVPR.2015.7298594]
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 37
TC 36
Z9 36
U1 0
U2 35
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2020
VL 93
AR 103811
DI 10.1016/j.imavis.2019.09.002
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA KM3IZ
UT WOS:000514016000005
DA 2024-07-18
ER

PT J
AU Steiner, H
   Sommerhoff, H
   Bulczak, D
   Jung, N
   Lambers, M
   Kolb, A
AF Steiner, Holger
   Sommerhoff, Hendrik
   Bulczak, David
   Jung, Norbert
   Lambers, Martin
   Kolb, Andreas
TI Fast motion estimation for field sequential imaging: Survey and
   benchmark
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Field sequential imaging; Motion estimation; Optical flow
ID FLIGHT; QUALITY
AB Field sequential (FS) imaging comprises image acquisition systems that capture image channels in temporal sequence in order to provide the final image. A classical application is multispectral imaging. In case of dynamic scenes, the sequential nature of the acquisition imposes motion artifacts, i.e., spatially misaligned images channels. Compensating motion artifacts for this kind of imagery is non-trivial, as common methods for motion estimation rely on the intensity consistency constraint that is violated in FS imaging.
   This paper surveys approaches to motion compensation in the context of FS imaging. We focus on accuracy in handling intensity inconsistent data and, secondarily, speed, as FS imaging is commonly done in real-time. We introduce a conceptual classification for algorithmic approaches for motion estimation for FS imagery and discuss known and modified approaches to tackle the intensity inconsistencies between adjacent image channels using image transformation and intensity correction methods. As result, we get a set of 379 variants of motion estimation methods applicable to FS data streams. We evaluate these methods using our benchmark database, which comprises data sets from the Middlebury and the MPI Sintel databases, modified to emulate FS imagery, as well as additionally captured multispectral short wave infrared (SWIR) and sRGB image sequences, as well as simulated Time-of-Flight (ToF) image sequences that consist of four channels (called phase images). In order to quantify the motion estimation techniques, we use a ranking scheme similar to Middlebury and combine it with a run-time evaluation. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Steiner, Holger; Jung, Norbert] Hsch Bonn Rhein Sieg, St Augustin, Germany.
   [Sommerhoff, Hendrik; Bulczak, David; Lambers, Martin; Kolb, Andreas] Univ Siegen, Siegen, Germany.
C3 Hochschule Bonn Rhein Sieg; Universitat Siegen
RP Kolb, A (corresponding author), Univ Siegen, Siegen, Germany.
EM andreas.kolb@uni-siegen.de
RI ; Kolb, Andreas/A-2067-2012
OI Jung, Norbert/0000-0003-4826-1691; Sommerhoff,
   Hendrik/0000-0001-5262-821X; Kolb, Andreas/0000-0003-4753-7801; Lambers,
   Martin/0000-0002-0994-3318
FU German Research Foundation (DFG) within the Research Training Group GRK
   1564 "Imaging New Modalities"; DFG [KO-2960/12-1]
FX This research was partially funded by German Research Foundation (DFG)
   within the Research Training Group GRK 1564 "Imaging New Modalities" and
   the DFG project grant KO-2960/12-1.
CR [Anonymous], P SPIE DEF SEC 3 DIM
   [Anonymous], 2007, 9 BIENN C AUSTR PATT, DOI DOI 10.1109/DICTA.2007.4426846
   [Anonymous], 2011, 2011 INT C 3D IM IC3
   [Anonymous], 2012, THESIS
   [Anonymous], 2015, P IEEE INT C COMP VI
   [Anonymous], IEEE INT C COMP VIS
   [Anonymous], P BRIT C MACH VIS BM
   [Anonymous], 2015, COMPUTER VISION PATT
   [Anonymous], 2017, P AAAI C ART INT
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   Bourlai T, 2012, PROC SPIE, V8353, DOI 10.1117/12.919392
   Brauers J, 2009, J IMAGING SCI TECHN, V53, DOI 10.2352/J.ImagingSci.Technol.2009.53.3.031103
   Bredies K, 2010, SIAM J IMAGING SCI, V3, P492, DOI 10.1137/090769521
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Bulczak D, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18010013
   Butler DJ, 2012, LECT NOTES COMPUT SC, V7577, P611, DOI 10.1007/978-3-642-33783-3_44
   Choi BD, 2007, IEEE T CIRC SYST VID, V17, P407, DOI 10.1109/TCSVT.2007.893835
   Cuevas E, 2013, ENG APPL ARTIF INTEL, V26, P488, DOI 10.1016/j.engappai.2012.08.003
   Daly S., US Patent, Patent No. [6,690,422, 6690422]
   Fortun Denis, 2015, Computer Vision and Image Understanding, V134, P1, DOI 10.1016/j.cviu.2015.02.008
   Gat N, 2000, P SOC PHOTO-OPT INS, V4056, P50, DOI 10.1117/12.381686
   Gowen AA, 2007, TRENDS FOOD SCI TECH, V18, P590, DOI 10.1016/j.tifs.2007.06.001
   Helling S, 2004, CGIV 2004: SECOND EUROPEAN CONFERENCE ON COLOR IN GRAPHICS, IMAGING, AND VISION - CONFERENCE PROCEEDINGS, P254
   Hoegg Thomas, 2013, Time-Of-Flight and Depth Imaging. Sensors, Algorithms and Applications. Dagstuhl 2012 Seminar on Time-of-Flight Imaging and GCPR 2013 Workshop on Imaging New Modalities: LNCS 8200, P273, DOI 10.1007/978-3-642-44964-2_13
   HORN BKP, 1981, P SOC PHOTO-OPT INST, V281, P319
   Hui TW, 2018, PROC CVPR IEEE, P8981, DOI 10.1109/CVPR.2018.00936
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Jahne B., 2005, Digital Image Processing: Concepts, Algorithms, and Scientific Applications, Vsixth
   Jakubowski M, 2013, OPTO-ELECTRON REV, V21, P86, DOI 10.2478/s11772-013-0071-0
   Kern JP, 2007, IEEE T GEOSCI REMOTE, V45, P1494, DOI 10.1109/TGRS.2007.892599
   Kolb A, 2010, COMPUT GRAPH FORUM, V29, P141, DOI 10.1111/j.1467-8659.2009.01583.x
   Lambers M, 2015, IEEE SENS J, V15, P4019, DOI 10.1109/JSEN.2015.2409816
   Lange R, 2001, IEEE J QUANTUM ELECT, V37, P390, DOI 10.1109/3.910448
   Lindner M, 2009, LECT NOTES COMPUT SC, V5742, P16, DOI 10.1007/978-3-642-03778-8_2
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Petrou M. M., 2010, Image processing: the fundamentals
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ranftl R, 2014, LECT NOTES COMPUT SC, V8689, P439, DOI 10.1007/978-3-319-10590-1_29
   Sage Daniel., 2011, Local normalization
   Steinbrucker F., 2009, VMV, P155
   Steiner H, 2016, J SENSORS, V2016, DOI 10.1155/2016/9682453
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zabih R., 1994, Computer Vision - ECCV '94. Third European Conference on Computer Vision. Proceedings. Vol.II, P151, DOI 10.1007/BFb0028345
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zitová B, 2003, IMAGE VISION COMPUT, V21, P977, DOI 10.1016/S0262-8856(03)00137-9
NR 47
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2019
VL 89
BP 170
EP 182
DI 10.1016/j.imavis.2019.07.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA JA1KC
UT WOS:000487574900015
DA 2024-07-18
ER

PT J
AU Ahmine, Y
   Caron, G
   Mouaddib, E
   Chouireb, F
AF Ahmine, Yassine
   Caron, Guillaume
   Mouaddib, El Mustapha
   Chouireb, Fatima
TI Adaptive Lucas-Kanade tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image alignment; Scale-space theory; Lucas & Kanade; Gradient descent
   method
AB Dense image alignment, when the displacement between the frames is large, can be a challenging task. This paper presents a novel dense image alignment algorithm, the Adaptive Forwards Additive Lucas-Kanade (AFA-LK) tracking algorithm, which considers the scale-space representation of the images, parametrized by a scale parameter, to estimate the geometric transformation between an input image and the corresponding template. The main result in this framework is the optimization of the scale parameter along with the transformation parameters, which permits to significantly increase the convergence domain of the proposed algorithm while keeping a high estimation precision. The performance of the proposed method was tested in various computer-based experiments, which reveal its interest in comparison with geometric as well as learning-based methods from the literature, both in terms of precision and convergence rate. (C) 2019 Elsevier B.V. All rights reserved.
C1 [Ahmine, Yassine; Caron, Guillaume; Mouaddib, El Mustapha] Univ Picardie Jules Verne, MIS Lab, 33 Rue St Leu, F-80000 Amiens, France.
   [Ahmine, Yassine; Chouireb, Fatima] Univ Amar Telidji Laghouat, LTSS Lab, BP 37G Route Ghardaia, Laghouat 03000, Algeria.
C3 Universite de Picardie Jules Verne (UPJV); Universite Amar Telidji de
   Laghouat
RP Ahmine, Y (corresponding author), Univ Picardie Jules Verne, MIS Lab, 33 Rue St Leu, F-80000 Amiens, France.
EM yassine.ahmine@u-picardie.fr
FU PROFAS B+ (Algeria-France 2017) grant
FX A part of this work was done under PROFAS B+ (Algeria-France 2017)
   grant.
CR Alismail H., 2016, P 2016 4 INT C 3D VI
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   [Anonymous], 2014, Computer Vision, DOI DOI 10.1007/978-0-387-31439-6_242
   Antonakos E, 2015, IEEE T IMAGE PROCESS, V24, DOI 10.1109/TIP.2015.2431445
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Benhimane S., 2004, 2004 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS) (IEEE Cat. No.04CH37566), P943
   Bouguet J-Y, 1999, Pyramidal implementation of the Lucas Kanade feature tracker
   Bristow H., 2016, DEFENSE GRADIENT BAS
   Brown M., 2007, INT J COMPUTER VISIO
   Bruhn A., 2005, INT J COMPUT VIS
   Capel D., 2004, IMAGE MOSAICING IMAG
   Chang CH, 2017, PROC CVPR IEEE, P3777, DOI 10.1109/CVPR.2017.402
   Crivellaro A, 2014, PROC CVPR IEEE, P3414, DOI 10.1109/CVPR.2014.436
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Engel J, 2014, LECT NOTES COMPUT SC, V8690, P834, DOI 10.1007/978-3-319-10605-2_54
   Forster C, 2014, IEEE INT CONF ROBOT, P15, DOI 10.1109/ICRA.2014.6906584
   Kanade T., 1981, P 7 INT JOINT C ARTI, V1, P674, DOI DOI 10.5555/1623264.1623280
   Lin CH, 2016, LECT NOTES COMPUT SC, V9909, P793, DOI 10.1007/978-3-319-46454-1_48
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mei C, 2008, IEEE T ROBOT, V24, P1352, DOI 10.1109/TRO.2008.2007941
   Mobahi H, 2012, PROC CVPR IEEE, P1736, DOI 10.1109/CVPR.2012.6247869
   Oron S, 2014, LECT NOTES COMPUT SC, V8693, P142, DOI 10.1007/978-3-319-10602-1_10
   Sharmin N, 2012, SENSORS-BASEL, V12, P12694, DOI 10.3390/s120912694
   Shin J, 2016, IMAGE VISION COMPUT, V51, P69, DOI 10.1016/j.imavis.2016.04.012
   Snape P, 2016, IMAGE VISION COMPUT, V52, P97, DOI 10.1016/j.imavis.2016.05.006
   Xiong X., 2014, ABS14050601 CORR
NR 29
TC 12
Z9 14
U1 2
U2 9
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2019
VL 88
BP 1
EP 8
DI 10.1016/j.imavis.2019.04.004
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA IW9TA
UT WOS:000485335400001
OA Green Submitted, hybrid
DA 2024-07-18
ER

PT J
AU Gomez-Donoso, F
   Orts-Escolano, S
   Cazorla, M
AF Gomez-Donoso, Francisco
   Orts-Escolano, Sergio
   Cazorla, Miguel
TI Large-scale multiview 3D hand pose dataset
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D hand pose; Multiview; Dataset; Deep learning
AB Accurate visual hand pose estimation at joint level has several applications for human-robot interaction, natural user interfaces and virtual/augmented reality applications. However, it is still an open problem being addressed by the computer vision community. Recent novel deep learning techniques may help circumvent the limitations of standard approaches. However, they require large amounts of accurate annotated data. Hand pose datasets that have been released so far present issues such as limited number of samples, inaccurate data or high-level annotations. Moreover, most of them are focused on depth-based approaches, providing only depth information (missing RGB data).
   In this work, we present a novel multiview hand pose dataset in which we provide hand color images and different kind of annotations for each sample, i.e. the bounding box and the 2D and 3D location on the joints in the hand. Furthermore, we introduce a simple yet accurate deep learning architecture for real-time robust 2D hand pose estimation. Then, we conduct experiments that show how the use of the proposed dataset in the training stage produces accurate results for 2D hand pose estimation using a single color camera. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Gomez-Donoso, Francisco; Orts-Escolano, Sergio; Cazorla, Miguel] Univ Alicante, Univ Inst Comp Res, Alicante, Spain.
C3 Universitat d'Alacant
RP Gomez-Donoso, F (corresponding author), Univ Alicante, Univ Inst Comp Res, Alicante, Spain.
EM fgomez@dccia.ua.es
RI Gomez-Donoso, Francisco/H-7539-2016; Cazorla, Miguel/B-4464-2013
OI Gomez-Donoso, Francisco/0000-0002-7830-2661; Cazorla,
   Miguel/0000-0001-6805-3633
FU Spanish Government [TIN2016-76515-R]; Feder funds; University of
   Alicante [GRE16-19]; Generalitat Valenciana [GV/2018/22]; Spanish grant
   [ACIF/2017/243]
FX This work has been funded by the Spanish Government TIN2016-76515-R
   grant for the COMBAHO project, supported with Feder funds. It has also
   been supported by the University of Alicante project GRE16-19, and by
   the Generalitat Valenciana project GV/2018/22 and by a Spanish grant for
   PhD studies ACIF/2017/243. Experiments were made possible by a generous
   hardware donation from NVIDIA.
CR [Anonymous], ARXIV E PRINTS
   Bambach S, 2015, IEEE I CONF COMP VIS, P1949, DOI 10.1109/ICCV.2015.226
   Cazorla M., 2015, LECT NOTES COMPUTER, V9422
   Gomez-Donoso F, 2016, EXPERT SYST, V33, P480, DOI 10.1111/exsy.12160
   Grzejszczak T, 2016, MULTIMED TOOLS APPL, V75, P16363, DOI 10.1007/s11042-015-2934-5
   He Kaiming, 2016, EUR C COMP VIS ECCV, DOI [DOI 10.1109/CVPR.2016.90, DOI 10.1007/978-3-319-46493-0_38]
   Marcel S, 1999, LECT NOTES ARTIF INT, V1739, P97
   Marcel S., P 4 IEEE INT C AUT F
   Mittal A, 2011, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2011, DOI 10.5244/C.25.75
   Molina J, 2014, MACH VISION APPL, V25, P943, DOI 10.1007/s00138-013-0576-z
   Oberweger M., 2016, ARXIV E PRINTS
   Pisharady P. K., 2014, HAND POSTURE FACE RE, P63
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smedt Q.D., 2017, EUR WORKSH 3D OBJ RE, DOI DOI 10.2312/3DOR.20171049
   Tompson J, 2014, ACM T GRAPHIC, V33, DOI 10.1145/2629500
   WENG JY, 1992, IEEE T PATTERN ANAL, V14, P965, DOI 10.1109/34.159901
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zimmermann C, 2017, IEEE I CONF COMP VIS, P4913, DOI 10.1109/ICCV.2017.525
NR 20
TC 31
Z9 33
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2019
VL 81
BP 25
EP 33
DI 10.1016/j.imavis.2018.12.001
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HO1ZJ
UT WOS:000460710900003
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Fernández, PDM
   Peña, FAG
   Ren, TI
   Leandro, JJG
AF Marrero Fernandez, Pedro D.
   Guerrero Pena, Fidel A.
   Ren, Tsang Ing
   Leandro, Jorge J. G.
TI Fast and robust multiple ColorChecker detection using deep convolutional
   neural networks
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE ColorChecker detection; Photograph; Image quality; Color science; Color
   balance; Segmentation; Convolutional neural network
AB ColorCheckers are reference standards that professional photographers and filmmakers use to ensure predictable results under every lighting condition. The objective of this work is to propose a new fast and robust method for automatic ColorChecker detection. The process is divided into two steps: (1) ColorCheckers localization and (2) ColorChecker patches recognition. For the ColorChecker localization, we trained a detection convolutional neural network using synthetic images. The synthetic images are created with the 3D models of the ColorChecker and different background images. The output of the neural networks are the bounding box of each possible ColorChecker candidates in the input image. Each bounding box defines a cropped image which is evaluated by a recognition system, and each image is canonized with regards to color and dimensions. Subsequently, all possible color patches are extracted and grouped with respect to the center's distance. Each group is evaluated as a candidate for a ColorChecker part, and its position in the scene is estimated. Finally, a cost function is applied to evaluate the accuracy of the estimation. The method is tested using real and synthetic images. The proposed method is fast, robust to overlaps and invariant to affine projections. The algorithm also performs well in case of multiple ColorCheckers detection. (C) 2018 Elsevier B.V. All rights reserved.
C1 [Marrero Fernandez, Pedro D.; Guerrero Pena, Fidel A.; Ren, Tsang Ing] Univ Fed Pernambuco UFPE, Ctr Informat, Recife, PE, Brazil.
   [Leandro, Jorge J. G.] Motorola Mobil LLC, Sao Paulo, Brazil.
C3 Universidade Federal de Pernambuco
RP Fernández, PDM (corresponding author), Univ Fed Pernambuco UFPE, Ctr Informat, Recife, PE, Brazil.
EM pdmf@cin.ufpe.br
RI Fernandez, Pedro Diamel Marrero/P-8363-2019; Peña, Fidel A.
   Guerrero/K-8251-2016; Ren, Tsang Ing/AAD-3221-2022
OI Fernandez, Pedro Diamel Marrero/0000-0002-7225-2915; Peña, Fidel A.
   Guerrero/0000-0002-9999-5321; 
FU Motorola Mobility LLC (a Lenovo Company); CIn-UFPE; Brazilian government
   agency
FX This work was supported by the research cooperation project between
   Motorola Mobility LLC (a Lenovo Company) and CIn-UFPE. Tsang Ing Ren,
   Pedro D. Marrero Fernandez and Fidel A. Guerrero-Pena gratefully
   acknowledge financial support from the Brazilian government agency. The
   authors would also like to thank Leonardo Coutinho de Mendonca,
   Alexandre Cabral Mota, Rudi Minghim and Gabriel Humpire for valuable
   discussions.
CR [Anonymous], 16 WORKSH FARBB
   [Anonymous], 37 GERM C PATT REC
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587765
   [Anonymous], 11 ANN S COMP GEOM
   [Anonymous], 3 INT WORKSH COMP CO
   [Anonymous], 6 INT C COMP VIS COM
   Bradski G., 2008, LEARNING OPENCV
   Douglas D.H., 1973, Cartographica: The International Journal for Geographic Information and Geovisualization, V10, P112, DOI [https://doi.org/10.3138/FM57-6770-U75U-7727, DOI 10.1002/9780470669488.CH2]
   Gershman S., 2014, P ANN M COGN SCI SOC
   Gil-García RJ, 2006, INT C PATT RECOG, P569
   Goodfellow I, 2014, ADV NEURAL INFORM PR, P2672
   Gupta A, 2016, PROC CVPR IEEE, P2315, DOI 10.1109/CVPR.2016.254
   Jaderberg M, 2016, INT J COMPUT VISION, V116, P1, DOI 10.1007/s11263-015-0823-z
   Jaderberg Max, 2014, WORKSH DEEP LEARN NI
   Kordecki Andrzej, 2014, Przeglad Elektrotechniczny, V90, P197, DOI 10.12915/pe.2014.09.49
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Ramer U., 1972, Comput. Graph. Image Process., V1, P244, DOI DOI 10.1016/S0146-664X(72)80017-0
   Simard PY, 2003, PROC INT CONF DOC, P958
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tajbakhsh Touraj, 2008, Proceedings of the Fifth IASTED International Conference on Signal Processing, Pattern Recognition, and Applications, P347
   Le TA, 2017, IEEE IJCNN, P3514, DOI 10.1109/IJCNN.2017.7966298
   von Ahn L, 2008, SCIENCE, V321, P1465, DOI 10.1126/science.1160379
   Wang ZY, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P451, DOI 10.1145/2733373.2806219
NR 23
TC 9
Z9 9
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2019
VL 81
BP 15
EP 24
DI 10.1016/j.imavis.2018.11.001
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA HO1ZJ
UT WOS:000460710900002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Jacob, GM
   Das, S
AF Jacob, Geethu Miriam
   Das, Sukhendu
TI Moving object segmentation for jittery videos, by clustering of
   stabilized latent trajectories
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Video Stabilization; pLSA; Trajectory Clustering; GraphCut; Jitter
   Synthesis
AB Moving object segmentation in videos has always been a challenging task in the presence of large camera movements. Moreover, when the camera motion is jittery, most of the existing motion segmentation approaches fail. In this work, we propose an optimization framework for the segmentation of moving object in jittery videos. A novel Optical Trajectory Descriptor Matrix (OTDM) built on point trajectories has been proposed for this purpose. An optimization function has been formulated for stabilizing the trajectories, followed by spectral clustering of the proposed latent trajectories. Latent trajectories are obtained by performing Probabilistic Latent Semantic Analysis (pLSA) on the OTDM (factorization of OTDM using KL divergence). This integrated framework yields accurate clustering of the trajectories from jittery videos. Foreground pixel labelling is obtained by utilizing the clustered trajectory coordinates for modelling the foreground and background, using a GraphCut based energy formulation. Experiments were performed on 16 real-world jittery videos. Also, the results have been generated for a standard segmentation dataset, SegTrackv2, with synthetic jitter incorporated. Jitter extracted from a real video is inserted into stable SegTrackv2 videos for analysis of performance. The proposed method, when compared to the state-of-the-art methods, was found to be superior. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Jacob, Geethu Miriam; Das, Sukhendu] Indian Inst Technol, Dept CS&E, VP Lab, Madras, Tamil Nadu, India.
C3 Indian Institute of Technology System (IIT System); Indian Institute of
   Technology (IIT) - Madras
RP Das, S (corresponding author), Indian Inst Technol, Dept CS&E, VP Lab, Madras, Tamil Nadu, India.
EM geethumiriam@gmail.com; sdas@iitm.ac.in
RI Das, Sukhendu/AAP-8630-2020
OI Das, Sukhendu/0000-0002-2823-9211; Jacob, Geethu
   Miriam/0000-0001-6326-2081
FU TCS Research Scholar Program, India
FX This work is partially funded by TCS Research Scholar Program, India.
CR [Anonymous], 2010, ECCV
   [Anonymous], ICCV
   [Anonymous], 1995, Handbooks in Operations Research and Management Science
   [Anonymous], 2010, ECCV
   [Anonymous], ECCV
   [Anonymous], 2013, CVPR
   [Anonymous], 2013, CVPR
   [Anonymous], 1999, P 1999 IEEE COMP SOC
   [Anonymous], CVPR
   [Anonymous], 2015, CVPR
   [Anonymous], 2014, PROC BRIT MACH VIS C
   [Anonymous], 2007, Handbook of Mathematics
   [Anonymous], 2011, ICCV
   [Anonymous], 2013, ICCV
   [Anonymous], 2012, CVPR
   Barnich O, 2011, IEEE T IMAGE PROCESS, V20, P1709, DOI 10.1109/TIP.2010.2101613
   Bosch A., 2006, ECCV
   Cheriyadat A., 2009, ICCV
   Ding C, 2008, COMPUT STAT DATA AN, V52, P3913, DOI 10.1016/j.csda.2008.01.011
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Gleicher ML, 2008, ACM T MULTIM COMPUT, V5, DOI 10.1145/1404880.1404882
   Grundmann M, 2011, PROC CVPR IEEE, P225, DOI 10.1109/CVPR.2011.5995525
   Hartley R., 2003, MULTIPLE VIEW GEOMET
   Hofmann T, 1999, SIGIR'99: PROCEEDINGS OF 22ND INTERNATIONAL CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P50, DOI 10.1145/312624.312649
   Hofmann T, 2001, MACH LEARN, V42, P177, DOI 10.1023/A:1007617005950
   Liu F, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531350
   Liu S, 2013, ACM T GRAPHIC, V32, DOI 10.1145/2461912.2461995
   Liu Shuaicheng, 2014, CVPR
   Matsushita Y, 2006, IEEE T PATTERN ANAL, V28, P1150, DOI 10.1109/TPAMI.2006.141
   Mittal A., 2004, CVPR
   Mittal A, 2009, COMPUT VIS IMAGE UND, V113, P63, DOI 10.1016/j.cviu.2008.07.004
   Ochs P, 2014, IEEE T PATTERN ANAL, V36, P1187, DOI 10.1109/TPAMI.2013.242
   Ogale AS, 2005, IEEE T PATTERN ANAL, V27, P988, DOI 10.1109/TPAMI.2005.123
   Oreifej O, 2013, IEEE T PATTERN ANAL, V35, P450, DOI 10.1109/TPAMI.2012.97
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sun D.L., 2014, ICASSP, V2014
   Walha A, 2014, MULTIMED TOOLS APPL, P1
   Wang Chong., 2014, ECCV
   Wen Longyin., 2015, CVPR
   Zhou Zihan, 2013, CVPR
NR 41
TC 3
Z9 3
U1 1
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2017
VL 64
BP 10
EP 22
DI 10.1016/j.imavis.2017.05.002
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA FH0ZW
UT WOS:000410870200002
DA 2024-07-18
ER

PT J
AU Phillips, PJ
   Flynn, PJ
   Bowyer, KW
AF Phillips, P. Jonathon
   Flynn, Patrick J.
   Bowyer, Kevin W.
TI Lessons from collecting a million biometric samples
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face recognition; Algorithm performance; Human performance; Challenge
   problem
ID FACE-RECOGNITION; BODY
AB Over the past decade, independent evaluations have become commonplace in many areas of experimental computer science, including face and gesture recognition. A key attribute of many successful independent evaluations is a curated data set. Desired aspects associated with these data sets include appropriateness to the experimental design, a corpus size large enough to allow statistically rigorous characterization of results, and the availability of comprehensive metadata that allow inferences to be made on various data set attributes. In this paper, we review a ten-year biometric sampling effort that enabled the creation of several key biometrics challenge problems. We summarize the design and execution of data collections, identify key challenges, and convey some lessons learned. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Phillips, P. Jonathon] NIST, 100 Bur Dr MS 8490, Gaithersburg, MD 20899 USA.
   [Flynn, Patrick J.; Bowyer, Kevin W.] Univ Notre Dame, Comp Sci & Engn, Notre Dame, IN 46556 USA.
C3 National Institute of Standards & Technology (NIST) - USA; University of
   Notre Dame
RP Phillips, PJ (corresponding author), NIST, 100 Bur Dr MS 8490, Gaithersburg, MD 20899 USA.
EM jonathon@nist.gov; flynn@nd.edu; kwd@cse.nd.edu
OI Bowyer, Kevin/0000-0002-7562-4390
FU Defense Advanced Research Project Agency (DARPA); Air Force Office of
   Scientific Research (AFOSR); National Science Foundation (NSF);
   Technical Support Working Group (TSWG); Federal Bureau of Investigation
   (FBI); Intelligence Advanced Research Project Activity (IARPA); Army
   Research Laboratory (ARL); National Institute of Justice (NIJ); United
   States Government
FX PJF and MB received support from the following sources for 2002-2012
   data collection activities: Defense Advanced Research Project Agency
   (DARPA), Air Force Office of Scientific Research (AFOSR), National
   Science Foundation (NSF), Technical Support Working Group (TSWG),
   Federal Bureau of Investigation (FBI), Intelligence Advanced Research
   Project Activity (IARPA), Army Research Laboratory (ARL), National
   Institute of Justice (NIJ), and the United States Government. PJP
   received support from the FBI and IARPA.
CR [Anonymous], P 9 IEEE INT C AUT F
   [Anonymous], MAKING SENSE IREX 6
   [Anonymous], P 2 WORKSH MULT US A
   [Anonymous], P 12 AS C COMP VIS A
   [Anonymous], 2012, P 2012 IEEE COMP VIS
   [Anonymous], BIOM IJCB 2014 IEEE
   Bailly-Bailliére E, 2003, LECT NOTES COMPUT SC, V2688, P625
   Baker S.E., 2013, Handbook of Iris Recognition, P205
   Baker SE, 2010, COMPUT VIS IMAGE UND, V114, P1030, DOI 10.1016/j.cviu.2010.06.002
   Baker SE, 2009, LECT NOTES COMPUT SC, V5558, P1170, DOI 10.1007/978-3-642-01793-3_118
   Beveridge J., 2013, BIOM THEOR APPL SYST
   Beveridge J. R., 2014, P INT JOINT C BIOM
   Beveridge J. R., 2015, P 11 IEEE INT C AUT
   BEVERIDGE JR, 2008, P 8 INT C AUT FAC GE
   Bui H, 2009, CLUSTER COMPUT, V12, P373, DOI 10.1007/s10586-009-0098-7
   Chen X, 2005, COMPUT VIS IMAGE UND, V99, P332, DOI 10.1016/j.cviu.2005.03.001
   Czajka A., 2013, BIOSIGNALS
   Ding CX, 2015, IEEE T IMAGE PROCESS, V24, P980, DOI 10.1109/TIP.2015.2390959
   Ellavarason E, 2013, HDADASEC2013001 CTR
   Fenker SP, 2013, IEEE ACCESS, V1, P266, DOI 10.1109/ACCESS.2013.2262916
   Fenker SamuelP., 2011, WORKSHOP APPL COMPUT, P232, DOI DOI 10.1109/WACV.2011.5711508
   Flynn PJ, 2003, LECT NOTES COMPUT SC, V2688, P44
   Givens GH, 2013, COMPUT STAT DATA AN, V67, P236, DOI 10.1016/j.csda.2013.05.025
   Gross R., 2004, Handbook of Face Recognition, P193
   Grother P., 2010, Report on the evaluation of 2d still-image face recognition algorithms
   Grother P., 2013, IREX VI: Temporal Stability of Iris Recognition Accuracy
   Hollingsworth K, 2011, COMPUT VIS IMAGE UND, V115, P1493, DOI 10.1016/j.cviu.2011.06.010
   Hollingsworth K, 2009, COMPUT VIS IMAGE UND, V113, P150, DOI 10.1016/j.cviu.2008.08.001
   Huang G.B., 2008, PROC WORKSHOP FACES
   Huang Z., 2014, P 12 AS C COMP VIS
   Li HX, 2013, PROC CVPR IEEE, P3499, DOI 10.1109/CVPR.2013.449
   MATAS J, 2000, P INT C PATT REC BAR, V4, P4858
   McGinn K., 2013, IEEE INT C BIOM THEO
   Mehrotra H, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0078333
   Messer K, 2004, INT C PATT RECOG, P523, DOI 10.1109/ICPR.2004.1333826
   O'Toole AJ, 2007, IEEE T SYST MAN CY B, V37, P1149, DOI 10.1109/TSMCB.2007.907034
   O'Toole AJ, 2012, ACM T APPL PERCEPT, V9, DOI 10.1145/2355598.2355599
   O'Toole AJ, 2011, VISION RES, V51, P74, DOI 10.1016/j.visres.2010.09.035
   Ortiz E, 2015, IEEE COMPUT SOC CONF
   Paone JR, 2014, IEEE T INF FOREN SEC, V9, P285, DOI 10.1109/TIFS.2013.2296373
   Petrovska-Delacretaz D., 2009, GUIDE BIOMETRIC REFE
   Phillips P.J., 2008, 2 IEEE INT C BIOM TH
   Phillips P. J., 2009, P 3 IAPR INT C BIOM
   Phillips P. J., 2013, IEEE BIOMETRICS THEO
   Phillips PJ, 2015, INT CONF BIOMETR THE
   Phillips PJ, 2014, IMAGE VISION COMPUT, V32, P74, DOI 10.1016/j.imavis.2013.12.002
   Phillips PJ, 2011, ACM T APPL PERCEPT, V8, DOI 10.1145/1870076.1870082
   Phillips PJ, 2010, IEEE T PATTERN ANAL, V32, P831, DOI 10.1109/TPAMI.2009.59
   Phillips PJ, 2005, PROC CVPR IEEE, P947
   Phillips PJ, 2000, IEEE T PATTERN ANAL, V22, P1090, DOI 10.1109/34.879790
   Phillips PJ, 1998, IMAGE VISION COMPUT, V16, P295, DOI 10.1016/S0262-8856(97)00070-X
   PHILLIPS PJ, 2003, 6965 NISTIR
   Proença H, 2005, LECT NOTES COMPUT SC, V3617, P970, DOI 10.1007/11553595_119
   Rice A, 2013, APPL COGNITIVE PSYCH, V27, P761, DOI 10.1002/acp.2969
   Rice A, 2013, PSYCHOL SCI, V24, P2235, DOI 10.1177/0956797613492986
   SARKAR S, 2005, IEEE T PAMI, V27
   Sazonova N., 2012, P SOC PHOTO-OPT INS, V8371
   Struc J. K. V., 2015, 3 INT WORKSH BIOM FO
   White D., 2015, P R SOC B, V282
   Wolf L, 2011, PROC CVPR IEEE, P529, DOI 10.1109/CVPR.2011.5995566
   Yadav D, 2014, IEEE T INF FOREN SEC, V9, P851, DOI 10.1109/TIFS.2014.2313025
NR 61
TC 4
Z9 5
U1 0
U2 9
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2017
VL 58
BP 96
EP 107
DI 10.1016/j.imavis.2016.08.004
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EN2MN
UT WOS:000395844700010
OA Bronze
DA 2024-07-18
ER

PT J
AU Florea, C
   Florea, L
   Butnaru, R
   Bandrabur, A
   Vertan, C
AF Florea, Corneliu
   Florea, Laura
   Butnaru, Raluca
   Bandrabur, Alessandra
   Vertan, Constantin
TI Pain intensity estimation by a self-taught selection of histograms of
   topographical features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Histograms of Topographical (HoT) features; Spectral regression;
   Transfer learning; Temporal filtering; Continuous pain intensity
   estimation
ID FACIAL EXPRESSION; RECOGNITION; SCALE
AB Pain assessment through observational pain scales is necessary for special categories of patients such as neonates, patients with dementia, and critically ill patients. The recently introduced Prkachin Solomon score allows pain assessment directly from facial images opening the path for multiple assistive applications. In this paper, we proposed a system built upon the Histograms of Topographical (HoT) features, which are a generalization of the topographical primal sketch, for the description of the face parts contributing to the mentioned score. We further propose a semi-supervised, clustering oriented self-taught learning procedure developed on the Cohn-Kanade emotion oriented database by adapting the spectral regression. To make use of inter-frame pain correlation we introduce a machine learning based temporal filtering. We use this procedure to improve the discrimination between different pain intensity levels and the generalization with respect to the monitored persons, while testing on the UNBC McMaster Shoulder Pain database. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Florea, Corneliu; Florea, Laura; Butnaru, Raluca; Bandrabur, Alessandra; Vertan, Constantin] Univ Politehn Bucuresti, Image Proc & Anal Lab LAPI, Splaiul Independetei 313, Bucharest, Romania.
C3 National University of Science & Technology POLITEHNICA Bucharest
RP Florea, C (corresponding author), Univ Politehn Bucuresti, Image Proc & Anal Lab LAPI, Splaiul Independetei 313, Bucharest, Romania.
EM corneliu.florea@ppb.ro; laura.florea@upb.ro; rboia@imag.pub.ro;
   abandrabur@imag.pub.ro; constantin.vertan@upb.ro
RI Florea, Laura Maria/I-6823-2013; Vertan, Constantin/F-4459-2015; Florea,
   Corneliu/B-5540-2012
OI Florea, Laura Maria/0000-0001-6095-9692; Florea,
   Corneliu/0000-0001-9754-6795
FU Sectoral Operational Programme Human Resources Development of the
   Ministry of European Funds [POSDRU/159/1.5/S/134398,
   POSDRU/159/1.5/S/132395]; Romanian National Agency for Scientific
   Research [PNCDI2 RU-TE-2014 253/01.10.2015]
FX The work has been partially funded by the Sectoral Operational Programme
   Human Resources Development 2007-2013 of the Ministry of European Funds
   through the Financial Agreement POSDRU/159/1.5/S/134398 and
   POSDRU/159/1.5/S/132395 and partially through the Romanian National
   Agency for Scientific Research under the PNCDI2 RU-TE-2014
   253/01.10.2015 (Pandora) research grant.
CR [Anonymous], 2007, P 24 INT C MACHINE L, DOI DOI 10.1145/1273496.1273592
   [Anonymous], FRONTIERS PSYCHOL
   [Anonymous], 1962, PAPERS TECHNICAL GRO
   [Anonymous], 2014, OXFORD HDB AFFECTIVE
   [Anonymous], 2006, IEEE COMP SOC C COMP
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Boyd J., 2011, CLASSIFICATION CHRON
   Brahnam S, 2007, STUD COMPUT INTELL, V48, P225
   Cai D, 2007, IEEE C COMP VIS ICCV, P1, DOI DOI 10.1109/CVPR.2007.383054
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chanques G, 2014, CRIT CARE, V18, DOI 10.1186/cc14000
   Chen JX, 2013, PATTERN RECOGN LETT, V34, P1964, DOI 10.1016/j.patrec.2013.02.002
   Chu W.-S., 2013, COMPUTER VISION PATT, P886
   Coltuc D., 1999, Proceedings 1999 International Conference on Image Processing (Cat. 99CH36348), P150, DOI 10.1109/ICIP.1999.817089
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   Ekman P, 1978, FACIAL ACTION CODING
   FLORACK LMJ, 1992, IMAGE VISION COMPUT, V10, P376, DOI 10.1016/0262-8856(92)90024-W
   Florea C, 2015, LECT NOTES COMPUT SC, V8927, P778, DOI 10.1007/978-3-319-16199-0_54
   Florea Laura, 2007, 2007 15th European Signal Processing Conference (EUSIPCO), P1103
   Frangi AF, 1998, LECT NOTES COMPUT SC, V1496, P130, DOI 10.1007/BFb0056195
   Gawande A., 2004, CHECKLIST MANIFESTO
   Gholami B, 2010, IEEE T BIO-MED ENG, V57, P1457, DOI 10.1109/TBME.2009.2039214
   Guo YM, 2012, PATTERN RECOGN, V45, P3834, DOI 10.1016/j.patcog.2012.04.003
   Hadjistavropouls T, 2004, PAIN: PSYCHOLOGICAL PERSPECTIVES, P87
   Hammal Z, 2012, ICMI '12: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P47, DOI 10.1145/2388676.2388688
   HARALICK RM, 1983, INT J ROBOT RES, V2, P50, DOI 10.1177/027836498300200105
   Haslam L., 2011, J ADV NURS, V68, P329
   Hatzis J, 2004, MICRON, V35, P201, DOI 10.1016/j.micron.2003.11.007
   He X., 2003, ADV NEURAL INFORM PR, P153
   Hong XP, 2016, NEUROCOMPUTING, V184, P99, DOI 10.1016/j.neucom.2015.07.134
   Huguet A, 2010, J PSYCHOSOM RES, V68, P329, DOI 10.1016/j.jpsychores.2009.06.003
   Kaltwang S, 2012, LECT NOTES COMPUT SC, V7432, P368, DOI 10.1007/978-3-642-33191-6_36
   Kanade T., 2000, P 4 IEEE INT C AUT F, P46, DOI [10.1109/AFGR.2000.840611, DOI 10.1109/AFGR.2000.840611]
   Lee WT, 2009, PROC CVPR IEEE, P1590, DOI 10.1109/CVPRW.2009.5206521
   Lindeberg T., 1994, Journal of AppliedStatistics, V21, P225
   Lindeberg T, 2015, J MATH IMAGING VIS, V52, P3, DOI 10.1007/s10851-014-0541-0
   Littlewort GC, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P15
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Lucey P., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P57, DOI 10.1109/FG.2011.5771462
   Lucey P., 2010, ieee computer society conference on computer vision and pattern recognition-workshops, P94
   Lucey P, 2012, IMAGE VISION COMPUT, V30, P197, DOI 10.1016/j.imavis.2011.12.003
   Manias E, 2002, J CLIN NURS, V11, P724, DOI 10.1046/j.1365-2702.2002.00691.x
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Panigrahi S., 2021, IEEE Transactions on Knowledge and Data Engineering, V194, P781, DOI [DOI 10.1109/TKDE.2009.191, 10.1007/978-981-15-5971-6_83]
   Prkachin KM, 2008, PAIN, V139, P267, DOI 10.1016/j.pain.2008.04.010
   PRKACHIN KM, 1992, PAIN, V51, P297, DOI 10.1016/0304-3959(92)90213-U
   Rudovic O, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P492, DOI 10.1109/ICCVW.2013.70
   Sangineto E, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P357, DOI 10.1145/2647868.2654916
   Shavit I, 2008, EMERG MED J, V25, P552, DOI 10.1136/emj.2008.058297
   SHI JB, 1994, 1994 IEEE COMPUTER SOCIETY CONFERENCE ON COMPUTER VISION AND PATTERN RECOGNITION, PROCEEDINGS, P593, DOI 10.1109/CVPR.1994.323794
   Stites M, 2013, CRIT CARE NURSE, V33, P68, DOI 10.4037/ccn2013804
   Tipping ME, 1999, J R STAT SOC B, V61, P611, DOI 10.1111/1467-9868.00196
   Topolovec-Vranic J, 2013, PAIN RES MANAG, V18, pE107, DOI 10.1155/2013/263104
   Tuytelaars T, 2007, FOUND TRENDS COMPUT, V3, P177, DOI 10.1561/0600000017
   von Baeyer CL, 2007, PAIN, V127, P140, DOI 10.1016/j.pain.2006.08.014
   Wang J, 2007, COMPUT VIS IMAGE UND, V108, P19, DOI 10.1016/j.cviu.2006.10.011
   Wenhao Jiang, 2012, Machine Learning and Knowledge Discovery in Databases. Proceedings of the European Conference (ECML PKDD 2012), P789, DOI 10.1007/978-3-642-33486-3_50
   Werner P, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.119
   Zen Gloria., 2014, P OF THE 16 INT C ON, P128, DOI DOI 10.1145/2663204.2663247
   Zeng ZH, 2009, IEEE T PATTERN ANAL, V31, P39, DOI 10.1109/TPAMI.2008.52
   Zhao Q, 2014, PR MACH LEARN RES, V32, P55
NR 65
TC 7
Z9 8
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2016
VL 56
BP 13
EP 27
DI 10.1016/j.imavis.2016.08.014
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EF1FW
UT WOS:000390071700002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Perez, A
   Tabia, H
   Declercq, D
   Zanotti, A
AF Perez, Alexandre
   Tabia, Hedi
   Declercq, David
   Zanotti, Alain
TI Using the conflict in Dempster-Shafer evidence theory as a rejection
   criterion in classifier output combination for 3D human action
   recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Human action recognition; Classifier combination; Dempster-Shafer
   evidence theory; Rejection; Actionlet; HON4D
AB In this paper, we propose a comprehensive solution to 3D human action recognition including feature extraction, classification, and multiple classifier combination. We effectively present two feature extraction methods, four different types of well-known classifiers, and four multiple classifier combination strategies including a specially designed belief based method. In order to enhance the recognition accuracy, we propose a new rejection criterion based on the conflict from the information sources: the classifier outputs. We test our method on the MSRAction 3D dataset. Discarding examples using the conflict based criterion shows superior results than other combination approaches. Moreover this criterion allows choosing a tradeoff between the performance and rejection rate. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Perez, Alexandre; Zanotti, Alain] AUSY Expertise & Rech, 6 Rue Troyon, F-92310 Sevres, France.
   [Perez, Alexandre; Tabia, Hedi; Declercq, David] Univ Cergy Pontoise, CNRS, ETIS ENSEA, UMR 8051, Cergy Pontoise, France.
C3 Centre National de la Recherche Scientifique (CNRS); CY Cergy Paris
   Universite
RP Perez, A (corresponding author), AUSY Expertise & Rech, 6 Rue Troyon, F-92310 Sevres, France.; Perez, A (corresponding author), Univ Cergy Pontoise, CNRS, ETIS ENSEA, UMR 8051, Cergy Pontoise, France.
EM alexandre.perez@ensea.fr
CR [Anonymous], 2013, INFORM FUSION SIGNAL
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Denceux T., 2014, BRIT MACH VIS C
   Florea M.C., 2009, C31 CRISIS EMERGENCY
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Iosifidis A, 2014, IEEE IMAGE PROC, P1510, DOI 10.1109/ICIP.2014.7025302
   Iosifidis A, 2012, IEEE T NEUR NET LEAR, V23, P412, DOI 10.1109/TNNLS.2011.2181865
   Jain M, 2013, PROC CVPR IEEE, P2555, DOI 10.1109/CVPR.2013.330
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Joussleme A.-L., 2001, Information Fusion, V2, P91, DOI 10.1016/S1566-2535(01)00026-4
   Kim HJ, 2007, LECT NOTES COMPUT SC, V4492, P715
   Kuncheva LI, 2003, PATTERN ANAL APPL, V6, P22, DOI 10.1007/s10044-002-0173-7
   Lam L, 1997, IEEE T SYST MAN CY A, V27, P553, DOI 10.1109/3468.618255
   Li WB, 2010, 2010 THE 3RD INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND INDUSTRIAL APPLICATION (PACIIA2010), VOL I, P9, DOI 10.1109/cvprw.2010.5543273
   Liu L, 2016, IEEE T CYBERNETICS, V46, P158, DOI 10.1109/TCYB.2015.2399172
   Lu XG, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P13
   Lv F, 2006, LECT NOTES COMPUT SC, V3954, P359
   Muller Meinard., 2006, P ACM SIGGRAPHEUROGR, P137
   MARTENS J, 2011, P 28 INT C MACH LEAR, P1033
   Martin A., 2008, INF FUS 2008 11 INT
   Oreifej O, 2013, PROC CVPR IEEE, P716, DOI 10.1109/CVPR.2013.98
   Quinlan J. R., 1993, PROGRAMS MACHINE LEA
   Quost B, 2007, PATTERN RECOGN LETT, V28, P644, DOI 10.1016/j.patrec.2006.11.002
   Quost B, 2011, INT J APPROX REASON, V52, P353, DOI 10.1016/j.ijar.2010.11.008
   Shao L, 2016, INT J COMPUT VISION, V118, P115, DOI 10.1007/s11263-015-0861-6
   Shao L, 2014, IEEE T CYBERNETICS, V44, P817, DOI 10.1109/TCYB.2013.2273174
   Simonyan K., Advances in neural information processing systems, P568
   Smarandache F., 2012, COMP STUDY CONTRADIC, P271
   Tabia H., 2013, Proceedings of the Sixth Eurographics Workshop on 3D Object Retrieval, P17
   Tabia H, 2011, IEEE T PATTERN ANAL, V33, P852, DOI 10.1109/TPAMI.2010.202
   Vieira A. W., 2012, PROGR PATTERN RECOGN, P252, DOI [DOI 10.1007/978-3-642-33275-3, DOI 10.1007/978-3-642-33275]
   Vishwakarma S, 2013, VISUAL COMPUT, V29, P983, DOI 10.1007/s00371-012-0752-6
   Wang J, 2012, PROC CVPR IEEE, P1290, DOI 10.1109/CVPR.2012.6247813
   Xia L., 2012, IEEE COMP SOC C COMP, P20, DOI DOI 10.1109/CVPRW.2012.6239233
   Xia L, 2013, PROC CVPR IEEE, P2834, DOI 10.1109/CVPR.2013.365
   XU L, 1992, IEEE T SYST MAN CYB, V22, P418, DOI 10.1109/21.155943
   Yang X., 2012, P 20 ACM INT C MULT, P1057, DOI DOI 10.1145/2393347.2396382
   Yu MC, 2015, INT SYMP NETW COD, P1, DOI [10.1109/IRMMW-THz.2015.7327562, 10.1080/0740817X.2014.999179, 10.1109/NETCOD.2015.7176778]
NR 40
TC 16
Z9 17
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2016
VL 55
SI SI
BP 149
EP 157
DI 10.1016/j.imavis.2016.04.010
PN 2
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA ED9BE
UT WOS:000389164300013
DA 2024-07-18
ER

PT J
AU Akinlar, C
AF Akinlar, Cuneyt
TI CEDContours: A high speed contour detector for color images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Edge detection; Contour detection; Image segmentation; Color Edge
   Drawing
ID BOUNDARY DETECTION; EDGE; MODEL
AB We propose a high-speed contour detector for color images that produces its contours as set of edge segments, each a chain of pixels. The proposed algorithm performs a multi-scale analysis of the input image by combining the edge segments produced by Color Edge Drawing (CED) at different scales; thus, the name CEDContours. We evaluate the performance of CEDContours both qualitatively by presenting visual experimental results, and quantitatively within the precision-recall framework of the Berkeley Segmentation Dataset and Benchmark (BSDS300 and BSDS500). Experimental results show that CEDContours with the DiZenzo gradient operator, named CEDContours-DiZenzo, surpasses many of the prominent contour detectors found in the literature (0.70 and 0.71 F-score for BSDS300 and BSDS500 respectively), and gives comparable results to the leading contour detectors, i.e., the global Probability of boundary ultrametric contour maps (gPb-ucm: 0.71 and 0.73), and the sparse code gradients (scg: 0.72 and 0.74), but runs up to 100 times faster than these contour detectors (700ms for 481x321 images as opposed to 40s for gPb-ucm and 70s for scg), making it suitable for high-speed image processing and computer vision applications. (C) 2016 Published by Elsevier B.V.
C1 [Akinlar, Cuneyt] Anadolu Univ, Dept Comp Engn, Eskisehir, Turkey.
C3 Anadolu University
RP Akinlar, C (corresponding author), Anadolu Univ, Dept Comp Engn, Eskisehir, Turkey.
EM cakinlar@anadolu.edu.tr
RI Akinlar, Cuneyt/AAH-7483-2019; Akinlar, Cuneyt/U-5132-2019
OI AKINLAR, CUNEYT/0000-0002-0961-7790
CR Akinlar C., 2016, COLORED COLOR UNPUB
   Akinlar C, 2013, PATTERN RECOGN, V46, P725, DOI 10.1016/j.patcog.2012.09.020
   Akinlar C, 2012, INT J PATTERN RECOGN, V26, DOI 10.1142/S0218001412550026
   Akinlar C, 2011, PATTERN RECOGN LETT, V32, P1633, DOI 10.1016/j.patrec.2011.06.001
   [Anonymous], DIGITAL IMAGE PROCES
   [Anonymous], 2016, BERKELEY SEGMENTATIO
   [Anonymous], 2008, 2008 IEEE C COMP VIS, DOI DOI 10.1109/CVPR.2008.4587420
   Arbelaez P., 2006, IEEE COMP VIS PATT R
   Arbeláez P, 2011, IEEE T PATTERN ANAL, V33, P898, DOI 10.1109/TPAMI.2010.161
   Azzopardi G, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0098424
   Azzopardi G, 2012, BIOL CYBERN, V106, P177, DOI 10.1007/s00422-012-0486-6
   BERGHOLM F, 1987, IEEE T PATTERN ANAL, V9, P726, DOI 10.1109/TPAMI.1987.4767980
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Catanzaro B, 2009, IEEE I CONF COMP VIS, P2381, DOI 10.1109/ICCV.2009.5459410
   DERICHE R, 1987, INT J COMPUT VISION, V1, P167, DOI 10.1007/BF00123164
   DIZENZO S, 1986, COMPUT VISION GRAPH, V33, P116, DOI 10.1016/0734-189X(86)90223-9
   Dollar P., 2006, 2006 IEEE COMP SOC C, V2, P1964, DOI DOI 10.1109/CVPR.2006.298
   Dollár P, 2013, IEEE I CONF COMP VIS, P1841, DOI 10.1109/ICCV.2013.231
   Felzenszwalb P., 2006, IEEE COMP VIS PATT R
   Ferrari V., 2006, EUR C COMP VIS ECCV, P1428
   Goshtasby A., 1994, IMAGE VISION COMPUT, V12
   Grigorescu C, 2004, IMAGE VISION COMPUT, V22, P609, DOI 10.1016/j.imavis.2003.12.004
   Grigorescu C, 2003, IEEE T IMAGE PROCESS, V12, P729, DOI 10.1109/TIP.2003.814250
   Gu CH, 2009, PROC CVPR IEEE, P1030, DOI 10.1109/CVPRW.2009.5206727
   Gupta S, 2014, LECT NOTES COMPUT SC, V8695, P345, DOI 10.1007/978-3-319-10584-0_23
   Gupta S, 2013, PROC CVPR IEEE, P564, DOI 10.1109/CVPR.2013.79
   Hu WM, 2013, IEEE T IMAGE PROCESS, V22, P1778, DOI 10.1109/TIP.2012.2236340
   LI H, 1995, IEEE T IMAGE PROCESS, V4, P320, DOI 10.1109/83.366480
   Lim JJ, 2013, PROC CVPR IEEE, P3158, DOI 10.1109/CVPR.2013.406
   Maire M, 2015, LECT NOTES COMPUT SC, V9006, P273, DOI 10.1007/978-3-319-16817-3_18
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   MCLAREN K, 1976, J SOC DYERS COLOUR, V92, P338
   Meer P, 2001, IEEE T PATTERN ANAL, V23, P1351, DOI 10.1109/34.977560
   NALWA VS, 1986, IEEE T PATTERN ANAL, V8, P699, DOI 10.1109/TPAMI.1986.4767852
   Papari G, 2008, IEEE T IMAGE PROCESS, V17, P1950, DOI 10.1109/TIP.2008.2002306
   Papari G, 2007, EURASIP J ADV SIG PR, DOI 10.1155/2007/71828
   Papari G, 2011, IMAGE VISION COMPUT, V29, P79, DOI 10.1016/j.imavis.2010.08.009
   Ren X., 2012, ADV NEURAL INF PROCE
   Ren XF, 2008, LECT NOTES COMPUT SC, V5304, P533
   Ruzon M. A., 1999, Proceedings. 1999 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No PR00149), P160, DOI 10.1109/CVPR.1999.784624
   Ruzon MA, 2001, IEEE T PATTERN ANAL, V23, P1281, DOI 10.1109/34.969118
   Sáez A, 2013, IET IMAGE PROCESS, V7, P355, DOI 10.1049/iet-ipr.2012.0085
   Silberman N., 2012, EUR C COMP VIS ECCV, P564
   Smith SM, 1997, INT J COMPUT VISION, V23, P45, DOI 10.1023/A:1007963824710
   Topal C, 2012, J VIS COMMUN IMAGE R, V23, P862, DOI 10.1016/j.jvcir.2012.05.004
   Wei H, 2013, NEUROCOMPUTING, V103, P247, DOI 10.1016/j.neucom.2012.09.027
NR 48
TC 5
Z9 5
U1 0
U2 17
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2016
VL 54
BP 60
EP 70
DI 10.1016/j.imavis.2016.08.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA EB6UG
UT WOS:000387520500006
DA 2024-07-18
ER

PT J
AU Wood, MD
   Das, M
   Stubler, PO
   Loui, AC
AF Wood, Mark D.
   Das, Madirakshi
   Stubler, Peter O.
   Loui, Alexander C.
TI Event-enabled intelligent asset selection and grouping for photobook
   creation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Metadata generation; Event detection; Asset selection; Image quality;
   Semantic understanding; Consumer image collection; Photobook
AB The process of creating a photo product, such as a photobook, calendar or collage, from a large personal image collection requires intensive user effort. The primary goal of the current research was to develop an end-to-end solution to the problem of photo product generation that enables the user to complete the process with minimal edits, where the system intelligently selects assets and groups them before presenting the output to the user. The automation is driven by metadata extracted both from individual images as well as from sets of assets in a collection. In particular, we use an automatically detected event hierarchy to establish meaningful groupings in the assets, and to determine an appropriate grouping and pagination for the final product. We propose a novel intermediate construct, called a storyboard, which can be translated to different product types without recomputing the underlying metadata. In addition to chronological storyboards, we also describe a novel hybrid storyboard that joins chronological image presentation with groups of images of a common theme. A pagination algorithm uses the information in the storyboard and the product constraints to generate a product. Finally, the user is provided with a metadata-driven editing mechanism that makes it easy to change the auto-populated product. Given that the proposed system envisions user interaction in creating the final product, user studies are conducted to judge the usefulness of the system, where consumers use the system to generate a photobook with their own images. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Wood, Mark D.; Das, Madirakshi; Stubler, Peter O.; Loui, Alexander C.] Kodak Alaris Inc, Rochester, NY 14615 USA.
C3 Eastman Kodak
RP Loui, AC (corresponding author), Kodak Alaris Inc, Imaging R&D, 2400 Mt Read Blvd, Rochester, NY 14615 USA.
EM alexander.loui@kodakalaris.com
CR [Anonymous], P ACM INT C MULT
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], IEEE INT C IM PROC I
   [Anonymous], IEEE C COMP VIS CVPR
   [Anonymous], ACM C MULT
   [Anonymous], ACM C MULT
   [Anonymous], P IS T SPIE EL IM SA
   [Anonymous], IEEE INT C SEM COMP
   [Anonymous], IEEE MULTIMEDIA
   [Anonymous], P ACM INT C MULT
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], P 1 INT WORKSH INT S
   [Anonymous], ACM INT C MULT RETR
   [Anonymous], 2014, RDF 1 1 CONCEPTS ABS
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], ACM MULTIMEDIA
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], IEEE C SEM COMP ICSC
   [Anonymous], IEEE WORKSH APPL COM
   [Anonymous], IEEE COMPUTER VISION
   [Anonymous], P 15 INT C INT US IN
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], ACM C MULT
   Boutell MR, 2004, PATTERN RECOGN, V37, P1757, DOI 10.1016/j.patcog.2004.03.009
   Carneiro G, 2007, IEEE T PATTERN ANAL, V29, P394, DOI 10.1109/TPAMI.2007.61
   Das Gupta M, 2011, PROC CVPR IEEE
   Guntuku SC, 2015, IEEE INT CON MULTI
   KNUTH DE, 1981, SOFTWARE PRACT EXPER, V11, P1119, DOI 10.1002/spe.4380111102
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lazebnik S., 2006, CVPR, DOI DOI 10.1109/CVPR.2006.68
   Li LJ, 2007, IEEE I CONF COMP VIS, P345
   Loui AC, 2003, IEEE T MULTIMEDIA, V5, P390, DOI 10.1109/TMM.2003.814723
NR 32
TC 1
Z9 1
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2016
VL 53
BP 57
EP 67
DI 10.1016/j.imavis.2015.12.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DX4YH
UT WOS:000384386500006
DA 2024-07-18
ER

PT J
AU Snape, P
   Pszczolkowski, S
   Zafeiriou, S
   Tzimiropoulos, G
   Ledig, C
   Rueckert, D
AF Snape, Patrick
   Pszczolkowski, Stefan
   Zafeiriou, Stefanos
   Tzimiropoulos, Georgios
   Ledig, Christian
   Rueckert, Daniel
TI A robust similarity measure for volumetric image registration with
   outliers
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image registration; Lucas-Kanade; Normalised gradient; Free-form
   deformation
ID DEFORMABLE REGISTRATION; MUTUAL-INFORMATION; MRI
AB Image registration under challenging realistic conditions is a very important area of research. In this paper, we focus on algorithms that seek to densely align two volumetric images according to a global similarity measure. Despite intensive research in this area, there is still a need for similarity measures that are robust to outliers common to many different types of images. For example, medical image data is often corrupted by intensity inhomogeneities and may contain outliers in the form of pathologies. In this paper we propose a global similarity measure that is robust to both intensity inhomogeneities and outliers without requiring prior knowledge of the type of outliers. We combine the normalised gradients of images with the cosine function and show that it is theoretically robust against a very general class of outliers. Experimentally, we verify the robustness of our measures within two distinct algorithms. Firstly, we embed our similarity measures within a proof-of-concept extension of the Lucas-Kanade algorithm for volumetric data. Finally, we embed our measures within a popular non-rigid alignment framework based on free-form deformations and show it to be robust against both simulated tumours and intensity inhomogeneities. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Snape, Patrick; Zafeiriou, Stefanos; Ledig, Christian; Rueckert, Daniel] Imperial Coll London, Dept Comp, London SW7 2AZ, England.
   [Tzimiropoulos, Georgios] Univ Nottingham, Sch Comp Sci, Nottingham NG8 1BB, England.
   [Pszczolkowski, Stefan] Univ Nottingham, Sch Med, Nottingham NG7 2UH, England.
C3 Imperial College London; University of Nottingham; University of
   Nottingham
RP Snape, P (corresponding author), Imperial Coll London, Dept Comp, London SW7 2AZ, England.
EM p.snape@imperial.ac.uk; stefan.pszczolkowskiparraguez@nottingham.ac.uk;
   s.zafeiriou@imperial.ac.uk; yorgos.tzimiropoulos@nottingham.ac.uk;
   christian.ledig@imperial.ac.uk; d.rueckert@imperial.ac.uk
RI Rueckert, Daniel/C-4393-2008; Pszczolkowski, Stefan/AAP-7393-2021;
   Pszczolkowski, Stefan/HMO-6849-2023
OI Pszczolkowski, Stefan/0000-0002-5859-3190; Rueckert,
   Daniel/0000-0002-5683-5889; Ledig, Christian/0000-0003-4862-3138
FU Qualcomm Innovation Fellowship; EPSRC DTA from Imperial College London;
   EPSRC [EP/J017787/1]; 7th Framework Programme [FP7-270259-TBIcare];
   EPSRC [EP/H016988/1, EP/J017787/1, EP/N007743/1] Funding Source: UKRI
FX The work of Patrick Snape was funded by the Qualcomm Innovation
   Fellowship and by an EPSRC DTA from Imperial College London. The work of
   Stefanos Zafeiriou was partially supported by the EPSRC project
   EP/J017787/1 (4DFAB). This work is partially funded under the 7th
   Framework Programme (FP7-270259-TBIcare).
CR [Anonymous], 2008, P IEEE C COMP VIS PA
   Ashraf AB, 2010, PROC CVPR IEEE, P2480, DOI 10.1109/CVPR.2010.5539948
   Baker S, 2004, INT J COMPUT VISION, V56, P221, DOI 10.1023/B:VISI.0000011205.11775.fd
   Baker S, 2001, PROC CVPR IEEE, P1090
   Baker S., 2003, TECH REP
   BAKER S, 2004, CMURITR0464
   Black M.J., 1996, Fourth European Conference on Computer 650 Vision (ECCV), P329
   Butz T., 2001, AFFINE REGISTRATION, P549, DOI 10.1007/3-540-45468-3_66
   Dowson N., IEEE T PATTERN ANAL, V30
   Droske M, 2003, SIAM J APPL MATH, V64, P668, DOI 10.1137/S0036139902419528
   Evangelidis G.D., IEEE T PATTERN ANAL, V30
   Guerquin-Kern M, 2012, IEEE T MED IMAGING, V31, P626, DOI 10.1109/TMI.2011.2174158
   Haber E, 2006, LECT NOTES COMPUT SC, V4191, P726
   Hachama M, 2012, IEEE T IMAGE PROCESS, V21, P4080, DOI 10.1109/TIP.2012.2200495
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Heldmann S., 2009, P SPIE
   Lange T, 2009, INT J COMPUT ASS RAD, V4, P79, DOI 10.1007/s11548-008-0270-1
   Liu X., 2014, LOW RANK RESCUE ATLA, P97
   Livyatan H, 2003, IEEE T MED IMAGING, V22, P1395, DOI 10.1109/TMI.2003.819288
   Loeckx D, 2010, IEEE T MED IMAGING, V29, P19, DOI 10.1109/TMI.2009.2021843
   Lucas B.D., DARPA IMAGE UNDERSTA
   Lucey S, 2013, IEEE T PATTERN ANAL, V35, P1383, DOI 10.1109/TPAMI.2012.220
   Marcus D.S., J COGN NEUROSCI, P19
   Matthews I., 2004, INT J COMPUT VIS
   MEYER CR, 1995, IEEE T MED IMAGING, V14, P36, DOI 10.1109/42.370400
   Ou YM, 2011, MED IMAGE ANAL, V15, P622, DOI 10.1016/j.media.2010.07.002
   Parraguez S. Pszczolkowski, 2014, THESIS
   Pluim JPW, 2000, IEEE T MED IMAGING, V19, P809, DOI 10.1109/42.876307
   Pluim JPW, 2003, IEEE T MED IMAGING, V22, P986, DOI 10.1109/TMI.2003.815867
   Pszczolkowski S., 2014, ROBUST SIMILARITY ME
   Richard FJP, 2004, INT C PATT RECOG, P649, DOI 10.1109/ICPR.2004.1333856
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Rühaak J, 2013, I S BIOMED IMAGING, P572
   Sled JG, 1998, IEEE T MED IMAGING, V17, P87, DOI 10.1109/42.668698
   Spitzer V, 1996, J AM MED INFORM ASSN, V3, P118, DOI 10.1136/jamia.1996.96236280
   Studholme C, 1999, PATTERN RECOGN, V32, P71, DOI 10.1016/S0031-3203(98)00091-0
   Studholme C, 2006, IEEE T MED IMAGING, V25, P626, DOI 10.1109/TMI.2006.872745
   Tustison NJ, 2010, IEEE T MED IMAGING, V29, P1310, DOI 10.1109/TMI.2010.2046908
   Tzimiropoulos G, 2011, IEEE I CONF COMP VIS, P1847, DOI 10.1109/ICCV.2011.6126452
   Tzimiropoulos G, 2010, IEEE T PATTERN ANAL, V32, P1899, DOI 10.1109/TPAMI.2010.107
   Zacharaki EI, 2008, IEEE T MED IMAGING, V27, P1003, DOI 10.1109/TMI.2008.916954
   Zhuang X., 2011, IEEE T MED IMAGING, P1
NR 42
TC 6
Z9 7
U1 2
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2016
VL 52
BP 97
EP 113
DI 10.1016/j.imavis.2016.05.006
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DW7GE
UT WOS:000383818400008
DA 2024-07-18
ER

PT J
AU Antunes, M
   Barreto, JP
   Nunes, U
AF Antunes, Michel
   Barreto, Joao P.
   Nunes, Urbano
TI Piecewise-planar reconstruction using two views
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Piecewise-planar reconstruction; SymStereo; Stereo-rangefinding;
   Semi-dense reconstruction
AB The article describes a reconstruction pipeline that generates piecewise-planar models of man-made environments using two calibrated views. The 3D space is sampled by a set of virtual cut planes that intersect the baseline of the stereo rig and implicitly define possible pixel correspondences across views. The likelihood of these correspondences being true matches is measured using signal symmetry analysis [1], which enables to obtain profile contours of the 3D scene that become lines whenever the virtual cut planes intersect planar surfaces. The detection and estimation of these lines cuts is formulated as a global optimization problem over the symmetry matching cost, and pairs of reconstructed lines are used to generate plane hypotheses that serve as input to PEARL clustering [2]. The PEARL algorithm alternates between a discrete optimization step, which merges planar surface hypotheses and discards detections with poor support, and a continuous optimization step, which refines the plane poses taking into account surface slant. The pipeline outputs an accurate semi-dense Piecewise-Planar Reconstruction of the 3D scene. In addition, the input images can be segmented into piecewise-planar regions using a standard labeling formulation for assigning pixels to plane detections. Extensive experiments with both indoor and outdoor stereo pairs show significant improvements over state-of-the-art methods with respect to accuracy and robustness. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Antunes, Michel] Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust SnT, Luxembourg, Luxembourg.
   [Barreto, Joao P.; Nunes, Urbano] Univ Coimbra, Fac Sci & Technol, ISR, Coimbra, Portugal.
C3 University of Luxembourg; Universidade de Coimbra
RP Antunes, M (corresponding author), Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust SnT, Luxembourg, Luxembourg.; Barreto, JP; Nunes, U (corresponding author), Univ Coimbra, Fac Sci & Technol, ISR, Coimbra, Portugal.
EM michel.antunes@uni.lu; jpbar@isr.uc.pt; urbano@isr.uc.pt
RI ; Barreto, Joao P/I-2845-2012; Nunes, Urbano J./G-1187-2011
OI Antunes, Michel/0000-0001-6115-5186; Barreto, Joao
   P/0000-0001-5220-9170; Nunes, Urbano J./0000-0002-7750-5221
FU Portuguese Science Foundation (FCT) [SFRH/BD/47488/2008]; FCT; COMPETE
   program [AMS-HMI12:RECI/EEI-AUT/0181/2012]; FEDER; Fundação para a
   Ciência e a Tecnologia [SFRH/BD/47488/2008] Funding Source: FCT
FX Michel Antunes acknowledges the Portuguese Science Foundation (FCT) that
   generously funded his work through the grant SFRH/BD/47488/2008. This
   work was also supported by FCT and the COMPETE program (co-funded by
   FEDER) under the project grant AMS-HMI12:RECI/EEI-AUT/0181/2012.
CR [Anonymous], PAMI
   [Anonymous], 2009, CVPR
   [Anonymous], 2002, IJCV
   [Anonymous], 2012, IJCV
   [Anonymous], PAMI
   [Anonymous], CVPR
   [Anonymous], PAMI
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 2011, BMVC
   [Anonymous], 2006, CVPR
   [Anonymous], 1981, COMMUN ACM
   [Anonymous], 2009, ICCV
   Antunes M., 2011, BMVC
   Antunes M., 2014, IJCV
   Antunes Michel, 2013, CVPR
   Baker Simon, 1998, CVPR
   Bartoli A., 2007, CVIU
   Birchfield S., 1999, ICCV
   Bleyer M., 2004, ICIP
   Bleyer M., 2010, CVPR
   Collins Robert T, 1996, CVPR
   Gallup D., 2008, CVPR
   Gallup D., 2007, CVPR
   Gallup David., CVPR
   Grompone von Gioi R., 2010, PAMI
   Hirschmuller H., 2009, IEEE T PATTERN ANAL
   Isack Hossam, 2012, IJCV
   Klaus A., 2006, ICPR
   Klette R., 2011, VEHICULAR TECHNOLOGY
   Kolmogorov V., 2004, PAMI
   Lin M.H., 2004, PAMI
   Pollefeys M., 2008, IJCV
   Scharstein D., 2007, CVPR
   Tao H., 2001, ICCV
   Werner T., 2002, ECCV
   Zhang Y., 2008, ICPR
NR 36
TC 4
Z9 8
U1 0
U2 2
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2016
VL 46
BP 47
EP 63
DI 10.1016/j.imavis.2015.11.008
PG 17
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DH3IJ
UT WOS:000372680400004
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Ma, C
   Yang, XK
   Zhang, CY
   Ruan, X
   Yang, MH
AF Ma, Chao
   Yang, Xiaokang
   Zhang, Chongyang
   Ruan, Xiang
   Yang, Ming-Hsuan
TI Sketch retrieval via local dense stroke features
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Sketch retrieval; Stroke feature; Poisson based histogram of orientation
ID IMAGE; RECOGNITION; SIMILARITY
AB Sketch retrieval aims at retrieving the most similar sketches from a large database based on one hand-drawn query. Successful retrieval hinges on an effective representation of sketch images and an efficient search method. In this paper, we propose a representation scheme which takes sketch strokes into account with local features, thereby facilitating efficient retrieval with codebooks. Stroke features are detected via densely sampled points on stroke lines with crucial corners as anchor points, from which local gradients are enhanced and described by a quantized histogram of gradients. A codebook is organized in a hierarchical vocabulary tree, which maintains structural information of visual words and enables efficient retrieval in sub-linear time. Experimental results on three data sets demonstrate the merits of the proposed algorithm for effective and efficient sketch retrieval. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Ma, Chao; Yang, Xiaokang; Zhang, Chongyang] Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai 200240, Peoples R China.
   [Ruan, Xiang] Omron Corp, Kyoto, Japan.
   [Yang, Ming-Hsuan] Univ Calif, Elect Engn & Comp Sci, Merced, CA 95344 USA.
C3 Shanghai Jiao Tong University; Omron Corporation; University of
   California System; University of California Merced
RP Ma, C (corresponding author), Shanghai Jiao Tong Univ, Inst Image Commun & Network Engn, Shanghai 200240, Peoples R China.
EM chaoma@sjtu.edu.cn; xkyang@sjtu.edu.cn; sunny_zhang@sjtu.edu.cn;
   gen@omm.ncl.omron.co.jp; mhyang@ucmerced.edu
RI Yang, Ming-Hsuan/T-9533-2019; Yang, Xiaokang/C-6137-2009; Yang,
   Ming-Hsuan/AAE-7350-2019
OI Yang, Ming-Hsuan/0000-0003-4848-2304; Yang,
   Xiaokang/0000-0003-4029-3322; 
FU China Scholarship Council
FX C. Ma was sponsored by China Scholarship Council and took a two-year
   study in University of California at Merced.
CR [Anonymous], P ACM SIGGRAPH
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Aslan C, 2005, IEEE I CONF COMP VIS, P1339
   Bai X, 2008, IEEE T PATTERN ANAL, V30, P1282, DOI 10.1109/TPAMI.2007.70769
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Cao Y, 2011, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2011.5995460
   Chalechale A, 2005, IEEE T SYST MAN CY A, V35, P28, DOI 10.1109/TSMCA.2004.838464
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Donoser M., 2009, P AS C COMP VIS
   Eitz M., 2012, ACM T GRAPHIC, V31, P1, DOI DOI 10.1145/2185520.2335395
   Eitz M, 2011, IEEE T VIS COMPUT GR, V17, P1624, DOI 10.1109/TVCG.2010.266
   Ferrari V, 2006, LECT NOTES COMPUT SC, V3953, P14, DOI 10.1007/11744078_2
   Ferrari V, 2010, INT J COMPUT VISION, V87, P284, DOI 10.1007/s11263-009-0270-9
   Harris C., 1988, P 4 ALV VIS C, V15, P10
   Hu R, 2013, COMPUT VIS IMAGE UND, V117, P790, DOI 10.1016/j.cviu.2013.02.005
   Hu R, 2010, IEEE IMAGE PROC, P1025, DOI 10.1109/ICIP.2010.5649331
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leung W.H., 2003, THESIS CARNEGIE MELL
   Leung WH, 2002, IEEE IMAGE PROC, P908
   Liu MY, 2010, PROC CVPR IEEE, P1696, DOI 10.1109/CVPR.2010.5539837
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Ma C, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.65
   Ma TY, 2011, PROC CVPR IEEE, P1441, DOI 10.1109/CVPR.2011.5995591
   Marr D., 1982, Visual perception
   Mikolajczyk K, 2004, INT J COMPUT VISION, V60, P63, DOI 10.1023/B:VISI.0000027790.02288.f2
   Nister David, 2006, CVPR
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Parui S., 2014, P EUR C COMP VIS, P398
   Perez P., P SIGGRAPH 2003, P313
   PERSOON E, 1986, IEEE T PATTERN ANAL, V8, P388, DOI 10.1109/TPAMI.1986.4767799
   Rui Y, 1999, J VIS COMMUN IMAGE R, V10, P39, DOI 10.1006/jvci.1999.0413
   Sebastian TB, 2004, IEEE T PATTERN ANAL, V26, P550, DOI 10.1109/TPAMI.2004.1273924
   Shao TJ, 2011, COMPUT GRAPH FORUM, V30, P2011, DOI 10.1111/j.1467-8659.2011.02050.x
   Srinivasan P, 2010, PROC CVPR IEEE, P1673, DOI 10.1109/CVPR.2010.5539834
   Vedaldi A., P IEEE C COMP VIS PA, P3539
   Yang JC, 2009, PROC CVPR IEEE, P1794, DOI 10.1109/CVPRW.2009.5206757
   ZAHN CT, 1972, IEEE T COMPUT, VC 21, P269, DOI 10.1109/TC.1972.5008949
   Zhang DS, 2002, IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL I AND II, PROCEEDINGS, P425, DOI 10.1109/ICME.2002.1035809
NR 40
TC 7
Z9 7
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2016
VL 46
BP 64
EP 73
DI 10.1016/j.imavis.2015.11.007
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DH3IJ
UT WOS:000372680400005
DA 2024-07-18
ER

PT J
AU Shi, F
   Laganière, R
   Petriu, E
AF Shi, Feng
   Laganiere, Robert
   Petriu, Emil
TI Local part model for action recognition
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Bag-of-features (BoF); Action recognition; Random sampling; Local part
   model; Multi-channel SVM
ID IMAGE DESCRIPTORS
AB This paper introduces an action recognition system based on a multiscale local part model. This model includes both a coarse primitive level root patch covering local global information and higher resolution overlapping part patches incorporating local structure and temporal relations. Descriptors are then computed over the local part models by applying fast random sampling at very high density. We also improve the recognition performance using a discontinuity-preserving optical flow algorithm. The evaluation shows that the feature dimensions can be reduced by 7/8 through PCA while preserving high accuracy. Our system achieves state-of-the-art results on large challenging realistic datasets, namely, 61.0% on HMDB51, 92.0% on UCF50, 86.6% on UCF101 and 653% on Hollywood2. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Shi, Feng; Laganiere, Robert; Petriu, Emil] Univ Ottawa, Sch EECS, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
C3 University of Ottawa
RP Laganière, R (corresponding author), Univ Ottawa, Sch EECS, 800 King Edward Ave, Ottawa, ON K1N 6N5, Canada.
EM fshi098@eecs.uottawa.ca; laganier@eecs.uottawa.ca;
   petriu@eecs.uottawa.ca
RI Shi, Feng/G-3247-2012; Laganiere, Robert/H-9138-2013
CR Agarwal A., 2006, ECCV
   [Anonymous], CORR
   [Anonymous], CVPR 2011
   [Anonymous], ECCV 2008
   [Anonymous], IEEE T PATTERN ANAL
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], SIGNAL PROCESS
   [Anonymous], CROAT COMP VIS WORKS
   [Anonymous], IEEE I CONF COMP VIS
   [Anonymous], BMVC 2009
   [Anonymous], INT C COMP VIS ICCV
   [Anonymous], 2013, ICCV
   [Anonymous], PROBABILISTIC FRAMEW
   [Anonymous], 2008, CVPR
   [Anonymous], ECCV 2012
   [Anonymous], ICCV 2009
   [Anonymous], COMP ROB VIS CRV 201
   [Anonymous], 2010, ECCV
   [Anonymous], VIS APPL J SEP
   [Anonymous], P IEEE 12 INT COMP V
   [Anonymous], CVPR 2011
   [Anonymous], 2008, CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], 2008, CVPR
   [Anonymous], ECCV 2012
   [Anonymous], 2013, CVPR
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   [Anonymous], COMP VIS PATT REC 20
   [Anonymous], CVPR 2009
   Brox T, 2011, IEEE T PATTERN ANAL, V33, P500, DOI 10.1109/TPAMI.2010.143
   Cao ZM, 2010, PROC CVPR IEEE, P2707, DOI 10.1109/CVPR.2010.5539992
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Dollar P., 2005, Proceedings. 2nd Joint IEEE International Workshop on Visual Surveillance and Performance Evaluation of Tracking and Surveillance (VS-PETS) (IEEE Cat. No. 05EX1178), P65
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Feng Shi, 2011, 2011 IEEE International Workshop on Haptic Audio Visual Environments and Games (HAVE 2011), P35, DOI 10.1109/HAVE.2011.6088408
   Gaidon A., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3201, DOI 10.1109/CVPR.2011.5995646
   Gilbert A, 2011, IEEE T PATTERN ANAL, V33, P883, DOI 10.1109/TPAMI.2010.144
   Hamid R, 2005, PROC CVPR IEEE, P1031
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Ke Y, 2005, IEEE I CONF COMP VIS, P166
   Ke Y., 2004, P 2004 IEEE COMP SOC, V2, pII
   Klaser A., 2008, P BMVC, P275, DOI DOI 10.5244/C.22.99
   Kuehne H, 2011, IEEE I CONF COMP VIS, P2556, DOI 10.1109/ICCV.2011.6126543
   Laptev I, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P432, DOI 10.1109/iccv.2003.1238378
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Leung T, 2001, INT J COMPUT VISION, V43, P29, DOI 10.1023/A:1011126920638
   Linde O, 2012, COMPUT VIS IMAGE UND, V116, P538, DOI 10.1016/j.cviu.2011.12.003
   Liu C, 2008, COMPUTER VISION PATT, P1
   Nowak E, 2006, LECT NOTES COMPUT SC, V3954, P490
   Oneata D, 2013, IEEE I CONF COMP VIS, P1817, DOI 10.1109/ICCV.2013.228
   Oshin O., 2011, Proceedings 2011 IEEE International Conference on Automatic Face & Gesture Recognition (FG 2011), P111, DOI 10.1109/FG.2011.5771382
   Park JS, 2013, I C COMP SYST APPLIC
   Schindler K, 2008, PROC CVPR IEEE, P3025
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Schwartz WR, 2009, IEEE I CONF COMP VIS, P24, DOI 10.1109/ICCV.2009.5459205
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Tang K, 2012, PROC CVPR IEEE, P1250, DOI 10.1109/CVPR.2012.6247808
   Vedaldi A., VLFEAT OPEN PORTABLE
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang H, 2013, INT J COMPUT VISION, V103, P60, DOI 10.1007/s11263-012-0594-8
   Yu T.H., 2010, BMVC
   Zach C, 2007, LECT NOTES COMPUT SC, V4713, P214, DOI 10.1007/978-3-540-74936-3_22
   Zhang J, 2007, INT J COMPUT VISION, V73, P213, DOI 10.1007/s11263-006-9794-4
NR 65
TC 4
Z9 4
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2016
VL 46
BP 18
EP 28
DI 10.1016/j.imavis.2015.11.010
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA DH3IJ
UT WOS:000372680400002
DA 2024-07-18
ER

PT J
AU Xu, K
   Liu, SH
   Ai, YH
AF Xu, Ke
   Liu, Shunhua
   Ai, Yonghao
TI Application of Shearlet transform to classification of surface defects
   for metals
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Surface inspection; Feature extraction; Multi-scale geometric analysis;
   Shearlet transform; Kernel Locality Preserving Projections
ID FILTER BANKS; IMAGE; REPRESENTATION; ALGORITHM
AB Surface defects are important factors of surface quality of industrial products. Most of the traditional machine vision based methods for surface defect recognition have some shortcomings such as low detection rate of defects and high rate of false alarms. Different types of defects have special information at some directions and scales of their images, while the traditional methods of feature extraction, such as Wavelet transform, are unable to get the information at all directions. In this study, Shearlet transform is introduced to provide efficient multi-scale directional representation, and a general framework has been developed to analyze and represent surface defect images with anisotropic information. The metal surface images captured from production lines are decomposed into multiple directional subbands with Shearlet transform, and features are extracted from all subbands and combined into a high-dimensional feature vector. Kernel Locality Preserving Projection is applied to the dimension reduction of the feature vector. The proposed method is tested with the surface images captured from different production lines, and the results show that the classification rates of surface defects of continuous casting slabs, hot-rolled steels, and aluminum sheets are 94.35%, 95.75% and 92.5% respectively. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Xu, Ke; Liu, Shunhua; Ai, Yonghao] Univ Sci & Technol Beijing, Natl Engn Res Ctr Adv Rolling Technol, Beijing 100083, Peoples R China.
C3 University of Science & Technology Beijing
RP Xu, K (corresponding author), Univ Sci & Technol Beijing, Natl Engn Res Ctr Adv Rolling Technol, Beijing 100083, Peoples R China.
EM xuke@ustb.edu.cn
RI Xu, Ke/GZM-9218-2022
OI Xu, Ke/0000-0003-1809-7413
FU National Science and Technology Support Program of China [2012BAB19B06];
   Doctoral Fund of Ministry of Education of China [20120006110033]
FX This work is sponsored by the National Science and Technology Support
   Program of China (Grant no. 2012BAB19B06), and Doctoral Fund of Ministry
   of Education of China (Grant no. 20120006110033).
CR Ai Y., 2012, OPT ENG, V51, P1
   Ai YH, 2013, J IRON STEEL RES INT, V20, P80, DOI 10.1016/S1006-706X(13)60102-8
   [Anonymous], WAVELET TOUR SIGNAL
   [Anonymous], 2005, ADV NEURAL INFORM PR
   BARALDI A, 1995, IEEE T GEOSCI REMOTE, V33, P293, DOI 10.1109/36.377929
   Candes E.J., 1999, CURVELETS SURPRINGLY
   CANDES EJ, 1998, THESIS STANFORD U CA
   Candès E, 2006, MULTISCALE MODEL SIM, V5, P861, DOI 10.1137/05064182X
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1007/BF00994018
   Do M., 2002, P IEEE INT C IM PROC
   Do M.N., 2001, TECHNOLOGY
   Do MN, 2005, IEEE T IMAGE PROCESS, V14, P2091, DOI 10.1109/TIP.2005.859376
   Easley G, 2008, APPL COMPUT HARMON A, V25, P25, DOI 10.1016/j.acha.2007.09.003
   Gu J, 2002, PATTERN RECOGN, V35, P2905, DOI 10.1016/S0031-3203(01)00194-7
   Guo K, 2008, J FOURIER ANAL APPL, V14, P327, DOI 10.1007/s00041-008-9018-0
   Guo K, 2007, SIAM J MATH ANAL, V39, P298, DOI 10.1137/060649781
   He X., 2005, THESIS U CHICAGO CHI
   HUPKENS TM, 1995, PATTERN RECOGN LETT, V16, P371, DOI 10.1016/0167-8655(94)00110-O
   Jeon Y.-J., 2009, P ICROS SICE INT JOI
   KUTYNIOK G., 2007, J WAVELET THEORY APP, V1, P1
   Landström A, 2012, IEEE J-STSP, V6, P866, DOI 10.1109/JSTSP.2012.2212416
   Le Pennec E, 2005, MULTISCALE MODEL SIM, V4, P992, DOI 10.1137/040619454
   Le Pennec E, 2005, IEEE T IMAGE PROCESS, V14, P423, DOI 10.1109/TIP.2005.843753
   Lim Wang-Q, 2010, DISCRETE SHEARLET TR
   Mallat S, 2007, NUMER ALGORITHMS, V44, P205, DOI 10.1007/s11075-007-9092-4
   Papakostas GA, 2009, APPL MATH COMPUT, V212, P162, DOI 10.1016/j.amc.2009.02.029
   Paulraj M.P., 2010, P 6 INT C SIGN PROC
   PHOONG SM, 1995, IEEE T SIGNAL PROCES, V43, P649, DOI 10.1109/78.370620
   Pieringer C, 2010, INSIGHT, V52, P548, DOI 10.1784/insi.2010.52.10.548
   Schwartz W.R., 2011, P IEEE INT C IM PROC
   VETTERLI M, 1992, IEEE T SIGNAL PROCES, V40, P2207, DOI 10.1109/78.157221
   Xu K, 1999, J UNIV SCI TECHNOL B, V6, P296
   Xu K, 2013, INT J MIN MET MATER, V20, P37, DOI 10.1007/s12613-013-0690-y
   Yun JP, 2009, NDT&E INT, V42, P389, DOI 10.1016/j.ndteint.2009.01.007
NR 34
TC 45
Z9 50
U1 1
U2 63
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2015
VL 35
BP 23
EP 30
DI 10.1016/j.imavis.2015.01.001
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CE4JD
UT WOS:000351796000003
DA 2024-07-18
ER

PT J
AU Khoury, E
   El Shafey, L
   McCool, C
   Günther, M
   Marcel, S
AF Khoury, Elie
   El Shafey, Laurent
   McCool, Christopher
   Guenther, Manuel
   Marcel, Sebastien
TI Bi-modal biometric authentication on mobile phones in challenging
   conditions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Face authentication; Speaker authentication; Bi-modal authentication;
   Gaussian mixture model; Session variability; Inter-session variability;
   Total variability; I-vector; Fusion
ID SESSION VARIABILITY; VERIFICATION; MODELS
AB This paper examines the issue of face, speaker and bi-modal authentication in mobile environments when there is significant condition mismatch. We introduce this mismatch by enrolling client models on high quality biometric samples obtained on a laptop computer and authenticating them on lower quality biometric samples acquired with a mobile phone. To perform these experiments we develop three novel authentication protocols for the large publicly available MOBIO database. We evaluate state-of-the-art face, speaker and bi-modal authentication techniques and show that inter-session variability modelling using Gaussian mixture models provides a consistently robust system for face, speaker and bi-modal authentication. It is also shown that multi-algorithm fusion provides a consistent performance improvement for face, speaker and bi-modal authentication. Using this bi-modal multi-algorithm system we derive a state-of-the-art authentication system that obtains a half total error rate of 63% and 1.9% for Female and Male trials, respectively. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Khoury, Elie; El Shafey, Laurent; Guenther, Manuel; Marcel, Sebastien] Idiap Res Inst, Martigny, Switzerland.
RP Khoury, E (corresponding author), Idiap Res Inst, Martigny, Switzerland.
EM elie.khowy@idiap.ch; laurent.el-shafey@idiap.ch;
   chris.mccool@nicta.com.au; manuel.guenther@idiap.ch; marcel@idiap.ch
RI Khoury, Elie/ABH-2176-2022; Günther, Manuel/AAX-2010-2020
OI Khoury, Elie/0000-0001-9568-3729; Günther, Manuel/0000-0003-1489-7448;
   McCool, Chris/0000-0002-0577-1299
FU Swiss National Science Foundation; European Community [238803, 284989];
   NICTA; Australian Government through the Department of Communications;
   Australian Research Council through the ICT Centre of Excellence Program
FX The research leading to these results has received funding from the
   Swiss National Science Foundation under the LOBI project, from the
   European Community's Seventh Framework Programme (FP7) under grant
   agreements 238803 (BBfor2) and 284989 (BEAT), and from NICTA. NICTA is
   funded by the Australian Government through the Department of
   Communications and the Australian Research Council through the ICT
   Centre of Excellence Program.
CR Adami Andre., 2002, Proceedings of ICSLP, V1, P4
   [Anonymous], IEEE IAPR INT C BIOM
   [Anonymous], INT C PATT REC ICPR
   [Anonymous], INT C SPOK LANG PROC
   [Anonymous], INT JOINT C BIOM IJC
   [Anonymous], INT C IM VIS COMP IC
   [Anonymous], 20 ACM INT C MULT AC
   [Anonymous], 21 INT C PATT REC IC
   [Anonymous], IEEE T AUDIO SPEECH
   [Anonymous], 2001, ALGORITHMS MAXIMUM L
   [Anonymous], NIST SPEAK REC WORKS
   Auckenthaler R, 2000, DIGIT SIGNAL PROCESS, V10, P42, DOI 10.1006/dspr.1999.0360
   Brümmer N, 2007, IEEE T AUDIO SPEECH, V15, P2072, DOI 10.1109/TASL.2007.902870
   Brummer N., 2010, P NIST 2010 SPEAK EV, P1
   Burget L, 2011, INT CONF ACOUST SPEE, P4832
   Cardinaux F, 2006, IEEE T SIGNAL PROCES, V54, P361, DOI 10.1109/TSP.2005.861075
   Cardinaux F, 2003, LECT NOTES COMPUT SC, V2688, P911
   Dasarathy B.V., 1994, DECISION FUSION
   Dehak N., 2009, ECOLE TECHNOLOGIE SU
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INTERSPEECH 2009: 10TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2009, VOLS 1-5, P1527
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   El Shafey L, 2013, IEEE T PATTERN ANAL, V35, P1788, DOI 10.1109/TPAMI.2013.38
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Perera LP, 2011, COMPUT SIST, V15, P17
   Garcia-Romero D., 2011, INTERSPEECH
   Glembek O, 2009, INT CONF ACOUST SPEE, P4057, DOI 10.1109/ICASSP.2009.4960519
   Hasan T., 2013, IEEE INT C AC SPEECH
   Hatch AO, 2006, INTERSPEECH 2006 AND 9TH INTERNATIONAL CONFERENCE ON SPOKEN LANGUAGE PROCESSING, VOLS 1-5, P1471
   Kenny P, 2005, IEEE T SPEECH AUDI P, V13, P345, DOI 10.1109/TSA.2004.840940
   Li P, 2012, IEEE T PATTERN ANAL, V34, P144, DOI 10.1109/TPAMI.2011.104
   Linlin Shen, 2010, 2010 IEEE International Conference on Intelligent Computing and Intelligent Systems (ICIS 2010), P97, DOI 10.1109/ICICISYS.2010.5658534
   Lucey S, 2004, PROC CVPR IEEE, P855
   Martin A., 1997, PROC EURO SPEECH 97, V4, P1895
   McCool C, 2012, IEEE INT CONF MULTI, P635, DOI 10.1109/ICMEW.2012.116
   McCool C, 2013, IET BIOMETRICS, V2, P117, DOI 10.1049/iet-bmt.2012.0059
   McLaren M, 2010, IEEE T INF FOREN SEC, V5, P802, DOI 10.1109/TIFS.2010.2068290
   Pigeon S, 2000, DIGIT SIGNAL PROCESS, V10, P237, DOI 10.1006/dspr.1999.0358
   Prince SJ. D., 2007, IEEE INT CONE COMPUT, P1
   REYNOLDS DA, 1995, IEEE T SPEECH AUDI P, V3, P72, DOI 10.1109/89.365379
   Reynolds DA, 2000, DIGIT SIGNAL PROCESS, V10, P19, DOI 10.1006/dspr.1999.0361
   Roy A, 2012, IEEE T INF FOREN SEC, V7, P241, DOI 10.1109/TIFS.2011.2166387
   Sanderson C, 2003, PATTERN RECOGN LETT, V24, P2409, DOI 10.1016/S0167-8655(03)00070-9
   Scheirer E, 1997, INT CONF ACOUST SPEE, P1331, DOI 10.1109/ICASSP.1997.596192
   Shah D, 2009, 2009 11TH IEEE INTERNATIONAL SYMPOSIUM ON MULTIMEDIA (ISM 2009), P24, DOI 10.1109/ISM.2009.78
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   Vogt R, 2008, COMPUT SPEECH LANG, V22, P17, DOI 10.1016/j.csl.2007.05.003
   Wallace R, 2012, IET BIOMETRICS, V1, P188, DOI 10.1049/iet-bmt.2012.0024
   Wallace R, 2012, IEEE T INF FOREN SEC, V7, P553, DOI 10.1109/TIFS.2012.2184095
NR 49
TC 22
Z9 24
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2014
VL 32
IS 12
BP 1147
EP 1160
DI 10.1016/j.imavis.2013.10.001
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA CA4QB
UT WOS:000348888600016
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Liu, HD
   Yang, M
   Gao, Y
   Cui, CY
AF Liu, Hui-Dong
   Yang, Ming
   Gao, Yang
   Cui, Chunyan
TI Local histogram specification for face recognition under varying
   lighting conditions
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Local histogram specification; Local histogram statistics; Face
   recognition; High frequency illumination; Low frequency face features
ID CONTRAST ENHANCEMENT; IMAGES; EQUALIZATION; EIGENFACES; PATTERNS;
   OBJECT; MODELS
AB High frequency illumination and low frequency face features bring difficulties for most of the state-of-the-art face image preprocessors. In this paper, we propose two methods based on Local Histogram Specification (LHS) to preprocess face images under varying lighting conditions. The proposed methods are able to significantly remove both the low and high frequency parts of illumination on face images, as well as enhance face features lying in the low frequency part. Specifically, we first apply a high-pass filter on a face image to filter the low frequency illumination. Then, local histograms and local histogram statistics are learned from normal lighting images. In our first method, LHS is applied on the entire image. By contrast, in the second method, the regions contain high frequency illumination and weak face features on a face image are identified by local histogram statistics, before LHS is applied on these regions to eliminate high frequency illumination and enhance weak face features. Experimental results on the CMU PIE, Extended Yale B and CAS-PEAL-R1 databases demonstrate the effectiveness and efficiency of our methods. (C) 2014 Elsevier B.V. All rights reserved.
C1 [Liu, Hui-Dong; Yang, Ming; Cui, Chunyan] Nanjing Normal Univ, Sch Comp Sci & Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Gao, Yang] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
C3 Nanjing Normal University; Nanjing University
RP Yang, M (corresponding author), Nanjing Normal Univ, Sch Comp Sci & Technol, 1 Wenyuan Rd, Nanjing 210023, Jiangsu, Peoples R China.
EM h.d.liew@gmail.com; m.yang@njnu.edu.cn
RI GAO, Yang/HMO-8142-2023
FU National Natural Science Foundation of China [61272222, 61003116];
   Natural Science Foundation of Jiangsu Province of China [BK2011782]; Key
   (Major) Program of Natural Science Foundation of Jiangsu Province of
   China [BK2011005]
FX The authors would like to thank the editor and anonymous reviewers for
   their valuable comments and suggestions to improve the quality of this
   paper, Prof. Xiaoyang Tan for providing us the code for face image
   preprocessing and recognition, and Dr. Qinfeng Shi for helpful
   discussions. This work is supported in part by the National Natural
   Science Foundation of China under Grant Nos. 61272222 and 61003116, the
   Natural Science Foundation of Jiangsu Province of China under No.
   BK2011782, and Key (Major) Program of Natural Science Foundation of
   Jiangsu Province of China under No. BK2011005.
CR Adini Y, 1997, IEEE T PATTERN ANAL, V19, P721, DOI 10.1109/34.598229
   Ahonen T., 2005, EUR C COMP VIS PRAG, P469
   Ahonen T, 2006, IEEE T PATTERN ANAL, V28, P2037, DOI 10.1109/TPAMI.2006.244
   [Anonymous], IEEE CVPR
   Basri R, 2003, IEEE T PATTERN ANAL, V25, P218, DOI 10.1109/TPAMI.2003.1177153
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Belhumeur PN, 1998, INT J COMPUT VISION, V28, P245, DOI 10.1023/A:1008005721484
   Blanz V, 2003, IEEE T PATTERN ANAL, V25, P1063, DOI 10.1109/TPAMI.2003.1227983
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Caselles V, 1999, IEEE T IMAGE PROCESS, V8, P220, DOI 10.1109/83.743856
   Chen HF, 2000, PROC CVPR IEEE, P254, DOI 10.1109/CVPR.2000.855827
   Chen LH, 2011, PROC CVPR IEEE, P681, DOI 10.1109/CVPR.2011.5995621
   Chen T, 2006, IEEE T PATTERN ANAL, V28, P1519, DOI 10.1109/TPAMI.2006.195
   Coltuc D, 2006, IEEE T IMAGE PROCESS, V15, P1143, DOI 10.1109/TIP.2005.864170
   Felsberg M, 2001, IEEE T SIGNAL PROCES, V49, P3136, DOI 10.1109/78.969520
   Gao W, 2008, IEEE T SYST MAN CY A, V38, P149, DOI 10.1109/TSMCA.2007.909557
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jiang J., 2010, SPRINGER TEXTS STAT, DOI DOI 10.1007/978-1-4419-6827-2
   Kim JY, 2001, IEEE T CIRC SYST VID, V11, P475, DOI 10.1109/76.915354
   Lee KC, 2005, IEEE T PATTERN ANAL, V27, P684, DOI 10.1109/TPAMI.2005.92
   Lee PH, 2012, IEEE T IMAGE PROCESS, V21, P4280, DOI 10.1109/TIP.2012.2202670
   Liu CJ, 2002, IEEE T IMAGE PROCESS, V11, P467, DOI 10.1109/TIP.2002.999679
   Liu HD, 2012, IEEE IMAGE PROC, P597, DOI 10.1109/ICIP.2012.6466930
   Mika S., 1999, Neural Networks for Signal Processing IX: Proceedings of the 1999 IEEE Signal Processing Society Workshop (Cat. No.98TH8468), P41, DOI 10.1109/NNSP.1999.788121
   Ngoc-Son Vu, 2011, State of the Art in Biometrics, P123
   Nikolova M, 2013, J MATH IMAGING VIS, V46, P309, DOI 10.1007/s10851-012-0401-8
   Pang YW, 2008, IEEE T CIRC SYST VID, V18, P989, DOI 10.1109/TCSVT.2008.924108
   PIZER SM, 1987, COMPUT VISION GRAPH, V39, P355, DOI 10.1016/S0734-189X(87)80186-X
   Ramamoorthi R, 2002, IEEE T PATTERN ANAL, V24, P1322, DOI 10.1109/TPAMI.2002.1039204
   Sen D, 2011, IEEE T IMAGE PROCESS, V20, P1211, DOI 10.1109/TIP.2010.2083676
   Sim T, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P53, DOI 10.1109/AFGR.2002.1004130
   Stark JA, 2000, IEEE T IMAGE PROCESS, V9, P889, DOI 10.1109/83.841534
   Tan XY, 2010, IEEE T IMAGE PROCESS, V19, P1635, DOI 10.1109/TIP.2010.2042645
   TURK M, 1991, J COGNITIVE NEUROSCI, V3, P71, DOI 10.1162/jocn.1991.3.1.71
   Villegas M., 2005, 3 COST 275 WORKSH BI, P27
   Villegas M., 2007, 1 SPAN WORKSH BIOM, P1
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wan Y, 2007, IEEE T IMAGE PROCESS, V16, P2245, DOI 10.1109/TIP.2007.902332
   Wang HT, 2004, SIXTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P819
   Wiskott L, 1997, IEEE T PATTERN ANAL, V19, P775, DOI 10.1109/34.598235
   Woods R. E., 2007, DIGITAL IMAGE PROCES, V3
   Xie SF, 2010, IEEE T IMAGE PROCESS, V19, P1349, DOI 10.1109/TIP.2010.2041397
   Xie XH, 2008, PROC CVPR IEEE, P3645, DOI 10.1109/CVPR.2008.4587811
   Yang M, 2012, IEEE T INF FOREN SEC, V7, P1738, DOI 10.1109/TIFS.2012.2217332
   Zhang BH, 2007, IEEE T IMAGE PROCESS, V16, P57, DOI 10.1109/TIP.2006.884956
   Zhang L, 2006, IEEE T PATTERN ANAL, V28, P351, DOI 10.1109/TPAMI.2006.53
NR 47
TC 23
Z9 25
U1 0
U2 15
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2014
VL 32
IS 5
BP 335
EP 347
DI 10.1016/j.imavis.2014.02.010
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA AH3HI
UT WOS:000336013900003
DA 2024-07-18
ER

PT J
AU Roshtkhari, MJ
   Levine, MD
AF Roshtkhari, Mehrsan Javan
   Levine, Martin D.
TI Human activity recognition in videos using a single example
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Action recognition; Bag of video words; Hierarchical codebook;
   Spatio-temporal contextual information; Probabilistic modeling; Context;
   Ensemble of volumes
ID SPATIOTEMPORAL CONTEXT; ANOMALY DETECTION; MOTION; FEATURES; SCENES
AB This paper presents a novel approach for action recognition, localization and video matching based on a hierarchical codebook model of local spatio-temporal video volumes. Given a single example of an activity as a query video, the proposed method finds similar videos to the query in a target video dataset. The method is based on the bag of video words (BOV) representation and does not require prior knowledge about actions, background subtraction, motion estimation or tracking. It is also robust to spatial and temporal scale changes, as well as some deformations. The hierarchical algorithm codes a video as a compact set of spatio-temporal volumes, while considering their spatio-temporal compositions in order to account for spatial and temporal contextual information. This hierarchy is achieved by first constructing a codebook of spatio-temporal video volumes. Then a large contextual volume containing many spatio-temporal volumes (ensemble of volumes) is considered. These ensembles are used to construct a probabilistic model of video volumes and their spatio-temporal compositions. The algorithm was applied to three available video datasets for action recognition with different complexities (KTH. Weizmann, and MSR II) and the results were superior to other approaches, especially in the case of a single training example and cross-dataset(1) action recognition. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Roshtkhari, Mehrsan Javan; Levine, Martin D.] McGill Univ, Dept Elect & Comp Engn, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.
C3 McGill University
RP Roshtkhari, MJ (corresponding author), McGill Univ, Dept Elect & Comp Engn, Ctr Intelligent Machines, Montreal, PQ H3A 2A7, Canada.
EM javan@cim.mcgill.ca; levine@cim.mcgill.ca
OI Javan Roshtkhari, Mehrsan/0000-0001-7350-0696
CR [Anonymous], CVPR
   [Anonymous], 2009, BMVC
   [Anonymous], EUR C COMP VIS ECCV
   Bertini M, 2012, COMPUT VIS IMAGE UND, V116, P320, DOI 10.1016/j.cviu.2011.09.009
   Bishop C, 2007, RECOGNITION PATTERN
   Boiman O, 2007, INT J COMPUT VISION, V74, P17, DOI 10.1007/s11263-006-0009-9
   Bregonzio M, 2009, PROC CVPR IEEE, P1948, DOI 10.1109/CVPRW.2009.5206779
   Chakraborty B, 2012, COMPUT VIS IMAGE UND, V116, P396, DOI 10.1016/j.cviu.2011.09.010
   Derpanis KG, 2010, PROC CVPR IEEE, P1990, DOI 10.1109/CVPR.2010.5539874
   Efros AA, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P726
   Gilbert A, 2008, LECT NOTES COMPUT SC, V5302, P222, DOI 10.1007/978-3-540-88682-2_18
   Gilbert A, 2011, IEEE T PATTERN ANAL, V33, P883, DOI 10.1109/TPAMI.2010.144
   Gorelick L, 2007, IEEE T PATTERN ANAL, V29, P2247, DOI 10.1109/TPAMI.2007.70711
   Han D, 2009, IEEE I CONF COMP VIS, P1933, DOI 10.1109/ICCV.2009.5459427
   Heng Wang, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3169, DOI 10.1109/CVPR.2011.5995407
   Hore P, 2009, J SIGNAL PROCESS SYS, V54, P183, DOI 10.1007/s11265-008-0243-1
   Jiang ZL, 2012, IEEE T PATTERN ANAL, V34, P533, DOI 10.1109/TPAMI.2011.147
   Ke Y, 2010, INT J COMPUT VISION, V88, P339, DOI 10.1007/s11263-009-0308-z
   Khamis S, 2012, PROC CVPR IEEE, P1218, DOI 10.1109/CVPR.2012.6247804
   Kim K, 2005, REAL-TIME IMAGING, V11, P172, DOI 10.1016/j.rti.2004.12.004
   Kovashka A, 2010, PROC CVPR IEEE, P2046, DOI 10.1109/CVPR.2010.5539881
   Kratz L, 2009, PROC CVPR IEEE, P1446, DOI 10.1109/CVPRW.2009.5206771
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Liu Q, 2008, IEEE IC COMP COM NET, P1
   Marszalek M., 2006, PROC IEEE INT C COMP, V2, P2118
   Messing R, 2009, IEEE I CONF COMP VIS, P104, DOI 10.1109/ICCV.2009.5459154
   Mikolajczyk K, 2011, COMPUT VIS IMAGE UND, V115, P426, DOI 10.1016/j.cviu.2010.11.002
   Mittal A, 2009, COMPUT VIS IMAGE UND, V113, P63, DOI 10.1016/j.cviu.2008.07.004
   Ng AY, 2002, ADV NEUR IN, V14, P849
   Niebles JC, 2008, INT J COMPUT VISION, V79, P299, DOI 10.1007/s11263-007-0122-4
   Oikonomopoulos A, 2011, IEEE T IMAGE PROCESS, V20, P1126, DOI 10.1109/TIP.2010.2076821
   Poppe R, 2010, IMAGE VISION COMPUT, V28, P976, DOI 10.1016/j.imavis.2009.11.014
   Ramanan D, 2004, ADV NEUR IN, V16, P1547
   Rao C, 2002, INT J COMPUT VISION, V50, P203, DOI 10.1023/A:1020350100748
   Roshtkhari M. J., 2012, 2012 Canadian Conference on Computer and Robot Vision, P182, DOI 10.1109/CRV.2012.32
   Roshtkhari MJ, 2013, PROC CVPR IEEE, P2611, DOI 10.1109/CVPR.2013.337
   Roshtkhari MJ, 2013, COMPUT VIS IMAGE UND, V117, P1436, DOI 10.1016/j.cviu.2013.06.007
   Ryoo MS, 2009, IEEE I CONF COMP VIS, P1593, DOI 10.1109/ICCV.2009.5459361
   Sadanand S, 2012, PROC CVPR IEEE, P1234, DOI 10.1109/CVPR.2012.6247806
   Savarese S., 2008, WMVC, P1
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Scovanner P., 2007, P 15 ACM INT C MULT, P357, DOI DOI 10.1145/1291233.1291311
   Seo HJ, 2011, IEEE T PATTERN ANAL, V33, P867, DOI 10.1109/TPAMI.2010.156
   Shechtman E, 2007, IEEE T PATTERN ANAL, V29, P2045, DOI 10.1109/TPAMI.2007.1119
   Sun J, 2009, PROC CVPR IEEE, P2004, DOI 10.1109/CVPRW.2009.5206721
   Tian YL, 2012, IEEE T SYST MAN CY C, V42, P313, DOI 10.1109/TSMCC.2011.2149519
   Thi TH, 2012, COMPUT VIS IMAGE UND, V116, P378, DOI 10.1016/j.cviu.2011.09.007
   Turaga P, 2008, IEEE T CIRC SYST VID, V18, P1473, DOI 10.1109/TCSVT.2008.2005594
   von Luxburg U, 2007, STAT COMPUT, V17, P395, DOI 10.1007/s11222-007-9033-z
   Wang J, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995493
   Wang L, 2011, IEEE T IMAGE PROCESS, V20, P1725, DOI 10.1109/TIP.2010.2102043
   Weinland D, 2011, COMPUT VIS IMAGE UND, V115, P224, DOI 10.1016/j.cviu.2010.10.002
   Yang HX, 2011, NEUROCOMPUTING, V74, P3823, DOI 10.1016/j.neucom.2011.07.024
   Yao A, 2010, PROC CVPR IEEE, P2061, DOI 10.1109/CVPR.2010.5539883
   Yilmaz A, 2005, PROC CVPR IEEE, P984
   Yu G, 2011, PROC CVPR IEEE, P865, DOI 10.1109/CVPR.2011.5995488
   Yu T.-H., 2010, P BRIT MACHINE VISIO, P56
   Yuan F, 2012, PATTERN RECOGN, V45, P4182, DOI 10.1016/j.patcog.2012.05.001
   Yuan JS, 2011, IEEE T PATTERN ANAL, V33, P1728, DOI 10.1109/TPAMI.2011.38
   Yuan JS, 2009, PROC CVPR IEEE, P2442, DOI [10.1109/CVPRW.2009.5206671, 10.1109/CVPR.2009.5206671]
   Zhong H, 2004, PROC CVPR IEEE, P819
NR 61
TC 27
Z9 33
U1 0
U2 12
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2013
VL 31
IS 11
BP 864
EP 876
DI 10.1016/j.imavis.2013.08.005
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 268PX
UT WOS:000328184100004
DA 2024-07-18
ER

PT J
AU Vojodi, H
   Fakhari, A
   Moghadam, AME
AF Vojodi, Hakime
   Fakhari, Ali
   Moghadam, Amir Masoud Eftekhari
TI A new evaluation measure for color image segmentation based on genetic
   programming approach
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Evaluation measure; Genetic programming;
   Intra-region; Inter-region; Over-segmentation
ID VIDEO OBJECT SEGMENTATION; ALGORITHMS
AB One of the greatest challenges while working on image segmentation algorithms is a comprehensive measure to evaluate their accuracy. Although there are some measures for doing this task, but they can consider only one aspect of segmentation in evaluation process. The performance of evaluation measures can be improved using a combination of single measures. However, combination of single measures does not always lead to an appropriate criterion. Besides its effectiveness, the efficiency of the new measure should be considered. In this paper, a new and combined evaluation measure based on genetic programming (GP) has been sought. Because of the nature of evolutionary approaches, the proposed approach allows nonlinear and linear combinations of other single evaluation measures and can search within many and different combinations of basic operators to find a good enough one. We have also proposed a new fitness function to make GP enable to search within search space effectively and efficiently. To test the method, Berkeley and Weizmann datasets besides several different experiments have been used. Experimental results demonstrate that the GP based approach is suitable for effective combination of single evaluation measures. (C) 2013 Published by Elsevier B.V.
C1 [Vojodi, Hakime; Fakhari, Ali; Moghadam, Amir Masoud Eftekhari] Islamic Azad Univ, Dept IT & Comp Engn, Qazvin Branch, Qazvin, Iran.
C3 Islamic Azad University
RP Vojodi, H (corresponding author), Islamic Azad Univ, Dept IT & Comp Engn, Qazvin Branch, Qazvin, Iran.
EM h.vojodi@qiau.ac.ir; a.fakhari@qiau.ac.ir; eftekhari@qiau.ac.ir
RI Moghadam, Amir Masoud Eftekhari/ABA-5362-2021
OI Eftekhari Moghadam, Amir-Masoud/0000-0003-3413-0607
CR Brieva J, 2007, P ANN INT IEEE EMBS, P5555, DOI 10.1109/IEMBS.2007.4353605
   Chabrier S, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/96306
   Chen HC, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P593
   Correia PL, 2003, IEEE T IMAGE PROCESS, V12, P186, DOI 10.1109/TIP.2002.807355
   Cour T, 2005, PROC CVPR IEEE, P1124
   Cour Timothee, MULTISCALE NORMALIZE
   Eggermont J., 2005, THESIS LEIDEN U NETH, P133
   Eiben AE, 2004, LECT NOTES COMPUT SC, V3242, P41
   Erdem ÇE, 2004, IEEE T IMAGE PROCESS, V13, P937, DOI 10.1109/TIP.2004.828427
   Fenster A, 2005, P ANN INT IEEE EMBS, P7186, DOI 10.1109/IEMBS.2005.1616166
   Gelasca ED, 2009, IEEE J-STSP, V3, P319, DOI 10.1109/JSTSP.2009.2015067
   Han YF, 2007, NEUROCOMPUTING, V70, P665, DOI 10.1016/j.neucom.2006.10.022
   Holland I.H., 1975, ADAPTATION NATURAL A
   Jaber M., 2010, IEEE 39 APPL IM PATT, P1
   Jiang XY, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/35909
   Kishore JK, 2000, IEEE T EVOLUT COMPUT, V4, P242, DOI 10.1109/4235.873235
   Koza J.R., 1992, GENETIC PROGRAMMING, VVolume 1
   Langdon W.B., 1998, DATA STRUCTURES GENE
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   McGuinness K, 2010, PATTERN RECOGN, V43, P434, DOI 10.1016/j.patcog.2009.03.008
   Nasab NM, 2003, J ELECTRON IMAGING, V12, P50, DOI 10.1117/1.1525280
   PAL NR, 1993, SIGNAL PROCESS, V33, P139, DOI 10.1016/0165-1684(93)90107-L
   Polak M, 2009, IMAGE VISION COMPUT, V27, P1223, DOI 10.1016/j.imavis.2008.09.008
   Poli R., 2008, A Field Guide to Genetic Programming
   ROSENBERGER C, 1999, THESIS U RENNES 1 RE
   Senthilkumaran N., 2009, Proceedings of the 2009 International Conference on Advances in Recent Technologies in Communication and Computing. ARTCom 2009, P844, DOI 10.1109/ARTCom.2009.219
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Sivaraj R., 2011, Int. J. Eng. Sci. Technol, V3, P3792
   Smart W., 2003, PROC IVCNZ, P402
   Tao WB, 2007, IEEE T SYST MAN CY B, V37, P1382, DOI 10.1109/TSMCB.2007.902249
   Unnikrishnan R, 2007, IEEE T PATTERN ANAL, V29, P929, DOI 10.1109/TPAMI.2007.1046
   ZEBOUDJ R, 1988, THESIS U SAINT ETIEN
   Zhang H, 2005, PROC SPIE, V5809, P420, DOI 10.1117/12.604213
   Zhang H., 2004, P SPIE STORAGE RETRI
   Zhang H., 2006, Proc. IEEE Conf. on Comp. Vis. and Pat. Rec. (CVPR), P1138
   Zhang H, 2008, COMPUT VIS IMAGE UND, V110, P260, DOI 10.1016/j.cviu.2007.08.003
NR 36
TC 18
Z9 18
U1 0
U2 11
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2013
VL 31
IS 11
BP 877
EP 886
DI 10.1016/j.imavis.2013.08.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 268PX
UT WOS:000328184100005
DA 2024-07-18
ER

PT J
AU Lee, KJ
   Yun, ID
   Lee, SU
AF Lee, Kyong Joon
   Yun, Il Dong
   Lee, Sang Uk
TI Adaptive large window correlation for optical flow estimation with
   discrete optimization
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Window correlation; Optical flow; Data cost; Discrete optimization
ID ENERGY MINIMIZATION; ALGORITHM; STEREO
AB We propose a scheme for comparing local neighborhoods (window) of image points, to estimate optical flow using discrete optimization. The proposed approach is based on using large correlation windows with adaptive support-weights. We present three new types of weighting constraints derived from image gradient, color statistics and occlusion information. The first type provides gradient structure constraints that favor flow consistency across strong image gradients. The second type imposes perceptual color constraints that reinforce relationship among pixels in a window according to their color statistics. The third type yields occlusion constraints that reject pixels that are seen in one window but not seen in the other. All these constraints contribute to suppress the effect of cluttered background, which is unavoidably included in the large correlation windows. Experimental results demonstrate that each of the proposed constraints appreciably elevates the quality of estimations, and that they jointly yield results that compare favorably to current techniques, especially on object boundaries. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Lee, Kyong Joon; Lee, Sang Uk] Seoul Natl Univ, Sch EECS, ASRI, INMC, Seoul 151742, South Korea.
   [Yun, Il Dong] Hankuk Univ FS, Sch EIE, Yongin 449791, South Korea.
C3 Seoul National University (SNU); Hankuk University Foreign Studies
RP Yun, ID (corresponding author), Hankuk Univ FS, Sch EIE, Yongin 449791, South Korea.
EM kjoon@spl.snu.ac.kr; yun@hufs.ac.kr; sanguk@spl.snu.ac.kr
RI Lee, Kyoung Ho/J-5570-2012
OI Lee, Kyong Joon/0000-0002-0658-433X
FU Basic Science Research Program through the National Research Foundation
   of Korea (NRF); Ministry of Education, Science and Technology
   [2010-0012006, 2013R1A1A2A10004550]
FX This research was supported by the Basic Science Research Program
   through the National Research Foundation of Korea (NRF) funded by the
   Ministry of Education, Science and Technology (2010-0012006,
   2013R1A1A2A10004550).
CR Black MJ, 1996, COMPUT VIS IMAGE UND, V63, P75, DOI 10.1006/cviu.1996.0006
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Brox T, 2004, LECT NOTES COMPUT SC, V2034, P25, DOI 10.1007/978-3-540-24673-2_3
   Bruhn A, 2005, INT J COMPUT VISION, V61, P211, DOI 10.1023/B:VISI.0000045324.43199.43
   Cooke Tristrom, 2008, 2008 Digital Image Computing: Techniques and Applications, P498, DOI 10.1109/DICTA.2008.32
   Felzenszwalb PF, 2006, INT J COMPUT VISION, V70, P41, DOI 10.1007/s11263-006-7899-4
   Fusiello A, 1997, PROC CVPR IEEE, P858, DOI 10.1109/CVPR.1997.609428
   Glocker B., 2008, IEEE COMPUTER VISION, P1, DOI [DOI 10.1109/CVPR.2008.4587562, 10.1109/CVPR.2008.4587562]
   Heo YS, 2011, IEEE T PATTERN ANAL, V33, P807, DOI 10.1109/TPAMI.2010.136
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   KANADE T, 1994, IEEE T PATTERN ANAL, V16, P920, DOI 10.1109/34.310690
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Komodakis N., 2007, CVPR, P1
   Lee KJ, 2010, PROC CVPR IEEE, P2504, DOI 10.1109/CVPR.2010.5539953
   Lei C, 2009, IEEE I CONF COMP VIS, P1562, DOI 10.1109/ICCV.2009.5459253
   Lempitsky V, 2010, IEEE T PATTERN ANAL, V32, P1392, DOI 10.1109/TPAMI.2009.143
   Liang CK, 2011, IEEE T CIRC SYST VID, V21, P525, DOI 10.1109/TCSVT.2011.2125570
   Liu C, 2011, PROC CVPR IEEE, P209, DOI 10.1109/CVPR.2011.5995614
   Liu C, 2010, LECT NOTES COMPUT SC, V6313, P706
   Lucas B.D., DARPA IMAGE UNDERSTA
   Newcombe RA, 2010, PROC CVPR IEEE, P1498, DOI 10.1109/CVPR.2010.5539794
   Rhemann C, 2011, PROC CVPR IEEE, DOI 10.1109/CVPR.2011.5995372
   Shekhovtsov A, 2008, COMPUT VIS IMAGE UND, V112, P91, DOI 10.1016/j.cviu.2008.06.006
   Sun DQ, 2010, PROC CVPR IEEE, P2432, DOI 10.1109/CVPR.2010.5539939
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Wedel A, 2009, LECT NOTES COMPUT SC, V5604, P23, DOI 10.1007/978-3-642-03061-1_2
   Weickert J, 2001, INT J COMPUT VISION, V45, P245, DOI 10.1023/A:1013614317973
   WERLBERGER M., 2009, BMVC, V1, P3
   Xiao JJ, 2006, LECT NOTES COMPUT SC, V3951, P211
   Xu L, 2012, IEEE T PATTERN ANAL, V34, P1744, DOI 10.1109/TPAMI.2011.236
   Yoon KJ, 2006, IEEE T PATTERN ANAL, V28, P650, DOI 10.1109/TPAMI.2006.70
NR 31
TC 2
Z9 2
U1 0
U2 10
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP
PY 2013
VL 31
IS 9
BP 631
EP 639
DI 10.1016/j.imavis.2013.06.009
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 220EG
UT WOS:000324564300004
DA 2024-07-18
ER

PT J
AU Baik, YK
   Kwon, J
   Lee, HS
   Lee, KM
AF Baik, Young Ki
   Kwon, Junghyun
   Lee, Hee Seok
   Lee, Kyoung Mu
TI Geometric particle swarm optimization for robust visual ego-motion
   estimation via particle filtering
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual ego-motion estimation; Visual odometry; Visual SLAM; Particle
   filtering; Particle swarm optimization; Special Euclidean group
ID EUCLIDEAN GROUP; FRAMEWORK; TRACKING
AB Conventional particle filtering-based visual ego-motion estimation or visual odometry often suffers from large local linearization errors in the case of abrupt camera motion. The main contribution of this paper is to present a novel particle filtering-based visual ego-motion estimation algorithm that is especially robust to the abrupt camera motion. The robustness to the abrupt camera motion is achieved by multi-layered importance sampling via particle swarm optimization (PSO), which iteratively moves particles to higher likelihood region without local linearization of the measurement equation. Furthermore, we make the proposed visual ego-motion estimation algorithm in real-time by reformulating the conventional vector space PSO algorithm in consideration of the geometry of the special Euclidean group SE(3), which is a Lie group representing the space of 3-D camera poses. The performance of our proposed algorithm is experimentally evaluated and compared with the local linearization and unscented particle filter-based visual ego-motion estimation algorithms on both simulated and real data sets. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Baik, Young Ki; Kwon, Junghyun; Lee, Hee Seok; Lee, Kyoung Mu] Seoul Natl Univ, ASRI, Dept Elect & Comp Engn, Seoul 151600, South Korea.
C3 Seoul National University (SNU)
RP Lee, KM (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, Gwanak POB 34, Seoul 151600, South Korea.
EM hyunxx@gmail.com; junghyunkwon@gmail.com; ultra21@snu.ac.kr;
   kyoungmu@snu.ac.kr
RI Lee, Kyoung Mu/AAC-4063-2020
OI Lee, Kyoung Mu/0000-0001-7210-1036
CR [Anonymous], 2001, Sequential Monte Carlo methods in practice
   [Anonymous], 2007, Computer Vision and Pattern Recognition
   Blackwell T, 2006, IEEE T EVOLUT COMPUT, V10, P459, DOI 10.1109/TEVC.2005.857074
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276
   Davison AJ, 2002, IEEE T PATTERN ANAL, V24, P865, DOI 10.1109/TPAMI.2002.1017615
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Eade E., 2006, P 2006 IEEE COMPUTER, VVolume 1, P469, DOI DOI 10.1109/CVPR.2006.263
   Gwak S, 2003, IEEE T ROBOTIC AUTOM, V19, P65, DOI 10.1109/TRA.2002.807530
   Julier S, 2000, IEEE T AUTOMAT CONTR, V45, P477, DOI 10.1109/9.847726
   Julier SJ, 2004, P IEEE, V92, P401, DOI 10.1109/JPROC.2003.823141
   Julier SJ, 2002, P AMER CONTR CONF, V1-6, P4555, DOI 10.1109/ACC.2002.1025369
   Klein G, 2008, LECT NOTES COMPUT SC, V5303, P802, DOI 10.1007/978-3-540-88688-4_59
   Klein George, 2007, P1
   Kwon J., 2010, PROCEEDINGS OF IEEE
   Kwon J, 2007, ROBOTICA, V25, P725, DOI 10.1017/S0263574707003529
   Lee HS, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P924, DOI 10.1109/IROS.2009.5354144
   Lee HC, 2009, IEEE SYS MAN CYBERN, P2763, DOI 10.1109/ICSMC.2009.5346572
   Maimone M, 2007, J FIELD ROBOT, V24, P169, DOI 10.1002/rob.20184
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7
   Montemerlo M., 2003, P INT JOINT C ARTIFI, P1151, DOI [10.5555/1630659.1630824, DOI 10.5555/1630659.1630824]
   Montemerlo M., 2003, THESIS
   Newman P. R., 1999, THESIS
   Nistér D, 2004, PROC CVPR IEEE, P652
   Olson CF, 2003, ROBOT AUTON SYST, V43, P215, DOI 10.1016/S0921-8890(03)00004-6
   Pérez P, 2004, P IEEE, V92, P495, DOI 10.1109/JPROC.2003.823147
   Poli Riccardo, 2007, Swarm Intelligence, V1, P33, DOI 10.1007/s11721-007-0002-0
   Pupilli M., 2005, BMVC, P519
   Rosten E, 2010, IEEE T PATTERN ANAL, V32, P105, DOI 10.1109/TPAMI.2008.275
   SIM R, 2005, IJCAI WORKSHOP ON RE
   Smith M, 2009, INT J ROBOT RES, V28, P595, DOI 10.1177/0278364909103911
   Subbarao R, 2009, INT J COMPUT VISION, V84, P1, DOI 10.1007/s11263-008-0195-8
   Sulistijono IA, 2007, J ADV COMPUT INTELL, V11, P681, DOI 10.20965/jaciii.2007.p0681
   van der Merwe R., 2000, PROCEEDINGS ON NEURA
   Zhang XQ, 2008, PROC CVPR IEEE, P1317, DOI 10.1109/CVPR.2008.4587512
NR 35
TC 7
Z9 8
U1 0
U2 14
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2013
VL 31
IS 8
BP 565
EP 579
DI 10.1016/j.imavis.2013.04.004
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 185TO
UT WOS:000321993400004
DA 2024-07-18
ER

PT J
AU Romero, J
   Kjellström, H
   Ek, CH
   Kragic, D
AF Romero, Javier
   Kjellstrom, Hedvig
   Ek, Carl Henrik
   Kragic, Danica
TI Non-parametric hand pose estimation with object context
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Articulated hand pose; Approximate nearest neighbor; Context
ID 3D HUMAN POSE
AB In the spirit of recent work on contextual recognition and estimation, we present a method for estimating the pose of human hands, employing information about the shape of the object in the hand. Despite the fact that most applications of human hand tracking involve grasping and manipulation of objects, the majority of methods in the literature assume a free hand, isolated from the surrounding environment. Occlusion of the hand from grasped objects does in fact often pose a severe challenge to the estimation of hand pose. In the presented method, object occlusion is not only compensated for, it contributes to the pose estimation in a contextual fashion; this without an explicit model of object shape. Our hand tracking method is non-parametric, performing a nearest neighbor search in a large database (.. entries) of hand poses with and without grasped objects. The system that operates in real time, is robust to self occlusions, object occlusions and segmentation errors, and provides full hand pose reconstruction from monocular video. Temporal consistency in hand pose is taken into account, without explicitly tracking the hand in the high-dim pose space. Experiments show the non-parametric method to outperform other state of the art regression methods, while operating at a significantly lower computational cost than comparable model-based hand tracking methods. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Romero, Javier] Max Planck Inst Intelligent Syst, Perceiving Syst Dept, D-72076 Tubingen, Germany.
   [Kjellstrom, Hedvig; Ek, Carl Henrik; Kragic, Danica] KTH, CVAP CAS, SE-10044 Stockholm, Sweden.
C3 Max Planck Society; Royal Institute of Technology
RP Romero, J (corresponding author), Max Planck Inst Intelligent Syst, Perceiving Syst Dept, D-72076 Tubingen, Germany.
EM javier.romero@tuebingen.mpg.de; hedvig@kth.se; chek@csc.kth.se;
   dani@kth.se
RI Kjellström, Hedvig/AEF-4955-2022
OI Kjellström, Hedvig/0000-0002-5750-9655; Ek, Carl
   Henrik/0000-0003-1302-6309
FU EU project TOMSY [ICT-FP7-270436]; Swedish Foundation for Strategic
   Research
FX This work was supported by the EU project TOMSY (ICT-FP7-270436) and by
   the Swedish Foundation for Strategic Research. An early version of the
   paper can be found in [1].
CR Agarwal A, 2006, IEEE T PATTERN ANAL, V28, P44, DOI 10.1109/TPAMI.2006.21
   Agarwal A, 2004, PROC CVPR IEEE, P882
   [Anonymous], IEEE INT C ROB AUT
   [Anonymous], 2003, IEEE INT C COMP VIS
   [Anonymous], IEEE RAS INT C HUM R
   [Anonymous], RSS WORKSH UND HUM H
   [Anonymous], IEEE C COMP VIS PATT
   [Anonymous], 2009, FLANN-Fast Library for Approximate Nearest Neighbors User Manual
   [Anonymous], 2006, IEEE C COMP VIS PATT
   [Anonymous], 2011, IEEE C COMP VIS PATT
   Argyros A. A., 2004, EUR C COMP VIS
   Athitsos V., 2003, IEEE C COMP VIS PATT
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   Dalal N., 2005, IEEE C COMP VIS PATT
   de Campos T.E., 2006, IEEE C COMP VIS PATT
   Dong W., 2008, ACM MULTIMEDIA
   Ek C.H., 2007, JOINT WORKSH MULT IN
   Ekvall S, 2004, IEEE INT CONF ROBOT, P3519, DOI 10.1109/ROBOT.2004.1308798
   EKVALL S, 2005, IEEE INT C ROB AUT
   Erol A, 2007, COMPUT VIS IMAGE UND, V108, P52, DOI 10.1016/j.cviu.2006.10.012
   Gupta A, 2009, IEEE T PATTERN ANAL, V31, P1775, DOI 10.1109/TPAMI.2009.83
   Hamer H, 2009, IEEE I CONF COMP VIS, P1475, DOI 10.1109/ICCV.2009.5459282
   Kanaujia A., 2007, IEEE C COMP VIS PATT
   Kjellstrom H., COMP VISION IMAGE UN, P115
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Moeslund TB, 2006, COMPUT VIS IMAGE UND, V104, P90, DOI 10.1016/j.cviu.2006.08.002
   Morariu V., 2008, NEURAL INFORM PROCES
   Mori G, 2005, IEEE T PATTERN ANAL, V27, P1832, DOI 10.1109/TPAMI.2005.220
   Oikonomidis I, 2011, IEEE I CONF COMP VIS, P2088, DOI 10.1109/ICCV.2011.6126483
   Rasmussen C.E., 2003, ADV LECT MACHINE LEA
   Stenger B, 2006, IEEE T PATTERN ANAL, V28, P1372, DOI 10.1109/TPAMI.2006.189
   Thayananthan A, 2008, PATTERN RECOGN LETT, V29, P1302, DOI 10.1016/j.patrec.2008.02.004
   Tipping ME, 2001, J MACH LEARN RES, V1, P211, DOI 10.1162/15324430152748236
   Wang JM, 2008, IEEE T PATTERN ANAL, V30, P283, DOI 10.1109/TPAMI.2007.1167
   Wang R. Y., 2011, ACM S US INT SOFTW T
   Wang RY, 2009, ACM T GRAPHIC, V28, DOI 10.1145/1531326.1531369
   Zhao X., 2008, IAPR INT C IM PROC
NR 37
TC 27
Z9 32
U1 0
U2 21
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG
PY 2013
VL 31
IS 8
BP 555
EP 564
DI 10.1016/j.imavis.2013.04.002
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 185TO
UT WOS:000321993400003
DA 2024-07-18
ER

PT J
AU Fasciano, T
   Souvenir, R
   Shin, MC
AF Fasciano, Thomas
   Souvenir, Richard
   Shin, Min C.
TI Learning to rank biological motion trajectories
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Biomedical imaging; Motion analysis; Cell motion; Rank-based learning
ID RETRIEVAL; IMAGES
AB Many feature transforms have been proposed for the problem of trajectory matching. These methods, which are often based on shape matching, tend to perform poorly for biological trajectories, such as cell motion, because similar biological behavior often results in dissimilar trajectory shape. Additionally, the criteria used for similarity may differ depending on the user's particular interest or the specific query behavior. We present a rank-based distance metric learning method that combines user input and a new set of biologically-motivated features for biological trajectory matching. We show that, with a small amount of user effort, this method outperforms existing trajectory methods. On an information retrieval task using real world data, our method outperforms recent, related methods by similar to 9%. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Fasciano, Thomas; Souvenir, Richard; Shin, Min C.] Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
C3 University of North Carolina; University of North Carolina Charlotte
RP Fasciano, T (corresponding author), Univ N Carolina, Dept Comp Sci, Charlotte, NC 28223 USA.
EM twfascia@uncc.edu; souvenir@uncc.edu; mcshin@uncc.edu
CR ANDERSON JA, 1984, J R STAT SOC B, V46, P1
   Anjum N, 2008, IEEE T CIRC SYST VID, V18, P1555, DOI 10.1109/TCSVT.2008.2005603
   [Anonymous], 2007, P 30 ANN INT ACM SIG, DOI [DOI 10.1145/1277741.1277809, 10.1145/1277741.1277809]
   Baeza-Yates R., 1999, Modern information retrieval, V82
   Bashir FI, 2007, IEEE T MULTIMEDIA, V9, P58, DOI 10.1109/TMM.2006.886346
   Burges Chris, 2005, P 22 INT C MACH LEAR, P89, DOI DOI 10.1145/1102351.1102363
   Cantarella C, 2009, BMC BIOINFORMATICS, V10, DOI 10.1186/1471-2105-10-S12-S12
   Cao Z., 2007, P 24 INT C MACHINE L, P129, DOI DOI 10.1145/1273496.1273513
   Carpenter AE, 2006, GENOME BIOL, V7, DOI 10.1186/gb-2006-7-10-r100
   Cohen WW, 1999, J ARTIF INTELL RES, V10, P243, DOI 10.1613/jair.587
   Crammer K, 2002, ADV NEUR IN, V14, P641
   Debeir O, 2004, CYTOM PART A, V60A, P29, DOI 10.1002/cyto.a.20040
   Geissmann F, 2005, PLOS BIOL, V3, P650, DOI 10.1371/journal.pbio.0030113
   Hsieh JW, 2006, IEEE T CIRC SYST VID, V16, P396, DOI 10.1109/TCSVT.2006.869965
   Huang W, 2011, IEEE T MED IMAGING, V30, P94, DOI 10.1109/TMI.2010.2062197
   Järvelin K, 2002, ACM T INFORM SYST, V20, P422, DOI 10.1145/582415.582418
   Jiang F, 2009, IEEE T IMAGE PROCESS, V18, P907, DOI 10.1109/TIP.2008.2012070
   Joachims T, 2002, P 8 ACM SIGKDD INT C, P133, DOI [DOI 10.1145/775047.775067, 10.1145/775047.775067]
   Li X, 2006, INT C PATT RECOG, P591
   Morris B, 2009, PROC CVPR IEEE, P312, DOI 10.1109/CVPRW.2009.5206559
   Nguyen N., 2010, WORKSH APPL COMP VIS
   Sakai T, 2008, INFORM RETRIEVAL, V11, P447, DOI 10.1007/s10791-008-9059-7
   Vlachos M., 2004, KDD 04, P707, DOI DOI 10.1145/1014052.1014144
   Wang M, 2010, IEEE T MULTIMEDIA, V12, P829, DOI 10.1109/TMM.2010.2055045
   Wang M, 2009, IEEE T MULTIMEDIA, V11, P465, DOI 10.1109/TMM.2009.2012919
NR 25
TC 0
Z9 0
U1 0
U2 4
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2013
VL 31
IS 6-7
BP 502
EP 510
DI 10.1016/j.imavis.2012.07.010
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 172UH
UT WOS:000321029900008
DA 2024-07-18
ER

PT J
AU Ohnishi, N
   Imiya, A
AF Ohnishi, Naoya
   Imiya, Atsushi
TI Appearance-based navigation and homing for autonomous mobile robot
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual navigation; Visual homing; Nonholonomic mobile robot; Visual
   potential; Optical flow; Dominant plane
ID OPTICAL-FLOW; VISION
AB In this paper, we develop an algorithm for navigating a mobile robot using the visual potential. The visual potential is computed from an image sequence and optical flow computed from successive images captured by a camera mounted on the robot, that is, the visual potential for navigation is computed from appearances of the workspace observed as an image sequence. The direction to the destination is provided at the initial position of the robot. The robot dynamically selects a local pathway to the destination without collision with obstacles and without any knowledge of the robot workspace. Furthermore, the guidance algorithm to destination allows the mobile robot to return from the destination to the initial position. We present the experimental results of navigation and homing in synthetic and real environments. (C) 2013 Elsevier B.V. All rights reserved.
C1 [Ohnishi, Naoya] Chiba Univ, Grad Sch Sci & Technol, Chiba, Japan.
   [Imiya, Atsushi] Chiba Univ, Inst Media & Informat Technol, Chiba, Japan.
C3 Chiba University; Chiba University
RP Imiya, A (corresponding author), Yaoi Cho 1-33,Inage Ku, Chiba 2638522, Japan.
EM imiya@faculuty.chiba-u.jp
CR Aarno D, 2004, IEEE INT CONF ROBOT, P461, DOI 10.1109/ROBOT.2004.1307192
   [Anonymous], AUSTR C ROB AUT
   [Anonymous], 1999, INTEL CORPORATION MI
   BARRON JL, 1994, INT J COMPUT VISION, V12, P43, DOI 10.1007/BF01420984
   Braillon C, 2006, 2006 IEEE INTELLIGENT VEHICLES SYMPOSIUM, P468
   Buenaposada J.M., 2004, P CVPRW 04 CONJ INT
   Bur A, 2006, INT C PATT RECOG, P695
   Capparella F, 2005, 2005 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P2021
   Conner DC, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3546
   Coombs D., 1993, P CVPR, P400
   Das AK, 2001, IEEE INT CONF ROBOT, P1714, DOI 10.1109/ROBOT.2001.932858
   DeSouza GN, 2002, IEEE T PATTERN ANAL, V24, P237, DOI 10.1109/34.982903
   FISCHLER MA, 1981, COMMUN ACM, V24, P381, DOI 10.1145/358669.358692
   Franz MO, 2000, ROBOT AUTON SYST, V30, P133, DOI 10.1016/S0921-8890(99)00069-X
   Green WE, 2004, IEEE INT CONF ROBOT, P2347, DOI 10.1109/ROBOT.2004.1307412
   Hartley R, 2000, MULTIPLE VIEW GEOMET
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Imiya A, 1999, COMPUT VIS IMAGE UND, V73, P309, DOI 10.1006/cviu.1998.0734
   Jones S. D., 1997, Proceedings of the 1997 IEEE/RSJ International Conference on Intelligent Robot and Systems. Innovative Robotics for Real-World Applications. IROS '97 (Cat. No.97CH36108), P551, DOI 10.1109/IROS.1997.655066
   KHATIB O, 1986, INT J ROBOT RES, V5, P90, DOI 10.1177/027836498600500106
   Kim YG, 2004, IEEE INT CONF ROBOT, P13
   Liang BJ, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P205, DOI 10.1109/ROBOT.2002.1013362
   López-de-Teruel PE, 2006, INT C PATT RECOG, P143
   López-Franco C, 2006, INT C PATT RECOG, P570
   Lucas Bruce D., ITERATIVE IMAGE REGI, P674, DOI DOI 10.1109/HPDC.2004.1323531
   Ma Y, 1999, IEEE T ROBOTIC AUTOM, V15, P521, DOI 10.1109/70.768184
   MALLOT HA, 1991, BIOL CYBERN, V64, P177, DOI 10.1007/BF00201978
   Mnif F., 2005, International Journal of Advanced Robotic Systems, V2, P59
   MURASE H, 1995, INT J COMPUT VISION, V14, P5, DOI 10.1007/BF01421486
   NAGEL HH, 1986, IEEE T PATTERN ANAL, V8, P565, DOI 10.1109/TPAMI.1986.4767833
   Naoya O, 2010, VISAPP 2010: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P435
   Ohnishi N, 2005, CONNECT SCI, V17, P23, DOI 10.1080/09540090500140990
   OHNISHI N, 2007, INT C COMP VIS SYST
   Ohnishi N, 2007, FOURTH CANADIAN CONFERENCE ON COMPUTER AND ROBOT VISION, PROCEEDINGS, P131, DOI 10.1109/CRV.2007.21
   Ohnishi N, 2006, PATTERN RECOGN LETT, V27, P1009, DOI 10.1016/j.patrec.2005.11.012
   Shimoda S, 2005, IEEE INT CONF ROBOT, P2828
   SOBEY PJ, 1994, BIOL CYBERN, V71, P433, DOI 10.1007/BF00198919
   Stemmer A, 2007, IEEE INT CONF ROBOT, P317, DOI 10.1109/ROBOT.2007.363806
   Suraj MG, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P605
   Tews AD, 2004, IEEE INT CONF ROBOT, P2379, DOI 10.1109/ROBOT.2004.1307417
   Ulrich I., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P1023, DOI 10.1109/ROBOT.2000.844734
   Valavanis KP, 2000, IEEE T SYST MAN CY A, V30, P187, DOI 10.1109/3468.833100
   Vardy A, 2005, CONNECT SCI, V17, P47, DOI 10.1080/09540090500140958
   Wada N, 2004, JSME INT J C-MECH SY, V47, P694, DOI 10.1299/jsmec.47.694
NR 44
TC 31
Z9 36
U1 0
U2 13
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN-JUL
PY 2013
VL 31
IS 6-7
BP 511
EP 532
DI 10.1016/j.imavis.2012.11.004
PG 22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 172UH
UT WOS:000321029900009
DA 2024-07-18
ER

PT J
AU González, A
   Bergasa, LM
AF Gonzalez, Alvaro
   Miguel Bergasa, Luis
TI A text reading algorithm for natural images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Text detection; Text recognition; Character recognition; Character
   segmentation; Natural images; Scene text detection
ID CLASSIFICATION; SEGMENTATION
AB Reading text in natural images has focused again the attention of many researchers during the last few years due to the increasing availability of cheap image-capturing devices in low-cost products like mobile phones. Therefore, as text can be found on any environment, the applicability of text-reading systems is really extensive. For this purpose, we present in this paper a robust method to read text in natural images. It is composed of two main separated stages. Firstly, text is located in the image using a set of simple and fast-to-compute features highly discriminative between character and non-character objects. They are based on geometric and gradient properties. The second part of the system carries out the recognition of the previously detected text. It uses gradient features to recognize single characters and Dynamic Programming (DP) to correct misspelled words. Experimental results obtained with different challenging datasets show that the proposed system exceeds state-of-the-art performance, both in terms of localization and recognition. (c) 2013 Elsevier B.V. All rights reserved.
C1 [Gonzalez, Alvaro; Miguel Bergasa, Luis] Univ Alcala de Henares, Dept Elect, Alcala De Henares 28871, Madrid, Spain.
C3 Universidad de Alcala
RP González, A (corresponding author), Univ Alcala de Henares, Dept Elect, Univ Campus, Alcala De Henares 28871, Madrid, Spain.
EM alvaro.g.arroyo@depeca.uah.es; bergasa@depeca.uah.es
RI Bergasa, Luis M./H-9810-2013
OI Bergasa, Luis M./0000-0002-0087-3077
FU Ministerio de Economia y Competitividad through the project ADD-Gaze
   [TRA2011-29001-C04-01]; Comunidad de Madrid through the project
   Robocity2030 [CAM-S-0505/DPI000176]
FX This work has been financed with funds from the Ministerio de Economia y
   Competitividad through the project ADD-Gaze (TRA2011-29001-C04-01), as
   well as from the Comunidad de Madrid through the project Robocity2030
   (CAM-S-0505/DPI000176).
CR Alcantarilla P.F., 2011, THESIS U ALCALA ALCA
   [Anonymous], C COMP VIS PATT REC
   [Anonymous], 2008, An Open and Portable Library of Computer Vision Algorithms
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   Berg AC, 2005, PROC CVPR IEEE, P26
   Chen H., 2011, ICIP
   Chen XR, 2004, PROC CVPR IEEE, P366
   Coates A, 2011, PROC INT CONF DOC, P440, DOI 10.1109/ICDAR.2011.95
   Dalal N., 2005, PROC IEEE COMPUT SOC, V1, P886
   de Campos TE, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 2, P273
   Epshtein B, 2010, PROC CVPR IEEE, P2963, DOI 10.1109/CVPR.2010.5540041
   Escalera S, 2009, FRONT ARTIF INTEL AP, V202, P35, DOI 10.3233/978-1-60750-061-2-35
   Hanif Shehzad Muhammad, 2009, 2009 10th International Conference on Document Analysis and Recognition (ICDAR), P1, DOI 10.1109/ICDAR.2009.172
   Karatzas D, 2007, IMAGE VISION COMPUT, V25, P564, DOI 10.1016/j.imavis.2006.05.003
   Karatzas D, 2011, PROC INT CONF DOC, P1485, DOI 10.1109/ICDAR.2011.295
   Lafferty John, 2001, INT C MACH LEARN ICM
   Lazebnik S, 2005, IEEE T PATTERN ANAL, V27, P1265, DOI 10.1109/TPAMI.2005.151
   Lee S., 2010, ICPR
   Lowe, 1999, P INT C COMP VIS, P1150, DOI DOI 10.1109/ICCV.1999.790410
   Lucas S. M., 2005, International Journal on Document Analysis and Recognition, V7, P105, DOI 10.1007/s10032-004-0134-3
   Lucas SM, 2005, PROC INT CONF DOC, P80, DOI 10.1109/ICDAR.2005.231
   Lucas SM, 2003, PROC INT CONF DOC, P682
   Matas J., 2002, Robust Wide Baseline Stereo from Maximally Stable Extremal Regions
   Neumann L, 2011, LECT NOTES COMPUT SC, V6494, P770, DOI 10.1007/978-3-642-19318-7_60
   Newell A. J., 2011, Proceedings of the 2011 International Conference on Digital Image Computing: Techniques and Applications (DICTA 2011), P191, DOI 10.1109/DICTA.2011.39
   Niblack W., 1986, An Introduction to Digital Image Processing
   Ojala T, 2002, IEEE T PATTERN ANAL, V24, P971, DOI 10.1109/TPAMI.2002.1017623
   Pan YF, 2011, IEEE T IMAGE PROCESS, V20, P800, DOI 10.1109/TIP.2010.2070803
   Shahab A, 2011, PROC INT CONF DOC, P1491, DOI 10.1109/ICDAR.2011.296
   Sochman J, 2005, PROC CVPR IEEE, P150
   Varma M, 2002, LECT NOTES COMPUT SC, V2352, P255
   VARMA M, 2003, PROC CVPR IEEE, P691, DOI DOI 10.1109/CVPR.2003.1211534
   Wai-Lin Chan, 2011, 2011 Seventh International Conference on Intelligent Information Hiding and Multimedia Signal Processing, P310, DOI 10.1109/IIHMSP.2011.55
   Wolf C, 2006, INT J DOC ANAL RECOG, V8, P280, DOI 10.1007/s10032-006-0014-0
   Yao JL, 2007, INT C WAVEL ANAL PAT, P1418
   Yuanping Zhu, 2012, Camera-Based Document Analysis and Recognition. 4th International Workshop, CBDAR 2011. Revised Selected Papers, P69, DOI 10.1007/978-3-642-29364-1_6
   Zhang J., 2010, ICPR
NR 38
TC 41
Z9 45
U1 2
U2 25
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2013
VL 31
IS 3
BP 255
EP 274
DI 10.1016/j.imavis.2013.01.003
PG 20
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 122NK
UT WOS:000317324600004
DA 2024-07-18
ER

PT J
AU Noceti, N
   Odone, F
AF Noceti, Nicoletta
   Odone, Francesca
TI Learning common behaviors from large sets of unlabeled temporal series
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Behavior analysis; Temporal series clustering; Anomaly detection;
   Unsupervised learning
AB This paper is about extracting knowledge from large sets of videos, with a particular reference to the video-surveillance application domain. We consider an unsupervised framework and address the specific problem of modeling common behaviors from long-term collection of instantaneous observations. Specifically, such data describe dynamic events and may be represented as time series in an appropriate space of features. Starting off from a set of data meaningful of the common events in a given scenario, the pipeline we propose includes a data abstraction level, that allows us to process different data in a homogeneous way, and a behavior modeling level, based on spectral clustering. At the end of the pipeline we obtain a model of the behaviors which are more frequent in the observed scene, represented by a prototypical behavior, which we call a cluster candidate. We report a detailed experimental evaluation referring to both benchmark datasets and on a complex set of data collected in-house. The experiments show that our method compares very favorably with other approaches from the recent literature. In particular the results we obtain prove that our method is able to capture meaningful information and discard noisy one from very heterogeneous datasets with different levels of prior information available. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Noceti, Nicoletta; Odone, Francesca] Univ Genoa, DIBRIS, Via Dodecaneso 35, I-16146 Genoa, Italy.
C3 University of Genoa
RP Noceti, N (corresponding author), Univ Genoa, DIBRIS, Via Dodecaneso 35, I-16146 Genoa, Italy.
EM Nicoletta.Noceti@unige.it; Francesca.Odone@unige.it
CR Anjum N., 2008, IEEE T CIRCUITS SYST, V18
   [Anonymous], 2004, Kernel Methods for Pattern Analysis
   [Anonymous], 2011, CVPR
   [Anonymous], 2010, ECCV
   [Anonymous], 7 IEEE WORKSH APPL C
   [Anonymous], 2005, P 3 ACM INT WORKSH V
   Atev S, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P4851, DOI 10.1109/IROS.2006.282362
   Bashir F, 2005, IEEE IMAGE PROC, P3401
   Bashir FI, 2007, IEEE T IMAGE PROCESS, V16, P1912, DOI 10.1109/TIP.2007.898960
   Bolei Zhou, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3441, DOI 10.1109/CVPR.2011.5995459
   Brox T, 2010, LECT NOTES COMPUT SC, V6315, P282, DOI 10.1007/978-3-642-15555-0_21
   Bulpitt A. J., 1998, BMVC
   Castellini C, 2011, IEEE T AUTON MENT DE, V3, P207, DOI 10.1109/TAMD.2011.2106782
   Chia-Chih Chen, 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3425, DOI 10.1109/CVPR.2011.5995555
   Fei-Fei  L., 2006, BMVC
   Fowlkes C, 2004, IEEE T PATTERN ANAL, V26, P214, DOI 10.1109/TPAMI.2004.1262185
   Hu WM, 2007, IEEE T IMAGE PROCESS, V16, P1168, DOI 10.1109/TIP.2006.891352
   Hu WM, 2006, IEEE T PATTERN ANAL, V28, P1450, DOI 10.1109/TPAMI.2006.176
   Jebara T, 2007, LECT NOTES ARTIF INT, V4701, P164
   Johnson N, 1995, PROCEEDINGS OF THE 6TH BRITISH MACHINE VISION CONFERENCE 1995, VOLS 1 AND 2, P583
   Junejo IN, 2004, INT C PATT RECOG, P716, DOI 10.1109/ICPR.2004.1334359
   Jung CR, 2008, IEEE T CIRC SYST VID, V18, P1565, DOI 10.1109/TCSVT.2008.2005600
   Khalid S., 2005, ACM INT WORKSH VID S, P45
   Kuettel Daniel., 2010, CVPR
   Li J, 2008, LECT NOTES COMPUT SC, V5305, P383
   Li X, 2006, INT C PATT RECOG, P591
   Liao HYM, 2006, IEEE INT SYMP CIRC S, P509, DOI 10.1109/ISCAS.2006.1692634
   Liao T. W., 2005, PATTERN RECOGNIT, V38
   Makris D, 2002, IMAGE VISION COMPUT, V20, P895, DOI 10.1016/S0262-8856(02)00098-7
   Morris B., 2009, CVPR
   Morris BT, 2008, IEEE T CIRC SYST VID, V18, P1114, DOI 10.1109/TCSVT.2008.927109
   Morris BT, 2011, IEEE T PATTERN ANAL, V33, P2287, DOI 10.1109/TPAMI.2011.64
   Naftel A., 2006, Proceedings of the 4th IEEE International Conference on Computer Vision Systems (ICVS'06), P47, DOI [DOI 10.1109/ICVS.2006.41, 10.1109/ICVS.2006.41]
   Noceti N., 2008, THEMIS BMVC
   Noceti N., 2010, MACHINE LEARNING VIS
   Noceti N, 2009, AVSS: 2009 6TH IEEE INTERNATIONAL CONFERENCE ON ADVANCED VIDEO AND SIGNAL BASED SURVEILLANCE, P412, DOI 10.1109/AVSS.2009.40
   Piciarelli Claudio, 2008, IEEE T CIRCUITS SYST, V18
   Pittore M, 2000, INT J COMPUT VISION, V38, P35, DOI 10.1023/A:1008114700759
   Porikli F, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXP (ICME), VOLS 1-3, P1171, DOI 10.1109/ICME.2004.1394427
   Rieck K, 2008, J MACH LEARN RES, V9, P23
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Stauffer C, 2000, IEEE T PATTERN ANAL, V22, P747, DOI 10.1109/34.868677
   Stauffer C., 2002, CVPR, V2, P2
   Sumpter N, 2000, IMAGE VISION COMPUT, V18, P697, DOI 10.1016/S0262-8856(99)00073-6
   Tommasi T., 2008, PATTERN RECOGNIT LET, V29
   Wang XG, 2006, LECT NOTES COMPUT SC, V3953, P110, DOI 10.1007/11744078_9
   Wang XG, 2009, IEEE T PATTERN ANAL, V31, P539, DOI 10.1109/TPAMI.2008.87
   Xiang T, 2005, IEEE I CONF COMP VIS, P1238
   Xiang T, 2008, IEEE T PATTERN ANAL, V30, P893, DOI 10.1109/TPAMI.2007.70731
   Xiong YM, 2004, PATTERN RECOGN, V37, P1675, DOI 10.1016/j.patcog.2003.12.018
   Yan W, 2005, WACV 2005: SEVENTH IEEE WORKSHOP ON APPLICATIONS OF COMPUTER VISION, PROCEEDINGS, P370
   Zhong H, 2004, PROC CVPR IEEE, P819
NR 53
TC 14
Z9 15
U1 1
U2 7
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV
PY 2012
VL 30
IS 11
BP 875
EP 895
DI 10.1016/j.imavis.2012.07.005
PG 21
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 052CW
UT WOS:000312176300007
DA 2024-07-18
ER

PT J
AU Matuszewski, BJ
   Quan, W
   Shark, LK
   McLoughlin, AS
   Lightbody, CE
   Emsley, HCA
   Watkins, CL
AF Matuszewski, Bogdan J.
   Quan, Wei
   Shark, Lik-Kwan
   McLoughlin, Alison S.
   Lightbody, Catherine E.
   Emsley, Hedley C. A.
   Watkins, Caroline L.
TI Hi4D-ADSIP 3-D dynamic facial articulation database
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial articulation database; Expression recognition; Facial;
   Dysfunctions; Facial expression validation
ID 3D; FACES
AB The face is an important medium used by humans to communicate, and facial articulation also reflects a person's emotional and awareness states, cognitive activity, personality or wellbeing. With the advances in 3-D imaging technology and ever increasing computing power, automatic analysis of facial articulation using 3-D sequences is becoming viable. This paper describes Hi4D-ADSIP - a comprehensive 3-D dynamic facial articulation database, containing scans with high spatial and temporal resolution. The database is designed not only to facilitate studies on facial expression analysis, but also to aid research into clinical diagnosis of facial dysfunctions. The database currently contains 3360 facial sequences captured from 80 healthy volunteers (control subjects) of various age, gender and ethnicity. The database has been validated using psychophysical experiments used to formally evaluate the accuracy of the recorded expressions. The results of baseline automatic facial expression recognition methods using Eigen- and Fisher-faces are also presented alongside some initial results obtained for clinical cases. This database is believed to be one of the most comprehensive repositories of facial 3-D dynamic articulations to date. The extension of this database is currently under construction aiming at building a comprehensive repository of representative facial dysfunctions exhibited by patients with stroke, Bell's palsy and Parkinson's disease. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Matuszewski, Bogdan J.; Quan, Wei; Shark, Lik-Kwan] Univ Cent Lancashire, Appl Digital Signal & Image Proc ADSIP Res Ctr, Sch Comp Engn & Phys Sci, Preston PR1 2HE, Lancs, England.
   [McLoughlin, Alison S.; Lightbody, Catherine E.; Watkins, Caroline L.] Univ Cent Lancashire, Sch Hlth, Preston PR1 2HE, Lancs, England.
   [Emsley, Hedley C. A.] Royal Preston Hosp, Dept Neurol, Preston PR2 9HT, Lancs, England.
C3 University of Central Lancashire; University of Central Lancashire;
   Royal Preston Hospital
RP Matuszewski, BJ (corresponding author), Univ Cent Lancashire, Appl Digital Signal & Image Proc ADSIP Res Ctr, Sch Comp Engn & Phys Sci, Preston PR1 2HE, Lancs, England.
EM bmatuszewski1@uclan.ac.uk
RI McLoughlin, Alison/L-3049-2016; Watkins, Caroline/E-6898-2013
OI McLoughlin, Alison/0000-0001-5298-9306; Watkins,
   Caroline/0000-0002-9403-3772; Lightbody, Elizabeth/0000-0001-5016-3471;
   Emsley, Hedley/0000-0003-0129-4488
FU Engineering and Physical Sciences Research Council [EP/H024913/1];
   Dimensional Imaging; National Institute for Health Research, through
   Comprehensive Clinical Research Network; EPSRC [EP/H024913/1] Funding
   Source: UKRI
FX This work was supported by the Engineering and Physical Sciences
   Research Council [grant number EP/H024913/1]. The authors would like to
   also acknowledge the support from Dimensional Imaging and the National
   Institute for Health Research, through Comprehensive Clinical Research
   Network.
CR Anitha C., 2010, International Journal of Engineering Science and Technology, V2, P5158
   [Anonymous], 2005, ICME
   [Anonymous], 2008, 8 INT C AUT FAC GEST
   [Anonymous], 1997, IEEE COMP SOC C COMP
   [Anonymous], IEEE INT C AUT FAC G
   [Anonymous], 1 COST 2101 WORKSH B
   [Anonymous], 9 WSEAS INT C MULT I
   [Anonymous], 2002, IEEE INT C AUT FAC G
   Battocchi A, 2005, LECT NOTES COMPUT SC, V3814, P303, DOI 10.1007/11590323_39
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bowyer KW, 2006, COMPUT VIS IMAGE UND, V101, P1, DOI 10.1016/j.cviu.2005.05.005
   COOTES TF, 1995, COMPUT VIS IMAGE UND, V61, P38, DOI 10.1006/cviu.1995.1004
   DUNN OJ, 1961, J AM STAT ASSOC, V56, P52, DOI 10.2307/2282330
   Gross R, 2010, IMAGE VISION COMPUT, V28, P807, DOI 10.1016/j.imavis.2009.08.002
   Lu XG, 2006, IEEE T PATTERN ANAL, V28, P31, DOI 10.1109/TPAMI.2006.15
   Lyons MJ, 1999, IEEE T PATTERN ANAL, V21, P1357, DOI 10.1109/34.817413
   Matuszewski B.J., 2011, FACIAL EXPRESSION RE
   Matuszewski B.J., 2011, IEEE INT WORKSH BENC
   O'Toole AJ, 2002, TRENDS COGN SCI, V6, P261, DOI 10.1016/S1364-6613(02)01908-3
   PEARSON DE, 1995, P IEEE, V83, P892, DOI 10.1109/5.387091
   Pentland A, 2000, IEEE T PATTERN ANAL, V22, P107, DOI 10.1109/34.824823
   Pilz KS, 2006, EXP BRAIN RES, V171, P436, DOI 10.1007/s00221-005-0283-8
   Quan W, 2010, IEEE IMAGE PROC, P2433, DOI 10.1109/ICIP.2010.5651357
   Quan W, 2009, EURASIP J ADV SIG PR, DOI 10.1155/2009/261542
   Wallhoff F., Facial expressions and emotion database
   Wang YM, 2006, LECT NOTES COMPUT SC, V3851, P581
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
NR 27
TC 29
Z9 30
U1 0
U2 18
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2012
VL 30
IS 10
BP 713
EP 727
DI 10.1016/j.imavis.2012.02.002
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 027YD
UT WOS:000310389100004
DA 2024-07-18
ER

PT J
AU Sandbach, G
   Zafeiriou, S
   Pantic, M
   Rueckert, D
AF Sandbach, Georgia
   Zafeiriou, Stefanos
   Pantic, Maja
   Rueckert, Daniel
TI Recognition of 3D facial expression dynamics
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Facial expression recognition; 3D facial geometries; Motion-based
   features; Quad-tree decomposition; 2D/3D comparison
ID TEMPORAL SEGMENTS; FACE; MODELS; REGISTRATION; SEQUENCES; VIEW
AB In this paper we propose a method that exploits 3D motion-based features between frames of 3D facial geometry sequences for dynamic facial expression recognition. An expressive sequence is modelled to contain an onset followed by an apex and an offset. Feature selection methods are applied in order to extract features for each of the onset and offset segments of the expression. These features are then used to train GentleBoost classifiers and build a Hidden Markov Model in order to model the full temporal dynamics of the expression. The proposed fully automatic system was employed on the BU-4DFE database for distinguishing between the six universal expressions: Happy, Sad, Angry, Disgust, Surprise and Fear. Comparisons with a similar 2D system based on the motion extracted from facial intensity images was also performed. The attained results suggest that the use of the 3D information does indeed improve the recognition accuracy when compared to the 2D data in a fully automatic manner. (c) 2012 Elsevier B.V. All rights reserved.
C1 [Sandbach, Georgia; Zafeiriou, Stefanos; Pantic, Maja; Rueckert, Daniel] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
   [Pantic, Maja] Univ Twente, Dept Comp Sci, NL-7500 AE Enschede, Netherlands.
C3 Imperial College London; University of Twente
RP Sandbach, G (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London, England.
EM gls09@imperial.ac.uk; s.zafeiriou@imperial.ac.uk;
   m.pantic@imperial.ac.uk; d.rueckert@imperial.ac.uk
RI Rueckert, Daniel/C-4393-2008
OI Rueckert, Daniel/0000-0002-5683-5889
FU European Research Council under the ERC Starting Grant
   [ERC-2007-StG-203143]; Engineering and Physical Sciences Research
   Council (EPSRC) through a Doctoral Training Account Studentship; Junior
   Research Fellowship of Imperial College London; EPSRC [EP/H016988/1]
   Funding Source: UKRI
FX This work has been funded by the European Research Council under the ERC
   Starting Grant agreement no. ERC-2007-StG-203143 (MAHNOB). The work of
   Georgia Sandbach is funded by the Engineering and Physical Sciences
   Research Council (EPSRC) through a Doctoral Training Account
   Studentship. The work of S. Zafeiriou was funded in part by the Junior
   Research Fellowship of Imperial College London.
CR Ambadar Z, 2005, PSYCHOL SCI, V16, P403, DOI 10.1111/j.0956-7976.2005.01548.x
   [Anonymous], 2010, IEEE CVPR 10 WORKSHO
   [Anonymous], 2009, INT C MAN SER SCI
   [Anonymous], 10 INT WORKSH IM AN
   [Anonymous], 2008 23 INT S COMP I
   [Anonymous], IM PROC 2006 IEEE IN
   Bartlett MS, 2005, PROC CVPR IEEE, P568
   Chang Y, 2005, LECT NOTES COMPUT SC, V3723, P293
   Chang Y., 2004, COMPUTER VISION PATT, V2
   Cohen I, 2003, COMPUT VIS IMAGE UND, V91, P160, DOI 10.1016/S1077-3142(03)00081-X
   Costa M, 2001, J NONVERBAL BEHAV, V25, P225, DOI 10.1023/A:1012544204986
   Ekman P., 2005, WHAT FACE REVEALS BA
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gokturk SB, 2002, FIFTH IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION, PROCEEDINGS, P287, DOI 10.1109/AFGR.2002.1004168
   Gralewski L, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P217
   Hao Tang, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563052
   Koelstra S., 2008, INT C AUT FAC GEST R, V1
   Koelstra S, 2010, IEEE T PATTERN ANAL, V32, P1940, DOI 10.1109/TPAMI.2010.50
   Kotsia I, 2007, IEEE T IMAGE PROCESS, V16, P172, DOI 10.1109/TIP.2006.884954
   Littlewort G, 2006, IMAGE VISION COMPUT, V24, P615, DOI 10.1016/j.imavis.2005.09.011
   Mpiperis I., 2008, FG'08, P1
   Mpiperis I, 2008, IEEE T INF FOREN SEC, V3, P498, DOI 10.1109/TIFS.2008.924598
   Pantic M, 2005, IEEE SYS MAN CYBERN, P3358
   Pantic M, 2006, IEEE T SYST MAN CY B, V36, P433, DOI 10.1109/TSMCB.2005.859075
   Pantic M, 2009, PHILOS T R SOC B, V364, P3505, DOI 10.1098/rstb.2009.0135
   Rueckert D, 2003, IEEE T MED IMAGING, V22, P1014, DOI 10.1109/TMI.2003.815865
   Rueckert D, 1999, IEEE T MED IMAGING, V18, P712, DOI 10.1109/42.796284
   Savran Arman, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P1993, DOI 10.1109/ICCVW.2009.5457526
   Savran Arman, 2008, 2008 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P1, DOI 10.1109/CVPRW.2008.4563083
   Sebe N, 2007, IMAGE VISION COMPUT, V25, P1856, DOI 10.1016/j.imavis.2005.12.021
   Shan CF, 2009, IMAGE VISION COMPUT, V27, P803, DOI 10.1016/j.imavis.2008.08.005
   Soyel H, 2007, LECT NOTES COMPUT SC, V4633, P831
   Sun Y, 2008, LECT NOTES COMPUT SC, V5303, P58, DOI 10.1007/978-3-540-88688-4_5
   Tong Y, 2007, IEEE T PATTERN ANAL, V29, P1683, DOI 10.1109/TPAMI.2007.1094
   Tsalakanidou Filareti, 2009, 2009 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops (CVPR Workshops), P4, DOI 10.1109/CVPR.2009.5204281
   Tsalakanidou F, 2010, PATTERN RECOGN, V43, P1763, DOI 10.1016/j.patcog.2009.12.009
   Valstar MF, 2007, LECT NOTES COMPUT SC, V4796, P118
   Valstar MF, 2007, ICMI'07: PROCEEDINGS OF THE NINTH INTERNATIONAL CONFERENCE ON MULTIMODAL INTERFACES, P38
   van Rijsbergen C. J, 1979, Information Retrieval, V2nd
   Wang J., 2006, P IEEE C COMPUTER VI, P1399
   Wang P, 2007, PROC CVPR IEEE, P701
   Wen Z., 2008, COMP VIS 2003 P 9 IE, P1343
   Williams ACD, 2002, BEHAV BRAIN SCI, V25, P439, DOI 10.1017/S0140525X02000080
   Yeasin M, 2004, PROC CVPR IEEE, P922
   Yeasin M, 2006, IEEE T MULTIMEDIA, V8, P500, DOI 10.1109/TMM.2006.870737
   Yin LJ, 2006, INT C PATT RECOG, P1248
   Zafeiriou S, 2008, IEEE T MULTIMEDIA, V10, P1528, DOI 10.1109/TMM.2008.2007292
   Zhang YM, 2005, IEEE T PATTERN ANAL, V27, P699, DOI 10.1109/TPAMI.2005.93
   ZHANG ZY, 1994, INT J COMPUT VISION, V13, P119, DOI 10.1007/BF01427149
   Zhao GY, 2007, IEEE T PATTERN ANAL, V29, P915, DOI 10.1109/TPAMI.2007.1110
NR 50
TC 78
Z9 82
U1 1
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT
PY 2012
VL 30
IS 10
BP 762
EP 773
DI 10.1016/j.imavis.2012.01.006
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 027YD
UT WOS:000310389100008
OA Green Submitted, Green Published
DA 2024-07-18
ER

PT J
AU Bak, S
   Corvée, E
   Brémond, F
   Thonnat, M
AF Bak, Slawomir
   Corvee, Etienne
   Bremond, Francois
   Thonnat, Monique
TI Boosted human re-identification using Riemannian manifolds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Re-identification; Covariance matrix; Riemannian manifold; Human
   detection; Appearance matching; Boosting
ID RECOGNITION
AB This paper presents an appearance-based model to address the human re-identification problem. Human re-identification is an important and still unsolved task in computer vision. In many systems there is a requirement to identify individuals or determine whether a given individual has already appeared over a network of cameras. The human appearance obtained in one camera is usually different from the ones obtained in another camera. In order to re-identify people a human signature should handle difference in illumination, pose and camera parameters. The paper focuses on a new appearance model based on Mean Riemannian Covariance (MRC) patches extracted from tracks of a particular individual. A new similarity measure using Riemannian manifold theory is also proposed to distinguish sets of patches belonging to a specific individual. We investigate the significance of MRC patches based on their reliability extracted during tracking and their discriminative power obtained by a boosting scheme. Our method is evaluated and compared with the state of the art using benchmark video sequences from the ETHZ and the i-LIDS datasets. Re-identification performance is presented using a cumulative matching characteristic (CMC) curve. We demonstrate that the proposed approach outperforms state of the art methods. Finally, the results of our approach are shown on two further and more pertinent datasets. (c) 2011 Elsevier B.V. All rights reserved.
C1 [Bak, Slawomir; Corvee, Etienne; Bremond, Francois; Thonnat, Monique] INRIA Sophia Antipolis, PULSAR Grp 2004, F-06902 Sophia Antipolis, France.
RP Bak, S (corresponding author), INRIA Sophia Antipolis, PULSAR Grp 2004, Route Lucioles,BP93, F-06902 Sophia Antipolis, France.
EM Slawomir.Bak@inria.fr
FU Agence National de la Recherche (ANR); VIDEO-ID; VANAHEIM project
FX The authors would like to thank Dr. Guillaume Charpiat for his comments
   and fruitful discussions. This work has been supported by Agence
   National de la Recherche (ANR), VIDEO-ID and VANAHEIM project.
CR [Anonymous], P 20 C COMP VIS PATT
   [Anonymous], 1999, QUA VADIS GEODESIA
   [Anonymous], P 19 INT C PATT REC
   [Anonymous], P 7 IEEE INT C ADV V
   [Anonymous], P 2 WORKSH ACT MON M
   [Anonymous], P 3 INT C IM CRIM DE
   [Anonymous], P 19 INT C PATT REC
   [Anonymous], IEEE INT VEH S
   [Anonymous], P 7 IEEE INT C ADV V
   [Anonymous], P 20 BRIT MACH VIS C
   [Anonymous], COMMUNICATIONS COMPU
   [Anonymous], 2010, P BRIT MACH VIS C
   Bay H., 2008, COMPUT VIS IMAGE UND, V10, P346, DOI DOI 10.1016/j.cviu.2007.09.014
   Bazzani Loris, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P1413, DOI 10.1109/ICPR.2010.349
   Bird ND, 2005, IEEE T INTELL TRANSP, V6, P167, DOI 10.1109/TITS.2005.848370
   Catanzaro B., 2008, P 25 INT C MACHINE L, P104, DOI DOI 10.1145/1390156.1390170
   Chellappa R., 2007, IEEE Conference on Computer Vision and Pattern Recognition, P1
   Cressie N, 1999, J AM STAT ASSOC, V94, P1330, DOI 10.2307/2669946
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ess A., 2007, P 11 INT C COMPUTER, P1
   Farenzena M, 2010, PROC CVPR IEEE, P2360, DOI 10.1109/CVPR.2010.5539926
   Finlayson G, 2005, PATTERN RECOGN, V38, P179, DOI 10.1016/j.patcog.2004.04.010
   Fuentes M, 2006, J STAT PLAN INFER, V136, P447, DOI 10.1016/j.jspi.2004.07.004
   Gallagher AC, 2008, PROC CVPR IEEE, P1073
   Gheissari N., 2006, 2006 IEEE computer society conference on computer vision and pattern recognition (CVPR'06), V2, P1528
   Gonzalez R.C., 2018, DIGITAL IMAGE PROCES, V4th
   Gray D, 2008, LECT NOTES COMPUT SC, V5302, P262, DOI 10.1007/978-3-540-88682-2_21
   Hamdoun O., 2008, P 2 ACMIEEE INT C DI, P1
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   Lazebnik S., COMPUTER VISION PATT, V2, P2169
   Lin Z, 2008, LECT NOTES COMPUT SC, V5358, P23, DOI 10.1007/978-3-540-89639-5_3
   Lindholm E, 2008, IEEE MICRO, V28, P39, DOI 10.1109/MM.2008.31
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Oreifej O, 2010, PROC CVPR IEEE, P709, DOI 10.1109/CVPR.2010.5540147
   Park U, 2006, INT C PATT RECOG, P1204
   Pennec X, 2006, INT J COMPUT VISION, V66, P41, DOI 10.1007/s11263-005-3222-z
   Proença H, 2010, IEEE T PATTERN ANAL, V32, P1502, DOI 10.1109/TPAMI.2009.140
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Schwartz WR, 2009, SIBGRAPI, P322, DOI 10.1109/SIBGRAPI.2009.42
   Tao H, 2007, 10 INT WORKSH PERF E
   Teixeira LF, 2009, PATTERN RECOGN LETT, V30, P157, DOI 10.1016/j.patrec.2008.04.001
   Tuzel O, 2008, IEEE T PATTERN ANAL, V30, P1713, DOI 10.1109/TPAMI.2008.75
   Tuzel Oncel., 2006, PROC EUROPEAN C COMP, V2, P589
   Wang L, 2003, IEEE T PATTERN ANAL, V25, P1505, DOI 10.1109/TPAMI.2003.1251144
   Wang XQ, 2007, INT J THERM SCI, V46, P1, DOI 10.1016/j.ijthermalsci.2006.06.010
   Yinghao Cai, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P2744, DOI 10.1109/ICPR.2010.672
NR 46
TC 63
Z9 67
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN
PY 2012
VL 30
IS 6-7
SI SI
BP 443
EP 452
DI 10.1016/j.imavis.2011.08.008
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 977BA
UT WOS:000306630100007
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Kumar, BGV
   Kotsia, I
   Patras, I
AF Kumar, B. G. Vijay
   Kotsia, Irene
   Patras, Ioannis
TI Max-margin Non-negative Matrix Factorization
SO IMAGE AND VISION COMPUTING
LA English
DT Review
DE Non-negative Matrix Factorization; Supervised feature extraction;
   Semi-NMF; Max-margin classifier
AB In this paper we introduce a supervised, maximum margin framework for linear and non-linear Non-negative Matrix Factorization. By contrast to existing methods in which the matrix factorization phase (i.e. the feature extraction phase) and the classification phase are separated, we incorporate the maximum margin classification constraints within the NMF formulation. This results to a non-convex constrained optimization problem with respect to the bases and the separating hyperplane, which we solve following a block coordinate descent iterative optimization procedure. At each iteration a set of convex (constrained quadratic or Support Vector Machine-type) sub-problems are solved with respect to subsets of the unknown variables. By doing so, we obtain a bases matrix that maximizes the margin of the classifier in the low dimensional space (in the linear case) or in the high dimensional feature space (in the non-linear case). The proposed algorithms are evaluated on several computer vision problems such as pedestrian detection, image retrieval, facial expression recognition and action recognition where they are shown to consistently outperform schemes that extract features using bases that are learned using semi-NMF and classify them using an SVM classifier. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Kumar, B. G. Vijay; Kotsia, Irene; Patras, Ioannis] Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.
C3 University of London
RP Kumar, BGV (corresponding author), Univ London, Sch Elect Engn & Comp Sci, London E1 4NS, England.
EM vijay.kumar@elec.qmul.ac.uk
OI Patras, Ioannis/0000-0003-3913-4738
FU EPSRC [EP/G033935/1]; EPSRC [EP/G033935/1] Funding Source: UKRI
FX This work was supported by the EPSRC grant 'Recognition and Localization
   of Human Actions in Image Sequences', (EP/G033935/1).
CR Agarwal A, 2006, LECT NOTES COMPUT SC, V3851, P50
   [Anonymous], 2006, ACM INT C MULTIMEDIA, DOI [10.1145/1180639.1180727, DOI 10.1145/1180639.1180727]
   Bazaraa M.S., 2013, NONLINEAR PROGRAMMIN
   Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Boutsidis C, 2008, PATTERN RECOGN, V41, P1350, DOI 10.1016/j.patcog.2007.09.010
   Buciu I, 2004, MACHINE LEARN SIGN P, P539
   CAI D, 2008, ICDM
   Chen XR, 2001, PROC CVPR IEEE, P1126
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding C, 2010, IEEE T PATTERN ANAL, V32, P45, DOI 10.1109/TPAMI.2008.277
   Hoyer PO, 2002, NEURAL NETWORKS FOR SIGNAL PROCESSING XII, PROCEEDINGS, P557, DOI 10.1109/NNSP.2002.1030067
   Jia Y. W. Y., 2004, P AS C COMP VIS, P27
   Kotsia I, 2007, IEEE T INF FOREN SEC, V2, P588, DOI 10.1109/TIFS.2007.902017
   Lee D D, 2000, Adv. Neural Inf. Process., P535, DOI DOI 10.1186/GB-2013-14-4-R39
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Li SZ, 2001, PROC CVPR IEEE, P207
   Lin C.-J., 2005, PROJECTED GRADIENT M
   Lin CJ, 2007, IEEE T NEURAL NETWOR, V18, P1589, DOI 10.1109/TNN.2007.895831
   Liu WX, 2004, PATTERN RECOGN LETT, V25, P893, DOI 10.1016/j.patrec.2004.02.002
   Liu WX, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL III, PROCEEDINGS, P293
   Lyons M, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P200, DOI 10.1109/AFGR.1998.670949
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   Paatero P, 1997, CHEMOMETR INTELL LAB, V37, P23, DOI 10.1016/S0169-7439(96)00044-5
   Pascual-Montano A, 2006, IEEE T PATTERN ANAL, V28, P403, DOI 10.1109/TPAMI.2006.60
   Roth P. M., 2009, IEEE WORKSH VID OR O
   Schüldt C, 2004, INT C PATT RECOG, P32, DOI 10.1109/ICPR.2004.1334462
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Thurau C., 2008, CVPR, P1, DOI DOI 10.1109/CVPR.2008.4587721
   Yin LJ, 2006, PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE ON AUTOMATIC FACE AND GESTURE RECOGNITION - PROCEEDINGS OF THE SEVENTH INTERNATIONAL CONFERENCE, P211
   Zafeiriou S, 2006, IEEE T NEURAL NETWOR, V17, P683, DOI 10.1109/TNN.2006.873291
   Zhang DQ, 2006, LECT NOTES ARTIF INT, V4099, P404, DOI 10.1007/978-3-540-36668-3_44
NR 31
TC 11
Z9 12
U1 0
U2 29
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY
PY 2012
VL 30
IS 4-5
BP 279
EP 291
DI 10.1016/j.imavis.2012.02.010
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 964WF
UT WOS:000305726700002
DA 2024-07-18
ER

PT J
AU Strasdat, H
   Montiel, JMM
   Davison, AJ
AF Strasdat, Hauke
   Montiel, J. M. M.
   Davison, Andrew J.
TI Visual SLAM: Why filter?
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE SLAM; Structure from motion; Bundle adjustment; EKF; Information filter;
   Monocular vision; Stereo vision
ID STRUCTURE-FROM-MOTION
AB While the most accurate solution to off-line structure from motion (SFM) problems is undoubtedly to extract as much correspondence information as possible and perform batch optimisation, sequential methods suitable for live video streams must approximate this to fit within fixed computational bounds. Two quite different approaches to real-time SFM - also called visual SLAM (simultaneous localisation and mapping) - have proven successful, but they sparsify the problem in different ways. Filtering methods marginalise out past poses and summarise the information gained over time with a probability distribution. Keyframe methods retain the optimisation approach of global bundle adjustment, but computationally must select only a small number of past frames to process.
   In this paper we perform a rigorous analysis of the relative advantages of filtering and sparse bundle adjustment for sequential visual SLAM. In a series of Monte Carlo experiments we investigate the accuracy and cost of visual SLAM. We measure accuracy in terms of entropy reduction as well as root mean square error (RMSE), and analyse the efficiency of bundle adjustment versus filtering using combined cost/accuracy measures. In our analysis, we consider both SLAM using a stereo rig and monocular SLAM as well as various different scenes and motion patterns. For all these scenarios, we conclude that keyframe bundle adjustment outperforms filtering, since it gives the most accuracy per unit of computing time. (C) 2012 Elsevier B.V. All rights reserved.
C1 [Strasdat, Hauke; Davison, Andrew J.] Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
   [Montiel, J. M. M.] Univ Zaragoza, I3A, E-50009 Zaragoza, Spain.
C3 Imperial College London; University of Zaragoza
RP Strasdat, H (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Comp, London SW7 2AZ, England.
EM strasdat@doc.ic.ac.uk; josemari@unizar.es; ajd@doc.ic.ac.uk
RI Montiel, Jose María Martínez/A-1197-2012
OI Montiel, Jose María Martínez/0000-0002-3627-7306
FU European Research Council [210346]; Spanish MEC [DPI2009-07130]; EU
   [FP7-ICT-248942 Robo Earth]; European Research Council (ERC) [210346]
   Funding Source: European Research Council (ERC)
FX This research was supported by the European Research Council Starting
   Grant 210346, the Spanish MEC Grant DPI2009-07130 and EU FP7-ICT-248942
   Robo Earth. We are grateful to our close colleagues at Imperial College
   London and the Universidad de Zaragoza for many discussions.
CR [Anonymous], P ROB SCI SYST RSS
   [Anonymous], 2010, P IEEE C COMP VIS PA
   [Anonymous], P 3 ALV VIS C
   [Anonymous], 2002, P AAAI IAAI
   [Anonymous], P IEEE INT C ROB AUT
   [Anonymous], 2009, P ROB SCI SYST RSS
   [Anonymous], THESIS U CAMBRIDGE
   [Anonymous], 2001, GEOMETRIC METHODS AP
   [Anonymous], 2006, P IEEE COMPUTER SOC
   [Anonymous], 2001, Robotica, DOI DOI 10.1017/S0263574700223217
   [Anonymous], 1999, INT WORKSH VIS ALG
   AZARBAYEJANI A, 1995, IEEE T PATTERN ANAL, V17, P562, DOI 10.1109/34.387503
   BELL BM, 1993, IEEE T AUTOMAT CONTR, V38, P294, DOI 10.1109/9.250476
   Chiuso A, 2002, IEEE T PATTERN ANAL, V24, P523, DOI 10.1109/34.993559
   Chli M, 2009, ROBOT AUTON SYST, V57, P1173, DOI 10.1016/j.robot.2009.07.010
   Civera J, 2008, IEEE T ROBOT, V24, P932, DOI 10.1109/TRO.2008.2003276
   Civera J, 2010, J FIELD ROBOT, V27, P609, DOI 10.1002/rob.20345
   CLEMENTE LA, 2007, P ROB SCI SYST RSS
   DAVISON AJ, 2005, P INT C COMP VIS ICC
   DAVISON AJ, 2003, P INT C COMP VIS ICC
   Davison AJ, 2007, IEEE T PATTERN ANAL, V29, P1052, DOI 10.1109/TPAMI.2007.1049
   Deans M., 2001, EXPT ROBOTICS, VVII, P395
   Dellaert F., 2005, P ROB SCI SYST RSS
   Dyer P., 1969, Journal of Optimization Theory and Applications, V3, P444, DOI 10.1007/BF00929358
   EADE E, 2007, P INT C COMP VIS ICC
   EADE E, 2006, P IEEE C COMP VIS PA
   Engels C., 2006, P PHOT COMP VIS
   Eustice R.M., 2005, P IEEE INT C ROB AUT
   Jeong Y, 2010, PROC CVPR IEEE, P1474, DOI 10.1109/CVPR.2010.5539795
   Julier SJ, 2001, IEEE INT CONF ROBOT, P4238, DOI 10.1109/ROBOT.2001.933280
   Kaess M., 2012, INT J ROB R IN PRESS
   Kaess M, 2008, IEEE T ROBOT, V24, P1365, DOI 10.1109/TRO.2008.2006706
   Klein G., 2007, P INT S MIX AUG REAL
   Klein G., 2009, P INT S MIX AUG REAL
   Konolige K, 2008, IEEE T ROBOT, V24, P1066, DOI 10.1109/TRO.2008.2004832
   Lim Jongwoo, 2011, P IEEE C COMP VIS PA
   Mahony R, 2002, J GLOBAL OPTIM, V23, P309, DOI 10.1023/A:1016586831090
   McLauchlan P., 1994, P EUR C COMP VIS ECC
   Mei C, 2011, INT J COMPUT VISION, V94, P198, DOI 10.1007/s11263-010-0361-7
   Montiel J.M.M., 2006, P ROB SCI SYST RSS
   MOURAGNON E, 2006, P IEEE C COMP VIS PA
   Neira J, 2001, IEEE T ROBOTIC AUTOM, V17, P890, DOI 10.1109/70.976019
   Nistér D, 2004, IEEE T PATTERN ANAL, V26, P756, DOI 10.1109/TPAMI.2004.17
   Nister D., CVPR
   Pietzsch T., 2008, P BRIT MACH VIS C BM
   Piniés P, 2008, IEEE T ROBOT, V24, P1094, DOI 10.1109/TRO.2008.2004636
   Sibley G., 2005, 12 INT S ROB RES
   Sibley G., 2009, P ROB SCI SYST RSS, p[1, 2, 4]
   Sibley G, 2008, LECT NOTES ELECTR EN, V8, P103
   Sim R., 2005, P IJCAI WORKSH REAS
   Strasdat H., 2010, P IEEE INT C ROB AUT
   Tikhonov A., 1977, Solution of Ill-Posed Problems
NR 52
TC 302
Z9 366
U1 2
U2 99
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2012
VL 30
IS 2
BP 65
EP 77
DI 10.1016/j.imavis.2012.02.009
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 934ZJ
UT WOS:000303486200001
DA 2024-07-18
ER

PT J
AU Dunne, P
   Matuszewski, B
AF Dunne, Peter
   Matuszewski, Bogdan
TI Choice of similarity measure, likelihood function and parameters for
   histogram based particle filter tracking in CCTV grey scale video
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Particle filter; Similarity measure; Likelihood; Grey scale; Histogram
   intersection
ID PEOPLE
AB The choice of particle filter dissimilarity distance measures and likelihood functions is considered in the context of object tracking in grey scale CCR/video. The geometrical interpretation of the Bhattacharyya coefficient and distance is reviewed and the relationships between the Bhattacharyya, Matusita, histogram intersection and chi(2) distances are examined. It is argued that as long as the likelihood function satisfies certain criteria its analytical form is not critical in the stated tracking context. This is demonstrated through an experimental comparison between the use of the standard Bhattacharyya distance/Gaussian likelihood combination and the potentially computationally simpler histogram intersection distance/triangular likelihood combination in particle filter tracking sequences. It is shown that the differences between the approaches are marginal when the likelihood criteria are applied. Whilst the analysis was focused on a specific application and context, we suggest that the findings will be of value to particle filter tracking in general. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Dunne, Peter] AD Grp, Warrington WA4 4HS, Cheshire, England.
   [Dunne, Peter; Matuszewski, Bogdan] Univ Cent Lancashire, Sch Comp Engn & Phys Sci, Appl Digital Signal & Image Proc Res Ctr ADSIP, Preston PR1 2HE, Lancs, England.
C3 University of Central Lancashire
RP Dunne, P (corresponding author), AD Grp, Daresbury Pk, Warrington WA4 4HS, Cheshire, England.
EM pdunne@uclan.ac.uk; bmatuszewski1@uclan.ac.uk
CR Aherne F., 1997, KYBERNETIKA, V32, P1
   [Anonymous], 2008, PROC IET SEMINAR TAR
   Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Birchfield ST, 2007, ETRI J, V29, P697, DOI 10.4218/etrij.07.0207.0017
   Briegel T, 2000, ADV NEUR IN, V12, P407
   *BRIT SEC IND ASS, 2009, INTR VID CONT AN
   CAI Y, 2006, LNCS, V354, P107
   Chen G, 2003, PUBL ASTRON SOC PAC, V115, P1269, DOI 10.1086/379219
   Chipwrights, PROGR VIS SIGN PROC
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   CZYZ J, 2005, P IEEE INT C AC SPEE, V2, P217
   Czyz J, 2007, IMAGE VISION COMPUT, V25, P1271, DOI 10.1016/j.imavis.2006.07.027
   Doucet A, 2000, STAT COMPUT, V10, P197, DOI 10.1023/A:1008935410038
   Duda R., 1973, Pattern Classification and Scene Analysis
   Fuentes LM, 2006, IMAGE VISION COMPUT, V24, P1165, DOI 10.1016/j.imavis.2005.06.006
   GAGUNASHVILI ND, 2007, POS ACAT, V60, P1
   Hall D, 2004, MACH VISION APPL, V16, P41, DOI 10.1007/s00138-004-0146-5
   HAN B, 2005, ICIP 05, P442
   Hanson KM, 2005, AIP CONF PROC, V803, P431, DOI 10.1063/1.2149823
   *HOM OFF SCI DEV B, I LIDS DAT AVSS 2007
   Ikoma N, 2001, JOINT 9TH IFSA WORLD CONGRESS AND 20TH NAFIPS INTERNATIONAL CONFERENCE, PROCEEDINGS, VOLS. 1-5, P2223, DOI 10.1109/NAFIPS.2001.944415
   Iwahori Y., 2007, IAPR C MACH VIS APPL, P307
   Khalid M. S., 2006, Journal of Multimedia, V1, DOI 10.4304/jmm.1.1.56-61
   Kim K, 2006, LECT NOTES COMPUT SC, V3953, P98
   KONG S, 2007, AVSS 07, P159
   Lu WL, 2009, IMAGE VISION COMPUT, V27, P189, DOI 10.1016/j.imavis.2008.02.008
   Maggio E, 2007, IEEE T CIRC SYST VID, V17, P1348, DOI 10.1109/TCSVT.2007.903781
   Mason M, 2001, 30TH APPLIED IMAGERY PATTERN RECOGNITION WORKSHOP, PROCEEDINGS, P154, DOI 10.1109/AIPR.2001.991219
   MATUSITA K, 1954, ANN I STAT MATH, V2, P133
   MEIER EB, 1999, 3 EUR WORKSH ADV MOB, P73
   Nummiaro K, 2003, IMAGE VISION COMPUT, V21, P99, DOI 10.1016/S0262-8856(02)00129-4
   Okuma K., 2003, Proceedings of the SPIE - The International Society for Optical Engineering, V5304, P202, DOI 10.1117/12.528372
   Okuma K, 2004, LECT NOTES COMPUT SC, V3021, P28, DOI 10.1007/978-3-540-24670-1_3
   Pérez P, 2002, LECT NOTES COMPUT SC, V2350, P661
   *PETS, 2006, BENCHM DAT FRAM S1 T
   Porikli F, 2005, PROC CVPR IEEE, P829, DOI 10.1109/CVPR.2005.188
   Ristic R., 2004, KALMAN FILTER
   Sanderson C., 2007, ELECT LETT COMPUTER, V6, P30
   Snoek J, 2009, IMAGE VISION COMPUT, V27, P153, DOI 10.1016/j.imavis.2008.04.021
   SONG X, 2008, BMVC 08, P223
   SWAIN MJ, 1991, INT J COMPUT VISION, V7, P11, DOI 10.1007/BF00130487
   Yilmaz A, 2006, ACM COMPUT SURV, V38, DOI 10.1145/1177352.1177355
   Yin F., 2007, P 10 IEEE INT WORKSH, P17
NR 43
TC 11
Z9 17
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2011
VL 29
IS 2-3
BP 178
EP 189
DI 10.1016/j.imavis.2010.08.013
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 707NV
UT WOS:000286294200008
DA 2024-07-18
ER

PT J
AU Lu, XY
   Manduchi, R
AF Lu, Xiaoye
   Manduchi, Roberto
TI Fast image motion segmentation for surveillance applications
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Optical flow; Motion computation; Belief propagation
ID TRACKING; SEARCH
AB Wireless, battery-powered camera networks are becoming of increasing interest for surveillance and monitoring applications. The computational power of these platforms is often limited in order to reduce energy consumption. In addition, many embedded processors do not have floating point support in hardware. Among the visual tasks that a visual sensor node may be required to perform, motion analysis is one of the most basic and relevant. Events of interest are usually characterized by the presence of moving objects or persons. Knowledge of the direction of motion and velocity of a moving body may be used to take actions such as sending an alarm or triggering other camera nodes in the network.
   We present a fast algorithm for identifying moving areas in an image. The algorithm is efficient and amenable to implementation in fixed point arithmetic. Once the moving blobs in an image have been precisely localized, the average velocity vector can be computed using a small number of floating point operations. Our procedure starts by determining an initial labeling of image blocks based on local differential analysis. Then, belief propagation is used to impose spatial coherence and to resolve aperture effect inherent in texture less areas. A detailed analysis of the computational cost of the algorithm and of the provisions that must be taken in order to avoid overflow with 32-bit words is included. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Manduchi, Roberto] Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA.
   [Lu, Xiaoye] Google Inc, Mountain View, CA 94043 USA.
C3 University of California System; University of California Santa Cruz;
   Google Incorporated
RP Manduchi, R (corresponding author), Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA.
EM bright@google.com; manduchi@soe.ucsc.edu
FU NASA [NNA04CK89A]
FX This work was supported by NASA, Intelligent Systems Program, under
   contract NNA04CK89A.
CR [Anonymous], TR200122 MERL
   [Anonymous], P IEEE C COMP VIS PA
   Barron J., 2005, Tutorial: Computing 2D and 3D optical flow
   Benedetti A, 1998, PROC CVPR IEEE, P586, DOI 10.1109/CVPR.1998.698665
   Benini L, 1999, IEEE T COMPUT AID D, V18, P813, DOI 10.1109/43.766730
   Black M.J., 1993, International Conference on Computer Vision (ICCV), P231
   Black MJ, 2000, COMPUT VIS IMAGE UND, V78, P8, DOI 10.1006/cviu.1999.0825
   Bogliolo A, 2004, P IEEE, V92, P1308, DOI 10.1109/JPROC.2004.831207
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Cai Q, 1999, IEEE T PATTERN ANAL, V21, P1241, DOI 10.1109/34.809119
   COUGHLAN J, 2002, P 7 EUR C COMP VIS E
   Golub G.H., 2013, Matrix Computations, DOI DOI 10.56021/9781421407944
   Hager GD, 1998, IEEE T PATTERN ANAL, V20, P1025, DOI 10.1109/34.722606
   Hariharakrishnan K, 2005, IEEE T MULTIMEDIA, V7, P853, DOI 10.1109/TMM.2005.854437
   HAUSSECKER H, 1997, P DAGM S
   HORN BKP, 1981, ARTIF INTELL, V17, P185, DOI 10.1016/0004-3702(81)90024-2
   Horn R. A., 2012, MATRIX ANAL
   Javed O, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P952
   LU X, 2006, 2 IEEE WORKSH EMB CO
   Lucas B., 1981, P INT JOINT C ART IN, P674, DOI DOI 10.1364/J0SAA.19.002142
   MARGI CB, 2006, P WORKSH DISTR SMART
   Nie Y, 2002, IEEE T IMAGE PROCESS, V11, P1442, DOI 10.1109/TIP.2002.806251
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAPADEMETRIS X, 1996, P INT C ONIMAGE PROC, DOI DOI 10.1109/ICIP.1996.559545
   Piccardi M, 2004, IEEE SYS MAN CYBERN, P3099, DOI 10.1109/ICSMC.2004.1400815
   *PLATFORMX PROJ, STARG PLATF PROJ
   Radke RJ, 2005, IEEE T IMAGE PROCESS, V14, P294, DOI 10.1109/TIP.2004.838698
   RAHIMI M, 2005, SENSYS 2005
   STAUFFER C, 1999, IEEE INT C COMP VIS
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Szeliski R, 1997, INT J COMPUT VISION, V22, P199, DOI 10.1023/A:1007996332012
   Szeliski R, 2006, FOUND TRENDS COMPUT, V2, P1, DOI 10.1561/0600000009
   TAAKA K, 2003, P WORKSH NEUR NETW S
   TOMASI C, 1992, INT J COMPUT VISION, V9, P137, DOI 10.1007/BF00129684
   Viola P, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P747
   WEBER J, 1995, INT J COMPUT VISION, V14, P67, DOI 10.1007/BF01421489
   ZHANG G, 2007, P IEEE INT WORKSH AD
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 38
TC 7
Z9 10
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB
PY 2011
VL 29
IS 2-3
BP 104
EP 116
DI 10.1016/j.imavis.2010.08.001
PG 13
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 707NV
UT WOS:000286294200002
DA 2024-07-18
ER

PT J
AU Yang, CN
   Ciou, CB
AF Yang, Ching-Nung
   Ciou, Chuei-Bang
TI Image secret sharing method with two-decoding-options: Loss less
   recovery and previewing capability
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image secret sharing; Visual cryptography; Polynomial-based secret
   sharing; Lagrange interpolation
ID VISUAL CRYPTOGRAPHY SCHEMES; SIZE; STEGANOGRAPHY
AB Visual cryptography scheme (VCS) is a research area in image secret sharing, where one can easily stack shadow images and decode a black-and-white secret image through the human visual system without computation. Although VCS does not provide a competitive reconstruction quality, its stacking-to-see property clearly has the intended applications. To develop the ease of decoding of VCS and simultaneously overcome its weakness, Lin et al. recently proposed a novel two-in-one image secret sharing scheme (TiOISSS) with two decoding options based on VCS and a polynomial-based image secret sharing scheme (PISSS). In this TiOISSS, the first decoding stage has the stacking-to-see property to preview a vague image, and the second decoding stage is to obtain the original gray-level secret image. In this paper, we design a new TiOISSS by combining VCS and PISSS in a different way: in specific, our new scheme reduce shadow image size, and is more suitable for faster transmission within a distributed multimedia system. (c) 2010 Elsevier B.V. All rights reserved.
C1 [Yang, Ching-Nung; Ciou, Chuei-Bang] Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, Hualien, Taiwan.
C3 National Dong Hwa University
RP Yang, CN (corresponding author), Natl Dong Hwa Univ, Dept Comp Sci & Informat Engn, 1 Sec 2,Hsueh Rd, Hualien, Taiwan.
EM cnyang@mail.ndhu.edu.tw
RI Yang, Ching-Nung/HKV-1639-2023
OI Yang, Ching-Nung/0000-0002-3881-7329
FU NSC [97-2745-P-001-001]; Testbed@TWISC, National Science Council [NSC
   98-2219-E-006-001]
FX This research was supported in part by the iCAST project under Grant NSC
   97-2745-P-001-001, and the Testbed@TWISC, National Science Council under
   the Grants NSC 98-2219-E-006-001.
CR Ateniese G, 2001, THEOR COMPUT SCI, V250, P143, DOI 10.1016/S0304-3975(99)00127-9
   Blundo C, 2000, INFORM PROCESS LETT, V75, P255, DOI 10.1016/S0020-0190(00)00108-3
   Chang CC, 2008, PATTERN RECOGN, V41, P3130, DOI 10.1016/j.patcog.2008.04.006
   Cimato S, 2006, COMPUT J, V49, P97, DOI 10.1093/comjnl/bxh152
   Cimato S, 2005, DESIGN CODE CRYPTOGR, V35, P311, DOI 10.1007/s10623-003-6741-z
   Cimato S, 2005, INFORM PROCESS LETT, V93, P199, DOI 10.1016/j.ipl.2004.10.011
   CIMATO S, 2007, THEORETICAL COMPUTER, V374, P26
   Eisen PA, 2002, DESIGN CODE CRYPTOGR, V25, P15, DOI 10.1023/A:1012504516447
   Feng JB, 2008, PATTERN RECOGN, V41, P3572, DOI 10.1016/j.patcog.2008.05.031
   Horng G, 2006, DESIGN CODE CRYPTOGR, V38, P219, DOI 10.1007/s10623-005-6342-0
   Hou YC, 2003, PATTERN RECOGN, V36, P1619, DOI 10.1016/S0031-3203(02)00258-3
   Ishihara T, 2003, IEICE T FUND ELECTR, VE86A, P194
   Ito R, 1999, IEICE T FUND ELECTR, VE82A, P2172
   Iwamoto M, 2002, IEICE T FUND ELECTR, VE85A, P2238
   Jin D, 2005, J ELECTRON IMAGING, V14, DOI 10.1117/1.1993625
   Kuwakado H, 2004, IEICE T FUND ELECTR, VE87A, P1193
   Lin CC, 2004, J SYST SOFTWARE, V73, P405, DOI 10.1016/S0164-1212(03)00239-5
   Lin CC, 2003, PATTERN RECOGN LETT, V24, P349, DOI 10.1016/S0167-8655(02)00259-3
   Lin SJ, 2007, PATTERN RECOGN, V40, P3652, DOI 10.1016/j.patcog.2007.04.001
   Liu GQ, 2009, AVIAN BIOL RES, V2, P151, DOI 10.3184/175815509X12474776260634
   Naor M, 1994, LECT NOTES COMPUTER, V950, P1, DOI [10.1007/BFb0053419, DOI 10.1007/BFB0053419]
   SHAMIR A, 1979, COMMUN ACM, V22, P612, DOI 10.1145/359168.359176
   Shyu SH, 2006, PATTERN RECOGN, V39, P866, DOI 10.1016/j.patcog.2005.06.010
   Shyu SJ, 2007, PATTERN RECOGN, V40, P3633, DOI 10.1016/j.patcog.2007.03.012
   Thien CC, 2002, COMPUT GRAPH-UK, V26, P766
   Thien CC, 2003, IEEE T CIRC SYST VID, V13, P1161, DOI 10.1109/TCSVT.2003.819176
   Tsai DS, 2007, PATTERN RECOGN, V40, P2356, DOI 10.1016/j.patcog.2007.01.013
   Verheul E. R., 1997, Designs, Codes and Cryptography, V11, P179, DOI 10.1023/A:1008280705142
   Wang RZ, 2007, SIGNAL PROCESS-IMAGE, V22, P363, DOI 10.1016/j.image.2006.12.012
   Wang RZ, 2006, PATTERN RECOGN LETT, V27, P551, DOI 10.1016/j.patrec.2005.09.021
   Yang CN, 2008, COMPUT J, V51, P710, DOI 10.1093/comjnl/bxm118
   Yang CN, 2007, INT J PATTERN RECOGN, V21, P879, DOI 10.1142/S0218001407005740
   Yang CN, 2008, PATTERN RECOGN, V41, P3114, DOI 10.1016/j.patcog.2008.03.031
   Yang CN, 2007, INT J IMAG SYST TECH, V17, P40, DOI 10.1002/ima.20096
   Yang CN, 2007, J SYST SOFTWARE, V80, P1070, DOI 10.1016/j.jss.2006.11.022
   Yang CN, 2006, PATTERN RECOGN, V39, P1300, DOI 10.1016/j.patcog.2006.01.013
   Yang CN, 2006, IEICE T FUND ELECTR, VE89A, P620, DOI 10.1093/ietfec/e89-a.2.620
   Yang CN, 2000, DESIGN CODE CRYPTOGR, V20, P325, DOI 10.1023/A:1008382327051
   Yang CN, 2005, IEICE T FUND ELECTR, VE88A, P2471, DOI 10.1093/ietfec/e88-a.9.2471
   Yang CN, 2004, PATTERN RECOGN LETT, V25, P481, DOI 10.1016/j.patrec.2003.12.011
NR 40
TC 88
Z9 91
U1 0
U2 6
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD DEC
PY 2010
VL 28
IS 12
BP 1600
EP 1610
DI 10.1016/j.imavis.2010.04.003
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 657IV
UT WOS:000282407300003
DA 2024-07-18
ER

PT J
AU Xie, ZX
   Xu, S
   Li, XY
AF Xie, Zexiao
   Xu, Shang
   Li, Xuyong
TI A high-accuracy method for fine registration of overlapping point clouds
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Fine registration; ICP algorithm; Dual interpolating point-to-surface;
   Surface fitting; Auxiliary pair
ID RANGE IMAGE REGISTRATION; VIEWS; ICP
AB This paper presents a high-accuracy method for fine registration of two partially overlapping point clouds that have been coarsely registered. The proposed algorithm, which is named dual interpolating point-to-surface method, is principally a modified variant of point-to-surface Iterative Closest Point (ICP) algorithm. The original correspondences are established by adopting a dual surface fitting approach using B-spline interpolation. A novel auxiliary pair constraint based on the surface fitting approach, together with surface curvature information, is employed to remove unreliable point matches. The combined constraint directly utilizes global rigid motion consistency in conjunction with local geometric invariant to reject false correspondences precisely and efficiently. The experimental results involving a number of realistic point clouds demonstrate that the new method can obtain accurate and robust fine registration for pairwise 3D point clouds. This method addresses highest accuracy alignment with less focus on recovery from poor coarse registrations. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Xie, Zexiao; Xu, Shang; Li, Xuyong] Ocean Univ China, Coll Engn, Qingdao 266100, Peoples R China.
C3 Ocean University of China
RP Xie, ZX (corresponding author), Ocean Univ China, Coll Engn, Qingdao 266100, Peoples R China.
EM xiezexiao@ouc.edu.cn; xushang11@hotmail.com; lixuyong_0@yahoo.cn
FU Natural Science Foundation of China [60772057]
FX This research has been partially supported by the Natural Science
   Foundation of China, Grant No. 60772057. The authors would like to thank
   professor G.X. Zhang for his help on this research.
CR ARMIT AP, 1993, COMPUT AIDED DESIGN, V25, P251, DOI 10.1016/0010-4485(93)90057-U
   ARUN KS, 1987, IEEE T PATTERN ANAL, V9, P699, DOI 10.1109/TPAMI.1987.4767965
   BEEKER E, 1986, COMPUT AIDED DESIGN, V18, P224, DOI 10.1016/0010-4485(86)90134-X
   Bergevin R, 1996, IEEE T PATTERN ANAL, V18, P540, DOI 10.1109/34.494643
   BES PJ, 1992, IEEE T PATTERN ANAL, V14, P239
   BLAIS G, 1995, IEEE T PATTERN ANAL, V17, P820, DOI 10.1109/34.400574
   CHEN Y, 1992, IMAGE VISION COMPUT, V10, P145, DOI 10.1016/0262-8856(92)90066-C
   Choi B.K., 1991, SURFACE MODELING CAD
   Chua CS, 1996, INT J COMPUT VISION, V17, P77, DOI 10.1007/BF00127819
   Dalley G, 2002, COMPUT VIS IMAGE UND, V87, P104, DOI 10.1006/cviu.2002.0986
   Dorai C, 1998, IEEE T PATTERN ANAL, V20, P83, DOI 10.1109/34.655652
   Eggert DW, 1998, COMPUT VIS IMAGE UND, V69, P253, DOI 10.1006/cviu.1998.0667
   Fan KC, 2001, ROBOT CIM-INT MANUF, V17, P215, DOI 10.1016/S0736-5845(00)00029-6
   Farin G., 2014, Curves and Surfaces for Computer-Aided Geometric Design: A Practical Guide
   Farin G., 2002, HDB COMPUTER AIDED G
   Feldmar J, 1996, INT J COMPUT VISION, V18, P99, DOI 10.1007/BF00054998
   GODIN G, 1995, INT ARCH PHOTOGRAMME, V30, P170
   Guehring J, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P224, DOI 10.1109/IM.2001.924440
   Kase K, 1999, COMPUT AIDED DESIGN, V31, P495, DOI 10.1016/S0010-4485(99)00046-9
   Li L, 2002, ROBOT CIM-INT MANUF, V18, P53, DOI 10.1016/S0736-5845(01)00026-6
   Liu YH, 2004, ROBOT AUTON SYST, V47, P11, DOI 10.1016/j.robot.2004.02.002
   Liu YH, 2004, PATTERN RECOGN, V37, P211, DOI 10.1016/S0031-3203(03)00239-5
   Neugebauer P, 1997, 1997 INTERNATIONAL CONFERENCE ON SHAPE MODELING AND APPLICATIONS, PROCEEDINGS, P130, DOI 10.1109/SMA.1997.634890
   PAJDLA T, 1995, FIFTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, PROCEEDINGS, P390, DOI 10.1109/ICCV.1995.466913
   Park SY, 2003, FOURTH INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P276
   Pulli K., 1999, Second International Conference on 3-D Digital Imaging and Modeling (Cat. No.PR00062), P160, DOI 10.1109/IM.1999.805346
   Ristic M, 1997, IMAGE VISION COMPUT, V15, P925, DOI 10.1016/S0262-8856(97)00049-8
   Rusinkiewicz S, 2001, THIRD INTERNATIONAL CONFERENCE ON 3-D DIGITAL IMAGING AND MODELING, PROCEEDINGS, P145, DOI 10.1109/IM.2001.924423
   Salvi J, 2007, IMAGE VISION COMPUT, V25, P578, DOI 10.1016/j.imavis.2006.05.012
   Sharp GC, 2002, IEEE T PATTERN ANAL, V24, P90, DOI 10.1109/34.982886
   Silva L, 2005, IEEE T PATTERN ANAL, V27, P762, DOI 10.1109/TPAMI.2005.108
   Varady T, 1997, COMPUT AIDED DESIGN, V29, P255, DOI 10.1016/S0010-4485(96)00054-1
   Wyngaerd JV, 2002, COMPUT VIS IMAGE UND, V87, P8, DOI 10.1006/cviu.2002.0979
   Zinsser T, 2003, 2003 INTERNATIONAL CONFERENCE ON IMAGE PROCESSING, VOL 2, PROCEEDINGS, P695
NR 34
TC 44
Z9 59
U1 0
U2 43
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR
PY 2010
VL 28
IS 4
BP 563
EP 570
DI 10.1016/j.imavis.2009.09.006
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 563LD
UT WOS:000275132600002
DA 2024-07-18
ER

PT J
AU Baeza, I
   Verdoy, JA
   Villanueva, RJ
   Villanueva-Oller, J
AF Baeza, Ismael
   Verdoy, Jose-Antonio
   Villanueva, Rafael-Jacinto
   Villanueva-Oller, Javier
TI SVD lossy adaptive encoding of 3D digital images for ROI progressive
   transmission
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE 3D digital images; Singular value decomposition encoding; Lossy
   progressive transmission; Region of interest (ROI) transmission
ID SYSTEM
AB In this paper, we propose an algorithm for lossy adaptive encoding of digital three-dimensional (3D) images based on singular value decomposition (SVD). This encoding allows us to design algorithms for progressive transmission and reconstruction of the 3D image, for one or several selected regions of interest (ROI) avoiding redundancy in data transmission. The main characteristic of the proposed algorithms is that the ROIs can be selected during the transmission process and it is not necessary to re-encode the image again to transmit the data corresponding to the selected ROI. An example with a data set of a CT scan consisting of 93 parallel slices where we added an implanted tumor (the ROI in this example) and a comparative with JPEC2000 are given. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Baeza, Ismael; Verdoy, Jose-Antonio; Villanueva, Rafael-Jacinto] Univ Politecn Valencia, Inst Matemat Multidisciplinar, Valencia 46022, Spain.
   [Villanueva-Oller, Javier] CES Felipe II, Ing Tecn Informat Sistemas, Madrid, Spain.
C3 Universitat Politecnica de Valencia
RP Villanueva, RJ (corresponding author), Univ Politecn Valencia, Inst Matemat Multidisciplinar, Edificio 8G Piso 2, Valencia 46022, Spain.
EM ibaeza@upvnet.upv.es; javerdoy@mat.upv.es; rjvillan@imm.upv.es;
   jvillanueva@cesfelipesegundo.com
RI Villanueva, Rafael-Jacinto/C-5916-2016; Verdoy, José
   Antonio/F-7178-2016; Villanueva-Oller, Javier/HKW-1266-2023
OI Villanueva, Rafael-Jacinto/0000-0002-0131-0532; Verdoy, José
   Antonio/0000-0002-1196-8821; Villanueva-Oller,
   Javier/0000-0002-2148-9162
FU Programa de Incentivo a la Investigacion [5706]; Generalitat Valenciana
   [AE06/001]
FX This paper has been supported by the grant Programa de Incentivo a la
   Investigacion 2005 de la UPV No. 5706 and the Generalitat Valenciana
   Grant AE06/001.
CR [Anonymous], 2002, JPEG2000: Image Compression Fundamentals, Standards, and Practice
   Baeza I, 2005, MATH COMPUT MODEL, V41, P1325, DOI 10.1016/j.mcm.2004.02.035
   Baeza I, 2009, MATH COMPUT MODEL, V50, P849, DOI 10.1016/j.mcm.2009.05.014
   Christopoulos C, 2000, IEEE T CONSUM ELECTR, V46, P1103, DOI 10.1109/30.920468
   Defez E, 2002, J MATH IMAGING VIS, V17, P41, DOI 10.1023/A:1020774608752
   Dilmaghani RS, 2004, IEEE SIGNAL PROC LET, V11, P806, DOI 10.1109/LSP.2004.835563
   Golub G.H., 1989, MATRIX COMPUTATIONS
   Gorodetski VI, 2001, LECT NOTES COMPUT SC, V2052, P263
   *KAK SOFTW, KAK SOFTW COMPR FRAM
   KANJILAL PP, 1995, IEEE T SIGNAL PROCES, V43, P1536, DOI 10.1109/78.388873
   Kim YS, 1998, IEEE T MED IMAGING, V17, P383, DOI 10.1109/42.712128
   Menegaz G, 2002, IEEE T IMAGE PROCESS, V11, P1053, DOI 10.1109/TIP.2002.802525
   PEDROCHE F, 2002, WSEAS T MATH, V1, P67
   Pratap R., 2002, GETTING STARTED MATL
   Selivanov VV, 2001, IEEE T NUCL SCI, V48, P761, DOI 10.1109/23.940160
   SIGITANI T, 1999, PHYS MED BIOL, V44, P1565
   Walker J.S., 1999, ST ADV MATH
   Wu XL, 2005, IEEE T MED IMAGING, V24, P719, DOI 10.1109/TMI.2005.846858
   ZHU H, 2004, ANZIAM J, V45, pC1002
NR 19
TC 3
Z9 4
U1 0
U2 3
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 449
EP 457
DI 10.1016/j.imavis.2009.07.004
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300015
DA 2024-07-18
ER

PT J
AU Cárdenes, R
   Alberola-López, C
   Ruiz-Alzola, J
AF Cardenes, Ruben
   Alberola-Lopez, Carlos
   Ruiz-Alzola, Juan
TI Fast and accurate geodesic distance transform by ordered propagation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Distance transform; Geodesic distance transform; Geodesic metric; Hidden
   pixels; Ordered propagation; Visibility
ID ALGORITHMS; MAPS
AB In this paper, we present a new geodesic distance transform that uses a non-Euclidean metric suitable for non-convex discrete 2D domains. The geodesic metric used is defined as the shortest path length through a set of pixels called Locally Nearest Hidden Pixels, and manages visibility zones using bounding angles. The algorithm is designed using ordered propagation, which makes it extremely efficient and linear in the number of pixels in the domain. We have compared our algorithm with the four most similar geodesic distance transform techniques, and we show that our approach has higher accuracy and lower computational complexity. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Cardenes, Ruben; Alberola-Lopez, Carlos] Univ Valladolid, Lab Image Proc, E-47002 Valladolid, Spain.
   [Ruiz-Alzola, Juan] Univ Las Palmas Gran Canaria, Las Palmas Gran Canaria, Spain.
C3 Universidad de Valladolid; Universidad de Las Palmas de Gran Canaria
RP Cárdenes, R (corresponding author), Univ Valladolid, Lab Image Proc, E-47002 Valladolid, Spain.
EM ruben@lpi.tel.uva.es; caralb@tel.uva.es; jruiz@ctm.ulpgc.es
RI Ruiz-Alzola, Juan/R-6942-2019; Alberola-Lopez, Carlos/M-1582-2014
OI Ruiz-Alzola, Juan/0000-0002-3545-2328; Alberola-Lopez,
   Carlos/0000-0003-3684-0055
FU Comision Interministerial de Ciencia y Tecnologia [TEC
   2004-06647-C03-01, TEC 2007-67073/TCM]; Fondo de Investigaciones
   Sanitarias [PI-041483]; Junta de Castilla y Leon [VA075A05]; European
   Commission [FP6-507609]
FX The authors acknowledge the Comision Interministerial de Ciencia y
   Tecnologia for research grants TEC 2004-06647-C03-01 and TEC
   2007-67073/TCM, the Fondo de Investigaciones Sanitarias for grant
   PI-041483, the Junta de Castilla y Leon for grant VA075A05 and the
   European Commission for the funds associated to the Network of
   Excellence SIMILAR (FP6-507609). The first author also acknowledges Emma
   Munoz for her helpful comments about this work.
CR [Anonymous], 1996, LEVEL SET METHODS FA
   BORGEFORS G, 1986, COMPUT VISION GRAPH, V34, P344, DOI 10.1016/S0734-189X(86)80047-0
   CARDENES R, 2003, ICIP03, V1, P361
   Coeurjolly D, 2004, PATTERN RECOGN LETT, V25, P561, DOI 10.1016/j.patrec.2003.12.002
   Cohen LD, 1996, PROC CVPR IEEE, P666, DOI 10.1109/CVPR.1996.517144
   CUISENAIRE O, 1999, THESIS UCL
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   DESCHAMPS T, 2000, ECCV 00, P543
   Kimmel R, 1998, IEEE T ROBOTIC AUTOM, V14, P427, DOI 10.1109/70.678452
   Kimmel R, 1996, J MATH IMAGING VIS, V6, P223, DOI 10.1007/BF00119840
   KOVACSV ZM, 1995, PATTERN RECOGN, V28, P293, DOI 10.1016/0031-3203(94)00099-8
   LANTUEJOUL C, 1984, PATTERN RECOGN, V17, P177, DOI 10.1016/0031-3203(84)90057-8
   PIPER J, 1987, PATTERN RECOGN, V20, P599, DOI 10.1016/0031-3203(87)90030-6
   Pitas I, 2000, IEEE T IMAGE PROCESS, V9, P1185, DOI 10.1109/83.847832
   RAGNEMALM I, 1993, PATTERN RECOGN LETT, V14, P883, DOI 10.1016/0167-8655(93)90152-4
   Rettmann ME, 2000, IEEE WORKSHOP ON MATHEMATICAL METHODS IN BIOMEDICAL IMAGE ANALYSIS, PROCEEDINGS, P20, DOI 10.1109/MMBIA.2000.852356
   ROSENFELD A, 1968, PATTERN RECOGN, V1, P33, DOI 10.1016/0031-3203(68)90013-7
   SAITO T, 1994, PATTERN RECOGN, V27, P1551, DOI 10.1016/0031-3203(94)90133-3
   Srivastava S, 2003, LECT NOTES COMPUT SC, V2879, P488
   VERWER BJH, 1989, IEEE T PATTERN ANAL, V11, P425, DOI 10.1109/34.19041
   Warfield S, 1996, PATTERN RECOGN LETT, V17, P713, DOI 10.1016/0167-8655(96)00036-0
NR 21
TC 15
Z9 20
U1 0
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 307
EP 316
DI 10.1016/j.imavis.2009.05.013
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300003
DA 2024-07-18
ER

PT J
AU Li, SX
   Chang, HX
   Zhu, CF
AF Li, Shu-Xiao
   Chang, Hong-Xing
   Zhu, Cheng-Fei
TI Adaptive pyramid mean shift for global real-time visual tracking
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Global visual tracking; Fast mean shift; Adaptive level; Kernel-based
   tracking; Tracking and pointing subsystem
ID OBJECT TRACKING; MODE SEEKING; COLOR
AB Tracking objects in videos using the mean shift technique has attracted considerable attention. In this work, a novel approach for global target tracking based on mean shift technique is proposed. The proposed method represents the model and the candidate in terms of background weighted histogram and color weighted histogram, respectively, which can obtain precise object size adaptively with low computational complexity. To track targets whose displacements between two successive frames are relatively large, we implement the mean shift procedure via a coarse-to-fine way for global maximum seeking. This procedure is termed as adaptive pyramid mean shift, because it uses the pyramid analysis technique and can determine the pyramid level adaptively to decrease the number of iterations required to achieve convergence. Experimental results on various tracking videos and its application to a tracking and pointing subsystem show that the proposed method can successfully cope with different situations such as camera motion, camera vibration, camera zoom and focus, high-speed moving object tracking, partial occlusions, target scale variations, etc. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Li, Shu-Xiao; Chang, Hong-Xing; Zhu, Cheng-Fei] Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
C3 Chinese Academy of Sciences; Institute of Automation, CAS
RP Li, SX (corresponding author), Chinese Acad Sci, Inst Automat, Beijing, Peoples R China.
EM shower140@163.com
RI Yang, Jing/JFK-4046-2023
OI Yang, Jing/0009-0004-8274-9863
FU China 863 Programming [2007AA04Z233]
FX This work is supported by China 863 Programming (2007AA04Z233). The
   authors thank the anonymous reviewers for their constructive advice and
   for the revision of the paper.
CR Arulampalam MS, 2002, IEEE T SIGNAL PROCES, V50, P174, DOI 10.1109/78.978374
   Avidan S, 2001, PROC CVPR IEEE, P184
   Avidan S, 2007, IEEE T PATTERN ANAL, V29, P261, DOI 10.1109/TPAMI.2007.35
   Babu RV, 2007, IMAGE VISION COMPUT, V25, P1205, DOI 10.1016/j.imavis.2006.07.016
   Chen YQ, 2006, IEEE T PATTERN ANAL, V28, P1525, DOI 10.1109/TPAMI.2006.190
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   Collins RT, 2005, IEEE T PATTERN ANAL, V27, P1631, DOI 10.1109/TPAMI.2005.205
   Collins RT, 2003, PROC CVPR IEEE, P234
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2002, IEEE T PATTERN ANAL, V24, P603, DOI 10.1109/34.1000236
   Cui JS, 2008, IMAGE VISION COMPUT, V26, P240, DOI 10.1016/j.imavis.2007.05.005
   Dawoud A, 2006, IEEE T IMAGE PROCESS, V15, P404, DOI 10.1109/TIP.2005.860626
   Fashing M, 2005, IEEE T PATTERN ANAL, V27, P471, DOI 10.1109/TPAMI.2005.59
   Forsyth D. A., 2002, Computer vision: a modern approach, DOI DOI 10.5555/580035
   Georgescu B, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P456
   Guo YL, 2007, IEEE T PATTERN ANAL, V29, P824, DOI 10.1109/TPAMI.2007.1052
   Hall P, 2004, ANN STAT, V32, P2124, DOI 10.1214/009053604000000715
   Jeyakar J, 2008, COMPUT VIS IMAGE UND, V112, P296, DOI 10.1016/j.cviu.2008.05.005
   Jiang ZL, 2007, INT C WAVEL ANAL PAT, P1060
   Julier SJ, 1997, P SOC PHOTO-OPT INS, V3068, P182, DOI 10.1117/12.280797
   Khan Z, 2005, IEEE T PATTERN ANAL, V27, P1805, DOI 10.1109/TPAMI.2005.223
   Khan Z, 2006, IEEE T PATTERN ANAL, V28, P1960, DOI 10.1109/TPAMI.2006.247
   Kumar R, 2001, P IEEE, V89, P1518, DOI 10.1109/5.959344
   Leichter I, 2009, IEEE T PATTERN ANAL, V31, P164, DOI 10.1109/TPAMI.2008.194
   Liu TL, 2004, IEEE T PATTERN ANAL, V26, P397, DOI 10.1109/TPAMI.2004.1262335
   LIU YZ, 2003, CHIN J SHANGHAI JIAO, V37, P1957
   Rosten E, 2005, IEEE I CONF COMP VIS, P1508
   Shen CH, 2005, IEEE I CONF COMP VIS, P1516
   Shen CH, 2007, IEEE T IMAGE PROCESS, V16, P1457, DOI 10.1109/TIP.2007.894233
   Sun ZH, 2006, IEEE T PATTERN ANAL, V28, P694, DOI 10.1109/TPAMI.2006.104
   Wang JQ, 2008, IEEE T IMAGE PROCESS, V17, P235, DOI 10.1109/TIP.2007.914150
   [王民钢 WANG Mingang], 2005, [计算机仿真, Computer Simulation], V22, P50
   XU C, 2002, INTRO CALCULATION ME
   Xu XY, 2007, IEEE T IMAGE PROCESS, V16, P838, DOI 10.1109/TIP.2007.891074
   Yang CJ, 2005, IEEE I CONF COMP VIS, P212
   ZHANG F, 2002, CHIN J NANJING U SCI, V24, P376
NR 36
TC 41
Z9 61
U1 0
U2 23
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR
PY 2010
VL 28
IS 3
BP 424
EP 437
DI 10.1016/j.imavis.2009.06.012
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 537HG
UT WOS:000273103300013
DA 2024-07-18
ER

PT J
AU Campbell, NDF
   Vogiatzis, G
   Hernández, C
   Cipolla, R
AF Campbell, N. D. F.
   Vogiatzis, G.
   Hernandez, C.
   Cipolla, R.
TI Automatic 3D object segmentation in multiple views using volumetric
   graph-cuts
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Segmentation; Multiple view; Graph-cut
AB We propose an algorithm for automatically obtaining a segmentation of a rigid object in a sequence of images that are calibrated for camera pose and intrinsic parameters. Until recently, the best segmentation results have been obtained by interactive methods that require manual labelling of image regions. Our method requires no user input but instead relies on the camera fixating on the object of interest during the sequence. We begin by learning a model of the object's colour, from the image pixels around the fixation points. We then extract image edges and combine these with the object colour information in a volumetric binary MRF model. The globally optimal segmentation of 3D space is obtained by a graph-cut optimisation. From this segmentation an improved colour model is extracted and the whole process is iterated until convergence.
   Our first finding is that the fixation constraint, which requires that the object of interest is more or less central in the image, is enough to determine what to segment and initialise an automatic segmentation process. Second, we find that by performing a single segmentation in 3D, we implicitly exploit a 3D rigidity constraint, expressed as silhouette coherency, which significantly improves silhouette quality over independent 2D segmentations. We demonstrate the validity of our approach by providing segmentation results on real sequences. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Campbell, N. D. F.; Cipolla, R.] Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
   [Vogiatzis, G.; Hernandez, C.] Toshiba Res Europe, Cambridge CB4 0GZ, England.
C3 University of Cambridge; Toshiba Corporation
RP Campbell, NDF (corresponding author), Univ Cambridge, Dept Engn, Cambridge CB2 1PZ, England.
EM ndfc2@cam.ac.uk; george.vogiatzis@crl.toshiba.co.uk;
   carlos.hernandez@crl.toshiba.co.uk; cipolla@eng.cam.ac.uk
RI Arandjelović, Ognjen/V-5255-2019
OI Arandjelović, Ognjen/0000-0002-9314-194X; Vogiatzis,
   George/0000-0002-3226-0603; Cipolla, Roberto/0000-0002-8999-2151
FU Schiff Foundation; Toshiba Research Europe
FX This work is supported by the Schiff Foundation and Toshiba Research
   Europe.
CR Bishop Christopher M, 2006, PATTERN RECOGN, V128, P1
   Blake A, 2004, LECT NOTES COMPUT SC, V3021, P428
   Boykov Y, 2006, INT J COMPUT VISION, V70, P109, DOI 10.1007/s11263-006-7934-5
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Esteban CH, 2004, COMPUT VIS IMAGE UND, V96, P367, DOI 10.1016/j.cviu.2004.03.016
   Hartley R, 2003, MULTIPLE VIEW GEOMET, DOI 10.1016/S0143-8166(01)00145-2
   Hernández C, 2007, IEEE T PATTERN ANAL, V29, P343, DOI 10.1109/TPAMI.2007.42
   Kolmogorov V, 2004, IEEE T PATTERN ANAL, V26, P147, DOI 10.1109/TPAMI.2004.1262177
   Lee W, 2007, LECT NOTES COMPUT SC, V4844, P580
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Martínez AM, 2004, COMPUT VIS IMAGE UND, V95, P72, DOI 10.1016/j.cviu.2004.01.003
   Rother C, 2004, ACM T GRAPHIC, V23, P309, DOI 10.1145/1015706.1015720
   Seitz S.M., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI https://doi.org/10.1109/CVPR.2006.19
   Snow D, 2000, PROC CVPR IEEE, P345, DOI 10.1109/CVPR.2000.855839
   TAALEBINEZHAAD MA, 1992, IEEE T PATTERN ANAL, V14, P847, DOI 10.1109/34.149584
   Vogiatzis G, 2005, PROC CVPR IEEE, P391
   Xu N, 2003, PROC CVPR IEEE, P46
   Yezzi A, 2003, INT J COMPUT VISION, V53, P31, DOI 10.1023/A:1023079624234
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
NR 19
TC 40
Z9 94
U1 0
U2 16
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JAN
PY 2010
VL 28
IS 1
BP 14
EP 25
DI 10.1016/j.imavis.2008.09.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 534KK
UT WOS:000272895000003
OA Green Submitted, Green Accepted
DA 2024-07-18
ER

PT J
AU Mak, KL
   Peng, P
   Yiu, KFC
AF Mak, K. L.
   Peng, P.
   Yiu, K. F. C.
TI Fabric defect detection using morphological filters
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Gabor wavelet network; Morphological filter; Defect detection; Quality
   control; Textile fabrics
ID AUTOMATED INSPECTION; FLAW DETECTION; TEXTILE; SYSTEM
AB In this paper, a novel defect detection scheme based on morphological filters is proposed to tackle the problem of automated defect detection for woven fabrics. In the proposed scheme, important texture features of the textile fabric are extracted using a pre-trained Gabor wavelet network. These texture features are then used to facilitate the construction of structuring elements in subsequent morphological processing to remove the fabric background and isolate the defects. Since the proposed defect detection scheme requires a few morphological filters only, the amount of computational load involved is not significant. The performance of the proposed scheme is evaluated by using a wide variety of homogeneous textile images with different types of common fabric defects. The test results obtained exhibit accurate defect detection with low false alarms, thus showing the effectiveness and robustness of the proposed detection scheme. In addition, the proposed detection scheme is further evaluated in real time by using a prototyped automated inspection system. (C) 2009 Elsevier B.V. All rights reserved.
C1 [Mak, K. L.; Peng, P.; Yiu, K. F. C.] Univ Hong Kong, Dept Ind & Mfg Syst Engn, Hong Kong, Hong Kong, Peoples R China.
C3 University of Hong Kong
RP Mak, KL (corresponding author), Univ Hong Kong, Dept Ind & Mfg Syst Engn, Pokfulam Rd, Hong Kong, Hong Kong, Peoples R China.
EM makkl@hkucc.hku.hk
RI Yiu, Cedric Ka Fai/C-1784-2009
OI Yiu, K.F.C./0000-0002-7523-4069
FU Hong Kong Special Administrative Region, China [HKU7382/02E]
FX The work described in this paper was supported by a grant from the
   research Grants Council of the Hong Kong Special Administrative Region,
   China (Project No. HKU7382/02E). The authors would also like to thank
   the reviewers for their helpful suggestions and constructive comments on
   the earlier versions of the paper.
CR [Anonymous], INT J COMPUT SCI
   [Anonymous], 1967, Elements pour une theorie des milieux poreux
   [Anonymous], THESIS C ALBRECHT U
   [Anonymous], DAGM S GERM
   Bodnarova A, 2000, PATTERN ANAL APPL, V3, P254, DOI 10.1007/s100440070010
   Bodnarova A, 2002, PATTERN RECOGN, V35, P2973, DOI 10.1016/S0031-3203(02)00017-1
   Bodnarova A, 1997, TENCON IEEE REGION, P307, DOI 10.1109/TENCON.1997.647318
   Bodnarova A, 1998, IEEE SYS MAN CYBERN, P4423, DOI 10.1109/ICSMC.1998.727546
   Campbell JG, 1998, OPT ENG, V37, P2536, DOI 10.1117/1.601692
   Campbell JG, 1997, PATTERN RECOGN LETT, V18, P1539, DOI 10.1016/S0167-8655(97)00148-7
   Campbell JG, 1999, INT J IMAG SYST TECH, V10, P339, DOI 10.1002/(SICI)1098-1098(1999)10:4<339::AID-IMA5>3.0.CO;2-3
   Chan CH, 2000, IEEE T IND APPL, V36, P1267, DOI 10.1109/28.871274
   Chetverikov D, 2002, PATTERN RECOGN, V35, P2165, DOI 10.1016/S0031-3203(01)00188-1
   Cho CS, 2005, IEEE T IND ELECTRON, V52, P1073, DOI 10.1109/TIE.2005.851648
   DOCKERY A, 2001, AUTOMATED FABRIC INS
   DORRITY JL, 1998, PROCESS FABRIC DEFEC
   Escofet J, 1998, OPT ENG, V37, P2297, DOI 10.1117/1.601751
   Gonzalez R. C., 2006, Digital Image Processing, V3rd
   *GRAN CO, 1975, MAN STAND FABR DEF T
   Jasper WJ, 1996, OPT ENG, V35, P3140, DOI 10.1117/1.601054
   Krüger V, 2002, IMAGE VISION COMPUT, V20, P665, DOI 10.1016/S0262-8856(02)00056-2
   Kumar A, 2003, PATTERN RECOGN, V36, P1645, DOI 10.1016/S0031-3203(03)00005-0
   Kumar A, 2002, IEEE T SYST MAN CY B, V32, P553, DOI 10.1109/TSMCB.2002.1033176
   Kumar A, 2000, OPT ENG, V39, P3176, DOI 10.1117/1.1327837
   Lane J.S., 1998, U.S. Patent, Patent No. [5,774,177, 5774177]
   Mak KL, 2008, ROBOT CIM-INT MANUF, V24, P359, DOI 10.1016/j.rcim.2007.02.019
   Muller S., 1994, P SOC PHOTO-OPT INS, V2249, P298
   Ozdemir S., 1996, P IEEE C EM TECHN FA, V2, P697
   Saeidi RG, 2005, TEXT RES J, V75, P492, DOI 10.1177/0040517505053874
   Sari-Sarraf H, 1999, IEEE T IND APPL, V35, P1252, DOI 10.1109/28.806035
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   SRINIVASAN K, 1992, J TEXT I, V83, P431, DOI 10.1080/00405009208631217
   Tsai DM, 1999, IMAGE VISION COMPUT, V18, P49, DOI 10.1016/S0262-8856(99)00009-8
   WANG J, 1995, P SOC PHOTO-OPT INS, V2345, P180, DOI 10.1117/12.198873
   Young IT, 1998, ELEC ENG HANDB SER, P511
   ZHANG QG, 1992, IEEE T NEURAL NETWOR, V3, P889, DOI 10.1109/72.165591
   ZHANG YXF, 1995, TEXT RES J, V65, P1, DOI 10.1177/004051759506500101
NR 37
TC 163
Z9 198
U1 4
U2 72
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD SEP 2
PY 2009
VL 27
IS 10
BP 1585
EP 1592
DI 10.1016/j.imavis.2009.03.007
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 475YO
UT WOS:000268403800015
DA 2024-07-18
ER

PT J
AU Tsai, CY
   Song, KT
AF Tsai, Chi-Yi
   Song, Kai-Tai
TI Dynamic visual tracking control of a mobile robot with image noise and
   occlusion robustness
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Visual interaction model; Visual tracking control; Visual state
   estimation; Nonholonomic mobile robots; Temporary partial/full occlusion
ID UNIFIED APPROACH; MOVING TARGET; SERVO CONTROL
AB This paper presents a robust visual tracking control design for a nonholonomic mobile robot equipped with a tilt camera. This design aims to allow the mobile robot to keep track of a dynamic moving target in the camera's field-of-view; even though the target is temporarily fully occluded. To achieve this, a control system consisting of a visual tracking controller (VTC) and a visual state estimator (VSE) is proposed. A novel visual interaction model is derived to facilitate the design of VTC and VSE. The VSE is responsible for estimating the optimal target state and target image velocity in the image space. The VTC then calculates the corresponding command velocities for the mobile robot to work in the world coordinates. The proposed VSE not only possesses robustness against the image noise, but also overcomes the temporary occlusion problem. Computer simulations and practical experiments of a mobile robot to track a moving target have been carried out to validate the performance and robustness of the proposed system. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Tsai, Chi-Yi; Song, Kai-Tai] Natl Chiao Tung Univ, Dept Elect & Control Engn, Hsinchu 300, Taiwan.
C3 National Yang Ming Chiao Tung University
RP Tsai, CY (corresponding author), Natl Chiao Tung Univ, Dept Elect & Control Engn, 1001 Hsueh Rd, Hsinchu 300, Taiwan.
EM chiyi.ece91g@nctu.edu.tw; ktsong@mail.nctu.edu.tw
RI Tsai, Chi-Yi/AFJ-8560-2022; Tsai, Chi-Yi/AAT-2837-2021
OI Tsai, Chi-Yi/0000-0001-9872-4338; Tsai, Chi-Yi/0000-0001-9872-4338
FU Ministry of Economic Affairs [95-EC-17-A-04-SI-054]; National Science
   Council of Taiwan, ROC [NSC 95-2218-E-009-024]
FX The authors thank Fu-Sheng Huang, Chen-Yang Lin, and Chun-Wei Chen for
   their assistance in the experiments. This work was supported by the
   Ministry of Economic Affairs under Grant 95-EC-17-A-04-SI-054 and the
   National Science Council of Taiwan, ROC under Grant NSC
   95-2218-E-009-024.
CR Borgstadt J. A., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P3189, DOI 10.1109/ROBOT.2000.845154
   Bradski G.R., 1998, INTEL TECHNOLOGY J, P15
   Chaumette F, 2007, IEEE ROBOT AUTOM MAG, V14, P109, DOI 10.1109/MRA.2007.339609
   Chaumette F, 2006, IEEE ROBOT AUTOM MAG, V13, P82, DOI 10.1109/MRA.2006.250573
   Chen YW, 2006, TRENDS GENET, V22, P416, DOI 10.1016/j.tig.2006.06.008
   Comport AI, 2006, IEEE T ROBOT, V22, P416, DOI 10.1109/TRO.2006.870666
   Coulaud JB, 2006, IEEE T ROBOT, V22, P1062, DOI 10.1109/TRO.2006.878934
   Das AK, 2002, IEEE T ROBOTIC AUTOM, V18, P813, DOI 10.1109/TRA.2002.803463
   Fang YC, 2005, IEEE T SYST MAN CY B, V35, P1041, DOI 10.1109/TSMCB.2005.850155
   Freda L, 2007, ROBOT AUTON SYST, V55, P419, DOI 10.1016/j.robot.2007.02.001
   GROSKY WI, 1990, IEEE T PATTERN ANAL, V12, P663, DOI 10.1109/34.56209
   Han Y, 2005, ROBOT AUTON SYST, V53, P265, DOI 10.1016/j.robot.2005.09.005
   Hutchinson S, 1996, IEEE T ROBOTIC AUTOM, V12, P651, DOI 10.1109/70.538972
   Lee TC, 2004, IEEE T CONTR SYST T, V12, P661, DOI 10.1109/TCST.2004.826964
   López-Nicolás G, 2008, ROBOT AUTON SYST, V56, P592, DOI 10.1016/j.robot.2007.10.005
   Ma Y, 1999, IEEE T ROBOTIC AUTOM, V15, P521, DOI 10.1109/70.768184
   Malis E, 2005, ROBOT AUTON SYST, V52, P39, DOI 10.1016/j.robot.2005.03.014
   Mariottini GL, 2006, IEEE INT CONF ROBOT, P538, DOI 10.1109/ROBOT.2006.1641766
   Mariottini GL, 2007, IEEE T ROBOT, V23, P87, DOI 10.1109/TRO.2006.886842
   SCHUTTER JD, 1999, JOURNAL A, V40, P52
   Slotine J.-J. E., 1991, APPL NONLINEAR CONTR, V199
   Tsai C. F., 2007, P IEEE INT S COMP IN, P161
   Vidal R, 2004, IEEE ROBOT AUTOM MAG, V11, P14, DOI 10.1109/MRA.2004.1371604
   Wang HY, 2001, IROS 2001: PROCEEDINGS OF THE 2001 IEEE/RJS INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P1, DOI 10.1109/IROS.2001.973327
   Zhang H, 2002, IEEE T ROBOTIC AUTOM, V18, P199, DOI 10.1109/TRA.2002.999648
   [No title captured]
   [No title captured]
   [No title captured]
   [No title captured]
NR 29
TC 11
Z9 12
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUL 2
PY 2009
VL 27
IS 8
BP 1007
EP 1022
DI 10.1016/j.imavis.2008.08.011
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 467FJ
UT WOS:000267723000003
DA 2024-07-18
ER

PT J
AU Emms, D
   Wilson, RC
   Hancock, ER
AF Emms, David
   Wilson, Richard C.
   Hancock, Edwin R.
TI Graph matching using the interference of discrete-time quantum walks
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 6th International Workshop on Graph-Based Representations in Pattern
   Recognition
CY JUN 11-13, 2007
CL Alicante, SPAIN
SP IAPR TC15, Univ Alicante, Robot Vis Grp, Pattern Anal, Stat Modelling & Computat Learning, European Excellence Network, Generalitat Valenciana, Dept Co, Univ & Sci, UA, Off Extracurricular Activities, UA, Inst Informat Res, Alicante Convent Bur, Patronato Municipal Turismo, UA, Dept Comp Sci & Artificial Intelligence, UA, Off Res, Dept & Innovat
DE Graph matching; Discrete time quantum walk; Auxiliary structure;
   Interference amplitude; Probabilistic model
ID EDIT DISTANCE; ALGORITHM
AB In this paper, we consider how discrete-time quantum walks can be applied to graph-matching problems. The matching problem is abstracted using an auxiliary graph that connects pairs of vertices from the graphs to be matched by way of auxiliary vertices. A discrete-time quantum walk is simulated on this auxiliary graph and the quantum interference on the auxiliary vertices indicates possible matches. When dealing with graphs for which there is no exact match, the interference amplitudes together with edge consistencies are used to define a consistency measure. We also explore the use of the method for inexact graph-matching problems. We have tested the algorithm on graphs derived from the NCI molecule database and found it to significantly reduce the space of possible permutation matchings, typically by a factor of 10(-20)-10(-30), thereby allowing the graphs to be matched directly. An analysis of the quantum walk in the presence of structural errors between graphs is used as the basis of the consistency measure. We test the performance of this measure on graphs derived from images in the COIL-100 database. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Emms, David; Wilson, Richard C.; Hancock, Edwin R.] Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
C3 University of York - UK
RP Hancock, ER (corresponding author), Univ York, Dept Comp Sci, York YO10 5DD, N Yorkshire, England.
EM erh@cs.york.ac.uk
RI Hancock, Edwin/N-7548-2019
OI Hancock, Edwin/0000-0003-4496-2028; Emms, David/0000-0002-9065-8978
CR Ambainis A, 2003, INT J QUANTUM INF, V1, P507, DOI 10.1142/S0219749903000383
   [Anonymous], 200043 DIMACS
   [Anonymous], 2003, STOC 03
   [Anonymous], CONDMAT0209112
   [Anonymous], QUANTUM INFORM COMPU
   [Anonymous], 1982, STOC 82PROCEEDINGS 1
   [Anonymous], PHYS REV A
   [Anonymous], PHYS REV A
   [Anonymous], MARKOV CHAIN APPROAC
   [Anonymous], CONSTRUCTING PHYSICA
   [Anonymous], 1996, Citeseer
   [Anonymous], 2006, ADV NEURAL INFORM PR
   [Anonymous], J PHYS A
   [Anonymous], P 4 ALV VIS C, DOI DOI 10.5244/C.2.23
   [Anonymous], STOC 01
   [Anonymous], PATTERN ANAL MACH IN
   [Anonymous], 2009, QUANTUM INF COMPUT
   [Anonymous], SIAM J COMPUT
   [Anonymous], P ECCV
   [Anonymous], 2000, Quantum computing and quantum information
   [Anonymous], CIE
   [Anonymous], P ROY SOC LONDON
   [Anonymous], 1974, P 6 ANN ACM S THEORY
   [Anonymous], ICML
   [Anonymous], 2003, LECT NOTES COMPUTER
   [Anonymous], AI STAT AISTATS
   [Anonymous], 2001, PROC 33 ACM SOTC
   [Anonymous], PATTERN RECOGNITION
   [Anonymous], 2007, ABS07110189 CORR
   [Anonymous], 1993, Combinatorics, Paul Erdos is Eighty
   [Anonymous], BIOINFORMATICS
   Barrow H. G., 1971, Machine Intelligence Volume 6, P377
   Barrow H. G., 1976, Information Processing Letters, V4, P83, DOI 10.1016/0020-0190(76)90049-1
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Bunke H, 1997, PATTERN RECOGN LETT, V18, P689, DOI 10.1016/S0167-8655(97)00060-3
   Childs AM, 2002, QUANTUM INF PROCESS, V1, P35, DOI 10.1023/A:1019609420309
   CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565
   Cirac JI, 1997, PHYS REV LETT, V78, P3221, DOI 10.1103/PhysRevLett.78.3221
   Doyle P.G., 1984, Random Walks and Electric Networks, V22
   ESHERA MA, 1984, IEEE T SYST MAN CYB, V14, P398, DOI 10.1109/TSMC.1984.6313232
   FISCHLER MA, 1973, IEEE T COMPUT, VC 22, P67, DOI 10.1109/T-C.1973.223602
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   Gori M, 2005, IEEE T PATTERN ANAL, V27, P1100, DOI 10.1109/TPAMI.2005.138
   Grady L, 2006, IEEE T PATTERN ANAL, V28, P1768, DOI 10.1109/TPAMI.2006.233
   Grover L. K., 1996, P 28 ANN ACM S THEOR, P212, DOI [DOI 10.1145/237814.237866, 10.1145/237814.237866]
   HORAUD R, 1989, IEEE T PATTERN ANAL, V11, P1168, DOI 10.1109/34.42855
   Kempe J, 2003, CONTEMP PHYS, V44, P307, DOI 10.1080/00107151031000110776
   Kuhn HW, 2005, NAV RES LOG, V52, P7, DOI 10.1002/nav.20053
   Kwiat PG, 2000, J MOD OPTIC, V47, P257, DOI 10.1080/095003400148187
   Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602
   McKay B., 1981, CONGR NUMERANTIUM, V30, P45
   MILNE GWA, 1994, J CHEM INF COMP SCI, V34, P1219, DOI 10.1021/ci00021a032
   Miyazaki T., 1997, DIMACS SERIES DISCRE, V28, P239
   Neuhaus M, 2006, LECT NOTES COMPUT SC, V4109, P191
   Norris J. R., 1998, MARKOV CHAINS
   Robles-Kelly A, 2005, IEEE T PATTERN ANAL, V27, P365, DOI 10.1109/TPAMI.2005.56
   Robles-Kelly A, 2004, INT J PATTERN RECOGN, V18, P315, DOI 10.1142/S0218001404003277
   Robles-Kelly A, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P234
   SANFELIU A, 1983, IEEE T SYST MAN CYB, V13, P353, DOI 10.1109/TSMC.1983.6313175
   SHAPIRO LG, 1982, IEEE T PATTERN ANAL, V4, P595, DOI 10.1109/TPAMI.1982.4767312
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925
   Wilson RC, 1997, IEEE T PATTERN ANAL, V19, P634, DOI 10.1109/34.601251
NR 63
TC 15
Z9 18
U1 1
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD JUN 4
PY 2009
VL 27
IS 7
SI SI
BP 934
EP 949
DI 10.1016/j.imavis.2008.10.013
PG 16
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 450ID
UT WOS:000266393300011
DA 2024-07-18
ER

PT J
AU Hanbury, A
   Marcotegui, B
AF Hanbury, Allan
   Marcotegui, Beatriz
TI Morphological segmentation on learned boundaries
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE Image segmentation; Watershed; Waterfall; Normalised cuts; Segmentation
   evaluation; Volume extinction values
AB Colour information is usually not enough to segment natural complex scenes. Texture contains relevant information that segmentation approaches should consider. Martin et al. [Learning to detect natural image boundaries using local brightness, color, and texture cues, IEEE Transactions on Pattern Analysis and Machine Intelligence 26 (5) (2004) 530-549] proposed a particularly interesting colour-texture gradient. This gradient is not suitable for Watershed-based approaches because it contains gaps. In this paper, we propose a method based on the distance function to fill these gaps. Then, two hierarchical Watershed-based approaches, the Watershed using volume extinction values and the Waterfall, are used to segment natural complex scenes.
   Resulting segmentations are thoroughly evaluated and compared to segmentations produced by the Normalised Cuts algorithm using the Berkeley segmentation dataset and benchmark. Evaluations based on both the area overlap and boundary agreement with manual segmentations are performed. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Hanbury, Allan] Inst Comp Aided Automat, Pattern Recognit & Image Proc Grp PRIP, A-1040 Vienna, Austria.
   [Marcotegui, Beatriz] Ecole Mines Paris, Ctr Morphol Math, F-77305 Fontainebleau, France.
C3 Universite PSL; MINES ParisTech
RP Hanbury, A (corresponding author), Inst Comp Aided Automat, Pattern Recognit & Image Proc Grp PRIP, Favoritenstr 9-1832, A-1040 Vienna, Austria.
EM hanbury@prip.tuwien.ac.at; marcoteg@cmm.ensmp.fr
FU Austrian Science Foundation (FWF) SESAME [P17189-N04]; European Union
   Network of Excellence MUSCLE [FP6-507752]; Austrian Science Fund (FWF)
   [P17189] Funding Source: Austrian Science Fund (FWF)
FX This work was supported by the Austrian Science Foundation (FWF) under
   grant SESAME (P17189-N04) and the European Union Network of Excellence
   MUSCLE (FP6-507752). The area-based error measure code was written by
   Adrian Ion and Branislav Micusik.
CR Barnard K, 2003, J MACH LEARN RES, V3, P1107, DOI 10.1162/153244303322533214
   Beucher S, 1994, COMP IMAG VIS, V2, P69
   Beucher S., 2018, Mathematical Morphology in Image Processing, P433
   Beucher S, 2007, IMAGE VISION COMPUT, V25, P405, DOI 10.1016/j.imavis.2006.07.020
   Carbonetto P, 2004, LECT NOTES COMPUT SC, V3021, P350
   Chen YX, 2004, J MACH LEARN RES, V5, P913
   HANBURY A, 2006, P AS C COMP VIS ACCV, P888
   Jiang XY, 2006, EURASIP J APPL SIG P, DOI 10.1155/ASP/2006/35909
   LANTUEJOUL C, 1981, J MICROSC-OXFORD, V121, P39, DOI 10.1111/j.1365-2818.1981.tb01197.x
   LEUNG T, 1998, P 5 EUR C COMP VIS, P544
   Malik J, 2001, INT J COMPUT VISION, V43, P7, DOI 10.1023/A:1011174803800
   Marcotegui B, 2005, COMPUT IMAGING VIS, V30, P177
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martin DR, 2004, IEEE T PATTERN ANAL, V26, P530, DOI 10.1109/TPAMI.2004.1273918
   Meyer F, 2001, INT J PATTERN RECOGN, V15, P1089, DOI 10.1142/S0218001401001337
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Soille P., 2002, Morphological Image Analysis: Principles and Applications, Vsecond
   VACHIER C, 1995, P IEEE WORKSH NONL S, P254
NR 18
TC 15
Z9 15
U1 0
U2 19
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2009
VL 27
IS 4
BP 480
EP 488
DI 10.1016/j.imavis.2008.06.012
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 400TN
UT WOS:000262891600018
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Wu, YG
   Wu, CH
AF Wu, Yung-Gi
   Wu, Chia-Hao
TI Image vector quantization codec indices recovery using Lagrange
   interpolation
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE vector quantization; image communication; Lagrange interpolation; index
   recovery
AB Vector quantization (VQ) which has been widely used in the field of video and image coding is an efficient coding algorithm due to its fast decoding efficiency. Sometimes, the indices of VQ will be lost because of the signal interference during the transmission. In this paper, we propose an efficient estimation method by using the Lagrange interpolation formula to conceal and recover the lost indices on the decoder side instead of re-transmitting the whole image again. If the image OF video has the limitation of the period of validity, re-transmitting the data wastes of time and occupies the network bandwidth. Therefore, using the received correct data to estimate and recover the lost data is efficient in time constraint situation such as network conference or mobile transmission. For nature images, the pixels with its neighbors are correlative and VQ partitions the image into sub-blocks and quantize them to form the indices to transmit, the correlation between adjacent indices is very strong as well. There are two parts of the proposed method. The first one is preprocessing and the other is the estimation process. In preprocessing, we modify the order of code-vectors in the VQ codebook to increases the correlation among the neighboring vectors. In the second part, using the Lagrange interpolation formula to constitute a polynomial to describe the tendency of VQ indices and use the polynomial to estimate the lost VQ indices on the decoder side. Using conventional VQ to compress Lenna and transmit without any index lost can achieve the PSNR of 30.154 dB on the decoder. The simulation results demonstrate that our method can efficient estimate the indices to achieve the PSNR value of 28.418 dB when the lost rate is 5% and 29.735 dB at the lost rate of 1%. (C) 2008 Elsevier B.V. All rights reserved.
C1 [Wu, Yung-Gi] Leader Univ, Dept Comp Sci & Informat Engn, Tainan 709, Taiwan.
   [Wu, Chia-Hao] Leader Univ, Inst Appl Informat, Tainan 709, Taiwan.
RP Wu, YG (corresponding author), Leader Univ, Dept Comp Sci & Informat Engn, 188 Sec 5,An Chung Rd, Tainan 709, Taiwan.
EM wyg@mail.leader.edu.tw
CR Abramowitz M., 1972, HDB MATH FUNCTIONS F, p[878, 883]
   [Anonymous], 1988, 9011 METHODS MATH PH
   [Anonymous], 1996, Techniques and standards for image, video, and audio coding
   Gersho A., 2003, Vector Quantization and Signal Compression
   Hung KL, 2003, SIGNAL PROCESS, V83, P431, DOI 10.1016/S0165-1684(02)00394-8
   Hung KL, 1999, IEEE T CONSUM ELECTR, V45, P1190, DOI 10.1109/30.809208
   Kuo CJ, 1999, IEEE T IMAGE PROCESS, V8, P33, DOI 10.1109/83.736682
   LEE XB, 1995, IEEE T IMAGE PROCESS, V4, P259, DOI 10.1109/83.366475
   LINDE Y, 1980, IEEE T COMMUN, V28, P84, DOI 10.1109/TCOM.1980.1094577
   NASRABADI NM, 1988, IEEE T COMMUN, V36, P957, DOI 10.1109/26.3776
   Sayood K, 2017, Introduction to data compression
   Wang Y, 1998, P IEEE, V86, P974, DOI 10.1109/5.664283
   Wu YG, 2004, J ELECTRON IMAGING, V13, P324, DOI 10.1117/1.1666877
   Wu YG, 2007, OPT ENG, V46, DOI 10.1117/1.2768066
   ZEGER K, 1990, IEEE T COMMUN, V38, P2147, DOI 10.1109/26.64657
   Zeng WJ, 1996, IEEE T CIRC SYST VID, V6, P108, DOI 10.1109/76.486425
NR 16
TC 5
Z9 5
U1 0
U2 4
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2008
VL 26
IS 8
BP 1171
EP 1177
DI 10.1016/j.imavis.2008.02.007
PG 7
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 324QE
UT WOS:000257532300011
DA 2024-07-18
ER

PT J
AU Cao, L
   Bao, P
   Shi, Z
AF Cao, Li
   Bao, Paul
   Shi, Zhongke
TI The strongest schema learning GA and its application to multilevel
   thresholding
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE multilevel thresholding; Otsu method; Kapur method; genetic algorithms;
   schema
ID IMAGE SEGMENTATION; GENETIC ALGORITHMS; ENTROPY; HISTOGRAM
AB The multilevel thresholding segmentation methods often outperform the bi-level methods. However, their computational complexity will also grow exponentially as the threshold number increases due to the exhaustive search. Genetic algorithms (GAs) can accelerate the optimization calculation but suffer drawbacks such as slow convergence and easy to trap into local optimum. Extracting from several highest performance strings, a strongest scheme can be obtained. With the low performance strings learning from it with a certain probability, the average-fitness of each generation can increase and the computational time will improve. On the other hand, the learning program can also improve the population diversity. This will enhance the stability of the optimization calculation. Experiment results showed that it was very effective for multilevel thresholding. (C) 2007 Elsevier B.V. All rights reserved.
C1 [Cao, Li] Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Jiangsu 210016, Peoples R China.
   [Cao, Li; Bao, Paul] Univ S Florida, Dept Informat Technol, Tampa, FL 33620 USA.
   [Shi, Zhongke] Northwestern Polytech Univ, Dept Automat Control, Xian 710072, Peoples R China.
C3 Nanjing University of Aeronautics & Astronautics; State University
   System of Florida; University of South Florida; Northwestern
   Polytechnical University
RP Cao, L (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Civil Aviat, Jiangsu 210016, Peoples R China.
EM caoli@nuaa.edu.cn; pbao@lakeland.usf.edu; zkeshi@nwpu.edu.cn
CR Bhandarkar SM, 1999, IEEE T EVOLUT COMPUT, V3, P1, DOI 10.1109/4235.752917
   Chan FHY, 1998, IEEE T IMAGE PROCESS, V7, P468, DOI 10.1109/83.661196
   DAVIES KE, 1981, HUMAN GENET, V58, P251
   Digalakis JG, 2002, INT J COMPUT MATH, V79, P403, DOI 10.1080/00207160210939
   Goldberg D. E., 1992, Complex Systems, V6, P333
   Ho SY, 2003, J VLSI SIG PROC SYST, V35, P29, DOI 10.1023/A:1023331803664
   KAPUR JN, 1985, COMPUT VISION GRAPH, V29, P273, DOI 10.1016/0734-189X(85)90125-2
   Lai CC., 2004, INT J HYBRID INTELL, V1, P143
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   PAL NR, 1993, PATTERN RECOGN, V26, P1277, DOI 10.1016/0031-3203(93)90135-J
   PUN T, 1980, SIGNAL PROCESS, V2, P223, DOI 10.1016/0165-1684(80)90020-1
   RUDOLPH G, 1994, IEEE T NEURAL NETWOR, V5, P96, DOI 10.1109/72.265964
   SAHOO PK, 1988, COMPUT VISION GRAPH, V41, P233, DOI 10.1016/0734-189X(88)90022-9
   Tao WB, 2003, PATTERN RECOGN LETT, V24, P3069, DOI 10.1016/S0167-8655(03)00166-1
   TSAI WH, 1985, COMPUT VISION GRAPH, V29, P377, DOI 10.1016/0734-189X(85)90133-1
   YEN JC, 1995, IEEE T IMAGE PROCESS, V4, P370, DOI 10.1109/83.366472
   Yin PY, 1999, SIGNAL PROCESS, V72, P85, DOI 10.1016/S0165-1684(98)00167-4
   Yin PY, 1997, SIGNAL PROCESS, V60, P305, DOI 10.1016/S0165-1684(97)00080-7
NR 18
TC 39
Z9 46
U1 1
U2 11
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAY 1
PY 2008
VL 26
IS 5
BP 716
EP 724
DI 10.1016/j.imavis.2007.08.007
PG 9
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 284DU
UT WOS:000254686900011
DA 2024-07-18
ER

PT J
AU Heseltine, T
   Pears, N
   Austin, J
AF Heseltine, Thomas
   Pears, Nick
   Austin, Jim
TI Three-dimensional face recognition using combinations of surface feature
   map subspace components
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 15th Annual British Machine Vision Conference (BMVC 2004)
CY SEP, 2004
CL Kingston Univ, London, ENGLAND
SP British Machine Vis Assoc
HO Kingston Univ
DE face recognition; three-dimensional; depth map; range data;
   multi-feature; subspace combinations
AB In this paper, we show the effect of using a variety of facial surface feature maps within the Fishersurface technique, which uses linear discriminant analysis, and suggest a method of identifying and extracting useful qualities offered by each surface feature map. Combining these multi-feature subspace components into a unified surface subspace, we create a three-dimensional face recognition system producing significantly lower error rates than individual surface feature map systems tested on the same data. We evaluate systems by performing up to 1,079,715 verification operations on a large test set of 3D face models. Results are presented in the form of false acceptance and false rejection rates, generated by varying a decision threshold applied to a distance metric in surface space. (c) 2007 Published by Elsevier B.V.
C1 [Heseltine, Thomas; Pears, Nick; Austin, Jim] Univ York, Dept Comp Sci, Adv Comp Architecture Grp, York YO10 5DD, N Yorkshire, England.
C3 University of York - UK
RP Heseltine, T (corresponding author), Univ York, Dept Comp Sci, Adv Comp Architecture Grp, York YO10 5DD, N Yorkshire, England.
EM tomh@cs.york.ac.uk
CR [Anonymous], 1994, IEEE C COMP VIS PATT
   [Anonymous], 3D FAC DAT
   Belhumeur P.N., 1996, P EUR C COMP VIS
   Beumier C, 2000, IMAGE VISION COMPUT, V18, P315, DOI 10.1016/S0262-8856(99)00052-9
   BEUMIER C, 2000, 11 PORT C PATT REC
   Blanz V., 2002, P 5 IEEE C AUT FAC G
   GORDON G, 1992, P IEEE C COMP VIS PA
   HESELTINE T, 2004, P SPIE DEF SEC S
   HESELTINE T, 2004, P INT C IM PROC
   HESELTINE T, 2004, P INT C IM AN REC
   HESHER C, 2002, P CISST
   Phillips P., 2003, FRVT 2002: Overview and summary
   ROMDHANI S, 2002, EUR C COMP VIS
   ZHAO W, 2000, P INT C IM PROC
NR 14
TC 36
Z9 41
U1 0
U2 8
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD MAR 3
PY 2008
VL 26
IS 3
BP 382
EP 396
DI 10.1016/j.imavis.2006.12.008
PG 15
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 248ZR
UT WOS:000252196500007
DA 2024-07-18
ER

PT J
AU Anelli, M
   Cinque, L
   Sangineto, E
AF Anelli, M.
   Cinque, L.
   Sangineto, Enver
TI Deformation tolerant generalized Hough transform for sketch-based image
   retrieval in complex scenes
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE content-based image retrieval; generalized hough transform; unsegmented
   images; query by sketch; object recognition
ID MODEL
AB Sketch-based image retrieval systems need to handle two main problems. First of all, they have to recognize shapes similar but not necessarily identical to the user's query. Hence, exact object identification techniques do not fit in this case. The second problem is the selection of the image features to compare with the user's sketch. In domain-independent visual repositories, real-life images with non-uniform background and possible occluding objects make this second task particularly hard. We address the second problem proposing a variant of the well-known Generalized Hough Transform (GHT), which is a robust object identification technique for unsegmented images. Moreover, we solve the first problem modifying the GHT to deal with an inexact matching problem. In this paper, we show how this idea can be efficiently and accurately realized. Experimental results are shown with two different databases of real, unsegmented images. (c) 2007 Elsevier B.V. All rights reserved.
C1 Elettr SPA, Rome, Italy.
   Univ Roma La Sapienza, Dipartimento Informat, I-00198 Rome, Italy.
C3 Sapienza University Rome
RP Sangineto, E (corresponding author), Elettr SPA, Via Tiburtina Valeria Km 13-7, Rome, Italy.
EM sangineto@di.uniroma1.it
RI Sangineto, Enver/AAS-9542-2020
OI Sangineto, Enver/0000-0002-5187-4133
CR ANELLI M, 2003, P IJCAI 2003 ACAP ME
   [Anonymous], 2004, 2004 C COMP VIS PATT
   [Anonymous], 1999, Visual Information Retrieval
   BALLARD DH, 1981, PATTERN RECOGN, V13, P111, DOI 10.1016/0031-3203(81)90009-1
   Beinglass A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P461, DOI 10.1109/CVPR.1991.139736
   Belongie S, 2002, IEEE T PATTERN ANAL, V24, P509, DOI 10.1109/34.993558
   BHANDARKAR SM, 1994, IEEE T SYST MAN CYB, V24, P745, DOI 10.1109/21.293488
   Bonnet N, 2002, PATTERN RECOGN, V35, P1193, DOI 10.1016/S0031-3203(01)00219-9
   Brandt S, 2000, INT C PATT RECOG, P1062, DOI 10.1109/ICPR.2000.906258
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chau CP, 2004, COMPUT VIS IMAGE UND, V96, P1, DOI 10.1016/j.cviu.2004.04.005
   CHENG YZ, 1995, IEEE T PATTERN ANAL, V17, P790, DOI 10.1109/34.400568
   COLOMBO C, 2002, VISIBLE IMAGE RETRIE, P11
   DelBimbo A, 1997, IEEE T PATTERN ANAL, V19, P121, DOI 10.1109/34.574790
   DISCIASCIO E, 1996, J COMP INF TECHNOL, V4
   Ecabert O, 2004, PATTERN RECOGN LETT, V25, P1411, DOI 10.1016/j.patrec.2004.05.009
   Flickner M., 1995, IEEE COMPUT, V28, P23, DOI DOI 10.1109/2.410146
   Folkers A, 2002, INT C PATT RECOG, P521, DOI 10.1109/ICPR.2002.1047991
   Gdalyahu Y, 1999, IEEE T PATTERN ANAL, V21, P1312, DOI 10.1109/34.817410
   Hough P.V., 1962, U.S. Patent, Patent No. 3069654
   ILLINGWORTH J, 1987, IEEE T PATTERN ANAL, V9, P690, DOI 10.1109/TPAMI.1987.4767964
   Jain AK, 1996, IEEE T PATTERN ANAL, V18, P267, DOI 10.1109/34.485555
   KASS M, 1987, INT J COMPUT VISION, V1, P321, DOI 10.1007/BF00133570
   Kassim AA, 1999, IMAGE VISION COMPUT, V17, P737, DOI 10.1016/S0262-8856(98)00156-5
   KIMIA BB, 2002, IMAGE DATABASES SEAR, P345
   Kimura A, 2002, INT C PATT RECOG, P65, DOI 10.1109/ICPR.2002.1044613
   Koffka Kurt, 2013, PRINCIPLES GESTALT P
   Latecki LJ, 2000, PROC CVPR IEEE, P424, DOI 10.1109/CVPR.2000.855850
   Li ZN, 1999, J VIS COMMUN IMAGE R, V10, P219, DOI 10.1006/jvci.1998.0403
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Mokhtarian F, 2002, PATTERN RECOGN, V35, P31, DOI 10.1016/S0031-3203(01)00040-1
   MORI G, 2003, P CVPR 03
   SER PK, 1995, J VIS COMMUN IMAGE R, V6, P256, DOI 10.1006/jvci.1995.1022
   Sharvit D, 1998, J VIS COMMUN IMAGE R, V9, P366, DOI 10.1006/jvci.1998.0396
   Smeulders AWM, 2000, IEEE T PATTERN ANAL, V22, P1349, DOI 10.1109/34.895972
   Soffer M, 1998, COMPUT VIS IMAGE UND, V69, P119, DOI 10.1006/cviu.1997.0557
   SUAREZ O, 1999, IEEE T PAMI, V21, P946
   Tek H, 2001, J MATH IMAGING VIS, V14, P211, DOI 10.1023/A:1011229911541
   THAYANANTHAN A, 2003, P CVPR 05, V1
   VIOLA P, 2001, P 2 INT WORK STAT CO
   Xue Z, 2002, IMAGE VISION COMPUT, V20, P77, DOI 10.1016/S0262-8856(01)00078-6
NR 41
TC 4
Z9 8
U1 1
U2 5
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD NOV 1
PY 2007
VL 25
IS 11
BP 1802
EP 1813
DI 10.1016/j.imavis.2007.03.002
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 207IN
UT WOS:000249244900009
DA 2024-07-18
ER

PT J
AU Han-Hai, C
   Chang-Hou, L
   Chun-Yi, S
AF Han-Hai, Cao
   Chang-Hou, Lu
   Chun-Yi, Shi
TI Product quality on-line inspecting for the pressed protuberant character
   on a metal tag
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE pressed protuberant character; ring projection; vector sum; quality
   inspecting
AB The pressed protuberant character is a reflectorized character based on the difference of reflectance. The quality of its image is lower than the image of the generally character based on the chromatic difference between background and foreground. So, the general quality inspecting method based on the binary-scale character cannot adapt for the protuberant character. To solve this problem, a new method of direct gray-scale feature extraction based on the ring projection algorithm and the vector sum for inspecting the quality of the pressed character is presented. The new method keeps integrity feature of the protuberant character information dramatically, and can overcome the main shortages of the traditional method on binary-scale image, such as depending on a binarization algorithm extremely, lower performance of anti-jamming. A limited set of the tag pressed protuberant characters is extracted feature and inspected by the new method. The results show that the proposed method adapts to the variant gray-scale, location and orientation of the character, can yield an excellent performance on the condition of noise and deformity, and its accuracy is 97.27%. It is easy to control the pressed character quality using to adjust the inspecting threshold value. It has highly worth applying to correlated fields. (c) 2006 Elsevier B.V. All rights reserved.
C1 Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
   Shandong Univ, Sch Mech Engn, Jinan 250061, Peoples R China.
   Shenzhen Modern Comp Manufacturer Co Ltd, Shenzhen 518057, Peoples R China.
C3 Tsinghua University; Shandong University
RP Han-Hai, C (corresponding author), Tsinghua Univ, Dept Comp Sci & Technol, Beijing 100084, Peoples R China.
EM cjh800@l63.com
CR Cappelli R, 2001, IEEE T PATTERN ANAL, V23, P977, DOI 10.1109/34.955111
   Choi MS, 2002, PATTERN RECOGN, V35, P119, DOI 10.1016/S0031-3203(01)00025-5
   JIANHAI C, 2004, J OPTOELECTRONICS LA, V15, P477
   Lee SW, 1996, IEEE T PATTERN ANAL, V18, P1045, DOI 10.1109/34.541415
   PARK HS, 1996, SPIE, V3027, P40
   Pavlidis T, 2003, PATTERN RECOGN LETT, V24, P1, DOI 10.1016/S0167-8655(02)00211-8
   PROKOP RJ, 1992, CVGIP-GRAPH MODEL IM, V54, P438, DOI 10.1016/1049-9652(92)90027-U
   ROSENFELD A, 1982, DIGITAL IMAGE PROCES, V2
   SECILLA JP, 1988, SIGNAL PROCESS, V14, P347, DOI 10.1016/0165-1684(88)90093-X
   Tang Y. Y., 1991, International Journal of Pattern Recognition and Artificial Intelligence, V5, P25, DOI 10.1142/S0218001491000053
   Tsai DM, 2002, PATTERN RECOGN LETT, V23, P191, DOI 10.1016/S0167-8655(01)00099-X
   Tsai DM, 2003, MACH VISION APPL, V13, P194, DOI 10.1007/s00138-002-0069-y
   WANG L, 1993, IEEE T PATTERN ANAL, V15, P1053, DOI 10.1109/34.254062
   WEIFENG J, 2001, J IMAGE GRAPHICS, V2, P186
   WONG RY, 1978, IEEE T COMPUT, V27, P359, DOI 10.1109/TC.1978.1675108
   YIQUAN W, 1993, J DATA ACQUISITION P, V4, P268
   YUANG Y, 1999, INT J PATTERN RECOGN, V6, P803
NR 17
TC 4
Z9 5
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1255
EP 1262
DI 10.1016/j.imavis.2006.07.025
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000006
DA 2024-07-18
ER

PT J
AU Schellewald, C
   Roth, S
   Schnörr, C
AF Schellewald, Christian
   Roth, Stefan
   Schnoerr, Christoph
TI Evaluation of a convex relaxation to a quadratic assignment matching
   approach for relational object views
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE quadratic assignment; weighted graph matching; combinatorial
   optimization; convex programming; object recognition
ID EM ALGORITHM; GRAPHS
AB We introduce a convex relaxation approach for the quadratic assignment problem to the field of computer vision. Due to convexity, a favourable property of this approach is the absence of any tuning parameters and the computation of high-quality combinatorial solutions by solving a mathematically simple optimization problem. Furthermore, the relaxation step always computes a tight lower bound of the objective function and thus can additionally be used as an efficient subroutine of an exact search algorithm. We report the results of both established benchmark experiments from combinatorial mathematics and random ground-truth experiments using computer-generated graphs. For comparison, a deterministic annealing approach is investigated as well. Both approaches show similarly good performance. In contrast to the convex approach, however, the annealing approach yields no problem relaxation, and four parameters have to be tuned by hand for the annealing algorithm to become competitive. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Mannheim, Dept Math & Comp Sci, CVGPR Grp, D-68131 Mannheim, Germany.
   Brown Univ, Dept Comp Sci, Providence, RI 02912 USA.
C3 University of Mannheim; Brown University
RP Schellewald, C (corresponding author), Univ Mannheim, Dept Math & Comp Sci, CVGPR Grp, D-68131 Mannheim, Germany.
EM c.schellewald@psyreon.de; roth@cs.brown.edu; schnoerr@uni-mannheim.de
OI Roth, Stefan/0000-0001-9002-9832; Schellewald,
   Christian/0000-0002-2003-6612
CR ALMOHAMAD HA, 1993, IEEE T PATTERN ANAL, V15, P522, DOI 10.1109/34.211474
   [Anonymous], 1997, Local Search in Combinatorial Optimization
   [Anonymous], 1987, Visual Reconstruction
   [Anonymous], 1987, North-Holland Mathematics Studies, DOI DOI 10.1016/S0304-0208(08)73232-8
   Anstreicher K, 2000, SIAM J MATRIX ANAL A, V22, P41, DOI 10.1137/S0895479898340299
   BAZARAA MS, 1982, J OPER RES SOC, V33, P991, DOI 10.1057/jors.1982.210
   Brixius NW, 2001, OPTIM METHOD SOFTW, V16, P49, DOI 10.1080/10556780108805828
   BULTHOFF H, 1992, P NATL ACAD SCI USA, V92, P60
   Bunke H, 1999, IEEE T PATTERN ANAL, V21, P917, DOI 10.1109/34.790431
   Burkard Rainer E, 1998, Handbook of Combinatorial Optimization, P1713, DOI 10.1007/978-1-4613-0303-9_27
   Burkard RE, 1997, J GLOBAL OPTIM, V10, P391, DOI 10.1023/A:1008293323270
   CHRISTMAS WJ, 1995, IEEE T PATTERN ANAL, V17, P749, DOI 10.1109/34.400565
   Cross ADJ, 1998, IEEE T PATTERN ANAL, V20, P1236, DOI 10.1109/34.730557
   Cross ADJ, 1997, PATTERN RECOGN, V30, P953, DOI 10.1016/S0031-3203(96)00123-9
   Drezner Z, 2003, INFORMS J COMPUT, V15, P320, DOI 10.1287/ijoc.15.3.320.16076
   FORSTNER W, 1994, COMPUTER VISION ECCV, V801, P61
   Gambardella LM, 1999, J OPER RES SOC, V50, P167, DOI 10.1057/palgrave.jors.2600676
   Garey M.R., 1991, COMPUTERS INTRACTABI
   GEIGER D, 1991, IEEE T PATTERN ANAL, V13, P401, DOI 10.1109/34.134040
   GEIGER D, 1991, INT J COMPUT VISION, V6, P227, DOI 10.1007/BF00115697
   GILMORE PC, 1962, J SOC IND APPL MATH, V10, P305, DOI 10.1137/0110022
   Gold S, 1996, IEEE T PATTERN ANAL, V18, P377, DOI 10.1109/34.491619
   HADLEY SW, 1992, MATH OPER RES, V17, P727, DOI 10.1287/moor.17.3.727
   HERBERT M, 1995, OBJECT REPRESENTATIO
   Hofmann T, 1997, IEEE T PATTERN ANAL, V19, P1, DOI 10.1109/34.566806
   Ishii S, 2002, NEUROCOMPUTING, V43, P239, DOI 10.1016/S0925-2312(01)00343-5
   KOSOWSKY JJ, 1994, NEURAL NETWORKS, V7, P477, DOI 10.1016/0893-6080(94)90081-7
   KREE R, 1988, J PHYS A-MATH GEN, V21, pL813, DOI 10.1088/0305-4470/21/16/006
   LAWLER EL, 1963, MANAGE SCI, V9, P586, DOI 10.1287/mnsc.9.4.586
   LECLERC YG, 1989, INT J COMPUT VISION, V3, P73, DOI 10.1007/BF00054839
   Luo B, 2001, IEEE T PATTERN ANAL, V23, P1120, DOI 10.1109/34.954602
   MATSUI S, 2004, P IJCNN, P2221
   Messmer BT, 1998, IEEE T PATTERN ANAL, V20, P493, DOI 10.1109/34.682179
   Misevicius A, 2003, INFORMATICA-LITHUAN, V14, P497
   Nesterov Y., 1994, SIAM SERIES APPL MAT
   Pardalos PM, 1997, SIAM J OPTIMIZ, V7, P280, DOI 10.1137/S1052623494273393
   Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105
   Peterson C., 1989, International Journal of Neural Systems, V1, P3, DOI 10.1142/S0129065789000414
   Rangarajan A, 1999, NEURAL COMPUT, V11, P1455, DOI 10.1162/089976699300016313
   Rao AV, 1999, IEEE T PATTERN ANAL, V21, P159, DOI 10.1109/34.748824
   ROTH S, 2001, THESIS U MANNHEIM
   SAHNI S, 1976, J ACM, V23, P555, DOI 10.1145/321958.321975
   Sato M, 1996, PHYS REV E, V53, P5153, DOI 10.1103/PhysRevE.53.5153
   SCHELLEWALD C, 2005, THESIS U MANNHEIM
   Simic PD, 1991, NEURAL COMPUT, V3, P268, DOI 10.1162/neco.1991.3.2.268
   UMEYAMA S, 1988, IEEE T PATTERN ANAL, V10, P695, DOI 10.1109/34.6778
   Yuille AL, 1990, NEURAL COMPUT, V2, P1, DOI 10.1162/neco.1990.2.1.1
NR 47
TC 9
Z9 10
U1 0
U2 3
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD AUG 1
PY 2007
VL 25
IS 8
BP 1301
EP 1314
DI 10.1016/j.imavis.2006.08.005
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 187KH
UT WOS:000247846000011
DA 2024-07-18
ER

PT J
AU Keshet, R
AF Keshet, Renato
TI Adjacency lattices and shape-tree semilattices
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE complete inf-semilattices; self-dual operators; tree of shapes; fillhole
ID MORPHOLOGICAL OPERATORS
AB This paper further investigates a new approach for self-dual morphological processing, where eroded images have all shapes shrunk in a contrast-invariant way. In the binary case, we operate on a given image with morphological operators in the so-called "adjacency lattice," which is intimately related to the image's adjacency tree. These operators are generalized to grayscale images by means of the so-called "shape-tree semilattice," which is based on the tree of shapes of the given image. Apart of reviewing their original definition, different algorithms for computing the shape-tree morphological operators are addressed. (c) 2006 Elsevier B.V. All rights reserved.
C1 Technion Israel Inst Technol, Hewlett Packard Labs, IL-32000 Haifa, Israel.
C3 Hewlett-Packard; Technion Israel Institute of Technology
RP Keshet, R (corresponding author), Technion Israel Inst Technol, Hewlett Packard Labs, IL-32000 Haifa, Israel.
EM renato.keshet@hp.com
CR Ballester C, 2003, ESAIM CONTR OPTIM CA, V9, P1, DOI 10.1051/cocv:2002069
   Caselles V, 2002, J MATH IMAGING VIS, V17, P249, DOI 10.1023/A:1020715626538
   Heijmans HJAM, 2002, J MATH IMAGING VIS, V17, P55, DOI 10.1023/A:1020726725590
   Heijmans HJAM, 1999, COMPUT VIS IMAGE UND, V73, P99, DOI 10.1006/cviu.1998.0703
   Heijmans HJAM, 1996, J MATH IMAGING VIS, V6, P15, DOI 10.1007/BF00127373
   Keshet R, 2005, J MATH IMAGING VIS, V22, P309, DOI 10.1007/s10851-005-4896-0
   Keshet R, 2005, COMP IMAG VIS, V30, P139
   Keshet R., 2000, Fundamenta Informaticae, V41, P33
   Mehnert AJH, 2000, COMP IMAG VIS, V18, P99
   Meyer F, 1998, COMP IMAG VIS, V12, P199
   Meyer F, 1998, COMP IMAG VIS, V12, P191
   Monasse P, 2000, J VIS COMMUN IMAGE R, V11, P224, DOI 10.1006/jvci.1999.0441
   Monasse P, 2000, IEEE T IMAGE PROCESS, V9, P860, DOI 10.1109/83.841532
   RAY N, 2003, P IEEE INT C IMAGE P
   Salembier P, 2002, PATTERN RECOGN, V35, P563, DOI 10.1016/S0031-3203(01)00060-7
   Salembier P, 2000, IEEE T IMAGE PROCESS, V9, P561, DOI 10.1109/83.841934
   Serra J., 2000, Fundamenta Informaticae, V41, P147
   Soille P, 2002, IEEE T GEOSCI REMOTE, V40, P2042, DOI 10.1109/TGRS.2002.804618
   Soille P., 2003, Morphological image analysis: principles and applications, Vsecond
   1982, J SERRAIMAGE ANAL MA, V1
NR 20
TC 7
Z9 7
U1 0
U2 1
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 436
EP 446
DI 10.1016/j.imavis.2006.04.016
PG 11
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600006
DA 2024-07-18
ER

PT J
AU Lerallut, R
   Decencière, É
   Meyer, F
AF Lerallut, Romain
   Decenciere, Etienne
   Meyer, Fernand
TI Image filtering using morphological amoebas
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 7th International Symposium on Mathematical Morphology
CY APR 18-20, 2005
CL Paris, FRANCE
DE anisotropic filters; noise reduction; morphological filters; color
   filters; 3D image processing
ID EDGE-DETECTION; DIFFUSION
AB This paper presents morphological operators with non-fixed shape kernels, or amoebas, which take into account the image contour variations to adapt their shape. Experiments on grayscale and color images demonstrate that these novel filters outperform classical morphological operations with a fixed, space-invariant structuring element for noise reduction applications. Tests on synthetic 3D images are then performed to show the high noise-reduction capacity of amoeba-based filters. (c) 2006 Elsevier B.V. All rights reserved.
C1 Ecole Mines Paris, Ctr Morphol Mathemat, F-77305 Fontainebleau, France.
C3 Universite PSL; MINES ParisTech
RP Lerallut, R (corresponding author), Ecole Mines Paris, Ctr Morphol Mathemat, 35 Rue St Honore, F-77305 Fontainebleau, France.
EM lerallut@emm.ensmp.fr
OI Decenciere, Etienne/0000-0002-1349-8042
CR [Anonymous], 1988, IMAGE ANAL MATH MORP
   BOEHM M, 2004, THESIS ECOLE MINES P
   Braga-Neto U., 1996, P INT S MATH MORPH I, P139
   Brodnik A, 2001, SIAM PROC S, P523
   CATTE F, 1992, SIAM J NUMER ANAL, V29, P182, DOI 10.1137/0729012
   CHERKASSKY BV, 1996, 96045 TR NEC RES I
   DEBAYLE J, 2005, P IEEE INT C IM PROC
   LERALLUT R, 2005, P 5 INT S MATH MORPH
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   TOMASI C, 1998, P IEEE INT C COMP VI
   Verly JG, 1993, IEEE T IMAGE PROCESS, V2, P272, DOI 10.1109/83.217233
NR 11
TC 102
Z9 108
U1 0
U2 15
PU ELSEVIER SCIENCE BV
PI AMSTERDAM
PA PO BOX 211, 1000 AE AMSTERDAM, NETHERLANDS
SN 0262-8856
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD APR 1
PY 2007
VL 25
IS 4
BP 395
EP 404
DI 10.1016/j.imavis.2006.04.018
PG 10
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Conference Proceedings Citation Index - Science (CPCI-S); Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 143NZ
UT WOS:000244730600002
OA Green Submitted
DA 2024-07-18
ER

PT J
AU Lombardi, L
   Petrosino, A
AF Lombardi, Luca
   Petrosino, Alfredo
TI Distributed recursive learning for shape recognition through multiscale
   trees
SO IMAGE AND VISION COMPUTING
LA English
DT Article; Proceedings Paper
CT 5th International Workshop on Fuzzy Logic and Applications
CY OCT 09-11, 2003
CL Naples, ITALY
DE multiscale tree representation; syntactic shape recognitiom; fuzzy
   neural networks; recursive learning
ID FINITE-STATE AUTOMATA; OBJECT RECOGNITION; SCALE-SPACE; REPRESENTATION;
   CLASSIFICATION; EDGES
AB The paper reports an efficient and fully parallel 2D shape recognition method based on the use of a multiscale tree representation of the shape boundary and recursive learning of trees. Specifically, the shape is represented by means of a tree where each node, corresponding to a boundary segment at some level of resolution, is characterized by a real vector containing curvature, length, symmetry of the boundary segment, while the nodes are connected by arcs when segments at successive levels are spatially related. The recognition procedure is formulated as a training procedure made by a Fuzzy recursive neural network followed by a testing procedure over unknown tree structured patterns. The proposed neural network model is able to facilitate the exchange of information between symbolic and sub-symbolic domains and deal with structured organization of information, that is typically required by symbolic processing. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Pavia, Dipartimento Informat & Sistemist, I-27100 Pavia, Italy.
   Univ Parthenope Napoli, Dipartimento Sci Applicate, I-80131 Naples, Italy.
C3 University of Pavia; Parthenope University Naples
RP Lombardi, L (corresponding author), Univ Pavia, Dipartimento Informat & Sistemist, Via Ferrata 1, I-27100 Pavia, Italy.
EM luca.lombardi@unipv.it; alfredo.petrosino@uniparthenope.it
CR [Anonymous], 1974, Syntactic Methods in Pattern Recognition
   BURT PJ, 1983, IEEE T COMMUN, V31, P532, DOI 10.1109/TCOM.1983.1095851
   BURT PS, 1988, P 11 INT C PATT REC, P977
   Cantoni V, 1998, PATTERN RECOGN, V31, P1443, DOI 10.1016/S0031-3203(97)00085-X
   Chang T, 1993, IEEE T IMAGE PROCESS, V2, P429, DOI 10.1109/83.242353
   CINQUE L, 1995, PATTERN RECOGN LETT, V16, P1097, DOI 10.1016/0167-8655(95)00056-M
   CLARK JJ, 1989, IEEE T PATTERN ANAL, V11, P43, DOI 10.1109/34.23112
   Di Ruberto C, 2004, PATTERN RECOGN, V37, P21, DOI 10.1016/j.patcog.2003.07.004
   DYER C. R., 1987, PARALLEL COMPUTER VI, P171
   Fdez-Valdivia J, 1998, IEEE T PATTERN ANAL, V20, P458, DOI 10.1109/34.682176
   Fitch AJ, 2002, INT C PATT RECOG, P903, DOI 10.1109/ICPR.2002.1048178
   Frasconi P, 1996, MACH LEARN, V23, P5
   Frasconi P, 1998, IEEE T NEURAL NETWOR, V9, P768, DOI 10.1109/72.712151
   FU FS, 1973, IEEE T COMPUTER C, V22, P1087
   Gauch JM, 1999, IEEE T IMAGE PROCESS, V8, P69, DOI 10.1109/83.736688
   Gori M, 2004, IEEE T NEURAL NETWOR, V15, P1435, DOI 10.1109/TNN.2004.837585
   Guerra C, 1998, PATTERN RECOGN, V31, P83, DOI 10.1016/S0031-3203(97)00032-0
   Jang J-SR, 1997, IEEE T AUTOMAT CONTR, V42, P1482
   Juang CF, 1999, IEEE T NEURAL NETWOR, V10, P828, DOI 10.1109/72.774232
   KAPUR JN, 1985, COMPUTER VISION GRAP, V29
   KASHYAP R, 1981, IEEE T INFORM THEORY, V27, P109
   LEE JS, 1995, IEEE T IMAGE PROCESS, V4, P100, DOI 10.1109/83.350810
   LOMBARDI L, 2005, LECT NOTES COMPUTER, V2955, P255
   LU Y, 1989, IEEE T PATTERN ANAL, V11, P337, DOI 10.1109/34.19032
   Messmer BT, 2000, IEEE T KNOWL DATA EN, V12, P307, DOI 10.1109/69.842269
   MOKHTARIAN F, 1995, IEEE T PATTERN ANAL, V17, P539, DOI 10.1109/34.391387
   Omlin CW, 1996, J ACM, V43, P937, DOI 10.1145/235809.235811
   Oommen BJ, 1996, IEEE T COMPUT, V45, P1426, DOI 10.1109/12.545972
   PAL NR, 1993, PATTERN RECOGN, V26, P543, DOI 10.1016/0031-3203(93)90109-A
   Pelillo M, 1999, IEEE T PATTERN ANAL, V21, P1105, DOI 10.1109/34.809105
   PERONA P, 1990, IEEE T PATTERN ANAL, V12, P629, DOI 10.1109/34.56205
   PETROSINO A, 2005, SYSTEMATIC APROACH R
   Pichler O, 1996, PATTERN RECOGN, V29, P733, DOI 10.1016/0031-3203(95)00127-1
   POWELL MJD, 1977, MATH PROGRAM, V12, P241, DOI 10.1007/BF01593790
   RAY BK, PATTERN RECOGNITION, V30, P1463
   ROSENFELD A, 1996, J ACM, V43, P937
   ROSENFELD A, 1993, IEEE T PATTERN ANAL, V15, P337
   Safar M, 2000, 2000 IEEE INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, PROCEEDINGS VOLS I-III, P141, DOI 10.1109/ICME.2000.869564
   Sperduti A, 1997, IEEE T NEURAL NETWOR, V8, P714, DOI 10.1109/72.572108
   UEDA N, 1993, IEEE T PATTERN ANAL, V15, P337, DOI 10.1109/34.206954
   Vincken KL, 1997, IEEE T PATTERN ANAL, V19, P109, DOI 10.1109/34.574787
   WANG JTL, 1994, IEEE T KNOWL DATA EN, V6, P559, DOI 10.1109/69.298173
   Wang YP, 1998, IEEE T PATTERN ANAL, V20, P1040, DOI 10.1109/34.722612
   Zhang SG, 2001, NETWORKS, V37, P102, DOI 10.1002/1097-0037(200103)37:2<102::AID-NET5>3.0.CO;2-S
NR 44
TC 4
Z9 5
U1 0
U2 2
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD FEB 1
PY 2007
VL 25
IS 2
BP 240
EP 247
DI 10.1016/j.imavis.2006.01.022
PG 8
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED); Conference Proceedings Citation Index - Science (CPCI-S)
SC Computer Science; Engineering; Optics
GA 123HT
UT WOS:000243287700013
DA 2024-07-18
ER

PT J
AU Hsiao, YT
   Chuang, CL
   Lu, YL
   Jiang, JA
AF Hsiao, Ying-Tung
   Chuang, Cheng-Long
   Lu, Yen-Ling
   Jiang, Joe-Air
TI Robust multiple objects tracking using image segmentation and trajectory
   estimation scheme in video frames
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE mathematical morphology; edge detection; image segmentation; motion
   estimation
AB In this paper, a novel image segmentation and a robust unsupervised video objects tracking algorithm are proposed. The proposed method is able to track complete object regions in a sequence of video frames. In this work, object tracking is achieved by analysing the movement of the contours with frame by frame in the video stream. The proposed algorithm involves with three major components for analysing the shapes and motions of the object in the video frames. First, a modified mathematical morphology edge detection algorithm is utilized to extract the contour features in the video frames. Then, a contour-based image segmentation algorithm is proposed and applied to the contour features for partitioning the predetermined target objects in the video frames. Finally, a trajectory estimation scheme is developed to handle the movements of the objects in the video frames. The proposed image segmentation algorithm is capable of automatically partitioning the predetermined objects. The proposed tracking algorithm is also robust against overlapping and videos acquired by non-stationary cameras. The experimental results show that the proposed algorithm can precisely partition and track the predetermined objects in video frames. (c) 2006 Elsevier B.V. All rights reserved.
C1 Natl Taiwan Univ, Dept BioInd Mechatron Engn, Taipei 106, Taiwan.
   Natl Taiwan Univ Educ, Dept Comp Sci, Taipei, Taiwan.
   Natl Taiwan Univ Educ, Grad Sch Comp Sci, Taipei, Taiwan.
   Cent Personnel Adm, Informat Off, Taipei, Taiwan.
C3 National Taiwan University; National Taiwan University; National Taiwan
   University
RP Jiang, JA (corresponding author), Natl Taiwan Univ, Dept BioInd Mechatron Engn, 1,Sect 4,Roosevelt Rd, Taipei 106, Taiwan.
EM jajiang@ntu.edu.tw
RI Chuang, Cheng-Long/IQU-5029-2023
OI Chuang, Cheng-Long/0000-0003-1913-8168; Jiang,
   Joe-Air/0000-0001-9886-1404
CR Chang SF, 2001, IEEE T CIRC SYST VID, V11, P688, DOI 10.1109/76.927421
   CHIARIGLIONE L, 1997, IEEE T CIRCUITS SYST, P25
   Comaniciu D, 2003, IEEE T PATTERN ANAL, V25, P564, DOI 10.1109/TPAMI.2003.1195991
   Comaniciu D, 2000, PROC CVPR IEEE, P142, DOI 10.1109/CVPR.2000.854761
   HONG TH, 1984, IEEE T PATTERN ANAL, V6, P222, DOI 10.1109/TPAMI.1984.4767505
   Hsiao YT, 2004, PROCEEDINGS OF THE FOURTH IEEE INTERNATIONAL SYMPOSIUM ON SIGNAL PROCESSING AND INFORMATION TECHNOLOGY, P310, DOI 10.1109/ISSPIT.2004.1433746
   HUANG CP, 2002, THESIS TAMKANG U TAI
   JEPSON AD, 2003, IEEE T PATTERN ANAL, P415
   LEONARDIS L, 1995, INT J COMPUT VISION, P253
   Patras I, 2001, IEEE T PATTERN ANAL, V23, P326, DOI 10.1109/34.910886
   RITTSCHER J, 2000, P EUR C COMP
   Serra J., 1983, IMAGE ANAL MATH MORP
   YEZZI A, 2001, P INT C COMP VIS, P56
   Yilmaz A, 2004, IEEE T PATTERN ANAL, V26, P1531, DOI 10.1109/TPAMI.2004.96
NR 14
TC 27
Z9 31
U1 0
U2 8
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1123
EP 1136
DI 10.1016/j.imavis.2006.04.002
PG 14
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300008
DA 2024-07-18
ER

PT J
AU Kato, Z
   Pong, TC
AF Kato, Zoltan
   Pong, Ting-Chuen
TI A Markov random field image segmentation model for color textured images
SO IMAGE AND VISION COMPUTING
LA English
DT Article
DE segmentation; color; texture; Markov random fields; parameter estimation
ID UNSUPERVISED SEGMENTATION; MAXIMUM-LIKELIHOOD; CLASSIFICATION
AB We propose a Markov random field (MRF) image segmentation model, which aims at combining color and texture features. The theoretical framework relies on Bayesian estimation via combinatorial optimization (simulated annealing). The segmentation is obtained by classifying the pixels into different pixel classes. These classes are represented by multi-variate Gaussian distributions. Thus, the only hypothesis about the nature of the features is that an additive Gaussian noise model is suitable to describe the feature distribution belonging to a given class. Here, we use the perceptually uniform CIE-L*u*v* color values as color features and a set of Gabor filters as texture features. Gaussian parameters are either computed using a training data set or estimated from the input image. We also propose a parameter estimation method using the EM algorithm. Experimental results are provided to illustrate the performance of our method on both synthetic and natural color images. (c) 2006 Elsevier B.V. All rights reserved.
C1 Univ Szeged, Dept Informat, H-6701 Szeged, Hungary.
   Hong Kong Univ Sci & Technol, Dept Comp Sci, Kowloon, Hong Kong, Peoples R China.
C3 Szeged University; Hong Kong University of Science & Technology
RP Kato, Z (corresponding author), Univ Szeged, Dept Informat, POB 652, H-6701 Szeged, Hungary.
EM kato@inf.u-szeged.hu; tcpong@cs.ust.hk
RI Kato, Zoltan/AAD-6406-2019; Kato, Zenichiro/E-8900-2010
CR [Anonymous], EXACTLY SOLVED MODEL
   [Anonymous], 1987, Visual Reconstruction
   [Anonymous], P INT GEOSC REM SENS
   [Anonymous], 2002, ART H SIG PROC LIB
   Barker SA, 2000, PATTERN RECOGN, V33, P587, DOI 10.1016/S0031-3203(99)00074-6
   Berthod M, 1996, IMAGE VISION COMPUT, V14, P285, DOI 10.1016/0262-8856(95)01072-6
   BESAG J, 1986, J R STAT SOC B, V48, P259
   BRAATHEN B, 1993, MACHINE GRAPHICS VIS, V2, P39
   Celeux G., 1985, Computational Statistics Quarterly, V2, P73
   CHALMOND B, 1989, PATTERN RECOGN, V22, P747, DOI 10.1016/0031-3203(89)90011-3
   Chalmond B., 2003, Modeling and Inverse Problems in Image Analysis
   COLANTONI P, 2004, COLORSPACE 1 06 SOFT
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Deng YN, 2001, IEEE T PATTERN ANAL, V23, P800, DOI 10.1109/34.946985
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   HUANG CL, 1992, PATTERN RECOGN, V25, P1217, DOI 10.1016/0031-3203(92)90023-C
   JAIN AK, 1991, PATTERN RECOGN, V24, P1167, DOI 10.1016/0031-3203(91)90143-S
   Kato Z, 2003, IEEE IMAGE PROC, P961
   Kato Z, 1999, PATTERN RECOGN, V32, P591, DOI 10.1016/S0031-3203(98)00104-6
   KATO Z, 1995, INT CONF ACOUST SPEE, P2399, DOI 10.1109/ICASSP.1995.479976
   KATO Z, 2004, P BRIT MACH VIS C, V1, P37
   Kersten D, 2004, ANNU REV PSYCHOL, V55, P271, DOI 10.1146/annurev.psych.55.090902.142005
   LIU JQ, 1994, IEEE T PATTERN ANAL, V16, P689, DOI 10.1109/34.297949
   MASSON P, 1993, IEEE T GEOSCI REMOTE, V31, P618, DOI 10.1109/36.225529
   Mirmehdi M, 2000, IEEE T PATTERN ANAL, V22, P142, DOI 10.1109/34.825753
   *MIT VISTEX, 1995, TEXT DAT
   MUMFORD D, 1989, COMMUN PUR APPL MATH, V42, P577, DOI 10.1002/cpa.3160420503
   Mumford D., 1996, PERCEPTION BAYESIAN, P25
   Mumford D., 1994, GEOMETRY DRIVEN DIFF, P141
   Nammalwar P, 2004, INT C PATT RECOG, P716, DOI 10.1109/ICPR.2004.1334283
   PANJWANI DK, 1995, IEEE T PATTERN ANAL, V17, P939, DOI 10.1109/34.464559
   Permuter H, 2006, PATTERN RECOGN, V39, P695, DOI 10.1016/j.patcog.2005.10.028
   Randen T, 1999, IEEE T PATTERN ANAL, V21, P291, DOI 10.1109/34.761261
   REDNER RA, 1984, SIAM REV, V26, P195, DOI 10.1137/1026034
   Sangwine S. J., 1998, The colour image processing handbook
   Shi JB, 2000, IEEE T PATTERN ANAL, V22, P888, DOI 10.1109/34.868688
   Vandenbroucke N, 2000, INT C PATT RECOG, P621, DOI 10.1109/ICPR.2000.903622
   Winkler G., 2003, RANDOM FIELDS MARKOV
   Zoltan Kato, 2001, Computer Analysis of Images and Patterns. 9th International Conference, CAIP 2001. Proceedings (Lecture Notes in Computer Science Vol.2124), P547
NR 39
TC 133
Z9 163
U1 0
U2 17
PU ELSEVIER
PI AMSTERDAM
PA RADARWEG 29, 1043 NX AMSTERDAM, NETHERLANDS
SN 0262-8856
EI 1872-8138
J9 IMAGE VISION COMPUT
JI Image Vis. Comput.
PD OCT 1
PY 2006
VL 24
IS 10
BP 1103
EP 1114
DI 10.1016/j.imavis.2006.03.005
PG 12
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic; Optics
WE Science Citation Index Expanded (SCI-EXPANDED)
SC Computer Science; Engineering; Optics
GA 094GQ
UT WOS:000241228300006
OA Green Submitted
DA 2024-07-18
ER

EF